[
    {
        "func_name": "__init__",
        "original": "def __init__(self, input_ids, input_mask, segment_ids, label_id, is_real_example=True):\n    self.input_ids = input_ids\n    self.input_mask = input_mask\n    self.segment_ids = segment_ids\n    self.label_id = label_id\n    self.is_real_example = is_real_example",
        "mutated": [
            "def __init__(self, input_ids, input_mask, segment_ids, label_id, is_real_example=True):\n    if False:\n        i = 10\n    self.input_ids = input_ids\n    self.input_mask = input_mask\n    self.segment_ids = segment_ids\n    self.label_id = label_id\n    self.is_real_example = is_real_example",
            "def __init__(self, input_ids, input_mask, segment_ids, label_id, is_real_example=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.input_ids = input_ids\n    self.input_mask = input_mask\n    self.segment_ids = segment_ids\n    self.label_id = label_id\n    self.is_real_example = is_real_example",
            "def __init__(self, input_ids, input_mask, segment_ids, label_id, is_real_example=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.input_ids = input_ids\n    self.input_mask = input_mask\n    self.segment_ids = segment_ids\n    self.label_id = label_id\n    self.is_real_example = is_real_example",
            "def __init__(self, input_ids, input_mask, segment_ids, label_id, is_real_example=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.input_ids = input_ids\n    self.input_mask = input_mask\n    self.segment_ids = segment_ids\n    self.label_id = label_id\n    self.is_real_example = is_real_example",
            "def __init__(self, input_ids, input_mask, segment_ids, label_id, is_real_example=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.input_ids = input_ids\n    self.input_mask = input_mask\n    self.segment_ids = segment_ids\n    self.label_id = label_id\n    self.is_real_example = is_real_example"
        ]
    },
    {
        "func_name": "_truncate_seq_pair",
        "original": "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_length:\n            break\n        if len(tokens_a) > len(tokens_b):\n            tokens_a.pop()\n        else:\n            tokens_b.pop()",
        "mutated": [
            "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n    if False:\n        i = 10\n    'Truncates a sequence pair in place to the maximum length.'\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_length:\n            break\n        if len(tokens_a) > len(tokens_b):\n            tokens_a.pop()\n        else:\n            tokens_b.pop()",
            "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Truncates a sequence pair in place to the maximum length.'\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_length:\n            break\n        if len(tokens_a) > len(tokens_b):\n            tokens_a.pop()\n        else:\n            tokens_b.pop()",
            "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Truncates a sequence pair in place to the maximum length.'\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_length:\n            break\n        if len(tokens_a) > len(tokens_b):\n            tokens_a.pop()\n        else:\n            tokens_b.pop()",
            "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Truncates a sequence pair in place to the maximum length.'\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_length:\n            break\n        if len(tokens_a) > len(tokens_b):\n            tokens_a.pop()\n        else:\n            tokens_b.pop()",
            "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Truncates a sequence pair in place to the maximum length.'\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_length:\n            break\n        if len(tokens_a) > len(tokens_b):\n            tokens_a.pop()\n        else:\n            tokens_b.pop()"
        ]
    },
    {
        "func_name": "convert_single_example",
        "original": "def convert_single_example(example_index, example, label_list, max_seq_length, tokenize_fn, use_bert_format):\n    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n    if isinstance(example, PaddingInputExample):\n        return InputFeatures(input_ids=[0] * max_seq_length, input_mask=[1] * max_seq_length, segment_ids=[0] * max_seq_length, label_id=0, is_real_example=False)\n    if label_list is not None:\n        label_map = {}\n        for (i, label) in enumerate(label_list):\n            label_map[label] = i\n    tokens_a = tokenize_fn(example.text_a)\n    tokens_b = None\n    if example.text_b:\n        tokens_b = tokenize_fn(example.text_b)\n    if tokens_b:\n        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n    elif len(tokens_a) > max_seq_length - 2:\n        tokens_a = tokens_a[:max_seq_length - 2]\n    tokens = []\n    segment_ids = []\n    for token in tokens_a:\n        tokens.append(token)\n        segment_ids.append(SEG_ID_A)\n    tokens.append(data_utils.SEP_ID)\n    segment_ids.append(SEG_ID_A)\n    if tokens_b:\n        for token in tokens_b:\n            tokens.append(token)\n            segment_ids.append(SEG_ID_B)\n        tokens.append(data_utils.SEP_ID)\n        segment_ids.append(SEG_ID_B)\n    if use_bert_format:\n        tokens.insert(0, data_utils.CLS_ID)\n        segment_ids.insert(0, data_utils.SEG_ID_CLS)\n    else:\n        tokens.append(data_utils.CLS_ID)\n        segment_ids.append(data_utils.SEG_ID_CLS)\n    input_ids = tokens\n    input_mask = [0] * len(input_ids)\n    if len(input_ids) < max_seq_length:\n        delta_len = max_seq_length - len(input_ids)\n        if use_bert_format:\n            input_ids = input_ids + [0] * delta_len\n            input_mask = input_mask + [1] * delta_len\n            segment_ids = segment_ids + [data_utils.SEG_ID_PAD] * delta_len\n        else:\n            input_ids = [0] * delta_len + input_ids\n            input_mask = [1] * delta_len + input_mask\n            segment_ids = [data_utils.SEG_ID_PAD] * delta_len + segment_ids\n    assert len(input_ids) == max_seq_length\n    assert len(input_mask) == max_seq_length\n    assert len(segment_ids) == max_seq_length\n    if label_list is not None:\n        label_id = label_map[example.label]\n    else:\n        label_id = example.label\n    if example_index < 5:\n        logging.info('*** Example ***')\n        logging.info('guid: %s', example.guid)\n        logging.info('input_ids: %s', ' '.join([str(x) for x in input_ids]))\n        logging.info('input_mask: %s', ' '.join([str(x) for x in input_mask]))\n        logging.info('segment_ids: %s', ' '.join([str(x) for x in segment_ids]))\n        logging.info('label: %d (id = %d)', example.label, label_id)\n    feature = InputFeatures(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id)\n    return feature",
        "mutated": [
            "def convert_single_example(example_index, example, label_list, max_seq_length, tokenize_fn, use_bert_format):\n    if False:\n        i = 10\n    'Converts a single `InputExample` into a single `InputFeatures`.'\n    if isinstance(example, PaddingInputExample):\n        return InputFeatures(input_ids=[0] * max_seq_length, input_mask=[1] * max_seq_length, segment_ids=[0] * max_seq_length, label_id=0, is_real_example=False)\n    if label_list is not None:\n        label_map = {}\n        for (i, label) in enumerate(label_list):\n            label_map[label] = i\n    tokens_a = tokenize_fn(example.text_a)\n    tokens_b = None\n    if example.text_b:\n        tokens_b = tokenize_fn(example.text_b)\n    if tokens_b:\n        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n    elif len(tokens_a) > max_seq_length - 2:\n        tokens_a = tokens_a[:max_seq_length - 2]\n    tokens = []\n    segment_ids = []\n    for token in tokens_a:\n        tokens.append(token)\n        segment_ids.append(SEG_ID_A)\n    tokens.append(data_utils.SEP_ID)\n    segment_ids.append(SEG_ID_A)\n    if tokens_b:\n        for token in tokens_b:\n            tokens.append(token)\n            segment_ids.append(SEG_ID_B)\n        tokens.append(data_utils.SEP_ID)\n        segment_ids.append(SEG_ID_B)\n    if use_bert_format:\n        tokens.insert(0, data_utils.CLS_ID)\n        segment_ids.insert(0, data_utils.SEG_ID_CLS)\n    else:\n        tokens.append(data_utils.CLS_ID)\n        segment_ids.append(data_utils.SEG_ID_CLS)\n    input_ids = tokens\n    input_mask = [0] * len(input_ids)\n    if len(input_ids) < max_seq_length:\n        delta_len = max_seq_length - len(input_ids)\n        if use_bert_format:\n            input_ids = input_ids + [0] * delta_len\n            input_mask = input_mask + [1] * delta_len\n            segment_ids = segment_ids + [data_utils.SEG_ID_PAD] * delta_len\n        else:\n            input_ids = [0] * delta_len + input_ids\n            input_mask = [1] * delta_len + input_mask\n            segment_ids = [data_utils.SEG_ID_PAD] * delta_len + segment_ids\n    assert len(input_ids) == max_seq_length\n    assert len(input_mask) == max_seq_length\n    assert len(segment_ids) == max_seq_length\n    if label_list is not None:\n        label_id = label_map[example.label]\n    else:\n        label_id = example.label\n    if example_index < 5:\n        logging.info('*** Example ***')\n        logging.info('guid: %s', example.guid)\n        logging.info('input_ids: %s', ' '.join([str(x) for x in input_ids]))\n        logging.info('input_mask: %s', ' '.join([str(x) for x in input_mask]))\n        logging.info('segment_ids: %s', ' '.join([str(x) for x in segment_ids]))\n        logging.info('label: %d (id = %d)', example.label, label_id)\n    feature = InputFeatures(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id)\n    return feature",
            "def convert_single_example(example_index, example, label_list, max_seq_length, tokenize_fn, use_bert_format):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Converts a single `InputExample` into a single `InputFeatures`.'\n    if isinstance(example, PaddingInputExample):\n        return InputFeatures(input_ids=[0] * max_seq_length, input_mask=[1] * max_seq_length, segment_ids=[0] * max_seq_length, label_id=0, is_real_example=False)\n    if label_list is not None:\n        label_map = {}\n        for (i, label) in enumerate(label_list):\n            label_map[label] = i\n    tokens_a = tokenize_fn(example.text_a)\n    tokens_b = None\n    if example.text_b:\n        tokens_b = tokenize_fn(example.text_b)\n    if tokens_b:\n        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n    elif len(tokens_a) > max_seq_length - 2:\n        tokens_a = tokens_a[:max_seq_length - 2]\n    tokens = []\n    segment_ids = []\n    for token in tokens_a:\n        tokens.append(token)\n        segment_ids.append(SEG_ID_A)\n    tokens.append(data_utils.SEP_ID)\n    segment_ids.append(SEG_ID_A)\n    if tokens_b:\n        for token in tokens_b:\n            tokens.append(token)\n            segment_ids.append(SEG_ID_B)\n        tokens.append(data_utils.SEP_ID)\n        segment_ids.append(SEG_ID_B)\n    if use_bert_format:\n        tokens.insert(0, data_utils.CLS_ID)\n        segment_ids.insert(0, data_utils.SEG_ID_CLS)\n    else:\n        tokens.append(data_utils.CLS_ID)\n        segment_ids.append(data_utils.SEG_ID_CLS)\n    input_ids = tokens\n    input_mask = [0] * len(input_ids)\n    if len(input_ids) < max_seq_length:\n        delta_len = max_seq_length - len(input_ids)\n        if use_bert_format:\n            input_ids = input_ids + [0] * delta_len\n            input_mask = input_mask + [1] * delta_len\n            segment_ids = segment_ids + [data_utils.SEG_ID_PAD] * delta_len\n        else:\n            input_ids = [0] * delta_len + input_ids\n            input_mask = [1] * delta_len + input_mask\n            segment_ids = [data_utils.SEG_ID_PAD] * delta_len + segment_ids\n    assert len(input_ids) == max_seq_length\n    assert len(input_mask) == max_seq_length\n    assert len(segment_ids) == max_seq_length\n    if label_list is not None:\n        label_id = label_map[example.label]\n    else:\n        label_id = example.label\n    if example_index < 5:\n        logging.info('*** Example ***')\n        logging.info('guid: %s', example.guid)\n        logging.info('input_ids: %s', ' '.join([str(x) for x in input_ids]))\n        logging.info('input_mask: %s', ' '.join([str(x) for x in input_mask]))\n        logging.info('segment_ids: %s', ' '.join([str(x) for x in segment_ids]))\n        logging.info('label: %d (id = %d)', example.label, label_id)\n    feature = InputFeatures(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id)\n    return feature",
            "def convert_single_example(example_index, example, label_list, max_seq_length, tokenize_fn, use_bert_format):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Converts a single `InputExample` into a single `InputFeatures`.'\n    if isinstance(example, PaddingInputExample):\n        return InputFeatures(input_ids=[0] * max_seq_length, input_mask=[1] * max_seq_length, segment_ids=[0] * max_seq_length, label_id=0, is_real_example=False)\n    if label_list is not None:\n        label_map = {}\n        for (i, label) in enumerate(label_list):\n            label_map[label] = i\n    tokens_a = tokenize_fn(example.text_a)\n    tokens_b = None\n    if example.text_b:\n        tokens_b = tokenize_fn(example.text_b)\n    if tokens_b:\n        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n    elif len(tokens_a) > max_seq_length - 2:\n        tokens_a = tokens_a[:max_seq_length - 2]\n    tokens = []\n    segment_ids = []\n    for token in tokens_a:\n        tokens.append(token)\n        segment_ids.append(SEG_ID_A)\n    tokens.append(data_utils.SEP_ID)\n    segment_ids.append(SEG_ID_A)\n    if tokens_b:\n        for token in tokens_b:\n            tokens.append(token)\n            segment_ids.append(SEG_ID_B)\n        tokens.append(data_utils.SEP_ID)\n        segment_ids.append(SEG_ID_B)\n    if use_bert_format:\n        tokens.insert(0, data_utils.CLS_ID)\n        segment_ids.insert(0, data_utils.SEG_ID_CLS)\n    else:\n        tokens.append(data_utils.CLS_ID)\n        segment_ids.append(data_utils.SEG_ID_CLS)\n    input_ids = tokens\n    input_mask = [0] * len(input_ids)\n    if len(input_ids) < max_seq_length:\n        delta_len = max_seq_length - len(input_ids)\n        if use_bert_format:\n            input_ids = input_ids + [0] * delta_len\n            input_mask = input_mask + [1] * delta_len\n            segment_ids = segment_ids + [data_utils.SEG_ID_PAD] * delta_len\n        else:\n            input_ids = [0] * delta_len + input_ids\n            input_mask = [1] * delta_len + input_mask\n            segment_ids = [data_utils.SEG_ID_PAD] * delta_len + segment_ids\n    assert len(input_ids) == max_seq_length\n    assert len(input_mask) == max_seq_length\n    assert len(segment_ids) == max_seq_length\n    if label_list is not None:\n        label_id = label_map[example.label]\n    else:\n        label_id = example.label\n    if example_index < 5:\n        logging.info('*** Example ***')\n        logging.info('guid: %s', example.guid)\n        logging.info('input_ids: %s', ' '.join([str(x) for x in input_ids]))\n        logging.info('input_mask: %s', ' '.join([str(x) for x in input_mask]))\n        logging.info('segment_ids: %s', ' '.join([str(x) for x in segment_ids]))\n        logging.info('label: %d (id = %d)', example.label, label_id)\n    feature = InputFeatures(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id)\n    return feature",
            "def convert_single_example(example_index, example, label_list, max_seq_length, tokenize_fn, use_bert_format):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Converts a single `InputExample` into a single `InputFeatures`.'\n    if isinstance(example, PaddingInputExample):\n        return InputFeatures(input_ids=[0] * max_seq_length, input_mask=[1] * max_seq_length, segment_ids=[0] * max_seq_length, label_id=0, is_real_example=False)\n    if label_list is not None:\n        label_map = {}\n        for (i, label) in enumerate(label_list):\n            label_map[label] = i\n    tokens_a = tokenize_fn(example.text_a)\n    tokens_b = None\n    if example.text_b:\n        tokens_b = tokenize_fn(example.text_b)\n    if tokens_b:\n        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n    elif len(tokens_a) > max_seq_length - 2:\n        tokens_a = tokens_a[:max_seq_length - 2]\n    tokens = []\n    segment_ids = []\n    for token in tokens_a:\n        tokens.append(token)\n        segment_ids.append(SEG_ID_A)\n    tokens.append(data_utils.SEP_ID)\n    segment_ids.append(SEG_ID_A)\n    if tokens_b:\n        for token in tokens_b:\n            tokens.append(token)\n            segment_ids.append(SEG_ID_B)\n        tokens.append(data_utils.SEP_ID)\n        segment_ids.append(SEG_ID_B)\n    if use_bert_format:\n        tokens.insert(0, data_utils.CLS_ID)\n        segment_ids.insert(0, data_utils.SEG_ID_CLS)\n    else:\n        tokens.append(data_utils.CLS_ID)\n        segment_ids.append(data_utils.SEG_ID_CLS)\n    input_ids = tokens\n    input_mask = [0] * len(input_ids)\n    if len(input_ids) < max_seq_length:\n        delta_len = max_seq_length - len(input_ids)\n        if use_bert_format:\n            input_ids = input_ids + [0] * delta_len\n            input_mask = input_mask + [1] * delta_len\n            segment_ids = segment_ids + [data_utils.SEG_ID_PAD] * delta_len\n        else:\n            input_ids = [0] * delta_len + input_ids\n            input_mask = [1] * delta_len + input_mask\n            segment_ids = [data_utils.SEG_ID_PAD] * delta_len + segment_ids\n    assert len(input_ids) == max_seq_length\n    assert len(input_mask) == max_seq_length\n    assert len(segment_ids) == max_seq_length\n    if label_list is not None:\n        label_id = label_map[example.label]\n    else:\n        label_id = example.label\n    if example_index < 5:\n        logging.info('*** Example ***')\n        logging.info('guid: %s', example.guid)\n        logging.info('input_ids: %s', ' '.join([str(x) for x in input_ids]))\n        logging.info('input_mask: %s', ' '.join([str(x) for x in input_mask]))\n        logging.info('segment_ids: %s', ' '.join([str(x) for x in segment_ids]))\n        logging.info('label: %d (id = %d)', example.label, label_id)\n    feature = InputFeatures(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id)\n    return feature",
            "def convert_single_example(example_index, example, label_list, max_seq_length, tokenize_fn, use_bert_format):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Converts a single `InputExample` into a single `InputFeatures`.'\n    if isinstance(example, PaddingInputExample):\n        return InputFeatures(input_ids=[0] * max_seq_length, input_mask=[1] * max_seq_length, segment_ids=[0] * max_seq_length, label_id=0, is_real_example=False)\n    if label_list is not None:\n        label_map = {}\n        for (i, label) in enumerate(label_list):\n            label_map[label] = i\n    tokens_a = tokenize_fn(example.text_a)\n    tokens_b = None\n    if example.text_b:\n        tokens_b = tokenize_fn(example.text_b)\n    if tokens_b:\n        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n    elif len(tokens_a) > max_seq_length - 2:\n        tokens_a = tokens_a[:max_seq_length - 2]\n    tokens = []\n    segment_ids = []\n    for token in tokens_a:\n        tokens.append(token)\n        segment_ids.append(SEG_ID_A)\n    tokens.append(data_utils.SEP_ID)\n    segment_ids.append(SEG_ID_A)\n    if tokens_b:\n        for token in tokens_b:\n            tokens.append(token)\n            segment_ids.append(SEG_ID_B)\n        tokens.append(data_utils.SEP_ID)\n        segment_ids.append(SEG_ID_B)\n    if use_bert_format:\n        tokens.insert(0, data_utils.CLS_ID)\n        segment_ids.insert(0, data_utils.SEG_ID_CLS)\n    else:\n        tokens.append(data_utils.CLS_ID)\n        segment_ids.append(data_utils.SEG_ID_CLS)\n    input_ids = tokens\n    input_mask = [0] * len(input_ids)\n    if len(input_ids) < max_seq_length:\n        delta_len = max_seq_length - len(input_ids)\n        if use_bert_format:\n            input_ids = input_ids + [0] * delta_len\n            input_mask = input_mask + [1] * delta_len\n            segment_ids = segment_ids + [data_utils.SEG_ID_PAD] * delta_len\n        else:\n            input_ids = [0] * delta_len + input_ids\n            input_mask = [1] * delta_len + input_mask\n            segment_ids = [data_utils.SEG_ID_PAD] * delta_len + segment_ids\n    assert len(input_ids) == max_seq_length\n    assert len(input_mask) == max_seq_length\n    assert len(segment_ids) == max_seq_length\n    if label_list is not None:\n        label_id = label_map[example.label]\n    else:\n        label_id = example.label\n    if example_index < 5:\n        logging.info('*** Example ***')\n        logging.info('guid: %s', example.guid)\n        logging.info('input_ids: %s', ' '.join([str(x) for x in input_ids]))\n        logging.info('input_mask: %s', ' '.join([str(x) for x in input_mask]))\n        logging.info('segment_ids: %s', ' '.join([str(x) for x in segment_ids]))\n        logging.info('label: %d (id = %d)', example.label, label_id)\n    feature = InputFeatures(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label_id)\n    return feature"
        ]
    }
]