[
    {
        "func_name": "_update_tree_weights",
        "original": "def _update_tree_weights(self, frame, weights_column):\n    \"\"\"\n        Re-calculates tree-node weights based on provided dataset. Modifying node weights will affect how\n        contribution predictions (Shapley values) are calculated. This can be used to explain the model\n        on a curated sub-population of the training dataset.\n\n        :param frame: frame that will be used to re-populate trees with new observations and to collect per-node weights \n        :param weights_column: name of the weight column (can be different from training weights) \n        \"\"\"\n    from h2o.expr import ExprNode\n    result = ExprNode('tree.update.weights', self, frame, weights_column)._eval_driver('scalar')._cache._data\n    if result != 'OK':\n        warn(result)",
        "mutated": [
            "def _update_tree_weights(self, frame, weights_column):\n    if False:\n        i = 10\n    '\\n        Re-calculates tree-node weights based on provided dataset. Modifying node weights will affect how\\n        contribution predictions (Shapley values) are calculated. This can be used to explain the model\\n        on a curated sub-population of the training dataset.\\n\\n        :param frame: frame that will be used to re-populate trees with new observations and to collect per-node weights \\n        :param weights_column: name of the weight column (can be different from training weights) \\n        '\n    from h2o.expr import ExprNode\n    result = ExprNode('tree.update.weights', self, frame, weights_column)._eval_driver('scalar')._cache._data\n    if result != 'OK':\n        warn(result)",
            "def _update_tree_weights(self, frame, weights_column):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Re-calculates tree-node weights based on provided dataset. Modifying node weights will affect how\\n        contribution predictions (Shapley values) are calculated. This can be used to explain the model\\n        on a curated sub-population of the training dataset.\\n\\n        :param frame: frame that will be used to re-populate trees with new observations and to collect per-node weights \\n        :param weights_column: name of the weight column (can be different from training weights) \\n        '\n    from h2o.expr import ExprNode\n    result = ExprNode('tree.update.weights', self, frame, weights_column)._eval_driver('scalar')._cache._data\n    if result != 'OK':\n        warn(result)",
            "def _update_tree_weights(self, frame, weights_column):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Re-calculates tree-node weights based on provided dataset. Modifying node weights will affect how\\n        contribution predictions (Shapley values) are calculated. This can be used to explain the model\\n        on a curated sub-population of the training dataset.\\n\\n        :param frame: frame that will be used to re-populate trees with new observations and to collect per-node weights \\n        :param weights_column: name of the weight column (can be different from training weights) \\n        '\n    from h2o.expr import ExprNode\n    result = ExprNode('tree.update.weights', self, frame, weights_column)._eval_driver('scalar')._cache._data\n    if result != 'OK':\n        warn(result)",
            "def _update_tree_weights(self, frame, weights_column):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Re-calculates tree-node weights based on provided dataset. Modifying node weights will affect how\\n        contribution predictions (Shapley values) are calculated. This can be used to explain the model\\n        on a curated sub-population of the training dataset.\\n\\n        :param frame: frame that will be used to re-populate trees with new observations and to collect per-node weights \\n        :param weights_column: name of the weight column (can be different from training weights) \\n        '\n    from h2o.expr import ExprNode\n    result = ExprNode('tree.update.weights', self, frame, weights_column)._eval_driver('scalar')._cache._data\n    if result != 'OK':\n        warn(result)",
            "def _update_tree_weights(self, frame, weights_column):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Re-calculates tree-node weights based on provided dataset. Modifying node weights will affect how\\n        contribution predictions (Shapley values) are calculated. This can be used to explain the model\\n        on a curated sub-population of the training dataset.\\n\\n        :param frame: frame that will be used to re-populate trees with new observations and to collect per-node weights \\n        :param weights_column: name of the weight column (can be different from training weights) \\n        '\n    from h2o.expr import ExprNode\n    result = ExprNode('tree.update.weights', self, frame, weights_column)._eval_driver('scalar')._cache._data\n    if result != 'OK':\n        warn(result)"
        ]
    },
    {
        "func_name": "_calibrate",
        "original": "def _calibrate(self, calibration_model):\n    \"\"\"\n        Calibrate a trained model with a supplied calibration model.\n\n        Only tree-based models can be calibrated.\n\n        :param calibration_model: a GLM model (for Platt Scaling) or Isotonic Regression model trained with the purpose\n            of calibrating output of this model.\n\n        :examples:\n\n        >>> from h2o.estimators.gbm import H2OGradientBoostingEstimator\n        >>> from h2o.estimators.isotonicregression import H2OIsotonicRegressionEstimator\n        >>> df = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/ecology_model.csv\")\n        >>> df[\"Angaus\"] = df[\"Angaus\"].asfactor()\n        >>> train, calib = df.split_frame(ratios=[.8], destination_frames=[\"eco_train\", \"eco_calib\"], seed=42)\n        >>> model = H2OGradientBoostingEstimator()\n        >>> model.train(x=list(range(2, train.ncol)), y=\"Angaus\", training_frame=train)\n        >>> isotonic_train = calib[[\"Angaus\"]]\n        >>> isotonic_train = isotonic_train.cbind(model.predict(calib)[\"p1\"])\n        >>> h2o_iso_reg = H2OIsotonicRegressionEstimator(out_of_bounds=\"clip\")\n        >>> h2o_iso_reg.train(training_frame=isotonic_train, x=\"p1\", y=\"Angaus\")\n        >>> model.calibrate(h2o_iso_reg)\n        >>> model.predict(train)\n        \"\"\"\n    from h2o.expr import ExprNode\n    result = ExprNode('set.calibration.model', self, calibration_model)._eval_driver('scalar')._cache._data\n    if result != 'OK':\n        warn(result)",
        "mutated": [
            "def _calibrate(self, calibration_model):\n    if False:\n        i = 10\n    '\\n        Calibrate a trained model with a supplied calibration model.\\n\\n        Only tree-based models can be calibrated.\\n\\n        :param calibration_model: a GLM model (for Platt Scaling) or Isotonic Regression model trained with the purpose\\n            of calibrating output of this model.\\n\\n        :examples:\\n\\n        >>> from h2o.estimators.gbm import H2OGradientBoostingEstimator\\n        >>> from h2o.estimators.isotonicregression import H2OIsotonicRegressionEstimator\\n        >>> df = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/ecology_model.csv\")\\n        >>> df[\"Angaus\"] = df[\"Angaus\"].asfactor()\\n        >>> train, calib = df.split_frame(ratios=[.8], destination_frames=[\"eco_train\", \"eco_calib\"], seed=42)\\n        >>> model = H2OGradientBoostingEstimator()\\n        >>> model.train(x=list(range(2, train.ncol)), y=\"Angaus\", training_frame=train)\\n        >>> isotonic_train = calib[[\"Angaus\"]]\\n        >>> isotonic_train = isotonic_train.cbind(model.predict(calib)[\"p1\"])\\n        >>> h2o_iso_reg = H2OIsotonicRegressionEstimator(out_of_bounds=\"clip\")\\n        >>> h2o_iso_reg.train(training_frame=isotonic_train, x=\"p1\", y=\"Angaus\")\\n        >>> model.calibrate(h2o_iso_reg)\\n        >>> model.predict(train)\\n        '\n    from h2o.expr import ExprNode\n    result = ExprNode('set.calibration.model', self, calibration_model)._eval_driver('scalar')._cache._data\n    if result != 'OK':\n        warn(result)",
            "def _calibrate(self, calibration_model):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Calibrate a trained model with a supplied calibration model.\\n\\n        Only tree-based models can be calibrated.\\n\\n        :param calibration_model: a GLM model (for Platt Scaling) or Isotonic Regression model trained with the purpose\\n            of calibrating output of this model.\\n\\n        :examples:\\n\\n        >>> from h2o.estimators.gbm import H2OGradientBoostingEstimator\\n        >>> from h2o.estimators.isotonicregression import H2OIsotonicRegressionEstimator\\n        >>> df = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/ecology_model.csv\")\\n        >>> df[\"Angaus\"] = df[\"Angaus\"].asfactor()\\n        >>> train, calib = df.split_frame(ratios=[.8], destination_frames=[\"eco_train\", \"eco_calib\"], seed=42)\\n        >>> model = H2OGradientBoostingEstimator()\\n        >>> model.train(x=list(range(2, train.ncol)), y=\"Angaus\", training_frame=train)\\n        >>> isotonic_train = calib[[\"Angaus\"]]\\n        >>> isotonic_train = isotonic_train.cbind(model.predict(calib)[\"p1\"])\\n        >>> h2o_iso_reg = H2OIsotonicRegressionEstimator(out_of_bounds=\"clip\")\\n        >>> h2o_iso_reg.train(training_frame=isotonic_train, x=\"p1\", y=\"Angaus\")\\n        >>> model.calibrate(h2o_iso_reg)\\n        >>> model.predict(train)\\n        '\n    from h2o.expr import ExprNode\n    result = ExprNode('set.calibration.model', self, calibration_model)._eval_driver('scalar')._cache._data\n    if result != 'OK':\n        warn(result)",
            "def _calibrate(self, calibration_model):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Calibrate a trained model with a supplied calibration model.\\n\\n        Only tree-based models can be calibrated.\\n\\n        :param calibration_model: a GLM model (for Platt Scaling) or Isotonic Regression model trained with the purpose\\n            of calibrating output of this model.\\n\\n        :examples:\\n\\n        >>> from h2o.estimators.gbm import H2OGradientBoostingEstimator\\n        >>> from h2o.estimators.isotonicregression import H2OIsotonicRegressionEstimator\\n        >>> df = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/ecology_model.csv\")\\n        >>> df[\"Angaus\"] = df[\"Angaus\"].asfactor()\\n        >>> train, calib = df.split_frame(ratios=[.8], destination_frames=[\"eco_train\", \"eco_calib\"], seed=42)\\n        >>> model = H2OGradientBoostingEstimator()\\n        >>> model.train(x=list(range(2, train.ncol)), y=\"Angaus\", training_frame=train)\\n        >>> isotonic_train = calib[[\"Angaus\"]]\\n        >>> isotonic_train = isotonic_train.cbind(model.predict(calib)[\"p1\"])\\n        >>> h2o_iso_reg = H2OIsotonicRegressionEstimator(out_of_bounds=\"clip\")\\n        >>> h2o_iso_reg.train(training_frame=isotonic_train, x=\"p1\", y=\"Angaus\")\\n        >>> model.calibrate(h2o_iso_reg)\\n        >>> model.predict(train)\\n        '\n    from h2o.expr import ExprNode\n    result = ExprNode('set.calibration.model', self, calibration_model)._eval_driver('scalar')._cache._data\n    if result != 'OK':\n        warn(result)",
            "def _calibrate(self, calibration_model):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Calibrate a trained model with a supplied calibration model.\\n\\n        Only tree-based models can be calibrated.\\n\\n        :param calibration_model: a GLM model (for Platt Scaling) or Isotonic Regression model trained with the purpose\\n            of calibrating output of this model.\\n\\n        :examples:\\n\\n        >>> from h2o.estimators.gbm import H2OGradientBoostingEstimator\\n        >>> from h2o.estimators.isotonicregression import H2OIsotonicRegressionEstimator\\n        >>> df = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/ecology_model.csv\")\\n        >>> df[\"Angaus\"] = df[\"Angaus\"].asfactor()\\n        >>> train, calib = df.split_frame(ratios=[.8], destination_frames=[\"eco_train\", \"eco_calib\"], seed=42)\\n        >>> model = H2OGradientBoostingEstimator()\\n        >>> model.train(x=list(range(2, train.ncol)), y=\"Angaus\", training_frame=train)\\n        >>> isotonic_train = calib[[\"Angaus\"]]\\n        >>> isotonic_train = isotonic_train.cbind(model.predict(calib)[\"p1\"])\\n        >>> h2o_iso_reg = H2OIsotonicRegressionEstimator(out_of_bounds=\"clip\")\\n        >>> h2o_iso_reg.train(training_frame=isotonic_train, x=\"p1\", y=\"Angaus\")\\n        >>> model.calibrate(h2o_iso_reg)\\n        >>> model.predict(train)\\n        '\n    from h2o.expr import ExprNode\n    result = ExprNode('set.calibration.model', self, calibration_model)._eval_driver('scalar')._cache._data\n    if result != 'OK':\n        warn(result)",
            "def _calibrate(self, calibration_model):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Calibrate a trained model with a supplied calibration model.\\n\\n        Only tree-based models can be calibrated.\\n\\n        :param calibration_model: a GLM model (for Platt Scaling) or Isotonic Regression model trained with the purpose\\n            of calibrating output of this model.\\n\\n        :examples:\\n\\n        >>> from h2o.estimators.gbm import H2OGradientBoostingEstimator\\n        >>> from h2o.estimators.isotonicregression import H2OIsotonicRegressionEstimator\\n        >>> df = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/ecology_model.csv\")\\n        >>> df[\"Angaus\"] = df[\"Angaus\"].asfactor()\\n        >>> train, calib = df.split_frame(ratios=[.8], destination_frames=[\"eco_train\", \"eco_calib\"], seed=42)\\n        >>> model = H2OGradientBoostingEstimator()\\n        >>> model.train(x=list(range(2, train.ncol)), y=\"Angaus\", training_frame=train)\\n        >>> isotonic_train = calib[[\"Angaus\"]]\\n        >>> isotonic_train = isotonic_train.cbind(model.predict(calib)[\"p1\"])\\n        >>> h2o_iso_reg = H2OIsotonicRegressionEstimator(out_of_bounds=\"clip\")\\n        >>> h2o_iso_reg.train(training_frame=isotonic_train, x=\"p1\", y=\"Angaus\")\\n        >>> model.calibrate(h2o_iso_reg)\\n        >>> model.predict(train)\\n        '\n    from h2o.expr import ExprNode\n    result = ExprNode('set.calibration.model', self, calibration_model)._eval_driver('scalar')._cache._data\n    if result != 'OK':\n        warn(result)"
        ]
    }
]