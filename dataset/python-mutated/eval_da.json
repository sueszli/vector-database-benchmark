[
    {
        "func_name": "eval_model",
        "original": "def eval_model(db: FeverDocDB, args) -> Model:\n    archive = load_archive(args.archive_file, cuda_device=args.cuda_device)\n    config = archive.config\n    ds_params = config['dataset_reader']\n    model = archive.model\n    model.eval()\n    reader = FEVERReader(db, sentence_level=ds_params.pop('sentence_level', False), wiki_tokenizer=Tokenizer.from_params(ds_params.pop('wiki_tokenizer', {})), claim_tokenizer=Tokenizer.from_params(ds_params.pop('claim_tokenizer', {})), token_indexers=TokenIndexer.dict_from_params(ds_params.pop('token_indexers', {})))\n    logger.info('Reading training data from %s', args.in_file)\n    data = reader.read(args.in_file).instances\n    actual = []\n    predicted = []\n    if args.log is not None:\n        f = open(args.log, 'w+')\n    for item in tqdm(data):\n        if item.fields['premise'] is None or item.fields['premise'].sequence_length() == 0:\n            cls = 'NOT ENOUGH INFO'\n        else:\n            prediction = model.forward_on_instance(item, args.cuda_device)\n            cls = model.vocab._index_to_token['labels'][np.argmax(prediction['label_probs'])]\n        if 'label' in item.fields:\n            actual.append(item.fields['label'].label)\n        predicted.append(cls)\n        if args.log is not None:\n            if 'label' in item.fields:\n                f.write(json.dumps({'actual': item.fields['label'].label, 'predicted': cls}) + '\\n')\n            else:\n                f.write(json.dumps({'predicted': cls}) + '\\n')\n    if args.log is not None:\n        f.close()\n    if len(actual) > 0:\n        print(accuracy_score(actual, predicted))\n        print(classification_report(actual, predicted))\n        print(confusion_matrix(actual, predicted))\n    return model",
        "mutated": [
            "def eval_model(db: FeverDocDB, args) -> Model:\n    if False:\n        i = 10\n    archive = load_archive(args.archive_file, cuda_device=args.cuda_device)\n    config = archive.config\n    ds_params = config['dataset_reader']\n    model = archive.model\n    model.eval()\n    reader = FEVERReader(db, sentence_level=ds_params.pop('sentence_level', False), wiki_tokenizer=Tokenizer.from_params(ds_params.pop('wiki_tokenizer', {})), claim_tokenizer=Tokenizer.from_params(ds_params.pop('claim_tokenizer', {})), token_indexers=TokenIndexer.dict_from_params(ds_params.pop('token_indexers', {})))\n    logger.info('Reading training data from %s', args.in_file)\n    data = reader.read(args.in_file).instances\n    actual = []\n    predicted = []\n    if args.log is not None:\n        f = open(args.log, 'w+')\n    for item in tqdm(data):\n        if item.fields['premise'] is None or item.fields['premise'].sequence_length() == 0:\n            cls = 'NOT ENOUGH INFO'\n        else:\n            prediction = model.forward_on_instance(item, args.cuda_device)\n            cls = model.vocab._index_to_token['labels'][np.argmax(prediction['label_probs'])]\n        if 'label' in item.fields:\n            actual.append(item.fields['label'].label)\n        predicted.append(cls)\n        if args.log is not None:\n            if 'label' in item.fields:\n                f.write(json.dumps({'actual': item.fields['label'].label, 'predicted': cls}) + '\\n')\n            else:\n                f.write(json.dumps({'predicted': cls}) + '\\n')\n    if args.log is not None:\n        f.close()\n    if len(actual) > 0:\n        print(accuracy_score(actual, predicted))\n        print(classification_report(actual, predicted))\n        print(confusion_matrix(actual, predicted))\n    return model",
            "def eval_model(db: FeverDocDB, args) -> Model:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    archive = load_archive(args.archive_file, cuda_device=args.cuda_device)\n    config = archive.config\n    ds_params = config['dataset_reader']\n    model = archive.model\n    model.eval()\n    reader = FEVERReader(db, sentence_level=ds_params.pop('sentence_level', False), wiki_tokenizer=Tokenizer.from_params(ds_params.pop('wiki_tokenizer', {})), claim_tokenizer=Tokenizer.from_params(ds_params.pop('claim_tokenizer', {})), token_indexers=TokenIndexer.dict_from_params(ds_params.pop('token_indexers', {})))\n    logger.info('Reading training data from %s', args.in_file)\n    data = reader.read(args.in_file).instances\n    actual = []\n    predicted = []\n    if args.log is not None:\n        f = open(args.log, 'w+')\n    for item in tqdm(data):\n        if item.fields['premise'] is None or item.fields['premise'].sequence_length() == 0:\n            cls = 'NOT ENOUGH INFO'\n        else:\n            prediction = model.forward_on_instance(item, args.cuda_device)\n            cls = model.vocab._index_to_token['labels'][np.argmax(prediction['label_probs'])]\n        if 'label' in item.fields:\n            actual.append(item.fields['label'].label)\n        predicted.append(cls)\n        if args.log is not None:\n            if 'label' in item.fields:\n                f.write(json.dumps({'actual': item.fields['label'].label, 'predicted': cls}) + '\\n')\n            else:\n                f.write(json.dumps({'predicted': cls}) + '\\n')\n    if args.log is not None:\n        f.close()\n    if len(actual) > 0:\n        print(accuracy_score(actual, predicted))\n        print(classification_report(actual, predicted))\n        print(confusion_matrix(actual, predicted))\n    return model",
            "def eval_model(db: FeverDocDB, args) -> Model:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    archive = load_archive(args.archive_file, cuda_device=args.cuda_device)\n    config = archive.config\n    ds_params = config['dataset_reader']\n    model = archive.model\n    model.eval()\n    reader = FEVERReader(db, sentence_level=ds_params.pop('sentence_level', False), wiki_tokenizer=Tokenizer.from_params(ds_params.pop('wiki_tokenizer', {})), claim_tokenizer=Tokenizer.from_params(ds_params.pop('claim_tokenizer', {})), token_indexers=TokenIndexer.dict_from_params(ds_params.pop('token_indexers', {})))\n    logger.info('Reading training data from %s', args.in_file)\n    data = reader.read(args.in_file).instances\n    actual = []\n    predicted = []\n    if args.log is not None:\n        f = open(args.log, 'w+')\n    for item in tqdm(data):\n        if item.fields['premise'] is None or item.fields['premise'].sequence_length() == 0:\n            cls = 'NOT ENOUGH INFO'\n        else:\n            prediction = model.forward_on_instance(item, args.cuda_device)\n            cls = model.vocab._index_to_token['labels'][np.argmax(prediction['label_probs'])]\n        if 'label' in item.fields:\n            actual.append(item.fields['label'].label)\n        predicted.append(cls)\n        if args.log is not None:\n            if 'label' in item.fields:\n                f.write(json.dumps({'actual': item.fields['label'].label, 'predicted': cls}) + '\\n')\n            else:\n                f.write(json.dumps({'predicted': cls}) + '\\n')\n    if args.log is not None:\n        f.close()\n    if len(actual) > 0:\n        print(accuracy_score(actual, predicted))\n        print(classification_report(actual, predicted))\n        print(confusion_matrix(actual, predicted))\n    return model",
            "def eval_model(db: FeverDocDB, args) -> Model:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    archive = load_archive(args.archive_file, cuda_device=args.cuda_device)\n    config = archive.config\n    ds_params = config['dataset_reader']\n    model = archive.model\n    model.eval()\n    reader = FEVERReader(db, sentence_level=ds_params.pop('sentence_level', False), wiki_tokenizer=Tokenizer.from_params(ds_params.pop('wiki_tokenizer', {})), claim_tokenizer=Tokenizer.from_params(ds_params.pop('claim_tokenizer', {})), token_indexers=TokenIndexer.dict_from_params(ds_params.pop('token_indexers', {})))\n    logger.info('Reading training data from %s', args.in_file)\n    data = reader.read(args.in_file).instances\n    actual = []\n    predicted = []\n    if args.log is not None:\n        f = open(args.log, 'w+')\n    for item in tqdm(data):\n        if item.fields['premise'] is None or item.fields['premise'].sequence_length() == 0:\n            cls = 'NOT ENOUGH INFO'\n        else:\n            prediction = model.forward_on_instance(item, args.cuda_device)\n            cls = model.vocab._index_to_token['labels'][np.argmax(prediction['label_probs'])]\n        if 'label' in item.fields:\n            actual.append(item.fields['label'].label)\n        predicted.append(cls)\n        if args.log is not None:\n            if 'label' in item.fields:\n                f.write(json.dumps({'actual': item.fields['label'].label, 'predicted': cls}) + '\\n')\n            else:\n                f.write(json.dumps({'predicted': cls}) + '\\n')\n    if args.log is not None:\n        f.close()\n    if len(actual) > 0:\n        print(accuracy_score(actual, predicted))\n        print(classification_report(actual, predicted))\n        print(confusion_matrix(actual, predicted))\n    return model",
            "def eval_model(db: FeverDocDB, args) -> Model:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    archive = load_archive(args.archive_file, cuda_device=args.cuda_device)\n    config = archive.config\n    ds_params = config['dataset_reader']\n    model = archive.model\n    model.eval()\n    reader = FEVERReader(db, sentence_level=ds_params.pop('sentence_level', False), wiki_tokenizer=Tokenizer.from_params(ds_params.pop('wiki_tokenizer', {})), claim_tokenizer=Tokenizer.from_params(ds_params.pop('claim_tokenizer', {})), token_indexers=TokenIndexer.dict_from_params(ds_params.pop('token_indexers', {})))\n    logger.info('Reading training data from %s', args.in_file)\n    data = reader.read(args.in_file).instances\n    actual = []\n    predicted = []\n    if args.log is not None:\n        f = open(args.log, 'w+')\n    for item in tqdm(data):\n        if item.fields['premise'] is None or item.fields['premise'].sequence_length() == 0:\n            cls = 'NOT ENOUGH INFO'\n        else:\n            prediction = model.forward_on_instance(item, args.cuda_device)\n            cls = model.vocab._index_to_token['labels'][np.argmax(prediction['label_probs'])]\n        if 'label' in item.fields:\n            actual.append(item.fields['label'].label)\n        predicted.append(cls)\n        if args.log is not None:\n            if 'label' in item.fields:\n                f.write(json.dumps({'actual': item.fields['label'].label, 'predicted': cls}) + '\\n')\n            else:\n                f.write(json.dumps({'predicted': cls}) + '\\n')\n    if args.log is not None:\n        f.close()\n    if len(actual) > 0:\n        print(accuracy_score(actual, predicted))\n        print(classification_report(actual, predicted))\n        print(confusion_matrix(actual, predicted))\n    return model"
        ]
    }
]