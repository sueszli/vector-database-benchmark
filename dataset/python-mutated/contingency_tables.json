[
    {
        "func_name": "_make_df_square",
        "original": "def _make_df_square(table):\n    \"\"\"\n    Reindex a pandas DataFrame so that it becomes square, meaning that\n    the row and column indices contain the same values, in the same\n    order.  The row and column index are extended to achieve this.\n    \"\"\"\n    if not isinstance(table, pd.DataFrame):\n        return table\n    if not table.index.equals(table.columns):\n        ix = list(set(table.index) | set(table.columns))\n        ix.sort()\n        table = table.reindex(index=ix, columns=ix, fill_value=0)\n    table = table.reindex(table.columns)\n    return table",
        "mutated": [
            "def _make_df_square(table):\n    if False:\n        i = 10\n    '\\n    Reindex a pandas DataFrame so that it becomes square, meaning that\\n    the row and column indices contain the same values, in the same\\n    order.  The row and column index are extended to achieve this.\\n    '\n    if not isinstance(table, pd.DataFrame):\n        return table\n    if not table.index.equals(table.columns):\n        ix = list(set(table.index) | set(table.columns))\n        ix.sort()\n        table = table.reindex(index=ix, columns=ix, fill_value=0)\n    table = table.reindex(table.columns)\n    return table",
            "def _make_df_square(table):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Reindex a pandas DataFrame so that it becomes square, meaning that\\n    the row and column indices contain the same values, in the same\\n    order.  The row and column index are extended to achieve this.\\n    '\n    if not isinstance(table, pd.DataFrame):\n        return table\n    if not table.index.equals(table.columns):\n        ix = list(set(table.index) | set(table.columns))\n        ix.sort()\n        table = table.reindex(index=ix, columns=ix, fill_value=0)\n    table = table.reindex(table.columns)\n    return table",
            "def _make_df_square(table):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Reindex a pandas DataFrame so that it becomes square, meaning that\\n    the row and column indices contain the same values, in the same\\n    order.  The row and column index are extended to achieve this.\\n    '\n    if not isinstance(table, pd.DataFrame):\n        return table\n    if not table.index.equals(table.columns):\n        ix = list(set(table.index) | set(table.columns))\n        ix.sort()\n        table = table.reindex(index=ix, columns=ix, fill_value=0)\n    table = table.reindex(table.columns)\n    return table",
            "def _make_df_square(table):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Reindex a pandas DataFrame so that it becomes square, meaning that\\n    the row and column indices contain the same values, in the same\\n    order.  The row and column index are extended to achieve this.\\n    '\n    if not isinstance(table, pd.DataFrame):\n        return table\n    if not table.index.equals(table.columns):\n        ix = list(set(table.index) | set(table.columns))\n        ix.sort()\n        table = table.reindex(index=ix, columns=ix, fill_value=0)\n    table = table.reindex(table.columns)\n    return table",
            "def _make_df_square(table):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Reindex a pandas DataFrame so that it becomes square, meaning that\\n    the row and column indices contain the same values, in the same\\n    order.  The row and column index are extended to achieve this.\\n    '\n    if not isinstance(table, pd.DataFrame):\n        return table\n    if not table.index.equals(table.columns):\n        ix = list(set(table.index) | set(table.columns))\n        ix.sort()\n        table = table.reindex(index=ix, columns=ix, fill_value=0)\n    table = table.reindex(table.columns)\n    return table"
        ]
    },
    {
        "func_name": "__repr__",
        "original": "def __repr__(self):\n    return '<bunch containing results, print to see contents>'",
        "mutated": [
            "def __repr__(self):\n    if False:\n        i = 10\n    return '<bunch containing results, print to see contents>'",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return '<bunch containing results, print to see contents>'",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return '<bunch containing results, print to see contents>'",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return '<bunch containing results, print to see contents>'",
            "def __repr__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return '<bunch containing results, print to see contents>'"
        ]
    },
    {
        "func_name": "__str__",
        "original": "def __str__(self):\n    ky = [k for (k, _) in self.__dict__.items()]\n    ky.sort()\n    m = max([len(k) for k in ky])\n    tab = []\n    f = '{:' + str(m) + '}   {}'\n    for k in ky:\n        tab.append(f.format(k, self.__dict__[k]))\n    return '\\n'.join(tab)",
        "mutated": [
            "def __str__(self):\n    if False:\n        i = 10\n    ky = [k for (k, _) in self.__dict__.items()]\n    ky.sort()\n    m = max([len(k) for k in ky])\n    tab = []\n    f = '{:' + str(m) + '}   {}'\n    for k in ky:\n        tab.append(f.format(k, self.__dict__[k]))\n    return '\\n'.join(tab)",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    ky = [k for (k, _) in self.__dict__.items()]\n    ky.sort()\n    m = max([len(k) for k in ky])\n    tab = []\n    f = '{:' + str(m) + '}   {}'\n    for k in ky:\n        tab.append(f.format(k, self.__dict__[k]))\n    return '\\n'.join(tab)",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    ky = [k for (k, _) in self.__dict__.items()]\n    ky.sort()\n    m = max([len(k) for k in ky])\n    tab = []\n    f = '{:' + str(m) + '}   {}'\n    for k in ky:\n        tab.append(f.format(k, self.__dict__[k]))\n    return '\\n'.join(tab)",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    ky = [k for (k, _) in self.__dict__.items()]\n    ky.sort()\n    m = max([len(k) for k in ky])\n    tab = []\n    f = '{:' + str(m) + '}   {}'\n    for k in ky:\n        tab.append(f.format(k, self.__dict__[k]))\n    return '\\n'.join(tab)",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    ky = [k for (k, _) in self.__dict__.items()]\n    ky.sort()\n    m = max([len(k) for k in ky])\n    tab = []\n    f = '{:' + str(m) + '}   {}'\n    for k in ky:\n        tab.append(f.format(k, self.__dict__[k]))\n    return '\\n'.join(tab)"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, table, shift_zeros=True):\n    self.table_orig = table\n    self.table = np.asarray(table, dtype=np.float64)\n    if shift_zeros and self.table.min() == 0:\n        self.table[self.table == 0] = 0.5",
        "mutated": [
            "def __init__(self, table, shift_zeros=True):\n    if False:\n        i = 10\n    self.table_orig = table\n    self.table = np.asarray(table, dtype=np.float64)\n    if shift_zeros and self.table.min() == 0:\n        self.table[self.table == 0] = 0.5",
            "def __init__(self, table, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.table_orig = table\n    self.table = np.asarray(table, dtype=np.float64)\n    if shift_zeros and self.table.min() == 0:\n        self.table[self.table == 0] = 0.5",
            "def __init__(self, table, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.table_orig = table\n    self.table = np.asarray(table, dtype=np.float64)\n    if shift_zeros and self.table.min() == 0:\n        self.table[self.table == 0] = 0.5",
            "def __init__(self, table, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.table_orig = table\n    self.table = np.asarray(table, dtype=np.float64)\n    if shift_zeros and self.table.min() == 0:\n        self.table[self.table == 0] = 0.5",
            "def __init__(self, table, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.table_orig = table\n    self.table = np.asarray(table, dtype=np.float64)\n    if shift_zeros and self.table.min() == 0:\n        self.table[self.table == 0] = 0.5"
        ]
    },
    {
        "func_name": "__str__",
        "original": "def __str__(self):\n    s = 'A %dx%d contingency table with counts:\\n' % tuple(self.table.shape)\n    s += np.array_str(self.table)\n    return s",
        "mutated": [
            "def __str__(self):\n    if False:\n        i = 10\n    s = 'A %dx%d contingency table with counts:\\n' % tuple(self.table.shape)\n    s += np.array_str(self.table)\n    return s",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    s = 'A %dx%d contingency table with counts:\\n' % tuple(self.table.shape)\n    s += np.array_str(self.table)\n    return s",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    s = 'A %dx%d contingency table with counts:\\n' % tuple(self.table.shape)\n    s += np.array_str(self.table)\n    return s",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    s = 'A %dx%d contingency table with counts:\\n' % tuple(self.table.shape)\n    s += np.array_str(self.table)\n    return s",
            "def __str__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    s = 'A %dx%d contingency table with counts:\\n' % tuple(self.table.shape)\n    s += np.array_str(self.table)\n    return s"
        ]
    },
    {
        "func_name": "from_data",
        "original": "@classmethod\ndef from_data(cls, data, shift_zeros=True):\n    \"\"\"\n        Construct a Table object from data.\n\n        Parameters\n        ----------\n        data : array_like\n            The raw data, from which a contingency table is constructed\n            using the first two columns.\n        shift_zeros : bool\n            If True and any cell count is zero, add 0.5 to all values\n            in the table.\n\n        Returns\n        -------\n        A Table instance.\n        \"\"\"\n    if isinstance(data, pd.DataFrame):\n        table = pd.crosstab(data.iloc[:, 0], data.iloc[:, 1])\n    else:\n        table = pd.crosstab(data[:, 0], data[:, 1])\n    return cls(table, shift_zeros)",
        "mutated": [
            "@classmethod\ndef from_data(cls, data, shift_zeros=True):\n    if False:\n        i = 10\n    '\\n        Construct a Table object from data.\\n\\n        Parameters\\n        ----------\\n        data : array_like\\n            The raw data, from which a contingency table is constructed\\n            using the first two columns.\\n        shift_zeros : bool\\n            If True and any cell count is zero, add 0.5 to all values\\n            in the table.\\n\\n        Returns\\n        -------\\n        A Table instance.\\n        '\n    if isinstance(data, pd.DataFrame):\n        table = pd.crosstab(data.iloc[:, 0], data.iloc[:, 1])\n    else:\n        table = pd.crosstab(data[:, 0], data[:, 1])\n    return cls(table, shift_zeros)",
            "@classmethod\ndef from_data(cls, data, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Construct a Table object from data.\\n\\n        Parameters\\n        ----------\\n        data : array_like\\n            The raw data, from which a contingency table is constructed\\n            using the first two columns.\\n        shift_zeros : bool\\n            If True and any cell count is zero, add 0.5 to all values\\n            in the table.\\n\\n        Returns\\n        -------\\n        A Table instance.\\n        '\n    if isinstance(data, pd.DataFrame):\n        table = pd.crosstab(data.iloc[:, 0], data.iloc[:, 1])\n    else:\n        table = pd.crosstab(data[:, 0], data[:, 1])\n    return cls(table, shift_zeros)",
            "@classmethod\ndef from_data(cls, data, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Construct a Table object from data.\\n\\n        Parameters\\n        ----------\\n        data : array_like\\n            The raw data, from which a contingency table is constructed\\n            using the first two columns.\\n        shift_zeros : bool\\n            If True and any cell count is zero, add 0.5 to all values\\n            in the table.\\n\\n        Returns\\n        -------\\n        A Table instance.\\n        '\n    if isinstance(data, pd.DataFrame):\n        table = pd.crosstab(data.iloc[:, 0], data.iloc[:, 1])\n    else:\n        table = pd.crosstab(data[:, 0], data[:, 1])\n    return cls(table, shift_zeros)",
            "@classmethod\ndef from_data(cls, data, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Construct a Table object from data.\\n\\n        Parameters\\n        ----------\\n        data : array_like\\n            The raw data, from which a contingency table is constructed\\n            using the first two columns.\\n        shift_zeros : bool\\n            If True and any cell count is zero, add 0.5 to all values\\n            in the table.\\n\\n        Returns\\n        -------\\n        A Table instance.\\n        '\n    if isinstance(data, pd.DataFrame):\n        table = pd.crosstab(data.iloc[:, 0], data.iloc[:, 1])\n    else:\n        table = pd.crosstab(data[:, 0], data[:, 1])\n    return cls(table, shift_zeros)",
            "@classmethod\ndef from_data(cls, data, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Construct a Table object from data.\\n\\n        Parameters\\n        ----------\\n        data : array_like\\n            The raw data, from which a contingency table is constructed\\n            using the first two columns.\\n        shift_zeros : bool\\n            If True and any cell count is zero, add 0.5 to all values\\n            in the table.\\n\\n        Returns\\n        -------\\n        A Table instance.\\n        '\n    if isinstance(data, pd.DataFrame):\n        table = pd.crosstab(data.iloc[:, 0], data.iloc[:, 1])\n    else:\n        table = pd.crosstab(data[:, 0], data[:, 1])\n    return cls(table, shift_zeros)"
        ]
    },
    {
        "func_name": "test_nominal_association",
        "original": "def test_nominal_association(self):\n    \"\"\"\n        Assess independence for nominal factors.\n\n        Assessment of independence between rows and columns using\n        chi^2 testing.  The rows and columns are treated as nominal\n        (unordered) categorical variables.\n\n        Returns\n        -------\n        A bunch containing the following attributes:\n\n        statistic : float\n            The chi^2 test statistic.\n        df : int\n            The degrees of freedom of the reference distribution\n        pvalue : float\n            The p-value for the test.\n        \"\"\"\n    statistic = np.asarray(self.chi2_contribs).sum()\n    df = np.prod(np.asarray(self.table.shape) - 1)\n    pvalue = 1 - stats.chi2.cdf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.df = df\n    b.pvalue = pvalue\n    return b",
        "mutated": [
            "def test_nominal_association(self):\n    if False:\n        i = 10\n    '\\n        Assess independence for nominal factors.\\n\\n        Assessment of independence between rows and columns using\\n        chi^2 testing.  The rows and columns are treated as nominal\\n        (unordered) categorical variables.\\n\\n        Returns\\n        -------\\n        A bunch containing the following attributes:\\n\\n        statistic : float\\n            The chi^2 test statistic.\\n        df : int\\n            The degrees of freedom of the reference distribution\\n        pvalue : float\\n            The p-value for the test.\\n        '\n    statistic = np.asarray(self.chi2_contribs).sum()\n    df = np.prod(np.asarray(self.table.shape) - 1)\n    pvalue = 1 - stats.chi2.cdf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.df = df\n    b.pvalue = pvalue\n    return b",
            "def test_nominal_association(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Assess independence for nominal factors.\\n\\n        Assessment of independence between rows and columns using\\n        chi^2 testing.  The rows and columns are treated as nominal\\n        (unordered) categorical variables.\\n\\n        Returns\\n        -------\\n        A bunch containing the following attributes:\\n\\n        statistic : float\\n            The chi^2 test statistic.\\n        df : int\\n            The degrees of freedom of the reference distribution\\n        pvalue : float\\n            The p-value for the test.\\n        '\n    statistic = np.asarray(self.chi2_contribs).sum()\n    df = np.prod(np.asarray(self.table.shape) - 1)\n    pvalue = 1 - stats.chi2.cdf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.df = df\n    b.pvalue = pvalue\n    return b",
            "def test_nominal_association(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Assess independence for nominal factors.\\n\\n        Assessment of independence between rows and columns using\\n        chi^2 testing.  The rows and columns are treated as nominal\\n        (unordered) categorical variables.\\n\\n        Returns\\n        -------\\n        A bunch containing the following attributes:\\n\\n        statistic : float\\n            The chi^2 test statistic.\\n        df : int\\n            The degrees of freedom of the reference distribution\\n        pvalue : float\\n            The p-value for the test.\\n        '\n    statistic = np.asarray(self.chi2_contribs).sum()\n    df = np.prod(np.asarray(self.table.shape) - 1)\n    pvalue = 1 - stats.chi2.cdf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.df = df\n    b.pvalue = pvalue\n    return b",
            "def test_nominal_association(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Assess independence for nominal factors.\\n\\n        Assessment of independence between rows and columns using\\n        chi^2 testing.  The rows and columns are treated as nominal\\n        (unordered) categorical variables.\\n\\n        Returns\\n        -------\\n        A bunch containing the following attributes:\\n\\n        statistic : float\\n            The chi^2 test statistic.\\n        df : int\\n            The degrees of freedom of the reference distribution\\n        pvalue : float\\n            The p-value for the test.\\n        '\n    statistic = np.asarray(self.chi2_contribs).sum()\n    df = np.prod(np.asarray(self.table.shape) - 1)\n    pvalue = 1 - stats.chi2.cdf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.df = df\n    b.pvalue = pvalue\n    return b",
            "def test_nominal_association(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Assess independence for nominal factors.\\n\\n        Assessment of independence between rows and columns using\\n        chi^2 testing.  The rows and columns are treated as nominal\\n        (unordered) categorical variables.\\n\\n        Returns\\n        -------\\n        A bunch containing the following attributes:\\n\\n        statistic : float\\n            The chi^2 test statistic.\\n        df : int\\n            The degrees of freedom of the reference distribution\\n        pvalue : float\\n            The p-value for the test.\\n        '\n    statistic = np.asarray(self.chi2_contribs).sum()\n    df = np.prod(np.asarray(self.table.shape) - 1)\n    pvalue = 1 - stats.chi2.cdf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.df = df\n    b.pvalue = pvalue\n    return b"
        ]
    },
    {
        "func_name": "test_ordinal_association",
        "original": "def test_ordinal_association(self, row_scores=None, col_scores=None):\n    \"\"\"\n        Assess independence between two ordinal variables.\n\n        This is the 'linear by linear' association test, which uses\n        weights or scores to target the test to have more power\n        against ordered alternatives.\n\n        Parameters\n        ----------\n        row_scores : array_like\n            An array of numeric row scores\n        col_scores : array_like\n            An array of numeric column scores\n\n        Returns\n        -------\n        A bunch with the following attributes:\n\n        statistic : float\n            The test statistic.\n        null_mean : float\n            The expected value of the test statistic under the null\n            hypothesis.\n        null_sd : float\n            The standard deviation of the test statistic under the\n            null hypothesis.\n        zscore : float\n            The Z-score for the test statistic.\n        pvalue : float\n            The p-value for the test.\n\n        Notes\n        -----\n        The scores define the trend to which the test is most sensitive.\n\n        Using the default row and column scores gives the\n        Cochran-Armitage trend test.\n        \"\"\"\n    if row_scores is None:\n        row_scores = np.arange(self.table.shape[0])\n    if col_scores is None:\n        col_scores = np.arange(self.table.shape[1])\n    if len(row_scores) != self.table.shape[0]:\n        msg = 'The length of `row_scores` must match the first ' + 'dimension of `table`.'\n        raise ValueError(msg)\n    if len(col_scores) != self.table.shape[1]:\n        msg = 'The length of `col_scores` must match the second ' + 'dimension of `table`.'\n        raise ValueError(msg)\n    statistic = np.dot(row_scores, np.dot(self.table, col_scores))\n    n_obs = self.table.sum()\n    rtot = self.table.sum(1)\n    um = np.dot(row_scores, rtot)\n    u2m = np.dot(row_scores ** 2, rtot)\n    ctot = self.table.sum(0)\n    vn = np.dot(col_scores, ctot)\n    v2n = np.dot(col_scores ** 2, ctot)\n    e_stat = um * vn / n_obs\n    v_stat = (u2m - um ** 2 / n_obs) * (v2n - vn ** 2 / n_obs) / (n_obs - 1)\n    sd_stat = np.sqrt(v_stat)\n    zscore = (statistic - e_stat) / sd_stat\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    b = _Bunch()\n    b.statistic = statistic\n    b.null_mean = e_stat\n    b.null_sd = sd_stat\n    b.zscore = zscore\n    b.pvalue = pvalue\n    return b",
        "mutated": [
            "def test_ordinal_association(self, row_scores=None, col_scores=None):\n    if False:\n        i = 10\n    \"\\n        Assess independence between two ordinal variables.\\n\\n        This is the 'linear by linear' association test, which uses\\n        weights or scores to target the test to have more power\\n        against ordered alternatives.\\n\\n        Parameters\\n        ----------\\n        row_scores : array_like\\n            An array of numeric row scores\\n        col_scores : array_like\\n            An array of numeric column scores\\n\\n        Returns\\n        -------\\n        A bunch with the following attributes:\\n\\n        statistic : float\\n            The test statistic.\\n        null_mean : float\\n            The expected value of the test statistic under the null\\n            hypothesis.\\n        null_sd : float\\n            The standard deviation of the test statistic under the\\n            null hypothesis.\\n        zscore : float\\n            The Z-score for the test statistic.\\n        pvalue : float\\n            The p-value for the test.\\n\\n        Notes\\n        -----\\n        The scores define the trend to which the test is most sensitive.\\n\\n        Using the default row and column scores gives the\\n        Cochran-Armitage trend test.\\n        \"\n    if row_scores is None:\n        row_scores = np.arange(self.table.shape[0])\n    if col_scores is None:\n        col_scores = np.arange(self.table.shape[1])\n    if len(row_scores) != self.table.shape[0]:\n        msg = 'The length of `row_scores` must match the first ' + 'dimension of `table`.'\n        raise ValueError(msg)\n    if len(col_scores) != self.table.shape[1]:\n        msg = 'The length of `col_scores` must match the second ' + 'dimension of `table`.'\n        raise ValueError(msg)\n    statistic = np.dot(row_scores, np.dot(self.table, col_scores))\n    n_obs = self.table.sum()\n    rtot = self.table.sum(1)\n    um = np.dot(row_scores, rtot)\n    u2m = np.dot(row_scores ** 2, rtot)\n    ctot = self.table.sum(0)\n    vn = np.dot(col_scores, ctot)\n    v2n = np.dot(col_scores ** 2, ctot)\n    e_stat = um * vn / n_obs\n    v_stat = (u2m - um ** 2 / n_obs) * (v2n - vn ** 2 / n_obs) / (n_obs - 1)\n    sd_stat = np.sqrt(v_stat)\n    zscore = (statistic - e_stat) / sd_stat\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    b = _Bunch()\n    b.statistic = statistic\n    b.null_mean = e_stat\n    b.null_sd = sd_stat\n    b.zscore = zscore\n    b.pvalue = pvalue\n    return b",
            "def test_ordinal_association(self, row_scores=None, col_scores=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Assess independence between two ordinal variables.\\n\\n        This is the 'linear by linear' association test, which uses\\n        weights or scores to target the test to have more power\\n        against ordered alternatives.\\n\\n        Parameters\\n        ----------\\n        row_scores : array_like\\n            An array of numeric row scores\\n        col_scores : array_like\\n            An array of numeric column scores\\n\\n        Returns\\n        -------\\n        A bunch with the following attributes:\\n\\n        statistic : float\\n            The test statistic.\\n        null_mean : float\\n            The expected value of the test statistic under the null\\n            hypothesis.\\n        null_sd : float\\n            The standard deviation of the test statistic under the\\n            null hypothesis.\\n        zscore : float\\n            The Z-score for the test statistic.\\n        pvalue : float\\n            The p-value for the test.\\n\\n        Notes\\n        -----\\n        The scores define the trend to which the test is most sensitive.\\n\\n        Using the default row and column scores gives the\\n        Cochran-Armitage trend test.\\n        \"\n    if row_scores is None:\n        row_scores = np.arange(self.table.shape[0])\n    if col_scores is None:\n        col_scores = np.arange(self.table.shape[1])\n    if len(row_scores) != self.table.shape[0]:\n        msg = 'The length of `row_scores` must match the first ' + 'dimension of `table`.'\n        raise ValueError(msg)\n    if len(col_scores) != self.table.shape[1]:\n        msg = 'The length of `col_scores` must match the second ' + 'dimension of `table`.'\n        raise ValueError(msg)\n    statistic = np.dot(row_scores, np.dot(self.table, col_scores))\n    n_obs = self.table.sum()\n    rtot = self.table.sum(1)\n    um = np.dot(row_scores, rtot)\n    u2m = np.dot(row_scores ** 2, rtot)\n    ctot = self.table.sum(0)\n    vn = np.dot(col_scores, ctot)\n    v2n = np.dot(col_scores ** 2, ctot)\n    e_stat = um * vn / n_obs\n    v_stat = (u2m - um ** 2 / n_obs) * (v2n - vn ** 2 / n_obs) / (n_obs - 1)\n    sd_stat = np.sqrt(v_stat)\n    zscore = (statistic - e_stat) / sd_stat\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    b = _Bunch()\n    b.statistic = statistic\n    b.null_mean = e_stat\n    b.null_sd = sd_stat\n    b.zscore = zscore\n    b.pvalue = pvalue\n    return b",
            "def test_ordinal_association(self, row_scores=None, col_scores=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Assess independence between two ordinal variables.\\n\\n        This is the 'linear by linear' association test, which uses\\n        weights or scores to target the test to have more power\\n        against ordered alternatives.\\n\\n        Parameters\\n        ----------\\n        row_scores : array_like\\n            An array of numeric row scores\\n        col_scores : array_like\\n            An array of numeric column scores\\n\\n        Returns\\n        -------\\n        A bunch with the following attributes:\\n\\n        statistic : float\\n            The test statistic.\\n        null_mean : float\\n            The expected value of the test statistic under the null\\n            hypothesis.\\n        null_sd : float\\n            The standard deviation of the test statistic under the\\n            null hypothesis.\\n        zscore : float\\n            The Z-score for the test statistic.\\n        pvalue : float\\n            The p-value for the test.\\n\\n        Notes\\n        -----\\n        The scores define the trend to which the test is most sensitive.\\n\\n        Using the default row and column scores gives the\\n        Cochran-Armitage trend test.\\n        \"\n    if row_scores is None:\n        row_scores = np.arange(self.table.shape[0])\n    if col_scores is None:\n        col_scores = np.arange(self.table.shape[1])\n    if len(row_scores) != self.table.shape[0]:\n        msg = 'The length of `row_scores` must match the first ' + 'dimension of `table`.'\n        raise ValueError(msg)\n    if len(col_scores) != self.table.shape[1]:\n        msg = 'The length of `col_scores` must match the second ' + 'dimension of `table`.'\n        raise ValueError(msg)\n    statistic = np.dot(row_scores, np.dot(self.table, col_scores))\n    n_obs = self.table.sum()\n    rtot = self.table.sum(1)\n    um = np.dot(row_scores, rtot)\n    u2m = np.dot(row_scores ** 2, rtot)\n    ctot = self.table.sum(0)\n    vn = np.dot(col_scores, ctot)\n    v2n = np.dot(col_scores ** 2, ctot)\n    e_stat = um * vn / n_obs\n    v_stat = (u2m - um ** 2 / n_obs) * (v2n - vn ** 2 / n_obs) / (n_obs - 1)\n    sd_stat = np.sqrt(v_stat)\n    zscore = (statistic - e_stat) / sd_stat\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    b = _Bunch()\n    b.statistic = statistic\n    b.null_mean = e_stat\n    b.null_sd = sd_stat\n    b.zscore = zscore\n    b.pvalue = pvalue\n    return b",
            "def test_ordinal_association(self, row_scores=None, col_scores=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Assess independence between two ordinal variables.\\n\\n        This is the 'linear by linear' association test, which uses\\n        weights or scores to target the test to have more power\\n        against ordered alternatives.\\n\\n        Parameters\\n        ----------\\n        row_scores : array_like\\n            An array of numeric row scores\\n        col_scores : array_like\\n            An array of numeric column scores\\n\\n        Returns\\n        -------\\n        A bunch with the following attributes:\\n\\n        statistic : float\\n            The test statistic.\\n        null_mean : float\\n            The expected value of the test statistic under the null\\n            hypothesis.\\n        null_sd : float\\n            The standard deviation of the test statistic under the\\n            null hypothesis.\\n        zscore : float\\n            The Z-score for the test statistic.\\n        pvalue : float\\n            The p-value for the test.\\n\\n        Notes\\n        -----\\n        The scores define the trend to which the test is most sensitive.\\n\\n        Using the default row and column scores gives the\\n        Cochran-Armitage trend test.\\n        \"\n    if row_scores is None:\n        row_scores = np.arange(self.table.shape[0])\n    if col_scores is None:\n        col_scores = np.arange(self.table.shape[1])\n    if len(row_scores) != self.table.shape[0]:\n        msg = 'The length of `row_scores` must match the first ' + 'dimension of `table`.'\n        raise ValueError(msg)\n    if len(col_scores) != self.table.shape[1]:\n        msg = 'The length of `col_scores` must match the second ' + 'dimension of `table`.'\n        raise ValueError(msg)\n    statistic = np.dot(row_scores, np.dot(self.table, col_scores))\n    n_obs = self.table.sum()\n    rtot = self.table.sum(1)\n    um = np.dot(row_scores, rtot)\n    u2m = np.dot(row_scores ** 2, rtot)\n    ctot = self.table.sum(0)\n    vn = np.dot(col_scores, ctot)\n    v2n = np.dot(col_scores ** 2, ctot)\n    e_stat = um * vn / n_obs\n    v_stat = (u2m - um ** 2 / n_obs) * (v2n - vn ** 2 / n_obs) / (n_obs - 1)\n    sd_stat = np.sqrt(v_stat)\n    zscore = (statistic - e_stat) / sd_stat\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    b = _Bunch()\n    b.statistic = statistic\n    b.null_mean = e_stat\n    b.null_sd = sd_stat\n    b.zscore = zscore\n    b.pvalue = pvalue\n    return b",
            "def test_ordinal_association(self, row_scores=None, col_scores=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Assess independence between two ordinal variables.\\n\\n        This is the 'linear by linear' association test, which uses\\n        weights or scores to target the test to have more power\\n        against ordered alternatives.\\n\\n        Parameters\\n        ----------\\n        row_scores : array_like\\n            An array of numeric row scores\\n        col_scores : array_like\\n            An array of numeric column scores\\n\\n        Returns\\n        -------\\n        A bunch with the following attributes:\\n\\n        statistic : float\\n            The test statistic.\\n        null_mean : float\\n            The expected value of the test statistic under the null\\n            hypothesis.\\n        null_sd : float\\n            The standard deviation of the test statistic under the\\n            null hypothesis.\\n        zscore : float\\n            The Z-score for the test statistic.\\n        pvalue : float\\n            The p-value for the test.\\n\\n        Notes\\n        -----\\n        The scores define the trend to which the test is most sensitive.\\n\\n        Using the default row and column scores gives the\\n        Cochran-Armitage trend test.\\n        \"\n    if row_scores is None:\n        row_scores = np.arange(self.table.shape[0])\n    if col_scores is None:\n        col_scores = np.arange(self.table.shape[1])\n    if len(row_scores) != self.table.shape[0]:\n        msg = 'The length of `row_scores` must match the first ' + 'dimension of `table`.'\n        raise ValueError(msg)\n    if len(col_scores) != self.table.shape[1]:\n        msg = 'The length of `col_scores` must match the second ' + 'dimension of `table`.'\n        raise ValueError(msg)\n    statistic = np.dot(row_scores, np.dot(self.table, col_scores))\n    n_obs = self.table.sum()\n    rtot = self.table.sum(1)\n    um = np.dot(row_scores, rtot)\n    u2m = np.dot(row_scores ** 2, rtot)\n    ctot = self.table.sum(0)\n    vn = np.dot(col_scores, ctot)\n    v2n = np.dot(col_scores ** 2, ctot)\n    e_stat = um * vn / n_obs\n    v_stat = (u2m - um ** 2 / n_obs) * (v2n - vn ** 2 / n_obs) / (n_obs - 1)\n    sd_stat = np.sqrt(v_stat)\n    zscore = (statistic - e_stat) / sd_stat\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    b = _Bunch()\n    b.statistic = statistic\n    b.null_mean = e_stat\n    b.null_sd = sd_stat\n    b.zscore = zscore\n    b.pvalue = pvalue\n    return b"
        ]
    },
    {
        "func_name": "marginal_probabilities",
        "original": "@cache_readonly\ndef marginal_probabilities(self):\n    \"\"\"\n        Estimate marginal probability distributions for the rows and columns.\n\n        Returns\n        -------\n        row : ndarray\n            Marginal row probabilities\n        col : ndarray\n            Marginal column probabilities\n        \"\"\"\n    n = self.table.sum()\n    row = self.table.sum(1) / n\n    col = self.table.sum(0) / n\n    if isinstance(self.table_orig, pd.DataFrame):\n        row = pd.Series(row, self.table_orig.index)\n        col = pd.Series(col, self.table_orig.columns)\n    return (row, col)",
        "mutated": [
            "@cache_readonly\ndef marginal_probabilities(self):\n    if False:\n        i = 10\n    '\\n        Estimate marginal probability distributions for the rows and columns.\\n\\n        Returns\\n        -------\\n        row : ndarray\\n            Marginal row probabilities\\n        col : ndarray\\n            Marginal column probabilities\\n        '\n    n = self.table.sum()\n    row = self.table.sum(1) / n\n    col = self.table.sum(0) / n\n    if isinstance(self.table_orig, pd.DataFrame):\n        row = pd.Series(row, self.table_orig.index)\n        col = pd.Series(col, self.table_orig.columns)\n    return (row, col)",
            "@cache_readonly\ndef marginal_probabilities(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Estimate marginal probability distributions for the rows and columns.\\n\\n        Returns\\n        -------\\n        row : ndarray\\n            Marginal row probabilities\\n        col : ndarray\\n            Marginal column probabilities\\n        '\n    n = self.table.sum()\n    row = self.table.sum(1) / n\n    col = self.table.sum(0) / n\n    if isinstance(self.table_orig, pd.DataFrame):\n        row = pd.Series(row, self.table_orig.index)\n        col = pd.Series(col, self.table_orig.columns)\n    return (row, col)",
            "@cache_readonly\ndef marginal_probabilities(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Estimate marginal probability distributions for the rows and columns.\\n\\n        Returns\\n        -------\\n        row : ndarray\\n            Marginal row probabilities\\n        col : ndarray\\n            Marginal column probabilities\\n        '\n    n = self.table.sum()\n    row = self.table.sum(1) / n\n    col = self.table.sum(0) / n\n    if isinstance(self.table_orig, pd.DataFrame):\n        row = pd.Series(row, self.table_orig.index)\n        col = pd.Series(col, self.table_orig.columns)\n    return (row, col)",
            "@cache_readonly\ndef marginal_probabilities(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Estimate marginal probability distributions for the rows and columns.\\n\\n        Returns\\n        -------\\n        row : ndarray\\n            Marginal row probabilities\\n        col : ndarray\\n            Marginal column probabilities\\n        '\n    n = self.table.sum()\n    row = self.table.sum(1) / n\n    col = self.table.sum(0) / n\n    if isinstance(self.table_orig, pd.DataFrame):\n        row = pd.Series(row, self.table_orig.index)\n        col = pd.Series(col, self.table_orig.columns)\n    return (row, col)",
            "@cache_readonly\ndef marginal_probabilities(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Estimate marginal probability distributions for the rows and columns.\\n\\n        Returns\\n        -------\\n        row : ndarray\\n            Marginal row probabilities\\n        col : ndarray\\n            Marginal column probabilities\\n        '\n    n = self.table.sum()\n    row = self.table.sum(1) / n\n    col = self.table.sum(0) / n\n    if isinstance(self.table_orig, pd.DataFrame):\n        row = pd.Series(row, self.table_orig.index)\n        col = pd.Series(col, self.table_orig.columns)\n    return (row, col)"
        ]
    },
    {
        "func_name": "independence_probabilities",
        "original": "@cache_readonly\ndef independence_probabilities(self):\n    \"\"\"\n        Returns fitted joint probabilities under independence.\n\n        The returned table is outer(row, column), where row and\n        column are the estimated marginal distributions\n        of the rows and columns.\n        \"\"\"\n    (row, col) = self.marginal_probabilities\n    itab = np.outer(row, col)\n    if isinstance(self.table_orig, pd.DataFrame):\n        itab = pd.DataFrame(itab, self.table_orig.index, self.table_orig.columns)\n    return itab",
        "mutated": [
            "@cache_readonly\ndef independence_probabilities(self):\n    if False:\n        i = 10\n    '\\n        Returns fitted joint probabilities under independence.\\n\\n        The returned table is outer(row, column), where row and\\n        column are the estimated marginal distributions\\n        of the rows and columns.\\n        '\n    (row, col) = self.marginal_probabilities\n    itab = np.outer(row, col)\n    if isinstance(self.table_orig, pd.DataFrame):\n        itab = pd.DataFrame(itab, self.table_orig.index, self.table_orig.columns)\n    return itab",
            "@cache_readonly\ndef independence_probabilities(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns fitted joint probabilities under independence.\\n\\n        The returned table is outer(row, column), where row and\\n        column are the estimated marginal distributions\\n        of the rows and columns.\\n        '\n    (row, col) = self.marginal_probabilities\n    itab = np.outer(row, col)\n    if isinstance(self.table_orig, pd.DataFrame):\n        itab = pd.DataFrame(itab, self.table_orig.index, self.table_orig.columns)\n    return itab",
            "@cache_readonly\ndef independence_probabilities(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns fitted joint probabilities under independence.\\n\\n        The returned table is outer(row, column), where row and\\n        column are the estimated marginal distributions\\n        of the rows and columns.\\n        '\n    (row, col) = self.marginal_probabilities\n    itab = np.outer(row, col)\n    if isinstance(self.table_orig, pd.DataFrame):\n        itab = pd.DataFrame(itab, self.table_orig.index, self.table_orig.columns)\n    return itab",
            "@cache_readonly\ndef independence_probabilities(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns fitted joint probabilities under independence.\\n\\n        The returned table is outer(row, column), where row and\\n        column are the estimated marginal distributions\\n        of the rows and columns.\\n        '\n    (row, col) = self.marginal_probabilities\n    itab = np.outer(row, col)\n    if isinstance(self.table_orig, pd.DataFrame):\n        itab = pd.DataFrame(itab, self.table_orig.index, self.table_orig.columns)\n    return itab",
            "@cache_readonly\ndef independence_probabilities(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns fitted joint probabilities under independence.\\n\\n        The returned table is outer(row, column), where row and\\n        column are the estimated marginal distributions\\n        of the rows and columns.\\n        '\n    (row, col) = self.marginal_probabilities\n    itab = np.outer(row, col)\n    if isinstance(self.table_orig, pd.DataFrame):\n        itab = pd.DataFrame(itab, self.table_orig.index, self.table_orig.columns)\n    return itab"
        ]
    },
    {
        "func_name": "fittedvalues",
        "original": "@cache_readonly\ndef fittedvalues(self):\n    \"\"\"\n        Returns fitted cell counts under independence.\n\n        The returned cell counts are estimates under a model\n        where the rows and columns of the table are independent.\n        \"\"\"\n    probs = self.independence_probabilities\n    fit = self.table.sum() * probs\n    return fit",
        "mutated": [
            "@cache_readonly\ndef fittedvalues(self):\n    if False:\n        i = 10\n    '\\n        Returns fitted cell counts under independence.\\n\\n        The returned cell counts are estimates under a model\\n        where the rows and columns of the table are independent.\\n        '\n    probs = self.independence_probabilities\n    fit = self.table.sum() * probs\n    return fit",
            "@cache_readonly\ndef fittedvalues(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns fitted cell counts under independence.\\n\\n        The returned cell counts are estimates under a model\\n        where the rows and columns of the table are independent.\\n        '\n    probs = self.independence_probabilities\n    fit = self.table.sum() * probs\n    return fit",
            "@cache_readonly\ndef fittedvalues(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns fitted cell counts under independence.\\n\\n        The returned cell counts are estimates under a model\\n        where the rows and columns of the table are independent.\\n        '\n    probs = self.independence_probabilities\n    fit = self.table.sum() * probs\n    return fit",
            "@cache_readonly\ndef fittedvalues(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns fitted cell counts under independence.\\n\\n        The returned cell counts are estimates under a model\\n        where the rows and columns of the table are independent.\\n        '\n    probs = self.independence_probabilities\n    fit = self.table.sum() * probs\n    return fit",
            "@cache_readonly\ndef fittedvalues(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns fitted cell counts under independence.\\n\\n        The returned cell counts are estimates under a model\\n        where the rows and columns of the table are independent.\\n        '\n    probs = self.independence_probabilities\n    fit = self.table.sum() * probs\n    return fit"
        ]
    },
    {
        "func_name": "resid_pearson",
        "original": "@cache_readonly\ndef resid_pearson(self):\n    \"\"\"\n        Returns Pearson residuals.\n\n        The Pearson residuals are calculated under a model where\n        the rows and columns of the table are independent.\n        \"\"\"\n    fit = self.fittedvalues\n    resids = (self.table - fit) / np.sqrt(fit)\n    return resids",
        "mutated": [
            "@cache_readonly\ndef resid_pearson(self):\n    if False:\n        i = 10\n    '\\n        Returns Pearson residuals.\\n\\n        The Pearson residuals are calculated under a model where\\n        the rows and columns of the table are independent.\\n        '\n    fit = self.fittedvalues\n    resids = (self.table - fit) / np.sqrt(fit)\n    return resids",
            "@cache_readonly\ndef resid_pearson(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns Pearson residuals.\\n\\n        The Pearson residuals are calculated under a model where\\n        the rows and columns of the table are independent.\\n        '\n    fit = self.fittedvalues\n    resids = (self.table - fit) / np.sqrt(fit)\n    return resids",
            "@cache_readonly\ndef resid_pearson(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns Pearson residuals.\\n\\n        The Pearson residuals are calculated under a model where\\n        the rows and columns of the table are independent.\\n        '\n    fit = self.fittedvalues\n    resids = (self.table - fit) / np.sqrt(fit)\n    return resids",
            "@cache_readonly\ndef resid_pearson(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns Pearson residuals.\\n\\n        The Pearson residuals are calculated under a model where\\n        the rows and columns of the table are independent.\\n        '\n    fit = self.fittedvalues\n    resids = (self.table - fit) / np.sqrt(fit)\n    return resids",
            "@cache_readonly\ndef resid_pearson(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns Pearson residuals.\\n\\n        The Pearson residuals are calculated under a model where\\n        the rows and columns of the table are independent.\\n        '\n    fit = self.fittedvalues\n    resids = (self.table - fit) / np.sqrt(fit)\n    return resids"
        ]
    },
    {
        "func_name": "standardized_resids",
        "original": "@cache_readonly\ndef standardized_resids(self):\n    \"\"\"\n        Returns standardized residuals under independence.\n        \"\"\"\n    (row, col) = self.marginal_probabilities\n    sresids = self.resid_pearson / np.sqrt(np.outer(1 - row, 1 - col))\n    return sresids",
        "mutated": [
            "@cache_readonly\ndef standardized_resids(self):\n    if False:\n        i = 10\n    '\\n        Returns standardized residuals under independence.\\n        '\n    (row, col) = self.marginal_probabilities\n    sresids = self.resid_pearson / np.sqrt(np.outer(1 - row, 1 - col))\n    return sresids",
            "@cache_readonly\ndef standardized_resids(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns standardized residuals under independence.\\n        '\n    (row, col) = self.marginal_probabilities\n    sresids = self.resid_pearson / np.sqrt(np.outer(1 - row, 1 - col))\n    return sresids",
            "@cache_readonly\ndef standardized_resids(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns standardized residuals under independence.\\n        '\n    (row, col) = self.marginal_probabilities\n    sresids = self.resid_pearson / np.sqrt(np.outer(1 - row, 1 - col))\n    return sresids",
            "@cache_readonly\ndef standardized_resids(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns standardized residuals under independence.\\n        '\n    (row, col) = self.marginal_probabilities\n    sresids = self.resid_pearson / np.sqrt(np.outer(1 - row, 1 - col))\n    return sresids",
            "@cache_readonly\ndef standardized_resids(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns standardized residuals under independence.\\n        '\n    (row, col) = self.marginal_probabilities\n    sresids = self.resid_pearson / np.sqrt(np.outer(1 - row, 1 - col))\n    return sresids"
        ]
    },
    {
        "func_name": "chi2_contribs",
        "original": "@cache_readonly\ndef chi2_contribs(self):\n    \"\"\"\n        Returns the contributions to the chi^2 statistic for independence.\n\n        The returned table contains the contribution of each cell to the chi^2\n        test statistic for the null hypothesis that the rows and columns\n        are independent.\n        \"\"\"\n    return self.resid_pearson ** 2",
        "mutated": [
            "@cache_readonly\ndef chi2_contribs(self):\n    if False:\n        i = 10\n    '\\n        Returns the contributions to the chi^2 statistic for independence.\\n\\n        The returned table contains the contribution of each cell to the chi^2\\n        test statistic for the null hypothesis that the rows and columns\\n        are independent.\\n        '\n    return self.resid_pearson ** 2",
            "@cache_readonly\ndef chi2_contribs(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the contributions to the chi^2 statistic for independence.\\n\\n        The returned table contains the contribution of each cell to the chi^2\\n        test statistic for the null hypothesis that the rows and columns\\n        are independent.\\n        '\n    return self.resid_pearson ** 2",
            "@cache_readonly\ndef chi2_contribs(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the contributions to the chi^2 statistic for independence.\\n\\n        The returned table contains the contribution of each cell to the chi^2\\n        test statistic for the null hypothesis that the rows and columns\\n        are independent.\\n        '\n    return self.resid_pearson ** 2",
            "@cache_readonly\ndef chi2_contribs(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the contributions to the chi^2 statistic for independence.\\n\\n        The returned table contains the contribution of each cell to the chi^2\\n        test statistic for the null hypothesis that the rows and columns\\n        are independent.\\n        '\n    return self.resid_pearson ** 2",
            "@cache_readonly\ndef chi2_contribs(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the contributions to the chi^2 statistic for independence.\\n\\n        The returned table contains the contribution of each cell to the chi^2\\n        test statistic for the null hypothesis that the rows and columns\\n        are independent.\\n        '\n    return self.resid_pearson ** 2"
        ]
    },
    {
        "func_name": "local_log_oddsratios",
        "original": "@cache_readonly\ndef local_log_oddsratios(self):\n    \"\"\"\n        Returns local log odds ratios.\n\n        The local log odds ratios are the log odds ratios\n        calculated for contiguous 2x2 sub-tables.\n        \"\"\"\n    ta = self.table.copy()\n    a = ta[0:-1, 0:-1]\n    b = ta[0:-1, 1:]\n    c = ta[1:, 0:-1]\n    d = ta[1:, 1:]\n    tab = np.log(a) + np.log(d) - np.log(b) - np.log(c)\n    rslt = np.empty(self.table.shape, np.float64)\n    rslt *= np.nan\n    rslt[0:-1, 0:-1] = tab\n    if isinstance(self.table_orig, pd.DataFrame):\n        rslt = pd.DataFrame(rslt, index=self.table_orig.index, columns=self.table_orig.columns)\n    return rslt",
        "mutated": [
            "@cache_readonly\ndef local_log_oddsratios(self):\n    if False:\n        i = 10\n    '\\n        Returns local log odds ratios.\\n\\n        The local log odds ratios are the log odds ratios\\n        calculated for contiguous 2x2 sub-tables.\\n        '\n    ta = self.table.copy()\n    a = ta[0:-1, 0:-1]\n    b = ta[0:-1, 1:]\n    c = ta[1:, 0:-1]\n    d = ta[1:, 1:]\n    tab = np.log(a) + np.log(d) - np.log(b) - np.log(c)\n    rslt = np.empty(self.table.shape, np.float64)\n    rslt *= np.nan\n    rslt[0:-1, 0:-1] = tab\n    if isinstance(self.table_orig, pd.DataFrame):\n        rslt = pd.DataFrame(rslt, index=self.table_orig.index, columns=self.table_orig.columns)\n    return rslt",
            "@cache_readonly\ndef local_log_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns local log odds ratios.\\n\\n        The local log odds ratios are the log odds ratios\\n        calculated for contiguous 2x2 sub-tables.\\n        '\n    ta = self.table.copy()\n    a = ta[0:-1, 0:-1]\n    b = ta[0:-1, 1:]\n    c = ta[1:, 0:-1]\n    d = ta[1:, 1:]\n    tab = np.log(a) + np.log(d) - np.log(b) - np.log(c)\n    rslt = np.empty(self.table.shape, np.float64)\n    rslt *= np.nan\n    rslt[0:-1, 0:-1] = tab\n    if isinstance(self.table_orig, pd.DataFrame):\n        rslt = pd.DataFrame(rslt, index=self.table_orig.index, columns=self.table_orig.columns)\n    return rslt",
            "@cache_readonly\ndef local_log_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns local log odds ratios.\\n\\n        The local log odds ratios are the log odds ratios\\n        calculated for contiguous 2x2 sub-tables.\\n        '\n    ta = self.table.copy()\n    a = ta[0:-1, 0:-1]\n    b = ta[0:-1, 1:]\n    c = ta[1:, 0:-1]\n    d = ta[1:, 1:]\n    tab = np.log(a) + np.log(d) - np.log(b) - np.log(c)\n    rslt = np.empty(self.table.shape, np.float64)\n    rslt *= np.nan\n    rslt[0:-1, 0:-1] = tab\n    if isinstance(self.table_orig, pd.DataFrame):\n        rslt = pd.DataFrame(rslt, index=self.table_orig.index, columns=self.table_orig.columns)\n    return rslt",
            "@cache_readonly\ndef local_log_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns local log odds ratios.\\n\\n        The local log odds ratios are the log odds ratios\\n        calculated for contiguous 2x2 sub-tables.\\n        '\n    ta = self.table.copy()\n    a = ta[0:-1, 0:-1]\n    b = ta[0:-1, 1:]\n    c = ta[1:, 0:-1]\n    d = ta[1:, 1:]\n    tab = np.log(a) + np.log(d) - np.log(b) - np.log(c)\n    rslt = np.empty(self.table.shape, np.float64)\n    rslt *= np.nan\n    rslt[0:-1, 0:-1] = tab\n    if isinstance(self.table_orig, pd.DataFrame):\n        rslt = pd.DataFrame(rslt, index=self.table_orig.index, columns=self.table_orig.columns)\n    return rslt",
            "@cache_readonly\ndef local_log_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns local log odds ratios.\\n\\n        The local log odds ratios are the log odds ratios\\n        calculated for contiguous 2x2 sub-tables.\\n        '\n    ta = self.table.copy()\n    a = ta[0:-1, 0:-1]\n    b = ta[0:-1, 1:]\n    c = ta[1:, 0:-1]\n    d = ta[1:, 1:]\n    tab = np.log(a) + np.log(d) - np.log(b) - np.log(c)\n    rslt = np.empty(self.table.shape, np.float64)\n    rslt *= np.nan\n    rslt[0:-1, 0:-1] = tab\n    if isinstance(self.table_orig, pd.DataFrame):\n        rslt = pd.DataFrame(rslt, index=self.table_orig.index, columns=self.table_orig.columns)\n    return rslt"
        ]
    },
    {
        "func_name": "local_oddsratios",
        "original": "@cache_readonly\ndef local_oddsratios(self):\n    \"\"\"\n        Returns local odds ratios.\n\n        See documentation for local_log_oddsratios.\n        \"\"\"\n    return np.exp(self.local_log_oddsratios)",
        "mutated": [
            "@cache_readonly\ndef local_oddsratios(self):\n    if False:\n        i = 10\n    '\\n        Returns local odds ratios.\\n\\n        See documentation for local_log_oddsratios.\\n        '\n    return np.exp(self.local_log_oddsratios)",
            "@cache_readonly\ndef local_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns local odds ratios.\\n\\n        See documentation for local_log_oddsratios.\\n        '\n    return np.exp(self.local_log_oddsratios)",
            "@cache_readonly\ndef local_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns local odds ratios.\\n\\n        See documentation for local_log_oddsratios.\\n        '\n    return np.exp(self.local_log_oddsratios)",
            "@cache_readonly\ndef local_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns local odds ratios.\\n\\n        See documentation for local_log_oddsratios.\\n        '\n    return np.exp(self.local_log_oddsratios)",
            "@cache_readonly\ndef local_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns local odds ratios.\\n\\n        See documentation for local_log_oddsratios.\\n        '\n    return np.exp(self.local_log_oddsratios)"
        ]
    },
    {
        "func_name": "cumulative_log_oddsratios",
        "original": "@cache_readonly\ndef cumulative_log_oddsratios(self):\n    \"\"\"\n        Returns cumulative log odds ratios.\n\n        The cumulative log odds ratios for a contingency table\n        with ordered rows and columns are calculated by collapsing\n        all cells to the left/right and above/below a given point,\n        to obtain a 2x2 table from which a log odds ratio can be\n        calculated.\n        \"\"\"\n    ta = self.table.cumsum(0).cumsum(1)\n    a = ta[0:-1, 0:-1]\n    b = ta[0:-1, -1:] - a\n    c = ta[-1:, 0:-1] - a\n    d = ta[-1, -1] - (a + b + c)\n    tab = np.log(a) + np.log(d) - np.log(b) - np.log(c)\n    rslt = np.empty(self.table.shape, np.float64)\n    rslt *= np.nan\n    rslt[0:-1, 0:-1] = tab\n    if isinstance(self.table_orig, pd.DataFrame):\n        rslt = pd.DataFrame(rslt, index=self.table_orig.index, columns=self.table_orig.columns)\n    return rslt",
        "mutated": [
            "@cache_readonly\ndef cumulative_log_oddsratios(self):\n    if False:\n        i = 10\n    '\\n        Returns cumulative log odds ratios.\\n\\n        The cumulative log odds ratios for a contingency table\\n        with ordered rows and columns are calculated by collapsing\\n        all cells to the left/right and above/below a given point,\\n        to obtain a 2x2 table from which a log odds ratio can be\\n        calculated.\\n        '\n    ta = self.table.cumsum(0).cumsum(1)\n    a = ta[0:-1, 0:-1]\n    b = ta[0:-1, -1:] - a\n    c = ta[-1:, 0:-1] - a\n    d = ta[-1, -1] - (a + b + c)\n    tab = np.log(a) + np.log(d) - np.log(b) - np.log(c)\n    rslt = np.empty(self.table.shape, np.float64)\n    rslt *= np.nan\n    rslt[0:-1, 0:-1] = tab\n    if isinstance(self.table_orig, pd.DataFrame):\n        rslt = pd.DataFrame(rslt, index=self.table_orig.index, columns=self.table_orig.columns)\n    return rslt",
            "@cache_readonly\ndef cumulative_log_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns cumulative log odds ratios.\\n\\n        The cumulative log odds ratios for a contingency table\\n        with ordered rows and columns are calculated by collapsing\\n        all cells to the left/right and above/below a given point,\\n        to obtain a 2x2 table from which a log odds ratio can be\\n        calculated.\\n        '\n    ta = self.table.cumsum(0).cumsum(1)\n    a = ta[0:-1, 0:-1]\n    b = ta[0:-1, -1:] - a\n    c = ta[-1:, 0:-1] - a\n    d = ta[-1, -1] - (a + b + c)\n    tab = np.log(a) + np.log(d) - np.log(b) - np.log(c)\n    rslt = np.empty(self.table.shape, np.float64)\n    rslt *= np.nan\n    rslt[0:-1, 0:-1] = tab\n    if isinstance(self.table_orig, pd.DataFrame):\n        rslt = pd.DataFrame(rslt, index=self.table_orig.index, columns=self.table_orig.columns)\n    return rslt",
            "@cache_readonly\ndef cumulative_log_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns cumulative log odds ratios.\\n\\n        The cumulative log odds ratios for a contingency table\\n        with ordered rows and columns are calculated by collapsing\\n        all cells to the left/right and above/below a given point,\\n        to obtain a 2x2 table from which a log odds ratio can be\\n        calculated.\\n        '\n    ta = self.table.cumsum(0).cumsum(1)\n    a = ta[0:-1, 0:-1]\n    b = ta[0:-1, -1:] - a\n    c = ta[-1:, 0:-1] - a\n    d = ta[-1, -1] - (a + b + c)\n    tab = np.log(a) + np.log(d) - np.log(b) - np.log(c)\n    rslt = np.empty(self.table.shape, np.float64)\n    rslt *= np.nan\n    rslt[0:-1, 0:-1] = tab\n    if isinstance(self.table_orig, pd.DataFrame):\n        rslt = pd.DataFrame(rslt, index=self.table_orig.index, columns=self.table_orig.columns)\n    return rslt",
            "@cache_readonly\ndef cumulative_log_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns cumulative log odds ratios.\\n\\n        The cumulative log odds ratios for a contingency table\\n        with ordered rows and columns are calculated by collapsing\\n        all cells to the left/right and above/below a given point,\\n        to obtain a 2x2 table from which a log odds ratio can be\\n        calculated.\\n        '\n    ta = self.table.cumsum(0).cumsum(1)\n    a = ta[0:-1, 0:-1]\n    b = ta[0:-1, -1:] - a\n    c = ta[-1:, 0:-1] - a\n    d = ta[-1, -1] - (a + b + c)\n    tab = np.log(a) + np.log(d) - np.log(b) - np.log(c)\n    rslt = np.empty(self.table.shape, np.float64)\n    rslt *= np.nan\n    rslt[0:-1, 0:-1] = tab\n    if isinstance(self.table_orig, pd.DataFrame):\n        rslt = pd.DataFrame(rslt, index=self.table_orig.index, columns=self.table_orig.columns)\n    return rslt",
            "@cache_readonly\ndef cumulative_log_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns cumulative log odds ratios.\\n\\n        The cumulative log odds ratios for a contingency table\\n        with ordered rows and columns are calculated by collapsing\\n        all cells to the left/right and above/below a given point,\\n        to obtain a 2x2 table from which a log odds ratio can be\\n        calculated.\\n        '\n    ta = self.table.cumsum(0).cumsum(1)\n    a = ta[0:-1, 0:-1]\n    b = ta[0:-1, -1:] - a\n    c = ta[-1:, 0:-1] - a\n    d = ta[-1, -1] - (a + b + c)\n    tab = np.log(a) + np.log(d) - np.log(b) - np.log(c)\n    rslt = np.empty(self.table.shape, np.float64)\n    rslt *= np.nan\n    rslt[0:-1, 0:-1] = tab\n    if isinstance(self.table_orig, pd.DataFrame):\n        rslt = pd.DataFrame(rslt, index=self.table_orig.index, columns=self.table_orig.columns)\n    return rslt"
        ]
    },
    {
        "func_name": "cumulative_oddsratios",
        "original": "@cache_readonly\ndef cumulative_oddsratios(self):\n    \"\"\"\n        Returns the cumulative odds ratios for a contingency table.\n\n        See documentation for cumulative_log_oddsratio.\n        \"\"\"\n    return np.exp(self.cumulative_log_oddsratios)",
        "mutated": [
            "@cache_readonly\ndef cumulative_oddsratios(self):\n    if False:\n        i = 10\n    '\\n        Returns the cumulative odds ratios for a contingency table.\\n\\n        See documentation for cumulative_log_oddsratio.\\n        '\n    return np.exp(self.cumulative_log_oddsratios)",
            "@cache_readonly\ndef cumulative_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the cumulative odds ratios for a contingency table.\\n\\n        See documentation for cumulative_log_oddsratio.\\n        '\n    return np.exp(self.cumulative_log_oddsratios)",
            "@cache_readonly\ndef cumulative_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the cumulative odds ratios for a contingency table.\\n\\n        See documentation for cumulative_log_oddsratio.\\n        '\n    return np.exp(self.cumulative_log_oddsratios)",
            "@cache_readonly\ndef cumulative_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the cumulative odds ratios for a contingency table.\\n\\n        See documentation for cumulative_log_oddsratio.\\n        '\n    return np.exp(self.cumulative_log_oddsratios)",
            "@cache_readonly\ndef cumulative_oddsratios(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the cumulative odds ratios for a contingency table.\\n\\n        See documentation for cumulative_log_oddsratio.\\n        '\n    return np.exp(self.cumulative_log_oddsratios)"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, table, shift_zeros=True):\n    table = _make_df_square(table)\n    (k1, k2) = table.shape\n    if k1 != k2:\n        raise ValueError('table must be square')\n    super(SquareTable, self).__init__(table, shift_zeros)",
        "mutated": [
            "def __init__(self, table, shift_zeros=True):\n    if False:\n        i = 10\n    table = _make_df_square(table)\n    (k1, k2) = table.shape\n    if k1 != k2:\n        raise ValueError('table must be square')\n    super(SquareTable, self).__init__(table, shift_zeros)",
            "def __init__(self, table, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    table = _make_df_square(table)\n    (k1, k2) = table.shape\n    if k1 != k2:\n        raise ValueError('table must be square')\n    super(SquareTable, self).__init__(table, shift_zeros)",
            "def __init__(self, table, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    table = _make_df_square(table)\n    (k1, k2) = table.shape\n    if k1 != k2:\n        raise ValueError('table must be square')\n    super(SquareTable, self).__init__(table, shift_zeros)",
            "def __init__(self, table, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    table = _make_df_square(table)\n    (k1, k2) = table.shape\n    if k1 != k2:\n        raise ValueError('table must be square')\n    super(SquareTable, self).__init__(table, shift_zeros)",
            "def __init__(self, table, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    table = _make_df_square(table)\n    (k1, k2) = table.shape\n    if k1 != k2:\n        raise ValueError('table must be square')\n    super(SquareTable, self).__init__(table, shift_zeros)"
        ]
    },
    {
        "func_name": "symmetry",
        "original": "def symmetry(self, method='bowker'):\n    \"\"\"\n        Test for symmetry of a joint distribution.\n\n        This procedure tests the null hypothesis that the joint\n        distribution is symmetric around the main diagonal, that is\n\n        .. math::\n\n        p_{i, j} = p_{j, i}  for all i, j\n\n        Returns\n        -------\n        Bunch\n            A bunch with attributes\n\n            * statistic : float\n                chisquare test statistic\n            * p-value : float\n                p-value of the test statistic based on chisquare distribution\n            * df : int\n                degrees of freedom of the chisquare distribution\n\n        Notes\n        -----\n        The implementation is based on the SAS documentation. R includes\n        it in `mcnemar.test` if the table is not 2 by 2.  However a more\n        direct generalization of the McNemar test to larger tables is\n        provided by the homogeneity test (TableSymmetry.homogeneity).\n\n        The p-value is based on the chi-square distribution which requires\n        that the sample size is not very small to be a good approximation\n        of the true distribution. For 2x2 contingency tables the exact\n        distribution can be obtained with `mcnemar`\n\n        See Also\n        --------\n        mcnemar\n        homogeneity\n        \"\"\"\n    if method.lower() != 'bowker':\n        raise ValueError(\"method for symmetry testing must be 'bowker'\")\n    k = self.table.shape[0]\n    upp_idx = np.triu_indices(k, 1)\n    tril = self.table.T[upp_idx]\n    triu = self.table[upp_idx]\n    statistic = ((tril - triu) ** 2 / (tril + triu + 1e-20)).sum()\n    df = k * (k - 1) / 2.0\n    pvalue = stats.chi2.sf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    b.df = df\n    return b",
        "mutated": [
            "def symmetry(self, method='bowker'):\n    if False:\n        i = 10\n    '\\n        Test for symmetry of a joint distribution.\\n\\n        This procedure tests the null hypothesis that the joint\\n        distribution is symmetric around the main diagonal, that is\\n\\n        .. math::\\n\\n        p_{i, j} = p_{j, i}  for all i, j\\n\\n        Returns\\n        -------\\n        Bunch\\n            A bunch with attributes\\n\\n            * statistic : float\\n                chisquare test statistic\\n            * p-value : float\\n                p-value of the test statistic based on chisquare distribution\\n            * df : int\\n                degrees of freedom of the chisquare distribution\\n\\n        Notes\\n        -----\\n        The implementation is based on the SAS documentation. R includes\\n        it in `mcnemar.test` if the table is not 2 by 2.  However a more\\n        direct generalization of the McNemar test to larger tables is\\n        provided by the homogeneity test (TableSymmetry.homogeneity).\\n\\n        The p-value is based on the chi-square distribution which requires\\n        that the sample size is not very small to be a good approximation\\n        of the true distribution. For 2x2 contingency tables the exact\\n        distribution can be obtained with `mcnemar`\\n\\n        See Also\\n        --------\\n        mcnemar\\n        homogeneity\\n        '\n    if method.lower() != 'bowker':\n        raise ValueError(\"method for symmetry testing must be 'bowker'\")\n    k = self.table.shape[0]\n    upp_idx = np.triu_indices(k, 1)\n    tril = self.table.T[upp_idx]\n    triu = self.table[upp_idx]\n    statistic = ((tril - triu) ** 2 / (tril + triu + 1e-20)).sum()\n    df = k * (k - 1) / 2.0\n    pvalue = stats.chi2.sf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    b.df = df\n    return b",
            "def symmetry(self, method='bowker'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Test for symmetry of a joint distribution.\\n\\n        This procedure tests the null hypothesis that the joint\\n        distribution is symmetric around the main diagonal, that is\\n\\n        .. math::\\n\\n        p_{i, j} = p_{j, i}  for all i, j\\n\\n        Returns\\n        -------\\n        Bunch\\n            A bunch with attributes\\n\\n            * statistic : float\\n                chisquare test statistic\\n            * p-value : float\\n                p-value of the test statistic based on chisquare distribution\\n            * df : int\\n                degrees of freedom of the chisquare distribution\\n\\n        Notes\\n        -----\\n        The implementation is based on the SAS documentation. R includes\\n        it in `mcnemar.test` if the table is not 2 by 2.  However a more\\n        direct generalization of the McNemar test to larger tables is\\n        provided by the homogeneity test (TableSymmetry.homogeneity).\\n\\n        The p-value is based on the chi-square distribution which requires\\n        that the sample size is not very small to be a good approximation\\n        of the true distribution. For 2x2 contingency tables the exact\\n        distribution can be obtained with `mcnemar`\\n\\n        See Also\\n        --------\\n        mcnemar\\n        homogeneity\\n        '\n    if method.lower() != 'bowker':\n        raise ValueError(\"method for symmetry testing must be 'bowker'\")\n    k = self.table.shape[0]\n    upp_idx = np.triu_indices(k, 1)\n    tril = self.table.T[upp_idx]\n    triu = self.table[upp_idx]\n    statistic = ((tril - triu) ** 2 / (tril + triu + 1e-20)).sum()\n    df = k * (k - 1) / 2.0\n    pvalue = stats.chi2.sf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    b.df = df\n    return b",
            "def symmetry(self, method='bowker'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Test for symmetry of a joint distribution.\\n\\n        This procedure tests the null hypothesis that the joint\\n        distribution is symmetric around the main diagonal, that is\\n\\n        .. math::\\n\\n        p_{i, j} = p_{j, i}  for all i, j\\n\\n        Returns\\n        -------\\n        Bunch\\n            A bunch with attributes\\n\\n            * statistic : float\\n                chisquare test statistic\\n            * p-value : float\\n                p-value of the test statistic based on chisquare distribution\\n            * df : int\\n                degrees of freedom of the chisquare distribution\\n\\n        Notes\\n        -----\\n        The implementation is based on the SAS documentation. R includes\\n        it in `mcnemar.test` if the table is not 2 by 2.  However a more\\n        direct generalization of the McNemar test to larger tables is\\n        provided by the homogeneity test (TableSymmetry.homogeneity).\\n\\n        The p-value is based on the chi-square distribution which requires\\n        that the sample size is not very small to be a good approximation\\n        of the true distribution. For 2x2 contingency tables the exact\\n        distribution can be obtained with `mcnemar`\\n\\n        See Also\\n        --------\\n        mcnemar\\n        homogeneity\\n        '\n    if method.lower() != 'bowker':\n        raise ValueError(\"method for symmetry testing must be 'bowker'\")\n    k = self.table.shape[0]\n    upp_idx = np.triu_indices(k, 1)\n    tril = self.table.T[upp_idx]\n    triu = self.table[upp_idx]\n    statistic = ((tril - triu) ** 2 / (tril + triu + 1e-20)).sum()\n    df = k * (k - 1) / 2.0\n    pvalue = stats.chi2.sf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    b.df = df\n    return b",
            "def symmetry(self, method='bowker'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Test for symmetry of a joint distribution.\\n\\n        This procedure tests the null hypothesis that the joint\\n        distribution is symmetric around the main diagonal, that is\\n\\n        .. math::\\n\\n        p_{i, j} = p_{j, i}  for all i, j\\n\\n        Returns\\n        -------\\n        Bunch\\n            A bunch with attributes\\n\\n            * statistic : float\\n                chisquare test statistic\\n            * p-value : float\\n                p-value of the test statistic based on chisquare distribution\\n            * df : int\\n                degrees of freedom of the chisquare distribution\\n\\n        Notes\\n        -----\\n        The implementation is based on the SAS documentation. R includes\\n        it in `mcnemar.test` if the table is not 2 by 2.  However a more\\n        direct generalization of the McNemar test to larger tables is\\n        provided by the homogeneity test (TableSymmetry.homogeneity).\\n\\n        The p-value is based on the chi-square distribution which requires\\n        that the sample size is not very small to be a good approximation\\n        of the true distribution. For 2x2 contingency tables the exact\\n        distribution can be obtained with `mcnemar`\\n\\n        See Also\\n        --------\\n        mcnemar\\n        homogeneity\\n        '\n    if method.lower() != 'bowker':\n        raise ValueError(\"method for symmetry testing must be 'bowker'\")\n    k = self.table.shape[0]\n    upp_idx = np.triu_indices(k, 1)\n    tril = self.table.T[upp_idx]\n    triu = self.table[upp_idx]\n    statistic = ((tril - triu) ** 2 / (tril + triu + 1e-20)).sum()\n    df = k * (k - 1) / 2.0\n    pvalue = stats.chi2.sf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    b.df = df\n    return b",
            "def symmetry(self, method='bowker'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Test for symmetry of a joint distribution.\\n\\n        This procedure tests the null hypothesis that the joint\\n        distribution is symmetric around the main diagonal, that is\\n\\n        .. math::\\n\\n        p_{i, j} = p_{j, i}  for all i, j\\n\\n        Returns\\n        -------\\n        Bunch\\n            A bunch with attributes\\n\\n            * statistic : float\\n                chisquare test statistic\\n            * p-value : float\\n                p-value of the test statistic based on chisquare distribution\\n            * df : int\\n                degrees of freedom of the chisquare distribution\\n\\n        Notes\\n        -----\\n        The implementation is based on the SAS documentation. R includes\\n        it in `mcnemar.test` if the table is not 2 by 2.  However a more\\n        direct generalization of the McNemar test to larger tables is\\n        provided by the homogeneity test (TableSymmetry.homogeneity).\\n\\n        The p-value is based on the chi-square distribution which requires\\n        that the sample size is not very small to be a good approximation\\n        of the true distribution. For 2x2 contingency tables the exact\\n        distribution can be obtained with `mcnemar`\\n\\n        See Also\\n        --------\\n        mcnemar\\n        homogeneity\\n        '\n    if method.lower() != 'bowker':\n        raise ValueError(\"method for symmetry testing must be 'bowker'\")\n    k = self.table.shape[0]\n    upp_idx = np.triu_indices(k, 1)\n    tril = self.table.T[upp_idx]\n    triu = self.table[upp_idx]\n    statistic = ((tril - triu) ** 2 / (tril + triu + 1e-20)).sum()\n    df = k * (k - 1) / 2.0\n    pvalue = stats.chi2.sf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    b.df = df\n    return b"
        ]
    },
    {
        "func_name": "homogeneity",
        "original": "def homogeneity(self, method='stuart_maxwell'):\n    \"\"\"\n        Compare row and column marginal distributions.\n\n        Parameters\n        ----------\n        method : str\n            Either 'stuart_maxwell' or 'bhapkar', leading to two different\n            estimates of the covariance matrix for the estimated\n            difference between the row margins and the column margins.\n\n        Returns\n        -------\n        Bunch\n            A bunch with attributes:\n\n            * statistic : float\n                The chi^2 test statistic\n            * pvalue : float\n                The p-value of the test statistic\n            * df : int\n                The degrees of freedom of the reference distribution\n\n        Notes\n        -----\n        For a 2x2 table this is equivalent to McNemar's test.  More\n        generally the procedure tests the null hypothesis that the\n        marginal distribution of the row factor is equal to the\n        marginal distribution of the column factor.  For this to be\n        meaningful, the two factors must have the same sample space\n        (i.e. the same categories).\n        \"\"\"\n    if self.table.shape[0] < 1:\n        raise ValueError('table is empty')\n    elif self.table.shape[0] == 1:\n        b = _Bunch()\n        b.statistic = 0\n        b.pvalue = 1\n        b.df = 0\n        return b\n    method = method.lower()\n    if method not in ['bhapkar', 'stuart_maxwell']:\n        raise ValueError(\"method '%s' for homogeneity not known\" % method)\n    n_obs = self.table.sum()\n    pr = self.table.astype(np.float64) / n_obs\n    row = pr.sum(1)[0:-1]\n    col = pr.sum(0)[0:-1]\n    pr = pr[0:-1, 0:-1]\n    d = col - row\n    df = pr.shape[0]\n    if method == 'bhapkar':\n        vmat = -(pr + pr.T) - np.outer(d, d)\n        dv = col + row - 2 * np.diag(pr) - d ** 2\n        np.fill_diagonal(vmat, dv)\n    elif method == 'stuart_maxwell':\n        vmat = -(pr + pr.T)\n        dv = row + col - 2 * np.diag(pr)\n        np.fill_diagonal(vmat, dv)\n    try:\n        statistic = n_obs * np.dot(d, np.linalg.solve(vmat, d))\n    except np.linalg.LinAlgError:\n        warnings.warn('Unable to invert covariance matrix', sm_exceptions.SingularMatrixWarning)\n        b = _Bunch()\n        b.statistic = np.nan\n        b.pvalue = np.nan\n        b.df = df\n        return b\n    pvalue = 1 - stats.chi2.cdf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    b.df = df\n    return b",
        "mutated": [
            "def homogeneity(self, method='stuart_maxwell'):\n    if False:\n        i = 10\n    \"\\n        Compare row and column marginal distributions.\\n\\n        Parameters\\n        ----------\\n        method : str\\n            Either 'stuart_maxwell' or 'bhapkar', leading to two different\\n            estimates of the covariance matrix for the estimated\\n            difference between the row margins and the column margins.\\n\\n        Returns\\n        -------\\n        Bunch\\n            A bunch with attributes:\\n\\n            * statistic : float\\n                The chi^2 test statistic\\n            * pvalue : float\\n                The p-value of the test statistic\\n            * df : int\\n                The degrees of freedom of the reference distribution\\n\\n        Notes\\n        -----\\n        For a 2x2 table this is equivalent to McNemar's test.  More\\n        generally the procedure tests the null hypothesis that the\\n        marginal distribution of the row factor is equal to the\\n        marginal distribution of the column factor.  For this to be\\n        meaningful, the two factors must have the same sample space\\n        (i.e. the same categories).\\n        \"\n    if self.table.shape[0] < 1:\n        raise ValueError('table is empty')\n    elif self.table.shape[0] == 1:\n        b = _Bunch()\n        b.statistic = 0\n        b.pvalue = 1\n        b.df = 0\n        return b\n    method = method.lower()\n    if method not in ['bhapkar', 'stuart_maxwell']:\n        raise ValueError(\"method '%s' for homogeneity not known\" % method)\n    n_obs = self.table.sum()\n    pr = self.table.astype(np.float64) / n_obs\n    row = pr.sum(1)[0:-1]\n    col = pr.sum(0)[0:-1]\n    pr = pr[0:-1, 0:-1]\n    d = col - row\n    df = pr.shape[0]\n    if method == 'bhapkar':\n        vmat = -(pr + pr.T) - np.outer(d, d)\n        dv = col + row - 2 * np.diag(pr) - d ** 2\n        np.fill_diagonal(vmat, dv)\n    elif method == 'stuart_maxwell':\n        vmat = -(pr + pr.T)\n        dv = row + col - 2 * np.diag(pr)\n        np.fill_diagonal(vmat, dv)\n    try:\n        statistic = n_obs * np.dot(d, np.linalg.solve(vmat, d))\n    except np.linalg.LinAlgError:\n        warnings.warn('Unable to invert covariance matrix', sm_exceptions.SingularMatrixWarning)\n        b = _Bunch()\n        b.statistic = np.nan\n        b.pvalue = np.nan\n        b.df = df\n        return b\n    pvalue = 1 - stats.chi2.cdf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    b.df = df\n    return b",
            "def homogeneity(self, method='stuart_maxwell'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Compare row and column marginal distributions.\\n\\n        Parameters\\n        ----------\\n        method : str\\n            Either 'stuart_maxwell' or 'bhapkar', leading to two different\\n            estimates of the covariance matrix for the estimated\\n            difference between the row margins and the column margins.\\n\\n        Returns\\n        -------\\n        Bunch\\n            A bunch with attributes:\\n\\n            * statistic : float\\n                The chi^2 test statistic\\n            * pvalue : float\\n                The p-value of the test statistic\\n            * df : int\\n                The degrees of freedom of the reference distribution\\n\\n        Notes\\n        -----\\n        For a 2x2 table this is equivalent to McNemar's test.  More\\n        generally the procedure tests the null hypothesis that the\\n        marginal distribution of the row factor is equal to the\\n        marginal distribution of the column factor.  For this to be\\n        meaningful, the two factors must have the same sample space\\n        (i.e. the same categories).\\n        \"\n    if self.table.shape[0] < 1:\n        raise ValueError('table is empty')\n    elif self.table.shape[0] == 1:\n        b = _Bunch()\n        b.statistic = 0\n        b.pvalue = 1\n        b.df = 0\n        return b\n    method = method.lower()\n    if method not in ['bhapkar', 'stuart_maxwell']:\n        raise ValueError(\"method '%s' for homogeneity not known\" % method)\n    n_obs = self.table.sum()\n    pr = self.table.astype(np.float64) / n_obs\n    row = pr.sum(1)[0:-1]\n    col = pr.sum(0)[0:-1]\n    pr = pr[0:-1, 0:-1]\n    d = col - row\n    df = pr.shape[0]\n    if method == 'bhapkar':\n        vmat = -(pr + pr.T) - np.outer(d, d)\n        dv = col + row - 2 * np.diag(pr) - d ** 2\n        np.fill_diagonal(vmat, dv)\n    elif method == 'stuart_maxwell':\n        vmat = -(pr + pr.T)\n        dv = row + col - 2 * np.diag(pr)\n        np.fill_diagonal(vmat, dv)\n    try:\n        statistic = n_obs * np.dot(d, np.linalg.solve(vmat, d))\n    except np.linalg.LinAlgError:\n        warnings.warn('Unable to invert covariance matrix', sm_exceptions.SingularMatrixWarning)\n        b = _Bunch()\n        b.statistic = np.nan\n        b.pvalue = np.nan\n        b.df = df\n        return b\n    pvalue = 1 - stats.chi2.cdf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    b.df = df\n    return b",
            "def homogeneity(self, method='stuart_maxwell'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Compare row and column marginal distributions.\\n\\n        Parameters\\n        ----------\\n        method : str\\n            Either 'stuart_maxwell' or 'bhapkar', leading to two different\\n            estimates of the covariance matrix for the estimated\\n            difference between the row margins and the column margins.\\n\\n        Returns\\n        -------\\n        Bunch\\n            A bunch with attributes:\\n\\n            * statistic : float\\n                The chi^2 test statistic\\n            * pvalue : float\\n                The p-value of the test statistic\\n            * df : int\\n                The degrees of freedom of the reference distribution\\n\\n        Notes\\n        -----\\n        For a 2x2 table this is equivalent to McNemar's test.  More\\n        generally the procedure tests the null hypothesis that the\\n        marginal distribution of the row factor is equal to the\\n        marginal distribution of the column factor.  For this to be\\n        meaningful, the two factors must have the same sample space\\n        (i.e. the same categories).\\n        \"\n    if self.table.shape[0] < 1:\n        raise ValueError('table is empty')\n    elif self.table.shape[0] == 1:\n        b = _Bunch()\n        b.statistic = 0\n        b.pvalue = 1\n        b.df = 0\n        return b\n    method = method.lower()\n    if method not in ['bhapkar', 'stuart_maxwell']:\n        raise ValueError(\"method '%s' for homogeneity not known\" % method)\n    n_obs = self.table.sum()\n    pr = self.table.astype(np.float64) / n_obs\n    row = pr.sum(1)[0:-1]\n    col = pr.sum(0)[0:-1]\n    pr = pr[0:-1, 0:-1]\n    d = col - row\n    df = pr.shape[0]\n    if method == 'bhapkar':\n        vmat = -(pr + pr.T) - np.outer(d, d)\n        dv = col + row - 2 * np.diag(pr) - d ** 2\n        np.fill_diagonal(vmat, dv)\n    elif method == 'stuart_maxwell':\n        vmat = -(pr + pr.T)\n        dv = row + col - 2 * np.diag(pr)\n        np.fill_diagonal(vmat, dv)\n    try:\n        statistic = n_obs * np.dot(d, np.linalg.solve(vmat, d))\n    except np.linalg.LinAlgError:\n        warnings.warn('Unable to invert covariance matrix', sm_exceptions.SingularMatrixWarning)\n        b = _Bunch()\n        b.statistic = np.nan\n        b.pvalue = np.nan\n        b.df = df\n        return b\n    pvalue = 1 - stats.chi2.cdf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    b.df = df\n    return b",
            "def homogeneity(self, method='stuart_maxwell'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Compare row and column marginal distributions.\\n\\n        Parameters\\n        ----------\\n        method : str\\n            Either 'stuart_maxwell' or 'bhapkar', leading to two different\\n            estimates of the covariance matrix for the estimated\\n            difference between the row margins and the column margins.\\n\\n        Returns\\n        -------\\n        Bunch\\n            A bunch with attributes:\\n\\n            * statistic : float\\n                The chi^2 test statistic\\n            * pvalue : float\\n                The p-value of the test statistic\\n            * df : int\\n                The degrees of freedom of the reference distribution\\n\\n        Notes\\n        -----\\n        For a 2x2 table this is equivalent to McNemar's test.  More\\n        generally the procedure tests the null hypothesis that the\\n        marginal distribution of the row factor is equal to the\\n        marginal distribution of the column factor.  For this to be\\n        meaningful, the two factors must have the same sample space\\n        (i.e. the same categories).\\n        \"\n    if self.table.shape[0] < 1:\n        raise ValueError('table is empty')\n    elif self.table.shape[0] == 1:\n        b = _Bunch()\n        b.statistic = 0\n        b.pvalue = 1\n        b.df = 0\n        return b\n    method = method.lower()\n    if method not in ['bhapkar', 'stuart_maxwell']:\n        raise ValueError(\"method '%s' for homogeneity not known\" % method)\n    n_obs = self.table.sum()\n    pr = self.table.astype(np.float64) / n_obs\n    row = pr.sum(1)[0:-1]\n    col = pr.sum(0)[0:-1]\n    pr = pr[0:-1, 0:-1]\n    d = col - row\n    df = pr.shape[0]\n    if method == 'bhapkar':\n        vmat = -(pr + pr.T) - np.outer(d, d)\n        dv = col + row - 2 * np.diag(pr) - d ** 2\n        np.fill_diagonal(vmat, dv)\n    elif method == 'stuart_maxwell':\n        vmat = -(pr + pr.T)\n        dv = row + col - 2 * np.diag(pr)\n        np.fill_diagonal(vmat, dv)\n    try:\n        statistic = n_obs * np.dot(d, np.linalg.solve(vmat, d))\n    except np.linalg.LinAlgError:\n        warnings.warn('Unable to invert covariance matrix', sm_exceptions.SingularMatrixWarning)\n        b = _Bunch()\n        b.statistic = np.nan\n        b.pvalue = np.nan\n        b.df = df\n        return b\n    pvalue = 1 - stats.chi2.cdf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    b.df = df\n    return b",
            "def homogeneity(self, method='stuart_maxwell'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Compare row and column marginal distributions.\\n\\n        Parameters\\n        ----------\\n        method : str\\n            Either 'stuart_maxwell' or 'bhapkar', leading to two different\\n            estimates of the covariance matrix for the estimated\\n            difference between the row margins and the column margins.\\n\\n        Returns\\n        -------\\n        Bunch\\n            A bunch with attributes:\\n\\n            * statistic : float\\n                The chi^2 test statistic\\n            * pvalue : float\\n                The p-value of the test statistic\\n            * df : int\\n                The degrees of freedom of the reference distribution\\n\\n        Notes\\n        -----\\n        For a 2x2 table this is equivalent to McNemar's test.  More\\n        generally the procedure tests the null hypothesis that the\\n        marginal distribution of the row factor is equal to the\\n        marginal distribution of the column factor.  For this to be\\n        meaningful, the two factors must have the same sample space\\n        (i.e. the same categories).\\n        \"\n    if self.table.shape[0] < 1:\n        raise ValueError('table is empty')\n    elif self.table.shape[0] == 1:\n        b = _Bunch()\n        b.statistic = 0\n        b.pvalue = 1\n        b.df = 0\n        return b\n    method = method.lower()\n    if method not in ['bhapkar', 'stuart_maxwell']:\n        raise ValueError(\"method '%s' for homogeneity not known\" % method)\n    n_obs = self.table.sum()\n    pr = self.table.astype(np.float64) / n_obs\n    row = pr.sum(1)[0:-1]\n    col = pr.sum(0)[0:-1]\n    pr = pr[0:-1, 0:-1]\n    d = col - row\n    df = pr.shape[0]\n    if method == 'bhapkar':\n        vmat = -(pr + pr.T) - np.outer(d, d)\n        dv = col + row - 2 * np.diag(pr) - d ** 2\n        np.fill_diagonal(vmat, dv)\n    elif method == 'stuart_maxwell':\n        vmat = -(pr + pr.T)\n        dv = row + col - 2 * np.diag(pr)\n        np.fill_diagonal(vmat, dv)\n    try:\n        statistic = n_obs * np.dot(d, np.linalg.solve(vmat, d))\n    except np.linalg.LinAlgError:\n        warnings.warn('Unable to invert covariance matrix', sm_exceptions.SingularMatrixWarning)\n        b = _Bunch()\n        b.statistic = np.nan\n        b.pvalue = np.nan\n        b.df = df\n        return b\n    pvalue = 1 - stats.chi2.cdf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    b.df = df\n    return b"
        ]
    },
    {
        "func_name": "summary",
        "original": "def summary(self, alpha=0.05, float_format='%.3f'):\n    \"\"\"\n        Produce a summary of the analysis.\n\n        Parameters\n        ----------\n        alpha : float\n            `1 - alpha` is the nominal coverage probability of the interval.\n        float_format : str\n            Used to format numeric values in the table.\n        method : str\n            The method for producing the confidence interval.  Currently\n            must be 'normal' which uses the normal approximation.\n        \"\"\"\n    fmt = float_format\n    headers = ['Statistic', 'P-value', 'DF']\n    stubs = ['Symmetry', 'Homogeneity']\n    sy = self.symmetry()\n    hm = self.homogeneity()\n    data = [[fmt % sy.statistic, fmt % sy.pvalue, '%d' % sy.df], [fmt % hm.statistic, fmt % hm.pvalue, '%d' % hm.df]]\n    tab = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    return tab",
        "mutated": [
            "def summary(self, alpha=0.05, float_format='%.3f'):\n    if False:\n        i = 10\n    \"\\n        Produce a summary of the analysis.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the interval.\\n        float_format : str\\n            Used to format numeric values in the table.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    fmt = float_format\n    headers = ['Statistic', 'P-value', 'DF']\n    stubs = ['Symmetry', 'Homogeneity']\n    sy = self.symmetry()\n    hm = self.homogeneity()\n    data = [[fmt % sy.statistic, fmt % sy.pvalue, '%d' % sy.df], [fmt % hm.statistic, fmt % hm.pvalue, '%d' % hm.df]]\n    tab = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    return tab",
            "def summary(self, alpha=0.05, float_format='%.3f'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Produce a summary of the analysis.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the interval.\\n        float_format : str\\n            Used to format numeric values in the table.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    fmt = float_format\n    headers = ['Statistic', 'P-value', 'DF']\n    stubs = ['Symmetry', 'Homogeneity']\n    sy = self.symmetry()\n    hm = self.homogeneity()\n    data = [[fmt % sy.statistic, fmt % sy.pvalue, '%d' % sy.df], [fmt % hm.statistic, fmt % hm.pvalue, '%d' % hm.df]]\n    tab = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    return tab",
            "def summary(self, alpha=0.05, float_format='%.3f'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Produce a summary of the analysis.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the interval.\\n        float_format : str\\n            Used to format numeric values in the table.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    fmt = float_format\n    headers = ['Statistic', 'P-value', 'DF']\n    stubs = ['Symmetry', 'Homogeneity']\n    sy = self.symmetry()\n    hm = self.homogeneity()\n    data = [[fmt % sy.statistic, fmt % sy.pvalue, '%d' % sy.df], [fmt % hm.statistic, fmt % hm.pvalue, '%d' % hm.df]]\n    tab = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    return tab",
            "def summary(self, alpha=0.05, float_format='%.3f'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Produce a summary of the analysis.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the interval.\\n        float_format : str\\n            Used to format numeric values in the table.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    fmt = float_format\n    headers = ['Statistic', 'P-value', 'DF']\n    stubs = ['Symmetry', 'Homogeneity']\n    sy = self.symmetry()\n    hm = self.homogeneity()\n    data = [[fmt % sy.statistic, fmt % sy.pvalue, '%d' % sy.df], [fmt % hm.statistic, fmt % hm.pvalue, '%d' % hm.df]]\n    tab = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    return tab",
            "def summary(self, alpha=0.05, float_format='%.3f'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Produce a summary of the analysis.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the interval.\\n        float_format : str\\n            Used to format numeric values in the table.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    fmt = float_format\n    headers = ['Statistic', 'P-value', 'DF']\n    stubs = ['Symmetry', 'Homogeneity']\n    sy = self.symmetry()\n    hm = self.homogeneity()\n    data = [[fmt % sy.statistic, fmt % sy.pvalue, '%d' % sy.df], [fmt % hm.statistic, fmt % hm.pvalue, '%d' % hm.df]]\n    tab = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    return tab"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, table, shift_zeros=True):\n    if type(table) is list:\n        table = np.asarray(table)\n    if table.ndim != 2 or table.shape[0] != 2 or table.shape[1] != 2:\n        raise ValueError('Table2x2 takes a 2x2 table as input.')\n    super(Table2x2, self).__init__(table, shift_zeros)",
        "mutated": [
            "def __init__(self, table, shift_zeros=True):\n    if False:\n        i = 10\n    if type(table) is list:\n        table = np.asarray(table)\n    if table.ndim != 2 or table.shape[0] != 2 or table.shape[1] != 2:\n        raise ValueError('Table2x2 takes a 2x2 table as input.')\n    super(Table2x2, self).__init__(table, shift_zeros)",
            "def __init__(self, table, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if type(table) is list:\n        table = np.asarray(table)\n    if table.ndim != 2 or table.shape[0] != 2 or table.shape[1] != 2:\n        raise ValueError('Table2x2 takes a 2x2 table as input.')\n    super(Table2x2, self).__init__(table, shift_zeros)",
            "def __init__(self, table, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if type(table) is list:\n        table = np.asarray(table)\n    if table.ndim != 2 or table.shape[0] != 2 or table.shape[1] != 2:\n        raise ValueError('Table2x2 takes a 2x2 table as input.')\n    super(Table2x2, self).__init__(table, shift_zeros)",
            "def __init__(self, table, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if type(table) is list:\n        table = np.asarray(table)\n    if table.ndim != 2 or table.shape[0] != 2 or table.shape[1] != 2:\n        raise ValueError('Table2x2 takes a 2x2 table as input.')\n    super(Table2x2, self).__init__(table, shift_zeros)",
            "def __init__(self, table, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if type(table) is list:\n        table = np.asarray(table)\n    if table.ndim != 2 or table.shape[0] != 2 or table.shape[1] != 2:\n        raise ValueError('Table2x2 takes a 2x2 table as input.')\n    super(Table2x2, self).__init__(table, shift_zeros)"
        ]
    },
    {
        "func_name": "from_data",
        "original": "@classmethod\ndef from_data(cls, data, shift_zeros=True):\n    \"\"\"\n        Construct a Table object from data.\n\n        Parameters\n        ----------\n        data : array_like\n            The raw data, the first column defines the rows and the\n            second column defines the columns.\n        shift_zeros : bool\n            If True, and if there are any zeros in the contingency\n            table, add 0.5 to all four cells of the table.\n        \"\"\"\n    if isinstance(data, pd.DataFrame):\n        table = pd.crosstab(data.iloc[:, 0], data.iloc[:, 1])\n    else:\n        table = pd.crosstab(data[:, 0], data[:, 1])\n    return cls(table, shift_zeros)",
        "mutated": [
            "@classmethod\ndef from_data(cls, data, shift_zeros=True):\n    if False:\n        i = 10\n    '\\n        Construct a Table object from data.\\n\\n        Parameters\\n        ----------\\n        data : array_like\\n            The raw data, the first column defines the rows and the\\n            second column defines the columns.\\n        shift_zeros : bool\\n            If True, and if there are any zeros in the contingency\\n            table, add 0.5 to all four cells of the table.\\n        '\n    if isinstance(data, pd.DataFrame):\n        table = pd.crosstab(data.iloc[:, 0], data.iloc[:, 1])\n    else:\n        table = pd.crosstab(data[:, 0], data[:, 1])\n    return cls(table, shift_zeros)",
            "@classmethod\ndef from_data(cls, data, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Construct a Table object from data.\\n\\n        Parameters\\n        ----------\\n        data : array_like\\n            The raw data, the first column defines the rows and the\\n            second column defines the columns.\\n        shift_zeros : bool\\n            If True, and if there are any zeros in the contingency\\n            table, add 0.5 to all four cells of the table.\\n        '\n    if isinstance(data, pd.DataFrame):\n        table = pd.crosstab(data.iloc[:, 0], data.iloc[:, 1])\n    else:\n        table = pd.crosstab(data[:, 0], data[:, 1])\n    return cls(table, shift_zeros)",
            "@classmethod\ndef from_data(cls, data, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Construct a Table object from data.\\n\\n        Parameters\\n        ----------\\n        data : array_like\\n            The raw data, the first column defines the rows and the\\n            second column defines the columns.\\n        shift_zeros : bool\\n            If True, and if there are any zeros in the contingency\\n            table, add 0.5 to all four cells of the table.\\n        '\n    if isinstance(data, pd.DataFrame):\n        table = pd.crosstab(data.iloc[:, 0], data.iloc[:, 1])\n    else:\n        table = pd.crosstab(data[:, 0], data[:, 1])\n    return cls(table, shift_zeros)",
            "@classmethod\ndef from_data(cls, data, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Construct a Table object from data.\\n\\n        Parameters\\n        ----------\\n        data : array_like\\n            The raw data, the first column defines the rows and the\\n            second column defines the columns.\\n        shift_zeros : bool\\n            If True, and if there are any zeros in the contingency\\n            table, add 0.5 to all four cells of the table.\\n        '\n    if isinstance(data, pd.DataFrame):\n        table = pd.crosstab(data.iloc[:, 0], data.iloc[:, 1])\n    else:\n        table = pd.crosstab(data[:, 0], data[:, 1])\n    return cls(table, shift_zeros)",
            "@classmethod\ndef from_data(cls, data, shift_zeros=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Construct a Table object from data.\\n\\n        Parameters\\n        ----------\\n        data : array_like\\n            The raw data, the first column defines the rows and the\\n            second column defines the columns.\\n        shift_zeros : bool\\n            If True, and if there are any zeros in the contingency\\n            table, add 0.5 to all four cells of the table.\\n        '\n    if isinstance(data, pd.DataFrame):\n        table = pd.crosstab(data.iloc[:, 0], data.iloc[:, 1])\n    else:\n        table = pd.crosstab(data[:, 0], data[:, 1])\n    return cls(table, shift_zeros)"
        ]
    },
    {
        "func_name": "log_oddsratio",
        "original": "@cache_readonly\ndef log_oddsratio(self):\n    \"\"\"\n        Returns the log odds ratio for a 2x2 table.\n        \"\"\"\n    f = self.table.flatten()\n    return np.dot(np.log(f), np.r_[1, -1, -1, 1])",
        "mutated": [
            "@cache_readonly\ndef log_oddsratio(self):\n    if False:\n        i = 10\n    '\\n        Returns the log odds ratio for a 2x2 table.\\n        '\n    f = self.table.flatten()\n    return np.dot(np.log(f), np.r_[1, -1, -1, 1])",
            "@cache_readonly\ndef log_oddsratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the log odds ratio for a 2x2 table.\\n        '\n    f = self.table.flatten()\n    return np.dot(np.log(f), np.r_[1, -1, -1, 1])",
            "@cache_readonly\ndef log_oddsratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the log odds ratio for a 2x2 table.\\n        '\n    f = self.table.flatten()\n    return np.dot(np.log(f), np.r_[1, -1, -1, 1])",
            "@cache_readonly\ndef log_oddsratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the log odds ratio for a 2x2 table.\\n        '\n    f = self.table.flatten()\n    return np.dot(np.log(f), np.r_[1, -1, -1, 1])",
            "@cache_readonly\ndef log_oddsratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the log odds ratio for a 2x2 table.\\n        '\n    f = self.table.flatten()\n    return np.dot(np.log(f), np.r_[1, -1, -1, 1])"
        ]
    },
    {
        "func_name": "oddsratio",
        "original": "@cache_readonly\ndef oddsratio(self):\n    \"\"\"\n        Returns the odds ratio for a 2x2 table.\n        \"\"\"\n    return self.table[0, 0] * self.table[1, 1] / (self.table[0, 1] * self.table[1, 0])",
        "mutated": [
            "@cache_readonly\ndef oddsratio(self):\n    if False:\n        i = 10\n    '\\n        Returns the odds ratio for a 2x2 table.\\n        '\n    return self.table[0, 0] * self.table[1, 1] / (self.table[0, 1] * self.table[1, 0])",
            "@cache_readonly\ndef oddsratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the odds ratio for a 2x2 table.\\n        '\n    return self.table[0, 0] * self.table[1, 1] / (self.table[0, 1] * self.table[1, 0])",
            "@cache_readonly\ndef oddsratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the odds ratio for a 2x2 table.\\n        '\n    return self.table[0, 0] * self.table[1, 1] / (self.table[0, 1] * self.table[1, 0])",
            "@cache_readonly\ndef oddsratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the odds ratio for a 2x2 table.\\n        '\n    return self.table[0, 0] * self.table[1, 1] / (self.table[0, 1] * self.table[1, 0])",
            "@cache_readonly\ndef oddsratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the odds ratio for a 2x2 table.\\n        '\n    return self.table[0, 0] * self.table[1, 1] / (self.table[0, 1] * self.table[1, 0])"
        ]
    },
    {
        "func_name": "log_oddsratio_se",
        "original": "@cache_readonly\ndef log_oddsratio_se(self):\n    \"\"\"\n        Returns the standard error for the log odds ratio.\n        \"\"\"\n    return np.sqrt(np.sum(1 / self.table))",
        "mutated": [
            "@cache_readonly\ndef log_oddsratio_se(self):\n    if False:\n        i = 10\n    '\\n        Returns the standard error for the log odds ratio.\\n        '\n    return np.sqrt(np.sum(1 / self.table))",
            "@cache_readonly\ndef log_oddsratio_se(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the standard error for the log odds ratio.\\n        '\n    return np.sqrt(np.sum(1 / self.table))",
            "@cache_readonly\ndef log_oddsratio_se(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the standard error for the log odds ratio.\\n        '\n    return np.sqrt(np.sum(1 / self.table))",
            "@cache_readonly\ndef log_oddsratio_se(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the standard error for the log odds ratio.\\n        '\n    return np.sqrt(np.sum(1 / self.table))",
            "@cache_readonly\ndef log_oddsratio_se(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the standard error for the log odds ratio.\\n        '\n    return np.sqrt(np.sum(1 / self.table))"
        ]
    },
    {
        "func_name": "oddsratio_pvalue",
        "original": "def oddsratio_pvalue(self, null=1):\n    \"\"\"\n        P-value for a hypothesis test about the odds ratio.\n\n        Parameters\n        ----------\n        null : float\n            The null value of the odds ratio.\n        \"\"\"\n    return self.log_oddsratio_pvalue(np.log(null))",
        "mutated": [
            "def oddsratio_pvalue(self, null=1):\n    if False:\n        i = 10\n    '\\n        P-value for a hypothesis test about the odds ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the odds ratio.\\n        '\n    return self.log_oddsratio_pvalue(np.log(null))",
            "def oddsratio_pvalue(self, null=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        P-value for a hypothesis test about the odds ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the odds ratio.\\n        '\n    return self.log_oddsratio_pvalue(np.log(null))",
            "def oddsratio_pvalue(self, null=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        P-value for a hypothesis test about the odds ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the odds ratio.\\n        '\n    return self.log_oddsratio_pvalue(np.log(null))",
            "def oddsratio_pvalue(self, null=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        P-value for a hypothesis test about the odds ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the odds ratio.\\n        '\n    return self.log_oddsratio_pvalue(np.log(null))",
            "def oddsratio_pvalue(self, null=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        P-value for a hypothesis test about the odds ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the odds ratio.\\n        '\n    return self.log_oddsratio_pvalue(np.log(null))"
        ]
    },
    {
        "func_name": "log_oddsratio_pvalue",
        "original": "def log_oddsratio_pvalue(self, null=0):\n    \"\"\"\n        P-value for a hypothesis test about the log odds ratio.\n\n        Parameters\n        ----------\n        null : float\n            The null value of the log odds ratio.\n        \"\"\"\n    zscore = (self.log_oddsratio - null) / self.log_oddsratio_se\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    return pvalue",
        "mutated": [
            "def log_oddsratio_pvalue(self, null=0):\n    if False:\n        i = 10\n    '\\n        P-value for a hypothesis test about the log odds ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the log odds ratio.\\n        '\n    zscore = (self.log_oddsratio - null) / self.log_oddsratio_se\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    return pvalue",
            "def log_oddsratio_pvalue(self, null=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        P-value for a hypothesis test about the log odds ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the log odds ratio.\\n        '\n    zscore = (self.log_oddsratio - null) / self.log_oddsratio_se\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    return pvalue",
            "def log_oddsratio_pvalue(self, null=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        P-value for a hypothesis test about the log odds ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the log odds ratio.\\n        '\n    zscore = (self.log_oddsratio - null) / self.log_oddsratio_se\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    return pvalue",
            "def log_oddsratio_pvalue(self, null=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        P-value for a hypothesis test about the log odds ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the log odds ratio.\\n        '\n    zscore = (self.log_oddsratio - null) / self.log_oddsratio_se\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    return pvalue",
            "def log_oddsratio_pvalue(self, null=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        P-value for a hypothesis test about the log odds ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the log odds ratio.\\n        '\n    zscore = (self.log_oddsratio - null) / self.log_oddsratio_se\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    return pvalue"
        ]
    },
    {
        "func_name": "log_oddsratio_confint",
        "original": "def log_oddsratio_confint(self, alpha=0.05, method='normal'):\n    \"\"\"\n        A confidence level for the log odds ratio.\n\n        Parameters\n        ----------\n        alpha : float\n            `1 - alpha` is the nominal coverage probability of the\n            confidence interval.\n        method : str\n            The method for producing the confidence interval.  Currently\n            must be 'normal' which uses the normal approximation.\n        \"\"\"\n    f = -stats.norm.ppf(alpha / 2)\n    lor = self.log_oddsratio\n    se = self.log_oddsratio_se\n    lcb = lor - f * se\n    ucb = lor + f * se\n    return (lcb, ucb)",
        "mutated": [
            "def log_oddsratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n    \"\\n        A confidence level for the log odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    f = -stats.norm.ppf(alpha / 2)\n    lor = self.log_oddsratio\n    se = self.log_oddsratio_se\n    lcb = lor - f * se\n    ucb = lor + f * se\n    return (lcb, ucb)",
            "def log_oddsratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        A confidence level for the log odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    f = -stats.norm.ppf(alpha / 2)\n    lor = self.log_oddsratio\n    se = self.log_oddsratio_se\n    lcb = lor - f * se\n    ucb = lor + f * se\n    return (lcb, ucb)",
            "def log_oddsratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        A confidence level for the log odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    f = -stats.norm.ppf(alpha / 2)\n    lor = self.log_oddsratio\n    se = self.log_oddsratio_se\n    lcb = lor - f * se\n    ucb = lor + f * se\n    return (lcb, ucb)",
            "def log_oddsratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        A confidence level for the log odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    f = -stats.norm.ppf(alpha / 2)\n    lor = self.log_oddsratio\n    se = self.log_oddsratio_se\n    lcb = lor - f * se\n    ucb = lor + f * se\n    return (lcb, ucb)",
            "def log_oddsratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        A confidence level for the log odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    f = -stats.norm.ppf(alpha / 2)\n    lor = self.log_oddsratio\n    se = self.log_oddsratio_se\n    lcb = lor - f * se\n    ucb = lor + f * se\n    return (lcb, ucb)"
        ]
    },
    {
        "func_name": "oddsratio_confint",
        "original": "def oddsratio_confint(self, alpha=0.05, method='normal'):\n    \"\"\"\n        A confidence interval for the odds ratio.\n\n        Parameters\n        ----------\n        alpha : float\n            `1 - alpha` is the nominal coverage probability of the\n            confidence interval.\n        method : str\n            The method for producing the confidence interval.  Currently\n            must be 'normal' which uses the normal approximation.\n        \"\"\"\n    (lcb, ucb) = self.log_oddsratio_confint(alpha, method=method)\n    return (np.exp(lcb), np.exp(ucb))",
        "mutated": [
            "def oddsratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n    \"\\n        A confidence interval for the odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    (lcb, ucb) = self.log_oddsratio_confint(alpha, method=method)\n    return (np.exp(lcb), np.exp(ucb))",
            "def oddsratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        A confidence interval for the odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    (lcb, ucb) = self.log_oddsratio_confint(alpha, method=method)\n    return (np.exp(lcb), np.exp(ucb))",
            "def oddsratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        A confidence interval for the odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    (lcb, ucb) = self.log_oddsratio_confint(alpha, method=method)\n    return (np.exp(lcb), np.exp(ucb))",
            "def oddsratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        A confidence interval for the odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    (lcb, ucb) = self.log_oddsratio_confint(alpha, method=method)\n    return (np.exp(lcb), np.exp(ucb))",
            "def oddsratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        A confidence interval for the odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    (lcb, ucb) = self.log_oddsratio_confint(alpha, method=method)\n    return (np.exp(lcb), np.exp(ucb))"
        ]
    },
    {
        "func_name": "riskratio",
        "original": "@cache_readonly\ndef riskratio(self):\n    \"\"\"\n        Returns the risk ratio for a 2x2 table.\n\n        The risk ratio is calculated with respect to the rows.\n        \"\"\"\n    p = self.table[:, 0] / self.table.sum(1)\n    return p[0] / p[1]",
        "mutated": [
            "@cache_readonly\ndef riskratio(self):\n    if False:\n        i = 10\n    '\\n        Returns the risk ratio for a 2x2 table.\\n\\n        The risk ratio is calculated with respect to the rows.\\n        '\n    p = self.table[:, 0] / self.table.sum(1)\n    return p[0] / p[1]",
            "@cache_readonly\ndef riskratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the risk ratio for a 2x2 table.\\n\\n        The risk ratio is calculated with respect to the rows.\\n        '\n    p = self.table[:, 0] / self.table.sum(1)\n    return p[0] / p[1]",
            "@cache_readonly\ndef riskratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the risk ratio for a 2x2 table.\\n\\n        The risk ratio is calculated with respect to the rows.\\n        '\n    p = self.table[:, 0] / self.table.sum(1)\n    return p[0] / p[1]",
            "@cache_readonly\ndef riskratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the risk ratio for a 2x2 table.\\n\\n        The risk ratio is calculated with respect to the rows.\\n        '\n    p = self.table[:, 0] / self.table.sum(1)\n    return p[0] / p[1]",
            "@cache_readonly\ndef riskratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the risk ratio for a 2x2 table.\\n\\n        The risk ratio is calculated with respect to the rows.\\n        '\n    p = self.table[:, 0] / self.table.sum(1)\n    return p[0] / p[1]"
        ]
    },
    {
        "func_name": "log_riskratio",
        "original": "@cache_readonly\ndef log_riskratio(self):\n    \"\"\"\n        Returns the log of the risk ratio.\n        \"\"\"\n    return np.log(self.riskratio)",
        "mutated": [
            "@cache_readonly\ndef log_riskratio(self):\n    if False:\n        i = 10\n    '\\n        Returns the log of the risk ratio.\\n        '\n    return np.log(self.riskratio)",
            "@cache_readonly\ndef log_riskratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the log of the risk ratio.\\n        '\n    return np.log(self.riskratio)",
            "@cache_readonly\ndef log_riskratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the log of the risk ratio.\\n        '\n    return np.log(self.riskratio)",
            "@cache_readonly\ndef log_riskratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the log of the risk ratio.\\n        '\n    return np.log(self.riskratio)",
            "@cache_readonly\ndef log_riskratio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the log of the risk ratio.\\n        '\n    return np.log(self.riskratio)"
        ]
    },
    {
        "func_name": "log_riskratio_se",
        "original": "@cache_readonly\ndef log_riskratio_se(self):\n    \"\"\"\n        Returns the standard error of the log of the risk ratio.\n        \"\"\"\n    n = self.table.sum(1)\n    p = self.table[:, 0] / n\n    va = np.sum((1 - p) / (n * p))\n    return np.sqrt(va)",
        "mutated": [
            "@cache_readonly\ndef log_riskratio_se(self):\n    if False:\n        i = 10\n    '\\n        Returns the standard error of the log of the risk ratio.\\n        '\n    n = self.table.sum(1)\n    p = self.table[:, 0] / n\n    va = np.sum((1 - p) / (n * p))\n    return np.sqrt(va)",
            "@cache_readonly\ndef log_riskratio_se(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the standard error of the log of the risk ratio.\\n        '\n    n = self.table.sum(1)\n    p = self.table[:, 0] / n\n    va = np.sum((1 - p) / (n * p))\n    return np.sqrt(va)",
            "@cache_readonly\ndef log_riskratio_se(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the standard error of the log of the risk ratio.\\n        '\n    n = self.table.sum(1)\n    p = self.table[:, 0] / n\n    va = np.sum((1 - p) / (n * p))\n    return np.sqrt(va)",
            "@cache_readonly\ndef log_riskratio_se(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the standard error of the log of the risk ratio.\\n        '\n    n = self.table.sum(1)\n    p = self.table[:, 0] / n\n    va = np.sum((1 - p) / (n * p))\n    return np.sqrt(va)",
            "@cache_readonly\ndef log_riskratio_se(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the standard error of the log of the risk ratio.\\n        '\n    n = self.table.sum(1)\n    p = self.table[:, 0] / n\n    va = np.sum((1 - p) / (n * p))\n    return np.sqrt(va)"
        ]
    },
    {
        "func_name": "riskratio_pvalue",
        "original": "def riskratio_pvalue(self, null=1):\n    \"\"\"\n        p-value for a hypothesis test about the risk ratio.\n\n        Parameters\n        ----------\n        null : float\n            The null value of the risk ratio.\n        \"\"\"\n    return self.log_riskratio_pvalue(np.log(null))",
        "mutated": [
            "def riskratio_pvalue(self, null=1):\n    if False:\n        i = 10\n    '\\n        p-value for a hypothesis test about the risk ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the risk ratio.\\n        '\n    return self.log_riskratio_pvalue(np.log(null))",
            "def riskratio_pvalue(self, null=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        p-value for a hypothesis test about the risk ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the risk ratio.\\n        '\n    return self.log_riskratio_pvalue(np.log(null))",
            "def riskratio_pvalue(self, null=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        p-value for a hypothesis test about the risk ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the risk ratio.\\n        '\n    return self.log_riskratio_pvalue(np.log(null))",
            "def riskratio_pvalue(self, null=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        p-value for a hypothesis test about the risk ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the risk ratio.\\n        '\n    return self.log_riskratio_pvalue(np.log(null))",
            "def riskratio_pvalue(self, null=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        p-value for a hypothesis test about the risk ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the risk ratio.\\n        '\n    return self.log_riskratio_pvalue(np.log(null))"
        ]
    },
    {
        "func_name": "log_riskratio_pvalue",
        "original": "def log_riskratio_pvalue(self, null=0):\n    \"\"\"\n        p-value for a hypothesis test about the log risk ratio.\n\n        Parameters\n        ----------\n        null : float\n            The null value of the log risk ratio.\n        \"\"\"\n    zscore = (self.log_riskratio - null) / self.log_riskratio_se\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    return pvalue",
        "mutated": [
            "def log_riskratio_pvalue(self, null=0):\n    if False:\n        i = 10\n    '\\n        p-value for a hypothesis test about the log risk ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the log risk ratio.\\n        '\n    zscore = (self.log_riskratio - null) / self.log_riskratio_se\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    return pvalue",
            "def log_riskratio_pvalue(self, null=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        p-value for a hypothesis test about the log risk ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the log risk ratio.\\n        '\n    zscore = (self.log_riskratio - null) / self.log_riskratio_se\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    return pvalue",
            "def log_riskratio_pvalue(self, null=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        p-value for a hypothesis test about the log risk ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the log risk ratio.\\n        '\n    zscore = (self.log_riskratio - null) / self.log_riskratio_se\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    return pvalue",
            "def log_riskratio_pvalue(self, null=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        p-value for a hypothesis test about the log risk ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the log risk ratio.\\n        '\n    zscore = (self.log_riskratio - null) / self.log_riskratio_se\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    return pvalue",
            "def log_riskratio_pvalue(self, null=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        p-value for a hypothesis test about the log risk ratio.\\n\\n        Parameters\\n        ----------\\n        null : float\\n            The null value of the log risk ratio.\\n        '\n    zscore = (self.log_riskratio - null) / self.log_riskratio_se\n    pvalue = 2 * stats.norm.cdf(-np.abs(zscore))\n    return pvalue"
        ]
    },
    {
        "func_name": "log_riskratio_confint",
        "original": "def log_riskratio_confint(self, alpha=0.05, method='normal'):\n    \"\"\"\n        A confidence interval for the log risk ratio.\n\n        Parameters\n        ----------\n        alpha : float\n            `1 - alpha` is the nominal coverage probability of the\n            confidence interval.\n        method : str\n            The method for producing the confidence interval.  Currently\n            must be 'normal' which uses the normal approximation.\n        \"\"\"\n    f = -stats.norm.ppf(alpha / 2)\n    lrr = self.log_riskratio\n    se = self.log_riskratio_se\n    lcb = lrr - f * se\n    ucb = lrr + f * se\n    return (lcb, ucb)",
        "mutated": [
            "def log_riskratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n    \"\\n        A confidence interval for the log risk ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    f = -stats.norm.ppf(alpha / 2)\n    lrr = self.log_riskratio\n    se = self.log_riskratio_se\n    lcb = lrr - f * se\n    ucb = lrr + f * se\n    return (lcb, ucb)",
            "def log_riskratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        A confidence interval for the log risk ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    f = -stats.norm.ppf(alpha / 2)\n    lrr = self.log_riskratio\n    se = self.log_riskratio_se\n    lcb = lrr - f * se\n    ucb = lrr + f * se\n    return (lcb, ucb)",
            "def log_riskratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        A confidence interval for the log risk ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    f = -stats.norm.ppf(alpha / 2)\n    lrr = self.log_riskratio\n    se = self.log_riskratio_se\n    lcb = lrr - f * se\n    ucb = lrr + f * se\n    return (lcb, ucb)",
            "def log_riskratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        A confidence interval for the log risk ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    f = -stats.norm.ppf(alpha / 2)\n    lrr = self.log_riskratio\n    se = self.log_riskratio_se\n    lcb = lrr - f * se\n    ucb = lrr + f * se\n    return (lcb, ucb)",
            "def log_riskratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        A confidence interval for the log risk ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    f = -stats.norm.ppf(alpha / 2)\n    lrr = self.log_riskratio\n    se = self.log_riskratio_se\n    lcb = lrr - f * se\n    ucb = lrr + f * se\n    return (lcb, ucb)"
        ]
    },
    {
        "func_name": "riskratio_confint",
        "original": "def riskratio_confint(self, alpha=0.05, method='normal'):\n    \"\"\"\n        A confidence interval for the risk ratio.\n\n        Parameters\n        ----------\n        alpha : float\n            `1 - alpha` is the nominal coverage probability of the\n            confidence interval.\n        method : str\n            The method for producing the confidence interval.  Currently\n            must be 'normal' which uses the normal approximation.\n        \"\"\"\n    (lcb, ucb) = self.log_riskratio_confint(alpha, method=method)\n    return (np.exp(lcb), np.exp(ucb))",
        "mutated": [
            "def riskratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n    \"\\n        A confidence interval for the risk ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    (lcb, ucb) = self.log_riskratio_confint(alpha, method=method)\n    return (np.exp(lcb), np.exp(ucb))",
            "def riskratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        A confidence interval for the risk ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    (lcb, ucb) = self.log_riskratio_confint(alpha, method=method)\n    return (np.exp(lcb), np.exp(ucb))",
            "def riskratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        A confidence interval for the risk ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    (lcb, ucb) = self.log_riskratio_confint(alpha, method=method)\n    return (np.exp(lcb), np.exp(ucb))",
            "def riskratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        A confidence interval for the risk ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    (lcb, ucb) = self.log_riskratio_confint(alpha, method=method)\n    return (np.exp(lcb), np.exp(ucb))",
            "def riskratio_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        A confidence interval for the risk ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n    (lcb, ucb) = self.log_riskratio_confint(alpha, method=method)\n    return (np.exp(lcb), np.exp(ucb))"
        ]
    },
    {
        "func_name": "fmt",
        "original": "def fmt(x):\n    if isinstance(x, str):\n        return x\n    return float_format % x",
        "mutated": [
            "def fmt(x):\n    if False:\n        i = 10\n    if isinstance(x, str):\n        return x\n    return float_format % x",
            "def fmt(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if isinstance(x, str):\n        return x\n    return float_format % x",
            "def fmt(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if isinstance(x, str):\n        return x\n    return float_format % x",
            "def fmt(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if isinstance(x, str):\n        return x\n    return float_format % x",
            "def fmt(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if isinstance(x, str):\n        return x\n    return float_format % x"
        ]
    },
    {
        "func_name": "summary",
        "original": "def summary(self, alpha=0.05, float_format='%.3f', method='normal'):\n    \"\"\"\n        Summarizes results for a 2x2 table analysis.\n\n        Parameters\n        ----------\n        alpha : float\n            `1 - alpha` is the nominal coverage probability of the confidence\n            intervals.\n        float_format : str\n            Used to format the numeric values in the table.\n        method : str\n            The method for producing the confidence interval.  Currently\n            must be 'normal' which uses the normal approximation.\n        \"\"\"\n\n    def fmt(x):\n        if isinstance(x, str):\n            return x\n        return float_format % x\n    headers = ['Estimate', 'SE', 'LCB', 'UCB', 'p-value']\n    stubs = ['Odds ratio', 'Log odds ratio', 'Risk ratio', 'Log risk ratio']\n    (lcb1, ucb1) = self.oddsratio_confint(alpha, method)\n    (lcb2, ucb2) = self.log_oddsratio_confint(alpha, method)\n    (lcb3, ucb3) = self.riskratio_confint(alpha, method)\n    (lcb4, ucb4) = self.log_riskratio_confint(alpha, method)\n    data = [[fmt(x) for x in [self.oddsratio, '', lcb1, ucb1, self.oddsratio_pvalue()]], [fmt(x) for x in [self.log_oddsratio, self.log_oddsratio_se, lcb2, ucb2, self.oddsratio_pvalue()]], [fmt(x) for x in [self.riskratio, '', lcb3, ucb3, self.riskratio_pvalue()]], [fmt(x) for x in [self.log_riskratio, self.log_riskratio_se, lcb4, ucb4, self.riskratio_pvalue()]]]\n    tab = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    return tab",
        "mutated": [
            "def summary(self, alpha=0.05, float_format='%.3f', method='normal'):\n    if False:\n        i = 10\n    \"\\n        Summarizes results for a 2x2 table analysis.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the confidence\\n            intervals.\\n        float_format : str\\n            Used to format the numeric values in the table.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n\n    def fmt(x):\n        if isinstance(x, str):\n            return x\n        return float_format % x\n    headers = ['Estimate', 'SE', 'LCB', 'UCB', 'p-value']\n    stubs = ['Odds ratio', 'Log odds ratio', 'Risk ratio', 'Log risk ratio']\n    (lcb1, ucb1) = self.oddsratio_confint(alpha, method)\n    (lcb2, ucb2) = self.log_oddsratio_confint(alpha, method)\n    (lcb3, ucb3) = self.riskratio_confint(alpha, method)\n    (lcb4, ucb4) = self.log_riskratio_confint(alpha, method)\n    data = [[fmt(x) for x in [self.oddsratio, '', lcb1, ucb1, self.oddsratio_pvalue()]], [fmt(x) for x in [self.log_oddsratio, self.log_oddsratio_se, lcb2, ucb2, self.oddsratio_pvalue()]], [fmt(x) for x in [self.riskratio, '', lcb3, ucb3, self.riskratio_pvalue()]], [fmt(x) for x in [self.log_riskratio, self.log_riskratio_se, lcb4, ucb4, self.riskratio_pvalue()]]]\n    tab = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    return tab",
            "def summary(self, alpha=0.05, float_format='%.3f', method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Summarizes results for a 2x2 table analysis.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the confidence\\n            intervals.\\n        float_format : str\\n            Used to format the numeric values in the table.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n\n    def fmt(x):\n        if isinstance(x, str):\n            return x\n        return float_format % x\n    headers = ['Estimate', 'SE', 'LCB', 'UCB', 'p-value']\n    stubs = ['Odds ratio', 'Log odds ratio', 'Risk ratio', 'Log risk ratio']\n    (lcb1, ucb1) = self.oddsratio_confint(alpha, method)\n    (lcb2, ucb2) = self.log_oddsratio_confint(alpha, method)\n    (lcb3, ucb3) = self.riskratio_confint(alpha, method)\n    (lcb4, ucb4) = self.log_riskratio_confint(alpha, method)\n    data = [[fmt(x) for x in [self.oddsratio, '', lcb1, ucb1, self.oddsratio_pvalue()]], [fmt(x) for x in [self.log_oddsratio, self.log_oddsratio_se, lcb2, ucb2, self.oddsratio_pvalue()]], [fmt(x) for x in [self.riskratio, '', lcb3, ucb3, self.riskratio_pvalue()]], [fmt(x) for x in [self.log_riskratio, self.log_riskratio_se, lcb4, ucb4, self.riskratio_pvalue()]]]\n    tab = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    return tab",
            "def summary(self, alpha=0.05, float_format='%.3f', method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Summarizes results for a 2x2 table analysis.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the confidence\\n            intervals.\\n        float_format : str\\n            Used to format the numeric values in the table.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n\n    def fmt(x):\n        if isinstance(x, str):\n            return x\n        return float_format % x\n    headers = ['Estimate', 'SE', 'LCB', 'UCB', 'p-value']\n    stubs = ['Odds ratio', 'Log odds ratio', 'Risk ratio', 'Log risk ratio']\n    (lcb1, ucb1) = self.oddsratio_confint(alpha, method)\n    (lcb2, ucb2) = self.log_oddsratio_confint(alpha, method)\n    (lcb3, ucb3) = self.riskratio_confint(alpha, method)\n    (lcb4, ucb4) = self.log_riskratio_confint(alpha, method)\n    data = [[fmt(x) for x in [self.oddsratio, '', lcb1, ucb1, self.oddsratio_pvalue()]], [fmt(x) for x in [self.log_oddsratio, self.log_oddsratio_se, lcb2, ucb2, self.oddsratio_pvalue()]], [fmt(x) for x in [self.riskratio, '', lcb3, ucb3, self.riskratio_pvalue()]], [fmt(x) for x in [self.log_riskratio, self.log_riskratio_se, lcb4, ucb4, self.riskratio_pvalue()]]]\n    tab = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    return tab",
            "def summary(self, alpha=0.05, float_format='%.3f', method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Summarizes results for a 2x2 table analysis.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the confidence\\n            intervals.\\n        float_format : str\\n            Used to format the numeric values in the table.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n\n    def fmt(x):\n        if isinstance(x, str):\n            return x\n        return float_format % x\n    headers = ['Estimate', 'SE', 'LCB', 'UCB', 'p-value']\n    stubs = ['Odds ratio', 'Log odds ratio', 'Risk ratio', 'Log risk ratio']\n    (lcb1, ucb1) = self.oddsratio_confint(alpha, method)\n    (lcb2, ucb2) = self.log_oddsratio_confint(alpha, method)\n    (lcb3, ucb3) = self.riskratio_confint(alpha, method)\n    (lcb4, ucb4) = self.log_riskratio_confint(alpha, method)\n    data = [[fmt(x) for x in [self.oddsratio, '', lcb1, ucb1, self.oddsratio_pvalue()]], [fmt(x) for x in [self.log_oddsratio, self.log_oddsratio_se, lcb2, ucb2, self.oddsratio_pvalue()]], [fmt(x) for x in [self.riskratio, '', lcb3, ucb3, self.riskratio_pvalue()]], [fmt(x) for x in [self.log_riskratio, self.log_riskratio_se, lcb4, ucb4, self.riskratio_pvalue()]]]\n    tab = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    return tab",
            "def summary(self, alpha=0.05, float_format='%.3f', method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Summarizes results for a 2x2 table analysis.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the confidence\\n            intervals.\\n        float_format : str\\n            Used to format the numeric values in the table.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n\n    def fmt(x):\n        if isinstance(x, str):\n            return x\n        return float_format % x\n    headers = ['Estimate', 'SE', 'LCB', 'UCB', 'p-value']\n    stubs = ['Odds ratio', 'Log odds ratio', 'Risk ratio', 'Log risk ratio']\n    (lcb1, ucb1) = self.oddsratio_confint(alpha, method)\n    (lcb2, ucb2) = self.log_oddsratio_confint(alpha, method)\n    (lcb3, ucb3) = self.riskratio_confint(alpha, method)\n    (lcb4, ucb4) = self.log_riskratio_confint(alpha, method)\n    data = [[fmt(x) for x in [self.oddsratio, '', lcb1, ucb1, self.oddsratio_pvalue()]], [fmt(x) for x in [self.log_oddsratio, self.log_oddsratio_se, lcb2, ucb2, self.oddsratio_pvalue()]], [fmt(x) for x in [self.riskratio, '', lcb3, ucb3, self.riskratio_pvalue()]], [fmt(x) for x in [self.log_riskratio, self.log_riskratio_se, lcb4, ucb4, self.riskratio_pvalue()]]]\n    tab = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    return tab"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, tables, shift_zeros=False):\n    if isinstance(tables, np.ndarray):\n        sp = tables.shape\n        if len(sp) != 3 or sp[0] != 2 or sp[1] != 2:\n            raise ValueError('If an ndarray, argument must be 2x2xn')\n        table = tables * 1.0\n    else:\n        if any([np.asarray(x).shape != (2, 2) for x in tables]):\n            m = 'If `tables` is a list, all of its elements should be 2x2'\n            raise ValueError(m)\n        table = np.dstack(tables).astype(np.float64)\n    if shift_zeros:\n        zx = (table == 0).sum(0).sum(0)\n        ix = np.flatnonzero(zx > 0)\n        if len(ix) > 0:\n            table = table.copy()\n            table[:, :, ix] += 0.5\n    self.table = table\n    self._cache = {}\n    self._apb = table[0, 0, :] + table[0, 1, :]\n    self._apc = table[0, 0, :] + table[1, 0, :]\n    self._bpd = table[0, 1, :] + table[1, 1, :]\n    self._cpd = table[1, 0, :] + table[1, 1, :]\n    self._ad = table[0, 0, :] * table[1, 1, :]\n    self._bc = table[0, 1, :] * table[1, 0, :]\n    self._apd = table[0, 0, :] + table[1, 1, :]\n    self._dma = table[1, 1, :] - table[0, 0, :]\n    self._n = table.sum(0).sum(0)",
        "mutated": [
            "def __init__(self, tables, shift_zeros=False):\n    if False:\n        i = 10\n    if isinstance(tables, np.ndarray):\n        sp = tables.shape\n        if len(sp) != 3 or sp[0] != 2 or sp[1] != 2:\n            raise ValueError('If an ndarray, argument must be 2x2xn')\n        table = tables * 1.0\n    else:\n        if any([np.asarray(x).shape != (2, 2) for x in tables]):\n            m = 'If `tables` is a list, all of its elements should be 2x2'\n            raise ValueError(m)\n        table = np.dstack(tables).astype(np.float64)\n    if shift_zeros:\n        zx = (table == 0).sum(0).sum(0)\n        ix = np.flatnonzero(zx > 0)\n        if len(ix) > 0:\n            table = table.copy()\n            table[:, :, ix] += 0.5\n    self.table = table\n    self._cache = {}\n    self._apb = table[0, 0, :] + table[0, 1, :]\n    self._apc = table[0, 0, :] + table[1, 0, :]\n    self._bpd = table[0, 1, :] + table[1, 1, :]\n    self._cpd = table[1, 0, :] + table[1, 1, :]\n    self._ad = table[0, 0, :] * table[1, 1, :]\n    self._bc = table[0, 1, :] * table[1, 0, :]\n    self._apd = table[0, 0, :] + table[1, 1, :]\n    self._dma = table[1, 1, :] - table[0, 0, :]\n    self._n = table.sum(0).sum(0)",
            "def __init__(self, tables, shift_zeros=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if isinstance(tables, np.ndarray):\n        sp = tables.shape\n        if len(sp) != 3 or sp[0] != 2 or sp[1] != 2:\n            raise ValueError('If an ndarray, argument must be 2x2xn')\n        table = tables * 1.0\n    else:\n        if any([np.asarray(x).shape != (2, 2) for x in tables]):\n            m = 'If `tables` is a list, all of its elements should be 2x2'\n            raise ValueError(m)\n        table = np.dstack(tables).astype(np.float64)\n    if shift_zeros:\n        zx = (table == 0).sum(0).sum(0)\n        ix = np.flatnonzero(zx > 0)\n        if len(ix) > 0:\n            table = table.copy()\n            table[:, :, ix] += 0.5\n    self.table = table\n    self._cache = {}\n    self._apb = table[0, 0, :] + table[0, 1, :]\n    self._apc = table[0, 0, :] + table[1, 0, :]\n    self._bpd = table[0, 1, :] + table[1, 1, :]\n    self._cpd = table[1, 0, :] + table[1, 1, :]\n    self._ad = table[0, 0, :] * table[1, 1, :]\n    self._bc = table[0, 1, :] * table[1, 0, :]\n    self._apd = table[0, 0, :] + table[1, 1, :]\n    self._dma = table[1, 1, :] - table[0, 0, :]\n    self._n = table.sum(0).sum(0)",
            "def __init__(self, tables, shift_zeros=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if isinstance(tables, np.ndarray):\n        sp = tables.shape\n        if len(sp) != 3 or sp[0] != 2 or sp[1] != 2:\n            raise ValueError('If an ndarray, argument must be 2x2xn')\n        table = tables * 1.0\n    else:\n        if any([np.asarray(x).shape != (2, 2) for x in tables]):\n            m = 'If `tables` is a list, all of its elements should be 2x2'\n            raise ValueError(m)\n        table = np.dstack(tables).astype(np.float64)\n    if shift_zeros:\n        zx = (table == 0).sum(0).sum(0)\n        ix = np.flatnonzero(zx > 0)\n        if len(ix) > 0:\n            table = table.copy()\n            table[:, :, ix] += 0.5\n    self.table = table\n    self._cache = {}\n    self._apb = table[0, 0, :] + table[0, 1, :]\n    self._apc = table[0, 0, :] + table[1, 0, :]\n    self._bpd = table[0, 1, :] + table[1, 1, :]\n    self._cpd = table[1, 0, :] + table[1, 1, :]\n    self._ad = table[0, 0, :] * table[1, 1, :]\n    self._bc = table[0, 1, :] * table[1, 0, :]\n    self._apd = table[0, 0, :] + table[1, 1, :]\n    self._dma = table[1, 1, :] - table[0, 0, :]\n    self._n = table.sum(0).sum(0)",
            "def __init__(self, tables, shift_zeros=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if isinstance(tables, np.ndarray):\n        sp = tables.shape\n        if len(sp) != 3 or sp[0] != 2 or sp[1] != 2:\n            raise ValueError('If an ndarray, argument must be 2x2xn')\n        table = tables * 1.0\n    else:\n        if any([np.asarray(x).shape != (2, 2) for x in tables]):\n            m = 'If `tables` is a list, all of its elements should be 2x2'\n            raise ValueError(m)\n        table = np.dstack(tables).astype(np.float64)\n    if shift_zeros:\n        zx = (table == 0).sum(0).sum(0)\n        ix = np.flatnonzero(zx > 0)\n        if len(ix) > 0:\n            table = table.copy()\n            table[:, :, ix] += 0.5\n    self.table = table\n    self._cache = {}\n    self._apb = table[0, 0, :] + table[0, 1, :]\n    self._apc = table[0, 0, :] + table[1, 0, :]\n    self._bpd = table[0, 1, :] + table[1, 1, :]\n    self._cpd = table[1, 0, :] + table[1, 1, :]\n    self._ad = table[0, 0, :] * table[1, 1, :]\n    self._bc = table[0, 1, :] * table[1, 0, :]\n    self._apd = table[0, 0, :] + table[1, 1, :]\n    self._dma = table[1, 1, :] - table[0, 0, :]\n    self._n = table.sum(0).sum(0)",
            "def __init__(self, tables, shift_zeros=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if isinstance(tables, np.ndarray):\n        sp = tables.shape\n        if len(sp) != 3 or sp[0] != 2 or sp[1] != 2:\n            raise ValueError('If an ndarray, argument must be 2x2xn')\n        table = tables * 1.0\n    else:\n        if any([np.asarray(x).shape != (2, 2) for x in tables]):\n            m = 'If `tables` is a list, all of its elements should be 2x2'\n            raise ValueError(m)\n        table = np.dstack(tables).astype(np.float64)\n    if shift_zeros:\n        zx = (table == 0).sum(0).sum(0)\n        ix = np.flatnonzero(zx > 0)\n        if len(ix) > 0:\n            table = table.copy()\n            table[:, :, ix] += 0.5\n    self.table = table\n    self._cache = {}\n    self._apb = table[0, 0, :] + table[0, 1, :]\n    self._apc = table[0, 0, :] + table[1, 0, :]\n    self._bpd = table[0, 1, :] + table[1, 1, :]\n    self._cpd = table[1, 0, :] + table[1, 1, :]\n    self._ad = table[0, 0, :] * table[1, 1, :]\n    self._bc = table[0, 1, :] * table[1, 0, :]\n    self._apd = table[0, 0, :] + table[1, 1, :]\n    self._dma = table[1, 1, :] - table[0, 0, :]\n    self._n = table.sum(0).sum(0)"
        ]
    },
    {
        "func_name": "from_data",
        "original": "@classmethod\ndef from_data(cls, var1, var2, strata, data):\n    \"\"\"\n        Construct a StratifiedTable object from data.\n\n        Parameters\n        ----------\n        var1 : int or string\n            The column index or name of `data` specifying the variable\n            defining the rows of the contingency table.  The variable\n            must have only two distinct values.\n        var2 : int or string\n            The column index or name of `data` specifying the variable\n            defining the columns of the contingency table.  The variable\n            must have only two distinct values.\n        strata : int or string\n            The column index or name of `data` specifying the variable\n            defining the strata.\n        data : array_like\n            The raw data.  A cross-table for analysis is constructed\n            from the first two columns.\n\n        Returns\n        -------\n        StratifiedTable\n        \"\"\"\n    if not isinstance(data, pd.DataFrame):\n        data1 = pd.DataFrame(index=np.arange(data.shape[0]), columns=[var1, var2, strata])\n        data1[data1.columns[var1]] = data[:, var1]\n        data1[data1.columns[var2]] = data[:, var2]\n        data1[data1.columns[strata]] = data[:, strata]\n    else:\n        data1 = data[[var1, var2, strata]]\n    gb = data1.groupby(strata).groups\n    tables = []\n    for g in gb:\n        ii = gb[g]\n        tab = pd.crosstab(data1.loc[ii, var1], data1.loc[ii, var2])\n        if (tab.shape != np.r_[2, 2]).any():\n            msg = 'Invalid table dimensions'\n            raise ValueError(msg)\n        tables.append(np.asarray(tab))\n    return cls(tables)",
        "mutated": [
            "@classmethod\ndef from_data(cls, var1, var2, strata, data):\n    if False:\n        i = 10\n    '\\n        Construct a StratifiedTable object from data.\\n\\n        Parameters\\n        ----------\\n        var1 : int or string\\n            The column index or name of `data` specifying the variable\\n            defining the rows of the contingency table.  The variable\\n            must have only two distinct values.\\n        var2 : int or string\\n            The column index or name of `data` specifying the variable\\n            defining the columns of the contingency table.  The variable\\n            must have only two distinct values.\\n        strata : int or string\\n            The column index or name of `data` specifying the variable\\n            defining the strata.\\n        data : array_like\\n            The raw data.  A cross-table for analysis is constructed\\n            from the first two columns.\\n\\n        Returns\\n        -------\\n        StratifiedTable\\n        '\n    if not isinstance(data, pd.DataFrame):\n        data1 = pd.DataFrame(index=np.arange(data.shape[0]), columns=[var1, var2, strata])\n        data1[data1.columns[var1]] = data[:, var1]\n        data1[data1.columns[var2]] = data[:, var2]\n        data1[data1.columns[strata]] = data[:, strata]\n    else:\n        data1 = data[[var1, var2, strata]]\n    gb = data1.groupby(strata).groups\n    tables = []\n    for g in gb:\n        ii = gb[g]\n        tab = pd.crosstab(data1.loc[ii, var1], data1.loc[ii, var2])\n        if (tab.shape != np.r_[2, 2]).any():\n            msg = 'Invalid table dimensions'\n            raise ValueError(msg)\n        tables.append(np.asarray(tab))\n    return cls(tables)",
            "@classmethod\ndef from_data(cls, var1, var2, strata, data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Construct a StratifiedTable object from data.\\n\\n        Parameters\\n        ----------\\n        var1 : int or string\\n            The column index or name of `data` specifying the variable\\n            defining the rows of the contingency table.  The variable\\n            must have only two distinct values.\\n        var2 : int or string\\n            The column index or name of `data` specifying the variable\\n            defining the columns of the contingency table.  The variable\\n            must have only two distinct values.\\n        strata : int or string\\n            The column index or name of `data` specifying the variable\\n            defining the strata.\\n        data : array_like\\n            The raw data.  A cross-table for analysis is constructed\\n            from the first two columns.\\n\\n        Returns\\n        -------\\n        StratifiedTable\\n        '\n    if not isinstance(data, pd.DataFrame):\n        data1 = pd.DataFrame(index=np.arange(data.shape[0]), columns=[var1, var2, strata])\n        data1[data1.columns[var1]] = data[:, var1]\n        data1[data1.columns[var2]] = data[:, var2]\n        data1[data1.columns[strata]] = data[:, strata]\n    else:\n        data1 = data[[var1, var2, strata]]\n    gb = data1.groupby(strata).groups\n    tables = []\n    for g in gb:\n        ii = gb[g]\n        tab = pd.crosstab(data1.loc[ii, var1], data1.loc[ii, var2])\n        if (tab.shape != np.r_[2, 2]).any():\n            msg = 'Invalid table dimensions'\n            raise ValueError(msg)\n        tables.append(np.asarray(tab))\n    return cls(tables)",
            "@classmethod\ndef from_data(cls, var1, var2, strata, data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Construct a StratifiedTable object from data.\\n\\n        Parameters\\n        ----------\\n        var1 : int or string\\n            The column index or name of `data` specifying the variable\\n            defining the rows of the contingency table.  The variable\\n            must have only two distinct values.\\n        var2 : int or string\\n            The column index or name of `data` specifying the variable\\n            defining the columns of the contingency table.  The variable\\n            must have only two distinct values.\\n        strata : int or string\\n            The column index or name of `data` specifying the variable\\n            defining the strata.\\n        data : array_like\\n            The raw data.  A cross-table for analysis is constructed\\n            from the first two columns.\\n\\n        Returns\\n        -------\\n        StratifiedTable\\n        '\n    if not isinstance(data, pd.DataFrame):\n        data1 = pd.DataFrame(index=np.arange(data.shape[0]), columns=[var1, var2, strata])\n        data1[data1.columns[var1]] = data[:, var1]\n        data1[data1.columns[var2]] = data[:, var2]\n        data1[data1.columns[strata]] = data[:, strata]\n    else:\n        data1 = data[[var1, var2, strata]]\n    gb = data1.groupby(strata).groups\n    tables = []\n    for g in gb:\n        ii = gb[g]\n        tab = pd.crosstab(data1.loc[ii, var1], data1.loc[ii, var2])\n        if (tab.shape != np.r_[2, 2]).any():\n            msg = 'Invalid table dimensions'\n            raise ValueError(msg)\n        tables.append(np.asarray(tab))\n    return cls(tables)",
            "@classmethod\ndef from_data(cls, var1, var2, strata, data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Construct a StratifiedTable object from data.\\n\\n        Parameters\\n        ----------\\n        var1 : int or string\\n            The column index or name of `data` specifying the variable\\n            defining the rows of the contingency table.  The variable\\n            must have only two distinct values.\\n        var2 : int or string\\n            The column index or name of `data` specifying the variable\\n            defining the columns of the contingency table.  The variable\\n            must have only two distinct values.\\n        strata : int or string\\n            The column index or name of `data` specifying the variable\\n            defining the strata.\\n        data : array_like\\n            The raw data.  A cross-table for analysis is constructed\\n            from the first two columns.\\n\\n        Returns\\n        -------\\n        StratifiedTable\\n        '\n    if not isinstance(data, pd.DataFrame):\n        data1 = pd.DataFrame(index=np.arange(data.shape[0]), columns=[var1, var2, strata])\n        data1[data1.columns[var1]] = data[:, var1]\n        data1[data1.columns[var2]] = data[:, var2]\n        data1[data1.columns[strata]] = data[:, strata]\n    else:\n        data1 = data[[var1, var2, strata]]\n    gb = data1.groupby(strata).groups\n    tables = []\n    for g in gb:\n        ii = gb[g]\n        tab = pd.crosstab(data1.loc[ii, var1], data1.loc[ii, var2])\n        if (tab.shape != np.r_[2, 2]).any():\n            msg = 'Invalid table dimensions'\n            raise ValueError(msg)\n        tables.append(np.asarray(tab))\n    return cls(tables)",
            "@classmethod\ndef from_data(cls, var1, var2, strata, data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Construct a StratifiedTable object from data.\\n\\n        Parameters\\n        ----------\\n        var1 : int or string\\n            The column index or name of `data` specifying the variable\\n            defining the rows of the contingency table.  The variable\\n            must have only two distinct values.\\n        var2 : int or string\\n            The column index or name of `data` specifying the variable\\n            defining the columns of the contingency table.  The variable\\n            must have only two distinct values.\\n        strata : int or string\\n            The column index or name of `data` specifying the variable\\n            defining the strata.\\n        data : array_like\\n            The raw data.  A cross-table for analysis is constructed\\n            from the first two columns.\\n\\n        Returns\\n        -------\\n        StratifiedTable\\n        '\n    if not isinstance(data, pd.DataFrame):\n        data1 = pd.DataFrame(index=np.arange(data.shape[0]), columns=[var1, var2, strata])\n        data1[data1.columns[var1]] = data[:, var1]\n        data1[data1.columns[var2]] = data[:, var2]\n        data1[data1.columns[strata]] = data[:, strata]\n    else:\n        data1 = data[[var1, var2, strata]]\n    gb = data1.groupby(strata).groups\n    tables = []\n    for g in gb:\n        ii = gb[g]\n        tab = pd.crosstab(data1.loc[ii, var1], data1.loc[ii, var2])\n        if (tab.shape != np.r_[2, 2]).any():\n            msg = 'Invalid table dimensions'\n            raise ValueError(msg)\n        tables.append(np.asarray(tab))\n    return cls(tables)"
        ]
    },
    {
        "func_name": "test_null_odds",
        "original": "def test_null_odds(self, correction=False):\n    \"\"\"\n        Test that all tables have odds ratio equal to 1.\n\n        This is the 'Mantel-Haenszel' test.\n\n        Parameters\n        ----------\n        correction : bool\n            If True, use the continuity correction when calculating the\n            test statistic.\n\n        Returns\n        -------\n        Bunch\n            A bunch containing the chi^2 test statistic and p-value.\n        \"\"\"\n    statistic = np.sum(self.table[0, 0, :] - self._apb * self._apc / self._n)\n    statistic = np.abs(statistic)\n    if correction:\n        statistic -= 0.5\n    statistic = statistic ** 2\n    denom = self._apb * self._apc * self._bpd * self._cpd\n    denom /= self._n ** 2 * (self._n - 1)\n    denom = np.sum(denom)\n    statistic /= denom\n    pvalue = 1 - stats.chi2.cdf(statistic, 1)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b",
        "mutated": [
            "def test_null_odds(self, correction=False):\n    if False:\n        i = 10\n    \"\\n        Test that all tables have odds ratio equal to 1.\\n\\n        This is the 'Mantel-Haenszel' test.\\n\\n        Parameters\\n        ----------\\n        correction : bool\\n            If True, use the continuity correction when calculating the\\n            test statistic.\\n\\n        Returns\\n        -------\\n        Bunch\\n            A bunch containing the chi^2 test statistic and p-value.\\n        \"\n    statistic = np.sum(self.table[0, 0, :] - self._apb * self._apc / self._n)\n    statistic = np.abs(statistic)\n    if correction:\n        statistic -= 0.5\n    statistic = statistic ** 2\n    denom = self._apb * self._apc * self._bpd * self._cpd\n    denom /= self._n ** 2 * (self._n - 1)\n    denom = np.sum(denom)\n    statistic /= denom\n    pvalue = 1 - stats.chi2.cdf(statistic, 1)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b",
            "def test_null_odds(self, correction=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Test that all tables have odds ratio equal to 1.\\n\\n        This is the 'Mantel-Haenszel' test.\\n\\n        Parameters\\n        ----------\\n        correction : bool\\n            If True, use the continuity correction when calculating the\\n            test statistic.\\n\\n        Returns\\n        -------\\n        Bunch\\n            A bunch containing the chi^2 test statistic and p-value.\\n        \"\n    statistic = np.sum(self.table[0, 0, :] - self._apb * self._apc / self._n)\n    statistic = np.abs(statistic)\n    if correction:\n        statistic -= 0.5\n    statistic = statistic ** 2\n    denom = self._apb * self._apc * self._bpd * self._cpd\n    denom /= self._n ** 2 * (self._n - 1)\n    denom = np.sum(denom)\n    statistic /= denom\n    pvalue = 1 - stats.chi2.cdf(statistic, 1)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b",
            "def test_null_odds(self, correction=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Test that all tables have odds ratio equal to 1.\\n\\n        This is the 'Mantel-Haenszel' test.\\n\\n        Parameters\\n        ----------\\n        correction : bool\\n            If True, use the continuity correction when calculating the\\n            test statistic.\\n\\n        Returns\\n        -------\\n        Bunch\\n            A bunch containing the chi^2 test statistic and p-value.\\n        \"\n    statistic = np.sum(self.table[0, 0, :] - self._apb * self._apc / self._n)\n    statistic = np.abs(statistic)\n    if correction:\n        statistic -= 0.5\n    statistic = statistic ** 2\n    denom = self._apb * self._apc * self._bpd * self._cpd\n    denom /= self._n ** 2 * (self._n - 1)\n    denom = np.sum(denom)\n    statistic /= denom\n    pvalue = 1 - stats.chi2.cdf(statistic, 1)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b",
            "def test_null_odds(self, correction=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Test that all tables have odds ratio equal to 1.\\n\\n        This is the 'Mantel-Haenszel' test.\\n\\n        Parameters\\n        ----------\\n        correction : bool\\n            If True, use the continuity correction when calculating the\\n            test statistic.\\n\\n        Returns\\n        -------\\n        Bunch\\n            A bunch containing the chi^2 test statistic and p-value.\\n        \"\n    statistic = np.sum(self.table[0, 0, :] - self._apb * self._apc / self._n)\n    statistic = np.abs(statistic)\n    if correction:\n        statistic -= 0.5\n    statistic = statistic ** 2\n    denom = self._apb * self._apc * self._bpd * self._cpd\n    denom /= self._n ** 2 * (self._n - 1)\n    denom = np.sum(denom)\n    statistic /= denom\n    pvalue = 1 - stats.chi2.cdf(statistic, 1)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b",
            "def test_null_odds(self, correction=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Test that all tables have odds ratio equal to 1.\\n\\n        This is the 'Mantel-Haenszel' test.\\n\\n        Parameters\\n        ----------\\n        correction : bool\\n            If True, use the continuity correction when calculating the\\n            test statistic.\\n\\n        Returns\\n        -------\\n        Bunch\\n            A bunch containing the chi^2 test statistic and p-value.\\n        \"\n    statistic = np.sum(self.table[0, 0, :] - self._apb * self._apc / self._n)\n    statistic = np.abs(statistic)\n    if correction:\n        statistic -= 0.5\n    statistic = statistic ** 2\n    denom = self._apb * self._apc * self._bpd * self._cpd\n    denom /= self._n ** 2 * (self._n - 1)\n    denom = np.sum(denom)\n    statistic /= denom\n    pvalue = 1 - stats.chi2.cdf(statistic, 1)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b"
        ]
    },
    {
        "func_name": "oddsratio_pooled",
        "original": "@cache_readonly\ndef oddsratio_pooled(self):\n    \"\"\"\n        The pooled odds ratio.\n\n        The value is an estimate of a common odds ratio across all of the\n        stratified tables.\n        \"\"\"\n    odds_ratio = np.sum(self._ad / self._n) / np.sum(self._bc / self._n)\n    return odds_ratio",
        "mutated": [
            "@cache_readonly\ndef oddsratio_pooled(self):\n    if False:\n        i = 10\n    '\\n        The pooled odds ratio.\\n\\n        The value is an estimate of a common odds ratio across all of the\\n        stratified tables.\\n        '\n    odds_ratio = np.sum(self._ad / self._n) / np.sum(self._bc / self._n)\n    return odds_ratio",
            "@cache_readonly\ndef oddsratio_pooled(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        The pooled odds ratio.\\n\\n        The value is an estimate of a common odds ratio across all of the\\n        stratified tables.\\n        '\n    odds_ratio = np.sum(self._ad / self._n) / np.sum(self._bc / self._n)\n    return odds_ratio",
            "@cache_readonly\ndef oddsratio_pooled(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        The pooled odds ratio.\\n\\n        The value is an estimate of a common odds ratio across all of the\\n        stratified tables.\\n        '\n    odds_ratio = np.sum(self._ad / self._n) / np.sum(self._bc / self._n)\n    return odds_ratio",
            "@cache_readonly\ndef oddsratio_pooled(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        The pooled odds ratio.\\n\\n        The value is an estimate of a common odds ratio across all of the\\n        stratified tables.\\n        '\n    odds_ratio = np.sum(self._ad / self._n) / np.sum(self._bc / self._n)\n    return odds_ratio",
            "@cache_readonly\ndef oddsratio_pooled(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        The pooled odds ratio.\\n\\n        The value is an estimate of a common odds ratio across all of the\\n        stratified tables.\\n        '\n    odds_ratio = np.sum(self._ad / self._n) / np.sum(self._bc / self._n)\n    return odds_ratio"
        ]
    },
    {
        "func_name": "logodds_pooled",
        "original": "@cache_readonly\ndef logodds_pooled(self):\n    \"\"\"\n        Returns the logarithm of the pooled odds ratio.\n\n        See oddsratio_pooled for more information.\n        \"\"\"\n    return np.log(self.oddsratio_pooled)",
        "mutated": [
            "@cache_readonly\ndef logodds_pooled(self):\n    if False:\n        i = 10\n    '\\n        Returns the logarithm of the pooled odds ratio.\\n\\n        See oddsratio_pooled for more information.\\n        '\n    return np.log(self.oddsratio_pooled)",
            "@cache_readonly\ndef logodds_pooled(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the logarithm of the pooled odds ratio.\\n\\n        See oddsratio_pooled for more information.\\n        '\n    return np.log(self.oddsratio_pooled)",
            "@cache_readonly\ndef logodds_pooled(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the logarithm of the pooled odds ratio.\\n\\n        See oddsratio_pooled for more information.\\n        '\n    return np.log(self.oddsratio_pooled)",
            "@cache_readonly\ndef logodds_pooled(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the logarithm of the pooled odds ratio.\\n\\n        See oddsratio_pooled for more information.\\n        '\n    return np.log(self.oddsratio_pooled)",
            "@cache_readonly\ndef logodds_pooled(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the logarithm of the pooled odds ratio.\\n\\n        See oddsratio_pooled for more information.\\n        '\n    return np.log(self.oddsratio_pooled)"
        ]
    },
    {
        "func_name": "riskratio_pooled",
        "original": "@cache_readonly\ndef riskratio_pooled(self):\n    \"\"\"\n        Estimate of the pooled risk ratio.\n        \"\"\"\n    acd = self.table[0, 0, :] * self._cpd\n    cab = self.table[1, 0, :] * self._apb\n    rr = np.sum(acd / self._n) / np.sum(cab / self._n)\n    return rr",
        "mutated": [
            "@cache_readonly\ndef riskratio_pooled(self):\n    if False:\n        i = 10\n    '\\n        Estimate of the pooled risk ratio.\\n        '\n    acd = self.table[0, 0, :] * self._cpd\n    cab = self.table[1, 0, :] * self._apb\n    rr = np.sum(acd / self._n) / np.sum(cab / self._n)\n    return rr",
            "@cache_readonly\ndef riskratio_pooled(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Estimate of the pooled risk ratio.\\n        '\n    acd = self.table[0, 0, :] * self._cpd\n    cab = self.table[1, 0, :] * self._apb\n    rr = np.sum(acd / self._n) / np.sum(cab / self._n)\n    return rr",
            "@cache_readonly\ndef riskratio_pooled(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Estimate of the pooled risk ratio.\\n        '\n    acd = self.table[0, 0, :] * self._cpd\n    cab = self.table[1, 0, :] * self._apb\n    rr = np.sum(acd / self._n) / np.sum(cab / self._n)\n    return rr",
            "@cache_readonly\ndef riskratio_pooled(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Estimate of the pooled risk ratio.\\n        '\n    acd = self.table[0, 0, :] * self._cpd\n    cab = self.table[1, 0, :] * self._apb\n    rr = np.sum(acd / self._n) / np.sum(cab / self._n)\n    return rr",
            "@cache_readonly\ndef riskratio_pooled(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Estimate of the pooled risk ratio.\\n        '\n    acd = self.table[0, 0, :] * self._cpd\n    cab = self.table[1, 0, :] * self._apb\n    rr = np.sum(acd / self._n) / np.sum(cab / self._n)\n    return rr"
        ]
    },
    {
        "func_name": "logodds_pooled_se",
        "original": "@cache_readonly\ndef logodds_pooled_se(self):\n    \"\"\"\n        Estimated standard error of the pooled log odds ratio\n\n        References\n        ----------\n        J. Robins, N. Breslow, S. Greenland. \"Estimators of the\n        Mantel-Haenszel Variance Consistent in Both Sparse Data and\n        Large-Strata Limiting Models.\" Biometrics 42, no. 2 (1986): 311-23.\n        \"\"\"\n    adns = np.sum(self._ad / self._n)\n    bcns = np.sum(self._bc / self._n)\n    lor_va = np.sum(self._apd * self._ad / self._n ** 2) / adns ** 2\n    mid = self._apd * self._bc / self._n ** 2\n    mid += (1 - self._apd / self._n) * self._ad / self._n\n    mid = np.sum(mid)\n    mid /= adns * bcns\n    lor_va += mid\n    lor_va += np.sum((1 - self._apd / self._n) * self._bc / self._n) / bcns ** 2\n    lor_va /= 2\n    lor_se = np.sqrt(lor_va)\n    return lor_se",
        "mutated": [
            "@cache_readonly\ndef logodds_pooled_se(self):\n    if False:\n        i = 10\n    '\\n        Estimated standard error of the pooled log odds ratio\\n\\n        References\\n        ----------\\n        J. Robins, N. Breslow, S. Greenland. \"Estimators of the\\n        Mantel-Haenszel Variance Consistent in Both Sparse Data and\\n        Large-Strata Limiting Models.\" Biometrics 42, no. 2 (1986): 311-23.\\n        '\n    adns = np.sum(self._ad / self._n)\n    bcns = np.sum(self._bc / self._n)\n    lor_va = np.sum(self._apd * self._ad / self._n ** 2) / adns ** 2\n    mid = self._apd * self._bc / self._n ** 2\n    mid += (1 - self._apd / self._n) * self._ad / self._n\n    mid = np.sum(mid)\n    mid /= adns * bcns\n    lor_va += mid\n    lor_va += np.sum((1 - self._apd / self._n) * self._bc / self._n) / bcns ** 2\n    lor_va /= 2\n    lor_se = np.sqrt(lor_va)\n    return lor_se",
            "@cache_readonly\ndef logodds_pooled_se(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Estimated standard error of the pooled log odds ratio\\n\\n        References\\n        ----------\\n        J. Robins, N. Breslow, S. Greenland. \"Estimators of the\\n        Mantel-Haenszel Variance Consistent in Both Sparse Data and\\n        Large-Strata Limiting Models.\" Biometrics 42, no. 2 (1986): 311-23.\\n        '\n    adns = np.sum(self._ad / self._n)\n    bcns = np.sum(self._bc / self._n)\n    lor_va = np.sum(self._apd * self._ad / self._n ** 2) / adns ** 2\n    mid = self._apd * self._bc / self._n ** 2\n    mid += (1 - self._apd / self._n) * self._ad / self._n\n    mid = np.sum(mid)\n    mid /= adns * bcns\n    lor_va += mid\n    lor_va += np.sum((1 - self._apd / self._n) * self._bc / self._n) / bcns ** 2\n    lor_va /= 2\n    lor_se = np.sqrt(lor_va)\n    return lor_se",
            "@cache_readonly\ndef logodds_pooled_se(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Estimated standard error of the pooled log odds ratio\\n\\n        References\\n        ----------\\n        J. Robins, N. Breslow, S. Greenland. \"Estimators of the\\n        Mantel-Haenszel Variance Consistent in Both Sparse Data and\\n        Large-Strata Limiting Models.\" Biometrics 42, no. 2 (1986): 311-23.\\n        '\n    adns = np.sum(self._ad / self._n)\n    bcns = np.sum(self._bc / self._n)\n    lor_va = np.sum(self._apd * self._ad / self._n ** 2) / adns ** 2\n    mid = self._apd * self._bc / self._n ** 2\n    mid += (1 - self._apd / self._n) * self._ad / self._n\n    mid = np.sum(mid)\n    mid /= adns * bcns\n    lor_va += mid\n    lor_va += np.sum((1 - self._apd / self._n) * self._bc / self._n) / bcns ** 2\n    lor_va /= 2\n    lor_se = np.sqrt(lor_va)\n    return lor_se",
            "@cache_readonly\ndef logodds_pooled_se(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Estimated standard error of the pooled log odds ratio\\n\\n        References\\n        ----------\\n        J. Robins, N. Breslow, S. Greenland. \"Estimators of the\\n        Mantel-Haenszel Variance Consistent in Both Sparse Data and\\n        Large-Strata Limiting Models.\" Biometrics 42, no. 2 (1986): 311-23.\\n        '\n    adns = np.sum(self._ad / self._n)\n    bcns = np.sum(self._bc / self._n)\n    lor_va = np.sum(self._apd * self._ad / self._n ** 2) / adns ** 2\n    mid = self._apd * self._bc / self._n ** 2\n    mid += (1 - self._apd / self._n) * self._ad / self._n\n    mid = np.sum(mid)\n    mid /= adns * bcns\n    lor_va += mid\n    lor_va += np.sum((1 - self._apd / self._n) * self._bc / self._n) / bcns ** 2\n    lor_va /= 2\n    lor_se = np.sqrt(lor_va)\n    return lor_se",
            "@cache_readonly\ndef logodds_pooled_se(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Estimated standard error of the pooled log odds ratio\\n\\n        References\\n        ----------\\n        J. Robins, N. Breslow, S. Greenland. \"Estimators of the\\n        Mantel-Haenszel Variance Consistent in Both Sparse Data and\\n        Large-Strata Limiting Models.\" Biometrics 42, no. 2 (1986): 311-23.\\n        '\n    adns = np.sum(self._ad / self._n)\n    bcns = np.sum(self._bc / self._n)\n    lor_va = np.sum(self._apd * self._ad / self._n ** 2) / adns ** 2\n    mid = self._apd * self._bc / self._n ** 2\n    mid += (1 - self._apd / self._n) * self._ad / self._n\n    mid = np.sum(mid)\n    mid /= adns * bcns\n    lor_va += mid\n    lor_va += np.sum((1 - self._apd / self._n) * self._bc / self._n) / bcns ** 2\n    lor_va /= 2\n    lor_se = np.sqrt(lor_va)\n    return lor_se"
        ]
    },
    {
        "func_name": "logodds_pooled_confint",
        "original": "def logodds_pooled_confint(self, alpha=0.05, method='normal'):\n    \"\"\"\n        A confidence interval for the pooled log odds ratio.\n\n        Parameters\n        ----------\n        alpha : float\n            `1 - alpha` is the nominal coverage probability of the\n            interval.\n        method : str\n            The method for producing the confidence interval.  Currently\n            must be 'normal' which uses the normal approximation.\n\n        Returns\n        -------\n        lcb : float\n            The lower confidence limit.\n        ucb : float\n            The upper confidence limit.\n        \"\"\"\n    lor = np.log(self.oddsratio_pooled)\n    lor_se = self.logodds_pooled_se\n    f = -stats.norm.ppf(alpha / 2)\n    lcb = lor - f * lor_se\n    ucb = lor + f * lor_se\n    return (lcb, ucb)",
        "mutated": [
            "def logodds_pooled_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n    \"\\n        A confidence interval for the pooled log odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n\\n        Returns\\n        -------\\n        lcb : float\\n            The lower confidence limit.\\n        ucb : float\\n            The upper confidence limit.\\n        \"\n    lor = np.log(self.oddsratio_pooled)\n    lor_se = self.logodds_pooled_se\n    f = -stats.norm.ppf(alpha / 2)\n    lcb = lor - f * lor_se\n    ucb = lor + f * lor_se\n    return (lcb, ucb)",
            "def logodds_pooled_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        A confidence interval for the pooled log odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n\\n        Returns\\n        -------\\n        lcb : float\\n            The lower confidence limit.\\n        ucb : float\\n            The upper confidence limit.\\n        \"\n    lor = np.log(self.oddsratio_pooled)\n    lor_se = self.logodds_pooled_se\n    f = -stats.norm.ppf(alpha / 2)\n    lcb = lor - f * lor_se\n    ucb = lor + f * lor_se\n    return (lcb, ucb)",
            "def logodds_pooled_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        A confidence interval for the pooled log odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n\\n        Returns\\n        -------\\n        lcb : float\\n            The lower confidence limit.\\n        ucb : float\\n            The upper confidence limit.\\n        \"\n    lor = np.log(self.oddsratio_pooled)\n    lor_se = self.logodds_pooled_se\n    f = -stats.norm.ppf(alpha / 2)\n    lcb = lor - f * lor_se\n    ucb = lor + f * lor_se\n    return (lcb, ucb)",
            "def logodds_pooled_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        A confidence interval for the pooled log odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n\\n        Returns\\n        -------\\n        lcb : float\\n            The lower confidence limit.\\n        ucb : float\\n            The upper confidence limit.\\n        \"\n    lor = np.log(self.oddsratio_pooled)\n    lor_se = self.logodds_pooled_se\n    f = -stats.norm.ppf(alpha / 2)\n    lcb = lor - f * lor_se\n    ucb = lor + f * lor_se\n    return (lcb, ucb)",
            "def logodds_pooled_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        A confidence interval for the pooled log odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n\\n        Returns\\n        -------\\n        lcb : float\\n            The lower confidence limit.\\n        ucb : float\\n            The upper confidence limit.\\n        \"\n    lor = np.log(self.oddsratio_pooled)\n    lor_se = self.logodds_pooled_se\n    f = -stats.norm.ppf(alpha / 2)\n    lcb = lor - f * lor_se\n    ucb = lor + f * lor_se\n    return (lcb, ucb)"
        ]
    },
    {
        "func_name": "oddsratio_pooled_confint",
        "original": "def oddsratio_pooled_confint(self, alpha=0.05, method='normal'):\n    \"\"\"\n        A confidence interval for the pooled odds ratio.\n\n        Parameters\n        ----------\n        alpha : float\n            `1 - alpha` is the nominal coverage probability of the\n            interval.\n        method : str\n            The method for producing the confidence interval.  Currently\n            must be 'normal' which uses the normal approximation.\n\n        Returns\n        -------\n        lcb : float\n            The lower confidence limit.\n        ucb : float\n            The upper confidence limit.\n        \"\"\"\n    (lcb, ucb) = self.logodds_pooled_confint(alpha, method=method)\n    lcb = np.exp(lcb)\n    ucb = np.exp(ucb)\n    return (lcb, ucb)",
        "mutated": [
            "def oddsratio_pooled_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n    \"\\n        A confidence interval for the pooled odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n\\n        Returns\\n        -------\\n        lcb : float\\n            The lower confidence limit.\\n        ucb : float\\n            The upper confidence limit.\\n        \"\n    (lcb, ucb) = self.logodds_pooled_confint(alpha, method=method)\n    lcb = np.exp(lcb)\n    ucb = np.exp(ucb)\n    return (lcb, ucb)",
            "def oddsratio_pooled_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        A confidence interval for the pooled odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n\\n        Returns\\n        -------\\n        lcb : float\\n            The lower confidence limit.\\n        ucb : float\\n            The upper confidence limit.\\n        \"\n    (lcb, ucb) = self.logodds_pooled_confint(alpha, method=method)\n    lcb = np.exp(lcb)\n    ucb = np.exp(ucb)\n    return (lcb, ucb)",
            "def oddsratio_pooled_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        A confidence interval for the pooled odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n\\n        Returns\\n        -------\\n        lcb : float\\n            The lower confidence limit.\\n        ucb : float\\n            The upper confidence limit.\\n        \"\n    (lcb, ucb) = self.logodds_pooled_confint(alpha, method=method)\n    lcb = np.exp(lcb)\n    ucb = np.exp(ucb)\n    return (lcb, ucb)",
            "def oddsratio_pooled_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        A confidence interval for the pooled odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n\\n        Returns\\n        -------\\n        lcb : float\\n            The lower confidence limit.\\n        ucb : float\\n            The upper confidence limit.\\n        \"\n    (lcb, ucb) = self.logodds_pooled_confint(alpha, method=method)\n    lcb = np.exp(lcb)\n    ucb = np.exp(ucb)\n    return (lcb, ucb)",
            "def oddsratio_pooled_confint(self, alpha=0.05, method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        A confidence interval for the pooled odds ratio.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            interval.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n\\n        Returns\\n        -------\\n        lcb : float\\n            The lower confidence limit.\\n        ucb : float\\n            The upper confidence limit.\\n        \"\n    (lcb, ucb) = self.logodds_pooled_confint(alpha, method=method)\n    lcb = np.exp(lcb)\n    ucb = np.exp(ucb)\n    return (lcb, ucb)"
        ]
    },
    {
        "func_name": "test_equal_odds",
        "original": "def test_equal_odds(self, adjust=False):\n    \"\"\"\n        Test that all odds ratios are identical.\n\n        This is the 'Breslow-Day' testing procedure.\n\n        Parameters\n        ----------\n        adjust : bool\n            Use the 'Tarone' adjustment to achieve the chi^2\n            asymptotic distribution.\n\n        Returns\n        -------\n        A bunch containing the following attributes:\n\n        statistic : float\n            The chi^2 test statistic.\n        p-value : float\n            The p-value for the test.\n        \"\"\"\n    table = self.table\n    r = self.oddsratio_pooled\n    a = 1 - r\n    b = r * (self._apb + self._apc) + self._dma\n    c = -r * self._apb * self._apc\n    dr = np.sqrt(b ** 2 - 4 * a * c)\n    e11 = (-b + dr) / (2 * a)\n    v11 = 1 / e11 + 1 / (self._apc - e11) + 1 / (self._apb - e11) + 1 / (self._dma + e11)\n    v11 = 1 / v11\n    statistic = np.sum((table[0, 0, :] - e11) ** 2 / v11)\n    if adjust:\n        adj = table[0, 0, :].sum() - e11.sum()\n        adj = adj ** 2\n        adj /= np.sum(v11)\n        statistic -= adj\n    pvalue = 1 - stats.chi2.cdf(statistic, table.shape[2] - 1)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b",
        "mutated": [
            "def test_equal_odds(self, adjust=False):\n    if False:\n        i = 10\n    \"\\n        Test that all odds ratios are identical.\\n\\n        This is the 'Breslow-Day' testing procedure.\\n\\n        Parameters\\n        ----------\\n        adjust : bool\\n            Use the 'Tarone' adjustment to achieve the chi^2\\n            asymptotic distribution.\\n\\n        Returns\\n        -------\\n        A bunch containing the following attributes:\\n\\n        statistic : float\\n            The chi^2 test statistic.\\n        p-value : float\\n            The p-value for the test.\\n        \"\n    table = self.table\n    r = self.oddsratio_pooled\n    a = 1 - r\n    b = r * (self._apb + self._apc) + self._dma\n    c = -r * self._apb * self._apc\n    dr = np.sqrt(b ** 2 - 4 * a * c)\n    e11 = (-b + dr) / (2 * a)\n    v11 = 1 / e11 + 1 / (self._apc - e11) + 1 / (self._apb - e11) + 1 / (self._dma + e11)\n    v11 = 1 / v11\n    statistic = np.sum((table[0, 0, :] - e11) ** 2 / v11)\n    if adjust:\n        adj = table[0, 0, :].sum() - e11.sum()\n        adj = adj ** 2\n        adj /= np.sum(v11)\n        statistic -= adj\n    pvalue = 1 - stats.chi2.cdf(statistic, table.shape[2] - 1)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b",
            "def test_equal_odds(self, adjust=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Test that all odds ratios are identical.\\n\\n        This is the 'Breslow-Day' testing procedure.\\n\\n        Parameters\\n        ----------\\n        adjust : bool\\n            Use the 'Tarone' adjustment to achieve the chi^2\\n            asymptotic distribution.\\n\\n        Returns\\n        -------\\n        A bunch containing the following attributes:\\n\\n        statistic : float\\n            The chi^2 test statistic.\\n        p-value : float\\n            The p-value for the test.\\n        \"\n    table = self.table\n    r = self.oddsratio_pooled\n    a = 1 - r\n    b = r * (self._apb + self._apc) + self._dma\n    c = -r * self._apb * self._apc\n    dr = np.sqrt(b ** 2 - 4 * a * c)\n    e11 = (-b + dr) / (2 * a)\n    v11 = 1 / e11 + 1 / (self._apc - e11) + 1 / (self._apb - e11) + 1 / (self._dma + e11)\n    v11 = 1 / v11\n    statistic = np.sum((table[0, 0, :] - e11) ** 2 / v11)\n    if adjust:\n        adj = table[0, 0, :].sum() - e11.sum()\n        adj = adj ** 2\n        adj /= np.sum(v11)\n        statistic -= adj\n    pvalue = 1 - stats.chi2.cdf(statistic, table.shape[2] - 1)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b",
            "def test_equal_odds(self, adjust=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Test that all odds ratios are identical.\\n\\n        This is the 'Breslow-Day' testing procedure.\\n\\n        Parameters\\n        ----------\\n        adjust : bool\\n            Use the 'Tarone' adjustment to achieve the chi^2\\n            asymptotic distribution.\\n\\n        Returns\\n        -------\\n        A bunch containing the following attributes:\\n\\n        statistic : float\\n            The chi^2 test statistic.\\n        p-value : float\\n            The p-value for the test.\\n        \"\n    table = self.table\n    r = self.oddsratio_pooled\n    a = 1 - r\n    b = r * (self._apb + self._apc) + self._dma\n    c = -r * self._apb * self._apc\n    dr = np.sqrt(b ** 2 - 4 * a * c)\n    e11 = (-b + dr) / (2 * a)\n    v11 = 1 / e11 + 1 / (self._apc - e11) + 1 / (self._apb - e11) + 1 / (self._dma + e11)\n    v11 = 1 / v11\n    statistic = np.sum((table[0, 0, :] - e11) ** 2 / v11)\n    if adjust:\n        adj = table[0, 0, :].sum() - e11.sum()\n        adj = adj ** 2\n        adj /= np.sum(v11)\n        statistic -= adj\n    pvalue = 1 - stats.chi2.cdf(statistic, table.shape[2] - 1)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b",
            "def test_equal_odds(self, adjust=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Test that all odds ratios are identical.\\n\\n        This is the 'Breslow-Day' testing procedure.\\n\\n        Parameters\\n        ----------\\n        adjust : bool\\n            Use the 'Tarone' adjustment to achieve the chi^2\\n            asymptotic distribution.\\n\\n        Returns\\n        -------\\n        A bunch containing the following attributes:\\n\\n        statistic : float\\n            The chi^2 test statistic.\\n        p-value : float\\n            The p-value for the test.\\n        \"\n    table = self.table\n    r = self.oddsratio_pooled\n    a = 1 - r\n    b = r * (self._apb + self._apc) + self._dma\n    c = -r * self._apb * self._apc\n    dr = np.sqrt(b ** 2 - 4 * a * c)\n    e11 = (-b + dr) / (2 * a)\n    v11 = 1 / e11 + 1 / (self._apc - e11) + 1 / (self._apb - e11) + 1 / (self._dma + e11)\n    v11 = 1 / v11\n    statistic = np.sum((table[0, 0, :] - e11) ** 2 / v11)\n    if adjust:\n        adj = table[0, 0, :].sum() - e11.sum()\n        adj = adj ** 2\n        adj /= np.sum(v11)\n        statistic -= adj\n    pvalue = 1 - stats.chi2.cdf(statistic, table.shape[2] - 1)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b",
            "def test_equal_odds(self, adjust=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Test that all odds ratios are identical.\\n\\n        This is the 'Breslow-Day' testing procedure.\\n\\n        Parameters\\n        ----------\\n        adjust : bool\\n            Use the 'Tarone' adjustment to achieve the chi^2\\n            asymptotic distribution.\\n\\n        Returns\\n        -------\\n        A bunch containing the following attributes:\\n\\n        statistic : float\\n            The chi^2 test statistic.\\n        p-value : float\\n            The p-value for the test.\\n        \"\n    table = self.table\n    r = self.oddsratio_pooled\n    a = 1 - r\n    b = r * (self._apb + self._apc) + self._dma\n    c = -r * self._apb * self._apc\n    dr = np.sqrt(b ** 2 - 4 * a * c)\n    e11 = (-b + dr) / (2 * a)\n    v11 = 1 / e11 + 1 / (self._apc - e11) + 1 / (self._apb - e11) + 1 / (self._dma + e11)\n    v11 = 1 / v11\n    statistic = np.sum((table[0, 0, :] - e11) ** 2 / v11)\n    if adjust:\n        adj = table[0, 0, :].sum() - e11.sum()\n        adj = adj ** 2\n        adj /= np.sum(v11)\n        statistic -= adj\n    pvalue = 1 - stats.chi2.cdf(statistic, table.shape[2] - 1)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b"
        ]
    },
    {
        "func_name": "fmt",
        "original": "def fmt(x):\n    if isinstance(x, str):\n        return x\n    return float_format % x",
        "mutated": [
            "def fmt(x):\n    if False:\n        i = 10\n    if isinstance(x, str):\n        return x\n    return float_format % x",
            "def fmt(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if isinstance(x, str):\n        return x\n    return float_format % x",
            "def fmt(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if isinstance(x, str):\n        return x\n    return float_format % x",
            "def fmt(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if isinstance(x, str):\n        return x\n    return float_format % x",
            "def fmt(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if isinstance(x, str):\n        return x\n    return float_format % x"
        ]
    },
    {
        "func_name": "summary",
        "original": "def summary(self, alpha=0.05, float_format='%.3f', method='normal'):\n    \"\"\"\n        A summary of all the main results.\n\n        Parameters\n        ----------\n        alpha : float\n            `1 - alpha` is the nominal coverage probability of the\n            confidence intervals.\n        float_format : str\n            Used for formatting numeric values in the summary.\n        method : str\n            The method for producing the confidence interval.  Currently\n            must be 'normal' which uses the normal approximation.\n        \"\"\"\n\n    def fmt(x):\n        if isinstance(x, str):\n            return x\n        return float_format % x\n    (co_lcb, co_ucb) = self.oddsratio_pooled_confint(alpha=alpha, method=method)\n    (clo_lcb, clo_ucb) = self.logodds_pooled_confint(alpha=alpha, method=method)\n    headers = ['Estimate', 'LCB', 'UCB']\n    stubs = ['Pooled odds', 'Pooled log odds', 'Pooled risk ratio', '']\n    data = [[fmt(x) for x in [self.oddsratio_pooled, co_lcb, co_ucb]], [fmt(x) for x in [self.logodds_pooled, clo_lcb, clo_ucb]], [fmt(x) for x in [self.riskratio_pooled, '', '']], ['', '', '']]\n    tab1 = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    headers = ['Statistic', 'P-value', '']\n    stubs = ['Test of OR=1', 'Test constant OR']\n    rslt1 = self.test_null_odds()\n    rslt2 = self.test_equal_odds()\n    data = [[fmt(x) for x in [rslt1.statistic, rslt1.pvalue, '']], [fmt(x) for x in [rslt2.statistic, rslt2.pvalue, '']]]\n    tab2 = iolib.SimpleTable(data, headers, stubs, data_aligns='r')\n    tab1.extend(tab2)\n    headers = ['', '', '']\n    stubs = ['Number of tables', 'Min n', 'Max n', 'Avg n', 'Total n']\n    ss = self.table.sum(0).sum(0)\n    data = [['%d' % self.table.shape[2], '', ''], ['%d' % min(ss), '', ''], ['%d' % max(ss), '', ''], ['%.0f' % np.mean(ss), '', ''], ['%d' % sum(ss), '', '', '']]\n    tab3 = iolib.SimpleTable(data, headers, stubs, data_aligns='r')\n    tab1.extend(tab3)\n    return tab1",
        "mutated": [
            "def summary(self, alpha=0.05, float_format='%.3f', method='normal'):\n    if False:\n        i = 10\n    \"\\n        A summary of all the main results.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence intervals.\\n        float_format : str\\n            Used for formatting numeric values in the summary.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n\n    def fmt(x):\n        if isinstance(x, str):\n            return x\n        return float_format % x\n    (co_lcb, co_ucb) = self.oddsratio_pooled_confint(alpha=alpha, method=method)\n    (clo_lcb, clo_ucb) = self.logodds_pooled_confint(alpha=alpha, method=method)\n    headers = ['Estimate', 'LCB', 'UCB']\n    stubs = ['Pooled odds', 'Pooled log odds', 'Pooled risk ratio', '']\n    data = [[fmt(x) for x in [self.oddsratio_pooled, co_lcb, co_ucb]], [fmt(x) for x in [self.logodds_pooled, clo_lcb, clo_ucb]], [fmt(x) for x in [self.riskratio_pooled, '', '']], ['', '', '']]\n    tab1 = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    headers = ['Statistic', 'P-value', '']\n    stubs = ['Test of OR=1', 'Test constant OR']\n    rslt1 = self.test_null_odds()\n    rslt2 = self.test_equal_odds()\n    data = [[fmt(x) for x in [rslt1.statistic, rslt1.pvalue, '']], [fmt(x) for x in [rslt2.statistic, rslt2.pvalue, '']]]\n    tab2 = iolib.SimpleTable(data, headers, stubs, data_aligns='r')\n    tab1.extend(tab2)\n    headers = ['', '', '']\n    stubs = ['Number of tables', 'Min n', 'Max n', 'Avg n', 'Total n']\n    ss = self.table.sum(0).sum(0)\n    data = [['%d' % self.table.shape[2], '', ''], ['%d' % min(ss), '', ''], ['%d' % max(ss), '', ''], ['%.0f' % np.mean(ss), '', ''], ['%d' % sum(ss), '', '', '']]\n    tab3 = iolib.SimpleTable(data, headers, stubs, data_aligns='r')\n    tab1.extend(tab3)\n    return tab1",
            "def summary(self, alpha=0.05, float_format='%.3f', method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        A summary of all the main results.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence intervals.\\n        float_format : str\\n            Used for formatting numeric values in the summary.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n\n    def fmt(x):\n        if isinstance(x, str):\n            return x\n        return float_format % x\n    (co_lcb, co_ucb) = self.oddsratio_pooled_confint(alpha=alpha, method=method)\n    (clo_lcb, clo_ucb) = self.logodds_pooled_confint(alpha=alpha, method=method)\n    headers = ['Estimate', 'LCB', 'UCB']\n    stubs = ['Pooled odds', 'Pooled log odds', 'Pooled risk ratio', '']\n    data = [[fmt(x) for x in [self.oddsratio_pooled, co_lcb, co_ucb]], [fmt(x) for x in [self.logodds_pooled, clo_lcb, clo_ucb]], [fmt(x) for x in [self.riskratio_pooled, '', '']], ['', '', '']]\n    tab1 = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    headers = ['Statistic', 'P-value', '']\n    stubs = ['Test of OR=1', 'Test constant OR']\n    rslt1 = self.test_null_odds()\n    rslt2 = self.test_equal_odds()\n    data = [[fmt(x) for x in [rslt1.statistic, rslt1.pvalue, '']], [fmt(x) for x in [rslt2.statistic, rslt2.pvalue, '']]]\n    tab2 = iolib.SimpleTable(data, headers, stubs, data_aligns='r')\n    tab1.extend(tab2)\n    headers = ['', '', '']\n    stubs = ['Number of tables', 'Min n', 'Max n', 'Avg n', 'Total n']\n    ss = self.table.sum(0).sum(0)\n    data = [['%d' % self.table.shape[2], '', ''], ['%d' % min(ss), '', ''], ['%d' % max(ss), '', ''], ['%.0f' % np.mean(ss), '', ''], ['%d' % sum(ss), '', '', '']]\n    tab3 = iolib.SimpleTable(data, headers, stubs, data_aligns='r')\n    tab1.extend(tab3)\n    return tab1",
            "def summary(self, alpha=0.05, float_format='%.3f', method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        A summary of all the main results.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence intervals.\\n        float_format : str\\n            Used for formatting numeric values in the summary.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n\n    def fmt(x):\n        if isinstance(x, str):\n            return x\n        return float_format % x\n    (co_lcb, co_ucb) = self.oddsratio_pooled_confint(alpha=alpha, method=method)\n    (clo_lcb, clo_ucb) = self.logodds_pooled_confint(alpha=alpha, method=method)\n    headers = ['Estimate', 'LCB', 'UCB']\n    stubs = ['Pooled odds', 'Pooled log odds', 'Pooled risk ratio', '']\n    data = [[fmt(x) for x in [self.oddsratio_pooled, co_lcb, co_ucb]], [fmt(x) for x in [self.logodds_pooled, clo_lcb, clo_ucb]], [fmt(x) for x in [self.riskratio_pooled, '', '']], ['', '', '']]\n    tab1 = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    headers = ['Statistic', 'P-value', '']\n    stubs = ['Test of OR=1', 'Test constant OR']\n    rslt1 = self.test_null_odds()\n    rslt2 = self.test_equal_odds()\n    data = [[fmt(x) for x in [rslt1.statistic, rslt1.pvalue, '']], [fmt(x) for x in [rslt2.statistic, rslt2.pvalue, '']]]\n    tab2 = iolib.SimpleTable(data, headers, stubs, data_aligns='r')\n    tab1.extend(tab2)\n    headers = ['', '', '']\n    stubs = ['Number of tables', 'Min n', 'Max n', 'Avg n', 'Total n']\n    ss = self.table.sum(0).sum(0)\n    data = [['%d' % self.table.shape[2], '', ''], ['%d' % min(ss), '', ''], ['%d' % max(ss), '', ''], ['%.0f' % np.mean(ss), '', ''], ['%d' % sum(ss), '', '', '']]\n    tab3 = iolib.SimpleTable(data, headers, stubs, data_aligns='r')\n    tab1.extend(tab3)\n    return tab1",
            "def summary(self, alpha=0.05, float_format='%.3f', method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        A summary of all the main results.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence intervals.\\n        float_format : str\\n            Used for formatting numeric values in the summary.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n\n    def fmt(x):\n        if isinstance(x, str):\n            return x\n        return float_format % x\n    (co_lcb, co_ucb) = self.oddsratio_pooled_confint(alpha=alpha, method=method)\n    (clo_lcb, clo_ucb) = self.logodds_pooled_confint(alpha=alpha, method=method)\n    headers = ['Estimate', 'LCB', 'UCB']\n    stubs = ['Pooled odds', 'Pooled log odds', 'Pooled risk ratio', '']\n    data = [[fmt(x) for x in [self.oddsratio_pooled, co_lcb, co_ucb]], [fmt(x) for x in [self.logodds_pooled, clo_lcb, clo_ucb]], [fmt(x) for x in [self.riskratio_pooled, '', '']], ['', '', '']]\n    tab1 = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    headers = ['Statistic', 'P-value', '']\n    stubs = ['Test of OR=1', 'Test constant OR']\n    rslt1 = self.test_null_odds()\n    rslt2 = self.test_equal_odds()\n    data = [[fmt(x) for x in [rslt1.statistic, rslt1.pvalue, '']], [fmt(x) for x in [rslt2.statistic, rslt2.pvalue, '']]]\n    tab2 = iolib.SimpleTable(data, headers, stubs, data_aligns='r')\n    tab1.extend(tab2)\n    headers = ['', '', '']\n    stubs = ['Number of tables', 'Min n', 'Max n', 'Avg n', 'Total n']\n    ss = self.table.sum(0).sum(0)\n    data = [['%d' % self.table.shape[2], '', ''], ['%d' % min(ss), '', ''], ['%d' % max(ss), '', ''], ['%.0f' % np.mean(ss), '', ''], ['%d' % sum(ss), '', '', '']]\n    tab3 = iolib.SimpleTable(data, headers, stubs, data_aligns='r')\n    tab1.extend(tab3)\n    return tab1",
            "def summary(self, alpha=0.05, float_format='%.3f', method='normal'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        A summary of all the main results.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the nominal coverage probability of the\\n            confidence intervals.\\n        float_format : str\\n            Used for formatting numeric values in the summary.\\n        method : str\\n            The method for producing the confidence interval.  Currently\\n            must be 'normal' which uses the normal approximation.\\n        \"\n\n    def fmt(x):\n        if isinstance(x, str):\n            return x\n        return float_format % x\n    (co_lcb, co_ucb) = self.oddsratio_pooled_confint(alpha=alpha, method=method)\n    (clo_lcb, clo_ucb) = self.logodds_pooled_confint(alpha=alpha, method=method)\n    headers = ['Estimate', 'LCB', 'UCB']\n    stubs = ['Pooled odds', 'Pooled log odds', 'Pooled risk ratio', '']\n    data = [[fmt(x) for x in [self.oddsratio_pooled, co_lcb, co_ucb]], [fmt(x) for x in [self.logodds_pooled, clo_lcb, clo_ucb]], [fmt(x) for x in [self.riskratio_pooled, '', '']], ['', '', '']]\n    tab1 = iolib.SimpleTable(data, headers, stubs, data_aligns='r', table_dec_above='')\n    headers = ['Statistic', 'P-value', '']\n    stubs = ['Test of OR=1', 'Test constant OR']\n    rslt1 = self.test_null_odds()\n    rslt2 = self.test_equal_odds()\n    data = [[fmt(x) for x in [rslt1.statistic, rslt1.pvalue, '']], [fmt(x) for x in [rslt2.statistic, rslt2.pvalue, '']]]\n    tab2 = iolib.SimpleTable(data, headers, stubs, data_aligns='r')\n    tab1.extend(tab2)\n    headers = ['', '', '']\n    stubs = ['Number of tables', 'Min n', 'Max n', 'Avg n', 'Total n']\n    ss = self.table.sum(0).sum(0)\n    data = [['%d' % self.table.shape[2], '', ''], ['%d' % min(ss), '', ''], ['%d' % max(ss), '', ''], ['%.0f' % np.mean(ss), '', ''], ['%d' % sum(ss), '', '', '']]\n    tab3 = iolib.SimpleTable(data, headers, stubs, data_aligns='r')\n    tab1.extend(tab3)\n    return tab1"
        ]
    },
    {
        "func_name": "mcnemar",
        "original": "def mcnemar(table, exact=True, correction=True):\n    \"\"\"\n    McNemar test of homogeneity.\n\n    Parameters\n    ----------\n    table : array_like\n        A square contingency table.\n    exact : bool\n        If exact is true, then the binomial distribution will be used.\n        If exact is false, then the chisquare distribution will be\n        used, which is the approximation to the distribution of the\n        test statistic for large sample sizes.\n    correction : bool\n        If true, then a continuity correction is used for the chisquare\n        distribution (if exact is false.)\n\n    Returns\n    -------\n    A bunch with attributes:\n\n    statistic : float or int, array\n        The test statistic is the chisquare statistic if exact is\n        false. If the exact binomial distribution is used, then this\n        contains the min(n1, n2), where n1, n2 are cases that are zero\n        in one sample but one in the other sample.\n    pvalue : float or array\n        p-value of the null hypothesis of equal marginal distributions.\n\n    Notes\n    -----\n    This is a special case of Cochran's Q test, and of the homogeneity\n    test. The results when the chisquare distribution is used are\n    identical, except for continuity correction.\n    \"\"\"\n    table = _make_df_square(table)\n    table = np.asarray(table, dtype=np.float64)\n    (n1, n2) = (table[0, 1], table[1, 0])\n    if exact:\n        statistic = np.minimum(n1, n2)\n        int_sum = int(n1 + n2)\n        if int_sum != n1 + n2:\n            raise ValueError('exact can only be used with tables containing integers.')\n        pvalue = stats.binom.cdf(statistic, int_sum, 0.5) * 2\n        pvalue = np.minimum(pvalue, 1)\n    else:\n        corr = int(correction)\n        statistic = (np.abs(n1 - n2) - corr) ** 2 / (1.0 * (n1 + n2))\n        df = 1\n        pvalue = stats.chi2.sf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b",
        "mutated": [
            "def mcnemar(table, exact=True, correction=True):\n    if False:\n        i = 10\n    \"\\n    McNemar test of homogeneity.\\n\\n    Parameters\\n    ----------\\n    table : array_like\\n        A square contingency table.\\n    exact : bool\\n        If exact is true, then the binomial distribution will be used.\\n        If exact is false, then the chisquare distribution will be\\n        used, which is the approximation to the distribution of the\\n        test statistic for large sample sizes.\\n    correction : bool\\n        If true, then a continuity correction is used for the chisquare\\n        distribution (if exact is false.)\\n\\n    Returns\\n    -------\\n    A bunch with attributes:\\n\\n    statistic : float or int, array\\n        The test statistic is the chisquare statistic if exact is\\n        false. If the exact binomial distribution is used, then this\\n        contains the min(n1, n2), where n1, n2 are cases that are zero\\n        in one sample but one in the other sample.\\n    pvalue : float or array\\n        p-value of the null hypothesis of equal marginal distributions.\\n\\n    Notes\\n    -----\\n    This is a special case of Cochran's Q test, and of the homogeneity\\n    test. The results when the chisquare distribution is used are\\n    identical, except for continuity correction.\\n    \"\n    table = _make_df_square(table)\n    table = np.asarray(table, dtype=np.float64)\n    (n1, n2) = (table[0, 1], table[1, 0])\n    if exact:\n        statistic = np.minimum(n1, n2)\n        int_sum = int(n1 + n2)\n        if int_sum != n1 + n2:\n            raise ValueError('exact can only be used with tables containing integers.')\n        pvalue = stats.binom.cdf(statistic, int_sum, 0.5) * 2\n        pvalue = np.minimum(pvalue, 1)\n    else:\n        corr = int(correction)\n        statistic = (np.abs(n1 - n2) - corr) ** 2 / (1.0 * (n1 + n2))\n        df = 1\n        pvalue = stats.chi2.sf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b",
            "def mcnemar(table, exact=True, correction=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    McNemar test of homogeneity.\\n\\n    Parameters\\n    ----------\\n    table : array_like\\n        A square contingency table.\\n    exact : bool\\n        If exact is true, then the binomial distribution will be used.\\n        If exact is false, then the chisquare distribution will be\\n        used, which is the approximation to the distribution of the\\n        test statistic for large sample sizes.\\n    correction : bool\\n        If true, then a continuity correction is used for the chisquare\\n        distribution (if exact is false.)\\n\\n    Returns\\n    -------\\n    A bunch with attributes:\\n\\n    statistic : float or int, array\\n        The test statistic is the chisquare statistic if exact is\\n        false. If the exact binomial distribution is used, then this\\n        contains the min(n1, n2), where n1, n2 are cases that are zero\\n        in one sample but one in the other sample.\\n    pvalue : float or array\\n        p-value of the null hypothesis of equal marginal distributions.\\n\\n    Notes\\n    -----\\n    This is a special case of Cochran's Q test, and of the homogeneity\\n    test. The results when the chisquare distribution is used are\\n    identical, except for continuity correction.\\n    \"\n    table = _make_df_square(table)\n    table = np.asarray(table, dtype=np.float64)\n    (n1, n2) = (table[0, 1], table[1, 0])\n    if exact:\n        statistic = np.minimum(n1, n2)\n        int_sum = int(n1 + n2)\n        if int_sum != n1 + n2:\n            raise ValueError('exact can only be used with tables containing integers.')\n        pvalue = stats.binom.cdf(statistic, int_sum, 0.5) * 2\n        pvalue = np.minimum(pvalue, 1)\n    else:\n        corr = int(correction)\n        statistic = (np.abs(n1 - n2) - corr) ** 2 / (1.0 * (n1 + n2))\n        df = 1\n        pvalue = stats.chi2.sf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b",
            "def mcnemar(table, exact=True, correction=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    McNemar test of homogeneity.\\n\\n    Parameters\\n    ----------\\n    table : array_like\\n        A square contingency table.\\n    exact : bool\\n        If exact is true, then the binomial distribution will be used.\\n        If exact is false, then the chisquare distribution will be\\n        used, which is the approximation to the distribution of the\\n        test statistic for large sample sizes.\\n    correction : bool\\n        If true, then a continuity correction is used for the chisquare\\n        distribution (if exact is false.)\\n\\n    Returns\\n    -------\\n    A bunch with attributes:\\n\\n    statistic : float or int, array\\n        The test statistic is the chisquare statistic if exact is\\n        false. If the exact binomial distribution is used, then this\\n        contains the min(n1, n2), where n1, n2 are cases that are zero\\n        in one sample but one in the other sample.\\n    pvalue : float or array\\n        p-value of the null hypothesis of equal marginal distributions.\\n\\n    Notes\\n    -----\\n    This is a special case of Cochran's Q test, and of the homogeneity\\n    test. The results when the chisquare distribution is used are\\n    identical, except for continuity correction.\\n    \"\n    table = _make_df_square(table)\n    table = np.asarray(table, dtype=np.float64)\n    (n1, n2) = (table[0, 1], table[1, 0])\n    if exact:\n        statistic = np.minimum(n1, n2)\n        int_sum = int(n1 + n2)\n        if int_sum != n1 + n2:\n            raise ValueError('exact can only be used with tables containing integers.')\n        pvalue = stats.binom.cdf(statistic, int_sum, 0.5) * 2\n        pvalue = np.minimum(pvalue, 1)\n    else:\n        corr = int(correction)\n        statistic = (np.abs(n1 - n2) - corr) ** 2 / (1.0 * (n1 + n2))\n        df = 1\n        pvalue = stats.chi2.sf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b",
            "def mcnemar(table, exact=True, correction=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    McNemar test of homogeneity.\\n\\n    Parameters\\n    ----------\\n    table : array_like\\n        A square contingency table.\\n    exact : bool\\n        If exact is true, then the binomial distribution will be used.\\n        If exact is false, then the chisquare distribution will be\\n        used, which is the approximation to the distribution of the\\n        test statistic for large sample sizes.\\n    correction : bool\\n        If true, then a continuity correction is used for the chisquare\\n        distribution (if exact is false.)\\n\\n    Returns\\n    -------\\n    A bunch with attributes:\\n\\n    statistic : float or int, array\\n        The test statistic is the chisquare statistic if exact is\\n        false. If the exact binomial distribution is used, then this\\n        contains the min(n1, n2), where n1, n2 are cases that are zero\\n        in one sample but one in the other sample.\\n    pvalue : float or array\\n        p-value of the null hypothesis of equal marginal distributions.\\n\\n    Notes\\n    -----\\n    This is a special case of Cochran's Q test, and of the homogeneity\\n    test. The results when the chisquare distribution is used are\\n    identical, except for continuity correction.\\n    \"\n    table = _make_df_square(table)\n    table = np.asarray(table, dtype=np.float64)\n    (n1, n2) = (table[0, 1], table[1, 0])\n    if exact:\n        statistic = np.minimum(n1, n2)\n        int_sum = int(n1 + n2)\n        if int_sum != n1 + n2:\n            raise ValueError('exact can only be used with tables containing integers.')\n        pvalue = stats.binom.cdf(statistic, int_sum, 0.5) * 2\n        pvalue = np.minimum(pvalue, 1)\n    else:\n        corr = int(correction)\n        statistic = (np.abs(n1 - n2) - corr) ** 2 / (1.0 * (n1 + n2))\n        df = 1\n        pvalue = stats.chi2.sf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b",
            "def mcnemar(table, exact=True, correction=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    McNemar test of homogeneity.\\n\\n    Parameters\\n    ----------\\n    table : array_like\\n        A square contingency table.\\n    exact : bool\\n        If exact is true, then the binomial distribution will be used.\\n        If exact is false, then the chisquare distribution will be\\n        used, which is the approximation to the distribution of the\\n        test statistic for large sample sizes.\\n    correction : bool\\n        If true, then a continuity correction is used for the chisquare\\n        distribution (if exact is false.)\\n\\n    Returns\\n    -------\\n    A bunch with attributes:\\n\\n    statistic : float or int, array\\n        The test statistic is the chisquare statistic if exact is\\n        false. If the exact binomial distribution is used, then this\\n        contains the min(n1, n2), where n1, n2 are cases that are zero\\n        in one sample but one in the other sample.\\n    pvalue : float or array\\n        p-value of the null hypothesis of equal marginal distributions.\\n\\n    Notes\\n    -----\\n    This is a special case of Cochran's Q test, and of the homogeneity\\n    test. The results when the chisquare distribution is used are\\n    identical, except for continuity correction.\\n    \"\n    table = _make_df_square(table)\n    table = np.asarray(table, dtype=np.float64)\n    (n1, n2) = (table[0, 1], table[1, 0])\n    if exact:\n        statistic = np.minimum(n1, n2)\n        int_sum = int(n1 + n2)\n        if int_sum != n1 + n2:\n            raise ValueError('exact can only be used with tables containing integers.')\n        pvalue = stats.binom.cdf(statistic, int_sum, 0.5) * 2\n        pvalue = np.minimum(pvalue, 1)\n    else:\n        corr = int(correction)\n        statistic = (np.abs(n1 - n2) - corr) ** 2 / (1.0 * (n1 + n2))\n        df = 1\n        pvalue = stats.chi2.sf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b"
        ]
    },
    {
        "func_name": "cochrans_q",
        "original": "def cochrans_q(x, return_object=True):\n    \"\"\"\n    Cochran's Q test for identical binomial proportions.\n\n    Parameters\n    ----------\n    x : array_like, 2d (N, k)\n        data with N cases and k variables\n    return_object : bool\n        Return values as bunch instead of as individual values.\n\n    Returns\n    -------\n    Returns a bunch containing the following attributes, or the\n    individual values according to the value of `return_object`.\n\n    statistic : float\n       test statistic\n    pvalue : float\n       pvalue from the chisquare distribution\n\n    Notes\n    -----\n    Cochran's Q is a k-sample extension of the McNemar test. If there\n    are only two groups, then Cochran's Q test and the McNemar test\n    are equivalent.\n\n    The procedure tests that the probability of success is the same\n    for every group.  The alternative hypothesis is that at least two\n    groups have a different probability of success.\n\n    In Wikipedia terminology, rows are blocks and columns are\n    treatments.  The number of rows N, should be large for the\n    chisquare distribution to be a good approximation.\n\n    The Null hypothesis of the test is that all treatments have the\n    same effect.\n\n    References\n    ----------\n    https://en.wikipedia.org/wiki/Cochran_test\n    SAS Manual for NPAR TESTS\n    \"\"\"\n    x = np.asarray(x, dtype=np.float64)\n    gruni = np.unique(x)\n    (N, k) = x.shape\n    count_row_success = (x == gruni[-1]).sum(1, float)\n    count_col_success = (x == gruni[-1]).sum(0, float)\n    count_row_ss = count_row_success.sum()\n    count_col_ss = count_col_success.sum()\n    assert count_row_ss == count_col_ss\n    q_stat = (k - 1) * (k * np.sum(count_col_success ** 2) - count_col_ss ** 2) / (k * count_row_ss - np.sum(count_row_success ** 2))\n    df = k - 1\n    pvalue = stats.chi2.sf(q_stat, df)\n    if return_object:\n        b = _Bunch()\n        b.statistic = q_stat\n        b.df = df\n        b.pvalue = pvalue\n        return b\n    return (q_stat, pvalue, df)",
        "mutated": [
            "def cochrans_q(x, return_object=True):\n    if False:\n        i = 10\n    \"\\n    Cochran's Q test for identical binomial proportions.\\n\\n    Parameters\\n    ----------\\n    x : array_like, 2d (N, k)\\n        data with N cases and k variables\\n    return_object : bool\\n        Return values as bunch instead of as individual values.\\n\\n    Returns\\n    -------\\n    Returns a bunch containing the following attributes, or the\\n    individual values according to the value of `return_object`.\\n\\n    statistic : float\\n       test statistic\\n    pvalue : float\\n       pvalue from the chisquare distribution\\n\\n    Notes\\n    -----\\n    Cochran's Q is a k-sample extension of the McNemar test. If there\\n    are only two groups, then Cochran's Q test and the McNemar test\\n    are equivalent.\\n\\n    The procedure tests that the probability of success is the same\\n    for every group.  The alternative hypothesis is that at least two\\n    groups have a different probability of success.\\n\\n    In Wikipedia terminology, rows are blocks and columns are\\n    treatments.  The number of rows N, should be large for the\\n    chisquare distribution to be a good approximation.\\n\\n    The Null hypothesis of the test is that all treatments have the\\n    same effect.\\n\\n    References\\n    ----------\\n    https://en.wikipedia.org/wiki/Cochran_test\\n    SAS Manual for NPAR TESTS\\n    \"\n    x = np.asarray(x, dtype=np.float64)\n    gruni = np.unique(x)\n    (N, k) = x.shape\n    count_row_success = (x == gruni[-1]).sum(1, float)\n    count_col_success = (x == gruni[-1]).sum(0, float)\n    count_row_ss = count_row_success.sum()\n    count_col_ss = count_col_success.sum()\n    assert count_row_ss == count_col_ss\n    q_stat = (k - 1) * (k * np.sum(count_col_success ** 2) - count_col_ss ** 2) / (k * count_row_ss - np.sum(count_row_success ** 2))\n    df = k - 1\n    pvalue = stats.chi2.sf(q_stat, df)\n    if return_object:\n        b = _Bunch()\n        b.statistic = q_stat\n        b.df = df\n        b.pvalue = pvalue\n        return b\n    return (q_stat, pvalue, df)",
            "def cochrans_q(x, return_object=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Cochran's Q test for identical binomial proportions.\\n\\n    Parameters\\n    ----------\\n    x : array_like, 2d (N, k)\\n        data with N cases and k variables\\n    return_object : bool\\n        Return values as bunch instead of as individual values.\\n\\n    Returns\\n    -------\\n    Returns a bunch containing the following attributes, or the\\n    individual values according to the value of `return_object`.\\n\\n    statistic : float\\n       test statistic\\n    pvalue : float\\n       pvalue from the chisquare distribution\\n\\n    Notes\\n    -----\\n    Cochran's Q is a k-sample extension of the McNemar test. If there\\n    are only two groups, then Cochran's Q test and the McNemar test\\n    are equivalent.\\n\\n    The procedure tests that the probability of success is the same\\n    for every group.  The alternative hypothesis is that at least two\\n    groups have a different probability of success.\\n\\n    In Wikipedia terminology, rows are blocks and columns are\\n    treatments.  The number of rows N, should be large for the\\n    chisquare distribution to be a good approximation.\\n\\n    The Null hypothesis of the test is that all treatments have the\\n    same effect.\\n\\n    References\\n    ----------\\n    https://en.wikipedia.org/wiki/Cochran_test\\n    SAS Manual for NPAR TESTS\\n    \"\n    x = np.asarray(x, dtype=np.float64)\n    gruni = np.unique(x)\n    (N, k) = x.shape\n    count_row_success = (x == gruni[-1]).sum(1, float)\n    count_col_success = (x == gruni[-1]).sum(0, float)\n    count_row_ss = count_row_success.sum()\n    count_col_ss = count_col_success.sum()\n    assert count_row_ss == count_col_ss\n    q_stat = (k - 1) * (k * np.sum(count_col_success ** 2) - count_col_ss ** 2) / (k * count_row_ss - np.sum(count_row_success ** 2))\n    df = k - 1\n    pvalue = stats.chi2.sf(q_stat, df)\n    if return_object:\n        b = _Bunch()\n        b.statistic = q_stat\n        b.df = df\n        b.pvalue = pvalue\n        return b\n    return (q_stat, pvalue, df)",
            "def cochrans_q(x, return_object=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Cochran's Q test for identical binomial proportions.\\n\\n    Parameters\\n    ----------\\n    x : array_like, 2d (N, k)\\n        data with N cases and k variables\\n    return_object : bool\\n        Return values as bunch instead of as individual values.\\n\\n    Returns\\n    -------\\n    Returns a bunch containing the following attributes, or the\\n    individual values according to the value of `return_object`.\\n\\n    statistic : float\\n       test statistic\\n    pvalue : float\\n       pvalue from the chisquare distribution\\n\\n    Notes\\n    -----\\n    Cochran's Q is a k-sample extension of the McNemar test. If there\\n    are only two groups, then Cochran's Q test and the McNemar test\\n    are equivalent.\\n\\n    The procedure tests that the probability of success is the same\\n    for every group.  The alternative hypothesis is that at least two\\n    groups have a different probability of success.\\n\\n    In Wikipedia terminology, rows are blocks and columns are\\n    treatments.  The number of rows N, should be large for the\\n    chisquare distribution to be a good approximation.\\n\\n    The Null hypothesis of the test is that all treatments have the\\n    same effect.\\n\\n    References\\n    ----------\\n    https://en.wikipedia.org/wiki/Cochran_test\\n    SAS Manual for NPAR TESTS\\n    \"\n    x = np.asarray(x, dtype=np.float64)\n    gruni = np.unique(x)\n    (N, k) = x.shape\n    count_row_success = (x == gruni[-1]).sum(1, float)\n    count_col_success = (x == gruni[-1]).sum(0, float)\n    count_row_ss = count_row_success.sum()\n    count_col_ss = count_col_success.sum()\n    assert count_row_ss == count_col_ss\n    q_stat = (k - 1) * (k * np.sum(count_col_success ** 2) - count_col_ss ** 2) / (k * count_row_ss - np.sum(count_row_success ** 2))\n    df = k - 1\n    pvalue = stats.chi2.sf(q_stat, df)\n    if return_object:\n        b = _Bunch()\n        b.statistic = q_stat\n        b.df = df\n        b.pvalue = pvalue\n        return b\n    return (q_stat, pvalue, df)",
            "def cochrans_q(x, return_object=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Cochran's Q test for identical binomial proportions.\\n\\n    Parameters\\n    ----------\\n    x : array_like, 2d (N, k)\\n        data with N cases and k variables\\n    return_object : bool\\n        Return values as bunch instead of as individual values.\\n\\n    Returns\\n    -------\\n    Returns a bunch containing the following attributes, or the\\n    individual values according to the value of `return_object`.\\n\\n    statistic : float\\n       test statistic\\n    pvalue : float\\n       pvalue from the chisquare distribution\\n\\n    Notes\\n    -----\\n    Cochran's Q is a k-sample extension of the McNemar test. If there\\n    are only two groups, then Cochran's Q test and the McNemar test\\n    are equivalent.\\n\\n    The procedure tests that the probability of success is the same\\n    for every group.  The alternative hypothesis is that at least two\\n    groups have a different probability of success.\\n\\n    In Wikipedia terminology, rows are blocks and columns are\\n    treatments.  The number of rows N, should be large for the\\n    chisquare distribution to be a good approximation.\\n\\n    The Null hypothesis of the test is that all treatments have the\\n    same effect.\\n\\n    References\\n    ----------\\n    https://en.wikipedia.org/wiki/Cochran_test\\n    SAS Manual for NPAR TESTS\\n    \"\n    x = np.asarray(x, dtype=np.float64)\n    gruni = np.unique(x)\n    (N, k) = x.shape\n    count_row_success = (x == gruni[-1]).sum(1, float)\n    count_col_success = (x == gruni[-1]).sum(0, float)\n    count_row_ss = count_row_success.sum()\n    count_col_ss = count_col_success.sum()\n    assert count_row_ss == count_col_ss\n    q_stat = (k - 1) * (k * np.sum(count_col_success ** 2) - count_col_ss ** 2) / (k * count_row_ss - np.sum(count_row_success ** 2))\n    df = k - 1\n    pvalue = stats.chi2.sf(q_stat, df)\n    if return_object:\n        b = _Bunch()\n        b.statistic = q_stat\n        b.df = df\n        b.pvalue = pvalue\n        return b\n    return (q_stat, pvalue, df)",
            "def cochrans_q(x, return_object=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Cochran's Q test for identical binomial proportions.\\n\\n    Parameters\\n    ----------\\n    x : array_like, 2d (N, k)\\n        data with N cases and k variables\\n    return_object : bool\\n        Return values as bunch instead of as individual values.\\n\\n    Returns\\n    -------\\n    Returns a bunch containing the following attributes, or the\\n    individual values according to the value of `return_object`.\\n\\n    statistic : float\\n       test statistic\\n    pvalue : float\\n       pvalue from the chisquare distribution\\n\\n    Notes\\n    -----\\n    Cochran's Q is a k-sample extension of the McNemar test. If there\\n    are only two groups, then Cochran's Q test and the McNemar test\\n    are equivalent.\\n\\n    The procedure tests that the probability of success is the same\\n    for every group.  The alternative hypothesis is that at least two\\n    groups have a different probability of success.\\n\\n    In Wikipedia terminology, rows are blocks and columns are\\n    treatments.  The number of rows N, should be large for the\\n    chisquare distribution to be a good approximation.\\n\\n    The Null hypothesis of the test is that all treatments have the\\n    same effect.\\n\\n    References\\n    ----------\\n    https://en.wikipedia.org/wiki/Cochran_test\\n    SAS Manual for NPAR TESTS\\n    \"\n    x = np.asarray(x, dtype=np.float64)\n    gruni = np.unique(x)\n    (N, k) = x.shape\n    count_row_success = (x == gruni[-1]).sum(1, float)\n    count_col_success = (x == gruni[-1]).sum(0, float)\n    count_row_ss = count_row_success.sum()\n    count_col_ss = count_col_success.sum()\n    assert count_row_ss == count_col_ss\n    q_stat = (k - 1) * (k * np.sum(count_col_success ** 2) - count_col_ss ** 2) / (k * count_row_ss - np.sum(count_row_success ** 2))\n    df = k - 1\n    pvalue = stats.chi2.sf(q_stat, df)\n    if return_object:\n        b = _Bunch()\n        b.statistic = q_stat\n        b.df = df\n        b.pvalue = pvalue\n        return b\n    return (q_stat, pvalue, df)"
        ]
    }
]