[
    {
        "func_name": "__init__",
        "original": "def __init__(self, file_time, process_time, batch_size, name):\n    self.data = torch.randn(256, 256)\n    self.file_time = file_time\n    self.process_time = process_time\n    self.batch_size = batch_size\n    self.path = osp.join(osp.dirname(__file__), '../traj_files/{}/data'.format(name))\n    self.file_list = os.listdir(self.path)\n    self.file_sequence = random.sample(range(0, len(self.file_list)), len(self.file_list))\n    self.i = 0",
        "mutated": [
            "def __init__(self, file_time, process_time, batch_size, name):\n    if False:\n        i = 10\n    self.data = torch.randn(256, 256)\n    self.file_time = file_time\n    self.process_time = process_time\n    self.batch_size = batch_size\n    self.path = osp.join(osp.dirname(__file__), '../traj_files/{}/data'.format(name))\n    self.file_list = os.listdir(self.path)\n    self.file_sequence = random.sample(range(0, len(self.file_list)), len(self.file_list))\n    self.i = 0",
            "def __init__(self, file_time, process_time, batch_size, name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.data = torch.randn(256, 256)\n    self.file_time = file_time\n    self.process_time = process_time\n    self.batch_size = batch_size\n    self.path = osp.join(osp.dirname(__file__), '../traj_files/{}/data'.format(name))\n    self.file_list = os.listdir(self.path)\n    self.file_sequence = random.sample(range(0, len(self.file_list)), len(self.file_list))\n    self.i = 0",
            "def __init__(self, file_time, process_time, batch_size, name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.data = torch.randn(256, 256)\n    self.file_time = file_time\n    self.process_time = process_time\n    self.batch_size = batch_size\n    self.path = osp.join(osp.dirname(__file__), '../traj_files/{}/data'.format(name))\n    self.file_list = os.listdir(self.path)\n    self.file_sequence = random.sample(range(0, len(self.file_list)), len(self.file_list))\n    self.i = 0",
            "def __init__(self, file_time, process_time, batch_size, name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.data = torch.randn(256, 256)\n    self.file_time = file_time\n    self.process_time = process_time\n    self.batch_size = batch_size\n    self.path = osp.join(osp.dirname(__file__), '../traj_files/{}/data'.format(name))\n    self.file_list = os.listdir(self.path)\n    self.file_sequence = random.sample(range(0, len(self.file_list)), len(self.file_list))\n    self.i = 0",
            "def __init__(self, file_time, process_time, batch_size, name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.data = torch.randn(256, 256)\n    self.file_time = file_time\n    self.process_time = process_time\n    self.batch_size = batch_size\n    self.path = osp.join(osp.dirname(__file__), '../traj_files/{}/data'.format(name))\n    self.file_list = os.listdir(self.path)\n    self.file_sequence = random.sample(range(0, len(self.file_list)), len(self.file_list))\n    self.i = 0"
        ]
    },
    {
        "func_name": "__len__",
        "original": "def __len__(self):\n    return self.batch_size * max_iter * 2",
        "mutated": [
            "def __len__(self):\n    if False:\n        i = 10\n    return self.batch_size * max_iter * 2",
            "def __len__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return self.batch_size * max_iter * 2",
            "def __len__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return self.batch_size * max_iter * 2",
            "def __len__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return self.batch_size * max_iter * 2",
            "def __len__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return self.batch_size * max_iter * 2"
        ]
    },
    {
        "func_name": "__getitem__",
        "original": "def __getitem__(self, idx):\n    try:\n        s = read_file(osp.join(self.path, self.file_list[self.file_sequence[self.i]]))\n    except:\n        print('file read meets an error')\n        time.sleep(self.file_time)\n    self.i = (self.i + 1) % len(self.file_list)\n    time.sleep(self.process_time)\n    return [self.data, idx]",
        "mutated": [
            "def __getitem__(self, idx):\n    if False:\n        i = 10\n    try:\n        s = read_file(osp.join(self.path, self.file_list[self.file_sequence[self.i]]))\n    except:\n        print('file read meets an error')\n        time.sleep(self.file_time)\n    self.i = (self.i + 1) % len(self.file_list)\n    time.sleep(self.process_time)\n    return [self.data, idx]",
            "def __getitem__(self, idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    try:\n        s = read_file(osp.join(self.path, self.file_list[self.file_sequence[self.i]]))\n    except:\n        print('file read meets an error')\n        time.sleep(self.file_time)\n    self.i = (self.i + 1) % len(self.file_list)\n    time.sleep(self.process_time)\n    return [self.data, idx]",
            "def __getitem__(self, idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    try:\n        s = read_file(osp.join(self.path, self.file_list[self.file_sequence[self.i]]))\n    except:\n        print('file read meets an error')\n        time.sleep(self.file_time)\n    self.i = (self.i + 1) % len(self.file_list)\n    time.sleep(self.process_time)\n    return [self.data, idx]",
            "def __getitem__(self, idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    try:\n        s = read_file(osp.join(self.path, self.file_list[self.file_sequence[self.i]]))\n    except:\n        print('file read meets an error')\n        time.sleep(self.file_time)\n    self.i = (self.i + 1) % len(self.file_list)\n    time.sleep(self.process_time)\n    return [self.data, idx]",
            "def __getitem__(self, idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    try:\n        s = read_file(osp.join(self.path, self.file_list[self.file_sequence[self.i]]))\n    except:\n        print('file read meets an error')\n        time.sleep(self.file_time)\n    self.i = (self.i + 1) % len(self.file_list)\n    time.sleep(self.process_time)\n    return [self.data, idx]"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, infer_time):\n    super().__init__()\n    self.main = [nn.Linear(256, 256) for _ in range(10)]\n    self.main = nn.Sequential(*self.main)\n    self.infer_time = infer_time",
        "mutated": [
            "def __init__(self, infer_time):\n    if False:\n        i = 10\n    super().__init__()\n    self.main = [nn.Linear(256, 256) for _ in range(10)]\n    self.main = nn.Sequential(*self.main)\n    self.infer_time = infer_time",
            "def __init__(self, infer_time):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super().__init__()\n    self.main = [nn.Linear(256, 256) for _ in range(10)]\n    self.main = nn.Sequential(*self.main)\n    self.infer_time = infer_time",
            "def __init__(self, infer_time):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super().__init__()\n    self.main = [nn.Linear(256, 256) for _ in range(10)]\n    self.main = nn.Sequential(*self.main)\n    self.infer_time = infer_time",
            "def __init__(self, infer_time):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super().__init__()\n    self.main = [nn.Linear(256, 256) for _ in range(10)]\n    self.main = nn.Sequential(*self.main)\n    self.infer_time = infer_time",
            "def __init__(self, infer_time):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super().__init__()\n    self.main = [nn.Linear(256, 256) for _ in range(10)]\n    self.main = nn.Sequential(*self.main)\n    self.infer_time = infer_time"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, x):\n    idx = x[1]\n    time.sleep(self.infer_time)\n    return [x, idx]",
        "mutated": [
            "def forward(self, x):\n    if False:\n        i = 10\n    idx = x[1]\n    time.sleep(self.infer_time)\n    return [x, idx]",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    idx = x[1]\n    time.sleep(self.infer_time)\n    return [x, idx]",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    idx = x[1]\n    time.sleep(self.infer_time)\n    return [x, idx]",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    idx = x[1]\n    time.sleep(self.infer_time)\n    return [x, idx]",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    idx = x[1]\n    time.sleep(self.infer_time)\n    return [x, idx]"
        ]
    },
    {
        "func_name": "data_source_fn",
        "original": "def data_source_fn(batch_size):\n    return [partial(dataset.__getitem__, idx=i) for i in range(batch_size)]",
        "mutated": [
            "def data_source_fn(batch_size):\n    if False:\n        i = 10\n    return [partial(dataset.__getitem__, idx=i) for i in range(batch_size)]",
            "def data_source_fn(batch_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return [partial(dataset.__getitem__, idx=i) for i in range(batch_size)]",
            "def data_source_fn(batch_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return [partial(dataset.__getitem__, idx=i) for i in range(batch_size)]",
            "def data_source_fn(batch_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return [partial(dataset.__getitem__, idx=i) for i in range(batch_size)]",
            "def data_source_fn(batch_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return [partial(dataset.__getitem__, idx=i) for i in range(batch_size)]"
        ]
    },
    {
        "func_name": "get_data_source",
        "original": "def get_data_source(dataset):\n\n    def data_source_fn(batch_size):\n        return [partial(dataset.__getitem__, idx=i) for i in range(batch_size)]\n    return data_source_fn",
        "mutated": [
            "def get_data_source(dataset):\n    if False:\n        i = 10\n\n    def data_source_fn(batch_size):\n        return [partial(dataset.__getitem__, idx=i) for i in range(batch_size)]\n    return data_source_fn",
            "def get_data_source(dataset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n\n    def data_source_fn(batch_size):\n        return [partial(dataset.__getitem__, idx=i) for i in range(batch_size)]\n    return data_source_fn",
            "def get_data_source(dataset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n    def data_source_fn(batch_size):\n        return [partial(dataset.__getitem__, idx=i) for i in range(batch_size)]\n    return data_source_fn",
            "def get_data_source(dataset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n\n    def data_source_fn(batch_size):\n        return [partial(dataset.__getitem__, idx=i) for i in range(batch_size)]\n    return data_source_fn",
            "def get_data_source(dataset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n\n    def data_source_fn(batch_size):\n        return [partial(dataset.__getitem__, idx=i) for i in range(batch_size)]\n    return data_source_fn"
        ]
    },
    {
        "func_name": "entry",
        "original": "def entry(env, read_infer_ratio, use_cuda):\n    (file_time, process_time, batch_size, chunk_size, data_name) = (env[0], env[1], env[2], env[3], env[4])\n    data_time = file_time + process_time\n    infer_time = data_time * (batch_size / num_workers) * 1.05 / read_infer_ratio\n    out_str = '\\n===== each_data: {:.4f}({}), infer: {:.4f}, read/infer: {:.4f},         batch_size: {}, chunk_size: {} ====='.format(data_time, data_name, infer_time, read_infer_ratio, batch_size, chunk_size)\n    out_str_list.append(out_str)\n    print(out_str)\n    model = MyModel(infer_time)\n    if use_cuda:\n        model.cuda()\n    timer = EasyTimer()\n    total_sum_time_list = []\n    total_data_time_list = []\n    total_infer_time_list = []\n    for _ in range(exp_times):\n        print('\\t----- Our DataLoader -----')\n        dataset = MyDataset(file_time, process_time, batch_size, data_name)\n        data_source = get_data_source(dataset)\n        device = 'cuda' if use_cuda else 'cpu'\n        our_dataloader = AsyncDataLoader(data_source, batch_size, device, num_workers=num_workers, chunk_size=chunk_size)\n        iter = 0\n        total_data_time = 0.0\n        total_infer_time = 0.0\n        total_sum_time = 0.0\n        while True:\n            with timer:\n                data = next(our_dataloader)\n            data_time = timer.value\n            with timer:\n                with torch.no_grad():\n                    (_, idx) = model(data)\n            infer_time = timer.value\n            sum_time = data_time + infer_time\n            if iter > 5:\n                total_data_time += data_time\n                total_infer_time += infer_time\n            print('\\t\\titer {:0>2d}, sum_time: {:.4f}, data_time: {:.4f}, infer_time: {:.4f}'.format(iter, sum_time, data_time, infer_time))\n            iter += 1\n            if iter == max_iter:\n                break\n        total_sum_time = total_data_time + total_infer_time\n        out_str = '\\ttotal_sum_time: {:.4f}, total_data_time: {:.4f},             total_infer_time: {:.4f}, data/sum: {:.4f}'.format(total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n        print(out_str)\n        our_dataloader.__del__()\n        torch.cuda.empty_cache()\n        total_sum_time_list.append(total_sum_time)\n        total_data_time_list.append(total_data_time)\n        total_infer_time_list.append(total_infer_time)\n    total_sum_time = sum(total_sum_time_list) / len(total_sum_time_list)\n    total_data_time = sum(total_data_time_list) / len(total_data_time_list)\n    total_infer_time = sum(total_infer_time_list) / len(total_infer_time_list)\n    out_str = '\\t(Our DataLoader {} average) total_sum_time: {:.4f},         total_data_time: {:.4f}, total_infer_time: {:.4f}, data/sum: {:.4f}'.format(exp_times, total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n    out_str_list.append(out_str)\n    print(out_str)\n    for real_num_workers in [0, 8]:\n        total_sum_time_list = []\n        total_data_time_list = []\n        total_infer_time_list = []\n        for _ in range(exp_times):\n            print('\\t----- PyTorch DataLoader (num_workers = {}) -----'.format(real_num_workers))\n            dataset = MyDataset(file_time, process_time, batch_size, data_name)\n            torch_dataloader = DataLoader(dataset, batch_size, num_workers=real_num_workers)\n            torch_dataloader_iter = torch_dataloader.__iter__()\n            iter = 0\n            total_data_time = 0.0\n            total_infer_time = 0.0\n            total_sum_time = 0.0\n            while True:\n                with timer:\n                    data = next(torch_dataloader_iter)[0]\n                    if use_cuda:\n                        data = data.cuda()\n                data_time = timer.value\n                with timer:\n                    with torch.no_grad():\n                        (_, idx) = model(data)\n                infer_time = timer.value\n                sum_time = data_time + infer_time\n                if iter > 5:\n                    total_data_time += data_time\n                    total_infer_time += infer_time\n                print('\\t\\titer {:0>2d}, sum_time: {:.4f}, data_time: {:.4f}, infer_time: {:.4f}'.format(iter, sum_time, data_time, infer_time))\n                iter += 1\n                if iter == max_iter:\n                    break\n            total_sum_time = total_data_time + total_infer_time\n            out_str = '\\ttotal_sum_time: {:.4f}, total_data_time: {:.4f},                 total_infer_time: {:.4f}, data/sum: {:.4f}'.format(total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n            print(out_str)\n            torch.cuda.empty_cache()\n            total_sum_time_list.append(total_sum_time)\n            total_data_time_list.append(total_data_time)\n            total_infer_time_list.append(total_infer_time)\n        total_sum_time = sum(total_sum_time_list) / len(total_sum_time_list)\n        total_data_time = sum(total_data_time_list) / len(total_data_time_list)\n        total_infer_time = sum(total_infer_time_list) / len(total_infer_time_list)\n        out_str = '\\t(PyTorch DataLoader baseline {} average) total_sum_time: {:.4f},             total_data_time: {:.4f}, total_infer_time: {:.4f}, data/sum: {:.4f}'.format(exp_times, total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n        out_str_list.append(out_str)\n        print(out_str)",
        "mutated": [
            "def entry(env, read_infer_ratio, use_cuda):\n    if False:\n        i = 10\n    (file_time, process_time, batch_size, chunk_size, data_name) = (env[0], env[1], env[2], env[3], env[4])\n    data_time = file_time + process_time\n    infer_time = data_time * (batch_size / num_workers) * 1.05 / read_infer_ratio\n    out_str = '\\n===== each_data: {:.4f}({}), infer: {:.4f}, read/infer: {:.4f},         batch_size: {}, chunk_size: {} ====='.format(data_time, data_name, infer_time, read_infer_ratio, batch_size, chunk_size)\n    out_str_list.append(out_str)\n    print(out_str)\n    model = MyModel(infer_time)\n    if use_cuda:\n        model.cuda()\n    timer = EasyTimer()\n    total_sum_time_list = []\n    total_data_time_list = []\n    total_infer_time_list = []\n    for _ in range(exp_times):\n        print('\\t----- Our DataLoader -----')\n        dataset = MyDataset(file_time, process_time, batch_size, data_name)\n        data_source = get_data_source(dataset)\n        device = 'cuda' if use_cuda else 'cpu'\n        our_dataloader = AsyncDataLoader(data_source, batch_size, device, num_workers=num_workers, chunk_size=chunk_size)\n        iter = 0\n        total_data_time = 0.0\n        total_infer_time = 0.0\n        total_sum_time = 0.0\n        while True:\n            with timer:\n                data = next(our_dataloader)\n            data_time = timer.value\n            with timer:\n                with torch.no_grad():\n                    (_, idx) = model(data)\n            infer_time = timer.value\n            sum_time = data_time + infer_time\n            if iter > 5:\n                total_data_time += data_time\n                total_infer_time += infer_time\n            print('\\t\\titer {:0>2d}, sum_time: {:.4f}, data_time: {:.4f}, infer_time: {:.4f}'.format(iter, sum_time, data_time, infer_time))\n            iter += 1\n            if iter == max_iter:\n                break\n        total_sum_time = total_data_time + total_infer_time\n        out_str = '\\ttotal_sum_time: {:.4f}, total_data_time: {:.4f},             total_infer_time: {:.4f}, data/sum: {:.4f}'.format(total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n        print(out_str)\n        our_dataloader.__del__()\n        torch.cuda.empty_cache()\n        total_sum_time_list.append(total_sum_time)\n        total_data_time_list.append(total_data_time)\n        total_infer_time_list.append(total_infer_time)\n    total_sum_time = sum(total_sum_time_list) / len(total_sum_time_list)\n    total_data_time = sum(total_data_time_list) / len(total_data_time_list)\n    total_infer_time = sum(total_infer_time_list) / len(total_infer_time_list)\n    out_str = '\\t(Our DataLoader {} average) total_sum_time: {:.4f},         total_data_time: {:.4f}, total_infer_time: {:.4f}, data/sum: {:.4f}'.format(exp_times, total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n    out_str_list.append(out_str)\n    print(out_str)\n    for real_num_workers in [0, 8]:\n        total_sum_time_list = []\n        total_data_time_list = []\n        total_infer_time_list = []\n        for _ in range(exp_times):\n            print('\\t----- PyTorch DataLoader (num_workers = {}) -----'.format(real_num_workers))\n            dataset = MyDataset(file_time, process_time, batch_size, data_name)\n            torch_dataloader = DataLoader(dataset, batch_size, num_workers=real_num_workers)\n            torch_dataloader_iter = torch_dataloader.__iter__()\n            iter = 0\n            total_data_time = 0.0\n            total_infer_time = 0.0\n            total_sum_time = 0.0\n            while True:\n                with timer:\n                    data = next(torch_dataloader_iter)[0]\n                    if use_cuda:\n                        data = data.cuda()\n                data_time = timer.value\n                with timer:\n                    with torch.no_grad():\n                        (_, idx) = model(data)\n                infer_time = timer.value\n                sum_time = data_time + infer_time\n                if iter > 5:\n                    total_data_time += data_time\n                    total_infer_time += infer_time\n                print('\\t\\titer {:0>2d}, sum_time: {:.4f}, data_time: {:.4f}, infer_time: {:.4f}'.format(iter, sum_time, data_time, infer_time))\n                iter += 1\n                if iter == max_iter:\n                    break\n            total_sum_time = total_data_time + total_infer_time\n            out_str = '\\ttotal_sum_time: {:.4f}, total_data_time: {:.4f},                 total_infer_time: {:.4f}, data/sum: {:.4f}'.format(total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n            print(out_str)\n            torch.cuda.empty_cache()\n            total_sum_time_list.append(total_sum_time)\n            total_data_time_list.append(total_data_time)\n            total_infer_time_list.append(total_infer_time)\n        total_sum_time = sum(total_sum_time_list) / len(total_sum_time_list)\n        total_data_time = sum(total_data_time_list) / len(total_data_time_list)\n        total_infer_time = sum(total_infer_time_list) / len(total_infer_time_list)\n        out_str = '\\t(PyTorch DataLoader baseline {} average) total_sum_time: {:.4f},             total_data_time: {:.4f}, total_infer_time: {:.4f}, data/sum: {:.4f}'.format(exp_times, total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n        out_str_list.append(out_str)\n        print(out_str)",
            "def entry(env, read_infer_ratio, use_cuda):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (file_time, process_time, batch_size, chunk_size, data_name) = (env[0], env[1], env[2], env[3], env[4])\n    data_time = file_time + process_time\n    infer_time = data_time * (batch_size / num_workers) * 1.05 / read_infer_ratio\n    out_str = '\\n===== each_data: {:.4f}({}), infer: {:.4f}, read/infer: {:.4f},         batch_size: {}, chunk_size: {} ====='.format(data_time, data_name, infer_time, read_infer_ratio, batch_size, chunk_size)\n    out_str_list.append(out_str)\n    print(out_str)\n    model = MyModel(infer_time)\n    if use_cuda:\n        model.cuda()\n    timer = EasyTimer()\n    total_sum_time_list = []\n    total_data_time_list = []\n    total_infer_time_list = []\n    for _ in range(exp_times):\n        print('\\t----- Our DataLoader -----')\n        dataset = MyDataset(file_time, process_time, batch_size, data_name)\n        data_source = get_data_source(dataset)\n        device = 'cuda' if use_cuda else 'cpu'\n        our_dataloader = AsyncDataLoader(data_source, batch_size, device, num_workers=num_workers, chunk_size=chunk_size)\n        iter = 0\n        total_data_time = 0.0\n        total_infer_time = 0.0\n        total_sum_time = 0.0\n        while True:\n            with timer:\n                data = next(our_dataloader)\n            data_time = timer.value\n            with timer:\n                with torch.no_grad():\n                    (_, idx) = model(data)\n            infer_time = timer.value\n            sum_time = data_time + infer_time\n            if iter > 5:\n                total_data_time += data_time\n                total_infer_time += infer_time\n            print('\\t\\titer {:0>2d}, sum_time: {:.4f}, data_time: {:.4f}, infer_time: {:.4f}'.format(iter, sum_time, data_time, infer_time))\n            iter += 1\n            if iter == max_iter:\n                break\n        total_sum_time = total_data_time + total_infer_time\n        out_str = '\\ttotal_sum_time: {:.4f}, total_data_time: {:.4f},             total_infer_time: {:.4f}, data/sum: {:.4f}'.format(total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n        print(out_str)\n        our_dataloader.__del__()\n        torch.cuda.empty_cache()\n        total_sum_time_list.append(total_sum_time)\n        total_data_time_list.append(total_data_time)\n        total_infer_time_list.append(total_infer_time)\n    total_sum_time = sum(total_sum_time_list) / len(total_sum_time_list)\n    total_data_time = sum(total_data_time_list) / len(total_data_time_list)\n    total_infer_time = sum(total_infer_time_list) / len(total_infer_time_list)\n    out_str = '\\t(Our DataLoader {} average) total_sum_time: {:.4f},         total_data_time: {:.4f}, total_infer_time: {:.4f}, data/sum: {:.4f}'.format(exp_times, total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n    out_str_list.append(out_str)\n    print(out_str)\n    for real_num_workers in [0, 8]:\n        total_sum_time_list = []\n        total_data_time_list = []\n        total_infer_time_list = []\n        for _ in range(exp_times):\n            print('\\t----- PyTorch DataLoader (num_workers = {}) -----'.format(real_num_workers))\n            dataset = MyDataset(file_time, process_time, batch_size, data_name)\n            torch_dataloader = DataLoader(dataset, batch_size, num_workers=real_num_workers)\n            torch_dataloader_iter = torch_dataloader.__iter__()\n            iter = 0\n            total_data_time = 0.0\n            total_infer_time = 0.0\n            total_sum_time = 0.0\n            while True:\n                with timer:\n                    data = next(torch_dataloader_iter)[0]\n                    if use_cuda:\n                        data = data.cuda()\n                data_time = timer.value\n                with timer:\n                    with torch.no_grad():\n                        (_, idx) = model(data)\n                infer_time = timer.value\n                sum_time = data_time + infer_time\n                if iter > 5:\n                    total_data_time += data_time\n                    total_infer_time += infer_time\n                print('\\t\\titer {:0>2d}, sum_time: {:.4f}, data_time: {:.4f}, infer_time: {:.4f}'.format(iter, sum_time, data_time, infer_time))\n                iter += 1\n                if iter == max_iter:\n                    break\n            total_sum_time = total_data_time + total_infer_time\n            out_str = '\\ttotal_sum_time: {:.4f}, total_data_time: {:.4f},                 total_infer_time: {:.4f}, data/sum: {:.4f}'.format(total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n            print(out_str)\n            torch.cuda.empty_cache()\n            total_sum_time_list.append(total_sum_time)\n            total_data_time_list.append(total_data_time)\n            total_infer_time_list.append(total_infer_time)\n        total_sum_time = sum(total_sum_time_list) / len(total_sum_time_list)\n        total_data_time = sum(total_data_time_list) / len(total_data_time_list)\n        total_infer_time = sum(total_infer_time_list) / len(total_infer_time_list)\n        out_str = '\\t(PyTorch DataLoader baseline {} average) total_sum_time: {:.4f},             total_data_time: {:.4f}, total_infer_time: {:.4f}, data/sum: {:.4f}'.format(exp_times, total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n        out_str_list.append(out_str)\n        print(out_str)",
            "def entry(env, read_infer_ratio, use_cuda):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (file_time, process_time, batch_size, chunk_size, data_name) = (env[0], env[1], env[2], env[3], env[4])\n    data_time = file_time + process_time\n    infer_time = data_time * (batch_size / num_workers) * 1.05 / read_infer_ratio\n    out_str = '\\n===== each_data: {:.4f}({}), infer: {:.4f}, read/infer: {:.4f},         batch_size: {}, chunk_size: {} ====='.format(data_time, data_name, infer_time, read_infer_ratio, batch_size, chunk_size)\n    out_str_list.append(out_str)\n    print(out_str)\n    model = MyModel(infer_time)\n    if use_cuda:\n        model.cuda()\n    timer = EasyTimer()\n    total_sum_time_list = []\n    total_data_time_list = []\n    total_infer_time_list = []\n    for _ in range(exp_times):\n        print('\\t----- Our DataLoader -----')\n        dataset = MyDataset(file_time, process_time, batch_size, data_name)\n        data_source = get_data_source(dataset)\n        device = 'cuda' if use_cuda else 'cpu'\n        our_dataloader = AsyncDataLoader(data_source, batch_size, device, num_workers=num_workers, chunk_size=chunk_size)\n        iter = 0\n        total_data_time = 0.0\n        total_infer_time = 0.0\n        total_sum_time = 0.0\n        while True:\n            with timer:\n                data = next(our_dataloader)\n            data_time = timer.value\n            with timer:\n                with torch.no_grad():\n                    (_, idx) = model(data)\n            infer_time = timer.value\n            sum_time = data_time + infer_time\n            if iter > 5:\n                total_data_time += data_time\n                total_infer_time += infer_time\n            print('\\t\\titer {:0>2d}, sum_time: {:.4f}, data_time: {:.4f}, infer_time: {:.4f}'.format(iter, sum_time, data_time, infer_time))\n            iter += 1\n            if iter == max_iter:\n                break\n        total_sum_time = total_data_time + total_infer_time\n        out_str = '\\ttotal_sum_time: {:.4f}, total_data_time: {:.4f},             total_infer_time: {:.4f}, data/sum: {:.4f}'.format(total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n        print(out_str)\n        our_dataloader.__del__()\n        torch.cuda.empty_cache()\n        total_sum_time_list.append(total_sum_time)\n        total_data_time_list.append(total_data_time)\n        total_infer_time_list.append(total_infer_time)\n    total_sum_time = sum(total_sum_time_list) / len(total_sum_time_list)\n    total_data_time = sum(total_data_time_list) / len(total_data_time_list)\n    total_infer_time = sum(total_infer_time_list) / len(total_infer_time_list)\n    out_str = '\\t(Our DataLoader {} average) total_sum_time: {:.4f},         total_data_time: {:.4f}, total_infer_time: {:.4f}, data/sum: {:.4f}'.format(exp_times, total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n    out_str_list.append(out_str)\n    print(out_str)\n    for real_num_workers in [0, 8]:\n        total_sum_time_list = []\n        total_data_time_list = []\n        total_infer_time_list = []\n        for _ in range(exp_times):\n            print('\\t----- PyTorch DataLoader (num_workers = {}) -----'.format(real_num_workers))\n            dataset = MyDataset(file_time, process_time, batch_size, data_name)\n            torch_dataloader = DataLoader(dataset, batch_size, num_workers=real_num_workers)\n            torch_dataloader_iter = torch_dataloader.__iter__()\n            iter = 0\n            total_data_time = 0.0\n            total_infer_time = 0.0\n            total_sum_time = 0.0\n            while True:\n                with timer:\n                    data = next(torch_dataloader_iter)[0]\n                    if use_cuda:\n                        data = data.cuda()\n                data_time = timer.value\n                with timer:\n                    with torch.no_grad():\n                        (_, idx) = model(data)\n                infer_time = timer.value\n                sum_time = data_time + infer_time\n                if iter > 5:\n                    total_data_time += data_time\n                    total_infer_time += infer_time\n                print('\\t\\titer {:0>2d}, sum_time: {:.4f}, data_time: {:.4f}, infer_time: {:.4f}'.format(iter, sum_time, data_time, infer_time))\n                iter += 1\n                if iter == max_iter:\n                    break\n            total_sum_time = total_data_time + total_infer_time\n            out_str = '\\ttotal_sum_time: {:.4f}, total_data_time: {:.4f},                 total_infer_time: {:.4f}, data/sum: {:.4f}'.format(total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n            print(out_str)\n            torch.cuda.empty_cache()\n            total_sum_time_list.append(total_sum_time)\n            total_data_time_list.append(total_data_time)\n            total_infer_time_list.append(total_infer_time)\n        total_sum_time = sum(total_sum_time_list) / len(total_sum_time_list)\n        total_data_time = sum(total_data_time_list) / len(total_data_time_list)\n        total_infer_time = sum(total_infer_time_list) / len(total_infer_time_list)\n        out_str = '\\t(PyTorch DataLoader baseline {} average) total_sum_time: {:.4f},             total_data_time: {:.4f}, total_infer_time: {:.4f}, data/sum: {:.4f}'.format(exp_times, total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n        out_str_list.append(out_str)\n        print(out_str)",
            "def entry(env, read_infer_ratio, use_cuda):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (file_time, process_time, batch_size, chunk_size, data_name) = (env[0], env[1], env[2], env[3], env[4])\n    data_time = file_time + process_time\n    infer_time = data_time * (batch_size / num_workers) * 1.05 / read_infer_ratio\n    out_str = '\\n===== each_data: {:.4f}({}), infer: {:.4f}, read/infer: {:.4f},         batch_size: {}, chunk_size: {} ====='.format(data_time, data_name, infer_time, read_infer_ratio, batch_size, chunk_size)\n    out_str_list.append(out_str)\n    print(out_str)\n    model = MyModel(infer_time)\n    if use_cuda:\n        model.cuda()\n    timer = EasyTimer()\n    total_sum_time_list = []\n    total_data_time_list = []\n    total_infer_time_list = []\n    for _ in range(exp_times):\n        print('\\t----- Our DataLoader -----')\n        dataset = MyDataset(file_time, process_time, batch_size, data_name)\n        data_source = get_data_source(dataset)\n        device = 'cuda' if use_cuda else 'cpu'\n        our_dataloader = AsyncDataLoader(data_source, batch_size, device, num_workers=num_workers, chunk_size=chunk_size)\n        iter = 0\n        total_data_time = 0.0\n        total_infer_time = 0.0\n        total_sum_time = 0.0\n        while True:\n            with timer:\n                data = next(our_dataloader)\n            data_time = timer.value\n            with timer:\n                with torch.no_grad():\n                    (_, idx) = model(data)\n            infer_time = timer.value\n            sum_time = data_time + infer_time\n            if iter > 5:\n                total_data_time += data_time\n                total_infer_time += infer_time\n            print('\\t\\titer {:0>2d}, sum_time: {:.4f}, data_time: {:.4f}, infer_time: {:.4f}'.format(iter, sum_time, data_time, infer_time))\n            iter += 1\n            if iter == max_iter:\n                break\n        total_sum_time = total_data_time + total_infer_time\n        out_str = '\\ttotal_sum_time: {:.4f}, total_data_time: {:.4f},             total_infer_time: {:.4f}, data/sum: {:.4f}'.format(total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n        print(out_str)\n        our_dataloader.__del__()\n        torch.cuda.empty_cache()\n        total_sum_time_list.append(total_sum_time)\n        total_data_time_list.append(total_data_time)\n        total_infer_time_list.append(total_infer_time)\n    total_sum_time = sum(total_sum_time_list) / len(total_sum_time_list)\n    total_data_time = sum(total_data_time_list) / len(total_data_time_list)\n    total_infer_time = sum(total_infer_time_list) / len(total_infer_time_list)\n    out_str = '\\t(Our DataLoader {} average) total_sum_time: {:.4f},         total_data_time: {:.4f}, total_infer_time: {:.4f}, data/sum: {:.4f}'.format(exp_times, total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n    out_str_list.append(out_str)\n    print(out_str)\n    for real_num_workers in [0, 8]:\n        total_sum_time_list = []\n        total_data_time_list = []\n        total_infer_time_list = []\n        for _ in range(exp_times):\n            print('\\t----- PyTorch DataLoader (num_workers = {}) -----'.format(real_num_workers))\n            dataset = MyDataset(file_time, process_time, batch_size, data_name)\n            torch_dataloader = DataLoader(dataset, batch_size, num_workers=real_num_workers)\n            torch_dataloader_iter = torch_dataloader.__iter__()\n            iter = 0\n            total_data_time = 0.0\n            total_infer_time = 0.0\n            total_sum_time = 0.0\n            while True:\n                with timer:\n                    data = next(torch_dataloader_iter)[0]\n                    if use_cuda:\n                        data = data.cuda()\n                data_time = timer.value\n                with timer:\n                    with torch.no_grad():\n                        (_, idx) = model(data)\n                infer_time = timer.value\n                sum_time = data_time + infer_time\n                if iter > 5:\n                    total_data_time += data_time\n                    total_infer_time += infer_time\n                print('\\t\\titer {:0>2d}, sum_time: {:.4f}, data_time: {:.4f}, infer_time: {:.4f}'.format(iter, sum_time, data_time, infer_time))\n                iter += 1\n                if iter == max_iter:\n                    break\n            total_sum_time = total_data_time + total_infer_time\n            out_str = '\\ttotal_sum_time: {:.4f}, total_data_time: {:.4f},                 total_infer_time: {:.4f}, data/sum: {:.4f}'.format(total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n            print(out_str)\n            torch.cuda.empty_cache()\n            total_sum_time_list.append(total_sum_time)\n            total_data_time_list.append(total_data_time)\n            total_infer_time_list.append(total_infer_time)\n        total_sum_time = sum(total_sum_time_list) / len(total_sum_time_list)\n        total_data_time = sum(total_data_time_list) / len(total_data_time_list)\n        total_infer_time = sum(total_infer_time_list) / len(total_infer_time_list)\n        out_str = '\\t(PyTorch DataLoader baseline {} average) total_sum_time: {:.4f},             total_data_time: {:.4f}, total_infer_time: {:.4f}, data/sum: {:.4f}'.format(exp_times, total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n        out_str_list.append(out_str)\n        print(out_str)",
            "def entry(env, read_infer_ratio, use_cuda):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (file_time, process_time, batch_size, chunk_size, data_name) = (env[0], env[1], env[2], env[3], env[4])\n    data_time = file_time + process_time\n    infer_time = data_time * (batch_size / num_workers) * 1.05 / read_infer_ratio\n    out_str = '\\n===== each_data: {:.4f}({}), infer: {:.4f}, read/infer: {:.4f},         batch_size: {}, chunk_size: {} ====='.format(data_time, data_name, infer_time, read_infer_ratio, batch_size, chunk_size)\n    out_str_list.append(out_str)\n    print(out_str)\n    model = MyModel(infer_time)\n    if use_cuda:\n        model.cuda()\n    timer = EasyTimer()\n    total_sum_time_list = []\n    total_data_time_list = []\n    total_infer_time_list = []\n    for _ in range(exp_times):\n        print('\\t----- Our DataLoader -----')\n        dataset = MyDataset(file_time, process_time, batch_size, data_name)\n        data_source = get_data_source(dataset)\n        device = 'cuda' if use_cuda else 'cpu'\n        our_dataloader = AsyncDataLoader(data_source, batch_size, device, num_workers=num_workers, chunk_size=chunk_size)\n        iter = 0\n        total_data_time = 0.0\n        total_infer_time = 0.0\n        total_sum_time = 0.0\n        while True:\n            with timer:\n                data = next(our_dataloader)\n            data_time = timer.value\n            with timer:\n                with torch.no_grad():\n                    (_, idx) = model(data)\n            infer_time = timer.value\n            sum_time = data_time + infer_time\n            if iter > 5:\n                total_data_time += data_time\n                total_infer_time += infer_time\n            print('\\t\\titer {:0>2d}, sum_time: {:.4f}, data_time: {:.4f}, infer_time: {:.4f}'.format(iter, sum_time, data_time, infer_time))\n            iter += 1\n            if iter == max_iter:\n                break\n        total_sum_time = total_data_time + total_infer_time\n        out_str = '\\ttotal_sum_time: {:.4f}, total_data_time: {:.4f},             total_infer_time: {:.4f}, data/sum: {:.4f}'.format(total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n        print(out_str)\n        our_dataloader.__del__()\n        torch.cuda.empty_cache()\n        total_sum_time_list.append(total_sum_time)\n        total_data_time_list.append(total_data_time)\n        total_infer_time_list.append(total_infer_time)\n    total_sum_time = sum(total_sum_time_list) / len(total_sum_time_list)\n    total_data_time = sum(total_data_time_list) / len(total_data_time_list)\n    total_infer_time = sum(total_infer_time_list) / len(total_infer_time_list)\n    out_str = '\\t(Our DataLoader {} average) total_sum_time: {:.4f},         total_data_time: {:.4f}, total_infer_time: {:.4f}, data/sum: {:.4f}'.format(exp_times, total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n    out_str_list.append(out_str)\n    print(out_str)\n    for real_num_workers in [0, 8]:\n        total_sum_time_list = []\n        total_data_time_list = []\n        total_infer_time_list = []\n        for _ in range(exp_times):\n            print('\\t----- PyTorch DataLoader (num_workers = {}) -----'.format(real_num_workers))\n            dataset = MyDataset(file_time, process_time, batch_size, data_name)\n            torch_dataloader = DataLoader(dataset, batch_size, num_workers=real_num_workers)\n            torch_dataloader_iter = torch_dataloader.__iter__()\n            iter = 0\n            total_data_time = 0.0\n            total_infer_time = 0.0\n            total_sum_time = 0.0\n            while True:\n                with timer:\n                    data = next(torch_dataloader_iter)[0]\n                    if use_cuda:\n                        data = data.cuda()\n                data_time = timer.value\n                with timer:\n                    with torch.no_grad():\n                        (_, idx) = model(data)\n                infer_time = timer.value\n                sum_time = data_time + infer_time\n                if iter > 5:\n                    total_data_time += data_time\n                    total_infer_time += infer_time\n                print('\\t\\titer {:0>2d}, sum_time: {:.4f}, data_time: {:.4f}, infer_time: {:.4f}'.format(iter, sum_time, data_time, infer_time))\n                iter += 1\n                if iter == max_iter:\n                    break\n            total_sum_time = total_data_time + total_infer_time\n            out_str = '\\ttotal_sum_time: {:.4f}, total_data_time: {:.4f},                 total_infer_time: {:.4f}, data/sum: {:.4f}'.format(total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n            print(out_str)\n            torch.cuda.empty_cache()\n            total_sum_time_list.append(total_sum_time)\n            total_data_time_list.append(total_data_time)\n            total_infer_time_list.append(total_infer_time)\n        total_sum_time = sum(total_sum_time_list) / len(total_sum_time_list)\n        total_data_time = sum(total_data_time_list) / len(total_data_time_list)\n        total_infer_time = sum(total_infer_time_list) / len(total_infer_time_list)\n        out_str = '\\t(PyTorch DataLoader baseline {} average) total_sum_time: {:.4f},             total_data_time: {:.4f}, total_infer_time: {:.4f}, data/sum: {:.4f}'.format(exp_times, total_sum_time, total_data_time, total_infer_time, total_data_time / total_sum_time)\n        out_str_list.append(out_str)\n        print(out_str)"
        ]
    }
]