[
    {
        "func_name": "encode",
        "original": "def encode(x):\n    (Z, _) = model.encode(x, layer_count - 1, 1)\n    Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n    return Z",
        "mutated": [
            "def encode(x):\n    if False:\n        i = 10\n    (Z, _) = model.encode(x, layer_count - 1, 1)\n    Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n    return Z",
            "def encode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (Z, _) = model.encode(x, layer_count - 1, 1)\n    Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n    return Z",
            "def encode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (Z, _) = model.encode(x, layer_count - 1, 1)\n    Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n    return Z",
            "def encode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (Z, _) = model.encode(x, layer_count - 1, 1)\n    Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n    return Z",
            "def encode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (Z, _) = model.encode(x, layer_count - 1, 1)\n    Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n    return Z"
        ]
    },
    {
        "func_name": "decode",
        "original": "def decode(x):\n    layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    return model.decoder(x, layer_count - 1, 1, noise=True)",
        "mutated": [
            "def decode(x):\n    if False:\n        i = 10\n    layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    return model.decoder(x, layer_count - 1, 1, noise=True)",
            "def decode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    return model.decoder(x, layer_count - 1, 1, noise=True)",
            "def decode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    return model.decoder(x, layer_count - 1, 1, noise=True)",
            "def decode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    return model.decoder(x, layer_count - 1, 1, noise=True)",
            "def decode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    return model.decoder(x, layer_count - 1, 1, noise=True)"
        ]
    },
    {
        "func_name": "loadNext",
        "original": "def loadNext():\n    img = np.asarray(Image.open(path + '/' + paths[0]))\n    current_file.value = paths[0]\n    paths.pop(0)\n    if len(paths) == 0:\n        paths.extend(paths_backup)\n    if img.shape[2] == 4:\n        img = img[:, :, :3]\n    im = img.transpose((2, 0, 1))\n    x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n    if x.shape[0] == 4:\n        x = x[:3]\n    needed_resolution = model.decoder.layer_to_resolution[-1]\n    while x.shape[2] > needed_resolution:\n        x = F.avg_pool2d(x, 2, 2)\n    if x.shape[2] != needed_resolution:\n        x = F.adaptive_avg_pool2d(x, (needed_resolution, needed_resolution))\n    img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n    latents_original = encode(x[None, ...].cuda())\n    latents = latents_original[0, 0].clone()\n    latents -= model.dlatent_avg.buff.data[0]\n    for (v, w) in zip(attribute_values, W):\n        v.value = (latents * w).sum()\n    for (v, w) in zip(attribute_values, W):\n        latents = latents - v.value * w\n    return (latents, latents_original, img_src)",
        "mutated": [
            "def loadNext():\n    if False:\n        i = 10\n    img = np.asarray(Image.open(path + '/' + paths[0]))\n    current_file.value = paths[0]\n    paths.pop(0)\n    if len(paths) == 0:\n        paths.extend(paths_backup)\n    if img.shape[2] == 4:\n        img = img[:, :, :3]\n    im = img.transpose((2, 0, 1))\n    x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n    if x.shape[0] == 4:\n        x = x[:3]\n    needed_resolution = model.decoder.layer_to_resolution[-1]\n    while x.shape[2] > needed_resolution:\n        x = F.avg_pool2d(x, 2, 2)\n    if x.shape[2] != needed_resolution:\n        x = F.adaptive_avg_pool2d(x, (needed_resolution, needed_resolution))\n    img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n    latents_original = encode(x[None, ...].cuda())\n    latents = latents_original[0, 0].clone()\n    latents -= model.dlatent_avg.buff.data[0]\n    for (v, w) in zip(attribute_values, W):\n        v.value = (latents * w).sum()\n    for (v, w) in zip(attribute_values, W):\n        latents = latents - v.value * w\n    return (latents, latents_original, img_src)",
            "def loadNext():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    img = np.asarray(Image.open(path + '/' + paths[0]))\n    current_file.value = paths[0]\n    paths.pop(0)\n    if len(paths) == 0:\n        paths.extend(paths_backup)\n    if img.shape[2] == 4:\n        img = img[:, :, :3]\n    im = img.transpose((2, 0, 1))\n    x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n    if x.shape[0] == 4:\n        x = x[:3]\n    needed_resolution = model.decoder.layer_to_resolution[-1]\n    while x.shape[2] > needed_resolution:\n        x = F.avg_pool2d(x, 2, 2)\n    if x.shape[2] != needed_resolution:\n        x = F.adaptive_avg_pool2d(x, (needed_resolution, needed_resolution))\n    img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n    latents_original = encode(x[None, ...].cuda())\n    latents = latents_original[0, 0].clone()\n    latents -= model.dlatent_avg.buff.data[0]\n    for (v, w) in zip(attribute_values, W):\n        v.value = (latents * w).sum()\n    for (v, w) in zip(attribute_values, W):\n        latents = latents - v.value * w\n    return (latents, latents_original, img_src)",
            "def loadNext():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    img = np.asarray(Image.open(path + '/' + paths[0]))\n    current_file.value = paths[0]\n    paths.pop(0)\n    if len(paths) == 0:\n        paths.extend(paths_backup)\n    if img.shape[2] == 4:\n        img = img[:, :, :3]\n    im = img.transpose((2, 0, 1))\n    x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n    if x.shape[0] == 4:\n        x = x[:3]\n    needed_resolution = model.decoder.layer_to_resolution[-1]\n    while x.shape[2] > needed_resolution:\n        x = F.avg_pool2d(x, 2, 2)\n    if x.shape[2] != needed_resolution:\n        x = F.adaptive_avg_pool2d(x, (needed_resolution, needed_resolution))\n    img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n    latents_original = encode(x[None, ...].cuda())\n    latents = latents_original[0, 0].clone()\n    latents -= model.dlatent_avg.buff.data[0]\n    for (v, w) in zip(attribute_values, W):\n        v.value = (latents * w).sum()\n    for (v, w) in zip(attribute_values, W):\n        latents = latents - v.value * w\n    return (latents, latents_original, img_src)",
            "def loadNext():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    img = np.asarray(Image.open(path + '/' + paths[0]))\n    current_file.value = paths[0]\n    paths.pop(0)\n    if len(paths) == 0:\n        paths.extend(paths_backup)\n    if img.shape[2] == 4:\n        img = img[:, :, :3]\n    im = img.transpose((2, 0, 1))\n    x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n    if x.shape[0] == 4:\n        x = x[:3]\n    needed_resolution = model.decoder.layer_to_resolution[-1]\n    while x.shape[2] > needed_resolution:\n        x = F.avg_pool2d(x, 2, 2)\n    if x.shape[2] != needed_resolution:\n        x = F.adaptive_avg_pool2d(x, (needed_resolution, needed_resolution))\n    img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n    latents_original = encode(x[None, ...].cuda())\n    latents = latents_original[0, 0].clone()\n    latents -= model.dlatent_avg.buff.data[0]\n    for (v, w) in zip(attribute_values, W):\n        v.value = (latents * w).sum()\n    for (v, w) in zip(attribute_values, W):\n        latents = latents - v.value * w\n    return (latents, latents_original, img_src)",
            "def loadNext():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    img = np.asarray(Image.open(path + '/' + paths[0]))\n    current_file.value = paths[0]\n    paths.pop(0)\n    if len(paths) == 0:\n        paths.extend(paths_backup)\n    if img.shape[2] == 4:\n        img = img[:, :, :3]\n    im = img.transpose((2, 0, 1))\n    x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n    if x.shape[0] == 4:\n        x = x[:3]\n    needed_resolution = model.decoder.layer_to_resolution[-1]\n    while x.shape[2] > needed_resolution:\n        x = F.avg_pool2d(x, 2, 2)\n    if x.shape[2] != needed_resolution:\n        x = F.adaptive_avg_pool2d(x, (needed_resolution, needed_resolution))\n    img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n    latents_original = encode(x[None, ...].cuda())\n    latents = latents_original[0, 0].clone()\n    latents -= model.dlatent_avg.buff.data[0]\n    for (v, w) in zip(attribute_values, W):\n        v.value = (latents * w).sum()\n    for (v, w) in zip(attribute_values, W):\n        latents = latents - v.value * w\n    return (latents, latents_original, img_src)"
        ]
    },
    {
        "func_name": "loadRandom",
        "original": "def loadRandom():\n    latents = rnd.randn(1, cfg.MODEL.LATENT_SPACE_SIZE)\n    lat = torch.tensor(latents).float().cuda()\n    dlat = mapping_fl(lat)\n    layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    dlat = torch.lerp(model.dlatent_avg.buff.data, dlat, coefs)\n    x = decode(dlat)[0]\n    img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n    latents_original = dlat\n    latents = latents_original[0, 0].clone()\n    latents -= model.dlatent_avg.buff.data[0]\n    for (v, w) in zip(attribute_values, W):\n        v.value = (latents * w).sum()\n    for (v, w) in zip(attribute_values, W):\n        latents = latents - v.value * w\n    return (latents, latents_original, img_src)",
        "mutated": [
            "def loadRandom():\n    if False:\n        i = 10\n    latents = rnd.randn(1, cfg.MODEL.LATENT_SPACE_SIZE)\n    lat = torch.tensor(latents).float().cuda()\n    dlat = mapping_fl(lat)\n    layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    dlat = torch.lerp(model.dlatent_avg.buff.data, dlat, coefs)\n    x = decode(dlat)[0]\n    img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n    latents_original = dlat\n    latents = latents_original[0, 0].clone()\n    latents -= model.dlatent_avg.buff.data[0]\n    for (v, w) in zip(attribute_values, W):\n        v.value = (latents * w).sum()\n    for (v, w) in zip(attribute_values, W):\n        latents = latents - v.value * w\n    return (latents, latents_original, img_src)",
            "def loadRandom():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    latents = rnd.randn(1, cfg.MODEL.LATENT_SPACE_SIZE)\n    lat = torch.tensor(latents).float().cuda()\n    dlat = mapping_fl(lat)\n    layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    dlat = torch.lerp(model.dlatent_avg.buff.data, dlat, coefs)\n    x = decode(dlat)[0]\n    img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n    latents_original = dlat\n    latents = latents_original[0, 0].clone()\n    latents -= model.dlatent_avg.buff.data[0]\n    for (v, w) in zip(attribute_values, W):\n        v.value = (latents * w).sum()\n    for (v, w) in zip(attribute_values, W):\n        latents = latents - v.value * w\n    return (latents, latents_original, img_src)",
            "def loadRandom():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    latents = rnd.randn(1, cfg.MODEL.LATENT_SPACE_SIZE)\n    lat = torch.tensor(latents).float().cuda()\n    dlat = mapping_fl(lat)\n    layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    dlat = torch.lerp(model.dlatent_avg.buff.data, dlat, coefs)\n    x = decode(dlat)[0]\n    img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n    latents_original = dlat\n    latents = latents_original[0, 0].clone()\n    latents -= model.dlatent_avg.buff.data[0]\n    for (v, w) in zip(attribute_values, W):\n        v.value = (latents * w).sum()\n    for (v, w) in zip(attribute_values, W):\n        latents = latents - v.value * w\n    return (latents, latents_original, img_src)",
            "def loadRandom():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    latents = rnd.randn(1, cfg.MODEL.LATENT_SPACE_SIZE)\n    lat = torch.tensor(latents).float().cuda()\n    dlat = mapping_fl(lat)\n    layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    dlat = torch.lerp(model.dlatent_avg.buff.data, dlat, coefs)\n    x = decode(dlat)[0]\n    img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n    latents_original = dlat\n    latents = latents_original[0, 0].clone()\n    latents -= model.dlatent_avg.buff.data[0]\n    for (v, w) in zip(attribute_values, W):\n        v.value = (latents * w).sum()\n    for (v, w) in zip(attribute_values, W):\n        latents = latents - v.value * w\n    return (latents, latents_original, img_src)",
            "def loadRandom():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    latents = rnd.randn(1, cfg.MODEL.LATENT_SPACE_SIZE)\n    lat = torch.tensor(latents).float().cuda()\n    dlat = mapping_fl(lat)\n    layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    dlat = torch.lerp(model.dlatent_avg.buff.data, dlat, coefs)\n    x = decode(dlat)[0]\n    img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n    latents_original = dlat\n    latents = latents_original[0, 0].clone()\n    latents -= model.dlatent_avg.buff.data[0]\n    for (v, w) in zip(attribute_values, W):\n        v.value = (latents * w).sum()\n    for (v, w) in zip(attribute_values, W):\n        latents = latents - v.value * w\n    return (latents, latents_original, img_src)"
        ]
    },
    {
        "func_name": "update_image",
        "original": "def update_image(w, latents_original):\n    with torch.no_grad():\n        w = w + model.dlatent_avg.buff.data[0]\n        w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n        layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n        cur_layers = (7 + 1) * 2\n        mixing_cutoff = cur_layers\n        styles = torch.where(layer_idx < mixing_cutoff, w, latents_original)\n        x_rec = decode(styles)\n        resultsample = ((x_rec * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255)\n        resultsample = resultsample.cpu()[0, :, :, :]\n        return resultsample.type(torch.uint8).transpose(0, 2).transpose(0, 1)",
        "mutated": [
            "def update_image(w, latents_original):\n    if False:\n        i = 10\n    with torch.no_grad():\n        w = w + model.dlatent_avg.buff.data[0]\n        w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n        layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n        cur_layers = (7 + 1) * 2\n        mixing_cutoff = cur_layers\n        styles = torch.where(layer_idx < mixing_cutoff, w, latents_original)\n        x_rec = decode(styles)\n        resultsample = ((x_rec * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255)\n        resultsample = resultsample.cpu()[0, :, :, :]\n        return resultsample.type(torch.uint8).transpose(0, 2).transpose(0, 1)",
            "def update_image(w, latents_original):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with torch.no_grad():\n        w = w + model.dlatent_avg.buff.data[0]\n        w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n        layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n        cur_layers = (7 + 1) * 2\n        mixing_cutoff = cur_layers\n        styles = torch.where(layer_idx < mixing_cutoff, w, latents_original)\n        x_rec = decode(styles)\n        resultsample = ((x_rec * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255)\n        resultsample = resultsample.cpu()[0, :, :, :]\n        return resultsample.type(torch.uint8).transpose(0, 2).transpose(0, 1)",
            "def update_image(w, latents_original):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with torch.no_grad():\n        w = w + model.dlatent_avg.buff.data[0]\n        w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n        layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n        cur_layers = (7 + 1) * 2\n        mixing_cutoff = cur_layers\n        styles = torch.where(layer_idx < mixing_cutoff, w, latents_original)\n        x_rec = decode(styles)\n        resultsample = ((x_rec * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255)\n        resultsample = resultsample.cpu()[0, :, :, :]\n        return resultsample.type(torch.uint8).transpose(0, 2).transpose(0, 1)",
            "def update_image(w, latents_original):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with torch.no_grad():\n        w = w + model.dlatent_avg.buff.data[0]\n        w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n        layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n        cur_layers = (7 + 1) * 2\n        mixing_cutoff = cur_layers\n        styles = torch.where(layer_idx < mixing_cutoff, w, latents_original)\n        x_rec = decode(styles)\n        resultsample = ((x_rec * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255)\n        resultsample = resultsample.cpu()[0, :, :, :]\n        return resultsample.type(torch.uint8).transpose(0, 2).transpose(0, 1)",
            "def update_image(w, latents_original):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with torch.no_grad():\n        w = w + model.dlatent_avg.buff.data[0]\n        w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n        layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n        cur_layers = (7 + 1) * 2\n        mixing_cutoff = cur_layers\n        styles = torch.where(layer_idx < mixing_cutoff, w, latents_original)\n        x_rec = decode(styles)\n        resultsample = ((x_rec * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255)\n        resultsample = resultsample.cpu()[0, :, :, :]\n        return resultsample.type(torch.uint8).transpose(0, 2).transpose(0, 1)"
        ]
    },
    {
        "func_name": "sample",
        "original": "def sample(cfg, logger):\n    torch.cuda.set_device(0)\n    model = Model(startf=cfg.MODEL.START_CHANNEL_COUNT, layer_count=cfg.MODEL.LAYER_COUNT, maxf=cfg.MODEL.MAX_CHANNEL_COUNT, latent_size=cfg.MODEL.LATENT_SPACE_SIZE, truncation_psi=cfg.MODEL.TRUNCATIOM_PSI, truncation_cutoff=cfg.MODEL.TRUNCATIOM_CUTOFF, mapping_layers=cfg.MODEL.MAPPING_LAYERS, channels=cfg.MODEL.CHANNELS, generator=cfg.MODEL.GENERATOR, encoder=cfg.MODEL.ENCODER)\n    model.cuda(0)\n    model.eval()\n    model.requires_grad_(False)\n    decoder = model.decoder\n    encoder = model.encoder\n    mapping_tl = model.mapping_d\n    mapping_fl = model.mapping_f\n    dlatent_avg = model.dlatent_avg\n    logger.info('Trainable parameters generator:')\n    count_parameters(decoder)\n    logger.info('Trainable parameters discriminator:')\n    count_parameters(encoder)\n    arguments = dict()\n    arguments['iteration'] = 0\n    model_dict = {'discriminator_s': encoder, 'generator_s': decoder, 'mapping_tl_s': mapping_tl, 'mapping_fl_s': mapping_fl, 'dlatent_avg': dlatent_avg}\n    checkpointer = Checkpointer(cfg, model_dict, {}, logger=logger, save=False)\n    extra_checkpoint_data = checkpointer.load()\n    model.eval()\n    layer_count = cfg.MODEL.LAYER_COUNT\n\n    def encode(x):\n        (Z, _) = model.encode(x, layer_count - 1, 1)\n        Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n        return Z\n\n    def decode(x):\n        layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        return model.decoder(x, layer_count - 1, 1, noise=True)\n    path = 'dataset_samples/faces/realign1024x1024'\n    paths = list(os.listdir(path))\n    paths.sort()\n    paths_backup = paths[:]\n    randomize = bimpy.Bool(True)\n    current_file = bimpy.String('')\n    ctx = bimpy.Context()\n    attribute_values = [bimpy.Float(0) for i in indices]\n    W = [torch.tensor(np.load('principal_directions/direction_%d.npy' % i), dtype=torch.float32) for i in indices]\n    rnd = np.random.RandomState(5)\n\n    def loadNext():\n        img = np.asarray(Image.open(path + '/' + paths[0]))\n        current_file.value = paths[0]\n        paths.pop(0)\n        if len(paths) == 0:\n            paths.extend(paths_backup)\n        if img.shape[2] == 4:\n            img = img[:, :, :3]\n        im = img.transpose((2, 0, 1))\n        x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n        if x.shape[0] == 4:\n            x = x[:3]\n        needed_resolution = model.decoder.layer_to_resolution[-1]\n        while x.shape[2] > needed_resolution:\n            x = F.avg_pool2d(x, 2, 2)\n        if x.shape[2] != needed_resolution:\n            x = F.adaptive_avg_pool2d(x, (needed_resolution, needed_resolution))\n        img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n        latents_original = encode(x[None, ...].cuda())\n        latents = latents_original[0, 0].clone()\n        latents -= model.dlatent_avg.buff.data[0]\n        for (v, w) in zip(attribute_values, W):\n            v.value = (latents * w).sum()\n        for (v, w) in zip(attribute_values, W):\n            latents = latents - v.value * w\n        return (latents, latents_original, img_src)\n\n    def loadRandom():\n        latents = rnd.randn(1, cfg.MODEL.LATENT_SPACE_SIZE)\n        lat = torch.tensor(latents).float().cuda()\n        dlat = mapping_fl(lat)\n        layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        dlat = torch.lerp(model.dlatent_avg.buff.data, dlat, coefs)\n        x = decode(dlat)[0]\n        img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n        latents_original = dlat\n        latents = latents_original[0, 0].clone()\n        latents -= model.dlatent_avg.buff.data[0]\n        for (v, w) in zip(attribute_values, W):\n            v.value = (latents * w).sum()\n        for (v, w) in zip(attribute_values, W):\n            latents = latents - v.value * w\n        return (latents, latents_original, img_src)\n    (latents, latents_original, img_src) = loadNext()\n    ctx.init(1800, 1600, 'Styles')\n\n    def update_image(w, latents_original):\n        with torch.no_grad():\n            w = w + model.dlatent_avg.buff.data[0]\n            w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n            layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n            cur_layers = (7 + 1) * 2\n            mixing_cutoff = cur_layers\n            styles = torch.where(layer_idx < mixing_cutoff, w, latents_original)\n            x_rec = decode(styles)\n            resultsample = ((x_rec * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255)\n            resultsample = resultsample.cpu()[0, :, :, :]\n            return resultsample.type(torch.uint8).transpose(0, 2).transpose(0, 1)\n    im_size = 2 ** (cfg.MODEL.LAYER_COUNT + 1)\n    im = update_image(latents, latents_original)\n    print(im.shape)\n    im = bimpy.Image(im)\n    display_original = True\n    seed = 0\n    while not ctx.should_close():\n        with ctx:\n            new_latents = latents + sum([v.value * w for (v, w) in zip(attribute_values, W)])\n            if display_original:\n                im = bimpy.Image(img_src)\n            else:\n                im = bimpy.Image(update_image(new_latents, latents_original))\n            bimpy.begin('Principal directions')\n            bimpy.columns(2)\n            bimpy.set_column_width(0, im_size + 20)\n            bimpy.image(im)\n            bimpy.next_column()\n            for (v, label) in zip(attribute_values, labels):\n                bimpy.slider_float(label, v, -40.0, 40.0)\n            bimpy.checkbox('Randomize noise', randomize)\n            if randomize.value:\n                seed += 1\n            torch.manual_seed(seed)\n            if bimpy.button('Next'):\n                (latents, latents_original, img_src) = loadNext()\n                display_original = True\n            if bimpy.button('Display Reconstruction'):\n                display_original = False\n            if bimpy.button('Generate random'):\n                (latents, latents_original, img_src) = loadRandom()\n                display_original = False\n            if bimpy.input_text('Current file', current_file, 64) and os.path.exists(path + '/' + current_file.value):\n                paths.insert(0, current_file.value)\n                (latents, latents_original, img_src) = loadNext()\n            bimpy.end()",
        "mutated": [
            "def sample(cfg, logger):\n    if False:\n        i = 10\n    torch.cuda.set_device(0)\n    model = Model(startf=cfg.MODEL.START_CHANNEL_COUNT, layer_count=cfg.MODEL.LAYER_COUNT, maxf=cfg.MODEL.MAX_CHANNEL_COUNT, latent_size=cfg.MODEL.LATENT_SPACE_SIZE, truncation_psi=cfg.MODEL.TRUNCATIOM_PSI, truncation_cutoff=cfg.MODEL.TRUNCATIOM_CUTOFF, mapping_layers=cfg.MODEL.MAPPING_LAYERS, channels=cfg.MODEL.CHANNELS, generator=cfg.MODEL.GENERATOR, encoder=cfg.MODEL.ENCODER)\n    model.cuda(0)\n    model.eval()\n    model.requires_grad_(False)\n    decoder = model.decoder\n    encoder = model.encoder\n    mapping_tl = model.mapping_d\n    mapping_fl = model.mapping_f\n    dlatent_avg = model.dlatent_avg\n    logger.info('Trainable parameters generator:')\n    count_parameters(decoder)\n    logger.info('Trainable parameters discriminator:')\n    count_parameters(encoder)\n    arguments = dict()\n    arguments['iteration'] = 0\n    model_dict = {'discriminator_s': encoder, 'generator_s': decoder, 'mapping_tl_s': mapping_tl, 'mapping_fl_s': mapping_fl, 'dlatent_avg': dlatent_avg}\n    checkpointer = Checkpointer(cfg, model_dict, {}, logger=logger, save=False)\n    extra_checkpoint_data = checkpointer.load()\n    model.eval()\n    layer_count = cfg.MODEL.LAYER_COUNT\n\n    def encode(x):\n        (Z, _) = model.encode(x, layer_count - 1, 1)\n        Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n        return Z\n\n    def decode(x):\n        layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        return model.decoder(x, layer_count - 1, 1, noise=True)\n    path = 'dataset_samples/faces/realign1024x1024'\n    paths = list(os.listdir(path))\n    paths.sort()\n    paths_backup = paths[:]\n    randomize = bimpy.Bool(True)\n    current_file = bimpy.String('')\n    ctx = bimpy.Context()\n    attribute_values = [bimpy.Float(0) for i in indices]\n    W = [torch.tensor(np.load('principal_directions/direction_%d.npy' % i), dtype=torch.float32) for i in indices]\n    rnd = np.random.RandomState(5)\n\n    def loadNext():\n        img = np.asarray(Image.open(path + '/' + paths[0]))\n        current_file.value = paths[0]\n        paths.pop(0)\n        if len(paths) == 0:\n            paths.extend(paths_backup)\n        if img.shape[2] == 4:\n            img = img[:, :, :3]\n        im = img.transpose((2, 0, 1))\n        x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n        if x.shape[0] == 4:\n            x = x[:3]\n        needed_resolution = model.decoder.layer_to_resolution[-1]\n        while x.shape[2] > needed_resolution:\n            x = F.avg_pool2d(x, 2, 2)\n        if x.shape[2] != needed_resolution:\n            x = F.adaptive_avg_pool2d(x, (needed_resolution, needed_resolution))\n        img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n        latents_original = encode(x[None, ...].cuda())\n        latents = latents_original[0, 0].clone()\n        latents -= model.dlatent_avg.buff.data[0]\n        for (v, w) in zip(attribute_values, W):\n            v.value = (latents * w).sum()\n        for (v, w) in zip(attribute_values, W):\n            latents = latents - v.value * w\n        return (latents, latents_original, img_src)\n\n    def loadRandom():\n        latents = rnd.randn(1, cfg.MODEL.LATENT_SPACE_SIZE)\n        lat = torch.tensor(latents).float().cuda()\n        dlat = mapping_fl(lat)\n        layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        dlat = torch.lerp(model.dlatent_avg.buff.data, dlat, coefs)\n        x = decode(dlat)[0]\n        img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n        latents_original = dlat\n        latents = latents_original[0, 0].clone()\n        latents -= model.dlatent_avg.buff.data[0]\n        for (v, w) in zip(attribute_values, W):\n            v.value = (latents * w).sum()\n        for (v, w) in zip(attribute_values, W):\n            latents = latents - v.value * w\n        return (latents, latents_original, img_src)\n    (latents, latents_original, img_src) = loadNext()\n    ctx.init(1800, 1600, 'Styles')\n\n    def update_image(w, latents_original):\n        with torch.no_grad():\n            w = w + model.dlatent_avg.buff.data[0]\n            w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n            layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n            cur_layers = (7 + 1) * 2\n            mixing_cutoff = cur_layers\n            styles = torch.where(layer_idx < mixing_cutoff, w, latents_original)\n            x_rec = decode(styles)\n            resultsample = ((x_rec * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255)\n            resultsample = resultsample.cpu()[0, :, :, :]\n            return resultsample.type(torch.uint8).transpose(0, 2).transpose(0, 1)\n    im_size = 2 ** (cfg.MODEL.LAYER_COUNT + 1)\n    im = update_image(latents, latents_original)\n    print(im.shape)\n    im = bimpy.Image(im)\n    display_original = True\n    seed = 0\n    while not ctx.should_close():\n        with ctx:\n            new_latents = latents + sum([v.value * w for (v, w) in zip(attribute_values, W)])\n            if display_original:\n                im = bimpy.Image(img_src)\n            else:\n                im = bimpy.Image(update_image(new_latents, latents_original))\n            bimpy.begin('Principal directions')\n            bimpy.columns(2)\n            bimpy.set_column_width(0, im_size + 20)\n            bimpy.image(im)\n            bimpy.next_column()\n            for (v, label) in zip(attribute_values, labels):\n                bimpy.slider_float(label, v, -40.0, 40.0)\n            bimpy.checkbox('Randomize noise', randomize)\n            if randomize.value:\n                seed += 1\n            torch.manual_seed(seed)\n            if bimpy.button('Next'):\n                (latents, latents_original, img_src) = loadNext()\n                display_original = True\n            if bimpy.button('Display Reconstruction'):\n                display_original = False\n            if bimpy.button('Generate random'):\n                (latents, latents_original, img_src) = loadRandom()\n                display_original = False\n            if bimpy.input_text('Current file', current_file, 64) and os.path.exists(path + '/' + current_file.value):\n                paths.insert(0, current_file.value)\n                (latents, latents_original, img_src) = loadNext()\n            bimpy.end()",
            "def sample(cfg, logger):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    torch.cuda.set_device(0)\n    model = Model(startf=cfg.MODEL.START_CHANNEL_COUNT, layer_count=cfg.MODEL.LAYER_COUNT, maxf=cfg.MODEL.MAX_CHANNEL_COUNT, latent_size=cfg.MODEL.LATENT_SPACE_SIZE, truncation_psi=cfg.MODEL.TRUNCATIOM_PSI, truncation_cutoff=cfg.MODEL.TRUNCATIOM_CUTOFF, mapping_layers=cfg.MODEL.MAPPING_LAYERS, channels=cfg.MODEL.CHANNELS, generator=cfg.MODEL.GENERATOR, encoder=cfg.MODEL.ENCODER)\n    model.cuda(0)\n    model.eval()\n    model.requires_grad_(False)\n    decoder = model.decoder\n    encoder = model.encoder\n    mapping_tl = model.mapping_d\n    mapping_fl = model.mapping_f\n    dlatent_avg = model.dlatent_avg\n    logger.info('Trainable parameters generator:')\n    count_parameters(decoder)\n    logger.info('Trainable parameters discriminator:')\n    count_parameters(encoder)\n    arguments = dict()\n    arguments['iteration'] = 0\n    model_dict = {'discriminator_s': encoder, 'generator_s': decoder, 'mapping_tl_s': mapping_tl, 'mapping_fl_s': mapping_fl, 'dlatent_avg': dlatent_avg}\n    checkpointer = Checkpointer(cfg, model_dict, {}, logger=logger, save=False)\n    extra_checkpoint_data = checkpointer.load()\n    model.eval()\n    layer_count = cfg.MODEL.LAYER_COUNT\n\n    def encode(x):\n        (Z, _) = model.encode(x, layer_count - 1, 1)\n        Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n        return Z\n\n    def decode(x):\n        layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        return model.decoder(x, layer_count - 1, 1, noise=True)\n    path = 'dataset_samples/faces/realign1024x1024'\n    paths = list(os.listdir(path))\n    paths.sort()\n    paths_backup = paths[:]\n    randomize = bimpy.Bool(True)\n    current_file = bimpy.String('')\n    ctx = bimpy.Context()\n    attribute_values = [bimpy.Float(0) for i in indices]\n    W = [torch.tensor(np.load('principal_directions/direction_%d.npy' % i), dtype=torch.float32) for i in indices]\n    rnd = np.random.RandomState(5)\n\n    def loadNext():\n        img = np.asarray(Image.open(path + '/' + paths[0]))\n        current_file.value = paths[0]\n        paths.pop(0)\n        if len(paths) == 0:\n            paths.extend(paths_backup)\n        if img.shape[2] == 4:\n            img = img[:, :, :3]\n        im = img.transpose((2, 0, 1))\n        x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n        if x.shape[0] == 4:\n            x = x[:3]\n        needed_resolution = model.decoder.layer_to_resolution[-1]\n        while x.shape[2] > needed_resolution:\n            x = F.avg_pool2d(x, 2, 2)\n        if x.shape[2] != needed_resolution:\n            x = F.adaptive_avg_pool2d(x, (needed_resolution, needed_resolution))\n        img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n        latents_original = encode(x[None, ...].cuda())\n        latents = latents_original[0, 0].clone()\n        latents -= model.dlatent_avg.buff.data[0]\n        for (v, w) in zip(attribute_values, W):\n            v.value = (latents * w).sum()\n        for (v, w) in zip(attribute_values, W):\n            latents = latents - v.value * w\n        return (latents, latents_original, img_src)\n\n    def loadRandom():\n        latents = rnd.randn(1, cfg.MODEL.LATENT_SPACE_SIZE)\n        lat = torch.tensor(latents).float().cuda()\n        dlat = mapping_fl(lat)\n        layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        dlat = torch.lerp(model.dlatent_avg.buff.data, dlat, coefs)\n        x = decode(dlat)[0]\n        img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n        latents_original = dlat\n        latents = latents_original[0, 0].clone()\n        latents -= model.dlatent_avg.buff.data[0]\n        for (v, w) in zip(attribute_values, W):\n            v.value = (latents * w).sum()\n        for (v, w) in zip(attribute_values, W):\n            latents = latents - v.value * w\n        return (latents, latents_original, img_src)\n    (latents, latents_original, img_src) = loadNext()\n    ctx.init(1800, 1600, 'Styles')\n\n    def update_image(w, latents_original):\n        with torch.no_grad():\n            w = w + model.dlatent_avg.buff.data[0]\n            w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n            layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n            cur_layers = (7 + 1) * 2\n            mixing_cutoff = cur_layers\n            styles = torch.where(layer_idx < mixing_cutoff, w, latents_original)\n            x_rec = decode(styles)\n            resultsample = ((x_rec * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255)\n            resultsample = resultsample.cpu()[0, :, :, :]\n            return resultsample.type(torch.uint8).transpose(0, 2).transpose(0, 1)\n    im_size = 2 ** (cfg.MODEL.LAYER_COUNT + 1)\n    im = update_image(latents, latents_original)\n    print(im.shape)\n    im = bimpy.Image(im)\n    display_original = True\n    seed = 0\n    while not ctx.should_close():\n        with ctx:\n            new_latents = latents + sum([v.value * w for (v, w) in zip(attribute_values, W)])\n            if display_original:\n                im = bimpy.Image(img_src)\n            else:\n                im = bimpy.Image(update_image(new_latents, latents_original))\n            bimpy.begin('Principal directions')\n            bimpy.columns(2)\n            bimpy.set_column_width(0, im_size + 20)\n            bimpy.image(im)\n            bimpy.next_column()\n            for (v, label) in zip(attribute_values, labels):\n                bimpy.slider_float(label, v, -40.0, 40.0)\n            bimpy.checkbox('Randomize noise', randomize)\n            if randomize.value:\n                seed += 1\n            torch.manual_seed(seed)\n            if bimpy.button('Next'):\n                (latents, latents_original, img_src) = loadNext()\n                display_original = True\n            if bimpy.button('Display Reconstruction'):\n                display_original = False\n            if bimpy.button('Generate random'):\n                (latents, latents_original, img_src) = loadRandom()\n                display_original = False\n            if bimpy.input_text('Current file', current_file, 64) and os.path.exists(path + '/' + current_file.value):\n                paths.insert(0, current_file.value)\n                (latents, latents_original, img_src) = loadNext()\n            bimpy.end()",
            "def sample(cfg, logger):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    torch.cuda.set_device(0)\n    model = Model(startf=cfg.MODEL.START_CHANNEL_COUNT, layer_count=cfg.MODEL.LAYER_COUNT, maxf=cfg.MODEL.MAX_CHANNEL_COUNT, latent_size=cfg.MODEL.LATENT_SPACE_SIZE, truncation_psi=cfg.MODEL.TRUNCATIOM_PSI, truncation_cutoff=cfg.MODEL.TRUNCATIOM_CUTOFF, mapping_layers=cfg.MODEL.MAPPING_LAYERS, channels=cfg.MODEL.CHANNELS, generator=cfg.MODEL.GENERATOR, encoder=cfg.MODEL.ENCODER)\n    model.cuda(0)\n    model.eval()\n    model.requires_grad_(False)\n    decoder = model.decoder\n    encoder = model.encoder\n    mapping_tl = model.mapping_d\n    mapping_fl = model.mapping_f\n    dlatent_avg = model.dlatent_avg\n    logger.info('Trainable parameters generator:')\n    count_parameters(decoder)\n    logger.info('Trainable parameters discriminator:')\n    count_parameters(encoder)\n    arguments = dict()\n    arguments['iteration'] = 0\n    model_dict = {'discriminator_s': encoder, 'generator_s': decoder, 'mapping_tl_s': mapping_tl, 'mapping_fl_s': mapping_fl, 'dlatent_avg': dlatent_avg}\n    checkpointer = Checkpointer(cfg, model_dict, {}, logger=logger, save=False)\n    extra_checkpoint_data = checkpointer.load()\n    model.eval()\n    layer_count = cfg.MODEL.LAYER_COUNT\n\n    def encode(x):\n        (Z, _) = model.encode(x, layer_count - 1, 1)\n        Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n        return Z\n\n    def decode(x):\n        layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        return model.decoder(x, layer_count - 1, 1, noise=True)\n    path = 'dataset_samples/faces/realign1024x1024'\n    paths = list(os.listdir(path))\n    paths.sort()\n    paths_backup = paths[:]\n    randomize = bimpy.Bool(True)\n    current_file = bimpy.String('')\n    ctx = bimpy.Context()\n    attribute_values = [bimpy.Float(0) for i in indices]\n    W = [torch.tensor(np.load('principal_directions/direction_%d.npy' % i), dtype=torch.float32) for i in indices]\n    rnd = np.random.RandomState(5)\n\n    def loadNext():\n        img = np.asarray(Image.open(path + '/' + paths[0]))\n        current_file.value = paths[0]\n        paths.pop(0)\n        if len(paths) == 0:\n            paths.extend(paths_backup)\n        if img.shape[2] == 4:\n            img = img[:, :, :3]\n        im = img.transpose((2, 0, 1))\n        x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n        if x.shape[0] == 4:\n            x = x[:3]\n        needed_resolution = model.decoder.layer_to_resolution[-1]\n        while x.shape[2] > needed_resolution:\n            x = F.avg_pool2d(x, 2, 2)\n        if x.shape[2] != needed_resolution:\n            x = F.adaptive_avg_pool2d(x, (needed_resolution, needed_resolution))\n        img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n        latents_original = encode(x[None, ...].cuda())\n        latents = latents_original[0, 0].clone()\n        latents -= model.dlatent_avg.buff.data[0]\n        for (v, w) in zip(attribute_values, W):\n            v.value = (latents * w).sum()\n        for (v, w) in zip(attribute_values, W):\n            latents = latents - v.value * w\n        return (latents, latents_original, img_src)\n\n    def loadRandom():\n        latents = rnd.randn(1, cfg.MODEL.LATENT_SPACE_SIZE)\n        lat = torch.tensor(latents).float().cuda()\n        dlat = mapping_fl(lat)\n        layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        dlat = torch.lerp(model.dlatent_avg.buff.data, dlat, coefs)\n        x = decode(dlat)[0]\n        img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n        latents_original = dlat\n        latents = latents_original[0, 0].clone()\n        latents -= model.dlatent_avg.buff.data[0]\n        for (v, w) in zip(attribute_values, W):\n            v.value = (latents * w).sum()\n        for (v, w) in zip(attribute_values, W):\n            latents = latents - v.value * w\n        return (latents, latents_original, img_src)\n    (latents, latents_original, img_src) = loadNext()\n    ctx.init(1800, 1600, 'Styles')\n\n    def update_image(w, latents_original):\n        with torch.no_grad():\n            w = w + model.dlatent_avg.buff.data[0]\n            w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n            layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n            cur_layers = (7 + 1) * 2\n            mixing_cutoff = cur_layers\n            styles = torch.where(layer_idx < mixing_cutoff, w, latents_original)\n            x_rec = decode(styles)\n            resultsample = ((x_rec * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255)\n            resultsample = resultsample.cpu()[0, :, :, :]\n            return resultsample.type(torch.uint8).transpose(0, 2).transpose(0, 1)\n    im_size = 2 ** (cfg.MODEL.LAYER_COUNT + 1)\n    im = update_image(latents, latents_original)\n    print(im.shape)\n    im = bimpy.Image(im)\n    display_original = True\n    seed = 0\n    while not ctx.should_close():\n        with ctx:\n            new_latents = latents + sum([v.value * w for (v, w) in zip(attribute_values, W)])\n            if display_original:\n                im = bimpy.Image(img_src)\n            else:\n                im = bimpy.Image(update_image(new_latents, latents_original))\n            bimpy.begin('Principal directions')\n            bimpy.columns(2)\n            bimpy.set_column_width(0, im_size + 20)\n            bimpy.image(im)\n            bimpy.next_column()\n            for (v, label) in zip(attribute_values, labels):\n                bimpy.slider_float(label, v, -40.0, 40.0)\n            bimpy.checkbox('Randomize noise', randomize)\n            if randomize.value:\n                seed += 1\n            torch.manual_seed(seed)\n            if bimpy.button('Next'):\n                (latents, latents_original, img_src) = loadNext()\n                display_original = True\n            if bimpy.button('Display Reconstruction'):\n                display_original = False\n            if bimpy.button('Generate random'):\n                (latents, latents_original, img_src) = loadRandom()\n                display_original = False\n            if bimpy.input_text('Current file', current_file, 64) and os.path.exists(path + '/' + current_file.value):\n                paths.insert(0, current_file.value)\n                (latents, latents_original, img_src) = loadNext()\n            bimpy.end()",
            "def sample(cfg, logger):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    torch.cuda.set_device(0)\n    model = Model(startf=cfg.MODEL.START_CHANNEL_COUNT, layer_count=cfg.MODEL.LAYER_COUNT, maxf=cfg.MODEL.MAX_CHANNEL_COUNT, latent_size=cfg.MODEL.LATENT_SPACE_SIZE, truncation_psi=cfg.MODEL.TRUNCATIOM_PSI, truncation_cutoff=cfg.MODEL.TRUNCATIOM_CUTOFF, mapping_layers=cfg.MODEL.MAPPING_LAYERS, channels=cfg.MODEL.CHANNELS, generator=cfg.MODEL.GENERATOR, encoder=cfg.MODEL.ENCODER)\n    model.cuda(0)\n    model.eval()\n    model.requires_grad_(False)\n    decoder = model.decoder\n    encoder = model.encoder\n    mapping_tl = model.mapping_d\n    mapping_fl = model.mapping_f\n    dlatent_avg = model.dlatent_avg\n    logger.info('Trainable parameters generator:')\n    count_parameters(decoder)\n    logger.info('Trainable parameters discriminator:')\n    count_parameters(encoder)\n    arguments = dict()\n    arguments['iteration'] = 0\n    model_dict = {'discriminator_s': encoder, 'generator_s': decoder, 'mapping_tl_s': mapping_tl, 'mapping_fl_s': mapping_fl, 'dlatent_avg': dlatent_avg}\n    checkpointer = Checkpointer(cfg, model_dict, {}, logger=logger, save=False)\n    extra_checkpoint_data = checkpointer.load()\n    model.eval()\n    layer_count = cfg.MODEL.LAYER_COUNT\n\n    def encode(x):\n        (Z, _) = model.encode(x, layer_count - 1, 1)\n        Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n        return Z\n\n    def decode(x):\n        layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        return model.decoder(x, layer_count - 1, 1, noise=True)\n    path = 'dataset_samples/faces/realign1024x1024'\n    paths = list(os.listdir(path))\n    paths.sort()\n    paths_backup = paths[:]\n    randomize = bimpy.Bool(True)\n    current_file = bimpy.String('')\n    ctx = bimpy.Context()\n    attribute_values = [bimpy.Float(0) for i in indices]\n    W = [torch.tensor(np.load('principal_directions/direction_%d.npy' % i), dtype=torch.float32) for i in indices]\n    rnd = np.random.RandomState(5)\n\n    def loadNext():\n        img = np.asarray(Image.open(path + '/' + paths[0]))\n        current_file.value = paths[0]\n        paths.pop(0)\n        if len(paths) == 0:\n            paths.extend(paths_backup)\n        if img.shape[2] == 4:\n            img = img[:, :, :3]\n        im = img.transpose((2, 0, 1))\n        x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n        if x.shape[0] == 4:\n            x = x[:3]\n        needed_resolution = model.decoder.layer_to_resolution[-1]\n        while x.shape[2] > needed_resolution:\n            x = F.avg_pool2d(x, 2, 2)\n        if x.shape[2] != needed_resolution:\n            x = F.adaptive_avg_pool2d(x, (needed_resolution, needed_resolution))\n        img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n        latents_original = encode(x[None, ...].cuda())\n        latents = latents_original[0, 0].clone()\n        latents -= model.dlatent_avg.buff.data[0]\n        for (v, w) in zip(attribute_values, W):\n            v.value = (latents * w).sum()\n        for (v, w) in zip(attribute_values, W):\n            latents = latents - v.value * w\n        return (latents, latents_original, img_src)\n\n    def loadRandom():\n        latents = rnd.randn(1, cfg.MODEL.LATENT_SPACE_SIZE)\n        lat = torch.tensor(latents).float().cuda()\n        dlat = mapping_fl(lat)\n        layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        dlat = torch.lerp(model.dlatent_avg.buff.data, dlat, coefs)\n        x = decode(dlat)[0]\n        img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n        latents_original = dlat\n        latents = latents_original[0, 0].clone()\n        latents -= model.dlatent_avg.buff.data[0]\n        for (v, w) in zip(attribute_values, W):\n            v.value = (latents * w).sum()\n        for (v, w) in zip(attribute_values, W):\n            latents = latents - v.value * w\n        return (latents, latents_original, img_src)\n    (latents, latents_original, img_src) = loadNext()\n    ctx.init(1800, 1600, 'Styles')\n\n    def update_image(w, latents_original):\n        with torch.no_grad():\n            w = w + model.dlatent_avg.buff.data[0]\n            w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n            layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n            cur_layers = (7 + 1) * 2\n            mixing_cutoff = cur_layers\n            styles = torch.where(layer_idx < mixing_cutoff, w, latents_original)\n            x_rec = decode(styles)\n            resultsample = ((x_rec * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255)\n            resultsample = resultsample.cpu()[0, :, :, :]\n            return resultsample.type(torch.uint8).transpose(0, 2).transpose(0, 1)\n    im_size = 2 ** (cfg.MODEL.LAYER_COUNT + 1)\n    im = update_image(latents, latents_original)\n    print(im.shape)\n    im = bimpy.Image(im)\n    display_original = True\n    seed = 0\n    while not ctx.should_close():\n        with ctx:\n            new_latents = latents + sum([v.value * w for (v, w) in zip(attribute_values, W)])\n            if display_original:\n                im = bimpy.Image(img_src)\n            else:\n                im = bimpy.Image(update_image(new_latents, latents_original))\n            bimpy.begin('Principal directions')\n            bimpy.columns(2)\n            bimpy.set_column_width(0, im_size + 20)\n            bimpy.image(im)\n            bimpy.next_column()\n            for (v, label) in zip(attribute_values, labels):\n                bimpy.slider_float(label, v, -40.0, 40.0)\n            bimpy.checkbox('Randomize noise', randomize)\n            if randomize.value:\n                seed += 1\n            torch.manual_seed(seed)\n            if bimpy.button('Next'):\n                (latents, latents_original, img_src) = loadNext()\n                display_original = True\n            if bimpy.button('Display Reconstruction'):\n                display_original = False\n            if bimpy.button('Generate random'):\n                (latents, latents_original, img_src) = loadRandom()\n                display_original = False\n            if bimpy.input_text('Current file', current_file, 64) and os.path.exists(path + '/' + current_file.value):\n                paths.insert(0, current_file.value)\n                (latents, latents_original, img_src) = loadNext()\n            bimpy.end()",
            "def sample(cfg, logger):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    torch.cuda.set_device(0)\n    model = Model(startf=cfg.MODEL.START_CHANNEL_COUNT, layer_count=cfg.MODEL.LAYER_COUNT, maxf=cfg.MODEL.MAX_CHANNEL_COUNT, latent_size=cfg.MODEL.LATENT_SPACE_SIZE, truncation_psi=cfg.MODEL.TRUNCATIOM_PSI, truncation_cutoff=cfg.MODEL.TRUNCATIOM_CUTOFF, mapping_layers=cfg.MODEL.MAPPING_LAYERS, channels=cfg.MODEL.CHANNELS, generator=cfg.MODEL.GENERATOR, encoder=cfg.MODEL.ENCODER)\n    model.cuda(0)\n    model.eval()\n    model.requires_grad_(False)\n    decoder = model.decoder\n    encoder = model.encoder\n    mapping_tl = model.mapping_d\n    mapping_fl = model.mapping_f\n    dlatent_avg = model.dlatent_avg\n    logger.info('Trainable parameters generator:')\n    count_parameters(decoder)\n    logger.info('Trainable parameters discriminator:')\n    count_parameters(encoder)\n    arguments = dict()\n    arguments['iteration'] = 0\n    model_dict = {'discriminator_s': encoder, 'generator_s': decoder, 'mapping_tl_s': mapping_tl, 'mapping_fl_s': mapping_fl, 'dlatent_avg': dlatent_avg}\n    checkpointer = Checkpointer(cfg, model_dict, {}, logger=logger, save=False)\n    extra_checkpoint_data = checkpointer.load()\n    model.eval()\n    layer_count = cfg.MODEL.LAYER_COUNT\n\n    def encode(x):\n        (Z, _) = model.encode(x, layer_count - 1, 1)\n        Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n        return Z\n\n    def decode(x):\n        layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        return model.decoder(x, layer_count - 1, 1, noise=True)\n    path = 'dataset_samples/faces/realign1024x1024'\n    paths = list(os.listdir(path))\n    paths.sort()\n    paths_backup = paths[:]\n    randomize = bimpy.Bool(True)\n    current_file = bimpy.String('')\n    ctx = bimpy.Context()\n    attribute_values = [bimpy.Float(0) for i in indices]\n    W = [torch.tensor(np.load('principal_directions/direction_%d.npy' % i), dtype=torch.float32) for i in indices]\n    rnd = np.random.RandomState(5)\n\n    def loadNext():\n        img = np.asarray(Image.open(path + '/' + paths[0]))\n        current_file.value = paths[0]\n        paths.pop(0)\n        if len(paths) == 0:\n            paths.extend(paths_backup)\n        if img.shape[2] == 4:\n            img = img[:, :, :3]\n        im = img.transpose((2, 0, 1))\n        x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n        if x.shape[0] == 4:\n            x = x[:3]\n        needed_resolution = model.decoder.layer_to_resolution[-1]\n        while x.shape[2] > needed_resolution:\n            x = F.avg_pool2d(x, 2, 2)\n        if x.shape[2] != needed_resolution:\n            x = F.adaptive_avg_pool2d(x, (needed_resolution, needed_resolution))\n        img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n        latents_original = encode(x[None, ...].cuda())\n        latents = latents_original[0, 0].clone()\n        latents -= model.dlatent_avg.buff.data[0]\n        for (v, w) in zip(attribute_values, W):\n            v.value = (latents * w).sum()\n        for (v, w) in zip(attribute_values, W):\n            latents = latents - v.value * w\n        return (latents, latents_original, img_src)\n\n    def loadRandom():\n        latents = rnd.randn(1, cfg.MODEL.LATENT_SPACE_SIZE)\n        lat = torch.tensor(latents).float().cuda()\n        dlat = mapping_fl(lat)\n        layer_idx = torch.arange(2 * layer_count)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        dlat = torch.lerp(model.dlatent_avg.buff.data, dlat, coefs)\n        x = decode(dlat)[0]\n        img_src = ((x * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255).cpu().type(torch.uint8).transpose(0, 2).transpose(0, 1).numpy()\n        latents_original = dlat\n        latents = latents_original[0, 0].clone()\n        latents -= model.dlatent_avg.buff.data[0]\n        for (v, w) in zip(attribute_values, W):\n            v.value = (latents * w).sum()\n        for (v, w) in zip(attribute_values, W):\n            latents = latents - v.value * w\n        return (latents, latents_original, img_src)\n    (latents, latents_original, img_src) = loadNext()\n    ctx.init(1800, 1600, 'Styles')\n\n    def update_image(w, latents_original):\n        with torch.no_grad():\n            w = w + model.dlatent_avg.buff.data[0]\n            w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n            layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n            cur_layers = (7 + 1) * 2\n            mixing_cutoff = cur_layers\n            styles = torch.where(layer_idx < mixing_cutoff, w, latents_original)\n            x_rec = decode(styles)\n            resultsample = ((x_rec * 0.5 + 0.5) * 255).type(torch.long).clamp(0, 255)\n            resultsample = resultsample.cpu()[0, :, :, :]\n            return resultsample.type(torch.uint8).transpose(0, 2).transpose(0, 1)\n    im_size = 2 ** (cfg.MODEL.LAYER_COUNT + 1)\n    im = update_image(latents, latents_original)\n    print(im.shape)\n    im = bimpy.Image(im)\n    display_original = True\n    seed = 0\n    while not ctx.should_close():\n        with ctx:\n            new_latents = latents + sum([v.value * w for (v, w) in zip(attribute_values, W)])\n            if display_original:\n                im = bimpy.Image(img_src)\n            else:\n                im = bimpy.Image(update_image(new_latents, latents_original))\n            bimpy.begin('Principal directions')\n            bimpy.columns(2)\n            bimpy.set_column_width(0, im_size + 20)\n            bimpy.image(im)\n            bimpy.next_column()\n            for (v, label) in zip(attribute_values, labels):\n                bimpy.slider_float(label, v, -40.0, 40.0)\n            bimpy.checkbox('Randomize noise', randomize)\n            if randomize.value:\n                seed += 1\n            torch.manual_seed(seed)\n            if bimpy.button('Next'):\n                (latents, latents_original, img_src) = loadNext()\n                display_original = True\n            if bimpy.button('Display Reconstruction'):\n                display_original = False\n            if bimpy.button('Generate random'):\n                (latents, latents_original, img_src) = loadRandom()\n                display_original = False\n            if bimpy.input_text('Current file', current_file, 64) and os.path.exists(path + '/' + current_file.value):\n                paths.insert(0, current_file.value)\n                (latents, latents_original, img_src) = loadNext()\n            bimpy.end()"
        ]
    }
]