[
    {
        "func_name": "topstories",
        "original": "@asset(deps=[topstory_ids])\ndef topstories(context: AssetExecutionContext) -> MaterializeResult:\n    with open('data/topstory_ids.json', 'r') as f:\n        topstory_ids = json.load(f)\n    results = []\n    for item_id in topstory_ids:\n        item = requests.get(f'https://hacker-news.firebaseio.com/v0/item/{item_id}.json').json()\n        results.append(item)\n        if len(results) % 20 == 0:\n            context.log.info(f'Got {len(results)} items so far.')\n    df = pd.DataFrame(results)\n    df.to_csv('data/topstories.csv')\n    return MaterializeResult(metadata={'num_records': len(df), 'preview': MetadataValue.md(df.head().to_markdown())})",
        "mutated": [
            "@asset(deps=[topstory_ids])\ndef topstories(context: AssetExecutionContext) -> MaterializeResult:\n    if False:\n        i = 10\n    with open('data/topstory_ids.json', 'r') as f:\n        topstory_ids = json.load(f)\n    results = []\n    for item_id in topstory_ids:\n        item = requests.get(f'https://hacker-news.firebaseio.com/v0/item/{item_id}.json').json()\n        results.append(item)\n        if len(results) % 20 == 0:\n            context.log.info(f'Got {len(results)} items so far.')\n    df = pd.DataFrame(results)\n    df.to_csv('data/topstories.csv')\n    return MaterializeResult(metadata={'num_records': len(df), 'preview': MetadataValue.md(df.head().to_markdown())})",
            "@asset(deps=[topstory_ids])\ndef topstories(context: AssetExecutionContext) -> MaterializeResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with open('data/topstory_ids.json', 'r') as f:\n        topstory_ids = json.load(f)\n    results = []\n    for item_id in topstory_ids:\n        item = requests.get(f'https://hacker-news.firebaseio.com/v0/item/{item_id}.json').json()\n        results.append(item)\n        if len(results) % 20 == 0:\n            context.log.info(f'Got {len(results)} items so far.')\n    df = pd.DataFrame(results)\n    df.to_csv('data/topstories.csv')\n    return MaterializeResult(metadata={'num_records': len(df), 'preview': MetadataValue.md(df.head().to_markdown())})",
            "@asset(deps=[topstory_ids])\ndef topstories(context: AssetExecutionContext) -> MaterializeResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with open('data/topstory_ids.json', 'r') as f:\n        topstory_ids = json.load(f)\n    results = []\n    for item_id in topstory_ids:\n        item = requests.get(f'https://hacker-news.firebaseio.com/v0/item/{item_id}.json').json()\n        results.append(item)\n        if len(results) % 20 == 0:\n            context.log.info(f'Got {len(results)} items so far.')\n    df = pd.DataFrame(results)\n    df.to_csv('data/topstories.csv')\n    return MaterializeResult(metadata={'num_records': len(df), 'preview': MetadataValue.md(df.head().to_markdown())})",
            "@asset(deps=[topstory_ids])\ndef topstories(context: AssetExecutionContext) -> MaterializeResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with open('data/topstory_ids.json', 'r') as f:\n        topstory_ids = json.load(f)\n    results = []\n    for item_id in topstory_ids:\n        item = requests.get(f'https://hacker-news.firebaseio.com/v0/item/{item_id}.json').json()\n        results.append(item)\n        if len(results) % 20 == 0:\n            context.log.info(f'Got {len(results)} items so far.')\n    df = pd.DataFrame(results)\n    df.to_csv('data/topstories.csv')\n    return MaterializeResult(metadata={'num_records': len(df), 'preview': MetadataValue.md(df.head().to_markdown())})",
            "@asset(deps=[topstory_ids])\ndef topstories(context: AssetExecutionContext) -> MaterializeResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with open('data/topstory_ids.json', 'r') as f:\n        topstory_ids = json.load(f)\n    results = []\n    for item_id in topstory_ids:\n        item = requests.get(f'https://hacker-news.firebaseio.com/v0/item/{item_id}.json').json()\n        results.append(item)\n        if len(results) % 20 == 0:\n            context.log.info(f'Got {len(results)} items so far.')\n    df = pd.DataFrame(results)\n    df.to_csv('data/topstories.csv')\n    return MaterializeResult(metadata={'num_records': len(df), 'preview': MetadataValue.md(df.head().to_markdown())})"
        ]
    },
    {
        "func_name": "most_frequent_words",
        "original": "@asset(deps=[topstories])\ndef most_frequent_words() -> MaterializeResult:\n    stopwords = ['a', 'the', 'an', 'of', 'to', 'in', 'for', 'and', 'with', 'on', 'is']\n    topstories = pd.read_csv('data/topstories.csv')\n    word_counts = {}\n    for raw_title in topstories['title']:\n        title = raw_title.lower()\n        for word in title.split():\n            cleaned_word = word.strip('.,-!?:;()[]\\'\"-')\n            if cleaned_word not in stopwords and len(cleaned_word) > 0:\n                word_counts[cleaned_word] = word_counts.get(cleaned_word, 0) + 1\n    top_words = {pair[0]: pair[1] for pair in sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:25]}\n    plt.figure(figsize=(10, 6))\n    plt.bar(list(top_words.keys()), list(top_words.values()))\n    plt.xticks(rotation=45, ha='right')\n    plt.title('Top 25 Words in Hacker News Titles')\n    plt.tight_layout()\n    buffer = BytesIO()\n    plt.savefig(buffer, format='png')\n    image_data = base64.b64encode(buffer.getvalue())\n    md_content = f'![img](data:image/png;base64,{image_data.decode()})'\n    with open('data/most_frequent_words.json', 'w') as f:\n        json.dump(top_words, f)\n    return MaterializeResult(metadata={'plot': MetadataValue.md(md_content)})",
        "mutated": [
            "@asset(deps=[topstories])\ndef most_frequent_words() -> MaterializeResult:\n    if False:\n        i = 10\n    stopwords = ['a', 'the', 'an', 'of', 'to', 'in', 'for', 'and', 'with', 'on', 'is']\n    topstories = pd.read_csv('data/topstories.csv')\n    word_counts = {}\n    for raw_title in topstories['title']:\n        title = raw_title.lower()\n        for word in title.split():\n            cleaned_word = word.strip('.,-!?:;()[]\\'\"-')\n            if cleaned_word not in stopwords and len(cleaned_word) > 0:\n                word_counts[cleaned_word] = word_counts.get(cleaned_word, 0) + 1\n    top_words = {pair[0]: pair[1] for pair in sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:25]}\n    plt.figure(figsize=(10, 6))\n    plt.bar(list(top_words.keys()), list(top_words.values()))\n    plt.xticks(rotation=45, ha='right')\n    plt.title('Top 25 Words in Hacker News Titles')\n    plt.tight_layout()\n    buffer = BytesIO()\n    plt.savefig(buffer, format='png')\n    image_data = base64.b64encode(buffer.getvalue())\n    md_content = f'![img](data:image/png;base64,{image_data.decode()})'\n    with open('data/most_frequent_words.json', 'w') as f:\n        json.dump(top_words, f)\n    return MaterializeResult(metadata={'plot': MetadataValue.md(md_content)})",
            "@asset(deps=[topstories])\ndef most_frequent_words() -> MaterializeResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    stopwords = ['a', 'the', 'an', 'of', 'to', 'in', 'for', 'and', 'with', 'on', 'is']\n    topstories = pd.read_csv('data/topstories.csv')\n    word_counts = {}\n    for raw_title in topstories['title']:\n        title = raw_title.lower()\n        for word in title.split():\n            cleaned_word = word.strip('.,-!?:;()[]\\'\"-')\n            if cleaned_word not in stopwords and len(cleaned_word) > 0:\n                word_counts[cleaned_word] = word_counts.get(cleaned_word, 0) + 1\n    top_words = {pair[0]: pair[1] for pair in sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:25]}\n    plt.figure(figsize=(10, 6))\n    plt.bar(list(top_words.keys()), list(top_words.values()))\n    plt.xticks(rotation=45, ha='right')\n    plt.title('Top 25 Words in Hacker News Titles')\n    plt.tight_layout()\n    buffer = BytesIO()\n    plt.savefig(buffer, format='png')\n    image_data = base64.b64encode(buffer.getvalue())\n    md_content = f'![img](data:image/png;base64,{image_data.decode()})'\n    with open('data/most_frequent_words.json', 'w') as f:\n        json.dump(top_words, f)\n    return MaterializeResult(metadata={'plot': MetadataValue.md(md_content)})",
            "@asset(deps=[topstories])\ndef most_frequent_words() -> MaterializeResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    stopwords = ['a', 'the', 'an', 'of', 'to', 'in', 'for', 'and', 'with', 'on', 'is']\n    topstories = pd.read_csv('data/topstories.csv')\n    word_counts = {}\n    for raw_title in topstories['title']:\n        title = raw_title.lower()\n        for word in title.split():\n            cleaned_word = word.strip('.,-!?:;()[]\\'\"-')\n            if cleaned_word not in stopwords and len(cleaned_word) > 0:\n                word_counts[cleaned_word] = word_counts.get(cleaned_word, 0) + 1\n    top_words = {pair[0]: pair[1] for pair in sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:25]}\n    plt.figure(figsize=(10, 6))\n    plt.bar(list(top_words.keys()), list(top_words.values()))\n    plt.xticks(rotation=45, ha='right')\n    plt.title('Top 25 Words in Hacker News Titles')\n    plt.tight_layout()\n    buffer = BytesIO()\n    plt.savefig(buffer, format='png')\n    image_data = base64.b64encode(buffer.getvalue())\n    md_content = f'![img](data:image/png;base64,{image_data.decode()})'\n    with open('data/most_frequent_words.json', 'w') as f:\n        json.dump(top_words, f)\n    return MaterializeResult(metadata={'plot': MetadataValue.md(md_content)})",
            "@asset(deps=[topstories])\ndef most_frequent_words() -> MaterializeResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    stopwords = ['a', 'the', 'an', 'of', 'to', 'in', 'for', 'and', 'with', 'on', 'is']\n    topstories = pd.read_csv('data/topstories.csv')\n    word_counts = {}\n    for raw_title in topstories['title']:\n        title = raw_title.lower()\n        for word in title.split():\n            cleaned_word = word.strip('.,-!?:;()[]\\'\"-')\n            if cleaned_word not in stopwords and len(cleaned_word) > 0:\n                word_counts[cleaned_word] = word_counts.get(cleaned_word, 0) + 1\n    top_words = {pair[0]: pair[1] for pair in sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:25]}\n    plt.figure(figsize=(10, 6))\n    plt.bar(list(top_words.keys()), list(top_words.values()))\n    plt.xticks(rotation=45, ha='right')\n    plt.title('Top 25 Words in Hacker News Titles')\n    plt.tight_layout()\n    buffer = BytesIO()\n    plt.savefig(buffer, format='png')\n    image_data = base64.b64encode(buffer.getvalue())\n    md_content = f'![img](data:image/png;base64,{image_data.decode()})'\n    with open('data/most_frequent_words.json', 'w') as f:\n        json.dump(top_words, f)\n    return MaterializeResult(metadata={'plot': MetadataValue.md(md_content)})",
            "@asset(deps=[topstories])\ndef most_frequent_words() -> MaterializeResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    stopwords = ['a', 'the', 'an', 'of', 'to', 'in', 'for', 'and', 'with', 'on', 'is']\n    topstories = pd.read_csv('data/topstories.csv')\n    word_counts = {}\n    for raw_title in topstories['title']:\n        title = raw_title.lower()\n        for word in title.split():\n            cleaned_word = word.strip('.,-!?:;()[]\\'\"-')\n            if cleaned_word not in stopwords and len(cleaned_word) > 0:\n                word_counts[cleaned_word] = word_counts.get(cleaned_word, 0) + 1\n    top_words = {pair[0]: pair[1] for pair in sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:25]}\n    plt.figure(figsize=(10, 6))\n    plt.bar(list(top_words.keys()), list(top_words.values()))\n    plt.xticks(rotation=45, ha='right')\n    plt.title('Top 25 Words in Hacker News Titles')\n    plt.tight_layout()\n    buffer = BytesIO()\n    plt.savefig(buffer, format='png')\n    image_data = base64.b64encode(buffer.getvalue())\n    md_content = f'![img](data:image/png;base64,{image_data.decode()})'\n    with open('data/most_frequent_words.json', 'w') as f:\n        json.dump(top_words, f)\n    return MaterializeResult(metadata={'plot': MetadataValue.md(md_content)})"
        ]
    }
]