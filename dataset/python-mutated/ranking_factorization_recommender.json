[
    {
        "func_name": "create",
        "original": "def create(observation_data, user_id='user_id', item_id='item_id', target=None, user_data=None, item_data=None, num_factors=32, regularization=1e-09, linear_regularization=1e-09, side_data_factorization=True, ranking_regularization=0.25, unobserved_rating_value=None, num_sampled_negative_examples=4, max_iterations=25, sgd_step_size=0, random_seed=0, binary_target=False, solver='auto', verbose=True, **kwargs):\n    \"\"\"Create a RankingFactorizationRecommender that learns latent factors for each\n    user and item and uses them to make rating predictions.\n\n    Parameters\n    ----------\n    observation_data : SFrame\n        The dataset to use for training the model. It must contain a column of\n        user ids and a column of item ids. Each row represents an observed\n        interaction between the user and the item.  The (user, item) pairs\n        are stored with the model so that they can later be excluded from\n        recommendations if desired. It can optionally contain a target ratings\n        column. All other columns are interpreted by the underlying model as\n        side features for the observations.\n\n        The user id and item id columns must be of type 'int' or 'str'. The\n        target column must be of type 'int' or 'float'.\n\n    user_id : string, optional\n        The name of the column in `observation_data` that corresponds to the\n        user id.\n\n    item_id : string, optional\n        The name of the column in `observation_data` that corresponds to the\n        item id.\n\n    target : string, optional\n        The `observation_data` can optionally contain a column of scores\n        representing ratings given by the users. If present, the name of this\n        column may be specified variables `target`.\n\n    user_data : SFrame, optional\n        Side information for the users.  This SFrame must have a column with\n        the same name as what is specified by the `user_id` input parameter.\n        `user_data` can provide any amount of additional user-specific\n        information.\n\n    item_data : SFrame, optional\n        Side information for the items.  This SFrame must have a column with\n        the same name as what is specified by the `item_id` input parameter.\n        `item_data` can provide any amount of additional item-specific\n        information.\n\n    num_factors : int, optional\n        Number of latent factors.\n\n    regularization : float, optional\n        L2 regularization for interaction terms. Default: 1e-10; a typical range\n        for this parameter is between 1e-12 and 1. Setting this to 0 may cause\n        numerical issues.\n\n    linear_regularization : float, optional\n        L2 regularization for linear term. Default: 1e-10; a typical range for this\n        parameter is between 1e-12 and 1. Setting this to 0 may cause numerical issues.\n\n    side_data_factorization : boolean, optional\n        Use factorization for modeling any additional features beyond the user\n        and item columns. If True, and side features or any additional columns are\n        present, then a Factorization Machine model is trained. Otherwise, only\n        the linear terms are fit to these features.  See\n        :class:`turicreate.recommender.ranking_factorization_recommender.RankingFactorizationRecommender`\n        for more information. Default: True.\n\n    ranking_regularization : float, optional\n        Penalize the predicted value of user-item pairs not in the\n        training set. Larger values increase this penalization.\n        Suggested values: 0, 0.1, 0.5, 1.  NOTE: if no target column\n        is present, this parameter is ignored.\n\n    unobserved_rating_value : float, optional\n        Penalize unobserved items with a larger predicted score than this value.\n        By default, the estimated 5% quantile is used (mean - 1.96*std_dev).\n\n    num_sampled_negative_examples : integer, optional\n        For each (user, item) pair in the data, the ranking sgd solver evaluates\n        this many randomly chosen unseen items for the negative example step.\n        Increasing this can give better performance at the expense of speed,\n        particularly when the number of items is large.  Default is 4.\n\n    binary_target : boolean, optional\n        Assume the target column is composed of 0's and 1's. If True, use\n        logistic loss to fit the model.\n\n    max_iterations : int, optional\n        The training algorithm will make at most this many iterations through\n        the observed data. Default: 50.\n\n    sgd_step_size : float, optional\n        Step size for stochastic gradient descent. Smaller values generally\n        lead to more accurate models that take more time to train. The\n        default setting of 0 means that the step size is chosen by trying\n        several options on a small subset of the data.\n\n    random_seed :  int, optional\n        The random seed used to choose the initial starting point for\n        model training. Note that some randomness in the training is\n        unavoidable, so models trained with the same random seed may still\n        differ. Default: 0.\n\n    solver : string, optional\n        Name of the solver to be used to solve the regression. See the\n        references for more detail on each solver. The available solvers for\n        this model are:\n\n        - *auto (default)*: automatically chooses the best solver for the data\n                              and model parameters.\n        - *ials*:           Implicit Alternating Least Squares [1].\n        - *adagrad*:        Adaptive Gradient Stochastic Gradient Descent.\n        - *sgd*:            Stochastic Gradient Descent\n\n    verbose : bool, optional\n        Enables verbose output.\n\n    kwargs : optional\n        Optional advanced keyword arguments passed in to the model\n        optimization procedure. These parameters do not typically\n        need to be changed.\n\n    Examples\n    --------\n    **Basic usage**\n\n    When given just user and item pairs, one can create a RankingFactorizationRecommender\n    as follows.\n\n    >>> sf = turicreate.SFrame({'user_id': [\"0\", \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"2\"],\n    ...                       'item_id': [\"a\", \"b\", \"c\", \"a\", \"b\", \"b\", \"c\", \"d\"])\n    >>> from turicreate.recommender import ranking_factorization_recommender\n    >>> m1 = ranking_factorization_recommender.create(sf)\n\n    When a target column is present, one can include this to try and recommend\n    items that are rated highly.\n\n    >>> sf = turicreate.SFrame({'user_id': [\"0\", \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"2\"],\n    ...                       'item_id': [\"a\", \"b\", \"c\", \"a\", \"b\", \"b\", \"c\", \"d\"],\n    ...                       'rating': [1, 3, 2, 5, 4, 1, 4, 3]})\n\n    >>> m1 = ranking_factorization_recommender.create(sf, target='rating')\n\n\n    **Including side features**\n\n    >>> user_info = turicreate.SFrame({'user_id': [\"0\", \"1\", \"2\"],\n    ...                              'name': [\"Alice\", \"Bob\", \"Charlie\"],\n    ...                              'numeric_feature': [0.1, 12, 22]})\n    >>> item_info = turicreate.SFrame({'item_id': [\"a\", \"b\", \"c\", \"d\"],\n    ...                              'name': [\"item1\", \"item2\", \"item3\", \"item4\"],\n    ...                              'dict_feature': [{'a' : 23}, {'a' : 13},\n    ...                                               {'b' : 1},\n    ...                                               {'a' : 23, 'b' : 32}]})\n    >>> m2 = ranking_factorization_recommender.create(sf, target='rating',\n    ...                                               user_data=user_info,\n    ...                                               item_data=item_info)\n\n    **Customizing ranking regularization**\n\n    Create a model that pushes predicted ratings of unobserved user-item\n    pairs toward 1 or below.\n\n    >>> m3 = ranking_factorization_recommender.create(sf, target='rating',\n    ...                                               ranking_regularization = 0.1,\n    ...                                               unobserved_rating_value = 1)\n\n    **Using the implicit alternating least squares model**\n\n    Ranking factorization also implements implicit alternating least squares [1] as\n    an alternative solver.  This is enable using ``solver = 'ials'``.\n\n    >>> m3 = ranking_factorization_recommender.create(sf, target='rating',\n                                                      solver = 'ials')\n\n    See Also\n    --------\n    :class:`turicreate.recommender.factorization_recommender.FactorizationRecommender`,\n    :class:`turicreate.recommender.ranking_factorization_recommender.RankingFactorizationRecommender`\n\n    References\n    -----------\n\n    [1] Collaborative Filtering for Implicit Feedback Datasets Hu, Y.; Koren,\n        Y.; Volinsky, C. IEEE International Conference on Data Mining\n        (ICDM 2008), IEEE (2008).\n\n    \"\"\"\n    from turicreate._cython.cy_server import QuietProgress\n    if not isinstance(observation_data, _SFrame):\n        raise TypeError('observation_data input must be a SFrame')\n    opts = {}\n    model_proxy = _turicreate.extensions.ranking_factorization_recommender()\n    model_proxy.init_options(opts)\n    if user_data is None:\n        user_data = _turicreate.SFrame()\n    if item_data is None:\n        item_data = _turicreate.SFrame()\n    if target is None:\n        binary_target = True\n    opts = {'user_id': user_id, 'item_id': item_id, 'target': target, 'random_seed': random_seed, 'num_factors': num_factors, 'regularization': regularization, 'linear_regularization': linear_regularization, 'ranking_regularization': ranking_regularization, 'binary_target': binary_target, 'max_iterations': max_iterations, 'side_data_factorization': side_data_factorization, 'num_sampled_negative_examples': num_sampled_negative_examples, 'solver': solver, 'sgd_step_size': sgd_step_size}\n    if unobserved_rating_value is not None:\n        opts['unobserved_rating_value'] = unobserved_rating_value\n    if kwargs:\n        try:\n            possible_args = set(_get_default_options()['name'])\n        except (RuntimeError, KeyError):\n            possible_args = set()\n        bad_arguments = set(kwargs.keys()).difference(possible_args)\n        if bad_arguments:\n            raise TypeError('Bad Keyword Arguments: ' + ', '.join(bad_arguments))\n        opts.update(kwargs)\n    extra_data = {'nearest_items': _turicreate.SFrame()}\n    with QuietProgress(verbose):\n        model_proxy.train(observation_data, user_data, item_data, opts, extra_data)\n    return RankingFactorizationRecommender(model_proxy)",
        "mutated": [
            "def create(observation_data, user_id='user_id', item_id='item_id', target=None, user_data=None, item_data=None, num_factors=32, regularization=1e-09, linear_regularization=1e-09, side_data_factorization=True, ranking_regularization=0.25, unobserved_rating_value=None, num_sampled_negative_examples=4, max_iterations=25, sgd_step_size=0, random_seed=0, binary_target=False, solver='auto', verbose=True, **kwargs):\n    if False:\n        i = 10\n    'Create a RankingFactorizationRecommender that learns latent factors for each\\n    user and item and uses them to make rating predictions.\\n\\n    Parameters\\n    ----------\\n    observation_data : SFrame\\n        The dataset to use for training the model. It must contain a column of\\n        user ids and a column of item ids. Each row represents an observed\\n        interaction between the user and the item.  The (user, item) pairs\\n        are stored with the model so that they can later be excluded from\\n        recommendations if desired. It can optionally contain a target ratings\\n        column. All other columns are interpreted by the underlying model as\\n        side features for the observations.\\n\\n        The user id and item id columns must be of type \\'int\\' or \\'str\\'. The\\n        target column must be of type \\'int\\' or \\'float\\'.\\n\\n    user_id : string, optional\\n        The name of the column in `observation_data` that corresponds to the\\n        user id.\\n\\n    item_id : string, optional\\n        The name of the column in `observation_data` that corresponds to the\\n        item id.\\n\\n    target : string, optional\\n        The `observation_data` can optionally contain a column of scores\\n        representing ratings given by the users. If present, the name of this\\n        column may be specified variables `target`.\\n\\n    user_data : SFrame, optional\\n        Side information for the users.  This SFrame must have a column with\\n        the same name as what is specified by the `user_id` input parameter.\\n        `user_data` can provide any amount of additional user-specific\\n        information.\\n\\n    item_data : SFrame, optional\\n        Side information for the items.  This SFrame must have a column with\\n        the same name as what is specified by the `item_id` input parameter.\\n        `item_data` can provide any amount of additional item-specific\\n        information.\\n\\n    num_factors : int, optional\\n        Number of latent factors.\\n\\n    regularization : float, optional\\n        L2 regularization for interaction terms. Default: 1e-10; a typical range\\n        for this parameter is between 1e-12 and 1. Setting this to 0 may cause\\n        numerical issues.\\n\\n    linear_regularization : float, optional\\n        L2 regularization for linear term. Default: 1e-10; a typical range for this\\n        parameter is between 1e-12 and 1. Setting this to 0 may cause numerical issues.\\n\\n    side_data_factorization : boolean, optional\\n        Use factorization for modeling any additional features beyond the user\\n        and item columns. If True, and side features or any additional columns are\\n        present, then a Factorization Machine model is trained. Otherwise, only\\n        the linear terms are fit to these features.  See\\n        :class:`turicreate.recommender.ranking_factorization_recommender.RankingFactorizationRecommender`\\n        for more information. Default: True.\\n\\n    ranking_regularization : float, optional\\n        Penalize the predicted value of user-item pairs not in the\\n        training set. Larger values increase this penalization.\\n        Suggested values: 0, 0.1, 0.5, 1.  NOTE: if no target column\\n        is present, this parameter is ignored.\\n\\n    unobserved_rating_value : float, optional\\n        Penalize unobserved items with a larger predicted score than this value.\\n        By default, the estimated 5% quantile is used (mean - 1.96*std_dev).\\n\\n    num_sampled_negative_examples : integer, optional\\n        For each (user, item) pair in the data, the ranking sgd solver evaluates\\n        this many randomly chosen unseen items for the negative example step.\\n        Increasing this can give better performance at the expense of speed,\\n        particularly when the number of items is large.  Default is 4.\\n\\n    binary_target : boolean, optional\\n        Assume the target column is composed of 0\\'s and 1\\'s. If True, use\\n        logistic loss to fit the model.\\n\\n    max_iterations : int, optional\\n        The training algorithm will make at most this many iterations through\\n        the observed data. Default: 50.\\n\\n    sgd_step_size : float, optional\\n        Step size for stochastic gradient descent. Smaller values generally\\n        lead to more accurate models that take more time to train. The\\n        default setting of 0 means that the step size is chosen by trying\\n        several options on a small subset of the data.\\n\\n    random_seed :  int, optional\\n        The random seed used to choose the initial starting point for\\n        model training. Note that some randomness in the training is\\n        unavoidable, so models trained with the same random seed may still\\n        differ. Default: 0.\\n\\n    solver : string, optional\\n        Name of the solver to be used to solve the regression. See the\\n        references for more detail on each solver. The available solvers for\\n        this model are:\\n\\n        - *auto (default)*: automatically chooses the best solver for the data\\n                              and model parameters.\\n        - *ials*:           Implicit Alternating Least Squares [1].\\n        - *adagrad*:        Adaptive Gradient Stochastic Gradient Descent.\\n        - *sgd*:            Stochastic Gradient Descent\\n\\n    verbose : bool, optional\\n        Enables verbose output.\\n\\n    kwargs : optional\\n        Optional advanced keyword arguments passed in to the model\\n        optimization procedure. These parameters do not typically\\n        need to be changed.\\n\\n    Examples\\n    --------\\n    **Basic usage**\\n\\n    When given just user and item pairs, one can create a RankingFactorizationRecommender\\n    as follows.\\n\\n    >>> sf = turicreate.SFrame({\\'user_id\\': [\"0\", \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"2\"],\\n    ...                       \\'item_id\\': [\"a\", \"b\", \"c\", \"a\", \"b\", \"b\", \"c\", \"d\"])\\n    >>> from turicreate.recommender import ranking_factorization_recommender\\n    >>> m1 = ranking_factorization_recommender.create(sf)\\n\\n    When a target column is present, one can include this to try and recommend\\n    items that are rated highly.\\n\\n    >>> sf = turicreate.SFrame({\\'user_id\\': [\"0\", \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"2\"],\\n    ...                       \\'item_id\\': [\"a\", \"b\", \"c\", \"a\", \"b\", \"b\", \"c\", \"d\"],\\n    ...                       \\'rating\\': [1, 3, 2, 5, 4, 1, 4, 3]})\\n\\n    >>> m1 = ranking_factorization_recommender.create(sf, target=\\'rating\\')\\n\\n\\n    **Including side features**\\n\\n    >>> user_info = turicreate.SFrame({\\'user_id\\': [\"0\", \"1\", \"2\"],\\n    ...                              \\'name\\': [\"Alice\", \"Bob\", \"Charlie\"],\\n    ...                              \\'numeric_feature\\': [0.1, 12, 22]})\\n    >>> item_info = turicreate.SFrame({\\'item_id\\': [\"a\", \"b\", \"c\", \"d\"],\\n    ...                              \\'name\\': [\"item1\", \"item2\", \"item3\", \"item4\"],\\n    ...                              \\'dict_feature\\': [{\\'a\\' : 23}, {\\'a\\' : 13},\\n    ...                                               {\\'b\\' : 1},\\n    ...                                               {\\'a\\' : 23, \\'b\\' : 32}]})\\n    >>> m2 = ranking_factorization_recommender.create(sf, target=\\'rating\\',\\n    ...                                               user_data=user_info,\\n    ...                                               item_data=item_info)\\n\\n    **Customizing ranking regularization**\\n\\n    Create a model that pushes predicted ratings of unobserved user-item\\n    pairs toward 1 or below.\\n\\n    >>> m3 = ranking_factorization_recommender.create(sf, target=\\'rating\\',\\n    ...                                               ranking_regularization = 0.1,\\n    ...                                               unobserved_rating_value = 1)\\n\\n    **Using the implicit alternating least squares model**\\n\\n    Ranking factorization also implements implicit alternating least squares [1] as\\n    an alternative solver.  This is enable using ``solver = \\'ials\\'``.\\n\\n    >>> m3 = ranking_factorization_recommender.create(sf, target=\\'rating\\',\\n                                                      solver = \\'ials\\')\\n\\n    See Also\\n    --------\\n    :class:`turicreate.recommender.factorization_recommender.FactorizationRecommender`,\\n    :class:`turicreate.recommender.ranking_factorization_recommender.RankingFactorizationRecommender`\\n\\n    References\\n    -----------\\n\\n    [1] Collaborative Filtering for Implicit Feedback Datasets Hu, Y.; Koren,\\n        Y.; Volinsky, C. IEEE International Conference on Data Mining\\n        (ICDM 2008), IEEE (2008).\\n\\n    '\n    from turicreate._cython.cy_server import QuietProgress\n    if not isinstance(observation_data, _SFrame):\n        raise TypeError('observation_data input must be a SFrame')\n    opts = {}\n    model_proxy = _turicreate.extensions.ranking_factorization_recommender()\n    model_proxy.init_options(opts)\n    if user_data is None:\n        user_data = _turicreate.SFrame()\n    if item_data is None:\n        item_data = _turicreate.SFrame()\n    if target is None:\n        binary_target = True\n    opts = {'user_id': user_id, 'item_id': item_id, 'target': target, 'random_seed': random_seed, 'num_factors': num_factors, 'regularization': regularization, 'linear_regularization': linear_regularization, 'ranking_regularization': ranking_regularization, 'binary_target': binary_target, 'max_iterations': max_iterations, 'side_data_factorization': side_data_factorization, 'num_sampled_negative_examples': num_sampled_negative_examples, 'solver': solver, 'sgd_step_size': sgd_step_size}\n    if unobserved_rating_value is not None:\n        opts['unobserved_rating_value'] = unobserved_rating_value\n    if kwargs:\n        try:\n            possible_args = set(_get_default_options()['name'])\n        except (RuntimeError, KeyError):\n            possible_args = set()\n        bad_arguments = set(kwargs.keys()).difference(possible_args)\n        if bad_arguments:\n            raise TypeError('Bad Keyword Arguments: ' + ', '.join(bad_arguments))\n        opts.update(kwargs)\n    extra_data = {'nearest_items': _turicreate.SFrame()}\n    with QuietProgress(verbose):\n        model_proxy.train(observation_data, user_data, item_data, opts, extra_data)\n    return RankingFactorizationRecommender(model_proxy)",
            "def create(observation_data, user_id='user_id', item_id='item_id', target=None, user_data=None, item_data=None, num_factors=32, regularization=1e-09, linear_regularization=1e-09, side_data_factorization=True, ranking_regularization=0.25, unobserved_rating_value=None, num_sampled_negative_examples=4, max_iterations=25, sgd_step_size=0, random_seed=0, binary_target=False, solver='auto', verbose=True, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Create a RankingFactorizationRecommender that learns latent factors for each\\n    user and item and uses them to make rating predictions.\\n\\n    Parameters\\n    ----------\\n    observation_data : SFrame\\n        The dataset to use for training the model. It must contain a column of\\n        user ids and a column of item ids. Each row represents an observed\\n        interaction between the user and the item.  The (user, item) pairs\\n        are stored with the model so that they can later be excluded from\\n        recommendations if desired. It can optionally contain a target ratings\\n        column. All other columns are interpreted by the underlying model as\\n        side features for the observations.\\n\\n        The user id and item id columns must be of type \\'int\\' or \\'str\\'. The\\n        target column must be of type \\'int\\' or \\'float\\'.\\n\\n    user_id : string, optional\\n        The name of the column in `observation_data` that corresponds to the\\n        user id.\\n\\n    item_id : string, optional\\n        The name of the column in `observation_data` that corresponds to the\\n        item id.\\n\\n    target : string, optional\\n        The `observation_data` can optionally contain a column of scores\\n        representing ratings given by the users. If present, the name of this\\n        column may be specified variables `target`.\\n\\n    user_data : SFrame, optional\\n        Side information for the users.  This SFrame must have a column with\\n        the same name as what is specified by the `user_id` input parameter.\\n        `user_data` can provide any amount of additional user-specific\\n        information.\\n\\n    item_data : SFrame, optional\\n        Side information for the items.  This SFrame must have a column with\\n        the same name as what is specified by the `item_id` input parameter.\\n        `item_data` can provide any amount of additional item-specific\\n        information.\\n\\n    num_factors : int, optional\\n        Number of latent factors.\\n\\n    regularization : float, optional\\n        L2 regularization for interaction terms. Default: 1e-10; a typical range\\n        for this parameter is between 1e-12 and 1. Setting this to 0 may cause\\n        numerical issues.\\n\\n    linear_regularization : float, optional\\n        L2 regularization for linear term. Default: 1e-10; a typical range for this\\n        parameter is between 1e-12 and 1. Setting this to 0 may cause numerical issues.\\n\\n    side_data_factorization : boolean, optional\\n        Use factorization for modeling any additional features beyond the user\\n        and item columns. If True, and side features or any additional columns are\\n        present, then a Factorization Machine model is trained. Otherwise, only\\n        the linear terms are fit to these features.  See\\n        :class:`turicreate.recommender.ranking_factorization_recommender.RankingFactorizationRecommender`\\n        for more information. Default: True.\\n\\n    ranking_regularization : float, optional\\n        Penalize the predicted value of user-item pairs not in the\\n        training set. Larger values increase this penalization.\\n        Suggested values: 0, 0.1, 0.5, 1.  NOTE: if no target column\\n        is present, this parameter is ignored.\\n\\n    unobserved_rating_value : float, optional\\n        Penalize unobserved items with a larger predicted score than this value.\\n        By default, the estimated 5% quantile is used (mean - 1.96*std_dev).\\n\\n    num_sampled_negative_examples : integer, optional\\n        For each (user, item) pair in the data, the ranking sgd solver evaluates\\n        this many randomly chosen unseen items for the negative example step.\\n        Increasing this can give better performance at the expense of speed,\\n        particularly when the number of items is large.  Default is 4.\\n\\n    binary_target : boolean, optional\\n        Assume the target column is composed of 0\\'s and 1\\'s. If True, use\\n        logistic loss to fit the model.\\n\\n    max_iterations : int, optional\\n        The training algorithm will make at most this many iterations through\\n        the observed data. Default: 50.\\n\\n    sgd_step_size : float, optional\\n        Step size for stochastic gradient descent. Smaller values generally\\n        lead to more accurate models that take more time to train. The\\n        default setting of 0 means that the step size is chosen by trying\\n        several options on a small subset of the data.\\n\\n    random_seed :  int, optional\\n        The random seed used to choose the initial starting point for\\n        model training. Note that some randomness in the training is\\n        unavoidable, so models trained with the same random seed may still\\n        differ. Default: 0.\\n\\n    solver : string, optional\\n        Name of the solver to be used to solve the regression. See the\\n        references for more detail on each solver. The available solvers for\\n        this model are:\\n\\n        - *auto (default)*: automatically chooses the best solver for the data\\n                              and model parameters.\\n        - *ials*:           Implicit Alternating Least Squares [1].\\n        - *adagrad*:        Adaptive Gradient Stochastic Gradient Descent.\\n        - *sgd*:            Stochastic Gradient Descent\\n\\n    verbose : bool, optional\\n        Enables verbose output.\\n\\n    kwargs : optional\\n        Optional advanced keyword arguments passed in to the model\\n        optimization procedure. These parameters do not typically\\n        need to be changed.\\n\\n    Examples\\n    --------\\n    **Basic usage**\\n\\n    When given just user and item pairs, one can create a RankingFactorizationRecommender\\n    as follows.\\n\\n    >>> sf = turicreate.SFrame({\\'user_id\\': [\"0\", \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"2\"],\\n    ...                       \\'item_id\\': [\"a\", \"b\", \"c\", \"a\", \"b\", \"b\", \"c\", \"d\"])\\n    >>> from turicreate.recommender import ranking_factorization_recommender\\n    >>> m1 = ranking_factorization_recommender.create(sf)\\n\\n    When a target column is present, one can include this to try and recommend\\n    items that are rated highly.\\n\\n    >>> sf = turicreate.SFrame({\\'user_id\\': [\"0\", \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"2\"],\\n    ...                       \\'item_id\\': [\"a\", \"b\", \"c\", \"a\", \"b\", \"b\", \"c\", \"d\"],\\n    ...                       \\'rating\\': [1, 3, 2, 5, 4, 1, 4, 3]})\\n\\n    >>> m1 = ranking_factorization_recommender.create(sf, target=\\'rating\\')\\n\\n\\n    **Including side features**\\n\\n    >>> user_info = turicreate.SFrame({\\'user_id\\': [\"0\", \"1\", \"2\"],\\n    ...                              \\'name\\': [\"Alice\", \"Bob\", \"Charlie\"],\\n    ...                              \\'numeric_feature\\': [0.1, 12, 22]})\\n    >>> item_info = turicreate.SFrame({\\'item_id\\': [\"a\", \"b\", \"c\", \"d\"],\\n    ...                              \\'name\\': [\"item1\", \"item2\", \"item3\", \"item4\"],\\n    ...                              \\'dict_feature\\': [{\\'a\\' : 23}, {\\'a\\' : 13},\\n    ...                                               {\\'b\\' : 1},\\n    ...                                               {\\'a\\' : 23, \\'b\\' : 32}]})\\n    >>> m2 = ranking_factorization_recommender.create(sf, target=\\'rating\\',\\n    ...                                               user_data=user_info,\\n    ...                                               item_data=item_info)\\n\\n    **Customizing ranking regularization**\\n\\n    Create a model that pushes predicted ratings of unobserved user-item\\n    pairs toward 1 or below.\\n\\n    >>> m3 = ranking_factorization_recommender.create(sf, target=\\'rating\\',\\n    ...                                               ranking_regularization = 0.1,\\n    ...                                               unobserved_rating_value = 1)\\n\\n    **Using the implicit alternating least squares model**\\n\\n    Ranking factorization also implements implicit alternating least squares [1] as\\n    an alternative solver.  This is enable using ``solver = \\'ials\\'``.\\n\\n    >>> m3 = ranking_factorization_recommender.create(sf, target=\\'rating\\',\\n                                                      solver = \\'ials\\')\\n\\n    See Also\\n    --------\\n    :class:`turicreate.recommender.factorization_recommender.FactorizationRecommender`,\\n    :class:`turicreate.recommender.ranking_factorization_recommender.RankingFactorizationRecommender`\\n\\n    References\\n    -----------\\n\\n    [1] Collaborative Filtering for Implicit Feedback Datasets Hu, Y.; Koren,\\n        Y.; Volinsky, C. IEEE International Conference on Data Mining\\n        (ICDM 2008), IEEE (2008).\\n\\n    '\n    from turicreate._cython.cy_server import QuietProgress\n    if not isinstance(observation_data, _SFrame):\n        raise TypeError('observation_data input must be a SFrame')\n    opts = {}\n    model_proxy = _turicreate.extensions.ranking_factorization_recommender()\n    model_proxy.init_options(opts)\n    if user_data is None:\n        user_data = _turicreate.SFrame()\n    if item_data is None:\n        item_data = _turicreate.SFrame()\n    if target is None:\n        binary_target = True\n    opts = {'user_id': user_id, 'item_id': item_id, 'target': target, 'random_seed': random_seed, 'num_factors': num_factors, 'regularization': regularization, 'linear_regularization': linear_regularization, 'ranking_regularization': ranking_regularization, 'binary_target': binary_target, 'max_iterations': max_iterations, 'side_data_factorization': side_data_factorization, 'num_sampled_negative_examples': num_sampled_negative_examples, 'solver': solver, 'sgd_step_size': sgd_step_size}\n    if unobserved_rating_value is not None:\n        opts['unobserved_rating_value'] = unobserved_rating_value\n    if kwargs:\n        try:\n            possible_args = set(_get_default_options()['name'])\n        except (RuntimeError, KeyError):\n            possible_args = set()\n        bad_arguments = set(kwargs.keys()).difference(possible_args)\n        if bad_arguments:\n            raise TypeError('Bad Keyword Arguments: ' + ', '.join(bad_arguments))\n        opts.update(kwargs)\n    extra_data = {'nearest_items': _turicreate.SFrame()}\n    with QuietProgress(verbose):\n        model_proxy.train(observation_data, user_data, item_data, opts, extra_data)\n    return RankingFactorizationRecommender(model_proxy)",
            "def create(observation_data, user_id='user_id', item_id='item_id', target=None, user_data=None, item_data=None, num_factors=32, regularization=1e-09, linear_regularization=1e-09, side_data_factorization=True, ranking_regularization=0.25, unobserved_rating_value=None, num_sampled_negative_examples=4, max_iterations=25, sgd_step_size=0, random_seed=0, binary_target=False, solver='auto', verbose=True, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Create a RankingFactorizationRecommender that learns latent factors for each\\n    user and item and uses them to make rating predictions.\\n\\n    Parameters\\n    ----------\\n    observation_data : SFrame\\n        The dataset to use for training the model. It must contain a column of\\n        user ids and a column of item ids. Each row represents an observed\\n        interaction between the user and the item.  The (user, item) pairs\\n        are stored with the model so that they can later be excluded from\\n        recommendations if desired. It can optionally contain a target ratings\\n        column. All other columns are interpreted by the underlying model as\\n        side features for the observations.\\n\\n        The user id and item id columns must be of type \\'int\\' or \\'str\\'. The\\n        target column must be of type \\'int\\' or \\'float\\'.\\n\\n    user_id : string, optional\\n        The name of the column in `observation_data` that corresponds to the\\n        user id.\\n\\n    item_id : string, optional\\n        The name of the column in `observation_data` that corresponds to the\\n        item id.\\n\\n    target : string, optional\\n        The `observation_data` can optionally contain a column of scores\\n        representing ratings given by the users. If present, the name of this\\n        column may be specified variables `target`.\\n\\n    user_data : SFrame, optional\\n        Side information for the users.  This SFrame must have a column with\\n        the same name as what is specified by the `user_id` input parameter.\\n        `user_data` can provide any amount of additional user-specific\\n        information.\\n\\n    item_data : SFrame, optional\\n        Side information for the items.  This SFrame must have a column with\\n        the same name as what is specified by the `item_id` input parameter.\\n        `item_data` can provide any amount of additional item-specific\\n        information.\\n\\n    num_factors : int, optional\\n        Number of latent factors.\\n\\n    regularization : float, optional\\n        L2 regularization for interaction terms. Default: 1e-10; a typical range\\n        for this parameter is between 1e-12 and 1. Setting this to 0 may cause\\n        numerical issues.\\n\\n    linear_regularization : float, optional\\n        L2 regularization for linear term. Default: 1e-10; a typical range for this\\n        parameter is between 1e-12 and 1. Setting this to 0 may cause numerical issues.\\n\\n    side_data_factorization : boolean, optional\\n        Use factorization for modeling any additional features beyond the user\\n        and item columns. If True, and side features or any additional columns are\\n        present, then a Factorization Machine model is trained. Otherwise, only\\n        the linear terms are fit to these features.  See\\n        :class:`turicreate.recommender.ranking_factorization_recommender.RankingFactorizationRecommender`\\n        for more information. Default: True.\\n\\n    ranking_regularization : float, optional\\n        Penalize the predicted value of user-item pairs not in the\\n        training set. Larger values increase this penalization.\\n        Suggested values: 0, 0.1, 0.5, 1.  NOTE: if no target column\\n        is present, this parameter is ignored.\\n\\n    unobserved_rating_value : float, optional\\n        Penalize unobserved items with a larger predicted score than this value.\\n        By default, the estimated 5% quantile is used (mean - 1.96*std_dev).\\n\\n    num_sampled_negative_examples : integer, optional\\n        For each (user, item) pair in the data, the ranking sgd solver evaluates\\n        this many randomly chosen unseen items for the negative example step.\\n        Increasing this can give better performance at the expense of speed,\\n        particularly when the number of items is large.  Default is 4.\\n\\n    binary_target : boolean, optional\\n        Assume the target column is composed of 0\\'s and 1\\'s. If True, use\\n        logistic loss to fit the model.\\n\\n    max_iterations : int, optional\\n        The training algorithm will make at most this many iterations through\\n        the observed data. Default: 50.\\n\\n    sgd_step_size : float, optional\\n        Step size for stochastic gradient descent. Smaller values generally\\n        lead to more accurate models that take more time to train. The\\n        default setting of 0 means that the step size is chosen by trying\\n        several options on a small subset of the data.\\n\\n    random_seed :  int, optional\\n        The random seed used to choose the initial starting point for\\n        model training. Note that some randomness in the training is\\n        unavoidable, so models trained with the same random seed may still\\n        differ. Default: 0.\\n\\n    solver : string, optional\\n        Name of the solver to be used to solve the regression. See the\\n        references for more detail on each solver. The available solvers for\\n        this model are:\\n\\n        - *auto (default)*: automatically chooses the best solver for the data\\n                              and model parameters.\\n        - *ials*:           Implicit Alternating Least Squares [1].\\n        - *adagrad*:        Adaptive Gradient Stochastic Gradient Descent.\\n        - *sgd*:            Stochastic Gradient Descent\\n\\n    verbose : bool, optional\\n        Enables verbose output.\\n\\n    kwargs : optional\\n        Optional advanced keyword arguments passed in to the model\\n        optimization procedure. These parameters do not typically\\n        need to be changed.\\n\\n    Examples\\n    --------\\n    **Basic usage**\\n\\n    When given just user and item pairs, one can create a RankingFactorizationRecommender\\n    as follows.\\n\\n    >>> sf = turicreate.SFrame({\\'user_id\\': [\"0\", \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"2\"],\\n    ...                       \\'item_id\\': [\"a\", \"b\", \"c\", \"a\", \"b\", \"b\", \"c\", \"d\"])\\n    >>> from turicreate.recommender import ranking_factorization_recommender\\n    >>> m1 = ranking_factorization_recommender.create(sf)\\n\\n    When a target column is present, one can include this to try and recommend\\n    items that are rated highly.\\n\\n    >>> sf = turicreate.SFrame({\\'user_id\\': [\"0\", \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"2\"],\\n    ...                       \\'item_id\\': [\"a\", \"b\", \"c\", \"a\", \"b\", \"b\", \"c\", \"d\"],\\n    ...                       \\'rating\\': [1, 3, 2, 5, 4, 1, 4, 3]})\\n\\n    >>> m1 = ranking_factorization_recommender.create(sf, target=\\'rating\\')\\n\\n\\n    **Including side features**\\n\\n    >>> user_info = turicreate.SFrame({\\'user_id\\': [\"0\", \"1\", \"2\"],\\n    ...                              \\'name\\': [\"Alice\", \"Bob\", \"Charlie\"],\\n    ...                              \\'numeric_feature\\': [0.1, 12, 22]})\\n    >>> item_info = turicreate.SFrame({\\'item_id\\': [\"a\", \"b\", \"c\", \"d\"],\\n    ...                              \\'name\\': [\"item1\", \"item2\", \"item3\", \"item4\"],\\n    ...                              \\'dict_feature\\': [{\\'a\\' : 23}, {\\'a\\' : 13},\\n    ...                                               {\\'b\\' : 1},\\n    ...                                               {\\'a\\' : 23, \\'b\\' : 32}]})\\n    >>> m2 = ranking_factorization_recommender.create(sf, target=\\'rating\\',\\n    ...                                               user_data=user_info,\\n    ...                                               item_data=item_info)\\n\\n    **Customizing ranking regularization**\\n\\n    Create a model that pushes predicted ratings of unobserved user-item\\n    pairs toward 1 or below.\\n\\n    >>> m3 = ranking_factorization_recommender.create(sf, target=\\'rating\\',\\n    ...                                               ranking_regularization = 0.1,\\n    ...                                               unobserved_rating_value = 1)\\n\\n    **Using the implicit alternating least squares model**\\n\\n    Ranking factorization also implements implicit alternating least squares [1] as\\n    an alternative solver.  This is enable using ``solver = \\'ials\\'``.\\n\\n    >>> m3 = ranking_factorization_recommender.create(sf, target=\\'rating\\',\\n                                                      solver = \\'ials\\')\\n\\n    See Also\\n    --------\\n    :class:`turicreate.recommender.factorization_recommender.FactorizationRecommender`,\\n    :class:`turicreate.recommender.ranking_factorization_recommender.RankingFactorizationRecommender`\\n\\n    References\\n    -----------\\n\\n    [1] Collaborative Filtering for Implicit Feedback Datasets Hu, Y.; Koren,\\n        Y.; Volinsky, C. IEEE International Conference on Data Mining\\n        (ICDM 2008), IEEE (2008).\\n\\n    '\n    from turicreate._cython.cy_server import QuietProgress\n    if not isinstance(observation_data, _SFrame):\n        raise TypeError('observation_data input must be a SFrame')\n    opts = {}\n    model_proxy = _turicreate.extensions.ranking_factorization_recommender()\n    model_proxy.init_options(opts)\n    if user_data is None:\n        user_data = _turicreate.SFrame()\n    if item_data is None:\n        item_data = _turicreate.SFrame()\n    if target is None:\n        binary_target = True\n    opts = {'user_id': user_id, 'item_id': item_id, 'target': target, 'random_seed': random_seed, 'num_factors': num_factors, 'regularization': regularization, 'linear_regularization': linear_regularization, 'ranking_regularization': ranking_regularization, 'binary_target': binary_target, 'max_iterations': max_iterations, 'side_data_factorization': side_data_factorization, 'num_sampled_negative_examples': num_sampled_negative_examples, 'solver': solver, 'sgd_step_size': sgd_step_size}\n    if unobserved_rating_value is not None:\n        opts['unobserved_rating_value'] = unobserved_rating_value\n    if kwargs:\n        try:\n            possible_args = set(_get_default_options()['name'])\n        except (RuntimeError, KeyError):\n            possible_args = set()\n        bad_arguments = set(kwargs.keys()).difference(possible_args)\n        if bad_arguments:\n            raise TypeError('Bad Keyword Arguments: ' + ', '.join(bad_arguments))\n        opts.update(kwargs)\n    extra_data = {'nearest_items': _turicreate.SFrame()}\n    with QuietProgress(verbose):\n        model_proxy.train(observation_data, user_data, item_data, opts, extra_data)\n    return RankingFactorizationRecommender(model_proxy)",
            "def create(observation_data, user_id='user_id', item_id='item_id', target=None, user_data=None, item_data=None, num_factors=32, regularization=1e-09, linear_regularization=1e-09, side_data_factorization=True, ranking_regularization=0.25, unobserved_rating_value=None, num_sampled_negative_examples=4, max_iterations=25, sgd_step_size=0, random_seed=0, binary_target=False, solver='auto', verbose=True, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Create a RankingFactorizationRecommender that learns latent factors for each\\n    user and item and uses them to make rating predictions.\\n\\n    Parameters\\n    ----------\\n    observation_data : SFrame\\n        The dataset to use for training the model. It must contain a column of\\n        user ids and a column of item ids. Each row represents an observed\\n        interaction between the user and the item.  The (user, item) pairs\\n        are stored with the model so that they can later be excluded from\\n        recommendations if desired. It can optionally contain a target ratings\\n        column. All other columns are interpreted by the underlying model as\\n        side features for the observations.\\n\\n        The user id and item id columns must be of type \\'int\\' or \\'str\\'. The\\n        target column must be of type \\'int\\' or \\'float\\'.\\n\\n    user_id : string, optional\\n        The name of the column in `observation_data` that corresponds to the\\n        user id.\\n\\n    item_id : string, optional\\n        The name of the column in `observation_data` that corresponds to the\\n        item id.\\n\\n    target : string, optional\\n        The `observation_data` can optionally contain a column of scores\\n        representing ratings given by the users. If present, the name of this\\n        column may be specified variables `target`.\\n\\n    user_data : SFrame, optional\\n        Side information for the users.  This SFrame must have a column with\\n        the same name as what is specified by the `user_id` input parameter.\\n        `user_data` can provide any amount of additional user-specific\\n        information.\\n\\n    item_data : SFrame, optional\\n        Side information for the items.  This SFrame must have a column with\\n        the same name as what is specified by the `item_id` input parameter.\\n        `item_data` can provide any amount of additional item-specific\\n        information.\\n\\n    num_factors : int, optional\\n        Number of latent factors.\\n\\n    regularization : float, optional\\n        L2 regularization for interaction terms. Default: 1e-10; a typical range\\n        for this parameter is between 1e-12 and 1. Setting this to 0 may cause\\n        numerical issues.\\n\\n    linear_regularization : float, optional\\n        L2 regularization for linear term. Default: 1e-10; a typical range for this\\n        parameter is between 1e-12 and 1. Setting this to 0 may cause numerical issues.\\n\\n    side_data_factorization : boolean, optional\\n        Use factorization for modeling any additional features beyond the user\\n        and item columns. If True, and side features or any additional columns are\\n        present, then a Factorization Machine model is trained. Otherwise, only\\n        the linear terms are fit to these features.  See\\n        :class:`turicreate.recommender.ranking_factorization_recommender.RankingFactorizationRecommender`\\n        for more information. Default: True.\\n\\n    ranking_regularization : float, optional\\n        Penalize the predicted value of user-item pairs not in the\\n        training set. Larger values increase this penalization.\\n        Suggested values: 0, 0.1, 0.5, 1.  NOTE: if no target column\\n        is present, this parameter is ignored.\\n\\n    unobserved_rating_value : float, optional\\n        Penalize unobserved items with a larger predicted score than this value.\\n        By default, the estimated 5% quantile is used (mean - 1.96*std_dev).\\n\\n    num_sampled_negative_examples : integer, optional\\n        For each (user, item) pair in the data, the ranking sgd solver evaluates\\n        this many randomly chosen unseen items for the negative example step.\\n        Increasing this can give better performance at the expense of speed,\\n        particularly when the number of items is large.  Default is 4.\\n\\n    binary_target : boolean, optional\\n        Assume the target column is composed of 0\\'s and 1\\'s. If True, use\\n        logistic loss to fit the model.\\n\\n    max_iterations : int, optional\\n        The training algorithm will make at most this many iterations through\\n        the observed data. Default: 50.\\n\\n    sgd_step_size : float, optional\\n        Step size for stochastic gradient descent. Smaller values generally\\n        lead to more accurate models that take more time to train. The\\n        default setting of 0 means that the step size is chosen by trying\\n        several options on a small subset of the data.\\n\\n    random_seed :  int, optional\\n        The random seed used to choose the initial starting point for\\n        model training. Note that some randomness in the training is\\n        unavoidable, so models trained with the same random seed may still\\n        differ. Default: 0.\\n\\n    solver : string, optional\\n        Name of the solver to be used to solve the regression. See the\\n        references for more detail on each solver. The available solvers for\\n        this model are:\\n\\n        - *auto (default)*: automatically chooses the best solver for the data\\n                              and model parameters.\\n        - *ials*:           Implicit Alternating Least Squares [1].\\n        - *adagrad*:        Adaptive Gradient Stochastic Gradient Descent.\\n        - *sgd*:            Stochastic Gradient Descent\\n\\n    verbose : bool, optional\\n        Enables verbose output.\\n\\n    kwargs : optional\\n        Optional advanced keyword arguments passed in to the model\\n        optimization procedure. These parameters do not typically\\n        need to be changed.\\n\\n    Examples\\n    --------\\n    **Basic usage**\\n\\n    When given just user and item pairs, one can create a RankingFactorizationRecommender\\n    as follows.\\n\\n    >>> sf = turicreate.SFrame({\\'user_id\\': [\"0\", \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"2\"],\\n    ...                       \\'item_id\\': [\"a\", \"b\", \"c\", \"a\", \"b\", \"b\", \"c\", \"d\"])\\n    >>> from turicreate.recommender import ranking_factorization_recommender\\n    >>> m1 = ranking_factorization_recommender.create(sf)\\n\\n    When a target column is present, one can include this to try and recommend\\n    items that are rated highly.\\n\\n    >>> sf = turicreate.SFrame({\\'user_id\\': [\"0\", \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"2\"],\\n    ...                       \\'item_id\\': [\"a\", \"b\", \"c\", \"a\", \"b\", \"b\", \"c\", \"d\"],\\n    ...                       \\'rating\\': [1, 3, 2, 5, 4, 1, 4, 3]})\\n\\n    >>> m1 = ranking_factorization_recommender.create(sf, target=\\'rating\\')\\n\\n\\n    **Including side features**\\n\\n    >>> user_info = turicreate.SFrame({\\'user_id\\': [\"0\", \"1\", \"2\"],\\n    ...                              \\'name\\': [\"Alice\", \"Bob\", \"Charlie\"],\\n    ...                              \\'numeric_feature\\': [0.1, 12, 22]})\\n    >>> item_info = turicreate.SFrame({\\'item_id\\': [\"a\", \"b\", \"c\", \"d\"],\\n    ...                              \\'name\\': [\"item1\", \"item2\", \"item3\", \"item4\"],\\n    ...                              \\'dict_feature\\': [{\\'a\\' : 23}, {\\'a\\' : 13},\\n    ...                                               {\\'b\\' : 1},\\n    ...                                               {\\'a\\' : 23, \\'b\\' : 32}]})\\n    >>> m2 = ranking_factorization_recommender.create(sf, target=\\'rating\\',\\n    ...                                               user_data=user_info,\\n    ...                                               item_data=item_info)\\n\\n    **Customizing ranking regularization**\\n\\n    Create a model that pushes predicted ratings of unobserved user-item\\n    pairs toward 1 or below.\\n\\n    >>> m3 = ranking_factorization_recommender.create(sf, target=\\'rating\\',\\n    ...                                               ranking_regularization = 0.1,\\n    ...                                               unobserved_rating_value = 1)\\n\\n    **Using the implicit alternating least squares model**\\n\\n    Ranking factorization also implements implicit alternating least squares [1] as\\n    an alternative solver.  This is enable using ``solver = \\'ials\\'``.\\n\\n    >>> m3 = ranking_factorization_recommender.create(sf, target=\\'rating\\',\\n                                                      solver = \\'ials\\')\\n\\n    See Also\\n    --------\\n    :class:`turicreate.recommender.factorization_recommender.FactorizationRecommender`,\\n    :class:`turicreate.recommender.ranking_factorization_recommender.RankingFactorizationRecommender`\\n\\n    References\\n    -----------\\n\\n    [1] Collaborative Filtering for Implicit Feedback Datasets Hu, Y.; Koren,\\n        Y.; Volinsky, C. IEEE International Conference on Data Mining\\n        (ICDM 2008), IEEE (2008).\\n\\n    '\n    from turicreate._cython.cy_server import QuietProgress\n    if not isinstance(observation_data, _SFrame):\n        raise TypeError('observation_data input must be a SFrame')\n    opts = {}\n    model_proxy = _turicreate.extensions.ranking_factorization_recommender()\n    model_proxy.init_options(opts)\n    if user_data is None:\n        user_data = _turicreate.SFrame()\n    if item_data is None:\n        item_data = _turicreate.SFrame()\n    if target is None:\n        binary_target = True\n    opts = {'user_id': user_id, 'item_id': item_id, 'target': target, 'random_seed': random_seed, 'num_factors': num_factors, 'regularization': regularization, 'linear_regularization': linear_regularization, 'ranking_regularization': ranking_regularization, 'binary_target': binary_target, 'max_iterations': max_iterations, 'side_data_factorization': side_data_factorization, 'num_sampled_negative_examples': num_sampled_negative_examples, 'solver': solver, 'sgd_step_size': sgd_step_size}\n    if unobserved_rating_value is not None:\n        opts['unobserved_rating_value'] = unobserved_rating_value\n    if kwargs:\n        try:\n            possible_args = set(_get_default_options()['name'])\n        except (RuntimeError, KeyError):\n            possible_args = set()\n        bad_arguments = set(kwargs.keys()).difference(possible_args)\n        if bad_arguments:\n            raise TypeError('Bad Keyword Arguments: ' + ', '.join(bad_arguments))\n        opts.update(kwargs)\n    extra_data = {'nearest_items': _turicreate.SFrame()}\n    with QuietProgress(verbose):\n        model_proxy.train(observation_data, user_data, item_data, opts, extra_data)\n    return RankingFactorizationRecommender(model_proxy)",
            "def create(observation_data, user_id='user_id', item_id='item_id', target=None, user_data=None, item_data=None, num_factors=32, regularization=1e-09, linear_regularization=1e-09, side_data_factorization=True, ranking_regularization=0.25, unobserved_rating_value=None, num_sampled_negative_examples=4, max_iterations=25, sgd_step_size=0, random_seed=0, binary_target=False, solver='auto', verbose=True, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Create a RankingFactorizationRecommender that learns latent factors for each\\n    user and item and uses them to make rating predictions.\\n\\n    Parameters\\n    ----------\\n    observation_data : SFrame\\n        The dataset to use for training the model. It must contain a column of\\n        user ids and a column of item ids. Each row represents an observed\\n        interaction between the user and the item.  The (user, item) pairs\\n        are stored with the model so that they can later be excluded from\\n        recommendations if desired. It can optionally contain a target ratings\\n        column. All other columns are interpreted by the underlying model as\\n        side features for the observations.\\n\\n        The user id and item id columns must be of type \\'int\\' or \\'str\\'. The\\n        target column must be of type \\'int\\' or \\'float\\'.\\n\\n    user_id : string, optional\\n        The name of the column in `observation_data` that corresponds to the\\n        user id.\\n\\n    item_id : string, optional\\n        The name of the column in `observation_data` that corresponds to the\\n        item id.\\n\\n    target : string, optional\\n        The `observation_data` can optionally contain a column of scores\\n        representing ratings given by the users. If present, the name of this\\n        column may be specified variables `target`.\\n\\n    user_data : SFrame, optional\\n        Side information for the users.  This SFrame must have a column with\\n        the same name as what is specified by the `user_id` input parameter.\\n        `user_data` can provide any amount of additional user-specific\\n        information.\\n\\n    item_data : SFrame, optional\\n        Side information for the items.  This SFrame must have a column with\\n        the same name as what is specified by the `item_id` input parameter.\\n        `item_data` can provide any amount of additional item-specific\\n        information.\\n\\n    num_factors : int, optional\\n        Number of latent factors.\\n\\n    regularization : float, optional\\n        L2 regularization for interaction terms. Default: 1e-10; a typical range\\n        for this parameter is between 1e-12 and 1. Setting this to 0 may cause\\n        numerical issues.\\n\\n    linear_regularization : float, optional\\n        L2 regularization for linear term. Default: 1e-10; a typical range for this\\n        parameter is between 1e-12 and 1. Setting this to 0 may cause numerical issues.\\n\\n    side_data_factorization : boolean, optional\\n        Use factorization for modeling any additional features beyond the user\\n        and item columns. If True, and side features or any additional columns are\\n        present, then a Factorization Machine model is trained. Otherwise, only\\n        the linear terms are fit to these features.  See\\n        :class:`turicreate.recommender.ranking_factorization_recommender.RankingFactorizationRecommender`\\n        for more information. Default: True.\\n\\n    ranking_regularization : float, optional\\n        Penalize the predicted value of user-item pairs not in the\\n        training set. Larger values increase this penalization.\\n        Suggested values: 0, 0.1, 0.5, 1.  NOTE: if no target column\\n        is present, this parameter is ignored.\\n\\n    unobserved_rating_value : float, optional\\n        Penalize unobserved items with a larger predicted score than this value.\\n        By default, the estimated 5% quantile is used (mean - 1.96*std_dev).\\n\\n    num_sampled_negative_examples : integer, optional\\n        For each (user, item) pair in the data, the ranking sgd solver evaluates\\n        this many randomly chosen unseen items for the negative example step.\\n        Increasing this can give better performance at the expense of speed,\\n        particularly when the number of items is large.  Default is 4.\\n\\n    binary_target : boolean, optional\\n        Assume the target column is composed of 0\\'s and 1\\'s. If True, use\\n        logistic loss to fit the model.\\n\\n    max_iterations : int, optional\\n        The training algorithm will make at most this many iterations through\\n        the observed data. Default: 50.\\n\\n    sgd_step_size : float, optional\\n        Step size for stochastic gradient descent. Smaller values generally\\n        lead to more accurate models that take more time to train. The\\n        default setting of 0 means that the step size is chosen by trying\\n        several options on a small subset of the data.\\n\\n    random_seed :  int, optional\\n        The random seed used to choose the initial starting point for\\n        model training. Note that some randomness in the training is\\n        unavoidable, so models trained with the same random seed may still\\n        differ. Default: 0.\\n\\n    solver : string, optional\\n        Name of the solver to be used to solve the regression. See the\\n        references for more detail on each solver. The available solvers for\\n        this model are:\\n\\n        - *auto (default)*: automatically chooses the best solver for the data\\n                              and model parameters.\\n        - *ials*:           Implicit Alternating Least Squares [1].\\n        - *adagrad*:        Adaptive Gradient Stochastic Gradient Descent.\\n        - *sgd*:            Stochastic Gradient Descent\\n\\n    verbose : bool, optional\\n        Enables verbose output.\\n\\n    kwargs : optional\\n        Optional advanced keyword arguments passed in to the model\\n        optimization procedure. These parameters do not typically\\n        need to be changed.\\n\\n    Examples\\n    --------\\n    **Basic usage**\\n\\n    When given just user and item pairs, one can create a RankingFactorizationRecommender\\n    as follows.\\n\\n    >>> sf = turicreate.SFrame({\\'user_id\\': [\"0\", \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"2\"],\\n    ...                       \\'item_id\\': [\"a\", \"b\", \"c\", \"a\", \"b\", \"b\", \"c\", \"d\"])\\n    >>> from turicreate.recommender import ranking_factorization_recommender\\n    >>> m1 = ranking_factorization_recommender.create(sf)\\n\\n    When a target column is present, one can include this to try and recommend\\n    items that are rated highly.\\n\\n    >>> sf = turicreate.SFrame({\\'user_id\\': [\"0\", \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"2\"],\\n    ...                       \\'item_id\\': [\"a\", \"b\", \"c\", \"a\", \"b\", \"b\", \"c\", \"d\"],\\n    ...                       \\'rating\\': [1, 3, 2, 5, 4, 1, 4, 3]})\\n\\n    >>> m1 = ranking_factorization_recommender.create(sf, target=\\'rating\\')\\n\\n\\n    **Including side features**\\n\\n    >>> user_info = turicreate.SFrame({\\'user_id\\': [\"0\", \"1\", \"2\"],\\n    ...                              \\'name\\': [\"Alice\", \"Bob\", \"Charlie\"],\\n    ...                              \\'numeric_feature\\': [0.1, 12, 22]})\\n    >>> item_info = turicreate.SFrame({\\'item_id\\': [\"a\", \"b\", \"c\", \"d\"],\\n    ...                              \\'name\\': [\"item1\", \"item2\", \"item3\", \"item4\"],\\n    ...                              \\'dict_feature\\': [{\\'a\\' : 23}, {\\'a\\' : 13},\\n    ...                                               {\\'b\\' : 1},\\n    ...                                               {\\'a\\' : 23, \\'b\\' : 32}]})\\n    >>> m2 = ranking_factorization_recommender.create(sf, target=\\'rating\\',\\n    ...                                               user_data=user_info,\\n    ...                                               item_data=item_info)\\n\\n    **Customizing ranking regularization**\\n\\n    Create a model that pushes predicted ratings of unobserved user-item\\n    pairs toward 1 or below.\\n\\n    >>> m3 = ranking_factorization_recommender.create(sf, target=\\'rating\\',\\n    ...                                               ranking_regularization = 0.1,\\n    ...                                               unobserved_rating_value = 1)\\n\\n    **Using the implicit alternating least squares model**\\n\\n    Ranking factorization also implements implicit alternating least squares [1] as\\n    an alternative solver.  This is enable using ``solver = \\'ials\\'``.\\n\\n    >>> m3 = ranking_factorization_recommender.create(sf, target=\\'rating\\',\\n                                                      solver = \\'ials\\')\\n\\n    See Also\\n    --------\\n    :class:`turicreate.recommender.factorization_recommender.FactorizationRecommender`,\\n    :class:`turicreate.recommender.ranking_factorization_recommender.RankingFactorizationRecommender`\\n\\n    References\\n    -----------\\n\\n    [1] Collaborative Filtering for Implicit Feedback Datasets Hu, Y.; Koren,\\n        Y.; Volinsky, C. IEEE International Conference on Data Mining\\n        (ICDM 2008), IEEE (2008).\\n\\n    '\n    from turicreate._cython.cy_server import QuietProgress\n    if not isinstance(observation_data, _SFrame):\n        raise TypeError('observation_data input must be a SFrame')\n    opts = {}\n    model_proxy = _turicreate.extensions.ranking_factorization_recommender()\n    model_proxy.init_options(opts)\n    if user_data is None:\n        user_data = _turicreate.SFrame()\n    if item_data is None:\n        item_data = _turicreate.SFrame()\n    if target is None:\n        binary_target = True\n    opts = {'user_id': user_id, 'item_id': item_id, 'target': target, 'random_seed': random_seed, 'num_factors': num_factors, 'regularization': regularization, 'linear_regularization': linear_regularization, 'ranking_regularization': ranking_regularization, 'binary_target': binary_target, 'max_iterations': max_iterations, 'side_data_factorization': side_data_factorization, 'num_sampled_negative_examples': num_sampled_negative_examples, 'solver': solver, 'sgd_step_size': sgd_step_size}\n    if unobserved_rating_value is not None:\n        opts['unobserved_rating_value'] = unobserved_rating_value\n    if kwargs:\n        try:\n            possible_args = set(_get_default_options()['name'])\n        except (RuntimeError, KeyError):\n            possible_args = set()\n        bad_arguments = set(kwargs.keys()).difference(possible_args)\n        if bad_arguments:\n            raise TypeError('Bad Keyword Arguments: ' + ', '.join(bad_arguments))\n        opts.update(kwargs)\n    extra_data = {'nearest_items': _turicreate.SFrame()}\n    with QuietProgress(verbose):\n        model_proxy.train(observation_data, user_data, item_data, opts, extra_data)\n    return RankingFactorizationRecommender(model_proxy)"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, model_proxy):\n    \"\"\"__init__(self)\"\"\"\n    self.__proxy__ = model_proxy",
        "mutated": [
            "def __init__(self, model_proxy):\n    if False:\n        i = 10\n    '__init__(self)'\n    self.__proxy__ = model_proxy",
            "def __init__(self, model_proxy):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '__init__(self)'\n    self.__proxy__ = model_proxy",
            "def __init__(self, model_proxy):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '__init__(self)'\n    self.__proxy__ = model_proxy",
            "def __init__(self, model_proxy):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '__init__(self)'\n    self.__proxy__ = model_proxy",
            "def __init__(self, model_proxy):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '__init__(self)'\n    self.__proxy__ = model_proxy"
        ]
    },
    {
        "func_name": "_native_name",
        "original": "@classmethod\ndef _native_name(cls):\n    return 'ranking_factorization_recommender'",
        "mutated": [
            "@classmethod\ndef _native_name(cls):\n    if False:\n        i = 10\n    return 'ranking_factorization_recommender'",
            "@classmethod\ndef _native_name(cls):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return 'ranking_factorization_recommender'",
            "@classmethod\ndef _native_name(cls):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return 'ranking_factorization_recommender'",
            "@classmethod\ndef _native_name(cls):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return 'ranking_factorization_recommender'",
            "@classmethod\ndef _native_name(cls):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return 'ranking_factorization_recommender'"
        ]
    }
]