[
    {
        "func_name": "test_timeseries_models",
        "original": "@pytest.mark.parametrize('model,obs_dim,nu_statedim', [('ssmgp', 3, 1.5), ('ssmgp', 2, 2.5), ('lcmgp', 3, 1.5), ('lcmgp', 2, 2.5), ('imgp', 1, 0.5), ('imgp', 2, 0.5), ('imgp', 1, 1.5), ('imgp', 3, 1.5), ('imgp', 1, 2.5), ('imgp', 3, 2.5), ('dmgp', 1, 1.5), ('dmgp', 2, 1.5), ('dmgp', 3, 1.5), ('glgssm', 1, 3), ('glgssm', 3, 1)])\n@pytest.mark.parametrize('T', [11, 37])\ndef test_timeseries_models(model, nu_statedim, obs_dim, T):\n    torch.set_default_dtype(torch.float64)\n    dt = 0.1 + torch.rand(1).item()\n    if model == 'lcmgp':\n        num_gps = 2\n        gp = LinearlyCoupledMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, num_gps=num_gps, length_scale_init=0.5 + torch.rand(num_gps), kernel_scale_init=0.5 + torch.rand(num_gps), obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'imgp':\n        gp = IndependentMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, length_scale_init=0.5 + torch.rand(obs_dim), kernel_scale_init=0.5 + torch.rand(obs_dim), obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'glgssm':\n        gp = GenericLGSSM(state_dim=nu_statedim, obs_dim=obs_dim, obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'ssmgp':\n        state_dim = {0.5: 4, 1.5: 3, 2.5: 2}[nu_statedim]\n        gp = GenericLGSSMWithGPNoiseModel(nu=nu_statedim, state_dim=state_dim, obs_dim=obs_dim, obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'dmgp':\n        linearly_coupled = bool(torch.rand(1).item() > 0.5)\n        gp = DependentMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, linearly_coupled=linearly_coupled, length_scale_init=0.5 + torch.rand(obs_dim))\n    targets = torch.randn(T, obs_dim)\n    gp_log_prob = gp.log_prob(targets)\n    if model == 'imgp':\n        assert gp_log_prob.shape == (obs_dim,)\n    else:\n        assert gp_log_prob.dim() == 0\n    if model == 'imgp':\n        times = dt * torch.arange(T).double()\n        for dim in range(obs_dim):\n            lengthscale = gp.kernel.length_scale[dim]\n            variance = gp.kernel.kernel_scale.pow(2)[dim]\n            obs_noise = gp.obs_noise_scale.pow(2)[dim]\n            kernel = {0.5: pyro.contrib.gp.kernels.Exponential, 1.5: pyro.contrib.gp.kernels.Matern32, 2.5: pyro.contrib.gp.kernels.Matern52}[nu_statedim]\n            kernel = kernel(input_dim=1, lengthscale=lengthscale, variance=variance)\n            kernel = kernel.forward(times) + obs_noise * torch.eye(T)\n            mvn = torch.distributions.MultivariateNormal(torch.zeros(T), kernel)\n            mvn_log_prob = mvn.log_prob(targets[:, dim])\n            assert_equal(mvn_log_prob, gp_log_prob[dim], prec=0.0001)\n    for S in [1, 5]:\n        if model in ['imgp', 'lcmgp', 'dmgp', 'lcdgp']:\n            dts = torch.rand(S).cumsum(dim=-1)\n            predictive = gp.forecast(targets, dts)\n        else:\n            predictive = gp.forecast(targets, S)\n        assert predictive.loc.shape == (S, obs_dim)\n        if model == 'imgp':\n            assert predictive.scale.shape == (S, obs_dim)\n            if S > 1:\n                delta = predictive.scale[1:S, :] - predictive.scale[0:S - 1, :]\n                assert (delta > 0.0).sum() == (S - 1) * obs_dim\n        else:\n            assert predictive.covariance_matrix.shape == (S, obs_dim, obs_dim)\n            if S > 1:\n                dets = predictive.covariance_matrix.det()\n                delta = dets[1:S] - dets[0:S - 1]\n                assert (delta > 0.0).sum() == S - 1\n    if model in ['imgp', 'lcmgp', 'dmgp', 'lcdgp']:\n        dts = torch.tensor([500.0])\n        predictive = gp.forecast(targets, dts)\n        assert_equal(predictive.loc, torch.zeros(1, obs_dim))",
        "mutated": [
            "@pytest.mark.parametrize('model,obs_dim,nu_statedim', [('ssmgp', 3, 1.5), ('ssmgp', 2, 2.5), ('lcmgp', 3, 1.5), ('lcmgp', 2, 2.5), ('imgp', 1, 0.5), ('imgp', 2, 0.5), ('imgp', 1, 1.5), ('imgp', 3, 1.5), ('imgp', 1, 2.5), ('imgp', 3, 2.5), ('dmgp', 1, 1.5), ('dmgp', 2, 1.5), ('dmgp', 3, 1.5), ('glgssm', 1, 3), ('glgssm', 3, 1)])\n@pytest.mark.parametrize('T', [11, 37])\ndef test_timeseries_models(model, nu_statedim, obs_dim, T):\n    if False:\n        i = 10\n    torch.set_default_dtype(torch.float64)\n    dt = 0.1 + torch.rand(1).item()\n    if model == 'lcmgp':\n        num_gps = 2\n        gp = LinearlyCoupledMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, num_gps=num_gps, length_scale_init=0.5 + torch.rand(num_gps), kernel_scale_init=0.5 + torch.rand(num_gps), obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'imgp':\n        gp = IndependentMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, length_scale_init=0.5 + torch.rand(obs_dim), kernel_scale_init=0.5 + torch.rand(obs_dim), obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'glgssm':\n        gp = GenericLGSSM(state_dim=nu_statedim, obs_dim=obs_dim, obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'ssmgp':\n        state_dim = {0.5: 4, 1.5: 3, 2.5: 2}[nu_statedim]\n        gp = GenericLGSSMWithGPNoiseModel(nu=nu_statedim, state_dim=state_dim, obs_dim=obs_dim, obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'dmgp':\n        linearly_coupled = bool(torch.rand(1).item() > 0.5)\n        gp = DependentMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, linearly_coupled=linearly_coupled, length_scale_init=0.5 + torch.rand(obs_dim))\n    targets = torch.randn(T, obs_dim)\n    gp_log_prob = gp.log_prob(targets)\n    if model == 'imgp':\n        assert gp_log_prob.shape == (obs_dim,)\n    else:\n        assert gp_log_prob.dim() == 0\n    if model == 'imgp':\n        times = dt * torch.arange(T).double()\n        for dim in range(obs_dim):\n            lengthscale = gp.kernel.length_scale[dim]\n            variance = gp.kernel.kernel_scale.pow(2)[dim]\n            obs_noise = gp.obs_noise_scale.pow(2)[dim]\n            kernel = {0.5: pyro.contrib.gp.kernels.Exponential, 1.5: pyro.contrib.gp.kernels.Matern32, 2.5: pyro.contrib.gp.kernels.Matern52}[nu_statedim]\n            kernel = kernel(input_dim=1, lengthscale=lengthscale, variance=variance)\n            kernel = kernel.forward(times) + obs_noise * torch.eye(T)\n            mvn = torch.distributions.MultivariateNormal(torch.zeros(T), kernel)\n            mvn_log_prob = mvn.log_prob(targets[:, dim])\n            assert_equal(mvn_log_prob, gp_log_prob[dim], prec=0.0001)\n    for S in [1, 5]:\n        if model in ['imgp', 'lcmgp', 'dmgp', 'lcdgp']:\n            dts = torch.rand(S).cumsum(dim=-1)\n            predictive = gp.forecast(targets, dts)\n        else:\n            predictive = gp.forecast(targets, S)\n        assert predictive.loc.shape == (S, obs_dim)\n        if model == 'imgp':\n            assert predictive.scale.shape == (S, obs_dim)\n            if S > 1:\n                delta = predictive.scale[1:S, :] - predictive.scale[0:S - 1, :]\n                assert (delta > 0.0).sum() == (S - 1) * obs_dim\n        else:\n            assert predictive.covariance_matrix.shape == (S, obs_dim, obs_dim)\n            if S > 1:\n                dets = predictive.covariance_matrix.det()\n                delta = dets[1:S] - dets[0:S - 1]\n                assert (delta > 0.0).sum() == S - 1\n    if model in ['imgp', 'lcmgp', 'dmgp', 'lcdgp']:\n        dts = torch.tensor([500.0])\n        predictive = gp.forecast(targets, dts)\n        assert_equal(predictive.loc, torch.zeros(1, obs_dim))",
            "@pytest.mark.parametrize('model,obs_dim,nu_statedim', [('ssmgp', 3, 1.5), ('ssmgp', 2, 2.5), ('lcmgp', 3, 1.5), ('lcmgp', 2, 2.5), ('imgp', 1, 0.5), ('imgp', 2, 0.5), ('imgp', 1, 1.5), ('imgp', 3, 1.5), ('imgp', 1, 2.5), ('imgp', 3, 2.5), ('dmgp', 1, 1.5), ('dmgp', 2, 1.5), ('dmgp', 3, 1.5), ('glgssm', 1, 3), ('glgssm', 3, 1)])\n@pytest.mark.parametrize('T', [11, 37])\ndef test_timeseries_models(model, nu_statedim, obs_dim, T):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    torch.set_default_dtype(torch.float64)\n    dt = 0.1 + torch.rand(1).item()\n    if model == 'lcmgp':\n        num_gps = 2\n        gp = LinearlyCoupledMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, num_gps=num_gps, length_scale_init=0.5 + torch.rand(num_gps), kernel_scale_init=0.5 + torch.rand(num_gps), obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'imgp':\n        gp = IndependentMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, length_scale_init=0.5 + torch.rand(obs_dim), kernel_scale_init=0.5 + torch.rand(obs_dim), obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'glgssm':\n        gp = GenericLGSSM(state_dim=nu_statedim, obs_dim=obs_dim, obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'ssmgp':\n        state_dim = {0.5: 4, 1.5: 3, 2.5: 2}[nu_statedim]\n        gp = GenericLGSSMWithGPNoiseModel(nu=nu_statedim, state_dim=state_dim, obs_dim=obs_dim, obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'dmgp':\n        linearly_coupled = bool(torch.rand(1).item() > 0.5)\n        gp = DependentMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, linearly_coupled=linearly_coupled, length_scale_init=0.5 + torch.rand(obs_dim))\n    targets = torch.randn(T, obs_dim)\n    gp_log_prob = gp.log_prob(targets)\n    if model == 'imgp':\n        assert gp_log_prob.shape == (obs_dim,)\n    else:\n        assert gp_log_prob.dim() == 0\n    if model == 'imgp':\n        times = dt * torch.arange(T).double()\n        for dim in range(obs_dim):\n            lengthscale = gp.kernel.length_scale[dim]\n            variance = gp.kernel.kernel_scale.pow(2)[dim]\n            obs_noise = gp.obs_noise_scale.pow(2)[dim]\n            kernel = {0.5: pyro.contrib.gp.kernels.Exponential, 1.5: pyro.contrib.gp.kernels.Matern32, 2.5: pyro.contrib.gp.kernels.Matern52}[nu_statedim]\n            kernel = kernel(input_dim=1, lengthscale=lengthscale, variance=variance)\n            kernel = kernel.forward(times) + obs_noise * torch.eye(T)\n            mvn = torch.distributions.MultivariateNormal(torch.zeros(T), kernel)\n            mvn_log_prob = mvn.log_prob(targets[:, dim])\n            assert_equal(mvn_log_prob, gp_log_prob[dim], prec=0.0001)\n    for S in [1, 5]:\n        if model in ['imgp', 'lcmgp', 'dmgp', 'lcdgp']:\n            dts = torch.rand(S).cumsum(dim=-1)\n            predictive = gp.forecast(targets, dts)\n        else:\n            predictive = gp.forecast(targets, S)\n        assert predictive.loc.shape == (S, obs_dim)\n        if model == 'imgp':\n            assert predictive.scale.shape == (S, obs_dim)\n            if S > 1:\n                delta = predictive.scale[1:S, :] - predictive.scale[0:S - 1, :]\n                assert (delta > 0.0).sum() == (S - 1) * obs_dim\n        else:\n            assert predictive.covariance_matrix.shape == (S, obs_dim, obs_dim)\n            if S > 1:\n                dets = predictive.covariance_matrix.det()\n                delta = dets[1:S] - dets[0:S - 1]\n                assert (delta > 0.0).sum() == S - 1\n    if model in ['imgp', 'lcmgp', 'dmgp', 'lcdgp']:\n        dts = torch.tensor([500.0])\n        predictive = gp.forecast(targets, dts)\n        assert_equal(predictive.loc, torch.zeros(1, obs_dim))",
            "@pytest.mark.parametrize('model,obs_dim,nu_statedim', [('ssmgp', 3, 1.5), ('ssmgp', 2, 2.5), ('lcmgp', 3, 1.5), ('lcmgp', 2, 2.5), ('imgp', 1, 0.5), ('imgp', 2, 0.5), ('imgp', 1, 1.5), ('imgp', 3, 1.5), ('imgp', 1, 2.5), ('imgp', 3, 2.5), ('dmgp', 1, 1.5), ('dmgp', 2, 1.5), ('dmgp', 3, 1.5), ('glgssm', 1, 3), ('glgssm', 3, 1)])\n@pytest.mark.parametrize('T', [11, 37])\ndef test_timeseries_models(model, nu_statedim, obs_dim, T):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    torch.set_default_dtype(torch.float64)\n    dt = 0.1 + torch.rand(1).item()\n    if model == 'lcmgp':\n        num_gps = 2\n        gp = LinearlyCoupledMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, num_gps=num_gps, length_scale_init=0.5 + torch.rand(num_gps), kernel_scale_init=0.5 + torch.rand(num_gps), obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'imgp':\n        gp = IndependentMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, length_scale_init=0.5 + torch.rand(obs_dim), kernel_scale_init=0.5 + torch.rand(obs_dim), obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'glgssm':\n        gp = GenericLGSSM(state_dim=nu_statedim, obs_dim=obs_dim, obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'ssmgp':\n        state_dim = {0.5: 4, 1.5: 3, 2.5: 2}[nu_statedim]\n        gp = GenericLGSSMWithGPNoiseModel(nu=nu_statedim, state_dim=state_dim, obs_dim=obs_dim, obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'dmgp':\n        linearly_coupled = bool(torch.rand(1).item() > 0.5)\n        gp = DependentMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, linearly_coupled=linearly_coupled, length_scale_init=0.5 + torch.rand(obs_dim))\n    targets = torch.randn(T, obs_dim)\n    gp_log_prob = gp.log_prob(targets)\n    if model == 'imgp':\n        assert gp_log_prob.shape == (obs_dim,)\n    else:\n        assert gp_log_prob.dim() == 0\n    if model == 'imgp':\n        times = dt * torch.arange(T).double()\n        for dim in range(obs_dim):\n            lengthscale = gp.kernel.length_scale[dim]\n            variance = gp.kernel.kernel_scale.pow(2)[dim]\n            obs_noise = gp.obs_noise_scale.pow(2)[dim]\n            kernel = {0.5: pyro.contrib.gp.kernels.Exponential, 1.5: pyro.contrib.gp.kernels.Matern32, 2.5: pyro.contrib.gp.kernels.Matern52}[nu_statedim]\n            kernel = kernel(input_dim=1, lengthscale=lengthscale, variance=variance)\n            kernel = kernel.forward(times) + obs_noise * torch.eye(T)\n            mvn = torch.distributions.MultivariateNormal(torch.zeros(T), kernel)\n            mvn_log_prob = mvn.log_prob(targets[:, dim])\n            assert_equal(mvn_log_prob, gp_log_prob[dim], prec=0.0001)\n    for S in [1, 5]:\n        if model in ['imgp', 'lcmgp', 'dmgp', 'lcdgp']:\n            dts = torch.rand(S).cumsum(dim=-1)\n            predictive = gp.forecast(targets, dts)\n        else:\n            predictive = gp.forecast(targets, S)\n        assert predictive.loc.shape == (S, obs_dim)\n        if model == 'imgp':\n            assert predictive.scale.shape == (S, obs_dim)\n            if S > 1:\n                delta = predictive.scale[1:S, :] - predictive.scale[0:S - 1, :]\n                assert (delta > 0.0).sum() == (S - 1) * obs_dim\n        else:\n            assert predictive.covariance_matrix.shape == (S, obs_dim, obs_dim)\n            if S > 1:\n                dets = predictive.covariance_matrix.det()\n                delta = dets[1:S] - dets[0:S - 1]\n                assert (delta > 0.0).sum() == S - 1\n    if model in ['imgp', 'lcmgp', 'dmgp', 'lcdgp']:\n        dts = torch.tensor([500.0])\n        predictive = gp.forecast(targets, dts)\n        assert_equal(predictive.loc, torch.zeros(1, obs_dim))",
            "@pytest.mark.parametrize('model,obs_dim,nu_statedim', [('ssmgp', 3, 1.5), ('ssmgp', 2, 2.5), ('lcmgp', 3, 1.5), ('lcmgp', 2, 2.5), ('imgp', 1, 0.5), ('imgp', 2, 0.5), ('imgp', 1, 1.5), ('imgp', 3, 1.5), ('imgp', 1, 2.5), ('imgp', 3, 2.5), ('dmgp', 1, 1.5), ('dmgp', 2, 1.5), ('dmgp', 3, 1.5), ('glgssm', 1, 3), ('glgssm', 3, 1)])\n@pytest.mark.parametrize('T', [11, 37])\ndef test_timeseries_models(model, nu_statedim, obs_dim, T):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    torch.set_default_dtype(torch.float64)\n    dt = 0.1 + torch.rand(1).item()\n    if model == 'lcmgp':\n        num_gps = 2\n        gp = LinearlyCoupledMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, num_gps=num_gps, length_scale_init=0.5 + torch.rand(num_gps), kernel_scale_init=0.5 + torch.rand(num_gps), obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'imgp':\n        gp = IndependentMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, length_scale_init=0.5 + torch.rand(obs_dim), kernel_scale_init=0.5 + torch.rand(obs_dim), obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'glgssm':\n        gp = GenericLGSSM(state_dim=nu_statedim, obs_dim=obs_dim, obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'ssmgp':\n        state_dim = {0.5: 4, 1.5: 3, 2.5: 2}[nu_statedim]\n        gp = GenericLGSSMWithGPNoiseModel(nu=nu_statedim, state_dim=state_dim, obs_dim=obs_dim, obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'dmgp':\n        linearly_coupled = bool(torch.rand(1).item() > 0.5)\n        gp = DependentMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, linearly_coupled=linearly_coupled, length_scale_init=0.5 + torch.rand(obs_dim))\n    targets = torch.randn(T, obs_dim)\n    gp_log_prob = gp.log_prob(targets)\n    if model == 'imgp':\n        assert gp_log_prob.shape == (obs_dim,)\n    else:\n        assert gp_log_prob.dim() == 0\n    if model == 'imgp':\n        times = dt * torch.arange(T).double()\n        for dim in range(obs_dim):\n            lengthscale = gp.kernel.length_scale[dim]\n            variance = gp.kernel.kernel_scale.pow(2)[dim]\n            obs_noise = gp.obs_noise_scale.pow(2)[dim]\n            kernel = {0.5: pyro.contrib.gp.kernels.Exponential, 1.5: pyro.contrib.gp.kernels.Matern32, 2.5: pyro.contrib.gp.kernels.Matern52}[nu_statedim]\n            kernel = kernel(input_dim=1, lengthscale=lengthscale, variance=variance)\n            kernel = kernel.forward(times) + obs_noise * torch.eye(T)\n            mvn = torch.distributions.MultivariateNormal(torch.zeros(T), kernel)\n            mvn_log_prob = mvn.log_prob(targets[:, dim])\n            assert_equal(mvn_log_prob, gp_log_prob[dim], prec=0.0001)\n    for S in [1, 5]:\n        if model in ['imgp', 'lcmgp', 'dmgp', 'lcdgp']:\n            dts = torch.rand(S).cumsum(dim=-1)\n            predictive = gp.forecast(targets, dts)\n        else:\n            predictive = gp.forecast(targets, S)\n        assert predictive.loc.shape == (S, obs_dim)\n        if model == 'imgp':\n            assert predictive.scale.shape == (S, obs_dim)\n            if S > 1:\n                delta = predictive.scale[1:S, :] - predictive.scale[0:S - 1, :]\n                assert (delta > 0.0).sum() == (S - 1) * obs_dim\n        else:\n            assert predictive.covariance_matrix.shape == (S, obs_dim, obs_dim)\n            if S > 1:\n                dets = predictive.covariance_matrix.det()\n                delta = dets[1:S] - dets[0:S - 1]\n                assert (delta > 0.0).sum() == S - 1\n    if model in ['imgp', 'lcmgp', 'dmgp', 'lcdgp']:\n        dts = torch.tensor([500.0])\n        predictive = gp.forecast(targets, dts)\n        assert_equal(predictive.loc, torch.zeros(1, obs_dim))",
            "@pytest.mark.parametrize('model,obs_dim,nu_statedim', [('ssmgp', 3, 1.5), ('ssmgp', 2, 2.5), ('lcmgp', 3, 1.5), ('lcmgp', 2, 2.5), ('imgp', 1, 0.5), ('imgp', 2, 0.5), ('imgp', 1, 1.5), ('imgp', 3, 1.5), ('imgp', 1, 2.5), ('imgp', 3, 2.5), ('dmgp', 1, 1.5), ('dmgp', 2, 1.5), ('dmgp', 3, 1.5), ('glgssm', 1, 3), ('glgssm', 3, 1)])\n@pytest.mark.parametrize('T', [11, 37])\ndef test_timeseries_models(model, nu_statedim, obs_dim, T):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    torch.set_default_dtype(torch.float64)\n    dt = 0.1 + torch.rand(1).item()\n    if model == 'lcmgp':\n        num_gps = 2\n        gp = LinearlyCoupledMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, num_gps=num_gps, length_scale_init=0.5 + torch.rand(num_gps), kernel_scale_init=0.5 + torch.rand(num_gps), obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'imgp':\n        gp = IndependentMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, length_scale_init=0.5 + torch.rand(obs_dim), kernel_scale_init=0.5 + torch.rand(obs_dim), obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'glgssm':\n        gp = GenericLGSSM(state_dim=nu_statedim, obs_dim=obs_dim, obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'ssmgp':\n        state_dim = {0.5: 4, 1.5: 3, 2.5: 2}[nu_statedim]\n        gp = GenericLGSSMWithGPNoiseModel(nu=nu_statedim, state_dim=state_dim, obs_dim=obs_dim, obs_noise_scale_init=0.5 + torch.rand(obs_dim))\n    elif model == 'dmgp':\n        linearly_coupled = bool(torch.rand(1).item() > 0.5)\n        gp = DependentMaternGP(nu=nu_statedim, obs_dim=obs_dim, dt=dt, linearly_coupled=linearly_coupled, length_scale_init=0.5 + torch.rand(obs_dim))\n    targets = torch.randn(T, obs_dim)\n    gp_log_prob = gp.log_prob(targets)\n    if model == 'imgp':\n        assert gp_log_prob.shape == (obs_dim,)\n    else:\n        assert gp_log_prob.dim() == 0\n    if model == 'imgp':\n        times = dt * torch.arange(T).double()\n        for dim in range(obs_dim):\n            lengthscale = gp.kernel.length_scale[dim]\n            variance = gp.kernel.kernel_scale.pow(2)[dim]\n            obs_noise = gp.obs_noise_scale.pow(2)[dim]\n            kernel = {0.5: pyro.contrib.gp.kernels.Exponential, 1.5: pyro.contrib.gp.kernels.Matern32, 2.5: pyro.contrib.gp.kernels.Matern52}[nu_statedim]\n            kernel = kernel(input_dim=1, lengthscale=lengthscale, variance=variance)\n            kernel = kernel.forward(times) + obs_noise * torch.eye(T)\n            mvn = torch.distributions.MultivariateNormal(torch.zeros(T), kernel)\n            mvn_log_prob = mvn.log_prob(targets[:, dim])\n            assert_equal(mvn_log_prob, gp_log_prob[dim], prec=0.0001)\n    for S in [1, 5]:\n        if model in ['imgp', 'lcmgp', 'dmgp', 'lcdgp']:\n            dts = torch.rand(S).cumsum(dim=-1)\n            predictive = gp.forecast(targets, dts)\n        else:\n            predictive = gp.forecast(targets, S)\n        assert predictive.loc.shape == (S, obs_dim)\n        if model == 'imgp':\n            assert predictive.scale.shape == (S, obs_dim)\n            if S > 1:\n                delta = predictive.scale[1:S, :] - predictive.scale[0:S - 1, :]\n                assert (delta > 0.0).sum() == (S - 1) * obs_dim\n        else:\n            assert predictive.covariance_matrix.shape == (S, obs_dim, obs_dim)\n            if S > 1:\n                dets = predictive.covariance_matrix.det()\n                delta = dets[1:S] - dets[0:S - 1]\n                assert (delta > 0.0).sum() == S - 1\n    if model in ['imgp', 'lcmgp', 'dmgp', 'lcdgp']:\n        dts = torch.tensor([500.0])\n        predictive = gp.forecast(targets, dts)\n        assert_equal(predictive.loc, torch.zeros(1, obs_dim))"
        ]
    },
    {
        "func_name": "test_dependent_matern_gp",
        "original": "@pytest.mark.parametrize('obs_dim', [1, 3])\ndef test_dependent_matern_gp(obs_dim):\n    dt = 0.5 + torch.rand(1).item()\n    gp = DependentMaternGP(nu=1.5, obs_dim=obs_dim, dt=dt, length_scale_init=0.5 + torch.rand(obs_dim))\n    lengthscale = gp.kernel.length_scale.unsqueeze(-1).unsqueeze(-1)\n    F = torch.tensor([[0.0, 1.0], [0.0, 0.0]])\n    mask1 = torch.tensor([[0.0, 0.0], [-3.0, 0.0]])\n    mask2 = torch.tensor([[0.0, 0.0], [0.0, -math.sqrt(12.0)]])\n    F = block_diag_embed(F + mask1 / lengthscale.pow(2.0) + mask2 / lengthscale)\n    stat_cov = gp._stationary_covariance()\n    wiener_cov = gp._get_wiener_cov()\n    wiener_cov *= torch.tensor([[0.0, 0.0], [0.0, 1.0]]).repeat(obs_dim, obs_dim)\n    expected_zero = torch.matmul(F, stat_cov) + torch.matmul(stat_cov, F.transpose(-1, -2)) + wiener_cov\n    assert_equal(expected_zero, torch.zeros(gp.full_state_dim, gp.full_state_dim))",
        "mutated": [
            "@pytest.mark.parametrize('obs_dim', [1, 3])\ndef test_dependent_matern_gp(obs_dim):\n    if False:\n        i = 10\n    dt = 0.5 + torch.rand(1).item()\n    gp = DependentMaternGP(nu=1.5, obs_dim=obs_dim, dt=dt, length_scale_init=0.5 + torch.rand(obs_dim))\n    lengthscale = gp.kernel.length_scale.unsqueeze(-1).unsqueeze(-1)\n    F = torch.tensor([[0.0, 1.0], [0.0, 0.0]])\n    mask1 = torch.tensor([[0.0, 0.0], [-3.0, 0.0]])\n    mask2 = torch.tensor([[0.0, 0.0], [0.0, -math.sqrt(12.0)]])\n    F = block_diag_embed(F + mask1 / lengthscale.pow(2.0) + mask2 / lengthscale)\n    stat_cov = gp._stationary_covariance()\n    wiener_cov = gp._get_wiener_cov()\n    wiener_cov *= torch.tensor([[0.0, 0.0], [0.0, 1.0]]).repeat(obs_dim, obs_dim)\n    expected_zero = torch.matmul(F, stat_cov) + torch.matmul(stat_cov, F.transpose(-1, -2)) + wiener_cov\n    assert_equal(expected_zero, torch.zeros(gp.full_state_dim, gp.full_state_dim))",
            "@pytest.mark.parametrize('obs_dim', [1, 3])\ndef test_dependent_matern_gp(obs_dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    dt = 0.5 + torch.rand(1).item()\n    gp = DependentMaternGP(nu=1.5, obs_dim=obs_dim, dt=dt, length_scale_init=0.5 + torch.rand(obs_dim))\n    lengthscale = gp.kernel.length_scale.unsqueeze(-1).unsqueeze(-1)\n    F = torch.tensor([[0.0, 1.0], [0.0, 0.0]])\n    mask1 = torch.tensor([[0.0, 0.0], [-3.0, 0.0]])\n    mask2 = torch.tensor([[0.0, 0.0], [0.0, -math.sqrt(12.0)]])\n    F = block_diag_embed(F + mask1 / lengthscale.pow(2.0) + mask2 / lengthscale)\n    stat_cov = gp._stationary_covariance()\n    wiener_cov = gp._get_wiener_cov()\n    wiener_cov *= torch.tensor([[0.0, 0.0], [0.0, 1.0]]).repeat(obs_dim, obs_dim)\n    expected_zero = torch.matmul(F, stat_cov) + torch.matmul(stat_cov, F.transpose(-1, -2)) + wiener_cov\n    assert_equal(expected_zero, torch.zeros(gp.full_state_dim, gp.full_state_dim))",
            "@pytest.mark.parametrize('obs_dim', [1, 3])\ndef test_dependent_matern_gp(obs_dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    dt = 0.5 + torch.rand(1).item()\n    gp = DependentMaternGP(nu=1.5, obs_dim=obs_dim, dt=dt, length_scale_init=0.5 + torch.rand(obs_dim))\n    lengthscale = gp.kernel.length_scale.unsqueeze(-1).unsqueeze(-1)\n    F = torch.tensor([[0.0, 1.0], [0.0, 0.0]])\n    mask1 = torch.tensor([[0.0, 0.0], [-3.0, 0.0]])\n    mask2 = torch.tensor([[0.0, 0.0], [0.0, -math.sqrt(12.0)]])\n    F = block_diag_embed(F + mask1 / lengthscale.pow(2.0) + mask2 / lengthscale)\n    stat_cov = gp._stationary_covariance()\n    wiener_cov = gp._get_wiener_cov()\n    wiener_cov *= torch.tensor([[0.0, 0.0], [0.0, 1.0]]).repeat(obs_dim, obs_dim)\n    expected_zero = torch.matmul(F, stat_cov) + torch.matmul(stat_cov, F.transpose(-1, -2)) + wiener_cov\n    assert_equal(expected_zero, torch.zeros(gp.full_state_dim, gp.full_state_dim))",
            "@pytest.mark.parametrize('obs_dim', [1, 3])\ndef test_dependent_matern_gp(obs_dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    dt = 0.5 + torch.rand(1).item()\n    gp = DependentMaternGP(nu=1.5, obs_dim=obs_dim, dt=dt, length_scale_init=0.5 + torch.rand(obs_dim))\n    lengthscale = gp.kernel.length_scale.unsqueeze(-1).unsqueeze(-1)\n    F = torch.tensor([[0.0, 1.0], [0.0, 0.0]])\n    mask1 = torch.tensor([[0.0, 0.0], [-3.0, 0.0]])\n    mask2 = torch.tensor([[0.0, 0.0], [0.0, -math.sqrt(12.0)]])\n    F = block_diag_embed(F + mask1 / lengthscale.pow(2.0) + mask2 / lengthscale)\n    stat_cov = gp._stationary_covariance()\n    wiener_cov = gp._get_wiener_cov()\n    wiener_cov *= torch.tensor([[0.0, 0.0], [0.0, 1.0]]).repeat(obs_dim, obs_dim)\n    expected_zero = torch.matmul(F, stat_cov) + torch.matmul(stat_cov, F.transpose(-1, -2)) + wiener_cov\n    assert_equal(expected_zero, torch.zeros(gp.full_state_dim, gp.full_state_dim))",
            "@pytest.mark.parametrize('obs_dim', [1, 3])\ndef test_dependent_matern_gp(obs_dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    dt = 0.5 + torch.rand(1).item()\n    gp = DependentMaternGP(nu=1.5, obs_dim=obs_dim, dt=dt, length_scale_init=0.5 + torch.rand(obs_dim))\n    lengthscale = gp.kernel.length_scale.unsqueeze(-1).unsqueeze(-1)\n    F = torch.tensor([[0.0, 1.0], [0.0, 0.0]])\n    mask1 = torch.tensor([[0.0, 0.0], [-3.0, 0.0]])\n    mask2 = torch.tensor([[0.0, 0.0], [0.0, -math.sqrt(12.0)]])\n    F = block_diag_embed(F + mask1 / lengthscale.pow(2.0) + mask2 / lengthscale)\n    stat_cov = gp._stationary_covariance()\n    wiener_cov = gp._get_wiener_cov()\n    wiener_cov *= torch.tensor([[0.0, 0.0], [0.0, 1.0]]).repeat(obs_dim, obs_dim)\n    expected_zero = torch.matmul(F, stat_cov) + torch.matmul(stat_cov, F.transpose(-1, -2)) + wiener_cov\n    assert_equal(expected_zero, torch.zeros(gp.full_state_dim, gp.full_state_dim))"
        ]
    }
]