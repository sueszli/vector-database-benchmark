[
    {
        "func_name": "conv",
        "original": "def conv(x, w, padding, stride=1):\n    (out_planes, in_planes, kernel_size, _) = w.shape\n    Kw = kernel_size\n    Kh = kernel_size\n    _C = in_planes\n    Kc = out_planes\n    (N, C, H, W) = x.shape\n    assert C == _C\n    xx = x.reindex([N, Kc, C, (H + padding * 2 - kernel_size) // stride + 1, (W + padding * 2 - kernel_size) // stride + 1, Kh, Kw], ['i0', 'i2', f'i3*{stride}-{padding}+i5', f'i4*{stride}-{padding}+i6'])\n    ww = w.broadcast(xx.shape, [0, 3, 4])\n    yy = xx * ww\n    y = yy.sum([2, 5, 6])\n    return y",
        "mutated": [
            "def conv(x, w, padding, stride=1):\n    if False:\n        i = 10\n    (out_planes, in_planes, kernel_size, _) = w.shape\n    Kw = kernel_size\n    Kh = kernel_size\n    _C = in_planes\n    Kc = out_planes\n    (N, C, H, W) = x.shape\n    assert C == _C\n    xx = x.reindex([N, Kc, C, (H + padding * 2 - kernel_size) // stride + 1, (W + padding * 2 - kernel_size) // stride + 1, Kh, Kw], ['i0', 'i2', f'i3*{stride}-{padding}+i5', f'i4*{stride}-{padding}+i6'])\n    ww = w.broadcast(xx.shape, [0, 3, 4])\n    yy = xx * ww\n    y = yy.sum([2, 5, 6])\n    return y",
            "def conv(x, w, padding, stride=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (out_planes, in_planes, kernel_size, _) = w.shape\n    Kw = kernel_size\n    Kh = kernel_size\n    _C = in_planes\n    Kc = out_planes\n    (N, C, H, W) = x.shape\n    assert C == _C\n    xx = x.reindex([N, Kc, C, (H + padding * 2 - kernel_size) // stride + 1, (W + padding * 2 - kernel_size) // stride + 1, Kh, Kw], ['i0', 'i2', f'i3*{stride}-{padding}+i5', f'i4*{stride}-{padding}+i6'])\n    ww = w.broadcast(xx.shape, [0, 3, 4])\n    yy = xx * ww\n    y = yy.sum([2, 5, 6])\n    return y",
            "def conv(x, w, padding, stride=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (out_planes, in_planes, kernel_size, _) = w.shape\n    Kw = kernel_size\n    Kh = kernel_size\n    _C = in_planes\n    Kc = out_planes\n    (N, C, H, W) = x.shape\n    assert C == _C\n    xx = x.reindex([N, Kc, C, (H + padding * 2 - kernel_size) // stride + 1, (W + padding * 2 - kernel_size) // stride + 1, Kh, Kw], ['i0', 'i2', f'i3*{stride}-{padding}+i5', f'i4*{stride}-{padding}+i6'])\n    ww = w.broadcast(xx.shape, [0, 3, 4])\n    yy = xx * ww\n    y = yy.sum([2, 5, 6])\n    return y",
            "def conv(x, w, padding, stride=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (out_planes, in_planes, kernel_size, _) = w.shape\n    Kw = kernel_size\n    Kh = kernel_size\n    _C = in_planes\n    Kc = out_planes\n    (N, C, H, W) = x.shape\n    assert C == _C\n    xx = x.reindex([N, Kc, C, (H + padding * 2 - kernel_size) // stride + 1, (W + padding * 2 - kernel_size) // stride + 1, Kh, Kw], ['i0', 'i2', f'i3*{stride}-{padding}+i5', f'i4*{stride}-{padding}+i6'])\n    ww = w.broadcast(xx.shape, [0, 3, 4])\n    yy = xx * ww\n    y = yy.sum([2, 5, 6])\n    return y",
            "def conv(x, w, padding, stride=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (out_planes, in_planes, kernel_size, _) = w.shape\n    Kw = kernel_size\n    Kh = kernel_size\n    _C = in_planes\n    Kc = out_planes\n    (N, C, H, W) = x.shape\n    assert C == _C\n    xx = x.reindex([N, Kc, C, (H + padding * 2 - kernel_size) // stride + 1, (W + padding * 2 - kernel_size) // stride + 1, Kh, Kw], ['i0', 'i2', f'i3*{stride}-{padding}+i5', f'i4*{stride}-{padding}+i6'])\n    ww = w.broadcast(xx.shape, [0, 3, 4])\n    yy = xx * ww\n    y = yy.sum([2, 5, 6])\n    return y"
        ]
    },
    {
        "func_name": "conv_nhwc_hwio",
        "original": "def conv_nhwc_hwio(x, w, stride=1, padding=0):\n    assert type(stride) == int and type(padding) == int\n    (N, H, W, C) = x.shape\n    (Kh, Kw, C2, c) = w.shape\n    (oh, ow) = ((H - Kh + padding * 2) // stride + 1, (W - Kw + padding * 2) // stride + 1)\n    assert C2 == C or C2 == 1\n    x = x.reindex([N, oh, ow, Kh, Kw, C2, c], ['i0', f'i1*{stride}+i3-{padding}', f'i2*{stride}+i4-{padding}', 'i6' if C2 == 1 else 'i5'])\n    y = (x * w).sum([3, 4, 5])\n    return y",
        "mutated": [
            "def conv_nhwc_hwio(x, w, stride=1, padding=0):\n    if False:\n        i = 10\n    assert type(stride) == int and type(padding) == int\n    (N, H, W, C) = x.shape\n    (Kh, Kw, C2, c) = w.shape\n    (oh, ow) = ((H - Kh + padding * 2) // stride + 1, (W - Kw + padding * 2) // stride + 1)\n    assert C2 == C or C2 == 1\n    x = x.reindex([N, oh, ow, Kh, Kw, C2, c], ['i0', f'i1*{stride}+i3-{padding}', f'i2*{stride}+i4-{padding}', 'i6' if C2 == 1 else 'i5'])\n    y = (x * w).sum([3, 4, 5])\n    return y",
            "def conv_nhwc_hwio(x, w, stride=1, padding=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    assert type(stride) == int and type(padding) == int\n    (N, H, W, C) = x.shape\n    (Kh, Kw, C2, c) = w.shape\n    (oh, ow) = ((H - Kh + padding * 2) // stride + 1, (W - Kw + padding * 2) // stride + 1)\n    assert C2 == C or C2 == 1\n    x = x.reindex([N, oh, ow, Kh, Kw, C2, c], ['i0', f'i1*{stride}+i3-{padding}', f'i2*{stride}+i4-{padding}', 'i6' if C2 == 1 else 'i5'])\n    y = (x * w).sum([3, 4, 5])\n    return y",
            "def conv_nhwc_hwio(x, w, stride=1, padding=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    assert type(stride) == int and type(padding) == int\n    (N, H, W, C) = x.shape\n    (Kh, Kw, C2, c) = w.shape\n    (oh, ow) = ((H - Kh + padding * 2) // stride + 1, (W - Kw + padding * 2) // stride + 1)\n    assert C2 == C or C2 == 1\n    x = x.reindex([N, oh, ow, Kh, Kw, C2, c], ['i0', f'i1*{stride}+i3-{padding}', f'i2*{stride}+i4-{padding}', 'i6' if C2 == 1 else 'i5'])\n    y = (x * w).sum([3, 4, 5])\n    return y",
            "def conv_nhwc_hwio(x, w, stride=1, padding=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    assert type(stride) == int and type(padding) == int\n    (N, H, W, C) = x.shape\n    (Kh, Kw, C2, c) = w.shape\n    (oh, ow) = ((H - Kh + padding * 2) // stride + 1, (W - Kw + padding * 2) // stride + 1)\n    assert C2 == C or C2 == 1\n    x = x.reindex([N, oh, ow, Kh, Kw, C2, c], ['i0', f'i1*{stride}+i3-{padding}', f'i2*{stride}+i4-{padding}', 'i6' if C2 == 1 else 'i5'])\n    y = (x * w).sum([3, 4, 5])\n    return y",
            "def conv_nhwc_hwio(x, w, stride=1, padding=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    assert type(stride) == int and type(padding) == int\n    (N, H, W, C) = x.shape\n    (Kh, Kw, C2, c) = w.shape\n    (oh, ow) = ((H - Kh + padding * 2) // stride + 1, (W - Kw + padding * 2) // stride + 1)\n    assert C2 == C or C2 == 1\n    x = x.reindex([N, oh, ow, Kh, Kw, C2, c], ['i0', f'i1*{stride}+i3-{padding}', f'i2*{stride}+i4-{padding}', 'i6' if C2 == 1 else 'i5'])\n    y = (x * w).sum([3, 4, 5])\n    return y"
        ]
    },
    {
        "func_name": "test_forward",
        "original": "def test_forward(self):\n    a = np.random.rand(1, 3, 224, 224).astype(np.float32)\n    b = np.random.rand(64, 3, 7, 7).astype(np.float32)\n    c = jt.mkl_ops.mkl_conv(a, b, 2, 2, 3, 3).data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': 1}):\n        c_jt = conv(a_jt, b_jt, 3, 2).data\n    with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': 2}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n        c_jt_tune = conv(a_jt, b_jt, 3, 2).data\n    assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n    logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 1\n    assert logs[0][0] == '20'\n    assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}",
        "mutated": [
            "def test_forward(self):\n    if False:\n        i = 10\n    a = np.random.rand(1, 3, 224, 224).astype(np.float32)\n    b = np.random.rand(64, 3, 7, 7).astype(np.float32)\n    c = jt.mkl_ops.mkl_conv(a, b, 2, 2, 3, 3).data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': 1}):\n        c_jt = conv(a_jt, b_jt, 3, 2).data\n    with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': 2}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n        c_jt_tune = conv(a_jt, b_jt, 3, 2).data\n    assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n    logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 1\n    assert logs[0][0] == '20'\n    assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}",
            "def test_forward(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    a = np.random.rand(1, 3, 224, 224).astype(np.float32)\n    b = np.random.rand(64, 3, 7, 7).astype(np.float32)\n    c = jt.mkl_ops.mkl_conv(a, b, 2, 2, 3, 3).data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': 1}):\n        c_jt = conv(a_jt, b_jt, 3, 2).data\n    with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': 2}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n        c_jt_tune = conv(a_jt, b_jt, 3, 2).data\n    assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n    logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 1\n    assert logs[0][0] == '20'\n    assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}",
            "def test_forward(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    a = np.random.rand(1, 3, 224, 224).astype(np.float32)\n    b = np.random.rand(64, 3, 7, 7).astype(np.float32)\n    c = jt.mkl_ops.mkl_conv(a, b, 2, 2, 3, 3).data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': 1}):\n        c_jt = conv(a_jt, b_jt, 3, 2).data\n    with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': 2}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n        c_jt_tune = conv(a_jt, b_jt, 3, 2).data\n    assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n    logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 1\n    assert logs[0][0] == '20'\n    assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}",
            "def test_forward(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    a = np.random.rand(1, 3, 224, 224).astype(np.float32)\n    b = np.random.rand(64, 3, 7, 7).astype(np.float32)\n    c = jt.mkl_ops.mkl_conv(a, b, 2, 2, 3, 3).data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': 1}):\n        c_jt = conv(a_jt, b_jt, 3, 2).data\n    with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': 2}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n        c_jt_tune = conv(a_jt, b_jt, 3, 2).data\n    assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n    logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 1\n    assert logs[0][0] == '20'\n    assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}",
            "def test_forward(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    a = np.random.rand(1, 3, 224, 224).astype(np.float32)\n    b = np.random.rand(64, 3, 7, 7).astype(np.float32)\n    c = jt.mkl_ops.mkl_conv(a, b, 2, 2, 3, 3).data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': 1}):\n        c_jt = conv(a_jt, b_jt, 3, 2).data\n    with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': 2}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n        c_jt_tune = conv(a_jt, b_jt, 3, 2).data\n    assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n    logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 1\n    assert logs[0][0] == '20'\n    assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}"
        ]
    },
    {
        "func_name": "check",
        "original": "def check(xshape, wshape, stride, pad):\n    a = np.random.rand(*xshape).astype(np.float32)\n    b = np.random.rand(*wshape).astype(np.float32)\n    c = jt.mkl_ops.mkl_conv(a, b, stride, stride, pad, pad, 1, 1, xformat='acdb', wformat='hwio').data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': uid[0]}):\n        c_jt = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n    with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': uid[0] + 1}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n        c_jt_tune = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n    uid[0] += 2\n    assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n    logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 1, raw_logs\n    assert logs[0][0] == '20'\n    assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}",
        "mutated": [
            "def check(xshape, wshape, stride, pad):\n    if False:\n        i = 10\n    a = np.random.rand(*xshape).astype(np.float32)\n    b = np.random.rand(*wshape).astype(np.float32)\n    c = jt.mkl_ops.mkl_conv(a, b, stride, stride, pad, pad, 1, 1, xformat='acdb', wformat='hwio').data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': uid[0]}):\n        c_jt = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n    with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': uid[0] + 1}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n        c_jt_tune = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n    uid[0] += 2\n    assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n    logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 1, raw_logs\n    assert logs[0][0] == '20'\n    assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}",
            "def check(xshape, wshape, stride, pad):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    a = np.random.rand(*xshape).astype(np.float32)\n    b = np.random.rand(*wshape).astype(np.float32)\n    c = jt.mkl_ops.mkl_conv(a, b, stride, stride, pad, pad, 1, 1, xformat='acdb', wformat='hwio').data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': uid[0]}):\n        c_jt = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n    with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': uid[0] + 1}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n        c_jt_tune = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n    uid[0] += 2\n    assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n    logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 1, raw_logs\n    assert logs[0][0] == '20'\n    assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}",
            "def check(xshape, wshape, stride, pad):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    a = np.random.rand(*xshape).astype(np.float32)\n    b = np.random.rand(*wshape).astype(np.float32)\n    c = jt.mkl_ops.mkl_conv(a, b, stride, stride, pad, pad, 1, 1, xformat='acdb', wformat='hwio').data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': uid[0]}):\n        c_jt = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n    with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': uid[0] + 1}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n        c_jt_tune = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n    uid[0] += 2\n    assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n    logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 1, raw_logs\n    assert logs[0][0] == '20'\n    assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}",
            "def check(xshape, wshape, stride, pad):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    a = np.random.rand(*xshape).astype(np.float32)\n    b = np.random.rand(*wshape).astype(np.float32)\n    c = jt.mkl_ops.mkl_conv(a, b, stride, stride, pad, pad, 1, 1, xformat='acdb', wformat='hwio').data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': uid[0]}):\n        c_jt = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n    with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': uid[0] + 1}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n        c_jt_tune = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n    uid[0] += 2\n    assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n    logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 1, raw_logs\n    assert logs[0][0] == '20'\n    assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}",
            "def check(xshape, wshape, stride, pad):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    a = np.random.rand(*xshape).astype(np.float32)\n    b = np.random.rand(*wshape).astype(np.float32)\n    c = jt.mkl_ops.mkl_conv(a, b, stride, stride, pad, pad, 1, 1, xformat='acdb', wformat='hwio').data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': uid[0]}):\n        c_jt = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n    with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': uid[0] + 1}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n        c_jt_tune = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n    uid[0] += 2\n    assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n    logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 1, raw_logs\n    assert logs[0][0] == '20'\n    assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}"
        ]
    },
    {
        "func_name": "test_forward_nhwc_hwio",
        "original": "def test_forward_nhwc_hwio(self):\n    uid = [123]\n\n    def check(xshape, wshape, stride, pad):\n        a = np.random.rand(*xshape).astype(np.float32)\n        b = np.random.rand(*wshape).astype(np.float32)\n        c = jt.mkl_ops.mkl_conv(a, b, stride, stride, pad, pad, 1, 1, xformat='acdb', wformat='hwio').data\n        a_jt = jt.array(a)\n        b_jt = jt.array(b)\n        with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': uid[0]}):\n            c_jt = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n        with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': uid[0] + 1}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n            c_jt_tune = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n        uid[0] += 2\n        assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n        logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n        assert len(logs) == 1, raw_logs\n        assert logs[0][0] == '20'\n        assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}\n    check([1, 100, 100, 3], [1, 1, 3, 64], 1, 0)\n    check([1, 100, 100, 3], [3, 3, 3, 16], 1, 0)\n    check([1, 100, 100, 3], [3, 3, 3, 16], 2, 1)",
        "mutated": [
            "def test_forward_nhwc_hwio(self):\n    if False:\n        i = 10\n    uid = [123]\n\n    def check(xshape, wshape, stride, pad):\n        a = np.random.rand(*xshape).astype(np.float32)\n        b = np.random.rand(*wshape).astype(np.float32)\n        c = jt.mkl_ops.mkl_conv(a, b, stride, stride, pad, pad, 1, 1, xformat='acdb', wformat='hwio').data\n        a_jt = jt.array(a)\n        b_jt = jt.array(b)\n        with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': uid[0]}):\n            c_jt = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n        with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': uid[0] + 1}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n            c_jt_tune = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n        uid[0] += 2\n        assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n        logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n        assert len(logs) == 1, raw_logs\n        assert logs[0][0] == '20'\n        assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}\n    check([1, 100, 100, 3], [1, 1, 3, 64], 1, 0)\n    check([1, 100, 100, 3], [3, 3, 3, 16], 1, 0)\n    check([1, 100, 100, 3], [3, 3, 3, 16], 2, 1)",
            "def test_forward_nhwc_hwio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    uid = [123]\n\n    def check(xshape, wshape, stride, pad):\n        a = np.random.rand(*xshape).astype(np.float32)\n        b = np.random.rand(*wshape).astype(np.float32)\n        c = jt.mkl_ops.mkl_conv(a, b, stride, stride, pad, pad, 1, 1, xformat='acdb', wformat='hwio').data\n        a_jt = jt.array(a)\n        b_jt = jt.array(b)\n        with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': uid[0]}):\n            c_jt = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n        with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': uid[0] + 1}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n            c_jt_tune = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n        uid[0] += 2\n        assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n        logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n        assert len(logs) == 1, raw_logs\n        assert logs[0][0] == '20'\n        assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}\n    check([1, 100, 100, 3], [1, 1, 3, 64], 1, 0)\n    check([1, 100, 100, 3], [3, 3, 3, 16], 1, 0)\n    check([1, 100, 100, 3], [3, 3, 3, 16], 2, 1)",
            "def test_forward_nhwc_hwio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    uid = [123]\n\n    def check(xshape, wshape, stride, pad):\n        a = np.random.rand(*xshape).astype(np.float32)\n        b = np.random.rand(*wshape).astype(np.float32)\n        c = jt.mkl_ops.mkl_conv(a, b, stride, stride, pad, pad, 1, 1, xformat='acdb', wformat='hwio').data\n        a_jt = jt.array(a)\n        b_jt = jt.array(b)\n        with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': uid[0]}):\n            c_jt = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n        with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': uid[0] + 1}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n            c_jt_tune = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n        uid[0] += 2\n        assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n        logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n        assert len(logs) == 1, raw_logs\n        assert logs[0][0] == '20'\n        assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}\n    check([1, 100, 100, 3], [1, 1, 3, 64], 1, 0)\n    check([1, 100, 100, 3], [3, 3, 3, 16], 1, 0)\n    check([1, 100, 100, 3], [3, 3, 3, 16], 2, 1)",
            "def test_forward_nhwc_hwio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    uid = [123]\n\n    def check(xshape, wshape, stride, pad):\n        a = np.random.rand(*xshape).astype(np.float32)\n        b = np.random.rand(*wshape).astype(np.float32)\n        c = jt.mkl_ops.mkl_conv(a, b, stride, stride, pad, pad, 1, 1, xformat='acdb', wformat='hwio').data\n        a_jt = jt.array(a)\n        b_jt = jt.array(b)\n        with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': uid[0]}):\n            c_jt = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n        with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': uid[0] + 1}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n            c_jt_tune = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n        uid[0] += 2\n        assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n        logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n        assert len(logs) == 1, raw_logs\n        assert logs[0][0] == '20'\n        assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}\n    check([1, 100, 100, 3], [1, 1, 3, 64], 1, 0)\n    check([1, 100, 100, 3], [3, 3, 3, 16], 1, 0)\n    check([1, 100, 100, 3], [3, 3, 3, 16], 2, 1)",
            "def test_forward_nhwc_hwio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    uid = [123]\n\n    def check(xshape, wshape, stride, pad):\n        a = np.random.rand(*xshape).astype(np.float32)\n        b = np.random.rand(*wshape).astype(np.float32)\n        c = jt.mkl_ops.mkl_conv(a, b, stride, stride, pad, pad, 1, 1, xformat='acdb', wformat='hwio').data\n        a_jt = jt.array(a)\n        b_jt = jt.array(b)\n        with jt.flag_scope(enable_tuner=0, compile_options={'test_mkl_conv': uid[0]}):\n            c_jt = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n        with jt.log_capture_scope(enable_tuner=1, compile_options={'test_mkl_conv': uid[0] + 1}, log_v=0, log_vprefix='tuner_manager=100,conv_tuner=1000') as raw_logs:\n            c_jt_tune = conv_nhwc_hwio(a_jt, b_jt, stride, pad).data\n        uid[0] += 2\n        assert np.max(c_jt - c) < 0.0001 and np.max(c_jt_tune - c) < 0.0001\n        logs = find_log_with_re(raw_logs, 'Run tuner conv: confidence\\\\((.*)\\\\) candidates\\\\((.*)\\\\)$')\n        assert len(logs) == 1, raw_logs\n        assert logs[0][0] == '20'\n        assert simple_parser(logs[0][1]) == {'relay0': [1, 0]}\n    check([1, 100, 100, 3], [1, 1, 3, 64], 1, 0)\n    check([1, 100, 100, 3], [3, 3, 3, 16], 1, 0)\n    check([1, 100, 100, 3], [3, 3, 3, 16], 2, 1)"
        ]
    },
    {
        "func_name": "test_backward",
        "original": "def test_backward(self):\n    (n, c, H, W) = (2, 3, 5, 5)\n    (o, i, h, w) = (4, c, 3, 3)\n    a = np.random.rand(n, c, H, W).astype(np.float32)\n    b = np.random.rand(o, i, h, w).astype(np.float32)\n    da = np.random.rand(n, o, H, W).astype(np.float32)\n    dx = jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1).data\n    dw = jt.mkl_ops.mkl_conv_backward_w(a, da, h, w, 1, 1, 1, 1, 1, 1).data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0):\n        c_jt = conv(a_jt, b_jt, 1, 1) * da\n        gs = jt.grad(c_jt, [a_jt, b_jt])\n        gs.append(c_jt)\n        jt.fetch_sync(gs)\n        dx_jt = gs[0].data\n        dw_jt = gs[1].data\n    with jt.log_capture_scope(log_v=10, log_vprefix='tuner_manager=100,var_relay=100', enable_tuner=1, compile_options={'test_mkl_conv': 2}) as rawlogs:\n        gs_tune = jt.grad(c_jt, [a_jt, b_jt])\n        jt.fetch_sync(gs_tune)\n        dx_jt_tune = gs_tune[0].data\n        dw_jt_tune = gs_tune[1].data\n    logs = find_log_with_re(rawlogs, 'Run tuner conv: confidence\\\\((20)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 2, len(logs)\n    assert logs[0][0] == '20', 'confidence of reorder should be 20'\n    candidates = simple_parser(logs[0][1])\n    assert candidates == {'relay0': [1, 0]}, candidates\n    logs = find_log_with_re(rawlogs, 'get_relay_src([\\\\s\\\\S]*)')\n    assert len(logs) == 2\n    assert '@relay_op' in logs[0]\n    assert '@relay_op' in logs[1]\n    assert np.max(dx_jt - dx) < 1e-05 and np.max(dw_jt - dw) < 1e-05\n    assert np.max(dx_jt_tune - dx) < 1e-05 and np.max(dw_jt_tune - dw) < 1e-05",
        "mutated": [
            "def test_backward(self):\n    if False:\n        i = 10\n    (n, c, H, W) = (2, 3, 5, 5)\n    (o, i, h, w) = (4, c, 3, 3)\n    a = np.random.rand(n, c, H, W).astype(np.float32)\n    b = np.random.rand(o, i, h, w).astype(np.float32)\n    da = np.random.rand(n, o, H, W).astype(np.float32)\n    dx = jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1).data\n    dw = jt.mkl_ops.mkl_conv_backward_w(a, da, h, w, 1, 1, 1, 1, 1, 1).data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0):\n        c_jt = conv(a_jt, b_jt, 1, 1) * da\n        gs = jt.grad(c_jt, [a_jt, b_jt])\n        gs.append(c_jt)\n        jt.fetch_sync(gs)\n        dx_jt = gs[0].data\n        dw_jt = gs[1].data\n    with jt.log_capture_scope(log_v=10, log_vprefix='tuner_manager=100,var_relay=100', enable_tuner=1, compile_options={'test_mkl_conv': 2}) as rawlogs:\n        gs_tune = jt.grad(c_jt, [a_jt, b_jt])\n        jt.fetch_sync(gs_tune)\n        dx_jt_tune = gs_tune[0].data\n        dw_jt_tune = gs_tune[1].data\n    logs = find_log_with_re(rawlogs, 'Run tuner conv: confidence\\\\((20)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 2, len(logs)\n    assert logs[0][0] == '20', 'confidence of reorder should be 20'\n    candidates = simple_parser(logs[0][1])\n    assert candidates == {'relay0': [1, 0]}, candidates\n    logs = find_log_with_re(rawlogs, 'get_relay_src([\\\\s\\\\S]*)')\n    assert len(logs) == 2\n    assert '@relay_op' in logs[0]\n    assert '@relay_op' in logs[1]\n    assert np.max(dx_jt - dx) < 1e-05 and np.max(dw_jt - dw) < 1e-05\n    assert np.max(dx_jt_tune - dx) < 1e-05 and np.max(dw_jt_tune - dw) < 1e-05",
            "def test_backward(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (n, c, H, W) = (2, 3, 5, 5)\n    (o, i, h, w) = (4, c, 3, 3)\n    a = np.random.rand(n, c, H, W).astype(np.float32)\n    b = np.random.rand(o, i, h, w).astype(np.float32)\n    da = np.random.rand(n, o, H, W).astype(np.float32)\n    dx = jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1).data\n    dw = jt.mkl_ops.mkl_conv_backward_w(a, da, h, w, 1, 1, 1, 1, 1, 1).data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0):\n        c_jt = conv(a_jt, b_jt, 1, 1) * da\n        gs = jt.grad(c_jt, [a_jt, b_jt])\n        gs.append(c_jt)\n        jt.fetch_sync(gs)\n        dx_jt = gs[0].data\n        dw_jt = gs[1].data\n    with jt.log_capture_scope(log_v=10, log_vprefix='tuner_manager=100,var_relay=100', enable_tuner=1, compile_options={'test_mkl_conv': 2}) as rawlogs:\n        gs_tune = jt.grad(c_jt, [a_jt, b_jt])\n        jt.fetch_sync(gs_tune)\n        dx_jt_tune = gs_tune[0].data\n        dw_jt_tune = gs_tune[1].data\n    logs = find_log_with_re(rawlogs, 'Run tuner conv: confidence\\\\((20)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 2, len(logs)\n    assert logs[0][0] == '20', 'confidence of reorder should be 20'\n    candidates = simple_parser(logs[0][1])\n    assert candidates == {'relay0': [1, 0]}, candidates\n    logs = find_log_with_re(rawlogs, 'get_relay_src([\\\\s\\\\S]*)')\n    assert len(logs) == 2\n    assert '@relay_op' in logs[0]\n    assert '@relay_op' in logs[1]\n    assert np.max(dx_jt - dx) < 1e-05 and np.max(dw_jt - dw) < 1e-05\n    assert np.max(dx_jt_tune - dx) < 1e-05 and np.max(dw_jt_tune - dw) < 1e-05",
            "def test_backward(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (n, c, H, W) = (2, 3, 5, 5)\n    (o, i, h, w) = (4, c, 3, 3)\n    a = np.random.rand(n, c, H, W).astype(np.float32)\n    b = np.random.rand(o, i, h, w).astype(np.float32)\n    da = np.random.rand(n, o, H, W).astype(np.float32)\n    dx = jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1).data\n    dw = jt.mkl_ops.mkl_conv_backward_w(a, da, h, w, 1, 1, 1, 1, 1, 1).data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0):\n        c_jt = conv(a_jt, b_jt, 1, 1) * da\n        gs = jt.grad(c_jt, [a_jt, b_jt])\n        gs.append(c_jt)\n        jt.fetch_sync(gs)\n        dx_jt = gs[0].data\n        dw_jt = gs[1].data\n    with jt.log_capture_scope(log_v=10, log_vprefix='tuner_manager=100,var_relay=100', enable_tuner=1, compile_options={'test_mkl_conv': 2}) as rawlogs:\n        gs_tune = jt.grad(c_jt, [a_jt, b_jt])\n        jt.fetch_sync(gs_tune)\n        dx_jt_tune = gs_tune[0].data\n        dw_jt_tune = gs_tune[1].data\n    logs = find_log_with_re(rawlogs, 'Run tuner conv: confidence\\\\((20)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 2, len(logs)\n    assert logs[0][0] == '20', 'confidence of reorder should be 20'\n    candidates = simple_parser(logs[0][1])\n    assert candidates == {'relay0': [1, 0]}, candidates\n    logs = find_log_with_re(rawlogs, 'get_relay_src([\\\\s\\\\S]*)')\n    assert len(logs) == 2\n    assert '@relay_op' in logs[0]\n    assert '@relay_op' in logs[1]\n    assert np.max(dx_jt - dx) < 1e-05 and np.max(dw_jt - dw) < 1e-05\n    assert np.max(dx_jt_tune - dx) < 1e-05 and np.max(dw_jt_tune - dw) < 1e-05",
            "def test_backward(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (n, c, H, W) = (2, 3, 5, 5)\n    (o, i, h, w) = (4, c, 3, 3)\n    a = np.random.rand(n, c, H, W).astype(np.float32)\n    b = np.random.rand(o, i, h, w).astype(np.float32)\n    da = np.random.rand(n, o, H, W).astype(np.float32)\n    dx = jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1).data\n    dw = jt.mkl_ops.mkl_conv_backward_w(a, da, h, w, 1, 1, 1, 1, 1, 1).data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0):\n        c_jt = conv(a_jt, b_jt, 1, 1) * da\n        gs = jt.grad(c_jt, [a_jt, b_jt])\n        gs.append(c_jt)\n        jt.fetch_sync(gs)\n        dx_jt = gs[0].data\n        dw_jt = gs[1].data\n    with jt.log_capture_scope(log_v=10, log_vprefix='tuner_manager=100,var_relay=100', enable_tuner=1, compile_options={'test_mkl_conv': 2}) as rawlogs:\n        gs_tune = jt.grad(c_jt, [a_jt, b_jt])\n        jt.fetch_sync(gs_tune)\n        dx_jt_tune = gs_tune[0].data\n        dw_jt_tune = gs_tune[1].data\n    logs = find_log_with_re(rawlogs, 'Run tuner conv: confidence\\\\((20)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 2, len(logs)\n    assert logs[0][0] == '20', 'confidence of reorder should be 20'\n    candidates = simple_parser(logs[0][1])\n    assert candidates == {'relay0': [1, 0]}, candidates\n    logs = find_log_with_re(rawlogs, 'get_relay_src([\\\\s\\\\S]*)')\n    assert len(logs) == 2\n    assert '@relay_op' in logs[0]\n    assert '@relay_op' in logs[1]\n    assert np.max(dx_jt - dx) < 1e-05 and np.max(dw_jt - dw) < 1e-05\n    assert np.max(dx_jt_tune - dx) < 1e-05 and np.max(dw_jt_tune - dw) < 1e-05",
            "def test_backward(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (n, c, H, W) = (2, 3, 5, 5)\n    (o, i, h, w) = (4, c, 3, 3)\n    a = np.random.rand(n, c, H, W).astype(np.float32)\n    b = np.random.rand(o, i, h, w).astype(np.float32)\n    da = np.random.rand(n, o, H, W).astype(np.float32)\n    dx = jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1).data\n    dw = jt.mkl_ops.mkl_conv_backward_w(a, da, h, w, 1, 1, 1, 1, 1, 1).data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0):\n        c_jt = conv(a_jt, b_jt, 1, 1) * da\n        gs = jt.grad(c_jt, [a_jt, b_jt])\n        gs.append(c_jt)\n        jt.fetch_sync(gs)\n        dx_jt = gs[0].data\n        dw_jt = gs[1].data\n    with jt.log_capture_scope(log_v=10, log_vprefix='tuner_manager=100,var_relay=100', enable_tuner=1, compile_options={'test_mkl_conv': 2}) as rawlogs:\n        gs_tune = jt.grad(c_jt, [a_jt, b_jt])\n        jt.fetch_sync(gs_tune)\n        dx_jt_tune = gs_tune[0].data\n        dw_jt_tune = gs_tune[1].data\n    logs = find_log_with_re(rawlogs, 'Run tuner conv: confidence\\\\((20)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 2, len(logs)\n    assert logs[0][0] == '20', 'confidence of reorder should be 20'\n    candidates = simple_parser(logs[0][1])\n    assert candidates == {'relay0': [1, 0]}, candidates\n    logs = find_log_with_re(rawlogs, 'get_relay_src([\\\\s\\\\S]*)')\n    assert len(logs) == 2\n    assert '@relay_op' in logs[0]\n    assert '@relay_op' in logs[1]\n    assert np.max(dx_jt - dx) < 1e-05 and np.max(dw_jt - dw) < 1e-05\n    assert np.max(dx_jt_tune - dx) < 1e-05 and np.max(dw_jt_tune - dw) < 1e-05"
        ]
    },
    {
        "func_name": "test_backward_nhwc_hwio",
        "original": "def test_backward_nhwc_hwio(self):\n    (n, c, H, W) = (2, 3, 5, 5)\n    (o, i, h, w) = (4, c, 3, 3)\n    a = np.random.rand(n, H, W, c).astype(np.float32)\n    b = np.random.rand(h, w, i, o).astype(np.float32)\n    da = np.random.rand(n, H, W, o).astype(np.float32)\n    jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb')\n    dx = jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb').data\n    dw = jt.mkl_ops.mkl_conv_backward_w(a, da, h, w, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb').data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0):\n        c_jt = conv_nhwc_hwio(a_jt, b_jt, 1, 1) * da\n        gs = jt.grad(c_jt, [a_jt, b_jt])\n        gs.append(c_jt)\n        jt.fetch_sync(gs)\n        dx_jt = gs[0].data\n        dw_jt = gs[1].data\n    with jt.log_capture_scope(log_v=10, log_vprefix='tuner_manager=100,var_relay=100', enable_tuner=1, compile_options={'test_mkl_conv': 2}) as rawlogs:\n        gs_tune = jt.grad(c_jt, [a_jt, b_jt])\n        jt.fetch_sync(gs_tune)\n        dx_jt_tune = gs_tune[0].data\n        dw_jt_tune = gs_tune[1].data\n    logs = find_log_with_re(rawlogs, 'Run tuner conv: confidence\\\\((20)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 2\n    assert logs[0][0] == '20', 'confidence of reorder should be 20'\n    candidates = simple_parser(logs[0][1])\n    assert candidates == {'relay0': [1, 0]}, candidates\n    logs = find_log_with_re(rawlogs, 'get_relay_src([\\\\s\\\\S]*)')\n    assert len(logs) == 2\n    assert '@relay_op' in logs[0]\n    assert '@relay_op' in logs[1]\n    assert np.max(dx_jt_tune - dx) < 1e-05 and np.max(dw_jt_tune - dw) < 1e-05\n    assert np.max(dx_jt - dx) < 1e-05 and np.max(dw_jt - dw) < 1e-05",
        "mutated": [
            "def test_backward_nhwc_hwio(self):\n    if False:\n        i = 10\n    (n, c, H, W) = (2, 3, 5, 5)\n    (o, i, h, w) = (4, c, 3, 3)\n    a = np.random.rand(n, H, W, c).astype(np.float32)\n    b = np.random.rand(h, w, i, o).astype(np.float32)\n    da = np.random.rand(n, H, W, o).astype(np.float32)\n    jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb')\n    dx = jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb').data\n    dw = jt.mkl_ops.mkl_conv_backward_w(a, da, h, w, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb').data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0):\n        c_jt = conv_nhwc_hwio(a_jt, b_jt, 1, 1) * da\n        gs = jt.grad(c_jt, [a_jt, b_jt])\n        gs.append(c_jt)\n        jt.fetch_sync(gs)\n        dx_jt = gs[0].data\n        dw_jt = gs[1].data\n    with jt.log_capture_scope(log_v=10, log_vprefix='tuner_manager=100,var_relay=100', enable_tuner=1, compile_options={'test_mkl_conv': 2}) as rawlogs:\n        gs_tune = jt.grad(c_jt, [a_jt, b_jt])\n        jt.fetch_sync(gs_tune)\n        dx_jt_tune = gs_tune[0].data\n        dw_jt_tune = gs_tune[1].data\n    logs = find_log_with_re(rawlogs, 'Run tuner conv: confidence\\\\((20)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 2\n    assert logs[0][0] == '20', 'confidence of reorder should be 20'\n    candidates = simple_parser(logs[0][1])\n    assert candidates == {'relay0': [1, 0]}, candidates\n    logs = find_log_with_re(rawlogs, 'get_relay_src([\\\\s\\\\S]*)')\n    assert len(logs) == 2\n    assert '@relay_op' in logs[0]\n    assert '@relay_op' in logs[1]\n    assert np.max(dx_jt_tune - dx) < 1e-05 and np.max(dw_jt_tune - dw) < 1e-05\n    assert np.max(dx_jt - dx) < 1e-05 and np.max(dw_jt - dw) < 1e-05",
            "def test_backward_nhwc_hwio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (n, c, H, W) = (2, 3, 5, 5)\n    (o, i, h, w) = (4, c, 3, 3)\n    a = np.random.rand(n, H, W, c).astype(np.float32)\n    b = np.random.rand(h, w, i, o).astype(np.float32)\n    da = np.random.rand(n, H, W, o).astype(np.float32)\n    jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb')\n    dx = jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb').data\n    dw = jt.mkl_ops.mkl_conv_backward_w(a, da, h, w, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb').data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0):\n        c_jt = conv_nhwc_hwio(a_jt, b_jt, 1, 1) * da\n        gs = jt.grad(c_jt, [a_jt, b_jt])\n        gs.append(c_jt)\n        jt.fetch_sync(gs)\n        dx_jt = gs[0].data\n        dw_jt = gs[1].data\n    with jt.log_capture_scope(log_v=10, log_vprefix='tuner_manager=100,var_relay=100', enable_tuner=1, compile_options={'test_mkl_conv': 2}) as rawlogs:\n        gs_tune = jt.grad(c_jt, [a_jt, b_jt])\n        jt.fetch_sync(gs_tune)\n        dx_jt_tune = gs_tune[0].data\n        dw_jt_tune = gs_tune[1].data\n    logs = find_log_with_re(rawlogs, 'Run tuner conv: confidence\\\\((20)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 2\n    assert logs[0][0] == '20', 'confidence of reorder should be 20'\n    candidates = simple_parser(logs[0][1])\n    assert candidates == {'relay0': [1, 0]}, candidates\n    logs = find_log_with_re(rawlogs, 'get_relay_src([\\\\s\\\\S]*)')\n    assert len(logs) == 2\n    assert '@relay_op' in logs[0]\n    assert '@relay_op' in logs[1]\n    assert np.max(dx_jt_tune - dx) < 1e-05 and np.max(dw_jt_tune - dw) < 1e-05\n    assert np.max(dx_jt - dx) < 1e-05 and np.max(dw_jt - dw) < 1e-05",
            "def test_backward_nhwc_hwio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (n, c, H, W) = (2, 3, 5, 5)\n    (o, i, h, w) = (4, c, 3, 3)\n    a = np.random.rand(n, H, W, c).astype(np.float32)\n    b = np.random.rand(h, w, i, o).astype(np.float32)\n    da = np.random.rand(n, H, W, o).astype(np.float32)\n    jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb')\n    dx = jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb').data\n    dw = jt.mkl_ops.mkl_conv_backward_w(a, da, h, w, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb').data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0):\n        c_jt = conv_nhwc_hwio(a_jt, b_jt, 1, 1) * da\n        gs = jt.grad(c_jt, [a_jt, b_jt])\n        gs.append(c_jt)\n        jt.fetch_sync(gs)\n        dx_jt = gs[0].data\n        dw_jt = gs[1].data\n    with jt.log_capture_scope(log_v=10, log_vprefix='tuner_manager=100,var_relay=100', enable_tuner=1, compile_options={'test_mkl_conv': 2}) as rawlogs:\n        gs_tune = jt.grad(c_jt, [a_jt, b_jt])\n        jt.fetch_sync(gs_tune)\n        dx_jt_tune = gs_tune[0].data\n        dw_jt_tune = gs_tune[1].data\n    logs = find_log_with_re(rawlogs, 'Run tuner conv: confidence\\\\((20)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 2\n    assert logs[0][0] == '20', 'confidence of reorder should be 20'\n    candidates = simple_parser(logs[0][1])\n    assert candidates == {'relay0': [1, 0]}, candidates\n    logs = find_log_with_re(rawlogs, 'get_relay_src([\\\\s\\\\S]*)')\n    assert len(logs) == 2\n    assert '@relay_op' in logs[0]\n    assert '@relay_op' in logs[1]\n    assert np.max(dx_jt_tune - dx) < 1e-05 and np.max(dw_jt_tune - dw) < 1e-05\n    assert np.max(dx_jt - dx) < 1e-05 and np.max(dw_jt - dw) < 1e-05",
            "def test_backward_nhwc_hwio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (n, c, H, W) = (2, 3, 5, 5)\n    (o, i, h, w) = (4, c, 3, 3)\n    a = np.random.rand(n, H, W, c).astype(np.float32)\n    b = np.random.rand(h, w, i, o).astype(np.float32)\n    da = np.random.rand(n, H, W, o).astype(np.float32)\n    jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb')\n    dx = jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb').data\n    dw = jt.mkl_ops.mkl_conv_backward_w(a, da, h, w, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb').data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0):\n        c_jt = conv_nhwc_hwio(a_jt, b_jt, 1, 1) * da\n        gs = jt.grad(c_jt, [a_jt, b_jt])\n        gs.append(c_jt)\n        jt.fetch_sync(gs)\n        dx_jt = gs[0].data\n        dw_jt = gs[1].data\n    with jt.log_capture_scope(log_v=10, log_vprefix='tuner_manager=100,var_relay=100', enable_tuner=1, compile_options={'test_mkl_conv': 2}) as rawlogs:\n        gs_tune = jt.grad(c_jt, [a_jt, b_jt])\n        jt.fetch_sync(gs_tune)\n        dx_jt_tune = gs_tune[0].data\n        dw_jt_tune = gs_tune[1].data\n    logs = find_log_with_re(rawlogs, 'Run tuner conv: confidence\\\\((20)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 2\n    assert logs[0][0] == '20', 'confidence of reorder should be 20'\n    candidates = simple_parser(logs[0][1])\n    assert candidates == {'relay0': [1, 0]}, candidates\n    logs = find_log_with_re(rawlogs, 'get_relay_src([\\\\s\\\\S]*)')\n    assert len(logs) == 2\n    assert '@relay_op' in logs[0]\n    assert '@relay_op' in logs[1]\n    assert np.max(dx_jt_tune - dx) < 1e-05 and np.max(dw_jt_tune - dw) < 1e-05\n    assert np.max(dx_jt - dx) < 1e-05 and np.max(dw_jt - dw) < 1e-05",
            "def test_backward_nhwc_hwio(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (n, c, H, W) = (2, 3, 5, 5)\n    (o, i, h, w) = (4, c, 3, 3)\n    a = np.random.rand(n, H, W, c).astype(np.float32)\n    b = np.random.rand(h, w, i, o).astype(np.float32)\n    da = np.random.rand(n, H, W, o).astype(np.float32)\n    jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb')\n    dx = jt.mkl_ops.mkl_conv_backward_x(b, da, H, W, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb').data\n    dw = jt.mkl_ops.mkl_conv_backward_w(a, da, h, w, 1, 1, 1, 1, 1, 1, xformat='acdb', wformat='hwio', yformat='acdb').data\n    a_jt = jt.array(a)\n    b_jt = jt.array(b)\n    with jt.flag_scope(enable_tuner=0):\n        c_jt = conv_nhwc_hwio(a_jt, b_jt, 1, 1) * da\n        gs = jt.grad(c_jt, [a_jt, b_jt])\n        gs.append(c_jt)\n        jt.fetch_sync(gs)\n        dx_jt = gs[0].data\n        dw_jt = gs[1].data\n    with jt.log_capture_scope(log_v=10, log_vprefix='tuner_manager=100,var_relay=100', enable_tuner=1, compile_options={'test_mkl_conv': 2}) as rawlogs:\n        gs_tune = jt.grad(c_jt, [a_jt, b_jt])\n        jt.fetch_sync(gs_tune)\n        dx_jt_tune = gs_tune[0].data\n        dw_jt_tune = gs_tune[1].data\n    logs = find_log_with_re(rawlogs, 'Run tuner conv: confidence\\\\((20)\\\\) candidates\\\\((.*)\\\\)$')\n    assert len(logs) == 2\n    assert logs[0][0] == '20', 'confidence of reorder should be 20'\n    candidates = simple_parser(logs[0][1])\n    assert candidates == {'relay0': [1, 0]}, candidates\n    logs = find_log_with_re(rawlogs, 'get_relay_src([\\\\s\\\\S]*)')\n    assert len(logs) == 2\n    assert '@relay_op' in logs[0]\n    assert '@relay_op' in logs[1]\n    assert np.max(dx_jt_tune - dx) < 1e-05 and np.max(dw_jt_tune - dw) < 1e-05\n    assert np.max(dx_jt - dx) < 1e-05 and np.max(dw_jt - dw) < 1e-05"
        ]
    }
]