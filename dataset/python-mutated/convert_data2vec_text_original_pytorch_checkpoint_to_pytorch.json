[
    {
        "func_name": "convert_data2vec_checkpoint_to_pytorch",
        "original": "def convert_data2vec_checkpoint_to_pytorch(data2vec_checkpoint_path: str, pytorch_dump_folder_path: str, classification_head: bool):\n    \"\"\"\n    Copy/paste/tweak data2vec's weights to our BERT structure.\n    \"\"\"\n    (data2vec_checkpoint_dir, data2vec_checkpoint_file_name) = os.path.split(data2vec_checkpoint_path)\n    data2vec = Data2VecTextModel.from_pretrained(data2vec_checkpoint_dir, checkpoint_file=data2vec_checkpoint_file_name)\n    data2vec.eval()\n    data2vec_model = data2vec.models[0]\n    data2vec_sent_encoder = data2vec_model.encoder.sentence_encoder\n    config = Data2VecTextConfig(vocab_size=data2vec_sent_encoder.embed_tokens.num_embeddings, hidden_size=data2vec_model.args.encoder_embed_dim, num_hidden_layers=data2vec_model.args.encoder_layers, num_attention_heads=data2vec_model.args.encoder_attention_heads, intermediate_size=data2vec_model.args.encoder_ffn_embed_dim, max_position_embeddings=514, type_vocab_size=1, layer_norm_eps=1e-05)\n    if classification_head:\n        config.num_labels = data2vec.model.classification_heads['mnli'].out_proj.weight.shape[0]\n    print('Our BERT config:', config)\n    model = Data2VecTextForSequenceClassification(config) if classification_head else Data2VecTextForMaskedLM(config)\n    model.eval()\n    model.data2vec_text.embeddings.word_embeddings.weight = data2vec_sent_encoder.embed_tokens.weight\n    model.data2vec_text.embeddings.position_embeddings.weight = data2vec_sent_encoder.embed_positions.weight\n    model.data2vec_text.embeddings.token_type_embeddings.weight.data = torch.zeros_like(model.data2vec_text.embeddings.token_type_embeddings.weight)\n    model.data2vec_text.embeddings.LayerNorm.weight = data2vec_sent_encoder.layernorm_embedding.weight\n    model.data2vec_text.embeddings.LayerNorm.bias = data2vec_sent_encoder.layernorm_embedding.bias\n    for i in range(config.num_hidden_layers):\n        layer: BertLayer = model.data2vec_text.encoder.layer[i]\n        data2vec_layer: TransformerSentenceEncoderLayer = data2vec_sent_encoder.layers[i]\n        self_attn: BertSelfAttention = layer.attention.self\n        assert data2vec_layer.self_attn.k_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.k_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        assert data2vec_layer.self_attn.q_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.q_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        assert data2vec_layer.self_attn.v_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.v_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        self_attn.query.weight.data = data2vec_layer.self_attn.q_proj.weight\n        self_attn.query.bias.data = data2vec_layer.self_attn.q_proj.bias\n        self_attn.key.weight.data = data2vec_layer.self_attn.k_proj.weight\n        self_attn.key.bias.data = data2vec_layer.self_attn.k_proj.bias\n        self_attn.value.weight.data = data2vec_layer.self_attn.v_proj.weight\n        self_attn.value.bias.data = data2vec_layer.self_attn.v_proj.bias\n        self_output: BertSelfOutput = layer.attention.output\n        assert self_output.dense.weight.shape == data2vec_layer.self_attn.out_proj.weight.shape, f'Shape for self_output.dense.weight should be {data2vec_layer.self_attn.out_proj.weight.shape}'\n        self_output.dense.weight = data2vec_layer.self_attn.out_proj.weight\n        self_output.dense.bias = data2vec_layer.self_attn.out_proj.bias\n        self_output.LayerNorm.weight = data2vec_layer.self_attn_layer_norm.weight\n        self_output.LayerNorm.bias = data2vec_layer.self_attn_layer_norm.bias\n        intermediate: BertIntermediate = layer.intermediate\n        assert intermediate.dense.weight.shape == data2vec_layer.fc1.weight.shape, f'Shape for intermediate.dense.weight should be {data2vec_layer.fc1.weight.shape}'\n        intermediate.dense.weight = data2vec_layer.fc1.weight\n        intermediate.dense.bias = data2vec_layer.fc1.bias\n        bert_output: BertOutput = layer.output\n        assert bert_output.dense.weight.shape == data2vec_layer.fc2.weight.shape, f'Shape for bert_output.dense.weight should be {data2vec_layer.fc2.weight.shape}'\n        bert_output.dense.weight = data2vec_layer.fc2.weight\n        bert_output.dense.bias = data2vec_layer.fc2.bias\n        bert_output.LayerNorm.weight = data2vec_layer.final_layer_norm.weight\n        bert_output.LayerNorm.bias = data2vec_layer.final_layer_norm.bias\n    if classification_head:\n        model.classifier.dense.weight = data2vec.model.classification_heads['mnli'].dense.weight\n        model.classifier.dense.bias = data2vec.model.classification_heads['mnli'].dense.bias\n        model.classifier.out_proj.weight = data2vec.model.classification_heads['mnli'].out_proj.weight\n        model.classifier.out_proj.bias = data2vec.model.classification_heads['mnli'].out_proj.bias\n    else:\n        model.lm_head.dense.weight = data2vec_model.encoder.lm_head.dense.weight\n        model.lm_head.dense.bias = data2vec_model.encoder.lm_head.dense.bias\n        model.lm_head.layer_norm.weight = data2vec_model.encoder.lm_head.layer_norm.weight\n        model.lm_head.layer_norm.bias = data2vec_model.encoder.lm_head.layer_norm.bias\n        model.lm_head.decoder.weight = data2vec_model.encoder.lm_head.weight\n        model.lm_head.decoder.bias = data2vec_model.encoder.lm_head.bias\n    input_ids: torch.Tensor = data2vec.encode(SAMPLE_TEXT).unsqueeze(0)\n    our_output = model(input_ids)[0]\n    if classification_head:\n        their_output = data2vec.model.classification_heads['mnli'](data2vec.extract_features(input_ids))\n    else:\n        their_output = data2vec_model(input_ids)[0]\n    print(our_output.shape, their_output.shape)\n    max_absolute_diff = torch.max(torch.abs(our_output - their_output)).item()\n    print(f'max_absolute_diff = {max_absolute_diff}')\n    success = torch.allclose(our_output, their_output, atol=0.001)\n    print('Do both models output the same tensors?', '\ud83d\udd25' if success else '\ud83d\udca9')\n    if not success:\n        raise Exception('Something went wRoNg')\n    pathlib.Path(pytorch_dump_folder_path).mkdir(parents=True, exist_ok=True)\n    print(f'Saving model to {pytorch_dump_folder_path}')\n    model.save_pretrained(pytorch_dump_folder_path)",
        "mutated": [
            "def convert_data2vec_checkpoint_to_pytorch(data2vec_checkpoint_path: str, pytorch_dump_folder_path: str, classification_head: bool):\n    if False:\n        i = 10\n    \"\\n    Copy/paste/tweak data2vec's weights to our BERT structure.\\n    \"\n    (data2vec_checkpoint_dir, data2vec_checkpoint_file_name) = os.path.split(data2vec_checkpoint_path)\n    data2vec = Data2VecTextModel.from_pretrained(data2vec_checkpoint_dir, checkpoint_file=data2vec_checkpoint_file_name)\n    data2vec.eval()\n    data2vec_model = data2vec.models[0]\n    data2vec_sent_encoder = data2vec_model.encoder.sentence_encoder\n    config = Data2VecTextConfig(vocab_size=data2vec_sent_encoder.embed_tokens.num_embeddings, hidden_size=data2vec_model.args.encoder_embed_dim, num_hidden_layers=data2vec_model.args.encoder_layers, num_attention_heads=data2vec_model.args.encoder_attention_heads, intermediate_size=data2vec_model.args.encoder_ffn_embed_dim, max_position_embeddings=514, type_vocab_size=1, layer_norm_eps=1e-05)\n    if classification_head:\n        config.num_labels = data2vec.model.classification_heads['mnli'].out_proj.weight.shape[0]\n    print('Our BERT config:', config)\n    model = Data2VecTextForSequenceClassification(config) if classification_head else Data2VecTextForMaskedLM(config)\n    model.eval()\n    model.data2vec_text.embeddings.word_embeddings.weight = data2vec_sent_encoder.embed_tokens.weight\n    model.data2vec_text.embeddings.position_embeddings.weight = data2vec_sent_encoder.embed_positions.weight\n    model.data2vec_text.embeddings.token_type_embeddings.weight.data = torch.zeros_like(model.data2vec_text.embeddings.token_type_embeddings.weight)\n    model.data2vec_text.embeddings.LayerNorm.weight = data2vec_sent_encoder.layernorm_embedding.weight\n    model.data2vec_text.embeddings.LayerNorm.bias = data2vec_sent_encoder.layernorm_embedding.bias\n    for i in range(config.num_hidden_layers):\n        layer: BertLayer = model.data2vec_text.encoder.layer[i]\n        data2vec_layer: TransformerSentenceEncoderLayer = data2vec_sent_encoder.layers[i]\n        self_attn: BertSelfAttention = layer.attention.self\n        assert data2vec_layer.self_attn.k_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.k_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        assert data2vec_layer.self_attn.q_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.q_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        assert data2vec_layer.self_attn.v_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.v_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        self_attn.query.weight.data = data2vec_layer.self_attn.q_proj.weight\n        self_attn.query.bias.data = data2vec_layer.self_attn.q_proj.bias\n        self_attn.key.weight.data = data2vec_layer.self_attn.k_proj.weight\n        self_attn.key.bias.data = data2vec_layer.self_attn.k_proj.bias\n        self_attn.value.weight.data = data2vec_layer.self_attn.v_proj.weight\n        self_attn.value.bias.data = data2vec_layer.self_attn.v_proj.bias\n        self_output: BertSelfOutput = layer.attention.output\n        assert self_output.dense.weight.shape == data2vec_layer.self_attn.out_proj.weight.shape, f'Shape for self_output.dense.weight should be {data2vec_layer.self_attn.out_proj.weight.shape}'\n        self_output.dense.weight = data2vec_layer.self_attn.out_proj.weight\n        self_output.dense.bias = data2vec_layer.self_attn.out_proj.bias\n        self_output.LayerNorm.weight = data2vec_layer.self_attn_layer_norm.weight\n        self_output.LayerNorm.bias = data2vec_layer.self_attn_layer_norm.bias\n        intermediate: BertIntermediate = layer.intermediate\n        assert intermediate.dense.weight.shape == data2vec_layer.fc1.weight.shape, f'Shape for intermediate.dense.weight should be {data2vec_layer.fc1.weight.shape}'\n        intermediate.dense.weight = data2vec_layer.fc1.weight\n        intermediate.dense.bias = data2vec_layer.fc1.bias\n        bert_output: BertOutput = layer.output\n        assert bert_output.dense.weight.shape == data2vec_layer.fc2.weight.shape, f'Shape for bert_output.dense.weight should be {data2vec_layer.fc2.weight.shape}'\n        bert_output.dense.weight = data2vec_layer.fc2.weight\n        bert_output.dense.bias = data2vec_layer.fc2.bias\n        bert_output.LayerNorm.weight = data2vec_layer.final_layer_norm.weight\n        bert_output.LayerNorm.bias = data2vec_layer.final_layer_norm.bias\n    if classification_head:\n        model.classifier.dense.weight = data2vec.model.classification_heads['mnli'].dense.weight\n        model.classifier.dense.bias = data2vec.model.classification_heads['mnli'].dense.bias\n        model.classifier.out_proj.weight = data2vec.model.classification_heads['mnli'].out_proj.weight\n        model.classifier.out_proj.bias = data2vec.model.classification_heads['mnli'].out_proj.bias\n    else:\n        model.lm_head.dense.weight = data2vec_model.encoder.lm_head.dense.weight\n        model.lm_head.dense.bias = data2vec_model.encoder.lm_head.dense.bias\n        model.lm_head.layer_norm.weight = data2vec_model.encoder.lm_head.layer_norm.weight\n        model.lm_head.layer_norm.bias = data2vec_model.encoder.lm_head.layer_norm.bias\n        model.lm_head.decoder.weight = data2vec_model.encoder.lm_head.weight\n        model.lm_head.decoder.bias = data2vec_model.encoder.lm_head.bias\n    input_ids: torch.Tensor = data2vec.encode(SAMPLE_TEXT).unsqueeze(0)\n    our_output = model(input_ids)[0]\n    if classification_head:\n        their_output = data2vec.model.classification_heads['mnli'](data2vec.extract_features(input_ids))\n    else:\n        their_output = data2vec_model(input_ids)[0]\n    print(our_output.shape, their_output.shape)\n    max_absolute_diff = torch.max(torch.abs(our_output - their_output)).item()\n    print(f'max_absolute_diff = {max_absolute_diff}')\n    success = torch.allclose(our_output, their_output, atol=0.001)\n    print('Do both models output the same tensors?', '\ud83d\udd25' if success else '\ud83d\udca9')\n    if not success:\n        raise Exception('Something went wRoNg')\n    pathlib.Path(pytorch_dump_folder_path).mkdir(parents=True, exist_ok=True)\n    print(f'Saving model to {pytorch_dump_folder_path}')\n    model.save_pretrained(pytorch_dump_folder_path)",
            "def convert_data2vec_checkpoint_to_pytorch(data2vec_checkpoint_path: str, pytorch_dump_folder_path: str, classification_head: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Copy/paste/tweak data2vec's weights to our BERT structure.\\n    \"\n    (data2vec_checkpoint_dir, data2vec_checkpoint_file_name) = os.path.split(data2vec_checkpoint_path)\n    data2vec = Data2VecTextModel.from_pretrained(data2vec_checkpoint_dir, checkpoint_file=data2vec_checkpoint_file_name)\n    data2vec.eval()\n    data2vec_model = data2vec.models[0]\n    data2vec_sent_encoder = data2vec_model.encoder.sentence_encoder\n    config = Data2VecTextConfig(vocab_size=data2vec_sent_encoder.embed_tokens.num_embeddings, hidden_size=data2vec_model.args.encoder_embed_dim, num_hidden_layers=data2vec_model.args.encoder_layers, num_attention_heads=data2vec_model.args.encoder_attention_heads, intermediate_size=data2vec_model.args.encoder_ffn_embed_dim, max_position_embeddings=514, type_vocab_size=1, layer_norm_eps=1e-05)\n    if classification_head:\n        config.num_labels = data2vec.model.classification_heads['mnli'].out_proj.weight.shape[0]\n    print('Our BERT config:', config)\n    model = Data2VecTextForSequenceClassification(config) if classification_head else Data2VecTextForMaskedLM(config)\n    model.eval()\n    model.data2vec_text.embeddings.word_embeddings.weight = data2vec_sent_encoder.embed_tokens.weight\n    model.data2vec_text.embeddings.position_embeddings.weight = data2vec_sent_encoder.embed_positions.weight\n    model.data2vec_text.embeddings.token_type_embeddings.weight.data = torch.zeros_like(model.data2vec_text.embeddings.token_type_embeddings.weight)\n    model.data2vec_text.embeddings.LayerNorm.weight = data2vec_sent_encoder.layernorm_embedding.weight\n    model.data2vec_text.embeddings.LayerNorm.bias = data2vec_sent_encoder.layernorm_embedding.bias\n    for i in range(config.num_hidden_layers):\n        layer: BertLayer = model.data2vec_text.encoder.layer[i]\n        data2vec_layer: TransformerSentenceEncoderLayer = data2vec_sent_encoder.layers[i]\n        self_attn: BertSelfAttention = layer.attention.self\n        assert data2vec_layer.self_attn.k_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.k_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        assert data2vec_layer.self_attn.q_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.q_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        assert data2vec_layer.self_attn.v_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.v_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        self_attn.query.weight.data = data2vec_layer.self_attn.q_proj.weight\n        self_attn.query.bias.data = data2vec_layer.self_attn.q_proj.bias\n        self_attn.key.weight.data = data2vec_layer.self_attn.k_proj.weight\n        self_attn.key.bias.data = data2vec_layer.self_attn.k_proj.bias\n        self_attn.value.weight.data = data2vec_layer.self_attn.v_proj.weight\n        self_attn.value.bias.data = data2vec_layer.self_attn.v_proj.bias\n        self_output: BertSelfOutput = layer.attention.output\n        assert self_output.dense.weight.shape == data2vec_layer.self_attn.out_proj.weight.shape, f'Shape for self_output.dense.weight should be {data2vec_layer.self_attn.out_proj.weight.shape}'\n        self_output.dense.weight = data2vec_layer.self_attn.out_proj.weight\n        self_output.dense.bias = data2vec_layer.self_attn.out_proj.bias\n        self_output.LayerNorm.weight = data2vec_layer.self_attn_layer_norm.weight\n        self_output.LayerNorm.bias = data2vec_layer.self_attn_layer_norm.bias\n        intermediate: BertIntermediate = layer.intermediate\n        assert intermediate.dense.weight.shape == data2vec_layer.fc1.weight.shape, f'Shape for intermediate.dense.weight should be {data2vec_layer.fc1.weight.shape}'\n        intermediate.dense.weight = data2vec_layer.fc1.weight\n        intermediate.dense.bias = data2vec_layer.fc1.bias\n        bert_output: BertOutput = layer.output\n        assert bert_output.dense.weight.shape == data2vec_layer.fc2.weight.shape, f'Shape for bert_output.dense.weight should be {data2vec_layer.fc2.weight.shape}'\n        bert_output.dense.weight = data2vec_layer.fc2.weight\n        bert_output.dense.bias = data2vec_layer.fc2.bias\n        bert_output.LayerNorm.weight = data2vec_layer.final_layer_norm.weight\n        bert_output.LayerNorm.bias = data2vec_layer.final_layer_norm.bias\n    if classification_head:\n        model.classifier.dense.weight = data2vec.model.classification_heads['mnli'].dense.weight\n        model.classifier.dense.bias = data2vec.model.classification_heads['mnli'].dense.bias\n        model.classifier.out_proj.weight = data2vec.model.classification_heads['mnli'].out_proj.weight\n        model.classifier.out_proj.bias = data2vec.model.classification_heads['mnli'].out_proj.bias\n    else:\n        model.lm_head.dense.weight = data2vec_model.encoder.lm_head.dense.weight\n        model.lm_head.dense.bias = data2vec_model.encoder.lm_head.dense.bias\n        model.lm_head.layer_norm.weight = data2vec_model.encoder.lm_head.layer_norm.weight\n        model.lm_head.layer_norm.bias = data2vec_model.encoder.lm_head.layer_norm.bias\n        model.lm_head.decoder.weight = data2vec_model.encoder.lm_head.weight\n        model.lm_head.decoder.bias = data2vec_model.encoder.lm_head.bias\n    input_ids: torch.Tensor = data2vec.encode(SAMPLE_TEXT).unsqueeze(0)\n    our_output = model(input_ids)[0]\n    if classification_head:\n        their_output = data2vec.model.classification_heads['mnli'](data2vec.extract_features(input_ids))\n    else:\n        their_output = data2vec_model(input_ids)[0]\n    print(our_output.shape, their_output.shape)\n    max_absolute_diff = torch.max(torch.abs(our_output - their_output)).item()\n    print(f'max_absolute_diff = {max_absolute_diff}')\n    success = torch.allclose(our_output, their_output, atol=0.001)\n    print('Do both models output the same tensors?', '\ud83d\udd25' if success else '\ud83d\udca9')\n    if not success:\n        raise Exception('Something went wRoNg')\n    pathlib.Path(pytorch_dump_folder_path).mkdir(parents=True, exist_ok=True)\n    print(f'Saving model to {pytorch_dump_folder_path}')\n    model.save_pretrained(pytorch_dump_folder_path)",
            "def convert_data2vec_checkpoint_to_pytorch(data2vec_checkpoint_path: str, pytorch_dump_folder_path: str, classification_head: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Copy/paste/tweak data2vec's weights to our BERT structure.\\n    \"\n    (data2vec_checkpoint_dir, data2vec_checkpoint_file_name) = os.path.split(data2vec_checkpoint_path)\n    data2vec = Data2VecTextModel.from_pretrained(data2vec_checkpoint_dir, checkpoint_file=data2vec_checkpoint_file_name)\n    data2vec.eval()\n    data2vec_model = data2vec.models[0]\n    data2vec_sent_encoder = data2vec_model.encoder.sentence_encoder\n    config = Data2VecTextConfig(vocab_size=data2vec_sent_encoder.embed_tokens.num_embeddings, hidden_size=data2vec_model.args.encoder_embed_dim, num_hidden_layers=data2vec_model.args.encoder_layers, num_attention_heads=data2vec_model.args.encoder_attention_heads, intermediate_size=data2vec_model.args.encoder_ffn_embed_dim, max_position_embeddings=514, type_vocab_size=1, layer_norm_eps=1e-05)\n    if classification_head:\n        config.num_labels = data2vec.model.classification_heads['mnli'].out_proj.weight.shape[0]\n    print('Our BERT config:', config)\n    model = Data2VecTextForSequenceClassification(config) if classification_head else Data2VecTextForMaskedLM(config)\n    model.eval()\n    model.data2vec_text.embeddings.word_embeddings.weight = data2vec_sent_encoder.embed_tokens.weight\n    model.data2vec_text.embeddings.position_embeddings.weight = data2vec_sent_encoder.embed_positions.weight\n    model.data2vec_text.embeddings.token_type_embeddings.weight.data = torch.zeros_like(model.data2vec_text.embeddings.token_type_embeddings.weight)\n    model.data2vec_text.embeddings.LayerNorm.weight = data2vec_sent_encoder.layernorm_embedding.weight\n    model.data2vec_text.embeddings.LayerNorm.bias = data2vec_sent_encoder.layernorm_embedding.bias\n    for i in range(config.num_hidden_layers):\n        layer: BertLayer = model.data2vec_text.encoder.layer[i]\n        data2vec_layer: TransformerSentenceEncoderLayer = data2vec_sent_encoder.layers[i]\n        self_attn: BertSelfAttention = layer.attention.self\n        assert data2vec_layer.self_attn.k_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.k_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        assert data2vec_layer.self_attn.q_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.q_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        assert data2vec_layer.self_attn.v_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.v_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        self_attn.query.weight.data = data2vec_layer.self_attn.q_proj.weight\n        self_attn.query.bias.data = data2vec_layer.self_attn.q_proj.bias\n        self_attn.key.weight.data = data2vec_layer.self_attn.k_proj.weight\n        self_attn.key.bias.data = data2vec_layer.self_attn.k_proj.bias\n        self_attn.value.weight.data = data2vec_layer.self_attn.v_proj.weight\n        self_attn.value.bias.data = data2vec_layer.self_attn.v_proj.bias\n        self_output: BertSelfOutput = layer.attention.output\n        assert self_output.dense.weight.shape == data2vec_layer.self_attn.out_proj.weight.shape, f'Shape for self_output.dense.weight should be {data2vec_layer.self_attn.out_proj.weight.shape}'\n        self_output.dense.weight = data2vec_layer.self_attn.out_proj.weight\n        self_output.dense.bias = data2vec_layer.self_attn.out_proj.bias\n        self_output.LayerNorm.weight = data2vec_layer.self_attn_layer_norm.weight\n        self_output.LayerNorm.bias = data2vec_layer.self_attn_layer_norm.bias\n        intermediate: BertIntermediate = layer.intermediate\n        assert intermediate.dense.weight.shape == data2vec_layer.fc1.weight.shape, f'Shape for intermediate.dense.weight should be {data2vec_layer.fc1.weight.shape}'\n        intermediate.dense.weight = data2vec_layer.fc1.weight\n        intermediate.dense.bias = data2vec_layer.fc1.bias\n        bert_output: BertOutput = layer.output\n        assert bert_output.dense.weight.shape == data2vec_layer.fc2.weight.shape, f'Shape for bert_output.dense.weight should be {data2vec_layer.fc2.weight.shape}'\n        bert_output.dense.weight = data2vec_layer.fc2.weight\n        bert_output.dense.bias = data2vec_layer.fc2.bias\n        bert_output.LayerNorm.weight = data2vec_layer.final_layer_norm.weight\n        bert_output.LayerNorm.bias = data2vec_layer.final_layer_norm.bias\n    if classification_head:\n        model.classifier.dense.weight = data2vec.model.classification_heads['mnli'].dense.weight\n        model.classifier.dense.bias = data2vec.model.classification_heads['mnli'].dense.bias\n        model.classifier.out_proj.weight = data2vec.model.classification_heads['mnli'].out_proj.weight\n        model.classifier.out_proj.bias = data2vec.model.classification_heads['mnli'].out_proj.bias\n    else:\n        model.lm_head.dense.weight = data2vec_model.encoder.lm_head.dense.weight\n        model.lm_head.dense.bias = data2vec_model.encoder.lm_head.dense.bias\n        model.lm_head.layer_norm.weight = data2vec_model.encoder.lm_head.layer_norm.weight\n        model.lm_head.layer_norm.bias = data2vec_model.encoder.lm_head.layer_norm.bias\n        model.lm_head.decoder.weight = data2vec_model.encoder.lm_head.weight\n        model.lm_head.decoder.bias = data2vec_model.encoder.lm_head.bias\n    input_ids: torch.Tensor = data2vec.encode(SAMPLE_TEXT).unsqueeze(0)\n    our_output = model(input_ids)[0]\n    if classification_head:\n        their_output = data2vec.model.classification_heads['mnli'](data2vec.extract_features(input_ids))\n    else:\n        their_output = data2vec_model(input_ids)[0]\n    print(our_output.shape, their_output.shape)\n    max_absolute_diff = torch.max(torch.abs(our_output - their_output)).item()\n    print(f'max_absolute_diff = {max_absolute_diff}')\n    success = torch.allclose(our_output, their_output, atol=0.001)\n    print('Do both models output the same tensors?', '\ud83d\udd25' if success else '\ud83d\udca9')\n    if not success:\n        raise Exception('Something went wRoNg')\n    pathlib.Path(pytorch_dump_folder_path).mkdir(parents=True, exist_ok=True)\n    print(f'Saving model to {pytorch_dump_folder_path}')\n    model.save_pretrained(pytorch_dump_folder_path)",
            "def convert_data2vec_checkpoint_to_pytorch(data2vec_checkpoint_path: str, pytorch_dump_folder_path: str, classification_head: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Copy/paste/tweak data2vec's weights to our BERT structure.\\n    \"\n    (data2vec_checkpoint_dir, data2vec_checkpoint_file_name) = os.path.split(data2vec_checkpoint_path)\n    data2vec = Data2VecTextModel.from_pretrained(data2vec_checkpoint_dir, checkpoint_file=data2vec_checkpoint_file_name)\n    data2vec.eval()\n    data2vec_model = data2vec.models[0]\n    data2vec_sent_encoder = data2vec_model.encoder.sentence_encoder\n    config = Data2VecTextConfig(vocab_size=data2vec_sent_encoder.embed_tokens.num_embeddings, hidden_size=data2vec_model.args.encoder_embed_dim, num_hidden_layers=data2vec_model.args.encoder_layers, num_attention_heads=data2vec_model.args.encoder_attention_heads, intermediate_size=data2vec_model.args.encoder_ffn_embed_dim, max_position_embeddings=514, type_vocab_size=1, layer_norm_eps=1e-05)\n    if classification_head:\n        config.num_labels = data2vec.model.classification_heads['mnli'].out_proj.weight.shape[0]\n    print('Our BERT config:', config)\n    model = Data2VecTextForSequenceClassification(config) if classification_head else Data2VecTextForMaskedLM(config)\n    model.eval()\n    model.data2vec_text.embeddings.word_embeddings.weight = data2vec_sent_encoder.embed_tokens.weight\n    model.data2vec_text.embeddings.position_embeddings.weight = data2vec_sent_encoder.embed_positions.weight\n    model.data2vec_text.embeddings.token_type_embeddings.weight.data = torch.zeros_like(model.data2vec_text.embeddings.token_type_embeddings.weight)\n    model.data2vec_text.embeddings.LayerNorm.weight = data2vec_sent_encoder.layernorm_embedding.weight\n    model.data2vec_text.embeddings.LayerNorm.bias = data2vec_sent_encoder.layernorm_embedding.bias\n    for i in range(config.num_hidden_layers):\n        layer: BertLayer = model.data2vec_text.encoder.layer[i]\n        data2vec_layer: TransformerSentenceEncoderLayer = data2vec_sent_encoder.layers[i]\n        self_attn: BertSelfAttention = layer.attention.self\n        assert data2vec_layer.self_attn.k_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.k_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        assert data2vec_layer.self_attn.q_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.q_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        assert data2vec_layer.self_attn.v_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.v_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        self_attn.query.weight.data = data2vec_layer.self_attn.q_proj.weight\n        self_attn.query.bias.data = data2vec_layer.self_attn.q_proj.bias\n        self_attn.key.weight.data = data2vec_layer.self_attn.k_proj.weight\n        self_attn.key.bias.data = data2vec_layer.self_attn.k_proj.bias\n        self_attn.value.weight.data = data2vec_layer.self_attn.v_proj.weight\n        self_attn.value.bias.data = data2vec_layer.self_attn.v_proj.bias\n        self_output: BertSelfOutput = layer.attention.output\n        assert self_output.dense.weight.shape == data2vec_layer.self_attn.out_proj.weight.shape, f'Shape for self_output.dense.weight should be {data2vec_layer.self_attn.out_proj.weight.shape}'\n        self_output.dense.weight = data2vec_layer.self_attn.out_proj.weight\n        self_output.dense.bias = data2vec_layer.self_attn.out_proj.bias\n        self_output.LayerNorm.weight = data2vec_layer.self_attn_layer_norm.weight\n        self_output.LayerNorm.bias = data2vec_layer.self_attn_layer_norm.bias\n        intermediate: BertIntermediate = layer.intermediate\n        assert intermediate.dense.weight.shape == data2vec_layer.fc1.weight.shape, f'Shape for intermediate.dense.weight should be {data2vec_layer.fc1.weight.shape}'\n        intermediate.dense.weight = data2vec_layer.fc1.weight\n        intermediate.dense.bias = data2vec_layer.fc1.bias\n        bert_output: BertOutput = layer.output\n        assert bert_output.dense.weight.shape == data2vec_layer.fc2.weight.shape, f'Shape for bert_output.dense.weight should be {data2vec_layer.fc2.weight.shape}'\n        bert_output.dense.weight = data2vec_layer.fc2.weight\n        bert_output.dense.bias = data2vec_layer.fc2.bias\n        bert_output.LayerNorm.weight = data2vec_layer.final_layer_norm.weight\n        bert_output.LayerNorm.bias = data2vec_layer.final_layer_norm.bias\n    if classification_head:\n        model.classifier.dense.weight = data2vec.model.classification_heads['mnli'].dense.weight\n        model.classifier.dense.bias = data2vec.model.classification_heads['mnli'].dense.bias\n        model.classifier.out_proj.weight = data2vec.model.classification_heads['mnli'].out_proj.weight\n        model.classifier.out_proj.bias = data2vec.model.classification_heads['mnli'].out_proj.bias\n    else:\n        model.lm_head.dense.weight = data2vec_model.encoder.lm_head.dense.weight\n        model.lm_head.dense.bias = data2vec_model.encoder.lm_head.dense.bias\n        model.lm_head.layer_norm.weight = data2vec_model.encoder.lm_head.layer_norm.weight\n        model.lm_head.layer_norm.bias = data2vec_model.encoder.lm_head.layer_norm.bias\n        model.lm_head.decoder.weight = data2vec_model.encoder.lm_head.weight\n        model.lm_head.decoder.bias = data2vec_model.encoder.lm_head.bias\n    input_ids: torch.Tensor = data2vec.encode(SAMPLE_TEXT).unsqueeze(0)\n    our_output = model(input_ids)[0]\n    if classification_head:\n        their_output = data2vec.model.classification_heads['mnli'](data2vec.extract_features(input_ids))\n    else:\n        their_output = data2vec_model(input_ids)[0]\n    print(our_output.shape, their_output.shape)\n    max_absolute_diff = torch.max(torch.abs(our_output - their_output)).item()\n    print(f'max_absolute_diff = {max_absolute_diff}')\n    success = torch.allclose(our_output, their_output, atol=0.001)\n    print('Do both models output the same tensors?', '\ud83d\udd25' if success else '\ud83d\udca9')\n    if not success:\n        raise Exception('Something went wRoNg')\n    pathlib.Path(pytorch_dump_folder_path).mkdir(parents=True, exist_ok=True)\n    print(f'Saving model to {pytorch_dump_folder_path}')\n    model.save_pretrained(pytorch_dump_folder_path)",
            "def convert_data2vec_checkpoint_to_pytorch(data2vec_checkpoint_path: str, pytorch_dump_folder_path: str, classification_head: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Copy/paste/tweak data2vec's weights to our BERT structure.\\n    \"\n    (data2vec_checkpoint_dir, data2vec_checkpoint_file_name) = os.path.split(data2vec_checkpoint_path)\n    data2vec = Data2VecTextModel.from_pretrained(data2vec_checkpoint_dir, checkpoint_file=data2vec_checkpoint_file_name)\n    data2vec.eval()\n    data2vec_model = data2vec.models[0]\n    data2vec_sent_encoder = data2vec_model.encoder.sentence_encoder\n    config = Data2VecTextConfig(vocab_size=data2vec_sent_encoder.embed_tokens.num_embeddings, hidden_size=data2vec_model.args.encoder_embed_dim, num_hidden_layers=data2vec_model.args.encoder_layers, num_attention_heads=data2vec_model.args.encoder_attention_heads, intermediate_size=data2vec_model.args.encoder_ffn_embed_dim, max_position_embeddings=514, type_vocab_size=1, layer_norm_eps=1e-05)\n    if classification_head:\n        config.num_labels = data2vec.model.classification_heads['mnli'].out_proj.weight.shape[0]\n    print('Our BERT config:', config)\n    model = Data2VecTextForSequenceClassification(config) if classification_head else Data2VecTextForMaskedLM(config)\n    model.eval()\n    model.data2vec_text.embeddings.word_embeddings.weight = data2vec_sent_encoder.embed_tokens.weight\n    model.data2vec_text.embeddings.position_embeddings.weight = data2vec_sent_encoder.embed_positions.weight\n    model.data2vec_text.embeddings.token_type_embeddings.weight.data = torch.zeros_like(model.data2vec_text.embeddings.token_type_embeddings.weight)\n    model.data2vec_text.embeddings.LayerNorm.weight = data2vec_sent_encoder.layernorm_embedding.weight\n    model.data2vec_text.embeddings.LayerNorm.bias = data2vec_sent_encoder.layernorm_embedding.bias\n    for i in range(config.num_hidden_layers):\n        layer: BertLayer = model.data2vec_text.encoder.layer[i]\n        data2vec_layer: TransformerSentenceEncoderLayer = data2vec_sent_encoder.layers[i]\n        self_attn: BertSelfAttention = layer.attention.self\n        assert data2vec_layer.self_attn.k_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.k_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        assert data2vec_layer.self_attn.q_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.q_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        assert data2vec_layer.self_attn.v_proj.weight.data.shape == torch.Size((config.hidden_size, config.hidden_size)), f'Shape for data2vec_layer.self_attn.v_proj.weight.data should be {torch.Size((config.hidden_size, config.hidden_size))}'\n        self_attn.query.weight.data = data2vec_layer.self_attn.q_proj.weight\n        self_attn.query.bias.data = data2vec_layer.self_attn.q_proj.bias\n        self_attn.key.weight.data = data2vec_layer.self_attn.k_proj.weight\n        self_attn.key.bias.data = data2vec_layer.self_attn.k_proj.bias\n        self_attn.value.weight.data = data2vec_layer.self_attn.v_proj.weight\n        self_attn.value.bias.data = data2vec_layer.self_attn.v_proj.bias\n        self_output: BertSelfOutput = layer.attention.output\n        assert self_output.dense.weight.shape == data2vec_layer.self_attn.out_proj.weight.shape, f'Shape for self_output.dense.weight should be {data2vec_layer.self_attn.out_proj.weight.shape}'\n        self_output.dense.weight = data2vec_layer.self_attn.out_proj.weight\n        self_output.dense.bias = data2vec_layer.self_attn.out_proj.bias\n        self_output.LayerNorm.weight = data2vec_layer.self_attn_layer_norm.weight\n        self_output.LayerNorm.bias = data2vec_layer.self_attn_layer_norm.bias\n        intermediate: BertIntermediate = layer.intermediate\n        assert intermediate.dense.weight.shape == data2vec_layer.fc1.weight.shape, f'Shape for intermediate.dense.weight should be {data2vec_layer.fc1.weight.shape}'\n        intermediate.dense.weight = data2vec_layer.fc1.weight\n        intermediate.dense.bias = data2vec_layer.fc1.bias\n        bert_output: BertOutput = layer.output\n        assert bert_output.dense.weight.shape == data2vec_layer.fc2.weight.shape, f'Shape for bert_output.dense.weight should be {data2vec_layer.fc2.weight.shape}'\n        bert_output.dense.weight = data2vec_layer.fc2.weight\n        bert_output.dense.bias = data2vec_layer.fc2.bias\n        bert_output.LayerNorm.weight = data2vec_layer.final_layer_norm.weight\n        bert_output.LayerNorm.bias = data2vec_layer.final_layer_norm.bias\n    if classification_head:\n        model.classifier.dense.weight = data2vec.model.classification_heads['mnli'].dense.weight\n        model.classifier.dense.bias = data2vec.model.classification_heads['mnli'].dense.bias\n        model.classifier.out_proj.weight = data2vec.model.classification_heads['mnli'].out_proj.weight\n        model.classifier.out_proj.bias = data2vec.model.classification_heads['mnli'].out_proj.bias\n    else:\n        model.lm_head.dense.weight = data2vec_model.encoder.lm_head.dense.weight\n        model.lm_head.dense.bias = data2vec_model.encoder.lm_head.dense.bias\n        model.lm_head.layer_norm.weight = data2vec_model.encoder.lm_head.layer_norm.weight\n        model.lm_head.layer_norm.bias = data2vec_model.encoder.lm_head.layer_norm.bias\n        model.lm_head.decoder.weight = data2vec_model.encoder.lm_head.weight\n        model.lm_head.decoder.bias = data2vec_model.encoder.lm_head.bias\n    input_ids: torch.Tensor = data2vec.encode(SAMPLE_TEXT).unsqueeze(0)\n    our_output = model(input_ids)[0]\n    if classification_head:\n        their_output = data2vec.model.classification_heads['mnli'](data2vec.extract_features(input_ids))\n    else:\n        their_output = data2vec_model(input_ids)[0]\n    print(our_output.shape, their_output.shape)\n    max_absolute_diff = torch.max(torch.abs(our_output - their_output)).item()\n    print(f'max_absolute_diff = {max_absolute_diff}')\n    success = torch.allclose(our_output, their_output, atol=0.001)\n    print('Do both models output the same tensors?', '\ud83d\udd25' if success else '\ud83d\udca9')\n    if not success:\n        raise Exception('Something went wRoNg')\n    pathlib.Path(pytorch_dump_folder_path).mkdir(parents=True, exist_ok=True)\n    print(f'Saving model to {pytorch_dump_folder_path}')\n    model.save_pretrained(pytorch_dump_folder_path)"
        ]
    }
]