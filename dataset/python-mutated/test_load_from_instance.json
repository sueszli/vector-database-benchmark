[
    {
        "func_name": "handle_output",
        "original": "def handle_output(self, context: OutputContext, obj) -> None:\n    assert context.dagster_type.is_nothing\n    return",
        "mutated": [
            "def handle_output(self, context: OutputContext, obj) -> None:\n    if False:\n        i = 10\n    assert context.dagster_type.is_nothing\n    return",
            "def handle_output(self, context: OutputContext, obj) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    assert context.dagster_type.is_nothing\n    return",
            "def handle_output(self, context: OutputContext, obj) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    assert context.dagster_type.is_nothing\n    return",
            "def handle_output(self, context: OutputContext, obj) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    assert context.dagster_type.is_nothing\n    return",
            "def handle_output(self, context: OutputContext, obj) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    assert context.dagster_type.is_nothing\n    return"
        ]
    },
    {
        "func_name": "load_input",
        "original": "def load_input(self, context: InputContext) -> Any:\n    load_calls.append(context.asset_key)\n    return None",
        "mutated": [
            "def load_input(self, context: InputContext) -> Any:\n    if False:\n        i = 10\n    load_calls.append(context.asset_key)\n    return None",
            "def load_input(self, context: InputContext) -> Any:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    load_calls.append(context.asset_key)\n    return None",
            "def load_input(self, context: InputContext) -> Any:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    load_calls.append(context.asset_key)\n    return None",
            "def load_input(self, context: InputContext) -> Any:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    load_calls.append(context.asset_key)\n    return None",
            "def load_input(self, context: InputContext) -> Any:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    load_calls.append(context.asset_key)\n    return None"
        ]
    },
    {
        "func_name": "test_io_manager",
        "original": "@io_manager\ndef test_io_manager(_context) -> IOManager:\n\n    class TestIOManager(IOManager):\n\n        def handle_output(self, context: OutputContext, obj) -> None:\n            assert context.dagster_type.is_nothing\n            return\n\n        def load_input(self, context: InputContext) -> Any:\n            load_calls.append(context.asset_key)\n            return None\n    return TestIOManager()",
        "mutated": [
            "@io_manager\ndef test_io_manager(_context) -> IOManager:\n    if False:\n        i = 10\n\n    class TestIOManager(IOManager):\n\n        def handle_output(self, context: OutputContext, obj) -> None:\n            assert context.dagster_type.is_nothing\n            return\n\n        def load_input(self, context: InputContext) -> Any:\n            load_calls.append(context.asset_key)\n            return None\n    return TestIOManager()",
            "@io_manager\ndef test_io_manager(_context) -> IOManager:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n\n    class TestIOManager(IOManager):\n\n        def handle_output(self, context: OutputContext, obj) -> None:\n            assert context.dagster_type.is_nothing\n            return\n\n        def load_input(self, context: InputContext) -> Any:\n            load_calls.append(context.asset_key)\n            return None\n    return TestIOManager()",
            "@io_manager\ndef test_io_manager(_context) -> IOManager:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n    class TestIOManager(IOManager):\n\n        def handle_output(self, context: OutputContext, obj) -> None:\n            assert context.dagster_type.is_nothing\n            return\n\n        def load_input(self, context: InputContext) -> Any:\n            load_calls.append(context.asset_key)\n            return None\n    return TestIOManager()",
            "@io_manager\ndef test_io_manager(_context) -> IOManager:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n\n    class TestIOManager(IOManager):\n\n        def handle_output(self, context: OutputContext, obj) -> None:\n            assert context.dagster_type.is_nothing\n            return\n\n        def load_input(self, context: InputContext) -> Any:\n            load_calls.append(context.asset_key)\n            return None\n    return TestIOManager()",
            "@io_manager\ndef test_io_manager(_context) -> IOManager:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n\n    class TestIOManager(IOManager):\n\n        def handle_output(self, context: OutputContext, obj) -> None:\n            assert context.dagster_type.is_nothing\n            return\n\n        def load_input(self, context: InputContext) -> Any:\n            load_calls.append(context.asset_key)\n            return None\n    return TestIOManager()"
        ]
    },
    {
        "func_name": "downstream_asset",
        "original": "@asset(ins={'xyz': AssetIn(key=xyz_asset_key)})\ndef downstream_asset(xyz):\n    return",
        "mutated": [
            "@asset(ins={'xyz': AssetIn(key=xyz_asset_key)})\ndef downstream_asset(xyz):\n    if False:\n        i = 10\n    return",
            "@asset(ins={'xyz': AssetIn(key=xyz_asset_key)})\ndef downstream_asset(xyz):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return",
            "@asset(ins={'xyz': AssetIn(key=xyz_asset_key)})\ndef downstream_asset(xyz):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return",
            "@asset(ins={'xyz': AssetIn(key=xyz_asset_key)})\ndef downstream_asset(xyz):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return",
            "@asset(ins={'xyz': AssetIn(key=xyz_asset_key)})\ndef downstream_asset(xyz):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return"
        ]
    },
    {
        "func_name": "test_load_from_instance",
        "original": "@responses.activate\n@pytest.mark.parametrize('connector_to_group_fn', [None, lambda x: f'{x[0]}_group'])\n@pytest.mark.parametrize('filter_connector', [True, False])\n@pytest.mark.parametrize('connector_to_asset_key_fn', [None, lambda conn, name: AssetKey([*conn.name.split('.'), *name.split('.')])])\n@pytest.mark.parametrize('multiple_connectors', [True, False])\ndef test_load_from_instance(connector_to_group_fn, filter_connector, connector_to_asset_key_fn, multiple_connectors):\n    with environ({'FIVETRAN_API_KEY': 'some_key', 'FIVETRAN_API_SECRET': 'some_secret'}):\n        load_calls = []\n\n        @io_manager\n        def test_io_manager(_context) -> IOManager:\n\n            class TestIOManager(IOManager):\n\n                def handle_output(self, context: OutputContext, obj) -> None:\n                    assert context.dagster_type.is_nothing\n                    return\n\n                def load_input(self, context: InputContext) -> Any:\n                    load_calls.append(context.asset_key)\n                    return None\n            return TestIOManager()\n        ft_resource = FivetranResource(api_key=EnvVar('FIVETRAN_API_KEY'), api_secret=EnvVar('FIVETRAN_API_SECRET'))\n        b64_encoded_auth_str = base64.b64encode(b'some_key:some_secret').decode('utf-8')\n        expected_auth_header = {'Authorization': f'Basic {b64_encoded_auth_str}'}\n        with responses.RequestsMock() as rsps:\n            rsps.add(method=rsps.GET, url=ft_resource.api_base_url + 'groups', json=get_sample_groups_response(), status=200, match=[matchers.header_matcher(expected_auth_header)])\n            rsps.add(method=rsps.GET, url=ft_resource.api_base_url + 'groups/some_group/connectors', json=get_sample_connectors_response_multiple() if multiple_connectors else get_sample_connectors_response(), status=200, match=[matchers.header_matcher(expected_auth_header)])\n            rsps.add(rsps.GET, f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID}/schemas', json=get_complex_sample_connector_schema_config())\n            if multiple_connectors:\n                rsps.add(rsps.GET, f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID_2}/schemas', json=get_complex_sample_connector_schema_config(), match=[matchers.header_matcher(expected_auth_header)])\n            if connector_to_group_fn:\n                ft_cacheable_assets = load_assets_from_fivetran_instance(ft_resource, connector_to_group_fn=connector_to_group_fn, connector_filter=(lambda _: False) if filter_connector else None, connector_to_asset_key_fn=connector_to_asset_key_fn, connector_to_io_manager_key_fn=lambda _: 'test_io_manager', poll_interval=10, poll_timeout=600)\n            else:\n                ft_cacheable_assets = load_assets_from_fivetran_instance(ft_resource, connector_filter=(lambda _: False) if filter_connector else None, connector_to_asset_key_fn=connector_to_asset_key_fn, io_manager_key='test_io_manager', poll_interval=10, poll_timeout=600)\n            ft_assets = ft_cacheable_assets.build_definitions(ft_cacheable_assets.compute_cacheable_data())\n            ft_assets = with_resources(ft_assets, {'test_io_manager': test_io_manager})\n        if filter_connector:\n            assert len(ft_assets) == 0\n            return\n        tables = {AssetKey(['xyz1', 'abc2']), AssetKey(['xyz1', 'abc1']), AssetKey(['abc', 'xyz'])}\n        if connector_to_asset_key_fn:\n            tables = {connector_to_asset_key_fn(FivetranConnectionMetadata('some_service.some_name', '', '=', []), '.'.join(t.path)) for t in tables}\n        xyz_asset_key = connector_to_asset_key_fn(FivetranConnectionMetadata('some_service.some_name', '', '=', []), 'abc.xyz') if connector_to_asset_key_fn else AssetKey(['abc', 'xyz'])\n\n        @asset(ins={'xyz': AssetIn(key=xyz_asset_key)})\n        def downstream_asset(xyz):\n            return\n        all_assets = [downstream_asset] + ft_assets\n        assert any((out.metadata.get('table_schema') == MetadataValue.table_schema(TableSchema(columns=[TableColumn(name='column_1', type='any'), TableColumn(name='column_2', type='any'), TableColumn(name='column_3', type='any')])) for out in ft_assets[0].node_def.output_defs))\n        assert ft_assets[0].keys == tables\n        assert all([ft_assets[0].group_names_by_key.get(t) == (connector_to_group_fn('some_service.some_name') if connector_to_group_fn else 'some_service_some_name') for t in tables])\n        assert len(ft_assets[0].op.output_defs) == len(tables)\n        final_data = {'succeeded_at': '2021-01-01T02:00:00.0Z'}\n        fivetran_sync_job = build_assets_job(name='fivetran_assets_job', assets=all_assets)\n        with responses.RequestsMock() as rsps:\n            api_prefixes = [f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID}']\n            if multiple_connectors:\n                api_prefixes.append(f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID_2}')\n            for api_prefix in api_prefixes:\n                rsps.add(rsps.PATCH, api_prefix, json=get_sample_update_response())\n                rsps.add(rsps.POST, f'{api_prefix}/force', json=get_sample_sync_response())\n                rsps.add(rsps.GET, f'{api_prefix}/schemas', json=get_complex_sample_connector_schema_config())\n                rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response())\n                for _ in range(2):\n                    rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response())\n                rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response(data=final_data))\n            result = fivetran_sync_job.execute_in_process()\n            asset_materializations = [event for event in result.events_for_node('fivetran_sync_some_connector') if event.event_type_value == 'ASSET_MATERIALIZATION']\n            assert len(asset_materializations) == 3\n            asset_keys = set((mat.event_specific_data.materialization.asset_key for mat in asset_materializations))\n            assert asset_keys == tables\n            assert load_calls == [xyz_asset_key]",
        "mutated": [
            "@responses.activate\n@pytest.mark.parametrize('connector_to_group_fn', [None, lambda x: f'{x[0]}_group'])\n@pytest.mark.parametrize('filter_connector', [True, False])\n@pytest.mark.parametrize('connector_to_asset_key_fn', [None, lambda conn, name: AssetKey([*conn.name.split('.'), *name.split('.')])])\n@pytest.mark.parametrize('multiple_connectors', [True, False])\ndef test_load_from_instance(connector_to_group_fn, filter_connector, connector_to_asset_key_fn, multiple_connectors):\n    if False:\n        i = 10\n    with environ({'FIVETRAN_API_KEY': 'some_key', 'FIVETRAN_API_SECRET': 'some_secret'}):\n        load_calls = []\n\n        @io_manager\n        def test_io_manager(_context) -> IOManager:\n\n            class TestIOManager(IOManager):\n\n                def handle_output(self, context: OutputContext, obj) -> None:\n                    assert context.dagster_type.is_nothing\n                    return\n\n                def load_input(self, context: InputContext) -> Any:\n                    load_calls.append(context.asset_key)\n                    return None\n            return TestIOManager()\n        ft_resource = FivetranResource(api_key=EnvVar('FIVETRAN_API_KEY'), api_secret=EnvVar('FIVETRAN_API_SECRET'))\n        b64_encoded_auth_str = base64.b64encode(b'some_key:some_secret').decode('utf-8')\n        expected_auth_header = {'Authorization': f'Basic {b64_encoded_auth_str}'}\n        with responses.RequestsMock() as rsps:\n            rsps.add(method=rsps.GET, url=ft_resource.api_base_url + 'groups', json=get_sample_groups_response(), status=200, match=[matchers.header_matcher(expected_auth_header)])\n            rsps.add(method=rsps.GET, url=ft_resource.api_base_url + 'groups/some_group/connectors', json=get_sample_connectors_response_multiple() if multiple_connectors else get_sample_connectors_response(), status=200, match=[matchers.header_matcher(expected_auth_header)])\n            rsps.add(rsps.GET, f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID}/schemas', json=get_complex_sample_connector_schema_config())\n            if multiple_connectors:\n                rsps.add(rsps.GET, f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID_2}/schemas', json=get_complex_sample_connector_schema_config(), match=[matchers.header_matcher(expected_auth_header)])\n            if connector_to_group_fn:\n                ft_cacheable_assets = load_assets_from_fivetran_instance(ft_resource, connector_to_group_fn=connector_to_group_fn, connector_filter=(lambda _: False) if filter_connector else None, connector_to_asset_key_fn=connector_to_asset_key_fn, connector_to_io_manager_key_fn=lambda _: 'test_io_manager', poll_interval=10, poll_timeout=600)\n            else:\n                ft_cacheable_assets = load_assets_from_fivetran_instance(ft_resource, connector_filter=(lambda _: False) if filter_connector else None, connector_to_asset_key_fn=connector_to_asset_key_fn, io_manager_key='test_io_manager', poll_interval=10, poll_timeout=600)\n            ft_assets = ft_cacheable_assets.build_definitions(ft_cacheable_assets.compute_cacheable_data())\n            ft_assets = with_resources(ft_assets, {'test_io_manager': test_io_manager})\n        if filter_connector:\n            assert len(ft_assets) == 0\n            return\n        tables = {AssetKey(['xyz1', 'abc2']), AssetKey(['xyz1', 'abc1']), AssetKey(['abc', 'xyz'])}\n        if connector_to_asset_key_fn:\n            tables = {connector_to_asset_key_fn(FivetranConnectionMetadata('some_service.some_name', '', '=', []), '.'.join(t.path)) for t in tables}\n        xyz_asset_key = connector_to_asset_key_fn(FivetranConnectionMetadata('some_service.some_name', '', '=', []), 'abc.xyz') if connector_to_asset_key_fn else AssetKey(['abc', 'xyz'])\n\n        @asset(ins={'xyz': AssetIn(key=xyz_asset_key)})\n        def downstream_asset(xyz):\n            return\n        all_assets = [downstream_asset] + ft_assets\n        assert any((out.metadata.get('table_schema') == MetadataValue.table_schema(TableSchema(columns=[TableColumn(name='column_1', type='any'), TableColumn(name='column_2', type='any'), TableColumn(name='column_3', type='any')])) for out in ft_assets[0].node_def.output_defs))\n        assert ft_assets[0].keys == tables\n        assert all([ft_assets[0].group_names_by_key.get(t) == (connector_to_group_fn('some_service.some_name') if connector_to_group_fn else 'some_service_some_name') for t in tables])\n        assert len(ft_assets[0].op.output_defs) == len(tables)\n        final_data = {'succeeded_at': '2021-01-01T02:00:00.0Z'}\n        fivetran_sync_job = build_assets_job(name='fivetran_assets_job', assets=all_assets)\n        with responses.RequestsMock() as rsps:\n            api_prefixes = [f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID}']\n            if multiple_connectors:\n                api_prefixes.append(f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID_2}')\n            for api_prefix in api_prefixes:\n                rsps.add(rsps.PATCH, api_prefix, json=get_sample_update_response())\n                rsps.add(rsps.POST, f'{api_prefix}/force', json=get_sample_sync_response())\n                rsps.add(rsps.GET, f'{api_prefix}/schemas', json=get_complex_sample_connector_schema_config())\n                rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response())\n                for _ in range(2):\n                    rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response())\n                rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response(data=final_data))\n            result = fivetran_sync_job.execute_in_process()\n            asset_materializations = [event for event in result.events_for_node('fivetran_sync_some_connector') if event.event_type_value == 'ASSET_MATERIALIZATION']\n            assert len(asset_materializations) == 3\n            asset_keys = set((mat.event_specific_data.materialization.asset_key for mat in asset_materializations))\n            assert asset_keys == tables\n            assert load_calls == [xyz_asset_key]",
            "@responses.activate\n@pytest.mark.parametrize('connector_to_group_fn', [None, lambda x: f'{x[0]}_group'])\n@pytest.mark.parametrize('filter_connector', [True, False])\n@pytest.mark.parametrize('connector_to_asset_key_fn', [None, lambda conn, name: AssetKey([*conn.name.split('.'), *name.split('.')])])\n@pytest.mark.parametrize('multiple_connectors', [True, False])\ndef test_load_from_instance(connector_to_group_fn, filter_connector, connector_to_asset_key_fn, multiple_connectors):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with environ({'FIVETRAN_API_KEY': 'some_key', 'FIVETRAN_API_SECRET': 'some_secret'}):\n        load_calls = []\n\n        @io_manager\n        def test_io_manager(_context) -> IOManager:\n\n            class TestIOManager(IOManager):\n\n                def handle_output(self, context: OutputContext, obj) -> None:\n                    assert context.dagster_type.is_nothing\n                    return\n\n                def load_input(self, context: InputContext) -> Any:\n                    load_calls.append(context.asset_key)\n                    return None\n            return TestIOManager()\n        ft_resource = FivetranResource(api_key=EnvVar('FIVETRAN_API_KEY'), api_secret=EnvVar('FIVETRAN_API_SECRET'))\n        b64_encoded_auth_str = base64.b64encode(b'some_key:some_secret').decode('utf-8')\n        expected_auth_header = {'Authorization': f'Basic {b64_encoded_auth_str}'}\n        with responses.RequestsMock() as rsps:\n            rsps.add(method=rsps.GET, url=ft_resource.api_base_url + 'groups', json=get_sample_groups_response(), status=200, match=[matchers.header_matcher(expected_auth_header)])\n            rsps.add(method=rsps.GET, url=ft_resource.api_base_url + 'groups/some_group/connectors', json=get_sample_connectors_response_multiple() if multiple_connectors else get_sample_connectors_response(), status=200, match=[matchers.header_matcher(expected_auth_header)])\n            rsps.add(rsps.GET, f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID}/schemas', json=get_complex_sample_connector_schema_config())\n            if multiple_connectors:\n                rsps.add(rsps.GET, f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID_2}/schemas', json=get_complex_sample_connector_schema_config(), match=[matchers.header_matcher(expected_auth_header)])\n            if connector_to_group_fn:\n                ft_cacheable_assets = load_assets_from_fivetran_instance(ft_resource, connector_to_group_fn=connector_to_group_fn, connector_filter=(lambda _: False) if filter_connector else None, connector_to_asset_key_fn=connector_to_asset_key_fn, connector_to_io_manager_key_fn=lambda _: 'test_io_manager', poll_interval=10, poll_timeout=600)\n            else:\n                ft_cacheable_assets = load_assets_from_fivetran_instance(ft_resource, connector_filter=(lambda _: False) if filter_connector else None, connector_to_asset_key_fn=connector_to_asset_key_fn, io_manager_key='test_io_manager', poll_interval=10, poll_timeout=600)\n            ft_assets = ft_cacheable_assets.build_definitions(ft_cacheable_assets.compute_cacheable_data())\n            ft_assets = with_resources(ft_assets, {'test_io_manager': test_io_manager})\n        if filter_connector:\n            assert len(ft_assets) == 0\n            return\n        tables = {AssetKey(['xyz1', 'abc2']), AssetKey(['xyz1', 'abc1']), AssetKey(['abc', 'xyz'])}\n        if connector_to_asset_key_fn:\n            tables = {connector_to_asset_key_fn(FivetranConnectionMetadata('some_service.some_name', '', '=', []), '.'.join(t.path)) for t in tables}\n        xyz_asset_key = connector_to_asset_key_fn(FivetranConnectionMetadata('some_service.some_name', '', '=', []), 'abc.xyz') if connector_to_asset_key_fn else AssetKey(['abc', 'xyz'])\n\n        @asset(ins={'xyz': AssetIn(key=xyz_asset_key)})\n        def downstream_asset(xyz):\n            return\n        all_assets = [downstream_asset] + ft_assets\n        assert any((out.metadata.get('table_schema') == MetadataValue.table_schema(TableSchema(columns=[TableColumn(name='column_1', type='any'), TableColumn(name='column_2', type='any'), TableColumn(name='column_3', type='any')])) for out in ft_assets[0].node_def.output_defs))\n        assert ft_assets[0].keys == tables\n        assert all([ft_assets[0].group_names_by_key.get(t) == (connector_to_group_fn('some_service.some_name') if connector_to_group_fn else 'some_service_some_name') for t in tables])\n        assert len(ft_assets[0].op.output_defs) == len(tables)\n        final_data = {'succeeded_at': '2021-01-01T02:00:00.0Z'}\n        fivetran_sync_job = build_assets_job(name='fivetran_assets_job', assets=all_assets)\n        with responses.RequestsMock() as rsps:\n            api_prefixes = [f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID}']\n            if multiple_connectors:\n                api_prefixes.append(f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID_2}')\n            for api_prefix in api_prefixes:\n                rsps.add(rsps.PATCH, api_prefix, json=get_sample_update_response())\n                rsps.add(rsps.POST, f'{api_prefix}/force', json=get_sample_sync_response())\n                rsps.add(rsps.GET, f'{api_prefix}/schemas', json=get_complex_sample_connector_schema_config())\n                rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response())\n                for _ in range(2):\n                    rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response())\n                rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response(data=final_data))\n            result = fivetran_sync_job.execute_in_process()\n            asset_materializations = [event for event in result.events_for_node('fivetran_sync_some_connector') if event.event_type_value == 'ASSET_MATERIALIZATION']\n            assert len(asset_materializations) == 3\n            asset_keys = set((mat.event_specific_data.materialization.asset_key for mat in asset_materializations))\n            assert asset_keys == tables\n            assert load_calls == [xyz_asset_key]",
            "@responses.activate\n@pytest.mark.parametrize('connector_to_group_fn', [None, lambda x: f'{x[0]}_group'])\n@pytest.mark.parametrize('filter_connector', [True, False])\n@pytest.mark.parametrize('connector_to_asset_key_fn', [None, lambda conn, name: AssetKey([*conn.name.split('.'), *name.split('.')])])\n@pytest.mark.parametrize('multiple_connectors', [True, False])\ndef test_load_from_instance(connector_to_group_fn, filter_connector, connector_to_asset_key_fn, multiple_connectors):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with environ({'FIVETRAN_API_KEY': 'some_key', 'FIVETRAN_API_SECRET': 'some_secret'}):\n        load_calls = []\n\n        @io_manager\n        def test_io_manager(_context) -> IOManager:\n\n            class TestIOManager(IOManager):\n\n                def handle_output(self, context: OutputContext, obj) -> None:\n                    assert context.dagster_type.is_nothing\n                    return\n\n                def load_input(self, context: InputContext) -> Any:\n                    load_calls.append(context.asset_key)\n                    return None\n            return TestIOManager()\n        ft_resource = FivetranResource(api_key=EnvVar('FIVETRAN_API_KEY'), api_secret=EnvVar('FIVETRAN_API_SECRET'))\n        b64_encoded_auth_str = base64.b64encode(b'some_key:some_secret').decode('utf-8')\n        expected_auth_header = {'Authorization': f'Basic {b64_encoded_auth_str}'}\n        with responses.RequestsMock() as rsps:\n            rsps.add(method=rsps.GET, url=ft_resource.api_base_url + 'groups', json=get_sample_groups_response(), status=200, match=[matchers.header_matcher(expected_auth_header)])\n            rsps.add(method=rsps.GET, url=ft_resource.api_base_url + 'groups/some_group/connectors', json=get_sample_connectors_response_multiple() if multiple_connectors else get_sample_connectors_response(), status=200, match=[matchers.header_matcher(expected_auth_header)])\n            rsps.add(rsps.GET, f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID}/schemas', json=get_complex_sample_connector_schema_config())\n            if multiple_connectors:\n                rsps.add(rsps.GET, f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID_2}/schemas', json=get_complex_sample_connector_schema_config(), match=[matchers.header_matcher(expected_auth_header)])\n            if connector_to_group_fn:\n                ft_cacheable_assets = load_assets_from_fivetran_instance(ft_resource, connector_to_group_fn=connector_to_group_fn, connector_filter=(lambda _: False) if filter_connector else None, connector_to_asset_key_fn=connector_to_asset_key_fn, connector_to_io_manager_key_fn=lambda _: 'test_io_manager', poll_interval=10, poll_timeout=600)\n            else:\n                ft_cacheable_assets = load_assets_from_fivetran_instance(ft_resource, connector_filter=(lambda _: False) if filter_connector else None, connector_to_asset_key_fn=connector_to_asset_key_fn, io_manager_key='test_io_manager', poll_interval=10, poll_timeout=600)\n            ft_assets = ft_cacheable_assets.build_definitions(ft_cacheable_assets.compute_cacheable_data())\n            ft_assets = with_resources(ft_assets, {'test_io_manager': test_io_manager})\n        if filter_connector:\n            assert len(ft_assets) == 0\n            return\n        tables = {AssetKey(['xyz1', 'abc2']), AssetKey(['xyz1', 'abc1']), AssetKey(['abc', 'xyz'])}\n        if connector_to_asset_key_fn:\n            tables = {connector_to_asset_key_fn(FivetranConnectionMetadata('some_service.some_name', '', '=', []), '.'.join(t.path)) for t in tables}\n        xyz_asset_key = connector_to_asset_key_fn(FivetranConnectionMetadata('some_service.some_name', '', '=', []), 'abc.xyz') if connector_to_asset_key_fn else AssetKey(['abc', 'xyz'])\n\n        @asset(ins={'xyz': AssetIn(key=xyz_asset_key)})\n        def downstream_asset(xyz):\n            return\n        all_assets = [downstream_asset] + ft_assets\n        assert any((out.metadata.get('table_schema') == MetadataValue.table_schema(TableSchema(columns=[TableColumn(name='column_1', type='any'), TableColumn(name='column_2', type='any'), TableColumn(name='column_3', type='any')])) for out in ft_assets[0].node_def.output_defs))\n        assert ft_assets[0].keys == tables\n        assert all([ft_assets[0].group_names_by_key.get(t) == (connector_to_group_fn('some_service.some_name') if connector_to_group_fn else 'some_service_some_name') for t in tables])\n        assert len(ft_assets[0].op.output_defs) == len(tables)\n        final_data = {'succeeded_at': '2021-01-01T02:00:00.0Z'}\n        fivetran_sync_job = build_assets_job(name='fivetran_assets_job', assets=all_assets)\n        with responses.RequestsMock() as rsps:\n            api_prefixes = [f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID}']\n            if multiple_connectors:\n                api_prefixes.append(f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID_2}')\n            for api_prefix in api_prefixes:\n                rsps.add(rsps.PATCH, api_prefix, json=get_sample_update_response())\n                rsps.add(rsps.POST, f'{api_prefix}/force', json=get_sample_sync_response())\n                rsps.add(rsps.GET, f'{api_prefix}/schemas', json=get_complex_sample_connector_schema_config())\n                rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response())\n                for _ in range(2):\n                    rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response())\n                rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response(data=final_data))\n            result = fivetran_sync_job.execute_in_process()\n            asset_materializations = [event for event in result.events_for_node('fivetran_sync_some_connector') if event.event_type_value == 'ASSET_MATERIALIZATION']\n            assert len(asset_materializations) == 3\n            asset_keys = set((mat.event_specific_data.materialization.asset_key for mat in asset_materializations))\n            assert asset_keys == tables\n            assert load_calls == [xyz_asset_key]",
            "@responses.activate\n@pytest.mark.parametrize('connector_to_group_fn', [None, lambda x: f'{x[0]}_group'])\n@pytest.mark.parametrize('filter_connector', [True, False])\n@pytest.mark.parametrize('connector_to_asset_key_fn', [None, lambda conn, name: AssetKey([*conn.name.split('.'), *name.split('.')])])\n@pytest.mark.parametrize('multiple_connectors', [True, False])\ndef test_load_from_instance(connector_to_group_fn, filter_connector, connector_to_asset_key_fn, multiple_connectors):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with environ({'FIVETRAN_API_KEY': 'some_key', 'FIVETRAN_API_SECRET': 'some_secret'}):\n        load_calls = []\n\n        @io_manager\n        def test_io_manager(_context) -> IOManager:\n\n            class TestIOManager(IOManager):\n\n                def handle_output(self, context: OutputContext, obj) -> None:\n                    assert context.dagster_type.is_nothing\n                    return\n\n                def load_input(self, context: InputContext) -> Any:\n                    load_calls.append(context.asset_key)\n                    return None\n            return TestIOManager()\n        ft_resource = FivetranResource(api_key=EnvVar('FIVETRAN_API_KEY'), api_secret=EnvVar('FIVETRAN_API_SECRET'))\n        b64_encoded_auth_str = base64.b64encode(b'some_key:some_secret').decode('utf-8')\n        expected_auth_header = {'Authorization': f'Basic {b64_encoded_auth_str}'}\n        with responses.RequestsMock() as rsps:\n            rsps.add(method=rsps.GET, url=ft_resource.api_base_url + 'groups', json=get_sample_groups_response(), status=200, match=[matchers.header_matcher(expected_auth_header)])\n            rsps.add(method=rsps.GET, url=ft_resource.api_base_url + 'groups/some_group/connectors', json=get_sample_connectors_response_multiple() if multiple_connectors else get_sample_connectors_response(), status=200, match=[matchers.header_matcher(expected_auth_header)])\n            rsps.add(rsps.GET, f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID}/schemas', json=get_complex_sample_connector_schema_config())\n            if multiple_connectors:\n                rsps.add(rsps.GET, f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID_2}/schemas', json=get_complex_sample_connector_schema_config(), match=[matchers.header_matcher(expected_auth_header)])\n            if connector_to_group_fn:\n                ft_cacheable_assets = load_assets_from_fivetran_instance(ft_resource, connector_to_group_fn=connector_to_group_fn, connector_filter=(lambda _: False) if filter_connector else None, connector_to_asset_key_fn=connector_to_asset_key_fn, connector_to_io_manager_key_fn=lambda _: 'test_io_manager', poll_interval=10, poll_timeout=600)\n            else:\n                ft_cacheable_assets = load_assets_from_fivetran_instance(ft_resource, connector_filter=(lambda _: False) if filter_connector else None, connector_to_asset_key_fn=connector_to_asset_key_fn, io_manager_key='test_io_manager', poll_interval=10, poll_timeout=600)\n            ft_assets = ft_cacheable_assets.build_definitions(ft_cacheable_assets.compute_cacheable_data())\n            ft_assets = with_resources(ft_assets, {'test_io_manager': test_io_manager})\n        if filter_connector:\n            assert len(ft_assets) == 0\n            return\n        tables = {AssetKey(['xyz1', 'abc2']), AssetKey(['xyz1', 'abc1']), AssetKey(['abc', 'xyz'])}\n        if connector_to_asset_key_fn:\n            tables = {connector_to_asset_key_fn(FivetranConnectionMetadata('some_service.some_name', '', '=', []), '.'.join(t.path)) for t in tables}\n        xyz_asset_key = connector_to_asset_key_fn(FivetranConnectionMetadata('some_service.some_name', '', '=', []), 'abc.xyz') if connector_to_asset_key_fn else AssetKey(['abc', 'xyz'])\n\n        @asset(ins={'xyz': AssetIn(key=xyz_asset_key)})\n        def downstream_asset(xyz):\n            return\n        all_assets = [downstream_asset] + ft_assets\n        assert any((out.metadata.get('table_schema') == MetadataValue.table_schema(TableSchema(columns=[TableColumn(name='column_1', type='any'), TableColumn(name='column_2', type='any'), TableColumn(name='column_3', type='any')])) for out in ft_assets[0].node_def.output_defs))\n        assert ft_assets[0].keys == tables\n        assert all([ft_assets[0].group_names_by_key.get(t) == (connector_to_group_fn('some_service.some_name') if connector_to_group_fn else 'some_service_some_name') for t in tables])\n        assert len(ft_assets[0].op.output_defs) == len(tables)\n        final_data = {'succeeded_at': '2021-01-01T02:00:00.0Z'}\n        fivetran_sync_job = build_assets_job(name='fivetran_assets_job', assets=all_assets)\n        with responses.RequestsMock() as rsps:\n            api_prefixes = [f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID}']\n            if multiple_connectors:\n                api_prefixes.append(f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID_2}')\n            for api_prefix in api_prefixes:\n                rsps.add(rsps.PATCH, api_prefix, json=get_sample_update_response())\n                rsps.add(rsps.POST, f'{api_prefix}/force', json=get_sample_sync_response())\n                rsps.add(rsps.GET, f'{api_prefix}/schemas', json=get_complex_sample_connector_schema_config())\n                rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response())\n                for _ in range(2):\n                    rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response())\n                rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response(data=final_data))\n            result = fivetran_sync_job.execute_in_process()\n            asset_materializations = [event for event in result.events_for_node('fivetran_sync_some_connector') if event.event_type_value == 'ASSET_MATERIALIZATION']\n            assert len(asset_materializations) == 3\n            asset_keys = set((mat.event_specific_data.materialization.asset_key for mat in asset_materializations))\n            assert asset_keys == tables\n            assert load_calls == [xyz_asset_key]",
            "@responses.activate\n@pytest.mark.parametrize('connector_to_group_fn', [None, lambda x: f'{x[0]}_group'])\n@pytest.mark.parametrize('filter_connector', [True, False])\n@pytest.mark.parametrize('connector_to_asset_key_fn', [None, lambda conn, name: AssetKey([*conn.name.split('.'), *name.split('.')])])\n@pytest.mark.parametrize('multiple_connectors', [True, False])\ndef test_load_from_instance(connector_to_group_fn, filter_connector, connector_to_asset_key_fn, multiple_connectors):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with environ({'FIVETRAN_API_KEY': 'some_key', 'FIVETRAN_API_SECRET': 'some_secret'}):\n        load_calls = []\n\n        @io_manager\n        def test_io_manager(_context) -> IOManager:\n\n            class TestIOManager(IOManager):\n\n                def handle_output(self, context: OutputContext, obj) -> None:\n                    assert context.dagster_type.is_nothing\n                    return\n\n                def load_input(self, context: InputContext) -> Any:\n                    load_calls.append(context.asset_key)\n                    return None\n            return TestIOManager()\n        ft_resource = FivetranResource(api_key=EnvVar('FIVETRAN_API_KEY'), api_secret=EnvVar('FIVETRAN_API_SECRET'))\n        b64_encoded_auth_str = base64.b64encode(b'some_key:some_secret').decode('utf-8')\n        expected_auth_header = {'Authorization': f'Basic {b64_encoded_auth_str}'}\n        with responses.RequestsMock() as rsps:\n            rsps.add(method=rsps.GET, url=ft_resource.api_base_url + 'groups', json=get_sample_groups_response(), status=200, match=[matchers.header_matcher(expected_auth_header)])\n            rsps.add(method=rsps.GET, url=ft_resource.api_base_url + 'groups/some_group/connectors', json=get_sample_connectors_response_multiple() if multiple_connectors else get_sample_connectors_response(), status=200, match=[matchers.header_matcher(expected_auth_header)])\n            rsps.add(rsps.GET, f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID}/schemas', json=get_complex_sample_connector_schema_config())\n            if multiple_connectors:\n                rsps.add(rsps.GET, f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID_2}/schemas', json=get_complex_sample_connector_schema_config(), match=[matchers.header_matcher(expected_auth_header)])\n            if connector_to_group_fn:\n                ft_cacheable_assets = load_assets_from_fivetran_instance(ft_resource, connector_to_group_fn=connector_to_group_fn, connector_filter=(lambda _: False) if filter_connector else None, connector_to_asset_key_fn=connector_to_asset_key_fn, connector_to_io_manager_key_fn=lambda _: 'test_io_manager', poll_interval=10, poll_timeout=600)\n            else:\n                ft_cacheable_assets = load_assets_from_fivetran_instance(ft_resource, connector_filter=(lambda _: False) if filter_connector else None, connector_to_asset_key_fn=connector_to_asset_key_fn, io_manager_key='test_io_manager', poll_interval=10, poll_timeout=600)\n            ft_assets = ft_cacheable_assets.build_definitions(ft_cacheable_assets.compute_cacheable_data())\n            ft_assets = with_resources(ft_assets, {'test_io_manager': test_io_manager})\n        if filter_connector:\n            assert len(ft_assets) == 0\n            return\n        tables = {AssetKey(['xyz1', 'abc2']), AssetKey(['xyz1', 'abc1']), AssetKey(['abc', 'xyz'])}\n        if connector_to_asset_key_fn:\n            tables = {connector_to_asset_key_fn(FivetranConnectionMetadata('some_service.some_name', '', '=', []), '.'.join(t.path)) for t in tables}\n        xyz_asset_key = connector_to_asset_key_fn(FivetranConnectionMetadata('some_service.some_name', '', '=', []), 'abc.xyz') if connector_to_asset_key_fn else AssetKey(['abc', 'xyz'])\n\n        @asset(ins={'xyz': AssetIn(key=xyz_asset_key)})\n        def downstream_asset(xyz):\n            return\n        all_assets = [downstream_asset] + ft_assets\n        assert any((out.metadata.get('table_schema') == MetadataValue.table_schema(TableSchema(columns=[TableColumn(name='column_1', type='any'), TableColumn(name='column_2', type='any'), TableColumn(name='column_3', type='any')])) for out in ft_assets[0].node_def.output_defs))\n        assert ft_assets[0].keys == tables\n        assert all([ft_assets[0].group_names_by_key.get(t) == (connector_to_group_fn('some_service.some_name') if connector_to_group_fn else 'some_service_some_name') for t in tables])\n        assert len(ft_assets[0].op.output_defs) == len(tables)\n        final_data = {'succeeded_at': '2021-01-01T02:00:00.0Z'}\n        fivetran_sync_job = build_assets_job(name='fivetran_assets_job', assets=all_assets)\n        with responses.RequestsMock() as rsps:\n            api_prefixes = [f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID}']\n            if multiple_connectors:\n                api_prefixes.append(f'{ft_resource.api_connector_url}{DEFAULT_CONNECTOR_ID_2}')\n            for api_prefix in api_prefixes:\n                rsps.add(rsps.PATCH, api_prefix, json=get_sample_update_response())\n                rsps.add(rsps.POST, f'{api_prefix}/force', json=get_sample_sync_response())\n                rsps.add(rsps.GET, f'{api_prefix}/schemas', json=get_complex_sample_connector_schema_config())\n                rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response())\n                for _ in range(2):\n                    rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response())\n                rsps.add(rsps.GET, api_prefix, json=get_sample_connector_response(data=final_data))\n            result = fivetran_sync_job.execute_in_process()\n            asset_materializations = [event for event in result.events_for_node('fivetran_sync_some_connector') if event.event_type_value == 'ASSET_MATERIALIZATION']\n            assert len(asset_materializations) == 3\n            asset_keys = set((mat.event_specific_data.materialization.asset_key for mat in asset_materializations))\n            assert asset_keys == tables\n            assert load_calls == [xyz_asset_key]"
        ]
    }
]