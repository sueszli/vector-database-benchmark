[
    {
        "func_name": "convert_flax_checkpoint_to_pytorch",
        "original": "def convert_flax_checkpoint_to_pytorch(flax_checkpoint_path, fnet_config_file, save_path):\n    config = FNetConfig.from_json_file(fnet_config_file)\n    print(f'Building PyTorch model from configuration: {config}')\n    fnet_pretraining_model = FNetForPreTraining(config)\n    checkpoint_dict = restore_checkpoint(flax_checkpoint_path, None)\n    pretrained_model_params = checkpoint_dict['target']\n    state_dict = fnet_pretraining_model.state_dict()\n    position_ids = state_dict['fnet.embeddings.position_ids']\n    new_state_dict = {'fnet.embeddings.position_ids': position_ids}\n    new_state_dict['fnet.embeddings.word_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['word']['embedding'])\n    new_state_dict['fnet.embeddings.position_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['position']['embedding'][0])\n    new_state_dict['fnet.embeddings.token_type_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['type']['embedding'])\n    new_state_dict['fnet.embeddings.projection.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['hidden_mapping_in']['kernel']).T\n    new_state_dict['fnet.embeddings.projection.bias'] = torch.tensor(pretrained_model_params['encoder']['embedder']['hidden_mapping_in']['bias'])\n    new_state_dict['fnet.embeddings.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['layer_norm']['scale'])\n    new_state_dict['fnet.embeddings.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder']['embedder']['layer_norm']['bias'])\n    for layer in range(config.num_hidden_layers):\n        new_state_dict[f'fnet.encoder.layer.{layer}.fourier.output.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['mixing_layer_norm']['scale'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.fourier.output.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['mixing_layer_norm']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.intermediate.dense.weight'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['intermediate']['kernel']).T\n        new_state_dict[f'fnet.encoder.layer.{layer}.intermediate.dense.bias'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['intermediate']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.dense.weight'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['output']['kernel']).T\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.dense.bias'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['output']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['output_layer_norm']['scale'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['output_layer_norm']['bias'])\n    new_state_dict['fnet.pooler.dense.weight'] = torch.tensor(pretrained_model_params['encoder']['pooler']['kernel']).T\n    new_state_dict['fnet.pooler.dense.bias'] = torch.tensor(pretrained_model_params['encoder']['pooler']['bias'])\n    new_state_dict['cls.predictions.transform.dense.weight'] = torch.tensor(pretrained_model_params['predictions_dense']['kernel']).T\n    new_state_dict['cls.predictions.transform.dense.bias'] = torch.tensor(pretrained_model_params['predictions_dense']['bias'])\n    new_state_dict['cls.predictions.transform.LayerNorm.weight'] = torch.tensor(pretrained_model_params['predictions_layer_norm']['scale'])\n    new_state_dict['cls.predictions.transform.LayerNorm.bias'] = torch.tensor(pretrained_model_params['predictions_layer_norm']['bias'])\n    new_state_dict['cls.predictions.decoder.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['word']['embedding'])\n    new_state_dict['cls.predictions.decoder.bias'] = torch.tensor(pretrained_model_params['predictions_output']['output_bias'])\n    new_state_dict['cls.predictions.bias'] = torch.tensor(pretrained_model_params['predictions_output']['output_bias'])\n    new_state_dict['cls.seq_relationship.weight'] = torch.tensor(pretrained_model_params['classification']['output_kernel'])\n    new_state_dict['cls.seq_relationship.bias'] = torch.tensor(pretrained_model_params['classification']['output_bias'])\n    fnet_pretraining_model.load_state_dict(new_state_dict)\n    print(f'Saving pretrained model to {save_path}')\n    fnet_pretraining_model.save_pretrained(save_path)",
        "mutated": [
            "def convert_flax_checkpoint_to_pytorch(flax_checkpoint_path, fnet_config_file, save_path):\n    if False:\n        i = 10\n    config = FNetConfig.from_json_file(fnet_config_file)\n    print(f'Building PyTorch model from configuration: {config}')\n    fnet_pretraining_model = FNetForPreTraining(config)\n    checkpoint_dict = restore_checkpoint(flax_checkpoint_path, None)\n    pretrained_model_params = checkpoint_dict['target']\n    state_dict = fnet_pretraining_model.state_dict()\n    position_ids = state_dict['fnet.embeddings.position_ids']\n    new_state_dict = {'fnet.embeddings.position_ids': position_ids}\n    new_state_dict['fnet.embeddings.word_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['word']['embedding'])\n    new_state_dict['fnet.embeddings.position_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['position']['embedding'][0])\n    new_state_dict['fnet.embeddings.token_type_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['type']['embedding'])\n    new_state_dict['fnet.embeddings.projection.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['hidden_mapping_in']['kernel']).T\n    new_state_dict['fnet.embeddings.projection.bias'] = torch.tensor(pretrained_model_params['encoder']['embedder']['hidden_mapping_in']['bias'])\n    new_state_dict['fnet.embeddings.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['layer_norm']['scale'])\n    new_state_dict['fnet.embeddings.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder']['embedder']['layer_norm']['bias'])\n    for layer in range(config.num_hidden_layers):\n        new_state_dict[f'fnet.encoder.layer.{layer}.fourier.output.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['mixing_layer_norm']['scale'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.fourier.output.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['mixing_layer_norm']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.intermediate.dense.weight'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['intermediate']['kernel']).T\n        new_state_dict[f'fnet.encoder.layer.{layer}.intermediate.dense.bias'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['intermediate']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.dense.weight'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['output']['kernel']).T\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.dense.bias'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['output']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['output_layer_norm']['scale'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['output_layer_norm']['bias'])\n    new_state_dict['fnet.pooler.dense.weight'] = torch.tensor(pretrained_model_params['encoder']['pooler']['kernel']).T\n    new_state_dict['fnet.pooler.dense.bias'] = torch.tensor(pretrained_model_params['encoder']['pooler']['bias'])\n    new_state_dict['cls.predictions.transform.dense.weight'] = torch.tensor(pretrained_model_params['predictions_dense']['kernel']).T\n    new_state_dict['cls.predictions.transform.dense.bias'] = torch.tensor(pretrained_model_params['predictions_dense']['bias'])\n    new_state_dict['cls.predictions.transform.LayerNorm.weight'] = torch.tensor(pretrained_model_params['predictions_layer_norm']['scale'])\n    new_state_dict['cls.predictions.transform.LayerNorm.bias'] = torch.tensor(pretrained_model_params['predictions_layer_norm']['bias'])\n    new_state_dict['cls.predictions.decoder.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['word']['embedding'])\n    new_state_dict['cls.predictions.decoder.bias'] = torch.tensor(pretrained_model_params['predictions_output']['output_bias'])\n    new_state_dict['cls.predictions.bias'] = torch.tensor(pretrained_model_params['predictions_output']['output_bias'])\n    new_state_dict['cls.seq_relationship.weight'] = torch.tensor(pretrained_model_params['classification']['output_kernel'])\n    new_state_dict['cls.seq_relationship.bias'] = torch.tensor(pretrained_model_params['classification']['output_bias'])\n    fnet_pretraining_model.load_state_dict(new_state_dict)\n    print(f'Saving pretrained model to {save_path}')\n    fnet_pretraining_model.save_pretrained(save_path)",
            "def convert_flax_checkpoint_to_pytorch(flax_checkpoint_path, fnet_config_file, save_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    config = FNetConfig.from_json_file(fnet_config_file)\n    print(f'Building PyTorch model from configuration: {config}')\n    fnet_pretraining_model = FNetForPreTraining(config)\n    checkpoint_dict = restore_checkpoint(flax_checkpoint_path, None)\n    pretrained_model_params = checkpoint_dict['target']\n    state_dict = fnet_pretraining_model.state_dict()\n    position_ids = state_dict['fnet.embeddings.position_ids']\n    new_state_dict = {'fnet.embeddings.position_ids': position_ids}\n    new_state_dict['fnet.embeddings.word_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['word']['embedding'])\n    new_state_dict['fnet.embeddings.position_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['position']['embedding'][0])\n    new_state_dict['fnet.embeddings.token_type_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['type']['embedding'])\n    new_state_dict['fnet.embeddings.projection.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['hidden_mapping_in']['kernel']).T\n    new_state_dict['fnet.embeddings.projection.bias'] = torch.tensor(pretrained_model_params['encoder']['embedder']['hidden_mapping_in']['bias'])\n    new_state_dict['fnet.embeddings.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['layer_norm']['scale'])\n    new_state_dict['fnet.embeddings.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder']['embedder']['layer_norm']['bias'])\n    for layer in range(config.num_hidden_layers):\n        new_state_dict[f'fnet.encoder.layer.{layer}.fourier.output.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['mixing_layer_norm']['scale'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.fourier.output.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['mixing_layer_norm']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.intermediate.dense.weight'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['intermediate']['kernel']).T\n        new_state_dict[f'fnet.encoder.layer.{layer}.intermediate.dense.bias'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['intermediate']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.dense.weight'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['output']['kernel']).T\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.dense.bias'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['output']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['output_layer_norm']['scale'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['output_layer_norm']['bias'])\n    new_state_dict['fnet.pooler.dense.weight'] = torch.tensor(pretrained_model_params['encoder']['pooler']['kernel']).T\n    new_state_dict['fnet.pooler.dense.bias'] = torch.tensor(pretrained_model_params['encoder']['pooler']['bias'])\n    new_state_dict['cls.predictions.transform.dense.weight'] = torch.tensor(pretrained_model_params['predictions_dense']['kernel']).T\n    new_state_dict['cls.predictions.transform.dense.bias'] = torch.tensor(pretrained_model_params['predictions_dense']['bias'])\n    new_state_dict['cls.predictions.transform.LayerNorm.weight'] = torch.tensor(pretrained_model_params['predictions_layer_norm']['scale'])\n    new_state_dict['cls.predictions.transform.LayerNorm.bias'] = torch.tensor(pretrained_model_params['predictions_layer_norm']['bias'])\n    new_state_dict['cls.predictions.decoder.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['word']['embedding'])\n    new_state_dict['cls.predictions.decoder.bias'] = torch.tensor(pretrained_model_params['predictions_output']['output_bias'])\n    new_state_dict['cls.predictions.bias'] = torch.tensor(pretrained_model_params['predictions_output']['output_bias'])\n    new_state_dict['cls.seq_relationship.weight'] = torch.tensor(pretrained_model_params['classification']['output_kernel'])\n    new_state_dict['cls.seq_relationship.bias'] = torch.tensor(pretrained_model_params['classification']['output_bias'])\n    fnet_pretraining_model.load_state_dict(new_state_dict)\n    print(f'Saving pretrained model to {save_path}')\n    fnet_pretraining_model.save_pretrained(save_path)",
            "def convert_flax_checkpoint_to_pytorch(flax_checkpoint_path, fnet_config_file, save_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    config = FNetConfig.from_json_file(fnet_config_file)\n    print(f'Building PyTorch model from configuration: {config}')\n    fnet_pretraining_model = FNetForPreTraining(config)\n    checkpoint_dict = restore_checkpoint(flax_checkpoint_path, None)\n    pretrained_model_params = checkpoint_dict['target']\n    state_dict = fnet_pretraining_model.state_dict()\n    position_ids = state_dict['fnet.embeddings.position_ids']\n    new_state_dict = {'fnet.embeddings.position_ids': position_ids}\n    new_state_dict['fnet.embeddings.word_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['word']['embedding'])\n    new_state_dict['fnet.embeddings.position_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['position']['embedding'][0])\n    new_state_dict['fnet.embeddings.token_type_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['type']['embedding'])\n    new_state_dict['fnet.embeddings.projection.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['hidden_mapping_in']['kernel']).T\n    new_state_dict['fnet.embeddings.projection.bias'] = torch.tensor(pretrained_model_params['encoder']['embedder']['hidden_mapping_in']['bias'])\n    new_state_dict['fnet.embeddings.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['layer_norm']['scale'])\n    new_state_dict['fnet.embeddings.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder']['embedder']['layer_norm']['bias'])\n    for layer in range(config.num_hidden_layers):\n        new_state_dict[f'fnet.encoder.layer.{layer}.fourier.output.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['mixing_layer_norm']['scale'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.fourier.output.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['mixing_layer_norm']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.intermediate.dense.weight'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['intermediate']['kernel']).T\n        new_state_dict[f'fnet.encoder.layer.{layer}.intermediate.dense.bias'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['intermediate']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.dense.weight'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['output']['kernel']).T\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.dense.bias'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['output']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['output_layer_norm']['scale'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['output_layer_norm']['bias'])\n    new_state_dict['fnet.pooler.dense.weight'] = torch.tensor(pretrained_model_params['encoder']['pooler']['kernel']).T\n    new_state_dict['fnet.pooler.dense.bias'] = torch.tensor(pretrained_model_params['encoder']['pooler']['bias'])\n    new_state_dict['cls.predictions.transform.dense.weight'] = torch.tensor(pretrained_model_params['predictions_dense']['kernel']).T\n    new_state_dict['cls.predictions.transform.dense.bias'] = torch.tensor(pretrained_model_params['predictions_dense']['bias'])\n    new_state_dict['cls.predictions.transform.LayerNorm.weight'] = torch.tensor(pretrained_model_params['predictions_layer_norm']['scale'])\n    new_state_dict['cls.predictions.transform.LayerNorm.bias'] = torch.tensor(pretrained_model_params['predictions_layer_norm']['bias'])\n    new_state_dict['cls.predictions.decoder.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['word']['embedding'])\n    new_state_dict['cls.predictions.decoder.bias'] = torch.tensor(pretrained_model_params['predictions_output']['output_bias'])\n    new_state_dict['cls.predictions.bias'] = torch.tensor(pretrained_model_params['predictions_output']['output_bias'])\n    new_state_dict['cls.seq_relationship.weight'] = torch.tensor(pretrained_model_params['classification']['output_kernel'])\n    new_state_dict['cls.seq_relationship.bias'] = torch.tensor(pretrained_model_params['classification']['output_bias'])\n    fnet_pretraining_model.load_state_dict(new_state_dict)\n    print(f'Saving pretrained model to {save_path}')\n    fnet_pretraining_model.save_pretrained(save_path)",
            "def convert_flax_checkpoint_to_pytorch(flax_checkpoint_path, fnet_config_file, save_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    config = FNetConfig.from_json_file(fnet_config_file)\n    print(f'Building PyTorch model from configuration: {config}')\n    fnet_pretraining_model = FNetForPreTraining(config)\n    checkpoint_dict = restore_checkpoint(flax_checkpoint_path, None)\n    pretrained_model_params = checkpoint_dict['target']\n    state_dict = fnet_pretraining_model.state_dict()\n    position_ids = state_dict['fnet.embeddings.position_ids']\n    new_state_dict = {'fnet.embeddings.position_ids': position_ids}\n    new_state_dict['fnet.embeddings.word_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['word']['embedding'])\n    new_state_dict['fnet.embeddings.position_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['position']['embedding'][0])\n    new_state_dict['fnet.embeddings.token_type_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['type']['embedding'])\n    new_state_dict['fnet.embeddings.projection.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['hidden_mapping_in']['kernel']).T\n    new_state_dict['fnet.embeddings.projection.bias'] = torch.tensor(pretrained_model_params['encoder']['embedder']['hidden_mapping_in']['bias'])\n    new_state_dict['fnet.embeddings.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['layer_norm']['scale'])\n    new_state_dict['fnet.embeddings.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder']['embedder']['layer_norm']['bias'])\n    for layer in range(config.num_hidden_layers):\n        new_state_dict[f'fnet.encoder.layer.{layer}.fourier.output.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['mixing_layer_norm']['scale'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.fourier.output.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['mixing_layer_norm']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.intermediate.dense.weight'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['intermediate']['kernel']).T\n        new_state_dict[f'fnet.encoder.layer.{layer}.intermediate.dense.bias'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['intermediate']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.dense.weight'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['output']['kernel']).T\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.dense.bias'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['output']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['output_layer_norm']['scale'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['output_layer_norm']['bias'])\n    new_state_dict['fnet.pooler.dense.weight'] = torch.tensor(pretrained_model_params['encoder']['pooler']['kernel']).T\n    new_state_dict['fnet.pooler.dense.bias'] = torch.tensor(pretrained_model_params['encoder']['pooler']['bias'])\n    new_state_dict['cls.predictions.transform.dense.weight'] = torch.tensor(pretrained_model_params['predictions_dense']['kernel']).T\n    new_state_dict['cls.predictions.transform.dense.bias'] = torch.tensor(pretrained_model_params['predictions_dense']['bias'])\n    new_state_dict['cls.predictions.transform.LayerNorm.weight'] = torch.tensor(pretrained_model_params['predictions_layer_norm']['scale'])\n    new_state_dict['cls.predictions.transform.LayerNorm.bias'] = torch.tensor(pretrained_model_params['predictions_layer_norm']['bias'])\n    new_state_dict['cls.predictions.decoder.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['word']['embedding'])\n    new_state_dict['cls.predictions.decoder.bias'] = torch.tensor(pretrained_model_params['predictions_output']['output_bias'])\n    new_state_dict['cls.predictions.bias'] = torch.tensor(pretrained_model_params['predictions_output']['output_bias'])\n    new_state_dict['cls.seq_relationship.weight'] = torch.tensor(pretrained_model_params['classification']['output_kernel'])\n    new_state_dict['cls.seq_relationship.bias'] = torch.tensor(pretrained_model_params['classification']['output_bias'])\n    fnet_pretraining_model.load_state_dict(new_state_dict)\n    print(f'Saving pretrained model to {save_path}')\n    fnet_pretraining_model.save_pretrained(save_path)",
            "def convert_flax_checkpoint_to_pytorch(flax_checkpoint_path, fnet_config_file, save_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    config = FNetConfig.from_json_file(fnet_config_file)\n    print(f'Building PyTorch model from configuration: {config}')\n    fnet_pretraining_model = FNetForPreTraining(config)\n    checkpoint_dict = restore_checkpoint(flax_checkpoint_path, None)\n    pretrained_model_params = checkpoint_dict['target']\n    state_dict = fnet_pretraining_model.state_dict()\n    position_ids = state_dict['fnet.embeddings.position_ids']\n    new_state_dict = {'fnet.embeddings.position_ids': position_ids}\n    new_state_dict['fnet.embeddings.word_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['word']['embedding'])\n    new_state_dict['fnet.embeddings.position_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['position']['embedding'][0])\n    new_state_dict['fnet.embeddings.token_type_embeddings.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['type']['embedding'])\n    new_state_dict['fnet.embeddings.projection.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['hidden_mapping_in']['kernel']).T\n    new_state_dict['fnet.embeddings.projection.bias'] = torch.tensor(pretrained_model_params['encoder']['embedder']['hidden_mapping_in']['bias'])\n    new_state_dict['fnet.embeddings.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['layer_norm']['scale'])\n    new_state_dict['fnet.embeddings.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder']['embedder']['layer_norm']['bias'])\n    for layer in range(config.num_hidden_layers):\n        new_state_dict[f'fnet.encoder.layer.{layer}.fourier.output.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['mixing_layer_norm']['scale'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.fourier.output.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['mixing_layer_norm']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.intermediate.dense.weight'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['intermediate']['kernel']).T\n        new_state_dict[f'fnet.encoder.layer.{layer}.intermediate.dense.bias'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['intermediate']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.dense.weight'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['output']['kernel']).T\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.dense.bias'] = torch.tensor(pretrained_model_params['encoder'][f'feed_forward_{layer}']['output']['bias'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.LayerNorm.weight'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['output_layer_norm']['scale'])\n        new_state_dict[f'fnet.encoder.layer.{layer}.output.LayerNorm.bias'] = torch.tensor(pretrained_model_params['encoder'][f'encoder_{layer}']['output_layer_norm']['bias'])\n    new_state_dict['fnet.pooler.dense.weight'] = torch.tensor(pretrained_model_params['encoder']['pooler']['kernel']).T\n    new_state_dict['fnet.pooler.dense.bias'] = torch.tensor(pretrained_model_params['encoder']['pooler']['bias'])\n    new_state_dict['cls.predictions.transform.dense.weight'] = torch.tensor(pretrained_model_params['predictions_dense']['kernel']).T\n    new_state_dict['cls.predictions.transform.dense.bias'] = torch.tensor(pretrained_model_params['predictions_dense']['bias'])\n    new_state_dict['cls.predictions.transform.LayerNorm.weight'] = torch.tensor(pretrained_model_params['predictions_layer_norm']['scale'])\n    new_state_dict['cls.predictions.transform.LayerNorm.bias'] = torch.tensor(pretrained_model_params['predictions_layer_norm']['bias'])\n    new_state_dict['cls.predictions.decoder.weight'] = torch.tensor(pretrained_model_params['encoder']['embedder']['word']['embedding'])\n    new_state_dict['cls.predictions.decoder.bias'] = torch.tensor(pretrained_model_params['predictions_output']['output_bias'])\n    new_state_dict['cls.predictions.bias'] = torch.tensor(pretrained_model_params['predictions_output']['output_bias'])\n    new_state_dict['cls.seq_relationship.weight'] = torch.tensor(pretrained_model_params['classification']['output_kernel'])\n    new_state_dict['cls.seq_relationship.bias'] = torch.tensor(pretrained_model_params['classification']['output_bias'])\n    fnet_pretraining_model.load_state_dict(new_state_dict)\n    print(f'Saving pretrained model to {save_path}')\n    fnet_pretraining_model.save_pretrained(save_path)"
        ]
    }
]