[
    {
        "func_name": "check_same",
        "original": "def check_same(data1, data2, min_rows_scale):\n    gbm1_regression = H2OGradientBoostingEstimator(min_rows=5, ntrees=5, max_depth=5)\n    gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n    gbm2_regression = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, ntrees=5, max_depth=5)\n    gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy', training_frame=data2, weights_column='weights')\n    gbm1_binomial = H2OGradientBoostingEstimator(min_rows=5, distribution='bernoulli', ntrees=5, max_depth=5)\n    gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n    gbm2_binomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='bernoulli', ntrees=5, max_depth=5)\n    gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n    gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=5, distribution='multinomial', ntrees=5, max_depth=5)\n    gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n    gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='multinomial', ntrees=5, max_depth=5)\n    gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='cylinders', weights_column='weights', training_frame=data2)\n    reg1_vi = gbm1_regression.varimp()\n    reg2_vi = gbm2_regression.varimp()\n    bin1_vi = gbm1_binomial.varimp()\n    bin2_vi = gbm2_binomial.varimp()\n    mul1_vi = gbm1_multinomial.varimp()\n    mul2_vi = gbm2_multinomial.varimp()\n    print('Varimp (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_vi, reg2_vi))\n    print('Varimp (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_vi, bin2_vi))\n    print('Varimp (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_vi, mul2_vi))\n    for (rvi1, rvi2) in zip(reg1_vi, reg2_vi):\n        assert rvi1 == rvi1, \"Expected vi's (regression)  to be the same, but got {0}, and {1}\".format(rvi1, rvi2)\n    for (bvi1, bvi2) in zip(bin1_vi, bin2_vi):\n        assert bvi1 == bvi1, \"Expected vi's (binomial)    to be the same, but got {0}, and {1}\".format(bvi1, bvi2)\n    for (mvi1, mvi2) in zip(mul1_vi, mul2_vi):\n        assert mvi1 == mvi1, \"Expected vi's (multinomial) to be the same, but got {0}, and {1}\".format(mvi1, mvi2)",
        "mutated": [
            "def check_same(data1, data2, min_rows_scale):\n    if False:\n        i = 10\n    gbm1_regression = H2OGradientBoostingEstimator(min_rows=5, ntrees=5, max_depth=5)\n    gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n    gbm2_regression = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, ntrees=5, max_depth=5)\n    gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy', training_frame=data2, weights_column='weights')\n    gbm1_binomial = H2OGradientBoostingEstimator(min_rows=5, distribution='bernoulli', ntrees=5, max_depth=5)\n    gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n    gbm2_binomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='bernoulli', ntrees=5, max_depth=5)\n    gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n    gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=5, distribution='multinomial', ntrees=5, max_depth=5)\n    gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n    gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='multinomial', ntrees=5, max_depth=5)\n    gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='cylinders', weights_column='weights', training_frame=data2)\n    reg1_vi = gbm1_regression.varimp()\n    reg2_vi = gbm2_regression.varimp()\n    bin1_vi = gbm1_binomial.varimp()\n    bin2_vi = gbm2_binomial.varimp()\n    mul1_vi = gbm1_multinomial.varimp()\n    mul2_vi = gbm2_multinomial.varimp()\n    print('Varimp (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_vi, reg2_vi))\n    print('Varimp (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_vi, bin2_vi))\n    print('Varimp (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_vi, mul2_vi))\n    for (rvi1, rvi2) in zip(reg1_vi, reg2_vi):\n        assert rvi1 == rvi1, \"Expected vi's (regression)  to be the same, but got {0}, and {1}\".format(rvi1, rvi2)\n    for (bvi1, bvi2) in zip(bin1_vi, bin2_vi):\n        assert bvi1 == bvi1, \"Expected vi's (binomial)    to be the same, but got {0}, and {1}\".format(bvi1, bvi2)\n    for (mvi1, mvi2) in zip(mul1_vi, mul2_vi):\n        assert mvi1 == mvi1, \"Expected vi's (multinomial) to be the same, but got {0}, and {1}\".format(mvi1, mvi2)",
            "def check_same(data1, data2, min_rows_scale):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    gbm1_regression = H2OGradientBoostingEstimator(min_rows=5, ntrees=5, max_depth=5)\n    gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n    gbm2_regression = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, ntrees=5, max_depth=5)\n    gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy', training_frame=data2, weights_column='weights')\n    gbm1_binomial = H2OGradientBoostingEstimator(min_rows=5, distribution='bernoulli', ntrees=5, max_depth=5)\n    gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n    gbm2_binomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='bernoulli', ntrees=5, max_depth=5)\n    gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n    gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=5, distribution='multinomial', ntrees=5, max_depth=5)\n    gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n    gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='multinomial', ntrees=5, max_depth=5)\n    gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='cylinders', weights_column='weights', training_frame=data2)\n    reg1_vi = gbm1_regression.varimp()\n    reg2_vi = gbm2_regression.varimp()\n    bin1_vi = gbm1_binomial.varimp()\n    bin2_vi = gbm2_binomial.varimp()\n    mul1_vi = gbm1_multinomial.varimp()\n    mul2_vi = gbm2_multinomial.varimp()\n    print('Varimp (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_vi, reg2_vi))\n    print('Varimp (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_vi, bin2_vi))\n    print('Varimp (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_vi, mul2_vi))\n    for (rvi1, rvi2) in zip(reg1_vi, reg2_vi):\n        assert rvi1 == rvi1, \"Expected vi's (regression)  to be the same, but got {0}, and {1}\".format(rvi1, rvi2)\n    for (bvi1, bvi2) in zip(bin1_vi, bin2_vi):\n        assert bvi1 == bvi1, \"Expected vi's (binomial)    to be the same, but got {0}, and {1}\".format(bvi1, bvi2)\n    for (mvi1, mvi2) in zip(mul1_vi, mul2_vi):\n        assert mvi1 == mvi1, \"Expected vi's (multinomial) to be the same, but got {0}, and {1}\".format(mvi1, mvi2)",
            "def check_same(data1, data2, min_rows_scale):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    gbm1_regression = H2OGradientBoostingEstimator(min_rows=5, ntrees=5, max_depth=5)\n    gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n    gbm2_regression = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, ntrees=5, max_depth=5)\n    gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy', training_frame=data2, weights_column='weights')\n    gbm1_binomial = H2OGradientBoostingEstimator(min_rows=5, distribution='bernoulli', ntrees=5, max_depth=5)\n    gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n    gbm2_binomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='bernoulli', ntrees=5, max_depth=5)\n    gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n    gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=5, distribution='multinomial', ntrees=5, max_depth=5)\n    gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n    gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='multinomial', ntrees=5, max_depth=5)\n    gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='cylinders', weights_column='weights', training_frame=data2)\n    reg1_vi = gbm1_regression.varimp()\n    reg2_vi = gbm2_regression.varimp()\n    bin1_vi = gbm1_binomial.varimp()\n    bin2_vi = gbm2_binomial.varimp()\n    mul1_vi = gbm1_multinomial.varimp()\n    mul2_vi = gbm2_multinomial.varimp()\n    print('Varimp (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_vi, reg2_vi))\n    print('Varimp (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_vi, bin2_vi))\n    print('Varimp (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_vi, mul2_vi))\n    for (rvi1, rvi2) in zip(reg1_vi, reg2_vi):\n        assert rvi1 == rvi1, \"Expected vi's (regression)  to be the same, but got {0}, and {1}\".format(rvi1, rvi2)\n    for (bvi1, bvi2) in zip(bin1_vi, bin2_vi):\n        assert bvi1 == bvi1, \"Expected vi's (binomial)    to be the same, but got {0}, and {1}\".format(bvi1, bvi2)\n    for (mvi1, mvi2) in zip(mul1_vi, mul2_vi):\n        assert mvi1 == mvi1, \"Expected vi's (multinomial) to be the same, but got {0}, and {1}\".format(mvi1, mvi2)",
            "def check_same(data1, data2, min_rows_scale):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    gbm1_regression = H2OGradientBoostingEstimator(min_rows=5, ntrees=5, max_depth=5)\n    gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n    gbm2_regression = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, ntrees=5, max_depth=5)\n    gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy', training_frame=data2, weights_column='weights')\n    gbm1_binomial = H2OGradientBoostingEstimator(min_rows=5, distribution='bernoulli', ntrees=5, max_depth=5)\n    gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n    gbm2_binomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='bernoulli', ntrees=5, max_depth=5)\n    gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n    gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=5, distribution='multinomial', ntrees=5, max_depth=5)\n    gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n    gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='multinomial', ntrees=5, max_depth=5)\n    gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='cylinders', weights_column='weights', training_frame=data2)\n    reg1_vi = gbm1_regression.varimp()\n    reg2_vi = gbm2_regression.varimp()\n    bin1_vi = gbm1_binomial.varimp()\n    bin2_vi = gbm2_binomial.varimp()\n    mul1_vi = gbm1_multinomial.varimp()\n    mul2_vi = gbm2_multinomial.varimp()\n    print('Varimp (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_vi, reg2_vi))\n    print('Varimp (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_vi, bin2_vi))\n    print('Varimp (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_vi, mul2_vi))\n    for (rvi1, rvi2) in zip(reg1_vi, reg2_vi):\n        assert rvi1 == rvi1, \"Expected vi's (regression)  to be the same, but got {0}, and {1}\".format(rvi1, rvi2)\n    for (bvi1, bvi2) in zip(bin1_vi, bin2_vi):\n        assert bvi1 == bvi1, \"Expected vi's (binomial)    to be the same, but got {0}, and {1}\".format(bvi1, bvi2)\n    for (mvi1, mvi2) in zip(mul1_vi, mul2_vi):\n        assert mvi1 == mvi1, \"Expected vi's (multinomial) to be the same, but got {0}, and {1}\".format(mvi1, mvi2)",
            "def check_same(data1, data2, min_rows_scale):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    gbm1_regression = H2OGradientBoostingEstimator(min_rows=5, ntrees=5, max_depth=5)\n    gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n    gbm2_regression = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, ntrees=5, max_depth=5)\n    gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy', training_frame=data2, weights_column='weights')\n    gbm1_binomial = H2OGradientBoostingEstimator(min_rows=5, distribution='bernoulli', ntrees=5, max_depth=5)\n    gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n    gbm2_binomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='bernoulli', ntrees=5, max_depth=5)\n    gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n    gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=5, distribution='multinomial', ntrees=5, max_depth=5)\n    gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n    gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='multinomial', ntrees=5, max_depth=5)\n    gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='cylinders', weights_column='weights', training_frame=data2)\n    reg1_vi = gbm1_regression.varimp()\n    reg2_vi = gbm2_regression.varimp()\n    bin1_vi = gbm1_binomial.varimp()\n    bin2_vi = gbm2_binomial.varimp()\n    mul1_vi = gbm1_multinomial.varimp()\n    mul2_vi = gbm2_multinomial.varimp()\n    print('Varimp (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_vi, reg2_vi))\n    print('Varimp (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_vi, bin2_vi))\n    print('Varimp (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_vi, mul2_vi))\n    for (rvi1, rvi2) in zip(reg1_vi, reg2_vi):\n        assert rvi1 == rvi1, \"Expected vi's (regression)  to be the same, but got {0}, and {1}\".format(rvi1, rvi2)\n    for (bvi1, bvi2) in zip(bin1_vi, bin2_vi):\n        assert bvi1 == bvi1, \"Expected vi's (binomial)    to be the same, but got {0}, and {1}\".format(bvi1, bvi2)\n    for (mvi1, mvi2) in zip(mul1_vi, mul2_vi):\n        assert mvi1 == mvi1, \"Expected vi's (multinomial) to be the same, but got {0}, and {1}\".format(mvi1, mvi2)"
        ]
    },
    {
        "func_name": "weights_var_imp",
        "original": "def weights_var_imp():\n\n    def check_same(data1, data2, min_rows_scale):\n        gbm1_regression = H2OGradientBoostingEstimator(min_rows=5, ntrees=5, max_depth=5)\n        gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n        gbm2_regression = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, ntrees=5, max_depth=5)\n        gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy', training_frame=data2, weights_column='weights')\n        gbm1_binomial = H2OGradientBoostingEstimator(min_rows=5, distribution='bernoulli', ntrees=5, max_depth=5)\n        gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n        gbm2_binomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='bernoulli', ntrees=5, max_depth=5)\n        gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n        gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=5, distribution='multinomial', ntrees=5, max_depth=5)\n        gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n        gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='multinomial', ntrees=5, max_depth=5)\n        gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='cylinders', weights_column='weights', training_frame=data2)\n        reg1_vi = gbm1_regression.varimp()\n        reg2_vi = gbm2_regression.varimp()\n        bin1_vi = gbm1_binomial.varimp()\n        bin2_vi = gbm2_binomial.varimp()\n        mul1_vi = gbm1_multinomial.varimp()\n        mul2_vi = gbm2_multinomial.varimp()\n        print('Varimp (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_vi, reg2_vi))\n        print('Varimp (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_vi, bin2_vi))\n        print('Varimp (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_vi, mul2_vi))\n        for (rvi1, rvi2) in zip(reg1_vi, reg2_vi):\n            assert rvi1 == rvi1, \"Expected vi's (regression)  to be the same, but got {0}, and {1}\".format(rvi1, rvi2)\n        for (bvi1, bvi2) in zip(bin1_vi, bin2_vi):\n            assert bvi1 == bvi1, \"Expected vi's (binomial)    to be the same, but got {0}, and {1}\".format(bvi1, bvi2)\n        for (mvi1, mvi2) in zip(mul1_vi, mul2_vi):\n            assert mvi1 == mvi1, \"Expected vi's (multinomial) to be the same, but got {0}, and {1}\".format(mvi1, mvi2)\n    h2o_cars_data = h2o.import_file(pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    h2o_cars_data['economy_20mpg'] = h2o_cars_data['economy_20mpg'].asfactor()\n    h2o_cars_data['cylinders'] = h2o_cars_data['cylinders'].asfactor()\n    weight = random.randint(1, 10)\n    uniform_weights = [[weight] for _ in range(406)]\n    h2o_uniform_weights = h2o.H2OFrame(uniform_weights)\n    h2o_uniform_weights.set_names(['weights'])\n    h2o_data_uniform_weights = h2o_cars_data.cbind(h2o_uniform_weights)\n    print('\\n\\nChecking that using uniform weights is equivalent to no weights:')\n    check_same(h2o_cars_data, h2o_data_uniform_weights, weight)\n    zero_weights = [[0 if random.randint(0, 1) else 1] for r in range(406)]\n    h2o_zero_weights = h2o.H2OFrame(zero_weights)\n    h2o_zero_weights.set_names(['weights'])\n    h2o_data_zero_weights = h2o_cars_data.cbind(h2o_zero_weights)\n    h2o_data_zeros_removed = h2o_cars_data[h2o_zero_weights['weights'] == 1]\n    print('\\n\\nChecking that using some zero weights is equivalent to removing those observations:')\n    check_same(h2o_data_zeros_removed, h2o_data_zero_weights, 1)\n    doubled_weights = [[1 if random.randint(0, 1) else 2] for r in range(406)]\n    h2o_doubled_weights = h2o.H2OFrame(doubled_weights)\n    h2o_doubled_weights.set_names(['weights'])\n    h2o_data_doubled_weights = h2o_cars_data.cbind(h2o_doubled_weights)\n    doubled_data = h2o.as_list(h2o_cars_data, use_pandas=False)\n    colnames = doubled_data.pop(0)\n    for (idx, w) in enumerate(doubled_weights[0]):\n        if w == 2:\n            doubled_data.append(doubled_data[idx])\n    h2o_data_doubled = h2o.H2OFrame(doubled_data)\n    h2o_data_doubled.set_names(list(colnames))\n    h2o_data_doubled['economy_20mpg'] = h2o_data_doubled['economy_20mpg'].asfactor()\n    h2o_data_doubled['cylinders'] = h2o_data_doubled['cylinders'].asfactor()\n    h2o_data_doubled_weights['economy_20mpg'] = h2o_data_doubled_weights['economy_20mpg'].asfactor()\n    h2o_data_doubled_weights['cylinders'] = h2o_data_doubled_weights['cylinders'].asfactor()\n    print('\\n\\nChecking that doubling some weights is equivalent to doubling those observations:')\n    check_same(h2o_data_doubled, h2o_data_doubled_weights, 1)",
        "mutated": [
            "def weights_var_imp():\n    if False:\n        i = 10\n\n    def check_same(data1, data2, min_rows_scale):\n        gbm1_regression = H2OGradientBoostingEstimator(min_rows=5, ntrees=5, max_depth=5)\n        gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n        gbm2_regression = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, ntrees=5, max_depth=5)\n        gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy', training_frame=data2, weights_column='weights')\n        gbm1_binomial = H2OGradientBoostingEstimator(min_rows=5, distribution='bernoulli', ntrees=5, max_depth=5)\n        gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n        gbm2_binomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='bernoulli', ntrees=5, max_depth=5)\n        gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n        gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=5, distribution='multinomial', ntrees=5, max_depth=5)\n        gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n        gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='multinomial', ntrees=5, max_depth=5)\n        gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='cylinders', weights_column='weights', training_frame=data2)\n        reg1_vi = gbm1_regression.varimp()\n        reg2_vi = gbm2_regression.varimp()\n        bin1_vi = gbm1_binomial.varimp()\n        bin2_vi = gbm2_binomial.varimp()\n        mul1_vi = gbm1_multinomial.varimp()\n        mul2_vi = gbm2_multinomial.varimp()\n        print('Varimp (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_vi, reg2_vi))\n        print('Varimp (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_vi, bin2_vi))\n        print('Varimp (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_vi, mul2_vi))\n        for (rvi1, rvi2) in zip(reg1_vi, reg2_vi):\n            assert rvi1 == rvi1, \"Expected vi's (regression)  to be the same, but got {0}, and {1}\".format(rvi1, rvi2)\n        for (bvi1, bvi2) in zip(bin1_vi, bin2_vi):\n            assert bvi1 == bvi1, \"Expected vi's (binomial)    to be the same, but got {0}, and {1}\".format(bvi1, bvi2)\n        for (mvi1, mvi2) in zip(mul1_vi, mul2_vi):\n            assert mvi1 == mvi1, \"Expected vi's (multinomial) to be the same, but got {0}, and {1}\".format(mvi1, mvi2)\n    h2o_cars_data = h2o.import_file(pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    h2o_cars_data['economy_20mpg'] = h2o_cars_data['economy_20mpg'].asfactor()\n    h2o_cars_data['cylinders'] = h2o_cars_data['cylinders'].asfactor()\n    weight = random.randint(1, 10)\n    uniform_weights = [[weight] for _ in range(406)]\n    h2o_uniform_weights = h2o.H2OFrame(uniform_weights)\n    h2o_uniform_weights.set_names(['weights'])\n    h2o_data_uniform_weights = h2o_cars_data.cbind(h2o_uniform_weights)\n    print('\\n\\nChecking that using uniform weights is equivalent to no weights:')\n    check_same(h2o_cars_data, h2o_data_uniform_weights, weight)\n    zero_weights = [[0 if random.randint(0, 1) else 1] for r in range(406)]\n    h2o_zero_weights = h2o.H2OFrame(zero_weights)\n    h2o_zero_weights.set_names(['weights'])\n    h2o_data_zero_weights = h2o_cars_data.cbind(h2o_zero_weights)\n    h2o_data_zeros_removed = h2o_cars_data[h2o_zero_weights['weights'] == 1]\n    print('\\n\\nChecking that using some zero weights is equivalent to removing those observations:')\n    check_same(h2o_data_zeros_removed, h2o_data_zero_weights, 1)\n    doubled_weights = [[1 if random.randint(0, 1) else 2] for r in range(406)]\n    h2o_doubled_weights = h2o.H2OFrame(doubled_weights)\n    h2o_doubled_weights.set_names(['weights'])\n    h2o_data_doubled_weights = h2o_cars_data.cbind(h2o_doubled_weights)\n    doubled_data = h2o.as_list(h2o_cars_data, use_pandas=False)\n    colnames = doubled_data.pop(0)\n    for (idx, w) in enumerate(doubled_weights[0]):\n        if w == 2:\n            doubled_data.append(doubled_data[idx])\n    h2o_data_doubled = h2o.H2OFrame(doubled_data)\n    h2o_data_doubled.set_names(list(colnames))\n    h2o_data_doubled['economy_20mpg'] = h2o_data_doubled['economy_20mpg'].asfactor()\n    h2o_data_doubled['cylinders'] = h2o_data_doubled['cylinders'].asfactor()\n    h2o_data_doubled_weights['economy_20mpg'] = h2o_data_doubled_weights['economy_20mpg'].asfactor()\n    h2o_data_doubled_weights['cylinders'] = h2o_data_doubled_weights['cylinders'].asfactor()\n    print('\\n\\nChecking that doubling some weights is equivalent to doubling those observations:')\n    check_same(h2o_data_doubled, h2o_data_doubled_weights, 1)",
            "def weights_var_imp():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n\n    def check_same(data1, data2, min_rows_scale):\n        gbm1_regression = H2OGradientBoostingEstimator(min_rows=5, ntrees=5, max_depth=5)\n        gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n        gbm2_regression = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, ntrees=5, max_depth=5)\n        gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy', training_frame=data2, weights_column='weights')\n        gbm1_binomial = H2OGradientBoostingEstimator(min_rows=5, distribution='bernoulli', ntrees=5, max_depth=5)\n        gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n        gbm2_binomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='bernoulli', ntrees=5, max_depth=5)\n        gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n        gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=5, distribution='multinomial', ntrees=5, max_depth=5)\n        gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n        gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='multinomial', ntrees=5, max_depth=5)\n        gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='cylinders', weights_column='weights', training_frame=data2)\n        reg1_vi = gbm1_regression.varimp()\n        reg2_vi = gbm2_regression.varimp()\n        bin1_vi = gbm1_binomial.varimp()\n        bin2_vi = gbm2_binomial.varimp()\n        mul1_vi = gbm1_multinomial.varimp()\n        mul2_vi = gbm2_multinomial.varimp()\n        print('Varimp (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_vi, reg2_vi))\n        print('Varimp (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_vi, bin2_vi))\n        print('Varimp (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_vi, mul2_vi))\n        for (rvi1, rvi2) in zip(reg1_vi, reg2_vi):\n            assert rvi1 == rvi1, \"Expected vi's (regression)  to be the same, but got {0}, and {1}\".format(rvi1, rvi2)\n        for (bvi1, bvi2) in zip(bin1_vi, bin2_vi):\n            assert bvi1 == bvi1, \"Expected vi's (binomial)    to be the same, but got {0}, and {1}\".format(bvi1, bvi2)\n        for (mvi1, mvi2) in zip(mul1_vi, mul2_vi):\n            assert mvi1 == mvi1, \"Expected vi's (multinomial) to be the same, but got {0}, and {1}\".format(mvi1, mvi2)\n    h2o_cars_data = h2o.import_file(pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    h2o_cars_data['economy_20mpg'] = h2o_cars_data['economy_20mpg'].asfactor()\n    h2o_cars_data['cylinders'] = h2o_cars_data['cylinders'].asfactor()\n    weight = random.randint(1, 10)\n    uniform_weights = [[weight] for _ in range(406)]\n    h2o_uniform_weights = h2o.H2OFrame(uniform_weights)\n    h2o_uniform_weights.set_names(['weights'])\n    h2o_data_uniform_weights = h2o_cars_data.cbind(h2o_uniform_weights)\n    print('\\n\\nChecking that using uniform weights is equivalent to no weights:')\n    check_same(h2o_cars_data, h2o_data_uniform_weights, weight)\n    zero_weights = [[0 if random.randint(0, 1) else 1] for r in range(406)]\n    h2o_zero_weights = h2o.H2OFrame(zero_weights)\n    h2o_zero_weights.set_names(['weights'])\n    h2o_data_zero_weights = h2o_cars_data.cbind(h2o_zero_weights)\n    h2o_data_zeros_removed = h2o_cars_data[h2o_zero_weights['weights'] == 1]\n    print('\\n\\nChecking that using some zero weights is equivalent to removing those observations:')\n    check_same(h2o_data_zeros_removed, h2o_data_zero_weights, 1)\n    doubled_weights = [[1 if random.randint(0, 1) else 2] for r in range(406)]\n    h2o_doubled_weights = h2o.H2OFrame(doubled_weights)\n    h2o_doubled_weights.set_names(['weights'])\n    h2o_data_doubled_weights = h2o_cars_data.cbind(h2o_doubled_weights)\n    doubled_data = h2o.as_list(h2o_cars_data, use_pandas=False)\n    colnames = doubled_data.pop(0)\n    for (idx, w) in enumerate(doubled_weights[0]):\n        if w == 2:\n            doubled_data.append(doubled_data[idx])\n    h2o_data_doubled = h2o.H2OFrame(doubled_data)\n    h2o_data_doubled.set_names(list(colnames))\n    h2o_data_doubled['economy_20mpg'] = h2o_data_doubled['economy_20mpg'].asfactor()\n    h2o_data_doubled['cylinders'] = h2o_data_doubled['cylinders'].asfactor()\n    h2o_data_doubled_weights['economy_20mpg'] = h2o_data_doubled_weights['economy_20mpg'].asfactor()\n    h2o_data_doubled_weights['cylinders'] = h2o_data_doubled_weights['cylinders'].asfactor()\n    print('\\n\\nChecking that doubling some weights is equivalent to doubling those observations:')\n    check_same(h2o_data_doubled, h2o_data_doubled_weights, 1)",
            "def weights_var_imp():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n    def check_same(data1, data2, min_rows_scale):\n        gbm1_regression = H2OGradientBoostingEstimator(min_rows=5, ntrees=5, max_depth=5)\n        gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n        gbm2_regression = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, ntrees=5, max_depth=5)\n        gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy', training_frame=data2, weights_column='weights')\n        gbm1_binomial = H2OGradientBoostingEstimator(min_rows=5, distribution='bernoulli', ntrees=5, max_depth=5)\n        gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n        gbm2_binomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='bernoulli', ntrees=5, max_depth=5)\n        gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n        gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=5, distribution='multinomial', ntrees=5, max_depth=5)\n        gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n        gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='multinomial', ntrees=5, max_depth=5)\n        gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='cylinders', weights_column='weights', training_frame=data2)\n        reg1_vi = gbm1_regression.varimp()\n        reg2_vi = gbm2_regression.varimp()\n        bin1_vi = gbm1_binomial.varimp()\n        bin2_vi = gbm2_binomial.varimp()\n        mul1_vi = gbm1_multinomial.varimp()\n        mul2_vi = gbm2_multinomial.varimp()\n        print('Varimp (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_vi, reg2_vi))\n        print('Varimp (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_vi, bin2_vi))\n        print('Varimp (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_vi, mul2_vi))\n        for (rvi1, rvi2) in zip(reg1_vi, reg2_vi):\n            assert rvi1 == rvi1, \"Expected vi's (regression)  to be the same, but got {0}, and {1}\".format(rvi1, rvi2)\n        for (bvi1, bvi2) in zip(bin1_vi, bin2_vi):\n            assert bvi1 == bvi1, \"Expected vi's (binomial)    to be the same, but got {0}, and {1}\".format(bvi1, bvi2)\n        for (mvi1, mvi2) in zip(mul1_vi, mul2_vi):\n            assert mvi1 == mvi1, \"Expected vi's (multinomial) to be the same, but got {0}, and {1}\".format(mvi1, mvi2)\n    h2o_cars_data = h2o.import_file(pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    h2o_cars_data['economy_20mpg'] = h2o_cars_data['economy_20mpg'].asfactor()\n    h2o_cars_data['cylinders'] = h2o_cars_data['cylinders'].asfactor()\n    weight = random.randint(1, 10)\n    uniform_weights = [[weight] for _ in range(406)]\n    h2o_uniform_weights = h2o.H2OFrame(uniform_weights)\n    h2o_uniform_weights.set_names(['weights'])\n    h2o_data_uniform_weights = h2o_cars_data.cbind(h2o_uniform_weights)\n    print('\\n\\nChecking that using uniform weights is equivalent to no weights:')\n    check_same(h2o_cars_data, h2o_data_uniform_weights, weight)\n    zero_weights = [[0 if random.randint(0, 1) else 1] for r in range(406)]\n    h2o_zero_weights = h2o.H2OFrame(zero_weights)\n    h2o_zero_weights.set_names(['weights'])\n    h2o_data_zero_weights = h2o_cars_data.cbind(h2o_zero_weights)\n    h2o_data_zeros_removed = h2o_cars_data[h2o_zero_weights['weights'] == 1]\n    print('\\n\\nChecking that using some zero weights is equivalent to removing those observations:')\n    check_same(h2o_data_zeros_removed, h2o_data_zero_weights, 1)\n    doubled_weights = [[1 if random.randint(0, 1) else 2] for r in range(406)]\n    h2o_doubled_weights = h2o.H2OFrame(doubled_weights)\n    h2o_doubled_weights.set_names(['weights'])\n    h2o_data_doubled_weights = h2o_cars_data.cbind(h2o_doubled_weights)\n    doubled_data = h2o.as_list(h2o_cars_data, use_pandas=False)\n    colnames = doubled_data.pop(0)\n    for (idx, w) in enumerate(doubled_weights[0]):\n        if w == 2:\n            doubled_data.append(doubled_data[idx])\n    h2o_data_doubled = h2o.H2OFrame(doubled_data)\n    h2o_data_doubled.set_names(list(colnames))\n    h2o_data_doubled['economy_20mpg'] = h2o_data_doubled['economy_20mpg'].asfactor()\n    h2o_data_doubled['cylinders'] = h2o_data_doubled['cylinders'].asfactor()\n    h2o_data_doubled_weights['economy_20mpg'] = h2o_data_doubled_weights['economy_20mpg'].asfactor()\n    h2o_data_doubled_weights['cylinders'] = h2o_data_doubled_weights['cylinders'].asfactor()\n    print('\\n\\nChecking that doubling some weights is equivalent to doubling those observations:')\n    check_same(h2o_data_doubled, h2o_data_doubled_weights, 1)",
            "def weights_var_imp():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n\n    def check_same(data1, data2, min_rows_scale):\n        gbm1_regression = H2OGradientBoostingEstimator(min_rows=5, ntrees=5, max_depth=5)\n        gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n        gbm2_regression = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, ntrees=5, max_depth=5)\n        gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy', training_frame=data2, weights_column='weights')\n        gbm1_binomial = H2OGradientBoostingEstimator(min_rows=5, distribution='bernoulli', ntrees=5, max_depth=5)\n        gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n        gbm2_binomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='bernoulli', ntrees=5, max_depth=5)\n        gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n        gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=5, distribution='multinomial', ntrees=5, max_depth=5)\n        gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n        gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='multinomial', ntrees=5, max_depth=5)\n        gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='cylinders', weights_column='weights', training_frame=data2)\n        reg1_vi = gbm1_regression.varimp()\n        reg2_vi = gbm2_regression.varimp()\n        bin1_vi = gbm1_binomial.varimp()\n        bin2_vi = gbm2_binomial.varimp()\n        mul1_vi = gbm1_multinomial.varimp()\n        mul2_vi = gbm2_multinomial.varimp()\n        print('Varimp (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_vi, reg2_vi))\n        print('Varimp (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_vi, bin2_vi))\n        print('Varimp (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_vi, mul2_vi))\n        for (rvi1, rvi2) in zip(reg1_vi, reg2_vi):\n            assert rvi1 == rvi1, \"Expected vi's (regression)  to be the same, but got {0}, and {1}\".format(rvi1, rvi2)\n        for (bvi1, bvi2) in zip(bin1_vi, bin2_vi):\n            assert bvi1 == bvi1, \"Expected vi's (binomial)    to be the same, but got {0}, and {1}\".format(bvi1, bvi2)\n        for (mvi1, mvi2) in zip(mul1_vi, mul2_vi):\n            assert mvi1 == mvi1, \"Expected vi's (multinomial) to be the same, but got {0}, and {1}\".format(mvi1, mvi2)\n    h2o_cars_data = h2o.import_file(pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    h2o_cars_data['economy_20mpg'] = h2o_cars_data['economy_20mpg'].asfactor()\n    h2o_cars_data['cylinders'] = h2o_cars_data['cylinders'].asfactor()\n    weight = random.randint(1, 10)\n    uniform_weights = [[weight] for _ in range(406)]\n    h2o_uniform_weights = h2o.H2OFrame(uniform_weights)\n    h2o_uniform_weights.set_names(['weights'])\n    h2o_data_uniform_weights = h2o_cars_data.cbind(h2o_uniform_weights)\n    print('\\n\\nChecking that using uniform weights is equivalent to no weights:')\n    check_same(h2o_cars_data, h2o_data_uniform_weights, weight)\n    zero_weights = [[0 if random.randint(0, 1) else 1] for r in range(406)]\n    h2o_zero_weights = h2o.H2OFrame(zero_weights)\n    h2o_zero_weights.set_names(['weights'])\n    h2o_data_zero_weights = h2o_cars_data.cbind(h2o_zero_weights)\n    h2o_data_zeros_removed = h2o_cars_data[h2o_zero_weights['weights'] == 1]\n    print('\\n\\nChecking that using some zero weights is equivalent to removing those observations:')\n    check_same(h2o_data_zeros_removed, h2o_data_zero_weights, 1)\n    doubled_weights = [[1 if random.randint(0, 1) else 2] for r in range(406)]\n    h2o_doubled_weights = h2o.H2OFrame(doubled_weights)\n    h2o_doubled_weights.set_names(['weights'])\n    h2o_data_doubled_weights = h2o_cars_data.cbind(h2o_doubled_weights)\n    doubled_data = h2o.as_list(h2o_cars_data, use_pandas=False)\n    colnames = doubled_data.pop(0)\n    for (idx, w) in enumerate(doubled_weights[0]):\n        if w == 2:\n            doubled_data.append(doubled_data[idx])\n    h2o_data_doubled = h2o.H2OFrame(doubled_data)\n    h2o_data_doubled.set_names(list(colnames))\n    h2o_data_doubled['economy_20mpg'] = h2o_data_doubled['economy_20mpg'].asfactor()\n    h2o_data_doubled['cylinders'] = h2o_data_doubled['cylinders'].asfactor()\n    h2o_data_doubled_weights['economy_20mpg'] = h2o_data_doubled_weights['economy_20mpg'].asfactor()\n    h2o_data_doubled_weights['cylinders'] = h2o_data_doubled_weights['cylinders'].asfactor()\n    print('\\n\\nChecking that doubling some weights is equivalent to doubling those observations:')\n    check_same(h2o_data_doubled, h2o_data_doubled_weights, 1)",
            "def weights_var_imp():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n\n    def check_same(data1, data2, min_rows_scale):\n        gbm1_regression = H2OGradientBoostingEstimator(min_rows=5, ntrees=5, max_depth=5)\n        gbm1_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy', training_frame=data1)\n        gbm2_regression = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, ntrees=5, max_depth=5)\n        gbm2_regression.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy', training_frame=data2, weights_column='weights')\n        gbm1_binomial = H2OGradientBoostingEstimator(min_rows=5, distribution='bernoulli', ntrees=5, max_depth=5)\n        gbm1_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='economy_20mpg', training_frame=data1)\n        gbm2_binomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='bernoulli', ntrees=5, max_depth=5)\n        gbm2_binomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='economy_20mpg', training_frame=data2, weights_column='weights')\n        gbm1_multinomial = H2OGradientBoostingEstimator(min_rows=5, distribution='multinomial', ntrees=5, max_depth=5)\n        gbm1_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year'], y='cylinders', training_frame=data1)\n        gbm2_multinomial = H2OGradientBoostingEstimator(min_rows=5 * min_rows_scale, distribution='multinomial', ntrees=5, max_depth=5)\n        gbm2_multinomial.train(x=['displacement', 'power', 'weight', 'acceleration', 'year', 'weights'], y='cylinders', weights_column='weights', training_frame=data2)\n        reg1_vi = gbm1_regression.varimp()\n        reg2_vi = gbm2_regression.varimp()\n        bin1_vi = gbm1_binomial.varimp()\n        bin2_vi = gbm2_binomial.varimp()\n        mul1_vi = gbm1_multinomial.varimp()\n        mul2_vi = gbm2_multinomial.varimp()\n        print('Varimp (regresson)   no weights vs. weights: {0}, {1}'.format(reg1_vi, reg2_vi))\n        print('Varimp (binomial)    no weights vs. weights: {0}, {1}'.format(bin1_vi, bin2_vi))\n        print('Varimp (multinomial) no weights vs. weights: {0}, {1}'.format(mul1_vi, mul2_vi))\n        for (rvi1, rvi2) in zip(reg1_vi, reg2_vi):\n            assert rvi1 == rvi1, \"Expected vi's (regression)  to be the same, but got {0}, and {1}\".format(rvi1, rvi2)\n        for (bvi1, bvi2) in zip(bin1_vi, bin2_vi):\n            assert bvi1 == bvi1, \"Expected vi's (binomial)    to be the same, but got {0}, and {1}\".format(bvi1, bvi2)\n        for (mvi1, mvi2) in zip(mul1_vi, mul2_vi):\n            assert mvi1 == mvi1, \"Expected vi's (multinomial) to be the same, but got {0}, and {1}\".format(mvi1, mvi2)\n    h2o_cars_data = h2o.import_file(pyunit_utils.locate('smalldata/junit/cars_20mpg.csv'))\n    h2o_cars_data['economy_20mpg'] = h2o_cars_data['economy_20mpg'].asfactor()\n    h2o_cars_data['cylinders'] = h2o_cars_data['cylinders'].asfactor()\n    weight = random.randint(1, 10)\n    uniform_weights = [[weight] for _ in range(406)]\n    h2o_uniform_weights = h2o.H2OFrame(uniform_weights)\n    h2o_uniform_weights.set_names(['weights'])\n    h2o_data_uniform_weights = h2o_cars_data.cbind(h2o_uniform_weights)\n    print('\\n\\nChecking that using uniform weights is equivalent to no weights:')\n    check_same(h2o_cars_data, h2o_data_uniform_weights, weight)\n    zero_weights = [[0 if random.randint(0, 1) else 1] for r in range(406)]\n    h2o_zero_weights = h2o.H2OFrame(zero_weights)\n    h2o_zero_weights.set_names(['weights'])\n    h2o_data_zero_weights = h2o_cars_data.cbind(h2o_zero_weights)\n    h2o_data_zeros_removed = h2o_cars_data[h2o_zero_weights['weights'] == 1]\n    print('\\n\\nChecking that using some zero weights is equivalent to removing those observations:')\n    check_same(h2o_data_zeros_removed, h2o_data_zero_weights, 1)\n    doubled_weights = [[1 if random.randint(0, 1) else 2] for r in range(406)]\n    h2o_doubled_weights = h2o.H2OFrame(doubled_weights)\n    h2o_doubled_weights.set_names(['weights'])\n    h2o_data_doubled_weights = h2o_cars_data.cbind(h2o_doubled_weights)\n    doubled_data = h2o.as_list(h2o_cars_data, use_pandas=False)\n    colnames = doubled_data.pop(0)\n    for (idx, w) in enumerate(doubled_weights[0]):\n        if w == 2:\n            doubled_data.append(doubled_data[idx])\n    h2o_data_doubled = h2o.H2OFrame(doubled_data)\n    h2o_data_doubled.set_names(list(colnames))\n    h2o_data_doubled['economy_20mpg'] = h2o_data_doubled['economy_20mpg'].asfactor()\n    h2o_data_doubled['cylinders'] = h2o_data_doubled['cylinders'].asfactor()\n    h2o_data_doubled_weights['economy_20mpg'] = h2o_data_doubled_weights['economy_20mpg'].asfactor()\n    h2o_data_doubled_weights['cylinders'] = h2o_data_doubled_weights['cylinders'].asfactor()\n    print('\\n\\nChecking that doubling some weights is equivalent to doubling those observations:')\n    check_same(h2o_data_doubled, h2o_data_doubled_weights, 1)"
        ]
    }
]