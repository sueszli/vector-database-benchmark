[
    {
        "func_name": "assign_class",
        "original": "@staticmethod\ndef assign_class(clusters: np.ndarray, clean_clusters: np.ndarray, poison_clusters: np.ndarray) -> np.ndarray:\n    \"\"\"\n        Determines whether each data point in the class is in a clean or poisonous cluster\n\n        :param clusters: `clusters[i]` indicates which cluster the i'th data point is in.\n        :param clean_clusters: List containing the clusters designated as clean.\n        :param poison_clusters: List containing the clusters designated as poisonous.\n        :return: assigned_clean: `assigned_clean[i]` is a boolean indicating whether the ith data point is clean.\n        \"\"\"\n    assigned_clean = np.empty(np.shape(clusters))\n    assigned_clean[np.isin(clusters, clean_clusters)] = 1\n    assigned_clean[np.isin(clusters, poison_clusters)] = 0\n    return assigned_clean",
        "mutated": [
            "@staticmethod\ndef assign_class(clusters: np.ndarray, clean_clusters: np.ndarray, poison_clusters: np.ndarray) -> np.ndarray:\n    if False:\n        i = 10\n    \"\\n        Determines whether each data point in the class is in a clean or poisonous cluster\\n\\n        :param clusters: `clusters[i]` indicates which cluster the i'th data point is in.\\n        :param clean_clusters: List containing the clusters designated as clean.\\n        :param poison_clusters: List containing the clusters designated as poisonous.\\n        :return: assigned_clean: `assigned_clean[i]` is a boolean indicating whether the ith data point is clean.\\n        \"\n    assigned_clean = np.empty(np.shape(clusters))\n    assigned_clean[np.isin(clusters, clean_clusters)] = 1\n    assigned_clean[np.isin(clusters, poison_clusters)] = 0\n    return assigned_clean",
            "@staticmethod\ndef assign_class(clusters: np.ndarray, clean_clusters: np.ndarray, poison_clusters: np.ndarray) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Determines whether each data point in the class is in a clean or poisonous cluster\\n\\n        :param clusters: `clusters[i]` indicates which cluster the i'th data point is in.\\n        :param clean_clusters: List containing the clusters designated as clean.\\n        :param poison_clusters: List containing the clusters designated as poisonous.\\n        :return: assigned_clean: `assigned_clean[i]` is a boolean indicating whether the ith data point is clean.\\n        \"\n    assigned_clean = np.empty(np.shape(clusters))\n    assigned_clean[np.isin(clusters, clean_clusters)] = 1\n    assigned_clean[np.isin(clusters, poison_clusters)] = 0\n    return assigned_clean",
            "@staticmethod\ndef assign_class(clusters: np.ndarray, clean_clusters: np.ndarray, poison_clusters: np.ndarray) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Determines whether each data point in the class is in a clean or poisonous cluster\\n\\n        :param clusters: `clusters[i]` indicates which cluster the i'th data point is in.\\n        :param clean_clusters: List containing the clusters designated as clean.\\n        :param poison_clusters: List containing the clusters designated as poisonous.\\n        :return: assigned_clean: `assigned_clean[i]` is a boolean indicating whether the ith data point is clean.\\n        \"\n    assigned_clean = np.empty(np.shape(clusters))\n    assigned_clean[np.isin(clusters, clean_clusters)] = 1\n    assigned_clean[np.isin(clusters, poison_clusters)] = 0\n    return assigned_clean",
            "@staticmethod\ndef assign_class(clusters: np.ndarray, clean_clusters: np.ndarray, poison_clusters: np.ndarray) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Determines whether each data point in the class is in a clean or poisonous cluster\\n\\n        :param clusters: `clusters[i]` indicates which cluster the i'th data point is in.\\n        :param clean_clusters: List containing the clusters designated as clean.\\n        :param poison_clusters: List containing the clusters designated as poisonous.\\n        :return: assigned_clean: `assigned_clean[i]` is a boolean indicating whether the ith data point is clean.\\n        \"\n    assigned_clean = np.empty(np.shape(clusters))\n    assigned_clean[np.isin(clusters, clean_clusters)] = 1\n    assigned_clean[np.isin(clusters, poison_clusters)] = 0\n    return assigned_clean",
            "@staticmethod\ndef assign_class(clusters: np.ndarray, clean_clusters: np.ndarray, poison_clusters: np.ndarray) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Determines whether each data point in the class is in a clean or poisonous cluster\\n\\n        :param clusters: `clusters[i]` indicates which cluster the i'th data point is in.\\n        :param clean_clusters: List containing the clusters designated as clean.\\n        :param poison_clusters: List containing the clusters designated as poisonous.\\n        :return: assigned_clean: `assigned_clean[i]` is a boolean indicating whether the ith data point is clean.\\n        \"\n    assigned_clean = np.empty(np.shape(clusters))\n    assigned_clean[np.isin(clusters, clean_clusters)] = 1\n    assigned_clean[np.isin(clusters, poison_clusters)] = 0\n    return assigned_clean"
        ]
    },
    {
        "func_name": "analyze_by_size",
        "original": "def analyze_by_size(self, separated_clusters: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    \"\"\"\n        Designates as poisonous the cluster with less number of items on it.\n\n        :param separated_clusters: list where separated_clusters[i] is the cluster assignments for the ith class.\n        :return: all_assigned_clean, summary_poison_clusters, report:\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether\n                 a given data point was determined to be clean (as opposed to poisonous) and\n                 summary_poison_clusters: array, where summary_poison_clusters[i][j]=1 if cluster j of class i was\n                 classified as poison, otherwise 0\n                 report: Dictionary with summary of the analysis\n        \"\"\"\n    report: Dict[str, Any] = {'cluster_analysis': 'smaller', 'suspicious_clusters': 0}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters: np.ndarray = np.zeros((nb_classes, nb_clusters), dtype=object)\n    for (i, clusters) in enumerate(separated_clusters):\n        sizes = np.bincount(clusters)\n        total_dp_in_class = np.sum(sizes)\n        poison_clusters = np.array([int(np.argmin(sizes))])\n        clean_clusters = np.array(list(set(clusters) - set(poison_clusters)))\n        for p_id in poison_clusters:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report_class = {}\n        for cluster_id in range(nb_clusters):\n            ptc = sizes[cluster_id] / total_dp_in_class\n            susp = cluster_id in poison_clusters\n            dict_i = dict(ptc_data_in_cluster=round(ptc, 2), suspicious_cluster=susp)\n            dict_cluster: Dict[str, Dict[str, int]] = {'cluster_' + str(cluster_id): dict_i}\n            report_class.update(dict_cluster)\n        report['Class_' + str(i)] = report_class\n    report['suspicious_clusters'] = report['suspicious_clusters'] + np.sum(summary_poison_clusters)\n    return (np.asarray(all_assigned_clean, dtype=object), summary_poison_clusters, report)",
        "mutated": [
            "def analyze_by_size(self, separated_clusters: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n    '\\n        Designates as poisonous the cluster with less number of items on it.\\n\\n        :param separated_clusters: list where separated_clusters[i] is the cluster assignments for the ith class.\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether\\n                 a given data point was determined to be clean (as opposed to poisonous) and\\n                 summary_poison_clusters: array, where summary_poison_clusters[i][j]=1 if cluster j of class i was\\n                 classified as poison, otherwise 0\\n                 report: Dictionary with summary of the analysis\\n        '\n    report: Dict[str, Any] = {'cluster_analysis': 'smaller', 'suspicious_clusters': 0}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters: np.ndarray = np.zeros((nb_classes, nb_clusters), dtype=object)\n    for (i, clusters) in enumerate(separated_clusters):\n        sizes = np.bincount(clusters)\n        total_dp_in_class = np.sum(sizes)\n        poison_clusters = np.array([int(np.argmin(sizes))])\n        clean_clusters = np.array(list(set(clusters) - set(poison_clusters)))\n        for p_id in poison_clusters:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report_class = {}\n        for cluster_id in range(nb_clusters):\n            ptc = sizes[cluster_id] / total_dp_in_class\n            susp = cluster_id in poison_clusters\n            dict_i = dict(ptc_data_in_cluster=round(ptc, 2), suspicious_cluster=susp)\n            dict_cluster: Dict[str, Dict[str, int]] = {'cluster_' + str(cluster_id): dict_i}\n            report_class.update(dict_cluster)\n        report['Class_' + str(i)] = report_class\n    report['suspicious_clusters'] = report['suspicious_clusters'] + np.sum(summary_poison_clusters)\n    return (np.asarray(all_assigned_clean, dtype=object), summary_poison_clusters, report)",
            "def analyze_by_size(self, separated_clusters: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Designates as poisonous the cluster with less number of items on it.\\n\\n        :param separated_clusters: list where separated_clusters[i] is the cluster assignments for the ith class.\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether\\n                 a given data point was determined to be clean (as opposed to poisonous) and\\n                 summary_poison_clusters: array, where summary_poison_clusters[i][j]=1 if cluster j of class i was\\n                 classified as poison, otherwise 0\\n                 report: Dictionary with summary of the analysis\\n        '\n    report: Dict[str, Any] = {'cluster_analysis': 'smaller', 'suspicious_clusters': 0}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters: np.ndarray = np.zeros((nb_classes, nb_clusters), dtype=object)\n    for (i, clusters) in enumerate(separated_clusters):\n        sizes = np.bincount(clusters)\n        total_dp_in_class = np.sum(sizes)\n        poison_clusters = np.array([int(np.argmin(sizes))])\n        clean_clusters = np.array(list(set(clusters) - set(poison_clusters)))\n        for p_id in poison_clusters:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report_class = {}\n        for cluster_id in range(nb_clusters):\n            ptc = sizes[cluster_id] / total_dp_in_class\n            susp = cluster_id in poison_clusters\n            dict_i = dict(ptc_data_in_cluster=round(ptc, 2), suspicious_cluster=susp)\n            dict_cluster: Dict[str, Dict[str, int]] = {'cluster_' + str(cluster_id): dict_i}\n            report_class.update(dict_cluster)\n        report['Class_' + str(i)] = report_class\n    report['suspicious_clusters'] = report['suspicious_clusters'] + np.sum(summary_poison_clusters)\n    return (np.asarray(all_assigned_clean, dtype=object), summary_poison_clusters, report)",
            "def analyze_by_size(self, separated_clusters: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Designates as poisonous the cluster with less number of items on it.\\n\\n        :param separated_clusters: list where separated_clusters[i] is the cluster assignments for the ith class.\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether\\n                 a given data point was determined to be clean (as opposed to poisonous) and\\n                 summary_poison_clusters: array, where summary_poison_clusters[i][j]=1 if cluster j of class i was\\n                 classified as poison, otherwise 0\\n                 report: Dictionary with summary of the analysis\\n        '\n    report: Dict[str, Any] = {'cluster_analysis': 'smaller', 'suspicious_clusters': 0}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters: np.ndarray = np.zeros((nb_classes, nb_clusters), dtype=object)\n    for (i, clusters) in enumerate(separated_clusters):\n        sizes = np.bincount(clusters)\n        total_dp_in_class = np.sum(sizes)\n        poison_clusters = np.array([int(np.argmin(sizes))])\n        clean_clusters = np.array(list(set(clusters) - set(poison_clusters)))\n        for p_id in poison_clusters:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report_class = {}\n        for cluster_id in range(nb_clusters):\n            ptc = sizes[cluster_id] / total_dp_in_class\n            susp = cluster_id in poison_clusters\n            dict_i = dict(ptc_data_in_cluster=round(ptc, 2), suspicious_cluster=susp)\n            dict_cluster: Dict[str, Dict[str, int]] = {'cluster_' + str(cluster_id): dict_i}\n            report_class.update(dict_cluster)\n        report['Class_' + str(i)] = report_class\n    report['suspicious_clusters'] = report['suspicious_clusters'] + np.sum(summary_poison_clusters)\n    return (np.asarray(all_assigned_clean, dtype=object), summary_poison_clusters, report)",
            "def analyze_by_size(self, separated_clusters: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Designates as poisonous the cluster with less number of items on it.\\n\\n        :param separated_clusters: list where separated_clusters[i] is the cluster assignments for the ith class.\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether\\n                 a given data point was determined to be clean (as opposed to poisonous) and\\n                 summary_poison_clusters: array, where summary_poison_clusters[i][j]=1 if cluster j of class i was\\n                 classified as poison, otherwise 0\\n                 report: Dictionary with summary of the analysis\\n        '\n    report: Dict[str, Any] = {'cluster_analysis': 'smaller', 'suspicious_clusters': 0}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters: np.ndarray = np.zeros((nb_classes, nb_clusters), dtype=object)\n    for (i, clusters) in enumerate(separated_clusters):\n        sizes = np.bincount(clusters)\n        total_dp_in_class = np.sum(sizes)\n        poison_clusters = np.array([int(np.argmin(sizes))])\n        clean_clusters = np.array(list(set(clusters) - set(poison_clusters)))\n        for p_id in poison_clusters:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report_class = {}\n        for cluster_id in range(nb_clusters):\n            ptc = sizes[cluster_id] / total_dp_in_class\n            susp = cluster_id in poison_clusters\n            dict_i = dict(ptc_data_in_cluster=round(ptc, 2), suspicious_cluster=susp)\n            dict_cluster: Dict[str, Dict[str, int]] = {'cluster_' + str(cluster_id): dict_i}\n            report_class.update(dict_cluster)\n        report['Class_' + str(i)] = report_class\n    report['suspicious_clusters'] = report['suspicious_clusters'] + np.sum(summary_poison_clusters)\n    return (np.asarray(all_assigned_clean, dtype=object), summary_poison_clusters, report)",
            "def analyze_by_size(self, separated_clusters: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Designates as poisonous the cluster with less number of items on it.\\n\\n        :param separated_clusters: list where separated_clusters[i] is the cluster assignments for the ith class.\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether\\n                 a given data point was determined to be clean (as opposed to poisonous) and\\n                 summary_poison_clusters: array, where summary_poison_clusters[i][j]=1 if cluster j of class i was\\n                 classified as poison, otherwise 0\\n                 report: Dictionary with summary of the analysis\\n        '\n    report: Dict[str, Any] = {'cluster_analysis': 'smaller', 'suspicious_clusters': 0}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters: np.ndarray = np.zeros((nb_classes, nb_clusters), dtype=object)\n    for (i, clusters) in enumerate(separated_clusters):\n        sizes = np.bincount(clusters)\n        total_dp_in_class = np.sum(sizes)\n        poison_clusters = np.array([int(np.argmin(sizes))])\n        clean_clusters = np.array(list(set(clusters) - set(poison_clusters)))\n        for p_id in poison_clusters:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report_class = {}\n        for cluster_id in range(nb_clusters):\n            ptc = sizes[cluster_id] / total_dp_in_class\n            susp = cluster_id in poison_clusters\n            dict_i = dict(ptc_data_in_cluster=round(ptc, 2), suspicious_cluster=susp)\n            dict_cluster: Dict[str, Dict[str, int]] = {'cluster_' + str(cluster_id): dict_i}\n            report_class.update(dict_cluster)\n        report['Class_' + str(i)] = report_class\n    report['suspicious_clusters'] = report['suspicious_clusters'] + np.sum(summary_poison_clusters)\n    return (np.asarray(all_assigned_clean, dtype=object), summary_poison_clusters, report)"
        ]
    },
    {
        "func_name": "analyze_by_distance",
        "original": "def analyze_by_distance(self, separated_clusters: List[np.ndarray], separated_activations: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    \"\"\"\n        Assigns a cluster as poisonous if its median activation is closer to the median activation for another class\n        than it is to the median activation of its own class. Currently, this function assumes there are only two\n        clusters per class.\n\n        :param separated_clusters: list where separated_clusters[i] is the cluster assignments for the ith class.\n        :param separated_activations: list where separated_activations[i] is a 1D array of [0,1] for [poison,clean].\n        :return: all_assigned_clean, summary_poison_clusters, report:\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\n                 to be clean (as opposed to poisonous) and summary_poison_clusters: array, where\n                 summary_poison_clusters[i][j]=1 if cluster j of class i was classified as poison, otherwise 0\n                 report: Dictionary with summary of the analysis.\n        \"\"\"\n    report: Dict[str, Any] = {'cluster_analysis': 0.0}\n    all_assigned_clean = []\n    cluster_centers = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (_, activations) in enumerate(separated_activations):\n        cluster_centers.append(np.median(activations, axis=0))\n    for (i, (clusters, activation)) in enumerate(zip(separated_clusters, separated_activations)):\n        clusters = np.array(clusters)\n        cluster0_center = np.median(activation[np.where(clusters == 0)], axis=0)\n        cluster1_center = np.median(activation[np.where(clusters == 1)], axis=0)\n        cluster0_distance = np.linalg.norm(cluster0_center - cluster_centers[i])\n        cluster1_distance = np.linalg.norm(cluster1_center - cluster_centers[i])\n        cluster0_is_poison = False\n        cluster1_is_poison = False\n        dict_k = {}\n        dict_cluster_0 = dict(cluster0_distance_to_its_class=str(cluster0_distance))\n        dict_cluster_1 = dict(cluster1_distance_to_its_class=str(cluster1_distance))\n        for (k, center) in enumerate(cluster_centers):\n            if k == i:\n                pass\n            else:\n                cluster0_distance_to_k = np.linalg.norm(cluster0_center - center)\n                cluster1_distance_to_k = np.linalg.norm(cluster1_center - center)\n                if cluster0_distance_to_k < cluster0_distance and cluster1_distance_to_k > cluster1_distance:\n                    cluster0_is_poison = True\n                if cluster1_distance_to_k < cluster1_distance and cluster0_distance_to_k > cluster0_distance:\n                    cluster1_is_poison = True\n                dict_cluster_0['distance_to_class_' + str(k)] = str(cluster0_distance_to_k)\n                dict_cluster_0['suspicious'] = str(cluster0_is_poison)\n                dict_cluster_1['distance_to_class_' + str(k)] = str(cluster1_distance_to_k)\n                dict_cluster_1['suspicious'] = str(cluster1_is_poison)\n                dict_k.update(dict_cluster_0)\n                dict_k.update(dict_cluster_1)\n        report_class = dict(cluster_0=dict_cluster_0, cluster_1=dict_cluster_1)\n        report['Class_' + str(i)] = report_class\n        poison_clusters = []\n        if cluster0_is_poison:\n            poison_clusters.append(0)\n            summary_poison_clusters[i][0] = 1\n        else:\n            summary_poison_clusters[i][0] = 0\n        if cluster1_is_poison:\n            poison_clusters.append(1)\n            summary_poison_clusters[i][1] = 1\n        else:\n            summary_poison_clusters[i][1] = 0\n        clean_clusters = np.array(list(set(clusters) - set(poison_clusters)))\n        assigned_clean = self.assign_class(clusters, clean_clusters, np.array(poison_clusters))\n        all_assigned_clean.append(assigned_clean)\n    all_assigned_clean_array = np.asarray(all_assigned_clean, dtype=object)\n    return (all_assigned_clean_array, summary_poison_clusters, report)",
        "mutated": [
            "def analyze_by_distance(self, separated_clusters: List[np.ndarray], separated_activations: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n    '\\n        Assigns a cluster as poisonous if its median activation is closer to the median activation for another class\\n        than it is to the median activation of its own class. Currently, this function assumes there are only two\\n        clusters per class.\\n\\n        :param separated_clusters: list where separated_clusters[i] is the cluster assignments for the ith class.\\n        :param separated_activations: list where separated_activations[i] is a 1D array of [0,1] for [poison,clean].\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\\n                 to be clean (as opposed to poisonous) and summary_poison_clusters: array, where\\n                 summary_poison_clusters[i][j]=1 if cluster j of class i was classified as poison, otherwise 0\\n                 report: Dictionary with summary of the analysis.\\n        '\n    report: Dict[str, Any] = {'cluster_analysis': 0.0}\n    all_assigned_clean = []\n    cluster_centers = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (_, activations) in enumerate(separated_activations):\n        cluster_centers.append(np.median(activations, axis=0))\n    for (i, (clusters, activation)) in enumerate(zip(separated_clusters, separated_activations)):\n        clusters = np.array(clusters)\n        cluster0_center = np.median(activation[np.where(clusters == 0)], axis=0)\n        cluster1_center = np.median(activation[np.where(clusters == 1)], axis=0)\n        cluster0_distance = np.linalg.norm(cluster0_center - cluster_centers[i])\n        cluster1_distance = np.linalg.norm(cluster1_center - cluster_centers[i])\n        cluster0_is_poison = False\n        cluster1_is_poison = False\n        dict_k = {}\n        dict_cluster_0 = dict(cluster0_distance_to_its_class=str(cluster0_distance))\n        dict_cluster_1 = dict(cluster1_distance_to_its_class=str(cluster1_distance))\n        for (k, center) in enumerate(cluster_centers):\n            if k == i:\n                pass\n            else:\n                cluster0_distance_to_k = np.linalg.norm(cluster0_center - center)\n                cluster1_distance_to_k = np.linalg.norm(cluster1_center - center)\n                if cluster0_distance_to_k < cluster0_distance and cluster1_distance_to_k > cluster1_distance:\n                    cluster0_is_poison = True\n                if cluster1_distance_to_k < cluster1_distance and cluster0_distance_to_k > cluster0_distance:\n                    cluster1_is_poison = True\n                dict_cluster_0['distance_to_class_' + str(k)] = str(cluster0_distance_to_k)\n                dict_cluster_0['suspicious'] = str(cluster0_is_poison)\n                dict_cluster_1['distance_to_class_' + str(k)] = str(cluster1_distance_to_k)\n                dict_cluster_1['suspicious'] = str(cluster1_is_poison)\n                dict_k.update(dict_cluster_0)\n                dict_k.update(dict_cluster_1)\n        report_class = dict(cluster_0=dict_cluster_0, cluster_1=dict_cluster_1)\n        report['Class_' + str(i)] = report_class\n        poison_clusters = []\n        if cluster0_is_poison:\n            poison_clusters.append(0)\n            summary_poison_clusters[i][0] = 1\n        else:\n            summary_poison_clusters[i][0] = 0\n        if cluster1_is_poison:\n            poison_clusters.append(1)\n            summary_poison_clusters[i][1] = 1\n        else:\n            summary_poison_clusters[i][1] = 0\n        clean_clusters = np.array(list(set(clusters) - set(poison_clusters)))\n        assigned_clean = self.assign_class(clusters, clean_clusters, np.array(poison_clusters))\n        all_assigned_clean.append(assigned_clean)\n    all_assigned_clean_array = np.asarray(all_assigned_clean, dtype=object)\n    return (all_assigned_clean_array, summary_poison_clusters, report)",
            "def analyze_by_distance(self, separated_clusters: List[np.ndarray], separated_activations: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Assigns a cluster as poisonous if its median activation is closer to the median activation for another class\\n        than it is to the median activation of its own class. Currently, this function assumes there are only two\\n        clusters per class.\\n\\n        :param separated_clusters: list where separated_clusters[i] is the cluster assignments for the ith class.\\n        :param separated_activations: list where separated_activations[i] is a 1D array of [0,1] for [poison,clean].\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\\n                 to be clean (as opposed to poisonous) and summary_poison_clusters: array, where\\n                 summary_poison_clusters[i][j]=1 if cluster j of class i was classified as poison, otherwise 0\\n                 report: Dictionary with summary of the analysis.\\n        '\n    report: Dict[str, Any] = {'cluster_analysis': 0.0}\n    all_assigned_clean = []\n    cluster_centers = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (_, activations) in enumerate(separated_activations):\n        cluster_centers.append(np.median(activations, axis=0))\n    for (i, (clusters, activation)) in enumerate(zip(separated_clusters, separated_activations)):\n        clusters = np.array(clusters)\n        cluster0_center = np.median(activation[np.where(clusters == 0)], axis=0)\n        cluster1_center = np.median(activation[np.where(clusters == 1)], axis=0)\n        cluster0_distance = np.linalg.norm(cluster0_center - cluster_centers[i])\n        cluster1_distance = np.linalg.norm(cluster1_center - cluster_centers[i])\n        cluster0_is_poison = False\n        cluster1_is_poison = False\n        dict_k = {}\n        dict_cluster_0 = dict(cluster0_distance_to_its_class=str(cluster0_distance))\n        dict_cluster_1 = dict(cluster1_distance_to_its_class=str(cluster1_distance))\n        for (k, center) in enumerate(cluster_centers):\n            if k == i:\n                pass\n            else:\n                cluster0_distance_to_k = np.linalg.norm(cluster0_center - center)\n                cluster1_distance_to_k = np.linalg.norm(cluster1_center - center)\n                if cluster0_distance_to_k < cluster0_distance and cluster1_distance_to_k > cluster1_distance:\n                    cluster0_is_poison = True\n                if cluster1_distance_to_k < cluster1_distance and cluster0_distance_to_k > cluster0_distance:\n                    cluster1_is_poison = True\n                dict_cluster_0['distance_to_class_' + str(k)] = str(cluster0_distance_to_k)\n                dict_cluster_0['suspicious'] = str(cluster0_is_poison)\n                dict_cluster_1['distance_to_class_' + str(k)] = str(cluster1_distance_to_k)\n                dict_cluster_1['suspicious'] = str(cluster1_is_poison)\n                dict_k.update(dict_cluster_0)\n                dict_k.update(dict_cluster_1)\n        report_class = dict(cluster_0=dict_cluster_0, cluster_1=dict_cluster_1)\n        report['Class_' + str(i)] = report_class\n        poison_clusters = []\n        if cluster0_is_poison:\n            poison_clusters.append(0)\n            summary_poison_clusters[i][0] = 1\n        else:\n            summary_poison_clusters[i][0] = 0\n        if cluster1_is_poison:\n            poison_clusters.append(1)\n            summary_poison_clusters[i][1] = 1\n        else:\n            summary_poison_clusters[i][1] = 0\n        clean_clusters = np.array(list(set(clusters) - set(poison_clusters)))\n        assigned_clean = self.assign_class(clusters, clean_clusters, np.array(poison_clusters))\n        all_assigned_clean.append(assigned_clean)\n    all_assigned_clean_array = np.asarray(all_assigned_clean, dtype=object)\n    return (all_assigned_clean_array, summary_poison_clusters, report)",
            "def analyze_by_distance(self, separated_clusters: List[np.ndarray], separated_activations: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Assigns a cluster as poisonous if its median activation is closer to the median activation for another class\\n        than it is to the median activation of its own class. Currently, this function assumes there are only two\\n        clusters per class.\\n\\n        :param separated_clusters: list where separated_clusters[i] is the cluster assignments for the ith class.\\n        :param separated_activations: list where separated_activations[i] is a 1D array of [0,1] for [poison,clean].\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\\n                 to be clean (as opposed to poisonous) and summary_poison_clusters: array, where\\n                 summary_poison_clusters[i][j]=1 if cluster j of class i was classified as poison, otherwise 0\\n                 report: Dictionary with summary of the analysis.\\n        '\n    report: Dict[str, Any] = {'cluster_analysis': 0.0}\n    all_assigned_clean = []\n    cluster_centers = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (_, activations) in enumerate(separated_activations):\n        cluster_centers.append(np.median(activations, axis=0))\n    for (i, (clusters, activation)) in enumerate(zip(separated_clusters, separated_activations)):\n        clusters = np.array(clusters)\n        cluster0_center = np.median(activation[np.where(clusters == 0)], axis=0)\n        cluster1_center = np.median(activation[np.where(clusters == 1)], axis=0)\n        cluster0_distance = np.linalg.norm(cluster0_center - cluster_centers[i])\n        cluster1_distance = np.linalg.norm(cluster1_center - cluster_centers[i])\n        cluster0_is_poison = False\n        cluster1_is_poison = False\n        dict_k = {}\n        dict_cluster_0 = dict(cluster0_distance_to_its_class=str(cluster0_distance))\n        dict_cluster_1 = dict(cluster1_distance_to_its_class=str(cluster1_distance))\n        for (k, center) in enumerate(cluster_centers):\n            if k == i:\n                pass\n            else:\n                cluster0_distance_to_k = np.linalg.norm(cluster0_center - center)\n                cluster1_distance_to_k = np.linalg.norm(cluster1_center - center)\n                if cluster0_distance_to_k < cluster0_distance and cluster1_distance_to_k > cluster1_distance:\n                    cluster0_is_poison = True\n                if cluster1_distance_to_k < cluster1_distance and cluster0_distance_to_k > cluster0_distance:\n                    cluster1_is_poison = True\n                dict_cluster_0['distance_to_class_' + str(k)] = str(cluster0_distance_to_k)\n                dict_cluster_0['suspicious'] = str(cluster0_is_poison)\n                dict_cluster_1['distance_to_class_' + str(k)] = str(cluster1_distance_to_k)\n                dict_cluster_1['suspicious'] = str(cluster1_is_poison)\n                dict_k.update(dict_cluster_0)\n                dict_k.update(dict_cluster_1)\n        report_class = dict(cluster_0=dict_cluster_0, cluster_1=dict_cluster_1)\n        report['Class_' + str(i)] = report_class\n        poison_clusters = []\n        if cluster0_is_poison:\n            poison_clusters.append(0)\n            summary_poison_clusters[i][0] = 1\n        else:\n            summary_poison_clusters[i][0] = 0\n        if cluster1_is_poison:\n            poison_clusters.append(1)\n            summary_poison_clusters[i][1] = 1\n        else:\n            summary_poison_clusters[i][1] = 0\n        clean_clusters = np.array(list(set(clusters) - set(poison_clusters)))\n        assigned_clean = self.assign_class(clusters, clean_clusters, np.array(poison_clusters))\n        all_assigned_clean.append(assigned_clean)\n    all_assigned_clean_array = np.asarray(all_assigned_clean, dtype=object)\n    return (all_assigned_clean_array, summary_poison_clusters, report)",
            "def analyze_by_distance(self, separated_clusters: List[np.ndarray], separated_activations: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Assigns a cluster as poisonous if its median activation is closer to the median activation for another class\\n        than it is to the median activation of its own class. Currently, this function assumes there are only two\\n        clusters per class.\\n\\n        :param separated_clusters: list where separated_clusters[i] is the cluster assignments for the ith class.\\n        :param separated_activations: list where separated_activations[i] is a 1D array of [0,1] for [poison,clean].\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\\n                 to be clean (as opposed to poisonous) and summary_poison_clusters: array, where\\n                 summary_poison_clusters[i][j]=1 if cluster j of class i was classified as poison, otherwise 0\\n                 report: Dictionary with summary of the analysis.\\n        '\n    report: Dict[str, Any] = {'cluster_analysis': 0.0}\n    all_assigned_clean = []\n    cluster_centers = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (_, activations) in enumerate(separated_activations):\n        cluster_centers.append(np.median(activations, axis=0))\n    for (i, (clusters, activation)) in enumerate(zip(separated_clusters, separated_activations)):\n        clusters = np.array(clusters)\n        cluster0_center = np.median(activation[np.where(clusters == 0)], axis=0)\n        cluster1_center = np.median(activation[np.where(clusters == 1)], axis=0)\n        cluster0_distance = np.linalg.norm(cluster0_center - cluster_centers[i])\n        cluster1_distance = np.linalg.norm(cluster1_center - cluster_centers[i])\n        cluster0_is_poison = False\n        cluster1_is_poison = False\n        dict_k = {}\n        dict_cluster_0 = dict(cluster0_distance_to_its_class=str(cluster0_distance))\n        dict_cluster_1 = dict(cluster1_distance_to_its_class=str(cluster1_distance))\n        for (k, center) in enumerate(cluster_centers):\n            if k == i:\n                pass\n            else:\n                cluster0_distance_to_k = np.linalg.norm(cluster0_center - center)\n                cluster1_distance_to_k = np.linalg.norm(cluster1_center - center)\n                if cluster0_distance_to_k < cluster0_distance and cluster1_distance_to_k > cluster1_distance:\n                    cluster0_is_poison = True\n                if cluster1_distance_to_k < cluster1_distance and cluster0_distance_to_k > cluster0_distance:\n                    cluster1_is_poison = True\n                dict_cluster_0['distance_to_class_' + str(k)] = str(cluster0_distance_to_k)\n                dict_cluster_0['suspicious'] = str(cluster0_is_poison)\n                dict_cluster_1['distance_to_class_' + str(k)] = str(cluster1_distance_to_k)\n                dict_cluster_1['suspicious'] = str(cluster1_is_poison)\n                dict_k.update(dict_cluster_0)\n                dict_k.update(dict_cluster_1)\n        report_class = dict(cluster_0=dict_cluster_0, cluster_1=dict_cluster_1)\n        report['Class_' + str(i)] = report_class\n        poison_clusters = []\n        if cluster0_is_poison:\n            poison_clusters.append(0)\n            summary_poison_clusters[i][0] = 1\n        else:\n            summary_poison_clusters[i][0] = 0\n        if cluster1_is_poison:\n            poison_clusters.append(1)\n            summary_poison_clusters[i][1] = 1\n        else:\n            summary_poison_clusters[i][1] = 0\n        clean_clusters = np.array(list(set(clusters) - set(poison_clusters)))\n        assigned_clean = self.assign_class(clusters, clean_clusters, np.array(poison_clusters))\n        all_assigned_clean.append(assigned_clean)\n    all_assigned_clean_array = np.asarray(all_assigned_clean, dtype=object)\n    return (all_assigned_clean_array, summary_poison_clusters, report)",
            "def analyze_by_distance(self, separated_clusters: List[np.ndarray], separated_activations: List[np.ndarray]) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Assigns a cluster as poisonous if its median activation is closer to the median activation for another class\\n        than it is to the median activation of its own class. Currently, this function assumes there are only two\\n        clusters per class.\\n\\n        :param separated_clusters: list where separated_clusters[i] is the cluster assignments for the ith class.\\n        :param separated_activations: list where separated_activations[i] is a 1D array of [0,1] for [poison,clean].\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\\n                 to be clean (as opposed to poisonous) and summary_poison_clusters: array, where\\n                 summary_poison_clusters[i][j]=1 if cluster j of class i was classified as poison, otherwise 0\\n                 report: Dictionary with summary of the analysis.\\n        '\n    report: Dict[str, Any] = {'cluster_analysis': 0.0}\n    all_assigned_clean = []\n    cluster_centers = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (_, activations) in enumerate(separated_activations):\n        cluster_centers.append(np.median(activations, axis=0))\n    for (i, (clusters, activation)) in enumerate(zip(separated_clusters, separated_activations)):\n        clusters = np.array(clusters)\n        cluster0_center = np.median(activation[np.where(clusters == 0)], axis=0)\n        cluster1_center = np.median(activation[np.where(clusters == 1)], axis=0)\n        cluster0_distance = np.linalg.norm(cluster0_center - cluster_centers[i])\n        cluster1_distance = np.linalg.norm(cluster1_center - cluster_centers[i])\n        cluster0_is_poison = False\n        cluster1_is_poison = False\n        dict_k = {}\n        dict_cluster_0 = dict(cluster0_distance_to_its_class=str(cluster0_distance))\n        dict_cluster_1 = dict(cluster1_distance_to_its_class=str(cluster1_distance))\n        for (k, center) in enumerate(cluster_centers):\n            if k == i:\n                pass\n            else:\n                cluster0_distance_to_k = np.linalg.norm(cluster0_center - center)\n                cluster1_distance_to_k = np.linalg.norm(cluster1_center - center)\n                if cluster0_distance_to_k < cluster0_distance and cluster1_distance_to_k > cluster1_distance:\n                    cluster0_is_poison = True\n                if cluster1_distance_to_k < cluster1_distance and cluster0_distance_to_k > cluster0_distance:\n                    cluster1_is_poison = True\n                dict_cluster_0['distance_to_class_' + str(k)] = str(cluster0_distance_to_k)\n                dict_cluster_0['suspicious'] = str(cluster0_is_poison)\n                dict_cluster_1['distance_to_class_' + str(k)] = str(cluster1_distance_to_k)\n                dict_cluster_1['suspicious'] = str(cluster1_is_poison)\n                dict_k.update(dict_cluster_0)\n                dict_k.update(dict_cluster_1)\n        report_class = dict(cluster_0=dict_cluster_0, cluster_1=dict_cluster_1)\n        report['Class_' + str(i)] = report_class\n        poison_clusters = []\n        if cluster0_is_poison:\n            poison_clusters.append(0)\n            summary_poison_clusters[i][0] = 1\n        else:\n            summary_poison_clusters[i][0] = 0\n        if cluster1_is_poison:\n            poison_clusters.append(1)\n            summary_poison_clusters[i][1] = 1\n        else:\n            summary_poison_clusters[i][1] = 0\n        clean_clusters = np.array(list(set(clusters) - set(poison_clusters)))\n        assigned_clean = self.assign_class(clusters, clean_clusters, np.array(poison_clusters))\n        all_assigned_clean.append(assigned_clean)\n    all_assigned_clean_array = np.asarray(all_assigned_clean, dtype=object)\n    return (all_assigned_clean_array, summary_poison_clusters, report)"
        ]
    },
    {
        "func_name": "analyze_by_relative_size",
        "original": "def analyze_by_relative_size(self, separated_clusters: List[np.ndarray], size_threshold: float=0.35, r_size: int=2) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    \"\"\"\n        Assigns a cluster as poisonous if the smaller one contains less than threshold of the data.\n        This method assumes only 2 clusters\n\n        :param separated_clusters: List where `separated_clusters[i]` is the cluster assignments for the ith class.\n        :param size_threshold: Threshold used to define when a cluster is substantially smaller.\n        :param r_size: Round number used for size rate comparisons.\n        :return: all_assigned_clean, summary_poison_clusters, report:\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\n                 to be clean (as opposed to poisonous) and summary_poison_clusters: array, where\n                 summary_poison_clusters[i][j]=1 if cluster j of class i was classified as poison, otherwise 0\n                 report: Dictionary with summary of the analysis.\n        \"\"\"\n    size_threshold = round(size_threshold, r_size)\n    report: Dict[str, Any] = {'cluster_analysis': 'relative_size', 'suspicious_clusters': 0, 'size_threshold': size_threshold}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (i, clusters) in enumerate(separated_clusters):\n        sizes = np.bincount(clusters)\n        total_dp_in_class = np.sum(sizes)\n        if np.size(sizes) > 2:\n            raise ValueError(' RelativeSizeAnalyzer does not support more than two clusters.')\n        percentages = np.round(sizes / float(np.sum(sizes)), r_size)\n        poison_clusters = np.where(percentages < size_threshold)\n        clean_clusters = np.where(percentages >= size_threshold)\n        for p_id in poison_clusters[0]:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters[0]:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report_class = {}\n        for cluster_id in range(nb_clusters):\n            ptc = sizes[cluster_id] / total_dp_in_class\n            susp = cluster_id in poison_clusters\n            dict_i = dict(ptc_data_in_cluster=round(ptc, 2), suspicious_cluster=susp)\n            dict_cluster = {'cluster_' + str(cluster_id): dict_i}\n            report_class.update(dict_cluster)\n        report['Class_' + str(i)] = report_class\n    report['suspicious_clusters'] = report['suspicious_clusters'] + np.sum(summary_poison_clusters).item()\n    return (np.asarray(all_assigned_clean), summary_poison_clusters, report)",
        "mutated": [
            "def analyze_by_relative_size(self, separated_clusters: List[np.ndarray], size_threshold: float=0.35, r_size: int=2) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n    '\\n        Assigns a cluster as poisonous if the smaller one contains less than threshold of the data.\\n        This method assumes only 2 clusters\\n\\n        :param separated_clusters: List where `separated_clusters[i]` is the cluster assignments for the ith class.\\n        :param size_threshold: Threshold used to define when a cluster is substantially smaller.\\n        :param r_size: Round number used for size rate comparisons.\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\\n                 to be clean (as opposed to poisonous) and summary_poison_clusters: array, where\\n                 summary_poison_clusters[i][j]=1 if cluster j of class i was classified as poison, otherwise 0\\n                 report: Dictionary with summary of the analysis.\\n        '\n    size_threshold = round(size_threshold, r_size)\n    report: Dict[str, Any] = {'cluster_analysis': 'relative_size', 'suspicious_clusters': 0, 'size_threshold': size_threshold}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (i, clusters) in enumerate(separated_clusters):\n        sizes = np.bincount(clusters)\n        total_dp_in_class = np.sum(sizes)\n        if np.size(sizes) > 2:\n            raise ValueError(' RelativeSizeAnalyzer does not support more than two clusters.')\n        percentages = np.round(sizes / float(np.sum(sizes)), r_size)\n        poison_clusters = np.where(percentages < size_threshold)\n        clean_clusters = np.where(percentages >= size_threshold)\n        for p_id in poison_clusters[0]:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters[0]:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report_class = {}\n        for cluster_id in range(nb_clusters):\n            ptc = sizes[cluster_id] / total_dp_in_class\n            susp = cluster_id in poison_clusters\n            dict_i = dict(ptc_data_in_cluster=round(ptc, 2), suspicious_cluster=susp)\n            dict_cluster = {'cluster_' + str(cluster_id): dict_i}\n            report_class.update(dict_cluster)\n        report['Class_' + str(i)] = report_class\n    report['suspicious_clusters'] = report['suspicious_clusters'] + np.sum(summary_poison_clusters).item()\n    return (np.asarray(all_assigned_clean), summary_poison_clusters, report)",
            "def analyze_by_relative_size(self, separated_clusters: List[np.ndarray], size_threshold: float=0.35, r_size: int=2) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Assigns a cluster as poisonous if the smaller one contains less than threshold of the data.\\n        This method assumes only 2 clusters\\n\\n        :param separated_clusters: List where `separated_clusters[i]` is the cluster assignments for the ith class.\\n        :param size_threshold: Threshold used to define when a cluster is substantially smaller.\\n        :param r_size: Round number used for size rate comparisons.\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\\n                 to be clean (as opposed to poisonous) and summary_poison_clusters: array, where\\n                 summary_poison_clusters[i][j]=1 if cluster j of class i was classified as poison, otherwise 0\\n                 report: Dictionary with summary of the analysis.\\n        '\n    size_threshold = round(size_threshold, r_size)\n    report: Dict[str, Any] = {'cluster_analysis': 'relative_size', 'suspicious_clusters': 0, 'size_threshold': size_threshold}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (i, clusters) in enumerate(separated_clusters):\n        sizes = np.bincount(clusters)\n        total_dp_in_class = np.sum(sizes)\n        if np.size(sizes) > 2:\n            raise ValueError(' RelativeSizeAnalyzer does not support more than two clusters.')\n        percentages = np.round(sizes / float(np.sum(sizes)), r_size)\n        poison_clusters = np.where(percentages < size_threshold)\n        clean_clusters = np.where(percentages >= size_threshold)\n        for p_id in poison_clusters[0]:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters[0]:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report_class = {}\n        for cluster_id in range(nb_clusters):\n            ptc = sizes[cluster_id] / total_dp_in_class\n            susp = cluster_id in poison_clusters\n            dict_i = dict(ptc_data_in_cluster=round(ptc, 2), suspicious_cluster=susp)\n            dict_cluster = {'cluster_' + str(cluster_id): dict_i}\n            report_class.update(dict_cluster)\n        report['Class_' + str(i)] = report_class\n    report['suspicious_clusters'] = report['suspicious_clusters'] + np.sum(summary_poison_clusters).item()\n    return (np.asarray(all_assigned_clean), summary_poison_clusters, report)",
            "def analyze_by_relative_size(self, separated_clusters: List[np.ndarray], size_threshold: float=0.35, r_size: int=2) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Assigns a cluster as poisonous if the smaller one contains less than threshold of the data.\\n        This method assumes only 2 clusters\\n\\n        :param separated_clusters: List where `separated_clusters[i]` is the cluster assignments for the ith class.\\n        :param size_threshold: Threshold used to define when a cluster is substantially smaller.\\n        :param r_size: Round number used for size rate comparisons.\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\\n                 to be clean (as opposed to poisonous) and summary_poison_clusters: array, where\\n                 summary_poison_clusters[i][j]=1 if cluster j of class i was classified as poison, otherwise 0\\n                 report: Dictionary with summary of the analysis.\\n        '\n    size_threshold = round(size_threshold, r_size)\n    report: Dict[str, Any] = {'cluster_analysis': 'relative_size', 'suspicious_clusters': 0, 'size_threshold': size_threshold}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (i, clusters) in enumerate(separated_clusters):\n        sizes = np.bincount(clusters)\n        total_dp_in_class = np.sum(sizes)\n        if np.size(sizes) > 2:\n            raise ValueError(' RelativeSizeAnalyzer does not support more than two clusters.')\n        percentages = np.round(sizes / float(np.sum(sizes)), r_size)\n        poison_clusters = np.where(percentages < size_threshold)\n        clean_clusters = np.where(percentages >= size_threshold)\n        for p_id in poison_clusters[0]:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters[0]:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report_class = {}\n        for cluster_id in range(nb_clusters):\n            ptc = sizes[cluster_id] / total_dp_in_class\n            susp = cluster_id in poison_clusters\n            dict_i = dict(ptc_data_in_cluster=round(ptc, 2), suspicious_cluster=susp)\n            dict_cluster = {'cluster_' + str(cluster_id): dict_i}\n            report_class.update(dict_cluster)\n        report['Class_' + str(i)] = report_class\n    report['suspicious_clusters'] = report['suspicious_clusters'] + np.sum(summary_poison_clusters).item()\n    return (np.asarray(all_assigned_clean), summary_poison_clusters, report)",
            "def analyze_by_relative_size(self, separated_clusters: List[np.ndarray], size_threshold: float=0.35, r_size: int=2) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Assigns a cluster as poisonous if the smaller one contains less than threshold of the data.\\n        This method assumes only 2 clusters\\n\\n        :param separated_clusters: List where `separated_clusters[i]` is the cluster assignments for the ith class.\\n        :param size_threshold: Threshold used to define when a cluster is substantially smaller.\\n        :param r_size: Round number used for size rate comparisons.\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\\n                 to be clean (as opposed to poisonous) and summary_poison_clusters: array, where\\n                 summary_poison_clusters[i][j]=1 if cluster j of class i was classified as poison, otherwise 0\\n                 report: Dictionary with summary of the analysis.\\n        '\n    size_threshold = round(size_threshold, r_size)\n    report: Dict[str, Any] = {'cluster_analysis': 'relative_size', 'suspicious_clusters': 0, 'size_threshold': size_threshold}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (i, clusters) in enumerate(separated_clusters):\n        sizes = np.bincount(clusters)\n        total_dp_in_class = np.sum(sizes)\n        if np.size(sizes) > 2:\n            raise ValueError(' RelativeSizeAnalyzer does not support more than two clusters.')\n        percentages = np.round(sizes / float(np.sum(sizes)), r_size)\n        poison_clusters = np.where(percentages < size_threshold)\n        clean_clusters = np.where(percentages >= size_threshold)\n        for p_id in poison_clusters[0]:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters[0]:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report_class = {}\n        for cluster_id in range(nb_clusters):\n            ptc = sizes[cluster_id] / total_dp_in_class\n            susp = cluster_id in poison_clusters\n            dict_i = dict(ptc_data_in_cluster=round(ptc, 2), suspicious_cluster=susp)\n            dict_cluster = {'cluster_' + str(cluster_id): dict_i}\n            report_class.update(dict_cluster)\n        report['Class_' + str(i)] = report_class\n    report['suspicious_clusters'] = report['suspicious_clusters'] + np.sum(summary_poison_clusters).item()\n    return (np.asarray(all_assigned_clean), summary_poison_clusters, report)",
            "def analyze_by_relative_size(self, separated_clusters: List[np.ndarray], size_threshold: float=0.35, r_size: int=2) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Assigns a cluster as poisonous if the smaller one contains less than threshold of the data.\\n        This method assumes only 2 clusters\\n\\n        :param separated_clusters: List where `separated_clusters[i]` is the cluster assignments for the ith class.\\n        :param size_threshold: Threshold used to define when a cluster is substantially smaller.\\n        :param r_size: Round number used for size rate comparisons.\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\\n                 to be clean (as opposed to poisonous) and summary_poison_clusters: array, where\\n                 summary_poison_clusters[i][j]=1 if cluster j of class i was classified as poison, otherwise 0\\n                 report: Dictionary with summary of the analysis.\\n        '\n    size_threshold = round(size_threshold, r_size)\n    report: Dict[str, Any] = {'cluster_analysis': 'relative_size', 'suspicious_clusters': 0, 'size_threshold': size_threshold}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (i, clusters) in enumerate(separated_clusters):\n        sizes = np.bincount(clusters)\n        total_dp_in_class = np.sum(sizes)\n        if np.size(sizes) > 2:\n            raise ValueError(' RelativeSizeAnalyzer does not support more than two clusters.')\n        percentages = np.round(sizes / float(np.sum(sizes)), r_size)\n        poison_clusters = np.where(percentages < size_threshold)\n        clean_clusters = np.where(percentages >= size_threshold)\n        for p_id in poison_clusters[0]:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters[0]:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report_class = {}\n        for cluster_id in range(nb_clusters):\n            ptc = sizes[cluster_id] / total_dp_in_class\n            susp = cluster_id in poison_clusters\n            dict_i = dict(ptc_data_in_cluster=round(ptc, 2), suspicious_cluster=susp)\n            dict_cluster = {'cluster_' + str(cluster_id): dict_i}\n            report_class.update(dict_cluster)\n        report['Class_' + str(i)] = report_class\n    report['suspicious_clusters'] = report['suspicious_clusters'] + np.sum(summary_poison_clusters).item()\n    return (np.asarray(all_assigned_clean), summary_poison_clusters, report)"
        ]
    },
    {
        "func_name": "analyze_by_silhouette_score",
        "original": "def analyze_by_silhouette_score(self, separated_clusters: list, reduced_activations_by_class: list, size_threshold: float=0.35, silhouette_threshold: float=0.1, r_size: int=2, r_silhouette: int=4) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    \"\"\"\n        Analyzes clusters to determine level of suspiciousness of poison based on the cluster's relative size\n        and silhouette score.\n        Computes a silhouette score for each class to determine how cohesive resulting clusters are.\n        A low silhouette score indicates that the clustering does not fit the data well, and the class can be considered\n        to be un-poisoned. Conversely, a high silhouette score indicates that the clusters reflect true splits in the\n        data.\n        The method concludes that a cluster is poison based on the silhouette score and the cluster relative size.\n        If the relative size is too small, below a size_threshold and at the same time\n        the silhouette score is higher than silhouette_threshold, the cluster is classified as poisonous.\n        If the above thresholds are not provided, the default ones will be used.\n\n        :param separated_clusters: list where `separated_clusters[i]` is the cluster assignments for the ith class.\n        :param reduced_activations_by_class: list where separated_activations[i] is a 1D array of [0,1] for\n               [poison,clean].\n        :param size_threshold: (optional) threshold used to define when a cluster is substantially smaller. A default\n        value is used if the parameter is not provided.\n        :param silhouette_threshold: (optional) threshold used to define when a cluster is cohesive. Default\n        value is used if the parameter is not provided.\n        :param r_size: Round number used for size rate comparisons.\n        :param r_silhouette: Round number used for silhouette rate comparisons.\n        :return: all_assigned_clean, summary_poison_clusters, report:\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\n                 to be clean (as opposed to poisonous) summary_poison_clusters: array, where\n                 summary_poison_clusters[i][j]=1 if cluster j of class j was classified as poison\n                 report: Dictionary with summary of the analysis.\n        \"\"\"\n    from sklearn.metrics import silhouette_score\n    size_threshold = round(size_threshold, r_size)\n    silhouette_threshold = round(silhouette_threshold, r_silhouette)\n    report: Dict[str, Any] = {'cluster_analysis': 'silhouette_score', 'size_threshold': str(size_threshold), 'silhouette_threshold': str(silhouette_threshold)}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (i, (clusters, activations)) in enumerate(zip(separated_clusters, reduced_activations_by_class)):\n        bins = np.bincount(clusters)\n        if np.size(bins) > 2:\n            raise ValueError('Analyzer does not support more than two clusters.')\n        percentages = np.round(bins / float(np.sum(bins)), r_size)\n        poison_clusters = np.where(percentages < size_threshold)\n        clean_clusters = np.where(percentages >= size_threshold)\n        silhouette_avg = round(silhouette_score(activations, clusters), r_silhouette)\n        dict_i: Dict[str, Any] = dict(sizes_clusters=str(bins), ptc_cluster=str(percentages), avg_silhouette_score=str(silhouette_avg))\n        if np.shape(poison_clusters)[1] != 0:\n            if silhouette_avg > silhouette_threshold:\n                clean_clusters = np.where(percentages < size_threshold)\n                logger.info('computed silhouette score: %s', silhouette_avg)\n                dict_i.update(suspicious=True)\n            else:\n                poison_clusters = [[]]\n                clean_clusters = np.where(percentages >= 0)\n                dict_i.update(suspicious=False)\n        else:\n            dict_i.update(suspicious=False)\n        report_class: Dict[str, Dict[str, bool]] = {'class_' + str(i): dict_i}\n        for p_id in poison_clusters[0]:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters[0]:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report.update(report_class)\n    return (np.asarray(all_assigned_clean), summary_poison_clusters, report)",
        "mutated": [
            "def analyze_by_silhouette_score(self, separated_clusters: list, reduced_activations_by_class: list, size_threshold: float=0.35, silhouette_threshold: float=0.1, r_size: int=2, r_silhouette: int=4) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n    \"\\n        Analyzes clusters to determine level of suspiciousness of poison based on the cluster's relative size\\n        and silhouette score.\\n        Computes a silhouette score for each class to determine how cohesive resulting clusters are.\\n        A low silhouette score indicates that the clustering does not fit the data well, and the class can be considered\\n        to be un-poisoned. Conversely, a high silhouette score indicates that the clusters reflect true splits in the\\n        data.\\n        The method concludes that a cluster is poison based on the silhouette score and the cluster relative size.\\n        If the relative size is too small, below a size_threshold and at the same time\\n        the silhouette score is higher than silhouette_threshold, the cluster is classified as poisonous.\\n        If the above thresholds are not provided, the default ones will be used.\\n\\n        :param separated_clusters: list where `separated_clusters[i]` is the cluster assignments for the ith class.\\n        :param reduced_activations_by_class: list where separated_activations[i] is a 1D array of [0,1] for\\n               [poison,clean].\\n        :param size_threshold: (optional) threshold used to define when a cluster is substantially smaller. A default\\n        value is used if the parameter is not provided.\\n        :param silhouette_threshold: (optional) threshold used to define when a cluster is cohesive. Default\\n        value is used if the parameter is not provided.\\n        :param r_size: Round number used for size rate comparisons.\\n        :param r_silhouette: Round number used for silhouette rate comparisons.\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\\n                 to be clean (as opposed to poisonous) summary_poison_clusters: array, where\\n                 summary_poison_clusters[i][j]=1 if cluster j of class j was classified as poison\\n                 report: Dictionary with summary of the analysis.\\n        \"\n    from sklearn.metrics import silhouette_score\n    size_threshold = round(size_threshold, r_size)\n    silhouette_threshold = round(silhouette_threshold, r_silhouette)\n    report: Dict[str, Any] = {'cluster_analysis': 'silhouette_score', 'size_threshold': str(size_threshold), 'silhouette_threshold': str(silhouette_threshold)}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (i, (clusters, activations)) in enumerate(zip(separated_clusters, reduced_activations_by_class)):\n        bins = np.bincount(clusters)\n        if np.size(bins) > 2:\n            raise ValueError('Analyzer does not support more than two clusters.')\n        percentages = np.round(bins / float(np.sum(bins)), r_size)\n        poison_clusters = np.where(percentages < size_threshold)\n        clean_clusters = np.where(percentages >= size_threshold)\n        silhouette_avg = round(silhouette_score(activations, clusters), r_silhouette)\n        dict_i: Dict[str, Any] = dict(sizes_clusters=str(bins), ptc_cluster=str(percentages), avg_silhouette_score=str(silhouette_avg))\n        if np.shape(poison_clusters)[1] != 0:\n            if silhouette_avg > silhouette_threshold:\n                clean_clusters = np.where(percentages < size_threshold)\n                logger.info('computed silhouette score: %s', silhouette_avg)\n                dict_i.update(suspicious=True)\n            else:\n                poison_clusters = [[]]\n                clean_clusters = np.where(percentages >= 0)\n                dict_i.update(suspicious=False)\n        else:\n            dict_i.update(suspicious=False)\n        report_class: Dict[str, Dict[str, bool]] = {'class_' + str(i): dict_i}\n        for p_id in poison_clusters[0]:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters[0]:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report.update(report_class)\n    return (np.asarray(all_assigned_clean), summary_poison_clusters, report)",
            "def analyze_by_silhouette_score(self, separated_clusters: list, reduced_activations_by_class: list, size_threshold: float=0.35, silhouette_threshold: float=0.1, r_size: int=2, r_silhouette: int=4) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Analyzes clusters to determine level of suspiciousness of poison based on the cluster's relative size\\n        and silhouette score.\\n        Computes a silhouette score for each class to determine how cohesive resulting clusters are.\\n        A low silhouette score indicates that the clustering does not fit the data well, and the class can be considered\\n        to be un-poisoned. Conversely, a high silhouette score indicates that the clusters reflect true splits in the\\n        data.\\n        The method concludes that a cluster is poison based on the silhouette score and the cluster relative size.\\n        If the relative size is too small, below a size_threshold and at the same time\\n        the silhouette score is higher than silhouette_threshold, the cluster is classified as poisonous.\\n        If the above thresholds are not provided, the default ones will be used.\\n\\n        :param separated_clusters: list where `separated_clusters[i]` is the cluster assignments for the ith class.\\n        :param reduced_activations_by_class: list where separated_activations[i] is a 1D array of [0,1] for\\n               [poison,clean].\\n        :param size_threshold: (optional) threshold used to define when a cluster is substantially smaller. A default\\n        value is used if the parameter is not provided.\\n        :param silhouette_threshold: (optional) threshold used to define when a cluster is cohesive. Default\\n        value is used if the parameter is not provided.\\n        :param r_size: Round number used for size rate comparisons.\\n        :param r_silhouette: Round number used for silhouette rate comparisons.\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\\n                 to be clean (as opposed to poisonous) summary_poison_clusters: array, where\\n                 summary_poison_clusters[i][j]=1 if cluster j of class j was classified as poison\\n                 report: Dictionary with summary of the analysis.\\n        \"\n    from sklearn.metrics import silhouette_score\n    size_threshold = round(size_threshold, r_size)\n    silhouette_threshold = round(silhouette_threshold, r_silhouette)\n    report: Dict[str, Any] = {'cluster_analysis': 'silhouette_score', 'size_threshold': str(size_threshold), 'silhouette_threshold': str(silhouette_threshold)}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (i, (clusters, activations)) in enumerate(zip(separated_clusters, reduced_activations_by_class)):\n        bins = np.bincount(clusters)\n        if np.size(bins) > 2:\n            raise ValueError('Analyzer does not support more than two clusters.')\n        percentages = np.round(bins / float(np.sum(bins)), r_size)\n        poison_clusters = np.where(percentages < size_threshold)\n        clean_clusters = np.where(percentages >= size_threshold)\n        silhouette_avg = round(silhouette_score(activations, clusters), r_silhouette)\n        dict_i: Dict[str, Any] = dict(sizes_clusters=str(bins), ptc_cluster=str(percentages), avg_silhouette_score=str(silhouette_avg))\n        if np.shape(poison_clusters)[1] != 0:\n            if silhouette_avg > silhouette_threshold:\n                clean_clusters = np.where(percentages < size_threshold)\n                logger.info('computed silhouette score: %s', silhouette_avg)\n                dict_i.update(suspicious=True)\n            else:\n                poison_clusters = [[]]\n                clean_clusters = np.where(percentages >= 0)\n                dict_i.update(suspicious=False)\n        else:\n            dict_i.update(suspicious=False)\n        report_class: Dict[str, Dict[str, bool]] = {'class_' + str(i): dict_i}\n        for p_id in poison_clusters[0]:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters[0]:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report.update(report_class)\n    return (np.asarray(all_assigned_clean), summary_poison_clusters, report)",
            "def analyze_by_silhouette_score(self, separated_clusters: list, reduced_activations_by_class: list, size_threshold: float=0.35, silhouette_threshold: float=0.1, r_size: int=2, r_silhouette: int=4) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Analyzes clusters to determine level of suspiciousness of poison based on the cluster's relative size\\n        and silhouette score.\\n        Computes a silhouette score for each class to determine how cohesive resulting clusters are.\\n        A low silhouette score indicates that the clustering does not fit the data well, and the class can be considered\\n        to be un-poisoned. Conversely, a high silhouette score indicates that the clusters reflect true splits in the\\n        data.\\n        The method concludes that a cluster is poison based on the silhouette score and the cluster relative size.\\n        If the relative size is too small, below a size_threshold and at the same time\\n        the silhouette score is higher than silhouette_threshold, the cluster is classified as poisonous.\\n        If the above thresholds are not provided, the default ones will be used.\\n\\n        :param separated_clusters: list where `separated_clusters[i]` is the cluster assignments for the ith class.\\n        :param reduced_activations_by_class: list where separated_activations[i] is a 1D array of [0,1] for\\n               [poison,clean].\\n        :param size_threshold: (optional) threshold used to define when a cluster is substantially smaller. A default\\n        value is used if the parameter is not provided.\\n        :param silhouette_threshold: (optional) threshold used to define when a cluster is cohesive. Default\\n        value is used if the parameter is not provided.\\n        :param r_size: Round number used for size rate comparisons.\\n        :param r_silhouette: Round number used for silhouette rate comparisons.\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\\n                 to be clean (as opposed to poisonous) summary_poison_clusters: array, where\\n                 summary_poison_clusters[i][j]=1 if cluster j of class j was classified as poison\\n                 report: Dictionary with summary of the analysis.\\n        \"\n    from sklearn.metrics import silhouette_score\n    size_threshold = round(size_threshold, r_size)\n    silhouette_threshold = round(silhouette_threshold, r_silhouette)\n    report: Dict[str, Any] = {'cluster_analysis': 'silhouette_score', 'size_threshold': str(size_threshold), 'silhouette_threshold': str(silhouette_threshold)}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (i, (clusters, activations)) in enumerate(zip(separated_clusters, reduced_activations_by_class)):\n        bins = np.bincount(clusters)\n        if np.size(bins) > 2:\n            raise ValueError('Analyzer does not support more than two clusters.')\n        percentages = np.round(bins / float(np.sum(bins)), r_size)\n        poison_clusters = np.where(percentages < size_threshold)\n        clean_clusters = np.where(percentages >= size_threshold)\n        silhouette_avg = round(silhouette_score(activations, clusters), r_silhouette)\n        dict_i: Dict[str, Any] = dict(sizes_clusters=str(bins), ptc_cluster=str(percentages), avg_silhouette_score=str(silhouette_avg))\n        if np.shape(poison_clusters)[1] != 0:\n            if silhouette_avg > silhouette_threshold:\n                clean_clusters = np.where(percentages < size_threshold)\n                logger.info('computed silhouette score: %s', silhouette_avg)\n                dict_i.update(suspicious=True)\n            else:\n                poison_clusters = [[]]\n                clean_clusters = np.where(percentages >= 0)\n                dict_i.update(suspicious=False)\n        else:\n            dict_i.update(suspicious=False)\n        report_class: Dict[str, Dict[str, bool]] = {'class_' + str(i): dict_i}\n        for p_id in poison_clusters[0]:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters[0]:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report.update(report_class)\n    return (np.asarray(all_assigned_clean), summary_poison_clusters, report)",
            "def analyze_by_silhouette_score(self, separated_clusters: list, reduced_activations_by_class: list, size_threshold: float=0.35, silhouette_threshold: float=0.1, r_size: int=2, r_silhouette: int=4) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Analyzes clusters to determine level of suspiciousness of poison based on the cluster's relative size\\n        and silhouette score.\\n        Computes a silhouette score for each class to determine how cohesive resulting clusters are.\\n        A low silhouette score indicates that the clustering does not fit the data well, and the class can be considered\\n        to be un-poisoned. Conversely, a high silhouette score indicates that the clusters reflect true splits in the\\n        data.\\n        The method concludes that a cluster is poison based on the silhouette score and the cluster relative size.\\n        If the relative size is too small, below a size_threshold and at the same time\\n        the silhouette score is higher than silhouette_threshold, the cluster is classified as poisonous.\\n        If the above thresholds are not provided, the default ones will be used.\\n\\n        :param separated_clusters: list where `separated_clusters[i]` is the cluster assignments for the ith class.\\n        :param reduced_activations_by_class: list where separated_activations[i] is a 1D array of [0,1] for\\n               [poison,clean].\\n        :param size_threshold: (optional) threshold used to define when a cluster is substantially smaller. A default\\n        value is used if the parameter is not provided.\\n        :param silhouette_threshold: (optional) threshold used to define when a cluster is cohesive. Default\\n        value is used if the parameter is not provided.\\n        :param r_size: Round number used for size rate comparisons.\\n        :param r_silhouette: Round number used for silhouette rate comparisons.\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\\n                 to be clean (as opposed to poisonous) summary_poison_clusters: array, where\\n                 summary_poison_clusters[i][j]=1 if cluster j of class j was classified as poison\\n                 report: Dictionary with summary of the analysis.\\n        \"\n    from sklearn.metrics import silhouette_score\n    size_threshold = round(size_threshold, r_size)\n    silhouette_threshold = round(silhouette_threshold, r_silhouette)\n    report: Dict[str, Any] = {'cluster_analysis': 'silhouette_score', 'size_threshold': str(size_threshold), 'silhouette_threshold': str(silhouette_threshold)}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (i, (clusters, activations)) in enumerate(zip(separated_clusters, reduced_activations_by_class)):\n        bins = np.bincount(clusters)\n        if np.size(bins) > 2:\n            raise ValueError('Analyzer does not support more than two clusters.')\n        percentages = np.round(bins / float(np.sum(bins)), r_size)\n        poison_clusters = np.where(percentages < size_threshold)\n        clean_clusters = np.where(percentages >= size_threshold)\n        silhouette_avg = round(silhouette_score(activations, clusters), r_silhouette)\n        dict_i: Dict[str, Any] = dict(sizes_clusters=str(bins), ptc_cluster=str(percentages), avg_silhouette_score=str(silhouette_avg))\n        if np.shape(poison_clusters)[1] != 0:\n            if silhouette_avg > silhouette_threshold:\n                clean_clusters = np.where(percentages < size_threshold)\n                logger.info('computed silhouette score: %s', silhouette_avg)\n                dict_i.update(suspicious=True)\n            else:\n                poison_clusters = [[]]\n                clean_clusters = np.where(percentages >= 0)\n                dict_i.update(suspicious=False)\n        else:\n            dict_i.update(suspicious=False)\n        report_class: Dict[str, Dict[str, bool]] = {'class_' + str(i): dict_i}\n        for p_id in poison_clusters[0]:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters[0]:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report.update(report_class)\n    return (np.asarray(all_assigned_clean), summary_poison_clusters, report)",
            "def analyze_by_silhouette_score(self, separated_clusters: list, reduced_activations_by_class: list, size_threshold: float=0.35, silhouette_threshold: float=0.1, r_size: int=2, r_silhouette: int=4) -> Tuple[np.ndarray, np.ndarray, Dict[str, int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Analyzes clusters to determine level of suspiciousness of poison based on the cluster's relative size\\n        and silhouette score.\\n        Computes a silhouette score for each class to determine how cohesive resulting clusters are.\\n        A low silhouette score indicates that the clustering does not fit the data well, and the class can be considered\\n        to be un-poisoned. Conversely, a high silhouette score indicates that the clusters reflect true splits in the\\n        data.\\n        The method concludes that a cluster is poison based on the silhouette score and the cluster relative size.\\n        If the relative size is too small, below a size_threshold and at the same time\\n        the silhouette score is higher than silhouette_threshold, the cluster is classified as poisonous.\\n        If the above thresholds are not provided, the default ones will be used.\\n\\n        :param separated_clusters: list where `separated_clusters[i]` is the cluster assignments for the ith class.\\n        :param reduced_activations_by_class: list where separated_activations[i] is a 1D array of [0,1] for\\n               [poison,clean].\\n        :param size_threshold: (optional) threshold used to define when a cluster is substantially smaller. A default\\n        value is used if the parameter is not provided.\\n        :param silhouette_threshold: (optional) threshold used to define when a cluster is cohesive. Default\\n        value is used if the parameter is not provided.\\n        :param r_size: Round number used for size rate comparisons.\\n        :param r_silhouette: Round number used for silhouette rate comparisons.\\n        :return: all_assigned_clean, summary_poison_clusters, report:\\n                 where all_assigned_clean[i] is a 1D boolean array indicating whether a given data point was determined\\n                 to be clean (as opposed to poisonous) summary_poison_clusters: array, where\\n                 summary_poison_clusters[i][j]=1 if cluster j of class j was classified as poison\\n                 report: Dictionary with summary of the analysis.\\n        \"\n    from sklearn.metrics import silhouette_score\n    size_threshold = round(size_threshold, r_size)\n    silhouette_threshold = round(silhouette_threshold, r_silhouette)\n    report: Dict[str, Any] = {'cluster_analysis': 'silhouette_score', 'size_threshold': str(size_threshold), 'silhouette_threshold': str(silhouette_threshold)}\n    all_assigned_clean = []\n    nb_classes = len(separated_clusters)\n    nb_clusters = len(np.unique(separated_clusters[0]))\n    summary_poison_clusters = np.zeros((nb_classes, nb_clusters))\n    for (i, (clusters, activations)) in enumerate(zip(separated_clusters, reduced_activations_by_class)):\n        bins = np.bincount(clusters)\n        if np.size(bins) > 2:\n            raise ValueError('Analyzer does not support more than two clusters.')\n        percentages = np.round(bins / float(np.sum(bins)), r_size)\n        poison_clusters = np.where(percentages < size_threshold)\n        clean_clusters = np.where(percentages >= size_threshold)\n        silhouette_avg = round(silhouette_score(activations, clusters), r_silhouette)\n        dict_i: Dict[str, Any] = dict(sizes_clusters=str(bins), ptc_cluster=str(percentages), avg_silhouette_score=str(silhouette_avg))\n        if np.shape(poison_clusters)[1] != 0:\n            if silhouette_avg > silhouette_threshold:\n                clean_clusters = np.where(percentages < size_threshold)\n                logger.info('computed silhouette score: %s', silhouette_avg)\n                dict_i.update(suspicious=True)\n            else:\n                poison_clusters = [[]]\n                clean_clusters = np.where(percentages >= 0)\n                dict_i.update(suspicious=False)\n        else:\n            dict_i.update(suspicious=False)\n        report_class: Dict[str, Dict[str, bool]] = {'class_' + str(i): dict_i}\n        for p_id in poison_clusters[0]:\n            summary_poison_clusters[i][p_id] = 1\n        for c_id in clean_clusters[0]:\n            summary_poison_clusters[i][c_id] = 0\n        assigned_clean = self.assign_class(clusters, clean_clusters, poison_clusters)\n        all_assigned_clean.append(assigned_clean)\n        report.update(report_class)\n    return (np.asarray(all_assigned_clean), summary_poison_clusters, report)"
        ]
    }
]