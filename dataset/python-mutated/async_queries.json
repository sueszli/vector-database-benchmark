[
    {
        "func_name": "set_form_data",
        "original": "def set_form_data(form_data: dict[str, Any]) -> None:\n    g.form_data = form_data",
        "mutated": [
            "def set_form_data(form_data: dict[str, Any]) -> None:\n    if False:\n        i = 10\n    g.form_data = form_data",
            "def set_form_data(form_data: dict[str, Any]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    g.form_data = form_data",
            "def set_form_data(form_data: dict[str, Any]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    g.form_data = form_data",
            "def set_form_data(form_data: dict[str, Any]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    g.form_data = form_data",
            "def set_form_data(form_data: dict[str, Any]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    g.form_data = form_data"
        ]
    },
    {
        "func_name": "_create_query_context_from_form",
        "original": "def _create_query_context_from_form(form_data: dict[str, Any]) -> QueryContext:\n    try:\n        return ChartDataQueryContextSchema().load(form_data)\n    except KeyError as ex:\n        raise ValidationError('Request is incorrect') from ex\n    except ValidationError as error:\n        raise error",
        "mutated": [
            "def _create_query_context_from_form(form_data: dict[str, Any]) -> QueryContext:\n    if False:\n        i = 10\n    try:\n        return ChartDataQueryContextSchema().load(form_data)\n    except KeyError as ex:\n        raise ValidationError('Request is incorrect') from ex\n    except ValidationError as error:\n        raise error",
            "def _create_query_context_from_form(form_data: dict[str, Any]) -> QueryContext:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    try:\n        return ChartDataQueryContextSchema().load(form_data)\n    except KeyError as ex:\n        raise ValidationError('Request is incorrect') from ex\n    except ValidationError as error:\n        raise error",
            "def _create_query_context_from_form(form_data: dict[str, Any]) -> QueryContext:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    try:\n        return ChartDataQueryContextSchema().load(form_data)\n    except KeyError as ex:\n        raise ValidationError('Request is incorrect') from ex\n    except ValidationError as error:\n        raise error",
            "def _create_query_context_from_form(form_data: dict[str, Any]) -> QueryContext:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    try:\n        return ChartDataQueryContextSchema().load(form_data)\n    except KeyError as ex:\n        raise ValidationError('Request is incorrect') from ex\n    except ValidationError as error:\n        raise error",
            "def _create_query_context_from_form(form_data: dict[str, Any]) -> QueryContext:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    try:\n        return ChartDataQueryContextSchema().load(form_data)\n    except KeyError as ex:\n        raise ValidationError('Request is incorrect') from ex\n    except ValidationError as error:\n        raise error"
        ]
    },
    {
        "func_name": "load_chart_data_into_cache",
        "original": "@celery_app.task(name='load_chart_data_into_cache', soft_time_limit=query_timeout)\ndef load_chart_data_into_cache(job_metadata: dict[str, Any], form_data: dict[str, Any]) -> None:\n    from superset.charts.data.commands.get_data_command import ChartDataCommand\n    user = security_manager.get_user_by_id(job_metadata.get('user_id')) or security_manager.get_anonymous_user()\n    with override_user(user, force=False):\n        try:\n            set_form_data(form_data)\n            query_context = _create_query_context_from_form(form_data)\n            command = ChartDataCommand(query_context)\n            result = command.run(cache=True)\n            cache_key = result['cache_key']\n            result_url = f'/api/v1/chart/data/{cache_key}'\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_DONE, result_url=result_url)\n        except SoftTimeLimitExceeded as ex:\n            logger.warning('A timeout occurred while loading chart data, error: %s', ex)\n            raise ex\n        except Exception as ex:\n            error = str(ex.message if hasattr(ex, 'message') else ex)\n            errors = [{'message': error}]\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_ERROR, errors=errors)\n            raise ex",
        "mutated": [
            "@celery_app.task(name='load_chart_data_into_cache', soft_time_limit=query_timeout)\ndef load_chart_data_into_cache(job_metadata: dict[str, Any], form_data: dict[str, Any]) -> None:\n    if False:\n        i = 10\n    from superset.charts.data.commands.get_data_command import ChartDataCommand\n    user = security_manager.get_user_by_id(job_metadata.get('user_id')) or security_manager.get_anonymous_user()\n    with override_user(user, force=False):\n        try:\n            set_form_data(form_data)\n            query_context = _create_query_context_from_form(form_data)\n            command = ChartDataCommand(query_context)\n            result = command.run(cache=True)\n            cache_key = result['cache_key']\n            result_url = f'/api/v1/chart/data/{cache_key}'\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_DONE, result_url=result_url)\n        except SoftTimeLimitExceeded as ex:\n            logger.warning('A timeout occurred while loading chart data, error: %s', ex)\n            raise ex\n        except Exception as ex:\n            error = str(ex.message if hasattr(ex, 'message') else ex)\n            errors = [{'message': error}]\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_ERROR, errors=errors)\n            raise ex",
            "@celery_app.task(name='load_chart_data_into_cache', soft_time_limit=query_timeout)\ndef load_chart_data_into_cache(job_metadata: dict[str, Any], form_data: dict[str, Any]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    from superset.charts.data.commands.get_data_command import ChartDataCommand\n    user = security_manager.get_user_by_id(job_metadata.get('user_id')) or security_manager.get_anonymous_user()\n    with override_user(user, force=False):\n        try:\n            set_form_data(form_data)\n            query_context = _create_query_context_from_form(form_data)\n            command = ChartDataCommand(query_context)\n            result = command.run(cache=True)\n            cache_key = result['cache_key']\n            result_url = f'/api/v1/chart/data/{cache_key}'\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_DONE, result_url=result_url)\n        except SoftTimeLimitExceeded as ex:\n            logger.warning('A timeout occurred while loading chart data, error: %s', ex)\n            raise ex\n        except Exception as ex:\n            error = str(ex.message if hasattr(ex, 'message') else ex)\n            errors = [{'message': error}]\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_ERROR, errors=errors)\n            raise ex",
            "@celery_app.task(name='load_chart_data_into_cache', soft_time_limit=query_timeout)\ndef load_chart_data_into_cache(job_metadata: dict[str, Any], form_data: dict[str, Any]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    from superset.charts.data.commands.get_data_command import ChartDataCommand\n    user = security_manager.get_user_by_id(job_metadata.get('user_id')) or security_manager.get_anonymous_user()\n    with override_user(user, force=False):\n        try:\n            set_form_data(form_data)\n            query_context = _create_query_context_from_form(form_data)\n            command = ChartDataCommand(query_context)\n            result = command.run(cache=True)\n            cache_key = result['cache_key']\n            result_url = f'/api/v1/chart/data/{cache_key}'\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_DONE, result_url=result_url)\n        except SoftTimeLimitExceeded as ex:\n            logger.warning('A timeout occurred while loading chart data, error: %s', ex)\n            raise ex\n        except Exception as ex:\n            error = str(ex.message if hasattr(ex, 'message') else ex)\n            errors = [{'message': error}]\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_ERROR, errors=errors)\n            raise ex",
            "@celery_app.task(name='load_chart_data_into_cache', soft_time_limit=query_timeout)\ndef load_chart_data_into_cache(job_metadata: dict[str, Any], form_data: dict[str, Any]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    from superset.charts.data.commands.get_data_command import ChartDataCommand\n    user = security_manager.get_user_by_id(job_metadata.get('user_id')) or security_manager.get_anonymous_user()\n    with override_user(user, force=False):\n        try:\n            set_form_data(form_data)\n            query_context = _create_query_context_from_form(form_data)\n            command = ChartDataCommand(query_context)\n            result = command.run(cache=True)\n            cache_key = result['cache_key']\n            result_url = f'/api/v1/chart/data/{cache_key}'\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_DONE, result_url=result_url)\n        except SoftTimeLimitExceeded as ex:\n            logger.warning('A timeout occurred while loading chart data, error: %s', ex)\n            raise ex\n        except Exception as ex:\n            error = str(ex.message if hasattr(ex, 'message') else ex)\n            errors = [{'message': error}]\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_ERROR, errors=errors)\n            raise ex",
            "@celery_app.task(name='load_chart_data_into_cache', soft_time_limit=query_timeout)\ndef load_chart_data_into_cache(job_metadata: dict[str, Any], form_data: dict[str, Any]) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    from superset.charts.data.commands.get_data_command import ChartDataCommand\n    user = security_manager.get_user_by_id(job_metadata.get('user_id')) or security_manager.get_anonymous_user()\n    with override_user(user, force=False):\n        try:\n            set_form_data(form_data)\n            query_context = _create_query_context_from_form(form_data)\n            command = ChartDataCommand(query_context)\n            result = command.run(cache=True)\n            cache_key = result['cache_key']\n            result_url = f'/api/v1/chart/data/{cache_key}'\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_DONE, result_url=result_url)\n        except SoftTimeLimitExceeded as ex:\n            logger.warning('A timeout occurred while loading chart data, error: %s', ex)\n            raise ex\n        except Exception as ex:\n            error = str(ex.message if hasattr(ex, 'message') else ex)\n            errors = [{'message': error}]\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_ERROR, errors=errors)\n            raise ex"
        ]
    },
    {
        "func_name": "load_explore_json_into_cache",
        "original": "@celery_app.task(name='load_explore_json_into_cache', soft_time_limit=query_timeout)\ndef load_explore_json_into_cache(job_metadata: dict[str, Any], form_data: dict[str, Any], response_type: str | None=None, force: bool=False) -> None:\n    cache_key_prefix = 'ejr-'\n    user = security_manager.get_user_by_id(job_metadata.get('user_id')) or security_manager.get_anonymous_user()\n    with override_user(user, force=False):\n        try:\n            set_form_data(form_data)\n            (datasource_id, datasource_type) = get_datasource_info(None, None, form_data)\n            original_form_data = copy.deepcopy(form_data)\n            viz_obj = get_viz(datasource_type=cast(str, datasource_type), datasource_id=datasource_id, form_data=form_data, force=force)\n            payload = viz_obj.get_payload()\n            if viz_obj.has_error(payload):\n                raise SupersetVizException(errors=payload['errors'])\n            cache_value = {'form_data': original_form_data, 'response_type': response_type}\n            cache_key = generate_cache_key(cache_value, cache_key_prefix)\n            set_and_log_cache(cache_manager.cache, cache_key, cache_value)\n            result_url = f'/superset/explore_json/data/{cache_key}'\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_DONE, result_url=result_url)\n        except SoftTimeLimitExceeded as ex:\n            logger.warning('A timeout occurred while loading explore json, error: %s', ex)\n            raise ex\n        except Exception as ex:\n            if isinstance(ex, SupersetVizException):\n                errors = ex.errors\n            else:\n                error = ex.message if hasattr(ex, 'message') else str(ex)\n                errors = [error]\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_ERROR, errors=errors)\n            raise ex",
        "mutated": [
            "@celery_app.task(name='load_explore_json_into_cache', soft_time_limit=query_timeout)\ndef load_explore_json_into_cache(job_metadata: dict[str, Any], form_data: dict[str, Any], response_type: str | None=None, force: bool=False) -> None:\n    if False:\n        i = 10\n    cache_key_prefix = 'ejr-'\n    user = security_manager.get_user_by_id(job_metadata.get('user_id')) or security_manager.get_anonymous_user()\n    with override_user(user, force=False):\n        try:\n            set_form_data(form_data)\n            (datasource_id, datasource_type) = get_datasource_info(None, None, form_data)\n            original_form_data = copy.deepcopy(form_data)\n            viz_obj = get_viz(datasource_type=cast(str, datasource_type), datasource_id=datasource_id, form_data=form_data, force=force)\n            payload = viz_obj.get_payload()\n            if viz_obj.has_error(payload):\n                raise SupersetVizException(errors=payload['errors'])\n            cache_value = {'form_data': original_form_data, 'response_type': response_type}\n            cache_key = generate_cache_key(cache_value, cache_key_prefix)\n            set_and_log_cache(cache_manager.cache, cache_key, cache_value)\n            result_url = f'/superset/explore_json/data/{cache_key}'\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_DONE, result_url=result_url)\n        except SoftTimeLimitExceeded as ex:\n            logger.warning('A timeout occurred while loading explore json, error: %s', ex)\n            raise ex\n        except Exception as ex:\n            if isinstance(ex, SupersetVizException):\n                errors = ex.errors\n            else:\n                error = ex.message if hasattr(ex, 'message') else str(ex)\n                errors = [error]\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_ERROR, errors=errors)\n            raise ex",
            "@celery_app.task(name='load_explore_json_into_cache', soft_time_limit=query_timeout)\ndef load_explore_json_into_cache(job_metadata: dict[str, Any], form_data: dict[str, Any], response_type: str | None=None, force: bool=False) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    cache_key_prefix = 'ejr-'\n    user = security_manager.get_user_by_id(job_metadata.get('user_id')) or security_manager.get_anonymous_user()\n    with override_user(user, force=False):\n        try:\n            set_form_data(form_data)\n            (datasource_id, datasource_type) = get_datasource_info(None, None, form_data)\n            original_form_data = copy.deepcopy(form_data)\n            viz_obj = get_viz(datasource_type=cast(str, datasource_type), datasource_id=datasource_id, form_data=form_data, force=force)\n            payload = viz_obj.get_payload()\n            if viz_obj.has_error(payload):\n                raise SupersetVizException(errors=payload['errors'])\n            cache_value = {'form_data': original_form_data, 'response_type': response_type}\n            cache_key = generate_cache_key(cache_value, cache_key_prefix)\n            set_and_log_cache(cache_manager.cache, cache_key, cache_value)\n            result_url = f'/superset/explore_json/data/{cache_key}'\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_DONE, result_url=result_url)\n        except SoftTimeLimitExceeded as ex:\n            logger.warning('A timeout occurred while loading explore json, error: %s', ex)\n            raise ex\n        except Exception as ex:\n            if isinstance(ex, SupersetVizException):\n                errors = ex.errors\n            else:\n                error = ex.message if hasattr(ex, 'message') else str(ex)\n                errors = [error]\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_ERROR, errors=errors)\n            raise ex",
            "@celery_app.task(name='load_explore_json_into_cache', soft_time_limit=query_timeout)\ndef load_explore_json_into_cache(job_metadata: dict[str, Any], form_data: dict[str, Any], response_type: str | None=None, force: bool=False) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    cache_key_prefix = 'ejr-'\n    user = security_manager.get_user_by_id(job_metadata.get('user_id')) or security_manager.get_anonymous_user()\n    with override_user(user, force=False):\n        try:\n            set_form_data(form_data)\n            (datasource_id, datasource_type) = get_datasource_info(None, None, form_data)\n            original_form_data = copy.deepcopy(form_data)\n            viz_obj = get_viz(datasource_type=cast(str, datasource_type), datasource_id=datasource_id, form_data=form_data, force=force)\n            payload = viz_obj.get_payload()\n            if viz_obj.has_error(payload):\n                raise SupersetVizException(errors=payload['errors'])\n            cache_value = {'form_data': original_form_data, 'response_type': response_type}\n            cache_key = generate_cache_key(cache_value, cache_key_prefix)\n            set_and_log_cache(cache_manager.cache, cache_key, cache_value)\n            result_url = f'/superset/explore_json/data/{cache_key}'\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_DONE, result_url=result_url)\n        except SoftTimeLimitExceeded as ex:\n            logger.warning('A timeout occurred while loading explore json, error: %s', ex)\n            raise ex\n        except Exception as ex:\n            if isinstance(ex, SupersetVizException):\n                errors = ex.errors\n            else:\n                error = ex.message if hasattr(ex, 'message') else str(ex)\n                errors = [error]\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_ERROR, errors=errors)\n            raise ex",
            "@celery_app.task(name='load_explore_json_into_cache', soft_time_limit=query_timeout)\ndef load_explore_json_into_cache(job_metadata: dict[str, Any], form_data: dict[str, Any], response_type: str | None=None, force: bool=False) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    cache_key_prefix = 'ejr-'\n    user = security_manager.get_user_by_id(job_metadata.get('user_id')) or security_manager.get_anonymous_user()\n    with override_user(user, force=False):\n        try:\n            set_form_data(form_data)\n            (datasource_id, datasource_type) = get_datasource_info(None, None, form_data)\n            original_form_data = copy.deepcopy(form_data)\n            viz_obj = get_viz(datasource_type=cast(str, datasource_type), datasource_id=datasource_id, form_data=form_data, force=force)\n            payload = viz_obj.get_payload()\n            if viz_obj.has_error(payload):\n                raise SupersetVizException(errors=payload['errors'])\n            cache_value = {'form_data': original_form_data, 'response_type': response_type}\n            cache_key = generate_cache_key(cache_value, cache_key_prefix)\n            set_and_log_cache(cache_manager.cache, cache_key, cache_value)\n            result_url = f'/superset/explore_json/data/{cache_key}'\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_DONE, result_url=result_url)\n        except SoftTimeLimitExceeded as ex:\n            logger.warning('A timeout occurred while loading explore json, error: %s', ex)\n            raise ex\n        except Exception as ex:\n            if isinstance(ex, SupersetVizException):\n                errors = ex.errors\n            else:\n                error = ex.message if hasattr(ex, 'message') else str(ex)\n                errors = [error]\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_ERROR, errors=errors)\n            raise ex",
            "@celery_app.task(name='load_explore_json_into_cache', soft_time_limit=query_timeout)\ndef load_explore_json_into_cache(job_metadata: dict[str, Any], form_data: dict[str, Any], response_type: str | None=None, force: bool=False) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    cache_key_prefix = 'ejr-'\n    user = security_manager.get_user_by_id(job_metadata.get('user_id')) or security_manager.get_anonymous_user()\n    with override_user(user, force=False):\n        try:\n            set_form_data(form_data)\n            (datasource_id, datasource_type) = get_datasource_info(None, None, form_data)\n            original_form_data = copy.deepcopy(form_data)\n            viz_obj = get_viz(datasource_type=cast(str, datasource_type), datasource_id=datasource_id, form_data=form_data, force=force)\n            payload = viz_obj.get_payload()\n            if viz_obj.has_error(payload):\n                raise SupersetVizException(errors=payload['errors'])\n            cache_value = {'form_data': original_form_data, 'response_type': response_type}\n            cache_key = generate_cache_key(cache_value, cache_key_prefix)\n            set_and_log_cache(cache_manager.cache, cache_key, cache_value)\n            result_url = f'/superset/explore_json/data/{cache_key}'\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_DONE, result_url=result_url)\n        except SoftTimeLimitExceeded as ex:\n            logger.warning('A timeout occurred while loading explore json, error: %s', ex)\n            raise ex\n        except Exception as ex:\n            if isinstance(ex, SupersetVizException):\n                errors = ex.errors\n            else:\n                error = ex.message if hasattr(ex, 'message') else str(ex)\n                errors = [error]\n            async_query_manager.update_job(job_metadata, async_query_manager.STATUS_ERROR, errors=errors)\n            raise ex"
        ]
    }
]