[
    {
        "func_name": "_next_fast_lengths",
        "original": "def _next_fast_lengths(shape):\n    \"\"\"\n    Find optimal or good sizes to pad an array of ``shape`` to for better\n    performance with `numpy.fft.*fft` and `scipy.fft.*fft`.\n    Calculated directly with `scipy.fft.next_fast_len`, if available; otherwise\n    looked up from list and scaled by powers of 10, if necessary.\n    \"\"\"\n    try:\n        import scipy.fft\n        return np.array([scipy.fft.next_fast_len(j) for j in shape])\n    except ImportError:\n        pass\n    newshape = np.empty(len(np.atleast_1d(shape)), dtype=int)\n    for (i, j) in enumerate(shape):\n        scale = 10 ** max(int(np.ceil(np.log10(j))) - _good_range, 0)\n        for n in _good_sizes:\n            if n * scale >= j:\n                newshape[i] = n * scale\n                break\n        else:\n            raise ValueError(f'No next fast length for {j} found in list of _good_sizes <= {_good_sizes[-1] * scale}.')\n    return newshape",
        "mutated": [
            "def _next_fast_lengths(shape):\n    if False:\n        i = 10\n    '\\n    Find optimal or good sizes to pad an array of ``shape`` to for better\\n    performance with `numpy.fft.*fft` and `scipy.fft.*fft`.\\n    Calculated directly with `scipy.fft.next_fast_len`, if available; otherwise\\n    looked up from list and scaled by powers of 10, if necessary.\\n    '\n    try:\n        import scipy.fft\n        return np.array([scipy.fft.next_fast_len(j) for j in shape])\n    except ImportError:\n        pass\n    newshape = np.empty(len(np.atleast_1d(shape)), dtype=int)\n    for (i, j) in enumerate(shape):\n        scale = 10 ** max(int(np.ceil(np.log10(j))) - _good_range, 0)\n        for n in _good_sizes:\n            if n * scale >= j:\n                newshape[i] = n * scale\n                break\n        else:\n            raise ValueError(f'No next fast length for {j} found in list of _good_sizes <= {_good_sizes[-1] * scale}.')\n    return newshape",
            "def _next_fast_lengths(shape):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Find optimal or good sizes to pad an array of ``shape`` to for better\\n    performance with `numpy.fft.*fft` and `scipy.fft.*fft`.\\n    Calculated directly with `scipy.fft.next_fast_len`, if available; otherwise\\n    looked up from list and scaled by powers of 10, if necessary.\\n    '\n    try:\n        import scipy.fft\n        return np.array([scipy.fft.next_fast_len(j) for j in shape])\n    except ImportError:\n        pass\n    newshape = np.empty(len(np.atleast_1d(shape)), dtype=int)\n    for (i, j) in enumerate(shape):\n        scale = 10 ** max(int(np.ceil(np.log10(j))) - _good_range, 0)\n        for n in _good_sizes:\n            if n * scale >= j:\n                newshape[i] = n * scale\n                break\n        else:\n            raise ValueError(f'No next fast length for {j} found in list of _good_sizes <= {_good_sizes[-1] * scale}.')\n    return newshape",
            "def _next_fast_lengths(shape):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Find optimal or good sizes to pad an array of ``shape`` to for better\\n    performance with `numpy.fft.*fft` and `scipy.fft.*fft`.\\n    Calculated directly with `scipy.fft.next_fast_len`, if available; otherwise\\n    looked up from list and scaled by powers of 10, if necessary.\\n    '\n    try:\n        import scipy.fft\n        return np.array([scipy.fft.next_fast_len(j) for j in shape])\n    except ImportError:\n        pass\n    newshape = np.empty(len(np.atleast_1d(shape)), dtype=int)\n    for (i, j) in enumerate(shape):\n        scale = 10 ** max(int(np.ceil(np.log10(j))) - _good_range, 0)\n        for n in _good_sizes:\n            if n * scale >= j:\n                newshape[i] = n * scale\n                break\n        else:\n            raise ValueError(f'No next fast length for {j} found in list of _good_sizes <= {_good_sizes[-1] * scale}.')\n    return newshape",
            "def _next_fast_lengths(shape):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Find optimal or good sizes to pad an array of ``shape`` to for better\\n    performance with `numpy.fft.*fft` and `scipy.fft.*fft`.\\n    Calculated directly with `scipy.fft.next_fast_len`, if available; otherwise\\n    looked up from list and scaled by powers of 10, if necessary.\\n    '\n    try:\n        import scipy.fft\n        return np.array([scipy.fft.next_fast_len(j) for j in shape])\n    except ImportError:\n        pass\n    newshape = np.empty(len(np.atleast_1d(shape)), dtype=int)\n    for (i, j) in enumerate(shape):\n        scale = 10 ** max(int(np.ceil(np.log10(j))) - _good_range, 0)\n        for n in _good_sizes:\n            if n * scale >= j:\n                newshape[i] = n * scale\n                break\n        else:\n            raise ValueError(f'No next fast length for {j} found in list of _good_sizes <= {_good_sizes[-1] * scale}.')\n    return newshape",
            "def _next_fast_lengths(shape):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Find optimal or good sizes to pad an array of ``shape`` to for better\\n    performance with `numpy.fft.*fft` and `scipy.fft.*fft`.\\n    Calculated directly with `scipy.fft.next_fast_len`, if available; otherwise\\n    looked up from list and scaled by powers of 10, if necessary.\\n    '\n    try:\n        import scipy.fft\n        return np.array([scipy.fft.next_fast_len(j) for j in shape])\n    except ImportError:\n        pass\n    newshape = np.empty(len(np.atleast_1d(shape)), dtype=int)\n    for (i, j) in enumerate(shape):\n        scale = 10 ** max(int(np.ceil(np.log10(j))) - _good_range, 0)\n        for n in _good_sizes:\n            if n * scale >= j:\n                newshape[i] = n * scale\n                break\n        else:\n            raise ValueError(f'No next fast length for {j} found in list of _good_sizes <= {_good_sizes[-1] * scale}.')\n    return newshape"
        ]
    },
    {
        "func_name": "_copy_input_if_needed",
        "original": "def _copy_input_if_needed(input, dtype=float, order='C', nan_treatment=None, mask=None, fill_value=None):\n    input = input.array if isinstance(input, Kernel) else input\n    if hasattr(input, 'unit'):\n        input = input.value\n    output = input\n    try:\n        if nan_treatment == 'fill' or np.ma.is_masked(input) or mask is not None:\n            if np.ma.is_masked(input):\n                output = np.array(input, dtype=dtype, copy=False, order=order, subok=True)\n                output = output.filled(fill_value)\n            else:\n                output = np.array(input, dtype=dtype, copy=True, order=order, subok=False)\n            if mask is not None:\n                output[mask != 0] = fill_value\n        else:\n            output = np.array(input, dtype=dtype, copy=False, order=order, subok=True)\n    except (TypeError, ValueError) as e:\n        raise TypeError('input should be a Numpy array or something convertible into a float array', e)\n    return output",
        "mutated": [
            "def _copy_input_if_needed(input, dtype=float, order='C', nan_treatment=None, mask=None, fill_value=None):\n    if False:\n        i = 10\n    input = input.array if isinstance(input, Kernel) else input\n    if hasattr(input, 'unit'):\n        input = input.value\n    output = input\n    try:\n        if nan_treatment == 'fill' or np.ma.is_masked(input) or mask is not None:\n            if np.ma.is_masked(input):\n                output = np.array(input, dtype=dtype, copy=False, order=order, subok=True)\n                output = output.filled(fill_value)\n            else:\n                output = np.array(input, dtype=dtype, copy=True, order=order, subok=False)\n            if mask is not None:\n                output[mask != 0] = fill_value\n        else:\n            output = np.array(input, dtype=dtype, copy=False, order=order, subok=True)\n    except (TypeError, ValueError) as e:\n        raise TypeError('input should be a Numpy array or something convertible into a float array', e)\n    return output",
            "def _copy_input_if_needed(input, dtype=float, order='C', nan_treatment=None, mask=None, fill_value=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    input = input.array if isinstance(input, Kernel) else input\n    if hasattr(input, 'unit'):\n        input = input.value\n    output = input\n    try:\n        if nan_treatment == 'fill' or np.ma.is_masked(input) or mask is not None:\n            if np.ma.is_masked(input):\n                output = np.array(input, dtype=dtype, copy=False, order=order, subok=True)\n                output = output.filled(fill_value)\n            else:\n                output = np.array(input, dtype=dtype, copy=True, order=order, subok=False)\n            if mask is not None:\n                output[mask != 0] = fill_value\n        else:\n            output = np.array(input, dtype=dtype, copy=False, order=order, subok=True)\n    except (TypeError, ValueError) as e:\n        raise TypeError('input should be a Numpy array or something convertible into a float array', e)\n    return output",
            "def _copy_input_if_needed(input, dtype=float, order='C', nan_treatment=None, mask=None, fill_value=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    input = input.array if isinstance(input, Kernel) else input\n    if hasattr(input, 'unit'):\n        input = input.value\n    output = input\n    try:\n        if nan_treatment == 'fill' or np.ma.is_masked(input) or mask is not None:\n            if np.ma.is_masked(input):\n                output = np.array(input, dtype=dtype, copy=False, order=order, subok=True)\n                output = output.filled(fill_value)\n            else:\n                output = np.array(input, dtype=dtype, copy=True, order=order, subok=False)\n            if mask is not None:\n                output[mask != 0] = fill_value\n        else:\n            output = np.array(input, dtype=dtype, copy=False, order=order, subok=True)\n    except (TypeError, ValueError) as e:\n        raise TypeError('input should be a Numpy array or something convertible into a float array', e)\n    return output",
            "def _copy_input_if_needed(input, dtype=float, order='C', nan_treatment=None, mask=None, fill_value=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    input = input.array if isinstance(input, Kernel) else input\n    if hasattr(input, 'unit'):\n        input = input.value\n    output = input\n    try:\n        if nan_treatment == 'fill' or np.ma.is_masked(input) or mask is not None:\n            if np.ma.is_masked(input):\n                output = np.array(input, dtype=dtype, copy=False, order=order, subok=True)\n                output = output.filled(fill_value)\n            else:\n                output = np.array(input, dtype=dtype, copy=True, order=order, subok=False)\n            if mask is not None:\n                output[mask != 0] = fill_value\n        else:\n            output = np.array(input, dtype=dtype, copy=False, order=order, subok=True)\n    except (TypeError, ValueError) as e:\n        raise TypeError('input should be a Numpy array or something convertible into a float array', e)\n    return output",
            "def _copy_input_if_needed(input, dtype=float, order='C', nan_treatment=None, mask=None, fill_value=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    input = input.array if isinstance(input, Kernel) else input\n    if hasattr(input, 'unit'):\n        input = input.value\n    output = input\n    try:\n        if nan_treatment == 'fill' or np.ma.is_masked(input) or mask is not None:\n            if np.ma.is_masked(input):\n                output = np.array(input, dtype=dtype, copy=False, order=order, subok=True)\n                output = output.filled(fill_value)\n            else:\n                output = np.array(input, dtype=dtype, copy=True, order=order, subok=False)\n            if mask is not None:\n                output[mask != 0] = fill_value\n        else:\n            output = np.array(input, dtype=dtype, copy=False, order=order, subok=True)\n    except (TypeError, ValueError) as e:\n        raise TypeError('input should be a Numpy array or something convertible into a float array', e)\n    return output"
        ]
    },
    {
        "func_name": "convolve",
        "original": "@support_nddata(data='array')\ndef convolve(array, kernel, boundary='fill', fill_value=0.0, nan_treatment='interpolate', normalize_kernel=True, mask=None, preserve_nan=False, normalization_zero_tol=1e-08):\n    \"\"\"\n    Convolve an array with a kernel.\n\n    This routine differs from `scipy.ndimage.convolve` because\n    it includes a special treatment for ``NaN`` values. Rather than\n    including ``NaN`` values in the array in the convolution calculation, which\n    causes large ``NaN`` holes in the convolved array, ``NaN`` values are\n    replaced with interpolated values using the kernel as an interpolation\n    function.\n\n    Parameters\n    ----------\n    array : `~astropy.nddata.NDData` or array-like\n        The array to convolve. This should be a 1, 2, or 3-dimensional array\n        or a list or a set of nested lists representing a 1, 2, or\n        3-dimensional array.  If an `~astropy.nddata.NDData`, the ``mask`` of\n        the `~astropy.nddata.NDData` will be used as the ``mask`` argument.\n    kernel : `numpy.ndarray` or `~astropy.convolution.Kernel`\n        The convolution kernel. The number of dimensions should match those for\n        the array, and the dimensions should be odd in all directions.  If a\n        masked array, the masked values will be replaced by ``fill_value``.\n    boundary : str, optional\n        A flag indicating how to handle boundaries:\n            * `None`\n                Set the ``result`` values to zero where the kernel\n                extends beyond the edge of the array.\n            * 'fill'\n                Set values outside the array boundary to ``fill_value`` (default).\n            * 'wrap'\n                Periodic boundary that wrap to the other side of ``array``.\n            * 'extend'\n                Set values outside the array to the nearest ``array``\n                value.\n    fill_value : float, optional\n        The value to use outside the array when using ``boundary='fill'``.\n    normalize_kernel : bool, optional\n        Whether to normalize the kernel to have a sum of one.\n    nan_treatment : {'interpolate', 'fill'}, optional\n        The method used to handle NaNs in the input ``array``:\n            * ``'interpolate'``: ``NaN`` values are replaced with\n              interpolated values using the kernel as an interpolation\n              function. Note that if the kernel has a sum equal to\n              zero, NaN interpolation is not possible and will raise an\n              exception.\n            * ``'fill'``: ``NaN`` values are replaced by ``fill_value``\n              prior to convolution.\n    preserve_nan : bool, optional\n        After performing convolution, should pixels that were originally NaN\n        again become NaN?\n    mask : None or ndarray, optional\n        A \"mask\" array.  Shape must match ``array``, and anything that is masked\n        (i.e., not 0/`False`) will be set to NaN for the convolution.  If\n        `None`, no masking will be performed unless ``array`` is a masked array.\n        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is\n        masked if it is masked in either ``mask`` *or* ``array.mask``.\n    normalization_zero_tol : float, optional\n        The absolute tolerance on whether the kernel is different than zero.\n        If the kernel sums to zero to within this precision, it cannot be\n        normalized. Default is \"1e-8\".\n\n    Returns\n    -------\n    result : `numpy.ndarray`\n        An array with the same dimensions and as the input array,\n        convolved with kernel.  The data type depends on the input\n        array type.  If array is a floating point type, then the\n        return array keeps the same data type, otherwise the type\n        is ``numpy.float``.\n\n    Notes\n    -----\n    For masked arrays, masked values are treated as NaNs.  The convolution\n    is always done at ``numpy.float`` precision.\n    \"\"\"\n    if boundary not in BOUNDARY_OPTIONS:\n        raise ValueError(f'Invalid boundary option: must be one of {BOUNDARY_OPTIONS}')\n    if nan_treatment not in ('interpolate', 'fill'):\n        raise ValueError(\"nan_treatment must be one of 'interpolate','fill'\")\n    n_threads = 1\n    passed_kernel = kernel\n    passed_array = array\n    array_internal = _copy_input_if_needed(passed_array, dtype=float, order='C', nan_treatment=nan_treatment, mask=mask, fill_value=np.nan)\n    array_dtype = getattr(passed_array, 'dtype', array_internal.dtype)\n    kernel_internal = _copy_input_if_needed(passed_kernel, dtype=float, order='C', nan_treatment=None, mask=None, fill_value=fill_value)\n    if has_even_axis(kernel_internal):\n        raise KernelSizeError('Kernel size must be odd in all axes.')\n    if isinstance(passed_array, Kernel) and isinstance(passed_kernel, Kernel):\n        warnings.warn(\"Both array and kernel are Kernel instances, hardwiring the following parameters: boundary='fill', fill_value=0, normalize_Kernel=True, nan_treatment='interpolate'\", AstropyUserWarning)\n        boundary = 'fill'\n        fill_value = 0\n        normalize_kernel = True\n        nan_treatment = 'interpolate'\n    if array_internal.ndim == 0:\n        raise Exception('cannot convolve 0-dimensional arrays')\n    elif array_internal.ndim > 3:\n        raise NotImplementedError('convolve only supports 1, 2, and 3-dimensional arrays at this time')\n    elif array_internal.ndim != kernel_internal.ndim:\n        raise Exception('array and kernel have differing number of dimensions.')\n    array_shape = np.array(array_internal.shape)\n    kernel_shape = np.array(kernel_internal.shape)\n    pad_width = kernel_shape // 2\n    if boundary is None and (not np.all(array_shape > 2 * pad_width)):\n        raise KernelSizeError(\"for boundary=None all kernel axes must be smaller than array's - use boundary in ['fill', 'extend', 'wrap'] instead.\")\n    nan_interpolate = nan_treatment == 'interpolate' and np.isnan(array_internal.sum())\n    if normalize_kernel or nan_interpolate:\n        kernel_sum = kernel_internal.sum()\n        kernel_sums_to_zero = np.isclose(kernel_sum, 0, atol=normalization_zero_tol)\n        if kernel_sum < 1.0 / MAX_NORMALIZATION or kernel_sums_to_zero:\n            if nan_interpolate:\n                raise ValueError(\"Setting nan_treatment='interpolate' requires the kernel to be normalized, but the input kernel has a sum close to zero. For a zero-sum kernel and data with NaNs, set nan_treatment='fill'.\")\n            else:\n                raise ValueError(f\"The kernel can't be normalized, because its sum is close to zero. The sum of the given kernel is < {1.0 / MAX_NORMALIZATION}\")\n    if preserve_nan or nan_treatment == 'fill':\n        initially_nan = np.isnan(array_internal)\n        if nan_treatment == 'fill':\n            array_internal[initially_nan] = fill_value\n    result = np.zeros(array_internal.shape, dtype=float, order='C')\n    embed_result_within_padded_region = True\n    array_to_convolve = array_internal\n    if boundary in ('fill', 'extend', 'wrap'):\n        embed_result_within_padded_region = False\n        if boundary == 'fill':\n            array_to_convolve = np.full(array_shape + 2 * pad_width, fill_value=fill_value, dtype=float, order='C')\n            if array_internal.ndim == 1:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0]] = array_internal\n            elif array_internal.ndim == 2:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0], pad_width[1]:array_shape[1] + pad_width[1]] = array_internal\n            else:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0], pad_width[1]:array_shape[1] + pad_width[1], pad_width[2]:array_shape[2] + pad_width[2]] = array_internal\n        else:\n            np_pad_mode_dict = {'fill': 'constant', 'extend': 'edge', 'wrap': 'wrap'}\n            np_pad_mode = np_pad_mode_dict[boundary]\n            pad_width = kernel_shape // 2\n            if array_internal.ndim == 1:\n                np_pad_width = (pad_width[0],)\n            elif array_internal.ndim == 2:\n                np_pad_width = ((pad_width[0],), (pad_width[1],))\n            else:\n                np_pad_width = ((pad_width[0],), (pad_width[1],), (pad_width[2],))\n            array_to_convolve = np.pad(array_internal, pad_width=np_pad_width, mode=np_pad_mode)\n    _convolveNd_c(result, array_to_convolve, kernel_internal, nan_interpolate, embed_result_within_padded_region, n_threads)\n    if normalize_kernel:\n        if not nan_interpolate:\n            result /= kernel_sum\n    elif nan_interpolate:\n        result *= kernel_sum\n    if nan_interpolate and (not preserve_nan) and np.isnan(result.sum()):\n        warnings.warn(\"nan_treatment='interpolate', however, NaN values detected post convolution. A contiguous region of NaN values, larger than the kernel size, are present in the input array. Increase the kernel size to avoid this.\", AstropyUserWarning)\n    if preserve_nan:\n        result[initially_nan] = np.nan\n    array_unit = getattr(passed_array, 'unit', None)\n    if array_unit is not None:\n        result <<= array_unit\n    if isinstance(passed_array, Kernel):\n        if isinstance(passed_array, Kernel1D):\n            new_result = Kernel1D(array=result)\n        elif isinstance(passed_array, Kernel2D):\n            new_result = Kernel2D(array=result)\n        else:\n            raise TypeError('Only 1D and 2D Kernels are supported.')\n        new_result._is_bool = False\n        new_result._separable = passed_array._separable\n        if isinstance(passed_kernel, Kernel):\n            new_result._separable = new_result._separable and passed_kernel._separable\n        return new_result\n    elif array_dtype.kind == 'f':\n        try:\n            return result.astype(array_dtype, copy=False)\n        except TypeError:\n            return result.astype(array_dtype)\n    else:\n        return result",
        "mutated": [
            "@support_nddata(data='array')\ndef convolve(array, kernel, boundary='fill', fill_value=0.0, nan_treatment='interpolate', normalize_kernel=True, mask=None, preserve_nan=False, normalization_zero_tol=1e-08):\n    if False:\n        i = 10\n    '\\n    Convolve an array with a kernel.\\n\\n    This routine differs from `scipy.ndimage.convolve` because\\n    it includes a special treatment for ``NaN`` values. Rather than\\n    including ``NaN`` values in the array in the convolution calculation, which\\n    causes large ``NaN`` holes in the convolved array, ``NaN`` values are\\n    replaced with interpolated values using the kernel as an interpolation\\n    function.\\n\\n    Parameters\\n    ----------\\n    array : `~astropy.nddata.NDData` or array-like\\n        The array to convolve. This should be a 1, 2, or 3-dimensional array\\n        or a list or a set of nested lists representing a 1, 2, or\\n        3-dimensional array.  If an `~astropy.nddata.NDData`, the ``mask`` of\\n        the `~astropy.nddata.NDData` will be used as the ``mask`` argument.\\n    kernel : `numpy.ndarray` or `~astropy.convolution.Kernel`\\n        The convolution kernel. The number of dimensions should match those for\\n        the array, and the dimensions should be odd in all directions.  If a\\n        masked array, the masked values will be replaced by ``fill_value``.\\n    boundary : str, optional\\n        A flag indicating how to handle boundaries:\\n            * `None`\\n                Set the ``result`` values to zero where the kernel\\n                extends beyond the edge of the array.\\n            * \\'fill\\'\\n                Set values outside the array boundary to ``fill_value`` (default).\\n            * \\'wrap\\'\\n                Periodic boundary that wrap to the other side of ``array``.\\n            * \\'extend\\'\\n                Set values outside the array to the nearest ``array``\\n                value.\\n    fill_value : float, optional\\n        The value to use outside the array when using ``boundary=\\'fill\\'``.\\n    normalize_kernel : bool, optional\\n        Whether to normalize the kernel to have a sum of one.\\n    nan_treatment : {\\'interpolate\\', \\'fill\\'}, optional\\n        The method used to handle NaNs in the input ``array``:\\n            * ``\\'interpolate\\'``: ``NaN`` values are replaced with\\n              interpolated values using the kernel as an interpolation\\n              function. Note that if the kernel has a sum equal to\\n              zero, NaN interpolation is not possible and will raise an\\n              exception.\\n            * ``\\'fill\\'``: ``NaN`` values are replaced by ``fill_value``\\n              prior to convolution.\\n    preserve_nan : bool, optional\\n        After performing convolution, should pixels that were originally NaN\\n        again become NaN?\\n    mask : None or ndarray, optional\\n        A \"mask\" array.  Shape must match ``array``, and anything that is masked\\n        (i.e., not 0/`False`) will be set to NaN for the convolution.  If\\n        `None`, no masking will be performed unless ``array`` is a masked array.\\n        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is\\n        masked if it is masked in either ``mask`` *or* ``array.mask``.\\n    normalization_zero_tol : float, optional\\n        The absolute tolerance on whether the kernel is different than zero.\\n        If the kernel sums to zero to within this precision, it cannot be\\n        normalized. Default is \"1e-8\".\\n\\n    Returns\\n    -------\\n    result : `numpy.ndarray`\\n        An array with the same dimensions and as the input array,\\n        convolved with kernel.  The data type depends on the input\\n        array type.  If array is a floating point type, then the\\n        return array keeps the same data type, otherwise the type\\n        is ``numpy.float``.\\n\\n    Notes\\n    -----\\n    For masked arrays, masked values are treated as NaNs.  The convolution\\n    is always done at ``numpy.float`` precision.\\n    '\n    if boundary not in BOUNDARY_OPTIONS:\n        raise ValueError(f'Invalid boundary option: must be one of {BOUNDARY_OPTIONS}')\n    if nan_treatment not in ('interpolate', 'fill'):\n        raise ValueError(\"nan_treatment must be one of 'interpolate','fill'\")\n    n_threads = 1\n    passed_kernel = kernel\n    passed_array = array\n    array_internal = _copy_input_if_needed(passed_array, dtype=float, order='C', nan_treatment=nan_treatment, mask=mask, fill_value=np.nan)\n    array_dtype = getattr(passed_array, 'dtype', array_internal.dtype)\n    kernel_internal = _copy_input_if_needed(passed_kernel, dtype=float, order='C', nan_treatment=None, mask=None, fill_value=fill_value)\n    if has_even_axis(kernel_internal):\n        raise KernelSizeError('Kernel size must be odd in all axes.')\n    if isinstance(passed_array, Kernel) and isinstance(passed_kernel, Kernel):\n        warnings.warn(\"Both array and kernel are Kernel instances, hardwiring the following parameters: boundary='fill', fill_value=0, normalize_Kernel=True, nan_treatment='interpolate'\", AstropyUserWarning)\n        boundary = 'fill'\n        fill_value = 0\n        normalize_kernel = True\n        nan_treatment = 'interpolate'\n    if array_internal.ndim == 0:\n        raise Exception('cannot convolve 0-dimensional arrays')\n    elif array_internal.ndim > 3:\n        raise NotImplementedError('convolve only supports 1, 2, and 3-dimensional arrays at this time')\n    elif array_internal.ndim != kernel_internal.ndim:\n        raise Exception('array and kernel have differing number of dimensions.')\n    array_shape = np.array(array_internal.shape)\n    kernel_shape = np.array(kernel_internal.shape)\n    pad_width = kernel_shape // 2\n    if boundary is None and (not np.all(array_shape > 2 * pad_width)):\n        raise KernelSizeError(\"for boundary=None all kernel axes must be smaller than array's - use boundary in ['fill', 'extend', 'wrap'] instead.\")\n    nan_interpolate = nan_treatment == 'interpolate' and np.isnan(array_internal.sum())\n    if normalize_kernel or nan_interpolate:\n        kernel_sum = kernel_internal.sum()\n        kernel_sums_to_zero = np.isclose(kernel_sum, 0, atol=normalization_zero_tol)\n        if kernel_sum < 1.0 / MAX_NORMALIZATION or kernel_sums_to_zero:\n            if nan_interpolate:\n                raise ValueError(\"Setting nan_treatment='interpolate' requires the kernel to be normalized, but the input kernel has a sum close to zero. For a zero-sum kernel and data with NaNs, set nan_treatment='fill'.\")\n            else:\n                raise ValueError(f\"The kernel can't be normalized, because its sum is close to zero. The sum of the given kernel is < {1.0 / MAX_NORMALIZATION}\")\n    if preserve_nan or nan_treatment == 'fill':\n        initially_nan = np.isnan(array_internal)\n        if nan_treatment == 'fill':\n            array_internal[initially_nan] = fill_value\n    result = np.zeros(array_internal.shape, dtype=float, order='C')\n    embed_result_within_padded_region = True\n    array_to_convolve = array_internal\n    if boundary in ('fill', 'extend', 'wrap'):\n        embed_result_within_padded_region = False\n        if boundary == 'fill':\n            array_to_convolve = np.full(array_shape + 2 * pad_width, fill_value=fill_value, dtype=float, order='C')\n            if array_internal.ndim == 1:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0]] = array_internal\n            elif array_internal.ndim == 2:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0], pad_width[1]:array_shape[1] + pad_width[1]] = array_internal\n            else:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0], pad_width[1]:array_shape[1] + pad_width[1], pad_width[2]:array_shape[2] + pad_width[2]] = array_internal\n        else:\n            np_pad_mode_dict = {'fill': 'constant', 'extend': 'edge', 'wrap': 'wrap'}\n            np_pad_mode = np_pad_mode_dict[boundary]\n            pad_width = kernel_shape // 2\n            if array_internal.ndim == 1:\n                np_pad_width = (pad_width[0],)\n            elif array_internal.ndim == 2:\n                np_pad_width = ((pad_width[0],), (pad_width[1],))\n            else:\n                np_pad_width = ((pad_width[0],), (pad_width[1],), (pad_width[2],))\n            array_to_convolve = np.pad(array_internal, pad_width=np_pad_width, mode=np_pad_mode)\n    _convolveNd_c(result, array_to_convolve, kernel_internal, nan_interpolate, embed_result_within_padded_region, n_threads)\n    if normalize_kernel:\n        if not nan_interpolate:\n            result /= kernel_sum\n    elif nan_interpolate:\n        result *= kernel_sum\n    if nan_interpolate and (not preserve_nan) and np.isnan(result.sum()):\n        warnings.warn(\"nan_treatment='interpolate', however, NaN values detected post convolution. A contiguous region of NaN values, larger than the kernel size, are present in the input array. Increase the kernel size to avoid this.\", AstropyUserWarning)\n    if preserve_nan:\n        result[initially_nan] = np.nan\n    array_unit = getattr(passed_array, 'unit', None)\n    if array_unit is not None:\n        result <<= array_unit\n    if isinstance(passed_array, Kernel):\n        if isinstance(passed_array, Kernel1D):\n            new_result = Kernel1D(array=result)\n        elif isinstance(passed_array, Kernel2D):\n            new_result = Kernel2D(array=result)\n        else:\n            raise TypeError('Only 1D and 2D Kernels are supported.')\n        new_result._is_bool = False\n        new_result._separable = passed_array._separable\n        if isinstance(passed_kernel, Kernel):\n            new_result._separable = new_result._separable and passed_kernel._separable\n        return new_result\n    elif array_dtype.kind == 'f':\n        try:\n            return result.astype(array_dtype, copy=False)\n        except TypeError:\n            return result.astype(array_dtype)\n    else:\n        return result",
            "@support_nddata(data='array')\ndef convolve(array, kernel, boundary='fill', fill_value=0.0, nan_treatment='interpolate', normalize_kernel=True, mask=None, preserve_nan=False, normalization_zero_tol=1e-08):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Convolve an array with a kernel.\\n\\n    This routine differs from `scipy.ndimage.convolve` because\\n    it includes a special treatment for ``NaN`` values. Rather than\\n    including ``NaN`` values in the array in the convolution calculation, which\\n    causes large ``NaN`` holes in the convolved array, ``NaN`` values are\\n    replaced with interpolated values using the kernel as an interpolation\\n    function.\\n\\n    Parameters\\n    ----------\\n    array : `~astropy.nddata.NDData` or array-like\\n        The array to convolve. This should be a 1, 2, or 3-dimensional array\\n        or a list or a set of nested lists representing a 1, 2, or\\n        3-dimensional array.  If an `~astropy.nddata.NDData`, the ``mask`` of\\n        the `~astropy.nddata.NDData` will be used as the ``mask`` argument.\\n    kernel : `numpy.ndarray` or `~astropy.convolution.Kernel`\\n        The convolution kernel. The number of dimensions should match those for\\n        the array, and the dimensions should be odd in all directions.  If a\\n        masked array, the masked values will be replaced by ``fill_value``.\\n    boundary : str, optional\\n        A flag indicating how to handle boundaries:\\n            * `None`\\n                Set the ``result`` values to zero where the kernel\\n                extends beyond the edge of the array.\\n            * \\'fill\\'\\n                Set values outside the array boundary to ``fill_value`` (default).\\n            * \\'wrap\\'\\n                Periodic boundary that wrap to the other side of ``array``.\\n            * \\'extend\\'\\n                Set values outside the array to the nearest ``array``\\n                value.\\n    fill_value : float, optional\\n        The value to use outside the array when using ``boundary=\\'fill\\'``.\\n    normalize_kernel : bool, optional\\n        Whether to normalize the kernel to have a sum of one.\\n    nan_treatment : {\\'interpolate\\', \\'fill\\'}, optional\\n        The method used to handle NaNs in the input ``array``:\\n            * ``\\'interpolate\\'``: ``NaN`` values are replaced with\\n              interpolated values using the kernel as an interpolation\\n              function. Note that if the kernel has a sum equal to\\n              zero, NaN interpolation is not possible and will raise an\\n              exception.\\n            * ``\\'fill\\'``: ``NaN`` values are replaced by ``fill_value``\\n              prior to convolution.\\n    preserve_nan : bool, optional\\n        After performing convolution, should pixels that were originally NaN\\n        again become NaN?\\n    mask : None or ndarray, optional\\n        A \"mask\" array.  Shape must match ``array``, and anything that is masked\\n        (i.e., not 0/`False`) will be set to NaN for the convolution.  If\\n        `None`, no masking will be performed unless ``array`` is a masked array.\\n        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is\\n        masked if it is masked in either ``mask`` *or* ``array.mask``.\\n    normalization_zero_tol : float, optional\\n        The absolute tolerance on whether the kernel is different than zero.\\n        If the kernel sums to zero to within this precision, it cannot be\\n        normalized. Default is \"1e-8\".\\n\\n    Returns\\n    -------\\n    result : `numpy.ndarray`\\n        An array with the same dimensions and as the input array,\\n        convolved with kernel.  The data type depends on the input\\n        array type.  If array is a floating point type, then the\\n        return array keeps the same data type, otherwise the type\\n        is ``numpy.float``.\\n\\n    Notes\\n    -----\\n    For masked arrays, masked values are treated as NaNs.  The convolution\\n    is always done at ``numpy.float`` precision.\\n    '\n    if boundary not in BOUNDARY_OPTIONS:\n        raise ValueError(f'Invalid boundary option: must be one of {BOUNDARY_OPTIONS}')\n    if nan_treatment not in ('interpolate', 'fill'):\n        raise ValueError(\"nan_treatment must be one of 'interpolate','fill'\")\n    n_threads = 1\n    passed_kernel = kernel\n    passed_array = array\n    array_internal = _copy_input_if_needed(passed_array, dtype=float, order='C', nan_treatment=nan_treatment, mask=mask, fill_value=np.nan)\n    array_dtype = getattr(passed_array, 'dtype', array_internal.dtype)\n    kernel_internal = _copy_input_if_needed(passed_kernel, dtype=float, order='C', nan_treatment=None, mask=None, fill_value=fill_value)\n    if has_even_axis(kernel_internal):\n        raise KernelSizeError('Kernel size must be odd in all axes.')\n    if isinstance(passed_array, Kernel) and isinstance(passed_kernel, Kernel):\n        warnings.warn(\"Both array and kernel are Kernel instances, hardwiring the following parameters: boundary='fill', fill_value=0, normalize_Kernel=True, nan_treatment='interpolate'\", AstropyUserWarning)\n        boundary = 'fill'\n        fill_value = 0\n        normalize_kernel = True\n        nan_treatment = 'interpolate'\n    if array_internal.ndim == 0:\n        raise Exception('cannot convolve 0-dimensional arrays')\n    elif array_internal.ndim > 3:\n        raise NotImplementedError('convolve only supports 1, 2, and 3-dimensional arrays at this time')\n    elif array_internal.ndim != kernel_internal.ndim:\n        raise Exception('array and kernel have differing number of dimensions.')\n    array_shape = np.array(array_internal.shape)\n    kernel_shape = np.array(kernel_internal.shape)\n    pad_width = kernel_shape // 2\n    if boundary is None and (not np.all(array_shape > 2 * pad_width)):\n        raise KernelSizeError(\"for boundary=None all kernel axes must be smaller than array's - use boundary in ['fill', 'extend', 'wrap'] instead.\")\n    nan_interpolate = nan_treatment == 'interpolate' and np.isnan(array_internal.sum())\n    if normalize_kernel or nan_interpolate:\n        kernel_sum = kernel_internal.sum()\n        kernel_sums_to_zero = np.isclose(kernel_sum, 0, atol=normalization_zero_tol)\n        if kernel_sum < 1.0 / MAX_NORMALIZATION or kernel_sums_to_zero:\n            if nan_interpolate:\n                raise ValueError(\"Setting nan_treatment='interpolate' requires the kernel to be normalized, but the input kernel has a sum close to zero. For a zero-sum kernel and data with NaNs, set nan_treatment='fill'.\")\n            else:\n                raise ValueError(f\"The kernel can't be normalized, because its sum is close to zero. The sum of the given kernel is < {1.0 / MAX_NORMALIZATION}\")\n    if preserve_nan or nan_treatment == 'fill':\n        initially_nan = np.isnan(array_internal)\n        if nan_treatment == 'fill':\n            array_internal[initially_nan] = fill_value\n    result = np.zeros(array_internal.shape, dtype=float, order='C')\n    embed_result_within_padded_region = True\n    array_to_convolve = array_internal\n    if boundary in ('fill', 'extend', 'wrap'):\n        embed_result_within_padded_region = False\n        if boundary == 'fill':\n            array_to_convolve = np.full(array_shape + 2 * pad_width, fill_value=fill_value, dtype=float, order='C')\n            if array_internal.ndim == 1:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0]] = array_internal\n            elif array_internal.ndim == 2:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0], pad_width[1]:array_shape[1] + pad_width[1]] = array_internal\n            else:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0], pad_width[1]:array_shape[1] + pad_width[1], pad_width[2]:array_shape[2] + pad_width[2]] = array_internal\n        else:\n            np_pad_mode_dict = {'fill': 'constant', 'extend': 'edge', 'wrap': 'wrap'}\n            np_pad_mode = np_pad_mode_dict[boundary]\n            pad_width = kernel_shape // 2\n            if array_internal.ndim == 1:\n                np_pad_width = (pad_width[0],)\n            elif array_internal.ndim == 2:\n                np_pad_width = ((pad_width[0],), (pad_width[1],))\n            else:\n                np_pad_width = ((pad_width[0],), (pad_width[1],), (pad_width[2],))\n            array_to_convolve = np.pad(array_internal, pad_width=np_pad_width, mode=np_pad_mode)\n    _convolveNd_c(result, array_to_convolve, kernel_internal, nan_interpolate, embed_result_within_padded_region, n_threads)\n    if normalize_kernel:\n        if not nan_interpolate:\n            result /= kernel_sum\n    elif nan_interpolate:\n        result *= kernel_sum\n    if nan_interpolate and (not preserve_nan) and np.isnan(result.sum()):\n        warnings.warn(\"nan_treatment='interpolate', however, NaN values detected post convolution. A contiguous region of NaN values, larger than the kernel size, are present in the input array. Increase the kernel size to avoid this.\", AstropyUserWarning)\n    if preserve_nan:\n        result[initially_nan] = np.nan\n    array_unit = getattr(passed_array, 'unit', None)\n    if array_unit is not None:\n        result <<= array_unit\n    if isinstance(passed_array, Kernel):\n        if isinstance(passed_array, Kernel1D):\n            new_result = Kernel1D(array=result)\n        elif isinstance(passed_array, Kernel2D):\n            new_result = Kernel2D(array=result)\n        else:\n            raise TypeError('Only 1D and 2D Kernels are supported.')\n        new_result._is_bool = False\n        new_result._separable = passed_array._separable\n        if isinstance(passed_kernel, Kernel):\n            new_result._separable = new_result._separable and passed_kernel._separable\n        return new_result\n    elif array_dtype.kind == 'f':\n        try:\n            return result.astype(array_dtype, copy=False)\n        except TypeError:\n            return result.astype(array_dtype)\n    else:\n        return result",
            "@support_nddata(data='array')\ndef convolve(array, kernel, boundary='fill', fill_value=0.0, nan_treatment='interpolate', normalize_kernel=True, mask=None, preserve_nan=False, normalization_zero_tol=1e-08):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Convolve an array with a kernel.\\n\\n    This routine differs from `scipy.ndimage.convolve` because\\n    it includes a special treatment for ``NaN`` values. Rather than\\n    including ``NaN`` values in the array in the convolution calculation, which\\n    causes large ``NaN`` holes in the convolved array, ``NaN`` values are\\n    replaced with interpolated values using the kernel as an interpolation\\n    function.\\n\\n    Parameters\\n    ----------\\n    array : `~astropy.nddata.NDData` or array-like\\n        The array to convolve. This should be a 1, 2, or 3-dimensional array\\n        or a list or a set of nested lists representing a 1, 2, or\\n        3-dimensional array.  If an `~astropy.nddata.NDData`, the ``mask`` of\\n        the `~astropy.nddata.NDData` will be used as the ``mask`` argument.\\n    kernel : `numpy.ndarray` or `~astropy.convolution.Kernel`\\n        The convolution kernel. The number of dimensions should match those for\\n        the array, and the dimensions should be odd in all directions.  If a\\n        masked array, the masked values will be replaced by ``fill_value``.\\n    boundary : str, optional\\n        A flag indicating how to handle boundaries:\\n            * `None`\\n                Set the ``result`` values to zero where the kernel\\n                extends beyond the edge of the array.\\n            * \\'fill\\'\\n                Set values outside the array boundary to ``fill_value`` (default).\\n            * \\'wrap\\'\\n                Periodic boundary that wrap to the other side of ``array``.\\n            * \\'extend\\'\\n                Set values outside the array to the nearest ``array``\\n                value.\\n    fill_value : float, optional\\n        The value to use outside the array when using ``boundary=\\'fill\\'``.\\n    normalize_kernel : bool, optional\\n        Whether to normalize the kernel to have a sum of one.\\n    nan_treatment : {\\'interpolate\\', \\'fill\\'}, optional\\n        The method used to handle NaNs in the input ``array``:\\n            * ``\\'interpolate\\'``: ``NaN`` values are replaced with\\n              interpolated values using the kernel as an interpolation\\n              function. Note that if the kernel has a sum equal to\\n              zero, NaN interpolation is not possible and will raise an\\n              exception.\\n            * ``\\'fill\\'``: ``NaN`` values are replaced by ``fill_value``\\n              prior to convolution.\\n    preserve_nan : bool, optional\\n        After performing convolution, should pixels that were originally NaN\\n        again become NaN?\\n    mask : None or ndarray, optional\\n        A \"mask\" array.  Shape must match ``array``, and anything that is masked\\n        (i.e., not 0/`False`) will be set to NaN for the convolution.  If\\n        `None`, no masking will be performed unless ``array`` is a masked array.\\n        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is\\n        masked if it is masked in either ``mask`` *or* ``array.mask``.\\n    normalization_zero_tol : float, optional\\n        The absolute tolerance on whether the kernel is different than zero.\\n        If the kernel sums to zero to within this precision, it cannot be\\n        normalized. Default is \"1e-8\".\\n\\n    Returns\\n    -------\\n    result : `numpy.ndarray`\\n        An array with the same dimensions and as the input array,\\n        convolved with kernel.  The data type depends on the input\\n        array type.  If array is a floating point type, then the\\n        return array keeps the same data type, otherwise the type\\n        is ``numpy.float``.\\n\\n    Notes\\n    -----\\n    For masked arrays, masked values are treated as NaNs.  The convolution\\n    is always done at ``numpy.float`` precision.\\n    '\n    if boundary not in BOUNDARY_OPTIONS:\n        raise ValueError(f'Invalid boundary option: must be one of {BOUNDARY_OPTIONS}')\n    if nan_treatment not in ('interpolate', 'fill'):\n        raise ValueError(\"nan_treatment must be one of 'interpolate','fill'\")\n    n_threads = 1\n    passed_kernel = kernel\n    passed_array = array\n    array_internal = _copy_input_if_needed(passed_array, dtype=float, order='C', nan_treatment=nan_treatment, mask=mask, fill_value=np.nan)\n    array_dtype = getattr(passed_array, 'dtype', array_internal.dtype)\n    kernel_internal = _copy_input_if_needed(passed_kernel, dtype=float, order='C', nan_treatment=None, mask=None, fill_value=fill_value)\n    if has_even_axis(kernel_internal):\n        raise KernelSizeError('Kernel size must be odd in all axes.')\n    if isinstance(passed_array, Kernel) and isinstance(passed_kernel, Kernel):\n        warnings.warn(\"Both array and kernel are Kernel instances, hardwiring the following parameters: boundary='fill', fill_value=0, normalize_Kernel=True, nan_treatment='interpolate'\", AstropyUserWarning)\n        boundary = 'fill'\n        fill_value = 0\n        normalize_kernel = True\n        nan_treatment = 'interpolate'\n    if array_internal.ndim == 0:\n        raise Exception('cannot convolve 0-dimensional arrays')\n    elif array_internal.ndim > 3:\n        raise NotImplementedError('convolve only supports 1, 2, and 3-dimensional arrays at this time')\n    elif array_internal.ndim != kernel_internal.ndim:\n        raise Exception('array and kernel have differing number of dimensions.')\n    array_shape = np.array(array_internal.shape)\n    kernel_shape = np.array(kernel_internal.shape)\n    pad_width = kernel_shape // 2\n    if boundary is None and (not np.all(array_shape > 2 * pad_width)):\n        raise KernelSizeError(\"for boundary=None all kernel axes must be smaller than array's - use boundary in ['fill', 'extend', 'wrap'] instead.\")\n    nan_interpolate = nan_treatment == 'interpolate' and np.isnan(array_internal.sum())\n    if normalize_kernel or nan_interpolate:\n        kernel_sum = kernel_internal.sum()\n        kernel_sums_to_zero = np.isclose(kernel_sum, 0, atol=normalization_zero_tol)\n        if kernel_sum < 1.0 / MAX_NORMALIZATION or kernel_sums_to_zero:\n            if nan_interpolate:\n                raise ValueError(\"Setting nan_treatment='interpolate' requires the kernel to be normalized, but the input kernel has a sum close to zero. For a zero-sum kernel and data with NaNs, set nan_treatment='fill'.\")\n            else:\n                raise ValueError(f\"The kernel can't be normalized, because its sum is close to zero. The sum of the given kernel is < {1.0 / MAX_NORMALIZATION}\")\n    if preserve_nan or nan_treatment == 'fill':\n        initially_nan = np.isnan(array_internal)\n        if nan_treatment == 'fill':\n            array_internal[initially_nan] = fill_value\n    result = np.zeros(array_internal.shape, dtype=float, order='C')\n    embed_result_within_padded_region = True\n    array_to_convolve = array_internal\n    if boundary in ('fill', 'extend', 'wrap'):\n        embed_result_within_padded_region = False\n        if boundary == 'fill':\n            array_to_convolve = np.full(array_shape + 2 * pad_width, fill_value=fill_value, dtype=float, order='C')\n            if array_internal.ndim == 1:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0]] = array_internal\n            elif array_internal.ndim == 2:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0], pad_width[1]:array_shape[1] + pad_width[1]] = array_internal\n            else:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0], pad_width[1]:array_shape[1] + pad_width[1], pad_width[2]:array_shape[2] + pad_width[2]] = array_internal\n        else:\n            np_pad_mode_dict = {'fill': 'constant', 'extend': 'edge', 'wrap': 'wrap'}\n            np_pad_mode = np_pad_mode_dict[boundary]\n            pad_width = kernel_shape // 2\n            if array_internal.ndim == 1:\n                np_pad_width = (pad_width[0],)\n            elif array_internal.ndim == 2:\n                np_pad_width = ((pad_width[0],), (pad_width[1],))\n            else:\n                np_pad_width = ((pad_width[0],), (pad_width[1],), (pad_width[2],))\n            array_to_convolve = np.pad(array_internal, pad_width=np_pad_width, mode=np_pad_mode)\n    _convolveNd_c(result, array_to_convolve, kernel_internal, nan_interpolate, embed_result_within_padded_region, n_threads)\n    if normalize_kernel:\n        if not nan_interpolate:\n            result /= kernel_sum\n    elif nan_interpolate:\n        result *= kernel_sum\n    if nan_interpolate and (not preserve_nan) and np.isnan(result.sum()):\n        warnings.warn(\"nan_treatment='interpolate', however, NaN values detected post convolution. A contiguous region of NaN values, larger than the kernel size, are present in the input array. Increase the kernel size to avoid this.\", AstropyUserWarning)\n    if preserve_nan:\n        result[initially_nan] = np.nan\n    array_unit = getattr(passed_array, 'unit', None)\n    if array_unit is not None:\n        result <<= array_unit\n    if isinstance(passed_array, Kernel):\n        if isinstance(passed_array, Kernel1D):\n            new_result = Kernel1D(array=result)\n        elif isinstance(passed_array, Kernel2D):\n            new_result = Kernel2D(array=result)\n        else:\n            raise TypeError('Only 1D and 2D Kernels are supported.')\n        new_result._is_bool = False\n        new_result._separable = passed_array._separable\n        if isinstance(passed_kernel, Kernel):\n            new_result._separable = new_result._separable and passed_kernel._separable\n        return new_result\n    elif array_dtype.kind == 'f':\n        try:\n            return result.astype(array_dtype, copy=False)\n        except TypeError:\n            return result.astype(array_dtype)\n    else:\n        return result",
            "@support_nddata(data='array')\ndef convolve(array, kernel, boundary='fill', fill_value=0.0, nan_treatment='interpolate', normalize_kernel=True, mask=None, preserve_nan=False, normalization_zero_tol=1e-08):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Convolve an array with a kernel.\\n\\n    This routine differs from `scipy.ndimage.convolve` because\\n    it includes a special treatment for ``NaN`` values. Rather than\\n    including ``NaN`` values in the array in the convolution calculation, which\\n    causes large ``NaN`` holes in the convolved array, ``NaN`` values are\\n    replaced with interpolated values using the kernel as an interpolation\\n    function.\\n\\n    Parameters\\n    ----------\\n    array : `~astropy.nddata.NDData` or array-like\\n        The array to convolve. This should be a 1, 2, or 3-dimensional array\\n        or a list or a set of nested lists representing a 1, 2, or\\n        3-dimensional array.  If an `~astropy.nddata.NDData`, the ``mask`` of\\n        the `~astropy.nddata.NDData` will be used as the ``mask`` argument.\\n    kernel : `numpy.ndarray` or `~astropy.convolution.Kernel`\\n        The convolution kernel. The number of dimensions should match those for\\n        the array, and the dimensions should be odd in all directions.  If a\\n        masked array, the masked values will be replaced by ``fill_value``.\\n    boundary : str, optional\\n        A flag indicating how to handle boundaries:\\n            * `None`\\n                Set the ``result`` values to zero where the kernel\\n                extends beyond the edge of the array.\\n            * \\'fill\\'\\n                Set values outside the array boundary to ``fill_value`` (default).\\n            * \\'wrap\\'\\n                Periodic boundary that wrap to the other side of ``array``.\\n            * \\'extend\\'\\n                Set values outside the array to the nearest ``array``\\n                value.\\n    fill_value : float, optional\\n        The value to use outside the array when using ``boundary=\\'fill\\'``.\\n    normalize_kernel : bool, optional\\n        Whether to normalize the kernel to have a sum of one.\\n    nan_treatment : {\\'interpolate\\', \\'fill\\'}, optional\\n        The method used to handle NaNs in the input ``array``:\\n            * ``\\'interpolate\\'``: ``NaN`` values are replaced with\\n              interpolated values using the kernel as an interpolation\\n              function. Note that if the kernel has a sum equal to\\n              zero, NaN interpolation is not possible and will raise an\\n              exception.\\n            * ``\\'fill\\'``: ``NaN`` values are replaced by ``fill_value``\\n              prior to convolution.\\n    preserve_nan : bool, optional\\n        After performing convolution, should pixels that were originally NaN\\n        again become NaN?\\n    mask : None or ndarray, optional\\n        A \"mask\" array.  Shape must match ``array``, and anything that is masked\\n        (i.e., not 0/`False`) will be set to NaN for the convolution.  If\\n        `None`, no masking will be performed unless ``array`` is a masked array.\\n        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is\\n        masked if it is masked in either ``mask`` *or* ``array.mask``.\\n    normalization_zero_tol : float, optional\\n        The absolute tolerance on whether the kernel is different than zero.\\n        If the kernel sums to zero to within this precision, it cannot be\\n        normalized. Default is \"1e-8\".\\n\\n    Returns\\n    -------\\n    result : `numpy.ndarray`\\n        An array with the same dimensions and as the input array,\\n        convolved with kernel.  The data type depends on the input\\n        array type.  If array is a floating point type, then the\\n        return array keeps the same data type, otherwise the type\\n        is ``numpy.float``.\\n\\n    Notes\\n    -----\\n    For masked arrays, masked values are treated as NaNs.  The convolution\\n    is always done at ``numpy.float`` precision.\\n    '\n    if boundary not in BOUNDARY_OPTIONS:\n        raise ValueError(f'Invalid boundary option: must be one of {BOUNDARY_OPTIONS}')\n    if nan_treatment not in ('interpolate', 'fill'):\n        raise ValueError(\"nan_treatment must be one of 'interpolate','fill'\")\n    n_threads = 1\n    passed_kernel = kernel\n    passed_array = array\n    array_internal = _copy_input_if_needed(passed_array, dtype=float, order='C', nan_treatment=nan_treatment, mask=mask, fill_value=np.nan)\n    array_dtype = getattr(passed_array, 'dtype', array_internal.dtype)\n    kernel_internal = _copy_input_if_needed(passed_kernel, dtype=float, order='C', nan_treatment=None, mask=None, fill_value=fill_value)\n    if has_even_axis(kernel_internal):\n        raise KernelSizeError('Kernel size must be odd in all axes.')\n    if isinstance(passed_array, Kernel) and isinstance(passed_kernel, Kernel):\n        warnings.warn(\"Both array and kernel are Kernel instances, hardwiring the following parameters: boundary='fill', fill_value=0, normalize_Kernel=True, nan_treatment='interpolate'\", AstropyUserWarning)\n        boundary = 'fill'\n        fill_value = 0\n        normalize_kernel = True\n        nan_treatment = 'interpolate'\n    if array_internal.ndim == 0:\n        raise Exception('cannot convolve 0-dimensional arrays')\n    elif array_internal.ndim > 3:\n        raise NotImplementedError('convolve only supports 1, 2, and 3-dimensional arrays at this time')\n    elif array_internal.ndim != kernel_internal.ndim:\n        raise Exception('array and kernel have differing number of dimensions.')\n    array_shape = np.array(array_internal.shape)\n    kernel_shape = np.array(kernel_internal.shape)\n    pad_width = kernel_shape // 2\n    if boundary is None and (not np.all(array_shape > 2 * pad_width)):\n        raise KernelSizeError(\"for boundary=None all kernel axes must be smaller than array's - use boundary in ['fill', 'extend', 'wrap'] instead.\")\n    nan_interpolate = nan_treatment == 'interpolate' and np.isnan(array_internal.sum())\n    if normalize_kernel or nan_interpolate:\n        kernel_sum = kernel_internal.sum()\n        kernel_sums_to_zero = np.isclose(kernel_sum, 0, atol=normalization_zero_tol)\n        if kernel_sum < 1.0 / MAX_NORMALIZATION or kernel_sums_to_zero:\n            if nan_interpolate:\n                raise ValueError(\"Setting nan_treatment='interpolate' requires the kernel to be normalized, but the input kernel has a sum close to zero. For a zero-sum kernel and data with NaNs, set nan_treatment='fill'.\")\n            else:\n                raise ValueError(f\"The kernel can't be normalized, because its sum is close to zero. The sum of the given kernel is < {1.0 / MAX_NORMALIZATION}\")\n    if preserve_nan or nan_treatment == 'fill':\n        initially_nan = np.isnan(array_internal)\n        if nan_treatment == 'fill':\n            array_internal[initially_nan] = fill_value\n    result = np.zeros(array_internal.shape, dtype=float, order='C')\n    embed_result_within_padded_region = True\n    array_to_convolve = array_internal\n    if boundary in ('fill', 'extend', 'wrap'):\n        embed_result_within_padded_region = False\n        if boundary == 'fill':\n            array_to_convolve = np.full(array_shape + 2 * pad_width, fill_value=fill_value, dtype=float, order='C')\n            if array_internal.ndim == 1:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0]] = array_internal\n            elif array_internal.ndim == 2:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0], pad_width[1]:array_shape[1] + pad_width[1]] = array_internal\n            else:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0], pad_width[1]:array_shape[1] + pad_width[1], pad_width[2]:array_shape[2] + pad_width[2]] = array_internal\n        else:\n            np_pad_mode_dict = {'fill': 'constant', 'extend': 'edge', 'wrap': 'wrap'}\n            np_pad_mode = np_pad_mode_dict[boundary]\n            pad_width = kernel_shape // 2\n            if array_internal.ndim == 1:\n                np_pad_width = (pad_width[0],)\n            elif array_internal.ndim == 2:\n                np_pad_width = ((pad_width[0],), (pad_width[1],))\n            else:\n                np_pad_width = ((pad_width[0],), (pad_width[1],), (pad_width[2],))\n            array_to_convolve = np.pad(array_internal, pad_width=np_pad_width, mode=np_pad_mode)\n    _convolveNd_c(result, array_to_convolve, kernel_internal, nan_interpolate, embed_result_within_padded_region, n_threads)\n    if normalize_kernel:\n        if not nan_interpolate:\n            result /= kernel_sum\n    elif nan_interpolate:\n        result *= kernel_sum\n    if nan_interpolate and (not preserve_nan) and np.isnan(result.sum()):\n        warnings.warn(\"nan_treatment='interpolate', however, NaN values detected post convolution. A contiguous region of NaN values, larger than the kernel size, are present in the input array. Increase the kernel size to avoid this.\", AstropyUserWarning)\n    if preserve_nan:\n        result[initially_nan] = np.nan\n    array_unit = getattr(passed_array, 'unit', None)\n    if array_unit is not None:\n        result <<= array_unit\n    if isinstance(passed_array, Kernel):\n        if isinstance(passed_array, Kernel1D):\n            new_result = Kernel1D(array=result)\n        elif isinstance(passed_array, Kernel2D):\n            new_result = Kernel2D(array=result)\n        else:\n            raise TypeError('Only 1D and 2D Kernels are supported.')\n        new_result._is_bool = False\n        new_result._separable = passed_array._separable\n        if isinstance(passed_kernel, Kernel):\n            new_result._separable = new_result._separable and passed_kernel._separable\n        return new_result\n    elif array_dtype.kind == 'f':\n        try:\n            return result.astype(array_dtype, copy=False)\n        except TypeError:\n            return result.astype(array_dtype)\n    else:\n        return result",
            "@support_nddata(data='array')\ndef convolve(array, kernel, boundary='fill', fill_value=0.0, nan_treatment='interpolate', normalize_kernel=True, mask=None, preserve_nan=False, normalization_zero_tol=1e-08):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Convolve an array with a kernel.\\n\\n    This routine differs from `scipy.ndimage.convolve` because\\n    it includes a special treatment for ``NaN`` values. Rather than\\n    including ``NaN`` values in the array in the convolution calculation, which\\n    causes large ``NaN`` holes in the convolved array, ``NaN`` values are\\n    replaced with interpolated values using the kernel as an interpolation\\n    function.\\n\\n    Parameters\\n    ----------\\n    array : `~astropy.nddata.NDData` or array-like\\n        The array to convolve. This should be a 1, 2, or 3-dimensional array\\n        or a list or a set of nested lists representing a 1, 2, or\\n        3-dimensional array.  If an `~astropy.nddata.NDData`, the ``mask`` of\\n        the `~astropy.nddata.NDData` will be used as the ``mask`` argument.\\n    kernel : `numpy.ndarray` or `~astropy.convolution.Kernel`\\n        The convolution kernel. The number of dimensions should match those for\\n        the array, and the dimensions should be odd in all directions.  If a\\n        masked array, the masked values will be replaced by ``fill_value``.\\n    boundary : str, optional\\n        A flag indicating how to handle boundaries:\\n            * `None`\\n                Set the ``result`` values to zero where the kernel\\n                extends beyond the edge of the array.\\n            * \\'fill\\'\\n                Set values outside the array boundary to ``fill_value`` (default).\\n            * \\'wrap\\'\\n                Periodic boundary that wrap to the other side of ``array``.\\n            * \\'extend\\'\\n                Set values outside the array to the nearest ``array``\\n                value.\\n    fill_value : float, optional\\n        The value to use outside the array when using ``boundary=\\'fill\\'``.\\n    normalize_kernel : bool, optional\\n        Whether to normalize the kernel to have a sum of one.\\n    nan_treatment : {\\'interpolate\\', \\'fill\\'}, optional\\n        The method used to handle NaNs in the input ``array``:\\n            * ``\\'interpolate\\'``: ``NaN`` values are replaced with\\n              interpolated values using the kernel as an interpolation\\n              function. Note that if the kernel has a sum equal to\\n              zero, NaN interpolation is not possible and will raise an\\n              exception.\\n            * ``\\'fill\\'``: ``NaN`` values are replaced by ``fill_value``\\n              prior to convolution.\\n    preserve_nan : bool, optional\\n        After performing convolution, should pixels that were originally NaN\\n        again become NaN?\\n    mask : None or ndarray, optional\\n        A \"mask\" array.  Shape must match ``array``, and anything that is masked\\n        (i.e., not 0/`False`) will be set to NaN for the convolution.  If\\n        `None`, no masking will be performed unless ``array`` is a masked array.\\n        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is\\n        masked if it is masked in either ``mask`` *or* ``array.mask``.\\n    normalization_zero_tol : float, optional\\n        The absolute tolerance on whether the kernel is different than zero.\\n        If the kernel sums to zero to within this precision, it cannot be\\n        normalized. Default is \"1e-8\".\\n\\n    Returns\\n    -------\\n    result : `numpy.ndarray`\\n        An array with the same dimensions and as the input array,\\n        convolved with kernel.  The data type depends on the input\\n        array type.  If array is a floating point type, then the\\n        return array keeps the same data type, otherwise the type\\n        is ``numpy.float``.\\n\\n    Notes\\n    -----\\n    For masked arrays, masked values are treated as NaNs.  The convolution\\n    is always done at ``numpy.float`` precision.\\n    '\n    if boundary not in BOUNDARY_OPTIONS:\n        raise ValueError(f'Invalid boundary option: must be one of {BOUNDARY_OPTIONS}')\n    if nan_treatment not in ('interpolate', 'fill'):\n        raise ValueError(\"nan_treatment must be one of 'interpolate','fill'\")\n    n_threads = 1\n    passed_kernel = kernel\n    passed_array = array\n    array_internal = _copy_input_if_needed(passed_array, dtype=float, order='C', nan_treatment=nan_treatment, mask=mask, fill_value=np.nan)\n    array_dtype = getattr(passed_array, 'dtype', array_internal.dtype)\n    kernel_internal = _copy_input_if_needed(passed_kernel, dtype=float, order='C', nan_treatment=None, mask=None, fill_value=fill_value)\n    if has_even_axis(kernel_internal):\n        raise KernelSizeError('Kernel size must be odd in all axes.')\n    if isinstance(passed_array, Kernel) and isinstance(passed_kernel, Kernel):\n        warnings.warn(\"Both array and kernel are Kernel instances, hardwiring the following parameters: boundary='fill', fill_value=0, normalize_Kernel=True, nan_treatment='interpolate'\", AstropyUserWarning)\n        boundary = 'fill'\n        fill_value = 0\n        normalize_kernel = True\n        nan_treatment = 'interpolate'\n    if array_internal.ndim == 0:\n        raise Exception('cannot convolve 0-dimensional arrays')\n    elif array_internal.ndim > 3:\n        raise NotImplementedError('convolve only supports 1, 2, and 3-dimensional arrays at this time')\n    elif array_internal.ndim != kernel_internal.ndim:\n        raise Exception('array and kernel have differing number of dimensions.')\n    array_shape = np.array(array_internal.shape)\n    kernel_shape = np.array(kernel_internal.shape)\n    pad_width = kernel_shape // 2\n    if boundary is None and (not np.all(array_shape > 2 * pad_width)):\n        raise KernelSizeError(\"for boundary=None all kernel axes must be smaller than array's - use boundary in ['fill', 'extend', 'wrap'] instead.\")\n    nan_interpolate = nan_treatment == 'interpolate' and np.isnan(array_internal.sum())\n    if normalize_kernel or nan_interpolate:\n        kernel_sum = kernel_internal.sum()\n        kernel_sums_to_zero = np.isclose(kernel_sum, 0, atol=normalization_zero_tol)\n        if kernel_sum < 1.0 / MAX_NORMALIZATION or kernel_sums_to_zero:\n            if nan_interpolate:\n                raise ValueError(\"Setting nan_treatment='interpolate' requires the kernel to be normalized, but the input kernel has a sum close to zero. For a zero-sum kernel and data with NaNs, set nan_treatment='fill'.\")\n            else:\n                raise ValueError(f\"The kernel can't be normalized, because its sum is close to zero. The sum of the given kernel is < {1.0 / MAX_NORMALIZATION}\")\n    if preserve_nan or nan_treatment == 'fill':\n        initially_nan = np.isnan(array_internal)\n        if nan_treatment == 'fill':\n            array_internal[initially_nan] = fill_value\n    result = np.zeros(array_internal.shape, dtype=float, order='C')\n    embed_result_within_padded_region = True\n    array_to_convolve = array_internal\n    if boundary in ('fill', 'extend', 'wrap'):\n        embed_result_within_padded_region = False\n        if boundary == 'fill':\n            array_to_convolve = np.full(array_shape + 2 * pad_width, fill_value=fill_value, dtype=float, order='C')\n            if array_internal.ndim == 1:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0]] = array_internal\n            elif array_internal.ndim == 2:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0], pad_width[1]:array_shape[1] + pad_width[1]] = array_internal\n            else:\n                array_to_convolve[pad_width[0]:array_shape[0] + pad_width[0], pad_width[1]:array_shape[1] + pad_width[1], pad_width[2]:array_shape[2] + pad_width[2]] = array_internal\n        else:\n            np_pad_mode_dict = {'fill': 'constant', 'extend': 'edge', 'wrap': 'wrap'}\n            np_pad_mode = np_pad_mode_dict[boundary]\n            pad_width = kernel_shape // 2\n            if array_internal.ndim == 1:\n                np_pad_width = (pad_width[0],)\n            elif array_internal.ndim == 2:\n                np_pad_width = ((pad_width[0],), (pad_width[1],))\n            else:\n                np_pad_width = ((pad_width[0],), (pad_width[1],), (pad_width[2],))\n            array_to_convolve = np.pad(array_internal, pad_width=np_pad_width, mode=np_pad_mode)\n    _convolveNd_c(result, array_to_convolve, kernel_internal, nan_interpolate, embed_result_within_padded_region, n_threads)\n    if normalize_kernel:\n        if not nan_interpolate:\n            result /= kernel_sum\n    elif nan_interpolate:\n        result *= kernel_sum\n    if nan_interpolate and (not preserve_nan) and np.isnan(result.sum()):\n        warnings.warn(\"nan_treatment='interpolate', however, NaN values detected post convolution. A contiguous region of NaN values, larger than the kernel size, are present in the input array. Increase the kernel size to avoid this.\", AstropyUserWarning)\n    if preserve_nan:\n        result[initially_nan] = np.nan\n    array_unit = getattr(passed_array, 'unit', None)\n    if array_unit is not None:\n        result <<= array_unit\n    if isinstance(passed_array, Kernel):\n        if isinstance(passed_array, Kernel1D):\n            new_result = Kernel1D(array=result)\n        elif isinstance(passed_array, Kernel2D):\n            new_result = Kernel2D(array=result)\n        else:\n            raise TypeError('Only 1D and 2D Kernels are supported.')\n        new_result._is_bool = False\n        new_result._separable = passed_array._separable\n        if isinstance(passed_kernel, Kernel):\n            new_result._separable = new_result._separable and passed_kernel._separable\n        return new_result\n    elif array_dtype.kind == 'f':\n        try:\n            return result.astype(array_dtype, copy=False)\n        except TypeError:\n            return result.astype(array_dtype)\n    else:\n        return result"
        ]
    },
    {
        "func_name": "convolve_fft",
        "original": "@support_nddata(data='array')\ndef convolve_fft(array, kernel, boundary='fill', fill_value=0.0, nan_treatment='interpolate', normalize_kernel=True, normalization_zero_tol=1e-08, preserve_nan=False, mask=None, crop=True, return_fft=False, fft_pad=None, psf_pad=None, min_wt=0.0, allow_huge=False, fftn=np.fft.fftn, ifftn=np.fft.ifftn, complex_dtype=complex, dealias=False):\n    \"\"\"\n    Convolve an ndarray with an nd-kernel.  Returns a convolved image with\n    ``shape = array.shape``.  Assumes kernel is centered.\n\n    `convolve_fft` is very similar to `convolve` in that it replaces ``NaN``\n    values in the original image with interpolated values using the kernel as\n    an interpolation function.  However, it also includes many additional\n    options specific to the implementation.\n\n    `convolve_fft` differs from `scipy.signal.fftconvolve` in a few ways:\n\n    * It can treat ``NaN`` values as zeros or interpolate over them.\n    * ``inf`` values are treated as ``NaN``\n    * It optionally pads to the nearest faster sizes to improve FFT speed.\n      These sizes are optimized for the numpy and scipy implementations, and\n      ``fftconvolve`` uses them by default as well; when using other external\n      functions (see below), results may vary.\n    * Its only valid ``mode`` is 'same' (i.e., the same shape array is returned)\n    * It lets you use your own fft, e.g.,\n      `pyFFTW <https://pypi.org/project/pyFFTW/>`_ or\n      `pyFFTW3 <https://pypi.org/project/PyFFTW3/0.2.1/>`_ , which can lead to\n      performance improvements, depending on your system configuration.  pyFFTW3\n      is threaded, and therefore may yield significant performance benefits on\n      multi-core machines at the cost of greater memory requirements.  Specify\n      the ``fftn`` and ``ifftn`` keywords to override the default, which is\n      `numpy.fft.fftn` and `numpy.fft.ifftn`.  The `scipy.fft` functions also\n      offer somewhat better performance and a multi-threaded option.\n\n    Parameters\n    ----------\n    array : `numpy.ndarray`\n        Array to be convolved with ``kernel``.  It can be of any\n        dimensionality, though only 1, 2, and 3d arrays have been tested.\n    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`\n        The convolution kernel. The number of dimensions should match those\n        for the array.  The dimensions *do not* have to be odd in all directions,\n        unlike in the non-fft `convolve` function.  The kernel will be\n        normalized if ``normalize_kernel`` is set.  It is assumed to be centered\n        (i.e., shifts may result if your kernel is asymmetric)\n    boundary : {'fill', 'wrap'}, optional\n        A flag indicating how to handle boundaries:\n\n            * 'fill': set values outside the array boundary to fill_value\n              (default)\n            * 'wrap': periodic boundary\n\n        The `None` and 'extend' parameters are not supported for FFT-based\n        convolution.\n    fill_value : float, optional\n        The value to use outside the array when using boundary='fill'.\n    nan_treatment : {'interpolate', 'fill'}, optional\n        The method used to handle NaNs in the input ``array``:\n            * ``'interpolate'``: ``NaN`` values are replaced with\n              interpolated values using the kernel as an interpolation\n              function. Note that if the kernel has a sum equal to\n              zero, NaN interpolation is not possible and will raise an\n              exception.\n            * ``'fill'``: ``NaN`` values are replaced by ``fill_value``\n              prior to convolution.\n    normalize_kernel : callable or boolean, optional\n        If specified, this is the function to divide kernel by to normalize it.\n        e.g., ``normalize_kernel=np.sum`` means that kernel will be modified to be:\n        ``kernel = kernel / np.sum(kernel)``.  If True, defaults to\n        ``normalize_kernel = np.sum``.\n    normalization_zero_tol : float, optional\n        The absolute tolerance on whether the kernel is different than zero.\n        If the kernel sums to zero to within this precision, it cannot be\n        normalized. Default is \"1e-8\".\n    preserve_nan : bool, optional\n        After performing convolution, should pixels that were originally NaN\n        again become NaN?\n    mask : None or ndarray, optional\n        A \"mask\" array.  Shape must match ``array``, and anything that is masked\n        (i.e., not 0/`False`) will be set to NaN for the convolution.  If\n        `None`, no masking will be performed unless ``array`` is a masked array.\n        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is\n        masked if it is masked in either ``mask`` *or* ``array.mask``.\n    crop : bool, optional\n        Default on.  Return an image of the size of the larger of the input\n        image and the kernel.\n        If the image and kernel are asymmetric in opposite directions, will\n        return the largest image in both directions.\n        For example, if an input image has shape [100,3] but a kernel with shape\n        [6,6] is used, the output will be [100,6].\n    return_fft : bool, optional\n        Return the ``fft(image)*fft(kernel)`` instead of the convolution (which is\n        ``ifft(fft(image)*fft(kernel))``).  Useful for making PSDs.\n    fft_pad : bool, optional\n        Default on.  Zero-pad image to the nearest size supporting more efficient\n        execution of the FFT, generally values factorizable into the first 3-5\n        prime numbers.  With ``boundary='wrap'``, this will be disabled.\n    psf_pad : bool, optional\n        Zero-pad image to be at least the sum of the image sizes to avoid\n        edge-wrapping when smoothing.  This is enabled by default with\n        ``boundary='fill'``, but it can be overridden with a boolean option.\n        ``boundary='wrap'`` and ``psf_pad=True`` are not compatible.\n    min_wt : float, optional\n        If ignoring ``NaN`` / zeros, force all grid points with a weight less than\n        this value to ``NaN`` (the weight of a grid point with *no* ignored\n        neighbors is 1.0).\n        If ``min_wt`` is zero, then all zero-weight points will be set to zero\n        instead of ``NaN`` (which they would be otherwise, because 1/0 = nan).\n        See the examples below.\n    allow_huge : bool, optional\n        Allow huge arrays in the FFT?  If False, will raise an exception if the\n        array or kernel size is >1 GB.\n    fftn : callable, optional\n        The fft function.  Can be overridden to use your own ffts,\n        e.g. an fftw3 wrapper or scipy's fftn, ``fft=scipy.fftpack.fftn``.\n    ifftn : callable, optional\n        The inverse fft function. Can be overridden the same way ``fttn``.\n    complex_dtype : complex type, optional\n        Which complex dtype to use.  `numpy` has a range of options, from 64 to\n        256.\n    dealias: bool, optional\n        Default off. Zero-pad image to enable explicit dealiasing\n        of convolution. With ``boundary='wrap'``, this will be disabled.\n        Note that for an input of nd dimensions this will increase\n        the size of the temporary arrays by at least ``1.5**nd``.\n        This may result in significantly more memory usage.\n\n    Returns\n    -------\n    default : ndarray\n        ``array`` convolved with ``kernel``.  If ``return_fft`` is set, returns\n        ``fft(array) * fft(kernel)``.  If crop is not set, returns the\n        image, but with the fft-padded size instead of the input size.\n\n    Raises\n    ------\n    `ValueError`\n        If the array is bigger than 1 GB after padding, will raise this\n        exception unless ``allow_huge`` is True.\n\n    See Also\n    --------\n    convolve:\n        Convolve is a non-fft version of this code.  It is more memory\n        efficient and for small kernels can be faster.\n\n    Notes\n    -----\n    With ``psf_pad=True`` and a large PSF, the resulting data\n    can become large and consume a lot of memory. See Issue\n    https://github.com/astropy/astropy/pull/4366 and the update in\n    https://github.com/astropy/astropy/pull/11533 for further details.\n\n    Dealiasing of pseudospectral convolutions is necessary for\n    numerical stability of the underlying algorithms. A common\n    method for handling this is to zero pad the image by at least\n    1/2 to eliminate the wavenumbers which have been aliased\n    by convolution. This is so that the aliased 1/3 of the\n    results of the convolution computation can be thrown out. See\n    https://doi.org/10.1175/1520-0469(1971)028%3C1074:OTEOAI%3E2.0.CO;2\n    https://iopscience.iop.org/article/10.1088/1742-6596/318/7/072037\n\n    Note that if dealiasing is necessary to your application, but your\n    process is memory constrained, you may want to consider using\n    FFTW++: https://github.com/dealias/fftwpp. It includes python\n    wrappers for a pseudospectral convolution which will implicitly\n    dealias your convolution without the need for additional padding.\n    Note that one cannot use FFTW++'s convlution directly in this\n    method as in handles the entire convolution process internally.\n    Additionally, FFTW++ includes other useful pseudospectral methods to\n    consider.\n\n    Examples\n    --------\n    >>> convolve_fft([1, 0, 3], [1, 1, 1])\n    array([0.33333333, 1.33333333, 1.        ])\n\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1])\n    array([0.5, 2. , 1.5])\n\n    >>> convolve_fft([1, 0, 3], [0, 1, 0])  # doctest: +FLOAT_CMP\n    array([ 1.00000000e+00, -3.70074342e-17,  3.00000000e+00])\n\n    >>> convolve_fft([1, 2, 3], [1])\n    array([1., 2., 3.])\n\n    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment='interpolate')\n    array([1., 0., 3.])\n\n    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment='interpolate',\n    ...              min_wt=1e-8)\n    array([ 1., nan,  3.])\n\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment='interpolate')\n    array([0.5, 2. , 1.5])\n\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment='interpolate',\n    ...               normalize_kernel=True)\n    array([0.5, 2. , 1.5])\n\n    >>> import scipy.fft  # optional - requires scipy\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment='interpolate',\n    ...               normalize_kernel=True,\n    ...               fftn=scipy.fft.fftn, ifftn=scipy.fft.ifftn)\n    array([0.5, 2. , 1.5])\n\n    >>> fft_mp = lambda a: scipy.fft.fftn(a, workers=-1)  # use all available cores\n    >>> ifft_mp = lambda a: scipy.fft.ifftn(a, workers=-1)\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment='interpolate',\n    ...               normalize_kernel=True, fftn=fft_mp, ifftn=ifft_mp)\n    array([0.5, 2. , 1.5])\n    \"\"\"\n    if isinstance(kernel, Kernel):\n        kernel = kernel.array\n        if isinstance(array, Kernel):\n            raise TypeError(\"Can't convolve two kernels with convolve_fft.  Use convolve instead.\")\n    if nan_treatment not in ('interpolate', 'fill'):\n        raise ValueError(\"nan_treatment must be one of 'interpolate','fill'\")\n    array_unit = getattr(array, 'unit', None)\n    array = _copy_input_if_needed(array, dtype=complex, order='C', nan_treatment=nan_treatment, mask=mask, fill_value=np.nan)\n    kernel = _copy_input_if_needed(kernel, dtype=complex, order='C', nan_treatment=None, mask=None, fill_value=0)\n    if array.ndim != kernel.ndim:\n        raise ValueError('Image and kernel must have same number of dimensions')\n    arrayshape = array.shape\n    kernshape = kernel.shape\n    array_size_B = np.prod(arrayshape, dtype=np.int64) * np.dtype(complex_dtype).itemsize * u.byte\n    if array_size_B > 1 * u.GB and (not allow_huge):\n        raise ValueError(f'Size Error: Arrays will be {human_file_size(array_size_B)}.  Use allow_huge=True to override this exception.')\n    nanmaskarray = np.isnan(array) | np.isinf(array)\n    if nan_treatment == 'fill':\n        array[nanmaskarray] = fill_value\n    else:\n        array[nanmaskarray] = 0\n    nanmaskkernel = np.isnan(kernel) | np.isinf(kernel)\n    kernel[nanmaskkernel] = 0\n    if normalize_kernel is True:\n        if kernel.sum() < 1.0 / MAX_NORMALIZATION:\n            raise Exception(f\"The kernel can't be normalized, because its sum is close to zero. The sum of the given kernel is < {1.0 / MAX_NORMALIZATION}\")\n        kernel_scale = kernel.sum()\n        normalized_kernel = kernel / kernel_scale\n        kernel_scale = 1\n    elif normalize_kernel:\n        kernel_scale = normalize_kernel(kernel)\n        normalized_kernel = kernel / kernel_scale\n    else:\n        kernel_scale = kernel.sum()\n        if np.abs(kernel_scale) < normalization_zero_tol:\n            if nan_treatment == 'interpolate':\n                raise ValueError('Cannot interpolate NaNs with an unnormalizable kernel')\n            else:\n                kernel_scale = 1\n                normalized_kernel = kernel\n        else:\n            normalized_kernel = kernel / kernel_scale\n    if boundary is None:\n        warnings.warn(\"The convolve_fft version of boundary=None is equivalent to the convolve boundary='fill'.  There is no FFT equivalent to convolve's zero-if-kernel-leaves-boundary\", AstropyUserWarning)\n        if psf_pad is None:\n            psf_pad = True\n        if fft_pad is None:\n            fft_pad = True\n    elif boundary == 'fill':\n        if psf_pad is False:\n            warnings.warn(f\"psf_pad was set to {psf_pad}, which overrides the boundary='fill' setting.\", AstropyUserWarning)\n        else:\n            psf_pad = True\n        if fft_pad is None:\n            fft_pad = True\n    elif boundary == 'wrap':\n        if psf_pad:\n            raise ValueError(\"With boundary='wrap', psf_pad cannot be enabled.\")\n        psf_pad = False\n        if fft_pad:\n            raise ValueError(\"With boundary='wrap', fft_pad cannot be enabled.\")\n        fft_pad = False\n        if dealias:\n            raise ValueError(\"With boundary='wrap', dealias cannot be enabled.\")\n        fill_value = 0\n    elif boundary == 'extend':\n        raise NotImplementedError(\"The 'extend' option is not implemented for fft-based convolution\")\n    if psf_pad:\n        newshape = np.array(arrayshape) + np.array(kernshape)\n    else:\n        newshape = np.maximum(arrayshape, kernshape)\n    if dealias:\n        newshape += np.ceil(newshape / 2).astype(int)\n    if fft_pad:\n        newshape = _next_fast_lengths(newshape)\n    array_size_C = np.prod(newshape, dtype=np.int64) * np.dtype(complex_dtype).itemsize * u.byte\n    if array_size_C > 1 * u.GB and (not allow_huge):\n        raise ValueError(f'Size Error: Arrays will be {human_file_size(array_size_C)}.  Use allow_huge=True to override this exception.')\n    arrayslices = []\n    kernslices = []\n    for (newdimsize, arraydimsize, kerndimsize) in zip(newshape, arrayshape, kernshape):\n        center = newdimsize - (newdimsize + 1) // 2\n        arrayslices += [slice(center - arraydimsize // 2, center + (arraydimsize + 1) // 2)]\n        kernslices += [slice(center - kerndimsize // 2, center + (kerndimsize + 1) // 2)]\n    arrayslices = tuple(arrayslices)\n    kernslices = tuple(kernslices)\n    if not np.all(newshape == arrayshape):\n        if np.isfinite(fill_value):\n            bigarray = np.ones(newshape, dtype=complex_dtype) * fill_value\n        else:\n            bigarray = np.zeros(newshape, dtype=complex_dtype)\n        bigarray[arrayslices] = array\n    else:\n        bigarray = array\n    if not np.all(newshape == kernshape):\n        bigkernel = np.zeros(newshape, dtype=complex_dtype)\n        bigkernel[kernslices] = normalized_kernel\n    else:\n        bigkernel = normalized_kernel\n    arrayfft = fftn(bigarray)\n    kernfft = fftn(np.fft.ifftshift(bigkernel))\n    fftmult = arrayfft * kernfft\n    interpolate_nan = nan_treatment == 'interpolate'\n    if interpolate_nan:\n        if not np.isfinite(fill_value):\n            bigimwt = np.zeros(newshape, dtype=complex_dtype)\n        else:\n            bigimwt = np.ones(newshape, dtype=complex_dtype)\n        bigimwt[arrayslices] = 1.0 - nanmaskarray * interpolate_nan\n        wtfft = fftn(bigimwt)\n        wtfftmult = wtfft * kernfft\n        wtsm = ifftn(wtfftmult)\n        bigimwt[arrayslices] = wtsm.real[arrayslices]\n    else:\n        bigimwt = 1\n    if np.isnan(fftmult).any():\n        raise ValueError('Encountered NaNs in convolve.  This is disallowed.')\n    fftmult *= kernel_scale\n    if array_unit is not None:\n        fftmult <<= array_unit\n    if return_fft:\n        return fftmult\n    if interpolate_nan:\n        with np.errstate(divide='ignore', invalid='ignore'):\n            rifft = ifftn(fftmult) / bigimwt\n        if not np.isscalar(bigimwt):\n            if min_wt > 0.0:\n                rifft[bigimwt < min_wt] = np.nan\n            else:\n                rifft[bigimwt < 10 * np.finfo(bigimwt.dtype).eps] = 0.0\n    else:\n        rifft = ifftn(fftmult)\n    if preserve_nan:\n        rifft[arrayslices][nanmaskarray] = np.nan\n    if crop:\n        result = rifft[arrayslices].real\n        return result\n    else:\n        return rifft.real",
        "mutated": [
            "@support_nddata(data='array')\ndef convolve_fft(array, kernel, boundary='fill', fill_value=0.0, nan_treatment='interpolate', normalize_kernel=True, normalization_zero_tol=1e-08, preserve_nan=False, mask=None, crop=True, return_fft=False, fft_pad=None, psf_pad=None, min_wt=0.0, allow_huge=False, fftn=np.fft.fftn, ifftn=np.fft.ifftn, complex_dtype=complex, dealias=False):\n    if False:\n        i = 10\n    '\\n    Convolve an ndarray with an nd-kernel.  Returns a convolved image with\\n    ``shape = array.shape``.  Assumes kernel is centered.\\n\\n    `convolve_fft` is very similar to `convolve` in that it replaces ``NaN``\\n    values in the original image with interpolated values using the kernel as\\n    an interpolation function.  However, it also includes many additional\\n    options specific to the implementation.\\n\\n    `convolve_fft` differs from `scipy.signal.fftconvolve` in a few ways:\\n\\n    * It can treat ``NaN`` values as zeros or interpolate over them.\\n    * ``inf`` values are treated as ``NaN``\\n    * It optionally pads to the nearest faster sizes to improve FFT speed.\\n      These sizes are optimized for the numpy and scipy implementations, and\\n      ``fftconvolve`` uses them by default as well; when using other external\\n      functions (see below), results may vary.\\n    * Its only valid ``mode`` is \\'same\\' (i.e., the same shape array is returned)\\n    * It lets you use your own fft, e.g.,\\n      `pyFFTW <https://pypi.org/project/pyFFTW/>`_ or\\n      `pyFFTW3 <https://pypi.org/project/PyFFTW3/0.2.1/>`_ , which can lead to\\n      performance improvements, depending on your system configuration.  pyFFTW3\\n      is threaded, and therefore may yield significant performance benefits on\\n      multi-core machines at the cost of greater memory requirements.  Specify\\n      the ``fftn`` and ``ifftn`` keywords to override the default, which is\\n      `numpy.fft.fftn` and `numpy.fft.ifftn`.  The `scipy.fft` functions also\\n      offer somewhat better performance and a multi-threaded option.\\n\\n    Parameters\\n    ----------\\n    array : `numpy.ndarray`\\n        Array to be convolved with ``kernel``.  It can be of any\\n        dimensionality, though only 1, 2, and 3d arrays have been tested.\\n    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`\\n        The convolution kernel. The number of dimensions should match those\\n        for the array.  The dimensions *do not* have to be odd in all directions,\\n        unlike in the non-fft `convolve` function.  The kernel will be\\n        normalized if ``normalize_kernel`` is set.  It is assumed to be centered\\n        (i.e., shifts may result if your kernel is asymmetric)\\n    boundary : {\\'fill\\', \\'wrap\\'}, optional\\n        A flag indicating how to handle boundaries:\\n\\n            * \\'fill\\': set values outside the array boundary to fill_value\\n              (default)\\n            * \\'wrap\\': periodic boundary\\n\\n        The `None` and \\'extend\\' parameters are not supported for FFT-based\\n        convolution.\\n    fill_value : float, optional\\n        The value to use outside the array when using boundary=\\'fill\\'.\\n    nan_treatment : {\\'interpolate\\', \\'fill\\'}, optional\\n        The method used to handle NaNs in the input ``array``:\\n            * ``\\'interpolate\\'``: ``NaN`` values are replaced with\\n              interpolated values using the kernel as an interpolation\\n              function. Note that if the kernel has a sum equal to\\n              zero, NaN interpolation is not possible and will raise an\\n              exception.\\n            * ``\\'fill\\'``: ``NaN`` values are replaced by ``fill_value``\\n              prior to convolution.\\n    normalize_kernel : callable or boolean, optional\\n        If specified, this is the function to divide kernel by to normalize it.\\n        e.g., ``normalize_kernel=np.sum`` means that kernel will be modified to be:\\n        ``kernel = kernel / np.sum(kernel)``.  If True, defaults to\\n        ``normalize_kernel = np.sum``.\\n    normalization_zero_tol : float, optional\\n        The absolute tolerance on whether the kernel is different than zero.\\n        If the kernel sums to zero to within this precision, it cannot be\\n        normalized. Default is \"1e-8\".\\n    preserve_nan : bool, optional\\n        After performing convolution, should pixels that were originally NaN\\n        again become NaN?\\n    mask : None or ndarray, optional\\n        A \"mask\" array.  Shape must match ``array``, and anything that is masked\\n        (i.e., not 0/`False`) will be set to NaN for the convolution.  If\\n        `None`, no masking will be performed unless ``array`` is a masked array.\\n        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is\\n        masked if it is masked in either ``mask`` *or* ``array.mask``.\\n    crop : bool, optional\\n        Default on.  Return an image of the size of the larger of the input\\n        image and the kernel.\\n        If the image and kernel are asymmetric in opposite directions, will\\n        return the largest image in both directions.\\n        For example, if an input image has shape [100,3] but a kernel with shape\\n        [6,6] is used, the output will be [100,6].\\n    return_fft : bool, optional\\n        Return the ``fft(image)*fft(kernel)`` instead of the convolution (which is\\n        ``ifft(fft(image)*fft(kernel))``).  Useful for making PSDs.\\n    fft_pad : bool, optional\\n        Default on.  Zero-pad image to the nearest size supporting more efficient\\n        execution of the FFT, generally values factorizable into the first 3-5\\n        prime numbers.  With ``boundary=\\'wrap\\'``, this will be disabled.\\n    psf_pad : bool, optional\\n        Zero-pad image to be at least the sum of the image sizes to avoid\\n        edge-wrapping when smoothing.  This is enabled by default with\\n        ``boundary=\\'fill\\'``, but it can be overridden with a boolean option.\\n        ``boundary=\\'wrap\\'`` and ``psf_pad=True`` are not compatible.\\n    min_wt : float, optional\\n        If ignoring ``NaN`` / zeros, force all grid points with a weight less than\\n        this value to ``NaN`` (the weight of a grid point with *no* ignored\\n        neighbors is 1.0).\\n        If ``min_wt`` is zero, then all zero-weight points will be set to zero\\n        instead of ``NaN`` (which they would be otherwise, because 1/0 = nan).\\n        See the examples below.\\n    allow_huge : bool, optional\\n        Allow huge arrays in the FFT?  If False, will raise an exception if the\\n        array or kernel size is >1 GB.\\n    fftn : callable, optional\\n        The fft function.  Can be overridden to use your own ffts,\\n        e.g. an fftw3 wrapper or scipy\\'s fftn, ``fft=scipy.fftpack.fftn``.\\n    ifftn : callable, optional\\n        The inverse fft function. Can be overridden the same way ``fttn``.\\n    complex_dtype : complex type, optional\\n        Which complex dtype to use.  `numpy` has a range of options, from 64 to\\n        256.\\n    dealias: bool, optional\\n        Default off. Zero-pad image to enable explicit dealiasing\\n        of convolution. With ``boundary=\\'wrap\\'``, this will be disabled.\\n        Note that for an input of nd dimensions this will increase\\n        the size of the temporary arrays by at least ``1.5**nd``.\\n        This may result in significantly more memory usage.\\n\\n    Returns\\n    -------\\n    default : ndarray\\n        ``array`` convolved with ``kernel``.  If ``return_fft`` is set, returns\\n        ``fft(array) * fft(kernel)``.  If crop is not set, returns the\\n        image, but with the fft-padded size instead of the input size.\\n\\n    Raises\\n    ------\\n    `ValueError`\\n        If the array is bigger than 1 GB after padding, will raise this\\n        exception unless ``allow_huge`` is True.\\n\\n    See Also\\n    --------\\n    convolve:\\n        Convolve is a non-fft version of this code.  It is more memory\\n        efficient and for small kernels can be faster.\\n\\n    Notes\\n    -----\\n    With ``psf_pad=True`` and a large PSF, the resulting data\\n    can become large and consume a lot of memory. See Issue\\n    https://github.com/astropy/astropy/pull/4366 and the update in\\n    https://github.com/astropy/astropy/pull/11533 for further details.\\n\\n    Dealiasing of pseudospectral convolutions is necessary for\\n    numerical stability of the underlying algorithms. A common\\n    method for handling this is to zero pad the image by at least\\n    1/2 to eliminate the wavenumbers which have been aliased\\n    by convolution. This is so that the aliased 1/3 of the\\n    results of the convolution computation can be thrown out. See\\n    https://doi.org/10.1175/1520-0469(1971)028%3C1074:OTEOAI%3E2.0.CO;2\\n    https://iopscience.iop.org/article/10.1088/1742-6596/318/7/072037\\n\\n    Note that if dealiasing is necessary to your application, but your\\n    process is memory constrained, you may want to consider using\\n    FFTW++: https://github.com/dealias/fftwpp. It includes python\\n    wrappers for a pseudospectral convolution which will implicitly\\n    dealias your convolution without the need for additional padding.\\n    Note that one cannot use FFTW++\\'s convlution directly in this\\n    method as in handles the entire convolution process internally.\\n    Additionally, FFTW++ includes other useful pseudospectral methods to\\n    consider.\\n\\n    Examples\\n    --------\\n    >>> convolve_fft([1, 0, 3], [1, 1, 1])\\n    array([0.33333333, 1.33333333, 1.        ])\\n\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1])\\n    array([0.5, 2. , 1.5])\\n\\n    >>> convolve_fft([1, 0, 3], [0, 1, 0])  # doctest: +FLOAT_CMP\\n    array([ 1.00000000e+00, -3.70074342e-17,  3.00000000e+00])\\n\\n    >>> convolve_fft([1, 2, 3], [1])\\n    array([1., 2., 3.])\\n\\n    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment=\\'interpolate\\')\\n    array([1., 0., 3.])\\n\\n    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment=\\'interpolate\\',\\n    ...              min_wt=1e-8)\\n    array([ 1., nan,  3.])\\n\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\')\\n    array([0.5, 2. , 1.5])\\n\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\',\\n    ...               normalize_kernel=True)\\n    array([0.5, 2. , 1.5])\\n\\n    >>> import scipy.fft  # optional - requires scipy\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\',\\n    ...               normalize_kernel=True,\\n    ...               fftn=scipy.fft.fftn, ifftn=scipy.fft.ifftn)\\n    array([0.5, 2. , 1.5])\\n\\n    >>> fft_mp = lambda a: scipy.fft.fftn(a, workers=-1)  # use all available cores\\n    >>> ifft_mp = lambda a: scipy.fft.ifftn(a, workers=-1)\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\',\\n    ...               normalize_kernel=True, fftn=fft_mp, ifftn=ifft_mp)\\n    array([0.5, 2. , 1.5])\\n    '\n    if isinstance(kernel, Kernel):\n        kernel = kernel.array\n        if isinstance(array, Kernel):\n            raise TypeError(\"Can't convolve two kernels with convolve_fft.  Use convolve instead.\")\n    if nan_treatment not in ('interpolate', 'fill'):\n        raise ValueError(\"nan_treatment must be one of 'interpolate','fill'\")\n    array_unit = getattr(array, 'unit', None)\n    array = _copy_input_if_needed(array, dtype=complex, order='C', nan_treatment=nan_treatment, mask=mask, fill_value=np.nan)\n    kernel = _copy_input_if_needed(kernel, dtype=complex, order='C', nan_treatment=None, mask=None, fill_value=0)\n    if array.ndim != kernel.ndim:\n        raise ValueError('Image and kernel must have same number of dimensions')\n    arrayshape = array.shape\n    kernshape = kernel.shape\n    array_size_B = np.prod(arrayshape, dtype=np.int64) * np.dtype(complex_dtype).itemsize * u.byte\n    if array_size_B > 1 * u.GB and (not allow_huge):\n        raise ValueError(f'Size Error: Arrays will be {human_file_size(array_size_B)}.  Use allow_huge=True to override this exception.')\n    nanmaskarray = np.isnan(array) | np.isinf(array)\n    if nan_treatment == 'fill':\n        array[nanmaskarray] = fill_value\n    else:\n        array[nanmaskarray] = 0\n    nanmaskkernel = np.isnan(kernel) | np.isinf(kernel)\n    kernel[nanmaskkernel] = 0\n    if normalize_kernel is True:\n        if kernel.sum() < 1.0 / MAX_NORMALIZATION:\n            raise Exception(f\"The kernel can't be normalized, because its sum is close to zero. The sum of the given kernel is < {1.0 / MAX_NORMALIZATION}\")\n        kernel_scale = kernel.sum()\n        normalized_kernel = kernel / kernel_scale\n        kernel_scale = 1\n    elif normalize_kernel:\n        kernel_scale = normalize_kernel(kernel)\n        normalized_kernel = kernel / kernel_scale\n    else:\n        kernel_scale = kernel.sum()\n        if np.abs(kernel_scale) < normalization_zero_tol:\n            if nan_treatment == 'interpolate':\n                raise ValueError('Cannot interpolate NaNs with an unnormalizable kernel')\n            else:\n                kernel_scale = 1\n                normalized_kernel = kernel\n        else:\n            normalized_kernel = kernel / kernel_scale\n    if boundary is None:\n        warnings.warn(\"The convolve_fft version of boundary=None is equivalent to the convolve boundary='fill'.  There is no FFT equivalent to convolve's zero-if-kernel-leaves-boundary\", AstropyUserWarning)\n        if psf_pad is None:\n            psf_pad = True\n        if fft_pad is None:\n            fft_pad = True\n    elif boundary == 'fill':\n        if psf_pad is False:\n            warnings.warn(f\"psf_pad was set to {psf_pad}, which overrides the boundary='fill' setting.\", AstropyUserWarning)\n        else:\n            psf_pad = True\n        if fft_pad is None:\n            fft_pad = True\n    elif boundary == 'wrap':\n        if psf_pad:\n            raise ValueError(\"With boundary='wrap', psf_pad cannot be enabled.\")\n        psf_pad = False\n        if fft_pad:\n            raise ValueError(\"With boundary='wrap', fft_pad cannot be enabled.\")\n        fft_pad = False\n        if dealias:\n            raise ValueError(\"With boundary='wrap', dealias cannot be enabled.\")\n        fill_value = 0\n    elif boundary == 'extend':\n        raise NotImplementedError(\"The 'extend' option is not implemented for fft-based convolution\")\n    if psf_pad:\n        newshape = np.array(arrayshape) + np.array(kernshape)\n    else:\n        newshape = np.maximum(arrayshape, kernshape)\n    if dealias:\n        newshape += np.ceil(newshape / 2).astype(int)\n    if fft_pad:\n        newshape = _next_fast_lengths(newshape)\n    array_size_C = np.prod(newshape, dtype=np.int64) * np.dtype(complex_dtype).itemsize * u.byte\n    if array_size_C > 1 * u.GB and (not allow_huge):\n        raise ValueError(f'Size Error: Arrays will be {human_file_size(array_size_C)}.  Use allow_huge=True to override this exception.')\n    arrayslices = []\n    kernslices = []\n    for (newdimsize, arraydimsize, kerndimsize) in zip(newshape, arrayshape, kernshape):\n        center = newdimsize - (newdimsize + 1) // 2\n        arrayslices += [slice(center - arraydimsize // 2, center + (arraydimsize + 1) // 2)]\n        kernslices += [slice(center - kerndimsize // 2, center + (kerndimsize + 1) // 2)]\n    arrayslices = tuple(arrayslices)\n    kernslices = tuple(kernslices)\n    if not np.all(newshape == arrayshape):\n        if np.isfinite(fill_value):\n            bigarray = np.ones(newshape, dtype=complex_dtype) * fill_value\n        else:\n            bigarray = np.zeros(newshape, dtype=complex_dtype)\n        bigarray[arrayslices] = array\n    else:\n        bigarray = array\n    if not np.all(newshape == kernshape):\n        bigkernel = np.zeros(newshape, dtype=complex_dtype)\n        bigkernel[kernslices] = normalized_kernel\n    else:\n        bigkernel = normalized_kernel\n    arrayfft = fftn(bigarray)\n    kernfft = fftn(np.fft.ifftshift(bigkernel))\n    fftmult = arrayfft * kernfft\n    interpolate_nan = nan_treatment == 'interpolate'\n    if interpolate_nan:\n        if not np.isfinite(fill_value):\n            bigimwt = np.zeros(newshape, dtype=complex_dtype)\n        else:\n            bigimwt = np.ones(newshape, dtype=complex_dtype)\n        bigimwt[arrayslices] = 1.0 - nanmaskarray * interpolate_nan\n        wtfft = fftn(bigimwt)\n        wtfftmult = wtfft * kernfft\n        wtsm = ifftn(wtfftmult)\n        bigimwt[arrayslices] = wtsm.real[arrayslices]\n    else:\n        bigimwt = 1\n    if np.isnan(fftmult).any():\n        raise ValueError('Encountered NaNs in convolve.  This is disallowed.')\n    fftmult *= kernel_scale\n    if array_unit is not None:\n        fftmult <<= array_unit\n    if return_fft:\n        return fftmult\n    if interpolate_nan:\n        with np.errstate(divide='ignore', invalid='ignore'):\n            rifft = ifftn(fftmult) / bigimwt\n        if not np.isscalar(bigimwt):\n            if min_wt > 0.0:\n                rifft[bigimwt < min_wt] = np.nan\n            else:\n                rifft[bigimwt < 10 * np.finfo(bigimwt.dtype).eps] = 0.0\n    else:\n        rifft = ifftn(fftmult)\n    if preserve_nan:\n        rifft[arrayslices][nanmaskarray] = np.nan\n    if crop:\n        result = rifft[arrayslices].real\n        return result\n    else:\n        return rifft.real",
            "@support_nddata(data='array')\ndef convolve_fft(array, kernel, boundary='fill', fill_value=0.0, nan_treatment='interpolate', normalize_kernel=True, normalization_zero_tol=1e-08, preserve_nan=False, mask=None, crop=True, return_fft=False, fft_pad=None, psf_pad=None, min_wt=0.0, allow_huge=False, fftn=np.fft.fftn, ifftn=np.fft.ifftn, complex_dtype=complex, dealias=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Convolve an ndarray with an nd-kernel.  Returns a convolved image with\\n    ``shape = array.shape``.  Assumes kernel is centered.\\n\\n    `convolve_fft` is very similar to `convolve` in that it replaces ``NaN``\\n    values in the original image with interpolated values using the kernel as\\n    an interpolation function.  However, it also includes many additional\\n    options specific to the implementation.\\n\\n    `convolve_fft` differs from `scipy.signal.fftconvolve` in a few ways:\\n\\n    * It can treat ``NaN`` values as zeros or interpolate over them.\\n    * ``inf`` values are treated as ``NaN``\\n    * It optionally pads to the nearest faster sizes to improve FFT speed.\\n      These sizes are optimized for the numpy and scipy implementations, and\\n      ``fftconvolve`` uses them by default as well; when using other external\\n      functions (see below), results may vary.\\n    * Its only valid ``mode`` is \\'same\\' (i.e., the same shape array is returned)\\n    * It lets you use your own fft, e.g.,\\n      `pyFFTW <https://pypi.org/project/pyFFTW/>`_ or\\n      `pyFFTW3 <https://pypi.org/project/PyFFTW3/0.2.1/>`_ , which can lead to\\n      performance improvements, depending on your system configuration.  pyFFTW3\\n      is threaded, and therefore may yield significant performance benefits on\\n      multi-core machines at the cost of greater memory requirements.  Specify\\n      the ``fftn`` and ``ifftn`` keywords to override the default, which is\\n      `numpy.fft.fftn` and `numpy.fft.ifftn`.  The `scipy.fft` functions also\\n      offer somewhat better performance and a multi-threaded option.\\n\\n    Parameters\\n    ----------\\n    array : `numpy.ndarray`\\n        Array to be convolved with ``kernel``.  It can be of any\\n        dimensionality, though only 1, 2, and 3d arrays have been tested.\\n    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`\\n        The convolution kernel. The number of dimensions should match those\\n        for the array.  The dimensions *do not* have to be odd in all directions,\\n        unlike in the non-fft `convolve` function.  The kernel will be\\n        normalized if ``normalize_kernel`` is set.  It is assumed to be centered\\n        (i.e., shifts may result if your kernel is asymmetric)\\n    boundary : {\\'fill\\', \\'wrap\\'}, optional\\n        A flag indicating how to handle boundaries:\\n\\n            * \\'fill\\': set values outside the array boundary to fill_value\\n              (default)\\n            * \\'wrap\\': periodic boundary\\n\\n        The `None` and \\'extend\\' parameters are not supported for FFT-based\\n        convolution.\\n    fill_value : float, optional\\n        The value to use outside the array when using boundary=\\'fill\\'.\\n    nan_treatment : {\\'interpolate\\', \\'fill\\'}, optional\\n        The method used to handle NaNs in the input ``array``:\\n            * ``\\'interpolate\\'``: ``NaN`` values are replaced with\\n              interpolated values using the kernel as an interpolation\\n              function. Note that if the kernel has a sum equal to\\n              zero, NaN interpolation is not possible and will raise an\\n              exception.\\n            * ``\\'fill\\'``: ``NaN`` values are replaced by ``fill_value``\\n              prior to convolution.\\n    normalize_kernel : callable or boolean, optional\\n        If specified, this is the function to divide kernel by to normalize it.\\n        e.g., ``normalize_kernel=np.sum`` means that kernel will be modified to be:\\n        ``kernel = kernel / np.sum(kernel)``.  If True, defaults to\\n        ``normalize_kernel = np.sum``.\\n    normalization_zero_tol : float, optional\\n        The absolute tolerance on whether the kernel is different than zero.\\n        If the kernel sums to zero to within this precision, it cannot be\\n        normalized. Default is \"1e-8\".\\n    preserve_nan : bool, optional\\n        After performing convolution, should pixels that were originally NaN\\n        again become NaN?\\n    mask : None or ndarray, optional\\n        A \"mask\" array.  Shape must match ``array``, and anything that is masked\\n        (i.e., not 0/`False`) will be set to NaN for the convolution.  If\\n        `None`, no masking will be performed unless ``array`` is a masked array.\\n        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is\\n        masked if it is masked in either ``mask`` *or* ``array.mask``.\\n    crop : bool, optional\\n        Default on.  Return an image of the size of the larger of the input\\n        image and the kernel.\\n        If the image and kernel are asymmetric in opposite directions, will\\n        return the largest image in both directions.\\n        For example, if an input image has shape [100,3] but a kernel with shape\\n        [6,6] is used, the output will be [100,6].\\n    return_fft : bool, optional\\n        Return the ``fft(image)*fft(kernel)`` instead of the convolution (which is\\n        ``ifft(fft(image)*fft(kernel))``).  Useful for making PSDs.\\n    fft_pad : bool, optional\\n        Default on.  Zero-pad image to the nearest size supporting more efficient\\n        execution of the FFT, generally values factorizable into the first 3-5\\n        prime numbers.  With ``boundary=\\'wrap\\'``, this will be disabled.\\n    psf_pad : bool, optional\\n        Zero-pad image to be at least the sum of the image sizes to avoid\\n        edge-wrapping when smoothing.  This is enabled by default with\\n        ``boundary=\\'fill\\'``, but it can be overridden with a boolean option.\\n        ``boundary=\\'wrap\\'`` and ``psf_pad=True`` are not compatible.\\n    min_wt : float, optional\\n        If ignoring ``NaN`` / zeros, force all grid points with a weight less than\\n        this value to ``NaN`` (the weight of a grid point with *no* ignored\\n        neighbors is 1.0).\\n        If ``min_wt`` is zero, then all zero-weight points will be set to zero\\n        instead of ``NaN`` (which they would be otherwise, because 1/0 = nan).\\n        See the examples below.\\n    allow_huge : bool, optional\\n        Allow huge arrays in the FFT?  If False, will raise an exception if the\\n        array or kernel size is >1 GB.\\n    fftn : callable, optional\\n        The fft function.  Can be overridden to use your own ffts,\\n        e.g. an fftw3 wrapper or scipy\\'s fftn, ``fft=scipy.fftpack.fftn``.\\n    ifftn : callable, optional\\n        The inverse fft function. Can be overridden the same way ``fttn``.\\n    complex_dtype : complex type, optional\\n        Which complex dtype to use.  `numpy` has a range of options, from 64 to\\n        256.\\n    dealias: bool, optional\\n        Default off. Zero-pad image to enable explicit dealiasing\\n        of convolution. With ``boundary=\\'wrap\\'``, this will be disabled.\\n        Note that for an input of nd dimensions this will increase\\n        the size of the temporary arrays by at least ``1.5**nd``.\\n        This may result in significantly more memory usage.\\n\\n    Returns\\n    -------\\n    default : ndarray\\n        ``array`` convolved with ``kernel``.  If ``return_fft`` is set, returns\\n        ``fft(array) * fft(kernel)``.  If crop is not set, returns the\\n        image, but with the fft-padded size instead of the input size.\\n\\n    Raises\\n    ------\\n    `ValueError`\\n        If the array is bigger than 1 GB after padding, will raise this\\n        exception unless ``allow_huge`` is True.\\n\\n    See Also\\n    --------\\n    convolve:\\n        Convolve is a non-fft version of this code.  It is more memory\\n        efficient and for small kernels can be faster.\\n\\n    Notes\\n    -----\\n    With ``psf_pad=True`` and a large PSF, the resulting data\\n    can become large and consume a lot of memory. See Issue\\n    https://github.com/astropy/astropy/pull/4366 and the update in\\n    https://github.com/astropy/astropy/pull/11533 for further details.\\n\\n    Dealiasing of pseudospectral convolutions is necessary for\\n    numerical stability of the underlying algorithms. A common\\n    method for handling this is to zero pad the image by at least\\n    1/2 to eliminate the wavenumbers which have been aliased\\n    by convolution. This is so that the aliased 1/3 of the\\n    results of the convolution computation can be thrown out. See\\n    https://doi.org/10.1175/1520-0469(1971)028%3C1074:OTEOAI%3E2.0.CO;2\\n    https://iopscience.iop.org/article/10.1088/1742-6596/318/7/072037\\n\\n    Note that if dealiasing is necessary to your application, but your\\n    process is memory constrained, you may want to consider using\\n    FFTW++: https://github.com/dealias/fftwpp. It includes python\\n    wrappers for a pseudospectral convolution which will implicitly\\n    dealias your convolution without the need for additional padding.\\n    Note that one cannot use FFTW++\\'s convlution directly in this\\n    method as in handles the entire convolution process internally.\\n    Additionally, FFTW++ includes other useful pseudospectral methods to\\n    consider.\\n\\n    Examples\\n    --------\\n    >>> convolve_fft([1, 0, 3], [1, 1, 1])\\n    array([0.33333333, 1.33333333, 1.        ])\\n\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1])\\n    array([0.5, 2. , 1.5])\\n\\n    >>> convolve_fft([1, 0, 3], [0, 1, 0])  # doctest: +FLOAT_CMP\\n    array([ 1.00000000e+00, -3.70074342e-17,  3.00000000e+00])\\n\\n    >>> convolve_fft([1, 2, 3], [1])\\n    array([1., 2., 3.])\\n\\n    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment=\\'interpolate\\')\\n    array([1., 0., 3.])\\n\\n    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment=\\'interpolate\\',\\n    ...              min_wt=1e-8)\\n    array([ 1., nan,  3.])\\n\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\')\\n    array([0.5, 2. , 1.5])\\n\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\',\\n    ...               normalize_kernel=True)\\n    array([0.5, 2. , 1.5])\\n\\n    >>> import scipy.fft  # optional - requires scipy\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\',\\n    ...               normalize_kernel=True,\\n    ...               fftn=scipy.fft.fftn, ifftn=scipy.fft.ifftn)\\n    array([0.5, 2. , 1.5])\\n\\n    >>> fft_mp = lambda a: scipy.fft.fftn(a, workers=-1)  # use all available cores\\n    >>> ifft_mp = lambda a: scipy.fft.ifftn(a, workers=-1)\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\',\\n    ...               normalize_kernel=True, fftn=fft_mp, ifftn=ifft_mp)\\n    array([0.5, 2. , 1.5])\\n    '\n    if isinstance(kernel, Kernel):\n        kernel = kernel.array\n        if isinstance(array, Kernel):\n            raise TypeError(\"Can't convolve two kernels with convolve_fft.  Use convolve instead.\")\n    if nan_treatment not in ('interpolate', 'fill'):\n        raise ValueError(\"nan_treatment must be one of 'interpolate','fill'\")\n    array_unit = getattr(array, 'unit', None)\n    array = _copy_input_if_needed(array, dtype=complex, order='C', nan_treatment=nan_treatment, mask=mask, fill_value=np.nan)\n    kernel = _copy_input_if_needed(kernel, dtype=complex, order='C', nan_treatment=None, mask=None, fill_value=0)\n    if array.ndim != kernel.ndim:\n        raise ValueError('Image and kernel must have same number of dimensions')\n    arrayshape = array.shape\n    kernshape = kernel.shape\n    array_size_B = np.prod(arrayshape, dtype=np.int64) * np.dtype(complex_dtype).itemsize * u.byte\n    if array_size_B > 1 * u.GB and (not allow_huge):\n        raise ValueError(f'Size Error: Arrays will be {human_file_size(array_size_B)}.  Use allow_huge=True to override this exception.')\n    nanmaskarray = np.isnan(array) | np.isinf(array)\n    if nan_treatment == 'fill':\n        array[nanmaskarray] = fill_value\n    else:\n        array[nanmaskarray] = 0\n    nanmaskkernel = np.isnan(kernel) | np.isinf(kernel)\n    kernel[nanmaskkernel] = 0\n    if normalize_kernel is True:\n        if kernel.sum() < 1.0 / MAX_NORMALIZATION:\n            raise Exception(f\"The kernel can't be normalized, because its sum is close to zero. The sum of the given kernel is < {1.0 / MAX_NORMALIZATION}\")\n        kernel_scale = kernel.sum()\n        normalized_kernel = kernel / kernel_scale\n        kernel_scale = 1\n    elif normalize_kernel:\n        kernel_scale = normalize_kernel(kernel)\n        normalized_kernel = kernel / kernel_scale\n    else:\n        kernel_scale = kernel.sum()\n        if np.abs(kernel_scale) < normalization_zero_tol:\n            if nan_treatment == 'interpolate':\n                raise ValueError('Cannot interpolate NaNs with an unnormalizable kernel')\n            else:\n                kernel_scale = 1\n                normalized_kernel = kernel\n        else:\n            normalized_kernel = kernel / kernel_scale\n    if boundary is None:\n        warnings.warn(\"The convolve_fft version of boundary=None is equivalent to the convolve boundary='fill'.  There is no FFT equivalent to convolve's zero-if-kernel-leaves-boundary\", AstropyUserWarning)\n        if psf_pad is None:\n            psf_pad = True\n        if fft_pad is None:\n            fft_pad = True\n    elif boundary == 'fill':\n        if psf_pad is False:\n            warnings.warn(f\"psf_pad was set to {psf_pad}, which overrides the boundary='fill' setting.\", AstropyUserWarning)\n        else:\n            psf_pad = True\n        if fft_pad is None:\n            fft_pad = True\n    elif boundary == 'wrap':\n        if psf_pad:\n            raise ValueError(\"With boundary='wrap', psf_pad cannot be enabled.\")\n        psf_pad = False\n        if fft_pad:\n            raise ValueError(\"With boundary='wrap', fft_pad cannot be enabled.\")\n        fft_pad = False\n        if dealias:\n            raise ValueError(\"With boundary='wrap', dealias cannot be enabled.\")\n        fill_value = 0\n    elif boundary == 'extend':\n        raise NotImplementedError(\"The 'extend' option is not implemented for fft-based convolution\")\n    if psf_pad:\n        newshape = np.array(arrayshape) + np.array(kernshape)\n    else:\n        newshape = np.maximum(arrayshape, kernshape)\n    if dealias:\n        newshape += np.ceil(newshape / 2).astype(int)\n    if fft_pad:\n        newshape = _next_fast_lengths(newshape)\n    array_size_C = np.prod(newshape, dtype=np.int64) * np.dtype(complex_dtype).itemsize * u.byte\n    if array_size_C > 1 * u.GB and (not allow_huge):\n        raise ValueError(f'Size Error: Arrays will be {human_file_size(array_size_C)}.  Use allow_huge=True to override this exception.')\n    arrayslices = []\n    kernslices = []\n    for (newdimsize, arraydimsize, kerndimsize) in zip(newshape, arrayshape, kernshape):\n        center = newdimsize - (newdimsize + 1) // 2\n        arrayslices += [slice(center - arraydimsize // 2, center + (arraydimsize + 1) // 2)]\n        kernslices += [slice(center - kerndimsize // 2, center + (kerndimsize + 1) // 2)]\n    arrayslices = tuple(arrayslices)\n    kernslices = tuple(kernslices)\n    if not np.all(newshape == arrayshape):\n        if np.isfinite(fill_value):\n            bigarray = np.ones(newshape, dtype=complex_dtype) * fill_value\n        else:\n            bigarray = np.zeros(newshape, dtype=complex_dtype)\n        bigarray[arrayslices] = array\n    else:\n        bigarray = array\n    if not np.all(newshape == kernshape):\n        bigkernel = np.zeros(newshape, dtype=complex_dtype)\n        bigkernel[kernslices] = normalized_kernel\n    else:\n        bigkernel = normalized_kernel\n    arrayfft = fftn(bigarray)\n    kernfft = fftn(np.fft.ifftshift(bigkernel))\n    fftmult = arrayfft * kernfft\n    interpolate_nan = nan_treatment == 'interpolate'\n    if interpolate_nan:\n        if not np.isfinite(fill_value):\n            bigimwt = np.zeros(newshape, dtype=complex_dtype)\n        else:\n            bigimwt = np.ones(newshape, dtype=complex_dtype)\n        bigimwt[arrayslices] = 1.0 - nanmaskarray * interpolate_nan\n        wtfft = fftn(bigimwt)\n        wtfftmult = wtfft * kernfft\n        wtsm = ifftn(wtfftmult)\n        bigimwt[arrayslices] = wtsm.real[arrayslices]\n    else:\n        bigimwt = 1\n    if np.isnan(fftmult).any():\n        raise ValueError('Encountered NaNs in convolve.  This is disallowed.')\n    fftmult *= kernel_scale\n    if array_unit is not None:\n        fftmult <<= array_unit\n    if return_fft:\n        return fftmult\n    if interpolate_nan:\n        with np.errstate(divide='ignore', invalid='ignore'):\n            rifft = ifftn(fftmult) / bigimwt\n        if not np.isscalar(bigimwt):\n            if min_wt > 0.0:\n                rifft[bigimwt < min_wt] = np.nan\n            else:\n                rifft[bigimwt < 10 * np.finfo(bigimwt.dtype).eps] = 0.0\n    else:\n        rifft = ifftn(fftmult)\n    if preserve_nan:\n        rifft[arrayslices][nanmaskarray] = np.nan\n    if crop:\n        result = rifft[arrayslices].real\n        return result\n    else:\n        return rifft.real",
            "@support_nddata(data='array')\ndef convolve_fft(array, kernel, boundary='fill', fill_value=0.0, nan_treatment='interpolate', normalize_kernel=True, normalization_zero_tol=1e-08, preserve_nan=False, mask=None, crop=True, return_fft=False, fft_pad=None, psf_pad=None, min_wt=0.0, allow_huge=False, fftn=np.fft.fftn, ifftn=np.fft.ifftn, complex_dtype=complex, dealias=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Convolve an ndarray with an nd-kernel.  Returns a convolved image with\\n    ``shape = array.shape``.  Assumes kernel is centered.\\n\\n    `convolve_fft` is very similar to `convolve` in that it replaces ``NaN``\\n    values in the original image with interpolated values using the kernel as\\n    an interpolation function.  However, it also includes many additional\\n    options specific to the implementation.\\n\\n    `convolve_fft` differs from `scipy.signal.fftconvolve` in a few ways:\\n\\n    * It can treat ``NaN`` values as zeros or interpolate over them.\\n    * ``inf`` values are treated as ``NaN``\\n    * It optionally pads to the nearest faster sizes to improve FFT speed.\\n      These sizes are optimized for the numpy and scipy implementations, and\\n      ``fftconvolve`` uses them by default as well; when using other external\\n      functions (see below), results may vary.\\n    * Its only valid ``mode`` is \\'same\\' (i.e., the same shape array is returned)\\n    * It lets you use your own fft, e.g.,\\n      `pyFFTW <https://pypi.org/project/pyFFTW/>`_ or\\n      `pyFFTW3 <https://pypi.org/project/PyFFTW3/0.2.1/>`_ , which can lead to\\n      performance improvements, depending on your system configuration.  pyFFTW3\\n      is threaded, and therefore may yield significant performance benefits on\\n      multi-core machines at the cost of greater memory requirements.  Specify\\n      the ``fftn`` and ``ifftn`` keywords to override the default, which is\\n      `numpy.fft.fftn` and `numpy.fft.ifftn`.  The `scipy.fft` functions also\\n      offer somewhat better performance and a multi-threaded option.\\n\\n    Parameters\\n    ----------\\n    array : `numpy.ndarray`\\n        Array to be convolved with ``kernel``.  It can be of any\\n        dimensionality, though only 1, 2, and 3d arrays have been tested.\\n    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`\\n        The convolution kernel. The number of dimensions should match those\\n        for the array.  The dimensions *do not* have to be odd in all directions,\\n        unlike in the non-fft `convolve` function.  The kernel will be\\n        normalized if ``normalize_kernel`` is set.  It is assumed to be centered\\n        (i.e., shifts may result if your kernel is asymmetric)\\n    boundary : {\\'fill\\', \\'wrap\\'}, optional\\n        A flag indicating how to handle boundaries:\\n\\n            * \\'fill\\': set values outside the array boundary to fill_value\\n              (default)\\n            * \\'wrap\\': periodic boundary\\n\\n        The `None` and \\'extend\\' parameters are not supported for FFT-based\\n        convolution.\\n    fill_value : float, optional\\n        The value to use outside the array when using boundary=\\'fill\\'.\\n    nan_treatment : {\\'interpolate\\', \\'fill\\'}, optional\\n        The method used to handle NaNs in the input ``array``:\\n            * ``\\'interpolate\\'``: ``NaN`` values are replaced with\\n              interpolated values using the kernel as an interpolation\\n              function. Note that if the kernel has a sum equal to\\n              zero, NaN interpolation is not possible and will raise an\\n              exception.\\n            * ``\\'fill\\'``: ``NaN`` values are replaced by ``fill_value``\\n              prior to convolution.\\n    normalize_kernel : callable or boolean, optional\\n        If specified, this is the function to divide kernel by to normalize it.\\n        e.g., ``normalize_kernel=np.sum`` means that kernel will be modified to be:\\n        ``kernel = kernel / np.sum(kernel)``.  If True, defaults to\\n        ``normalize_kernel = np.sum``.\\n    normalization_zero_tol : float, optional\\n        The absolute tolerance on whether the kernel is different than zero.\\n        If the kernel sums to zero to within this precision, it cannot be\\n        normalized. Default is \"1e-8\".\\n    preserve_nan : bool, optional\\n        After performing convolution, should pixels that were originally NaN\\n        again become NaN?\\n    mask : None or ndarray, optional\\n        A \"mask\" array.  Shape must match ``array``, and anything that is masked\\n        (i.e., not 0/`False`) will be set to NaN for the convolution.  If\\n        `None`, no masking will be performed unless ``array`` is a masked array.\\n        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is\\n        masked if it is masked in either ``mask`` *or* ``array.mask``.\\n    crop : bool, optional\\n        Default on.  Return an image of the size of the larger of the input\\n        image and the kernel.\\n        If the image and kernel are asymmetric in opposite directions, will\\n        return the largest image in both directions.\\n        For example, if an input image has shape [100,3] but a kernel with shape\\n        [6,6] is used, the output will be [100,6].\\n    return_fft : bool, optional\\n        Return the ``fft(image)*fft(kernel)`` instead of the convolution (which is\\n        ``ifft(fft(image)*fft(kernel))``).  Useful for making PSDs.\\n    fft_pad : bool, optional\\n        Default on.  Zero-pad image to the nearest size supporting more efficient\\n        execution of the FFT, generally values factorizable into the first 3-5\\n        prime numbers.  With ``boundary=\\'wrap\\'``, this will be disabled.\\n    psf_pad : bool, optional\\n        Zero-pad image to be at least the sum of the image sizes to avoid\\n        edge-wrapping when smoothing.  This is enabled by default with\\n        ``boundary=\\'fill\\'``, but it can be overridden with a boolean option.\\n        ``boundary=\\'wrap\\'`` and ``psf_pad=True`` are not compatible.\\n    min_wt : float, optional\\n        If ignoring ``NaN`` / zeros, force all grid points with a weight less than\\n        this value to ``NaN`` (the weight of a grid point with *no* ignored\\n        neighbors is 1.0).\\n        If ``min_wt`` is zero, then all zero-weight points will be set to zero\\n        instead of ``NaN`` (which they would be otherwise, because 1/0 = nan).\\n        See the examples below.\\n    allow_huge : bool, optional\\n        Allow huge arrays in the FFT?  If False, will raise an exception if the\\n        array or kernel size is >1 GB.\\n    fftn : callable, optional\\n        The fft function.  Can be overridden to use your own ffts,\\n        e.g. an fftw3 wrapper or scipy\\'s fftn, ``fft=scipy.fftpack.fftn``.\\n    ifftn : callable, optional\\n        The inverse fft function. Can be overridden the same way ``fttn``.\\n    complex_dtype : complex type, optional\\n        Which complex dtype to use.  `numpy` has a range of options, from 64 to\\n        256.\\n    dealias: bool, optional\\n        Default off. Zero-pad image to enable explicit dealiasing\\n        of convolution. With ``boundary=\\'wrap\\'``, this will be disabled.\\n        Note that for an input of nd dimensions this will increase\\n        the size of the temporary arrays by at least ``1.5**nd``.\\n        This may result in significantly more memory usage.\\n\\n    Returns\\n    -------\\n    default : ndarray\\n        ``array`` convolved with ``kernel``.  If ``return_fft`` is set, returns\\n        ``fft(array) * fft(kernel)``.  If crop is not set, returns the\\n        image, but with the fft-padded size instead of the input size.\\n\\n    Raises\\n    ------\\n    `ValueError`\\n        If the array is bigger than 1 GB after padding, will raise this\\n        exception unless ``allow_huge`` is True.\\n\\n    See Also\\n    --------\\n    convolve:\\n        Convolve is a non-fft version of this code.  It is more memory\\n        efficient and for small kernels can be faster.\\n\\n    Notes\\n    -----\\n    With ``psf_pad=True`` and a large PSF, the resulting data\\n    can become large and consume a lot of memory. See Issue\\n    https://github.com/astropy/astropy/pull/4366 and the update in\\n    https://github.com/astropy/astropy/pull/11533 for further details.\\n\\n    Dealiasing of pseudospectral convolutions is necessary for\\n    numerical stability of the underlying algorithms. A common\\n    method for handling this is to zero pad the image by at least\\n    1/2 to eliminate the wavenumbers which have been aliased\\n    by convolution. This is so that the aliased 1/3 of the\\n    results of the convolution computation can be thrown out. See\\n    https://doi.org/10.1175/1520-0469(1971)028%3C1074:OTEOAI%3E2.0.CO;2\\n    https://iopscience.iop.org/article/10.1088/1742-6596/318/7/072037\\n\\n    Note that if dealiasing is necessary to your application, but your\\n    process is memory constrained, you may want to consider using\\n    FFTW++: https://github.com/dealias/fftwpp. It includes python\\n    wrappers for a pseudospectral convolution which will implicitly\\n    dealias your convolution without the need for additional padding.\\n    Note that one cannot use FFTW++\\'s convlution directly in this\\n    method as in handles the entire convolution process internally.\\n    Additionally, FFTW++ includes other useful pseudospectral methods to\\n    consider.\\n\\n    Examples\\n    --------\\n    >>> convolve_fft([1, 0, 3], [1, 1, 1])\\n    array([0.33333333, 1.33333333, 1.        ])\\n\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1])\\n    array([0.5, 2. , 1.5])\\n\\n    >>> convolve_fft([1, 0, 3], [0, 1, 0])  # doctest: +FLOAT_CMP\\n    array([ 1.00000000e+00, -3.70074342e-17,  3.00000000e+00])\\n\\n    >>> convolve_fft([1, 2, 3], [1])\\n    array([1., 2., 3.])\\n\\n    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment=\\'interpolate\\')\\n    array([1., 0., 3.])\\n\\n    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment=\\'interpolate\\',\\n    ...              min_wt=1e-8)\\n    array([ 1., nan,  3.])\\n\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\')\\n    array([0.5, 2. , 1.5])\\n\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\',\\n    ...               normalize_kernel=True)\\n    array([0.5, 2. , 1.5])\\n\\n    >>> import scipy.fft  # optional - requires scipy\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\',\\n    ...               normalize_kernel=True,\\n    ...               fftn=scipy.fft.fftn, ifftn=scipy.fft.ifftn)\\n    array([0.5, 2. , 1.5])\\n\\n    >>> fft_mp = lambda a: scipy.fft.fftn(a, workers=-1)  # use all available cores\\n    >>> ifft_mp = lambda a: scipy.fft.ifftn(a, workers=-1)\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\',\\n    ...               normalize_kernel=True, fftn=fft_mp, ifftn=ifft_mp)\\n    array([0.5, 2. , 1.5])\\n    '\n    if isinstance(kernel, Kernel):\n        kernel = kernel.array\n        if isinstance(array, Kernel):\n            raise TypeError(\"Can't convolve two kernels with convolve_fft.  Use convolve instead.\")\n    if nan_treatment not in ('interpolate', 'fill'):\n        raise ValueError(\"nan_treatment must be one of 'interpolate','fill'\")\n    array_unit = getattr(array, 'unit', None)\n    array = _copy_input_if_needed(array, dtype=complex, order='C', nan_treatment=nan_treatment, mask=mask, fill_value=np.nan)\n    kernel = _copy_input_if_needed(kernel, dtype=complex, order='C', nan_treatment=None, mask=None, fill_value=0)\n    if array.ndim != kernel.ndim:\n        raise ValueError('Image and kernel must have same number of dimensions')\n    arrayshape = array.shape\n    kernshape = kernel.shape\n    array_size_B = np.prod(arrayshape, dtype=np.int64) * np.dtype(complex_dtype).itemsize * u.byte\n    if array_size_B > 1 * u.GB and (not allow_huge):\n        raise ValueError(f'Size Error: Arrays will be {human_file_size(array_size_B)}.  Use allow_huge=True to override this exception.')\n    nanmaskarray = np.isnan(array) | np.isinf(array)\n    if nan_treatment == 'fill':\n        array[nanmaskarray] = fill_value\n    else:\n        array[nanmaskarray] = 0\n    nanmaskkernel = np.isnan(kernel) | np.isinf(kernel)\n    kernel[nanmaskkernel] = 0\n    if normalize_kernel is True:\n        if kernel.sum() < 1.0 / MAX_NORMALIZATION:\n            raise Exception(f\"The kernel can't be normalized, because its sum is close to zero. The sum of the given kernel is < {1.0 / MAX_NORMALIZATION}\")\n        kernel_scale = kernel.sum()\n        normalized_kernel = kernel / kernel_scale\n        kernel_scale = 1\n    elif normalize_kernel:\n        kernel_scale = normalize_kernel(kernel)\n        normalized_kernel = kernel / kernel_scale\n    else:\n        kernel_scale = kernel.sum()\n        if np.abs(kernel_scale) < normalization_zero_tol:\n            if nan_treatment == 'interpolate':\n                raise ValueError('Cannot interpolate NaNs with an unnormalizable kernel')\n            else:\n                kernel_scale = 1\n                normalized_kernel = kernel\n        else:\n            normalized_kernel = kernel / kernel_scale\n    if boundary is None:\n        warnings.warn(\"The convolve_fft version of boundary=None is equivalent to the convolve boundary='fill'.  There is no FFT equivalent to convolve's zero-if-kernel-leaves-boundary\", AstropyUserWarning)\n        if psf_pad is None:\n            psf_pad = True\n        if fft_pad is None:\n            fft_pad = True\n    elif boundary == 'fill':\n        if psf_pad is False:\n            warnings.warn(f\"psf_pad was set to {psf_pad}, which overrides the boundary='fill' setting.\", AstropyUserWarning)\n        else:\n            psf_pad = True\n        if fft_pad is None:\n            fft_pad = True\n    elif boundary == 'wrap':\n        if psf_pad:\n            raise ValueError(\"With boundary='wrap', psf_pad cannot be enabled.\")\n        psf_pad = False\n        if fft_pad:\n            raise ValueError(\"With boundary='wrap', fft_pad cannot be enabled.\")\n        fft_pad = False\n        if dealias:\n            raise ValueError(\"With boundary='wrap', dealias cannot be enabled.\")\n        fill_value = 0\n    elif boundary == 'extend':\n        raise NotImplementedError(\"The 'extend' option is not implemented for fft-based convolution\")\n    if psf_pad:\n        newshape = np.array(arrayshape) + np.array(kernshape)\n    else:\n        newshape = np.maximum(arrayshape, kernshape)\n    if dealias:\n        newshape += np.ceil(newshape / 2).astype(int)\n    if fft_pad:\n        newshape = _next_fast_lengths(newshape)\n    array_size_C = np.prod(newshape, dtype=np.int64) * np.dtype(complex_dtype).itemsize * u.byte\n    if array_size_C > 1 * u.GB and (not allow_huge):\n        raise ValueError(f'Size Error: Arrays will be {human_file_size(array_size_C)}.  Use allow_huge=True to override this exception.')\n    arrayslices = []\n    kernslices = []\n    for (newdimsize, arraydimsize, kerndimsize) in zip(newshape, arrayshape, kernshape):\n        center = newdimsize - (newdimsize + 1) // 2\n        arrayslices += [slice(center - arraydimsize // 2, center + (arraydimsize + 1) // 2)]\n        kernslices += [slice(center - kerndimsize // 2, center + (kerndimsize + 1) // 2)]\n    arrayslices = tuple(arrayslices)\n    kernslices = tuple(kernslices)\n    if not np.all(newshape == arrayshape):\n        if np.isfinite(fill_value):\n            bigarray = np.ones(newshape, dtype=complex_dtype) * fill_value\n        else:\n            bigarray = np.zeros(newshape, dtype=complex_dtype)\n        bigarray[arrayslices] = array\n    else:\n        bigarray = array\n    if not np.all(newshape == kernshape):\n        bigkernel = np.zeros(newshape, dtype=complex_dtype)\n        bigkernel[kernslices] = normalized_kernel\n    else:\n        bigkernel = normalized_kernel\n    arrayfft = fftn(bigarray)\n    kernfft = fftn(np.fft.ifftshift(bigkernel))\n    fftmult = arrayfft * kernfft\n    interpolate_nan = nan_treatment == 'interpolate'\n    if interpolate_nan:\n        if not np.isfinite(fill_value):\n            bigimwt = np.zeros(newshape, dtype=complex_dtype)\n        else:\n            bigimwt = np.ones(newshape, dtype=complex_dtype)\n        bigimwt[arrayslices] = 1.0 - nanmaskarray * interpolate_nan\n        wtfft = fftn(bigimwt)\n        wtfftmult = wtfft * kernfft\n        wtsm = ifftn(wtfftmult)\n        bigimwt[arrayslices] = wtsm.real[arrayslices]\n    else:\n        bigimwt = 1\n    if np.isnan(fftmult).any():\n        raise ValueError('Encountered NaNs in convolve.  This is disallowed.')\n    fftmult *= kernel_scale\n    if array_unit is not None:\n        fftmult <<= array_unit\n    if return_fft:\n        return fftmult\n    if interpolate_nan:\n        with np.errstate(divide='ignore', invalid='ignore'):\n            rifft = ifftn(fftmult) / bigimwt\n        if not np.isscalar(bigimwt):\n            if min_wt > 0.0:\n                rifft[bigimwt < min_wt] = np.nan\n            else:\n                rifft[bigimwt < 10 * np.finfo(bigimwt.dtype).eps] = 0.0\n    else:\n        rifft = ifftn(fftmult)\n    if preserve_nan:\n        rifft[arrayslices][nanmaskarray] = np.nan\n    if crop:\n        result = rifft[arrayslices].real\n        return result\n    else:\n        return rifft.real",
            "@support_nddata(data='array')\ndef convolve_fft(array, kernel, boundary='fill', fill_value=0.0, nan_treatment='interpolate', normalize_kernel=True, normalization_zero_tol=1e-08, preserve_nan=False, mask=None, crop=True, return_fft=False, fft_pad=None, psf_pad=None, min_wt=0.0, allow_huge=False, fftn=np.fft.fftn, ifftn=np.fft.ifftn, complex_dtype=complex, dealias=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Convolve an ndarray with an nd-kernel.  Returns a convolved image with\\n    ``shape = array.shape``.  Assumes kernel is centered.\\n\\n    `convolve_fft` is very similar to `convolve` in that it replaces ``NaN``\\n    values in the original image with interpolated values using the kernel as\\n    an interpolation function.  However, it also includes many additional\\n    options specific to the implementation.\\n\\n    `convolve_fft` differs from `scipy.signal.fftconvolve` in a few ways:\\n\\n    * It can treat ``NaN`` values as zeros or interpolate over them.\\n    * ``inf`` values are treated as ``NaN``\\n    * It optionally pads to the nearest faster sizes to improve FFT speed.\\n      These sizes are optimized for the numpy and scipy implementations, and\\n      ``fftconvolve`` uses them by default as well; when using other external\\n      functions (see below), results may vary.\\n    * Its only valid ``mode`` is \\'same\\' (i.e., the same shape array is returned)\\n    * It lets you use your own fft, e.g.,\\n      `pyFFTW <https://pypi.org/project/pyFFTW/>`_ or\\n      `pyFFTW3 <https://pypi.org/project/PyFFTW3/0.2.1/>`_ , which can lead to\\n      performance improvements, depending on your system configuration.  pyFFTW3\\n      is threaded, and therefore may yield significant performance benefits on\\n      multi-core machines at the cost of greater memory requirements.  Specify\\n      the ``fftn`` and ``ifftn`` keywords to override the default, which is\\n      `numpy.fft.fftn` and `numpy.fft.ifftn`.  The `scipy.fft` functions also\\n      offer somewhat better performance and a multi-threaded option.\\n\\n    Parameters\\n    ----------\\n    array : `numpy.ndarray`\\n        Array to be convolved with ``kernel``.  It can be of any\\n        dimensionality, though only 1, 2, and 3d arrays have been tested.\\n    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`\\n        The convolution kernel. The number of dimensions should match those\\n        for the array.  The dimensions *do not* have to be odd in all directions,\\n        unlike in the non-fft `convolve` function.  The kernel will be\\n        normalized if ``normalize_kernel`` is set.  It is assumed to be centered\\n        (i.e., shifts may result if your kernel is asymmetric)\\n    boundary : {\\'fill\\', \\'wrap\\'}, optional\\n        A flag indicating how to handle boundaries:\\n\\n            * \\'fill\\': set values outside the array boundary to fill_value\\n              (default)\\n            * \\'wrap\\': periodic boundary\\n\\n        The `None` and \\'extend\\' parameters are not supported for FFT-based\\n        convolution.\\n    fill_value : float, optional\\n        The value to use outside the array when using boundary=\\'fill\\'.\\n    nan_treatment : {\\'interpolate\\', \\'fill\\'}, optional\\n        The method used to handle NaNs in the input ``array``:\\n            * ``\\'interpolate\\'``: ``NaN`` values are replaced with\\n              interpolated values using the kernel as an interpolation\\n              function. Note that if the kernel has a sum equal to\\n              zero, NaN interpolation is not possible and will raise an\\n              exception.\\n            * ``\\'fill\\'``: ``NaN`` values are replaced by ``fill_value``\\n              prior to convolution.\\n    normalize_kernel : callable or boolean, optional\\n        If specified, this is the function to divide kernel by to normalize it.\\n        e.g., ``normalize_kernel=np.sum`` means that kernel will be modified to be:\\n        ``kernel = kernel / np.sum(kernel)``.  If True, defaults to\\n        ``normalize_kernel = np.sum``.\\n    normalization_zero_tol : float, optional\\n        The absolute tolerance on whether the kernel is different than zero.\\n        If the kernel sums to zero to within this precision, it cannot be\\n        normalized. Default is \"1e-8\".\\n    preserve_nan : bool, optional\\n        After performing convolution, should pixels that were originally NaN\\n        again become NaN?\\n    mask : None or ndarray, optional\\n        A \"mask\" array.  Shape must match ``array``, and anything that is masked\\n        (i.e., not 0/`False`) will be set to NaN for the convolution.  If\\n        `None`, no masking will be performed unless ``array`` is a masked array.\\n        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is\\n        masked if it is masked in either ``mask`` *or* ``array.mask``.\\n    crop : bool, optional\\n        Default on.  Return an image of the size of the larger of the input\\n        image and the kernel.\\n        If the image and kernel are asymmetric in opposite directions, will\\n        return the largest image in both directions.\\n        For example, if an input image has shape [100,3] but a kernel with shape\\n        [6,6] is used, the output will be [100,6].\\n    return_fft : bool, optional\\n        Return the ``fft(image)*fft(kernel)`` instead of the convolution (which is\\n        ``ifft(fft(image)*fft(kernel))``).  Useful for making PSDs.\\n    fft_pad : bool, optional\\n        Default on.  Zero-pad image to the nearest size supporting more efficient\\n        execution of the FFT, generally values factorizable into the first 3-5\\n        prime numbers.  With ``boundary=\\'wrap\\'``, this will be disabled.\\n    psf_pad : bool, optional\\n        Zero-pad image to be at least the sum of the image sizes to avoid\\n        edge-wrapping when smoothing.  This is enabled by default with\\n        ``boundary=\\'fill\\'``, but it can be overridden with a boolean option.\\n        ``boundary=\\'wrap\\'`` and ``psf_pad=True`` are not compatible.\\n    min_wt : float, optional\\n        If ignoring ``NaN`` / zeros, force all grid points with a weight less than\\n        this value to ``NaN`` (the weight of a grid point with *no* ignored\\n        neighbors is 1.0).\\n        If ``min_wt`` is zero, then all zero-weight points will be set to zero\\n        instead of ``NaN`` (which they would be otherwise, because 1/0 = nan).\\n        See the examples below.\\n    allow_huge : bool, optional\\n        Allow huge arrays in the FFT?  If False, will raise an exception if the\\n        array or kernel size is >1 GB.\\n    fftn : callable, optional\\n        The fft function.  Can be overridden to use your own ffts,\\n        e.g. an fftw3 wrapper or scipy\\'s fftn, ``fft=scipy.fftpack.fftn``.\\n    ifftn : callable, optional\\n        The inverse fft function. Can be overridden the same way ``fttn``.\\n    complex_dtype : complex type, optional\\n        Which complex dtype to use.  `numpy` has a range of options, from 64 to\\n        256.\\n    dealias: bool, optional\\n        Default off. Zero-pad image to enable explicit dealiasing\\n        of convolution. With ``boundary=\\'wrap\\'``, this will be disabled.\\n        Note that for an input of nd dimensions this will increase\\n        the size of the temporary arrays by at least ``1.5**nd``.\\n        This may result in significantly more memory usage.\\n\\n    Returns\\n    -------\\n    default : ndarray\\n        ``array`` convolved with ``kernel``.  If ``return_fft`` is set, returns\\n        ``fft(array) * fft(kernel)``.  If crop is not set, returns the\\n        image, but with the fft-padded size instead of the input size.\\n\\n    Raises\\n    ------\\n    `ValueError`\\n        If the array is bigger than 1 GB after padding, will raise this\\n        exception unless ``allow_huge`` is True.\\n\\n    See Also\\n    --------\\n    convolve:\\n        Convolve is a non-fft version of this code.  It is more memory\\n        efficient and for small kernels can be faster.\\n\\n    Notes\\n    -----\\n    With ``psf_pad=True`` and a large PSF, the resulting data\\n    can become large and consume a lot of memory. See Issue\\n    https://github.com/astropy/astropy/pull/4366 and the update in\\n    https://github.com/astropy/astropy/pull/11533 for further details.\\n\\n    Dealiasing of pseudospectral convolutions is necessary for\\n    numerical stability of the underlying algorithms. A common\\n    method for handling this is to zero pad the image by at least\\n    1/2 to eliminate the wavenumbers which have been aliased\\n    by convolution. This is so that the aliased 1/3 of the\\n    results of the convolution computation can be thrown out. See\\n    https://doi.org/10.1175/1520-0469(1971)028%3C1074:OTEOAI%3E2.0.CO;2\\n    https://iopscience.iop.org/article/10.1088/1742-6596/318/7/072037\\n\\n    Note that if dealiasing is necessary to your application, but your\\n    process is memory constrained, you may want to consider using\\n    FFTW++: https://github.com/dealias/fftwpp. It includes python\\n    wrappers for a pseudospectral convolution which will implicitly\\n    dealias your convolution without the need for additional padding.\\n    Note that one cannot use FFTW++\\'s convlution directly in this\\n    method as in handles the entire convolution process internally.\\n    Additionally, FFTW++ includes other useful pseudospectral methods to\\n    consider.\\n\\n    Examples\\n    --------\\n    >>> convolve_fft([1, 0, 3], [1, 1, 1])\\n    array([0.33333333, 1.33333333, 1.        ])\\n\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1])\\n    array([0.5, 2. , 1.5])\\n\\n    >>> convolve_fft([1, 0, 3], [0, 1, 0])  # doctest: +FLOAT_CMP\\n    array([ 1.00000000e+00, -3.70074342e-17,  3.00000000e+00])\\n\\n    >>> convolve_fft([1, 2, 3], [1])\\n    array([1., 2., 3.])\\n\\n    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment=\\'interpolate\\')\\n    array([1., 0., 3.])\\n\\n    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment=\\'interpolate\\',\\n    ...              min_wt=1e-8)\\n    array([ 1., nan,  3.])\\n\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\')\\n    array([0.5, 2. , 1.5])\\n\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\',\\n    ...               normalize_kernel=True)\\n    array([0.5, 2. , 1.5])\\n\\n    >>> import scipy.fft  # optional - requires scipy\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\',\\n    ...               normalize_kernel=True,\\n    ...               fftn=scipy.fft.fftn, ifftn=scipy.fft.ifftn)\\n    array([0.5, 2. , 1.5])\\n\\n    >>> fft_mp = lambda a: scipy.fft.fftn(a, workers=-1)  # use all available cores\\n    >>> ifft_mp = lambda a: scipy.fft.ifftn(a, workers=-1)\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\',\\n    ...               normalize_kernel=True, fftn=fft_mp, ifftn=ifft_mp)\\n    array([0.5, 2. , 1.5])\\n    '\n    if isinstance(kernel, Kernel):\n        kernel = kernel.array\n        if isinstance(array, Kernel):\n            raise TypeError(\"Can't convolve two kernels with convolve_fft.  Use convolve instead.\")\n    if nan_treatment not in ('interpolate', 'fill'):\n        raise ValueError(\"nan_treatment must be one of 'interpolate','fill'\")\n    array_unit = getattr(array, 'unit', None)\n    array = _copy_input_if_needed(array, dtype=complex, order='C', nan_treatment=nan_treatment, mask=mask, fill_value=np.nan)\n    kernel = _copy_input_if_needed(kernel, dtype=complex, order='C', nan_treatment=None, mask=None, fill_value=0)\n    if array.ndim != kernel.ndim:\n        raise ValueError('Image and kernel must have same number of dimensions')\n    arrayshape = array.shape\n    kernshape = kernel.shape\n    array_size_B = np.prod(arrayshape, dtype=np.int64) * np.dtype(complex_dtype).itemsize * u.byte\n    if array_size_B > 1 * u.GB and (not allow_huge):\n        raise ValueError(f'Size Error: Arrays will be {human_file_size(array_size_B)}.  Use allow_huge=True to override this exception.')\n    nanmaskarray = np.isnan(array) | np.isinf(array)\n    if nan_treatment == 'fill':\n        array[nanmaskarray] = fill_value\n    else:\n        array[nanmaskarray] = 0\n    nanmaskkernel = np.isnan(kernel) | np.isinf(kernel)\n    kernel[nanmaskkernel] = 0\n    if normalize_kernel is True:\n        if kernel.sum() < 1.0 / MAX_NORMALIZATION:\n            raise Exception(f\"The kernel can't be normalized, because its sum is close to zero. The sum of the given kernel is < {1.0 / MAX_NORMALIZATION}\")\n        kernel_scale = kernel.sum()\n        normalized_kernel = kernel / kernel_scale\n        kernel_scale = 1\n    elif normalize_kernel:\n        kernel_scale = normalize_kernel(kernel)\n        normalized_kernel = kernel / kernel_scale\n    else:\n        kernel_scale = kernel.sum()\n        if np.abs(kernel_scale) < normalization_zero_tol:\n            if nan_treatment == 'interpolate':\n                raise ValueError('Cannot interpolate NaNs with an unnormalizable kernel')\n            else:\n                kernel_scale = 1\n                normalized_kernel = kernel\n        else:\n            normalized_kernel = kernel / kernel_scale\n    if boundary is None:\n        warnings.warn(\"The convolve_fft version of boundary=None is equivalent to the convolve boundary='fill'.  There is no FFT equivalent to convolve's zero-if-kernel-leaves-boundary\", AstropyUserWarning)\n        if psf_pad is None:\n            psf_pad = True\n        if fft_pad is None:\n            fft_pad = True\n    elif boundary == 'fill':\n        if psf_pad is False:\n            warnings.warn(f\"psf_pad was set to {psf_pad}, which overrides the boundary='fill' setting.\", AstropyUserWarning)\n        else:\n            psf_pad = True\n        if fft_pad is None:\n            fft_pad = True\n    elif boundary == 'wrap':\n        if psf_pad:\n            raise ValueError(\"With boundary='wrap', psf_pad cannot be enabled.\")\n        psf_pad = False\n        if fft_pad:\n            raise ValueError(\"With boundary='wrap', fft_pad cannot be enabled.\")\n        fft_pad = False\n        if dealias:\n            raise ValueError(\"With boundary='wrap', dealias cannot be enabled.\")\n        fill_value = 0\n    elif boundary == 'extend':\n        raise NotImplementedError(\"The 'extend' option is not implemented for fft-based convolution\")\n    if psf_pad:\n        newshape = np.array(arrayshape) + np.array(kernshape)\n    else:\n        newshape = np.maximum(arrayshape, kernshape)\n    if dealias:\n        newshape += np.ceil(newshape / 2).astype(int)\n    if fft_pad:\n        newshape = _next_fast_lengths(newshape)\n    array_size_C = np.prod(newshape, dtype=np.int64) * np.dtype(complex_dtype).itemsize * u.byte\n    if array_size_C > 1 * u.GB and (not allow_huge):\n        raise ValueError(f'Size Error: Arrays will be {human_file_size(array_size_C)}.  Use allow_huge=True to override this exception.')\n    arrayslices = []\n    kernslices = []\n    for (newdimsize, arraydimsize, kerndimsize) in zip(newshape, arrayshape, kernshape):\n        center = newdimsize - (newdimsize + 1) // 2\n        arrayslices += [slice(center - arraydimsize // 2, center + (arraydimsize + 1) // 2)]\n        kernslices += [slice(center - kerndimsize // 2, center + (kerndimsize + 1) // 2)]\n    arrayslices = tuple(arrayslices)\n    kernslices = tuple(kernslices)\n    if not np.all(newshape == arrayshape):\n        if np.isfinite(fill_value):\n            bigarray = np.ones(newshape, dtype=complex_dtype) * fill_value\n        else:\n            bigarray = np.zeros(newshape, dtype=complex_dtype)\n        bigarray[arrayslices] = array\n    else:\n        bigarray = array\n    if not np.all(newshape == kernshape):\n        bigkernel = np.zeros(newshape, dtype=complex_dtype)\n        bigkernel[kernslices] = normalized_kernel\n    else:\n        bigkernel = normalized_kernel\n    arrayfft = fftn(bigarray)\n    kernfft = fftn(np.fft.ifftshift(bigkernel))\n    fftmult = arrayfft * kernfft\n    interpolate_nan = nan_treatment == 'interpolate'\n    if interpolate_nan:\n        if not np.isfinite(fill_value):\n            bigimwt = np.zeros(newshape, dtype=complex_dtype)\n        else:\n            bigimwt = np.ones(newshape, dtype=complex_dtype)\n        bigimwt[arrayslices] = 1.0 - nanmaskarray * interpolate_nan\n        wtfft = fftn(bigimwt)\n        wtfftmult = wtfft * kernfft\n        wtsm = ifftn(wtfftmult)\n        bigimwt[arrayslices] = wtsm.real[arrayslices]\n    else:\n        bigimwt = 1\n    if np.isnan(fftmult).any():\n        raise ValueError('Encountered NaNs in convolve.  This is disallowed.')\n    fftmult *= kernel_scale\n    if array_unit is not None:\n        fftmult <<= array_unit\n    if return_fft:\n        return fftmult\n    if interpolate_nan:\n        with np.errstate(divide='ignore', invalid='ignore'):\n            rifft = ifftn(fftmult) / bigimwt\n        if not np.isscalar(bigimwt):\n            if min_wt > 0.0:\n                rifft[bigimwt < min_wt] = np.nan\n            else:\n                rifft[bigimwt < 10 * np.finfo(bigimwt.dtype).eps] = 0.0\n    else:\n        rifft = ifftn(fftmult)\n    if preserve_nan:\n        rifft[arrayslices][nanmaskarray] = np.nan\n    if crop:\n        result = rifft[arrayslices].real\n        return result\n    else:\n        return rifft.real",
            "@support_nddata(data='array')\ndef convolve_fft(array, kernel, boundary='fill', fill_value=0.0, nan_treatment='interpolate', normalize_kernel=True, normalization_zero_tol=1e-08, preserve_nan=False, mask=None, crop=True, return_fft=False, fft_pad=None, psf_pad=None, min_wt=0.0, allow_huge=False, fftn=np.fft.fftn, ifftn=np.fft.ifftn, complex_dtype=complex, dealias=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Convolve an ndarray with an nd-kernel.  Returns a convolved image with\\n    ``shape = array.shape``.  Assumes kernel is centered.\\n\\n    `convolve_fft` is very similar to `convolve` in that it replaces ``NaN``\\n    values in the original image with interpolated values using the kernel as\\n    an interpolation function.  However, it also includes many additional\\n    options specific to the implementation.\\n\\n    `convolve_fft` differs from `scipy.signal.fftconvolve` in a few ways:\\n\\n    * It can treat ``NaN`` values as zeros or interpolate over them.\\n    * ``inf`` values are treated as ``NaN``\\n    * It optionally pads to the nearest faster sizes to improve FFT speed.\\n      These sizes are optimized for the numpy and scipy implementations, and\\n      ``fftconvolve`` uses them by default as well; when using other external\\n      functions (see below), results may vary.\\n    * Its only valid ``mode`` is \\'same\\' (i.e., the same shape array is returned)\\n    * It lets you use your own fft, e.g.,\\n      `pyFFTW <https://pypi.org/project/pyFFTW/>`_ or\\n      `pyFFTW3 <https://pypi.org/project/PyFFTW3/0.2.1/>`_ , which can lead to\\n      performance improvements, depending on your system configuration.  pyFFTW3\\n      is threaded, and therefore may yield significant performance benefits on\\n      multi-core machines at the cost of greater memory requirements.  Specify\\n      the ``fftn`` and ``ifftn`` keywords to override the default, which is\\n      `numpy.fft.fftn` and `numpy.fft.ifftn`.  The `scipy.fft` functions also\\n      offer somewhat better performance and a multi-threaded option.\\n\\n    Parameters\\n    ----------\\n    array : `numpy.ndarray`\\n        Array to be convolved with ``kernel``.  It can be of any\\n        dimensionality, though only 1, 2, and 3d arrays have been tested.\\n    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`\\n        The convolution kernel. The number of dimensions should match those\\n        for the array.  The dimensions *do not* have to be odd in all directions,\\n        unlike in the non-fft `convolve` function.  The kernel will be\\n        normalized if ``normalize_kernel`` is set.  It is assumed to be centered\\n        (i.e., shifts may result if your kernel is asymmetric)\\n    boundary : {\\'fill\\', \\'wrap\\'}, optional\\n        A flag indicating how to handle boundaries:\\n\\n            * \\'fill\\': set values outside the array boundary to fill_value\\n              (default)\\n            * \\'wrap\\': periodic boundary\\n\\n        The `None` and \\'extend\\' parameters are not supported for FFT-based\\n        convolution.\\n    fill_value : float, optional\\n        The value to use outside the array when using boundary=\\'fill\\'.\\n    nan_treatment : {\\'interpolate\\', \\'fill\\'}, optional\\n        The method used to handle NaNs in the input ``array``:\\n            * ``\\'interpolate\\'``: ``NaN`` values are replaced with\\n              interpolated values using the kernel as an interpolation\\n              function. Note that if the kernel has a sum equal to\\n              zero, NaN interpolation is not possible and will raise an\\n              exception.\\n            * ``\\'fill\\'``: ``NaN`` values are replaced by ``fill_value``\\n              prior to convolution.\\n    normalize_kernel : callable or boolean, optional\\n        If specified, this is the function to divide kernel by to normalize it.\\n        e.g., ``normalize_kernel=np.sum`` means that kernel will be modified to be:\\n        ``kernel = kernel / np.sum(kernel)``.  If True, defaults to\\n        ``normalize_kernel = np.sum``.\\n    normalization_zero_tol : float, optional\\n        The absolute tolerance on whether the kernel is different than zero.\\n        If the kernel sums to zero to within this precision, it cannot be\\n        normalized. Default is \"1e-8\".\\n    preserve_nan : bool, optional\\n        After performing convolution, should pixels that were originally NaN\\n        again become NaN?\\n    mask : None or ndarray, optional\\n        A \"mask\" array.  Shape must match ``array``, and anything that is masked\\n        (i.e., not 0/`False`) will be set to NaN for the convolution.  If\\n        `None`, no masking will be performed unless ``array`` is a masked array.\\n        If ``mask`` is not `None` *and* ``array`` is a masked array, a pixel is\\n        masked if it is masked in either ``mask`` *or* ``array.mask``.\\n    crop : bool, optional\\n        Default on.  Return an image of the size of the larger of the input\\n        image and the kernel.\\n        If the image and kernel are asymmetric in opposite directions, will\\n        return the largest image in both directions.\\n        For example, if an input image has shape [100,3] but a kernel with shape\\n        [6,6] is used, the output will be [100,6].\\n    return_fft : bool, optional\\n        Return the ``fft(image)*fft(kernel)`` instead of the convolution (which is\\n        ``ifft(fft(image)*fft(kernel))``).  Useful for making PSDs.\\n    fft_pad : bool, optional\\n        Default on.  Zero-pad image to the nearest size supporting more efficient\\n        execution of the FFT, generally values factorizable into the first 3-5\\n        prime numbers.  With ``boundary=\\'wrap\\'``, this will be disabled.\\n    psf_pad : bool, optional\\n        Zero-pad image to be at least the sum of the image sizes to avoid\\n        edge-wrapping when smoothing.  This is enabled by default with\\n        ``boundary=\\'fill\\'``, but it can be overridden with a boolean option.\\n        ``boundary=\\'wrap\\'`` and ``psf_pad=True`` are not compatible.\\n    min_wt : float, optional\\n        If ignoring ``NaN`` / zeros, force all grid points with a weight less than\\n        this value to ``NaN`` (the weight of a grid point with *no* ignored\\n        neighbors is 1.0).\\n        If ``min_wt`` is zero, then all zero-weight points will be set to zero\\n        instead of ``NaN`` (which they would be otherwise, because 1/0 = nan).\\n        See the examples below.\\n    allow_huge : bool, optional\\n        Allow huge arrays in the FFT?  If False, will raise an exception if the\\n        array or kernel size is >1 GB.\\n    fftn : callable, optional\\n        The fft function.  Can be overridden to use your own ffts,\\n        e.g. an fftw3 wrapper or scipy\\'s fftn, ``fft=scipy.fftpack.fftn``.\\n    ifftn : callable, optional\\n        The inverse fft function. Can be overridden the same way ``fttn``.\\n    complex_dtype : complex type, optional\\n        Which complex dtype to use.  `numpy` has a range of options, from 64 to\\n        256.\\n    dealias: bool, optional\\n        Default off. Zero-pad image to enable explicit dealiasing\\n        of convolution. With ``boundary=\\'wrap\\'``, this will be disabled.\\n        Note that for an input of nd dimensions this will increase\\n        the size of the temporary arrays by at least ``1.5**nd``.\\n        This may result in significantly more memory usage.\\n\\n    Returns\\n    -------\\n    default : ndarray\\n        ``array`` convolved with ``kernel``.  If ``return_fft`` is set, returns\\n        ``fft(array) * fft(kernel)``.  If crop is not set, returns the\\n        image, but with the fft-padded size instead of the input size.\\n\\n    Raises\\n    ------\\n    `ValueError`\\n        If the array is bigger than 1 GB after padding, will raise this\\n        exception unless ``allow_huge`` is True.\\n\\n    See Also\\n    --------\\n    convolve:\\n        Convolve is a non-fft version of this code.  It is more memory\\n        efficient and for small kernels can be faster.\\n\\n    Notes\\n    -----\\n    With ``psf_pad=True`` and a large PSF, the resulting data\\n    can become large and consume a lot of memory. See Issue\\n    https://github.com/astropy/astropy/pull/4366 and the update in\\n    https://github.com/astropy/astropy/pull/11533 for further details.\\n\\n    Dealiasing of pseudospectral convolutions is necessary for\\n    numerical stability of the underlying algorithms. A common\\n    method for handling this is to zero pad the image by at least\\n    1/2 to eliminate the wavenumbers which have been aliased\\n    by convolution. This is so that the aliased 1/3 of the\\n    results of the convolution computation can be thrown out. See\\n    https://doi.org/10.1175/1520-0469(1971)028%3C1074:OTEOAI%3E2.0.CO;2\\n    https://iopscience.iop.org/article/10.1088/1742-6596/318/7/072037\\n\\n    Note that if dealiasing is necessary to your application, but your\\n    process is memory constrained, you may want to consider using\\n    FFTW++: https://github.com/dealias/fftwpp. It includes python\\n    wrappers for a pseudospectral convolution which will implicitly\\n    dealias your convolution without the need for additional padding.\\n    Note that one cannot use FFTW++\\'s convlution directly in this\\n    method as in handles the entire convolution process internally.\\n    Additionally, FFTW++ includes other useful pseudospectral methods to\\n    consider.\\n\\n    Examples\\n    --------\\n    >>> convolve_fft([1, 0, 3], [1, 1, 1])\\n    array([0.33333333, 1.33333333, 1.        ])\\n\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1])\\n    array([0.5, 2. , 1.5])\\n\\n    >>> convolve_fft([1, 0, 3], [0, 1, 0])  # doctest: +FLOAT_CMP\\n    array([ 1.00000000e+00, -3.70074342e-17,  3.00000000e+00])\\n\\n    >>> convolve_fft([1, 2, 3], [1])\\n    array([1., 2., 3.])\\n\\n    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment=\\'interpolate\\')\\n    array([1., 0., 3.])\\n\\n    >>> convolve_fft([1, np.nan, 3], [0, 1, 0], nan_treatment=\\'interpolate\\',\\n    ...              min_wt=1e-8)\\n    array([ 1., nan,  3.])\\n\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\')\\n    array([0.5, 2. , 1.5])\\n\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\',\\n    ...               normalize_kernel=True)\\n    array([0.5, 2. , 1.5])\\n\\n    >>> import scipy.fft  # optional - requires scipy\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\',\\n    ...               normalize_kernel=True,\\n    ...               fftn=scipy.fft.fftn, ifftn=scipy.fft.ifftn)\\n    array([0.5, 2. , 1.5])\\n\\n    >>> fft_mp = lambda a: scipy.fft.fftn(a, workers=-1)  # use all available cores\\n    >>> ifft_mp = lambda a: scipy.fft.ifftn(a, workers=-1)\\n    >>> convolve_fft([1, np.nan, 3], [1, 1, 1], nan_treatment=\\'interpolate\\',\\n    ...               normalize_kernel=True, fftn=fft_mp, ifftn=ifft_mp)\\n    array([0.5, 2. , 1.5])\\n    '\n    if isinstance(kernel, Kernel):\n        kernel = kernel.array\n        if isinstance(array, Kernel):\n            raise TypeError(\"Can't convolve two kernels with convolve_fft.  Use convolve instead.\")\n    if nan_treatment not in ('interpolate', 'fill'):\n        raise ValueError(\"nan_treatment must be one of 'interpolate','fill'\")\n    array_unit = getattr(array, 'unit', None)\n    array = _copy_input_if_needed(array, dtype=complex, order='C', nan_treatment=nan_treatment, mask=mask, fill_value=np.nan)\n    kernel = _copy_input_if_needed(kernel, dtype=complex, order='C', nan_treatment=None, mask=None, fill_value=0)\n    if array.ndim != kernel.ndim:\n        raise ValueError('Image and kernel must have same number of dimensions')\n    arrayshape = array.shape\n    kernshape = kernel.shape\n    array_size_B = np.prod(arrayshape, dtype=np.int64) * np.dtype(complex_dtype).itemsize * u.byte\n    if array_size_B > 1 * u.GB and (not allow_huge):\n        raise ValueError(f'Size Error: Arrays will be {human_file_size(array_size_B)}.  Use allow_huge=True to override this exception.')\n    nanmaskarray = np.isnan(array) | np.isinf(array)\n    if nan_treatment == 'fill':\n        array[nanmaskarray] = fill_value\n    else:\n        array[nanmaskarray] = 0\n    nanmaskkernel = np.isnan(kernel) | np.isinf(kernel)\n    kernel[nanmaskkernel] = 0\n    if normalize_kernel is True:\n        if kernel.sum() < 1.0 / MAX_NORMALIZATION:\n            raise Exception(f\"The kernel can't be normalized, because its sum is close to zero. The sum of the given kernel is < {1.0 / MAX_NORMALIZATION}\")\n        kernel_scale = kernel.sum()\n        normalized_kernel = kernel / kernel_scale\n        kernel_scale = 1\n    elif normalize_kernel:\n        kernel_scale = normalize_kernel(kernel)\n        normalized_kernel = kernel / kernel_scale\n    else:\n        kernel_scale = kernel.sum()\n        if np.abs(kernel_scale) < normalization_zero_tol:\n            if nan_treatment == 'interpolate':\n                raise ValueError('Cannot interpolate NaNs with an unnormalizable kernel')\n            else:\n                kernel_scale = 1\n                normalized_kernel = kernel\n        else:\n            normalized_kernel = kernel / kernel_scale\n    if boundary is None:\n        warnings.warn(\"The convolve_fft version of boundary=None is equivalent to the convolve boundary='fill'.  There is no FFT equivalent to convolve's zero-if-kernel-leaves-boundary\", AstropyUserWarning)\n        if psf_pad is None:\n            psf_pad = True\n        if fft_pad is None:\n            fft_pad = True\n    elif boundary == 'fill':\n        if psf_pad is False:\n            warnings.warn(f\"psf_pad was set to {psf_pad}, which overrides the boundary='fill' setting.\", AstropyUserWarning)\n        else:\n            psf_pad = True\n        if fft_pad is None:\n            fft_pad = True\n    elif boundary == 'wrap':\n        if psf_pad:\n            raise ValueError(\"With boundary='wrap', psf_pad cannot be enabled.\")\n        psf_pad = False\n        if fft_pad:\n            raise ValueError(\"With boundary='wrap', fft_pad cannot be enabled.\")\n        fft_pad = False\n        if dealias:\n            raise ValueError(\"With boundary='wrap', dealias cannot be enabled.\")\n        fill_value = 0\n    elif boundary == 'extend':\n        raise NotImplementedError(\"The 'extend' option is not implemented for fft-based convolution\")\n    if psf_pad:\n        newshape = np.array(arrayshape) + np.array(kernshape)\n    else:\n        newshape = np.maximum(arrayshape, kernshape)\n    if dealias:\n        newshape += np.ceil(newshape / 2).astype(int)\n    if fft_pad:\n        newshape = _next_fast_lengths(newshape)\n    array_size_C = np.prod(newshape, dtype=np.int64) * np.dtype(complex_dtype).itemsize * u.byte\n    if array_size_C > 1 * u.GB and (not allow_huge):\n        raise ValueError(f'Size Error: Arrays will be {human_file_size(array_size_C)}.  Use allow_huge=True to override this exception.')\n    arrayslices = []\n    kernslices = []\n    for (newdimsize, arraydimsize, kerndimsize) in zip(newshape, arrayshape, kernshape):\n        center = newdimsize - (newdimsize + 1) // 2\n        arrayslices += [slice(center - arraydimsize // 2, center + (arraydimsize + 1) // 2)]\n        kernslices += [slice(center - kerndimsize // 2, center + (kerndimsize + 1) // 2)]\n    arrayslices = tuple(arrayslices)\n    kernslices = tuple(kernslices)\n    if not np.all(newshape == arrayshape):\n        if np.isfinite(fill_value):\n            bigarray = np.ones(newshape, dtype=complex_dtype) * fill_value\n        else:\n            bigarray = np.zeros(newshape, dtype=complex_dtype)\n        bigarray[arrayslices] = array\n    else:\n        bigarray = array\n    if not np.all(newshape == kernshape):\n        bigkernel = np.zeros(newshape, dtype=complex_dtype)\n        bigkernel[kernslices] = normalized_kernel\n    else:\n        bigkernel = normalized_kernel\n    arrayfft = fftn(bigarray)\n    kernfft = fftn(np.fft.ifftshift(bigkernel))\n    fftmult = arrayfft * kernfft\n    interpolate_nan = nan_treatment == 'interpolate'\n    if interpolate_nan:\n        if not np.isfinite(fill_value):\n            bigimwt = np.zeros(newshape, dtype=complex_dtype)\n        else:\n            bigimwt = np.ones(newshape, dtype=complex_dtype)\n        bigimwt[arrayslices] = 1.0 - nanmaskarray * interpolate_nan\n        wtfft = fftn(bigimwt)\n        wtfftmult = wtfft * kernfft\n        wtsm = ifftn(wtfftmult)\n        bigimwt[arrayslices] = wtsm.real[arrayslices]\n    else:\n        bigimwt = 1\n    if np.isnan(fftmult).any():\n        raise ValueError('Encountered NaNs in convolve.  This is disallowed.')\n    fftmult *= kernel_scale\n    if array_unit is not None:\n        fftmult <<= array_unit\n    if return_fft:\n        return fftmult\n    if interpolate_nan:\n        with np.errstate(divide='ignore', invalid='ignore'):\n            rifft = ifftn(fftmult) / bigimwt\n        if not np.isscalar(bigimwt):\n            if min_wt > 0.0:\n                rifft[bigimwt < min_wt] = np.nan\n            else:\n                rifft[bigimwt < 10 * np.finfo(bigimwt.dtype).eps] = 0.0\n    else:\n        rifft = ifftn(fftmult)\n    if preserve_nan:\n        rifft[arrayslices][nanmaskarray] = np.nan\n    if crop:\n        result = rifft[arrayslices].real\n        return result\n    else:\n        return rifft.real"
        ]
    },
    {
        "func_name": "interpolate_replace_nans",
        "original": "def interpolate_replace_nans(array, kernel, convolve=convolve, **kwargs):\n    \"\"\"\n    Given a data set containing NaNs, replace the NaNs by interpolating from\n    neighboring data points with a given kernel.\n\n    Parameters\n    ----------\n    array : `numpy.ndarray`\n        Array to be convolved with ``kernel``.  It can be of any\n        dimensionality, though only 1, 2, and 3d arrays have been tested.\n    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`\n        The convolution kernel. The number of dimensions should match those\n        for the array.  The dimensions *do not* have to be odd in all directions,\n        unlike in the non-fft `convolve` function.  The kernel will be\n        normalized if ``normalize_kernel`` is set.  It is assumed to be centered\n        (i.e., shifts may result if your kernel is asymmetric).  The kernel\n        *must be normalizable* (i.e., its sum cannot be zero).\n    convolve : `convolve` or `convolve_fft`\n        One of the two convolution functions defined in this package.\n\n    Returns\n    -------\n    newarray : `numpy.ndarray`\n        A copy of the original array with NaN pixels replaced with their\n        interpolated counterparts\n    \"\"\"\n    if not np.any(np.isnan(array)):\n        return array.copy()\n    newarray = array.copy()\n    convolved = convolve(array, kernel, nan_treatment='interpolate', normalize_kernel=True, preserve_nan=False, **kwargs)\n    isnan = np.isnan(array)\n    newarray[isnan] = convolved[isnan]\n    return newarray",
        "mutated": [
            "def interpolate_replace_nans(array, kernel, convolve=convolve, **kwargs):\n    if False:\n        i = 10\n    '\\n    Given a data set containing NaNs, replace the NaNs by interpolating from\\n    neighboring data points with a given kernel.\\n\\n    Parameters\\n    ----------\\n    array : `numpy.ndarray`\\n        Array to be convolved with ``kernel``.  It can be of any\\n        dimensionality, though only 1, 2, and 3d arrays have been tested.\\n    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`\\n        The convolution kernel. The number of dimensions should match those\\n        for the array.  The dimensions *do not* have to be odd in all directions,\\n        unlike in the non-fft `convolve` function.  The kernel will be\\n        normalized if ``normalize_kernel`` is set.  It is assumed to be centered\\n        (i.e., shifts may result if your kernel is asymmetric).  The kernel\\n        *must be normalizable* (i.e., its sum cannot be zero).\\n    convolve : `convolve` or `convolve_fft`\\n        One of the two convolution functions defined in this package.\\n\\n    Returns\\n    -------\\n    newarray : `numpy.ndarray`\\n        A copy of the original array with NaN pixels replaced with their\\n        interpolated counterparts\\n    '\n    if not np.any(np.isnan(array)):\n        return array.copy()\n    newarray = array.copy()\n    convolved = convolve(array, kernel, nan_treatment='interpolate', normalize_kernel=True, preserve_nan=False, **kwargs)\n    isnan = np.isnan(array)\n    newarray[isnan] = convolved[isnan]\n    return newarray",
            "def interpolate_replace_nans(array, kernel, convolve=convolve, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Given a data set containing NaNs, replace the NaNs by interpolating from\\n    neighboring data points with a given kernel.\\n\\n    Parameters\\n    ----------\\n    array : `numpy.ndarray`\\n        Array to be convolved with ``kernel``.  It can be of any\\n        dimensionality, though only 1, 2, and 3d arrays have been tested.\\n    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`\\n        The convolution kernel. The number of dimensions should match those\\n        for the array.  The dimensions *do not* have to be odd in all directions,\\n        unlike in the non-fft `convolve` function.  The kernel will be\\n        normalized if ``normalize_kernel`` is set.  It is assumed to be centered\\n        (i.e., shifts may result if your kernel is asymmetric).  The kernel\\n        *must be normalizable* (i.e., its sum cannot be zero).\\n    convolve : `convolve` or `convolve_fft`\\n        One of the two convolution functions defined in this package.\\n\\n    Returns\\n    -------\\n    newarray : `numpy.ndarray`\\n        A copy of the original array with NaN pixels replaced with their\\n        interpolated counterparts\\n    '\n    if not np.any(np.isnan(array)):\n        return array.copy()\n    newarray = array.copy()\n    convolved = convolve(array, kernel, nan_treatment='interpolate', normalize_kernel=True, preserve_nan=False, **kwargs)\n    isnan = np.isnan(array)\n    newarray[isnan] = convolved[isnan]\n    return newarray",
            "def interpolate_replace_nans(array, kernel, convolve=convolve, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Given a data set containing NaNs, replace the NaNs by interpolating from\\n    neighboring data points with a given kernel.\\n\\n    Parameters\\n    ----------\\n    array : `numpy.ndarray`\\n        Array to be convolved with ``kernel``.  It can be of any\\n        dimensionality, though only 1, 2, and 3d arrays have been tested.\\n    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`\\n        The convolution kernel. The number of dimensions should match those\\n        for the array.  The dimensions *do not* have to be odd in all directions,\\n        unlike in the non-fft `convolve` function.  The kernel will be\\n        normalized if ``normalize_kernel`` is set.  It is assumed to be centered\\n        (i.e., shifts may result if your kernel is asymmetric).  The kernel\\n        *must be normalizable* (i.e., its sum cannot be zero).\\n    convolve : `convolve` or `convolve_fft`\\n        One of the two convolution functions defined in this package.\\n\\n    Returns\\n    -------\\n    newarray : `numpy.ndarray`\\n        A copy of the original array with NaN pixels replaced with their\\n        interpolated counterparts\\n    '\n    if not np.any(np.isnan(array)):\n        return array.copy()\n    newarray = array.copy()\n    convolved = convolve(array, kernel, nan_treatment='interpolate', normalize_kernel=True, preserve_nan=False, **kwargs)\n    isnan = np.isnan(array)\n    newarray[isnan] = convolved[isnan]\n    return newarray",
            "def interpolate_replace_nans(array, kernel, convolve=convolve, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Given a data set containing NaNs, replace the NaNs by interpolating from\\n    neighboring data points with a given kernel.\\n\\n    Parameters\\n    ----------\\n    array : `numpy.ndarray`\\n        Array to be convolved with ``kernel``.  It can be of any\\n        dimensionality, though only 1, 2, and 3d arrays have been tested.\\n    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`\\n        The convolution kernel. The number of dimensions should match those\\n        for the array.  The dimensions *do not* have to be odd in all directions,\\n        unlike in the non-fft `convolve` function.  The kernel will be\\n        normalized if ``normalize_kernel`` is set.  It is assumed to be centered\\n        (i.e., shifts may result if your kernel is asymmetric).  The kernel\\n        *must be normalizable* (i.e., its sum cannot be zero).\\n    convolve : `convolve` or `convolve_fft`\\n        One of the two convolution functions defined in this package.\\n\\n    Returns\\n    -------\\n    newarray : `numpy.ndarray`\\n        A copy of the original array with NaN pixels replaced with their\\n        interpolated counterparts\\n    '\n    if not np.any(np.isnan(array)):\n        return array.copy()\n    newarray = array.copy()\n    convolved = convolve(array, kernel, nan_treatment='interpolate', normalize_kernel=True, preserve_nan=False, **kwargs)\n    isnan = np.isnan(array)\n    newarray[isnan] = convolved[isnan]\n    return newarray",
            "def interpolate_replace_nans(array, kernel, convolve=convolve, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Given a data set containing NaNs, replace the NaNs by interpolating from\\n    neighboring data points with a given kernel.\\n\\n    Parameters\\n    ----------\\n    array : `numpy.ndarray`\\n        Array to be convolved with ``kernel``.  It can be of any\\n        dimensionality, though only 1, 2, and 3d arrays have been tested.\\n    kernel : `numpy.ndarray` or `astropy.convolution.Kernel`\\n        The convolution kernel. The number of dimensions should match those\\n        for the array.  The dimensions *do not* have to be odd in all directions,\\n        unlike in the non-fft `convolve` function.  The kernel will be\\n        normalized if ``normalize_kernel`` is set.  It is assumed to be centered\\n        (i.e., shifts may result if your kernel is asymmetric).  The kernel\\n        *must be normalizable* (i.e., its sum cannot be zero).\\n    convolve : `convolve` or `convolve_fft`\\n        One of the two convolution functions defined in this package.\\n\\n    Returns\\n    -------\\n    newarray : `numpy.ndarray`\\n        A copy of the original array with NaN pixels replaced with their\\n        interpolated counterparts\\n    '\n    if not np.any(np.isnan(array)):\n        return array.copy()\n    newarray = array.copy()\n    convolved = convolve(array, kernel, nan_treatment='interpolate', normalize_kernel=True, preserve_nan=False, **kwargs)\n    isnan = np.isnan(array)\n    newarray[isnan] = convolved[isnan]\n    return newarray"
        ]
    },
    {
        "func_name": "convolve_models",
        "original": "def convolve_models(model, kernel, mode='convolve_fft', **kwargs):\n    \"\"\"\n    Convolve two models using `~astropy.convolution.convolve_fft`.\n\n    Parameters\n    ----------\n    model : `~astropy.modeling.core.Model`\n        Functional model\n    kernel : `~astropy.modeling.core.Model`\n        Convolution kernel\n    mode : str\n        Keyword representing which function to use for convolution.\n            * 'convolve_fft' : use `~astropy.convolution.convolve_fft` function.\n            * 'convolve' : use `~astropy.convolution.convolve`.\n    **kwargs : dict\n        Keyword arguments to me passed either to `~astropy.convolution.convolve`\n        or `~astropy.convolution.convolve_fft` depending on ``mode``.\n\n    Returns\n    -------\n    default : `~astropy.modeling.core.CompoundModel`\n        Convolved model\n    \"\"\"\n    if mode == 'convolve_fft':\n        operator = SPECIAL_OPERATORS.add('convolve_fft', partial(convolve_fft, **kwargs))\n    elif mode == 'convolve':\n        operator = SPECIAL_OPERATORS.add('convolve', partial(convolve, **kwargs))\n    else:\n        raise ValueError(f'Mode {mode} is not supported.')\n    return CompoundModel(operator, model, kernel)",
        "mutated": [
            "def convolve_models(model, kernel, mode='convolve_fft', **kwargs):\n    if False:\n        i = 10\n    \"\\n    Convolve two models using `~astropy.convolution.convolve_fft`.\\n\\n    Parameters\\n    ----------\\n    model : `~astropy.modeling.core.Model`\\n        Functional model\\n    kernel : `~astropy.modeling.core.Model`\\n        Convolution kernel\\n    mode : str\\n        Keyword representing which function to use for convolution.\\n            * 'convolve_fft' : use `~astropy.convolution.convolve_fft` function.\\n            * 'convolve' : use `~astropy.convolution.convolve`.\\n    **kwargs : dict\\n        Keyword arguments to me passed either to `~astropy.convolution.convolve`\\n        or `~astropy.convolution.convolve_fft` depending on ``mode``.\\n\\n    Returns\\n    -------\\n    default : `~astropy.modeling.core.CompoundModel`\\n        Convolved model\\n    \"\n    if mode == 'convolve_fft':\n        operator = SPECIAL_OPERATORS.add('convolve_fft', partial(convolve_fft, **kwargs))\n    elif mode == 'convolve':\n        operator = SPECIAL_OPERATORS.add('convolve', partial(convolve, **kwargs))\n    else:\n        raise ValueError(f'Mode {mode} is not supported.')\n    return CompoundModel(operator, model, kernel)",
            "def convolve_models(model, kernel, mode='convolve_fft', **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Convolve two models using `~astropy.convolution.convolve_fft`.\\n\\n    Parameters\\n    ----------\\n    model : `~astropy.modeling.core.Model`\\n        Functional model\\n    kernel : `~astropy.modeling.core.Model`\\n        Convolution kernel\\n    mode : str\\n        Keyword representing which function to use for convolution.\\n            * 'convolve_fft' : use `~astropy.convolution.convolve_fft` function.\\n            * 'convolve' : use `~astropy.convolution.convolve`.\\n    **kwargs : dict\\n        Keyword arguments to me passed either to `~astropy.convolution.convolve`\\n        or `~astropy.convolution.convolve_fft` depending on ``mode``.\\n\\n    Returns\\n    -------\\n    default : `~astropy.modeling.core.CompoundModel`\\n        Convolved model\\n    \"\n    if mode == 'convolve_fft':\n        operator = SPECIAL_OPERATORS.add('convolve_fft', partial(convolve_fft, **kwargs))\n    elif mode == 'convolve':\n        operator = SPECIAL_OPERATORS.add('convolve', partial(convolve, **kwargs))\n    else:\n        raise ValueError(f'Mode {mode} is not supported.')\n    return CompoundModel(operator, model, kernel)",
            "def convolve_models(model, kernel, mode='convolve_fft', **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Convolve two models using `~astropy.convolution.convolve_fft`.\\n\\n    Parameters\\n    ----------\\n    model : `~astropy.modeling.core.Model`\\n        Functional model\\n    kernel : `~astropy.modeling.core.Model`\\n        Convolution kernel\\n    mode : str\\n        Keyword representing which function to use for convolution.\\n            * 'convolve_fft' : use `~astropy.convolution.convolve_fft` function.\\n            * 'convolve' : use `~astropy.convolution.convolve`.\\n    **kwargs : dict\\n        Keyword arguments to me passed either to `~astropy.convolution.convolve`\\n        or `~astropy.convolution.convolve_fft` depending on ``mode``.\\n\\n    Returns\\n    -------\\n    default : `~astropy.modeling.core.CompoundModel`\\n        Convolved model\\n    \"\n    if mode == 'convolve_fft':\n        operator = SPECIAL_OPERATORS.add('convolve_fft', partial(convolve_fft, **kwargs))\n    elif mode == 'convolve':\n        operator = SPECIAL_OPERATORS.add('convolve', partial(convolve, **kwargs))\n    else:\n        raise ValueError(f'Mode {mode} is not supported.')\n    return CompoundModel(operator, model, kernel)",
            "def convolve_models(model, kernel, mode='convolve_fft', **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Convolve two models using `~astropy.convolution.convolve_fft`.\\n\\n    Parameters\\n    ----------\\n    model : `~astropy.modeling.core.Model`\\n        Functional model\\n    kernel : `~astropy.modeling.core.Model`\\n        Convolution kernel\\n    mode : str\\n        Keyword representing which function to use for convolution.\\n            * 'convolve_fft' : use `~astropy.convolution.convolve_fft` function.\\n            * 'convolve' : use `~astropy.convolution.convolve`.\\n    **kwargs : dict\\n        Keyword arguments to me passed either to `~astropy.convolution.convolve`\\n        or `~astropy.convolution.convolve_fft` depending on ``mode``.\\n\\n    Returns\\n    -------\\n    default : `~astropy.modeling.core.CompoundModel`\\n        Convolved model\\n    \"\n    if mode == 'convolve_fft':\n        operator = SPECIAL_OPERATORS.add('convolve_fft', partial(convolve_fft, **kwargs))\n    elif mode == 'convolve':\n        operator = SPECIAL_OPERATORS.add('convolve', partial(convolve, **kwargs))\n    else:\n        raise ValueError(f'Mode {mode} is not supported.')\n    return CompoundModel(operator, model, kernel)",
            "def convolve_models(model, kernel, mode='convolve_fft', **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Convolve two models using `~astropy.convolution.convolve_fft`.\\n\\n    Parameters\\n    ----------\\n    model : `~astropy.modeling.core.Model`\\n        Functional model\\n    kernel : `~astropy.modeling.core.Model`\\n        Convolution kernel\\n    mode : str\\n        Keyword representing which function to use for convolution.\\n            * 'convolve_fft' : use `~astropy.convolution.convolve_fft` function.\\n            * 'convolve' : use `~astropy.convolution.convolve`.\\n    **kwargs : dict\\n        Keyword arguments to me passed either to `~astropy.convolution.convolve`\\n        or `~astropy.convolution.convolve_fft` depending on ``mode``.\\n\\n    Returns\\n    -------\\n    default : `~astropy.modeling.core.CompoundModel`\\n        Convolved model\\n    \"\n    if mode == 'convolve_fft':\n        operator = SPECIAL_OPERATORS.add('convolve_fft', partial(convolve_fft, **kwargs))\n    elif mode == 'convolve':\n        operator = SPECIAL_OPERATORS.add('convolve', partial(convolve, **kwargs))\n    else:\n        raise ValueError(f'Mode {mode} is not supported.')\n    return CompoundModel(operator, model, kernel)"
        ]
    },
    {
        "func_name": "convolve_models_fft",
        "original": "def convolve_models_fft(model, kernel, bounding_box, resolution, cache=True, **kwargs):\n    \"\"\"\n    Convolve two models using `~astropy.convolution.convolve_fft`.\n\n    Parameters\n    ----------\n    model : `~astropy.modeling.core.Model`\n        Functional model\n    kernel : `~astropy.modeling.core.Model`\n        Convolution kernel\n    bounding_box : tuple\n        The bounding box which encompasses enough of the support of both\n        the ``model`` and ``kernel`` so that an accurate convolution can be\n        computed.\n    resolution : float\n        The resolution that one wishes to approximate the convolution\n        integral at.\n    cache : optional, bool\n        Default value True. Allow for the storage of the convolution\n        computation for later reuse.\n    **kwargs : dict\n        Keyword arguments to be passed either to `~astropy.convolution.convolve`\n        or `~astropy.convolution.convolve_fft` depending on ``mode``.\n\n    Returns\n    -------\n    default : `~astropy.modeling.core.CompoundModel`\n        Convolved model\n    \"\"\"\n    operator = SPECIAL_OPERATORS.add('convolve_fft', partial(convolve_fft, **kwargs))\n    return Convolution(operator, model, kernel, bounding_box, resolution, cache)",
        "mutated": [
            "def convolve_models_fft(model, kernel, bounding_box, resolution, cache=True, **kwargs):\n    if False:\n        i = 10\n    '\\n    Convolve two models using `~astropy.convolution.convolve_fft`.\\n\\n    Parameters\\n    ----------\\n    model : `~astropy.modeling.core.Model`\\n        Functional model\\n    kernel : `~astropy.modeling.core.Model`\\n        Convolution kernel\\n    bounding_box : tuple\\n        The bounding box which encompasses enough of the support of both\\n        the ``model`` and ``kernel`` so that an accurate convolution can be\\n        computed.\\n    resolution : float\\n        The resolution that one wishes to approximate the convolution\\n        integral at.\\n    cache : optional, bool\\n        Default value True. Allow for the storage of the convolution\\n        computation for later reuse.\\n    **kwargs : dict\\n        Keyword arguments to be passed either to `~astropy.convolution.convolve`\\n        or `~astropy.convolution.convolve_fft` depending on ``mode``.\\n\\n    Returns\\n    -------\\n    default : `~astropy.modeling.core.CompoundModel`\\n        Convolved model\\n    '\n    operator = SPECIAL_OPERATORS.add('convolve_fft', partial(convolve_fft, **kwargs))\n    return Convolution(operator, model, kernel, bounding_box, resolution, cache)",
            "def convolve_models_fft(model, kernel, bounding_box, resolution, cache=True, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Convolve two models using `~astropy.convolution.convolve_fft`.\\n\\n    Parameters\\n    ----------\\n    model : `~astropy.modeling.core.Model`\\n        Functional model\\n    kernel : `~astropy.modeling.core.Model`\\n        Convolution kernel\\n    bounding_box : tuple\\n        The bounding box which encompasses enough of the support of both\\n        the ``model`` and ``kernel`` so that an accurate convolution can be\\n        computed.\\n    resolution : float\\n        The resolution that one wishes to approximate the convolution\\n        integral at.\\n    cache : optional, bool\\n        Default value True. Allow for the storage of the convolution\\n        computation for later reuse.\\n    **kwargs : dict\\n        Keyword arguments to be passed either to `~astropy.convolution.convolve`\\n        or `~astropy.convolution.convolve_fft` depending on ``mode``.\\n\\n    Returns\\n    -------\\n    default : `~astropy.modeling.core.CompoundModel`\\n        Convolved model\\n    '\n    operator = SPECIAL_OPERATORS.add('convolve_fft', partial(convolve_fft, **kwargs))\n    return Convolution(operator, model, kernel, bounding_box, resolution, cache)",
            "def convolve_models_fft(model, kernel, bounding_box, resolution, cache=True, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Convolve two models using `~astropy.convolution.convolve_fft`.\\n\\n    Parameters\\n    ----------\\n    model : `~astropy.modeling.core.Model`\\n        Functional model\\n    kernel : `~astropy.modeling.core.Model`\\n        Convolution kernel\\n    bounding_box : tuple\\n        The bounding box which encompasses enough of the support of both\\n        the ``model`` and ``kernel`` so that an accurate convolution can be\\n        computed.\\n    resolution : float\\n        The resolution that one wishes to approximate the convolution\\n        integral at.\\n    cache : optional, bool\\n        Default value True. Allow for the storage of the convolution\\n        computation for later reuse.\\n    **kwargs : dict\\n        Keyword arguments to be passed either to `~astropy.convolution.convolve`\\n        or `~astropy.convolution.convolve_fft` depending on ``mode``.\\n\\n    Returns\\n    -------\\n    default : `~astropy.modeling.core.CompoundModel`\\n        Convolved model\\n    '\n    operator = SPECIAL_OPERATORS.add('convolve_fft', partial(convolve_fft, **kwargs))\n    return Convolution(operator, model, kernel, bounding_box, resolution, cache)",
            "def convolve_models_fft(model, kernel, bounding_box, resolution, cache=True, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Convolve two models using `~astropy.convolution.convolve_fft`.\\n\\n    Parameters\\n    ----------\\n    model : `~astropy.modeling.core.Model`\\n        Functional model\\n    kernel : `~astropy.modeling.core.Model`\\n        Convolution kernel\\n    bounding_box : tuple\\n        The bounding box which encompasses enough of the support of both\\n        the ``model`` and ``kernel`` so that an accurate convolution can be\\n        computed.\\n    resolution : float\\n        The resolution that one wishes to approximate the convolution\\n        integral at.\\n    cache : optional, bool\\n        Default value True. Allow for the storage of the convolution\\n        computation for later reuse.\\n    **kwargs : dict\\n        Keyword arguments to be passed either to `~astropy.convolution.convolve`\\n        or `~astropy.convolution.convolve_fft` depending on ``mode``.\\n\\n    Returns\\n    -------\\n    default : `~astropy.modeling.core.CompoundModel`\\n        Convolved model\\n    '\n    operator = SPECIAL_OPERATORS.add('convolve_fft', partial(convolve_fft, **kwargs))\n    return Convolution(operator, model, kernel, bounding_box, resolution, cache)",
            "def convolve_models_fft(model, kernel, bounding_box, resolution, cache=True, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Convolve two models using `~astropy.convolution.convolve_fft`.\\n\\n    Parameters\\n    ----------\\n    model : `~astropy.modeling.core.Model`\\n        Functional model\\n    kernel : `~astropy.modeling.core.Model`\\n        Convolution kernel\\n    bounding_box : tuple\\n        The bounding box which encompasses enough of the support of both\\n        the ``model`` and ``kernel`` so that an accurate convolution can be\\n        computed.\\n    resolution : float\\n        The resolution that one wishes to approximate the convolution\\n        integral at.\\n    cache : optional, bool\\n        Default value True. Allow for the storage of the convolution\\n        computation for later reuse.\\n    **kwargs : dict\\n        Keyword arguments to be passed either to `~astropy.convolution.convolve`\\n        or `~astropy.convolution.convolve_fft` depending on ``mode``.\\n\\n    Returns\\n    -------\\n    default : `~astropy.modeling.core.CompoundModel`\\n        Convolved model\\n    '\n    operator = SPECIAL_OPERATORS.add('convolve_fft', partial(convolve_fft, **kwargs))\n    return Convolution(operator, model, kernel, bounding_box, resolution, cache)"
        ]
    }
]