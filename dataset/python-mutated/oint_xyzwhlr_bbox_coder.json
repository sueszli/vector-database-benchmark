[
    {
        "func_name": "__init__",
        "original": "def __init__(self, code_size=7, use_mean_size=True, mean_size=None):\n    super(PointXYZWHLRBBoxCoder, self).__init__()\n    self.code_size = code_size\n    self.use_mean_size = use_mean_size\n    if self.use_mean_size:\n        self.mean_size = torch.from_numpy(np.array(mean_size)).float()\n        assert self.mean_size.min() > 0, f'The min of mean_size should > 0, however currently it is {self.mean_size.min()}, please check it in your config.'",
        "mutated": [
            "def __init__(self, code_size=7, use_mean_size=True, mean_size=None):\n    if False:\n        i = 10\n    super(PointXYZWHLRBBoxCoder, self).__init__()\n    self.code_size = code_size\n    self.use_mean_size = use_mean_size\n    if self.use_mean_size:\n        self.mean_size = torch.from_numpy(np.array(mean_size)).float()\n        assert self.mean_size.min() > 0, f'The min of mean_size should > 0, however currently it is {self.mean_size.min()}, please check it in your config.'",
            "def __init__(self, code_size=7, use_mean_size=True, mean_size=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super(PointXYZWHLRBBoxCoder, self).__init__()\n    self.code_size = code_size\n    self.use_mean_size = use_mean_size\n    if self.use_mean_size:\n        self.mean_size = torch.from_numpy(np.array(mean_size)).float()\n        assert self.mean_size.min() > 0, f'The min of mean_size should > 0, however currently it is {self.mean_size.min()}, please check it in your config.'",
            "def __init__(self, code_size=7, use_mean_size=True, mean_size=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super(PointXYZWHLRBBoxCoder, self).__init__()\n    self.code_size = code_size\n    self.use_mean_size = use_mean_size\n    if self.use_mean_size:\n        self.mean_size = torch.from_numpy(np.array(mean_size)).float()\n        assert self.mean_size.min() > 0, f'The min of mean_size should > 0, however currently it is {self.mean_size.min()}, please check it in your config.'",
            "def __init__(self, code_size=7, use_mean_size=True, mean_size=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super(PointXYZWHLRBBoxCoder, self).__init__()\n    self.code_size = code_size\n    self.use_mean_size = use_mean_size\n    if self.use_mean_size:\n        self.mean_size = torch.from_numpy(np.array(mean_size)).float()\n        assert self.mean_size.min() > 0, f'The min of mean_size should > 0, however currently it is {self.mean_size.min()}, please check it in your config.'",
            "def __init__(self, code_size=7, use_mean_size=True, mean_size=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super(PointXYZWHLRBBoxCoder, self).__init__()\n    self.code_size = code_size\n    self.use_mean_size = use_mean_size\n    if self.use_mean_size:\n        self.mean_size = torch.from_numpy(np.array(mean_size)).float()\n        assert self.mean_size.min() > 0, f'The min of mean_size should > 0, however currently it is {self.mean_size.min()}, please check it in your config.'"
        ]
    },
    {
        "func_name": "encode",
        "original": "def encode(self, gt_bboxes_3d, points, gt_labels_3d=None):\n    \"\"\"Encode ground truth to prediction targets.\n\n        Args:\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth bboxes\n                with shape (N, 7 + C).\n            points (torch.Tensor): Point cloud with shape (N, 3).\n            gt_labels_3d (torch.Tensor, optional): Ground truth classes.\n                Defaults to None.\n\n        Returns:\n            torch.Tensor: Encoded boxes with shape (N, 8 + C).\n        \"\"\"\n    gt_bboxes_3d[:, 3:6] = torch.clamp_min(gt_bboxes_3d[:, 3:6], min=1e-05)\n    (xg, yg, zg, dxg, dyg, dzg, rg, *cgs) = torch.split(gt_bboxes_3d, 1, dim=-1)\n    (xa, ya, za) = torch.split(points, 1, dim=-1)\n    if self.use_mean_size:\n        assert gt_labels_3d.max() <= self.mean_size.shape[0] - 1, f'the max gt label {gt_labels_3d.max()} is bigger thananchor types {self.mean_size.shape[0] - 1}.'\n        self.mean_size = self.mean_size.to(gt_labels_3d.device)\n        point_anchor_size = self.mean_size[gt_labels_3d]\n        (dxa, dya, dza) = torch.split(point_anchor_size, 1, dim=-1)\n        diagonal = torch.sqrt(dxa ** 2 + dya ** 2)\n        xt = (xg - xa) / diagonal\n        yt = (yg - ya) / diagonal\n        zt = (zg - za) / dza\n        dxt = torch.log(dxg / dxa)\n        dyt = torch.log(dyg / dya)\n        dzt = torch.log(dzg / dza)\n    else:\n        xt = xg - xa\n        yt = yg - ya\n        zt = zg - za\n        dxt = torch.log(dxg)\n        dyt = torch.log(dyg)\n        dzt = torch.log(dzg)\n    return torch.cat([xt, yt, zt, dxt, dyt, dzt, torch.cos(rg), torch.sin(rg), *cgs], dim=-1)",
        "mutated": [
            "def encode(self, gt_bboxes_3d, points, gt_labels_3d=None):\n    if False:\n        i = 10\n    'Encode ground truth to prediction targets.\\n\\n        Args:\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth bboxes\\n                with shape (N, 7 + C).\\n            points (torch.Tensor): Point cloud with shape (N, 3).\\n            gt_labels_3d (torch.Tensor, optional): Ground truth classes.\\n                Defaults to None.\\n\\n        Returns:\\n            torch.Tensor: Encoded boxes with shape (N, 8 + C).\\n        '\n    gt_bboxes_3d[:, 3:6] = torch.clamp_min(gt_bboxes_3d[:, 3:6], min=1e-05)\n    (xg, yg, zg, dxg, dyg, dzg, rg, *cgs) = torch.split(gt_bboxes_3d, 1, dim=-1)\n    (xa, ya, za) = torch.split(points, 1, dim=-1)\n    if self.use_mean_size:\n        assert gt_labels_3d.max() <= self.mean_size.shape[0] - 1, f'the max gt label {gt_labels_3d.max()} is bigger thananchor types {self.mean_size.shape[0] - 1}.'\n        self.mean_size = self.mean_size.to(gt_labels_3d.device)\n        point_anchor_size = self.mean_size[gt_labels_3d]\n        (dxa, dya, dza) = torch.split(point_anchor_size, 1, dim=-1)\n        diagonal = torch.sqrt(dxa ** 2 + dya ** 2)\n        xt = (xg - xa) / diagonal\n        yt = (yg - ya) / diagonal\n        zt = (zg - za) / dza\n        dxt = torch.log(dxg / dxa)\n        dyt = torch.log(dyg / dya)\n        dzt = torch.log(dzg / dza)\n    else:\n        xt = xg - xa\n        yt = yg - ya\n        zt = zg - za\n        dxt = torch.log(dxg)\n        dyt = torch.log(dyg)\n        dzt = torch.log(dzg)\n    return torch.cat([xt, yt, zt, dxt, dyt, dzt, torch.cos(rg), torch.sin(rg), *cgs], dim=-1)",
            "def encode(self, gt_bboxes_3d, points, gt_labels_3d=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Encode ground truth to prediction targets.\\n\\n        Args:\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth bboxes\\n                with shape (N, 7 + C).\\n            points (torch.Tensor): Point cloud with shape (N, 3).\\n            gt_labels_3d (torch.Tensor, optional): Ground truth classes.\\n                Defaults to None.\\n\\n        Returns:\\n            torch.Tensor: Encoded boxes with shape (N, 8 + C).\\n        '\n    gt_bboxes_3d[:, 3:6] = torch.clamp_min(gt_bboxes_3d[:, 3:6], min=1e-05)\n    (xg, yg, zg, dxg, dyg, dzg, rg, *cgs) = torch.split(gt_bboxes_3d, 1, dim=-1)\n    (xa, ya, za) = torch.split(points, 1, dim=-1)\n    if self.use_mean_size:\n        assert gt_labels_3d.max() <= self.mean_size.shape[0] - 1, f'the max gt label {gt_labels_3d.max()} is bigger thananchor types {self.mean_size.shape[0] - 1}.'\n        self.mean_size = self.mean_size.to(gt_labels_3d.device)\n        point_anchor_size = self.mean_size[gt_labels_3d]\n        (dxa, dya, dza) = torch.split(point_anchor_size, 1, dim=-1)\n        diagonal = torch.sqrt(dxa ** 2 + dya ** 2)\n        xt = (xg - xa) / diagonal\n        yt = (yg - ya) / diagonal\n        zt = (zg - za) / dza\n        dxt = torch.log(dxg / dxa)\n        dyt = torch.log(dyg / dya)\n        dzt = torch.log(dzg / dza)\n    else:\n        xt = xg - xa\n        yt = yg - ya\n        zt = zg - za\n        dxt = torch.log(dxg)\n        dyt = torch.log(dyg)\n        dzt = torch.log(dzg)\n    return torch.cat([xt, yt, zt, dxt, dyt, dzt, torch.cos(rg), torch.sin(rg), *cgs], dim=-1)",
            "def encode(self, gt_bboxes_3d, points, gt_labels_3d=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Encode ground truth to prediction targets.\\n\\n        Args:\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth bboxes\\n                with shape (N, 7 + C).\\n            points (torch.Tensor): Point cloud with shape (N, 3).\\n            gt_labels_3d (torch.Tensor, optional): Ground truth classes.\\n                Defaults to None.\\n\\n        Returns:\\n            torch.Tensor: Encoded boxes with shape (N, 8 + C).\\n        '\n    gt_bboxes_3d[:, 3:6] = torch.clamp_min(gt_bboxes_3d[:, 3:6], min=1e-05)\n    (xg, yg, zg, dxg, dyg, dzg, rg, *cgs) = torch.split(gt_bboxes_3d, 1, dim=-1)\n    (xa, ya, za) = torch.split(points, 1, dim=-1)\n    if self.use_mean_size:\n        assert gt_labels_3d.max() <= self.mean_size.shape[0] - 1, f'the max gt label {gt_labels_3d.max()} is bigger thananchor types {self.mean_size.shape[0] - 1}.'\n        self.mean_size = self.mean_size.to(gt_labels_3d.device)\n        point_anchor_size = self.mean_size[gt_labels_3d]\n        (dxa, dya, dza) = torch.split(point_anchor_size, 1, dim=-1)\n        diagonal = torch.sqrt(dxa ** 2 + dya ** 2)\n        xt = (xg - xa) / diagonal\n        yt = (yg - ya) / diagonal\n        zt = (zg - za) / dza\n        dxt = torch.log(dxg / dxa)\n        dyt = torch.log(dyg / dya)\n        dzt = torch.log(dzg / dza)\n    else:\n        xt = xg - xa\n        yt = yg - ya\n        zt = zg - za\n        dxt = torch.log(dxg)\n        dyt = torch.log(dyg)\n        dzt = torch.log(dzg)\n    return torch.cat([xt, yt, zt, dxt, dyt, dzt, torch.cos(rg), torch.sin(rg), *cgs], dim=-1)",
            "def encode(self, gt_bboxes_3d, points, gt_labels_3d=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Encode ground truth to prediction targets.\\n\\n        Args:\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth bboxes\\n                with shape (N, 7 + C).\\n            points (torch.Tensor): Point cloud with shape (N, 3).\\n            gt_labels_3d (torch.Tensor, optional): Ground truth classes.\\n                Defaults to None.\\n\\n        Returns:\\n            torch.Tensor: Encoded boxes with shape (N, 8 + C).\\n        '\n    gt_bboxes_3d[:, 3:6] = torch.clamp_min(gt_bboxes_3d[:, 3:6], min=1e-05)\n    (xg, yg, zg, dxg, dyg, dzg, rg, *cgs) = torch.split(gt_bboxes_3d, 1, dim=-1)\n    (xa, ya, za) = torch.split(points, 1, dim=-1)\n    if self.use_mean_size:\n        assert gt_labels_3d.max() <= self.mean_size.shape[0] - 1, f'the max gt label {gt_labels_3d.max()} is bigger thananchor types {self.mean_size.shape[0] - 1}.'\n        self.mean_size = self.mean_size.to(gt_labels_3d.device)\n        point_anchor_size = self.mean_size[gt_labels_3d]\n        (dxa, dya, dza) = torch.split(point_anchor_size, 1, dim=-1)\n        diagonal = torch.sqrt(dxa ** 2 + dya ** 2)\n        xt = (xg - xa) / diagonal\n        yt = (yg - ya) / diagonal\n        zt = (zg - za) / dza\n        dxt = torch.log(dxg / dxa)\n        dyt = torch.log(dyg / dya)\n        dzt = torch.log(dzg / dza)\n    else:\n        xt = xg - xa\n        yt = yg - ya\n        zt = zg - za\n        dxt = torch.log(dxg)\n        dyt = torch.log(dyg)\n        dzt = torch.log(dzg)\n    return torch.cat([xt, yt, zt, dxt, dyt, dzt, torch.cos(rg), torch.sin(rg), *cgs], dim=-1)",
            "def encode(self, gt_bboxes_3d, points, gt_labels_3d=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Encode ground truth to prediction targets.\\n\\n        Args:\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth bboxes\\n                with shape (N, 7 + C).\\n            points (torch.Tensor): Point cloud with shape (N, 3).\\n            gt_labels_3d (torch.Tensor, optional): Ground truth classes.\\n                Defaults to None.\\n\\n        Returns:\\n            torch.Tensor: Encoded boxes with shape (N, 8 + C).\\n        '\n    gt_bboxes_3d[:, 3:6] = torch.clamp_min(gt_bboxes_3d[:, 3:6], min=1e-05)\n    (xg, yg, zg, dxg, dyg, dzg, rg, *cgs) = torch.split(gt_bboxes_3d, 1, dim=-1)\n    (xa, ya, za) = torch.split(points, 1, dim=-1)\n    if self.use_mean_size:\n        assert gt_labels_3d.max() <= self.mean_size.shape[0] - 1, f'the max gt label {gt_labels_3d.max()} is bigger thananchor types {self.mean_size.shape[0] - 1}.'\n        self.mean_size = self.mean_size.to(gt_labels_3d.device)\n        point_anchor_size = self.mean_size[gt_labels_3d]\n        (dxa, dya, dza) = torch.split(point_anchor_size, 1, dim=-1)\n        diagonal = torch.sqrt(dxa ** 2 + dya ** 2)\n        xt = (xg - xa) / diagonal\n        yt = (yg - ya) / diagonal\n        zt = (zg - za) / dza\n        dxt = torch.log(dxg / dxa)\n        dyt = torch.log(dyg / dya)\n        dzt = torch.log(dzg / dza)\n    else:\n        xt = xg - xa\n        yt = yg - ya\n        zt = zg - za\n        dxt = torch.log(dxg)\n        dyt = torch.log(dyg)\n        dzt = torch.log(dzg)\n    return torch.cat([xt, yt, zt, dxt, dyt, dzt, torch.cos(rg), torch.sin(rg), *cgs], dim=-1)"
        ]
    },
    {
        "func_name": "decode",
        "original": "def decode(self, box_encodings, points, pred_labels_3d=None):\n    \"\"\"Decode predicted parts and points to bbox3d.\n\n        Args:\n            box_encodings (torch.Tensor): Encoded boxes with shape (N, 8 + C).\n            points (torch.Tensor): Point cloud with shape (N, 3).\n            pred_labels_3d (torch.Tensor): Bbox predicted labels (N, M).\n\n        Returns:\n            torch.Tensor: Decoded boxes with shape (N, 7 + C)\n        \"\"\"\n    (xt, yt, zt, dxt, dyt, dzt, cost, sint, *cts) = torch.split(box_encodings, 1, dim=-1)\n    (xa, ya, za) = torch.split(points, 1, dim=-1)\n    if self.use_mean_size:\n        assert pred_labels_3d.max() <= self.mean_size.shape[0] - 1, f'The max pred label {pred_labels_3d.max()} is bigger thananchor types {self.mean_size.shape[0] - 1}.'\n        self.mean_size = self.mean_size.to(pred_labels_3d.device)\n        point_anchor_size = self.mean_size[pred_labels_3d]\n        (dxa, dya, dza) = torch.split(point_anchor_size, 1, dim=-1)\n        diagonal = torch.sqrt(dxa ** 2 + dya ** 2)\n        xg = xt * diagonal + xa\n        yg = yt * diagonal + ya\n        zg = zt * dza + za\n        dxg = torch.exp(dxt) * dxa\n        dyg = torch.exp(dyt) * dya\n        dzg = torch.exp(dzt) * dza\n    else:\n        xg = xt + xa\n        yg = yt + ya\n        zg = zt + za\n        (dxg, dyg, dzg) = torch.split(torch.exp(box_encodings[..., 3:6]), 1, dim=-1)\n    rg = torch.atan2(sint, cost)\n    return torch.cat([xg, yg, zg, dxg, dyg, dzg, rg, *cts], dim=-1)",
        "mutated": [
            "def decode(self, box_encodings, points, pred_labels_3d=None):\n    if False:\n        i = 10\n    'Decode predicted parts and points to bbox3d.\\n\\n        Args:\\n            box_encodings (torch.Tensor): Encoded boxes with shape (N, 8 + C).\\n            points (torch.Tensor): Point cloud with shape (N, 3).\\n            pred_labels_3d (torch.Tensor): Bbox predicted labels (N, M).\\n\\n        Returns:\\n            torch.Tensor: Decoded boxes with shape (N, 7 + C)\\n        '\n    (xt, yt, zt, dxt, dyt, dzt, cost, sint, *cts) = torch.split(box_encodings, 1, dim=-1)\n    (xa, ya, za) = torch.split(points, 1, dim=-1)\n    if self.use_mean_size:\n        assert pred_labels_3d.max() <= self.mean_size.shape[0] - 1, f'The max pred label {pred_labels_3d.max()} is bigger thananchor types {self.mean_size.shape[0] - 1}.'\n        self.mean_size = self.mean_size.to(pred_labels_3d.device)\n        point_anchor_size = self.mean_size[pred_labels_3d]\n        (dxa, dya, dza) = torch.split(point_anchor_size, 1, dim=-1)\n        diagonal = torch.sqrt(dxa ** 2 + dya ** 2)\n        xg = xt * diagonal + xa\n        yg = yt * diagonal + ya\n        zg = zt * dza + za\n        dxg = torch.exp(dxt) * dxa\n        dyg = torch.exp(dyt) * dya\n        dzg = torch.exp(dzt) * dza\n    else:\n        xg = xt + xa\n        yg = yt + ya\n        zg = zt + za\n        (dxg, dyg, dzg) = torch.split(torch.exp(box_encodings[..., 3:6]), 1, dim=-1)\n    rg = torch.atan2(sint, cost)\n    return torch.cat([xg, yg, zg, dxg, dyg, dzg, rg, *cts], dim=-1)",
            "def decode(self, box_encodings, points, pred_labels_3d=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Decode predicted parts and points to bbox3d.\\n\\n        Args:\\n            box_encodings (torch.Tensor): Encoded boxes with shape (N, 8 + C).\\n            points (torch.Tensor): Point cloud with shape (N, 3).\\n            pred_labels_3d (torch.Tensor): Bbox predicted labels (N, M).\\n\\n        Returns:\\n            torch.Tensor: Decoded boxes with shape (N, 7 + C)\\n        '\n    (xt, yt, zt, dxt, dyt, dzt, cost, sint, *cts) = torch.split(box_encodings, 1, dim=-1)\n    (xa, ya, za) = torch.split(points, 1, dim=-1)\n    if self.use_mean_size:\n        assert pred_labels_3d.max() <= self.mean_size.shape[0] - 1, f'The max pred label {pred_labels_3d.max()} is bigger thananchor types {self.mean_size.shape[0] - 1}.'\n        self.mean_size = self.mean_size.to(pred_labels_3d.device)\n        point_anchor_size = self.mean_size[pred_labels_3d]\n        (dxa, dya, dza) = torch.split(point_anchor_size, 1, dim=-1)\n        diagonal = torch.sqrt(dxa ** 2 + dya ** 2)\n        xg = xt * diagonal + xa\n        yg = yt * diagonal + ya\n        zg = zt * dza + za\n        dxg = torch.exp(dxt) * dxa\n        dyg = torch.exp(dyt) * dya\n        dzg = torch.exp(dzt) * dza\n    else:\n        xg = xt + xa\n        yg = yt + ya\n        zg = zt + za\n        (dxg, dyg, dzg) = torch.split(torch.exp(box_encodings[..., 3:6]), 1, dim=-1)\n    rg = torch.atan2(sint, cost)\n    return torch.cat([xg, yg, zg, dxg, dyg, dzg, rg, *cts], dim=-1)",
            "def decode(self, box_encodings, points, pred_labels_3d=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Decode predicted parts and points to bbox3d.\\n\\n        Args:\\n            box_encodings (torch.Tensor): Encoded boxes with shape (N, 8 + C).\\n            points (torch.Tensor): Point cloud with shape (N, 3).\\n            pred_labels_3d (torch.Tensor): Bbox predicted labels (N, M).\\n\\n        Returns:\\n            torch.Tensor: Decoded boxes with shape (N, 7 + C)\\n        '\n    (xt, yt, zt, dxt, dyt, dzt, cost, sint, *cts) = torch.split(box_encodings, 1, dim=-1)\n    (xa, ya, za) = torch.split(points, 1, dim=-1)\n    if self.use_mean_size:\n        assert pred_labels_3d.max() <= self.mean_size.shape[0] - 1, f'The max pred label {pred_labels_3d.max()} is bigger thananchor types {self.mean_size.shape[0] - 1}.'\n        self.mean_size = self.mean_size.to(pred_labels_3d.device)\n        point_anchor_size = self.mean_size[pred_labels_3d]\n        (dxa, dya, dza) = torch.split(point_anchor_size, 1, dim=-1)\n        diagonal = torch.sqrt(dxa ** 2 + dya ** 2)\n        xg = xt * diagonal + xa\n        yg = yt * diagonal + ya\n        zg = zt * dza + za\n        dxg = torch.exp(dxt) * dxa\n        dyg = torch.exp(dyt) * dya\n        dzg = torch.exp(dzt) * dza\n    else:\n        xg = xt + xa\n        yg = yt + ya\n        zg = zt + za\n        (dxg, dyg, dzg) = torch.split(torch.exp(box_encodings[..., 3:6]), 1, dim=-1)\n    rg = torch.atan2(sint, cost)\n    return torch.cat([xg, yg, zg, dxg, dyg, dzg, rg, *cts], dim=-1)",
            "def decode(self, box_encodings, points, pred_labels_3d=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Decode predicted parts and points to bbox3d.\\n\\n        Args:\\n            box_encodings (torch.Tensor): Encoded boxes with shape (N, 8 + C).\\n            points (torch.Tensor): Point cloud with shape (N, 3).\\n            pred_labels_3d (torch.Tensor): Bbox predicted labels (N, M).\\n\\n        Returns:\\n            torch.Tensor: Decoded boxes with shape (N, 7 + C)\\n        '\n    (xt, yt, zt, dxt, dyt, dzt, cost, sint, *cts) = torch.split(box_encodings, 1, dim=-1)\n    (xa, ya, za) = torch.split(points, 1, dim=-1)\n    if self.use_mean_size:\n        assert pred_labels_3d.max() <= self.mean_size.shape[0] - 1, f'The max pred label {pred_labels_3d.max()} is bigger thananchor types {self.mean_size.shape[0] - 1}.'\n        self.mean_size = self.mean_size.to(pred_labels_3d.device)\n        point_anchor_size = self.mean_size[pred_labels_3d]\n        (dxa, dya, dza) = torch.split(point_anchor_size, 1, dim=-1)\n        diagonal = torch.sqrt(dxa ** 2 + dya ** 2)\n        xg = xt * diagonal + xa\n        yg = yt * diagonal + ya\n        zg = zt * dza + za\n        dxg = torch.exp(dxt) * dxa\n        dyg = torch.exp(dyt) * dya\n        dzg = torch.exp(dzt) * dza\n    else:\n        xg = xt + xa\n        yg = yt + ya\n        zg = zt + za\n        (dxg, dyg, dzg) = torch.split(torch.exp(box_encodings[..., 3:6]), 1, dim=-1)\n    rg = torch.atan2(sint, cost)\n    return torch.cat([xg, yg, zg, dxg, dyg, dzg, rg, *cts], dim=-1)",
            "def decode(self, box_encodings, points, pred_labels_3d=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Decode predicted parts and points to bbox3d.\\n\\n        Args:\\n            box_encodings (torch.Tensor): Encoded boxes with shape (N, 8 + C).\\n            points (torch.Tensor): Point cloud with shape (N, 3).\\n            pred_labels_3d (torch.Tensor): Bbox predicted labels (N, M).\\n\\n        Returns:\\n            torch.Tensor: Decoded boxes with shape (N, 7 + C)\\n        '\n    (xt, yt, zt, dxt, dyt, dzt, cost, sint, *cts) = torch.split(box_encodings, 1, dim=-1)\n    (xa, ya, za) = torch.split(points, 1, dim=-1)\n    if self.use_mean_size:\n        assert pred_labels_3d.max() <= self.mean_size.shape[0] - 1, f'The max pred label {pred_labels_3d.max()} is bigger thananchor types {self.mean_size.shape[0] - 1}.'\n        self.mean_size = self.mean_size.to(pred_labels_3d.device)\n        point_anchor_size = self.mean_size[pred_labels_3d]\n        (dxa, dya, dza) = torch.split(point_anchor_size, 1, dim=-1)\n        diagonal = torch.sqrt(dxa ** 2 + dya ** 2)\n        xg = xt * diagonal + xa\n        yg = yt * diagonal + ya\n        zg = zt * dza + za\n        dxg = torch.exp(dxt) * dxa\n        dyg = torch.exp(dyt) * dya\n        dzg = torch.exp(dzt) * dza\n    else:\n        xg = xt + xa\n        yg = yt + ya\n        zg = zt + za\n        (dxg, dyg, dzg) = torch.split(torch.exp(box_encodings[..., 3:6]), 1, dim=-1)\n    rg = torch.atan2(sint, cost)\n    return torch.cat([xg, yg, zg, dxg, dyg, dzg, rg, *cts], dim=-1)"
        ]
    }
]