[
    {
        "func_name": "replace_netcdf_datetime",
        "original": "def replace_netcdf_datetime(match):\n    try:\n        datetime.strptime(match.group(0), DATETIME_FORMAT)\n    except Exception:\n        return match.group(0)\n    else:\n        return DATETIME_FORMAT",
        "mutated": [
            "def replace_netcdf_datetime(match):\n    if False:\n        i = 10\n    try:\n        datetime.strptime(match.group(0), DATETIME_FORMAT)\n    except Exception:\n        return match.group(0)\n    else:\n        return DATETIME_FORMAT",
            "def replace_netcdf_datetime(match):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    try:\n        datetime.strptime(match.group(0), DATETIME_FORMAT)\n    except Exception:\n        return match.group(0)\n    else:\n        return DATETIME_FORMAT",
            "def replace_netcdf_datetime(match):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    try:\n        datetime.strptime(match.group(0), DATETIME_FORMAT)\n    except Exception:\n        return match.group(0)\n    else:\n        return DATETIME_FORMAT",
            "def replace_netcdf_datetime(match):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    try:\n        datetime.strptime(match.group(0), DATETIME_FORMAT)\n    except Exception:\n        return match.group(0)\n    else:\n        return DATETIME_FORMAT",
            "def replace_netcdf_datetime(match):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    try:\n        datetime.strptime(match.group(0), DATETIME_FORMAT)\n    except Exception:\n        return match.group(0)\n    else:\n        return DATETIME_FORMAT"
        ]
    },
    {
        "func_name": "assert_print",
        "original": "def assert_print(*args):\n    output = DATETIME_PATTERN.sub(replace_netcdf_datetime, ' '.join((str(a) for a in args)))\n    expected = stdouts.pop(0)\n    if output != expected:\n        assert output == expected, f'{repr(output)} != {repr(expected)}'",
        "mutated": [
            "def assert_print(*args):\n    if False:\n        i = 10\n    output = DATETIME_PATTERN.sub(replace_netcdf_datetime, ' '.join((str(a) for a in args)))\n    expected = stdouts.pop(0)\n    if output != expected:\n        assert output == expected, f'{repr(output)} != {repr(expected)}'",
            "def assert_print(*args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    output = DATETIME_PATTERN.sub(replace_netcdf_datetime, ' '.join((str(a) for a in args)))\n    expected = stdouts.pop(0)\n    if output != expected:\n        assert output == expected, f'{repr(output)} != {repr(expected)}'",
            "def assert_print(*args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    output = DATETIME_PATTERN.sub(replace_netcdf_datetime, ' '.join((str(a) for a in args)))\n    expected = stdouts.pop(0)\n    if output != expected:\n        assert output == expected, f'{repr(output)} != {repr(expected)}'",
            "def assert_print(*args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    output = DATETIME_PATTERN.sub(replace_netcdf_datetime, ' '.join((str(a) for a in args)))\n    expected = stdouts.pop(0)\n    if output != expected:\n        assert output == expected, f'{repr(output)} != {repr(expected)}'",
            "def assert_print(*args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    output = DATETIME_PATTERN.sub(replace_netcdf_datetime, ' '.join((str(a) for a in args)))\n    expected = stdouts.pop(0)\n    if output != expected:\n        assert output == expected, f'{repr(output)} != {repr(expected)}'"
        ]
    },
    {
        "func_name": "walktree",
        "original": "def walktree(top):\n    yield top.groups.values()\n    for value in top.groups.values():\n        yield from walktree(value)",
        "mutated": [
            "def walktree(top):\n    if False:\n        i = 10\n    yield top.groups.values()\n    for value in top.groups.values():\n        yield from walktree(value)",
            "def walktree(top):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    yield top.groups.values()\n    for value in top.groups.values():\n        yield from walktree(value)",
            "def walktree(top):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    yield top.groups.values()\n    for value in top.groups.values():\n        yield from walktree(value)",
            "def walktree(top):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    yield top.groups.values()\n    for value in top.groups.values():\n        yield from walktree(value)",
            "def walktree(top):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    yield top.groups.values()\n    for value in top.groups.values():\n        yield from walktree(value)"
        ]
    },
    {
        "func_name": "test_netCDF4_tutorial",
        "original": "@pytest.mark.driver_timeout(60)\n@run_in_pyodide(packages=['netCDF4', 'numpy'])\ndef test_netCDF4_tutorial(selenium):\n    import re\n    from datetime import datetime\n    DATETIME_PATTERN = re.compile('[a-zA-Z]{3}\\\\s+[a-zA-Z]{3}\\\\s+[0-9]{1,2}\\\\s+[0-9]{2}:[0-9]{2}:[0-9]{2}\\\\s+[0-9]{4}')\n    DATETIME_FORMAT = '%a %b %d %H:%M:%S %Y'\n    stdouts = ['NETCDF4', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: forecasts, analyses\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: model1, model2\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /analyses:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model1:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model2:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"{'level': <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0, 'time': <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0, 'lat': <class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73, 'lon': <class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144}\", '144', 'False', 'True', \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0\", \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\", \"<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73\", \"<class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144\", \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\", \"<class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\n    least_significant_digit: 3\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model1:\\n    dimensions(sizes): \\n    variables(dimensions): float32 temp(time, level, lat, lon)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\npath = /forecasts/model1\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used\", 'Global attr description = bogus example script', 'Global attr history = Created %a %b %d %H:%M:%S %Y', 'Global attr source = netCDF4 python module tutorial', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    description: bogus example script\\n    history: Created %a %b %d %H:%M:%S %Y\\n    source: netCDF4 python module tutorial\\n    dimensions(sizes): level(0), time(0), lat(73), lon(144)\\n    variables(dimensions): float64 time(time), int32 level(level), float32 lat(lat), float32 lon(lon), float32 temp(time, level, lat, lon)\\n    groups: forecasts, analyses\", \"{'description': 'bogus example script', 'history': 'Created %a %b %d %H:%M:%S %Y', 'source': 'netCDF4 python module tutorial'}\", \"{'time': <class 'netCDF4._netCDF4.Variable'>\\nfloat64 time(time)\\n    units: hours since 0001-01-01 00:00:00.0\\n    calendar: gregorian\\nunlimited dimensions: time\\ncurrent shape = (0,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'level': <class 'netCDF4._netCDF4.Variable'>\\nint32 level(level)\\n    units: hPa\\nunlimited dimensions: level\\ncurrent shape = (0,)\\nfilling on, default _FillValue of -2147483647 used, 'lat': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 lat(lat)\\n    units: degrees north\\nunlimited dimensions: \\ncurrent shape = (73,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'lon': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 lon(lon)\\n    units: degrees east\\nunlimited dimensions: \\ncurrent shape = (144,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'temp': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\n    least_significant_digit: 3\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used}\", 'latitudes =\\n [-90.  -87.5 -85.  -82.5 -80.  -77.5 -75.  -72.5 -70.  -67.5 -65.  -62.5\\n -60.  -57.5 -55.  -52.5 -50.  -47.5 -45.  -42.5 -40.  -37.5 -35.  -32.5\\n -30.  -27.5 -25.  -22.5 -20.  -17.5 -15.  -12.5 -10.   -7.5  -5.   -2.5\\n   0.    2.5   5.    7.5  10.   12.5  15.   17.5  20.   22.5  25.   27.5\\n  30.   32.5  35.   37.5  40.   42.5  45.   47.5  50.   52.5  55.   57.5\\n  60.   62.5  65.   67.5  70.   72.5  75.   77.5  80.   82.5  85.   87.5\\n  90. ]', 'longitudes =\\n [-180.  -177.5 -175.  -172.5 -170.  -167.5 -165.  -162.5 -160.  -157.5\\n -155.  -152.5 -150.  -147.5 -145.  -142.5 -140.  -137.5 -135.  -132.5\\n -130.  -127.5 -125.  -122.5 -120.  -117.5 -115.  -112.5 -110.  -107.5\\n -105.  -102.5 -100.   -97.5  -95.   -92.5  -90.   -87.5  -85.   -82.5\\n  -80.   -77.5  -75.   -72.5  -70.   -67.5  -65.   -62.5  -60.   -57.5\\n  -55.   -52.5  -50.   -47.5  -45.   -42.5  -40.   -37.5  -35.   -32.5\\n  -30.   -27.5  -25.   -22.5  -20.   -17.5  -15.   -12.5  -10.    -7.5\\n   -5.    -2.5    0.     2.5    5.     7.5   10.    12.5   15.    17.5\\n   20.    22.5   25.    27.5   30.    32.5   35.    37.5   40.    42.5\\n   45.    47.5   50.    52.5   55.    57.5   60.    62.5   65.    67.5\\n   70.    72.5   75.    77.5   80.    82.5   85.    87.5   90.    92.5\\n   95.    97.5  100.   102.5  105.   107.5  110.   112.5  115.   117.5\\n  120.   122.5  125.   127.5  130.   132.5  135.   137.5  140.   142.5\\n  145.   147.5  150.   152.5  155.   157.5  160.   162.5  165.   167.5\\n  170.   172.5  175.   177.5]', 'temp shape before adding data =  (0, 0, 73, 144)', 'temp shape after adding data =  (5, 10, 73, 144)', 'levels shape after adding pressure data =  (10,)', 'shape of fancy temp slice =  (3, 3, 36, 71)', '(4, 4)', 'time values (in units hours since 0001-01-01 00:00:00.0):\\n[17533104. 17533116. 17533128. 17533140. 17533152.]', 'dates corresponding to time values:\\n[cftime.DatetimeGregorian(2001, 3, 1, 0, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 1, 12, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 2, 0, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 2, 12, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 3, 0, 0, 0, 0, has_year_zero=False)]', '[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\\n 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\\n 96 97 98 99]', 'complex128', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x_dim(3)\\n    variables(dimensions): {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True} cmplx_var(x_dim)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\ncompound cmplx_var(x_dim)\\ncompound data type: {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}\\nunlimited dimensions: x_dim\\ncurrent shape = (3,)\", \"{'complex128': <class 'netCDF4._netCDF4.CompoundType'>: name = 'complex128', numpy dtype = {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}}\", \"<class 'netCDF4._netCDF4.CompoundType'>: name = 'complex128', numpy dtype = {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}\", '(3,)', 'complex128 [ 0.54030231+0.84147098j -0.84147098+0.54030231j -0.54030231-0.84147098j]', 'complex128 [ 0.54030231+0.84147098j -0.84147098+0.54030231j -0.54030231-0.84147098j]', \"{'wind_data': <class 'netCDF4._netCDF4.CompoundType'>: name = 'wind_data', numpy dtype = {'names': ['speed', 'direction'], 'formats': ['<f4', '<i4'], 'offsets': [0, 4], 'itemsize': 8, 'aligned': True}, 'station_data': <class 'netCDF4._netCDF4.CompoundType'>: name = 'station_data', numpy dtype = {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True}, 'wind_data_units': <class 'netCDF4._netCDF4.CompoundType'>: name = 'wind_data_units', numpy dtype = {'names': ['speed', 'direction'], 'formats': [('S1', (12,)), ('S1', (12,))], 'offsets': [0, 12], 'itemsize': 24, 'aligned': True}, 'station_data_units': <class 'netCDF4._netCDF4.CompoundType'>: name = 'station_data_units', numpy dtype = {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'location_name', 'press_sounding'], 'formats': [('S1', (12,)), ('S1', (12,)), [('speed', 'S1', (12,)), ('direction', 'S1', (12,))], ('S1', (12,)), ('S1', (12,)), ('S1', (12,))], 'offsets': [0, 12, 24, 48, 60, 72], 'itemsize': 84, 'aligned': True}}\", \"[('latitude', 'S12'), ('longitude', 'S12'), ('surface_wind', [('speed', 'S12'), ('direction', 'S12')]), ('temp_sounding', 'S12'), ('location_name', 'S12'), ('press_sounding', 'S12')]\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): station(2)\\n    variables(dimensions): {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True} station_obs(station)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\ncompound station_obs(station)\\n    units: (b'degrees N', b'degrees W', (b'm/s', b'degrees'), b'Kelvin', b'None', b'hPa')\\ncompound data type: {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True}\\nunlimited dimensions: station\\ncurrent shape = (2,)\", 'data in a variable of compound type:', \"[(40.  , -105.  , ( 12.5, 270), [280.3, 272. , 270. , 269. , 266. , 258. , 254.1, 250. , 245.5, 240. ], [800, 750, 700, 650, 600, 550, 500, 450, 400, 350], b'Boulder, CO')\\n (40.78,  -73.99, (-12.5,  90), [290.2, 282.5, 279. , 277.9, 276. , 266. , 264.1, 260. , 255.5, 243. ], [900, 850, 800, 750, 700, 650, 600, 550, 500, 450], b'New York, NY')]\", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen phony_vlen_var(y, x)\\nvlen data type: int32\\nunlimited dimensions: \\ncurrent shape = (4, 3)\", 'vlen variable =\\n [[array([1, 2, 3, 4, 5, 6, 7]) array([1, 2, 3, 4, 5]) array([1])]\\n [array([1, 2, 3]) array([1, 2]) array([1])]\\n [array([1]) array([1, 2, 3, 4, 5, 6, 7]) array([1])]\\n [array([1, 2, 3, 4, 5, 6]) array([1, 2, 3, 4, 5]) array([1])]]', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(3), y(4)\\n    variables(dimensions): int32 phony_vlen_var(y, x)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen phony_vlen_var(y, x)\\nvlen data type: int32\\nunlimited dimensions: \\ncurrent shape = (4, 3)\", \"<class 'netCDF4._netCDF4.VLType'>: name = 'phony_vlen', numpy dtype = int32\", \"variable-length string variable:\\n ['ZOGMRmJo' 'BxdAK1fku' 'lgOzaanCtv' 'D5ALrXJCDU' 'W9r' 'Y7edBPrthEr'\\n 'OVeqx' 'aH1ZXc5A' 'LC1ajPJ' 'du']\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(3), y(4), z(10)\\n    variables(dimensions): int32 phony_vlen_var(y, x), <class 'str'> strvar(z)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen strvar(z)\\nvlen data type: <class 'str'>\\nunlimited dimensions: \\ncurrent shape = (10,)\", \"<class 'netCDF4._netCDF4.EnumType'>: name = 'cloud_t', numpy dtype = uint8, fields/values ={'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\", \"<class 'netCDF4._netCDF4.Variable'>\\nenum primary_cloud(time)\\n    _FillValue: 255\\nenum data type: uint8\\nunlimited dimensions: time\\ncurrent shape = (5,)\", \"{'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\", '[0 2 4 -- 1]', \"[[b'f' b'o' b'o']\\n [b'b' b'a' b'r']]\", \"['foo' 'bar']\", \"{'names': ['observation', 'station_name'], 'formats': ['<f4', ('S1', (12,))], 'offsets': [0, 4], 'itemsize': 16, 'aligned': True}\", \"[(123.  , b'Boulder') (  3.14, b'New York')]\", \"{'names': ['observation', 'station_name'], 'formats': ['<f4', 'S12'], 'offsets': [0, 4], 'itemsize': 16, 'aligned': True}\", \"[(123.  , [b'B', b'o', b'u', b'l', b'd', b'e', b'r', b'', b'', b'', b'', b''])\\n (  3.14, [b'N', b'e', b'w', b' ', b'Y', b'o', b'r', b'k', b'', b'', b'', b''])]\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]', \"<class 'memoryview'>\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]']\n\n    def replace_netcdf_datetime(match):\n        try:\n            datetime.strptime(match.group(0), DATETIME_FORMAT)\n        except Exception:\n            return match.group(0)\n        else:\n            return DATETIME_FORMAT\n\n    def assert_print(*args):\n        output = DATETIME_PATTERN.sub(replace_netcdf_datetime, ' '.join((str(a) for a in args)))\n        expected = stdouts.pop(0)\n        if output != expected:\n            assert output == expected, f'{repr(output)} != {repr(expected)}'\n    '\\n    Test adopted from (but with reproducible randomness):\\n    https://github.com/Unidata/netcdf4-python/blob/master/examples/tutorial.py\\n    Released under the MIT License\\n    '\n    from numpy.random import PCG64, Generator\n    rng = Generator(PCG64(seed=42))\n    from netCDF4 import Dataset\n    rootgrp = Dataset('test.nc', 'w', format='NETCDF4')\n    assert_print(rootgrp.file_format)\n    rootgrp.close()\n    rootgrp = Dataset('test.nc', 'a')\n    rootgrp.createGroup('forecasts')\n    rootgrp.createGroup('analyses')\n    rootgrp.createGroup('/forecasts/model1')\n    rootgrp.createGroup('/forecasts/model2')\n\n    def walktree(top):\n        yield top.groups.values()\n        for value in top.groups.values():\n            yield from walktree(value)\n    assert_print(rootgrp)\n    for children in walktree(rootgrp):\n        for child in children:\n            assert_print(child)\n    rootgrp.createDimension('level', None)\n    time = rootgrp.createDimension('time', None)\n    rootgrp.createDimension('lat', 73)\n    lon = rootgrp.createDimension('lon', 144)\n    assert_print(rootgrp.dimensions)\n    assert_print(len(lon))\n    assert_print(lon.isunlimited())\n    assert_print(time.isunlimited())\n    for dimobj in rootgrp.dimensions.values():\n        assert_print(dimobj)\n    assert_print(time)\n    times = rootgrp.createVariable('time', 'f8', ('time',))\n    levels = rootgrp.createVariable('level', 'i4', ('level',))\n    latitudes = rootgrp.createVariable('lat', 'f4', ('lat',))\n    longitudes = rootgrp.createVariable('lon', 'f4', ('lon',))\n    temp = rootgrp.createVariable('temp', 'f4', ('time', 'level', 'lat', 'lon'), least_significant_digit=3)\n    assert_print(temp)\n    temp = rootgrp.createVariable('/forecasts/model1/temp', 'f4', ('time', 'level', 'lat', 'lon'))\n    assert_print(rootgrp['/forecasts/model1'])\n    assert_print(rootgrp['/forecasts/model1/temp'])\n    import time\n    rootgrp.description = 'bogus example script'\n    rootgrp.history = 'Created ' + time.ctime(time.time())\n    rootgrp.source = 'netCDF4 python module tutorial'\n    latitudes.units = 'degrees north'\n    longitudes.units = 'degrees east'\n    levels.units = 'hPa'\n    temp.units = 'K'\n    times.units = 'hours since 0001-01-01 00:00:00.0'\n    times.calendar = 'gregorian'\n    for name in rootgrp.ncattrs():\n        assert_print('Global attr', name, '=', getattr(rootgrp, name))\n    assert_print(rootgrp)\n    assert_print(rootgrp.__dict__)\n    assert_print(rootgrp.variables)\n    import numpy as np\n    lats = np.arange(-90, 91, 2.5)\n    lons = np.arange(-180, 180, 2.5)\n    latitudes[:] = lats\n    longitudes[:] = lons\n    assert_print('latitudes =\\n', latitudes[:])\n    assert_print('longitudes =\\n', longitudes[:])\n    nlats = len(rootgrp.dimensions['lat'])\n    nlons = len(rootgrp.dimensions['lon'])\n    assert_print('temp shape before adding data = ', temp.shape)\n    temp[0:5, 0:10, :, :] = rng.uniform(size=(5, 10, nlats, nlons))\n    assert_print('temp shape after adding data = ', temp.shape)\n    assert_print('levels shape after adding pressure data = ', levels.shape)\n    levels[:] = [1000.0, 850.0, 700.0, 500.0, 300.0, 250.0, 200.0, 150.0, 100.0, 50.0]\n    tempdat = temp[::2, [1, 3, 6], lats > 0, lons > 0]\n    assert_print('shape of fancy temp slice = ', tempdat.shape)\n    assert_print(temp[0, 0, [0, 1, 2, 3], [0, 1, 2, 3]].shape)\n    from datetime import timedelta\n    from netCDF4 import date2num, num2date\n    dates = [datetime(2001, 3, 1) + n * timedelta(hours=12) for n in range(temp.shape[0])]\n    times[:] = date2num(dates, units=times.units, calendar=times.calendar)\n    assert_print(f'time values (in units {times.units}):\\n{times[:]}')\n    dates = num2date(times[:], units=times.units, calendar=times.calendar)\n    assert_print(f'dates corresponding to time values:\\n{dates}')\n    rootgrp.close()\n    for nfile in range(10):\n        f = Dataset('mftest' + repr(nfile) + '.nc', 'w', format='NETCDF4_CLASSIC')\n        f.createDimension('x', None)\n        x = f.createVariable('x', 'i', ('x',))\n        x[0:10] = np.arange(nfile * 10, 10 * (nfile + 1))\n        f.close()\n    from netCDF4 import MFDataset\n    f = MFDataset('mftest*nc')\n    assert_print(f.variables['x'][:])\n    f = Dataset('complex.nc', 'w')\n    size = 3\n    datac = np.exp(1j * (1.0 + np.linspace(0, np.pi, size)))\n    assert_print(datac.dtype)\n    complex128 = np.dtype([('real', np.float64), ('imag', np.float64)])\n    complex128_t = f.createCompoundType(complex128, 'complex128')\n    f.createDimension('x_dim', None)\n    v = f.createVariable('cmplx_var', complex128_t, 'x_dim')\n    data = np.empty(size, complex128)\n    data['real'] = datac.real\n    data['imag'] = datac.imag\n    v[:] = data\n    f.close()\n    f = Dataset('complex.nc')\n    assert_print(f)\n    assert_print(f.variables['cmplx_var'])\n    assert_print(f.cmptypes)\n    assert_print(f.cmptypes['complex128'])\n    v = f.variables['cmplx_var']\n    assert_print(v.shape)\n    datain = v[:]\n    datac2 = np.empty(datain.shape, np.complex128)\n    datac2.real = datain['real']\n    datac2.imag = datain['imag']\n    assert_print(datac.dtype, datac)\n    assert_print(datac2.dtype, datac2)\n    f = Dataset('compound_example.nc', 'w')\n    f.createDimension('station', None)\n    winddtype = np.dtype([('speed', 'f4'), ('direction', 'i4')])\n    statdtype = np.dtype([('latitude', 'f4'), ('longitude', 'f4'), ('surface_wind', winddtype), ('temp_sounding', 'f4', 10), ('press_sounding', 'i4', 10), ('location_name', 'S12')])\n    f.createCompoundType(winddtype, 'wind_data')\n    station_data_t = f.createCompoundType(statdtype, 'station_data')\n    winddtype_units = np.dtype([('speed', 'S12'), ('direction', 'S12')])\n    statdtype_units = np.dtype([('latitude', 'S12'), ('longitude', 'S12'), ('surface_wind', winddtype_units), ('temp_sounding', 'S12'), ('location_name', 'S12'), ('press_sounding', 'S12')])\n    f.createCompoundType(winddtype_units, 'wind_data_units')\n    f.createCompoundType(statdtype_units, 'station_data_units')\n    statdat = f.createVariable('station_obs', station_data_t, ('station',))\n    data = np.empty(1, statdtype)\n    data['latitude'] = 40.0\n    data['longitude'] = -105.0\n    data['surface_wind']['speed'] = 12.5\n    data['surface_wind']['direction'] = 270\n    data['temp_sounding'] = (280.3, 272.0, 270.0, 269.0, 266.0, 258.0, 254.1, 250.0, 245.5, 240.0)\n    data['press_sounding'] = range(800, 300, -50)\n    data['location_name'] = 'Boulder, CO'\n    statdat[0] = data\n    statdat[1] = np.array((40.78, -73.99, (-12.5, 90), (290.2, 282.5, 279.0, 277.9, 276.0, 266.0, 264.1, 260.0, 255.5, 243.0), range(900, 400, -50), 'New York, NY'), data.dtype)\n    assert_print(f.cmptypes)\n    windunits = np.empty(1, winddtype_units)\n    stationobs_units = np.empty(1, statdtype_units)\n    windunits['speed'] = 'm/s'\n    windunits['direction'] = 'degrees'\n    stationobs_units['latitude'] = 'degrees N'\n    stationobs_units['longitude'] = 'degrees W'\n    stationobs_units['surface_wind'] = windunits\n    stationobs_units['location_name'] = 'None'\n    stationobs_units['temp_sounding'] = 'Kelvin'\n    stationobs_units['press_sounding'] = 'hPa'\n    assert_print(stationobs_units.dtype)\n    statdat.units = stationobs_units\n    f.close()\n    f = Dataset('compound_example.nc')\n    assert_print(f)\n    statdat = f.variables['station_obs']\n    assert_print(statdat)\n    assert_print('data in a variable of compound type:')\n    assert_print(statdat[:])\n    f.close()\n    f = Dataset('tst_vlen.nc', 'w')\n    vlen_t = f.createVLType(np.int32, 'phony_vlen')\n    x = f.createDimension('x', 3)\n    y = f.createDimension('y', 4)\n    vlvar = f.createVariable('phony_vlen_var', vlen_t, ('y', 'x'))\n    data = np.empty(len(y) * len(x), object)\n    for n in range(len(y) * len(x)):\n        data[n] = np.arange(rng.integers(1, 10), dtype='int32') + 1\n    data = np.reshape(data, (len(y), len(x)))\n    vlvar[:] = data\n    assert_print(vlvar)\n    assert_print('vlen variable =\\n', vlvar[:])\n    assert_print(f)\n    assert_print(f.variables['phony_vlen_var'])\n    assert_print(f.vltypes['phony_vlen'])\n    f.createDimension('z', 10)\n    strvar = f.createVariable('strvar', str, 'z')\n    chars = list('1234567890aabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n    data = np.empty(10, object)\n    for n in range(10):\n        stringlen = rng.integers(2, 12)\n        data[n] = ''.join([rng.choice(chars) for i in range(stringlen)])\n    strvar[:] = data\n    assert_print('variable-length string variable:\\n', strvar[:])\n    assert_print(f)\n    assert_print(f.variables['strvar'])\n    f.close()\n    f = Dataset('clouds.nc', 'w')\n    enum_dict = {'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\n    cloud_type = f.createEnumType(np.uint8, 'cloud_t', enum_dict)\n    assert_print(cloud_type)\n    time = f.createDimension('time', None)\n    cloud_var = f.createVariable('primary_cloud', cloud_type, 'time', fill_value=enum_dict['Missing'])\n    cloud_var[:] = [enum_dict['Clear'], enum_dict['Stratus'], enum_dict['Cumulus'], enum_dict['Missing'], enum_dict['Cumulonimbus']]\n    f.close()\n    f = Dataset('clouds.nc')\n    cloud_var = f.variables['primary_cloud']\n    assert_print(cloud_var)\n    assert_print(cloud_var.datatype.enum_dict)\n    assert_print(cloud_var[:])\n    f.close()\n    from netCDF4 import stringtochar\n    nc = Dataset('stringtest.nc', 'w', format='NETCDF4_CLASSIC')\n    nc.createDimension('nchars', 3)\n    nc.createDimension('nstrings', None)\n    v = nc.createVariable('strings', 'S1', ('nstrings', 'nchars'))\n    datain = np.array(['foo', 'bar'], dtype='S3')\n    v[:] = stringtochar(datain)\n    assert_print(v[:])\n    v._Encoding = 'ascii'\n    v[:] = datain\n    assert_print(v[:])\n    nc.close()\n    nc = Dataset('compoundstring_example.nc', 'w')\n    dtype = np.dtype([('observation', 'f4'), ('station_name', 'S12')])\n    station_data_t = nc.createCompoundType(dtype, 'station_data')\n    nc.createDimension('station', None)\n    statdat = nc.createVariable('station_obs', station_data_t, ('station',))\n    data = np.empty(2, station_data_t.dtype_view)\n    data['observation'][:] = (123.0, 3.14)\n    data['station_name'][:] = ('Boulder', 'New York')\n    assert_print(statdat.dtype)\n    statdat[:] = data\n    assert_print(statdat[:])\n    assert_print(statdat[:].dtype)\n    statdat.set_auto_chartostring(False)\n    statdat[:] = data.view(station_data_t.dtype)\n    assert_print(statdat[:])\n    nc.close()\n    nc = Dataset('diskless_example.nc', 'w', diskless=True, persist=True)\n    nc.createDimension('x', None)\n    v = nc.createVariable('v', np.int32, 'x')\n    v[0:5] = np.arange(5)\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()\n    f = open('diskless_example.nc', 'rb')\n    nc_bytes = f.read()\n    f.close()\n    nc = Dataset('inmemory.nc', memory=nc_bytes)\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()\n    nc = Dataset('inmemory.nc', mode='w', memory=1028)\n    nc.createDimension('x', None)\n    v = nc.createVariable('v', np.int32, 'x')\n    v[0:5] = np.arange(5)\n    nc_buf = nc.close()\n    assert_print(type(nc_buf))\n    f = open('inmemory.nc', 'wb')\n    f.write(nc_buf)\n    f.close()\n    nc = Dataset('inmemory.nc')\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()",
        "mutated": [
            "@pytest.mark.driver_timeout(60)\n@run_in_pyodide(packages=['netCDF4', 'numpy'])\ndef test_netCDF4_tutorial(selenium):\n    if False:\n        i = 10\n    import re\n    from datetime import datetime\n    DATETIME_PATTERN = re.compile('[a-zA-Z]{3}\\\\s+[a-zA-Z]{3}\\\\s+[0-9]{1,2}\\\\s+[0-9]{2}:[0-9]{2}:[0-9]{2}\\\\s+[0-9]{4}')\n    DATETIME_FORMAT = '%a %b %d %H:%M:%S %Y'\n    stdouts = ['NETCDF4', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: forecasts, analyses\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: model1, model2\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /analyses:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model1:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model2:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"{'level': <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0, 'time': <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0, 'lat': <class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73, 'lon': <class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144}\", '144', 'False', 'True', \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0\", \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\", \"<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73\", \"<class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144\", \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\", \"<class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\n    least_significant_digit: 3\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model1:\\n    dimensions(sizes): \\n    variables(dimensions): float32 temp(time, level, lat, lon)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\npath = /forecasts/model1\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used\", 'Global attr description = bogus example script', 'Global attr history = Created %a %b %d %H:%M:%S %Y', 'Global attr source = netCDF4 python module tutorial', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    description: bogus example script\\n    history: Created %a %b %d %H:%M:%S %Y\\n    source: netCDF4 python module tutorial\\n    dimensions(sizes): level(0), time(0), lat(73), lon(144)\\n    variables(dimensions): float64 time(time), int32 level(level), float32 lat(lat), float32 lon(lon), float32 temp(time, level, lat, lon)\\n    groups: forecasts, analyses\", \"{'description': 'bogus example script', 'history': 'Created %a %b %d %H:%M:%S %Y', 'source': 'netCDF4 python module tutorial'}\", \"{'time': <class 'netCDF4._netCDF4.Variable'>\\nfloat64 time(time)\\n    units: hours since 0001-01-01 00:00:00.0\\n    calendar: gregorian\\nunlimited dimensions: time\\ncurrent shape = (0,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'level': <class 'netCDF4._netCDF4.Variable'>\\nint32 level(level)\\n    units: hPa\\nunlimited dimensions: level\\ncurrent shape = (0,)\\nfilling on, default _FillValue of -2147483647 used, 'lat': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 lat(lat)\\n    units: degrees north\\nunlimited dimensions: \\ncurrent shape = (73,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'lon': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 lon(lon)\\n    units: degrees east\\nunlimited dimensions: \\ncurrent shape = (144,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'temp': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\n    least_significant_digit: 3\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used}\", 'latitudes =\\n [-90.  -87.5 -85.  -82.5 -80.  -77.5 -75.  -72.5 -70.  -67.5 -65.  -62.5\\n -60.  -57.5 -55.  -52.5 -50.  -47.5 -45.  -42.5 -40.  -37.5 -35.  -32.5\\n -30.  -27.5 -25.  -22.5 -20.  -17.5 -15.  -12.5 -10.   -7.5  -5.   -2.5\\n   0.    2.5   5.    7.5  10.   12.5  15.   17.5  20.   22.5  25.   27.5\\n  30.   32.5  35.   37.5  40.   42.5  45.   47.5  50.   52.5  55.   57.5\\n  60.   62.5  65.   67.5  70.   72.5  75.   77.5  80.   82.5  85.   87.5\\n  90. ]', 'longitudes =\\n [-180.  -177.5 -175.  -172.5 -170.  -167.5 -165.  -162.5 -160.  -157.5\\n -155.  -152.5 -150.  -147.5 -145.  -142.5 -140.  -137.5 -135.  -132.5\\n -130.  -127.5 -125.  -122.5 -120.  -117.5 -115.  -112.5 -110.  -107.5\\n -105.  -102.5 -100.   -97.5  -95.   -92.5  -90.   -87.5  -85.   -82.5\\n  -80.   -77.5  -75.   -72.5  -70.   -67.5  -65.   -62.5  -60.   -57.5\\n  -55.   -52.5  -50.   -47.5  -45.   -42.5  -40.   -37.5  -35.   -32.5\\n  -30.   -27.5  -25.   -22.5  -20.   -17.5  -15.   -12.5  -10.    -7.5\\n   -5.    -2.5    0.     2.5    5.     7.5   10.    12.5   15.    17.5\\n   20.    22.5   25.    27.5   30.    32.5   35.    37.5   40.    42.5\\n   45.    47.5   50.    52.5   55.    57.5   60.    62.5   65.    67.5\\n   70.    72.5   75.    77.5   80.    82.5   85.    87.5   90.    92.5\\n   95.    97.5  100.   102.5  105.   107.5  110.   112.5  115.   117.5\\n  120.   122.5  125.   127.5  130.   132.5  135.   137.5  140.   142.5\\n  145.   147.5  150.   152.5  155.   157.5  160.   162.5  165.   167.5\\n  170.   172.5  175.   177.5]', 'temp shape before adding data =  (0, 0, 73, 144)', 'temp shape after adding data =  (5, 10, 73, 144)', 'levels shape after adding pressure data =  (10,)', 'shape of fancy temp slice =  (3, 3, 36, 71)', '(4, 4)', 'time values (in units hours since 0001-01-01 00:00:00.0):\\n[17533104. 17533116. 17533128. 17533140. 17533152.]', 'dates corresponding to time values:\\n[cftime.DatetimeGregorian(2001, 3, 1, 0, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 1, 12, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 2, 0, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 2, 12, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 3, 0, 0, 0, 0, has_year_zero=False)]', '[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\\n 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\\n 96 97 98 99]', 'complex128', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x_dim(3)\\n    variables(dimensions): {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True} cmplx_var(x_dim)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\ncompound cmplx_var(x_dim)\\ncompound data type: {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}\\nunlimited dimensions: x_dim\\ncurrent shape = (3,)\", \"{'complex128': <class 'netCDF4._netCDF4.CompoundType'>: name = 'complex128', numpy dtype = {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}}\", \"<class 'netCDF4._netCDF4.CompoundType'>: name = 'complex128', numpy dtype = {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}\", '(3,)', 'complex128 [ 0.54030231+0.84147098j -0.84147098+0.54030231j -0.54030231-0.84147098j]', 'complex128 [ 0.54030231+0.84147098j -0.84147098+0.54030231j -0.54030231-0.84147098j]', \"{'wind_data': <class 'netCDF4._netCDF4.CompoundType'>: name = 'wind_data', numpy dtype = {'names': ['speed', 'direction'], 'formats': ['<f4', '<i4'], 'offsets': [0, 4], 'itemsize': 8, 'aligned': True}, 'station_data': <class 'netCDF4._netCDF4.CompoundType'>: name = 'station_data', numpy dtype = {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True}, 'wind_data_units': <class 'netCDF4._netCDF4.CompoundType'>: name = 'wind_data_units', numpy dtype = {'names': ['speed', 'direction'], 'formats': [('S1', (12,)), ('S1', (12,))], 'offsets': [0, 12], 'itemsize': 24, 'aligned': True}, 'station_data_units': <class 'netCDF4._netCDF4.CompoundType'>: name = 'station_data_units', numpy dtype = {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'location_name', 'press_sounding'], 'formats': [('S1', (12,)), ('S1', (12,)), [('speed', 'S1', (12,)), ('direction', 'S1', (12,))], ('S1', (12,)), ('S1', (12,)), ('S1', (12,))], 'offsets': [0, 12, 24, 48, 60, 72], 'itemsize': 84, 'aligned': True}}\", \"[('latitude', 'S12'), ('longitude', 'S12'), ('surface_wind', [('speed', 'S12'), ('direction', 'S12')]), ('temp_sounding', 'S12'), ('location_name', 'S12'), ('press_sounding', 'S12')]\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): station(2)\\n    variables(dimensions): {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True} station_obs(station)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\ncompound station_obs(station)\\n    units: (b'degrees N', b'degrees W', (b'm/s', b'degrees'), b'Kelvin', b'None', b'hPa')\\ncompound data type: {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True}\\nunlimited dimensions: station\\ncurrent shape = (2,)\", 'data in a variable of compound type:', \"[(40.  , -105.  , ( 12.5, 270), [280.3, 272. , 270. , 269. , 266. , 258. , 254.1, 250. , 245.5, 240. ], [800, 750, 700, 650, 600, 550, 500, 450, 400, 350], b'Boulder, CO')\\n (40.78,  -73.99, (-12.5,  90), [290.2, 282.5, 279. , 277.9, 276. , 266. , 264.1, 260. , 255.5, 243. ], [900, 850, 800, 750, 700, 650, 600, 550, 500, 450], b'New York, NY')]\", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen phony_vlen_var(y, x)\\nvlen data type: int32\\nunlimited dimensions: \\ncurrent shape = (4, 3)\", 'vlen variable =\\n [[array([1, 2, 3, 4, 5, 6, 7]) array([1, 2, 3, 4, 5]) array([1])]\\n [array([1, 2, 3]) array([1, 2]) array([1])]\\n [array([1]) array([1, 2, 3, 4, 5, 6, 7]) array([1])]\\n [array([1, 2, 3, 4, 5, 6]) array([1, 2, 3, 4, 5]) array([1])]]', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(3), y(4)\\n    variables(dimensions): int32 phony_vlen_var(y, x)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen phony_vlen_var(y, x)\\nvlen data type: int32\\nunlimited dimensions: \\ncurrent shape = (4, 3)\", \"<class 'netCDF4._netCDF4.VLType'>: name = 'phony_vlen', numpy dtype = int32\", \"variable-length string variable:\\n ['ZOGMRmJo' 'BxdAK1fku' 'lgOzaanCtv' 'D5ALrXJCDU' 'W9r' 'Y7edBPrthEr'\\n 'OVeqx' 'aH1ZXc5A' 'LC1ajPJ' 'du']\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(3), y(4), z(10)\\n    variables(dimensions): int32 phony_vlen_var(y, x), <class 'str'> strvar(z)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen strvar(z)\\nvlen data type: <class 'str'>\\nunlimited dimensions: \\ncurrent shape = (10,)\", \"<class 'netCDF4._netCDF4.EnumType'>: name = 'cloud_t', numpy dtype = uint8, fields/values ={'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\", \"<class 'netCDF4._netCDF4.Variable'>\\nenum primary_cloud(time)\\n    _FillValue: 255\\nenum data type: uint8\\nunlimited dimensions: time\\ncurrent shape = (5,)\", \"{'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\", '[0 2 4 -- 1]', \"[[b'f' b'o' b'o']\\n [b'b' b'a' b'r']]\", \"['foo' 'bar']\", \"{'names': ['observation', 'station_name'], 'formats': ['<f4', ('S1', (12,))], 'offsets': [0, 4], 'itemsize': 16, 'aligned': True}\", \"[(123.  , b'Boulder') (  3.14, b'New York')]\", \"{'names': ['observation', 'station_name'], 'formats': ['<f4', 'S12'], 'offsets': [0, 4], 'itemsize': 16, 'aligned': True}\", \"[(123.  , [b'B', b'o', b'u', b'l', b'd', b'e', b'r', b'', b'', b'', b'', b''])\\n (  3.14, [b'N', b'e', b'w', b' ', b'Y', b'o', b'r', b'k', b'', b'', b'', b''])]\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]', \"<class 'memoryview'>\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]']\n\n    def replace_netcdf_datetime(match):\n        try:\n            datetime.strptime(match.group(0), DATETIME_FORMAT)\n        except Exception:\n            return match.group(0)\n        else:\n            return DATETIME_FORMAT\n\n    def assert_print(*args):\n        output = DATETIME_PATTERN.sub(replace_netcdf_datetime, ' '.join((str(a) for a in args)))\n        expected = stdouts.pop(0)\n        if output != expected:\n            assert output == expected, f'{repr(output)} != {repr(expected)}'\n    '\\n    Test adopted from (but with reproducible randomness):\\n    https://github.com/Unidata/netcdf4-python/blob/master/examples/tutorial.py\\n    Released under the MIT License\\n    '\n    from numpy.random import PCG64, Generator\n    rng = Generator(PCG64(seed=42))\n    from netCDF4 import Dataset\n    rootgrp = Dataset('test.nc', 'w', format='NETCDF4')\n    assert_print(rootgrp.file_format)\n    rootgrp.close()\n    rootgrp = Dataset('test.nc', 'a')\n    rootgrp.createGroup('forecasts')\n    rootgrp.createGroup('analyses')\n    rootgrp.createGroup('/forecasts/model1')\n    rootgrp.createGroup('/forecasts/model2')\n\n    def walktree(top):\n        yield top.groups.values()\n        for value in top.groups.values():\n            yield from walktree(value)\n    assert_print(rootgrp)\n    for children in walktree(rootgrp):\n        for child in children:\n            assert_print(child)\n    rootgrp.createDimension('level', None)\n    time = rootgrp.createDimension('time', None)\n    rootgrp.createDimension('lat', 73)\n    lon = rootgrp.createDimension('lon', 144)\n    assert_print(rootgrp.dimensions)\n    assert_print(len(lon))\n    assert_print(lon.isunlimited())\n    assert_print(time.isunlimited())\n    for dimobj in rootgrp.dimensions.values():\n        assert_print(dimobj)\n    assert_print(time)\n    times = rootgrp.createVariable('time', 'f8', ('time',))\n    levels = rootgrp.createVariable('level', 'i4', ('level',))\n    latitudes = rootgrp.createVariable('lat', 'f4', ('lat',))\n    longitudes = rootgrp.createVariable('lon', 'f4', ('lon',))\n    temp = rootgrp.createVariable('temp', 'f4', ('time', 'level', 'lat', 'lon'), least_significant_digit=3)\n    assert_print(temp)\n    temp = rootgrp.createVariable('/forecasts/model1/temp', 'f4', ('time', 'level', 'lat', 'lon'))\n    assert_print(rootgrp['/forecasts/model1'])\n    assert_print(rootgrp['/forecasts/model1/temp'])\n    import time\n    rootgrp.description = 'bogus example script'\n    rootgrp.history = 'Created ' + time.ctime(time.time())\n    rootgrp.source = 'netCDF4 python module tutorial'\n    latitudes.units = 'degrees north'\n    longitudes.units = 'degrees east'\n    levels.units = 'hPa'\n    temp.units = 'K'\n    times.units = 'hours since 0001-01-01 00:00:00.0'\n    times.calendar = 'gregorian'\n    for name in rootgrp.ncattrs():\n        assert_print('Global attr', name, '=', getattr(rootgrp, name))\n    assert_print(rootgrp)\n    assert_print(rootgrp.__dict__)\n    assert_print(rootgrp.variables)\n    import numpy as np\n    lats = np.arange(-90, 91, 2.5)\n    lons = np.arange(-180, 180, 2.5)\n    latitudes[:] = lats\n    longitudes[:] = lons\n    assert_print('latitudes =\\n', latitudes[:])\n    assert_print('longitudes =\\n', longitudes[:])\n    nlats = len(rootgrp.dimensions['lat'])\n    nlons = len(rootgrp.dimensions['lon'])\n    assert_print('temp shape before adding data = ', temp.shape)\n    temp[0:5, 0:10, :, :] = rng.uniform(size=(5, 10, nlats, nlons))\n    assert_print('temp shape after adding data = ', temp.shape)\n    assert_print('levels shape after adding pressure data = ', levels.shape)\n    levels[:] = [1000.0, 850.0, 700.0, 500.0, 300.0, 250.0, 200.0, 150.0, 100.0, 50.0]\n    tempdat = temp[::2, [1, 3, 6], lats > 0, lons > 0]\n    assert_print('shape of fancy temp slice = ', tempdat.shape)\n    assert_print(temp[0, 0, [0, 1, 2, 3], [0, 1, 2, 3]].shape)\n    from datetime import timedelta\n    from netCDF4 import date2num, num2date\n    dates = [datetime(2001, 3, 1) + n * timedelta(hours=12) for n in range(temp.shape[0])]\n    times[:] = date2num(dates, units=times.units, calendar=times.calendar)\n    assert_print(f'time values (in units {times.units}):\\n{times[:]}')\n    dates = num2date(times[:], units=times.units, calendar=times.calendar)\n    assert_print(f'dates corresponding to time values:\\n{dates}')\n    rootgrp.close()\n    for nfile in range(10):\n        f = Dataset('mftest' + repr(nfile) + '.nc', 'w', format='NETCDF4_CLASSIC')\n        f.createDimension('x', None)\n        x = f.createVariable('x', 'i', ('x',))\n        x[0:10] = np.arange(nfile * 10, 10 * (nfile + 1))\n        f.close()\n    from netCDF4 import MFDataset\n    f = MFDataset('mftest*nc')\n    assert_print(f.variables['x'][:])\n    f = Dataset('complex.nc', 'w')\n    size = 3\n    datac = np.exp(1j * (1.0 + np.linspace(0, np.pi, size)))\n    assert_print(datac.dtype)\n    complex128 = np.dtype([('real', np.float64), ('imag', np.float64)])\n    complex128_t = f.createCompoundType(complex128, 'complex128')\n    f.createDimension('x_dim', None)\n    v = f.createVariable('cmplx_var', complex128_t, 'x_dim')\n    data = np.empty(size, complex128)\n    data['real'] = datac.real\n    data['imag'] = datac.imag\n    v[:] = data\n    f.close()\n    f = Dataset('complex.nc')\n    assert_print(f)\n    assert_print(f.variables['cmplx_var'])\n    assert_print(f.cmptypes)\n    assert_print(f.cmptypes['complex128'])\n    v = f.variables['cmplx_var']\n    assert_print(v.shape)\n    datain = v[:]\n    datac2 = np.empty(datain.shape, np.complex128)\n    datac2.real = datain['real']\n    datac2.imag = datain['imag']\n    assert_print(datac.dtype, datac)\n    assert_print(datac2.dtype, datac2)\n    f = Dataset('compound_example.nc', 'w')\n    f.createDimension('station', None)\n    winddtype = np.dtype([('speed', 'f4'), ('direction', 'i4')])\n    statdtype = np.dtype([('latitude', 'f4'), ('longitude', 'f4'), ('surface_wind', winddtype), ('temp_sounding', 'f4', 10), ('press_sounding', 'i4', 10), ('location_name', 'S12')])\n    f.createCompoundType(winddtype, 'wind_data')\n    station_data_t = f.createCompoundType(statdtype, 'station_data')\n    winddtype_units = np.dtype([('speed', 'S12'), ('direction', 'S12')])\n    statdtype_units = np.dtype([('latitude', 'S12'), ('longitude', 'S12'), ('surface_wind', winddtype_units), ('temp_sounding', 'S12'), ('location_name', 'S12'), ('press_sounding', 'S12')])\n    f.createCompoundType(winddtype_units, 'wind_data_units')\n    f.createCompoundType(statdtype_units, 'station_data_units')\n    statdat = f.createVariable('station_obs', station_data_t, ('station',))\n    data = np.empty(1, statdtype)\n    data['latitude'] = 40.0\n    data['longitude'] = -105.0\n    data['surface_wind']['speed'] = 12.5\n    data['surface_wind']['direction'] = 270\n    data['temp_sounding'] = (280.3, 272.0, 270.0, 269.0, 266.0, 258.0, 254.1, 250.0, 245.5, 240.0)\n    data['press_sounding'] = range(800, 300, -50)\n    data['location_name'] = 'Boulder, CO'\n    statdat[0] = data\n    statdat[1] = np.array((40.78, -73.99, (-12.5, 90), (290.2, 282.5, 279.0, 277.9, 276.0, 266.0, 264.1, 260.0, 255.5, 243.0), range(900, 400, -50), 'New York, NY'), data.dtype)\n    assert_print(f.cmptypes)\n    windunits = np.empty(1, winddtype_units)\n    stationobs_units = np.empty(1, statdtype_units)\n    windunits['speed'] = 'm/s'\n    windunits['direction'] = 'degrees'\n    stationobs_units['latitude'] = 'degrees N'\n    stationobs_units['longitude'] = 'degrees W'\n    stationobs_units['surface_wind'] = windunits\n    stationobs_units['location_name'] = 'None'\n    stationobs_units['temp_sounding'] = 'Kelvin'\n    stationobs_units['press_sounding'] = 'hPa'\n    assert_print(stationobs_units.dtype)\n    statdat.units = stationobs_units\n    f.close()\n    f = Dataset('compound_example.nc')\n    assert_print(f)\n    statdat = f.variables['station_obs']\n    assert_print(statdat)\n    assert_print('data in a variable of compound type:')\n    assert_print(statdat[:])\n    f.close()\n    f = Dataset('tst_vlen.nc', 'w')\n    vlen_t = f.createVLType(np.int32, 'phony_vlen')\n    x = f.createDimension('x', 3)\n    y = f.createDimension('y', 4)\n    vlvar = f.createVariable('phony_vlen_var', vlen_t, ('y', 'x'))\n    data = np.empty(len(y) * len(x), object)\n    for n in range(len(y) * len(x)):\n        data[n] = np.arange(rng.integers(1, 10), dtype='int32') + 1\n    data = np.reshape(data, (len(y), len(x)))\n    vlvar[:] = data\n    assert_print(vlvar)\n    assert_print('vlen variable =\\n', vlvar[:])\n    assert_print(f)\n    assert_print(f.variables['phony_vlen_var'])\n    assert_print(f.vltypes['phony_vlen'])\n    f.createDimension('z', 10)\n    strvar = f.createVariable('strvar', str, 'z')\n    chars = list('1234567890aabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n    data = np.empty(10, object)\n    for n in range(10):\n        stringlen = rng.integers(2, 12)\n        data[n] = ''.join([rng.choice(chars) for i in range(stringlen)])\n    strvar[:] = data\n    assert_print('variable-length string variable:\\n', strvar[:])\n    assert_print(f)\n    assert_print(f.variables['strvar'])\n    f.close()\n    f = Dataset('clouds.nc', 'w')\n    enum_dict = {'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\n    cloud_type = f.createEnumType(np.uint8, 'cloud_t', enum_dict)\n    assert_print(cloud_type)\n    time = f.createDimension('time', None)\n    cloud_var = f.createVariable('primary_cloud', cloud_type, 'time', fill_value=enum_dict['Missing'])\n    cloud_var[:] = [enum_dict['Clear'], enum_dict['Stratus'], enum_dict['Cumulus'], enum_dict['Missing'], enum_dict['Cumulonimbus']]\n    f.close()\n    f = Dataset('clouds.nc')\n    cloud_var = f.variables['primary_cloud']\n    assert_print(cloud_var)\n    assert_print(cloud_var.datatype.enum_dict)\n    assert_print(cloud_var[:])\n    f.close()\n    from netCDF4 import stringtochar\n    nc = Dataset('stringtest.nc', 'w', format='NETCDF4_CLASSIC')\n    nc.createDimension('nchars', 3)\n    nc.createDimension('nstrings', None)\n    v = nc.createVariable('strings', 'S1', ('nstrings', 'nchars'))\n    datain = np.array(['foo', 'bar'], dtype='S3')\n    v[:] = stringtochar(datain)\n    assert_print(v[:])\n    v._Encoding = 'ascii'\n    v[:] = datain\n    assert_print(v[:])\n    nc.close()\n    nc = Dataset('compoundstring_example.nc', 'w')\n    dtype = np.dtype([('observation', 'f4'), ('station_name', 'S12')])\n    station_data_t = nc.createCompoundType(dtype, 'station_data')\n    nc.createDimension('station', None)\n    statdat = nc.createVariable('station_obs', station_data_t, ('station',))\n    data = np.empty(2, station_data_t.dtype_view)\n    data['observation'][:] = (123.0, 3.14)\n    data['station_name'][:] = ('Boulder', 'New York')\n    assert_print(statdat.dtype)\n    statdat[:] = data\n    assert_print(statdat[:])\n    assert_print(statdat[:].dtype)\n    statdat.set_auto_chartostring(False)\n    statdat[:] = data.view(station_data_t.dtype)\n    assert_print(statdat[:])\n    nc.close()\n    nc = Dataset('diskless_example.nc', 'w', diskless=True, persist=True)\n    nc.createDimension('x', None)\n    v = nc.createVariable('v', np.int32, 'x')\n    v[0:5] = np.arange(5)\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()\n    f = open('diskless_example.nc', 'rb')\n    nc_bytes = f.read()\n    f.close()\n    nc = Dataset('inmemory.nc', memory=nc_bytes)\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()\n    nc = Dataset('inmemory.nc', mode='w', memory=1028)\n    nc.createDimension('x', None)\n    v = nc.createVariable('v', np.int32, 'x')\n    v[0:5] = np.arange(5)\n    nc_buf = nc.close()\n    assert_print(type(nc_buf))\n    f = open('inmemory.nc', 'wb')\n    f.write(nc_buf)\n    f.close()\n    nc = Dataset('inmemory.nc')\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()",
            "@pytest.mark.driver_timeout(60)\n@run_in_pyodide(packages=['netCDF4', 'numpy'])\ndef test_netCDF4_tutorial(selenium):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    import re\n    from datetime import datetime\n    DATETIME_PATTERN = re.compile('[a-zA-Z]{3}\\\\s+[a-zA-Z]{3}\\\\s+[0-9]{1,2}\\\\s+[0-9]{2}:[0-9]{2}:[0-9]{2}\\\\s+[0-9]{4}')\n    DATETIME_FORMAT = '%a %b %d %H:%M:%S %Y'\n    stdouts = ['NETCDF4', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: forecasts, analyses\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: model1, model2\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /analyses:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model1:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model2:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"{'level': <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0, 'time': <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0, 'lat': <class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73, 'lon': <class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144}\", '144', 'False', 'True', \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0\", \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\", \"<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73\", \"<class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144\", \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\", \"<class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\n    least_significant_digit: 3\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model1:\\n    dimensions(sizes): \\n    variables(dimensions): float32 temp(time, level, lat, lon)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\npath = /forecasts/model1\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used\", 'Global attr description = bogus example script', 'Global attr history = Created %a %b %d %H:%M:%S %Y', 'Global attr source = netCDF4 python module tutorial', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    description: bogus example script\\n    history: Created %a %b %d %H:%M:%S %Y\\n    source: netCDF4 python module tutorial\\n    dimensions(sizes): level(0), time(0), lat(73), lon(144)\\n    variables(dimensions): float64 time(time), int32 level(level), float32 lat(lat), float32 lon(lon), float32 temp(time, level, lat, lon)\\n    groups: forecasts, analyses\", \"{'description': 'bogus example script', 'history': 'Created %a %b %d %H:%M:%S %Y', 'source': 'netCDF4 python module tutorial'}\", \"{'time': <class 'netCDF4._netCDF4.Variable'>\\nfloat64 time(time)\\n    units: hours since 0001-01-01 00:00:00.0\\n    calendar: gregorian\\nunlimited dimensions: time\\ncurrent shape = (0,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'level': <class 'netCDF4._netCDF4.Variable'>\\nint32 level(level)\\n    units: hPa\\nunlimited dimensions: level\\ncurrent shape = (0,)\\nfilling on, default _FillValue of -2147483647 used, 'lat': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 lat(lat)\\n    units: degrees north\\nunlimited dimensions: \\ncurrent shape = (73,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'lon': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 lon(lon)\\n    units: degrees east\\nunlimited dimensions: \\ncurrent shape = (144,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'temp': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\n    least_significant_digit: 3\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used}\", 'latitudes =\\n [-90.  -87.5 -85.  -82.5 -80.  -77.5 -75.  -72.5 -70.  -67.5 -65.  -62.5\\n -60.  -57.5 -55.  -52.5 -50.  -47.5 -45.  -42.5 -40.  -37.5 -35.  -32.5\\n -30.  -27.5 -25.  -22.5 -20.  -17.5 -15.  -12.5 -10.   -7.5  -5.   -2.5\\n   0.    2.5   5.    7.5  10.   12.5  15.   17.5  20.   22.5  25.   27.5\\n  30.   32.5  35.   37.5  40.   42.5  45.   47.5  50.   52.5  55.   57.5\\n  60.   62.5  65.   67.5  70.   72.5  75.   77.5  80.   82.5  85.   87.5\\n  90. ]', 'longitudes =\\n [-180.  -177.5 -175.  -172.5 -170.  -167.5 -165.  -162.5 -160.  -157.5\\n -155.  -152.5 -150.  -147.5 -145.  -142.5 -140.  -137.5 -135.  -132.5\\n -130.  -127.5 -125.  -122.5 -120.  -117.5 -115.  -112.5 -110.  -107.5\\n -105.  -102.5 -100.   -97.5  -95.   -92.5  -90.   -87.5  -85.   -82.5\\n  -80.   -77.5  -75.   -72.5  -70.   -67.5  -65.   -62.5  -60.   -57.5\\n  -55.   -52.5  -50.   -47.5  -45.   -42.5  -40.   -37.5  -35.   -32.5\\n  -30.   -27.5  -25.   -22.5  -20.   -17.5  -15.   -12.5  -10.    -7.5\\n   -5.    -2.5    0.     2.5    5.     7.5   10.    12.5   15.    17.5\\n   20.    22.5   25.    27.5   30.    32.5   35.    37.5   40.    42.5\\n   45.    47.5   50.    52.5   55.    57.5   60.    62.5   65.    67.5\\n   70.    72.5   75.    77.5   80.    82.5   85.    87.5   90.    92.5\\n   95.    97.5  100.   102.5  105.   107.5  110.   112.5  115.   117.5\\n  120.   122.5  125.   127.5  130.   132.5  135.   137.5  140.   142.5\\n  145.   147.5  150.   152.5  155.   157.5  160.   162.5  165.   167.5\\n  170.   172.5  175.   177.5]', 'temp shape before adding data =  (0, 0, 73, 144)', 'temp shape after adding data =  (5, 10, 73, 144)', 'levels shape after adding pressure data =  (10,)', 'shape of fancy temp slice =  (3, 3, 36, 71)', '(4, 4)', 'time values (in units hours since 0001-01-01 00:00:00.0):\\n[17533104. 17533116. 17533128. 17533140. 17533152.]', 'dates corresponding to time values:\\n[cftime.DatetimeGregorian(2001, 3, 1, 0, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 1, 12, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 2, 0, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 2, 12, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 3, 0, 0, 0, 0, has_year_zero=False)]', '[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\\n 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\\n 96 97 98 99]', 'complex128', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x_dim(3)\\n    variables(dimensions): {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True} cmplx_var(x_dim)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\ncompound cmplx_var(x_dim)\\ncompound data type: {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}\\nunlimited dimensions: x_dim\\ncurrent shape = (3,)\", \"{'complex128': <class 'netCDF4._netCDF4.CompoundType'>: name = 'complex128', numpy dtype = {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}}\", \"<class 'netCDF4._netCDF4.CompoundType'>: name = 'complex128', numpy dtype = {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}\", '(3,)', 'complex128 [ 0.54030231+0.84147098j -0.84147098+0.54030231j -0.54030231-0.84147098j]', 'complex128 [ 0.54030231+0.84147098j -0.84147098+0.54030231j -0.54030231-0.84147098j]', \"{'wind_data': <class 'netCDF4._netCDF4.CompoundType'>: name = 'wind_data', numpy dtype = {'names': ['speed', 'direction'], 'formats': ['<f4', '<i4'], 'offsets': [0, 4], 'itemsize': 8, 'aligned': True}, 'station_data': <class 'netCDF4._netCDF4.CompoundType'>: name = 'station_data', numpy dtype = {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True}, 'wind_data_units': <class 'netCDF4._netCDF4.CompoundType'>: name = 'wind_data_units', numpy dtype = {'names': ['speed', 'direction'], 'formats': [('S1', (12,)), ('S1', (12,))], 'offsets': [0, 12], 'itemsize': 24, 'aligned': True}, 'station_data_units': <class 'netCDF4._netCDF4.CompoundType'>: name = 'station_data_units', numpy dtype = {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'location_name', 'press_sounding'], 'formats': [('S1', (12,)), ('S1', (12,)), [('speed', 'S1', (12,)), ('direction', 'S1', (12,))], ('S1', (12,)), ('S1', (12,)), ('S1', (12,))], 'offsets': [0, 12, 24, 48, 60, 72], 'itemsize': 84, 'aligned': True}}\", \"[('latitude', 'S12'), ('longitude', 'S12'), ('surface_wind', [('speed', 'S12'), ('direction', 'S12')]), ('temp_sounding', 'S12'), ('location_name', 'S12'), ('press_sounding', 'S12')]\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): station(2)\\n    variables(dimensions): {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True} station_obs(station)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\ncompound station_obs(station)\\n    units: (b'degrees N', b'degrees W', (b'm/s', b'degrees'), b'Kelvin', b'None', b'hPa')\\ncompound data type: {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True}\\nunlimited dimensions: station\\ncurrent shape = (2,)\", 'data in a variable of compound type:', \"[(40.  , -105.  , ( 12.5, 270), [280.3, 272. , 270. , 269. , 266. , 258. , 254.1, 250. , 245.5, 240. ], [800, 750, 700, 650, 600, 550, 500, 450, 400, 350], b'Boulder, CO')\\n (40.78,  -73.99, (-12.5,  90), [290.2, 282.5, 279. , 277.9, 276. , 266. , 264.1, 260. , 255.5, 243. ], [900, 850, 800, 750, 700, 650, 600, 550, 500, 450], b'New York, NY')]\", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen phony_vlen_var(y, x)\\nvlen data type: int32\\nunlimited dimensions: \\ncurrent shape = (4, 3)\", 'vlen variable =\\n [[array([1, 2, 3, 4, 5, 6, 7]) array([1, 2, 3, 4, 5]) array([1])]\\n [array([1, 2, 3]) array([1, 2]) array([1])]\\n [array([1]) array([1, 2, 3, 4, 5, 6, 7]) array([1])]\\n [array([1, 2, 3, 4, 5, 6]) array([1, 2, 3, 4, 5]) array([1])]]', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(3), y(4)\\n    variables(dimensions): int32 phony_vlen_var(y, x)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen phony_vlen_var(y, x)\\nvlen data type: int32\\nunlimited dimensions: \\ncurrent shape = (4, 3)\", \"<class 'netCDF4._netCDF4.VLType'>: name = 'phony_vlen', numpy dtype = int32\", \"variable-length string variable:\\n ['ZOGMRmJo' 'BxdAK1fku' 'lgOzaanCtv' 'D5ALrXJCDU' 'W9r' 'Y7edBPrthEr'\\n 'OVeqx' 'aH1ZXc5A' 'LC1ajPJ' 'du']\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(3), y(4), z(10)\\n    variables(dimensions): int32 phony_vlen_var(y, x), <class 'str'> strvar(z)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen strvar(z)\\nvlen data type: <class 'str'>\\nunlimited dimensions: \\ncurrent shape = (10,)\", \"<class 'netCDF4._netCDF4.EnumType'>: name = 'cloud_t', numpy dtype = uint8, fields/values ={'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\", \"<class 'netCDF4._netCDF4.Variable'>\\nenum primary_cloud(time)\\n    _FillValue: 255\\nenum data type: uint8\\nunlimited dimensions: time\\ncurrent shape = (5,)\", \"{'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\", '[0 2 4 -- 1]', \"[[b'f' b'o' b'o']\\n [b'b' b'a' b'r']]\", \"['foo' 'bar']\", \"{'names': ['observation', 'station_name'], 'formats': ['<f4', ('S1', (12,))], 'offsets': [0, 4], 'itemsize': 16, 'aligned': True}\", \"[(123.  , b'Boulder') (  3.14, b'New York')]\", \"{'names': ['observation', 'station_name'], 'formats': ['<f4', 'S12'], 'offsets': [0, 4], 'itemsize': 16, 'aligned': True}\", \"[(123.  , [b'B', b'o', b'u', b'l', b'd', b'e', b'r', b'', b'', b'', b'', b''])\\n (  3.14, [b'N', b'e', b'w', b' ', b'Y', b'o', b'r', b'k', b'', b'', b'', b''])]\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]', \"<class 'memoryview'>\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]']\n\n    def replace_netcdf_datetime(match):\n        try:\n            datetime.strptime(match.group(0), DATETIME_FORMAT)\n        except Exception:\n            return match.group(0)\n        else:\n            return DATETIME_FORMAT\n\n    def assert_print(*args):\n        output = DATETIME_PATTERN.sub(replace_netcdf_datetime, ' '.join((str(a) for a in args)))\n        expected = stdouts.pop(0)\n        if output != expected:\n            assert output == expected, f'{repr(output)} != {repr(expected)}'\n    '\\n    Test adopted from (but with reproducible randomness):\\n    https://github.com/Unidata/netcdf4-python/blob/master/examples/tutorial.py\\n    Released under the MIT License\\n    '\n    from numpy.random import PCG64, Generator\n    rng = Generator(PCG64(seed=42))\n    from netCDF4 import Dataset\n    rootgrp = Dataset('test.nc', 'w', format='NETCDF4')\n    assert_print(rootgrp.file_format)\n    rootgrp.close()\n    rootgrp = Dataset('test.nc', 'a')\n    rootgrp.createGroup('forecasts')\n    rootgrp.createGroup('analyses')\n    rootgrp.createGroup('/forecasts/model1')\n    rootgrp.createGroup('/forecasts/model2')\n\n    def walktree(top):\n        yield top.groups.values()\n        for value in top.groups.values():\n            yield from walktree(value)\n    assert_print(rootgrp)\n    for children in walktree(rootgrp):\n        for child in children:\n            assert_print(child)\n    rootgrp.createDimension('level', None)\n    time = rootgrp.createDimension('time', None)\n    rootgrp.createDimension('lat', 73)\n    lon = rootgrp.createDimension('lon', 144)\n    assert_print(rootgrp.dimensions)\n    assert_print(len(lon))\n    assert_print(lon.isunlimited())\n    assert_print(time.isunlimited())\n    for dimobj in rootgrp.dimensions.values():\n        assert_print(dimobj)\n    assert_print(time)\n    times = rootgrp.createVariable('time', 'f8', ('time',))\n    levels = rootgrp.createVariable('level', 'i4', ('level',))\n    latitudes = rootgrp.createVariable('lat', 'f4', ('lat',))\n    longitudes = rootgrp.createVariable('lon', 'f4', ('lon',))\n    temp = rootgrp.createVariable('temp', 'f4', ('time', 'level', 'lat', 'lon'), least_significant_digit=3)\n    assert_print(temp)\n    temp = rootgrp.createVariable('/forecasts/model1/temp', 'f4', ('time', 'level', 'lat', 'lon'))\n    assert_print(rootgrp['/forecasts/model1'])\n    assert_print(rootgrp['/forecasts/model1/temp'])\n    import time\n    rootgrp.description = 'bogus example script'\n    rootgrp.history = 'Created ' + time.ctime(time.time())\n    rootgrp.source = 'netCDF4 python module tutorial'\n    latitudes.units = 'degrees north'\n    longitudes.units = 'degrees east'\n    levels.units = 'hPa'\n    temp.units = 'K'\n    times.units = 'hours since 0001-01-01 00:00:00.0'\n    times.calendar = 'gregorian'\n    for name in rootgrp.ncattrs():\n        assert_print('Global attr', name, '=', getattr(rootgrp, name))\n    assert_print(rootgrp)\n    assert_print(rootgrp.__dict__)\n    assert_print(rootgrp.variables)\n    import numpy as np\n    lats = np.arange(-90, 91, 2.5)\n    lons = np.arange(-180, 180, 2.5)\n    latitudes[:] = lats\n    longitudes[:] = lons\n    assert_print('latitudes =\\n', latitudes[:])\n    assert_print('longitudes =\\n', longitudes[:])\n    nlats = len(rootgrp.dimensions['lat'])\n    nlons = len(rootgrp.dimensions['lon'])\n    assert_print('temp shape before adding data = ', temp.shape)\n    temp[0:5, 0:10, :, :] = rng.uniform(size=(5, 10, nlats, nlons))\n    assert_print('temp shape after adding data = ', temp.shape)\n    assert_print('levels shape after adding pressure data = ', levels.shape)\n    levels[:] = [1000.0, 850.0, 700.0, 500.0, 300.0, 250.0, 200.0, 150.0, 100.0, 50.0]\n    tempdat = temp[::2, [1, 3, 6], lats > 0, lons > 0]\n    assert_print('shape of fancy temp slice = ', tempdat.shape)\n    assert_print(temp[0, 0, [0, 1, 2, 3], [0, 1, 2, 3]].shape)\n    from datetime import timedelta\n    from netCDF4 import date2num, num2date\n    dates = [datetime(2001, 3, 1) + n * timedelta(hours=12) for n in range(temp.shape[0])]\n    times[:] = date2num(dates, units=times.units, calendar=times.calendar)\n    assert_print(f'time values (in units {times.units}):\\n{times[:]}')\n    dates = num2date(times[:], units=times.units, calendar=times.calendar)\n    assert_print(f'dates corresponding to time values:\\n{dates}')\n    rootgrp.close()\n    for nfile in range(10):\n        f = Dataset('mftest' + repr(nfile) + '.nc', 'w', format='NETCDF4_CLASSIC')\n        f.createDimension('x', None)\n        x = f.createVariable('x', 'i', ('x',))\n        x[0:10] = np.arange(nfile * 10, 10 * (nfile + 1))\n        f.close()\n    from netCDF4 import MFDataset\n    f = MFDataset('mftest*nc')\n    assert_print(f.variables['x'][:])\n    f = Dataset('complex.nc', 'w')\n    size = 3\n    datac = np.exp(1j * (1.0 + np.linspace(0, np.pi, size)))\n    assert_print(datac.dtype)\n    complex128 = np.dtype([('real', np.float64), ('imag', np.float64)])\n    complex128_t = f.createCompoundType(complex128, 'complex128')\n    f.createDimension('x_dim', None)\n    v = f.createVariable('cmplx_var', complex128_t, 'x_dim')\n    data = np.empty(size, complex128)\n    data['real'] = datac.real\n    data['imag'] = datac.imag\n    v[:] = data\n    f.close()\n    f = Dataset('complex.nc')\n    assert_print(f)\n    assert_print(f.variables['cmplx_var'])\n    assert_print(f.cmptypes)\n    assert_print(f.cmptypes['complex128'])\n    v = f.variables['cmplx_var']\n    assert_print(v.shape)\n    datain = v[:]\n    datac2 = np.empty(datain.shape, np.complex128)\n    datac2.real = datain['real']\n    datac2.imag = datain['imag']\n    assert_print(datac.dtype, datac)\n    assert_print(datac2.dtype, datac2)\n    f = Dataset('compound_example.nc', 'w')\n    f.createDimension('station', None)\n    winddtype = np.dtype([('speed', 'f4'), ('direction', 'i4')])\n    statdtype = np.dtype([('latitude', 'f4'), ('longitude', 'f4'), ('surface_wind', winddtype), ('temp_sounding', 'f4', 10), ('press_sounding', 'i4', 10), ('location_name', 'S12')])\n    f.createCompoundType(winddtype, 'wind_data')\n    station_data_t = f.createCompoundType(statdtype, 'station_data')\n    winddtype_units = np.dtype([('speed', 'S12'), ('direction', 'S12')])\n    statdtype_units = np.dtype([('latitude', 'S12'), ('longitude', 'S12'), ('surface_wind', winddtype_units), ('temp_sounding', 'S12'), ('location_name', 'S12'), ('press_sounding', 'S12')])\n    f.createCompoundType(winddtype_units, 'wind_data_units')\n    f.createCompoundType(statdtype_units, 'station_data_units')\n    statdat = f.createVariable('station_obs', station_data_t, ('station',))\n    data = np.empty(1, statdtype)\n    data['latitude'] = 40.0\n    data['longitude'] = -105.0\n    data['surface_wind']['speed'] = 12.5\n    data['surface_wind']['direction'] = 270\n    data['temp_sounding'] = (280.3, 272.0, 270.0, 269.0, 266.0, 258.0, 254.1, 250.0, 245.5, 240.0)\n    data['press_sounding'] = range(800, 300, -50)\n    data['location_name'] = 'Boulder, CO'\n    statdat[0] = data\n    statdat[1] = np.array((40.78, -73.99, (-12.5, 90), (290.2, 282.5, 279.0, 277.9, 276.0, 266.0, 264.1, 260.0, 255.5, 243.0), range(900, 400, -50), 'New York, NY'), data.dtype)\n    assert_print(f.cmptypes)\n    windunits = np.empty(1, winddtype_units)\n    stationobs_units = np.empty(1, statdtype_units)\n    windunits['speed'] = 'm/s'\n    windunits['direction'] = 'degrees'\n    stationobs_units['latitude'] = 'degrees N'\n    stationobs_units['longitude'] = 'degrees W'\n    stationobs_units['surface_wind'] = windunits\n    stationobs_units['location_name'] = 'None'\n    stationobs_units['temp_sounding'] = 'Kelvin'\n    stationobs_units['press_sounding'] = 'hPa'\n    assert_print(stationobs_units.dtype)\n    statdat.units = stationobs_units\n    f.close()\n    f = Dataset('compound_example.nc')\n    assert_print(f)\n    statdat = f.variables['station_obs']\n    assert_print(statdat)\n    assert_print('data in a variable of compound type:')\n    assert_print(statdat[:])\n    f.close()\n    f = Dataset('tst_vlen.nc', 'w')\n    vlen_t = f.createVLType(np.int32, 'phony_vlen')\n    x = f.createDimension('x', 3)\n    y = f.createDimension('y', 4)\n    vlvar = f.createVariable('phony_vlen_var', vlen_t, ('y', 'x'))\n    data = np.empty(len(y) * len(x), object)\n    for n in range(len(y) * len(x)):\n        data[n] = np.arange(rng.integers(1, 10), dtype='int32') + 1\n    data = np.reshape(data, (len(y), len(x)))\n    vlvar[:] = data\n    assert_print(vlvar)\n    assert_print('vlen variable =\\n', vlvar[:])\n    assert_print(f)\n    assert_print(f.variables['phony_vlen_var'])\n    assert_print(f.vltypes['phony_vlen'])\n    f.createDimension('z', 10)\n    strvar = f.createVariable('strvar', str, 'z')\n    chars = list('1234567890aabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n    data = np.empty(10, object)\n    for n in range(10):\n        stringlen = rng.integers(2, 12)\n        data[n] = ''.join([rng.choice(chars) for i in range(stringlen)])\n    strvar[:] = data\n    assert_print('variable-length string variable:\\n', strvar[:])\n    assert_print(f)\n    assert_print(f.variables['strvar'])\n    f.close()\n    f = Dataset('clouds.nc', 'w')\n    enum_dict = {'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\n    cloud_type = f.createEnumType(np.uint8, 'cloud_t', enum_dict)\n    assert_print(cloud_type)\n    time = f.createDimension('time', None)\n    cloud_var = f.createVariable('primary_cloud', cloud_type, 'time', fill_value=enum_dict['Missing'])\n    cloud_var[:] = [enum_dict['Clear'], enum_dict['Stratus'], enum_dict['Cumulus'], enum_dict['Missing'], enum_dict['Cumulonimbus']]\n    f.close()\n    f = Dataset('clouds.nc')\n    cloud_var = f.variables['primary_cloud']\n    assert_print(cloud_var)\n    assert_print(cloud_var.datatype.enum_dict)\n    assert_print(cloud_var[:])\n    f.close()\n    from netCDF4 import stringtochar\n    nc = Dataset('stringtest.nc', 'w', format='NETCDF4_CLASSIC')\n    nc.createDimension('nchars', 3)\n    nc.createDimension('nstrings', None)\n    v = nc.createVariable('strings', 'S1', ('nstrings', 'nchars'))\n    datain = np.array(['foo', 'bar'], dtype='S3')\n    v[:] = stringtochar(datain)\n    assert_print(v[:])\n    v._Encoding = 'ascii'\n    v[:] = datain\n    assert_print(v[:])\n    nc.close()\n    nc = Dataset('compoundstring_example.nc', 'w')\n    dtype = np.dtype([('observation', 'f4'), ('station_name', 'S12')])\n    station_data_t = nc.createCompoundType(dtype, 'station_data')\n    nc.createDimension('station', None)\n    statdat = nc.createVariable('station_obs', station_data_t, ('station',))\n    data = np.empty(2, station_data_t.dtype_view)\n    data['observation'][:] = (123.0, 3.14)\n    data['station_name'][:] = ('Boulder', 'New York')\n    assert_print(statdat.dtype)\n    statdat[:] = data\n    assert_print(statdat[:])\n    assert_print(statdat[:].dtype)\n    statdat.set_auto_chartostring(False)\n    statdat[:] = data.view(station_data_t.dtype)\n    assert_print(statdat[:])\n    nc.close()\n    nc = Dataset('diskless_example.nc', 'w', diskless=True, persist=True)\n    nc.createDimension('x', None)\n    v = nc.createVariable('v', np.int32, 'x')\n    v[0:5] = np.arange(5)\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()\n    f = open('diskless_example.nc', 'rb')\n    nc_bytes = f.read()\n    f.close()\n    nc = Dataset('inmemory.nc', memory=nc_bytes)\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()\n    nc = Dataset('inmemory.nc', mode='w', memory=1028)\n    nc.createDimension('x', None)\n    v = nc.createVariable('v', np.int32, 'x')\n    v[0:5] = np.arange(5)\n    nc_buf = nc.close()\n    assert_print(type(nc_buf))\n    f = open('inmemory.nc', 'wb')\n    f.write(nc_buf)\n    f.close()\n    nc = Dataset('inmemory.nc')\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()",
            "@pytest.mark.driver_timeout(60)\n@run_in_pyodide(packages=['netCDF4', 'numpy'])\ndef test_netCDF4_tutorial(selenium):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    import re\n    from datetime import datetime\n    DATETIME_PATTERN = re.compile('[a-zA-Z]{3}\\\\s+[a-zA-Z]{3}\\\\s+[0-9]{1,2}\\\\s+[0-9]{2}:[0-9]{2}:[0-9]{2}\\\\s+[0-9]{4}')\n    DATETIME_FORMAT = '%a %b %d %H:%M:%S %Y'\n    stdouts = ['NETCDF4', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: forecasts, analyses\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: model1, model2\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /analyses:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model1:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model2:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"{'level': <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0, 'time': <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0, 'lat': <class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73, 'lon': <class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144}\", '144', 'False', 'True', \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0\", \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\", \"<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73\", \"<class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144\", \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\", \"<class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\n    least_significant_digit: 3\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model1:\\n    dimensions(sizes): \\n    variables(dimensions): float32 temp(time, level, lat, lon)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\npath = /forecasts/model1\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used\", 'Global attr description = bogus example script', 'Global attr history = Created %a %b %d %H:%M:%S %Y', 'Global attr source = netCDF4 python module tutorial', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    description: bogus example script\\n    history: Created %a %b %d %H:%M:%S %Y\\n    source: netCDF4 python module tutorial\\n    dimensions(sizes): level(0), time(0), lat(73), lon(144)\\n    variables(dimensions): float64 time(time), int32 level(level), float32 lat(lat), float32 lon(lon), float32 temp(time, level, lat, lon)\\n    groups: forecasts, analyses\", \"{'description': 'bogus example script', 'history': 'Created %a %b %d %H:%M:%S %Y', 'source': 'netCDF4 python module tutorial'}\", \"{'time': <class 'netCDF4._netCDF4.Variable'>\\nfloat64 time(time)\\n    units: hours since 0001-01-01 00:00:00.0\\n    calendar: gregorian\\nunlimited dimensions: time\\ncurrent shape = (0,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'level': <class 'netCDF4._netCDF4.Variable'>\\nint32 level(level)\\n    units: hPa\\nunlimited dimensions: level\\ncurrent shape = (0,)\\nfilling on, default _FillValue of -2147483647 used, 'lat': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 lat(lat)\\n    units: degrees north\\nunlimited dimensions: \\ncurrent shape = (73,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'lon': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 lon(lon)\\n    units: degrees east\\nunlimited dimensions: \\ncurrent shape = (144,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'temp': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\n    least_significant_digit: 3\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used}\", 'latitudes =\\n [-90.  -87.5 -85.  -82.5 -80.  -77.5 -75.  -72.5 -70.  -67.5 -65.  -62.5\\n -60.  -57.5 -55.  -52.5 -50.  -47.5 -45.  -42.5 -40.  -37.5 -35.  -32.5\\n -30.  -27.5 -25.  -22.5 -20.  -17.5 -15.  -12.5 -10.   -7.5  -5.   -2.5\\n   0.    2.5   5.    7.5  10.   12.5  15.   17.5  20.   22.5  25.   27.5\\n  30.   32.5  35.   37.5  40.   42.5  45.   47.5  50.   52.5  55.   57.5\\n  60.   62.5  65.   67.5  70.   72.5  75.   77.5  80.   82.5  85.   87.5\\n  90. ]', 'longitudes =\\n [-180.  -177.5 -175.  -172.5 -170.  -167.5 -165.  -162.5 -160.  -157.5\\n -155.  -152.5 -150.  -147.5 -145.  -142.5 -140.  -137.5 -135.  -132.5\\n -130.  -127.5 -125.  -122.5 -120.  -117.5 -115.  -112.5 -110.  -107.5\\n -105.  -102.5 -100.   -97.5  -95.   -92.5  -90.   -87.5  -85.   -82.5\\n  -80.   -77.5  -75.   -72.5  -70.   -67.5  -65.   -62.5  -60.   -57.5\\n  -55.   -52.5  -50.   -47.5  -45.   -42.5  -40.   -37.5  -35.   -32.5\\n  -30.   -27.5  -25.   -22.5  -20.   -17.5  -15.   -12.5  -10.    -7.5\\n   -5.    -2.5    0.     2.5    5.     7.5   10.    12.5   15.    17.5\\n   20.    22.5   25.    27.5   30.    32.5   35.    37.5   40.    42.5\\n   45.    47.5   50.    52.5   55.    57.5   60.    62.5   65.    67.5\\n   70.    72.5   75.    77.5   80.    82.5   85.    87.5   90.    92.5\\n   95.    97.5  100.   102.5  105.   107.5  110.   112.5  115.   117.5\\n  120.   122.5  125.   127.5  130.   132.5  135.   137.5  140.   142.5\\n  145.   147.5  150.   152.5  155.   157.5  160.   162.5  165.   167.5\\n  170.   172.5  175.   177.5]', 'temp shape before adding data =  (0, 0, 73, 144)', 'temp shape after adding data =  (5, 10, 73, 144)', 'levels shape after adding pressure data =  (10,)', 'shape of fancy temp slice =  (3, 3, 36, 71)', '(4, 4)', 'time values (in units hours since 0001-01-01 00:00:00.0):\\n[17533104. 17533116. 17533128. 17533140. 17533152.]', 'dates corresponding to time values:\\n[cftime.DatetimeGregorian(2001, 3, 1, 0, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 1, 12, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 2, 0, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 2, 12, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 3, 0, 0, 0, 0, has_year_zero=False)]', '[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\\n 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\\n 96 97 98 99]', 'complex128', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x_dim(3)\\n    variables(dimensions): {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True} cmplx_var(x_dim)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\ncompound cmplx_var(x_dim)\\ncompound data type: {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}\\nunlimited dimensions: x_dim\\ncurrent shape = (3,)\", \"{'complex128': <class 'netCDF4._netCDF4.CompoundType'>: name = 'complex128', numpy dtype = {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}}\", \"<class 'netCDF4._netCDF4.CompoundType'>: name = 'complex128', numpy dtype = {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}\", '(3,)', 'complex128 [ 0.54030231+0.84147098j -0.84147098+0.54030231j -0.54030231-0.84147098j]', 'complex128 [ 0.54030231+0.84147098j -0.84147098+0.54030231j -0.54030231-0.84147098j]', \"{'wind_data': <class 'netCDF4._netCDF4.CompoundType'>: name = 'wind_data', numpy dtype = {'names': ['speed', 'direction'], 'formats': ['<f4', '<i4'], 'offsets': [0, 4], 'itemsize': 8, 'aligned': True}, 'station_data': <class 'netCDF4._netCDF4.CompoundType'>: name = 'station_data', numpy dtype = {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True}, 'wind_data_units': <class 'netCDF4._netCDF4.CompoundType'>: name = 'wind_data_units', numpy dtype = {'names': ['speed', 'direction'], 'formats': [('S1', (12,)), ('S1', (12,))], 'offsets': [0, 12], 'itemsize': 24, 'aligned': True}, 'station_data_units': <class 'netCDF4._netCDF4.CompoundType'>: name = 'station_data_units', numpy dtype = {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'location_name', 'press_sounding'], 'formats': [('S1', (12,)), ('S1', (12,)), [('speed', 'S1', (12,)), ('direction', 'S1', (12,))], ('S1', (12,)), ('S1', (12,)), ('S1', (12,))], 'offsets': [0, 12, 24, 48, 60, 72], 'itemsize': 84, 'aligned': True}}\", \"[('latitude', 'S12'), ('longitude', 'S12'), ('surface_wind', [('speed', 'S12'), ('direction', 'S12')]), ('temp_sounding', 'S12'), ('location_name', 'S12'), ('press_sounding', 'S12')]\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): station(2)\\n    variables(dimensions): {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True} station_obs(station)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\ncompound station_obs(station)\\n    units: (b'degrees N', b'degrees W', (b'm/s', b'degrees'), b'Kelvin', b'None', b'hPa')\\ncompound data type: {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True}\\nunlimited dimensions: station\\ncurrent shape = (2,)\", 'data in a variable of compound type:', \"[(40.  , -105.  , ( 12.5, 270), [280.3, 272. , 270. , 269. , 266. , 258. , 254.1, 250. , 245.5, 240. ], [800, 750, 700, 650, 600, 550, 500, 450, 400, 350], b'Boulder, CO')\\n (40.78,  -73.99, (-12.5,  90), [290.2, 282.5, 279. , 277.9, 276. , 266. , 264.1, 260. , 255.5, 243. ], [900, 850, 800, 750, 700, 650, 600, 550, 500, 450], b'New York, NY')]\", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen phony_vlen_var(y, x)\\nvlen data type: int32\\nunlimited dimensions: \\ncurrent shape = (4, 3)\", 'vlen variable =\\n [[array([1, 2, 3, 4, 5, 6, 7]) array([1, 2, 3, 4, 5]) array([1])]\\n [array([1, 2, 3]) array([1, 2]) array([1])]\\n [array([1]) array([1, 2, 3, 4, 5, 6, 7]) array([1])]\\n [array([1, 2, 3, 4, 5, 6]) array([1, 2, 3, 4, 5]) array([1])]]', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(3), y(4)\\n    variables(dimensions): int32 phony_vlen_var(y, x)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen phony_vlen_var(y, x)\\nvlen data type: int32\\nunlimited dimensions: \\ncurrent shape = (4, 3)\", \"<class 'netCDF4._netCDF4.VLType'>: name = 'phony_vlen', numpy dtype = int32\", \"variable-length string variable:\\n ['ZOGMRmJo' 'BxdAK1fku' 'lgOzaanCtv' 'D5ALrXJCDU' 'W9r' 'Y7edBPrthEr'\\n 'OVeqx' 'aH1ZXc5A' 'LC1ajPJ' 'du']\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(3), y(4), z(10)\\n    variables(dimensions): int32 phony_vlen_var(y, x), <class 'str'> strvar(z)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen strvar(z)\\nvlen data type: <class 'str'>\\nunlimited dimensions: \\ncurrent shape = (10,)\", \"<class 'netCDF4._netCDF4.EnumType'>: name = 'cloud_t', numpy dtype = uint8, fields/values ={'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\", \"<class 'netCDF4._netCDF4.Variable'>\\nenum primary_cloud(time)\\n    _FillValue: 255\\nenum data type: uint8\\nunlimited dimensions: time\\ncurrent shape = (5,)\", \"{'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\", '[0 2 4 -- 1]', \"[[b'f' b'o' b'o']\\n [b'b' b'a' b'r']]\", \"['foo' 'bar']\", \"{'names': ['observation', 'station_name'], 'formats': ['<f4', ('S1', (12,))], 'offsets': [0, 4], 'itemsize': 16, 'aligned': True}\", \"[(123.  , b'Boulder') (  3.14, b'New York')]\", \"{'names': ['observation', 'station_name'], 'formats': ['<f4', 'S12'], 'offsets': [0, 4], 'itemsize': 16, 'aligned': True}\", \"[(123.  , [b'B', b'o', b'u', b'l', b'd', b'e', b'r', b'', b'', b'', b'', b''])\\n (  3.14, [b'N', b'e', b'w', b' ', b'Y', b'o', b'r', b'k', b'', b'', b'', b''])]\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]', \"<class 'memoryview'>\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]']\n\n    def replace_netcdf_datetime(match):\n        try:\n            datetime.strptime(match.group(0), DATETIME_FORMAT)\n        except Exception:\n            return match.group(0)\n        else:\n            return DATETIME_FORMAT\n\n    def assert_print(*args):\n        output = DATETIME_PATTERN.sub(replace_netcdf_datetime, ' '.join((str(a) for a in args)))\n        expected = stdouts.pop(0)\n        if output != expected:\n            assert output == expected, f'{repr(output)} != {repr(expected)}'\n    '\\n    Test adopted from (but with reproducible randomness):\\n    https://github.com/Unidata/netcdf4-python/blob/master/examples/tutorial.py\\n    Released under the MIT License\\n    '\n    from numpy.random import PCG64, Generator\n    rng = Generator(PCG64(seed=42))\n    from netCDF4 import Dataset\n    rootgrp = Dataset('test.nc', 'w', format='NETCDF4')\n    assert_print(rootgrp.file_format)\n    rootgrp.close()\n    rootgrp = Dataset('test.nc', 'a')\n    rootgrp.createGroup('forecasts')\n    rootgrp.createGroup('analyses')\n    rootgrp.createGroup('/forecasts/model1')\n    rootgrp.createGroup('/forecasts/model2')\n\n    def walktree(top):\n        yield top.groups.values()\n        for value in top.groups.values():\n            yield from walktree(value)\n    assert_print(rootgrp)\n    for children in walktree(rootgrp):\n        for child in children:\n            assert_print(child)\n    rootgrp.createDimension('level', None)\n    time = rootgrp.createDimension('time', None)\n    rootgrp.createDimension('lat', 73)\n    lon = rootgrp.createDimension('lon', 144)\n    assert_print(rootgrp.dimensions)\n    assert_print(len(lon))\n    assert_print(lon.isunlimited())\n    assert_print(time.isunlimited())\n    for dimobj in rootgrp.dimensions.values():\n        assert_print(dimobj)\n    assert_print(time)\n    times = rootgrp.createVariable('time', 'f8', ('time',))\n    levels = rootgrp.createVariable('level', 'i4', ('level',))\n    latitudes = rootgrp.createVariable('lat', 'f4', ('lat',))\n    longitudes = rootgrp.createVariable('lon', 'f4', ('lon',))\n    temp = rootgrp.createVariable('temp', 'f4', ('time', 'level', 'lat', 'lon'), least_significant_digit=3)\n    assert_print(temp)\n    temp = rootgrp.createVariable('/forecasts/model1/temp', 'f4', ('time', 'level', 'lat', 'lon'))\n    assert_print(rootgrp['/forecasts/model1'])\n    assert_print(rootgrp['/forecasts/model1/temp'])\n    import time\n    rootgrp.description = 'bogus example script'\n    rootgrp.history = 'Created ' + time.ctime(time.time())\n    rootgrp.source = 'netCDF4 python module tutorial'\n    latitudes.units = 'degrees north'\n    longitudes.units = 'degrees east'\n    levels.units = 'hPa'\n    temp.units = 'K'\n    times.units = 'hours since 0001-01-01 00:00:00.0'\n    times.calendar = 'gregorian'\n    for name in rootgrp.ncattrs():\n        assert_print('Global attr', name, '=', getattr(rootgrp, name))\n    assert_print(rootgrp)\n    assert_print(rootgrp.__dict__)\n    assert_print(rootgrp.variables)\n    import numpy as np\n    lats = np.arange(-90, 91, 2.5)\n    lons = np.arange(-180, 180, 2.5)\n    latitudes[:] = lats\n    longitudes[:] = lons\n    assert_print('latitudes =\\n', latitudes[:])\n    assert_print('longitudes =\\n', longitudes[:])\n    nlats = len(rootgrp.dimensions['lat'])\n    nlons = len(rootgrp.dimensions['lon'])\n    assert_print('temp shape before adding data = ', temp.shape)\n    temp[0:5, 0:10, :, :] = rng.uniform(size=(5, 10, nlats, nlons))\n    assert_print('temp shape after adding data = ', temp.shape)\n    assert_print('levels shape after adding pressure data = ', levels.shape)\n    levels[:] = [1000.0, 850.0, 700.0, 500.0, 300.0, 250.0, 200.0, 150.0, 100.0, 50.0]\n    tempdat = temp[::2, [1, 3, 6], lats > 0, lons > 0]\n    assert_print('shape of fancy temp slice = ', tempdat.shape)\n    assert_print(temp[0, 0, [0, 1, 2, 3], [0, 1, 2, 3]].shape)\n    from datetime import timedelta\n    from netCDF4 import date2num, num2date\n    dates = [datetime(2001, 3, 1) + n * timedelta(hours=12) for n in range(temp.shape[0])]\n    times[:] = date2num(dates, units=times.units, calendar=times.calendar)\n    assert_print(f'time values (in units {times.units}):\\n{times[:]}')\n    dates = num2date(times[:], units=times.units, calendar=times.calendar)\n    assert_print(f'dates corresponding to time values:\\n{dates}')\n    rootgrp.close()\n    for nfile in range(10):\n        f = Dataset('mftest' + repr(nfile) + '.nc', 'w', format='NETCDF4_CLASSIC')\n        f.createDimension('x', None)\n        x = f.createVariable('x', 'i', ('x',))\n        x[0:10] = np.arange(nfile * 10, 10 * (nfile + 1))\n        f.close()\n    from netCDF4 import MFDataset\n    f = MFDataset('mftest*nc')\n    assert_print(f.variables['x'][:])\n    f = Dataset('complex.nc', 'w')\n    size = 3\n    datac = np.exp(1j * (1.0 + np.linspace(0, np.pi, size)))\n    assert_print(datac.dtype)\n    complex128 = np.dtype([('real', np.float64), ('imag', np.float64)])\n    complex128_t = f.createCompoundType(complex128, 'complex128')\n    f.createDimension('x_dim', None)\n    v = f.createVariable('cmplx_var', complex128_t, 'x_dim')\n    data = np.empty(size, complex128)\n    data['real'] = datac.real\n    data['imag'] = datac.imag\n    v[:] = data\n    f.close()\n    f = Dataset('complex.nc')\n    assert_print(f)\n    assert_print(f.variables['cmplx_var'])\n    assert_print(f.cmptypes)\n    assert_print(f.cmptypes['complex128'])\n    v = f.variables['cmplx_var']\n    assert_print(v.shape)\n    datain = v[:]\n    datac2 = np.empty(datain.shape, np.complex128)\n    datac2.real = datain['real']\n    datac2.imag = datain['imag']\n    assert_print(datac.dtype, datac)\n    assert_print(datac2.dtype, datac2)\n    f = Dataset('compound_example.nc', 'w')\n    f.createDimension('station', None)\n    winddtype = np.dtype([('speed', 'f4'), ('direction', 'i4')])\n    statdtype = np.dtype([('latitude', 'f4'), ('longitude', 'f4'), ('surface_wind', winddtype), ('temp_sounding', 'f4', 10), ('press_sounding', 'i4', 10), ('location_name', 'S12')])\n    f.createCompoundType(winddtype, 'wind_data')\n    station_data_t = f.createCompoundType(statdtype, 'station_data')\n    winddtype_units = np.dtype([('speed', 'S12'), ('direction', 'S12')])\n    statdtype_units = np.dtype([('latitude', 'S12'), ('longitude', 'S12'), ('surface_wind', winddtype_units), ('temp_sounding', 'S12'), ('location_name', 'S12'), ('press_sounding', 'S12')])\n    f.createCompoundType(winddtype_units, 'wind_data_units')\n    f.createCompoundType(statdtype_units, 'station_data_units')\n    statdat = f.createVariable('station_obs', station_data_t, ('station',))\n    data = np.empty(1, statdtype)\n    data['latitude'] = 40.0\n    data['longitude'] = -105.0\n    data['surface_wind']['speed'] = 12.5\n    data['surface_wind']['direction'] = 270\n    data['temp_sounding'] = (280.3, 272.0, 270.0, 269.0, 266.0, 258.0, 254.1, 250.0, 245.5, 240.0)\n    data['press_sounding'] = range(800, 300, -50)\n    data['location_name'] = 'Boulder, CO'\n    statdat[0] = data\n    statdat[1] = np.array((40.78, -73.99, (-12.5, 90), (290.2, 282.5, 279.0, 277.9, 276.0, 266.0, 264.1, 260.0, 255.5, 243.0), range(900, 400, -50), 'New York, NY'), data.dtype)\n    assert_print(f.cmptypes)\n    windunits = np.empty(1, winddtype_units)\n    stationobs_units = np.empty(1, statdtype_units)\n    windunits['speed'] = 'm/s'\n    windunits['direction'] = 'degrees'\n    stationobs_units['latitude'] = 'degrees N'\n    stationobs_units['longitude'] = 'degrees W'\n    stationobs_units['surface_wind'] = windunits\n    stationobs_units['location_name'] = 'None'\n    stationobs_units['temp_sounding'] = 'Kelvin'\n    stationobs_units['press_sounding'] = 'hPa'\n    assert_print(stationobs_units.dtype)\n    statdat.units = stationobs_units\n    f.close()\n    f = Dataset('compound_example.nc')\n    assert_print(f)\n    statdat = f.variables['station_obs']\n    assert_print(statdat)\n    assert_print('data in a variable of compound type:')\n    assert_print(statdat[:])\n    f.close()\n    f = Dataset('tst_vlen.nc', 'w')\n    vlen_t = f.createVLType(np.int32, 'phony_vlen')\n    x = f.createDimension('x', 3)\n    y = f.createDimension('y', 4)\n    vlvar = f.createVariable('phony_vlen_var', vlen_t, ('y', 'x'))\n    data = np.empty(len(y) * len(x), object)\n    for n in range(len(y) * len(x)):\n        data[n] = np.arange(rng.integers(1, 10), dtype='int32') + 1\n    data = np.reshape(data, (len(y), len(x)))\n    vlvar[:] = data\n    assert_print(vlvar)\n    assert_print('vlen variable =\\n', vlvar[:])\n    assert_print(f)\n    assert_print(f.variables['phony_vlen_var'])\n    assert_print(f.vltypes['phony_vlen'])\n    f.createDimension('z', 10)\n    strvar = f.createVariable('strvar', str, 'z')\n    chars = list('1234567890aabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n    data = np.empty(10, object)\n    for n in range(10):\n        stringlen = rng.integers(2, 12)\n        data[n] = ''.join([rng.choice(chars) for i in range(stringlen)])\n    strvar[:] = data\n    assert_print('variable-length string variable:\\n', strvar[:])\n    assert_print(f)\n    assert_print(f.variables['strvar'])\n    f.close()\n    f = Dataset('clouds.nc', 'w')\n    enum_dict = {'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\n    cloud_type = f.createEnumType(np.uint8, 'cloud_t', enum_dict)\n    assert_print(cloud_type)\n    time = f.createDimension('time', None)\n    cloud_var = f.createVariable('primary_cloud', cloud_type, 'time', fill_value=enum_dict['Missing'])\n    cloud_var[:] = [enum_dict['Clear'], enum_dict['Stratus'], enum_dict['Cumulus'], enum_dict['Missing'], enum_dict['Cumulonimbus']]\n    f.close()\n    f = Dataset('clouds.nc')\n    cloud_var = f.variables['primary_cloud']\n    assert_print(cloud_var)\n    assert_print(cloud_var.datatype.enum_dict)\n    assert_print(cloud_var[:])\n    f.close()\n    from netCDF4 import stringtochar\n    nc = Dataset('stringtest.nc', 'w', format='NETCDF4_CLASSIC')\n    nc.createDimension('nchars', 3)\n    nc.createDimension('nstrings', None)\n    v = nc.createVariable('strings', 'S1', ('nstrings', 'nchars'))\n    datain = np.array(['foo', 'bar'], dtype='S3')\n    v[:] = stringtochar(datain)\n    assert_print(v[:])\n    v._Encoding = 'ascii'\n    v[:] = datain\n    assert_print(v[:])\n    nc.close()\n    nc = Dataset('compoundstring_example.nc', 'w')\n    dtype = np.dtype([('observation', 'f4'), ('station_name', 'S12')])\n    station_data_t = nc.createCompoundType(dtype, 'station_data')\n    nc.createDimension('station', None)\n    statdat = nc.createVariable('station_obs', station_data_t, ('station',))\n    data = np.empty(2, station_data_t.dtype_view)\n    data['observation'][:] = (123.0, 3.14)\n    data['station_name'][:] = ('Boulder', 'New York')\n    assert_print(statdat.dtype)\n    statdat[:] = data\n    assert_print(statdat[:])\n    assert_print(statdat[:].dtype)\n    statdat.set_auto_chartostring(False)\n    statdat[:] = data.view(station_data_t.dtype)\n    assert_print(statdat[:])\n    nc.close()\n    nc = Dataset('diskless_example.nc', 'w', diskless=True, persist=True)\n    nc.createDimension('x', None)\n    v = nc.createVariable('v', np.int32, 'x')\n    v[0:5] = np.arange(5)\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()\n    f = open('diskless_example.nc', 'rb')\n    nc_bytes = f.read()\n    f.close()\n    nc = Dataset('inmemory.nc', memory=nc_bytes)\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()\n    nc = Dataset('inmemory.nc', mode='w', memory=1028)\n    nc.createDimension('x', None)\n    v = nc.createVariable('v', np.int32, 'x')\n    v[0:5] = np.arange(5)\n    nc_buf = nc.close()\n    assert_print(type(nc_buf))\n    f = open('inmemory.nc', 'wb')\n    f.write(nc_buf)\n    f.close()\n    nc = Dataset('inmemory.nc')\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()",
            "@pytest.mark.driver_timeout(60)\n@run_in_pyodide(packages=['netCDF4', 'numpy'])\ndef test_netCDF4_tutorial(selenium):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    import re\n    from datetime import datetime\n    DATETIME_PATTERN = re.compile('[a-zA-Z]{3}\\\\s+[a-zA-Z]{3}\\\\s+[0-9]{1,2}\\\\s+[0-9]{2}:[0-9]{2}:[0-9]{2}\\\\s+[0-9]{4}')\n    DATETIME_FORMAT = '%a %b %d %H:%M:%S %Y'\n    stdouts = ['NETCDF4', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: forecasts, analyses\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: model1, model2\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /analyses:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model1:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model2:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"{'level': <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0, 'time': <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0, 'lat': <class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73, 'lon': <class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144}\", '144', 'False', 'True', \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0\", \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\", \"<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73\", \"<class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144\", \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\", \"<class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\n    least_significant_digit: 3\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model1:\\n    dimensions(sizes): \\n    variables(dimensions): float32 temp(time, level, lat, lon)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\npath = /forecasts/model1\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used\", 'Global attr description = bogus example script', 'Global attr history = Created %a %b %d %H:%M:%S %Y', 'Global attr source = netCDF4 python module tutorial', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    description: bogus example script\\n    history: Created %a %b %d %H:%M:%S %Y\\n    source: netCDF4 python module tutorial\\n    dimensions(sizes): level(0), time(0), lat(73), lon(144)\\n    variables(dimensions): float64 time(time), int32 level(level), float32 lat(lat), float32 lon(lon), float32 temp(time, level, lat, lon)\\n    groups: forecasts, analyses\", \"{'description': 'bogus example script', 'history': 'Created %a %b %d %H:%M:%S %Y', 'source': 'netCDF4 python module tutorial'}\", \"{'time': <class 'netCDF4._netCDF4.Variable'>\\nfloat64 time(time)\\n    units: hours since 0001-01-01 00:00:00.0\\n    calendar: gregorian\\nunlimited dimensions: time\\ncurrent shape = (0,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'level': <class 'netCDF4._netCDF4.Variable'>\\nint32 level(level)\\n    units: hPa\\nunlimited dimensions: level\\ncurrent shape = (0,)\\nfilling on, default _FillValue of -2147483647 used, 'lat': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 lat(lat)\\n    units: degrees north\\nunlimited dimensions: \\ncurrent shape = (73,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'lon': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 lon(lon)\\n    units: degrees east\\nunlimited dimensions: \\ncurrent shape = (144,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'temp': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\n    least_significant_digit: 3\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used}\", 'latitudes =\\n [-90.  -87.5 -85.  -82.5 -80.  -77.5 -75.  -72.5 -70.  -67.5 -65.  -62.5\\n -60.  -57.5 -55.  -52.5 -50.  -47.5 -45.  -42.5 -40.  -37.5 -35.  -32.5\\n -30.  -27.5 -25.  -22.5 -20.  -17.5 -15.  -12.5 -10.   -7.5  -5.   -2.5\\n   0.    2.5   5.    7.5  10.   12.5  15.   17.5  20.   22.5  25.   27.5\\n  30.   32.5  35.   37.5  40.   42.5  45.   47.5  50.   52.5  55.   57.5\\n  60.   62.5  65.   67.5  70.   72.5  75.   77.5  80.   82.5  85.   87.5\\n  90. ]', 'longitudes =\\n [-180.  -177.5 -175.  -172.5 -170.  -167.5 -165.  -162.5 -160.  -157.5\\n -155.  -152.5 -150.  -147.5 -145.  -142.5 -140.  -137.5 -135.  -132.5\\n -130.  -127.5 -125.  -122.5 -120.  -117.5 -115.  -112.5 -110.  -107.5\\n -105.  -102.5 -100.   -97.5  -95.   -92.5  -90.   -87.5  -85.   -82.5\\n  -80.   -77.5  -75.   -72.5  -70.   -67.5  -65.   -62.5  -60.   -57.5\\n  -55.   -52.5  -50.   -47.5  -45.   -42.5  -40.   -37.5  -35.   -32.5\\n  -30.   -27.5  -25.   -22.5  -20.   -17.5  -15.   -12.5  -10.    -7.5\\n   -5.    -2.5    0.     2.5    5.     7.5   10.    12.5   15.    17.5\\n   20.    22.5   25.    27.5   30.    32.5   35.    37.5   40.    42.5\\n   45.    47.5   50.    52.5   55.    57.5   60.    62.5   65.    67.5\\n   70.    72.5   75.    77.5   80.    82.5   85.    87.5   90.    92.5\\n   95.    97.5  100.   102.5  105.   107.5  110.   112.5  115.   117.5\\n  120.   122.5  125.   127.5  130.   132.5  135.   137.5  140.   142.5\\n  145.   147.5  150.   152.5  155.   157.5  160.   162.5  165.   167.5\\n  170.   172.5  175.   177.5]', 'temp shape before adding data =  (0, 0, 73, 144)', 'temp shape after adding data =  (5, 10, 73, 144)', 'levels shape after adding pressure data =  (10,)', 'shape of fancy temp slice =  (3, 3, 36, 71)', '(4, 4)', 'time values (in units hours since 0001-01-01 00:00:00.0):\\n[17533104. 17533116. 17533128. 17533140. 17533152.]', 'dates corresponding to time values:\\n[cftime.DatetimeGregorian(2001, 3, 1, 0, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 1, 12, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 2, 0, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 2, 12, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 3, 0, 0, 0, 0, has_year_zero=False)]', '[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\\n 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\\n 96 97 98 99]', 'complex128', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x_dim(3)\\n    variables(dimensions): {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True} cmplx_var(x_dim)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\ncompound cmplx_var(x_dim)\\ncompound data type: {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}\\nunlimited dimensions: x_dim\\ncurrent shape = (3,)\", \"{'complex128': <class 'netCDF4._netCDF4.CompoundType'>: name = 'complex128', numpy dtype = {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}}\", \"<class 'netCDF4._netCDF4.CompoundType'>: name = 'complex128', numpy dtype = {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}\", '(3,)', 'complex128 [ 0.54030231+0.84147098j -0.84147098+0.54030231j -0.54030231-0.84147098j]', 'complex128 [ 0.54030231+0.84147098j -0.84147098+0.54030231j -0.54030231-0.84147098j]', \"{'wind_data': <class 'netCDF4._netCDF4.CompoundType'>: name = 'wind_data', numpy dtype = {'names': ['speed', 'direction'], 'formats': ['<f4', '<i4'], 'offsets': [0, 4], 'itemsize': 8, 'aligned': True}, 'station_data': <class 'netCDF4._netCDF4.CompoundType'>: name = 'station_data', numpy dtype = {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True}, 'wind_data_units': <class 'netCDF4._netCDF4.CompoundType'>: name = 'wind_data_units', numpy dtype = {'names': ['speed', 'direction'], 'formats': [('S1', (12,)), ('S1', (12,))], 'offsets': [0, 12], 'itemsize': 24, 'aligned': True}, 'station_data_units': <class 'netCDF4._netCDF4.CompoundType'>: name = 'station_data_units', numpy dtype = {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'location_name', 'press_sounding'], 'formats': [('S1', (12,)), ('S1', (12,)), [('speed', 'S1', (12,)), ('direction', 'S1', (12,))], ('S1', (12,)), ('S1', (12,)), ('S1', (12,))], 'offsets': [0, 12, 24, 48, 60, 72], 'itemsize': 84, 'aligned': True}}\", \"[('latitude', 'S12'), ('longitude', 'S12'), ('surface_wind', [('speed', 'S12'), ('direction', 'S12')]), ('temp_sounding', 'S12'), ('location_name', 'S12'), ('press_sounding', 'S12')]\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): station(2)\\n    variables(dimensions): {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True} station_obs(station)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\ncompound station_obs(station)\\n    units: (b'degrees N', b'degrees W', (b'm/s', b'degrees'), b'Kelvin', b'None', b'hPa')\\ncompound data type: {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True}\\nunlimited dimensions: station\\ncurrent shape = (2,)\", 'data in a variable of compound type:', \"[(40.  , -105.  , ( 12.5, 270), [280.3, 272. , 270. , 269. , 266. , 258. , 254.1, 250. , 245.5, 240. ], [800, 750, 700, 650, 600, 550, 500, 450, 400, 350], b'Boulder, CO')\\n (40.78,  -73.99, (-12.5,  90), [290.2, 282.5, 279. , 277.9, 276. , 266. , 264.1, 260. , 255.5, 243. ], [900, 850, 800, 750, 700, 650, 600, 550, 500, 450], b'New York, NY')]\", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen phony_vlen_var(y, x)\\nvlen data type: int32\\nunlimited dimensions: \\ncurrent shape = (4, 3)\", 'vlen variable =\\n [[array([1, 2, 3, 4, 5, 6, 7]) array([1, 2, 3, 4, 5]) array([1])]\\n [array([1, 2, 3]) array([1, 2]) array([1])]\\n [array([1]) array([1, 2, 3, 4, 5, 6, 7]) array([1])]\\n [array([1, 2, 3, 4, 5, 6]) array([1, 2, 3, 4, 5]) array([1])]]', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(3), y(4)\\n    variables(dimensions): int32 phony_vlen_var(y, x)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen phony_vlen_var(y, x)\\nvlen data type: int32\\nunlimited dimensions: \\ncurrent shape = (4, 3)\", \"<class 'netCDF4._netCDF4.VLType'>: name = 'phony_vlen', numpy dtype = int32\", \"variable-length string variable:\\n ['ZOGMRmJo' 'BxdAK1fku' 'lgOzaanCtv' 'D5ALrXJCDU' 'W9r' 'Y7edBPrthEr'\\n 'OVeqx' 'aH1ZXc5A' 'LC1ajPJ' 'du']\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(3), y(4), z(10)\\n    variables(dimensions): int32 phony_vlen_var(y, x), <class 'str'> strvar(z)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen strvar(z)\\nvlen data type: <class 'str'>\\nunlimited dimensions: \\ncurrent shape = (10,)\", \"<class 'netCDF4._netCDF4.EnumType'>: name = 'cloud_t', numpy dtype = uint8, fields/values ={'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\", \"<class 'netCDF4._netCDF4.Variable'>\\nenum primary_cloud(time)\\n    _FillValue: 255\\nenum data type: uint8\\nunlimited dimensions: time\\ncurrent shape = (5,)\", \"{'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\", '[0 2 4 -- 1]', \"[[b'f' b'o' b'o']\\n [b'b' b'a' b'r']]\", \"['foo' 'bar']\", \"{'names': ['observation', 'station_name'], 'formats': ['<f4', ('S1', (12,))], 'offsets': [0, 4], 'itemsize': 16, 'aligned': True}\", \"[(123.  , b'Boulder') (  3.14, b'New York')]\", \"{'names': ['observation', 'station_name'], 'formats': ['<f4', 'S12'], 'offsets': [0, 4], 'itemsize': 16, 'aligned': True}\", \"[(123.  , [b'B', b'o', b'u', b'l', b'd', b'e', b'r', b'', b'', b'', b'', b''])\\n (  3.14, [b'N', b'e', b'w', b' ', b'Y', b'o', b'r', b'k', b'', b'', b'', b''])]\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]', \"<class 'memoryview'>\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]']\n\n    def replace_netcdf_datetime(match):\n        try:\n            datetime.strptime(match.group(0), DATETIME_FORMAT)\n        except Exception:\n            return match.group(0)\n        else:\n            return DATETIME_FORMAT\n\n    def assert_print(*args):\n        output = DATETIME_PATTERN.sub(replace_netcdf_datetime, ' '.join((str(a) for a in args)))\n        expected = stdouts.pop(0)\n        if output != expected:\n            assert output == expected, f'{repr(output)} != {repr(expected)}'\n    '\\n    Test adopted from (but with reproducible randomness):\\n    https://github.com/Unidata/netcdf4-python/blob/master/examples/tutorial.py\\n    Released under the MIT License\\n    '\n    from numpy.random import PCG64, Generator\n    rng = Generator(PCG64(seed=42))\n    from netCDF4 import Dataset\n    rootgrp = Dataset('test.nc', 'w', format='NETCDF4')\n    assert_print(rootgrp.file_format)\n    rootgrp.close()\n    rootgrp = Dataset('test.nc', 'a')\n    rootgrp.createGroup('forecasts')\n    rootgrp.createGroup('analyses')\n    rootgrp.createGroup('/forecasts/model1')\n    rootgrp.createGroup('/forecasts/model2')\n\n    def walktree(top):\n        yield top.groups.values()\n        for value in top.groups.values():\n            yield from walktree(value)\n    assert_print(rootgrp)\n    for children in walktree(rootgrp):\n        for child in children:\n            assert_print(child)\n    rootgrp.createDimension('level', None)\n    time = rootgrp.createDimension('time', None)\n    rootgrp.createDimension('lat', 73)\n    lon = rootgrp.createDimension('lon', 144)\n    assert_print(rootgrp.dimensions)\n    assert_print(len(lon))\n    assert_print(lon.isunlimited())\n    assert_print(time.isunlimited())\n    for dimobj in rootgrp.dimensions.values():\n        assert_print(dimobj)\n    assert_print(time)\n    times = rootgrp.createVariable('time', 'f8', ('time',))\n    levels = rootgrp.createVariable('level', 'i4', ('level',))\n    latitudes = rootgrp.createVariable('lat', 'f4', ('lat',))\n    longitudes = rootgrp.createVariable('lon', 'f4', ('lon',))\n    temp = rootgrp.createVariable('temp', 'f4', ('time', 'level', 'lat', 'lon'), least_significant_digit=3)\n    assert_print(temp)\n    temp = rootgrp.createVariable('/forecasts/model1/temp', 'f4', ('time', 'level', 'lat', 'lon'))\n    assert_print(rootgrp['/forecasts/model1'])\n    assert_print(rootgrp['/forecasts/model1/temp'])\n    import time\n    rootgrp.description = 'bogus example script'\n    rootgrp.history = 'Created ' + time.ctime(time.time())\n    rootgrp.source = 'netCDF4 python module tutorial'\n    latitudes.units = 'degrees north'\n    longitudes.units = 'degrees east'\n    levels.units = 'hPa'\n    temp.units = 'K'\n    times.units = 'hours since 0001-01-01 00:00:00.0'\n    times.calendar = 'gregorian'\n    for name in rootgrp.ncattrs():\n        assert_print('Global attr', name, '=', getattr(rootgrp, name))\n    assert_print(rootgrp)\n    assert_print(rootgrp.__dict__)\n    assert_print(rootgrp.variables)\n    import numpy as np\n    lats = np.arange(-90, 91, 2.5)\n    lons = np.arange(-180, 180, 2.5)\n    latitudes[:] = lats\n    longitudes[:] = lons\n    assert_print('latitudes =\\n', latitudes[:])\n    assert_print('longitudes =\\n', longitudes[:])\n    nlats = len(rootgrp.dimensions['lat'])\n    nlons = len(rootgrp.dimensions['lon'])\n    assert_print('temp shape before adding data = ', temp.shape)\n    temp[0:5, 0:10, :, :] = rng.uniform(size=(5, 10, nlats, nlons))\n    assert_print('temp shape after adding data = ', temp.shape)\n    assert_print('levels shape after adding pressure data = ', levels.shape)\n    levels[:] = [1000.0, 850.0, 700.0, 500.0, 300.0, 250.0, 200.0, 150.0, 100.0, 50.0]\n    tempdat = temp[::2, [1, 3, 6], lats > 0, lons > 0]\n    assert_print('shape of fancy temp slice = ', tempdat.shape)\n    assert_print(temp[0, 0, [0, 1, 2, 3], [0, 1, 2, 3]].shape)\n    from datetime import timedelta\n    from netCDF4 import date2num, num2date\n    dates = [datetime(2001, 3, 1) + n * timedelta(hours=12) for n in range(temp.shape[0])]\n    times[:] = date2num(dates, units=times.units, calendar=times.calendar)\n    assert_print(f'time values (in units {times.units}):\\n{times[:]}')\n    dates = num2date(times[:], units=times.units, calendar=times.calendar)\n    assert_print(f'dates corresponding to time values:\\n{dates}')\n    rootgrp.close()\n    for nfile in range(10):\n        f = Dataset('mftest' + repr(nfile) + '.nc', 'w', format='NETCDF4_CLASSIC')\n        f.createDimension('x', None)\n        x = f.createVariable('x', 'i', ('x',))\n        x[0:10] = np.arange(nfile * 10, 10 * (nfile + 1))\n        f.close()\n    from netCDF4 import MFDataset\n    f = MFDataset('mftest*nc')\n    assert_print(f.variables['x'][:])\n    f = Dataset('complex.nc', 'w')\n    size = 3\n    datac = np.exp(1j * (1.0 + np.linspace(0, np.pi, size)))\n    assert_print(datac.dtype)\n    complex128 = np.dtype([('real', np.float64), ('imag', np.float64)])\n    complex128_t = f.createCompoundType(complex128, 'complex128')\n    f.createDimension('x_dim', None)\n    v = f.createVariable('cmplx_var', complex128_t, 'x_dim')\n    data = np.empty(size, complex128)\n    data['real'] = datac.real\n    data['imag'] = datac.imag\n    v[:] = data\n    f.close()\n    f = Dataset('complex.nc')\n    assert_print(f)\n    assert_print(f.variables['cmplx_var'])\n    assert_print(f.cmptypes)\n    assert_print(f.cmptypes['complex128'])\n    v = f.variables['cmplx_var']\n    assert_print(v.shape)\n    datain = v[:]\n    datac2 = np.empty(datain.shape, np.complex128)\n    datac2.real = datain['real']\n    datac2.imag = datain['imag']\n    assert_print(datac.dtype, datac)\n    assert_print(datac2.dtype, datac2)\n    f = Dataset('compound_example.nc', 'w')\n    f.createDimension('station', None)\n    winddtype = np.dtype([('speed', 'f4'), ('direction', 'i4')])\n    statdtype = np.dtype([('latitude', 'f4'), ('longitude', 'f4'), ('surface_wind', winddtype), ('temp_sounding', 'f4', 10), ('press_sounding', 'i4', 10), ('location_name', 'S12')])\n    f.createCompoundType(winddtype, 'wind_data')\n    station_data_t = f.createCompoundType(statdtype, 'station_data')\n    winddtype_units = np.dtype([('speed', 'S12'), ('direction', 'S12')])\n    statdtype_units = np.dtype([('latitude', 'S12'), ('longitude', 'S12'), ('surface_wind', winddtype_units), ('temp_sounding', 'S12'), ('location_name', 'S12'), ('press_sounding', 'S12')])\n    f.createCompoundType(winddtype_units, 'wind_data_units')\n    f.createCompoundType(statdtype_units, 'station_data_units')\n    statdat = f.createVariable('station_obs', station_data_t, ('station',))\n    data = np.empty(1, statdtype)\n    data['latitude'] = 40.0\n    data['longitude'] = -105.0\n    data['surface_wind']['speed'] = 12.5\n    data['surface_wind']['direction'] = 270\n    data['temp_sounding'] = (280.3, 272.0, 270.0, 269.0, 266.0, 258.0, 254.1, 250.0, 245.5, 240.0)\n    data['press_sounding'] = range(800, 300, -50)\n    data['location_name'] = 'Boulder, CO'\n    statdat[0] = data\n    statdat[1] = np.array((40.78, -73.99, (-12.5, 90), (290.2, 282.5, 279.0, 277.9, 276.0, 266.0, 264.1, 260.0, 255.5, 243.0), range(900, 400, -50), 'New York, NY'), data.dtype)\n    assert_print(f.cmptypes)\n    windunits = np.empty(1, winddtype_units)\n    stationobs_units = np.empty(1, statdtype_units)\n    windunits['speed'] = 'm/s'\n    windunits['direction'] = 'degrees'\n    stationobs_units['latitude'] = 'degrees N'\n    stationobs_units['longitude'] = 'degrees W'\n    stationobs_units['surface_wind'] = windunits\n    stationobs_units['location_name'] = 'None'\n    stationobs_units['temp_sounding'] = 'Kelvin'\n    stationobs_units['press_sounding'] = 'hPa'\n    assert_print(stationobs_units.dtype)\n    statdat.units = stationobs_units\n    f.close()\n    f = Dataset('compound_example.nc')\n    assert_print(f)\n    statdat = f.variables['station_obs']\n    assert_print(statdat)\n    assert_print('data in a variable of compound type:')\n    assert_print(statdat[:])\n    f.close()\n    f = Dataset('tst_vlen.nc', 'w')\n    vlen_t = f.createVLType(np.int32, 'phony_vlen')\n    x = f.createDimension('x', 3)\n    y = f.createDimension('y', 4)\n    vlvar = f.createVariable('phony_vlen_var', vlen_t, ('y', 'x'))\n    data = np.empty(len(y) * len(x), object)\n    for n in range(len(y) * len(x)):\n        data[n] = np.arange(rng.integers(1, 10), dtype='int32') + 1\n    data = np.reshape(data, (len(y), len(x)))\n    vlvar[:] = data\n    assert_print(vlvar)\n    assert_print('vlen variable =\\n', vlvar[:])\n    assert_print(f)\n    assert_print(f.variables['phony_vlen_var'])\n    assert_print(f.vltypes['phony_vlen'])\n    f.createDimension('z', 10)\n    strvar = f.createVariable('strvar', str, 'z')\n    chars = list('1234567890aabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n    data = np.empty(10, object)\n    for n in range(10):\n        stringlen = rng.integers(2, 12)\n        data[n] = ''.join([rng.choice(chars) for i in range(stringlen)])\n    strvar[:] = data\n    assert_print('variable-length string variable:\\n', strvar[:])\n    assert_print(f)\n    assert_print(f.variables['strvar'])\n    f.close()\n    f = Dataset('clouds.nc', 'w')\n    enum_dict = {'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\n    cloud_type = f.createEnumType(np.uint8, 'cloud_t', enum_dict)\n    assert_print(cloud_type)\n    time = f.createDimension('time', None)\n    cloud_var = f.createVariable('primary_cloud', cloud_type, 'time', fill_value=enum_dict['Missing'])\n    cloud_var[:] = [enum_dict['Clear'], enum_dict['Stratus'], enum_dict['Cumulus'], enum_dict['Missing'], enum_dict['Cumulonimbus']]\n    f.close()\n    f = Dataset('clouds.nc')\n    cloud_var = f.variables['primary_cloud']\n    assert_print(cloud_var)\n    assert_print(cloud_var.datatype.enum_dict)\n    assert_print(cloud_var[:])\n    f.close()\n    from netCDF4 import stringtochar\n    nc = Dataset('stringtest.nc', 'w', format='NETCDF4_CLASSIC')\n    nc.createDimension('nchars', 3)\n    nc.createDimension('nstrings', None)\n    v = nc.createVariable('strings', 'S1', ('nstrings', 'nchars'))\n    datain = np.array(['foo', 'bar'], dtype='S3')\n    v[:] = stringtochar(datain)\n    assert_print(v[:])\n    v._Encoding = 'ascii'\n    v[:] = datain\n    assert_print(v[:])\n    nc.close()\n    nc = Dataset('compoundstring_example.nc', 'w')\n    dtype = np.dtype([('observation', 'f4'), ('station_name', 'S12')])\n    station_data_t = nc.createCompoundType(dtype, 'station_data')\n    nc.createDimension('station', None)\n    statdat = nc.createVariable('station_obs', station_data_t, ('station',))\n    data = np.empty(2, station_data_t.dtype_view)\n    data['observation'][:] = (123.0, 3.14)\n    data['station_name'][:] = ('Boulder', 'New York')\n    assert_print(statdat.dtype)\n    statdat[:] = data\n    assert_print(statdat[:])\n    assert_print(statdat[:].dtype)\n    statdat.set_auto_chartostring(False)\n    statdat[:] = data.view(station_data_t.dtype)\n    assert_print(statdat[:])\n    nc.close()\n    nc = Dataset('diskless_example.nc', 'w', diskless=True, persist=True)\n    nc.createDimension('x', None)\n    v = nc.createVariable('v', np.int32, 'x')\n    v[0:5] = np.arange(5)\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()\n    f = open('diskless_example.nc', 'rb')\n    nc_bytes = f.read()\n    f.close()\n    nc = Dataset('inmemory.nc', memory=nc_bytes)\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()\n    nc = Dataset('inmemory.nc', mode='w', memory=1028)\n    nc.createDimension('x', None)\n    v = nc.createVariable('v', np.int32, 'x')\n    v[0:5] = np.arange(5)\n    nc_buf = nc.close()\n    assert_print(type(nc_buf))\n    f = open('inmemory.nc', 'wb')\n    f.write(nc_buf)\n    f.close()\n    nc = Dataset('inmemory.nc')\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()",
            "@pytest.mark.driver_timeout(60)\n@run_in_pyodide(packages=['netCDF4', 'numpy'])\ndef test_netCDF4_tutorial(selenium):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    import re\n    from datetime import datetime\n    DATETIME_PATTERN = re.compile('[a-zA-Z]{3}\\\\s+[a-zA-Z]{3}\\\\s+[0-9]{1,2}\\\\s+[0-9]{2}:[0-9]{2}:[0-9]{2}\\\\s+[0-9]{4}')\n    DATETIME_FORMAT = '%a %b %d %H:%M:%S %Y'\n    stdouts = ['NETCDF4', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: forecasts, analyses\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: model1, model2\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /analyses:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model1:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model2:\\n    dimensions(sizes): \\n    variables(dimensions): \\n    groups: \", \"{'level': <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0, 'time': <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0, 'lat': <class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73, 'lon': <class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144}\", '144', 'False', 'True', \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'level', size = 0\", \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\", \"<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 73\", \"<class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 144\", \"<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\", \"<class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\n    least_significant_digit: 3\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used\", \"<class 'netCDF4._netCDF4.Group'>\\ngroup /forecasts/model1:\\n    dimensions(sizes): \\n    variables(dimensions): float32 temp(time, level, lat, lon)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\npath = /forecasts/model1\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used\", 'Global attr description = bogus example script', 'Global attr history = Created %a %b %d %H:%M:%S %Y', 'Global attr source = netCDF4 python module tutorial', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    description: bogus example script\\n    history: Created %a %b %d %H:%M:%S %Y\\n    source: netCDF4 python module tutorial\\n    dimensions(sizes): level(0), time(0), lat(73), lon(144)\\n    variables(dimensions): float64 time(time), int32 level(level), float32 lat(lat), float32 lon(lon), float32 temp(time, level, lat, lon)\\n    groups: forecasts, analyses\", \"{'description': 'bogus example script', 'history': 'Created %a %b %d %H:%M:%S %Y', 'source': 'netCDF4 python module tutorial'}\", \"{'time': <class 'netCDF4._netCDF4.Variable'>\\nfloat64 time(time)\\n    units: hours since 0001-01-01 00:00:00.0\\n    calendar: gregorian\\nunlimited dimensions: time\\ncurrent shape = (0,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'level': <class 'netCDF4._netCDF4.Variable'>\\nint32 level(level)\\n    units: hPa\\nunlimited dimensions: level\\ncurrent shape = (0,)\\nfilling on, default _FillValue of -2147483647 used, 'lat': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 lat(lat)\\n    units: degrees north\\nunlimited dimensions: \\ncurrent shape = (73,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'lon': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 lon(lon)\\n    units: degrees east\\nunlimited dimensions: \\ncurrent shape = (144,)\\nfilling on, default _FillValue of 9.969209968386869e+36 used, 'temp': <class 'netCDF4._netCDF4.Variable'>\\nfloat32 temp(time, level, lat, lon)\\n    least_significant_digit: 3\\nunlimited dimensions: time, level\\ncurrent shape = (0, 0, 73, 144)\\nfilling on, default _FillValue of 9.969209968386869e+36 used}\", 'latitudes =\\n [-90.  -87.5 -85.  -82.5 -80.  -77.5 -75.  -72.5 -70.  -67.5 -65.  -62.5\\n -60.  -57.5 -55.  -52.5 -50.  -47.5 -45.  -42.5 -40.  -37.5 -35.  -32.5\\n -30.  -27.5 -25.  -22.5 -20.  -17.5 -15.  -12.5 -10.   -7.5  -5.   -2.5\\n   0.    2.5   5.    7.5  10.   12.5  15.   17.5  20.   22.5  25.   27.5\\n  30.   32.5  35.   37.5  40.   42.5  45.   47.5  50.   52.5  55.   57.5\\n  60.   62.5  65.   67.5  70.   72.5  75.   77.5  80.   82.5  85.   87.5\\n  90. ]', 'longitudes =\\n [-180.  -177.5 -175.  -172.5 -170.  -167.5 -165.  -162.5 -160.  -157.5\\n -155.  -152.5 -150.  -147.5 -145.  -142.5 -140.  -137.5 -135.  -132.5\\n -130.  -127.5 -125.  -122.5 -120.  -117.5 -115.  -112.5 -110.  -107.5\\n -105.  -102.5 -100.   -97.5  -95.   -92.5  -90.   -87.5  -85.   -82.5\\n  -80.   -77.5  -75.   -72.5  -70.   -67.5  -65.   -62.5  -60.   -57.5\\n  -55.   -52.5  -50.   -47.5  -45.   -42.5  -40.   -37.5  -35.   -32.5\\n  -30.   -27.5  -25.   -22.5  -20.   -17.5  -15.   -12.5  -10.    -7.5\\n   -5.    -2.5    0.     2.5    5.     7.5   10.    12.5   15.    17.5\\n   20.    22.5   25.    27.5   30.    32.5   35.    37.5   40.    42.5\\n   45.    47.5   50.    52.5   55.    57.5   60.    62.5   65.    67.5\\n   70.    72.5   75.    77.5   80.    82.5   85.    87.5   90.    92.5\\n   95.    97.5  100.   102.5  105.   107.5  110.   112.5  115.   117.5\\n  120.   122.5  125.   127.5  130.   132.5  135.   137.5  140.   142.5\\n  145.   147.5  150.   152.5  155.   157.5  160.   162.5  165.   167.5\\n  170.   172.5  175.   177.5]', 'temp shape before adding data =  (0, 0, 73, 144)', 'temp shape after adding data =  (5, 10, 73, 144)', 'levels shape after adding pressure data =  (10,)', 'shape of fancy temp slice =  (3, 3, 36, 71)', '(4, 4)', 'time values (in units hours since 0001-01-01 00:00:00.0):\\n[17533104. 17533116. 17533128. 17533140. 17533152.]', 'dates corresponding to time values:\\n[cftime.DatetimeGregorian(2001, 3, 1, 0, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 1, 12, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 2, 0, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 2, 12, 0, 0, 0, has_year_zero=False)\\n cftime.DatetimeGregorian(2001, 3, 3, 0, 0, 0, 0, has_year_zero=False)]', '[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\\n 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\\n 96 97 98 99]', 'complex128', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x_dim(3)\\n    variables(dimensions): {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True} cmplx_var(x_dim)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\ncompound cmplx_var(x_dim)\\ncompound data type: {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}\\nunlimited dimensions: x_dim\\ncurrent shape = (3,)\", \"{'complex128': <class 'netCDF4._netCDF4.CompoundType'>: name = 'complex128', numpy dtype = {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}}\", \"<class 'netCDF4._netCDF4.CompoundType'>: name = 'complex128', numpy dtype = {'names': ['real', 'imag'], 'formats': ['<f8', '<f8'], 'offsets': [0, 8], 'itemsize': 16, 'aligned': True}\", '(3,)', 'complex128 [ 0.54030231+0.84147098j -0.84147098+0.54030231j -0.54030231-0.84147098j]', 'complex128 [ 0.54030231+0.84147098j -0.84147098+0.54030231j -0.54030231-0.84147098j]', \"{'wind_data': <class 'netCDF4._netCDF4.CompoundType'>: name = 'wind_data', numpy dtype = {'names': ['speed', 'direction'], 'formats': ['<f4', '<i4'], 'offsets': [0, 4], 'itemsize': 8, 'aligned': True}, 'station_data': <class 'netCDF4._netCDF4.CompoundType'>: name = 'station_data', numpy dtype = {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True}, 'wind_data_units': <class 'netCDF4._netCDF4.CompoundType'>: name = 'wind_data_units', numpy dtype = {'names': ['speed', 'direction'], 'formats': [('S1', (12,)), ('S1', (12,))], 'offsets': [0, 12], 'itemsize': 24, 'aligned': True}, 'station_data_units': <class 'netCDF4._netCDF4.CompoundType'>: name = 'station_data_units', numpy dtype = {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'location_name', 'press_sounding'], 'formats': [('S1', (12,)), ('S1', (12,)), [('speed', 'S1', (12,)), ('direction', 'S1', (12,))], ('S1', (12,)), ('S1', (12,)), ('S1', (12,))], 'offsets': [0, 12, 24, 48, 60, 72], 'itemsize': 84, 'aligned': True}}\", \"[('latitude', 'S12'), ('longitude', 'S12'), ('surface_wind', [('speed', 'S12'), ('direction', 'S12')]), ('temp_sounding', 'S12'), ('location_name', 'S12'), ('press_sounding', 'S12')]\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): station(2)\\n    variables(dimensions): {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True} station_obs(station)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\ncompound station_obs(station)\\n    units: (b'degrees N', b'degrees W', (b'm/s', b'degrees'), b'Kelvin', b'None', b'hPa')\\ncompound data type: {'names': ['latitude', 'longitude', 'surface_wind', 'temp_sounding', 'press_sounding', 'location_name'], 'formats': ['<f4', '<f4', [('speed', '<f4'), ('direction', '<i4')], ('<f4', (10,)), ('<i4', (10,)), ('S1', (12,))], 'offsets': [0, 4, 8, 16, 56, 96], 'itemsize': 108, 'aligned': True}\\nunlimited dimensions: station\\ncurrent shape = (2,)\", 'data in a variable of compound type:', \"[(40.  , -105.  , ( 12.5, 270), [280.3, 272. , 270. , 269. , 266. , 258. , 254.1, 250. , 245.5, 240. ], [800, 750, 700, 650, 600, 550, 500, 450, 400, 350], b'Boulder, CO')\\n (40.78,  -73.99, (-12.5,  90), [290.2, 282.5, 279. , 277.9, 276. , 266. , 264.1, 260. , 255.5, 243. ], [900, 850, 800, 750, 700, 650, 600, 550, 500, 450], b'New York, NY')]\", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen phony_vlen_var(y, x)\\nvlen data type: int32\\nunlimited dimensions: \\ncurrent shape = (4, 3)\", 'vlen variable =\\n [[array([1, 2, 3, 4, 5, 6, 7]) array([1, 2, 3, 4, 5]) array([1])]\\n [array([1, 2, 3]) array([1, 2]) array([1])]\\n [array([1]) array([1, 2, 3, 4, 5, 6, 7]) array([1])]\\n [array([1, 2, 3, 4, 5, 6]) array([1, 2, 3, 4, 5]) array([1])]]', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(3), y(4)\\n    variables(dimensions): int32 phony_vlen_var(y, x)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen phony_vlen_var(y, x)\\nvlen data type: int32\\nunlimited dimensions: \\ncurrent shape = (4, 3)\", \"<class 'netCDF4._netCDF4.VLType'>: name = 'phony_vlen', numpy dtype = int32\", \"variable-length string variable:\\n ['ZOGMRmJo' 'BxdAK1fku' 'lgOzaanCtv' 'D5ALrXJCDU' 'W9r' 'Y7edBPrthEr'\\n 'OVeqx' 'aH1ZXc5A' 'LC1ajPJ' 'du']\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(3), y(4), z(10)\\n    variables(dimensions): int32 phony_vlen_var(y, x), <class 'str'> strvar(z)\\n    groups: \", \"<class 'netCDF4._netCDF4.Variable'>\\nvlen strvar(z)\\nvlen data type: <class 'str'>\\nunlimited dimensions: \\ncurrent shape = (10,)\", \"<class 'netCDF4._netCDF4.EnumType'>: name = 'cloud_t', numpy dtype = uint8, fields/values ={'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\", \"<class 'netCDF4._netCDF4.Variable'>\\nenum primary_cloud(time)\\n    _FillValue: 255\\nenum data type: uint8\\nunlimited dimensions: time\\ncurrent shape = (5,)\", \"{'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\", '[0 2 4 -- 1]', \"[[b'f' b'o' b'o']\\n [b'b' b'a' b'r']]\", \"['foo' 'bar']\", \"{'names': ['observation', 'station_name'], 'formats': ['<f4', ('S1', (12,))], 'offsets': [0, 4], 'itemsize': 16, 'aligned': True}\", \"[(123.  , b'Boulder') (  3.14, b'New York')]\", \"{'names': ['observation', 'station_name'], 'formats': ['<f4', 'S12'], 'offsets': [0, 4], 'itemsize': 16, 'aligned': True}\", \"[(123.  , [b'B', b'o', b'u', b'l', b'd', b'e', b'r', b'', b'', b'', b'', b''])\\n (  3.14, [b'N', b'e', b'w', b' ', b'Y', b'o', b'r', b'k', b'', b'', b'', b''])]\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]', \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]', \"<class 'memoryview'>\", \"<class 'netCDF4._netCDF4.Dataset'>\\nroot group (NETCDF4 data model, file format HDF5):\\n    dimensions(sizes): x(5)\\n    variables(dimensions): int32 v(x)\\n    groups: \", '[0 1 2 3 4]']\n\n    def replace_netcdf_datetime(match):\n        try:\n            datetime.strptime(match.group(0), DATETIME_FORMAT)\n        except Exception:\n            return match.group(0)\n        else:\n            return DATETIME_FORMAT\n\n    def assert_print(*args):\n        output = DATETIME_PATTERN.sub(replace_netcdf_datetime, ' '.join((str(a) for a in args)))\n        expected = stdouts.pop(0)\n        if output != expected:\n            assert output == expected, f'{repr(output)} != {repr(expected)}'\n    '\\n    Test adopted from (but with reproducible randomness):\\n    https://github.com/Unidata/netcdf4-python/blob/master/examples/tutorial.py\\n    Released under the MIT License\\n    '\n    from numpy.random import PCG64, Generator\n    rng = Generator(PCG64(seed=42))\n    from netCDF4 import Dataset\n    rootgrp = Dataset('test.nc', 'w', format='NETCDF4')\n    assert_print(rootgrp.file_format)\n    rootgrp.close()\n    rootgrp = Dataset('test.nc', 'a')\n    rootgrp.createGroup('forecasts')\n    rootgrp.createGroup('analyses')\n    rootgrp.createGroup('/forecasts/model1')\n    rootgrp.createGroup('/forecasts/model2')\n\n    def walktree(top):\n        yield top.groups.values()\n        for value in top.groups.values():\n            yield from walktree(value)\n    assert_print(rootgrp)\n    for children in walktree(rootgrp):\n        for child in children:\n            assert_print(child)\n    rootgrp.createDimension('level', None)\n    time = rootgrp.createDimension('time', None)\n    rootgrp.createDimension('lat', 73)\n    lon = rootgrp.createDimension('lon', 144)\n    assert_print(rootgrp.dimensions)\n    assert_print(len(lon))\n    assert_print(lon.isunlimited())\n    assert_print(time.isunlimited())\n    for dimobj in rootgrp.dimensions.values():\n        assert_print(dimobj)\n    assert_print(time)\n    times = rootgrp.createVariable('time', 'f8', ('time',))\n    levels = rootgrp.createVariable('level', 'i4', ('level',))\n    latitudes = rootgrp.createVariable('lat', 'f4', ('lat',))\n    longitudes = rootgrp.createVariable('lon', 'f4', ('lon',))\n    temp = rootgrp.createVariable('temp', 'f4', ('time', 'level', 'lat', 'lon'), least_significant_digit=3)\n    assert_print(temp)\n    temp = rootgrp.createVariable('/forecasts/model1/temp', 'f4', ('time', 'level', 'lat', 'lon'))\n    assert_print(rootgrp['/forecasts/model1'])\n    assert_print(rootgrp['/forecasts/model1/temp'])\n    import time\n    rootgrp.description = 'bogus example script'\n    rootgrp.history = 'Created ' + time.ctime(time.time())\n    rootgrp.source = 'netCDF4 python module tutorial'\n    latitudes.units = 'degrees north'\n    longitudes.units = 'degrees east'\n    levels.units = 'hPa'\n    temp.units = 'K'\n    times.units = 'hours since 0001-01-01 00:00:00.0'\n    times.calendar = 'gregorian'\n    for name in rootgrp.ncattrs():\n        assert_print('Global attr', name, '=', getattr(rootgrp, name))\n    assert_print(rootgrp)\n    assert_print(rootgrp.__dict__)\n    assert_print(rootgrp.variables)\n    import numpy as np\n    lats = np.arange(-90, 91, 2.5)\n    lons = np.arange(-180, 180, 2.5)\n    latitudes[:] = lats\n    longitudes[:] = lons\n    assert_print('latitudes =\\n', latitudes[:])\n    assert_print('longitudes =\\n', longitudes[:])\n    nlats = len(rootgrp.dimensions['lat'])\n    nlons = len(rootgrp.dimensions['lon'])\n    assert_print('temp shape before adding data = ', temp.shape)\n    temp[0:5, 0:10, :, :] = rng.uniform(size=(5, 10, nlats, nlons))\n    assert_print('temp shape after adding data = ', temp.shape)\n    assert_print('levels shape after adding pressure data = ', levels.shape)\n    levels[:] = [1000.0, 850.0, 700.0, 500.0, 300.0, 250.0, 200.0, 150.0, 100.0, 50.0]\n    tempdat = temp[::2, [1, 3, 6], lats > 0, lons > 0]\n    assert_print('shape of fancy temp slice = ', tempdat.shape)\n    assert_print(temp[0, 0, [0, 1, 2, 3], [0, 1, 2, 3]].shape)\n    from datetime import timedelta\n    from netCDF4 import date2num, num2date\n    dates = [datetime(2001, 3, 1) + n * timedelta(hours=12) for n in range(temp.shape[0])]\n    times[:] = date2num(dates, units=times.units, calendar=times.calendar)\n    assert_print(f'time values (in units {times.units}):\\n{times[:]}')\n    dates = num2date(times[:], units=times.units, calendar=times.calendar)\n    assert_print(f'dates corresponding to time values:\\n{dates}')\n    rootgrp.close()\n    for nfile in range(10):\n        f = Dataset('mftest' + repr(nfile) + '.nc', 'w', format='NETCDF4_CLASSIC')\n        f.createDimension('x', None)\n        x = f.createVariable('x', 'i', ('x',))\n        x[0:10] = np.arange(nfile * 10, 10 * (nfile + 1))\n        f.close()\n    from netCDF4 import MFDataset\n    f = MFDataset('mftest*nc')\n    assert_print(f.variables['x'][:])\n    f = Dataset('complex.nc', 'w')\n    size = 3\n    datac = np.exp(1j * (1.0 + np.linspace(0, np.pi, size)))\n    assert_print(datac.dtype)\n    complex128 = np.dtype([('real', np.float64), ('imag', np.float64)])\n    complex128_t = f.createCompoundType(complex128, 'complex128')\n    f.createDimension('x_dim', None)\n    v = f.createVariable('cmplx_var', complex128_t, 'x_dim')\n    data = np.empty(size, complex128)\n    data['real'] = datac.real\n    data['imag'] = datac.imag\n    v[:] = data\n    f.close()\n    f = Dataset('complex.nc')\n    assert_print(f)\n    assert_print(f.variables['cmplx_var'])\n    assert_print(f.cmptypes)\n    assert_print(f.cmptypes['complex128'])\n    v = f.variables['cmplx_var']\n    assert_print(v.shape)\n    datain = v[:]\n    datac2 = np.empty(datain.shape, np.complex128)\n    datac2.real = datain['real']\n    datac2.imag = datain['imag']\n    assert_print(datac.dtype, datac)\n    assert_print(datac2.dtype, datac2)\n    f = Dataset('compound_example.nc', 'w')\n    f.createDimension('station', None)\n    winddtype = np.dtype([('speed', 'f4'), ('direction', 'i4')])\n    statdtype = np.dtype([('latitude', 'f4'), ('longitude', 'f4'), ('surface_wind', winddtype), ('temp_sounding', 'f4', 10), ('press_sounding', 'i4', 10), ('location_name', 'S12')])\n    f.createCompoundType(winddtype, 'wind_data')\n    station_data_t = f.createCompoundType(statdtype, 'station_data')\n    winddtype_units = np.dtype([('speed', 'S12'), ('direction', 'S12')])\n    statdtype_units = np.dtype([('latitude', 'S12'), ('longitude', 'S12'), ('surface_wind', winddtype_units), ('temp_sounding', 'S12'), ('location_name', 'S12'), ('press_sounding', 'S12')])\n    f.createCompoundType(winddtype_units, 'wind_data_units')\n    f.createCompoundType(statdtype_units, 'station_data_units')\n    statdat = f.createVariable('station_obs', station_data_t, ('station',))\n    data = np.empty(1, statdtype)\n    data['latitude'] = 40.0\n    data['longitude'] = -105.0\n    data['surface_wind']['speed'] = 12.5\n    data['surface_wind']['direction'] = 270\n    data['temp_sounding'] = (280.3, 272.0, 270.0, 269.0, 266.0, 258.0, 254.1, 250.0, 245.5, 240.0)\n    data['press_sounding'] = range(800, 300, -50)\n    data['location_name'] = 'Boulder, CO'\n    statdat[0] = data\n    statdat[1] = np.array((40.78, -73.99, (-12.5, 90), (290.2, 282.5, 279.0, 277.9, 276.0, 266.0, 264.1, 260.0, 255.5, 243.0), range(900, 400, -50), 'New York, NY'), data.dtype)\n    assert_print(f.cmptypes)\n    windunits = np.empty(1, winddtype_units)\n    stationobs_units = np.empty(1, statdtype_units)\n    windunits['speed'] = 'm/s'\n    windunits['direction'] = 'degrees'\n    stationobs_units['latitude'] = 'degrees N'\n    stationobs_units['longitude'] = 'degrees W'\n    stationobs_units['surface_wind'] = windunits\n    stationobs_units['location_name'] = 'None'\n    stationobs_units['temp_sounding'] = 'Kelvin'\n    stationobs_units['press_sounding'] = 'hPa'\n    assert_print(stationobs_units.dtype)\n    statdat.units = stationobs_units\n    f.close()\n    f = Dataset('compound_example.nc')\n    assert_print(f)\n    statdat = f.variables['station_obs']\n    assert_print(statdat)\n    assert_print('data in a variable of compound type:')\n    assert_print(statdat[:])\n    f.close()\n    f = Dataset('tst_vlen.nc', 'w')\n    vlen_t = f.createVLType(np.int32, 'phony_vlen')\n    x = f.createDimension('x', 3)\n    y = f.createDimension('y', 4)\n    vlvar = f.createVariable('phony_vlen_var', vlen_t, ('y', 'x'))\n    data = np.empty(len(y) * len(x), object)\n    for n in range(len(y) * len(x)):\n        data[n] = np.arange(rng.integers(1, 10), dtype='int32') + 1\n    data = np.reshape(data, (len(y), len(x)))\n    vlvar[:] = data\n    assert_print(vlvar)\n    assert_print('vlen variable =\\n', vlvar[:])\n    assert_print(f)\n    assert_print(f.variables['phony_vlen_var'])\n    assert_print(f.vltypes['phony_vlen'])\n    f.createDimension('z', 10)\n    strvar = f.createVariable('strvar', str, 'z')\n    chars = list('1234567890aabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n    data = np.empty(10, object)\n    for n in range(10):\n        stringlen = rng.integers(2, 12)\n        data[n] = ''.join([rng.choice(chars) for i in range(stringlen)])\n    strvar[:] = data\n    assert_print('variable-length string variable:\\n', strvar[:])\n    assert_print(f)\n    assert_print(f.variables['strvar'])\n    f.close()\n    f = Dataset('clouds.nc', 'w')\n    enum_dict = {'Altocumulus': 7, 'Missing': 255, 'Stratus': 2, 'Clear': 0, 'Nimbostratus': 6, 'Cumulus': 4, 'Altostratus': 5, 'Cumulonimbus': 1, 'Stratocumulus': 3}\n    cloud_type = f.createEnumType(np.uint8, 'cloud_t', enum_dict)\n    assert_print(cloud_type)\n    time = f.createDimension('time', None)\n    cloud_var = f.createVariable('primary_cloud', cloud_type, 'time', fill_value=enum_dict['Missing'])\n    cloud_var[:] = [enum_dict['Clear'], enum_dict['Stratus'], enum_dict['Cumulus'], enum_dict['Missing'], enum_dict['Cumulonimbus']]\n    f.close()\n    f = Dataset('clouds.nc')\n    cloud_var = f.variables['primary_cloud']\n    assert_print(cloud_var)\n    assert_print(cloud_var.datatype.enum_dict)\n    assert_print(cloud_var[:])\n    f.close()\n    from netCDF4 import stringtochar\n    nc = Dataset('stringtest.nc', 'w', format='NETCDF4_CLASSIC')\n    nc.createDimension('nchars', 3)\n    nc.createDimension('nstrings', None)\n    v = nc.createVariable('strings', 'S1', ('nstrings', 'nchars'))\n    datain = np.array(['foo', 'bar'], dtype='S3')\n    v[:] = stringtochar(datain)\n    assert_print(v[:])\n    v._Encoding = 'ascii'\n    v[:] = datain\n    assert_print(v[:])\n    nc.close()\n    nc = Dataset('compoundstring_example.nc', 'w')\n    dtype = np.dtype([('observation', 'f4'), ('station_name', 'S12')])\n    station_data_t = nc.createCompoundType(dtype, 'station_data')\n    nc.createDimension('station', None)\n    statdat = nc.createVariable('station_obs', station_data_t, ('station',))\n    data = np.empty(2, station_data_t.dtype_view)\n    data['observation'][:] = (123.0, 3.14)\n    data['station_name'][:] = ('Boulder', 'New York')\n    assert_print(statdat.dtype)\n    statdat[:] = data\n    assert_print(statdat[:])\n    assert_print(statdat[:].dtype)\n    statdat.set_auto_chartostring(False)\n    statdat[:] = data.view(station_data_t.dtype)\n    assert_print(statdat[:])\n    nc.close()\n    nc = Dataset('diskless_example.nc', 'w', diskless=True, persist=True)\n    nc.createDimension('x', None)\n    v = nc.createVariable('v', np.int32, 'x')\n    v[0:5] = np.arange(5)\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()\n    f = open('diskless_example.nc', 'rb')\n    nc_bytes = f.read()\n    f.close()\n    nc = Dataset('inmemory.nc', memory=nc_bytes)\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()\n    nc = Dataset('inmemory.nc', mode='w', memory=1028)\n    nc.createDimension('x', None)\n    v = nc.createVariable('v', np.int32, 'x')\n    v[0:5] = np.arange(5)\n    nc_buf = nc.close()\n    assert_print(type(nc_buf))\n    f = open('inmemory.nc', 'wb')\n    f.write(nc_buf)\n    f.close()\n    nc = Dataset('inmemory.nc')\n    assert_print(nc)\n    assert_print(nc['v'][:])\n    nc.close()"
        ]
    }
]