[
    {
        "func_name": "_ll_nbp",
        "original": "def _ll_nbp(y, X, beta, alph, Q):\n    \"\"\"\n    Negative Binomial Log-likelihood -- type P\n\n    References:\n\n    Greene, W. 2008. \"Functional forms for the negative binomial model\n        for count data\". Economics Letters. Volume 99, Number 3, pp.585-590.\n    Hilbe, J.M. 2011. \"Negative binomial regression\". Cambridge University Press.\n\n    Following notation in Greene (2008), with negative binomial heterogeneity\n    parameter :math:`\\\\alpha`:\n\n    .. math::\n\n        \\\\lambda_i = exp(X\\\\beta)\\\\\\\\\n        \\\\theta = 1 / \\\\alpha \\\\\\\\\n        g_i = \\\\theta \\\\lambda_i^Q \\\\\\\\\n        w_i = g_i/(g_i + \\\\lambda_i) \\\\\\\\\n        r_i = \\\\theta / (\\\\theta+\\\\lambda_i) \\\\\\\\\n        ln \\\\mathcal{L}_i = ln \\\\Gamma(y_i+g_i) - ln \\\\Gamma(1+y_i) + g_iln (r_i) + y_i ln(1-r_i)\n    \"\"\"\n    mu = np.exp(np.dot(X, beta))\n    size = 1 / alph * mu ** Q\n    prob = size / (size + mu)\n    ll = nbinom.logpmf(y, size, prob)\n    return ll",
        "mutated": [
            "def _ll_nbp(y, X, beta, alph, Q):\n    if False:\n        i = 10\n    '\\n    Negative Binomial Log-likelihood -- type P\\n\\n    References:\\n\\n    Greene, W. 2008. \"Functional forms for the negative binomial model\\n        for count data\". Economics Letters. Volume 99, Number 3, pp.585-590.\\n    Hilbe, J.M. 2011. \"Negative binomial regression\". Cambridge University Press.\\n\\n    Following notation in Greene (2008), with negative binomial heterogeneity\\n    parameter :math:`\\\\alpha`:\\n\\n    .. math::\\n\\n        \\\\lambda_i = exp(X\\\\beta)\\\\\\\\\\n        \\\\theta = 1 / \\\\alpha \\\\\\\\\\n        g_i = \\\\theta \\\\lambda_i^Q \\\\\\\\\\n        w_i = g_i/(g_i + \\\\lambda_i) \\\\\\\\\\n        r_i = \\\\theta / (\\\\theta+\\\\lambda_i) \\\\\\\\\\n        ln \\\\mathcal{L}_i = ln \\\\Gamma(y_i+g_i) - ln \\\\Gamma(1+y_i) + g_iln (r_i) + y_i ln(1-r_i)\\n    '\n    mu = np.exp(np.dot(X, beta))\n    size = 1 / alph * mu ** Q\n    prob = size / (size + mu)\n    ll = nbinom.logpmf(y, size, prob)\n    return ll",
            "def _ll_nbp(y, X, beta, alph, Q):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Negative Binomial Log-likelihood -- type P\\n\\n    References:\\n\\n    Greene, W. 2008. \"Functional forms for the negative binomial model\\n        for count data\". Economics Letters. Volume 99, Number 3, pp.585-590.\\n    Hilbe, J.M. 2011. \"Negative binomial regression\". Cambridge University Press.\\n\\n    Following notation in Greene (2008), with negative binomial heterogeneity\\n    parameter :math:`\\\\alpha`:\\n\\n    .. math::\\n\\n        \\\\lambda_i = exp(X\\\\beta)\\\\\\\\\\n        \\\\theta = 1 / \\\\alpha \\\\\\\\\\n        g_i = \\\\theta \\\\lambda_i^Q \\\\\\\\\\n        w_i = g_i/(g_i + \\\\lambda_i) \\\\\\\\\\n        r_i = \\\\theta / (\\\\theta+\\\\lambda_i) \\\\\\\\\\n        ln \\\\mathcal{L}_i = ln \\\\Gamma(y_i+g_i) - ln \\\\Gamma(1+y_i) + g_iln (r_i) + y_i ln(1-r_i)\\n    '\n    mu = np.exp(np.dot(X, beta))\n    size = 1 / alph * mu ** Q\n    prob = size / (size + mu)\n    ll = nbinom.logpmf(y, size, prob)\n    return ll",
            "def _ll_nbp(y, X, beta, alph, Q):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Negative Binomial Log-likelihood -- type P\\n\\n    References:\\n\\n    Greene, W. 2008. \"Functional forms for the negative binomial model\\n        for count data\". Economics Letters. Volume 99, Number 3, pp.585-590.\\n    Hilbe, J.M. 2011. \"Negative binomial regression\". Cambridge University Press.\\n\\n    Following notation in Greene (2008), with negative binomial heterogeneity\\n    parameter :math:`\\\\alpha`:\\n\\n    .. math::\\n\\n        \\\\lambda_i = exp(X\\\\beta)\\\\\\\\\\n        \\\\theta = 1 / \\\\alpha \\\\\\\\\\n        g_i = \\\\theta \\\\lambda_i^Q \\\\\\\\\\n        w_i = g_i/(g_i + \\\\lambda_i) \\\\\\\\\\n        r_i = \\\\theta / (\\\\theta+\\\\lambda_i) \\\\\\\\\\n        ln \\\\mathcal{L}_i = ln \\\\Gamma(y_i+g_i) - ln \\\\Gamma(1+y_i) + g_iln (r_i) + y_i ln(1-r_i)\\n    '\n    mu = np.exp(np.dot(X, beta))\n    size = 1 / alph * mu ** Q\n    prob = size / (size + mu)\n    ll = nbinom.logpmf(y, size, prob)\n    return ll",
            "def _ll_nbp(y, X, beta, alph, Q):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Negative Binomial Log-likelihood -- type P\\n\\n    References:\\n\\n    Greene, W. 2008. \"Functional forms for the negative binomial model\\n        for count data\". Economics Letters. Volume 99, Number 3, pp.585-590.\\n    Hilbe, J.M. 2011. \"Negative binomial regression\". Cambridge University Press.\\n\\n    Following notation in Greene (2008), with negative binomial heterogeneity\\n    parameter :math:`\\\\alpha`:\\n\\n    .. math::\\n\\n        \\\\lambda_i = exp(X\\\\beta)\\\\\\\\\\n        \\\\theta = 1 / \\\\alpha \\\\\\\\\\n        g_i = \\\\theta \\\\lambda_i^Q \\\\\\\\\\n        w_i = g_i/(g_i + \\\\lambda_i) \\\\\\\\\\n        r_i = \\\\theta / (\\\\theta+\\\\lambda_i) \\\\\\\\\\n        ln \\\\mathcal{L}_i = ln \\\\Gamma(y_i+g_i) - ln \\\\Gamma(1+y_i) + g_iln (r_i) + y_i ln(1-r_i)\\n    '\n    mu = np.exp(np.dot(X, beta))\n    size = 1 / alph * mu ** Q\n    prob = size / (size + mu)\n    ll = nbinom.logpmf(y, size, prob)\n    return ll",
            "def _ll_nbp(y, X, beta, alph, Q):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Negative Binomial Log-likelihood -- type P\\n\\n    References:\\n\\n    Greene, W. 2008. \"Functional forms for the negative binomial model\\n        for count data\". Economics Letters. Volume 99, Number 3, pp.585-590.\\n    Hilbe, J.M. 2011. \"Negative binomial regression\". Cambridge University Press.\\n\\n    Following notation in Greene (2008), with negative binomial heterogeneity\\n    parameter :math:`\\\\alpha`:\\n\\n    .. math::\\n\\n        \\\\lambda_i = exp(X\\\\beta)\\\\\\\\\\n        \\\\theta = 1 / \\\\alpha \\\\\\\\\\n        g_i = \\\\theta \\\\lambda_i^Q \\\\\\\\\\n        w_i = g_i/(g_i + \\\\lambda_i) \\\\\\\\\\n        r_i = \\\\theta / (\\\\theta+\\\\lambda_i) \\\\\\\\\\n        ln \\\\mathcal{L}_i = ln \\\\Gamma(y_i+g_i) - ln \\\\Gamma(1+y_i) + g_iln (r_i) + y_i ln(1-r_i)\\n    '\n    mu = np.exp(np.dot(X, beta))\n    size = 1 / alph * mu ** Q\n    prob = size / (size + mu)\n    ll = nbinom.logpmf(y, size, prob)\n    return ll"
        ]
    },
    {
        "func_name": "_ll_nb1",
        "original": "def _ll_nb1(y, X, beta, alph):\n    \"\"\"Negative Binomial regression (type 1 likelihood)\"\"\"\n    ll = _ll_nbp(y, X, beta, alph, Q=1)\n    return ll",
        "mutated": [
            "def _ll_nb1(y, X, beta, alph):\n    if False:\n        i = 10\n    'Negative Binomial regression (type 1 likelihood)'\n    ll = _ll_nbp(y, X, beta, alph, Q=1)\n    return ll",
            "def _ll_nb1(y, X, beta, alph):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Negative Binomial regression (type 1 likelihood)'\n    ll = _ll_nbp(y, X, beta, alph, Q=1)\n    return ll",
            "def _ll_nb1(y, X, beta, alph):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Negative Binomial regression (type 1 likelihood)'\n    ll = _ll_nbp(y, X, beta, alph, Q=1)\n    return ll",
            "def _ll_nb1(y, X, beta, alph):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Negative Binomial regression (type 1 likelihood)'\n    ll = _ll_nbp(y, X, beta, alph, Q=1)\n    return ll",
            "def _ll_nb1(y, X, beta, alph):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Negative Binomial regression (type 1 likelihood)'\n    ll = _ll_nbp(y, X, beta, alph, Q=1)\n    return ll"
        ]
    },
    {
        "func_name": "_ll_nb2",
        "original": "def _ll_nb2(y, X, beta, alph):\n    \"\"\"Negative Binomial regression (type 2 likelihood)\"\"\"\n    ll = _ll_nbp(y, X, beta, alph, Q=0)\n    return ll",
        "mutated": [
            "def _ll_nb2(y, X, beta, alph):\n    if False:\n        i = 10\n    'Negative Binomial regression (type 2 likelihood)'\n    ll = _ll_nbp(y, X, beta, alph, Q=0)\n    return ll",
            "def _ll_nb2(y, X, beta, alph):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Negative Binomial regression (type 2 likelihood)'\n    ll = _ll_nbp(y, X, beta, alph, Q=0)\n    return ll",
            "def _ll_nb2(y, X, beta, alph):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Negative Binomial regression (type 2 likelihood)'\n    ll = _ll_nbp(y, X, beta, alph, Q=0)\n    return ll",
            "def _ll_nb2(y, X, beta, alph):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Negative Binomial regression (type 2 likelihood)'\n    ll = _ll_nbp(y, X, beta, alph, Q=0)\n    return ll",
            "def _ll_nb2(y, X, beta, alph):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Negative Binomial regression (type 2 likelihood)'\n    ll = _ll_nbp(y, X, beta, alph, Q=0)\n    return ll"
        ]
    },
    {
        "func_name": "_ll_geom",
        "original": "def _ll_geom(y, X, beta):\n    \"\"\"Geometric regression\"\"\"\n    ll = _ll_nbp(y, X, beta, alph=1, Q=0)\n    return ll",
        "mutated": [
            "def _ll_geom(y, X, beta):\n    if False:\n        i = 10\n    'Geometric regression'\n    ll = _ll_nbp(y, X, beta, alph=1, Q=0)\n    return ll",
            "def _ll_geom(y, X, beta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Geometric regression'\n    ll = _ll_nbp(y, X, beta, alph=1, Q=0)\n    return ll",
            "def _ll_geom(y, X, beta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Geometric regression'\n    ll = _ll_nbp(y, X, beta, alph=1, Q=0)\n    return ll",
            "def _ll_geom(y, X, beta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Geometric regression'\n    ll = _ll_nbp(y, X, beta, alph=1, Q=0)\n    return ll",
            "def _ll_geom(y, X, beta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Geometric regression'\n    ll = _ll_nbp(y, X, beta, alph=1, Q=0)\n    return ll"
        ]
    },
    {
        "func_name": "_ll_nbt",
        "original": "def _ll_nbt(y, X, beta, alph, C=0):\n    \"\"\"\n    Negative Binomial (truncated)\n\n    Truncated densities for count models (Cameron & Trivedi, 2005, 680):\n\n    .. math::\n\n        f(y|\\\\beta, y \\\\geq C+1) = \\\\frac{f(y|\\\\beta)}{1-F(C|\\\\beta)}\n    \"\"\"\n    Q = 0\n    mu = np.exp(np.dot(X, beta))\n    size = 1 / alph * mu ** Q\n    prob = size / (size + mu)\n    ll = nbinom.logpmf(y, size, prob) - np.log(1 - nbinom.cdf(C, size, prob))\n    return ll",
        "mutated": [
            "def _ll_nbt(y, X, beta, alph, C=0):\n    if False:\n        i = 10\n    '\\n    Negative Binomial (truncated)\\n\\n    Truncated densities for count models (Cameron & Trivedi, 2005, 680):\\n\\n    .. math::\\n\\n        f(y|\\\\beta, y \\\\geq C+1) = \\\\frac{f(y|\\\\beta)}{1-F(C|\\\\beta)}\\n    '\n    Q = 0\n    mu = np.exp(np.dot(X, beta))\n    size = 1 / alph * mu ** Q\n    prob = size / (size + mu)\n    ll = nbinom.logpmf(y, size, prob) - np.log(1 - nbinom.cdf(C, size, prob))\n    return ll",
            "def _ll_nbt(y, X, beta, alph, C=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Negative Binomial (truncated)\\n\\n    Truncated densities for count models (Cameron & Trivedi, 2005, 680):\\n\\n    .. math::\\n\\n        f(y|\\\\beta, y \\\\geq C+1) = \\\\frac{f(y|\\\\beta)}{1-F(C|\\\\beta)}\\n    '\n    Q = 0\n    mu = np.exp(np.dot(X, beta))\n    size = 1 / alph * mu ** Q\n    prob = size / (size + mu)\n    ll = nbinom.logpmf(y, size, prob) - np.log(1 - nbinom.cdf(C, size, prob))\n    return ll",
            "def _ll_nbt(y, X, beta, alph, C=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Negative Binomial (truncated)\\n\\n    Truncated densities for count models (Cameron & Trivedi, 2005, 680):\\n\\n    .. math::\\n\\n        f(y|\\\\beta, y \\\\geq C+1) = \\\\frac{f(y|\\\\beta)}{1-F(C|\\\\beta)}\\n    '\n    Q = 0\n    mu = np.exp(np.dot(X, beta))\n    size = 1 / alph * mu ** Q\n    prob = size / (size + mu)\n    ll = nbinom.logpmf(y, size, prob) - np.log(1 - nbinom.cdf(C, size, prob))\n    return ll",
            "def _ll_nbt(y, X, beta, alph, C=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Negative Binomial (truncated)\\n\\n    Truncated densities for count models (Cameron & Trivedi, 2005, 680):\\n\\n    .. math::\\n\\n        f(y|\\\\beta, y \\\\geq C+1) = \\\\frac{f(y|\\\\beta)}{1-F(C|\\\\beta)}\\n    '\n    Q = 0\n    mu = np.exp(np.dot(X, beta))\n    size = 1 / alph * mu ** Q\n    prob = size / (size + mu)\n    ll = nbinom.logpmf(y, size, prob) - np.log(1 - nbinom.cdf(C, size, prob))\n    return ll",
            "def _ll_nbt(y, X, beta, alph, C=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Negative Binomial (truncated)\\n\\n    Truncated densities for count models (Cameron & Trivedi, 2005, 680):\\n\\n    .. math::\\n\\n        f(y|\\\\beta, y \\\\geq C+1) = \\\\frac{f(y|\\\\beta)}{1-F(C|\\\\beta)}\\n    '\n    Q = 0\n    mu = np.exp(np.dot(X, beta))\n    size = 1 / alph * mu ** Q\n    prob = size / (size + mu)\n    ll = nbinom.logpmf(y, size, prob) - np.log(1 - nbinom.cdf(C, size, prob))\n    return ll"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, endog, exog, ll_type='nb2', C=0, **kwds):\n    self.exog = np.array(exog)\n    self.endog = np.array(endog)\n    self.C = C\n    super(NBin, self).__init__(endog, exog, **kwds)\n    if ll_type not in ['nb2', 'nb1', 'nbp', 'nbt', 'geom']:\n        raise NameError('Valid ll_type are: nb2, nb1, nbp,  nbt, geom')\n    self.ll_type = ll_type\n    if ll_type == 'geom':\n        self.start_params_default = np.zeros(self.exog.shape[1])\n    elif ll_type == 'nbp':\n        start_mod = NBin(endog, exog, 'nb2')\n        start_res = start_mod.fit(disp=False)\n        self.start_params_default = np.append(start_res.params, 0)\n    else:\n        self.start_params_default = np.append(np.zeros(self.exog.shape[1]), 0.5)\n    self.start_params_default[0] = np.log(self.endog.mean())\n    if ll_type == 'nb1':\n        self.ll_func = _ll_nb1\n    elif ll_type == 'nb2':\n        self.ll_func = _ll_nb2\n    elif ll_type == 'geom':\n        self.ll_func = _ll_geom\n    elif ll_type == 'nbp':\n        self.ll_func = _ll_nbp\n    elif ll_type == 'nbt':\n        self.ll_func = _ll_nbt",
        "mutated": [
            "def __init__(self, endog, exog, ll_type='nb2', C=0, **kwds):\n    if False:\n        i = 10\n    self.exog = np.array(exog)\n    self.endog = np.array(endog)\n    self.C = C\n    super(NBin, self).__init__(endog, exog, **kwds)\n    if ll_type not in ['nb2', 'nb1', 'nbp', 'nbt', 'geom']:\n        raise NameError('Valid ll_type are: nb2, nb1, nbp,  nbt, geom')\n    self.ll_type = ll_type\n    if ll_type == 'geom':\n        self.start_params_default = np.zeros(self.exog.shape[1])\n    elif ll_type == 'nbp':\n        start_mod = NBin(endog, exog, 'nb2')\n        start_res = start_mod.fit(disp=False)\n        self.start_params_default = np.append(start_res.params, 0)\n    else:\n        self.start_params_default = np.append(np.zeros(self.exog.shape[1]), 0.5)\n    self.start_params_default[0] = np.log(self.endog.mean())\n    if ll_type == 'nb1':\n        self.ll_func = _ll_nb1\n    elif ll_type == 'nb2':\n        self.ll_func = _ll_nb2\n    elif ll_type == 'geom':\n        self.ll_func = _ll_geom\n    elif ll_type == 'nbp':\n        self.ll_func = _ll_nbp\n    elif ll_type == 'nbt':\n        self.ll_func = _ll_nbt",
            "def __init__(self, endog, exog, ll_type='nb2', C=0, **kwds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.exog = np.array(exog)\n    self.endog = np.array(endog)\n    self.C = C\n    super(NBin, self).__init__(endog, exog, **kwds)\n    if ll_type not in ['nb2', 'nb1', 'nbp', 'nbt', 'geom']:\n        raise NameError('Valid ll_type are: nb2, nb1, nbp,  nbt, geom')\n    self.ll_type = ll_type\n    if ll_type == 'geom':\n        self.start_params_default = np.zeros(self.exog.shape[1])\n    elif ll_type == 'nbp':\n        start_mod = NBin(endog, exog, 'nb2')\n        start_res = start_mod.fit(disp=False)\n        self.start_params_default = np.append(start_res.params, 0)\n    else:\n        self.start_params_default = np.append(np.zeros(self.exog.shape[1]), 0.5)\n    self.start_params_default[0] = np.log(self.endog.mean())\n    if ll_type == 'nb1':\n        self.ll_func = _ll_nb1\n    elif ll_type == 'nb2':\n        self.ll_func = _ll_nb2\n    elif ll_type == 'geom':\n        self.ll_func = _ll_geom\n    elif ll_type == 'nbp':\n        self.ll_func = _ll_nbp\n    elif ll_type == 'nbt':\n        self.ll_func = _ll_nbt",
            "def __init__(self, endog, exog, ll_type='nb2', C=0, **kwds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.exog = np.array(exog)\n    self.endog = np.array(endog)\n    self.C = C\n    super(NBin, self).__init__(endog, exog, **kwds)\n    if ll_type not in ['nb2', 'nb1', 'nbp', 'nbt', 'geom']:\n        raise NameError('Valid ll_type are: nb2, nb1, nbp,  nbt, geom')\n    self.ll_type = ll_type\n    if ll_type == 'geom':\n        self.start_params_default = np.zeros(self.exog.shape[1])\n    elif ll_type == 'nbp':\n        start_mod = NBin(endog, exog, 'nb2')\n        start_res = start_mod.fit(disp=False)\n        self.start_params_default = np.append(start_res.params, 0)\n    else:\n        self.start_params_default = np.append(np.zeros(self.exog.shape[1]), 0.5)\n    self.start_params_default[0] = np.log(self.endog.mean())\n    if ll_type == 'nb1':\n        self.ll_func = _ll_nb1\n    elif ll_type == 'nb2':\n        self.ll_func = _ll_nb2\n    elif ll_type == 'geom':\n        self.ll_func = _ll_geom\n    elif ll_type == 'nbp':\n        self.ll_func = _ll_nbp\n    elif ll_type == 'nbt':\n        self.ll_func = _ll_nbt",
            "def __init__(self, endog, exog, ll_type='nb2', C=0, **kwds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.exog = np.array(exog)\n    self.endog = np.array(endog)\n    self.C = C\n    super(NBin, self).__init__(endog, exog, **kwds)\n    if ll_type not in ['nb2', 'nb1', 'nbp', 'nbt', 'geom']:\n        raise NameError('Valid ll_type are: nb2, nb1, nbp,  nbt, geom')\n    self.ll_type = ll_type\n    if ll_type == 'geom':\n        self.start_params_default = np.zeros(self.exog.shape[1])\n    elif ll_type == 'nbp':\n        start_mod = NBin(endog, exog, 'nb2')\n        start_res = start_mod.fit(disp=False)\n        self.start_params_default = np.append(start_res.params, 0)\n    else:\n        self.start_params_default = np.append(np.zeros(self.exog.shape[1]), 0.5)\n    self.start_params_default[0] = np.log(self.endog.mean())\n    if ll_type == 'nb1':\n        self.ll_func = _ll_nb1\n    elif ll_type == 'nb2':\n        self.ll_func = _ll_nb2\n    elif ll_type == 'geom':\n        self.ll_func = _ll_geom\n    elif ll_type == 'nbp':\n        self.ll_func = _ll_nbp\n    elif ll_type == 'nbt':\n        self.ll_func = _ll_nbt",
            "def __init__(self, endog, exog, ll_type='nb2', C=0, **kwds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.exog = np.array(exog)\n    self.endog = np.array(endog)\n    self.C = C\n    super(NBin, self).__init__(endog, exog, **kwds)\n    if ll_type not in ['nb2', 'nb1', 'nbp', 'nbt', 'geom']:\n        raise NameError('Valid ll_type are: nb2, nb1, nbp,  nbt, geom')\n    self.ll_type = ll_type\n    if ll_type == 'geom':\n        self.start_params_default = np.zeros(self.exog.shape[1])\n    elif ll_type == 'nbp':\n        start_mod = NBin(endog, exog, 'nb2')\n        start_res = start_mod.fit(disp=False)\n        self.start_params_default = np.append(start_res.params, 0)\n    else:\n        self.start_params_default = np.append(np.zeros(self.exog.shape[1]), 0.5)\n    self.start_params_default[0] = np.log(self.endog.mean())\n    if ll_type == 'nb1':\n        self.ll_func = _ll_nb1\n    elif ll_type == 'nb2':\n        self.ll_func = _ll_nb2\n    elif ll_type == 'geom':\n        self.ll_func = _ll_geom\n    elif ll_type == 'nbp':\n        self.ll_func = _ll_nbp\n    elif ll_type == 'nbt':\n        self.ll_func = _ll_nbt"
        ]
    },
    {
        "func_name": "nloglikeobs",
        "original": "def nloglikeobs(self, params):\n    alph = params[-1]\n    beta = params[:self.exog.shape[1]]\n    if self.ll_type == 'geom':\n        return -self.ll_func(self.endog, self.exog, beta)\n    elif self.ll_type == 'nbt':\n        return -self.ll_func(self.endog, self.exog, beta, alph, self.C)\n    elif self.ll_type == 'nbp':\n        Q = params[-2]\n        return -self.ll_func(self.endog, self.exog, beta, alph, Q)\n    else:\n        return -self.ll_func(self.endog, self.exog, beta, alph)",
        "mutated": [
            "def nloglikeobs(self, params):\n    if False:\n        i = 10\n    alph = params[-1]\n    beta = params[:self.exog.shape[1]]\n    if self.ll_type == 'geom':\n        return -self.ll_func(self.endog, self.exog, beta)\n    elif self.ll_type == 'nbt':\n        return -self.ll_func(self.endog, self.exog, beta, alph, self.C)\n    elif self.ll_type == 'nbp':\n        Q = params[-2]\n        return -self.ll_func(self.endog, self.exog, beta, alph, Q)\n    else:\n        return -self.ll_func(self.endog, self.exog, beta, alph)",
            "def nloglikeobs(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    alph = params[-1]\n    beta = params[:self.exog.shape[1]]\n    if self.ll_type == 'geom':\n        return -self.ll_func(self.endog, self.exog, beta)\n    elif self.ll_type == 'nbt':\n        return -self.ll_func(self.endog, self.exog, beta, alph, self.C)\n    elif self.ll_type == 'nbp':\n        Q = params[-2]\n        return -self.ll_func(self.endog, self.exog, beta, alph, Q)\n    else:\n        return -self.ll_func(self.endog, self.exog, beta, alph)",
            "def nloglikeobs(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    alph = params[-1]\n    beta = params[:self.exog.shape[1]]\n    if self.ll_type == 'geom':\n        return -self.ll_func(self.endog, self.exog, beta)\n    elif self.ll_type == 'nbt':\n        return -self.ll_func(self.endog, self.exog, beta, alph, self.C)\n    elif self.ll_type == 'nbp':\n        Q = params[-2]\n        return -self.ll_func(self.endog, self.exog, beta, alph, Q)\n    else:\n        return -self.ll_func(self.endog, self.exog, beta, alph)",
            "def nloglikeobs(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    alph = params[-1]\n    beta = params[:self.exog.shape[1]]\n    if self.ll_type == 'geom':\n        return -self.ll_func(self.endog, self.exog, beta)\n    elif self.ll_type == 'nbt':\n        return -self.ll_func(self.endog, self.exog, beta, alph, self.C)\n    elif self.ll_type == 'nbp':\n        Q = params[-2]\n        return -self.ll_func(self.endog, self.exog, beta, alph, Q)\n    else:\n        return -self.ll_func(self.endog, self.exog, beta, alph)",
            "def nloglikeobs(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    alph = params[-1]\n    beta = params[:self.exog.shape[1]]\n    if self.ll_type == 'geom':\n        return -self.ll_func(self.endog, self.exog, beta)\n    elif self.ll_type == 'nbt':\n        return -self.ll_func(self.endog, self.exog, beta, alph, self.C)\n    elif self.ll_type == 'nbp':\n        Q = params[-2]\n        return -self.ll_func(self.endog, self.exog, beta, alph, Q)\n    else:\n        return -self.ll_func(self.endog, self.exog, beta, alph)"
        ]
    },
    {
        "func_name": "fit",
        "original": "def fit(self, start_params=None, maxiter=10000, maxfun=5000, **kwds):\n    if start_params is None:\n        countfit = super(NBin, self).fit(start_params=self.start_params_default, maxiter=maxiter, maxfun=maxfun, **kwds)\n    else:\n        countfit = super(NBin, self).fit(start_params=start_params, maxiter=maxiter, maxfun=maxfun, **kwds)\n    countfit = CountResults(self, countfit)\n    return countfit",
        "mutated": [
            "def fit(self, start_params=None, maxiter=10000, maxfun=5000, **kwds):\n    if False:\n        i = 10\n    if start_params is None:\n        countfit = super(NBin, self).fit(start_params=self.start_params_default, maxiter=maxiter, maxfun=maxfun, **kwds)\n    else:\n        countfit = super(NBin, self).fit(start_params=start_params, maxiter=maxiter, maxfun=maxfun, **kwds)\n    countfit = CountResults(self, countfit)\n    return countfit",
            "def fit(self, start_params=None, maxiter=10000, maxfun=5000, **kwds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if start_params is None:\n        countfit = super(NBin, self).fit(start_params=self.start_params_default, maxiter=maxiter, maxfun=maxfun, **kwds)\n    else:\n        countfit = super(NBin, self).fit(start_params=start_params, maxiter=maxiter, maxfun=maxfun, **kwds)\n    countfit = CountResults(self, countfit)\n    return countfit",
            "def fit(self, start_params=None, maxiter=10000, maxfun=5000, **kwds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if start_params is None:\n        countfit = super(NBin, self).fit(start_params=self.start_params_default, maxiter=maxiter, maxfun=maxfun, **kwds)\n    else:\n        countfit = super(NBin, self).fit(start_params=start_params, maxiter=maxiter, maxfun=maxfun, **kwds)\n    countfit = CountResults(self, countfit)\n    return countfit",
            "def fit(self, start_params=None, maxiter=10000, maxfun=5000, **kwds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if start_params is None:\n        countfit = super(NBin, self).fit(start_params=self.start_params_default, maxiter=maxiter, maxfun=maxfun, **kwds)\n    else:\n        countfit = super(NBin, self).fit(start_params=start_params, maxiter=maxiter, maxfun=maxfun, **kwds)\n    countfit = CountResults(self, countfit)\n    return countfit",
            "def fit(self, start_params=None, maxiter=10000, maxfun=5000, **kwds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if start_params is None:\n        countfit = super(NBin, self).fit(start_params=self.start_params_default, maxiter=maxiter, maxfun=maxfun, **kwds)\n    else:\n        countfit = super(NBin, self).fit(start_params=start_params, maxiter=maxiter, maxfun=maxfun, **kwds)\n    countfit = CountResults(self, countfit)\n    return countfit"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, model, mlefit):\n    self.model = model\n    self.__dict__.update(mlefit.__dict__)",
        "mutated": [
            "def __init__(self, model, mlefit):\n    if False:\n        i = 10\n    self.model = model\n    self.__dict__.update(mlefit.__dict__)",
            "def __init__(self, model, mlefit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.model = model\n    self.__dict__.update(mlefit.__dict__)",
            "def __init__(self, model, mlefit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.model = model\n    self.__dict__.update(mlefit.__dict__)",
            "def __init__(self, model, mlefit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.model = model\n    self.__dict__.update(mlefit.__dict__)",
            "def __init__(self, model, mlefit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.model = model\n    self.__dict__.update(mlefit.__dict__)"
        ]
    },
    {
        "func_name": "summary",
        "original": "def summary(self, yname=None, xname=None, title=None, alpha=0.05, yname_list=None):\n    top_left = [('Dep. Variable:', None), ('Model:', [self.model.__class__.__name__]), ('Method:', ['MLE']), ('Date:', None), ('Time:', None), ('Converged:', ['%s' % self.mle_retvals['converged']])]\n    top_right = [('No. Observations:', None), ('Log-Likelihood:', None)]\n    if title is None:\n        title = self.model.__class__.__name__ + ' ' + 'Regression Results'\n    from statsmodels.iolib.summary import Summary\n    smry = Summary()\n    smry.add_table_2cols(self, gleft=top_left, gright=top_right, yname=yname, xname=xname, title=title)\n    smry.add_table_params(self, yname=yname_list, xname=xname, alpha=alpha, use_t=True)\n    return smry",
        "mutated": [
            "def summary(self, yname=None, xname=None, title=None, alpha=0.05, yname_list=None):\n    if False:\n        i = 10\n    top_left = [('Dep. Variable:', None), ('Model:', [self.model.__class__.__name__]), ('Method:', ['MLE']), ('Date:', None), ('Time:', None), ('Converged:', ['%s' % self.mle_retvals['converged']])]\n    top_right = [('No. Observations:', None), ('Log-Likelihood:', None)]\n    if title is None:\n        title = self.model.__class__.__name__ + ' ' + 'Regression Results'\n    from statsmodels.iolib.summary import Summary\n    smry = Summary()\n    smry.add_table_2cols(self, gleft=top_left, gright=top_right, yname=yname, xname=xname, title=title)\n    smry.add_table_params(self, yname=yname_list, xname=xname, alpha=alpha, use_t=True)\n    return smry",
            "def summary(self, yname=None, xname=None, title=None, alpha=0.05, yname_list=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    top_left = [('Dep. Variable:', None), ('Model:', [self.model.__class__.__name__]), ('Method:', ['MLE']), ('Date:', None), ('Time:', None), ('Converged:', ['%s' % self.mle_retvals['converged']])]\n    top_right = [('No. Observations:', None), ('Log-Likelihood:', None)]\n    if title is None:\n        title = self.model.__class__.__name__ + ' ' + 'Regression Results'\n    from statsmodels.iolib.summary import Summary\n    smry = Summary()\n    smry.add_table_2cols(self, gleft=top_left, gright=top_right, yname=yname, xname=xname, title=title)\n    smry.add_table_params(self, yname=yname_list, xname=xname, alpha=alpha, use_t=True)\n    return smry",
            "def summary(self, yname=None, xname=None, title=None, alpha=0.05, yname_list=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    top_left = [('Dep. Variable:', None), ('Model:', [self.model.__class__.__name__]), ('Method:', ['MLE']), ('Date:', None), ('Time:', None), ('Converged:', ['%s' % self.mle_retvals['converged']])]\n    top_right = [('No. Observations:', None), ('Log-Likelihood:', None)]\n    if title is None:\n        title = self.model.__class__.__name__ + ' ' + 'Regression Results'\n    from statsmodels.iolib.summary import Summary\n    smry = Summary()\n    smry.add_table_2cols(self, gleft=top_left, gright=top_right, yname=yname, xname=xname, title=title)\n    smry.add_table_params(self, yname=yname_list, xname=xname, alpha=alpha, use_t=True)\n    return smry",
            "def summary(self, yname=None, xname=None, title=None, alpha=0.05, yname_list=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    top_left = [('Dep. Variable:', None), ('Model:', [self.model.__class__.__name__]), ('Method:', ['MLE']), ('Date:', None), ('Time:', None), ('Converged:', ['%s' % self.mle_retvals['converged']])]\n    top_right = [('No. Observations:', None), ('Log-Likelihood:', None)]\n    if title is None:\n        title = self.model.__class__.__name__ + ' ' + 'Regression Results'\n    from statsmodels.iolib.summary import Summary\n    smry = Summary()\n    smry.add_table_2cols(self, gleft=top_left, gright=top_right, yname=yname, xname=xname, title=title)\n    smry.add_table_params(self, yname=yname_list, xname=xname, alpha=alpha, use_t=True)\n    return smry",
            "def summary(self, yname=None, xname=None, title=None, alpha=0.05, yname_list=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    top_left = [('Dep. Variable:', None), ('Model:', [self.model.__class__.__name__]), ('Method:', ['MLE']), ('Date:', None), ('Time:', None), ('Converged:', ['%s' % self.mle_retvals['converged']])]\n    top_right = [('No. Observations:', None), ('Log-Likelihood:', None)]\n    if title is None:\n        title = self.model.__class__.__name__ + ' ' + 'Regression Results'\n    from statsmodels.iolib.summary import Summary\n    smry = Summary()\n    smry.add_table_2cols(self, gleft=top_left, gright=top_right, yname=yname, xname=xname, title=title)\n    smry.add_table_params(self, yname=yname_list, xname=xname, alpha=alpha, use_t=True)\n    return smry"
        ]
    },
    {
        "func_name": "_score_nbp",
        "original": "def _score_nbp(y, X, beta, thet, Q):\n    \"\"\"\n    Negative Binomial Score -- type P likelihood from Greene (2007)\n    .. math::\n\n        \\\\lambda_i = exp(X\\\\beta)\\\\\\\\\n        g_i = \\\\theta \\\\lambda_i^Q \\\\\\\\\n        w_i = g_i/(g_i + \\\\lambda_i) \\\\\\\\\n        r_i = \\\\theta / (\\\\theta+\\\\lambda_i) \\\\\\\\\n        A_i = \\\\left [ \\\\Psi(y_i+g_i) - \\\\Psi(g_i) + ln w_i \\\\right ] \\\\\\\\\n        B_i = \\\\left [ g_i (1-w_i) - y_iw_i \\\\right ] \\\\\\\\\n        \\\\partial ln \\\\mathcal{L}_i / \\\\partial\n            \\\\begin{pmatrix} \\\\lambda_i \\\\\\\\ \\\\theta \\\\\\\\ Q \\\\end{pmatrix}=\n            [A_i+B_i]\n            \\\\begin{pmatrix} Q/\\\\lambda_i \\\\\\\\ 1/\\\\theta \\\\\\\\ ln(\\\\lambda_i) \\\\end{pmatrix}\n            -B_i\n            \\\\begin{pmatrix} 1/\\\\lambda_i\\\\\\\\ 0 \\\\\\\\ 0 \\\\end{pmatrix} \\\\\\\\\n        \\\\frac{\\\\partial \\\\lambda}{\\\\partial \\\\beta} = \\\\lambda_i \\\\mathbf{x}_i \\\\\\\\\n        \\\\frac{\\\\partial \\\\mathcal{L}_i}{\\\\partial \\\\beta} =\n            \\\\left (\\\\frac{\\\\partial\\\\mathcal{L}_i}{\\\\partial \\\\lambda_i} \\\\right )\n            \\\\frac{\\\\partial \\\\lambda_i}{\\\\partial \\\\beta}\n    \"\"\"\n    lamb = np.exp(np.dot(X, beta))\n    g = thet * lamb ** Q\n    w = g / (g + lamb)\n    r = thet / (thet + lamb)\n    A = digamma(y + g) - digamma(g) + np.log(w)\n    B = g * (1 - w) - y * w\n    dl = (A + B) * Q / lamb - B * 1 / lamb\n    dt = (A + B) * 1 / thet\n    dq = (A + B) * np.log(lamb)\n    db = X * (dl * lamb)[:, np.newaxis]\n    sc = np.array([dt.sum(), dq.sum()])\n    sc = np.concatenate([db.sum(axis=0), sc])\n    return sc",
        "mutated": [
            "def _score_nbp(y, X, beta, thet, Q):\n    if False:\n        i = 10\n    '\\n    Negative Binomial Score -- type P likelihood from Greene (2007)\\n    .. math::\\n\\n        \\\\lambda_i = exp(X\\\\beta)\\\\\\\\\\n        g_i = \\\\theta \\\\lambda_i^Q \\\\\\\\\\n        w_i = g_i/(g_i + \\\\lambda_i) \\\\\\\\\\n        r_i = \\\\theta / (\\\\theta+\\\\lambda_i) \\\\\\\\\\n        A_i = \\\\left [ \\\\Psi(y_i+g_i) - \\\\Psi(g_i) + ln w_i \\\\right ] \\\\\\\\\\n        B_i = \\\\left [ g_i (1-w_i) - y_iw_i \\\\right ] \\\\\\\\\\n        \\\\partial ln \\\\mathcal{L}_i / \\\\partial\\n            \\\\begin{pmatrix} \\\\lambda_i \\\\\\\\ \\\\theta \\\\\\\\ Q \\\\end{pmatrix}=\\n            [A_i+B_i]\\n            \\\\begin{pmatrix} Q/\\\\lambda_i \\\\\\\\ 1/\\\\theta \\\\\\\\ ln(\\\\lambda_i) \\\\end{pmatrix}\\n            -B_i\\n            \\\\begin{pmatrix} 1/\\\\lambda_i\\\\\\\\ 0 \\\\\\\\ 0 \\\\end{pmatrix} \\\\\\\\\\n        \\\\frac{\\\\partial \\\\lambda}{\\\\partial \\\\beta} = \\\\lambda_i \\\\mathbf{x}_i \\\\\\\\\\n        \\\\frac{\\\\partial \\\\mathcal{L}_i}{\\\\partial \\\\beta} =\\n            \\\\left (\\\\frac{\\\\partial\\\\mathcal{L}_i}{\\\\partial \\\\lambda_i} \\\\right )\\n            \\\\frac{\\\\partial \\\\lambda_i}{\\\\partial \\\\beta}\\n    '\n    lamb = np.exp(np.dot(X, beta))\n    g = thet * lamb ** Q\n    w = g / (g + lamb)\n    r = thet / (thet + lamb)\n    A = digamma(y + g) - digamma(g) + np.log(w)\n    B = g * (1 - w) - y * w\n    dl = (A + B) * Q / lamb - B * 1 / lamb\n    dt = (A + B) * 1 / thet\n    dq = (A + B) * np.log(lamb)\n    db = X * (dl * lamb)[:, np.newaxis]\n    sc = np.array([dt.sum(), dq.sum()])\n    sc = np.concatenate([db.sum(axis=0), sc])\n    return sc",
            "def _score_nbp(y, X, beta, thet, Q):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Negative Binomial Score -- type P likelihood from Greene (2007)\\n    .. math::\\n\\n        \\\\lambda_i = exp(X\\\\beta)\\\\\\\\\\n        g_i = \\\\theta \\\\lambda_i^Q \\\\\\\\\\n        w_i = g_i/(g_i + \\\\lambda_i) \\\\\\\\\\n        r_i = \\\\theta / (\\\\theta+\\\\lambda_i) \\\\\\\\\\n        A_i = \\\\left [ \\\\Psi(y_i+g_i) - \\\\Psi(g_i) + ln w_i \\\\right ] \\\\\\\\\\n        B_i = \\\\left [ g_i (1-w_i) - y_iw_i \\\\right ] \\\\\\\\\\n        \\\\partial ln \\\\mathcal{L}_i / \\\\partial\\n            \\\\begin{pmatrix} \\\\lambda_i \\\\\\\\ \\\\theta \\\\\\\\ Q \\\\end{pmatrix}=\\n            [A_i+B_i]\\n            \\\\begin{pmatrix} Q/\\\\lambda_i \\\\\\\\ 1/\\\\theta \\\\\\\\ ln(\\\\lambda_i) \\\\end{pmatrix}\\n            -B_i\\n            \\\\begin{pmatrix} 1/\\\\lambda_i\\\\\\\\ 0 \\\\\\\\ 0 \\\\end{pmatrix} \\\\\\\\\\n        \\\\frac{\\\\partial \\\\lambda}{\\\\partial \\\\beta} = \\\\lambda_i \\\\mathbf{x}_i \\\\\\\\\\n        \\\\frac{\\\\partial \\\\mathcal{L}_i}{\\\\partial \\\\beta} =\\n            \\\\left (\\\\frac{\\\\partial\\\\mathcal{L}_i}{\\\\partial \\\\lambda_i} \\\\right )\\n            \\\\frac{\\\\partial \\\\lambda_i}{\\\\partial \\\\beta}\\n    '\n    lamb = np.exp(np.dot(X, beta))\n    g = thet * lamb ** Q\n    w = g / (g + lamb)\n    r = thet / (thet + lamb)\n    A = digamma(y + g) - digamma(g) + np.log(w)\n    B = g * (1 - w) - y * w\n    dl = (A + B) * Q / lamb - B * 1 / lamb\n    dt = (A + B) * 1 / thet\n    dq = (A + B) * np.log(lamb)\n    db = X * (dl * lamb)[:, np.newaxis]\n    sc = np.array([dt.sum(), dq.sum()])\n    sc = np.concatenate([db.sum(axis=0), sc])\n    return sc",
            "def _score_nbp(y, X, beta, thet, Q):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Negative Binomial Score -- type P likelihood from Greene (2007)\\n    .. math::\\n\\n        \\\\lambda_i = exp(X\\\\beta)\\\\\\\\\\n        g_i = \\\\theta \\\\lambda_i^Q \\\\\\\\\\n        w_i = g_i/(g_i + \\\\lambda_i) \\\\\\\\\\n        r_i = \\\\theta / (\\\\theta+\\\\lambda_i) \\\\\\\\\\n        A_i = \\\\left [ \\\\Psi(y_i+g_i) - \\\\Psi(g_i) + ln w_i \\\\right ] \\\\\\\\\\n        B_i = \\\\left [ g_i (1-w_i) - y_iw_i \\\\right ] \\\\\\\\\\n        \\\\partial ln \\\\mathcal{L}_i / \\\\partial\\n            \\\\begin{pmatrix} \\\\lambda_i \\\\\\\\ \\\\theta \\\\\\\\ Q \\\\end{pmatrix}=\\n            [A_i+B_i]\\n            \\\\begin{pmatrix} Q/\\\\lambda_i \\\\\\\\ 1/\\\\theta \\\\\\\\ ln(\\\\lambda_i) \\\\end{pmatrix}\\n            -B_i\\n            \\\\begin{pmatrix} 1/\\\\lambda_i\\\\\\\\ 0 \\\\\\\\ 0 \\\\end{pmatrix} \\\\\\\\\\n        \\\\frac{\\\\partial \\\\lambda}{\\\\partial \\\\beta} = \\\\lambda_i \\\\mathbf{x}_i \\\\\\\\\\n        \\\\frac{\\\\partial \\\\mathcal{L}_i}{\\\\partial \\\\beta} =\\n            \\\\left (\\\\frac{\\\\partial\\\\mathcal{L}_i}{\\\\partial \\\\lambda_i} \\\\right )\\n            \\\\frac{\\\\partial \\\\lambda_i}{\\\\partial \\\\beta}\\n    '\n    lamb = np.exp(np.dot(X, beta))\n    g = thet * lamb ** Q\n    w = g / (g + lamb)\n    r = thet / (thet + lamb)\n    A = digamma(y + g) - digamma(g) + np.log(w)\n    B = g * (1 - w) - y * w\n    dl = (A + B) * Q / lamb - B * 1 / lamb\n    dt = (A + B) * 1 / thet\n    dq = (A + B) * np.log(lamb)\n    db = X * (dl * lamb)[:, np.newaxis]\n    sc = np.array([dt.sum(), dq.sum()])\n    sc = np.concatenate([db.sum(axis=0), sc])\n    return sc",
            "def _score_nbp(y, X, beta, thet, Q):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Negative Binomial Score -- type P likelihood from Greene (2007)\\n    .. math::\\n\\n        \\\\lambda_i = exp(X\\\\beta)\\\\\\\\\\n        g_i = \\\\theta \\\\lambda_i^Q \\\\\\\\\\n        w_i = g_i/(g_i + \\\\lambda_i) \\\\\\\\\\n        r_i = \\\\theta / (\\\\theta+\\\\lambda_i) \\\\\\\\\\n        A_i = \\\\left [ \\\\Psi(y_i+g_i) - \\\\Psi(g_i) + ln w_i \\\\right ] \\\\\\\\\\n        B_i = \\\\left [ g_i (1-w_i) - y_iw_i \\\\right ] \\\\\\\\\\n        \\\\partial ln \\\\mathcal{L}_i / \\\\partial\\n            \\\\begin{pmatrix} \\\\lambda_i \\\\\\\\ \\\\theta \\\\\\\\ Q \\\\end{pmatrix}=\\n            [A_i+B_i]\\n            \\\\begin{pmatrix} Q/\\\\lambda_i \\\\\\\\ 1/\\\\theta \\\\\\\\ ln(\\\\lambda_i) \\\\end{pmatrix}\\n            -B_i\\n            \\\\begin{pmatrix} 1/\\\\lambda_i\\\\\\\\ 0 \\\\\\\\ 0 \\\\end{pmatrix} \\\\\\\\\\n        \\\\frac{\\\\partial \\\\lambda}{\\\\partial \\\\beta} = \\\\lambda_i \\\\mathbf{x}_i \\\\\\\\\\n        \\\\frac{\\\\partial \\\\mathcal{L}_i}{\\\\partial \\\\beta} =\\n            \\\\left (\\\\frac{\\\\partial\\\\mathcal{L}_i}{\\\\partial \\\\lambda_i} \\\\right )\\n            \\\\frac{\\\\partial \\\\lambda_i}{\\\\partial \\\\beta}\\n    '\n    lamb = np.exp(np.dot(X, beta))\n    g = thet * lamb ** Q\n    w = g / (g + lamb)\n    r = thet / (thet + lamb)\n    A = digamma(y + g) - digamma(g) + np.log(w)\n    B = g * (1 - w) - y * w\n    dl = (A + B) * Q / lamb - B * 1 / lamb\n    dt = (A + B) * 1 / thet\n    dq = (A + B) * np.log(lamb)\n    db = X * (dl * lamb)[:, np.newaxis]\n    sc = np.array([dt.sum(), dq.sum()])\n    sc = np.concatenate([db.sum(axis=0), sc])\n    return sc",
            "def _score_nbp(y, X, beta, thet, Q):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Negative Binomial Score -- type P likelihood from Greene (2007)\\n    .. math::\\n\\n        \\\\lambda_i = exp(X\\\\beta)\\\\\\\\\\n        g_i = \\\\theta \\\\lambda_i^Q \\\\\\\\\\n        w_i = g_i/(g_i + \\\\lambda_i) \\\\\\\\\\n        r_i = \\\\theta / (\\\\theta+\\\\lambda_i) \\\\\\\\\\n        A_i = \\\\left [ \\\\Psi(y_i+g_i) - \\\\Psi(g_i) + ln w_i \\\\right ] \\\\\\\\\\n        B_i = \\\\left [ g_i (1-w_i) - y_iw_i \\\\right ] \\\\\\\\\\n        \\\\partial ln \\\\mathcal{L}_i / \\\\partial\\n            \\\\begin{pmatrix} \\\\lambda_i \\\\\\\\ \\\\theta \\\\\\\\ Q \\\\end{pmatrix}=\\n            [A_i+B_i]\\n            \\\\begin{pmatrix} Q/\\\\lambda_i \\\\\\\\ 1/\\\\theta \\\\\\\\ ln(\\\\lambda_i) \\\\end{pmatrix}\\n            -B_i\\n            \\\\begin{pmatrix} 1/\\\\lambda_i\\\\\\\\ 0 \\\\\\\\ 0 \\\\end{pmatrix} \\\\\\\\\\n        \\\\frac{\\\\partial \\\\lambda}{\\\\partial \\\\beta} = \\\\lambda_i \\\\mathbf{x}_i \\\\\\\\\\n        \\\\frac{\\\\partial \\\\mathcal{L}_i}{\\\\partial \\\\beta} =\\n            \\\\left (\\\\frac{\\\\partial\\\\mathcal{L}_i}{\\\\partial \\\\lambda_i} \\\\right )\\n            \\\\frac{\\\\partial \\\\lambda_i}{\\\\partial \\\\beta}\\n    '\n    lamb = np.exp(np.dot(X, beta))\n    g = thet * lamb ** Q\n    w = g / (g + lamb)\n    r = thet / (thet + lamb)\n    A = digamma(y + g) - digamma(g) + np.log(w)\n    B = g * (1 - w) - y * w\n    dl = (A + B) * Q / lamb - B * 1 / lamb\n    dt = (A + B) * 1 / thet\n    dq = (A + B) * np.log(lamb)\n    db = X * (dl * lamb)[:, np.newaxis]\n    sc = np.array([dt.sum(), dq.sum()])\n    sc = np.concatenate([db.sum(axis=0), sc])\n    return sc"
        ]
    },
    {
        "func_name": "test_nb2",
        "original": "def test_nb2():\n    (y, X) = patsy.dmatrices('los ~ C(type) + hmo + white', medpar)\n    y = np.array(y)[:, 0]\n    nb2 = NBin(y, X, 'nb2').fit(maxiter=10000, maxfun=5000)\n    assert_almost_equal(nb2.params, [2.31027893349935, 0.221248978197356, 0.706158824346228, -0.067955221930748, -0.129065442248951, 0.4457567], decimal=2)",
        "mutated": [
            "def test_nb2():\n    if False:\n        i = 10\n    (y, X) = patsy.dmatrices('los ~ C(type) + hmo + white', medpar)\n    y = np.array(y)[:, 0]\n    nb2 = NBin(y, X, 'nb2').fit(maxiter=10000, maxfun=5000)\n    assert_almost_equal(nb2.params, [2.31027893349935, 0.221248978197356, 0.706158824346228, -0.067955221930748, -0.129065442248951, 0.4457567], decimal=2)",
            "def test_nb2():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (y, X) = patsy.dmatrices('los ~ C(type) + hmo + white', medpar)\n    y = np.array(y)[:, 0]\n    nb2 = NBin(y, X, 'nb2').fit(maxiter=10000, maxfun=5000)\n    assert_almost_equal(nb2.params, [2.31027893349935, 0.221248978197356, 0.706158824346228, -0.067955221930748, -0.129065442248951, 0.4457567], decimal=2)",
            "def test_nb2():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (y, X) = patsy.dmatrices('los ~ C(type) + hmo + white', medpar)\n    y = np.array(y)[:, 0]\n    nb2 = NBin(y, X, 'nb2').fit(maxiter=10000, maxfun=5000)\n    assert_almost_equal(nb2.params, [2.31027893349935, 0.221248978197356, 0.706158824346228, -0.067955221930748, -0.129065442248951, 0.4457567], decimal=2)",
            "def test_nb2():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (y, X) = patsy.dmatrices('los ~ C(type) + hmo + white', medpar)\n    y = np.array(y)[:, 0]\n    nb2 = NBin(y, X, 'nb2').fit(maxiter=10000, maxfun=5000)\n    assert_almost_equal(nb2.params, [2.31027893349935, 0.221248978197356, 0.706158824346228, -0.067955221930748, -0.129065442248951, 0.4457567], decimal=2)",
            "def test_nb2():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (y, X) = patsy.dmatrices('los ~ C(type) + hmo + white', medpar)\n    y = np.array(y)[:, 0]\n    nb2 = NBin(y, X, 'nb2').fit(maxiter=10000, maxfun=5000)\n    assert_almost_equal(nb2.params, [2.31027893349935, 0.221248978197356, 0.706158824346228, -0.067955221930748, -0.129065442248951, 0.4457567], decimal=2)"
        ]
    }
]