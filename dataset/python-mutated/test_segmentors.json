[
    {
        "func_name": "_get_config_directory",
        "original": "def _get_config_directory():\n    \"\"\"Find the predefined detector config directory.\"\"\"\n    try:\n        repo_dpath = dirname(dirname(dirname(__file__)))\n    except NameError:\n        import mmdet3d\n        repo_dpath = dirname(dirname(mmdet3d.__file__))\n    config_dpath = join(repo_dpath, 'configs')\n    if not exists(config_dpath):\n        raise Exception('Cannot find config path')\n    return config_dpath",
        "mutated": [
            "def _get_config_directory():\n    if False:\n        i = 10\n    'Find the predefined detector config directory.'\n    try:\n        repo_dpath = dirname(dirname(dirname(__file__)))\n    except NameError:\n        import mmdet3d\n        repo_dpath = dirname(dirname(mmdet3d.__file__))\n    config_dpath = join(repo_dpath, 'configs')\n    if not exists(config_dpath):\n        raise Exception('Cannot find config path')\n    return config_dpath",
            "def _get_config_directory():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Find the predefined detector config directory.'\n    try:\n        repo_dpath = dirname(dirname(dirname(__file__)))\n    except NameError:\n        import mmdet3d\n        repo_dpath = dirname(dirname(mmdet3d.__file__))\n    config_dpath = join(repo_dpath, 'configs')\n    if not exists(config_dpath):\n        raise Exception('Cannot find config path')\n    return config_dpath",
            "def _get_config_directory():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Find the predefined detector config directory.'\n    try:\n        repo_dpath = dirname(dirname(dirname(__file__)))\n    except NameError:\n        import mmdet3d\n        repo_dpath = dirname(dirname(mmdet3d.__file__))\n    config_dpath = join(repo_dpath, 'configs')\n    if not exists(config_dpath):\n        raise Exception('Cannot find config path')\n    return config_dpath",
            "def _get_config_directory():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Find the predefined detector config directory.'\n    try:\n        repo_dpath = dirname(dirname(dirname(__file__)))\n    except NameError:\n        import mmdet3d\n        repo_dpath = dirname(dirname(mmdet3d.__file__))\n    config_dpath = join(repo_dpath, 'configs')\n    if not exists(config_dpath):\n        raise Exception('Cannot find config path')\n    return config_dpath",
            "def _get_config_directory():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Find the predefined detector config directory.'\n    try:\n        repo_dpath = dirname(dirname(dirname(__file__)))\n    except NameError:\n        import mmdet3d\n        repo_dpath = dirname(dirname(mmdet3d.__file__))\n    config_dpath = join(repo_dpath, 'configs')\n    if not exists(config_dpath):\n        raise Exception('Cannot find config path')\n    return config_dpath"
        ]
    },
    {
        "func_name": "_get_config_module",
        "original": "def _get_config_module(fname):\n    \"\"\"Load a configuration as a python module.\"\"\"\n    from mmcv import Config\n    config_dpath = _get_config_directory()\n    config_fpath = join(config_dpath, fname)\n    config_mod = Config.fromfile(config_fpath)\n    return config_mod",
        "mutated": [
            "def _get_config_module(fname):\n    if False:\n        i = 10\n    'Load a configuration as a python module.'\n    from mmcv import Config\n    config_dpath = _get_config_directory()\n    config_fpath = join(config_dpath, fname)\n    config_mod = Config.fromfile(config_fpath)\n    return config_mod",
            "def _get_config_module(fname):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Load a configuration as a python module.'\n    from mmcv import Config\n    config_dpath = _get_config_directory()\n    config_fpath = join(config_dpath, fname)\n    config_mod = Config.fromfile(config_fpath)\n    return config_mod",
            "def _get_config_module(fname):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Load a configuration as a python module.'\n    from mmcv import Config\n    config_dpath = _get_config_directory()\n    config_fpath = join(config_dpath, fname)\n    config_mod = Config.fromfile(config_fpath)\n    return config_mod",
            "def _get_config_module(fname):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Load a configuration as a python module.'\n    from mmcv import Config\n    config_dpath = _get_config_directory()\n    config_fpath = join(config_dpath, fname)\n    config_mod = Config.fromfile(config_fpath)\n    return config_mod",
            "def _get_config_module(fname):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Load a configuration as a python module.'\n    from mmcv import Config\n    config_dpath = _get_config_directory()\n    config_fpath = join(config_dpath, fname)\n    config_mod = Config.fromfile(config_fpath)\n    return config_mod"
        ]
    },
    {
        "func_name": "_get_segmentor_cfg",
        "original": "def _get_segmentor_cfg(fname):\n    \"\"\"Grab configs necessary to create a segmentor.\n\n    These are deep copied to allow for safe modification of parameters without\n    influencing other tests.\n    \"\"\"\n    import mmcv\n    config = _get_config_module(fname)\n    model = copy.deepcopy(config.model)\n    train_cfg = mmcv.Config(copy.deepcopy(config.model.train_cfg))\n    test_cfg = mmcv.Config(copy.deepcopy(config.model.test_cfg))\n    model.update(train_cfg=train_cfg)\n    model.update(test_cfg=test_cfg)\n    return model",
        "mutated": [
            "def _get_segmentor_cfg(fname):\n    if False:\n        i = 10\n    'Grab configs necessary to create a segmentor.\\n\\n    These are deep copied to allow for safe modification of parameters without\\n    influencing other tests.\\n    '\n    import mmcv\n    config = _get_config_module(fname)\n    model = copy.deepcopy(config.model)\n    train_cfg = mmcv.Config(copy.deepcopy(config.model.train_cfg))\n    test_cfg = mmcv.Config(copy.deepcopy(config.model.test_cfg))\n    model.update(train_cfg=train_cfg)\n    model.update(test_cfg=test_cfg)\n    return model",
            "def _get_segmentor_cfg(fname):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Grab configs necessary to create a segmentor.\\n\\n    These are deep copied to allow for safe modification of parameters without\\n    influencing other tests.\\n    '\n    import mmcv\n    config = _get_config_module(fname)\n    model = copy.deepcopy(config.model)\n    train_cfg = mmcv.Config(copy.deepcopy(config.model.train_cfg))\n    test_cfg = mmcv.Config(copy.deepcopy(config.model.test_cfg))\n    model.update(train_cfg=train_cfg)\n    model.update(test_cfg=test_cfg)\n    return model",
            "def _get_segmentor_cfg(fname):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Grab configs necessary to create a segmentor.\\n\\n    These are deep copied to allow for safe modification of parameters without\\n    influencing other tests.\\n    '\n    import mmcv\n    config = _get_config_module(fname)\n    model = copy.deepcopy(config.model)\n    train_cfg = mmcv.Config(copy.deepcopy(config.model.train_cfg))\n    test_cfg = mmcv.Config(copy.deepcopy(config.model.test_cfg))\n    model.update(train_cfg=train_cfg)\n    model.update(test_cfg=test_cfg)\n    return model",
            "def _get_segmentor_cfg(fname):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Grab configs necessary to create a segmentor.\\n\\n    These are deep copied to allow for safe modification of parameters without\\n    influencing other tests.\\n    '\n    import mmcv\n    config = _get_config_module(fname)\n    model = copy.deepcopy(config.model)\n    train_cfg = mmcv.Config(copy.deepcopy(config.model.train_cfg))\n    test_cfg = mmcv.Config(copy.deepcopy(config.model.test_cfg))\n    model.update(train_cfg=train_cfg)\n    model.update(test_cfg=test_cfg)\n    return model",
            "def _get_segmentor_cfg(fname):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Grab configs necessary to create a segmentor.\\n\\n    These are deep copied to allow for safe modification of parameters without\\n    influencing other tests.\\n    '\n    import mmcv\n    config = _get_config_module(fname)\n    model = copy.deepcopy(config.model)\n    train_cfg = mmcv.Config(copy.deepcopy(config.model.train_cfg))\n    test_cfg = mmcv.Config(copy.deepcopy(config.model.test_cfg))\n    model.update(train_cfg=train_cfg)\n    model.update(test_cfg=test_cfg)\n    return model"
        ]
    },
    {
        "func_name": "test_pointnet2_ssg",
        "original": "def test_pointnet2_ssg():\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    pn2_ssg_cfg = _get_segmentor_cfg('pointnet2/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-20class.py')\n    pn2_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(pn2_ssg_cfg).cuda()\n    points = [torch.rand(1024, 6).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 20, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 20 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])",
        "mutated": [
            "def test_pointnet2_ssg():\n    if False:\n        i = 10\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    pn2_ssg_cfg = _get_segmentor_cfg('pointnet2/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-20class.py')\n    pn2_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(pn2_ssg_cfg).cuda()\n    points = [torch.rand(1024, 6).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 20, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 20 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])",
            "def test_pointnet2_ssg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    pn2_ssg_cfg = _get_segmentor_cfg('pointnet2/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-20class.py')\n    pn2_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(pn2_ssg_cfg).cuda()\n    points = [torch.rand(1024, 6).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 20, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 20 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])",
            "def test_pointnet2_ssg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    pn2_ssg_cfg = _get_segmentor_cfg('pointnet2/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-20class.py')\n    pn2_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(pn2_ssg_cfg).cuda()\n    points = [torch.rand(1024, 6).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 20, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 20 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])",
            "def test_pointnet2_ssg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    pn2_ssg_cfg = _get_segmentor_cfg('pointnet2/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-20class.py')\n    pn2_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(pn2_ssg_cfg).cuda()\n    points = [torch.rand(1024, 6).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 20, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 20 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])",
            "def test_pointnet2_ssg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    pn2_ssg_cfg = _get_segmentor_cfg('pointnet2/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-20class.py')\n    pn2_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(pn2_ssg_cfg).cuda()\n    points = [torch.rand(1024, 6).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 20, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 20 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])"
        ]
    },
    {
        "func_name": "test_pointnet2_msg",
        "original": "def test_pointnet2_msg():\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    pn2_msg_cfg = _get_segmentor_cfg('pointnet2/pointnet2_msg_16x2_cosine_250e_scannet_seg-3d-20class.py')\n    pn2_msg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(pn2_msg_cfg).cuda()\n    points = [torch.rand(1024, 6).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 20, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 20 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])",
        "mutated": [
            "def test_pointnet2_msg():\n    if False:\n        i = 10\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    pn2_msg_cfg = _get_segmentor_cfg('pointnet2/pointnet2_msg_16x2_cosine_250e_scannet_seg-3d-20class.py')\n    pn2_msg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(pn2_msg_cfg).cuda()\n    points = [torch.rand(1024, 6).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 20, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 20 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])",
            "def test_pointnet2_msg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    pn2_msg_cfg = _get_segmentor_cfg('pointnet2/pointnet2_msg_16x2_cosine_250e_scannet_seg-3d-20class.py')\n    pn2_msg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(pn2_msg_cfg).cuda()\n    points = [torch.rand(1024, 6).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 20, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 20 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])",
            "def test_pointnet2_msg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    pn2_msg_cfg = _get_segmentor_cfg('pointnet2/pointnet2_msg_16x2_cosine_250e_scannet_seg-3d-20class.py')\n    pn2_msg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(pn2_msg_cfg).cuda()\n    points = [torch.rand(1024, 6).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 20, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 20 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])",
            "def test_pointnet2_msg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    pn2_msg_cfg = _get_segmentor_cfg('pointnet2/pointnet2_msg_16x2_cosine_250e_scannet_seg-3d-20class.py')\n    pn2_msg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(pn2_msg_cfg).cuda()\n    points = [torch.rand(1024, 6).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 20, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 20 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])",
            "def test_pointnet2_msg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    pn2_msg_cfg = _get_segmentor_cfg('pointnet2/pointnet2_msg_16x2_cosine_250e_scannet_seg-3d-20class.py')\n    pn2_msg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(pn2_msg_cfg).cuda()\n    points = [torch.rand(1024, 6).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 20, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 20 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])"
        ]
    },
    {
        "func_name": "test_paconv_ssg",
        "original": "def test_paconv_ssg():\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    paconv_ssg_cfg = _get_segmentor_cfg('paconv/paconv_ssg_8x8_cosine_150e_s3dis_seg-3d-13class.py')\n    paconv_ssg_cfg.backbone.num_points = (256, 64, 16, 4)\n    paconv_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(paconv_ssg_cfg).cuda()\n    points = [torch.rand(1024, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    assert losses['regularize.loss_regularize'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    assert np.allclose(losses['regularize.loss_regularize'].item(), forward_losses['regularize.loss_regularize'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(200, 6).float().cuda() * 3.0, torch.randn(100, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 200, 6).float().cuda() * 3.0, torch.randn(2, 100, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])",
        "mutated": [
            "def test_paconv_ssg():\n    if False:\n        i = 10\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    paconv_ssg_cfg = _get_segmentor_cfg('paconv/paconv_ssg_8x8_cosine_150e_s3dis_seg-3d-13class.py')\n    paconv_ssg_cfg.backbone.num_points = (256, 64, 16, 4)\n    paconv_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(paconv_ssg_cfg).cuda()\n    points = [torch.rand(1024, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    assert losses['regularize.loss_regularize'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    assert np.allclose(losses['regularize.loss_regularize'].item(), forward_losses['regularize.loss_regularize'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(200, 6).float().cuda() * 3.0, torch.randn(100, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 200, 6).float().cuda() * 3.0, torch.randn(2, 100, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])",
            "def test_paconv_ssg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    paconv_ssg_cfg = _get_segmentor_cfg('paconv/paconv_ssg_8x8_cosine_150e_s3dis_seg-3d-13class.py')\n    paconv_ssg_cfg.backbone.num_points = (256, 64, 16, 4)\n    paconv_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(paconv_ssg_cfg).cuda()\n    points = [torch.rand(1024, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    assert losses['regularize.loss_regularize'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    assert np.allclose(losses['regularize.loss_regularize'].item(), forward_losses['regularize.loss_regularize'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(200, 6).float().cuda() * 3.0, torch.randn(100, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 200, 6).float().cuda() * 3.0, torch.randn(2, 100, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])",
            "def test_paconv_ssg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    paconv_ssg_cfg = _get_segmentor_cfg('paconv/paconv_ssg_8x8_cosine_150e_s3dis_seg-3d-13class.py')\n    paconv_ssg_cfg.backbone.num_points = (256, 64, 16, 4)\n    paconv_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(paconv_ssg_cfg).cuda()\n    points = [torch.rand(1024, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    assert losses['regularize.loss_regularize'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    assert np.allclose(losses['regularize.loss_regularize'].item(), forward_losses['regularize.loss_regularize'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(200, 6).float().cuda() * 3.0, torch.randn(100, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 200, 6).float().cuda() * 3.0, torch.randn(2, 100, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])",
            "def test_paconv_ssg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    paconv_ssg_cfg = _get_segmentor_cfg('paconv/paconv_ssg_8x8_cosine_150e_s3dis_seg-3d-13class.py')\n    paconv_ssg_cfg.backbone.num_points = (256, 64, 16, 4)\n    paconv_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(paconv_ssg_cfg).cuda()\n    points = [torch.rand(1024, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    assert losses['regularize.loss_regularize'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    assert np.allclose(losses['regularize.loss_regularize'].item(), forward_losses['regularize.loss_regularize'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(200, 6).float().cuda() * 3.0, torch.randn(100, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 200, 6).float().cuda() * 3.0, torch.randn(2, 100, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])",
            "def test_paconv_ssg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    paconv_ssg_cfg = _get_segmentor_cfg('paconv/paconv_ssg_8x8_cosine_150e_s3dis_seg-3d-13class.py')\n    paconv_ssg_cfg.backbone.num_points = (256, 64, 16, 4)\n    paconv_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(paconv_ssg_cfg).cuda()\n    points = [torch.rand(1024, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    assert losses['regularize.loss_regularize'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    assert np.allclose(losses['regularize.loss_regularize'].item(), forward_losses['regularize.loss_regularize'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(200, 6).float().cuda() * 3.0, torch.randn(100, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 200, 6).float().cuda() * 3.0, torch.randn(2, 100, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])"
        ]
    },
    {
        "func_name": "test_paconv_cuda_ssg",
        "original": "def test_paconv_cuda_ssg():\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    paconv_cuda_ssg_cfg = _get_segmentor_cfg('paconv/paconv_cuda_ssg_8x8_cosine_200e_s3dis_seg-3d-13class.py')\n    paconv_cuda_ssg_cfg.backbone.num_points = (256, 64, 16, 4)\n    paconv_cuda_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(paconv_cuda_ssg_cfg).cuda()\n    points = [torch.rand(1024, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    assert losses['regularize.loss_regularize'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    assert np.allclose(losses['regularize.loss_regularize'].item(), forward_losses['regularize.loss_regularize'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(200, 6).float().cuda() * 3.0, torch.randn(100, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 200, 6).float().cuda() * 3.0, torch.randn(2, 100, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])",
        "mutated": [
            "def test_paconv_cuda_ssg():\n    if False:\n        i = 10\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    paconv_cuda_ssg_cfg = _get_segmentor_cfg('paconv/paconv_cuda_ssg_8x8_cosine_200e_s3dis_seg-3d-13class.py')\n    paconv_cuda_ssg_cfg.backbone.num_points = (256, 64, 16, 4)\n    paconv_cuda_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(paconv_cuda_ssg_cfg).cuda()\n    points = [torch.rand(1024, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    assert losses['regularize.loss_regularize'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    assert np.allclose(losses['regularize.loss_regularize'].item(), forward_losses['regularize.loss_regularize'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(200, 6).float().cuda() * 3.0, torch.randn(100, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 200, 6).float().cuda() * 3.0, torch.randn(2, 100, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])",
            "def test_paconv_cuda_ssg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    paconv_cuda_ssg_cfg = _get_segmentor_cfg('paconv/paconv_cuda_ssg_8x8_cosine_200e_s3dis_seg-3d-13class.py')\n    paconv_cuda_ssg_cfg.backbone.num_points = (256, 64, 16, 4)\n    paconv_cuda_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(paconv_cuda_ssg_cfg).cuda()\n    points = [torch.rand(1024, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    assert losses['regularize.loss_regularize'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    assert np.allclose(losses['regularize.loss_regularize'].item(), forward_losses['regularize.loss_regularize'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(200, 6).float().cuda() * 3.0, torch.randn(100, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 200, 6).float().cuda() * 3.0, torch.randn(2, 100, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])",
            "def test_paconv_cuda_ssg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    paconv_cuda_ssg_cfg = _get_segmentor_cfg('paconv/paconv_cuda_ssg_8x8_cosine_200e_s3dis_seg-3d-13class.py')\n    paconv_cuda_ssg_cfg.backbone.num_points = (256, 64, 16, 4)\n    paconv_cuda_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(paconv_cuda_ssg_cfg).cuda()\n    points = [torch.rand(1024, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    assert losses['regularize.loss_regularize'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    assert np.allclose(losses['regularize.loss_regularize'].item(), forward_losses['regularize.loss_regularize'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(200, 6).float().cuda() * 3.0, torch.randn(100, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 200, 6).float().cuda() * 3.0, torch.randn(2, 100, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])",
            "def test_paconv_cuda_ssg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    paconv_cuda_ssg_cfg = _get_segmentor_cfg('paconv/paconv_cuda_ssg_8x8_cosine_200e_s3dis_seg-3d-13class.py')\n    paconv_cuda_ssg_cfg.backbone.num_points = (256, 64, 16, 4)\n    paconv_cuda_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(paconv_cuda_ssg_cfg).cuda()\n    points = [torch.rand(1024, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    assert losses['regularize.loss_regularize'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    assert np.allclose(losses['regularize.loss_regularize'].item(), forward_losses['regularize.loss_regularize'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(200, 6).float().cuda() * 3.0, torch.randn(100, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 200, 6).float().cuda() * 3.0, torch.randn(2, 100, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])",
            "def test_paconv_cuda_ssg():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    paconv_cuda_ssg_cfg = _get_segmentor_cfg('paconv/paconv_cuda_ssg_8x8_cosine_200e_s3dis_seg-3d-13class.py')\n    paconv_cuda_ssg_cfg.backbone.num_points = (256, 64, 16, 4)\n    paconv_cuda_ssg_cfg.test_cfg.num_points = 32\n    self = build_segmentor(paconv_cuda_ssg_cfg).cuda()\n    points = [torch.rand(1024, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (1024,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    assert losses['regularize.loss_regularize'].item() >= 0\n    set_random_seed(0, True)\n    data_dict = dict(points=points, img_metas=img_metas, pts_semantic_mask=gt_masks)\n    forward_losses = self.forward(return_loss=True, **data_dict)\n    assert np.allclose(losses['decode.loss_sem_seg'].item(), forward_losses['decode.loss_sem_seg'].item())\n    assert np.allclose(losses['regularize.loss_regularize'].item(), forward_losses['regularize.loss_regularize'].item())\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(200, 6).float().cuda() * 3.0, torch.randn(100, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=[scene_points], img_metas=[img_metas])\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 200, 6).float().cuda() * 3.0, torch.randn(2, 100, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])\n    with torch.no_grad():\n        data_dict = dict(points=scene_points, img_metas=img_metas)\n        results = self.forward(return_loss=False, **data_dict)\n        assert results[0]['semantic_mask'].shape == torch.Size([200])\n        assert results[1]['semantic_mask'].shape == torch.Size([100])"
        ]
    },
    {
        "func_name": "test_dgcnn",
        "original": "def test_dgcnn():\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    dgcnn_cfg = _get_segmentor_cfg('dgcnn/dgcnn_32x4_cosine_100e_s3dis_seg-3d-13class.py')\n    dgcnn_cfg.test_cfg.num_points = 32\n    self = build_segmentor(dgcnn_cfg).cuda()\n    points = [torch.rand(4096, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (4096,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])",
        "mutated": [
            "def test_dgcnn():\n    if False:\n        i = 10\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    dgcnn_cfg = _get_segmentor_cfg('dgcnn/dgcnn_32x4_cosine_100e_s3dis_seg-3d-13class.py')\n    dgcnn_cfg.test_cfg.num_points = 32\n    self = build_segmentor(dgcnn_cfg).cuda()\n    points = [torch.rand(4096, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (4096,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])",
            "def test_dgcnn():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    dgcnn_cfg = _get_segmentor_cfg('dgcnn/dgcnn_32x4_cosine_100e_s3dis_seg-3d-13class.py')\n    dgcnn_cfg.test_cfg.num_points = 32\n    self = build_segmentor(dgcnn_cfg).cuda()\n    points = [torch.rand(4096, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (4096,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])",
            "def test_dgcnn():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    dgcnn_cfg = _get_segmentor_cfg('dgcnn/dgcnn_32x4_cosine_100e_s3dis_seg-3d-13class.py')\n    dgcnn_cfg.test_cfg.num_points = 32\n    self = build_segmentor(dgcnn_cfg).cuda()\n    points = [torch.rand(4096, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (4096,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])",
            "def test_dgcnn():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    dgcnn_cfg = _get_segmentor_cfg('dgcnn/dgcnn_32x4_cosine_100e_s3dis_seg-3d-13class.py')\n    dgcnn_cfg.test_cfg.num_points = 32\n    self = build_segmentor(dgcnn_cfg).cuda()\n    points = [torch.rand(4096, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (4096,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])",
            "def test_dgcnn():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    set_random_seed(0, True)\n    dgcnn_cfg = _get_segmentor_cfg('dgcnn/dgcnn_32x4_cosine_100e_s3dis_seg-3d-13class.py')\n    dgcnn_cfg.test_cfg.num_points = 32\n    self = build_segmentor(dgcnn_cfg).cuda()\n    points = [torch.rand(4096, 9).float().cuda() for _ in range(2)]\n    img_metas = [dict(), dict()]\n    gt_masks = [torch.randint(0, 13, (4096,)).long().cuda() for _ in range(2)]\n    losses = self.forward_train(points, img_metas, gt_masks)\n    assert losses['decode.loss_sem_seg'].item() >= 0\n    ignore_masks = [torch.ones_like(gt_masks[0]) * 13 for _ in range(2)]\n    losses = self.forward_train(points, img_metas, ignore_masks)\n    assert losses['decode.loss_sem_seg'].item() == 0\n    self.eval()\n    with torch.no_grad():\n        scene_points = [torch.randn(500, 6).float().cuda() * 3.0, torch.randn(200, 6).float().cuda() * 2.5]\n        results = self.simple_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])\n    with torch.no_grad():\n        scene_points = [torch.randn(2, 500, 6).float().cuda() * 3.0, torch.randn(2, 200, 6).float().cuda() * 2.5]\n        img_metas = [[dict(), dict()], [dict(), dict()]]\n        results = self.aug_test(scene_points, img_metas)\n        assert results[0]['semantic_mask'].shape == torch.Size([500])\n        assert results[1]['semantic_mask'].shape == torch.Size([200])"
        ]
    }
]