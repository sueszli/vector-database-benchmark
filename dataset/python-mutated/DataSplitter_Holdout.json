[
    {
        "func_name": "__init__",
        "original": "def __init__(self, dataReader_object: _DataReader, split_interaction_quota_list=None, user_wise=True, allow_cold_users=False, forbid_new_split=False, force_new_split=False):\n    \"\"\"\n\n        :param dataReader_object:\n        :param n_folds:\n        :param force_new_split:\n        :param forbid_new_split:\n        :param save_folder_path:    path in which to save the loaded dataset\n                                    None    use default \"dataset_name/split_name/\"\n                                    False   do not save\n        \"\"\"\n    if split_interaction_quota_list is None:\n        split_interaction_quota_list = self._SPLIT_QUOTA_LIST_DEFAULT.copy()\n        self._print(\"input_split_item_quota_list not provided, using default '{}'\".format(split_interaction_quota_list))\n    assert len(split_interaction_quota_list) == 3, '{}: input_split_item_quota_list must contain 3 values: Train, Validation, Test'.format(self.DATA_SPLITTER_NAME)\n    assert all((split_quota >= 0.0 and split_quota <= 100 for split_quota in split_interaction_quota_list)), '{}: input_split_item_quota_list must contain values between 0 and 100'.format(self.DATA_SPLITTER_NAME)\n    assert sum(split_interaction_quota_list) == 100, \"{}: input_split_item_quota_list must be a probability distribution and sum to 100, current data sums to '{}'\".format(self.DATA_SPLITTER_NAME, sum(split_interaction_quota_list))\n    self.input_split_interaction_quota_list = split_interaction_quota_list.copy()\n    self.actual_split_interaction_quota_list = None\n    self.allow_cold_users = allow_cold_users\n    self.user_wise = user_wise\n    super(DataSplitter_Holdout, self).__init__(dataReader_object, forbid_new_split=forbid_new_split, force_new_split=force_new_split)",
        "mutated": [
            "def __init__(self, dataReader_object: _DataReader, split_interaction_quota_list=None, user_wise=True, allow_cold_users=False, forbid_new_split=False, force_new_split=False):\n    if False:\n        i = 10\n    '\\n\\n        :param dataReader_object:\\n        :param n_folds:\\n        :param force_new_split:\\n        :param forbid_new_split:\\n        :param save_folder_path:    path in which to save the loaded dataset\\n                                    None    use default \"dataset_name/split_name/\"\\n                                    False   do not save\\n        '\n    if split_interaction_quota_list is None:\n        split_interaction_quota_list = self._SPLIT_QUOTA_LIST_DEFAULT.copy()\n        self._print(\"input_split_item_quota_list not provided, using default '{}'\".format(split_interaction_quota_list))\n    assert len(split_interaction_quota_list) == 3, '{}: input_split_item_quota_list must contain 3 values: Train, Validation, Test'.format(self.DATA_SPLITTER_NAME)\n    assert all((split_quota >= 0.0 and split_quota <= 100 for split_quota in split_interaction_quota_list)), '{}: input_split_item_quota_list must contain values between 0 and 100'.format(self.DATA_SPLITTER_NAME)\n    assert sum(split_interaction_quota_list) == 100, \"{}: input_split_item_quota_list must be a probability distribution and sum to 100, current data sums to '{}'\".format(self.DATA_SPLITTER_NAME, sum(split_interaction_quota_list))\n    self.input_split_interaction_quota_list = split_interaction_quota_list.copy()\n    self.actual_split_interaction_quota_list = None\n    self.allow_cold_users = allow_cold_users\n    self.user_wise = user_wise\n    super(DataSplitter_Holdout, self).__init__(dataReader_object, forbid_new_split=forbid_new_split, force_new_split=force_new_split)",
            "def __init__(self, dataReader_object: _DataReader, split_interaction_quota_list=None, user_wise=True, allow_cold_users=False, forbid_new_split=False, force_new_split=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n\\n        :param dataReader_object:\\n        :param n_folds:\\n        :param force_new_split:\\n        :param forbid_new_split:\\n        :param save_folder_path:    path in which to save the loaded dataset\\n                                    None    use default \"dataset_name/split_name/\"\\n                                    False   do not save\\n        '\n    if split_interaction_quota_list is None:\n        split_interaction_quota_list = self._SPLIT_QUOTA_LIST_DEFAULT.copy()\n        self._print(\"input_split_item_quota_list not provided, using default '{}'\".format(split_interaction_quota_list))\n    assert len(split_interaction_quota_list) == 3, '{}: input_split_item_quota_list must contain 3 values: Train, Validation, Test'.format(self.DATA_SPLITTER_NAME)\n    assert all((split_quota >= 0.0 and split_quota <= 100 for split_quota in split_interaction_quota_list)), '{}: input_split_item_quota_list must contain values between 0 and 100'.format(self.DATA_SPLITTER_NAME)\n    assert sum(split_interaction_quota_list) == 100, \"{}: input_split_item_quota_list must be a probability distribution and sum to 100, current data sums to '{}'\".format(self.DATA_SPLITTER_NAME, sum(split_interaction_quota_list))\n    self.input_split_interaction_quota_list = split_interaction_quota_list.copy()\n    self.actual_split_interaction_quota_list = None\n    self.allow_cold_users = allow_cold_users\n    self.user_wise = user_wise\n    super(DataSplitter_Holdout, self).__init__(dataReader_object, forbid_new_split=forbid_new_split, force_new_split=force_new_split)",
            "def __init__(self, dataReader_object: _DataReader, split_interaction_quota_list=None, user_wise=True, allow_cold_users=False, forbid_new_split=False, force_new_split=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n\\n        :param dataReader_object:\\n        :param n_folds:\\n        :param force_new_split:\\n        :param forbid_new_split:\\n        :param save_folder_path:    path in which to save the loaded dataset\\n                                    None    use default \"dataset_name/split_name/\"\\n                                    False   do not save\\n        '\n    if split_interaction_quota_list is None:\n        split_interaction_quota_list = self._SPLIT_QUOTA_LIST_DEFAULT.copy()\n        self._print(\"input_split_item_quota_list not provided, using default '{}'\".format(split_interaction_quota_list))\n    assert len(split_interaction_quota_list) == 3, '{}: input_split_item_quota_list must contain 3 values: Train, Validation, Test'.format(self.DATA_SPLITTER_NAME)\n    assert all((split_quota >= 0.0 and split_quota <= 100 for split_quota in split_interaction_quota_list)), '{}: input_split_item_quota_list must contain values between 0 and 100'.format(self.DATA_SPLITTER_NAME)\n    assert sum(split_interaction_quota_list) == 100, \"{}: input_split_item_quota_list must be a probability distribution and sum to 100, current data sums to '{}'\".format(self.DATA_SPLITTER_NAME, sum(split_interaction_quota_list))\n    self.input_split_interaction_quota_list = split_interaction_quota_list.copy()\n    self.actual_split_interaction_quota_list = None\n    self.allow_cold_users = allow_cold_users\n    self.user_wise = user_wise\n    super(DataSplitter_Holdout, self).__init__(dataReader_object, forbid_new_split=forbid_new_split, force_new_split=force_new_split)",
            "def __init__(self, dataReader_object: _DataReader, split_interaction_quota_list=None, user_wise=True, allow_cold_users=False, forbid_new_split=False, force_new_split=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n\\n        :param dataReader_object:\\n        :param n_folds:\\n        :param force_new_split:\\n        :param forbid_new_split:\\n        :param save_folder_path:    path in which to save the loaded dataset\\n                                    None    use default \"dataset_name/split_name/\"\\n                                    False   do not save\\n        '\n    if split_interaction_quota_list is None:\n        split_interaction_quota_list = self._SPLIT_QUOTA_LIST_DEFAULT.copy()\n        self._print(\"input_split_item_quota_list not provided, using default '{}'\".format(split_interaction_quota_list))\n    assert len(split_interaction_quota_list) == 3, '{}: input_split_item_quota_list must contain 3 values: Train, Validation, Test'.format(self.DATA_SPLITTER_NAME)\n    assert all((split_quota >= 0.0 and split_quota <= 100 for split_quota in split_interaction_quota_list)), '{}: input_split_item_quota_list must contain values between 0 and 100'.format(self.DATA_SPLITTER_NAME)\n    assert sum(split_interaction_quota_list) == 100, \"{}: input_split_item_quota_list must be a probability distribution and sum to 100, current data sums to '{}'\".format(self.DATA_SPLITTER_NAME, sum(split_interaction_quota_list))\n    self.input_split_interaction_quota_list = split_interaction_quota_list.copy()\n    self.actual_split_interaction_quota_list = None\n    self.allow_cold_users = allow_cold_users\n    self.user_wise = user_wise\n    super(DataSplitter_Holdout, self).__init__(dataReader_object, forbid_new_split=forbid_new_split, force_new_split=force_new_split)",
            "def __init__(self, dataReader_object: _DataReader, split_interaction_quota_list=None, user_wise=True, allow_cold_users=False, forbid_new_split=False, force_new_split=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n\\n        :param dataReader_object:\\n        :param n_folds:\\n        :param force_new_split:\\n        :param forbid_new_split:\\n        :param save_folder_path:    path in which to save the loaded dataset\\n                                    None    use default \"dataset_name/split_name/\"\\n                                    False   do not save\\n        '\n    if split_interaction_quota_list is None:\n        split_interaction_quota_list = self._SPLIT_QUOTA_LIST_DEFAULT.copy()\n        self._print(\"input_split_item_quota_list not provided, using default '{}'\".format(split_interaction_quota_list))\n    assert len(split_interaction_quota_list) == 3, '{}: input_split_item_quota_list must contain 3 values: Train, Validation, Test'.format(self.DATA_SPLITTER_NAME)\n    assert all((split_quota >= 0.0 and split_quota <= 100 for split_quota in split_interaction_quota_list)), '{}: input_split_item_quota_list must contain values between 0 and 100'.format(self.DATA_SPLITTER_NAME)\n    assert sum(split_interaction_quota_list) == 100, \"{}: input_split_item_quota_list must be a probability distribution and sum to 100, current data sums to '{}'\".format(self.DATA_SPLITTER_NAME, sum(split_interaction_quota_list))\n    self.input_split_interaction_quota_list = split_interaction_quota_list.copy()\n    self.actual_split_interaction_quota_list = None\n    self.allow_cold_users = allow_cold_users\n    self.user_wise = user_wise\n    super(DataSplitter_Holdout, self).__init__(dataReader_object, forbid_new_split=forbid_new_split, force_new_split=force_new_split)"
        ]
    },
    {
        "func_name": "_get_split_subfolder_name",
        "original": "def _get_split_subfolder_name(self):\n    \"\"\"\n\n        :return: warm_{n_folds}_fold/\n        \"\"\"\n    if self.user_wise:\n        user_wise_string = 'user_wise'\n    else:\n        user_wise_string = 'global_sample'\n    return 'holdout_{}_{}/'.format('_'.join((str(split_quota) for split_quota in self.input_split_interaction_quota_list)), user_wise_string)",
        "mutated": [
            "def _get_split_subfolder_name(self):\n    if False:\n        i = 10\n    '\\n\\n        :return: warm_{n_folds}_fold/\\n        '\n    if self.user_wise:\n        user_wise_string = 'user_wise'\n    else:\n        user_wise_string = 'global_sample'\n    return 'holdout_{}_{}/'.format('_'.join((str(split_quota) for split_quota in self.input_split_interaction_quota_list)), user_wise_string)",
            "def _get_split_subfolder_name(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n\\n        :return: warm_{n_folds}_fold/\\n        '\n    if self.user_wise:\n        user_wise_string = 'user_wise'\n    else:\n        user_wise_string = 'global_sample'\n    return 'holdout_{}_{}/'.format('_'.join((str(split_quota) for split_quota in self.input_split_interaction_quota_list)), user_wise_string)",
            "def _get_split_subfolder_name(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n\\n        :return: warm_{n_folds}_fold/\\n        '\n    if self.user_wise:\n        user_wise_string = 'user_wise'\n    else:\n        user_wise_string = 'global_sample'\n    return 'holdout_{}_{}/'.format('_'.join((str(split_quota) for split_quota in self.input_split_interaction_quota_list)), user_wise_string)",
            "def _get_split_subfolder_name(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n\\n        :return: warm_{n_folds}_fold/\\n        '\n    if self.user_wise:\n        user_wise_string = 'user_wise'\n    else:\n        user_wise_string = 'global_sample'\n    return 'holdout_{}_{}/'.format('_'.join((str(split_quota) for split_quota in self.input_split_interaction_quota_list)), user_wise_string)",
            "def _get_split_subfolder_name(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n\\n        :return: warm_{n_folds}_fold/\\n        '\n    if self.user_wise:\n        user_wise_string = 'user_wise'\n    else:\n        user_wise_string = 'global_sample'\n    return 'holdout_{}_{}/'.format('_'.join((str(split_quota) for split_quota in self.input_split_interaction_quota_list)), user_wise_string)"
        ]
    },
    {
        "func_name": "get_statistics_URM",
        "original": "def get_statistics_URM(self):\n    self._assert_is_initialized()\n    (n_users, n_items) = self.SPLIT_URM_DICT['URM_train'].shape\n    statistics_string = 'DataReader: {}\\n\\tNum items: {}\\n\\tNum users: {}\\n\\tTrain \\t\\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n\\tValidation \\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n\\tTest \\t\\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n'.format(self.dataReader_object._get_dataset_name(), n_items, n_users, self.input_split_interaction_quota_list[0], self.actual_split_interaction_quota_list[0], self.SPLIT_URM_DICT['URM_train'].nnz, compute_density(self.SPLIT_URM_DICT['URM_train']), self.input_split_interaction_quota_list[1], self.actual_split_interaction_quota_list[1], self.SPLIT_URM_DICT['URM_validation'].nnz, compute_density(self.SPLIT_URM_DICT['URM_validation']), self.input_split_interaction_quota_list[2], self.actual_split_interaction_quota_list[2], self.SPLIT_URM_DICT['URM_test'].nnz, compute_density(self.SPLIT_URM_DICT['URM_test']))\n    self._print(statistics_string)\n    print('\\n')",
        "mutated": [
            "def get_statistics_URM(self):\n    if False:\n        i = 10\n    self._assert_is_initialized()\n    (n_users, n_items) = self.SPLIT_URM_DICT['URM_train'].shape\n    statistics_string = 'DataReader: {}\\n\\tNum items: {}\\n\\tNum users: {}\\n\\tTrain \\t\\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n\\tValidation \\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n\\tTest \\t\\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n'.format(self.dataReader_object._get_dataset_name(), n_items, n_users, self.input_split_interaction_quota_list[0], self.actual_split_interaction_quota_list[0], self.SPLIT_URM_DICT['URM_train'].nnz, compute_density(self.SPLIT_URM_DICT['URM_train']), self.input_split_interaction_quota_list[1], self.actual_split_interaction_quota_list[1], self.SPLIT_URM_DICT['URM_validation'].nnz, compute_density(self.SPLIT_URM_DICT['URM_validation']), self.input_split_interaction_quota_list[2], self.actual_split_interaction_quota_list[2], self.SPLIT_URM_DICT['URM_test'].nnz, compute_density(self.SPLIT_URM_DICT['URM_test']))\n    self._print(statistics_string)\n    print('\\n')",
            "def get_statistics_URM(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self._assert_is_initialized()\n    (n_users, n_items) = self.SPLIT_URM_DICT['URM_train'].shape\n    statistics_string = 'DataReader: {}\\n\\tNum items: {}\\n\\tNum users: {}\\n\\tTrain \\t\\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n\\tValidation \\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n\\tTest \\t\\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n'.format(self.dataReader_object._get_dataset_name(), n_items, n_users, self.input_split_interaction_quota_list[0], self.actual_split_interaction_quota_list[0], self.SPLIT_URM_DICT['URM_train'].nnz, compute_density(self.SPLIT_URM_DICT['URM_train']), self.input_split_interaction_quota_list[1], self.actual_split_interaction_quota_list[1], self.SPLIT_URM_DICT['URM_validation'].nnz, compute_density(self.SPLIT_URM_DICT['URM_validation']), self.input_split_interaction_quota_list[2], self.actual_split_interaction_quota_list[2], self.SPLIT_URM_DICT['URM_test'].nnz, compute_density(self.SPLIT_URM_DICT['URM_test']))\n    self._print(statistics_string)\n    print('\\n')",
            "def get_statistics_URM(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self._assert_is_initialized()\n    (n_users, n_items) = self.SPLIT_URM_DICT['URM_train'].shape\n    statistics_string = 'DataReader: {}\\n\\tNum items: {}\\n\\tNum users: {}\\n\\tTrain \\t\\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n\\tValidation \\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n\\tTest \\t\\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n'.format(self.dataReader_object._get_dataset_name(), n_items, n_users, self.input_split_interaction_quota_list[0], self.actual_split_interaction_quota_list[0], self.SPLIT_URM_DICT['URM_train'].nnz, compute_density(self.SPLIT_URM_DICT['URM_train']), self.input_split_interaction_quota_list[1], self.actual_split_interaction_quota_list[1], self.SPLIT_URM_DICT['URM_validation'].nnz, compute_density(self.SPLIT_URM_DICT['URM_validation']), self.input_split_interaction_quota_list[2], self.actual_split_interaction_quota_list[2], self.SPLIT_URM_DICT['URM_test'].nnz, compute_density(self.SPLIT_URM_DICT['URM_test']))\n    self._print(statistics_string)\n    print('\\n')",
            "def get_statistics_URM(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self._assert_is_initialized()\n    (n_users, n_items) = self.SPLIT_URM_DICT['URM_train'].shape\n    statistics_string = 'DataReader: {}\\n\\tNum items: {}\\n\\tNum users: {}\\n\\tTrain \\t\\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n\\tValidation \\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n\\tTest \\t\\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n'.format(self.dataReader_object._get_dataset_name(), n_items, n_users, self.input_split_interaction_quota_list[0], self.actual_split_interaction_quota_list[0], self.SPLIT_URM_DICT['URM_train'].nnz, compute_density(self.SPLIT_URM_DICT['URM_train']), self.input_split_interaction_quota_list[1], self.actual_split_interaction_quota_list[1], self.SPLIT_URM_DICT['URM_validation'].nnz, compute_density(self.SPLIT_URM_DICT['URM_validation']), self.input_split_interaction_quota_list[2], self.actual_split_interaction_quota_list[2], self.SPLIT_URM_DICT['URM_test'].nnz, compute_density(self.SPLIT_URM_DICT['URM_test']))\n    self._print(statistics_string)\n    print('\\n')",
            "def get_statistics_URM(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self._assert_is_initialized()\n    (n_users, n_items) = self.SPLIT_URM_DICT['URM_train'].shape\n    statistics_string = 'DataReader: {}\\n\\tNum items: {}\\n\\tNum users: {}\\n\\tTrain \\t\\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n\\tValidation \\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n\\tTest \\t\\tquota {:.2f} ({:.2f}), \\tinteractions {}, \\tdensity {:.2E}\\n'.format(self.dataReader_object._get_dataset_name(), n_items, n_users, self.input_split_interaction_quota_list[0], self.actual_split_interaction_quota_list[0], self.SPLIT_URM_DICT['URM_train'].nnz, compute_density(self.SPLIT_URM_DICT['URM_train']), self.input_split_interaction_quota_list[1], self.actual_split_interaction_quota_list[1], self.SPLIT_URM_DICT['URM_validation'].nnz, compute_density(self.SPLIT_URM_DICT['URM_validation']), self.input_split_interaction_quota_list[2], self.actual_split_interaction_quota_list[2], self.SPLIT_URM_DICT['URM_test'].nnz, compute_density(self.SPLIT_URM_DICT['URM_test']))\n    self._print(statistics_string)\n    print('\\n')"
        ]
    },
    {
        "func_name": "get_ICM_from_name",
        "original": "def get_ICM_from_name(self, ICM_name):\n    return self.SPLIT_ICM_DICT[ICM_name].copy()",
        "mutated": [
            "def get_ICM_from_name(self, ICM_name):\n    if False:\n        i = 10\n    return self.SPLIT_ICM_DICT[ICM_name].copy()",
            "def get_ICM_from_name(self, ICM_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return self.SPLIT_ICM_DICT[ICM_name].copy()",
            "def get_ICM_from_name(self, ICM_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return self.SPLIT_ICM_DICT[ICM_name].copy()",
            "def get_ICM_from_name(self, ICM_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return self.SPLIT_ICM_DICT[ICM_name].copy()",
            "def get_ICM_from_name(self, ICM_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return self.SPLIT_ICM_DICT[ICM_name].copy()"
        ]
    },
    {
        "func_name": "get_UCM_from_name",
        "original": "def get_UCM_from_name(self, UCM_name):\n    return self.SPLIT_UCM_DICT[UCM_name].copy()",
        "mutated": [
            "def get_UCM_from_name(self, UCM_name):\n    if False:\n        i = 10\n    return self.SPLIT_UCM_DICT[UCM_name].copy()",
            "def get_UCM_from_name(self, UCM_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return self.SPLIT_UCM_DICT[UCM_name].copy()",
            "def get_UCM_from_name(self, UCM_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return self.SPLIT_UCM_DICT[UCM_name].copy()",
            "def get_UCM_from_name(self, UCM_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return self.SPLIT_UCM_DICT[UCM_name].copy()",
            "def get_UCM_from_name(self, UCM_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return self.SPLIT_UCM_DICT[UCM_name].copy()"
        ]
    },
    {
        "func_name": "get_statistics_ICM",
        "original": "def get_statistics_ICM(self):\n    self._assert_is_initialized()\n    if len(self.dataReader_object.get_loaded_ICM_names()) > 0:\n        for (ICM_name, ICM_object) in self.SPLIT_ICM_DICT.items():\n            (n_items, n_features) = ICM_object.shape\n            statistics_string = '\\tICM name: {}, Num features: {}, feature occurrences: {}, density {:.2E}'.format(ICM_name, n_features, ICM_object.nnz, compute_density(ICM_object))\n            print(statistics_string)\n        print('\\n')",
        "mutated": [
            "def get_statistics_ICM(self):\n    if False:\n        i = 10\n    self._assert_is_initialized()\n    if len(self.dataReader_object.get_loaded_ICM_names()) > 0:\n        for (ICM_name, ICM_object) in self.SPLIT_ICM_DICT.items():\n            (n_items, n_features) = ICM_object.shape\n            statistics_string = '\\tICM name: {}, Num features: {}, feature occurrences: {}, density {:.2E}'.format(ICM_name, n_features, ICM_object.nnz, compute_density(ICM_object))\n            print(statistics_string)\n        print('\\n')",
            "def get_statistics_ICM(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self._assert_is_initialized()\n    if len(self.dataReader_object.get_loaded_ICM_names()) > 0:\n        for (ICM_name, ICM_object) in self.SPLIT_ICM_DICT.items():\n            (n_items, n_features) = ICM_object.shape\n            statistics_string = '\\tICM name: {}, Num features: {}, feature occurrences: {}, density {:.2E}'.format(ICM_name, n_features, ICM_object.nnz, compute_density(ICM_object))\n            print(statistics_string)\n        print('\\n')",
            "def get_statistics_ICM(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self._assert_is_initialized()\n    if len(self.dataReader_object.get_loaded_ICM_names()) > 0:\n        for (ICM_name, ICM_object) in self.SPLIT_ICM_DICT.items():\n            (n_items, n_features) = ICM_object.shape\n            statistics_string = '\\tICM name: {}, Num features: {}, feature occurrences: {}, density {:.2E}'.format(ICM_name, n_features, ICM_object.nnz, compute_density(ICM_object))\n            print(statistics_string)\n        print('\\n')",
            "def get_statistics_ICM(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self._assert_is_initialized()\n    if len(self.dataReader_object.get_loaded_ICM_names()) > 0:\n        for (ICM_name, ICM_object) in self.SPLIT_ICM_DICT.items():\n            (n_items, n_features) = ICM_object.shape\n            statistics_string = '\\tICM name: {}, Num features: {}, feature occurrences: {}, density {:.2E}'.format(ICM_name, n_features, ICM_object.nnz, compute_density(ICM_object))\n            print(statistics_string)\n        print('\\n')",
            "def get_statistics_ICM(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self._assert_is_initialized()\n    if len(self.dataReader_object.get_loaded_ICM_names()) > 0:\n        for (ICM_name, ICM_object) in self.SPLIT_ICM_DICT.items():\n            (n_items, n_features) = ICM_object.shape\n            statistics_string = '\\tICM name: {}, Num features: {}, feature occurrences: {}, density {:.2E}'.format(ICM_name, n_features, ICM_object.nnz, compute_density(ICM_object))\n            print(statistics_string)\n        print('\\n')"
        ]
    },
    {
        "func_name": "_assert_is_initialized",
        "original": "def _assert_is_initialized(self):\n    assert self.SPLIT_URM_DICT is not None, '{}: Unable to load data split. The split has not been generated yet, call the load_data function to do so.'.format(self.DATA_SPLITTER_NAME)",
        "mutated": [
            "def _assert_is_initialized(self):\n    if False:\n        i = 10\n    assert self.SPLIT_URM_DICT is not None, '{}: Unable to load data split. The split has not been generated yet, call the load_data function to do so.'.format(self.DATA_SPLITTER_NAME)",
            "def _assert_is_initialized(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    assert self.SPLIT_URM_DICT is not None, '{}: Unable to load data split. The split has not been generated yet, call the load_data function to do so.'.format(self.DATA_SPLITTER_NAME)",
            "def _assert_is_initialized(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    assert self.SPLIT_URM_DICT is not None, '{}: Unable to load data split. The split has not been generated yet, call the load_data function to do so.'.format(self.DATA_SPLITTER_NAME)",
            "def _assert_is_initialized(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    assert self.SPLIT_URM_DICT is not None, '{}: Unable to load data split. The split has not been generated yet, call the load_data function to do so.'.format(self.DATA_SPLITTER_NAME)",
            "def _assert_is_initialized(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    assert self.SPLIT_URM_DICT is not None, '{}: Unable to load data split. The split has not been generated yet, call the load_data function to do so.'.format(self.DATA_SPLITTER_NAME)"
        ]
    },
    {
        "func_name": "get_holdout_split",
        "original": "def get_holdout_split(self):\n    \"\"\"\n        The train set is defined as all data except the one of that fold, which is the test\n        :return: URM_train, URM_validation, URM_test\n        \"\"\"\n    self._assert_is_initialized()\n    return (self.SPLIT_URM_DICT['URM_train'].copy(), self.SPLIT_URM_DICT['URM_validation'].copy(), self.SPLIT_URM_DICT['URM_test'].copy())",
        "mutated": [
            "def get_holdout_split(self):\n    if False:\n        i = 10\n    '\\n        The train set is defined as all data except the one of that fold, which is the test\\n        :return: URM_train, URM_validation, URM_test\\n        '\n    self._assert_is_initialized()\n    return (self.SPLIT_URM_DICT['URM_train'].copy(), self.SPLIT_URM_DICT['URM_validation'].copy(), self.SPLIT_URM_DICT['URM_test'].copy())",
            "def get_holdout_split(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        The train set is defined as all data except the one of that fold, which is the test\\n        :return: URM_train, URM_validation, URM_test\\n        '\n    self._assert_is_initialized()\n    return (self.SPLIT_URM_DICT['URM_train'].copy(), self.SPLIT_URM_DICT['URM_validation'].copy(), self.SPLIT_URM_DICT['URM_test'].copy())",
            "def get_holdout_split(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        The train set is defined as all data except the one of that fold, which is the test\\n        :return: URM_train, URM_validation, URM_test\\n        '\n    self._assert_is_initialized()\n    return (self.SPLIT_URM_DICT['URM_train'].copy(), self.SPLIT_URM_DICT['URM_validation'].copy(), self.SPLIT_URM_DICT['URM_test'].copy())",
            "def get_holdout_split(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        The train set is defined as all data except the one of that fold, which is the test\\n        :return: URM_train, URM_validation, URM_test\\n        '\n    self._assert_is_initialized()\n    return (self.SPLIT_URM_DICT['URM_train'].copy(), self.SPLIT_URM_DICT['URM_validation'].copy(), self.SPLIT_URM_DICT['URM_test'].copy())",
            "def get_holdout_split(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        The train set is defined as all data except the one of that fold, which is the test\\n        :return: URM_train, URM_validation, URM_test\\n        '\n    self._assert_is_initialized()\n    return (self.SPLIT_URM_DICT['URM_train'].copy(), self.SPLIT_URM_DICT['URM_validation'].copy(), self.SPLIT_URM_DICT['URM_test'].copy())"
        ]
    },
    {
        "func_name": "_split_data_from_original_dataset",
        "original": "def _split_data_from_original_dataset(self, save_folder_path):\n    self.loaded_dataset = self.dataReader_object.load_data()\n    self._load_from_DataReader_ICM_and_mappers(self.loaded_dataset)\n    URM_all = self.loaded_dataset.get_URM_all()\n    (train_quota, validation_quota, test_quota) = self.input_split_interaction_quota_list\n    train_quota /= 100\n    validation_quota /= 100\n    test_quota /= 100\n    if self.user_wise:\n        (URM_train_validation, URM_test) = split_train_in_two_percentage_user_wise(URM_all, train_percentage=train_quota + validation_quota)\n    else:\n        (URM_train_validation, URM_test) = split_train_in_two_percentage_global_sample(URM_all, train_percentage=train_quota + validation_quota)\n    adjusted_train_quota = URM_all.nnz * train_quota / URM_train_validation.nnz\n    if self.user_wise:\n        (URM_train, URM_validation) = split_train_in_two_percentage_user_wise(URM_train_validation, train_percentage=adjusted_train_quota)\n    else:\n        (URM_train, URM_validation) = split_train_in_two_percentage_global_sample(URM_train_validation, train_percentage=adjusted_train_quota)\n    if not self.allow_cold_users:\n        user_interactions = np.ediff1d(URM_train.indptr)\n        user_to_preserve = user_interactions >= 1\n        user_to_remove = np.logical_not(user_to_preserve)\n        n_users = URM_train.shape[0]\n        if user_to_remove.sum() > 0:\n            self._print('Removing {} ({:.2f} %) of {} users because they have no interactions in train data.'.format(user_to_remove.sum(), user_to_remove.sum() / n_users * 100, n_users))\n            URM_train = URM_train[user_to_preserve, :]\n            URM_validation = URM_validation[user_to_preserve, :]\n            URM_test = URM_test[user_to_preserve, :]\n            self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'] = reconcile_mapper_with_removed_tokens(self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'], np.arange(0, len(user_to_remove), dtype=np.int)[user_to_remove])\n            for (UCM_name, UCM_object) in self.SPLIT_UCM_DICT.items():\n                UCM_object = UCM_object[user_to_preserve, :]\n                self.SPLIT_UCM_DICT[UCM_name] = UCM_object\n    self.SPLIT_URM_DICT = {'URM_train': URM_train, 'URM_validation': URM_validation, 'URM_test': URM_test}\n    self._compute_real_split_interaction_quota()\n    self._save_split(save_folder_path)\n    self._print('Split complete')",
        "mutated": [
            "def _split_data_from_original_dataset(self, save_folder_path):\n    if False:\n        i = 10\n    self.loaded_dataset = self.dataReader_object.load_data()\n    self._load_from_DataReader_ICM_and_mappers(self.loaded_dataset)\n    URM_all = self.loaded_dataset.get_URM_all()\n    (train_quota, validation_quota, test_quota) = self.input_split_interaction_quota_list\n    train_quota /= 100\n    validation_quota /= 100\n    test_quota /= 100\n    if self.user_wise:\n        (URM_train_validation, URM_test) = split_train_in_two_percentage_user_wise(URM_all, train_percentage=train_quota + validation_quota)\n    else:\n        (URM_train_validation, URM_test) = split_train_in_two_percentage_global_sample(URM_all, train_percentage=train_quota + validation_quota)\n    adjusted_train_quota = URM_all.nnz * train_quota / URM_train_validation.nnz\n    if self.user_wise:\n        (URM_train, URM_validation) = split_train_in_two_percentage_user_wise(URM_train_validation, train_percentage=adjusted_train_quota)\n    else:\n        (URM_train, URM_validation) = split_train_in_two_percentage_global_sample(URM_train_validation, train_percentage=adjusted_train_quota)\n    if not self.allow_cold_users:\n        user_interactions = np.ediff1d(URM_train.indptr)\n        user_to_preserve = user_interactions >= 1\n        user_to_remove = np.logical_not(user_to_preserve)\n        n_users = URM_train.shape[0]\n        if user_to_remove.sum() > 0:\n            self._print('Removing {} ({:.2f} %) of {} users because they have no interactions in train data.'.format(user_to_remove.sum(), user_to_remove.sum() / n_users * 100, n_users))\n            URM_train = URM_train[user_to_preserve, :]\n            URM_validation = URM_validation[user_to_preserve, :]\n            URM_test = URM_test[user_to_preserve, :]\n            self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'] = reconcile_mapper_with_removed_tokens(self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'], np.arange(0, len(user_to_remove), dtype=np.int)[user_to_remove])\n            for (UCM_name, UCM_object) in self.SPLIT_UCM_DICT.items():\n                UCM_object = UCM_object[user_to_preserve, :]\n                self.SPLIT_UCM_DICT[UCM_name] = UCM_object\n    self.SPLIT_URM_DICT = {'URM_train': URM_train, 'URM_validation': URM_validation, 'URM_test': URM_test}\n    self._compute_real_split_interaction_quota()\n    self._save_split(save_folder_path)\n    self._print('Split complete')",
            "def _split_data_from_original_dataset(self, save_folder_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.loaded_dataset = self.dataReader_object.load_data()\n    self._load_from_DataReader_ICM_and_mappers(self.loaded_dataset)\n    URM_all = self.loaded_dataset.get_URM_all()\n    (train_quota, validation_quota, test_quota) = self.input_split_interaction_quota_list\n    train_quota /= 100\n    validation_quota /= 100\n    test_quota /= 100\n    if self.user_wise:\n        (URM_train_validation, URM_test) = split_train_in_two_percentage_user_wise(URM_all, train_percentage=train_quota + validation_quota)\n    else:\n        (URM_train_validation, URM_test) = split_train_in_two_percentage_global_sample(URM_all, train_percentage=train_quota + validation_quota)\n    adjusted_train_quota = URM_all.nnz * train_quota / URM_train_validation.nnz\n    if self.user_wise:\n        (URM_train, URM_validation) = split_train_in_two_percentage_user_wise(URM_train_validation, train_percentage=adjusted_train_quota)\n    else:\n        (URM_train, URM_validation) = split_train_in_two_percentage_global_sample(URM_train_validation, train_percentage=adjusted_train_quota)\n    if not self.allow_cold_users:\n        user_interactions = np.ediff1d(URM_train.indptr)\n        user_to_preserve = user_interactions >= 1\n        user_to_remove = np.logical_not(user_to_preserve)\n        n_users = URM_train.shape[0]\n        if user_to_remove.sum() > 0:\n            self._print('Removing {} ({:.2f} %) of {} users because they have no interactions in train data.'.format(user_to_remove.sum(), user_to_remove.sum() / n_users * 100, n_users))\n            URM_train = URM_train[user_to_preserve, :]\n            URM_validation = URM_validation[user_to_preserve, :]\n            URM_test = URM_test[user_to_preserve, :]\n            self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'] = reconcile_mapper_with_removed_tokens(self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'], np.arange(0, len(user_to_remove), dtype=np.int)[user_to_remove])\n            for (UCM_name, UCM_object) in self.SPLIT_UCM_DICT.items():\n                UCM_object = UCM_object[user_to_preserve, :]\n                self.SPLIT_UCM_DICT[UCM_name] = UCM_object\n    self.SPLIT_URM_DICT = {'URM_train': URM_train, 'URM_validation': URM_validation, 'URM_test': URM_test}\n    self._compute_real_split_interaction_quota()\n    self._save_split(save_folder_path)\n    self._print('Split complete')",
            "def _split_data_from_original_dataset(self, save_folder_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.loaded_dataset = self.dataReader_object.load_data()\n    self._load_from_DataReader_ICM_and_mappers(self.loaded_dataset)\n    URM_all = self.loaded_dataset.get_URM_all()\n    (train_quota, validation_quota, test_quota) = self.input_split_interaction_quota_list\n    train_quota /= 100\n    validation_quota /= 100\n    test_quota /= 100\n    if self.user_wise:\n        (URM_train_validation, URM_test) = split_train_in_two_percentage_user_wise(URM_all, train_percentage=train_quota + validation_quota)\n    else:\n        (URM_train_validation, URM_test) = split_train_in_two_percentage_global_sample(URM_all, train_percentage=train_quota + validation_quota)\n    adjusted_train_quota = URM_all.nnz * train_quota / URM_train_validation.nnz\n    if self.user_wise:\n        (URM_train, URM_validation) = split_train_in_two_percentage_user_wise(URM_train_validation, train_percentage=adjusted_train_quota)\n    else:\n        (URM_train, URM_validation) = split_train_in_two_percentage_global_sample(URM_train_validation, train_percentage=adjusted_train_quota)\n    if not self.allow_cold_users:\n        user_interactions = np.ediff1d(URM_train.indptr)\n        user_to_preserve = user_interactions >= 1\n        user_to_remove = np.logical_not(user_to_preserve)\n        n_users = URM_train.shape[0]\n        if user_to_remove.sum() > 0:\n            self._print('Removing {} ({:.2f} %) of {} users because they have no interactions in train data.'.format(user_to_remove.sum(), user_to_remove.sum() / n_users * 100, n_users))\n            URM_train = URM_train[user_to_preserve, :]\n            URM_validation = URM_validation[user_to_preserve, :]\n            URM_test = URM_test[user_to_preserve, :]\n            self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'] = reconcile_mapper_with_removed_tokens(self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'], np.arange(0, len(user_to_remove), dtype=np.int)[user_to_remove])\n            for (UCM_name, UCM_object) in self.SPLIT_UCM_DICT.items():\n                UCM_object = UCM_object[user_to_preserve, :]\n                self.SPLIT_UCM_DICT[UCM_name] = UCM_object\n    self.SPLIT_URM_DICT = {'URM_train': URM_train, 'URM_validation': URM_validation, 'URM_test': URM_test}\n    self._compute_real_split_interaction_quota()\n    self._save_split(save_folder_path)\n    self._print('Split complete')",
            "def _split_data_from_original_dataset(self, save_folder_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.loaded_dataset = self.dataReader_object.load_data()\n    self._load_from_DataReader_ICM_and_mappers(self.loaded_dataset)\n    URM_all = self.loaded_dataset.get_URM_all()\n    (train_quota, validation_quota, test_quota) = self.input_split_interaction_quota_list\n    train_quota /= 100\n    validation_quota /= 100\n    test_quota /= 100\n    if self.user_wise:\n        (URM_train_validation, URM_test) = split_train_in_two_percentage_user_wise(URM_all, train_percentage=train_quota + validation_quota)\n    else:\n        (URM_train_validation, URM_test) = split_train_in_two_percentage_global_sample(URM_all, train_percentage=train_quota + validation_quota)\n    adjusted_train_quota = URM_all.nnz * train_quota / URM_train_validation.nnz\n    if self.user_wise:\n        (URM_train, URM_validation) = split_train_in_two_percentage_user_wise(URM_train_validation, train_percentage=adjusted_train_quota)\n    else:\n        (URM_train, URM_validation) = split_train_in_two_percentage_global_sample(URM_train_validation, train_percentage=adjusted_train_quota)\n    if not self.allow_cold_users:\n        user_interactions = np.ediff1d(URM_train.indptr)\n        user_to_preserve = user_interactions >= 1\n        user_to_remove = np.logical_not(user_to_preserve)\n        n_users = URM_train.shape[0]\n        if user_to_remove.sum() > 0:\n            self._print('Removing {} ({:.2f} %) of {} users because they have no interactions in train data.'.format(user_to_remove.sum(), user_to_remove.sum() / n_users * 100, n_users))\n            URM_train = URM_train[user_to_preserve, :]\n            URM_validation = URM_validation[user_to_preserve, :]\n            URM_test = URM_test[user_to_preserve, :]\n            self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'] = reconcile_mapper_with_removed_tokens(self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'], np.arange(0, len(user_to_remove), dtype=np.int)[user_to_remove])\n            for (UCM_name, UCM_object) in self.SPLIT_UCM_DICT.items():\n                UCM_object = UCM_object[user_to_preserve, :]\n                self.SPLIT_UCM_DICT[UCM_name] = UCM_object\n    self.SPLIT_URM_DICT = {'URM_train': URM_train, 'URM_validation': URM_validation, 'URM_test': URM_test}\n    self._compute_real_split_interaction_quota()\n    self._save_split(save_folder_path)\n    self._print('Split complete')",
            "def _split_data_from_original_dataset(self, save_folder_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.loaded_dataset = self.dataReader_object.load_data()\n    self._load_from_DataReader_ICM_and_mappers(self.loaded_dataset)\n    URM_all = self.loaded_dataset.get_URM_all()\n    (train_quota, validation_quota, test_quota) = self.input_split_interaction_quota_list\n    train_quota /= 100\n    validation_quota /= 100\n    test_quota /= 100\n    if self.user_wise:\n        (URM_train_validation, URM_test) = split_train_in_two_percentage_user_wise(URM_all, train_percentage=train_quota + validation_quota)\n    else:\n        (URM_train_validation, URM_test) = split_train_in_two_percentage_global_sample(URM_all, train_percentage=train_quota + validation_quota)\n    adjusted_train_quota = URM_all.nnz * train_quota / URM_train_validation.nnz\n    if self.user_wise:\n        (URM_train, URM_validation) = split_train_in_two_percentage_user_wise(URM_train_validation, train_percentage=adjusted_train_quota)\n    else:\n        (URM_train, URM_validation) = split_train_in_two_percentage_global_sample(URM_train_validation, train_percentage=adjusted_train_quota)\n    if not self.allow_cold_users:\n        user_interactions = np.ediff1d(URM_train.indptr)\n        user_to_preserve = user_interactions >= 1\n        user_to_remove = np.logical_not(user_to_preserve)\n        n_users = URM_train.shape[0]\n        if user_to_remove.sum() > 0:\n            self._print('Removing {} ({:.2f} %) of {} users because they have no interactions in train data.'.format(user_to_remove.sum(), user_to_remove.sum() / n_users * 100, n_users))\n            URM_train = URM_train[user_to_preserve, :]\n            URM_validation = URM_validation[user_to_preserve, :]\n            URM_test = URM_test[user_to_preserve, :]\n            self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'] = reconcile_mapper_with_removed_tokens(self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'], np.arange(0, len(user_to_remove), dtype=np.int)[user_to_remove])\n            for (UCM_name, UCM_object) in self.SPLIT_UCM_DICT.items():\n                UCM_object = UCM_object[user_to_preserve, :]\n                self.SPLIT_UCM_DICT[UCM_name] = UCM_object\n    self.SPLIT_URM_DICT = {'URM_train': URM_train, 'URM_validation': URM_validation, 'URM_test': URM_test}\n    self._compute_real_split_interaction_quota()\n    self._save_split(save_folder_path)\n    self._print('Split complete')"
        ]
    },
    {
        "func_name": "_compute_real_split_interaction_quota",
        "original": "def _compute_real_split_interaction_quota(self):\n    self._assert_is_initialized()\n    n_interactions_total = 0\n    self.actual_split_interaction_quota_list = [None] * len(self.input_split_interaction_quota_list)\n    for (_, URM_object) in self.SPLIT_URM_DICT.items():\n        n_interactions_total += URM_object.nnz\n    for (index, (_, URM_object)) in enumerate(self.SPLIT_URM_DICT.items()):\n        real_quota = URM_object.nnz / n_interactions_total * 100\n        self.actual_split_interaction_quota_list[index] = real_quota",
        "mutated": [
            "def _compute_real_split_interaction_quota(self):\n    if False:\n        i = 10\n    self._assert_is_initialized()\n    n_interactions_total = 0\n    self.actual_split_interaction_quota_list = [None] * len(self.input_split_interaction_quota_list)\n    for (_, URM_object) in self.SPLIT_URM_DICT.items():\n        n_interactions_total += URM_object.nnz\n    for (index, (_, URM_object)) in enumerate(self.SPLIT_URM_DICT.items()):\n        real_quota = URM_object.nnz / n_interactions_total * 100\n        self.actual_split_interaction_quota_list[index] = real_quota",
            "def _compute_real_split_interaction_quota(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self._assert_is_initialized()\n    n_interactions_total = 0\n    self.actual_split_interaction_quota_list = [None] * len(self.input_split_interaction_quota_list)\n    for (_, URM_object) in self.SPLIT_URM_DICT.items():\n        n_interactions_total += URM_object.nnz\n    for (index, (_, URM_object)) in enumerate(self.SPLIT_URM_DICT.items()):\n        real_quota = URM_object.nnz / n_interactions_total * 100\n        self.actual_split_interaction_quota_list[index] = real_quota",
            "def _compute_real_split_interaction_quota(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self._assert_is_initialized()\n    n_interactions_total = 0\n    self.actual_split_interaction_quota_list = [None] * len(self.input_split_interaction_quota_list)\n    for (_, URM_object) in self.SPLIT_URM_DICT.items():\n        n_interactions_total += URM_object.nnz\n    for (index, (_, URM_object)) in enumerate(self.SPLIT_URM_DICT.items()):\n        real_quota = URM_object.nnz / n_interactions_total * 100\n        self.actual_split_interaction_quota_list[index] = real_quota",
            "def _compute_real_split_interaction_quota(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self._assert_is_initialized()\n    n_interactions_total = 0\n    self.actual_split_interaction_quota_list = [None] * len(self.input_split_interaction_quota_list)\n    for (_, URM_object) in self.SPLIT_URM_DICT.items():\n        n_interactions_total += URM_object.nnz\n    for (index, (_, URM_object)) in enumerate(self.SPLIT_URM_DICT.items()):\n        real_quota = URM_object.nnz / n_interactions_total * 100\n        self.actual_split_interaction_quota_list[index] = real_quota",
            "def _compute_real_split_interaction_quota(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self._assert_is_initialized()\n    n_interactions_total = 0\n    self.actual_split_interaction_quota_list = [None] * len(self.input_split_interaction_quota_list)\n    for (_, URM_object) in self.SPLIT_URM_DICT.items():\n        n_interactions_total += URM_object.nnz\n    for (index, (_, URM_object)) in enumerate(self.SPLIT_URM_DICT.items()):\n        real_quota = URM_object.nnz / n_interactions_total * 100\n        self.actual_split_interaction_quota_list[index] = real_quota"
        ]
    },
    {
        "func_name": "_save_split",
        "original": "def _save_split(self, save_folder_path):\n    if save_folder_path:\n        if self.allow_cold_users:\n            allow_cold_users_suffix = 'allow_cold_users'\n        else:\n            allow_cold_users_suffix = 'only_warm_users'\n        if self.user_wise:\n            user_wise_string = 'user_wise'\n        else:\n            user_wise_string = 'global_sample'\n        name_suffix = '_{}_{}'.format(allow_cold_users_suffix, user_wise_string)\n        split_parameters_dict = {'input_split_interaction_quota_list': self.input_split_interaction_quota_list, 'actual_split_interaction_quota_list': self.actual_split_interaction_quota_list, 'allow_cold_users': self.allow_cold_users}\n        dataIO = DataIO(folder_path=save_folder_path)\n        dataIO.save_data(data_dict_to_save=split_parameters_dict, file_name='split_parameters' + name_suffix)\n        dataIO.save_data(data_dict_to_save=self.SPLIT_GLOBAL_MAPPER_DICT, file_name='split_mappers' + name_suffix)\n        dataIO.save_data(data_dict_to_save=self.SPLIT_URM_DICT, file_name='split_URM' + name_suffix)\n        if len(self.SPLIT_ICM_DICT) > 0:\n            dataIO.save_data(data_dict_to_save=self.SPLIT_ICM_DICT, file_name='split_ICM' + name_suffix)\n            dataIO.save_data(data_dict_to_save=self.SPLIT_ICM_MAPPER_DICT, file_name='split_ICM_mappers' + name_suffix)\n        if len(self.SPLIT_UCM_DICT) > 0:\n            dataIO.save_data(data_dict_to_save=self.SPLIT_UCM_DICT, file_name='split_UCM' + name_suffix)\n            dataIO.save_data(data_dict_to_save=self.SPLIT_UCM_MAPPER_DICT, file_name='split_UCM_mappers' + name_suffix)",
        "mutated": [
            "def _save_split(self, save_folder_path):\n    if False:\n        i = 10\n    if save_folder_path:\n        if self.allow_cold_users:\n            allow_cold_users_suffix = 'allow_cold_users'\n        else:\n            allow_cold_users_suffix = 'only_warm_users'\n        if self.user_wise:\n            user_wise_string = 'user_wise'\n        else:\n            user_wise_string = 'global_sample'\n        name_suffix = '_{}_{}'.format(allow_cold_users_suffix, user_wise_string)\n        split_parameters_dict = {'input_split_interaction_quota_list': self.input_split_interaction_quota_list, 'actual_split_interaction_quota_list': self.actual_split_interaction_quota_list, 'allow_cold_users': self.allow_cold_users}\n        dataIO = DataIO(folder_path=save_folder_path)\n        dataIO.save_data(data_dict_to_save=split_parameters_dict, file_name='split_parameters' + name_suffix)\n        dataIO.save_data(data_dict_to_save=self.SPLIT_GLOBAL_MAPPER_DICT, file_name='split_mappers' + name_suffix)\n        dataIO.save_data(data_dict_to_save=self.SPLIT_URM_DICT, file_name='split_URM' + name_suffix)\n        if len(self.SPLIT_ICM_DICT) > 0:\n            dataIO.save_data(data_dict_to_save=self.SPLIT_ICM_DICT, file_name='split_ICM' + name_suffix)\n            dataIO.save_data(data_dict_to_save=self.SPLIT_ICM_MAPPER_DICT, file_name='split_ICM_mappers' + name_suffix)\n        if len(self.SPLIT_UCM_DICT) > 0:\n            dataIO.save_data(data_dict_to_save=self.SPLIT_UCM_DICT, file_name='split_UCM' + name_suffix)\n            dataIO.save_data(data_dict_to_save=self.SPLIT_UCM_MAPPER_DICT, file_name='split_UCM_mappers' + name_suffix)",
            "def _save_split(self, save_folder_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if save_folder_path:\n        if self.allow_cold_users:\n            allow_cold_users_suffix = 'allow_cold_users'\n        else:\n            allow_cold_users_suffix = 'only_warm_users'\n        if self.user_wise:\n            user_wise_string = 'user_wise'\n        else:\n            user_wise_string = 'global_sample'\n        name_suffix = '_{}_{}'.format(allow_cold_users_suffix, user_wise_string)\n        split_parameters_dict = {'input_split_interaction_quota_list': self.input_split_interaction_quota_list, 'actual_split_interaction_quota_list': self.actual_split_interaction_quota_list, 'allow_cold_users': self.allow_cold_users}\n        dataIO = DataIO(folder_path=save_folder_path)\n        dataIO.save_data(data_dict_to_save=split_parameters_dict, file_name='split_parameters' + name_suffix)\n        dataIO.save_data(data_dict_to_save=self.SPLIT_GLOBAL_MAPPER_DICT, file_name='split_mappers' + name_suffix)\n        dataIO.save_data(data_dict_to_save=self.SPLIT_URM_DICT, file_name='split_URM' + name_suffix)\n        if len(self.SPLIT_ICM_DICT) > 0:\n            dataIO.save_data(data_dict_to_save=self.SPLIT_ICM_DICT, file_name='split_ICM' + name_suffix)\n            dataIO.save_data(data_dict_to_save=self.SPLIT_ICM_MAPPER_DICT, file_name='split_ICM_mappers' + name_suffix)\n        if len(self.SPLIT_UCM_DICT) > 0:\n            dataIO.save_data(data_dict_to_save=self.SPLIT_UCM_DICT, file_name='split_UCM' + name_suffix)\n            dataIO.save_data(data_dict_to_save=self.SPLIT_UCM_MAPPER_DICT, file_name='split_UCM_mappers' + name_suffix)",
            "def _save_split(self, save_folder_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if save_folder_path:\n        if self.allow_cold_users:\n            allow_cold_users_suffix = 'allow_cold_users'\n        else:\n            allow_cold_users_suffix = 'only_warm_users'\n        if self.user_wise:\n            user_wise_string = 'user_wise'\n        else:\n            user_wise_string = 'global_sample'\n        name_suffix = '_{}_{}'.format(allow_cold_users_suffix, user_wise_string)\n        split_parameters_dict = {'input_split_interaction_quota_list': self.input_split_interaction_quota_list, 'actual_split_interaction_quota_list': self.actual_split_interaction_quota_list, 'allow_cold_users': self.allow_cold_users}\n        dataIO = DataIO(folder_path=save_folder_path)\n        dataIO.save_data(data_dict_to_save=split_parameters_dict, file_name='split_parameters' + name_suffix)\n        dataIO.save_data(data_dict_to_save=self.SPLIT_GLOBAL_MAPPER_DICT, file_name='split_mappers' + name_suffix)\n        dataIO.save_data(data_dict_to_save=self.SPLIT_URM_DICT, file_name='split_URM' + name_suffix)\n        if len(self.SPLIT_ICM_DICT) > 0:\n            dataIO.save_data(data_dict_to_save=self.SPLIT_ICM_DICT, file_name='split_ICM' + name_suffix)\n            dataIO.save_data(data_dict_to_save=self.SPLIT_ICM_MAPPER_DICT, file_name='split_ICM_mappers' + name_suffix)\n        if len(self.SPLIT_UCM_DICT) > 0:\n            dataIO.save_data(data_dict_to_save=self.SPLIT_UCM_DICT, file_name='split_UCM' + name_suffix)\n            dataIO.save_data(data_dict_to_save=self.SPLIT_UCM_MAPPER_DICT, file_name='split_UCM_mappers' + name_suffix)",
            "def _save_split(self, save_folder_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if save_folder_path:\n        if self.allow_cold_users:\n            allow_cold_users_suffix = 'allow_cold_users'\n        else:\n            allow_cold_users_suffix = 'only_warm_users'\n        if self.user_wise:\n            user_wise_string = 'user_wise'\n        else:\n            user_wise_string = 'global_sample'\n        name_suffix = '_{}_{}'.format(allow_cold_users_suffix, user_wise_string)\n        split_parameters_dict = {'input_split_interaction_quota_list': self.input_split_interaction_quota_list, 'actual_split_interaction_quota_list': self.actual_split_interaction_quota_list, 'allow_cold_users': self.allow_cold_users}\n        dataIO = DataIO(folder_path=save_folder_path)\n        dataIO.save_data(data_dict_to_save=split_parameters_dict, file_name='split_parameters' + name_suffix)\n        dataIO.save_data(data_dict_to_save=self.SPLIT_GLOBAL_MAPPER_DICT, file_name='split_mappers' + name_suffix)\n        dataIO.save_data(data_dict_to_save=self.SPLIT_URM_DICT, file_name='split_URM' + name_suffix)\n        if len(self.SPLIT_ICM_DICT) > 0:\n            dataIO.save_data(data_dict_to_save=self.SPLIT_ICM_DICT, file_name='split_ICM' + name_suffix)\n            dataIO.save_data(data_dict_to_save=self.SPLIT_ICM_MAPPER_DICT, file_name='split_ICM_mappers' + name_suffix)\n        if len(self.SPLIT_UCM_DICT) > 0:\n            dataIO.save_data(data_dict_to_save=self.SPLIT_UCM_DICT, file_name='split_UCM' + name_suffix)\n            dataIO.save_data(data_dict_to_save=self.SPLIT_UCM_MAPPER_DICT, file_name='split_UCM_mappers' + name_suffix)",
            "def _save_split(self, save_folder_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if save_folder_path:\n        if self.allow_cold_users:\n            allow_cold_users_suffix = 'allow_cold_users'\n        else:\n            allow_cold_users_suffix = 'only_warm_users'\n        if self.user_wise:\n            user_wise_string = 'user_wise'\n        else:\n            user_wise_string = 'global_sample'\n        name_suffix = '_{}_{}'.format(allow_cold_users_suffix, user_wise_string)\n        split_parameters_dict = {'input_split_interaction_quota_list': self.input_split_interaction_quota_list, 'actual_split_interaction_quota_list': self.actual_split_interaction_quota_list, 'allow_cold_users': self.allow_cold_users}\n        dataIO = DataIO(folder_path=save_folder_path)\n        dataIO.save_data(data_dict_to_save=split_parameters_dict, file_name='split_parameters' + name_suffix)\n        dataIO.save_data(data_dict_to_save=self.SPLIT_GLOBAL_MAPPER_DICT, file_name='split_mappers' + name_suffix)\n        dataIO.save_data(data_dict_to_save=self.SPLIT_URM_DICT, file_name='split_URM' + name_suffix)\n        if len(self.SPLIT_ICM_DICT) > 0:\n            dataIO.save_data(data_dict_to_save=self.SPLIT_ICM_DICT, file_name='split_ICM' + name_suffix)\n            dataIO.save_data(data_dict_to_save=self.SPLIT_ICM_MAPPER_DICT, file_name='split_ICM_mappers' + name_suffix)\n        if len(self.SPLIT_UCM_DICT) > 0:\n            dataIO.save_data(data_dict_to_save=self.SPLIT_UCM_DICT, file_name='split_UCM' + name_suffix)\n            dataIO.save_data(data_dict_to_save=self.SPLIT_UCM_MAPPER_DICT, file_name='split_UCM_mappers' + name_suffix)"
        ]
    },
    {
        "func_name": "_load_previously_built_split_and_attributes",
        "original": "def _load_previously_built_split_and_attributes(self, save_folder_path):\n    \"\"\"\n        Loads all URM and ICM\n        :return:\n        \"\"\"\n    if self.allow_cold_users:\n        allow_cold_users_suffix = 'allow_cold_users'\n    else:\n        allow_cold_users_suffix = 'only_warm_users'\n    if self.user_wise:\n        user_wise_string = 'user_wise'\n    else:\n        user_wise_string = 'global_sample'\n    name_suffix = '_{}_{}'.format(allow_cold_users_suffix, user_wise_string)\n    dataIO = DataIO(folder_path=save_folder_path)\n    split_parameters_dict = dataIO.load_data(file_name='split_parameters' + name_suffix)\n    for attrib_name in split_parameters_dict.keys():\n        self.__setattr__(attrib_name, split_parameters_dict[attrib_name])\n    self.SPLIT_GLOBAL_MAPPER_DICT = dataIO.load_data(file_name='split_mappers' + name_suffix)\n    self.SPLIT_URM_DICT = dataIO.load_data(file_name='split_URM' + name_suffix)\n    if len(self.dataReader_object.get_loaded_ICM_names()) > 0:\n        self.SPLIT_ICM_DICT = dataIO.load_data(file_name='split_ICM' + name_suffix)\n        self.SPLIT_ICM_MAPPER_DICT = dataIO.load_data(file_name='split_ICM_mappers' + name_suffix)\n    if len(self.dataReader_object.get_loaded_UCM_names()) > 0:\n        self.SPLIT_UCM_DICT = dataIO.load_data(file_name='split_UCM' + name_suffix)\n        self.SPLIT_UCM_MAPPER_DICT = dataIO.load_data(file_name='split_UCM_mappers' + name_suffix)",
        "mutated": [
            "def _load_previously_built_split_and_attributes(self, save_folder_path):\n    if False:\n        i = 10\n    '\\n        Loads all URM and ICM\\n        :return:\\n        '\n    if self.allow_cold_users:\n        allow_cold_users_suffix = 'allow_cold_users'\n    else:\n        allow_cold_users_suffix = 'only_warm_users'\n    if self.user_wise:\n        user_wise_string = 'user_wise'\n    else:\n        user_wise_string = 'global_sample'\n    name_suffix = '_{}_{}'.format(allow_cold_users_suffix, user_wise_string)\n    dataIO = DataIO(folder_path=save_folder_path)\n    split_parameters_dict = dataIO.load_data(file_name='split_parameters' + name_suffix)\n    for attrib_name in split_parameters_dict.keys():\n        self.__setattr__(attrib_name, split_parameters_dict[attrib_name])\n    self.SPLIT_GLOBAL_MAPPER_DICT = dataIO.load_data(file_name='split_mappers' + name_suffix)\n    self.SPLIT_URM_DICT = dataIO.load_data(file_name='split_URM' + name_suffix)\n    if len(self.dataReader_object.get_loaded_ICM_names()) > 0:\n        self.SPLIT_ICM_DICT = dataIO.load_data(file_name='split_ICM' + name_suffix)\n        self.SPLIT_ICM_MAPPER_DICT = dataIO.load_data(file_name='split_ICM_mappers' + name_suffix)\n    if len(self.dataReader_object.get_loaded_UCM_names()) > 0:\n        self.SPLIT_UCM_DICT = dataIO.load_data(file_name='split_UCM' + name_suffix)\n        self.SPLIT_UCM_MAPPER_DICT = dataIO.load_data(file_name='split_UCM_mappers' + name_suffix)",
            "def _load_previously_built_split_and_attributes(self, save_folder_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Loads all URM and ICM\\n        :return:\\n        '\n    if self.allow_cold_users:\n        allow_cold_users_suffix = 'allow_cold_users'\n    else:\n        allow_cold_users_suffix = 'only_warm_users'\n    if self.user_wise:\n        user_wise_string = 'user_wise'\n    else:\n        user_wise_string = 'global_sample'\n    name_suffix = '_{}_{}'.format(allow_cold_users_suffix, user_wise_string)\n    dataIO = DataIO(folder_path=save_folder_path)\n    split_parameters_dict = dataIO.load_data(file_name='split_parameters' + name_suffix)\n    for attrib_name in split_parameters_dict.keys():\n        self.__setattr__(attrib_name, split_parameters_dict[attrib_name])\n    self.SPLIT_GLOBAL_MAPPER_DICT = dataIO.load_data(file_name='split_mappers' + name_suffix)\n    self.SPLIT_URM_DICT = dataIO.load_data(file_name='split_URM' + name_suffix)\n    if len(self.dataReader_object.get_loaded_ICM_names()) > 0:\n        self.SPLIT_ICM_DICT = dataIO.load_data(file_name='split_ICM' + name_suffix)\n        self.SPLIT_ICM_MAPPER_DICT = dataIO.load_data(file_name='split_ICM_mappers' + name_suffix)\n    if len(self.dataReader_object.get_loaded_UCM_names()) > 0:\n        self.SPLIT_UCM_DICT = dataIO.load_data(file_name='split_UCM' + name_suffix)\n        self.SPLIT_UCM_MAPPER_DICT = dataIO.load_data(file_name='split_UCM_mappers' + name_suffix)",
            "def _load_previously_built_split_and_attributes(self, save_folder_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Loads all URM and ICM\\n        :return:\\n        '\n    if self.allow_cold_users:\n        allow_cold_users_suffix = 'allow_cold_users'\n    else:\n        allow_cold_users_suffix = 'only_warm_users'\n    if self.user_wise:\n        user_wise_string = 'user_wise'\n    else:\n        user_wise_string = 'global_sample'\n    name_suffix = '_{}_{}'.format(allow_cold_users_suffix, user_wise_string)\n    dataIO = DataIO(folder_path=save_folder_path)\n    split_parameters_dict = dataIO.load_data(file_name='split_parameters' + name_suffix)\n    for attrib_name in split_parameters_dict.keys():\n        self.__setattr__(attrib_name, split_parameters_dict[attrib_name])\n    self.SPLIT_GLOBAL_MAPPER_DICT = dataIO.load_data(file_name='split_mappers' + name_suffix)\n    self.SPLIT_URM_DICT = dataIO.load_data(file_name='split_URM' + name_suffix)\n    if len(self.dataReader_object.get_loaded_ICM_names()) > 0:\n        self.SPLIT_ICM_DICT = dataIO.load_data(file_name='split_ICM' + name_suffix)\n        self.SPLIT_ICM_MAPPER_DICT = dataIO.load_data(file_name='split_ICM_mappers' + name_suffix)\n    if len(self.dataReader_object.get_loaded_UCM_names()) > 0:\n        self.SPLIT_UCM_DICT = dataIO.load_data(file_name='split_UCM' + name_suffix)\n        self.SPLIT_UCM_MAPPER_DICT = dataIO.load_data(file_name='split_UCM_mappers' + name_suffix)",
            "def _load_previously_built_split_and_attributes(self, save_folder_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Loads all URM and ICM\\n        :return:\\n        '\n    if self.allow_cold_users:\n        allow_cold_users_suffix = 'allow_cold_users'\n    else:\n        allow_cold_users_suffix = 'only_warm_users'\n    if self.user_wise:\n        user_wise_string = 'user_wise'\n    else:\n        user_wise_string = 'global_sample'\n    name_suffix = '_{}_{}'.format(allow_cold_users_suffix, user_wise_string)\n    dataIO = DataIO(folder_path=save_folder_path)\n    split_parameters_dict = dataIO.load_data(file_name='split_parameters' + name_suffix)\n    for attrib_name in split_parameters_dict.keys():\n        self.__setattr__(attrib_name, split_parameters_dict[attrib_name])\n    self.SPLIT_GLOBAL_MAPPER_DICT = dataIO.load_data(file_name='split_mappers' + name_suffix)\n    self.SPLIT_URM_DICT = dataIO.load_data(file_name='split_URM' + name_suffix)\n    if len(self.dataReader_object.get_loaded_ICM_names()) > 0:\n        self.SPLIT_ICM_DICT = dataIO.load_data(file_name='split_ICM' + name_suffix)\n        self.SPLIT_ICM_MAPPER_DICT = dataIO.load_data(file_name='split_ICM_mappers' + name_suffix)\n    if len(self.dataReader_object.get_loaded_UCM_names()) > 0:\n        self.SPLIT_UCM_DICT = dataIO.load_data(file_name='split_UCM' + name_suffix)\n        self.SPLIT_UCM_MAPPER_DICT = dataIO.load_data(file_name='split_UCM_mappers' + name_suffix)",
            "def _load_previously_built_split_and_attributes(self, save_folder_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Loads all URM and ICM\\n        :return:\\n        '\n    if self.allow_cold_users:\n        allow_cold_users_suffix = 'allow_cold_users'\n    else:\n        allow_cold_users_suffix = 'only_warm_users'\n    if self.user_wise:\n        user_wise_string = 'user_wise'\n    else:\n        user_wise_string = 'global_sample'\n    name_suffix = '_{}_{}'.format(allow_cold_users_suffix, user_wise_string)\n    dataIO = DataIO(folder_path=save_folder_path)\n    split_parameters_dict = dataIO.load_data(file_name='split_parameters' + name_suffix)\n    for attrib_name in split_parameters_dict.keys():\n        self.__setattr__(attrib_name, split_parameters_dict[attrib_name])\n    self.SPLIT_GLOBAL_MAPPER_DICT = dataIO.load_data(file_name='split_mappers' + name_suffix)\n    self.SPLIT_URM_DICT = dataIO.load_data(file_name='split_URM' + name_suffix)\n    if len(self.dataReader_object.get_loaded_ICM_names()) > 0:\n        self.SPLIT_ICM_DICT = dataIO.load_data(file_name='split_ICM' + name_suffix)\n        self.SPLIT_ICM_MAPPER_DICT = dataIO.load_data(file_name='split_ICM_mappers' + name_suffix)\n    if len(self.dataReader_object.get_loaded_UCM_names()) > 0:\n        self.SPLIT_UCM_DICT = dataIO.load_data(file_name='split_UCM' + name_suffix)\n        self.SPLIT_UCM_MAPPER_DICT = dataIO.load_data(file_name='split_UCM_mappers' + name_suffix)"
        ]
    },
    {
        "func_name": "_verify_data_consistency",
        "original": "def _verify_data_consistency(self):\n    self._assert_is_initialized()\n    print_preamble = '{} consistency check: '.format(self.DATA_SPLITTER_NAME)\n    assert len(self.SPLIT_URM_DICT) == len(self._SPLIT_URM_NAME_LIST), print_preamble + 'The available URM are not as many as they are supposed to be. URMs are {}, expected URMs are {}'.format(len(self.SPLIT_URM_DICT), len(self._SPLIT_URM_NAME_LIST))\n    assert all((URM_name in self.SPLIT_URM_DICT for URM_name in self._SPLIT_URM_NAME_LIST)), print_preamble + 'Not all URMs have been created'\n    assert all((URM_name in self._SPLIT_URM_NAME_LIST for URM_name in self.SPLIT_URM_DICT.keys())), print_preamble + 'The split contains URMs that should not exist'\n    URM_shape = None\n    for (URM_name, URM_object) in self.SPLIT_URM_DICT.items():\n        if URM_shape is None:\n            URM_shape = URM_object.shape\n            (n_users, n_items) = URM_shape\n            assert n_users != 0, print_preamble + 'Number of users in URM is 0'\n            assert n_items != 0, print_preamble + 'Number of items in URM is 0'\n        assert URM_shape == URM_object.shape, print_preamble + 'URM shape is inconsistent'\n    assert self.SPLIT_URM_DICT['URM_train'].nnz != 0, print_preamble + 'Number of interactions in URM Train is 0'\n    assert self.SPLIT_URM_DICT['URM_test'].nnz != 0, print_preamble + 'Number of interactions in URM Test is 0'\n    assert self.SPLIT_URM_DICT['URM_validation'].nnz == 0 and self.input_split_interaction_quota_list[1] == 0.0 or (self.SPLIT_URM_DICT['URM_validation'].nnz != 0 and self.input_split_interaction_quota_list[1] > 0.0), print_preamble + 'Number of interactions in Validation is 0'\n    quota_oscillation_allowed = 0.2\n    for (URM_index, URM_name) in enumerate(self._SPLIT_URM_NAME_LIST):\n        input_quota = self.input_split_interaction_quota_list[URM_index]\n        actual_quota = self.actual_split_interaction_quota_list[URM_index]\n        max_value_allowed = input_quota * (1 + quota_oscillation_allowed)\n        min_value_allowed = input_quota * (1 - quota_oscillation_allowed)\n        if actual_quota < min_value_allowed or actual_quota > max_value_allowed:\n            print(print_preamble + \"The differentce between the input interaction quota '{}' and actual interaction quota '{}' of '{}' higher than {} %\".format(input_quota, actual_quota, URM_name, quota_oscillation_allowed * 100))\n    URM = self.SPLIT_URM_DICT['URM_train'].copy()\n    user_interactions = np.ediff1d(sps.csr_matrix(URM).indptr)\n    if not self.allow_cold_users:\n        assert np.all(user_interactions != 0), print_preamble + 'Cold users exist despite not being allowed as per DataSplitter parameters, {} users out of {}'.format((user_interactions == 0).sum(), n_users)\n    assert assert_disjoint_matrices(list(self.SPLIT_URM_DICT.values()))\n    assert_URM_ICM_mapper_consistency(URM_DICT=self.SPLIT_URM_DICT, user_original_ID_to_index=self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'], item_original_ID_to_index=self.SPLIT_GLOBAL_MAPPER_DICT['item_original_ID_to_index'], ICM_DICT=self.SPLIT_ICM_DICT, ICM_MAPPER_DICT=self.SPLIT_ICM_MAPPER_DICT, UCM_DICT=self.SPLIT_UCM_DICT, UCM_MAPPER_DICT=self.SPLIT_UCM_MAPPER_DICT, DATA_SPLITTER_NAME=self.DATA_SPLITTER_NAME)",
        "mutated": [
            "def _verify_data_consistency(self):\n    if False:\n        i = 10\n    self._assert_is_initialized()\n    print_preamble = '{} consistency check: '.format(self.DATA_SPLITTER_NAME)\n    assert len(self.SPLIT_URM_DICT) == len(self._SPLIT_URM_NAME_LIST), print_preamble + 'The available URM are not as many as they are supposed to be. URMs are {}, expected URMs are {}'.format(len(self.SPLIT_URM_DICT), len(self._SPLIT_URM_NAME_LIST))\n    assert all((URM_name in self.SPLIT_URM_DICT for URM_name in self._SPLIT_URM_NAME_LIST)), print_preamble + 'Not all URMs have been created'\n    assert all((URM_name in self._SPLIT_URM_NAME_LIST for URM_name in self.SPLIT_URM_DICT.keys())), print_preamble + 'The split contains URMs that should not exist'\n    URM_shape = None\n    for (URM_name, URM_object) in self.SPLIT_URM_DICT.items():\n        if URM_shape is None:\n            URM_shape = URM_object.shape\n            (n_users, n_items) = URM_shape\n            assert n_users != 0, print_preamble + 'Number of users in URM is 0'\n            assert n_items != 0, print_preamble + 'Number of items in URM is 0'\n        assert URM_shape == URM_object.shape, print_preamble + 'URM shape is inconsistent'\n    assert self.SPLIT_URM_DICT['URM_train'].nnz != 0, print_preamble + 'Number of interactions in URM Train is 0'\n    assert self.SPLIT_URM_DICT['URM_test'].nnz != 0, print_preamble + 'Number of interactions in URM Test is 0'\n    assert self.SPLIT_URM_DICT['URM_validation'].nnz == 0 and self.input_split_interaction_quota_list[1] == 0.0 or (self.SPLIT_URM_DICT['URM_validation'].nnz != 0 and self.input_split_interaction_quota_list[1] > 0.0), print_preamble + 'Number of interactions in Validation is 0'\n    quota_oscillation_allowed = 0.2\n    for (URM_index, URM_name) in enumerate(self._SPLIT_URM_NAME_LIST):\n        input_quota = self.input_split_interaction_quota_list[URM_index]\n        actual_quota = self.actual_split_interaction_quota_list[URM_index]\n        max_value_allowed = input_quota * (1 + quota_oscillation_allowed)\n        min_value_allowed = input_quota * (1 - quota_oscillation_allowed)\n        if actual_quota < min_value_allowed or actual_quota > max_value_allowed:\n            print(print_preamble + \"The differentce between the input interaction quota '{}' and actual interaction quota '{}' of '{}' higher than {} %\".format(input_quota, actual_quota, URM_name, quota_oscillation_allowed * 100))\n    URM = self.SPLIT_URM_DICT['URM_train'].copy()\n    user_interactions = np.ediff1d(sps.csr_matrix(URM).indptr)\n    if not self.allow_cold_users:\n        assert np.all(user_interactions != 0), print_preamble + 'Cold users exist despite not being allowed as per DataSplitter parameters, {} users out of {}'.format((user_interactions == 0).sum(), n_users)\n    assert assert_disjoint_matrices(list(self.SPLIT_URM_DICT.values()))\n    assert_URM_ICM_mapper_consistency(URM_DICT=self.SPLIT_URM_DICT, user_original_ID_to_index=self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'], item_original_ID_to_index=self.SPLIT_GLOBAL_MAPPER_DICT['item_original_ID_to_index'], ICM_DICT=self.SPLIT_ICM_DICT, ICM_MAPPER_DICT=self.SPLIT_ICM_MAPPER_DICT, UCM_DICT=self.SPLIT_UCM_DICT, UCM_MAPPER_DICT=self.SPLIT_UCM_MAPPER_DICT, DATA_SPLITTER_NAME=self.DATA_SPLITTER_NAME)",
            "def _verify_data_consistency(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self._assert_is_initialized()\n    print_preamble = '{} consistency check: '.format(self.DATA_SPLITTER_NAME)\n    assert len(self.SPLIT_URM_DICT) == len(self._SPLIT_URM_NAME_LIST), print_preamble + 'The available URM are not as many as they are supposed to be. URMs are {}, expected URMs are {}'.format(len(self.SPLIT_URM_DICT), len(self._SPLIT_URM_NAME_LIST))\n    assert all((URM_name in self.SPLIT_URM_DICT for URM_name in self._SPLIT_URM_NAME_LIST)), print_preamble + 'Not all URMs have been created'\n    assert all((URM_name in self._SPLIT_URM_NAME_LIST for URM_name in self.SPLIT_URM_DICT.keys())), print_preamble + 'The split contains URMs that should not exist'\n    URM_shape = None\n    for (URM_name, URM_object) in self.SPLIT_URM_DICT.items():\n        if URM_shape is None:\n            URM_shape = URM_object.shape\n            (n_users, n_items) = URM_shape\n            assert n_users != 0, print_preamble + 'Number of users in URM is 0'\n            assert n_items != 0, print_preamble + 'Number of items in URM is 0'\n        assert URM_shape == URM_object.shape, print_preamble + 'URM shape is inconsistent'\n    assert self.SPLIT_URM_DICT['URM_train'].nnz != 0, print_preamble + 'Number of interactions in URM Train is 0'\n    assert self.SPLIT_URM_DICT['URM_test'].nnz != 0, print_preamble + 'Number of interactions in URM Test is 0'\n    assert self.SPLIT_URM_DICT['URM_validation'].nnz == 0 and self.input_split_interaction_quota_list[1] == 0.0 or (self.SPLIT_URM_DICT['URM_validation'].nnz != 0 and self.input_split_interaction_quota_list[1] > 0.0), print_preamble + 'Number of interactions in Validation is 0'\n    quota_oscillation_allowed = 0.2\n    for (URM_index, URM_name) in enumerate(self._SPLIT_URM_NAME_LIST):\n        input_quota = self.input_split_interaction_quota_list[URM_index]\n        actual_quota = self.actual_split_interaction_quota_list[URM_index]\n        max_value_allowed = input_quota * (1 + quota_oscillation_allowed)\n        min_value_allowed = input_quota * (1 - quota_oscillation_allowed)\n        if actual_quota < min_value_allowed or actual_quota > max_value_allowed:\n            print(print_preamble + \"The differentce between the input interaction quota '{}' and actual interaction quota '{}' of '{}' higher than {} %\".format(input_quota, actual_quota, URM_name, quota_oscillation_allowed * 100))\n    URM = self.SPLIT_URM_DICT['URM_train'].copy()\n    user_interactions = np.ediff1d(sps.csr_matrix(URM).indptr)\n    if not self.allow_cold_users:\n        assert np.all(user_interactions != 0), print_preamble + 'Cold users exist despite not being allowed as per DataSplitter parameters, {} users out of {}'.format((user_interactions == 0).sum(), n_users)\n    assert assert_disjoint_matrices(list(self.SPLIT_URM_DICT.values()))\n    assert_URM_ICM_mapper_consistency(URM_DICT=self.SPLIT_URM_DICT, user_original_ID_to_index=self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'], item_original_ID_to_index=self.SPLIT_GLOBAL_MAPPER_DICT['item_original_ID_to_index'], ICM_DICT=self.SPLIT_ICM_DICT, ICM_MAPPER_DICT=self.SPLIT_ICM_MAPPER_DICT, UCM_DICT=self.SPLIT_UCM_DICT, UCM_MAPPER_DICT=self.SPLIT_UCM_MAPPER_DICT, DATA_SPLITTER_NAME=self.DATA_SPLITTER_NAME)",
            "def _verify_data_consistency(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self._assert_is_initialized()\n    print_preamble = '{} consistency check: '.format(self.DATA_SPLITTER_NAME)\n    assert len(self.SPLIT_URM_DICT) == len(self._SPLIT_URM_NAME_LIST), print_preamble + 'The available URM are not as many as they are supposed to be. URMs are {}, expected URMs are {}'.format(len(self.SPLIT_URM_DICT), len(self._SPLIT_URM_NAME_LIST))\n    assert all((URM_name in self.SPLIT_URM_DICT for URM_name in self._SPLIT_URM_NAME_LIST)), print_preamble + 'Not all URMs have been created'\n    assert all((URM_name in self._SPLIT_URM_NAME_LIST for URM_name in self.SPLIT_URM_DICT.keys())), print_preamble + 'The split contains URMs that should not exist'\n    URM_shape = None\n    for (URM_name, URM_object) in self.SPLIT_URM_DICT.items():\n        if URM_shape is None:\n            URM_shape = URM_object.shape\n            (n_users, n_items) = URM_shape\n            assert n_users != 0, print_preamble + 'Number of users in URM is 0'\n            assert n_items != 0, print_preamble + 'Number of items in URM is 0'\n        assert URM_shape == URM_object.shape, print_preamble + 'URM shape is inconsistent'\n    assert self.SPLIT_URM_DICT['URM_train'].nnz != 0, print_preamble + 'Number of interactions in URM Train is 0'\n    assert self.SPLIT_URM_DICT['URM_test'].nnz != 0, print_preamble + 'Number of interactions in URM Test is 0'\n    assert self.SPLIT_URM_DICT['URM_validation'].nnz == 0 and self.input_split_interaction_quota_list[1] == 0.0 or (self.SPLIT_URM_DICT['URM_validation'].nnz != 0 and self.input_split_interaction_quota_list[1] > 0.0), print_preamble + 'Number of interactions in Validation is 0'\n    quota_oscillation_allowed = 0.2\n    for (URM_index, URM_name) in enumerate(self._SPLIT_URM_NAME_LIST):\n        input_quota = self.input_split_interaction_quota_list[URM_index]\n        actual_quota = self.actual_split_interaction_quota_list[URM_index]\n        max_value_allowed = input_quota * (1 + quota_oscillation_allowed)\n        min_value_allowed = input_quota * (1 - quota_oscillation_allowed)\n        if actual_quota < min_value_allowed or actual_quota > max_value_allowed:\n            print(print_preamble + \"The differentce between the input interaction quota '{}' and actual interaction quota '{}' of '{}' higher than {} %\".format(input_quota, actual_quota, URM_name, quota_oscillation_allowed * 100))\n    URM = self.SPLIT_URM_DICT['URM_train'].copy()\n    user_interactions = np.ediff1d(sps.csr_matrix(URM).indptr)\n    if not self.allow_cold_users:\n        assert np.all(user_interactions != 0), print_preamble + 'Cold users exist despite not being allowed as per DataSplitter parameters, {} users out of {}'.format((user_interactions == 0).sum(), n_users)\n    assert assert_disjoint_matrices(list(self.SPLIT_URM_DICT.values()))\n    assert_URM_ICM_mapper_consistency(URM_DICT=self.SPLIT_URM_DICT, user_original_ID_to_index=self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'], item_original_ID_to_index=self.SPLIT_GLOBAL_MAPPER_DICT['item_original_ID_to_index'], ICM_DICT=self.SPLIT_ICM_DICT, ICM_MAPPER_DICT=self.SPLIT_ICM_MAPPER_DICT, UCM_DICT=self.SPLIT_UCM_DICT, UCM_MAPPER_DICT=self.SPLIT_UCM_MAPPER_DICT, DATA_SPLITTER_NAME=self.DATA_SPLITTER_NAME)",
            "def _verify_data_consistency(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self._assert_is_initialized()\n    print_preamble = '{} consistency check: '.format(self.DATA_SPLITTER_NAME)\n    assert len(self.SPLIT_URM_DICT) == len(self._SPLIT_URM_NAME_LIST), print_preamble + 'The available URM are not as many as they are supposed to be. URMs are {}, expected URMs are {}'.format(len(self.SPLIT_URM_DICT), len(self._SPLIT_URM_NAME_LIST))\n    assert all((URM_name in self.SPLIT_URM_DICT for URM_name in self._SPLIT_URM_NAME_LIST)), print_preamble + 'Not all URMs have been created'\n    assert all((URM_name in self._SPLIT_URM_NAME_LIST for URM_name in self.SPLIT_URM_DICT.keys())), print_preamble + 'The split contains URMs that should not exist'\n    URM_shape = None\n    for (URM_name, URM_object) in self.SPLIT_URM_DICT.items():\n        if URM_shape is None:\n            URM_shape = URM_object.shape\n            (n_users, n_items) = URM_shape\n            assert n_users != 0, print_preamble + 'Number of users in URM is 0'\n            assert n_items != 0, print_preamble + 'Number of items in URM is 0'\n        assert URM_shape == URM_object.shape, print_preamble + 'URM shape is inconsistent'\n    assert self.SPLIT_URM_DICT['URM_train'].nnz != 0, print_preamble + 'Number of interactions in URM Train is 0'\n    assert self.SPLIT_URM_DICT['URM_test'].nnz != 0, print_preamble + 'Number of interactions in URM Test is 0'\n    assert self.SPLIT_URM_DICT['URM_validation'].nnz == 0 and self.input_split_interaction_quota_list[1] == 0.0 or (self.SPLIT_URM_DICT['URM_validation'].nnz != 0 and self.input_split_interaction_quota_list[1] > 0.0), print_preamble + 'Number of interactions in Validation is 0'\n    quota_oscillation_allowed = 0.2\n    for (URM_index, URM_name) in enumerate(self._SPLIT_URM_NAME_LIST):\n        input_quota = self.input_split_interaction_quota_list[URM_index]\n        actual_quota = self.actual_split_interaction_quota_list[URM_index]\n        max_value_allowed = input_quota * (1 + quota_oscillation_allowed)\n        min_value_allowed = input_quota * (1 - quota_oscillation_allowed)\n        if actual_quota < min_value_allowed or actual_quota > max_value_allowed:\n            print(print_preamble + \"The differentce between the input interaction quota '{}' and actual interaction quota '{}' of '{}' higher than {} %\".format(input_quota, actual_quota, URM_name, quota_oscillation_allowed * 100))\n    URM = self.SPLIT_URM_DICT['URM_train'].copy()\n    user_interactions = np.ediff1d(sps.csr_matrix(URM).indptr)\n    if not self.allow_cold_users:\n        assert np.all(user_interactions != 0), print_preamble + 'Cold users exist despite not being allowed as per DataSplitter parameters, {} users out of {}'.format((user_interactions == 0).sum(), n_users)\n    assert assert_disjoint_matrices(list(self.SPLIT_URM_DICT.values()))\n    assert_URM_ICM_mapper_consistency(URM_DICT=self.SPLIT_URM_DICT, user_original_ID_to_index=self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'], item_original_ID_to_index=self.SPLIT_GLOBAL_MAPPER_DICT['item_original_ID_to_index'], ICM_DICT=self.SPLIT_ICM_DICT, ICM_MAPPER_DICT=self.SPLIT_ICM_MAPPER_DICT, UCM_DICT=self.SPLIT_UCM_DICT, UCM_MAPPER_DICT=self.SPLIT_UCM_MAPPER_DICT, DATA_SPLITTER_NAME=self.DATA_SPLITTER_NAME)",
            "def _verify_data_consistency(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self._assert_is_initialized()\n    print_preamble = '{} consistency check: '.format(self.DATA_SPLITTER_NAME)\n    assert len(self.SPLIT_URM_DICT) == len(self._SPLIT_URM_NAME_LIST), print_preamble + 'The available URM are not as many as they are supposed to be. URMs are {}, expected URMs are {}'.format(len(self.SPLIT_URM_DICT), len(self._SPLIT_URM_NAME_LIST))\n    assert all((URM_name in self.SPLIT_URM_DICT for URM_name in self._SPLIT_URM_NAME_LIST)), print_preamble + 'Not all URMs have been created'\n    assert all((URM_name in self._SPLIT_URM_NAME_LIST for URM_name in self.SPLIT_URM_DICT.keys())), print_preamble + 'The split contains URMs that should not exist'\n    URM_shape = None\n    for (URM_name, URM_object) in self.SPLIT_URM_DICT.items():\n        if URM_shape is None:\n            URM_shape = URM_object.shape\n            (n_users, n_items) = URM_shape\n            assert n_users != 0, print_preamble + 'Number of users in URM is 0'\n            assert n_items != 0, print_preamble + 'Number of items in URM is 0'\n        assert URM_shape == URM_object.shape, print_preamble + 'URM shape is inconsistent'\n    assert self.SPLIT_URM_DICT['URM_train'].nnz != 0, print_preamble + 'Number of interactions in URM Train is 0'\n    assert self.SPLIT_URM_DICT['URM_test'].nnz != 0, print_preamble + 'Number of interactions in URM Test is 0'\n    assert self.SPLIT_URM_DICT['URM_validation'].nnz == 0 and self.input_split_interaction_quota_list[1] == 0.0 or (self.SPLIT_URM_DICT['URM_validation'].nnz != 0 and self.input_split_interaction_quota_list[1] > 0.0), print_preamble + 'Number of interactions in Validation is 0'\n    quota_oscillation_allowed = 0.2\n    for (URM_index, URM_name) in enumerate(self._SPLIT_URM_NAME_LIST):\n        input_quota = self.input_split_interaction_quota_list[URM_index]\n        actual_quota = self.actual_split_interaction_quota_list[URM_index]\n        max_value_allowed = input_quota * (1 + quota_oscillation_allowed)\n        min_value_allowed = input_quota * (1 - quota_oscillation_allowed)\n        if actual_quota < min_value_allowed or actual_quota > max_value_allowed:\n            print(print_preamble + \"The differentce between the input interaction quota '{}' and actual interaction quota '{}' of '{}' higher than {} %\".format(input_quota, actual_quota, URM_name, quota_oscillation_allowed * 100))\n    URM = self.SPLIT_URM_DICT['URM_train'].copy()\n    user_interactions = np.ediff1d(sps.csr_matrix(URM).indptr)\n    if not self.allow_cold_users:\n        assert np.all(user_interactions != 0), print_preamble + 'Cold users exist despite not being allowed as per DataSplitter parameters, {} users out of {}'.format((user_interactions == 0).sum(), n_users)\n    assert assert_disjoint_matrices(list(self.SPLIT_URM_DICT.values()))\n    assert_URM_ICM_mapper_consistency(URM_DICT=self.SPLIT_URM_DICT, user_original_ID_to_index=self.SPLIT_GLOBAL_MAPPER_DICT['user_original_ID_to_index'], item_original_ID_to_index=self.SPLIT_GLOBAL_MAPPER_DICT['item_original_ID_to_index'], ICM_DICT=self.SPLIT_ICM_DICT, ICM_MAPPER_DICT=self.SPLIT_ICM_MAPPER_DICT, UCM_DICT=self.SPLIT_UCM_DICT, UCM_MAPPER_DICT=self.SPLIT_UCM_MAPPER_DICT, DATA_SPLITTER_NAME=self.DATA_SPLITTER_NAME)"
        ]
    }
]