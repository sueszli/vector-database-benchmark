[
    {
        "func_name": "_process",
        "original": "def _process(proc_data: Dict) -> Dict:\n    \"\"\"\n    Final processing to conform to the schema.\n\n    Parameters:\n\n        proc_data:   (Dictionary) raw structured data to process\n\n    Returns:\n\n        Dictionary. Structured data to conform to the schema.\n    \"\"\"\n    int_list = {'process', 'sent', 'received', 'total_size', 'matches', 'hash_hits', 'false_alarms', 'data'}\n    float_list = {'bytes_sec', 'speedup'}\n    for key in proc_data.copy():\n        if key in int_list:\n            proc_data[key] = jc.utils.convert_to_int(proc_data[key])\n        if key in float_list:\n            proc_data[key] = jc.utils.convert_to_float(proc_data[key])\n        if 'date' in proc_data and 'time' in proc_data:\n            date = proc_data['date'].replace('/', '-')\n            date_time = f\"{date} {proc_data['time']}\"\n            ts = jc.utils.timestamp(date_time, format_hint=(7250,))\n            proc_data['epoch'] = ts.naive\n    return proc_data",
        "mutated": [
            "def _process(proc_data: Dict) -> Dict:\n    if False:\n        i = 10\n    '\\n    Final processing to conform to the schema.\\n\\n    Parameters:\\n\\n        proc_data:   (Dictionary) raw structured data to process\\n\\n    Returns:\\n\\n        Dictionary. Structured data to conform to the schema.\\n    '\n    int_list = {'process', 'sent', 'received', 'total_size', 'matches', 'hash_hits', 'false_alarms', 'data'}\n    float_list = {'bytes_sec', 'speedup'}\n    for key in proc_data.copy():\n        if key in int_list:\n            proc_data[key] = jc.utils.convert_to_int(proc_data[key])\n        if key in float_list:\n            proc_data[key] = jc.utils.convert_to_float(proc_data[key])\n        if 'date' in proc_data and 'time' in proc_data:\n            date = proc_data['date'].replace('/', '-')\n            date_time = f\"{date} {proc_data['time']}\"\n            ts = jc.utils.timestamp(date_time, format_hint=(7250,))\n            proc_data['epoch'] = ts.naive\n    return proc_data",
            "def _process(proc_data: Dict) -> Dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Final processing to conform to the schema.\\n\\n    Parameters:\\n\\n        proc_data:   (Dictionary) raw structured data to process\\n\\n    Returns:\\n\\n        Dictionary. Structured data to conform to the schema.\\n    '\n    int_list = {'process', 'sent', 'received', 'total_size', 'matches', 'hash_hits', 'false_alarms', 'data'}\n    float_list = {'bytes_sec', 'speedup'}\n    for key in proc_data.copy():\n        if key in int_list:\n            proc_data[key] = jc.utils.convert_to_int(proc_data[key])\n        if key in float_list:\n            proc_data[key] = jc.utils.convert_to_float(proc_data[key])\n        if 'date' in proc_data and 'time' in proc_data:\n            date = proc_data['date'].replace('/', '-')\n            date_time = f\"{date} {proc_data['time']}\"\n            ts = jc.utils.timestamp(date_time, format_hint=(7250,))\n            proc_data['epoch'] = ts.naive\n    return proc_data",
            "def _process(proc_data: Dict) -> Dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Final processing to conform to the schema.\\n\\n    Parameters:\\n\\n        proc_data:   (Dictionary) raw structured data to process\\n\\n    Returns:\\n\\n        Dictionary. Structured data to conform to the schema.\\n    '\n    int_list = {'process', 'sent', 'received', 'total_size', 'matches', 'hash_hits', 'false_alarms', 'data'}\n    float_list = {'bytes_sec', 'speedup'}\n    for key in proc_data.copy():\n        if key in int_list:\n            proc_data[key] = jc.utils.convert_to_int(proc_data[key])\n        if key in float_list:\n            proc_data[key] = jc.utils.convert_to_float(proc_data[key])\n        if 'date' in proc_data and 'time' in proc_data:\n            date = proc_data['date'].replace('/', '-')\n            date_time = f\"{date} {proc_data['time']}\"\n            ts = jc.utils.timestamp(date_time, format_hint=(7250,))\n            proc_data['epoch'] = ts.naive\n    return proc_data",
            "def _process(proc_data: Dict) -> Dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Final processing to conform to the schema.\\n\\n    Parameters:\\n\\n        proc_data:   (Dictionary) raw structured data to process\\n\\n    Returns:\\n\\n        Dictionary. Structured data to conform to the schema.\\n    '\n    int_list = {'process', 'sent', 'received', 'total_size', 'matches', 'hash_hits', 'false_alarms', 'data'}\n    float_list = {'bytes_sec', 'speedup'}\n    for key in proc_data.copy():\n        if key in int_list:\n            proc_data[key] = jc.utils.convert_to_int(proc_data[key])\n        if key in float_list:\n            proc_data[key] = jc.utils.convert_to_float(proc_data[key])\n        if 'date' in proc_data and 'time' in proc_data:\n            date = proc_data['date'].replace('/', '-')\n            date_time = f\"{date} {proc_data['time']}\"\n            ts = jc.utils.timestamp(date_time, format_hint=(7250,))\n            proc_data['epoch'] = ts.naive\n    return proc_data",
            "def _process(proc_data: Dict) -> Dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Final processing to conform to the schema.\\n\\n    Parameters:\\n\\n        proc_data:   (Dictionary) raw structured data to process\\n\\n    Returns:\\n\\n        Dictionary. Structured data to conform to the schema.\\n    '\n    int_list = {'process', 'sent', 'received', 'total_size', 'matches', 'hash_hits', 'false_alarms', 'data'}\n    float_list = {'bytes_sec', 'speedup'}\n    for key in proc_data.copy():\n        if key in int_list:\n            proc_data[key] = jc.utils.convert_to_int(proc_data[key])\n        if key in float_list:\n            proc_data[key] = jc.utils.convert_to_float(proc_data[key])\n        if 'date' in proc_data and 'time' in proc_data:\n            date = proc_data['date'].replace('/', '-')\n            date_time = f\"{date} {proc_data['time']}\"\n            ts = jc.utils.timestamp(date_time, format_hint=(7250,))\n            proc_data['epoch'] = ts.naive\n    return proc_data"
        ]
    },
    {
        "func_name": "parse",
        "original": "@add_jc_meta\ndef parse(data: Iterable[str], raw: bool=False, quiet: bool=False, ignore_exceptions: bool=False) -> Union[Iterable[Dict], tuple]:\n    \"\"\"\n    Main text parsing generator function. Returns an iterable object.\n\n    Parameters:\n\n        data:              (iterable)  line-based text data to parse\n                                       (e.g. sys.stdin or str.splitlines())\n\n        raw:               (boolean)   unprocessed output if True\n        quiet:             (boolean)   suppress warning messages if True\n        ignore_exceptions: (boolean)   ignore parsing exceptions if True\n\n    Returns:\n\n        Iterable of Dictionaries\n    \"\"\"\n    jc.utils.compatibility(__name__, info.compatible, quiet)\n    streaming_input_type_check(data)\n    summary: Dict = {}\n    process: str = ''\n    last_process: str = ''\n    update_type = {'<': 'file sent', '>': 'file received', 'c': 'local change or creation', 'h': 'hard link', '.': 'not updated', '*': 'message', '+': None}\n    file_type = {'f': 'file', 'd': 'directory', 'L': 'symlink', 'D': 'device', 'S': 'special file', '+': None}\n    checksum_or_value_different = {'c': True, '.': False, '+': None, ' ': None, '?': None}\n    size_different = {'s': True, '.': False, '+': None, ' ': None, '?': None}\n    modification_time_different = {'t': True, '.': False, '+': None, ' ': None, '?': None}\n    permissions_different = {'p': True, '.': False, '+': None, ' ': None, '?': None}\n    owner_different = {'o': True, '.': False, '+': None, ' ': None, '?': None}\n    group_different = {'g': True, '.': False, '+': None, ' ': None, '?': None}\n    acl_different = {'a': True, '.': False, '+': None, ' ': None, '?': None}\n    extended_attribute_different = {'x': True, '.': False, '+': None, ' ': None, '?': None}\n    file_line_re = re.compile('(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][u.+ ?][a.+ ?][x.+ ?]) (?P<name>.+)')\n    file_line_mac_re = re.compile('(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][x.+ ?]) (?P<name>.+)')\n    stat1_line_re = re.compile('(sent)\\\\s+(?P<sent>[0-9,]+)\\\\s+(bytes)\\\\s+(received)\\\\s+(?P<received>[0-9,]+)\\\\s+(bytes)\\\\s+(?P<bytes_sec>[0-9,.]+)\\\\s+(bytes/sec)')\n    stat2_line_re = re.compile('(total size is)\\\\s+(?P<total_size>[0-9,]+)\\\\s+(speedup is)\\\\s+(?P<speedup>[0-9,.]+)')\n    file_line_log_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][u.+ ?][a.+ ?][x.+ ?]) (?P<name>.+)')\n    file_line_log_mac_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][x.+ ?]) (?P<name>.+)')\n    stat_line_log_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+sent\\\\s+(?P<sent>[\\\\d,]+)\\\\s+bytes\\\\s+received\\\\s+(?P<received>[\\\\d,]+)\\\\s+bytes\\\\s+total\\\\s+size\\\\s+(?P<total_size>[\\\\d,]+)')\n    stat1_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)]\\\\s+total:\\\\s+matches=(?P<matches>[\\\\d,]+)\\\\s+hash_hits=(?P<hash_hits>[\\\\d,]+)\\\\s+false_alarms=(?P<false_alarms>[\\\\d,]+)\\\\s+data=(?P<data>[\\\\d,]+)')\n    stat2_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+sent\\\\s+(?P<sent>[\\\\d,]+)\\\\s+bytes\\\\s+received\\\\s+(?P<received>[\\\\d,]+)\\\\s+bytes\\\\s+(?P<bytes_sec>[\\\\d,.]+)\\\\s+bytes/sec')\n    stat3_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)]\\\\s+total\\\\s+size\\\\s+is\\\\s+(?P<total_size>[\\\\d,]+)\\\\s+speedup\\\\s+is\\\\s+(?P<speedup>[\\\\d,.]+)')\n    for line in data:\n        try:\n            streaming_line_input_type_check(line)\n            output_line: Dict = {}\n            if not line.strip():\n                continue\n            file_line = file_line_re.match(line)\n            if file_line:\n                filename = file_line.group('name')\n                meta = file_line.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]], 'acl_different': acl_different[meta[9]], 'extended_attribute_different': extended_attribute_different[meta[10]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_mac = file_line_mac_re.match(line)\n            if file_line_mac:\n                filename = file_line_mac.group('name')\n                meta = file_line_mac.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_log = file_line_log_re.match(line)\n            if file_line_log:\n                if process != last_process:\n                    if summary:\n                        yield (output_line if raw else _process(output_line))\n                    last_process = process\n                    summary = {}\n                filename = file_line_log.group('name')\n                date = file_line_log.group('date')\n                time = file_line_log.group('time')\n                process = file_line_log.group('process')\n                meta = file_line_log.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'date': date, 'time': time, 'process': process, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]], 'acl_different': acl_different[meta[9]], 'extended_attribute_different': extended_attribute_different[meta[10]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_log_mac = file_line_log_mac_re.match(line)\n            if file_line_log_mac:\n                if process != last_process:\n                    if summary:\n                        yield (output_line if raw else _process(output_line))\n                    last_process = process\n                    summary = {}\n                filename = file_line_log_mac.group('name')\n                date = file_line_log_mac.group('date')\n                time = file_line_log_mac.group('time')\n                process = file_line_log_mac.group('process')\n                meta = file_line_log_mac.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'date': date, 'time': time, 'process': process, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            stat1_line = stat1_line_re.match(line)\n            if stat1_line:\n                summary = {'type': 'summary', 'sent': stat1_line.group('sent'), 'received': stat1_line.group('received'), 'bytes_sec': stat1_line.group('bytes_sec')}\n                continue\n            stat2_line = stat2_line_re.match(line)\n            if stat2_line:\n                summary['total_size'] = stat2_line.group('total_size')\n                summary['speedup'] = stat2_line.group('speedup')\n                continue\n            stat_line_log = stat_line_log_re.match(line)\n            if stat_line_log:\n                summary = {'type': 'summary', 'date': stat_line_log.group('date'), 'time': stat_line_log.group('time'), 'process': stat_line_log.group('process'), 'sent': stat_line_log.group('sent'), 'received': stat_line_log.group('received'), 'total_size': stat_line_log.group('total_size')}\n                continue\n            stat1_line_log_v = stat1_line_log_v_re.match(line)\n            if stat1_line_log_v:\n                summary = {'type': 'summary', 'date': stat1_line_log_v.group('date'), 'time': stat1_line_log_v.group('time'), 'process': stat1_line_log_v.group('process'), 'matches': stat1_line_log_v.group('matches'), 'hash_hits': stat1_line_log_v.group('hash_hits'), 'false_alarms': stat1_line_log_v.group('false_alarms'), 'data': stat1_line_log_v.group('data')}\n                continue\n            stat2_line_log_v = stat2_line_log_v_re.match(line)\n            if stat2_line_log_v:\n                summary['sent'] = stat2_line_log_v.group('sent')\n                summary['received'] = stat2_line_log_v.group('received')\n                summary['bytes_sec'] = stat2_line_log_v.group('bytes_sec')\n                continue\n            stat3_line_log_v = stat3_line_log_v_re.match(line)\n            if stat3_line_log_v:\n                summary['total_size'] = stat3_line_log_v.group('total_size')\n                summary['speedup'] = stat3_line_log_v.group('speedup')\n                continue\n        except Exception as e:\n            yield raise_or_yield(ignore_exceptions, e, line)\n    try:\n        if summary:\n            yield (summary if raw else _process(summary))\n    except Exception as e:\n        yield raise_or_yield(ignore_exceptions, e, '')",
        "mutated": [
            "@add_jc_meta\ndef parse(data: Iterable[str], raw: bool=False, quiet: bool=False, ignore_exceptions: bool=False) -> Union[Iterable[Dict], tuple]:\n    if False:\n        i = 10\n    '\\n    Main text parsing generator function. Returns an iterable object.\\n\\n    Parameters:\\n\\n        data:              (iterable)  line-based text data to parse\\n                                       (e.g. sys.stdin or str.splitlines())\\n\\n        raw:               (boolean)   unprocessed output if True\\n        quiet:             (boolean)   suppress warning messages if True\\n        ignore_exceptions: (boolean)   ignore parsing exceptions if True\\n\\n    Returns:\\n\\n        Iterable of Dictionaries\\n    '\n    jc.utils.compatibility(__name__, info.compatible, quiet)\n    streaming_input_type_check(data)\n    summary: Dict = {}\n    process: str = ''\n    last_process: str = ''\n    update_type = {'<': 'file sent', '>': 'file received', 'c': 'local change or creation', 'h': 'hard link', '.': 'not updated', '*': 'message', '+': None}\n    file_type = {'f': 'file', 'd': 'directory', 'L': 'symlink', 'D': 'device', 'S': 'special file', '+': None}\n    checksum_or_value_different = {'c': True, '.': False, '+': None, ' ': None, '?': None}\n    size_different = {'s': True, '.': False, '+': None, ' ': None, '?': None}\n    modification_time_different = {'t': True, '.': False, '+': None, ' ': None, '?': None}\n    permissions_different = {'p': True, '.': False, '+': None, ' ': None, '?': None}\n    owner_different = {'o': True, '.': False, '+': None, ' ': None, '?': None}\n    group_different = {'g': True, '.': False, '+': None, ' ': None, '?': None}\n    acl_different = {'a': True, '.': False, '+': None, ' ': None, '?': None}\n    extended_attribute_different = {'x': True, '.': False, '+': None, ' ': None, '?': None}\n    file_line_re = re.compile('(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][u.+ ?][a.+ ?][x.+ ?]) (?P<name>.+)')\n    file_line_mac_re = re.compile('(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][x.+ ?]) (?P<name>.+)')\n    stat1_line_re = re.compile('(sent)\\\\s+(?P<sent>[0-9,]+)\\\\s+(bytes)\\\\s+(received)\\\\s+(?P<received>[0-9,]+)\\\\s+(bytes)\\\\s+(?P<bytes_sec>[0-9,.]+)\\\\s+(bytes/sec)')\n    stat2_line_re = re.compile('(total size is)\\\\s+(?P<total_size>[0-9,]+)\\\\s+(speedup is)\\\\s+(?P<speedup>[0-9,.]+)')\n    file_line_log_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][u.+ ?][a.+ ?][x.+ ?]) (?P<name>.+)')\n    file_line_log_mac_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][x.+ ?]) (?P<name>.+)')\n    stat_line_log_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+sent\\\\s+(?P<sent>[\\\\d,]+)\\\\s+bytes\\\\s+received\\\\s+(?P<received>[\\\\d,]+)\\\\s+bytes\\\\s+total\\\\s+size\\\\s+(?P<total_size>[\\\\d,]+)')\n    stat1_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)]\\\\s+total:\\\\s+matches=(?P<matches>[\\\\d,]+)\\\\s+hash_hits=(?P<hash_hits>[\\\\d,]+)\\\\s+false_alarms=(?P<false_alarms>[\\\\d,]+)\\\\s+data=(?P<data>[\\\\d,]+)')\n    stat2_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+sent\\\\s+(?P<sent>[\\\\d,]+)\\\\s+bytes\\\\s+received\\\\s+(?P<received>[\\\\d,]+)\\\\s+bytes\\\\s+(?P<bytes_sec>[\\\\d,.]+)\\\\s+bytes/sec')\n    stat3_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)]\\\\s+total\\\\s+size\\\\s+is\\\\s+(?P<total_size>[\\\\d,]+)\\\\s+speedup\\\\s+is\\\\s+(?P<speedup>[\\\\d,.]+)')\n    for line in data:\n        try:\n            streaming_line_input_type_check(line)\n            output_line: Dict = {}\n            if not line.strip():\n                continue\n            file_line = file_line_re.match(line)\n            if file_line:\n                filename = file_line.group('name')\n                meta = file_line.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]], 'acl_different': acl_different[meta[9]], 'extended_attribute_different': extended_attribute_different[meta[10]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_mac = file_line_mac_re.match(line)\n            if file_line_mac:\n                filename = file_line_mac.group('name')\n                meta = file_line_mac.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_log = file_line_log_re.match(line)\n            if file_line_log:\n                if process != last_process:\n                    if summary:\n                        yield (output_line if raw else _process(output_line))\n                    last_process = process\n                    summary = {}\n                filename = file_line_log.group('name')\n                date = file_line_log.group('date')\n                time = file_line_log.group('time')\n                process = file_line_log.group('process')\n                meta = file_line_log.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'date': date, 'time': time, 'process': process, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]], 'acl_different': acl_different[meta[9]], 'extended_attribute_different': extended_attribute_different[meta[10]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_log_mac = file_line_log_mac_re.match(line)\n            if file_line_log_mac:\n                if process != last_process:\n                    if summary:\n                        yield (output_line if raw else _process(output_line))\n                    last_process = process\n                    summary = {}\n                filename = file_line_log_mac.group('name')\n                date = file_line_log_mac.group('date')\n                time = file_line_log_mac.group('time')\n                process = file_line_log_mac.group('process')\n                meta = file_line_log_mac.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'date': date, 'time': time, 'process': process, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            stat1_line = stat1_line_re.match(line)\n            if stat1_line:\n                summary = {'type': 'summary', 'sent': stat1_line.group('sent'), 'received': stat1_line.group('received'), 'bytes_sec': stat1_line.group('bytes_sec')}\n                continue\n            stat2_line = stat2_line_re.match(line)\n            if stat2_line:\n                summary['total_size'] = stat2_line.group('total_size')\n                summary['speedup'] = stat2_line.group('speedup')\n                continue\n            stat_line_log = stat_line_log_re.match(line)\n            if stat_line_log:\n                summary = {'type': 'summary', 'date': stat_line_log.group('date'), 'time': stat_line_log.group('time'), 'process': stat_line_log.group('process'), 'sent': stat_line_log.group('sent'), 'received': stat_line_log.group('received'), 'total_size': stat_line_log.group('total_size')}\n                continue\n            stat1_line_log_v = stat1_line_log_v_re.match(line)\n            if stat1_line_log_v:\n                summary = {'type': 'summary', 'date': stat1_line_log_v.group('date'), 'time': stat1_line_log_v.group('time'), 'process': stat1_line_log_v.group('process'), 'matches': stat1_line_log_v.group('matches'), 'hash_hits': stat1_line_log_v.group('hash_hits'), 'false_alarms': stat1_line_log_v.group('false_alarms'), 'data': stat1_line_log_v.group('data')}\n                continue\n            stat2_line_log_v = stat2_line_log_v_re.match(line)\n            if stat2_line_log_v:\n                summary['sent'] = stat2_line_log_v.group('sent')\n                summary['received'] = stat2_line_log_v.group('received')\n                summary['bytes_sec'] = stat2_line_log_v.group('bytes_sec')\n                continue\n            stat3_line_log_v = stat3_line_log_v_re.match(line)\n            if stat3_line_log_v:\n                summary['total_size'] = stat3_line_log_v.group('total_size')\n                summary['speedup'] = stat3_line_log_v.group('speedup')\n                continue\n        except Exception as e:\n            yield raise_or_yield(ignore_exceptions, e, line)\n    try:\n        if summary:\n            yield (summary if raw else _process(summary))\n    except Exception as e:\n        yield raise_or_yield(ignore_exceptions, e, '')",
            "@add_jc_meta\ndef parse(data: Iterable[str], raw: bool=False, quiet: bool=False, ignore_exceptions: bool=False) -> Union[Iterable[Dict], tuple]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Main text parsing generator function. Returns an iterable object.\\n\\n    Parameters:\\n\\n        data:              (iterable)  line-based text data to parse\\n                                       (e.g. sys.stdin or str.splitlines())\\n\\n        raw:               (boolean)   unprocessed output if True\\n        quiet:             (boolean)   suppress warning messages if True\\n        ignore_exceptions: (boolean)   ignore parsing exceptions if True\\n\\n    Returns:\\n\\n        Iterable of Dictionaries\\n    '\n    jc.utils.compatibility(__name__, info.compatible, quiet)\n    streaming_input_type_check(data)\n    summary: Dict = {}\n    process: str = ''\n    last_process: str = ''\n    update_type = {'<': 'file sent', '>': 'file received', 'c': 'local change or creation', 'h': 'hard link', '.': 'not updated', '*': 'message', '+': None}\n    file_type = {'f': 'file', 'd': 'directory', 'L': 'symlink', 'D': 'device', 'S': 'special file', '+': None}\n    checksum_or_value_different = {'c': True, '.': False, '+': None, ' ': None, '?': None}\n    size_different = {'s': True, '.': False, '+': None, ' ': None, '?': None}\n    modification_time_different = {'t': True, '.': False, '+': None, ' ': None, '?': None}\n    permissions_different = {'p': True, '.': False, '+': None, ' ': None, '?': None}\n    owner_different = {'o': True, '.': False, '+': None, ' ': None, '?': None}\n    group_different = {'g': True, '.': False, '+': None, ' ': None, '?': None}\n    acl_different = {'a': True, '.': False, '+': None, ' ': None, '?': None}\n    extended_attribute_different = {'x': True, '.': False, '+': None, ' ': None, '?': None}\n    file_line_re = re.compile('(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][u.+ ?][a.+ ?][x.+ ?]) (?P<name>.+)')\n    file_line_mac_re = re.compile('(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][x.+ ?]) (?P<name>.+)')\n    stat1_line_re = re.compile('(sent)\\\\s+(?P<sent>[0-9,]+)\\\\s+(bytes)\\\\s+(received)\\\\s+(?P<received>[0-9,]+)\\\\s+(bytes)\\\\s+(?P<bytes_sec>[0-9,.]+)\\\\s+(bytes/sec)')\n    stat2_line_re = re.compile('(total size is)\\\\s+(?P<total_size>[0-9,]+)\\\\s+(speedup is)\\\\s+(?P<speedup>[0-9,.]+)')\n    file_line_log_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][u.+ ?][a.+ ?][x.+ ?]) (?P<name>.+)')\n    file_line_log_mac_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][x.+ ?]) (?P<name>.+)')\n    stat_line_log_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+sent\\\\s+(?P<sent>[\\\\d,]+)\\\\s+bytes\\\\s+received\\\\s+(?P<received>[\\\\d,]+)\\\\s+bytes\\\\s+total\\\\s+size\\\\s+(?P<total_size>[\\\\d,]+)')\n    stat1_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)]\\\\s+total:\\\\s+matches=(?P<matches>[\\\\d,]+)\\\\s+hash_hits=(?P<hash_hits>[\\\\d,]+)\\\\s+false_alarms=(?P<false_alarms>[\\\\d,]+)\\\\s+data=(?P<data>[\\\\d,]+)')\n    stat2_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+sent\\\\s+(?P<sent>[\\\\d,]+)\\\\s+bytes\\\\s+received\\\\s+(?P<received>[\\\\d,]+)\\\\s+bytes\\\\s+(?P<bytes_sec>[\\\\d,.]+)\\\\s+bytes/sec')\n    stat3_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)]\\\\s+total\\\\s+size\\\\s+is\\\\s+(?P<total_size>[\\\\d,]+)\\\\s+speedup\\\\s+is\\\\s+(?P<speedup>[\\\\d,.]+)')\n    for line in data:\n        try:\n            streaming_line_input_type_check(line)\n            output_line: Dict = {}\n            if not line.strip():\n                continue\n            file_line = file_line_re.match(line)\n            if file_line:\n                filename = file_line.group('name')\n                meta = file_line.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]], 'acl_different': acl_different[meta[9]], 'extended_attribute_different': extended_attribute_different[meta[10]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_mac = file_line_mac_re.match(line)\n            if file_line_mac:\n                filename = file_line_mac.group('name')\n                meta = file_line_mac.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_log = file_line_log_re.match(line)\n            if file_line_log:\n                if process != last_process:\n                    if summary:\n                        yield (output_line if raw else _process(output_line))\n                    last_process = process\n                    summary = {}\n                filename = file_line_log.group('name')\n                date = file_line_log.group('date')\n                time = file_line_log.group('time')\n                process = file_line_log.group('process')\n                meta = file_line_log.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'date': date, 'time': time, 'process': process, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]], 'acl_different': acl_different[meta[9]], 'extended_attribute_different': extended_attribute_different[meta[10]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_log_mac = file_line_log_mac_re.match(line)\n            if file_line_log_mac:\n                if process != last_process:\n                    if summary:\n                        yield (output_line if raw else _process(output_line))\n                    last_process = process\n                    summary = {}\n                filename = file_line_log_mac.group('name')\n                date = file_line_log_mac.group('date')\n                time = file_line_log_mac.group('time')\n                process = file_line_log_mac.group('process')\n                meta = file_line_log_mac.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'date': date, 'time': time, 'process': process, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            stat1_line = stat1_line_re.match(line)\n            if stat1_line:\n                summary = {'type': 'summary', 'sent': stat1_line.group('sent'), 'received': stat1_line.group('received'), 'bytes_sec': stat1_line.group('bytes_sec')}\n                continue\n            stat2_line = stat2_line_re.match(line)\n            if stat2_line:\n                summary['total_size'] = stat2_line.group('total_size')\n                summary['speedup'] = stat2_line.group('speedup')\n                continue\n            stat_line_log = stat_line_log_re.match(line)\n            if stat_line_log:\n                summary = {'type': 'summary', 'date': stat_line_log.group('date'), 'time': stat_line_log.group('time'), 'process': stat_line_log.group('process'), 'sent': stat_line_log.group('sent'), 'received': stat_line_log.group('received'), 'total_size': stat_line_log.group('total_size')}\n                continue\n            stat1_line_log_v = stat1_line_log_v_re.match(line)\n            if stat1_line_log_v:\n                summary = {'type': 'summary', 'date': stat1_line_log_v.group('date'), 'time': stat1_line_log_v.group('time'), 'process': stat1_line_log_v.group('process'), 'matches': stat1_line_log_v.group('matches'), 'hash_hits': stat1_line_log_v.group('hash_hits'), 'false_alarms': stat1_line_log_v.group('false_alarms'), 'data': stat1_line_log_v.group('data')}\n                continue\n            stat2_line_log_v = stat2_line_log_v_re.match(line)\n            if stat2_line_log_v:\n                summary['sent'] = stat2_line_log_v.group('sent')\n                summary['received'] = stat2_line_log_v.group('received')\n                summary['bytes_sec'] = stat2_line_log_v.group('bytes_sec')\n                continue\n            stat3_line_log_v = stat3_line_log_v_re.match(line)\n            if stat3_line_log_v:\n                summary['total_size'] = stat3_line_log_v.group('total_size')\n                summary['speedup'] = stat3_line_log_v.group('speedup')\n                continue\n        except Exception as e:\n            yield raise_or_yield(ignore_exceptions, e, line)\n    try:\n        if summary:\n            yield (summary if raw else _process(summary))\n    except Exception as e:\n        yield raise_or_yield(ignore_exceptions, e, '')",
            "@add_jc_meta\ndef parse(data: Iterable[str], raw: bool=False, quiet: bool=False, ignore_exceptions: bool=False) -> Union[Iterable[Dict], tuple]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Main text parsing generator function. Returns an iterable object.\\n\\n    Parameters:\\n\\n        data:              (iterable)  line-based text data to parse\\n                                       (e.g. sys.stdin or str.splitlines())\\n\\n        raw:               (boolean)   unprocessed output if True\\n        quiet:             (boolean)   suppress warning messages if True\\n        ignore_exceptions: (boolean)   ignore parsing exceptions if True\\n\\n    Returns:\\n\\n        Iterable of Dictionaries\\n    '\n    jc.utils.compatibility(__name__, info.compatible, quiet)\n    streaming_input_type_check(data)\n    summary: Dict = {}\n    process: str = ''\n    last_process: str = ''\n    update_type = {'<': 'file sent', '>': 'file received', 'c': 'local change or creation', 'h': 'hard link', '.': 'not updated', '*': 'message', '+': None}\n    file_type = {'f': 'file', 'd': 'directory', 'L': 'symlink', 'D': 'device', 'S': 'special file', '+': None}\n    checksum_or_value_different = {'c': True, '.': False, '+': None, ' ': None, '?': None}\n    size_different = {'s': True, '.': False, '+': None, ' ': None, '?': None}\n    modification_time_different = {'t': True, '.': False, '+': None, ' ': None, '?': None}\n    permissions_different = {'p': True, '.': False, '+': None, ' ': None, '?': None}\n    owner_different = {'o': True, '.': False, '+': None, ' ': None, '?': None}\n    group_different = {'g': True, '.': False, '+': None, ' ': None, '?': None}\n    acl_different = {'a': True, '.': False, '+': None, ' ': None, '?': None}\n    extended_attribute_different = {'x': True, '.': False, '+': None, ' ': None, '?': None}\n    file_line_re = re.compile('(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][u.+ ?][a.+ ?][x.+ ?]) (?P<name>.+)')\n    file_line_mac_re = re.compile('(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][x.+ ?]) (?P<name>.+)')\n    stat1_line_re = re.compile('(sent)\\\\s+(?P<sent>[0-9,]+)\\\\s+(bytes)\\\\s+(received)\\\\s+(?P<received>[0-9,]+)\\\\s+(bytes)\\\\s+(?P<bytes_sec>[0-9,.]+)\\\\s+(bytes/sec)')\n    stat2_line_re = re.compile('(total size is)\\\\s+(?P<total_size>[0-9,]+)\\\\s+(speedup is)\\\\s+(?P<speedup>[0-9,.]+)')\n    file_line_log_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][u.+ ?][a.+ ?][x.+ ?]) (?P<name>.+)')\n    file_line_log_mac_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][x.+ ?]) (?P<name>.+)')\n    stat_line_log_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+sent\\\\s+(?P<sent>[\\\\d,]+)\\\\s+bytes\\\\s+received\\\\s+(?P<received>[\\\\d,]+)\\\\s+bytes\\\\s+total\\\\s+size\\\\s+(?P<total_size>[\\\\d,]+)')\n    stat1_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)]\\\\s+total:\\\\s+matches=(?P<matches>[\\\\d,]+)\\\\s+hash_hits=(?P<hash_hits>[\\\\d,]+)\\\\s+false_alarms=(?P<false_alarms>[\\\\d,]+)\\\\s+data=(?P<data>[\\\\d,]+)')\n    stat2_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+sent\\\\s+(?P<sent>[\\\\d,]+)\\\\s+bytes\\\\s+received\\\\s+(?P<received>[\\\\d,]+)\\\\s+bytes\\\\s+(?P<bytes_sec>[\\\\d,.]+)\\\\s+bytes/sec')\n    stat3_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)]\\\\s+total\\\\s+size\\\\s+is\\\\s+(?P<total_size>[\\\\d,]+)\\\\s+speedup\\\\s+is\\\\s+(?P<speedup>[\\\\d,.]+)')\n    for line in data:\n        try:\n            streaming_line_input_type_check(line)\n            output_line: Dict = {}\n            if not line.strip():\n                continue\n            file_line = file_line_re.match(line)\n            if file_line:\n                filename = file_line.group('name')\n                meta = file_line.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]], 'acl_different': acl_different[meta[9]], 'extended_attribute_different': extended_attribute_different[meta[10]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_mac = file_line_mac_re.match(line)\n            if file_line_mac:\n                filename = file_line_mac.group('name')\n                meta = file_line_mac.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_log = file_line_log_re.match(line)\n            if file_line_log:\n                if process != last_process:\n                    if summary:\n                        yield (output_line if raw else _process(output_line))\n                    last_process = process\n                    summary = {}\n                filename = file_line_log.group('name')\n                date = file_line_log.group('date')\n                time = file_line_log.group('time')\n                process = file_line_log.group('process')\n                meta = file_line_log.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'date': date, 'time': time, 'process': process, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]], 'acl_different': acl_different[meta[9]], 'extended_attribute_different': extended_attribute_different[meta[10]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_log_mac = file_line_log_mac_re.match(line)\n            if file_line_log_mac:\n                if process != last_process:\n                    if summary:\n                        yield (output_line if raw else _process(output_line))\n                    last_process = process\n                    summary = {}\n                filename = file_line_log_mac.group('name')\n                date = file_line_log_mac.group('date')\n                time = file_line_log_mac.group('time')\n                process = file_line_log_mac.group('process')\n                meta = file_line_log_mac.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'date': date, 'time': time, 'process': process, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            stat1_line = stat1_line_re.match(line)\n            if stat1_line:\n                summary = {'type': 'summary', 'sent': stat1_line.group('sent'), 'received': stat1_line.group('received'), 'bytes_sec': stat1_line.group('bytes_sec')}\n                continue\n            stat2_line = stat2_line_re.match(line)\n            if stat2_line:\n                summary['total_size'] = stat2_line.group('total_size')\n                summary['speedup'] = stat2_line.group('speedup')\n                continue\n            stat_line_log = stat_line_log_re.match(line)\n            if stat_line_log:\n                summary = {'type': 'summary', 'date': stat_line_log.group('date'), 'time': stat_line_log.group('time'), 'process': stat_line_log.group('process'), 'sent': stat_line_log.group('sent'), 'received': stat_line_log.group('received'), 'total_size': stat_line_log.group('total_size')}\n                continue\n            stat1_line_log_v = stat1_line_log_v_re.match(line)\n            if stat1_line_log_v:\n                summary = {'type': 'summary', 'date': stat1_line_log_v.group('date'), 'time': stat1_line_log_v.group('time'), 'process': stat1_line_log_v.group('process'), 'matches': stat1_line_log_v.group('matches'), 'hash_hits': stat1_line_log_v.group('hash_hits'), 'false_alarms': stat1_line_log_v.group('false_alarms'), 'data': stat1_line_log_v.group('data')}\n                continue\n            stat2_line_log_v = stat2_line_log_v_re.match(line)\n            if stat2_line_log_v:\n                summary['sent'] = stat2_line_log_v.group('sent')\n                summary['received'] = stat2_line_log_v.group('received')\n                summary['bytes_sec'] = stat2_line_log_v.group('bytes_sec')\n                continue\n            stat3_line_log_v = stat3_line_log_v_re.match(line)\n            if stat3_line_log_v:\n                summary['total_size'] = stat3_line_log_v.group('total_size')\n                summary['speedup'] = stat3_line_log_v.group('speedup')\n                continue\n        except Exception as e:\n            yield raise_or_yield(ignore_exceptions, e, line)\n    try:\n        if summary:\n            yield (summary if raw else _process(summary))\n    except Exception as e:\n        yield raise_or_yield(ignore_exceptions, e, '')",
            "@add_jc_meta\ndef parse(data: Iterable[str], raw: bool=False, quiet: bool=False, ignore_exceptions: bool=False) -> Union[Iterable[Dict], tuple]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Main text parsing generator function. Returns an iterable object.\\n\\n    Parameters:\\n\\n        data:              (iterable)  line-based text data to parse\\n                                       (e.g. sys.stdin or str.splitlines())\\n\\n        raw:               (boolean)   unprocessed output if True\\n        quiet:             (boolean)   suppress warning messages if True\\n        ignore_exceptions: (boolean)   ignore parsing exceptions if True\\n\\n    Returns:\\n\\n        Iterable of Dictionaries\\n    '\n    jc.utils.compatibility(__name__, info.compatible, quiet)\n    streaming_input_type_check(data)\n    summary: Dict = {}\n    process: str = ''\n    last_process: str = ''\n    update_type = {'<': 'file sent', '>': 'file received', 'c': 'local change or creation', 'h': 'hard link', '.': 'not updated', '*': 'message', '+': None}\n    file_type = {'f': 'file', 'd': 'directory', 'L': 'symlink', 'D': 'device', 'S': 'special file', '+': None}\n    checksum_or_value_different = {'c': True, '.': False, '+': None, ' ': None, '?': None}\n    size_different = {'s': True, '.': False, '+': None, ' ': None, '?': None}\n    modification_time_different = {'t': True, '.': False, '+': None, ' ': None, '?': None}\n    permissions_different = {'p': True, '.': False, '+': None, ' ': None, '?': None}\n    owner_different = {'o': True, '.': False, '+': None, ' ': None, '?': None}\n    group_different = {'g': True, '.': False, '+': None, ' ': None, '?': None}\n    acl_different = {'a': True, '.': False, '+': None, ' ': None, '?': None}\n    extended_attribute_different = {'x': True, '.': False, '+': None, ' ': None, '?': None}\n    file_line_re = re.compile('(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][u.+ ?][a.+ ?][x.+ ?]) (?P<name>.+)')\n    file_line_mac_re = re.compile('(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][x.+ ?]) (?P<name>.+)')\n    stat1_line_re = re.compile('(sent)\\\\s+(?P<sent>[0-9,]+)\\\\s+(bytes)\\\\s+(received)\\\\s+(?P<received>[0-9,]+)\\\\s+(bytes)\\\\s+(?P<bytes_sec>[0-9,.]+)\\\\s+(bytes/sec)')\n    stat2_line_re = re.compile('(total size is)\\\\s+(?P<total_size>[0-9,]+)\\\\s+(speedup is)\\\\s+(?P<speedup>[0-9,.]+)')\n    file_line_log_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][u.+ ?][a.+ ?][x.+ ?]) (?P<name>.+)')\n    file_line_log_mac_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][x.+ ?]) (?P<name>.+)')\n    stat_line_log_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+sent\\\\s+(?P<sent>[\\\\d,]+)\\\\s+bytes\\\\s+received\\\\s+(?P<received>[\\\\d,]+)\\\\s+bytes\\\\s+total\\\\s+size\\\\s+(?P<total_size>[\\\\d,]+)')\n    stat1_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)]\\\\s+total:\\\\s+matches=(?P<matches>[\\\\d,]+)\\\\s+hash_hits=(?P<hash_hits>[\\\\d,]+)\\\\s+false_alarms=(?P<false_alarms>[\\\\d,]+)\\\\s+data=(?P<data>[\\\\d,]+)')\n    stat2_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+sent\\\\s+(?P<sent>[\\\\d,]+)\\\\s+bytes\\\\s+received\\\\s+(?P<received>[\\\\d,]+)\\\\s+bytes\\\\s+(?P<bytes_sec>[\\\\d,.]+)\\\\s+bytes/sec')\n    stat3_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)]\\\\s+total\\\\s+size\\\\s+is\\\\s+(?P<total_size>[\\\\d,]+)\\\\s+speedup\\\\s+is\\\\s+(?P<speedup>[\\\\d,.]+)')\n    for line in data:\n        try:\n            streaming_line_input_type_check(line)\n            output_line: Dict = {}\n            if not line.strip():\n                continue\n            file_line = file_line_re.match(line)\n            if file_line:\n                filename = file_line.group('name')\n                meta = file_line.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]], 'acl_different': acl_different[meta[9]], 'extended_attribute_different': extended_attribute_different[meta[10]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_mac = file_line_mac_re.match(line)\n            if file_line_mac:\n                filename = file_line_mac.group('name')\n                meta = file_line_mac.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_log = file_line_log_re.match(line)\n            if file_line_log:\n                if process != last_process:\n                    if summary:\n                        yield (output_line if raw else _process(output_line))\n                    last_process = process\n                    summary = {}\n                filename = file_line_log.group('name')\n                date = file_line_log.group('date')\n                time = file_line_log.group('time')\n                process = file_line_log.group('process')\n                meta = file_line_log.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'date': date, 'time': time, 'process': process, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]], 'acl_different': acl_different[meta[9]], 'extended_attribute_different': extended_attribute_different[meta[10]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_log_mac = file_line_log_mac_re.match(line)\n            if file_line_log_mac:\n                if process != last_process:\n                    if summary:\n                        yield (output_line if raw else _process(output_line))\n                    last_process = process\n                    summary = {}\n                filename = file_line_log_mac.group('name')\n                date = file_line_log_mac.group('date')\n                time = file_line_log_mac.group('time')\n                process = file_line_log_mac.group('process')\n                meta = file_line_log_mac.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'date': date, 'time': time, 'process': process, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            stat1_line = stat1_line_re.match(line)\n            if stat1_line:\n                summary = {'type': 'summary', 'sent': stat1_line.group('sent'), 'received': stat1_line.group('received'), 'bytes_sec': stat1_line.group('bytes_sec')}\n                continue\n            stat2_line = stat2_line_re.match(line)\n            if stat2_line:\n                summary['total_size'] = stat2_line.group('total_size')\n                summary['speedup'] = stat2_line.group('speedup')\n                continue\n            stat_line_log = stat_line_log_re.match(line)\n            if stat_line_log:\n                summary = {'type': 'summary', 'date': stat_line_log.group('date'), 'time': stat_line_log.group('time'), 'process': stat_line_log.group('process'), 'sent': stat_line_log.group('sent'), 'received': stat_line_log.group('received'), 'total_size': stat_line_log.group('total_size')}\n                continue\n            stat1_line_log_v = stat1_line_log_v_re.match(line)\n            if stat1_line_log_v:\n                summary = {'type': 'summary', 'date': stat1_line_log_v.group('date'), 'time': stat1_line_log_v.group('time'), 'process': stat1_line_log_v.group('process'), 'matches': stat1_line_log_v.group('matches'), 'hash_hits': stat1_line_log_v.group('hash_hits'), 'false_alarms': stat1_line_log_v.group('false_alarms'), 'data': stat1_line_log_v.group('data')}\n                continue\n            stat2_line_log_v = stat2_line_log_v_re.match(line)\n            if stat2_line_log_v:\n                summary['sent'] = stat2_line_log_v.group('sent')\n                summary['received'] = stat2_line_log_v.group('received')\n                summary['bytes_sec'] = stat2_line_log_v.group('bytes_sec')\n                continue\n            stat3_line_log_v = stat3_line_log_v_re.match(line)\n            if stat3_line_log_v:\n                summary['total_size'] = stat3_line_log_v.group('total_size')\n                summary['speedup'] = stat3_line_log_v.group('speedup')\n                continue\n        except Exception as e:\n            yield raise_or_yield(ignore_exceptions, e, line)\n    try:\n        if summary:\n            yield (summary if raw else _process(summary))\n    except Exception as e:\n        yield raise_or_yield(ignore_exceptions, e, '')",
            "@add_jc_meta\ndef parse(data: Iterable[str], raw: bool=False, quiet: bool=False, ignore_exceptions: bool=False) -> Union[Iterable[Dict], tuple]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Main text parsing generator function. Returns an iterable object.\\n\\n    Parameters:\\n\\n        data:              (iterable)  line-based text data to parse\\n                                       (e.g. sys.stdin or str.splitlines())\\n\\n        raw:               (boolean)   unprocessed output if True\\n        quiet:             (boolean)   suppress warning messages if True\\n        ignore_exceptions: (boolean)   ignore parsing exceptions if True\\n\\n    Returns:\\n\\n        Iterable of Dictionaries\\n    '\n    jc.utils.compatibility(__name__, info.compatible, quiet)\n    streaming_input_type_check(data)\n    summary: Dict = {}\n    process: str = ''\n    last_process: str = ''\n    update_type = {'<': 'file sent', '>': 'file received', 'c': 'local change or creation', 'h': 'hard link', '.': 'not updated', '*': 'message', '+': None}\n    file_type = {'f': 'file', 'd': 'directory', 'L': 'symlink', 'D': 'device', 'S': 'special file', '+': None}\n    checksum_or_value_different = {'c': True, '.': False, '+': None, ' ': None, '?': None}\n    size_different = {'s': True, '.': False, '+': None, ' ': None, '?': None}\n    modification_time_different = {'t': True, '.': False, '+': None, ' ': None, '?': None}\n    permissions_different = {'p': True, '.': False, '+': None, ' ': None, '?': None}\n    owner_different = {'o': True, '.': False, '+': None, ' ': None, '?': None}\n    group_different = {'g': True, '.': False, '+': None, ' ': None, '?': None}\n    acl_different = {'a': True, '.': False, '+': None, ' ': None, '?': None}\n    extended_attribute_different = {'x': True, '.': False, '+': None, ' ': None, '?': None}\n    file_line_re = re.compile('(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][u.+ ?][a.+ ?][x.+ ?]) (?P<name>.+)')\n    file_line_mac_re = re.compile('(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][x.+ ?]) (?P<name>.+)')\n    stat1_line_re = re.compile('(sent)\\\\s+(?P<sent>[0-9,]+)\\\\s+(bytes)\\\\s+(received)\\\\s+(?P<received>[0-9,]+)\\\\s+(bytes)\\\\s+(?P<bytes_sec>[0-9,.]+)\\\\s+(bytes/sec)')\n    stat2_line_re = re.compile('(total size is)\\\\s+(?P<total_size>[0-9,]+)\\\\s+(speedup is)\\\\s+(?P<speedup>[0-9,.]+)')\n    file_line_log_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][u.+ ?][a.+ ?][x.+ ?]) (?P<name>.+)')\n    file_line_log_mac_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+(?P<meta>[<>ch.*][fdlDS][c.+ ?][s.+ ?][t.+ ?][p.+ ?][o.+ ?][g.+ ?][x.+ ?]) (?P<name>.+)')\n    stat_line_log_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+sent\\\\s+(?P<sent>[\\\\d,]+)\\\\s+bytes\\\\s+received\\\\s+(?P<received>[\\\\d,]+)\\\\s+bytes\\\\s+total\\\\s+size\\\\s+(?P<total_size>[\\\\d,]+)')\n    stat1_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)]\\\\s+total:\\\\s+matches=(?P<matches>[\\\\d,]+)\\\\s+hash_hits=(?P<hash_hits>[\\\\d,]+)\\\\s+false_alarms=(?P<false_alarms>[\\\\d,]+)\\\\s+data=(?P<data>[\\\\d,]+)')\n    stat2_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)\\\\]\\\\s+sent\\\\s+(?P<sent>[\\\\d,]+)\\\\s+bytes\\\\s+received\\\\s+(?P<received>[\\\\d,]+)\\\\s+bytes\\\\s+(?P<bytes_sec>[\\\\d,.]+)\\\\s+bytes/sec')\n    stat3_line_log_v_re = re.compile('(?P<date>\\\\d\\\\d\\\\d\\\\d/\\\\d\\\\d/\\\\d\\\\d)\\\\s+(?P<time>\\\\d\\\\d:\\\\d\\\\d:\\\\d\\\\d)\\\\s+\\\\[(?P<process>\\\\d+)]\\\\s+total\\\\s+size\\\\s+is\\\\s+(?P<total_size>[\\\\d,]+)\\\\s+speedup\\\\s+is\\\\s+(?P<speedup>[\\\\d,.]+)')\n    for line in data:\n        try:\n            streaming_line_input_type_check(line)\n            output_line: Dict = {}\n            if not line.strip():\n                continue\n            file_line = file_line_re.match(line)\n            if file_line:\n                filename = file_line.group('name')\n                meta = file_line.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]], 'acl_different': acl_different[meta[9]], 'extended_attribute_different': extended_attribute_different[meta[10]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_mac = file_line_mac_re.match(line)\n            if file_line_mac:\n                filename = file_line_mac.group('name')\n                meta = file_line_mac.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_log = file_line_log_re.match(line)\n            if file_line_log:\n                if process != last_process:\n                    if summary:\n                        yield (output_line if raw else _process(output_line))\n                    last_process = process\n                    summary = {}\n                filename = file_line_log.group('name')\n                date = file_line_log.group('date')\n                time = file_line_log.group('time')\n                process = file_line_log.group('process')\n                meta = file_line_log.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'date': date, 'time': time, 'process': process, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]], 'acl_different': acl_different[meta[9]], 'extended_attribute_different': extended_attribute_different[meta[10]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            file_line_log_mac = file_line_log_mac_re.match(line)\n            if file_line_log_mac:\n                if process != last_process:\n                    if summary:\n                        yield (output_line if raw else _process(output_line))\n                    last_process = process\n                    summary = {}\n                filename = file_line_log_mac.group('name')\n                date = file_line_log_mac.group('date')\n                time = file_line_log_mac.group('time')\n                process = file_line_log_mac.group('process')\n                meta = file_line_log_mac.group('meta')\n                output_line = {'type': 'file', 'filename': filename, 'date': date, 'time': time, 'process': process, 'metadata': meta, 'update_type': update_type[meta[0]], 'file_type': file_type[meta[1]], 'checksum_or_value_different': checksum_or_value_different[meta[2]], 'size_different': size_different[meta[3]], 'modification_time_different': modification_time_different[meta[4]], 'permissions_different': permissions_different[meta[5]], 'owner_different': owner_different[meta[6]], 'group_different': group_different[meta[7]]}\n                yield (output_line if raw else _process(output_line))\n                continue\n            stat1_line = stat1_line_re.match(line)\n            if stat1_line:\n                summary = {'type': 'summary', 'sent': stat1_line.group('sent'), 'received': stat1_line.group('received'), 'bytes_sec': stat1_line.group('bytes_sec')}\n                continue\n            stat2_line = stat2_line_re.match(line)\n            if stat2_line:\n                summary['total_size'] = stat2_line.group('total_size')\n                summary['speedup'] = stat2_line.group('speedup')\n                continue\n            stat_line_log = stat_line_log_re.match(line)\n            if stat_line_log:\n                summary = {'type': 'summary', 'date': stat_line_log.group('date'), 'time': stat_line_log.group('time'), 'process': stat_line_log.group('process'), 'sent': stat_line_log.group('sent'), 'received': stat_line_log.group('received'), 'total_size': stat_line_log.group('total_size')}\n                continue\n            stat1_line_log_v = stat1_line_log_v_re.match(line)\n            if stat1_line_log_v:\n                summary = {'type': 'summary', 'date': stat1_line_log_v.group('date'), 'time': stat1_line_log_v.group('time'), 'process': stat1_line_log_v.group('process'), 'matches': stat1_line_log_v.group('matches'), 'hash_hits': stat1_line_log_v.group('hash_hits'), 'false_alarms': stat1_line_log_v.group('false_alarms'), 'data': stat1_line_log_v.group('data')}\n                continue\n            stat2_line_log_v = stat2_line_log_v_re.match(line)\n            if stat2_line_log_v:\n                summary['sent'] = stat2_line_log_v.group('sent')\n                summary['received'] = stat2_line_log_v.group('received')\n                summary['bytes_sec'] = stat2_line_log_v.group('bytes_sec')\n                continue\n            stat3_line_log_v = stat3_line_log_v_re.match(line)\n            if stat3_line_log_v:\n                summary['total_size'] = stat3_line_log_v.group('total_size')\n                summary['speedup'] = stat3_line_log_v.group('speedup')\n                continue\n        except Exception as e:\n            yield raise_or_yield(ignore_exceptions, e, line)\n    try:\n        if summary:\n            yield (summary if raw else _process(summary))\n    except Exception as e:\n        yield raise_or_yield(ignore_exceptions, e, '')"
        ]
    }
]