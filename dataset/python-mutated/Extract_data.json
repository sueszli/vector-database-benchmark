[
    {
        "func_name": "extract",
        "original": "def extract(Run_name):\n    if not os.path.exists(str(Run_name) + '/analysis'):\n        os.makedirs(str(Run_name) + '/analysis')\n    if not os.path.exists(str(Run_name) + '/analysis/txt_files'):\n        os.makedirs(str(Run_name) + '/analysis/txt_files')\n    mega_bining_in_mag = np.linspace(4, 9.9, num=60)\n    mega_MFD = []\n    f_sr = []\n    m_Mmax = []\n    a_s_model = []\n    faults_names = []\n    scenarios_names = []\n    b_sample = []\n    Mt_sample = []\n    sm_sample = []\n    faults_name_list = []\n    faults_id_list = []\n    fault_id = 0\n    scenarios_names_list = []\n    sample_list = []\n    BG_hyp_list = []\n    ScL_complet_list = []\n    ScL_list = []\n    dimension_used_list = []\n    Model_list = []\n    b_value_list = []\n    MFD_type_list = []\n    boolean_mfd = True\n    LT_file = str(Run_name) + '/Sources_Logic_tree.xml'\n    tree = ET.parse(LT_file)\n    nrml = tree.getroot()\n    Branch_names = []\n    branch_path = []\n    general_weight = []\n    for logicTree in nrml:\n        for logicTreeBranchLevel in logicTree:\n            for logicTreeBranchSet in logicTreeBranchLevel:\n                for logicTreeBranch in logicTreeBranchSet:\n                    Branch_names.append(logicTreeBranch.attrib['branchID'])\n                    path_i = logicTreeBranch[0].text[:-4]\n                    branch_path.append(path_i.split('/'))\n                    general_weight.append(logicTreeBranch[1].text)\n    df_mega_MFD = pd.DataFrame(columns=['selected_ScL', 'dim_used', 'str_all_data', 'Model', 'BG_hyp', 'b_min', 'b_max', 'MFD_type', 'scenario_set', 'sample', 'source', '4.0', '4.1', '4.2', '4.3', '4.4', '4.5', '4.6', '4.7', '4.8', '4.9', '5.0', '5.1', '5.2', '5.3', '5.4', '5.5', '5.6', '5.7', '5.8', '5.9', '6.0', '6.1', '6.2', '6.3', '6.4', '6.5', '6.6', '6.7', '6.8', '6.9', '7.0', '7.1', '7.2', '7.3', '7.4', '7.5', '7.6', '7.7', '7.8', '7.9', '8.0', '8.1', '8.2', '8.3', '8.4', '8.5', '8.6', '8.7', '8.8', '8.9', '9.0', '9.1', '9.2', '9.3', '9.4', '9.5', '9.6', '9.7', '9.8', '9.9'], index=range(len(Branch_names) * 100000))\n    index_df = 0\n    slip_rate_sampling = open(Run_name + '/analysis/txt_files/slip_rate_sampling.txt', 'w')\n    mean_parameters_faults = open(Run_name + '/analysis/txt_files/mean_parameters_faults.txt', 'w')\n    for branch in Branch_names:\n        branch = branch.split('-')\n        Model = branch[0]\n        BG_hyp = branch[1][3:]\n        selected_ScL = branch[2]\n        dim_used = branch[3][0]\n        str_all_data = branch[4]\n        scenario_set = branch[5][3:]\n        b_value = branch[6]\n        b_min = float(b_value.split('_')[1])\n        b_max = float(b_value.split('_')[3])\n        MFD_type = branch[7][4:]\n        sample = branch[8].split('_')[1]\n        log_sr_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/slip_rate_sample_' + str(sample) + '.txt'\n        (faults_names_i, faults_slip_rates__i) = Read_file.read_file_sr_log(log_sr_file)\n        f_sr.append(faults_slip_rates__i)\n        faults_names.append(faults_names_i)\n        for (fault_name, sr) in zip(faults_names_i, faults_slip_rates__i):\n            slip_rate_sampling.write(str(Run_name) + '\\t' + str(Model) + '\\t' + str(BG_hyp) + '\\t' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '\\t' + str(scenario_set) + '\\t' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '\\t' + str(MFD_type) + '\\t' + str(sample) + '\\t' + str(fault_name) + '\\t' + str(sr) + '\\n')\n        log_as_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/calculation_sample_' + str(sample) + '.txt'\n        a_s_i = Read_file.read_file_as_log(log_as_file)\n        a_s_model.append(a_s_i)\n        log_general_param_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/general_parameters_sample_' + str(sample) + '.txt'\n        (M_trunc_model, b_value_model) = Read_file.read_file_general_param_log(log_general_param_file)\n        b_sample.append(b_value_model)\n        Mt_sample.append(M_trunc_model)\n        log_Mmax_file = str(Run_name) + '/' + str(Model) + '/Log/Mmax_sample_' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '_sc_' + str(scenario_set) + '_' + str(sample) + '.txt'\n        (sources_names, sources_Mmax, sources_Lengths, sources_Areas) = Read_file.read_file_Mmax_log(log_Mmax_file)\n        m_Mmax.append(max(sources_Mmax))\n        for name in faults_names:\n            if not name in faults_name_list:\n                faults_name_list.append(name)\n                faults_id_list.append(fault_id)\n                fault_id += 1\n        if not sample in sample_list:\n            sample_list.append(sample)\n        if not b_value in b_value_list:\n            b_value_list.append(b_value)\n        if not MFD_type in MFD_type_list:\n            MFD_type_list.append(MFD_type)\n        if not dim_used in dimension_used_list:\n            dimension_used_list.append(dim_used)\n        scenarios_names.append(scenario_set)\n        if not scenario_set in scenarios_names_list:\n            scenarios_names_list.append(scenario_set)\n        if not BG_hyp in BG_hyp_list:\n            BG_hyp_list.append(BG_hyp)\n        if not str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data) in ScL_complet_list:\n            ScL_complet_list.append(str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data))\n        if not selected_ScL in ScL_list:\n            ScL_list.append(selected_ScL)\n        if not Model in Model_list:\n            Model_list.append(Model)\n        for (fault_name, sr) in zip(faults_names_i, faults_slip_rates__i):\n            if sample == '1' and BG_hyp == BG_hyp_list[0] and (str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data) == ScL_complet_list[0]):\n                if b_value == b_value_list[0] and MFD_type == MFD_type_list[0]:\n                    Mmax_fault = 0.0\n                    for (source, Mmax_i) in zip(sources_names, sources_Mmax):\n                        if fault_name == source or \"['\" + fault_name + \"']\" in source:\n                            if float(Mmax_i) > Mmax_fault:\n                                Mmax_fault = Mmax_i\n                    mean_parameters_faults.write(str(Model) + '\\t' + str(scenario_set) + '\\t' + str(fault_name) + '\\t' + str(sr) + '\\t' + str(Mmax_fault) + '\\n')\n        if boolean_mfd == True:\n            log_mfd_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/mdf_sample_' + str(sample) + '.txt'\n            (sources_names, Mmin, MFD) = Read_file.read_file_mfd_log(log_mfd_file)\n            index_Mmin = np.where(np.array(mega_bining_in_mag) == min(Mmin))[0]\n            index_source = 0\n            for source in sources_names:\n                '\\n                #the source is replaced by a list of id of fault as a tring to gain memory place\\n                list_id  =[]\\n                for i in source.split(\"=[\\'\"): \\n                    try :\\n                        iii = i.index(\"\\'\")\\n                        fault_id = np.where(np.array(faults_name_list[0])==i[:iii])[0][0]\\n                        list_id.append(fault_id)\\n                    except:\\n                        i=i\\n                if len(source.split(\"=[\\'\")) == 1:\\n                    if source == \\'Background\\':\\n                        list_id = \\'[Background]\\'\\n                    else:\\n                        #print(source[len(Model)+1:])\\n                        fault_id = np.where(np.array(faults_name_list[0])==source[len(Model)+1:])[0][0]\\n                        list_id.append(fault_id)'\n                mega_mfd_i = []\n                mega_mfd_i.append(selected_ScL)\n                mega_mfd_i.append(dim_used)\n                mega_mfd_i.append(str_all_data)\n                mega_mfd_i.append(Model)\n                mega_mfd_i.append(BG_hyp)\n                mega_mfd_i.append(str(b_min))\n                mega_mfd_i.append(str(b_max))\n                mega_mfd_i.append(MFD_type)\n                mega_mfd_i.append(scenario_set)\n                mega_mfd_i.append(sample)\n                mega_mfd_i.append(source)\n                for index_mag in range(len(mega_bining_in_mag)):\n                    if index_mag < len(MFD[index_source]) + index_Mmin and index_mag >= index_Mmin:\n                        try:\n                            mega_mfd_i.append(float(MFD[index_source][int(index_mag - index_Mmin)]))\n                        except TypeError:\n                            print('!!!!!!!!!!!!!!!!\\n\\n\\n' + 'There is a problem with a log file' + 'Delete the .xml corresponding to this file' + 'Then re-run SHERIFS with overwrite_files = False' + 'file with a problem : ')\n                            print(log_mfd_file)\n                    else:\n                        mega_mfd_i.append(0.0)\n                mega_MFD.append(np.array(mega_mfd_i))\n                dict_df_mfd_i = {'selected_ScL': selected_ScL, 'dim_used': dim_used, 'str_all_data': str_all_data, 'Model': Model, 'BG_hyp': BG_hyp, 'b_min': str(b_min), 'b_max': str(b_max), 'MFD_type': MFD_type, 'scenario_set': scenario_set, 'sample': sample, 'source': source, '4.0': np.sum(mega_mfd_i[11:]), '4.1': np.sum(mega_mfd_i[12:]), '4.2': np.sum(mega_mfd_i[13:]), '4.3': np.sum(mega_mfd_i[14:]), '4.4': np.sum(mega_mfd_i[15:]), '4.5': np.sum(mega_mfd_i[16:]), '4.6': np.sum(mega_mfd_i[17:]), '4.7': np.sum(mega_mfd_i[18:]), '4.8': np.sum(mega_mfd_i[19:]), '4.9': np.sum(mega_mfd_i[20:]), '5.0': np.sum(mega_mfd_i[21:]), '5.1': np.sum(mega_mfd_i[22:]), '5.2': np.sum(mega_mfd_i[23:]), '5.3': np.sum(mega_mfd_i[24:]), '5.4': np.sum(mega_mfd_i[25:]), '5.5': np.sum(mega_mfd_i[26:]), '5.6': np.sum(mega_mfd_i[27:]), '5.7': np.sum(mega_mfd_i[28:]), '5.8': np.sum(mega_mfd_i[29:]), '5.9': np.sum(mega_mfd_i[30:]), '6.0': np.sum(mega_mfd_i[31:]), '6.1': np.sum(mega_mfd_i[32:]), '6.2': np.sum(mega_mfd_i[33:]), '6.3': np.sum(mega_mfd_i[34:]), '6.4': np.sum(mega_mfd_i[35:]), '6.5': np.sum(mega_mfd_i[36:]), '6.6': np.sum(mega_mfd_i[37:]), '6.7': np.sum(mega_mfd_i[38:]), '6.8': np.sum(mega_mfd_i[39:]), '6.9': np.sum(mega_mfd_i[40:]), '7.0': np.sum(mega_mfd_i[41:]), '7.1': np.sum(mega_mfd_i[42:]), '7.2': np.sum(mega_mfd_i[43:]), '7.3': np.sum(mega_mfd_i[44:]), '7.4': np.sum(mega_mfd_i[45:]), '7.5': np.sum(mega_mfd_i[46:]), '7.6': np.sum(mega_mfd_i[47:]), '7.7': np.sum(mega_mfd_i[48:]), '7.8': np.sum(mega_mfd_i[49:]), '7.9': np.sum(mega_mfd_i[50:]), '8.0': np.sum(mega_mfd_i[51:]), '8.1': np.sum(mega_mfd_i[52:]), '8.2': np.sum(mega_mfd_i[53:]), '8.3': np.sum(mega_mfd_i[54:]), '8.4': np.sum(mega_mfd_i[55:]), '8.5': np.sum(mega_mfd_i[56:]), '8.6': np.sum(mega_mfd_i[57:]), '8.7': np.sum(mega_mfd_i[58:]), '8.8': np.sum(mega_mfd_i[59:]), '8.9': np.sum(mega_mfd_i[60:]), '9.0': np.sum(mega_mfd_i[61:]), '9.1': np.sum(mega_mfd_i[62:]), '9.2': np.sum(mega_mfd_i[63:]), '9.3': np.sum(mega_mfd_i[64:]), '9.4': np.sum(mega_mfd_i[65:]), '9.5': np.sum(mega_mfd_i[66:]), '9.6': np.sum(mega_mfd_i[67:]), '9.7': np.sum(mega_mfd_i[68:]), '9.8': np.sum(mega_mfd_i[69:]), '9.9': np.sum(mega_mfd_i[70:])}\n                df_mega_MFD.loc[index_df] = pd.Series(dict_df_mfd_i)\n                \"df_mega_MFD.loc[index_df] = mega_mfd_i\\n                ,columns=['selected_ScL','dim_used','str_all_data','Model','BG_hyp',\\n                                        'b_min','b_max','MFD_type','scenario_set','sample','source',\\n                                        '4.0','4.1','4.2','4.3','4.4','4.5','4.6','4.7','4.8','4.9',\\n                                        '5.0','5.1','5.2','5.3','5.4','5.5','5.6','5.7','5.8','5.9',\\n                                        '6.0','6.1','6.2','6.3','6.4','6.5','6.6','6.7','6.8','6.9',\\n                                        '7.0','7.1','7.2','7.3','7.4','7.5','7.6','7.7','7.8','7.9',\\n                                        '8.0','8.1','8.2','8.3','8.4','8.5','8.6','8.7','8.8','8.9',\\n                                        '9.0','9.1','9.2','9.3','9.4','9.5','9.6','9.7','9.8','9.9'])\"\n                index_df += 1\n                index_source += 1\n    boolean_mfd = True\n    file_MFD_name = str(Run_name) + '/analysis/txt_files/faults_MFD.txt'\n    file_MFD = open(file_MFD_name, 'w')\n    file_MFD.write(str(mega_MFD))\n    file_MFD.close()\n    slip_rate_sampling.close()\n    mean_parameters_faults.close()\n    df_mega_MFD = df_mega_MFD.dropna(how='all')\n    logictree = {'model': Model_list, 'scaling_law': ScL_complet_list, 'background': BG_hyp_list, 'b_value': b_value_list, 'MDF_type': MFD_type_list, 'rupture_set': scenarios_names_list}\n    return (mega_MFD, df_mega_MFD, scenarios_names_list, ScL_complet_list, ScL_list, Model_list, BG_hyp_list, dimension_used_list, faults_name_list, sample_list, b_value_list, MFD_type_list, m_Mmax, mega_bining_in_mag, a_s_model, b_sample, sm_sample, Mt_sample, sources_Lengths, sources_Areas, logictree)",
        "mutated": [
            "def extract(Run_name):\n    if False:\n        i = 10\n    if not os.path.exists(str(Run_name) + '/analysis'):\n        os.makedirs(str(Run_name) + '/analysis')\n    if not os.path.exists(str(Run_name) + '/analysis/txt_files'):\n        os.makedirs(str(Run_name) + '/analysis/txt_files')\n    mega_bining_in_mag = np.linspace(4, 9.9, num=60)\n    mega_MFD = []\n    f_sr = []\n    m_Mmax = []\n    a_s_model = []\n    faults_names = []\n    scenarios_names = []\n    b_sample = []\n    Mt_sample = []\n    sm_sample = []\n    faults_name_list = []\n    faults_id_list = []\n    fault_id = 0\n    scenarios_names_list = []\n    sample_list = []\n    BG_hyp_list = []\n    ScL_complet_list = []\n    ScL_list = []\n    dimension_used_list = []\n    Model_list = []\n    b_value_list = []\n    MFD_type_list = []\n    boolean_mfd = True\n    LT_file = str(Run_name) + '/Sources_Logic_tree.xml'\n    tree = ET.parse(LT_file)\n    nrml = tree.getroot()\n    Branch_names = []\n    branch_path = []\n    general_weight = []\n    for logicTree in nrml:\n        for logicTreeBranchLevel in logicTree:\n            for logicTreeBranchSet in logicTreeBranchLevel:\n                for logicTreeBranch in logicTreeBranchSet:\n                    Branch_names.append(logicTreeBranch.attrib['branchID'])\n                    path_i = logicTreeBranch[0].text[:-4]\n                    branch_path.append(path_i.split('/'))\n                    general_weight.append(logicTreeBranch[1].text)\n    df_mega_MFD = pd.DataFrame(columns=['selected_ScL', 'dim_used', 'str_all_data', 'Model', 'BG_hyp', 'b_min', 'b_max', 'MFD_type', 'scenario_set', 'sample', 'source', '4.0', '4.1', '4.2', '4.3', '4.4', '4.5', '4.6', '4.7', '4.8', '4.9', '5.0', '5.1', '5.2', '5.3', '5.4', '5.5', '5.6', '5.7', '5.8', '5.9', '6.0', '6.1', '6.2', '6.3', '6.4', '6.5', '6.6', '6.7', '6.8', '6.9', '7.0', '7.1', '7.2', '7.3', '7.4', '7.5', '7.6', '7.7', '7.8', '7.9', '8.0', '8.1', '8.2', '8.3', '8.4', '8.5', '8.6', '8.7', '8.8', '8.9', '9.0', '9.1', '9.2', '9.3', '9.4', '9.5', '9.6', '9.7', '9.8', '9.9'], index=range(len(Branch_names) * 100000))\n    index_df = 0\n    slip_rate_sampling = open(Run_name + '/analysis/txt_files/slip_rate_sampling.txt', 'w')\n    mean_parameters_faults = open(Run_name + '/analysis/txt_files/mean_parameters_faults.txt', 'w')\n    for branch in Branch_names:\n        branch = branch.split('-')\n        Model = branch[0]\n        BG_hyp = branch[1][3:]\n        selected_ScL = branch[2]\n        dim_used = branch[3][0]\n        str_all_data = branch[4]\n        scenario_set = branch[5][3:]\n        b_value = branch[6]\n        b_min = float(b_value.split('_')[1])\n        b_max = float(b_value.split('_')[3])\n        MFD_type = branch[7][4:]\n        sample = branch[8].split('_')[1]\n        log_sr_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/slip_rate_sample_' + str(sample) + '.txt'\n        (faults_names_i, faults_slip_rates__i) = Read_file.read_file_sr_log(log_sr_file)\n        f_sr.append(faults_slip_rates__i)\n        faults_names.append(faults_names_i)\n        for (fault_name, sr) in zip(faults_names_i, faults_slip_rates__i):\n            slip_rate_sampling.write(str(Run_name) + '\\t' + str(Model) + '\\t' + str(BG_hyp) + '\\t' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '\\t' + str(scenario_set) + '\\t' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '\\t' + str(MFD_type) + '\\t' + str(sample) + '\\t' + str(fault_name) + '\\t' + str(sr) + '\\n')\n        log_as_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/calculation_sample_' + str(sample) + '.txt'\n        a_s_i = Read_file.read_file_as_log(log_as_file)\n        a_s_model.append(a_s_i)\n        log_general_param_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/general_parameters_sample_' + str(sample) + '.txt'\n        (M_trunc_model, b_value_model) = Read_file.read_file_general_param_log(log_general_param_file)\n        b_sample.append(b_value_model)\n        Mt_sample.append(M_trunc_model)\n        log_Mmax_file = str(Run_name) + '/' + str(Model) + '/Log/Mmax_sample_' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '_sc_' + str(scenario_set) + '_' + str(sample) + '.txt'\n        (sources_names, sources_Mmax, sources_Lengths, sources_Areas) = Read_file.read_file_Mmax_log(log_Mmax_file)\n        m_Mmax.append(max(sources_Mmax))\n        for name in faults_names:\n            if not name in faults_name_list:\n                faults_name_list.append(name)\n                faults_id_list.append(fault_id)\n                fault_id += 1\n        if not sample in sample_list:\n            sample_list.append(sample)\n        if not b_value in b_value_list:\n            b_value_list.append(b_value)\n        if not MFD_type in MFD_type_list:\n            MFD_type_list.append(MFD_type)\n        if not dim_used in dimension_used_list:\n            dimension_used_list.append(dim_used)\n        scenarios_names.append(scenario_set)\n        if not scenario_set in scenarios_names_list:\n            scenarios_names_list.append(scenario_set)\n        if not BG_hyp in BG_hyp_list:\n            BG_hyp_list.append(BG_hyp)\n        if not str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data) in ScL_complet_list:\n            ScL_complet_list.append(str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data))\n        if not selected_ScL in ScL_list:\n            ScL_list.append(selected_ScL)\n        if not Model in Model_list:\n            Model_list.append(Model)\n        for (fault_name, sr) in zip(faults_names_i, faults_slip_rates__i):\n            if sample == '1' and BG_hyp == BG_hyp_list[0] and (str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data) == ScL_complet_list[0]):\n                if b_value == b_value_list[0] and MFD_type == MFD_type_list[0]:\n                    Mmax_fault = 0.0\n                    for (source, Mmax_i) in zip(sources_names, sources_Mmax):\n                        if fault_name == source or \"['\" + fault_name + \"']\" in source:\n                            if float(Mmax_i) > Mmax_fault:\n                                Mmax_fault = Mmax_i\n                    mean_parameters_faults.write(str(Model) + '\\t' + str(scenario_set) + '\\t' + str(fault_name) + '\\t' + str(sr) + '\\t' + str(Mmax_fault) + '\\n')\n        if boolean_mfd == True:\n            log_mfd_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/mdf_sample_' + str(sample) + '.txt'\n            (sources_names, Mmin, MFD) = Read_file.read_file_mfd_log(log_mfd_file)\n            index_Mmin = np.where(np.array(mega_bining_in_mag) == min(Mmin))[0]\n            index_source = 0\n            for source in sources_names:\n                '\\n                #the source is replaced by a list of id of fault as a tring to gain memory place\\n                list_id  =[]\\n                for i in source.split(\"=[\\'\"): \\n                    try :\\n                        iii = i.index(\"\\'\")\\n                        fault_id = np.where(np.array(faults_name_list[0])==i[:iii])[0][0]\\n                        list_id.append(fault_id)\\n                    except:\\n                        i=i\\n                if len(source.split(\"=[\\'\")) == 1:\\n                    if source == \\'Background\\':\\n                        list_id = \\'[Background]\\'\\n                    else:\\n                        #print(source[len(Model)+1:])\\n                        fault_id = np.where(np.array(faults_name_list[0])==source[len(Model)+1:])[0][0]\\n                        list_id.append(fault_id)'\n                mega_mfd_i = []\n                mega_mfd_i.append(selected_ScL)\n                mega_mfd_i.append(dim_used)\n                mega_mfd_i.append(str_all_data)\n                mega_mfd_i.append(Model)\n                mega_mfd_i.append(BG_hyp)\n                mega_mfd_i.append(str(b_min))\n                mega_mfd_i.append(str(b_max))\n                mega_mfd_i.append(MFD_type)\n                mega_mfd_i.append(scenario_set)\n                mega_mfd_i.append(sample)\n                mega_mfd_i.append(source)\n                for index_mag in range(len(mega_bining_in_mag)):\n                    if index_mag < len(MFD[index_source]) + index_Mmin and index_mag >= index_Mmin:\n                        try:\n                            mega_mfd_i.append(float(MFD[index_source][int(index_mag - index_Mmin)]))\n                        except TypeError:\n                            print('!!!!!!!!!!!!!!!!\\n\\n\\n' + 'There is a problem with a log file' + 'Delete the .xml corresponding to this file' + 'Then re-run SHERIFS with overwrite_files = False' + 'file with a problem : ')\n                            print(log_mfd_file)\n                    else:\n                        mega_mfd_i.append(0.0)\n                mega_MFD.append(np.array(mega_mfd_i))\n                dict_df_mfd_i = {'selected_ScL': selected_ScL, 'dim_used': dim_used, 'str_all_data': str_all_data, 'Model': Model, 'BG_hyp': BG_hyp, 'b_min': str(b_min), 'b_max': str(b_max), 'MFD_type': MFD_type, 'scenario_set': scenario_set, 'sample': sample, 'source': source, '4.0': np.sum(mega_mfd_i[11:]), '4.1': np.sum(mega_mfd_i[12:]), '4.2': np.sum(mega_mfd_i[13:]), '4.3': np.sum(mega_mfd_i[14:]), '4.4': np.sum(mega_mfd_i[15:]), '4.5': np.sum(mega_mfd_i[16:]), '4.6': np.sum(mega_mfd_i[17:]), '4.7': np.sum(mega_mfd_i[18:]), '4.8': np.sum(mega_mfd_i[19:]), '4.9': np.sum(mega_mfd_i[20:]), '5.0': np.sum(mega_mfd_i[21:]), '5.1': np.sum(mega_mfd_i[22:]), '5.2': np.sum(mega_mfd_i[23:]), '5.3': np.sum(mega_mfd_i[24:]), '5.4': np.sum(mega_mfd_i[25:]), '5.5': np.sum(mega_mfd_i[26:]), '5.6': np.sum(mega_mfd_i[27:]), '5.7': np.sum(mega_mfd_i[28:]), '5.8': np.sum(mega_mfd_i[29:]), '5.9': np.sum(mega_mfd_i[30:]), '6.0': np.sum(mega_mfd_i[31:]), '6.1': np.sum(mega_mfd_i[32:]), '6.2': np.sum(mega_mfd_i[33:]), '6.3': np.sum(mega_mfd_i[34:]), '6.4': np.sum(mega_mfd_i[35:]), '6.5': np.sum(mega_mfd_i[36:]), '6.6': np.sum(mega_mfd_i[37:]), '6.7': np.sum(mega_mfd_i[38:]), '6.8': np.sum(mega_mfd_i[39:]), '6.9': np.sum(mega_mfd_i[40:]), '7.0': np.sum(mega_mfd_i[41:]), '7.1': np.sum(mega_mfd_i[42:]), '7.2': np.sum(mega_mfd_i[43:]), '7.3': np.sum(mega_mfd_i[44:]), '7.4': np.sum(mega_mfd_i[45:]), '7.5': np.sum(mega_mfd_i[46:]), '7.6': np.sum(mega_mfd_i[47:]), '7.7': np.sum(mega_mfd_i[48:]), '7.8': np.sum(mega_mfd_i[49:]), '7.9': np.sum(mega_mfd_i[50:]), '8.0': np.sum(mega_mfd_i[51:]), '8.1': np.sum(mega_mfd_i[52:]), '8.2': np.sum(mega_mfd_i[53:]), '8.3': np.sum(mega_mfd_i[54:]), '8.4': np.sum(mega_mfd_i[55:]), '8.5': np.sum(mega_mfd_i[56:]), '8.6': np.sum(mega_mfd_i[57:]), '8.7': np.sum(mega_mfd_i[58:]), '8.8': np.sum(mega_mfd_i[59:]), '8.9': np.sum(mega_mfd_i[60:]), '9.0': np.sum(mega_mfd_i[61:]), '9.1': np.sum(mega_mfd_i[62:]), '9.2': np.sum(mega_mfd_i[63:]), '9.3': np.sum(mega_mfd_i[64:]), '9.4': np.sum(mega_mfd_i[65:]), '9.5': np.sum(mega_mfd_i[66:]), '9.6': np.sum(mega_mfd_i[67:]), '9.7': np.sum(mega_mfd_i[68:]), '9.8': np.sum(mega_mfd_i[69:]), '9.9': np.sum(mega_mfd_i[70:])}\n                df_mega_MFD.loc[index_df] = pd.Series(dict_df_mfd_i)\n                \"df_mega_MFD.loc[index_df] = mega_mfd_i\\n                ,columns=['selected_ScL','dim_used','str_all_data','Model','BG_hyp',\\n                                        'b_min','b_max','MFD_type','scenario_set','sample','source',\\n                                        '4.0','4.1','4.2','4.3','4.4','4.5','4.6','4.7','4.8','4.9',\\n                                        '5.0','5.1','5.2','5.3','5.4','5.5','5.6','5.7','5.8','5.9',\\n                                        '6.0','6.1','6.2','6.3','6.4','6.5','6.6','6.7','6.8','6.9',\\n                                        '7.0','7.1','7.2','7.3','7.4','7.5','7.6','7.7','7.8','7.9',\\n                                        '8.0','8.1','8.2','8.3','8.4','8.5','8.6','8.7','8.8','8.9',\\n                                        '9.0','9.1','9.2','9.3','9.4','9.5','9.6','9.7','9.8','9.9'])\"\n                index_df += 1\n                index_source += 1\n    boolean_mfd = True\n    file_MFD_name = str(Run_name) + '/analysis/txt_files/faults_MFD.txt'\n    file_MFD = open(file_MFD_name, 'w')\n    file_MFD.write(str(mega_MFD))\n    file_MFD.close()\n    slip_rate_sampling.close()\n    mean_parameters_faults.close()\n    df_mega_MFD = df_mega_MFD.dropna(how='all')\n    logictree = {'model': Model_list, 'scaling_law': ScL_complet_list, 'background': BG_hyp_list, 'b_value': b_value_list, 'MDF_type': MFD_type_list, 'rupture_set': scenarios_names_list}\n    return (mega_MFD, df_mega_MFD, scenarios_names_list, ScL_complet_list, ScL_list, Model_list, BG_hyp_list, dimension_used_list, faults_name_list, sample_list, b_value_list, MFD_type_list, m_Mmax, mega_bining_in_mag, a_s_model, b_sample, sm_sample, Mt_sample, sources_Lengths, sources_Areas, logictree)",
            "def extract(Run_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not os.path.exists(str(Run_name) + '/analysis'):\n        os.makedirs(str(Run_name) + '/analysis')\n    if not os.path.exists(str(Run_name) + '/analysis/txt_files'):\n        os.makedirs(str(Run_name) + '/analysis/txt_files')\n    mega_bining_in_mag = np.linspace(4, 9.9, num=60)\n    mega_MFD = []\n    f_sr = []\n    m_Mmax = []\n    a_s_model = []\n    faults_names = []\n    scenarios_names = []\n    b_sample = []\n    Mt_sample = []\n    sm_sample = []\n    faults_name_list = []\n    faults_id_list = []\n    fault_id = 0\n    scenarios_names_list = []\n    sample_list = []\n    BG_hyp_list = []\n    ScL_complet_list = []\n    ScL_list = []\n    dimension_used_list = []\n    Model_list = []\n    b_value_list = []\n    MFD_type_list = []\n    boolean_mfd = True\n    LT_file = str(Run_name) + '/Sources_Logic_tree.xml'\n    tree = ET.parse(LT_file)\n    nrml = tree.getroot()\n    Branch_names = []\n    branch_path = []\n    general_weight = []\n    for logicTree in nrml:\n        for logicTreeBranchLevel in logicTree:\n            for logicTreeBranchSet in logicTreeBranchLevel:\n                for logicTreeBranch in logicTreeBranchSet:\n                    Branch_names.append(logicTreeBranch.attrib['branchID'])\n                    path_i = logicTreeBranch[0].text[:-4]\n                    branch_path.append(path_i.split('/'))\n                    general_weight.append(logicTreeBranch[1].text)\n    df_mega_MFD = pd.DataFrame(columns=['selected_ScL', 'dim_used', 'str_all_data', 'Model', 'BG_hyp', 'b_min', 'b_max', 'MFD_type', 'scenario_set', 'sample', 'source', '4.0', '4.1', '4.2', '4.3', '4.4', '4.5', '4.6', '4.7', '4.8', '4.9', '5.0', '5.1', '5.2', '5.3', '5.4', '5.5', '5.6', '5.7', '5.8', '5.9', '6.0', '6.1', '6.2', '6.3', '6.4', '6.5', '6.6', '6.7', '6.8', '6.9', '7.0', '7.1', '7.2', '7.3', '7.4', '7.5', '7.6', '7.7', '7.8', '7.9', '8.0', '8.1', '8.2', '8.3', '8.4', '8.5', '8.6', '8.7', '8.8', '8.9', '9.0', '9.1', '9.2', '9.3', '9.4', '9.5', '9.6', '9.7', '9.8', '9.9'], index=range(len(Branch_names) * 100000))\n    index_df = 0\n    slip_rate_sampling = open(Run_name + '/analysis/txt_files/slip_rate_sampling.txt', 'w')\n    mean_parameters_faults = open(Run_name + '/analysis/txt_files/mean_parameters_faults.txt', 'w')\n    for branch in Branch_names:\n        branch = branch.split('-')\n        Model = branch[0]\n        BG_hyp = branch[1][3:]\n        selected_ScL = branch[2]\n        dim_used = branch[3][0]\n        str_all_data = branch[4]\n        scenario_set = branch[5][3:]\n        b_value = branch[6]\n        b_min = float(b_value.split('_')[1])\n        b_max = float(b_value.split('_')[3])\n        MFD_type = branch[7][4:]\n        sample = branch[8].split('_')[1]\n        log_sr_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/slip_rate_sample_' + str(sample) + '.txt'\n        (faults_names_i, faults_slip_rates__i) = Read_file.read_file_sr_log(log_sr_file)\n        f_sr.append(faults_slip_rates__i)\n        faults_names.append(faults_names_i)\n        for (fault_name, sr) in zip(faults_names_i, faults_slip_rates__i):\n            slip_rate_sampling.write(str(Run_name) + '\\t' + str(Model) + '\\t' + str(BG_hyp) + '\\t' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '\\t' + str(scenario_set) + '\\t' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '\\t' + str(MFD_type) + '\\t' + str(sample) + '\\t' + str(fault_name) + '\\t' + str(sr) + '\\n')\n        log_as_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/calculation_sample_' + str(sample) + '.txt'\n        a_s_i = Read_file.read_file_as_log(log_as_file)\n        a_s_model.append(a_s_i)\n        log_general_param_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/general_parameters_sample_' + str(sample) + '.txt'\n        (M_trunc_model, b_value_model) = Read_file.read_file_general_param_log(log_general_param_file)\n        b_sample.append(b_value_model)\n        Mt_sample.append(M_trunc_model)\n        log_Mmax_file = str(Run_name) + '/' + str(Model) + '/Log/Mmax_sample_' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '_sc_' + str(scenario_set) + '_' + str(sample) + '.txt'\n        (sources_names, sources_Mmax, sources_Lengths, sources_Areas) = Read_file.read_file_Mmax_log(log_Mmax_file)\n        m_Mmax.append(max(sources_Mmax))\n        for name in faults_names:\n            if not name in faults_name_list:\n                faults_name_list.append(name)\n                faults_id_list.append(fault_id)\n                fault_id += 1\n        if not sample in sample_list:\n            sample_list.append(sample)\n        if not b_value in b_value_list:\n            b_value_list.append(b_value)\n        if not MFD_type in MFD_type_list:\n            MFD_type_list.append(MFD_type)\n        if not dim_used in dimension_used_list:\n            dimension_used_list.append(dim_used)\n        scenarios_names.append(scenario_set)\n        if not scenario_set in scenarios_names_list:\n            scenarios_names_list.append(scenario_set)\n        if not BG_hyp in BG_hyp_list:\n            BG_hyp_list.append(BG_hyp)\n        if not str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data) in ScL_complet_list:\n            ScL_complet_list.append(str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data))\n        if not selected_ScL in ScL_list:\n            ScL_list.append(selected_ScL)\n        if not Model in Model_list:\n            Model_list.append(Model)\n        for (fault_name, sr) in zip(faults_names_i, faults_slip_rates__i):\n            if sample == '1' and BG_hyp == BG_hyp_list[0] and (str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data) == ScL_complet_list[0]):\n                if b_value == b_value_list[0] and MFD_type == MFD_type_list[0]:\n                    Mmax_fault = 0.0\n                    for (source, Mmax_i) in zip(sources_names, sources_Mmax):\n                        if fault_name == source or \"['\" + fault_name + \"']\" in source:\n                            if float(Mmax_i) > Mmax_fault:\n                                Mmax_fault = Mmax_i\n                    mean_parameters_faults.write(str(Model) + '\\t' + str(scenario_set) + '\\t' + str(fault_name) + '\\t' + str(sr) + '\\t' + str(Mmax_fault) + '\\n')\n        if boolean_mfd == True:\n            log_mfd_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/mdf_sample_' + str(sample) + '.txt'\n            (sources_names, Mmin, MFD) = Read_file.read_file_mfd_log(log_mfd_file)\n            index_Mmin = np.where(np.array(mega_bining_in_mag) == min(Mmin))[0]\n            index_source = 0\n            for source in sources_names:\n                '\\n                #the source is replaced by a list of id of fault as a tring to gain memory place\\n                list_id  =[]\\n                for i in source.split(\"=[\\'\"): \\n                    try :\\n                        iii = i.index(\"\\'\")\\n                        fault_id = np.where(np.array(faults_name_list[0])==i[:iii])[0][0]\\n                        list_id.append(fault_id)\\n                    except:\\n                        i=i\\n                if len(source.split(\"=[\\'\")) == 1:\\n                    if source == \\'Background\\':\\n                        list_id = \\'[Background]\\'\\n                    else:\\n                        #print(source[len(Model)+1:])\\n                        fault_id = np.where(np.array(faults_name_list[0])==source[len(Model)+1:])[0][0]\\n                        list_id.append(fault_id)'\n                mega_mfd_i = []\n                mega_mfd_i.append(selected_ScL)\n                mega_mfd_i.append(dim_used)\n                mega_mfd_i.append(str_all_data)\n                mega_mfd_i.append(Model)\n                mega_mfd_i.append(BG_hyp)\n                mega_mfd_i.append(str(b_min))\n                mega_mfd_i.append(str(b_max))\n                mega_mfd_i.append(MFD_type)\n                mega_mfd_i.append(scenario_set)\n                mega_mfd_i.append(sample)\n                mega_mfd_i.append(source)\n                for index_mag in range(len(mega_bining_in_mag)):\n                    if index_mag < len(MFD[index_source]) + index_Mmin and index_mag >= index_Mmin:\n                        try:\n                            mega_mfd_i.append(float(MFD[index_source][int(index_mag - index_Mmin)]))\n                        except TypeError:\n                            print('!!!!!!!!!!!!!!!!\\n\\n\\n' + 'There is a problem with a log file' + 'Delete the .xml corresponding to this file' + 'Then re-run SHERIFS with overwrite_files = False' + 'file with a problem : ')\n                            print(log_mfd_file)\n                    else:\n                        mega_mfd_i.append(0.0)\n                mega_MFD.append(np.array(mega_mfd_i))\n                dict_df_mfd_i = {'selected_ScL': selected_ScL, 'dim_used': dim_used, 'str_all_data': str_all_data, 'Model': Model, 'BG_hyp': BG_hyp, 'b_min': str(b_min), 'b_max': str(b_max), 'MFD_type': MFD_type, 'scenario_set': scenario_set, 'sample': sample, 'source': source, '4.0': np.sum(mega_mfd_i[11:]), '4.1': np.sum(mega_mfd_i[12:]), '4.2': np.sum(mega_mfd_i[13:]), '4.3': np.sum(mega_mfd_i[14:]), '4.4': np.sum(mega_mfd_i[15:]), '4.5': np.sum(mega_mfd_i[16:]), '4.6': np.sum(mega_mfd_i[17:]), '4.7': np.sum(mega_mfd_i[18:]), '4.8': np.sum(mega_mfd_i[19:]), '4.9': np.sum(mega_mfd_i[20:]), '5.0': np.sum(mega_mfd_i[21:]), '5.1': np.sum(mega_mfd_i[22:]), '5.2': np.sum(mega_mfd_i[23:]), '5.3': np.sum(mega_mfd_i[24:]), '5.4': np.sum(mega_mfd_i[25:]), '5.5': np.sum(mega_mfd_i[26:]), '5.6': np.sum(mega_mfd_i[27:]), '5.7': np.sum(mega_mfd_i[28:]), '5.8': np.sum(mega_mfd_i[29:]), '5.9': np.sum(mega_mfd_i[30:]), '6.0': np.sum(mega_mfd_i[31:]), '6.1': np.sum(mega_mfd_i[32:]), '6.2': np.sum(mega_mfd_i[33:]), '6.3': np.sum(mega_mfd_i[34:]), '6.4': np.sum(mega_mfd_i[35:]), '6.5': np.sum(mega_mfd_i[36:]), '6.6': np.sum(mega_mfd_i[37:]), '6.7': np.sum(mega_mfd_i[38:]), '6.8': np.sum(mega_mfd_i[39:]), '6.9': np.sum(mega_mfd_i[40:]), '7.0': np.sum(mega_mfd_i[41:]), '7.1': np.sum(mega_mfd_i[42:]), '7.2': np.sum(mega_mfd_i[43:]), '7.3': np.sum(mega_mfd_i[44:]), '7.4': np.sum(mega_mfd_i[45:]), '7.5': np.sum(mega_mfd_i[46:]), '7.6': np.sum(mega_mfd_i[47:]), '7.7': np.sum(mega_mfd_i[48:]), '7.8': np.sum(mega_mfd_i[49:]), '7.9': np.sum(mega_mfd_i[50:]), '8.0': np.sum(mega_mfd_i[51:]), '8.1': np.sum(mega_mfd_i[52:]), '8.2': np.sum(mega_mfd_i[53:]), '8.3': np.sum(mega_mfd_i[54:]), '8.4': np.sum(mega_mfd_i[55:]), '8.5': np.sum(mega_mfd_i[56:]), '8.6': np.sum(mega_mfd_i[57:]), '8.7': np.sum(mega_mfd_i[58:]), '8.8': np.sum(mega_mfd_i[59:]), '8.9': np.sum(mega_mfd_i[60:]), '9.0': np.sum(mega_mfd_i[61:]), '9.1': np.sum(mega_mfd_i[62:]), '9.2': np.sum(mega_mfd_i[63:]), '9.3': np.sum(mega_mfd_i[64:]), '9.4': np.sum(mega_mfd_i[65:]), '9.5': np.sum(mega_mfd_i[66:]), '9.6': np.sum(mega_mfd_i[67:]), '9.7': np.sum(mega_mfd_i[68:]), '9.8': np.sum(mega_mfd_i[69:]), '9.9': np.sum(mega_mfd_i[70:])}\n                df_mega_MFD.loc[index_df] = pd.Series(dict_df_mfd_i)\n                \"df_mega_MFD.loc[index_df] = mega_mfd_i\\n                ,columns=['selected_ScL','dim_used','str_all_data','Model','BG_hyp',\\n                                        'b_min','b_max','MFD_type','scenario_set','sample','source',\\n                                        '4.0','4.1','4.2','4.3','4.4','4.5','4.6','4.7','4.8','4.9',\\n                                        '5.0','5.1','5.2','5.3','5.4','5.5','5.6','5.7','5.8','5.9',\\n                                        '6.0','6.1','6.2','6.3','6.4','6.5','6.6','6.7','6.8','6.9',\\n                                        '7.0','7.1','7.2','7.3','7.4','7.5','7.6','7.7','7.8','7.9',\\n                                        '8.0','8.1','8.2','8.3','8.4','8.5','8.6','8.7','8.8','8.9',\\n                                        '9.0','9.1','9.2','9.3','9.4','9.5','9.6','9.7','9.8','9.9'])\"\n                index_df += 1\n                index_source += 1\n    boolean_mfd = True\n    file_MFD_name = str(Run_name) + '/analysis/txt_files/faults_MFD.txt'\n    file_MFD = open(file_MFD_name, 'w')\n    file_MFD.write(str(mega_MFD))\n    file_MFD.close()\n    slip_rate_sampling.close()\n    mean_parameters_faults.close()\n    df_mega_MFD = df_mega_MFD.dropna(how='all')\n    logictree = {'model': Model_list, 'scaling_law': ScL_complet_list, 'background': BG_hyp_list, 'b_value': b_value_list, 'MDF_type': MFD_type_list, 'rupture_set': scenarios_names_list}\n    return (mega_MFD, df_mega_MFD, scenarios_names_list, ScL_complet_list, ScL_list, Model_list, BG_hyp_list, dimension_used_list, faults_name_list, sample_list, b_value_list, MFD_type_list, m_Mmax, mega_bining_in_mag, a_s_model, b_sample, sm_sample, Mt_sample, sources_Lengths, sources_Areas, logictree)",
            "def extract(Run_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not os.path.exists(str(Run_name) + '/analysis'):\n        os.makedirs(str(Run_name) + '/analysis')\n    if not os.path.exists(str(Run_name) + '/analysis/txt_files'):\n        os.makedirs(str(Run_name) + '/analysis/txt_files')\n    mega_bining_in_mag = np.linspace(4, 9.9, num=60)\n    mega_MFD = []\n    f_sr = []\n    m_Mmax = []\n    a_s_model = []\n    faults_names = []\n    scenarios_names = []\n    b_sample = []\n    Mt_sample = []\n    sm_sample = []\n    faults_name_list = []\n    faults_id_list = []\n    fault_id = 0\n    scenarios_names_list = []\n    sample_list = []\n    BG_hyp_list = []\n    ScL_complet_list = []\n    ScL_list = []\n    dimension_used_list = []\n    Model_list = []\n    b_value_list = []\n    MFD_type_list = []\n    boolean_mfd = True\n    LT_file = str(Run_name) + '/Sources_Logic_tree.xml'\n    tree = ET.parse(LT_file)\n    nrml = tree.getroot()\n    Branch_names = []\n    branch_path = []\n    general_weight = []\n    for logicTree in nrml:\n        for logicTreeBranchLevel in logicTree:\n            for logicTreeBranchSet in logicTreeBranchLevel:\n                for logicTreeBranch in logicTreeBranchSet:\n                    Branch_names.append(logicTreeBranch.attrib['branchID'])\n                    path_i = logicTreeBranch[0].text[:-4]\n                    branch_path.append(path_i.split('/'))\n                    general_weight.append(logicTreeBranch[1].text)\n    df_mega_MFD = pd.DataFrame(columns=['selected_ScL', 'dim_used', 'str_all_data', 'Model', 'BG_hyp', 'b_min', 'b_max', 'MFD_type', 'scenario_set', 'sample', 'source', '4.0', '4.1', '4.2', '4.3', '4.4', '4.5', '4.6', '4.7', '4.8', '4.9', '5.0', '5.1', '5.2', '5.3', '5.4', '5.5', '5.6', '5.7', '5.8', '5.9', '6.0', '6.1', '6.2', '6.3', '6.4', '6.5', '6.6', '6.7', '6.8', '6.9', '7.0', '7.1', '7.2', '7.3', '7.4', '7.5', '7.6', '7.7', '7.8', '7.9', '8.0', '8.1', '8.2', '8.3', '8.4', '8.5', '8.6', '8.7', '8.8', '8.9', '9.0', '9.1', '9.2', '9.3', '9.4', '9.5', '9.6', '9.7', '9.8', '9.9'], index=range(len(Branch_names) * 100000))\n    index_df = 0\n    slip_rate_sampling = open(Run_name + '/analysis/txt_files/slip_rate_sampling.txt', 'w')\n    mean_parameters_faults = open(Run_name + '/analysis/txt_files/mean_parameters_faults.txt', 'w')\n    for branch in Branch_names:\n        branch = branch.split('-')\n        Model = branch[0]\n        BG_hyp = branch[1][3:]\n        selected_ScL = branch[2]\n        dim_used = branch[3][0]\n        str_all_data = branch[4]\n        scenario_set = branch[5][3:]\n        b_value = branch[6]\n        b_min = float(b_value.split('_')[1])\n        b_max = float(b_value.split('_')[3])\n        MFD_type = branch[7][4:]\n        sample = branch[8].split('_')[1]\n        log_sr_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/slip_rate_sample_' + str(sample) + '.txt'\n        (faults_names_i, faults_slip_rates__i) = Read_file.read_file_sr_log(log_sr_file)\n        f_sr.append(faults_slip_rates__i)\n        faults_names.append(faults_names_i)\n        for (fault_name, sr) in zip(faults_names_i, faults_slip_rates__i):\n            slip_rate_sampling.write(str(Run_name) + '\\t' + str(Model) + '\\t' + str(BG_hyp) + '\\t' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '\\t' + str(scenario_set) + '\\t' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '\\t' + str(MFD_type) + '\\t' + str(sample) + '\\t' + str(fault_name) + '\\t' + str(sr) + '\\n')\n        log_as_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/calculation_sample_' + str(sample) + '.txt'\n        a_s_i = Read_file.read_file_as_log(log_as_file)\n        a_s_model.append(a_s_i)\n        log_general_param_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/general_parameters_sample_' + str(sample) + '.txt'\n        (M_trunc_model, b_value_model) = Read_file.read_file_general_param_log(log_general_param_file)\n        b_sample.append(b_value_model)\n        Mt_sample.append(M_trunc_model)\n        log_Mmax_file = str(Run_name) + '/' + str(Model) + '/Log/Mmax_sample_' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '_sc_' + str(scenario_set) + '_' + str(sample) + '.txt'\n        (sources_names, sources_Mmax, sources_Lengths, sources_Areas) = Read_file.read_file_Mmax_log(log_Mmax_file)\n        m_Mmax.append(max(sources_Mmax))\n        for name in faults_names:\n            if not name in faults_name_list:\n                faults_name_list.append(name)\n                faults_id_list.append(fault_id)\n                fault_id += 1\n        if not sample in sample_list:\n            sample_list.append(sample)\n        if not b_value in b_value_list:\n            b_value_list.append(b_value)\n        if not MFD_type in MFD_type_list:\n            MFD_type_list.append(MFD_type)\n        if not dim_used in dimension_used_list:\n            dimension_used_list.append(dim_used)\n        scenarios_names.append(scenario_set)\n        if not scenario_set in scenarios_names_list:\n            scenarios_names_list.append(scenario_set)\n        if not BG_hyp in BG_hyp_list:\n            BG_hyp_list.append(BG_hyp)\n        if not str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data) in ScL_complet_list:\n            ScL_complet_list.append(str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data))\n        if not selected_ScL in ScL_list:\n            ScL_list.append(selected_ScL)\n        if not Model in Model_list:\n            Model_list.append(Model)\n        for (fault_name, sr) in zip(faults_names_i, faults_slip_rates__i):\n            if sample == '1' and BG_hyp == BG_hyp_list[0] and (str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data) == ScL_complet_list[0]):\n                if b_value == b_value_list[0] and MFD_type == MFD_type_list[0]:\n                    Mmax_fault = 0.0\n                    for (source, Mmax_i) in zip(sources_names, sources_Mmax):\n                        if fault_name == source or \"['\" + fault_name + \"']\" in source:\n                            if float(Mmax_i) > Mmax_fault:\n                                Mmax_fault = Mmax_i\n                    mean_parameters_faults.write(str(Model) + '\\t' + str(scenario_set) + '\\t' + str(fault_name) + '\\t' + str(sr) + '\\t' + str(Mmax_fault) + '\\n')\n        if boolean_mfd == True:\n            log_mfd_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/mdf_sample_' + str(sample) + '.txt'\n            (sources_names, Mmin, MFD) = Read_file.read_file_mfd_log(log_mfd_file)\n            index_Mmin = np.where(np.array(mega_bining_in_mag) == min(Mmin))[0]\n            index_source = 0\n            for source in sources_names:\n                '\\n                #the source is replaced by a list of id of fault as a tring to gain memory place\\n                list_id  =[]\\n                for i in source.split(\"=[\\'\"): \\n                    try :\\n                        iii = i.index(\"\\'\")\\n                        fault_id = np.where(np.array(faults_name_list[0])==i[:iii])[0][0]\\n                        list_id.append(fault_id)\\n                    except:\\n                        i=i\\n                if len(source.split(\"=[\\'\")) == 1:\\n                    if source == \\'Background\\':\\n                        list_id = \\'[Background]\\'\\n                    else:\\n                        #print(source[len(Model)+1:])\\n                        fault_id = np.where(np.array(faults_name_list[0])==source[len(Model)+1:])[0][0]\\n                        list_id.append(fault_id)'\n                mega_mfd_i = []\n                mega_mfd_i.append(selected_ScL)\n                mega_mfd_i.append(dim_used)\n                mega_mfd_i.append(str_all_data)\n                mega_mfd_i.append(Model)\n                mega_mfd_i.append(BG_hyp)\n                mega_mfd_i.append(str(b_min))\n                mega_mfd_i.append(str(b_max))\n                mega_mfd_i.append(MFD_type)\n                mega_mfd_i.append(scenario_set)\n                mega_mfd_i.append(sample)\n                mega_mfd_i.append(source)\n                for index_mag in range(len(mega_bining_in_mag)):\n                    if index_mag < len(MFD[index_source]) + index_Mmin and index_mag >= index_Mmin:\n                        try:\n                            mega_mfd_i.append(float(MFD[index_source][int(index_mag - index_Mmin)]))\n                        except TypeError:\n                            print('!!!!!!!!!!!!!!!!\\n\\n\\n' + 'There is a problem with a log file' + 'Delete the .xml corresponding to this file' + 'Then re-run SHERIFS with overwrite_files = False' + 'file with a problem : ')\n                            print(log_mfd_file)\n                    else:\n                        mega_mfd_i.append(0.0)\n                mega_MFD.append(np.array(mega_mfd_i))\n                dict_df_mfd_i = {'selected_ScL': selected_ScL, 'dim_used': dim_used, 'str_all_data': str_all_data, 'Model': Model, 'BG_hyp': BG_hyp, 'b_min': str(b_min), 'b_max': str(b_max), 'MFD_type': MFD_type, 'scenario_set': scenario_set, 'sample': sample, 'source': source, '4.0': np.sum(mega_mfd_i[11:]), '4.1': np.sum(mega_mfd_i[12:]), '4.2': np.sum(mega_mfd_i[13:]), '4.3': np.sum(mega_mfd_i[14:]), '4.4': np.sum(mega_mfd_i[15:]), '4.5': np.sum(mega_mfd_i[16:]), '4.6': np.sum(mega_mfd_i[17:]), '4.7': np.sum(mega_mfd_i[18:]), '4.8': np.sum(mega_mfd_i[19:]), '4.9': np.sum(mega_mfd_i[20:]), '5.0': np.sum(mega_mfd_i[21:]), '5.1': np.sum(mega_mfd_i[22:]), '5.2': np.sum(mega_mfd_i[23:]), '5.3': np.sum(mega_mfd_i[24:]), '5.4': np.sum(mega_mfd_i[25:]), '5.5': np.sum(mega_mfd_i[26:]), '5.6': np.sum(mega_mfd_i[27:]), '5.7': np.sum(mega_mfd_i[28:]), '5.8': np.sum(mega_mfd_i[29:]), '5.9': np.sum(mega_mfd_i[30:]), '6.0': np.sum(mega_mfd_i[31:]), '6.1': np.sum(mega_mfd_i[32:]), '6.2': np.sum(mega_mfd_i[33:]), '6.3': np.sum(mega_mfd_i[34:]), '6.4': np.sum(mega_mfd_i[35:]), '6.5': np.sum(mega_mfd_i[36:]), '6.6': np.sum(mega_mfd_i[37:]), '6.7': np.sum(mega_mfd_i[38:]), '6.8': np.sum(mega_mfd_i[39:]), '6.9': np.sum(mega_mfd_i[40:]), '7.0': np.sum(mega_mfd_i[41:]), '7.1': np.sum(mega_mfd_i[42:]), '7.2': np.sum(mega_mfd_i[43:]), '7.3': np.sum(mega_mfd_i[44:]), '7.4': np.sum(mega_mfd_i[45:]), '7.5': np.sum(mega_mfd_i[46:]), '7.6': np.sum(mega_mfd_i[47:]), '7.7': np.sum(mega_mfd_i[48:]), '7.8': np.sum(mega_mfd_i[49:]), '7.9': np.sum(mega_mfd_i[50:]), '8.0': np.sum(mega_mfd_i[51:]), '8.1': np.sum(mega_mfd_i[52:]), '8.2': np.sum(mega_mfd_i[53:]), '8.3': np.sum(mega_mfd_i[54:]), '8.4': np.sum(mega_mfd_i[55:]), '8.5': np.sum(mega_mfd_i[56:]), '8.6': np.sum(mega_mfd_i[57:]), '8.7': np.sum(mega_mfd_i[58:]), '8.8': np.sum(mega_mfd_i[59:]), '8.9': np.sum(mega_mfd_i[60:]), '9.0': np.sum(mega_mfd_i[61:]), '9.1': np.sum(mega_mfd_i[62:]), '9.2': np.sum(mega_mfd_i[63:]), '9.3': np.sum(mega_mfd_i[64:]), '9.4': np.sum(mega_mfd_i[65:]), '9.5': np.sum(mega_mfd_i[66:]), '9.6': np.sum(mega_mfd_i[67:]), '9.7': np.sum(mega_mfd_i[68:]), '9.8': np.sum(mega_mfd_i[69:]), '9.9': np.sum(mega_mfd_i[70:])}\n                df_mega_MFD.loc[index_df] = pd.Series(dict_df_mfd_i)\n                \"df_mega_MFD.loc[index_df] = mega_mfd_i\\n                ,columns=['selected_ScL','dim_used','str_all_data','Model','BG_hyp',\\n                                        'b_min','b_max','MFD_type','scenario_set','sample','source',\\n                                        '4.0','4.1','4.2','4.3','4.4','4.5','4.6','4.7','4.8','4.9',\\n                                        '5.0','5.1','5.2','5.3','5.4','5.5','5.6','5.7','5.8','5.9',\\n                                        '6.0','6.1','6.2','6.3','6.4','6.5','6.6','6.7','6.8','6.9',\\n                                        '7.0','7.1','7.2','7.3','7.4','7.5','7.6','7.7','7.8','7.9',\\n                                        '8.0','8.1','8.2','8.3','8.4','8.5','8.6','8.7','8.8','8.9',\\n                                        '9.0','9.1','9.2','9.3','9.4','9.5','9.6','9.7','9.8','9.9'])\"\n                index_df += 1\n                index_source += 1\n    boolean_mfd = True\n    file_MFD_name = str(Run_name) + '/analysis/txt_files/faults_MFD.txt'\n    file_MFD = open(file_MFD_name, 'w')\n    file_MFD.write(str(mega_MFD))\n    file_MFD.close()\n    slip_rate_sampling.close()\n    mean_parameters_faults.close()\n    df_mega_MFD = df_mega_MFD.dropna(how='all')\n    logictree = {'model': Model_list, 'scaling_law': ScL_complet_list, 'background': BG_hyp_list, 'b_value': b_value_list, 'MDF_type': MFD_type_list, 'rupture_set': scenarios_names_list}\n    return (mega_MFD, df_mega_MFD, scenarios_names_list, ScL_complet_list, ScL_list, Model_list, BG_hyp_list, dimension_used_list, faults_name_list, sample_list, b_value_list, MFD_type_list, m_Mmax, mega_bining_in_mag, a_s_model, b_sample, sm_sample, Mt_sample, sources_Lengths, sources_Areas, logictree)",
            "def extract(Run_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not os.path.exists(str(Run_name) + '/analysis'):\n        os.makedirs(str(Run_name) + '/analysis')\n    if not os.path.exists(str(Run_name) + '/analysis/txt_files'):\n        os.makedirs(str(Run_name) + '/analysis/txt_files')\n    mega_bining_in_mag = np.linspace(4, 9.9, num=60)\n    mega_MFD = []\n    f_sr = []\n    m_Mmax = []\n    a_s_model = []\n    faults_names = []\n    scenarios_names = []\n    b_sample = []\n    Mt_sample = []\n    sm_sample = []\n    faults_name_list = []\n    faults_id_list = []\n    fault_id = 0\n    scenarios_names_list = []\n    sample_list = []\n    BG_hyp_list = []\n    ScL_complet_list = []\n    ScL_list = []\n    dimension_used_list = []\n    Model_list = []\n    b_value_list = []\n    MFD_type_list = []\n    boolean_mfd = True\n    LT_file = str(Run_name) + '/Sources_Logic_tree.xml'\n    tree = ET.parse(LT_file)\n    nrml = tree.getroot()\n    Branch_names = []\n    branch_path = []\n    general_weight = []\n    for logicTree in nrml:\n        for logicTreeBranchLevel in logicTree:\n            for logicTreeBranchSet in logicTreeBranchLevel:\n                for logicTreeBranch in logicTreeBranchSet:\n                    Branch_names.append(logicTreeBranch.attrib['branchID'])\n                    path_i = logicTreeBranch[0].text[:-4]\n                    branch_path.append(path_i.split('/'))\n                    general_weight.append(logicTreeBranch[1].text)\n    df_mega_MFD = pd.DataFrame(columns=['selected_ScL', 'dim_used', 'str_all_data', 'Model', 'BG_hyp', 'b_min', 'b_max', 'MFD_type', 'scenario_set', 'sample', 'source', '4.0', '4.1', '4.2', '4.3', '4.4', '4.5', '4.6', '4.7', '4.8', '4.9', '5.0', '5.1', '5.2', '5.3', '5.4', '5.5', '5.6', '5.7', '5.8', '5.9', '6.0', '6.1', '6.2', '6.3', '6.4', '6.5', '6.6', '6.7', '6.8', '6.9', '7.0', '7.1', '7.2', '7.3', '7.4', '7.5', '7.6', '7.7', '7.8', '7.9', '8.0', '8.1', '8.2', '8.3', '8.4', '8.5', '8.6', '8.7', '8.8', '8.9', '9.0', '9.1', '9.2', '9.3', '9.4', '9.5', '9.6', '9.7', '9.8', '9.9'], index=range(len(Branch_names) * 100000))\n    index_df = 0\n    slip_rate_sampling = open(Run_name + '/analysis/txt_files/slip_rate_sampling.txt', 'w')\n    mean_parameters_faults = open(Run_name + '/analysis/txt_files/mean_parameters_faults.txt', 'w')\n    for branch in Branch_names:\n        branch = branch.split('-')\n        Model = branch[0]\n        BG_hyp = branch[1][3:]\n        selected_ScL = branch[2]\n        dim_used = branch[3][0]\n        str_all_data = branch[4]\n        scenario_set = branch[5][3:]\n        b_value = branch[6]\n        b_min = float(b_value.split('_')[1])\n        b_max = float(b_value.split('_')[3])\n        MFD_type = branch[7][4:]\n        sample = branch[8].split('_')[1]\n        log_sr_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/slip_rate_sample_' + str(sample) + '.txt'\n        (faults_names_i, faults_slip_rates__i) = Read_file.read_file_sr_log(log_sr_file)\n        f_sr.append(faults_slip_rates__i)\n        faults_names.append(faults_names_i)\n        for (fault_name, sr) in zip(faults_names_i, faults_slip_rates__i):\n            slip_rate_sampling.write(str(Run_name) + '\\t' + str(Model) + '\\t' + str(BG_hyp) + '\\t' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '\\t' + str(scenario_set) + '\\t' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '\\t' + str(MFD_type) + '\\t' + str(sample) + '\\t' + str(fault_name) + '\\t' + str(sr) + '\\n')\n        log_as_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/calculation_sample_' + str(sample) + '.txt'\n        a_s_i = Read_file.read_file_as_log(log_as_file)\n        a_s_model.append(a_s_i)\n        log_general_param_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/general_parameters_sample_' + str(sample) + '.txt'\n        (M_trunc_model, b_value_model) = Read_file.read_file_general_param_log(log_general_param_file)\n        b_sample.append(b_value_model)\n        Mt_sample.append(M_trunc_model)\n        log_Mmax_file = str(Run_name) + '/' + str(Model) + '/Log/Mmax_sample_' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '_sc_' + str(scenario_set) + '_' + str(sample) + '.txt'\n        (sources_names, sources_Mmax, sources_Lengths, sources_Areas) = Read_file.read_file_Mmax_log(log_Mmax_file)\n        m_Mmax.append(max(sources_Mmax))\n        for name in faults_names:\n            if not name in faults_name_list:\n                faults_name_list.append(name)\n                faults_id_list.append(fault_id)\n                fault_id += 1\n        if not sample in sample_list:\n            sample_list.append(sample)\n        if not b_value in b_value_list:\n            b_value_list.append(b_value)\n        if not MFD_type in MFD_type_list:\n            MFD_type_list.append(MFD_type)\n        if not dim_used in dimension_used_list:\n            dimension_used_list.append(dim_used)\n        scenarios_names.append(scenario_set)\n        if not scenario_set in scenarios_names_list:\n            scenarios_names_list.append(scenario_set)\n        if not BG_hyp in BG_hyp_list:\n            BG_hyp_list.append(BG_hyp)\n        if not str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data) in ScL_complet_list:\n            ScL_complet_list.append(str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data))\n        if not selected_ScL in ScL_list:\n            ScL_list.append(selected_ScL)\n        if not Model in Model_list:\n            Model_list.append(Model)\n        for (fault_name, sr) in zip(faults_names_i, faults_slip_rates__i):\n            if sample == '1' and BG_hyp == BG_hyp_list[0] and (str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data) == ScL_complet_list[0]):\n                if b_value == b_value_list[0] and MFD_type == MFD_type_list[0]:\n                    Mmax_fault = 0.0\n                    for (source, Mmax_i) in zip(sources_names, sources_Mmax):\n                        if fault_name == source or \"['\" + fault_name + \"']\" in source:\n                            if float(Mmax_i) > Mmax_fault:\n                                Mmax_fault = Mmax_i\n                    mean_parameters_faults.write(str(Model) + '\\t' + str(scenario_set) + '\\t' + str(fault_name) + '\\t' + str(sr) + '\\t' + str(Mmax_fault) + '\\n')\n        if boolean_mfd == True:\n            log_mfd_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/mdf_sample_' + str(sample) + '.txt'\n            (sources_names, Mmin, MFD) = Read_file.read_file_mfd_log(log_mfd_file)\n            index_Mmin = np.where(np.array(mega_bining_in_mag) == min(Mmin))[0]\n            index_source = 0\n            for source in sources_names:\n                '\\n                #the source is replaced by a list of id of fault as a tring to gain memory place\\n                list_id  =[]\\n                for i in source.split(\"=[\\'\"): \\n                    try :\\n                        iii = i.index(\"\\'\")\\n                        fault_id = np.where(np.array(faults_name_list[0])==i[:iii])[0][0]\\n                        list_id.append(fault_id)\\n                    except:\\n                        i=i\\n                if len(source.split(\"=[\\'\")) == 1:\\n                    if source == \\'Background\\':\\n                        list_id = \\'[Background]\\'\\n                    else:\\n                        #print(source[len(Model)+1:])\\n                        fault_id = np.where(np.array(faults_name_list[0])==source[len(Model)+1:])[0][0]\\n                        list_id.append(fault_id)'\n                mega_mfd_i = []\n                mega_mfd_i.append(selected_ScL)\n                mega_mfd_i.append(dim_used)\n                mega_mfd_i.append(str_all_data)\n                mega_mfd_i.append(Model)\n                mega_mfd_i.append(BG_hyp)\n                mega_mfd_i.append(str(b_min))\n                mega_mfd_i.append(str(b_max))\n                mega_mfd_i.append(MFD_type)\n                mega_mfd_i.append(scenario_set)\n                mega_mfd_i.append(sample)\n                mega_mfd_i.append(source)\n                for index_mag in range(len(mega_bining_in_mag)):\n                    if index_mag < len(MFD[index_source]) + index_Mmin and index_mag >= index_Mmin:\n                        try:\n                            mega_mfd_i.append(float(MFD[index_source][int(index_mag - index_Mmin)]))\n                        except TypeError:\n                            print('!!!!!!!!!!!!!!!!\\n\\n\\n' + 'There is a problem with a log file' + 'Delete the .xml corresponding to this file' + 'Then re-run SHERIFS with overwrite_files = False' + 'file with a problem : ')\n                            print(log_mfd_file)\n                    else:\n                        mega_mfd_i.append(0.0)\n                mega_MFD.append(np.array(mega_mfd_i))\n                dict_df_mfd_i = {'selected_ScL': selected_ScL, 'dim_used': dim_used, 'str_all_data': str_all_data, 'Model': Model, 'BG_hyp': BG_hyp, 'b_min': str(b_min), 'b_max': str(b_max), 'MFD_type': MFD_type, 'scenario_set': scenario_set, 'sample': sample, 'source': source, '4.0': np.sum(mega_mfd_i[11:]), '4.1': np.sum(mega_mfd_i[12:]), '4.2': np.sum(mega_mfd_i[13:]), '4.3': np.sum(mega_mfd_i[14:]), '4.4': np.sum(mega_mfd_i[15:]), '4.5': np.sum(mega_mfd_i[16:]), '4.6': np.sum(mega_mfd_i[17:]), '4.7': np.sum(mega_mfd_i[18:]), '4.8': np.sum(mega_mfd_i[19:]), '4.9': np.sum(mega_mfd_i[20:]), '5.0': np.sum(mega_mfd_i[21:]), '5.1': np.sum(mega_mfd_i[22:]), '5.2': np.sum(mega_mfd_i[23:]), '5.3': np.sum(mega_mfd_i[24:]), '5.4': np.sum(mega_mfd_i[25:]), '5.5': np.sum(mega_mfd_i[26:]), '5.6': np.sum(mega_mfd_i[27:]), '5.7': np.sum(mega_mfd_i[28:]), '5.8': np.sum(mega_mfd_i[29:]), '5.9': np.sum(mega_mfd_i[30:]), '6.0': np.sum(mega_mfd_i[31:]), '6.1': np.sum(mega_mfd_i[32:]), '6.2': np.sum(mega_mfd_i[33:]), '6.3': np.sum(mega_mfd_i[34:]), '6.4': np.sum(mega_mfd_i[35:]), '6.5': np.sum(mega_mfd_i[36:]), '6.6': np.sum(mega_mfd_i[37:]), '6.7': np.sum(mega_mfd_i[38:]), '6.8': np.sum(mega_mfd_i[39:]), '6.9': np.sum(mega_mfd_i[40:]), '7.0': np.sum(mega_mfd_i[41:]), '7.1': np.sum(mega_mfd_i[42:]), '7.2': np.sum(mega_mfd_i[43:]), '7.3': np.sum(mega_mfd_i[44:]), '7.4': np.sum(mega_mfd_i[45:]), '7.5': np.sum(mega_mfd_i[46:]), '7.6': np.sum(mega_mfd_i[47:]), '7.7': np.sum(mega_mfd_i[48:]), '7.8': np.sum(mega_mfd_i[49:]), '7.9': np.sum(mega_mfd_i[50:]), '8.0': np.sum(mega_mfd_i[51:]), '8.1': np.sum(mega_mfd_i[52:]), '8.2': np.sum(mega_mfd_i[53:]), '8.3': np.sum(mega_mfd_i[54:]), '8.4': np.sum(mega_mfd_i[55:]), '8.5': np.sum(mega_mfd_i[56:]), '8.6': np.sum(mega_mfd_i[57:]), '8.7': np.sum(mega_mfd_i[58:]), '8.8': np.sum(mega_mfd_i[59:]), '8.9': np.sum(mega_mfd_i[60:]), '9.0': np.sum(mega_mfd_i[61:]), '9.1': np.sum(mega_mfd_i[62:]), '9.2': np.sum(mega_mfd_i[63:]), '9.3': np.sum(mega_mfd_i[64:]), '9.4': np.sum(mega_mfd_i[65:]), '9.5': np.sum(mega_mfd_i[66:]), '9.6': np.sum(mega_mfd_i[67:]), '9.7': np.sum(mega_mfd_i[68:]), '9.8': np.sum(mega_mfd_i[69:]), '9.9': np.sum(mega_mfd_i[70:])}\n                df_mega_MFD.loc[index_df] = pd.Series(dict_df_mfd_i)\n                \"df_mega_MFD.loc[index_df] = mega_mfd_i\\n                ,columns=['selected_ScL','dim_used','str_all_data','Model','BG_hyp',\\n                                        'b_min','b_max','MFD_type','scenario_set','sample','source',\\n                                        '4.0','4.1','4.2','4.3','4.4','4.5','4.6','4.7','4.8','4.9',\\n                                        '5.0','5.1','5.2','5.3','5.4','5.5','5.6','5.7','5.8','5.9',\\n                                        '6.0','6.1','6.2','6.3','6.4','6.5','6.6','6.7','6.8','6.9',\\n                                        '7.0','7.1','7.2','7.3','7.4','7.5','7.6','7.7','7.8','7.9',\\n                                        '8.0','8.1','8.2','8.3','8.4','8.5','8.6','8.7','8.8','8.9',\\n                                        '9.0','9.1','9.2','9.3','9.4','9.5','9.6','9.7','9.8','9.9'])\"\n                index_df += 1\n                index_source += 1\n    boolean_mfd = True\n    file_MFD_name = str(Run_name) + '/analysis/txt_files/faults_MFD.txt'\n    file_MFD = open(file_MFD_name, 'w')\n    file_MFD.write(str(mega_MFD))\n    file_MFD.close()\n    slip_rate_sampling.close()\n    mean_parameters_faults.close()\n    df_mega_MFD = df_mega_MFD.dropna(how='all')\n    logictree = {'model': Model_list, 'scaling_law': ScL_complet_list, 'background': BG_hyp_list, 'b_value': b_value_list, 'MDF_type': MFD_type_list, 'rupture_set': scenarios_names_list}\n    return (mega_MFD, df_mega_MFD, scenarios_names_list, ScL_complet_list, ScL_list, Model_list, BG_hyp_list, dimension_used_list, faults_name_list, sample_list, b_value_list, MFD_type_list, m_Mmax, mega_bining_in_mag, a_s_model, b_sample, sm_sample, Mt_sample, sources_Lengths, sources_Areas, logictree)",
            "def extract(Run_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not os.path.exists(str(Run_name) + '/analysis'):\n        os.makedirs(str(Run_name) + '/analysis')\n    if not os.path.exists(str(Run_name) + '/analysis/txt_files'):\n        os.makedirs(str(Run_name) + '/analysis/txt_files')\n    mega_bining_in_mag = np.linspace(4, 9.9, num=60)\n    mega_MFD = []\n    f_sr = []\n    m_Mmax = []\n    a_s_model = []\n    faults_names = []\n    scenarios_names = []\n    b_sample = []\n    Mt_sample = []\n    sm_sample = []\n    faults_name_list = []\n    faults_id_list = []\n    fault_id = 0\n    scenarios_names_list = []\n    sample_list = []\n    BG_hyp_list = []\n    ScL_complet_list = []\n    ScL_list = []\n    dimension_used_list = []\n    Model_list = []\n    b_value_list = []\n    MFD_type_list = []\n    boolean_mfd = True\n    LT_file = str(Run_name) + '/Sources_Logic_tree.xml'\n    tree = ET.parse(LT_file)\n    nrml = tree.getroot()\n    Branch_names = []\n    branch_path = []\n    general_weight = []\n    for logicTree in nrml:\n        for logicTreeBranchLevel in logicTree:\n            for logicTreeBranchSet in logicTreeBranchLevel:\n                for logicTreeBranch in logicTreeBranchSet:\n                    Branch_names.append(logicTreeBranch.attrib['branchID'])\n                    path_i = logicTreeBranch[0].text[:-4]\n                    branch_path.append(path_i.split('/'))\n                    general_weight.append(logicTreeBranch[1].text)\n    df_mega_MFD = pd.DataFrame(columns=['selected_ScL', 'dim_used', 'str_all_data', 'Model', 'BG_hyp', 'b_min', 'b_max', 'MFD_type', 'scenario_set', 'sample', 'source', '4.0', '4.1', '4.2', '4.3', '4.4', '4.5', '4.6', '4.7', '4.8', '4.9', '5.0', '5.1', '5.2', '5.3', '5.4', '5.5', '5.6', '5.7', '5.8', '5.9', '6.0', '6.1', '6.2', '6.3', '6.4', '6.5', '6.6', '6.7', '6.8', '6.9', '7.0', '7.1', '7.2', '7.3', '7.4', '7.5', '7.6', '7.7', '7.8', '7.9', '8.0', '8.1', '8.2', '8.3', '8.4', '8.5', '8.6', '8.7', '8.8', '8.9', '9.0', '9.1', '9.2', '9.3', '9.4', '9.5', '9.6', '9.7', '9.8', '9.9'], index=range(len(Branch_names) * 100000))\n    index_df = 0\n    slip_rate_sampling = open(Run_name + '/analysis/txt_files/slip_rate_sampling.txt', 'w')\n    mean_parameters_faults = open(Run_name + '/analysis/txt_files/mean_parameters_faults.txt', 'w')\n    for branch in Branch_names:\n        branch = branch.split('-')\n        Model = branch[0]\n        BG_hyp = branch[1][3:]\n        selected_ScL = branch[2]\n        dim_used = branch[3][0]\n        str_all_data = branch[4]\n        scenario_set = branch[5][3:]\n        b_value = branch[6]\n        b_min = float(b_value.split('_')[1])\n        b_max = float(b_value.split('_')[3])\n        MFD_type = branch[7][4:]\n        sample = branch[8].split('_')[1]\n        log_sr_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/slip_rate_sample_' + str(sample) + '.txt'\n        (faults_names_i, faults_slip_rates__i) = Read_file.read_file_sr_log(log_sr_file)\n        f_sr.append(faults_slip_rates__i)\n        faults_names.append(faults_names_i)\n        for (fault_name, sr) in zip(faults_names_i, faults_slip_rates__i):\n            slip_rate_sampling.write(str(Run_name) + '\\t' + str(Model) + '\\t' + str(BG_hyp) + '\\t' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '\\t' + str(scenario_set) + '\\t' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '\\t' + str(MFD_type) + '\\t' + str(sample) + '\\t' + str(fault_name) + '\\t' + str(sr) + '\\n')\n        log_as_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/calculation_sample_' + str(sample) + '.txt'\n        a_s_i = Read_file.read_file_as_log(log_as_file)\n        a_s_model.append(a_s_i)\n        log_general_param_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/general_parameters_sample_' + str(sample) + '.txt'\n        (M_trunc_model, b_value_model) = Read_file.read_file_general_param_log(log_general_param_file)\n        b_sample.append(b_value_model)\n        Mt_sample.append(M_trunc_model)\n        log_Mmax_file = str(Run_name) + '/' + str(Model) + '/Log/Mmax_sample_' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '_sc_' + str(scenario_set) + '_' + str(sample) + '.txt'\n        (sources_names, sources_Mmax, sources_Lengths, sources_Areas) = Read_file.read_file_Mmax_log(log_Mmax_file)\n        m_Mmax.append(max(sources_Mmax))\n        for name in faults_names:\n            if not name in faults_name_list:\n                faults_name_list.append(name)\n                faults_id_list.append(fault_id)\n                fault_id += 1\n        if not sample in sample_list:\n            sample_list.append(sample)\n        if not b_value in b_value_list:\n            b_value_list.append(b_value)\n        if not MFD_type in MFD_type_list:\n            MFD_type_list.append(MFD_type)\n        if not dim_used in dimension_used_list:\n            dimension_used_list.append(dim_used)\n        scenarios_names.append(scenario_set)\n        if not scenario_set in scenarios_names_list:\n            scenarios_names_list.append(scenario_set)\n        if not BG_hyp in BG_hyp_list:\n            BG_hyp_list.append(BG_hyp)\n        if not str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data) in ScL_complet_list:\n            ScL_complet_list.append(str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data))\n        if not selected_ScL in ScL_list:\n            ScL_list.append(selected_ScL)\n        if not Model in Model_list:\n            Model_list.append(Model)\n        for (fault_name, sr) in zip(faults_names_i, faults_slip_rates__i):\n            if sample == '1' and BG_hyp == BG_hyp_list[0] and (str(selected_ScL) + '_' + str(dim_used) + '_' + str(str_all_data) == ScL_complet_list[0]):\n                if b_value == b_value_list[0] and MFD_type == MFD_type_list[0]:\n                    Mmax_fault = 0.0\n                    for (source, Mmax_i) in zip(sources_names, sources_Mmax):\n                        if fault_name == source or \"['\" + fault_name + \"']\" in source:\n                            if float(Mmax_i) > Mmax_fault:\n                                Mmax_fault = Mmax_i\n                    mean_parameters_faults.write(str(Model) + '\\t' + str(scenario_set) + '\\t' + str(fault_name) + '\\t' + str(sr) + '\\t' + str(Mmax_fault) + '\\n')\n        if boolean_mfd == True:\n            log_mfd_file = str(Run_name) + '/' + str(Model) + '/' + 'bg_' + str(BG_hyp) + '/' + str(selected_ScL) + '_' + str(dim_used) + '_' + str_all_data + '/sc_' + str(scenario_set) + '/' + 'bmin_' + str(b_min) + '_bmax_' + str(b_max) + '/' + 'MFD_' + str(MFD_type) + '/Log/mdf_sample_' + str(sample) + '.txt'\n            (sources_names, Mmin, MFD) = Read_file.read_file_mfd_log(log_mfd_file)\n            index_Mmin = np.where(np.array(mega_bining_in_mag) == min(Mmin))[0]\n            index_source = 0\n            for source in sources_names:\n                '\\n                #the source is replaced by a list of id of fault as a tring to gain memory place\\n                list_id  =[]\\n                for i in source.split(\"=[\\'\"): \\n                    try :\\n                        iii = i.index(\"\\'\")\\n                        fault_id = np.where(np.array(faults_name_list[0])==i[:iii])[0][0]\\n                        list_id.append(fault_id)\\n                    except:\\n                        i=i\\n                if len(source.split(\"=[\\'\")) == 1:\\n                    if source == \\'Background\\':\\n                        list_id = \\'[Background]\\'\\n                    else:\\n                        #print(source[len(Model)+1:])\\n                        fault_id = np.where(np.array(faults_name_list[0])==source[len(Model)+1:])[0][0]\\n                        list_id.append(fault_id)'\n                mega_mfd_i = []\n                mega_mfd_i.append(selected_ScL)\n                mega_mfd_i.append(dim_used)\n                mega_mfd_i.append(str_all_data)\n                mega_mfd_i.append(Model)\n                mega_mfd_i.append(BG_hyp)\n                mega_mfd_i.append(str(b_min))\n                mega_mfd_i.append(str(b_max))\n                mega_mfd_i.append(MFD_type)\n                mega_mfd_i.append(scenario_set)\n                mega_mfd_i.append(sample)\n                mega_mfd_i.append(source)\n                for index_mag in range(len(mega_bining_in_mag)):\n                    if index_mag < len(MFD[index_source]) + index_Mmin and index_mag >= index_Mmin:\n                        try:\n                            mega_mfd_i.append(float(MFD[index_source][int(index_mag - index_Mmin)]))\n                        except TypeError:\n                            print('!!!!!!!!!!!!!!!!\\n\\n\\n' + 'There is a problem with a log file' + 'Delete the .xml corresponding to this file' + 'Then re-run SHERIFS with overwrite_files = False' + 'file with a problem : ')\n                            print(log_mfd_file)\n                    else:\n                        mega_mfd_i.append(0.0)\n                mega_MFD.append(np.array(mega_mfd_i))\n                dict_df_mfd_i = {'selected_ScL': selected_ScL, 'dim_used': dim_used, 'str_all_data': str_all_data, 'Model': Model, 'BG_hyp': BG_hyp, 'b_min': str(b_min), 'b_max': str(b_max), 'MFD_type': MFD_type, 'scenario_set': scenario_set, 'sample': sample, 'source': source, '4.0': np.sum(mega_mfd_i[11:]), '4.1': np.sum(mega_mfd_i[12:]), '4.2': np.sum(mega_mfd_i[13:]), '4.3': np.sum(mega_mfd_i[14:]), '4.4': np.sum(mega_mfd_i[15:]), '4.5': np.sum(mega_mfd_i[16:]), '4.6': np.sum(mega_mfd_i[17:]), '4.7': np.sum(mega_mfd_i[18:]), '4.8': np.sum(mega_mfd_i[19:]), '4.9': np.sum(mega_mfd_i[20:]), '5.0': np.sum(mega_mfd_i[21:]), '5.1': np.sum(mega_mfd_i[22:]), '5.2': np.sum(mega_mfd_i[23:]), '5.3': np.sum(mega_mfd_i[24:]), '5.4': np.sum(mega_mfd_i[25:]), '5.5': np.sum(mega_mfd_i[26:]), '5.6': np.sum(mega_mfd_i[27:]), '5.7': np.sum(mega_mfd_i[28:]), '5.8': np.sum(mega_mfd_i[29:]), '5.9': np.sum(mega_mfd_i[30:]), '6.0': np.sum(mega_mfd_i[31:]), '6.1': np.sum(mega_mfd_i[32:]), '6.2': np.sum(mega_mfd_i[33:]), '6.3': np.sum(mega_mfd_i[34:]), '6.4': np.sum(mega_mfd_i[35:]), '6.5': np.sum(mega_mfd_i[36:]), '6.6': np.sum(mega_mfd_i[37:]), '6.7': np.sum(mega_mfd_i[38:]), '6.8': np.sum(mega_mfd_i[39:]), '6.9': np.sum(mega_mfd_i[40:]), '7.0': np.sum(mega_mfd_i[41:]), '7.1': np.sum(mega_mfd_i[42:]), '7.2': np.sum(mega_mfd_i[43:]), '7.3': np.sum(mega_mfd_i[44:]), '7.4': np.sum(mega_mfd_i[45:]), '7.5': np.sum(mega_mfd_i[46:]), '7.6': np.sum(mega_mfd_i[47:]), '7.7': np.sum(mega_mfd_i[48:]), '7.8': np.sum(mega_mfd_i[49:]), '7.9': np.sum(mega_mfd_i[50:]), '8.0': np.sum(mega_mfd_i[51:]), '8.1': np.sum(mega_mfd_i[52:]), '8.2': np.sum(mega_mfd_i[53:]), '8.3': np.sum(mega_mfd_i[54:]), '8.4': np.sum(mega_mfd_i[55:]), '8.5': np.sum(mega_mfd_i[56:]), '8.6': np.sum(mega_mfd_i[57:]), '8.7': np.sum(mega_mfd_i[58:]), '8.8': np.sum(mega_mfd_i[59:]), '8.9': np.sum(mega_mfd_i[60:]), '9.0': np.sum(mega_mfd_i[61:]), '9.1': np.sum(mega_mfd_i[62:]), '9.2': np.sum(mega_mfd_i[63:]), '9.3': np.sum(mega_mfd_i[64:]), '9.4': np.sum(mega_mfd_i[65:]), '9.5': np.sum(mega_mfd_i[66:]), '9.6': np.sum(mega_mfd_i[67:]), '9.7': np.sum(mega_mfd_i[68:]), '9.8': np.sum(mega_mfd_i[69:]), '9.9': np.sum(mega_mfd_i[70:])}\n                df_mega_MFD.loc[index_df] = pd.Series(dict_df_mfd_i)\n                \"df_mega_MFD.loc[index_df] = mega_mfd_i\\n                ,columns=['selected_ScL','dim_used','str_all_data','Model','BG_hyp',\\n                                        'b_min','b_max','MFD_type','scenario_set','sample','source',\\n                                        '4.0','4.1','4.2','4.3','4.4','4.5','4.6','4.7','4.8','4.9',\\n                                        '5.0','5.1','5.2','5.3','5.4','5.5','5.6','5.7','5.8','5.9',\\n                                        '6.0','6.1','6.2','6.3','6.4','6.5','6.6','6.7','6.8','6.9',\\n                                        '7.0','7.1','7.2','7.3','7.4','7.5','7.6','7.7','7.8','7.9',\\n                                        '8.0','8.1','8.2','8.3','8.4','8.5','8.6','8.7','8.8','8.9',\\n                                        '9.0','9.1','9.2','9.3','9.4','9.5','9.6','9.7','9.8','9.9'])\"\n                index_df += 1\n                index_source += 1\n    boolean_mfd = True\n    file_MFD_name = str(Run_name) + '/analysis/txt_files/faults_MFD.txt'\n    file_MFD = open(file_MFD_name, 'w')\n    file_MFD.write(str(mega_MFD))\n    file_MFD.close()\n    slip_rate_sampling.close()\n    mean_parameters_faults.close()\n    df_mega_MFD = df_mega_MFD.dropna(how='all')\n    logictree = {'model': Model_list, 'scaling_law': ScL_complet_list, 'background': BG_hyp_list, 'b_value': b_value_list, 'MDF_type': MFD_type_list, 'rupture_set': scenarios_names_list}\n    return (mega_MFD, df_mega_MFD, scenarios_names_list, ScL_complet_list, ScL_list, Model_list, BG_hyp_list, dimension_used_list, faults_name_list, sample_list, b_value_list, MFD_type_list, m_Mmax, mega_bining_in_mag, a_s_model, b_sample, sm_sample, Mt_sample, sources_Lengths, sources_Areas, logictree)"
        ]
    }
]