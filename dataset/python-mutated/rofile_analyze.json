[
    {
        "func_name": "_tabulate_ml",
        "original": "def _tabulate_ml(tab, **kwargs):\n    \"\"\"Tabulate profile output with multi-line support.\"\"\"\n    new_tab = []\n    new_tab_is_row = []\n    for row in tab:\n        col_lines = [str(i).split('\\n') for i in row]\n        max_nr_line = max(map(len, col_lines))\n        new_tab_is_row.append(True)\n        if max_nr_line > 1:\n            new_tab_is_row.extend([False] * (max_nr_line - 1))\n            for i in col_lines:\n                if len(i) < max_nr_line:\n                    i.extend([''] * (max_nr_line - len(i)))\n            new_tab.extend(zip(*col_lines))\n        else:\n            new_tab.append(row)\n    assert len(new_tab_is_row) == len(new_tab)\n    ret = [i + '\\n' for i in tabulate(new_tab, **kwargs).split('\\n')]\n    for (idx, val) in enumerate(new_tab_is_row):\n        if not val:\n            ret[idx * 2 + 2] = ''\n    return ''.join(ret)[:-1]",
        "mutated": [
            "def _tabulate_ml(tab, **kwargs):\n    if False:\n        i = 10\n    'Tabulate profile output with multi-line support.'\n    new_tab = []\n    new_tab_is_row = []\n    for row in tab:\n        col_lines = [str(i).split('\\n') for i in row]\n        max_nr_line = max(map(len, col_lines))\n        new_tab_is_row.append(True)\n        if max_nr_line > 1:\n            new_tab_is_row.extend([False] * (max_nr_line - 1))\n            for i in col_lines:\n                if len(i) < max_nr_line:\n                    i.extend([''] * (max_nr_line - len(i)))\n            new_tab.extend(zip(*col_lines))\n        else:\n            new_tab.append(row)\n    assert len(new_tab_is_row) == len(new_tab)\n    ret = [i + '\\n' for i in tabulate(new_tab, **kwargs).split('\\n')]\n    for (idx, val) in enumerate(new_tab_is_row):\n        if not val:\n            ret[idx * 2 + 2] = ''\n    return ''.join(ret)[:-1]",
            "def _tabulate_ml(tab, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Tabulate profile output with multi-line support.'\n    new_tab = []\n    new_tab_is_row = []\n    for row in tab:\n        col_lines = [str(i).split('\\n') for i in row]\n        max_nr_line = max(map(len, col_lines))\n        new_tab_is_row.append(True)\n        if max_nr_line > 1:\n            new_tab_is_row.extend([False] * (max_nr_line - 1))\n            for i in col_lines:\n                if len(i) < max_nr_line:\n                    i.extend([''] * (max_nr_line - len(i)))\n            new_tab.extend(zip(*col_lines))\n        else:\n            new_tab.append(row)\n    assert len(new_tab_is_row) == len(new_tab)\n    ret = [i + '\\n' for i in tabulate(new_tab, **kwargs).split('\\n')]\n    for (idx, val) in enumerate(new_tab_is_row):\n        if not val:\n            ret[idx * 2 + 2] = ''\n    return ''.join(ret)[:-1]",
            "def _tabulate_ml(tab, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Tabulate profile output with multi-line support.'\n    new_tab = []\n    new_tab_is_row = []\n    for row in tab:\n        col_lines = [str(i).split('\\n') for i in row]\n        max_nr_line = max(map(len, col_lines))\n        new_tab_is_row.append(True)\n        if max_nr_line > 1:\n            new_tab_is_row.extend([False] * (max_nr_line - 1))\n            for i in col_lines:\n                if len(i) < max_nr_line:\n                    i.extend([''] * (max_nr_line - len(i)))\n            new_tab.extend(zip(*col_lines))\n        else:\n            new_tab.append(row)\n    assert len(new_tab_is_row) == len(new_tab)\n    ret = [i + '\\n' for i in tabulate(new_tab, **kwargs).split('\\n')]\n    for (idx, val) in enumerate(new_tab_is_row):\n        if not val:\n            ret[idx * 2 + 2] = ''\n    return ''.join(ret)[:-1]",
            "def _tabulate_ml(tab, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Tabulate profile output with multi-line support.'\n    new_tab = []\n    new_tab_is_row = []\n    for row in tab:\n        col_lines = [str(i).split('\\n') for i in row]\n        max_nr_line = max(map(len, col_lines))\n        new_tab_is_row.append(True)\n        if max_nr_line > 1:\n            new_tab_is_row.extend([False] * (max_nr_line - 1))\n            for i in col_lines:\n                if len(i) < max_nr_line:\n                    i.extend([''] * (max_nr_line - len(i)))\n            new_tab.extend(zip(*col_lines))\n        else:\n            new_tab.append(row)\n    assert len(new_tab_is_row) == len(new_tab)\n    ret = [i + '\\n' for i in tabulate(new_tab, **kwargs).split('\\n')]\n    for (idx, val) in enumerate(new_tab_is_row):\n        if not val:\n            ret[idx * 2 + 2] = ''\n    return ''.join(ret)[:-1]",
            "def _tabulate_ml(tab, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Tabulate profile output with multi-line support.'\n    new_tab = []\n    new_tab_is_row = []\n    for row in tab:\n        col_lines = [str(i).split('\\n') for i in row]\n        max_nr_line = max(map(len, col_lines))\n        new_tab_is_row.append(True)\n        if max_nr_line > 1:\n            new_tab_is_row.extend([False] * (max_nr_line - 1))\n            for i in col_lines:\n                if len(i) < max_nr_line:\n                    i.extend([''] * (max_nr_line - len(i)))\n            new_tab.extend(zip(*col_lines))\n        else:\n            new_tab.append(row)\n    assert len(new_tab_is_row) == len(new_tab)\n    ret = [i + '\\n' for i in tabulate(new_tab, **kwargs).split('\\n')]\n    for (idx, val) in enumerate(new_tab_is_row):\n        if not val:\n            ret[idx * 2 + 2] = ''\n    return ''.join(ret)[:-1]"
        ]
    },
    {
        "func_name": "_tabulate_confluence",
        "original": "def _tabulate_confluence(tab, **kwargs):\n    \"\"\"Tabulate profile output.\"\"\"\n    kwargs.pop('tablefmt', None)\n    s = tabulate(tab, tablefmt='orgtbl', **kwargs)\n    lines = s.split('\\n')\n    lines[1] = lines[1].replace('+', '|')\n    return '\\n'.join(lines)",
        "mutated": [
            "def _tabulate_confluence(tab, **kwargs):\n    if False:\n        i = 10\n    'Tabulate profile output.'\n    kwargs.pop('tablefmt', None)\n    s = tabulate(tab, tablefmt='orgtbl', **kwargs)\n    lines = s.split('\\n')\n    lines[1] = lines[1].replace('+', '|')\n    return '\\n'.join(lines)",
            "def _tabulate_confluence(tab, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Tabulate profile output.'\n    kwargs.pop('tablefmt', None)\n    s = tabulate(tab, tablefmt='orgtbl', **kwargs)\n    lines = s.split('\\n')\n    lines[1] = lines[1].replace('+', '|')\n    return '\\n'.join(lines)",
            "def _tabulate_confluence(tab, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Tabulate profile output.'\n    kwargs.pop('tablefmt', None)\n    s = tabulate(tab, tablefmt='orgtbl', **kwargs)\n    lines = s.split('\\n')\n    lines[1] = lines[1].replace('+', '|')\n    return '\\n'.join(lines)",
            "def _tabulate_confluence(tab, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Tabulate profile output.'\n    kwargs.pop('tablefmt', None)\n    s = tabulate(tab, tablefmt='orgtbl', **kwargs)\n    lines = s.split('\\n')\n    lines[1] = lines[1].replace('+', '|')\n    return '\\n'.join(lines)",
            "def _tabulate_confluence(tab, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Tabulate profile output.'\n    kwargs.pop('tablefmt', None)\n    s = tabulate(tab, tablefmt='orgtbl', **kwargs)\n    lines = s.split('\\n')\n    lines[1] = lines[1].replace('+', '|')\n    return '\\n'.join(lines)"
        ]
    },
    {
        "func_name": "opr_filter",
        "original": "def opr_filter(o, a, b):\n    return True",
        "mutated": [
            "def opr_filter(o, a, b):\n    if False:\n        i = 10\n    return True",
            "def opr_filter(o, a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return True",
            "def opr_filter(o, a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return True",
            "def opr_filter(o, a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return True",
            "def opr_filter(o, a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return True"
        ]
    },
    {
        "func_name": "opr_filter",
        "original": "def opr_filter(o, a, b):\n    return all((i(o, a, b) for i in opr_filters))",
        "mutated": [
            "def opr_filter(o, a, b):\n    if False:\n        i = 10\n    return all((i(o, a, b) for i in opr_filters))",
            "def opr_filter(o, a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return all((i(o, a, b) for i in opr_filters))",
            "def opr_filter(o, a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return all((i(o, a, b) for i in opr_filters))",
            "def opr_filter(o, a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return all((i(o, a, b) for i in opr_filters))",
            "def opr_filter(o, a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return all((i(o, a, b) for i in opr_filters))"
        ]
    },
    {
        "func_name": "get_tot_time",
        "original": "def get_tot_time(func):\n    rec = analyzer_tot.select(func, aggregate=np.sum)\n    if not rec:\n        return 'N/A'\n    rec = rec[0]\n    return rec.time",
        "mutated": [
            "def get_tot_time(func):\n    if False:\n        i = 10\n    rec = analyzer_tot.select(func, aggregate=np.sum)\n    if not rec:\n        return 'N/A'\n    rec = rec[0]\n    return rec.time",
            "def get_tot_time(func):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    rec = analyzer_tot.select(func, aggregate=np.sum)\n    if not rec:\n        return 'N/A'\n    rec = rec[0]\n    return rec.time",
            "def get_tot_time(func):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    rec = analyzer_tot.select(func, aggregate=np.sum)\n    if not rec:\n        return 'N/A'\n    rec = rec[0]\n    return rec.time",
            "def get_tot_time(func):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    rec = analyzer_tot.select(func, aggregate=np.sum)\n    if not rec:\n        return 'N/A'\n    rec = rec[0]\n    return rec.time",
            "def get_tot_time(func):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    rec = analyzer_tot.select(func, aggregate=np.sum)\n    if not rec:\n        return 'N/A'\n    rec = rec[0]\n    return rec.time"
        ]
    },
    {
        "func_name": "fmt",
        "original": "def fmt(a, b):\n    a = a[0]\n    b = b[0]\n    return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)",
        "mutated": [
            "def fmt(a, b):\n    if False:\n        i = 10\n    a = a[0]\n    b = b[0]\n    return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)",
            "def fmt(a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    a = a[0]\n    b = b[0]\n    return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)",
            "def fmt(a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    a = a[0]\n    b = b[0]\n    return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)",
            "def fmt(a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    a = a[0]\n    b = b[0]\n    return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)",
            "def fmt(a, b):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    a = a[0]\n    b = b[0]\n    return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)"
        ]
    },
    {
        "func_name": "summary",
        "original": "def summary():\n    device_end_func = TimeFuncHelper.eval_time_func('device', 'end', np.max)\n    device_kern_func = TimeFuncHelper.eval_time_func('device', 'kern', np.max)\n    host_end_func = TimeFuncHelper.eval_time_func('host', 'end', np.max)\n\n    def get_tot_time(func):\n        rec = analyzer_tot.select(func, aggregate=np.sum)\n        if not rec:\n            return 'N/A'\n        rec = rec[0]\n        return rec.time\n    tab = []\n    tot_dev_time = get_tot_time(device_end_func)\n    tot_host_time = get_tot_time(host_end_func)\n    tab.append(('total device time', tot_dev_time))\n    if 0 == tot_dev_time:\n        msg = 'please call mgb::CompNode::enable_opencl_profile(true) before profile at c/c++ code' if is_profile_from_ocl else 'please raise a issue for Engine'\n        assert 0 != tot_dev_time, 'total device time should not be 0, {}'.format(msg)\n    tab.append(('total host time', tot_host_time))\n    if args.copy_time:\n\n        def fmt(a, b):\n            a = a[0]\n            b = b[0]\n            return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)\n        tab.append(('copy time', fmt(analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n        tab.append(('copy wait time', fmt(analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n    if args.confluence:\n        tab_str = _tabulate_confluence(tab, headers=['name', 'value'])\n    else:\n        tab_str = tabulate(tab)\n    return (tab_str, tot_dev_time, tot_host_time)",
        "mutated": [
            "def summary():\n    if False:\n        i = 10\n    device_end_func = TimeFuncHelper.eval_time_func('device', 'end', np.max)\n    device_kern_func = TimeFuncHelper.eval_time_func('device', 'kern', np.max)\n    host_end_func = TimeFuncHelper.eval_time_func('host', 'end', np.max)\n\n    def get_tot_time(func):\n        rec = analyzer_tot.select(func, aggregate=np.sum)\n        if not rec:\n            return 'N/A'\n        rec = rec[0]\n        return rec.time\n    tab = []\n    tot_dev_time = get_tot_time(device_end_func)\n    tot_host_time = get_tot_time(host_end_func)\n    tab.append(('total device time', tot_dev_time))\n    if 0 == tot_dev_time:\n        msg = 'please call mgb::CompNode::enable_opencl_profile(true) before profile at c/c++ code' if is_profile_from_ocl else 'please raise a issue for Engine'\n        assert 0 != tot_dev_time, 'total device time should not be 0, {}'.format(msg)\n    tab.append(('total host time', tot_host_time))\n    if args.copy_time:\n\n        def fmt(a, b):\n            a = a[0]\n            b = b[0]\n            return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)\n        tab.append(('copy time', fmt(analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n        tab.append(('copy wait time', fmt(analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n    if args.confluence:\n        tab_str = _tabulate_confluence(tab, headers=['name', 'value'])\n    else:\n        tab_str = tabulate(tab)\n    return (tab_str, tot_dev_time, tot_host_time)",
            "def summary():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    device_end_func = TimeFuncHelper.eval_time_func('device', 'end', np.max)\n    device_kern_func = TimeFuncHelper.eval_time_func('device', 'kern', np.max)\n    host_end_func = TimeFuncHelper.eval_time_func('host', 'end', np.max)\n\n    def get_tot_time(func):\n        rec = analyzer_tot.select(func, aggregate=np.sum)\n        if not rec:\n            return 'N/A'\n        rec = rec[0]\n        return rec.time\n    tab = []\n    tot_dev_time = get_tot_time(device_end_func)\n    tot_host_time = get_tot_time(host_end_func)\n    tab.append(('total device time', tot_dev_time))\n    if 0 == tot_dev_time:\n        msg = 'please call mgb::CompNode::enable_opencl_profile(true) before profile at c/c++ code' if is_profile_from_ocl else 'please raise a issue for Engine'\n        assert 0 != tot_dev_time, 'total device time should not be 0, {}'.format(msg)\n    tab.append(('total host time', tot_host_time))\n    if args.copy_time:\n\n        def fmt(a, b):\n            a = a[0]\n            b = b[0]\n            return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)\n        tab.append(('copy time', fmt(analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n        tab.append(('copy wait time', fmt(analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n    if args.confluence:\n        tab_str = _tabulate_confluence(tab, headers=['name', 'value'])\n    else:\n        tab_str = tabulate(tab)\n    return (tab_str, tot_dev_time, tot_host_time)",
            "def summary():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    device_end_func = TimeFuncHelper.eval_time_func('device', 'end', np.max)\n    device_kern_func = TimeFuncHelper.eval_time_func('device', 'kern', np.max)\n    host_end_func = TimeFuncHelper.eval_time_func('host', 'end', np.max)\n\n    def get_tot_time(func):\n        rec = analyzer_tot.select(func, aggregate=np.sum)\n        if not rec:\n            return 'N/A'\n        rec = rec[0]\n        return rec.time\n    tab = []\n    tot_dev_time = get_tot_time(device_end_func)\n    tot_host_time = get_tot_time(host_end_func)\n    tab.append(('total device time', tot_dev_time))\n    if 0 == tot_dev_time:\n        msg = 'please call mgb::CompNode::enable_opencl_profile(true) before profile at c/c++ code' if is_profile_from_ocl else 'please raise a issue for Engine'\n        assert 0 != tot_dev_time, 'total device time should not be 0, {}'.format(msg)\n    tab.append(('total host time', tot_host_time))\n    if args.copy_time:\n\n        def fmt(a, b):\n            a = a[0]\n            b = b[0]\n            return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)\n        tab.append(('copy time', fmt(analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n        tab.append(('copy wait time', fmt(analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n    if args.confluence:\n        tab_str = _tabulate_confluence(tab, headers=['name', 'value'])\n    else:\n        tab_str = tabulate(tab)\n    return (tab_str, tot_dev_time, tot_host_time)",
            "def summary():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    device_end_func = TimeFuncHelper.eval_time_func('device', 'end', np.max)\n    device_kern_func = TimeFuncHelper.eval_time_func('device', 'kern', np.max)\n    host_end_func = TimeFuncHelper.eval_time_func('host', 'end', np.max)\n\n    def get_tot_time(func):\n        rec = analyzer_tot.select(func, aggregate=np.sum)\n        if not rec:\n            return 'N/A'\n        rec = rec[0]\n        return rec.time\n    tab = []\n    tot_dev_time = get_tot_time(device_end_func)\n    tot_host_time = get_tot_time(host_end_func)\n    tab.append(('total device time', tot_dev_time))\n    if 0 == tot_dev_time:\n        msg = 'please call mgb::CompNode::enable_opencl_profile(true) before profile at c/c++ code' if is_profile_from_ocl else 'please raise a issue for Engine'\n        assert 0 != tot_dev_time, 'total device time should not be 0, {}'.format(msg)\n    tab.append(('total host time', tot_host_time))\n    if args.copy_time:\n\n        def fmt(a, b):\n            a = a[0]\n            b = b[0]\n            return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)\n        tab.append(('copy time', fmt(analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n        tab.append(('copy wait time', fmt(analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n    if args.confluence:\n        tab_str = _tabulate_confluence(tab, headers=['name', 'value'])\n    else:\n        tab_str = tabulate(tab)\n    return (tab_str, tot_dev_time, tot_host_time)",
            "def summary():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    device_end_func = TimeFuncHelper.eval_time_func('device', 'end', np.max)\n    device_kern_func = TimeFuncHelper.eval_time_func('device', 'kern', np.max)\n    host_end_func = TimeFuncHelper.eval_time_func('host', 'end', np.max)\n\n    def get_tot_time(func):\n        rec = analyzer_tot.select(func, aggregate=np.sum)\n        if not rec:\n            return 'N/A'\n        rec = rec[0]\n        return rec.time\n    tab = []\n    tot_dev_time = get_tot_time(device_end_func)\n    tot_host_time = get_tot_time(host_end_func)\n    tab.append(('total device time', tot_dev_time))\n    if 0 == tot_dev_time:\n        msg = 'please call mgb::CompNode::enable_opencl_profile(true) before profile at c/c++ code' if is_profile_from_ocl else 'please raise a issue for Engine'\n        assert 0 != tot_dev_time, 'total device time should not be 0, {}'.format(msg)\n    tab.append(('total host time', tot_host_time))\n    if args.copy_time:\n\n        def fmt(a, b):\n            a = a[0]\n            b = b[0]\n            return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)\n        tab.append(('copy time', fmt(analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n        tab.append(('copy wait time', fmt(analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n    if args.confluence:\n        tab_str = _tabulate_confluence(tab, headers=['name', 'value'])\n    else:\n        tab_str = tabulate(tab)\n    return (tab_str, tot_dev_time, tot_host_time)"
        ]
    },
    {
        "func_name": "func",
        "original": "def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n    t = f0(opr)\n    if t is not None and (t < args.min_time or t > args.max_time):\n        return None\n    return t",
        "mutated": [
            "def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n    if False:\n        i = 10\n    t = f0(opr)\n    if t is not None and (t < args.min_time or t > args.max_time):\n        return None\n    return t",
            "def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    t = f0(opr)\n    if t is not None and (t < args.min_time or t > args.max_time):\n        return None\n    return t",
            "def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    t = f0(opr)\n    if t is not None and (t < args.min_time or t > args.max_time):\n        return None\n    return t",
            "def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    t = f0(opr)\n    if t is not None and (t < args.min_time or t > args.max_time):\n        return None\n    return t",
            "def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    t = f0(opr)\n    if t is not None and (t < args.min_time or t > args.max_time):\n        return None\n    return t"
        ]
    },
    {
        "func_name": "format_shapes",
        "original": "def format_shapes(shapes, layouts=None, sep='\\n'):\n    if isinstance(shapes, NonExistNum) or shapes is None:\n        return repr(shapes)\n    if layouts is None:\n        layouts = [None] * len(shapes)\n    comp = []\n    for (i, j) in zip(shapes, layouts):\n        i = '{' + ','.join(map(str, i)) + '}'\n        if j:\n            i += '\\n -[' + ','.join(map(str, j)) + ']'\n        comp.append(i)\n    return sep.join(comp)",
        "mutated": [
            "def format_shapes(shapes, layouts=None, sep='\\n'):\n    if False:\n        i = 10\n    if isinstance(shapes, NonExistNum) or shapes is None:\n        return repr(shapes)\n    if layouts is None:\n        layouts = [None] * len(shapes)\n    comp = []\n    for (i, j) in zip(shapes, layouts):\n        i = '{' + ','.join(map(str, i)) + '}'\n        if j:\n            i += '\\n -[' + ','.join(map(str, j)) + ']'\n        comp.append(i)\n    return sep.join(comp)",
            "def format_shapes(shapes, layouts=None, sep='\\n'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if isinstance(shapes, NonExistNum) or shapes is None:\n        return repr(shapes)\n    if layouts is None:\n        layouts = [None] * len(shapes)\n    comp = []\n    for (i, j) in zip(shapes, layouts):\n        i = '{' + ','.join(map(str, i)) + '}'\n        if j:\n            i += '\\n -[' + ','.join(map(str, j)) + ']'\n        comp.append(i)\n    return sep.join(comp)",
            "def format_shapes(shapes, layouts=None, sep='\\n'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if isinstance(shapes, NonExistNum) or shapes is None:\n        return repr(shapes)\n    if layouts is None:\n        layouts = [None] * len(shapes)\n    comp = []\n    for (i, j) in zip(shapes, layouts):\n        i = '{' + ','.join(map(str, i)) + '}'\n        if j:\n            i += '\\n -[' + ','.join(map(str, j)) + ']'\n        comp.append(i)\n    return sep.join(comp)",
            "def format_shapes(shapes, layouts=None, sep='\\n'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if isinstance(shapes, NonExistNum) or shapes is None:\n        return repr(shapes)\n    if layouts is None:\n        layouts = [None] * len(shapes)\n    comp = []\n    for (i, j) in zip(shapes, layouts):\n        i = '{' + ','.join(map(str, i)) + '}'\n        if j:\n            i += '\\n -[' + ','.join(map(str, j)) + ']'\n        comp.append(i)\n    return sep.join(comp)",
            "def format_shapes(shapes, layouts=None, sep='\\n'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if isinstance(shapes, NonExistNum) or shapes is None:\n        return repr(shapes)\n    if layouts is None:\n        layouts = [None] * len(shapes)\n    comp = []\n    for (i, j) in zip(shapes, layouts):\n        i = '{' + ','.join(map(str, i)) + '}'\n        if j:\n            i += '\\n -[' + ','.join(map(str, j)) + ']'\n        comp.append(i)\n    return sep.join(comp)"
        ]
    },
    {
        "func_name": "fix_num_and_find_unit",
        "original": "def fix_num_and_find_unit(x, base):\n    if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n        return (x, '')\n    unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n    while x >= base:\n        x /= base\n        next(unit)\n    return (x, next(unit))",
        "mutated": [
            "def fix_num_and_find_unit(x, base):\n    if False:\n        i = 10\n    if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n        return (x, '')\n    unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n    while x >= base:\n        x /= base\n        next(unit)\n    return (x, next(unit))",
            "def fix_num_and_find_unit(x, base):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n        return (x, '')\n    unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n    while x >= base:\n        x /= base\n        next(unit)\n    return (x, next(unit))",
            "def fix_num_and_find_unit(x, base):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n        return (x, '')\n    unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n    while x >= base:\n        x /= base\n        next(unit)\n    return (x, next(unit))",
            "def fix_num_and_find_unit(x, base):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n        return (x, '')\n    unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n    while x >= base:\n        x /= base\n        next(unit)\n    return (x, next(unit))",
            "def fix_num_and_find_unit(x, base):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n        return (x, '')\n    unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n    while x >= base:\n        x /= base\n        next(unit)\n    return (x, next(unit))"
        ]
    },
    {
        "func_name": "get_number_with_unit",
        "original": "def get_number_with_unit(num, unit, base, sep='\\n'):\n    (num, unit_prefix) = fix_num_and_find_unit(num, base)\n    if isinstance(unit, list):\n        unit = unit[int(unit_prefix != '')]\n    return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)",
        "mutated": [
            "def get_number_with_unit(num, unit, base, sep='\\n'):\n    if False:\n        i = 10\n    (num, unit_prefix) = fix_num_and_find_unit(num, base)\n    if isinstance(unit, list):\n        unit = unit[int(unit_prefix != '')]\n    return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)",
            "def get_number_with_unit(num, unit, base, sep='\\n'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (num, unit_prefix) = fix_num_and_find_unit(num, base)\n    if isinstance(unit, list):\n        unit = unit[int(unit_prefix != '')]\n    return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)",
            "def get_number_with_unit(num, unit, base, sep='\\n'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (num, unit_prefix) = fix_num_and_find_unit(num, base)\n    if isinstance(unit, list):\n        unit = unit[int(unit_prefix != '')]\n    return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)",
            "def get_number_with_unit(num, unit, base, sep='\\n'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (num, unit_prefix) = fix_num_and_find_unit(num, base)\n    if isinstance(unit, list):\n        unit = unit[int(unit_prefix != '')]\n    return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)",
            "def get_number_with_unit(num, unit, base, sep='\\n'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (num, unit_prefix) = fix_num_and_find_unit(num, base)\n    if isinstance(unit, list):\n        unit = unit[int(unit_prefix != '')]\n    return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)"
        ]
    },
    {
        "func_name": "prof_details",
        "original": "def prof_details(prof_type, tot_time):\n    tab = []\n\n    def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n        t = f0(opr)\n        if t is not None and (t < args.min_time or t > args.max_time):\n            return None\n        return t\n    records = analyzer.select(func, aggregate=args.aggregate, aggregate_by=args.aggregate_by, top_k=args.top, sort_by=args.order_by)\n    if args.dump_only_opr:\n        ret = []\n        for i in records:\n            ret.append(' '.join(i.info.values()))\n        return '\\n'.join(ret)\n\n    def format_shapes(shapes, layouts=None, sep='\\n'):\n        if isinstance(shapes, NonExistNum) or shapes is None:\n            return repr(shapes)\n        if layouts is None:\n            layouts = [None] * len(shapes)\n        comp = []\n        for (i, j) in zip(shapes, layouts):\n            i = '{' + ','.join(map(str, i)) + '}'\n            if j:\n                i += '\\n -[' + ','.join(map(str, j)) + ']'\n            comp.append(i)\n        return sep.join(comp)\n\n    def fix_num_and_find_unit(x, base):\n        if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n            return (x, '')\n        unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n        while x >= base:\n            x /= base\n            next(unit)\n        return (x, next(unit))\n\n    def get_number_with_unit(num, unit, base, sep='\\n'):\n        (num, unit_prefix) = fix_num_and_find_unit(num, base)\n        if isinstance(unit, list):\n            unit = unit[int(unit_prefix != '')]\n        return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)\n    if args.confluence:\n        rows = []\n        cum_time = 0\n        max_time = max([r.time for r in records])\n        max_bandwidth = max([r.bandwidth for r in records])\n        max_flops = max([r.flops for r in records if not isinstance(r.flops, NonExistNum)])\n        bar_length = 15\n        for (idx, record) in enumerate(records):\n            cum_time += record.time\n            opr_info = [('opr ' + k, v) for (k, v) in record.info.items()]\n            row = collections.OrderedDict([('#', idx), ('time', '{:.3}'.format(record.time)), ('ratio', '{:.1f}%'.format(record.time / tot_time * 100)), ('time bar', '#' * int(record.time / max_time * bar_length)), ('cum-time', cum_time), ('cum-time ratio', cum_time / tot_time)] + opr_info + [('computation (MFLO)', '{:.1f}'.format(record.computation / 1000 ** 2)), ('MFLOPS', '{:.1f}'.format(record.flops / 1000 ** 2)), ('MFLOPS-bar', '' if isinstance(record.flops, NonExistNum) else '#' * int(record.flops / max_flops * bar_length)), ('memory (MB)', '{:.1f}'.format(record.memory / 1024 ** 2)), ('bandwidth (MiB/s)', '{:.1f}'.format(record.bandwidth / 1024 ** 2)), ('bandwidth bar', '#' * int(record.bandwidth / max_bandwidth * bar_length)), ('in_shapes', format_shapes(record.in_shapes, record.in_layouts, sep=', ')), ('out_shapes', format_shapes(record.out_shapes, sep=', '))])\n            rows.append(row)\n        headers = list(rows[0].keys())\n        tab = [[row[i] for i in headers] for row in rows]\n        return _tabulate_confluence(tab, headers=headers)\n    else:\n        cum_time = 0\n        for (idx, record) in enumerate(records):\n            cum_time += record.time\n            tab.append(('#{}\\n{:.3}\\n{:.1f}%'.format(idx, record.time, record.time / tot_time * 100), '{:.3}\\n{:.1f}%'.format(cum_time, cum_time / tot_time * 100), '\\n'.join(('\\n-  '.join(textwrap.wrap(str(i), width=30)) for i in record.info.values())), get_number_with_unit(record.computation, 'FLO', 1000), get_number_with_unit(record.flops, 'FLOPS', 1000), get_number_with_unit(record.memory, ['byte', 'iB'], 1024), get_number_with_unit(record.bandwidth, ['byte/s', 'iB/s'], 1024), format_shapes(record.in_shapes, record.in_layouts), format_shapes(record.out_shapes)))\n        return _tabulate_ml(tab, headers=['{} self time'.format(prof_type), 'cumulative', 'operator info', 'computation', 'FLOPS', 'memory', 'bandwidth', 'in_shapes', 'out_shapes'], tablefmt='fancy_grid')",
        "mutated": [
            "def prof_details(prof_type, tot_time):\n    if False:\n        i = 10\n    tab = []\n\n    def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n        t = f0(opr)\n        if t is not None and (t < args.min_time or t > args.max_time):\n            return None\n        return t\n    records = analyzer.select(func, aggregate=args.aggregate, aggregate_by=args.aggregate_by, top_k=args.top, sort_by=args.order_by)\n    if args.dump_only_opr:\n        ret = []\n        for i in records:\n            ret.append(' '.join(i.info.values()))\n        return '\\n'.join(ret)\n\n    def format_shapes(shapes, layouts=None, sep='\\n'):\n        if isinstance(shapes, NonExistNum) or shapes is None:\n            return repr(shapes)\n        if layouts is None:\n            layouts = [None] * len(shapes)\n        comp = []\n        for (i, j) in zip(shapes, layouts):\n            i = '{' + ','.join(map(str, i)) + '}'\n            if j:\n                i += '\\n -[' + ','.join(map(str, j)) + ']'\n            comp.append(i)\n        return sep.join(comp)\n\n    def fix_num_and_find_unit(x, base):\n        if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n            return (x, '')\n        unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n        while x >= base:\n            x /= base\n            next(unit)\n        return (x, next(unit))\n\n    def get_number_with_unit(num, unit, base, sep='\\n'):\n        (num, unit_prefix) = fix_num_and_find_unit(num, base)\n        if isinstance(unit, list):\n            unit = unit[int(unit_prefix != '')]\n        return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)\n    if args.confluence:\n        rows = []\n        cum_time = 0\n        max_time = max([r.time for r in records])\n        max_bandwidth = max([r.bandwidth for r in records])\n        max_flops = max([r.flops for r in records if not isinstance(r.flops, NonExistNum)])\n        bar_length = 15\n        for (idx, record) in enumerate(records):\n            cum_time += record.time\n            opr_info = [('opr ' + k, v) for (k, v) in record.info.items()]\n            row = collections.OrderedDict([('#', idx), ('time', '{:.3}'.format(record.time)), ('ratio', '{:.1f}%'.format(record.time / tot_time * 100)), ('time bar', '#' * int(record.time / max_time * bar_length)), ('cum-time', cum_time), ('cum-time ratio', cum_time / tot_time)] + opr_info + [('computation (MFLO)', '{:.1f}'.format(record.computation / 1000 ** 2)), ('MFLOPS', '{:.1f}'.format(record.flops / 1000 ** 2)), ('MFLOPS-bar', '' if isinstance(record.flops, NonExistNum) else '#' * int(record.flops / max_flops * bar_length)), ('memory (MB)', '{:.1f}'.format(record.memory / 1024 ** 2)), ('bandwidth (MiB/s)', '{:.1f}'.format(record.bandwidth / 1024 ** 2)), ('bandwidth bar', '#' * int(record.bandwidth / max_bandwidth * bar_length)), ('in_shapes', format_shapes(record.in_shapes, record.in_layouts, sep=', ')), ('out_shapes', format_shapes(record.out_shapes, sep=', '))])\n            rows.append(row)\n        headers = list(rows[0].keys())\n        tab = [[row[i] for i in headers] for row in rows]\n        return _tabulate_confluence(tab, headers=headers)\n    else:\n        cum_time = 0\n        for (idx, record) in enumerate(records):\n            cum_time += record.time\n            tab.append(('#{}\\n{:.3}\\n{:.1f}%'.format(idx, record.time, record.time / tot_time * 100), '{:.3}\\n{:.1f}%'.format(cum_time, cum_time / tot_time * 100), '\\n'.join(('\\n-  '.join(textwrap.wrap(str(i), width=30)) for i in record.info.values())), get_number_with_unit(record.computation, 'FLO', 1000), get_number_with_unit(record.flops, 'FLOPS', 1000), get_number_with_unit(record.memory, ['byte', 'iB'], 1024), get_number_with_unit(record.bandwidth, ['byte/s', 'iB/s'], 1024), format_shapes(record.in_shapes, record.in_layouts), format_shapes(record.out_shapes)))\n        return _tabulate_ml(tab, headers=['{} self time'.format(prof_type), 'cumulative', 'operator info', 'computation', 'FLOPS', 'memory', 'bandwidth', 'in_shapes', 'out_shapes'], tablefmt='fancy_grid')",
            "def prof_details(prof_type, tot_time):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    tab = []\n\n    def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n        t = f0(opr)\n        if t is not None and (t < args.min_time or t > args.max_time):\n            return None\n        return t\n    records = analyzer.select(func, aggregate=args.aggregate, aggregate_by=args.aggregate_by, top_k=args.top, sort_by=args.order_by)\n    if args.dump_only_opr:\n        ret = []\n        for i in records:\n            ret.append(' '.join(i.info.values()))\n        return '\\n'.join(ret)\n\n    def format_shapes(shapes, layouts=None, sep='\\n'):\n        if isinstance(shapes, NonExistNum) or shapes is None:\n            return repr(shapes)\n        if layouts is None:\n            layouts = [None] * len(shapes)\n        comp = []\n        for (i, j) in zip(shapes, layouts):\n            i = '{' + ','.join(map(str, i)) + '}'\n            if j:\n                i += '\\n -[' + ','.join(map(str, j)) + ']'\n            comp.append(i)\n        return sep.join(comp)\n\n    def fix_num_and_find_unit(x, base):\n        if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n            return (x, '')\n        unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n        while x >= base:\n            x /= base\n            next(unit)\n        return (x, next(unit))\n\n    def get_number_with_unit(num, unit, base, sep='\\n'):\n        (num, unit_prefix) = fix_num_and_find_unit(num, base)\n        if isinstance(unit, list):\n            unit = unit[int(unit_prefix != '')]\n        return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)\n    if args.confluence:\n        rows = []\n        cum_time = 0\n        max_time = max([r.time for r in records])\n        max_bandwidth = max([r.bandwidth for r in records])\n        max_flops = max([r.flops for r in records if not isinstance(r.flops, NonExistNum)])\n        bar_length = 15\n        for (idx, record) in enumerate(records):\n            cum_time += record.time\n            opr_info = [('opr ' + k, v) for (k, v) in record.info.items()]\n            row = collections.OrderedDict([('#', idx), ('time', '{:.3}'.format(record.time)), ('ratio', '{:.1f}%'.format(record.time / tot_time * 100)), ('time bar', '#' * int(record.time / max_time * bar_length)), ('cum-time', cum_time), ('cum-time ratio', cum_time / tot_time)] + opr_info + [('computation (MFLO)', '{:.1f}'.format(record.computation / 1000 ** 2)), ('MFLOPS', '{:.1f}'.format(record.flops / 1000 ** 2)), ('MFLOPS-bar', '' if isinstance(record.flops, NonExistNum) else '#' * int(record.flops / max_flops * bar_length)), ('memory (MB)', '{:.1f}'.format(record.memory / 1024 ** 2)), ('bandwidth (MiB/s)', '{:.1f}'.format(record.bandwidth / 1024 ** 2)), ('bandwidth bar', '#' * int(record.bandwidth / max_bandwidth * bar_length)), ('in_shapes', format_shapes(record.in_shapes, record.in_layouts, sep=', ')), ('out_shapes', format_shapes(record.out_shapes, sep=', '))])\n            rows.append(row)\n        headers = list(rows[0].keys())\n        tab = [[row[i] for i in headers] for row in rows]\n        return _tabulate_confluence(tab, headers=headers)\n    else:\n        cum_time = 0\n        for (idx, record) in enumerate(records):\n            cum_time += record.time\n            tab.append(('#{}\\n{:.3}\\n{:.1f}%'.format(idx, record.time, record.time / tot_time * 100), '{:.3}\\n{:.1f}%'.format(cum_time, cum_time / tot_time * 100), '\\n'.join(('\\n-  '.join(textwrap.wrap(str(i), width=30)) for i in record.info.values())), get_number_with_unit(record.computation, 'FLO', 1000), get_number_with_unit(record.flops, 'FLOPS', 1000), get_number_with_unit(record.memory, ['byte', 'iB'], 1024), get_number_with_unit(record.bandwidth, ['byte/s', 'iB/s'], 1024), format_shapes(record.in_shapes, record.in_layouts), format_shapes(record.out_shapes)))\n        return _tabulate_ml(tab, headers=['{} self time'.format(prof_type), 'cumulative', 'operator info', 'computation', 'FLOPS', 'memory', 'bandwidth', 'in_shapes', 'out_shapes'], tablefmt='fancy_grid')",
            "def prof_details(prof_type, tot_time):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    tab = []\n\n    def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n        t = f0(opr)\n        if t is not None and (t < args.min_time or t > args.max_time):\n            return None\n        return t\n    records = analyzer.select(func, aggregate=args.aggregate, aggregate_by=args.aggregate_by, top_k=args.top, sort_by=args.order_by)\n    if args.dump_only_opr:\n        ret = []\n        for i in records:\n            ret.append(' '.join(i.info.values()))\n        return '\\n'.join(ret)\n\n    def format_shapes(shapes, layouts=None, sep='\\n'):\n        if isinstance(shapes, NonExistNum) or shapes is None:\n            return repr(shapes)\n        if layouts is None:\n            layouts = [None] * len(shapes)\n        comp = []\n        for (i, j) in zip(shapes, layouts):\n            i = '{' + ','.join(map(str, i)) + '}'\n            if j:\n                i += '\\n -[' + ','.join(map(str, j)) + ']'\n            comp.append(i)\n        return sep.join(comp)\n\n    def fix_num_and_find_unit(x, base):\n        if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n            return (x, '')\n        unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n        while x >= base:\n            x /= base\n            next(unit)\n        return (x, next(unit))\n\n    def get_number_with_unit(num, unit, base, sep='\\n'):\n        (num, unit_prefix) = fix_num_and_find_unit(num, base)\n        if isinstance(unit, list):\n            unit = unit[int(unit_prefix != '')]\n        return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)\n    if args.confluence:\n        rows = []\n        cum_time = 0\n        max_time = max([r.time for r in records])\n        max_bandwidth = max([r.bandwidth for r in records])\n        max_flops = max([r.flops for r in records if not isinstance(r.flops, NonExistNum)])\n        bar_length = 15\n        for (idx, record) in enumerate(records):\n            cum_time += record.time\n            opr_info = [('opr ' + k, v) for (k, v) in record.info.items()]\n            row = collections.OrderedDict([('#', idx), ('time', '{:.3}'.format(record.time)), ('ratio', '{:.1f}%'.format(record.time / tot_time * 100)), ('time bar', '#' * int(record.time / max_time * bar_length)), ('cum-time', cum_time), ('cum-time ratio', cum_time / tot_time)] + opr_info + [('computation (MFLO)', '{:.1f}'.format(record.computation / 1000 ** 2)), ('MFLOPS', '{:.1f}'.format(record.flops / 1000 ** 2)), ('MFLOPS-bar', '' if isinstance(record.flops, NonExistNum) else '#' * int(record.flops / max_flops * bar_length)), ('memory (MB)', '{:.1f}'.format(record.memory / 1024 ** 2)), ('bandwidth (MiB/s)', '{:.1f}'.format(record.bandwidth / 1024 ** 2)), ('bandwidth bar', '#' * int(record.bandwidth / max_bandwidth * bar_length)), ('in_shapes', format_shapes(record.in_shapes, record.in_layouts, sep=', ')), ('out_shapes', format_shapes(record.out_shapes, sep=', '))])\n            rows.append(row)\n        headers = list(rows[0].keys())\n        tab = [[row[i] for i in headers] for row in rows]\n        return _tabulate_confluence(tab, headers=headers)\n    else:\n        cum_time = 0\n        for (idx, record) in enumerate(records):\n            cum_time += record.time\n            tab.append(('#{}\\n{:.3}\\n{:.1f}%'.format(idx, record.time, record.time / tot_time * 100), '{:.3}\\n{:.1f}%'.format(cum_time, cum_time / tot_time * 100), '\\n'.join(('\\n-  '.join(textwrap.wrap(str(i), width=30)) for i in record.info.values())), get_number_with_unit(record.computation, 'FLO', 1000), get_number_with_unit(record.flops, 'FLOPS', 1000), get_number_with_unit(record.memory, ['byte', 'iB'], 1024), get_number_with_unit(record.bandwidth, ['byte/s', 'iB/s'], 1024), format_shapes(record.in_shapes, record.in_layouts), format_shapes(record.out_shapes)))\n        return _tabulate_ml(tab, headers=['{} self time'.format(prof_type), 'cumulative', 'operator info', 'computation', 'FLOPS', 'memory', 'bandwidth', 'in_shapes', 'out_shapes'], tablefmt='fancy_grid')",
            "def prof_details(prof_type, tot_time):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    tab = []\n\n    def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n        t = f0(opr)\n        if t is not None and (t < args.min_time or t > args.max_time):\n            return None\n        return t\n    records = analyzer.select(func, aggregate=args.aggregate, aggregate_by=args.aggregate_by, top_k=args.top, sort_by=args.order_by)\n    if args.dump_only_opr:\n        ret = []\n        for i in records:\n            ret.append(' '.join(i.info.values()))\n        return '\\n'.join(ret)\n\n    def format_shapes(shapes, layouts=None, sep='\\n'):\n        if isinstance(shapes, NonExistNum) or shapes is None:\n            return repr(shapes)\n        if layouts is None:\n            layouts = [None] * len(shapes)\n        comp = []\n        for (i, j) in zip(shapes, layouts):\n            i = '{' + ','.join(map(str, i)) + '}'\n            if j:\n                i += '\\n -[' + ','.join(map(str, j)) + ']'\n            comp.append(i)\n        return sep.join(comp)\n\n    def fix_num_and_find_unit(x, base):\n        if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n            return (x, '')\n        unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n        while x >= base:\n            x /= base\n            next(unit)\n        return (x, next(unit))\n\n    def get_number_with_unit(num, unit, base, sep='\\n'):\n        (num, unit_prefix) = fix_num_and_find_unit(num, base)\n        if isinstance(unit, list):\n            unit = unit[int(unit_prefix != '')]\n        return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)\n    if args.confluence:\n        rows = []\n        cum_time = 0\n        max_time = max([r.time for r in records])\n        max_bandwidth = max([r.bandwidth for r in records])\n        max_flops = max([r.flops for r in records if not isinstance(r.flops, NonExistNum)])\n        bar_length = 15\n        for (idx, record) in enumerate(records):\n            cum_time += record.time\n            opr_info = [('opr ' + k, v) for (k, v) in record.info.items()]\n            row = collections.OrderedDict([('#', idx), ('time', '{:.3}'.format(record.time)), ('ratio', '{:.1f}%'.format(record.time / tot_time * 100)), ('time bar', '#' * int(record.time / max_time * bar_length)), ('cum-time', cum_time), ('cum-time ratio', cum_time / tot_time)] + opr_info + [('computation (MFLO)', '{:.1f}'.format(record.computation / 1000 ** 2)), ('MFLOPS', '{:.1f}'.format(record.flops / 1000 ** 2)), ('MFLOPS-bar', '' if isinstance(record.flops, NonExistNum) else '#' * int(record.flops / max_flops * bar_length)), ('memory (MB)', '{:.1f}'.format(record.memory / 1024 ** 2)), ('bandwidth (MiB/s)', '{:.1f}'.format(record.bandwidth / 1024 ** 2)), ('bandwidth bar', '#' * int(record.bandwidth / max_bandwidth * bar_length)), ('in_shapes', format_shapes(record.in_shapes, record.in_layouts, sep=', ')), ('out_shapes', format_shapes(record.out_shapes, sep=', '))])\n            rows.append(row)\n        headers = list(rows[0].keys())\n        tab = [[row[i] for i in headers] for row in rows]\n        return _tabulate_confluence(tab, headers=headers)\n    else:\n        cum_time = 0\n        for (idx, record) in enumerate(records):\n            cum_time += record.time\n            tab.append(('#{}\\n{:.3}\\n{:.1f}%'.format(idx, record.time, record.time / tot_time * 100), '{:.3}\\n{:.1f}%'.format(cum_time, cum_time / tot_time * 100), '\\n'.join(('\\n-  '.join(textwrap.wrap(str(i), width=30)) for i in record.info.values())), get_number_with_unit(record.computation, 'FLO', 1000), get_number_with_unit(record.flops, 'FLOPS', 1000), get_number_with_unit(record.memory, ['byte', 'iB'], 1024), get_number_with_unit(record.bandwidth, ['byte/s', 'iB/s'], 1024), format_shapes(record.in_shapes, record.in_layouts), format_shapes(record.out_shapes)))\n        return _tabulate_ml(tab, headers=['{} self time'.format(prof_type), 'cumulative', 'operator info', 'computation', 'FLOPS', 'memory', 'bandwidth', 'in_shapes', 'out_shapes'], tablefmt='fancy_grid')",
            "def prof_details(prof_type, tot_time):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    tab = []\n\n    def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n        t = f0(opr)\n        if t is not None and (t < args.min_time or t > args.max_time):\n            return None\n        return t\n    records = analyzer.select(func, aggregate=args.aggregate, aggregate_by=args.aggregate_by, top_k=args.top, sort_by=args.order_by)\n    if args.dump_only_opr:\n        ret = []\n        for i in records:\n            ret.append(' '.join(i.info.values()))\n        return '\\n'.join(ret)\n\n    def format_shapes(shapes, layouts=None, sep='\\n'):\n        if isinstance(shapes, NonExistNum) or shapes is None:\n            return repr(shapes)\n        if layouts is None:\n            layouts = [None] * len(shapes)\n        comp = []\n        for (i, j) in zip(shapes, layouts):\n            i = '{' + ','.join(map(str, i)) + '}'\n            if j:\n                i += '\\n -[' + ','.join(map(str, j)) + ']'\n            comp.append(i)\n        return sep.join(comp)\n\n    def fix_num_and_find_unit(x, base):\n        if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n            return (x, '')\n        unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n        while x >= base:\n            x /= base\n            next(unit)\n        return (x, next(unit))\n\n    def get_number_with_unit(num, unit, base, sep='\\n'):\n        (num, unit_prefix) = fix_num_and_find_unit(num, base)\n        if isinstance(unit, list):\n            unit = unit[int(unit_prefix != '')]\n        return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)\n    if args.confluence:\n        rows = []\n        cum_time = 0\n        max_time = max([r.time for r in records])\n        max_bandwidth = max([r.bandwidth for r in records])\n        max_flops = max([r.flops for r in records if not isinstance(r.flops, NonExistNum)])\n        bar_length = 15\n        for (idx, record) in enumerate(records):\n            cum_time += record.time\n            opr_info = [('opr ' + k, v) for (k, v) in record.info.items()]\n            row = collections.OrderedDict([('#', idx), ('time', '{:.3}'.format(record.time)), ('ratio', '{:.1f}%'.format(record.time / tot_time * 100)), ('time bar', '#' * int(record.time / max_time * bar_length)), ('cum-time', cum_time), ('cum-time ratio', cum_time / tot_time)] + opr_info + [('computation (MFLO)', '{:.1f}'.format(record.computation / 1000 ** 2)), ('MFLOPS', '{:.1f}'.format(record.flops / 1000 ** 2)), ('MFLOPS-bar', '' if isinstance(record.flops, NonExistNum) else '#' * int(record.flops / max_flops * bar_length)), ('memory (MB)', '{:.1f}'.format(record.memory / 1024 ** 2)), ('bandwidth (MiB/s)', '{:.1f}'.format(record.bandwidth / 1024 ** 2)), ('bandwidth bar', '#' * int(record.bandwidth / max_bandwidth * bar_length)), ('in_shapes', format_shapes(record.in_shapes, record.in_layouts, sep=', ')), ('out_shapes', format_shapes(record.out_shapes, sep=', '))])\n            rows.append(row)\n        headers = list(rows[0].keys())\n        tab = [[row[i] for i in headers] for row in rows]\n        return _tabulate_confluence(tab, headers=headers)\n    else:\n        cum_time = 0\n        for (idx, record) in enumerate(records):\n            cum_time += record.time\n            tab.append(('#{}\\n{:.3}\\n{:.1f}%'.format(idx, record.time, record.time / tot_time * 100), '{:.3}\\n{:.1f}%'.format(cum_time, cum_time / tot_time * 100), '\\n'.join(('\\n-  '.join(textwrap.wrap(str(i), width=30)) for i in record.info.values())), get_number_with_unit(record.computation, 'FLO', 1000), get_number_with_unit(record.flops, 'FLOPS', 1000), get_number_with_unit(record.memory, ['byte', 'iB'], 1024), get_number_with_unit(record.bandwidth, ['byte/s', 'iB/s'], 1024), format_shapes(record.in_shapes, record.in_layouts), format_shapes(record.out_shapes)))\n        return _tabulate_ml(tab, headers=['{} self time'.format(prof_type), 'cumulative', 'operator info', 'computation', 'FLOPS', 'memory', 'bandwidth', 'in_shapes', 'out_shapes'], tablefmt='fancy_grid')"
        ]
    },
    {
        "func_name": "main",
        "original": "def main(passed_args=None):\n    is_profile_from_ocl = False\n    'Analyses profile info from :mod:`~.utils.profile_analyzer` .\\n    Run this file with ``--help`` to get more usage.\\n    '\n    parser = argparse.ArgumentParser(description='analyze analyzer result', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument('dump')\n    parser.add_argument('-t', '--top', type=int, default=3, help='number of most time-consuming operators to print')\n    parser.add_argument('--type', action='append', help='filter oprs in the top list by type')\n    parser.add_argument('--aggregate-by', default=None, choices=['type'], help='aggragate profiling result by')\n    parser.add_argument('--opr-name', help='filter oprs in the top list by regex of name')\n    parser.add_argument('--input-dtype', type=str, help='filter oprs in the top list by input dtype')\n    parser.add_argument('--top-end-key', default='end', choices=['end', 'kern'], help='how time in top is calculated; end corresponds to total device time, and kern corresponds to only wait time')\n    parser.add_argument('--aggregate', default=None, help='aggregate operations', choices=['max', 'min', 'sum', 'mean'])\n    parser.add_argument('--order-by', default='time', help='sort result according to given column; the param can be <col_name> or +<col_name>, meaning sorting in descending or ascending order respectively')\n    parser.add_argument('--copy-time', action='store_true', help='show copy time related result')\n    parser.add_argument('--min-time', type=float, default=float('-inf'), help='minimal time of a result to be printed')\n    parser.add_argument('--max-time', type=float, default=float('inf'), help='maximal time of a result to be printed')\n    parser.add_argument('--show-host', action='store_true', help='show host profiling info')\n    parser.add_argument('--dump-only-opr', action='store_true', help='only dump operator info as plaintext; useful for diff between two filtered profile results')\n    parser.add_argument('--confluence', '--wiki', action='store_true', help='output confluence-markdown-compatible table')\n    parser.add_argument('--print-only', choices={'summary', 'device', 'host'}, help='print only chosen info')\n    args = parser.parse_args(passed_args)\n    opr_filters = []\n    if args.type:\n        opr_filters.append(lambda o, a, b: o['type'] in args.type)\n    if args.opr_name:\n        opr_filters.append(lambda o, a, b, r=re.compile(args.opr_name): r.match(o['name']))\n    if args.input_dtype:\n        opr_filters.append(lambda o, a, b: any([i['mem_plan']['layout']['dtype'] == args.input_dtype for i in a]))\n    if not opr_filters:\n\n        def opr_filter(o, a, b):\n            return True\n    else:\n\n        def opr_filter(o, a, b):\n            return all((i(o, a, b) for i in opr_filters))\n    with open(args.dump) as fin:\n        dump = json.load(fin)\n        if str(dump).find('opencl') != -1:\n            is_profile_from_ocl = True\n    analyzer = ProfileAnalyzer(dump, opr_filter)\n    analyzer_tot = ProfileAnalyzer(dump, lambda _, __, ___: True)\n\n    def summary():\n        device_end_func = TimeFuncHelper.eval_time_func('device', 'end', np.max)\n        device_kern_func = TimeFuncHelper.eval_time_func('device', 'kern', np.max)\n        host_end_func = TimeFuncHelper.eval_time_func('host', 'end', np.max)\n\n        def get_tot_time(func):\n            rec = analyzer_tot.select(func, aggregate=np.sum)\n            if not rec:\n                return 'N/A'\n            rec = rec[0]\n            return rec.time\n        tab = []\n        tot_dev_time = get_tot_time(device_end_func)\n        tot_host_time = get_tot_time(host_end_func)\n        tab.append(('total device time', tot_dev_time))\n        if 0 == tot_dev_time:\n            msg = 'please call mgb::CompNode::enable_opencl_profile(true) before profile at c/c++ code' if is_profile_from_ocl else 'please raise a issue for Engine'\n            assert 0 != tot_dev_time, 'total device time should not be 0, {}'.format(msg)\n        tab.append(('total host time', tot_host_time))\n        if args.copy_time:\n\n            def fmt(a, b):\n                a = a[0]\n                b = b[0]\n                return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)\n            tab.append(('copy time', fmt(analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n            tab.append(('copy wait time', fmt(analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n        if args.confluence:\n            tab_str = _tabulate_confluence(tab, headers=['name', 'value'])\n        else:\n            tab_str = tabulate(tab)\n        return (tab_str, tot_dev_time, tot_host_time)\n\n    def prof_details(prof_type, tot_time):\n        tab = []\n\n        def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n            t = f0(opr)\n            if t is not None and (t < args.min_time or t > args.max_time):\n                return None\n            return t\n        records = analyzer.select(func, aggregate=args.aggregate, aggregate_by=args.aggregate_by, top_k=args.top, sort_by=args.order_by)\n        if args.dump_only_opr:\n            ret = []\n            for i in records:\n                ret.append(' '.join(i.info.values()))\n            return '\\n'.join(ret)\n\n        def format_shapes(shapes, layouts=None, sep='\\n'):\n            if isinstance(shapes, NonExistNum) or shapes is None:\n                return repr(shapes)\n            if layouts is None:\n                layouts = [None] * len(shapes)\n            comp = []\n            for (i, j) in zip(shapes, layouts):\n                i = '{' + ','.join(map(str, i)) + '}'\n                if j:\n                    i += '\\n -[' + ','.join(map(str, j)) + ']'\n                comp.append(i)\n            return sep.join(comp)\n\n        def fix_num_and_find_unit(x, base):\n            if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n                return (x, '')\n            unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n            while x >= base:\n                x /= base\n                next(unit)\n            return (x, next(unit))\n\n        def get_number_with_unit(num, unit, base, sep='\\n'):\n            (num, unit_prefix) = fix_num_and_find_unit(num, base)\n            if isinstance(unit, list):\n                unit = unit[int(unit_prefix != '')]\n            return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)\n        if args.confluence:\n            rows = []\n            cum_time = 0\n            max_time = max([r.time for r in records])\n            max_bandwidth = max([r.bandwidth for r in records])\n            max_flops = max([r.flops for r in records if not isinstance(r.flops, NonExistNum)])\n            bar_length = 15\n            for (idx, record) in enumerate(records):\n                cum_time += record.time\n                opr_info = [('opr ' + k, v) for (k, v) in record.info.items()]\n                row = collections.OrderedDict([('#', idx), ('time', '{:.3}'.format(record.time)), ('ratio', '{:.1f}%'.format(record.time / tot_time * 100)), ('time bar', '#' * int(record.time / max_time * bar_length)), ('cum-time', cum_time), ('cum-time ratio', cum_time / tot_time)] + opr_info + [('computation (MFLO)', '{:.1f}'.format(record.computation / 1000 ** 2)), ('MFLOPS', '{:.1f}'.format(record.flops / 1000 ** 2)), ('MFLOPS-bar', '' if isinstance(record.flops, NonExistNum) else '#' * int(record.flops / max_flops * bar_length)), ('memory (MB)', '{:.1f}'.format(record.memory / 1024 ** 2)), ('bandwidth (MiB/s)', '{:.1f}'.format(record.bandwidth / 1024 ** 2)), ('bandwidth bar', '#' * int(record.bandwidth / max_bandwidth * bar_length)), ('in_shapes', format_shapes(record.in_shapes, record.in_layouts, sep=', ')), ('out_shapes', format_shapes(record.out_shapes, sep=', '))])\n                rows.append(row)\n            headers = list(rows[0].keys())\n            tab = [[row[i] for i in headers] for row in rows]\n            return _tabulate_confluence(tab, headers=headers)\n        else:\n            cum_time = 0\n            for (idx, record) in enumerate(records):\n                cum_time += record.time\n                tab.append(('#{}\\n{:.3}\\n{:.1f}%'.format(idx, record.time, record.time / tot_time * 100), '{:.3}\\n{:.1f}%'.format(cum_time, cum_time / tot_time * 100), '\\n'.join(('\\n-  '.join(textwrap.wrap(str(i), width=30)) for i in record.info.values())), get_number_with_unit(record.computation, 'FLO', 1000), get_number_with_unit(record.flops, 'FLOPS', 1000), get_number_with_unit(record.memory, ['byte', 'iB'], 1024), get_number_with_unit(record.bandwidth, ['byte/s', 'iB/s'], 1024), format_shapes(record.in_shapes, record.in_layouts), format_shapes(record.out_shapes)))\n            return _tabulate_ml(tab, headers=['{} self time'.format(prof_type), 'cumulative', 'operator info', 'computation', 'FLOPS', 'memory', 'bandwidth', 'in_shapes', 'out_shapes'], tablefmt='fancy_grid')\n    (summary_tab, tot_dev_time, tot_host_time) = summary()\n    if args.print_only:\n        print({'summary': lambda : summary_tab, 'device': lambda : prof_details('device', tot_dev_time), 'host': lambda : prof_details('host', tot_host_time)}[args.print_only]())\n    else:\n        print(summary_tab)\n        print()\n        print(prof_details('device', tot_dev_time))\n        if args.show_host:\n            print()\n            print(prof_details('host', tot_host_time))",
        "mutated": [
            "def main(passed_args=None):\n    if False:\n        i = 10\n    is_profile_from_ocl = False\n    'Analyses profile info from :mod:`~.utils.profile_analyzer` .\\n    Run this file with ``--help`` to get more usage.\\n    '\n    parser = argparse.ArgumentParser(description='analyze analyzer result', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument('dump')\n    parser.add_argument('-t', '--top', type=int, default=3, help='number of most time-consuming operators to print')\n    parser.add_argument('--type', action='append', help='filter oprs in the top list by type')\n    parser.add_argument('--aggregate-by', default=None, choices=['type'], help='aggragate profiling result by')\n    parser.add_argument('--opr-name', help='filter oprs in the top list by regex of name')\n    parser.add_argument('--input-dtype', type=str, help='filter oprs in the top list by input dtype')\n    parser.add_argument('--top-end-key', default='end', choices=['end', 'kern'], help='how time in top is calculated; end corresponds to total device time, and kern corresponds to only wait time')\n    parser.add_argument('--aggregate', default=None, help='aggregate operations', choices=['max', 'min', 'sum', 'mean'])\n    parser.add_argument('--order-by', default='time', help='sort result according to given column; the param can be <col_name> or +<col_name>, meaning sorting in descending or ascending order respectively')\n    parser.add_argument('--copy-time', action='store_true', help='show copy time related result')\n    parser.add_argument('--min-time', type=float, default=float('-inf'), help='minimal time of a result to be printed')\n    parser.add_argument('--max-time', type=float, default=float('inf'), help='maximal time of a result to be printed')\n    parser.add_argument('--show-host', action='store_true', help='show host profiling info')\n    parser.add_argument('--dump-only-opr', action='store_true', help='only dump operator info as plaintext; useful for diff between two filtered profile results')\n    parser.add_argument('--confluence', '--wiki', action='store_true', help='output confluence-markdown-compatible table')\n    parser.add_argument('--print-only', choices={'summary', 'device', 'host'}, help='print only chosen info')\n    args = parser.parse_args(passed_args)\n    opr_filters = []\n    if args.type:\n        opr_filters.append(lambda o, a, b: o['type'] in args.type)\n    if args.opr_name:\n        opr_filters.append(lambda o, a, b, r=re.compile(args.opr_name): r.match(o['name']))\n    if args.input_dtype:\n        opr_filters.append(lambda o, a, b: any([i['mem_plan']['layout']['dtype'] == args.input_dtype for i in a]))\n    if not opr_filters:\n\n        def opr_filter(o, a, b):\n            return True\n    else:\n\n        def opr_filter(o, a, b):\n            return all((i(o, a, b) for i in opr_filters))\n    with open(args.dump) as fin:\n        dump = json.load(fin)\n        if str(dump).find('opencl') != -1:\n            is_profile_from_ocl = True\n    analyzer = ProfileAnalyzer(dump, opr_filter)\n    analyzer_tot = ProfileAnalyzer(dump, lambda _, __, ___: True)\n\n    def summary():\n        device_end_func = TimeFuncHelper.eval_time_func('device', 'end', np.max)\n        device_kern_func = TimeFuncHelper.eval_time_func('device', 'kern', np.max)\n        host_end_func = TimeFuncHelper.eval_time_func('host', 'end', np.max)\n\n        def get_tot_time(func):\n            rec = analyzer_tot.select(func, aggregate=np.sum)\n            if not rec:\n                return 'N/A'\n            rec = rec[0]\n            return rec.time\n        tab = []\n        tot_dev_time = get_tot_time(device_end_func)\n        tot_host_time = get_tot_time(host_end_func)\n        tab.append(('total device time', tot_dev_time))\n        if 0 == tot_dev_time:\n            msg = 'please call mgb::CompNode::enable_opencl_profile(true) before profile at c/c++ code' if is_profile_from_ocl else 'please raise a issue for Engine'\n            assert 0 != tot_dev_time, 'total device time should not be 0, {}'.format(msg)\n        tab.append(('total host time', tot_host_time))\n        if args.copy_time:\n\n            def fmt(a, b):\n                a = a[0]\n                b = b[0]\n                return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)\n            tab.append(('copy time', fmt(analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n            tab.append(('copy wait time', fmt(analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n        if args.confluence:\n            tab_str = _tabulate_confluence(tab, headers=['name', 'value'])\n        else:\n            tab_str = tabulate(tab)\n        return (tab_str, tot_dev_time, tot_host_time)\n\n    def prof_details(prof_type, tot_time):\n        tab = []\n\n        def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n            t = f0(opr)\n            if t is not None and (t < args.min_time or t > args.max_time):\n                return None\n            return t\n        records = analyzer.select(func, aggregate=args.aggregate, aggregate_by=args.aggregate_by, top_k=args.top, sort_by=args.order_by)\n        if args.dump_only_opr:\n            ret = []\n            for i in records:\n                ret.append(' '.join(i.info.values()))\n            return '\\n'.join(ret)\n\n        def format_shapes(shapes, layouts=None, sep='\\n'):\n            if isinstance(shapes, NonExistNum) or shapes is None:\n                return repr(shapes)\n            if layouts is None:\n                layouts = [None] * len(shapes)\n            comp = []\n            for (i, j) in zip(shapes, layouts):\n                i = '{' + ','.join(map(str, i)) + '}'\n                if j:\n                    i += '\\n -[' + ','.join(map(str, j)) + ']'\n                comp.append(i)\n            return sep.join(comp)\n\n        def fix_num_and_find_unit(x, base):\n            if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n                return (x, '')\n            unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n            while x >= base:\n                x /= base\n                next(unit)\n            return (x, next(unit))\n\n        def get_number_with_unit(num, unit, base, sep='\\n'):\n            (num, unit_prefix) = fix_num_and_find_unit(num, base)\n            if isinstance(unit, list):\n                unit = unit[int(unit_prefix != '')]\n            return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)\n        if args.confluence:\n            rows = []\n            cum_time = 0\n            max_time = max([r.time for r in records])\n            max_bandwidth = max([r.bandwidth for r in records])\n            max_flops = max([r.flops for r in records if not isinstance(r.flops, NonExistNum)])\n            bar_length = 15\n            for (idx, record) in enumerate(records):\n                cum_time += record.time\n                opr_info = [('opr ' + k, v) for (k, v) in record.info.items()]\n                row = collections.OrderedDict([('#', idx), ('time', '{:.3}'.format(record.time)), ('ratio', '{:.1f}%'.format(record.time / tot_time * 100)), ('time bar', '#' * int(record.time / max_time * bar_length)), ('cum-time', cum_time), ('cum-time ratio', cum_time / tot_time)] + opr_info + [('computation (MFLO)', '{:.1f}'.format(record.computation / 1000 ** 2)), ('MFLOPS', '{:.1f}'.format(record.flops / 1000 ** 2)), ('MFLOPS-bar', '' if isinstance(record.flops, NonExistNum) else '#' * int(record.flops / max_flops * bar_length)), ('memory (MB)', '{:.1f}'.format(record.memory / 1024 ** 2)), ('bandwidth (MiB/s)', '{:.1f}'.format(record.bandwidth / 1024 ** 2)), ('bandwidth bar', '#' * int(record.bandwidth / max_bandwidth * bar_length)), ('in_shapes', format_shapes(record.in_shapes, record.in_layouts, sep=', ')), ('out_shapes', format_shapes(record.out_shapes, sep=', '))])\n                rows.append(row)\n            headers = list(rows[0].keys())\n            tab = [[row[i] for i in headers] for row in rows]\n            return _tabulate_confluence(tab, headers=headers)\n        else:\n            cum_time = 0\n            for (idx, record) in enumerate(records):\n                cum_time += record.time\n                tab.append(('#{}\\n{:.3}\\n{:.1f}%'.format(idx, record.time, record.time / tot_time * 100), '{:.3}\\n{:.1f}%'.format(cum_time, cum_time / tot_time * 100), '\\n'.join(('\\n-  '.join(textwrap.wrap(str(i), width=30)) for i in record.info.values())), get_number_with_unit(record.computation, 'FLO', 1000), get_number_with_unit(record.flops, 'FLOPS', 1000), get_number_with_unit(record.memory, ['byte', 'iB'], 1024), get_number_with_unit(record.bandwidth, ['byte/s', 'iB/s'], 1024), format_shapes(record.in_shapes, record.in_layouts), format_shapes(record.out_shapes)))\n            return _tabulate_ml(tab, headers=['{} self time'.format(prof_type), 'cumulative', 'operator info', 'computation', 'FLOPS', 'memory', 'bandwidth', 'in_shapes', 'out_shapes'], tablefmt='fancy_grid')\n    (summary_tab, tot_dev_time, tot_host_time) = summary()\n    if args.print_only:\n        print({'summary': lambda : summary_tab, 'device': lambda : prof_details('device', tot_dev_time), 'host': lambda : prof_details('host', tot_host_time)}[args.print_only]())\n    else:\n        print(summary_tab)\n        print()\n        print(prof_details('device', tot_dev_time))\n        if args.show_host:\n            print()\n            print(prof_details('host', tot_host_time))",
            "def main(passed_args=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    is_profile_from_ocl = False\n    'Analyses profile info from :mod:`~.utils.profile_analyzer` .\\n    Run this file with ``--help`` to get more usage.\\n    '\n    parser = argparse.ArgumentParser(description='analyze analyzer result', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument('dump')\n    parser.add_argument('-t', '--top', type=int, default=3, help='number of most time-consuming operators to print')\n    parser.add_argument('--type', action='append', help='filter oprs in the top list by type')\n    parser.add_argument('--aggregate-by', default=None, choices=['type'], help='aggragate profiling result by')\n    parser.add_argument('--opr-name', help='filter oprs in the top list by regex of name')\n    parser.add_argument('--input-dtype', type=str, help='filter oprs in the top list by input dtype')\n    parser.add_argument('--top-end-key', default='end', choices=['end', 'kern'], help='how time in top is calculated; end corresponds to total device time, and kern corresponds to only wait time')\n    parser.add_argument('--aggregate', default=None, help='aggregate operations', choices=['max', 'min', 'sum', 'mean'])\n    parser.add_argument('--order-by', default='time', help='sort result according to given column; the param can be <col_name> or +<col_name>, meaning sorting in descending or ascending order respectively')\n    parser.add_argument('--copy-time', action='store_true', help='show copy time related result')\n    parser.add_argument('--min-time', type=float, default=float('-inf'), help='minimal time of a result to be printed')\n    parser.add_argument('--max-time', type=float, default=float('inf'), help='maximal time of a result to be printed')\n    parser.add_argument('--show-host', action='store_true', help='show host profiling info')\n    parser.add_argument('--dump-only-opr', action='store_true', help='only dump operator info as plaintext; useful for diff between two filtered profile results')\n    parser.add_argument('--confluence', '--wiki', action='store_true', help='output confluence-markdown-compatible table')\n    parser.add_argument('--print-only', choices={'summary', 'device', 'host'}, help='print only chosen info')\n    args = parser.parse_args(passed_args)\n    opr_filters = []\n    if args.type:\n        opr_filters.append(lambda o, a, b: o['type'] in args.type)\n    if args.opr_name:\n        opr_filters.append(lambda o, a, b, r=re.compile(args.opr_name): r.match(o['name']))\n    if args.input_dtype:\n        opr_filters.append(lambda o, a, b: any([i['mem_plan']['layout']['dtype'] == args.input_dtype for i in a]))\n    if not opr_filters:\n\n        def opr_filter(o, a, b):\n            return True\n    else:\n\n        def opr_filter(o, a, b):\n            return all((i(o, a, b) for i in opr_filters))\n    with open(args.dump) as fin:\n        dump = json.load(fin)\n        if str(dump).find('opencl') != -1:\n            is_profile_from_ocl = True\n    analyzer = ProfileAnalyzer(dump, opr_filter)\n    analyzer_tot = ProfileAnalyzer(dump, lambda _, __, ___: True)\n\n    def summary():\n        device_end_func = TimeFuncHelper.eval_time_func('device', 'end', np.max)\n        device_kern_func = TimeFuncHelper.eval_time_func('device', 'kern', np.max)\n        host_end_func = TimeFuncHelper.eval_time_func('host', 'end', np.max)\n\n        def get_tot_time(func):\n            rec = analyzer_tot.select(func, aggregate=np.sum)\n            if not rec:\n                return 'N/A'\n            rec = rec[0]\n            return rec.time\n        tab = []\n        tot_dev_time = get_tot_time(device_end_func)\n        tot_host_time = get_tot_time(host_end_func)\n        tab.append(('total device time', tot_dev_time))\n        if 0 == tot_dev_time:\n            msg = 'please call mgb::CompNode::enable_opencl_profile(true) before profile at c/c++ code' if is_profile_from_ocl else 'please raise a issue for Engine'\n            assert 0 != tot_dev_time, 'total device time should not be 0, {}'.format(msg)\n        tab.append(('total host time', tot_host_time))\n        if args.copy_time:\n\n            def fmt(a, b):\n                a = a[0]\n                b = b[0]\n                return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)\n            tab.append(('copy time', fmt(analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n            tab.append(('copy wait time', fmt(analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n        if args.confluence:\n            tab_str = _tabulate_confluence(tab, headers=['name', 'value'])\n        else:\n            tab_str = tabulate(tab)\n        return (tab_str, tot_dev_time, tot_host_time)\n\n    def prof_details(prof_type, tot_time):\n        tab = []\n\n        def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n            t = f0(opr)\n            if t is not None and (t < args.min_time or t > args.max_time):\n                return None\n            return t\n        records = analyzer.select(func, aggregate=args.aggregate, aggregate_by=args.aggregate_by, top_k=args.top, sort_by=args.order_by)\n        if args.dump_only_opr:\n            ret = []\n            for i in records:\n                ret.append(' '.join(i.info.values()))\n            return '\\n'.join(ret)\n\n        def format_shapes(shapes, layouts=None, sep='\\n'):\n            if isinstance(shapes, NonExistNum) or shapes is None:\n                return repr(shapes)\n            if layouts is None:\n                layouts = [None] * len(shapes)\n            comp = []\n            for (i, j) in zip(shapes, layouts):\n                i = '{' + ','.join(map(str, i)) + '}'\n                if j:\n                    i += '\\n -[' + ','.join(map(str, j)) + ']'\n                comp.append(i)\n            return sep.join(comp)\n\n        def fix_num_and_find_unit(x, base):\n            if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n                return (x, '')\n            unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n            while x >= base:\n                x /= base\n                next(unit)\n            return (x, next(unit))\n\n        def get_number_with_unit(num, unit, base, sep='\\n'):\n            (num, unit_prefix) = fix_num_and_find_unit(num, base)\n            if isinstance(unit, list):\n                unit = unit[int(unit_prefix != '')]\n            return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)\n        if args.confluence:\n            rows = []\n            cum_time = 0\n            max_time = max([r.time for r in records])\n            max_bandwidth = max([r.bandwidth for r in records])\n            max_flops = max([r.flops for r in records if not isinstance(r.flops, NonExistNum)])\n            bar_length = 15\n            for (idx, record) in enumerate(records):\n                cum_time += record.time\n                opr_info = [('opr ' + k, v) for (k, v) in record.info.items()]\n                row = collections.OrderedDict([('#', idx), ('time', '{:.3}'.format(record.time)), ('ratio', '{:.1f}%'.format(record.time / tot_time * 100)), ('time bar', '#' * int(record.time / max_time * bar_length)), ('cum-time', cum_time), ('cum-time ratio', cum_time / tot_time)] + opr_info + [('computation (MFLO)', '{:.1f}'.format(record.computation / 1000 ** 2)), ('MFLOPS', '{:.1f}'.format(record.flops / 1000 ** 2)), ('MFLOPS-bar', '' if isinstance(record.flops, NonExistNum) else '#' * int(record.flops / max_flops * bar_length)), ('memory (MB)', '{:.1f}'.format(record.memory / 1024 ** 2)), ('bandwidth (MiB/s)', '{:.1f}'.format(record.bandwidth / 1024 ** 2)), ('bandwidth bar', '#' * int(record.bandwidth / max_bandwidth * bar_length)), ('in_shapes', format_shapes(record.in_shapes, record.in_layouts, sep=', ')), ('out_shapes', format_shapes(record.out_shapes, sep=', '))])\n                rows.append(row)\n            headers = list(rows[0].keys())\n            tab = [[row[i] for i in headers] for row in rows]\n            return _tabulate_confluence(tab, headers=headers)\n        else:\n            cum_time = 0\n            for (idx, record) in enumerate(records):\n                cum_time += record.time\n                tab.append(('#{}\\n{:.3}\\n{:.1f}%'.format(idx, record.time, record.time / tot_time * 100), '{:.3}\\n{:.1f}%'.format(cum_time, cum_time / tot_time * 100), '\\n'.join(('\\n-  '.join(textwrap.wrap(str(i), width=30)) for i in record.info.values())), get_number_with_unit(record.computation, 'FLO', 1000), get_number_with_unit(record.flops, 'FLOPS', 1000), get_number_with_unit(record.memory, ['byte', 'iB'], 1024), get_number_with_unit(record.bandwidth, ['byte/s', 'iB/s'], 1024), format_shapes(record.in_shapes, record.in_layouts), format_shapes(record.out_shapes)))\n            return _tabulate_ml(tab, headers=['{} self time'.format(prof_type), 'cumulative', 'operator info', 'computation', 'FLOPS', 'memory', 'bandwidth', 'in_shapes', 'out_shapes'], tablefmt='fancy_grid')\n    (summary_tab, tot_dev_time, tot_host_time) = summary()\n    if args.print_only:\n        print({'summary': lambda : summary_tab, 'device': lambda : prof_details('device', tot_dev_time), 'host': lambda : prof_details('host', tot_host_time)}[args.print_only]())\n    else:\n        print(summary_tab)\n        print()\n        print(prof_details('device', tot_dev_time))\n        if args.show_host:\n            print()\n            print(prof_details('host', tot_host_time))",
            "def main(passed_args=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    is_profile_from_ocl = False\n    'Analyses profile info from :mod:`~.utils.profile_analyzer` .\\n    Run this file with ``--help`` to get more usage.\\n    '\n    parser = argparse.ArgumentParser(description='analyze analyzer result', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument('dump')\n    parser.add_argument('-t', '--top', type=int, default=3, help='number of most time-consuming operators to print')\n    parser.add_argument('--type', action='append', help='filter oprs in the top list by type')\n    parser.add_argument('--aggregate-by', default=None, choices=['type'], help='aggragate profiling result by')\n    parser.add_argument('--opr-name', help='filter oprs in the top list by regex of name')\n    parser.add_argument('--input-dtype', type=str, help='filter oprs in the top list by input dtype')\n    parser.add_argument('--top-end-key', default='end', choices=['end', 'kern'], help='how time in top is calculated; end corresponds to total device time, and kern corresponds to only wait time')\n    parser.add_argument('--aggregate', default=None, help='aggregate operations', choices=['max', 'min', 'sum', 'mean'])\n    parser.add_argument('--order-by', default='time', help='sort result according to given column; the param can be <col_name> or +<col_name>, meaning sorting in descending or ascending order respectively')\n    parser.add_argument('--copy-time', action='store_true', help='show copy time related result')\n    parser.add_argument('--min-time', type=float, default=float('-inf'), help='minimal time of a result to be printed')\n    parser.add_argument('--max-time', type=float, default=float('inf'), help='maximal time of a result to be printed')\n    parser.add_argument('--show-host', action='store_true', help='show host profiling info')\n    parser.add_argument('--dump-only-opr', action='store_true', help='only dump operator info as plaintext; useful for diff between two filtered profile results')\n    parser.add_argument('--confluence', '--wiki', action='store_true', help='output confluence-markdown-compatible table')\n    parser.add_argument('--print-only', choices={'summary', 'device', 'host'}, help='print only chosen info')\n    args = parser.parse_args(passed_args)\n    opr_filters = []\n    if args.type:\n        opr_filters.append(lambda o, a, b: o['type'] in args.type)\n    if args.opr_name:\n        opr_filters.append(lambda o, a, b, r=re.compile(args.opr_name): r.match(o['name']))\n    if args.input_dtype:\n        opr_filters.append(lambda o, a, b: any([i['mem_plan']['layout']['dtype'] == args.input_dtype for i in a]))\n    if not opr_filters:\n\n        def opr_filter(o, a, b):\n            return True\n    else:\n\n        def opr_filter(o, a, b):\n            return all((i(o, a, b) for i in opr_filters))\n    with open(args.dump) as fin:\n        dump = json.load(fin)\n        if str(dump).find('opencl') != -1:\n            is_profile_from_ocl = True\n    analyzer = ProfileAnalyzer(dump, opr_filter)\n    analyzer_tot = ProfileAnalyzer(dump, lambda _, __, ___: True)\n\n    def summary():\n        device_end_func = TimeFuncHelper.eval_time_func('device', 'end', np.max)\n        device_kern_func = TimeFuncHelper.eval_time_func('device', 'kern', np.max)\n        host_end_func = TimeFuncHelper.eval_time_func('host', 'end', np.max)\n\n        def get_tot_time(func):\n            rec = analyzer_tot.select(func, aggregate=np.sum)\n            if not rec:\n                return 'N/A'\n            rec = rec[0]\n            return rec.time\n        tab = []\n        tot_dev_time = get_tot_time(device_end_func)\n        tot_host_time = get_tot_time(host_end_func)\n        tab.append(('total device time', tot_dev_time))\n        if 0 == tot_dev_time:\n            msg = 'please call mgb::CompNode::enable_opencl_profile(true) before profile at c/c++ code' if is_profile_from_ocl else 'please raise a issue for Engine'\n            assert 0 != tot_dev_time, 'total device time should not be 0, {}'.format(msg)\n        tab.append(('total host time', tot_host_time))\n        if args.copy_time:\n\n            def fmt(a, b):\n                a = a[0]\n                b = b[0]\n                return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)\n            tab.append(('copy time', fmt(analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n            tab.append(('copy wait time', fmt(analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n        if args.confluence:\n            tab_str = _tabulate_confluence(tab, headers=['name', 'value'])\n        else:\n            tab_str = tabulate(tab)\n        return (tab_str, tot_dev_time, tot_host_time)\n\n    def prof_details(prof_type, tot_time):\n        tab = []\n\n        def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n            t = f0(opr)\n            if t is not None and (t < args.min_time or t > args.max_time):\n                return None\n            return t\n        records = analyzer.select(func, aggregate=args.aggregate, aggregate_by=args.aggregate_by, top_k=args.top, sort_by=args.order_by)\n        if args.dump_only_opr:\n            ret = []\n            for i in records:\n                ret.append(' '.join(i.info.values()))\n            return '\\n'.join(ret)\n\n        def format_shapes(shapes, layouts=None, sep='\\n'):\n            if isinstance(shapes, NonExistNum) or shapes is None:\n                return repr(shapes)\n            if layouts is None:\n                layouts = [None] * len(shapes)\n            comp = []\n            for (i, j) in zip(shapes, layouts):\n                i = '{' + ','.join(map(str, i)) + '}'\n                if j:\n                    i += '\\n -[' + ','.join(map(str, j)) + ']'\n                comp.append(i)\n            return sep.join(comp)\n\n        def fix_num_and_find_unit(x, base):\n            if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n                return (x, '')\n            unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n            while x >= base:\n                x /= base\n                next(unit)\n            return (x, next(unit))\n\n        def get_number_with_unit(num, unit, base, sep='\\n'):\n            (num, unit_prefix) = fix_num_and_find_unit(num, base)\n            if isinstance(unit, list):\n                unit = unit[int(unit_prefix != '')]\n            return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)\n        if args.confluence:\n            rows = []\n            cum_time = 0\n            max_time = max([r.time for r in records])\n            max_bandwidth = max([r.bandwidth for r in records])\n            max_flops = max([r.flops for r in records if not isinstance(r.flops, NonExistNum)])\n            bar_length = 15\n            for (idx, record) in enumerate(records):\n                cum_time += record.time\n                opr_info = [('opr ' + k, v) for (k, v) in record.info.items()]\n                row = collections.OrderedDict([('#', idx), ('time', '{:.3}'.format(record.time)), ('ratio', '{:.1f}%'.format(record.time / tot_time * 100)), ('time bar', '#' * int(record.time / max_time * bar_length)), ('cum-time', cum_time), ('cum-time ratio', cum_time / tot_time)] + opr_info + [('computation (MFLO)', '{:.1f}'.format(record.computation / 1000 ** 2)), ('MFLOPS', '{:.1f}'.format(record.flops / 1000 ** 2)), ('MFLOPS-bar', '' if isinstance(record.flops, NonExistNum) else '#' * int(record.flops / max_flops * bar_length)), ('memory (MB)', '{:.1f}'.format(record.memory / 1024 ** 2)), ('bandwidth (MiB/s)', '{:.1f}'.format(record.bandwidth / 1024 ** 2)), ('bandwidth bar', '#' * int(record.bandwidth / max_bandwidth * bar_length)), ('in_shapes', format_shapes(record.in_shapes, record.in_layouts, sep=', ')), ('out_shapes', format_shapes(record.out_shapes, sep=', '))])\n                rows.append(row)\n            headers = list(rows[0].keys())\n            tab = [[row[i] for i in headers] for row in rows]\n            return _tabulate_confluence(tab, headers=headers)\n        else:\n            cum_time = 0\n            for (idx, record) in enumerate(records):\n                cum_time += record.time\n                tab.append(('#{}\\n{:.3}\\n{:.1f}%'.format(idx, record.time, record.time / tot_time * 100), '{:.3}\\n{:.1f}%'.format(cum_time, cum_time / tot_time * 100), '\\n'.join(('\\n-  '.join(textwrap.wrap(str(i), width=30)) for i in record.info.values())), get_number_with_unit(record.computation, 'FLO', 1000), get_number_with_unit(record.flops, 'FLOPS', 1000), get_number_with_unit(record.memory, ['byte', 'iB'], 1024), get_number_with_unit(record.bandwidth, ['byte/s', 'iB/s'], 1024), format_shapes(record.in_shapes, record.in_layouts), format_shapes(record.out_shapes)))\n            return _tabulate_ml(tab, headers=['{} self time'.format(prof_type), 'cumulative', 'operator info', 'computation', 'FLOPS', 'memory', 'bandwidth', 'in_shapes', 'out_shapes'], tablefmt='fancy_grid')\n    (summary_tab, tot_dev_time, tot_host_time) = summary()\n    if args.print_only:\n        print({'summary': lambda : summary_tab, 'device': lambda : prof_details('device', tot_dev_time), 'host': lambda : prof_details('host', tot_host_time)}[args.print_only]())\n    else:\n        print(summary_tab)\n        print()\n        print(prof_details('device', tot_dev_time))\n        if args.show_host:\n            print()\n            print(prof_details('host', tot_host_time))",
            "def main(passed_args=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    is_profile_from_ocl = False\n    'Analyses profile info from :mod:`~.utils.profile_analyzer` .\\n    Run this file with ``--help`` to get more usage.\\n    '\n    parser = argparse.ArgumentParser(description='analyze analyzer result', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument('dump')\n    parser.add_argument('-t', '--top', type=int, default=3, help='number of most time-consuming operators to print')\n    parser.add_argument('--type', action='append', help='filter oprs in the top list by type')\n    parser.add_argument('--aggregate-by', default=None, choices=['type'], help='aggragate profiling result by')\n    parser.add_argument('--opr-name', help='filter oprs in the top list by regex of name')\n    parser.add_argument('--input-dtype', type=str, help='filter oprs in the top list by input dtype')\n    parser.add_argument('--top-end-key', default='end', choices=['end', 'kern'], help='how time in top is calculated; end corresponds to total device time, and kern corresponds to only wait time')\n    parser.add_argument('--aggregate', default=None, help='aggregate operations', choices=['max', 'min', 'sum', 'mean'])\n    parser.add_argument('--order-by', default='time', help='sort result according to given column; the param can be <col_name> or +<col_name>, meaning sorting in descending or ascending order respectively')\n    parser.add_argument('--copy-time', action='store_true', help='show copy time related result')\n    parser.add_argument('--min-time', type=float, default=float('-inf'), help='minimal time of a result to be printed')\n    parser.add_argument('--max-time', type=float, default=float('inf'), help='maximal time of a result to be printed')\n    parser.add_argument('--show-host', action='store_true', help='show host profiling info')\n    parser.add_argument('--dump-only-opr', action='store_true', help='only dump operator info as plaintext; useful for diff between two filtered profile results')\n    parser.add_argument('--confluence', '--wiki', action='store_true', help='output confluence-markdown-compatible table')\n    parser.add_argument('--print-only', choices={'summary', 'device', 'host'}, help='print only chosen info')\n    args = parser.parse_args(passed_args)\n    opr_filters = []\n    if args.type:\n        opr_filters.append(lambda o, a, b: o['type'] in args.type)\n    if args.opr_name:\n        opr_filters.append(lambda o, a, b, r=re.compile(args.opr_name): r.match(o['name']))\n    if args.input_dtype:\n        opr_filters.append(lambda o, a, b: any([i['mem_plan']['layout']['dtype'] == args.input_dtype for i in a]))\n    if not opr_filters:\n\n        def opr_filter(o, a, b):\n            return True\n    else:\n\n        def opr_filter(o, a, b):\n            return all((i(o, a, b) for i in opr_filters))\n    with open(args.dump) as fin:\n        dump = json.load(fin)\n        if str(dump).find('opencl') != -1:\n            is_profile_from_ocl = True\n    analyzer = ProfileAnalyzer(dump, opr_filter)\n    analyzer_tot = ProfileAnalyzer(dump, lambda _, __, ___: True)\n\n    def summary():\n        device_end_func = TimeFuncHelper.eval_time_func('device', 'end', np.max)\n        device_kern_func = TimeFuncHelper.eval_time_func('device', 'kern', np.max)\n        host_end_func = TimeFuncHelper.eval_time_func('host', 'end', np.max)\n\n        def get_tot_time(func):\n            rec = analyzer_tot.select(func, aggregate=np.sum)\n            if not rec:\n                return 'N/A'\n            rec = rec[0]\n            return rec.time\n        tab = []\n        tot_dev_time = get_tot_time(device_end_func)\n        tot_host_time = get_tot_time(host_end_func)\n        tab.append(('total device time', tot_dev_time))\n        if 0 == tot_dev_time:\n            msg = 'please call mgb::CompNode::enable_opencl_profile(true) before profile at c/c++ code' if is_profile_from_ocl else 'please raise a issue for Engine'\n            assert 0 != tot_dev_time, 'total device time should not be 0, {}'.format(msg)\n        tab.append(('total host time', tot_host_time))\n        if args.copy_time:\n\n            def fmt(a, b):\n                a = a[0]\n                b = b[0]\n                return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)\n            tab.append(('copy time', fmt(analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n            tab.append(('copy wait time', fmt(analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n        if args.confluence:\n            tab_str = _tabulate_confluence(tab, headers=['name', 'value'])\n        else:\n            tab_str = tabulate(tab)\n        return (tab_str, tot_dev_time, tot_host_time)\n\n    def prof_details(prof_type, tot_time):\n        tab = []\n\n        def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n            t = f0(opr)\n            if t is not None and (t < args.min_time or t > args.max_time):\n                return None\n            return t\n        records = analyzer.select(func, aggregate=args.aggregate, aggregate_by=args.aggregate_by, top_k=args.top, sort_by=args.order_by)\n        if args.dump_only_opr:\n            ret = []\n            for i in records:\n                ret.append(' '.join(i.info.values()))\n            return '\\n'.join(ret)\n\n        def format_shapes(shapes, layouts=None, sep='\\n'):\n            if isinstance(shapes, NonExistNum) or shapes is None:\n                return repr(shapes)\n            if layouts is None:\n                layouts = [None] * len(shapes)\n            comp = []\n            for (i, j) in zip(shapes, layouts):\n                i = '{' + ','.join(map(str, i)) + '}'\n                if j:\n                    i += '\\n -[' + ','.join(map(str, j)) + ']'\n                comp.append(i)\n            return sep.join(comp)\n\n        def fix_num_and_find_unit(x, base):\n            if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n                return (x, '')\n            unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n            while x >= base:\n                x /= base\n                next(unit)\n            return (x, next(unit))\n\n        def get_number_with_unit(num, unit, base, sep='\\n'):\n            (num, unit_prefix) = fix_num_and_find_unit(num, base)\n            if isinstance(unit, list):\n                unit = unit[int(unit_prefix != '')]\n            return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)\n        if args.confluence:\n            rows = []\n            cum_time = 0\n            max_time = max([r.time for r in records])\n            max_bandwidth = max([r.bandwidth for r in records])\n            max_flops = max([r.flops for r in records if not isinstance(r.flops, NonExistNum)])\n            bar_length = 15\n            for (idx, record) in enumerate(records):\n                cum_time += record.time\n                opr_info = [('opr ' + k, v) for (k, v) in record.info.items()]\n                row = collections.OrderedDict([('#', idx), ('time', '{:.3}'.format(record.time)), ('ratio', '{:.1f}%'.format(record.time / tot_time * 100)), ('time bar', '#' * int(record.time / max_time * bar_length)), ('cum-time', cum_time), ('cum-time ratio', cum_time / tot_time)] + opr_info + [('computation (MFLO)', '{:.1f}'.format(record.computation / 1000 ** 2)), ('MFLOPS', '{:.1f}'.format(record.flops / 1000 ** 2)), ('MFLOPS-bar', '' if isinstance(record.flops, NonExistNum) else '#' * int(record.flops / max_flops * bar_length)), ('memory (MB)', '{:.1f}'.format(record.memory / 1024 ** 2)), ('bandwidth (MiB/s)', '{:.1f}'.format(record.bandwidth / 1024 ** 2)), ('bandwidth bar', '#' * int(record.bandwidth / max_bandwidth * bar_length)), ('in_shapes', format_shapes(record.in_shapes, record.in_layouts, sep=', ')), ('out_shapes', format_shapes(record.out_shapes, sep=', '))])\n                rows.append(row)\n            headers = list(rows[0].keys())\n            tab = [[row[i] for i in headers] for row in rows]\n            return _tabulate_confluence(tab, headers=headers)\n        else:\n            cum_time = 0\n            for (idx, record) in enumerate(records):\n                cum_time += record.time\n                tab.append(('#{}\\n{:.3}\\n{:.1f}%'.format(idx, record.time, record.time / tot_time * 100), '{:.3}\\n{:.1f}%'.format(cum_time, cum_time / tot_time * 100), '\\n'.join(('\\n-  '.join(textwrap.wrap(str(i), width=30)) for i in record.info.values())), get_number_with_unit(record.computation, 'FLO', 1000), get_number_with_unit(record.flops, 'FLOPS', 1000), get_number_with_unit(record.memory, ['byte', 'iB'], 1024), get_number_with_unit(record.bandwidth, ['byte/s', 'iB/s'], 1024), format_shapes(record.in_shapes, record.in_layouts), format_shapes(record.out_shapes)))\n            return _tabulate_ml(tab, headers=['{} self time'.format(prof_type), 'cumulative', 'operator info', 'computation', 'FLOPS', 'memory', 'bandwidth', 'in_shapes', 'out_shapes'], tablefmt='fancy_grid')\n    (summary_tab, tot_dev_time, tot_host_time) = summary()\n    if args.print_only:\n        print({'summary': lambda : summary_tab, 'device': lambda : prof_details('device', tot_dev_time), 'host': lambda : prof_details('host', tot_host_time)}[args.print_only]())\n    else:\n        print(summary_tab)\n        print()\n        print(prof_details('device', tot_dev_time))\n        if args.show_host:\n            print()\n            print(prof_details('host', tot_host_time))",
            "def main(passed_args=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    is_profile_from_ocl = False\n    'Analyses profile info from :mod:`~.utils.profile_analyzer` .\\n    Run this file with ``--help`` to get more usage.\\n    '\n    parser = argparse.ArgumentParser(description='analyze analyzer result', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument('dump')\n    parser.add_argument('-t', '--top', type=int, default=3, help='number of most time-consuming operators to print')\n    parser.add_argument('--type', action='append', help='filter oprs in the top list by type')\n    parser.add_argument('--aggregate-by', default=None, choices=['type'], help='aggragate profiling result by')\n    parser.add_argument('--opr-name', help='filter oprs in the top list by regex of name')\n    parser.add_argument('--input-dtype', type=str, help='filter oprs in the top list by input dtype')\n    parser.add_argument('--top-end-key', default='end', choices=['end', 'kern'], help='how time in top is calculated; end corresponds to total device time, and kern corresponds to only wait time')\n    parser.add_argument('--aggregate', default=None, help='aggregate operations', choices=['max', 'min', 'sum', 'mean'])\n    parser.add_argument('--order-by', default='time', help='sort result according to given column; the param can be <col_name> or +<col_name>, meaning sorting in descending or ascending order respectively')\n    parser.add_argument('--copy-time', action='store_true', help='show copy time related result')\n    parser.add_argument('--min-time', type=float, default=float('-inf'), help='minimal time of a result to be printed')\n    parser.add_argument('--max-time', type=float, default=float('inf'), help='maximal time of a result to be printed')\n    parser.add_argument('--show-host', action='store_true', help='show host profiling info')\n    parser.add_argument('--dump-only-opr', action='store_true', help='only dump operator info as plaintext; useful for diff between two filtered profile results')\n    parser.add_argument('--confluence', '--wiki', action='store_true', help='output confluence-markdown-compatible table')\n    parser.add_argument('--print-only', choices={'summary', 'device', 'host'}, help='print only chosen info')\n    args = parser.parse_args(passed_args)\n    opr_filters = []\n    if args.type:\n        opr_filters.append(lambda o, a, b: o['type'] in args.type)\n    if args.opr_name:\n        opr_filters.append(lambda o, a, b, r=re.compile(args.opr_name): r.match(o['name']))\n    if args.input_dtype:\n        opr_filters.append(lambda o, a, b: any([i['mem_plan']['layout']['dtype'] == args.input_dtype for i in a]))\n    if not opr_filters:\n\n        def opr_filter(o, a, b):\n            return True\n    else:\n\n        def opr_filter(o, a, b):\n            return all((i(o, a, b) for i in opr_filters))\n    with open(args.dump) as fin:\n        dump = json.load(fin)\n        if str(dump).find('opencl') != -1:\n            is_profile_from_ocl = True\n    analyzer = ProfileAnalyzer(dump, opr_filter)\n    analyzer_tot = ProfileAnalyzer(dump, lambda _, __, ___: True)\n\n    def summary():\n        device_end_func = TimeFuncHelper.eval_time_func('device', 'end', np.max)\n        device_kern_func = TimeFuncHelper.eval_time_func('device', 'kern', np.max)\n        host_end_func = TimeFuncHelper.eval_time_func('host', 'end', np.max)\n\n        def get_tot_time(func):\n            rec = analyzer_tot.select(func, aggregate=np.sum)\n            if not rec:\n                return 'N/A'\n            rec = rec[0]\n            return rec.time\n        tab = []\n        tot_dev_time = get_tot_time(device_end_func)\n        tot_host_time = get_tot_time(host_end_func)\n        tab.append(('total device time', tot_dev_time))\n        if 0 == tot_dev_time:\n            msg = 'please call mgb::CompNode::enable_opencl_profile(true) before profile at c/c++ code' if is_profile_from_ocl else 'please raise a issue for Engine'\n            assert 0 != tot_dev_time, 'total device time should not be 0, {}'.format(msg)\n        tab.append(('total host time', tot_host_time))\n        if args.copy_time:\n\n            def fmt(a, b):\n                a = a[0]\n                b = b[0]\n                return 'tot={:.4f} avg={:.4f}'.format(a.time, b.time)\n            tab.append(('copy time', fmt(analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_end_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n            tab.append(('copy wait time', fmt(analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.sum), analyzer.select(device_kern_func, lambda opr: opr.opr_info['type'] == 'Copy', aggregate=np.mean))))\n        if args.confluence:\n            tab_str = _tabulate_confluence(tab, headers=['name', 'value'])\n        else:\n            tab_str = tabulate(tab)\n        return (tab_str, tot_dev_time, tot_host_time)\n\n    def prof_details(prof_type, tot_time):\n        tab = []\n\n        def func(opr, *, f0=TimeFuncHelper.eval_time_func(prof_type, args.top_end_key, np.max)):\n            t = f0(opr)\n            if t is not None and (t < args.min_time or t > args.max_time):\n                return None\n            return t\n        records = analyzer.select(func, aggregate=args.aggregate, aggregate_by=args.aggregate_by, top_k=args.top, sort_by=args.order_by)\n        if args.dump_only_opr:\n            ret = []\n            for i in records:\n                ret.append(' '.join(i.info.values()))\n            return '\\n'.join(ret)\n\n        def format_shapes(shapes, layouts=None, sep='\\n'):\n            if isinstance(shapes, NonExistNum) or shapes is None:\n                return repr(shapes)\n            if layouts is None:\n                layouts = [None] * len(shapes)\n            comp = []\n            for (i, j) in zip(shapes, layouts):\n                i = '{' + ','.join(map(str, i)) + '}'\n                if j:\n                    i += '\\n -[' + ','.join(map(str, j)) + ']'\n                comp.append(i)\n            return sep.join(comp)\n\n        def fix_num_and_find_unit(x, base):\n            if isinstance(x, NonExistNum) or (isinstance(x, float) and (not np.isfinite(x))):\n                return (x, '')\n            unit = iter(['', 'K', 'M', 'G', 'T', 'P'])\n            while x >= base:\n                x /= base\n                next(unit)\n            return (x, next(unit))\n\n        def get_number_with_unit(num, unit, base, sep='\\n'):\n            (num, unit_prefix) = fix_num_and_find_unit(num, base)\n            if isinstance(unit, list):\n                unit = unit[int(unit_prefix != '')]\n            return ('{:.2f}' + sep + '{}{}').format(num, unit_prefix, unit)\n        if args.confluence:\n            rows = []\n            cum_time = 0\n            max_time = max([r.time for r in records])\n            max_bandwidth = max([r.bandwidth for r in records])\n            max_flops = max([r.flops for r in records if not isinstance(r.flops, NonExistNum)])\n            bar_length = 15\n            for (idx, record) in enumerate(records):\n                cum_time += record.time\n                opr_info = [('opr ' + k, v) for (k, v) in record.info.items()]\n                row = collections.OrderedDict([('#', idx), ('time', '{:.3}'.format(record.time)), ('ratio', '{:.1f}%'.format(record.time / tot_time * 100)), ('time bar', '#' * int(record.time / max_time * bar_length)), ('cum-time', cum_time), ('cum-time ratio', cum_time / tot_time)] + opr_info + [('computation (MFLO)', '{:.1f}'.format(record.computation / 1000 ** 2)), ('MFLOPS', '{:.1f}'.format(record.flops / 1000 ** 2)), ('MFLOPS-bar', '' if isinstance(record.flops, NonExistNum) else '#' * int(record.flops / max_flops * bar_length)), ('memory (MB)', '{:.1f}'.format(record.memory / 1024 ** 2)), ('bandwidth (MiB/s)', '{:.1f}'.format(record.bandwidth / 1024 ** 2)), ('bandwidth bar', '#' * int(record.bandwidth / max_bandwidth * bar_length)), ('in_shapes', format_shapes(record.in_shapes, record.in_layouts, sep=', ')), ('out_shapes', format_shapes(record.out_shapes, sep=', '))])\n                rows.append(row)\n            headers = list(rows[0].keys())\n            tab = [[row[i] for i in headers] for row in rows]\n            return _tabulate_confluence(tab, headers=headers)\n        else:\n            cum_time = 0\n            for (idx, record) in enumerate(records):\n                cum_time += record.time\n                tab.append(('#{}\\n{:.3}\\n{:.1f}%'.format(idx, record.time, record.time / tot_time * 100), '{:.3}\\n{:.1f}%'.format(cum_time, cum_time / tot_time * 100), '\\n'.join(('\\n-  '.join(textwrap.wrap(str(i), width=30)) for i in record.info.values())), get_number_with_unit(record.computation, 'FLO', 1000), get_number_with_unit(record.flops, 'FLOPS', 1000), get_number_with_unit(record.memory, ['byte', 'iB'], 1024), get_number_with_unit(record.bandwidth, ['byte/s', 'iB/s'], 1024), format_shapes(record.in_shapes, record.in_layouts), format_shapes(record.out_shapes)))\n            return _tabulate_ml(tab, headers=['{} self time'.format(prof_type), 'cumulative', 'operator info', 'computation', 'FLOPS', 'memory', 'bandwidth', 'in_shapes', 'out_shapes'], tablefmt='fancy_grid')\n    (summary_tab, tot_dev_time, tot_host_time) = summary()\n    if args.print_only:\n        print({'summary': lambda : summary_tab, 'device': lambda : prof_details('device', tot_dev_time), 'host': lambda : prof_details('host', tot_host_time)}[args.print_only]())\n    else:\n        print(summary_tab)\n        print()\n        print(prof_details('device', tot_dev_time))\n        if args.show_host:\n            print()\n            print(prof_details('host', tot_host_time))"
        ]
    }
]