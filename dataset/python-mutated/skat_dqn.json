[
    {
        "func_name": "eval_against_random_bots",
        "original": "def eval_against_random_bots(env, trained_agents, random_agents, num_episodes):\n    \"\"\"Evaluates `trained_agents` against `random_agents` for `num_episodes`.\"\"\"\n    num_players = len(trained_agents)\n    sum_episode_rewards = np.zeros(num_players)\n    for player_pos in range(num_players):\n        for _ in range(num_episodes):\n            cur_agents = random_agents[:]\n            if FLAGS.randomize_positions:\n                eval_player_pos = random.randrange(num_players)\n            else:\n                eval_player_pos = player_pos\n            cur_agents[eval_player_pos] = trained_agents[player_pos]\n            cur_agents[eval_player_pos].player_id = eval_player_pos\n            time_step = env.reset()\n            episode_rewards = 0\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = cur_agents[player_id].step(time_step, is_evaluation=True)\n                action_list = [agent_output.action]\n                time_step = env.step(action_list)\n                episode_rewards += time_step.rewards[eval_player_pos]\n            sum_episode_rewards[player_pos] += episode_rewards\n    return sum_episode_rewards / num_episodes",
        "mutated": [
            "def eval_against_random_bots(env, trained_agents, random_agents, num_episodes):\n    if False:\n        i = 10\n    'Evaluates `trained_agents` against `random_agents` for `num_episodes`.'\n    num_players = len(trained_agents)\n    sum_episode_rewards = np.zeros(num_players)\n    for player_pos in range(num_players):\n        for _ in range(num_episodes):\n            cur_agents = random_agents[:]\n            if FLAGS.randomize_positions:\n                eval_player_pos = random.randrange(num_players)\n            else:\n                eval_player_pos = player_pos\n            cur_agents[eval_player_pos] = trained_agents[player_pos]\n            cur_agents[eval_player_pos].player_id = eval_player_pos\n            time_step = env.reset()\n            episode_rewards = 0\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = cur_agents[player_id].step(time_step, is_evaluation=True)\n                action_list = [agent_output.action]\n                time_step = env.step(action_list)\n                episode_rewards += time_step.rewards[eval_player_pos]\n            sum_episode_rewards[player_pos] += episode_rewards\n    return sum_episode_rewards / num_episodes",
            "def eval_against_random_bots(env, trained_agents, random_agents, num_episodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Evaluates `trained_agents` against `random_agents` for `num_episodes`.'\n    num_players = len(trained_agents)\n    sum_episode_rewards = np.zeros(num_players)\n    for player_pos in range(num_players):\n        for _ in range(num_episodes):\n            cur_agents = random_agents[:]\n            if FLAGS.randomize_positions:\n                eval_player_pos = random.randrange(num_players)\n            else:\n                eval_player_pos = player_pos\n            cur_agents[eval_player_pos] = trained_agents[player_pos]\n            cur_agents[eval_player_pos].player_id = eval_player_pos\n            time_step = env.reset()\n            episode_rewards = 0\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = cur_agents[player_id].step(time_step, is_evaluation=True)\n                action_list = [agent_output.action]\n                time_step = env.step(action_list)\n                episode_rewards += time_step.rewards[eval_player_pos]\n            sum_episode_rewards[player_pos] += episode_rewards\n    return sum_episode_rewards / num_episodes",
            "def eval_against_random_bots(env, trained_agents, random_agents, num_episodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Evaluates `trained_agents` against `random_agents` for `num_episodes`.'\n    num_players = len(trained_agents)\n    sum_episode_rewards = np.zeros(num_players)\n    for player_pos in range(num_players):\n        for _ in range(num_episodes):\n            cur_agents = random_agents[:]\n            if FLAGS.randomize_positions:\n                eval_player_pos = random.randrange(num_players)\n            else:\n                eval_player_pos = player_pos\n            cur_agents[eval_player_pos] = trained_agents[player_pos]\n            cur_agents[eval_player_pos].player_id = eval_player_pos\n            time_step = env.reset()\n            episode_rewards = 0\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = cur_agents[player_id].step(time_step, is_evaluation=True)\n                action_list = [agent_output.action]\n                time_step = env.step(action_list)\n                episode_rewards += time_step.rewards[eval_player_pos]\n            sum_episode_rewards[player_pos] += episode_rewards\n    return sum_episode_rewards / num_episodes",
            "def eval_against_random_bots(env, trained_agents, random_agents, num_episodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Evaluates `trained_agents` against `random_agents` for `num_episodes`.'\n    num_players = len(trained_agents)\n    sum_episode_rewards = np.zeros(num_players)\n    for player_pos in range(num_players):\n        for _ in range(num_episodes):\n            cur_agents = random_agents[:]\n            if FLAGS.randomize_positions:\n                eval_player_pos = random.randrange(num_players)\n            else:\n                eval_player_pos = player_pos\n            cur_agents[eval_player_pos] = trained_agents[player_pos]\n            cur_agents[eval_player_pos].player_id = eval_player_pos\n            time_step = env.reset()\n            episode_rewards = 0\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = cur_agents[player_id].step(time_step, is_evaluation=True)\n                action_list = [agent_output.action]\n                time_step = env.step(action_list)\n                episode_rewards += time_step.rewards[eval_player_pos]\n            sum_episode_rewards[player_pos] += episode_rewards\n    return sum_episode_rewards / num_episodes",
            "def eval_against_random_bots(env, trained_agents, random_agents, num_episodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Evaluates `trained_agents` against `random_agents` for `num_episodes`.'\n    num_players = len(trained_agents)\n    sum_episode_rewards = np.zeros(num_players)\n    for player_pos in range(num_players):\n        for _ in range(num_episodes):\n            cur_agents = random_agents[:]\n            if FLAGS.randomize_positions:\n                eval_player_pos = random.randrange(num_players)\n            else:\n                eval_player_pos = player_pos\n            cur_agents[eval_player_pos] = trained_agents[player_pos]\n            cur_agents[eval_player_pos].player_id = eval_player_pos\n            time_step = env.reset()\n            episode_rewards = 0\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = cur_agents[player_id].step(time_step, is_evaluation=True)\n                action_list = [agent_output.action]\n                time_step = env.step(action_list)\n                episode_rewards += time_step.rewards[eval_player_pos]\n            sum_episode_rewards[player_pos] += episode_rewards\n    return sum_episode_rewards / num_episodes"
        ]
    },
    {
        "func_name": "main",
        "original": "def main(_):\n    game = 'skat'\n    num_players = 3\n    env_configs = {}\n    env = rl_environment.Environment(game, **env_configs)\n    observation_tensor_size = env.observation_spec()['info_state'][0]\n    num_actions = env.action_spec()['num_actions']\n    random_agents = [random_agent.RandomAgent(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    with tf.Session() as sess:\n        summaries_dir = os.path.join(FLAGS.checkpoint_dir, 'random_eval')\n        summary_writer = tf.summary.FileWriter(summaries_dir, tf.get_default_graph())\n        hidden_layers_sizes = [int(l) for l in FLAGS.hidden_layers_sizes]\n        agents = [dqn.DQN(session=sess, player_id=idx, state_representation_size=observation_tensor_size, num_actions=num_actions, hidden_layers_sizes=hidden_layers_sizes, replay_buffer_capacity=FLAGS.replay_buffer_capacity, batch_size=FLAGS.batch_size) for idx in range(num_players)]\n        saver = tf.train.Saver()\n        sess.run(tf.global_variables_initializer())\n        for ep in range(FLAGS.num_train_episodes):\n            if (ep + 1) % FLAGS.eval_every == 0:\n                r_mean = eval_against_random_bots(env, agents, random_agents, FLAGS.num_eval_games)\n                logging.info('[%s] Mean episode rewards %s', ep + 1, r_mean)\n                for i in range(num_players):\n                    summary = tf.Summary()\n                    summary.value.add(tag='mean_reward/random_{}'.format(i), simple_value=r_mean[i])\n                    summary_writer.add_summary(summary, ep)\n                summary_writer.flush()\n                saver.save(sess, FLAGS.checkpoint_dir, ep)\n            time_step = env.reset()\n            if FLAGS.randomize_positions:\n                positions = random.sample(range(len(agents)), len(agents))\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                if FLAGS.randomize_positions:\n                    position = positions[player_id]\n                    agents[position].player_id = player_id\n                else:\n                    position = player_id\n                agent_output = agents[position].step(time_step)\n                action_list = [agent_output.action]\n                time_step = env.step(action_list)\n            for agent in agents:\n                agent.step(time_step)",
        "mutated": [
            "def main(_):\n    if False:\n        i = 10\n    game = 'skat'\n    num_players = 3\n    env_configs = {}\n    env = rl_environment.Environment(game, **env_configs)\n    observation_tensor_size = env.observation_spec()['info_state'][0]\n    num_actions = env.action_spec()['num_actions']\n    random_agents = [random_agent.RandomAgent(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    with tf.Session() as sess:\n        summaries_dir = os.path.join(FLAGS.checkpoint_dir, 'random_eval')\n        summary_writer = tf.summary.FileWriter(summaries_dir, tf.get_default_graph())\n        hidden_layers_sizes = [int(l) for l in FLAGS.hidden_layers_sizes]\n        agents = [dqn.DQN(session=sess, player_id=idx, state_representation_size=observation_tensor_size, num_actions=num_actions, hidden_layers_sizes=hidden_layers_sizes, replay_buffer_capacity=FLAGS.replay_buffer_capacity, batch_size=FLAGS.batch_size) for idx in range(num_players)]\n        saver = tf.train.Saver()\n        sess.run(tf.global_variables_initializer())\n        for ep in range(FLAGS.num_train_episodes):\n            if (ep + 1) % FLAGS.eval_every == 0:\n                r_mean = eval_against_random_bots(env, agents, random_agents, FLAGS.num_eval_games)\n                logging.info('[%s] Mean episode rewards %s', ep + 1, r_mean)\n                for i in range(num_players):\n                    summary = tf.Summary()\n                    summary.value.add(tag='mean_reward/random_{}'.format(i), simple_value=r_mean[i])\n                    summary_writer.add_summary(summary, ep)\n                summary_writer.flush()\n                saver.save(sess, FLAGS.checkpoint_dir, ep)\n            time_step = env.reset()\n            if FLAGS.randomize_positions:\n                positions = random.sample(range(len(agents)), len(agents))\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                if FLAGS.randomize_positions:\n                    position = positions[player_id]\n                    agents[position].player_id = player_id\n                else:\n                    position = player_id\n                agent_output = agents[position].step(time_step)\n                action_list = [agent_output.action]\n                time_step = env.step(action_list)\n            for agent in agents:\n                agent.step(time_step)",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    game = 'skat'\n    num_players = 3\n    env_configs = {}\n    env = rl_environment.Environment(game, **env_configs)\n    observation_tensor_size = env.observation_spec()['info_state'][0]\n    num_actions = env.action_spec()['num_actions']\n    random_agents = [random_agent.RandomAgent(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    with tf.Session() as sess:\n        summaries_dir = os.path.join(FLAGS.checkpoint_dir, 'random_eval')\n        summary_writer = tf.summary.FileWriter(summaries_dir, tf.get_default_graph())\n        hidden_layers_sizes = [int(l) for l in FLAGS.hidden_layers_sizes]\n        agents = [dqn.DQN(session=sess, player_id=idx, state_representation_size=observation_tensor_size, num_actions=num_actions, hidden_layers_sizes=hidden_layers_sizes, replay_buffer_capacity=FLAGS.replay_buffer_capacity, batch_size=FLAGS.batch_size) for idx in range(num_players)]\n        saver = tf.train.Saver()\n        sess.run(tf.global_variables_initializer())\n        for ep in range(FLAGS.num_train_episodes):\n            if (ep + 1) % FLAGS.eval_every == 0:\n                r_mean = eval_against_random_bots(env, agents, random_agents, FLAGS.num_eval_games)\n                logging.info('[%s] Mean episode rewards %s', ep + 1, r_mean)\n                for i in range(num_players):\n                    summary = tf.Summary()\n                    summary.value.add(tag='mean_reward/random_{}'.format(i), simple_value=r_mean[i])\n                    summary_writer.add_summary(summary, ep)\n                summary_writer.flush()\n                saver.save(sess, FLAGS.checkpoint_dir, ep)\n            time_step = env.reset()\n            if FLAGS.randomize_positions:\n                positions = random.sample(range(len(agents)), len(agents))\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                if FLAGS.randomize_positions:\n                    position = positions[player_id]\n                    agents[position].player_id = player_id\n                else:\n                    position = player_id\n                agent_output = agents[position].step(time_step)\n                action_list = [agent_output.action]\n                time_step = env.step(action_list)\n            for agent in agents:\n                agent.step(time_step)",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    game = 'skat'\n    num_players = 3\n    env_configs = {}\n    env = rl_environment.Environment(game, **env_configs)\n    observation_tensor_size = env.observation_spec()['info_state'][0]\n    num_actions = env.action_spec()['num_actions']\n    random_agents = [random_agent.RandomAgent(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    with tf.Session() as sess:\n        summaries_dir = os.path.join(FLAGS.checkpoint_dir, 'random_eval')\n        summary_writer = tf.summary.FileWriter(summaries_dir, tf.get_default_graph())\n        hidden_layers_sizes = [int(l) for l in FLAGS.hidden_layers_sizes]\n        agents = [dqn.DQN(session=sess, player_id=idx, state_representation_size=observation_tensor_size, num_actions=num_actions, hidden_layers_sizes=hidden_layers_sizes, replay_buffer_capacity=FLAGS.replay_buffer_capacity, batch_size=FLAGS.batch_size) for idx in range(num_players)]\n        saver = tf.train.Saver()\n        sess.run(tf.global_variables_initializer())\n        for ep in range(FLAGS.num_train_episodes):\n            if (ep + 1) % FLAGS.eval_every == 0:\n                r_mean = eval_against_random_bots(env, agents, random_agents, FLAGS.num_eval_games)\n                logging.info('[%s] Mean episode rewards %s', ep + 1, r_mean)\n                for i in range(num_players):\n                    summary = tf.Summary()\n                    summary.value.add(tag='mean_reward/random_{}'.format(i), simple_value=r_mean[i])\n                    summary_writer.add_summary(summary, ep)\n                summary_writer.flush()\n                saver.save(sess, FLAGS.checkpoint_dir, ep)\n            time_step = env.reset()\n            if FLAGS.randomize_positions:\n                positions = random.sample(range(len(agents)), len(agents))\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                if FLAGS.randomize_positions:\n                    position = positions[player_id]\n                    agents[position].player_id = player_id\n                else:\n                    position = player_id\n                agent_output = agents[position].step(time_step)\n                action_list = [agent_output.action]\n                time_step = env.step(action_list)\n            for agent in agents:\n                agent.step(time_step)",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    game = 'skat'\n    num_players = 3\n    env_configs = {}\n    env = rl_environment.Environment(game, **env_configs)\n    observation_tensor_size = env.observation_spec()['info_state'][0]\n    num_actions = env.action_spec()['num_actions']\n    random_agents = [random_agent.RandomAgent(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    with tf.Session() as sess:\n        summaries_dir = os.path.join(FLAGS.checkpoint_dir, 'random_eval')\n        summary_writer = tf.summary.FileWriter(summaries_dir, tf.get_default_graph())\n        hidden_layers_sizes = [int(l) for l in FLAGS.hidden_layers_sizes]\n        agents = [dqn.DQN(session=sess, player_id=idx, state_representation_size=observation_tensor_size, num_actions=num_actions, hidden_layers_sizes=hidden_layers_sizes, replay_buffer_capacity=FLAGS.replay_buffer_capacity, batch_size=FLAGS.batch_size) for idx in range(num_players)]\n        saver = tf.train.Saver()\n        sess.run(tf.global_variables_initializer())\n        for ep in range(FLAGS.num_train_episodes):\n            if (ep + 1) % FLAGS.eval_every == 0:\n                r_mean = eval_against_random_bots(env, agents, random_agents, FLAGS.num_eval_games)\n                logging.info('[%s] Mean episode rewards %s', ep + 1, r_mean)\n                for i in range(num_players):\n                    summary = tf.Summary()\n                    summary.value.add(tag='mean_reward/random_{}'.format(i), simple_value=r_mean[i])\n                    summary_writer.add_summary(summary, ep)\n                summary_writer.flush()\n                saver.save(sess, FLAGS.checkpoint_dir, ep)\n            time_step = env.reset()\n            if FLAGS.randomize_positions:\n                positions = random.sample(range(len(agents)), len(agents))\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                if FLAGS.randomize_positions:\n                    position = positions[player_id]\n                    agents[position].player_id = player_id\n                else:\n                    position = player_id\n                agent_output = agents[position].step(time_step)\n                action_list = [agent_output.action]\n                time_step = env.step(action_list)\n            for agent in agents:\n                agent.step(time_step)",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    game = 'skat'\n    num_players = 3\n    env_configs = {}\n    env = rl_environment.Environment(game, **env_configs)\n    observation_tensor_size = env.observation_spec()['info_state'][0]\n    num_actions = env.action_spec()['num_actions']\n    random_agents = [random_agent.RandomAgent(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    with tf.Session() as sess:\n        summaries_dir = os.path.join(FLAGS.checkpoint_dir, 'random_eval')\n        summary_writer = tf.summary.FileWriter(summaries_dir, tf.get_default_graph())\n        hidden_layers_sizes = [int(l) for l in FLAGS.hidden_layers_sizes]\n        agents = [dqn.DQN(session=sess, player_id=idx, state_representation_size=observation_tensor_size, num_actions=num_actions, hidden_layers_sizes=hidden_layers_sizes, replay_buffer_capacity=FLAGS.replay_buffer_capacity, batch_size=FLAGS.batch_size) for idx in range(num_players)]\n        saver = tf.train.Saver()\n        sess.run(tf.global_variables_initializer())\n        for ep in range(FLAGS.num_train_episodes):\n            if (ep + 1) % FLAGS.eval_every == 0:\n                r_mean = eval_against_random_bots(env, agents, random_agents, FLAGS.num_eval_games)\n                logging.info('[%s] Mean episode rewards %s', ep + 1, r_mean)\n                for i in range(num_players):\n                    summary = tf.Summary()\n                    summary.value.add(tag='mean_reward/random_{}'.format(i), simple_value=r_mean[i])\n                    summary_writer.add_summary(summary, ep)\n                summary_writer.flush()\n                saver.save(sess, FLAGS.checkpoint_dir, ep)\n            time_step = env.reset()\n            if FLAGS.randomize_positions:\n                positions = random.sample(range(len(agents)), len(agents))\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                if FLAGS.randomize_positions:\n                    position = positions[player_id]\n                    agents[position].player_id = player_id\n                else:\n                    position = player_id\n                agent_output = agents[position].step(time_step)\n                action_list = [agent_output.action]\n                time_step = env.step(action_list)\n            for agent in agents:\n                agent.step(time_step)"
        ]
    }
]