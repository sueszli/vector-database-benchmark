[
    {
        "func_name": "__init__",
        "original": "def __init__(self, lhs, rhs, exog):\n    \"\"\"\n        Parameters\n        ----------\n        lhs : ndarray\n           A q x p matrix which is the left hand side of the\n           constraint lhs * param = rhs.  The number of constraints is\n           q >= 1 and p is the dimension of the parameter vector.\n        rhs : ndarray\n          A 1-dimensional vector of length q which is the right hand\n          side of the constraint equation.\n        exog : ndarray\n          The n x p exognenous data for the full model.\n        \"\"\"\n    rhs = np.atleast_1d(rhs.squeeze())\n    if rhs.ndim > 1:\n        raise ValueError('The right hand side of the constraint must be a vector.')\n    if len(rhs) != lhs.shape[0]:\n        raise ValueError('The number of rows of the left hand side constraint matrix L must equal the length of the right hand side constraint vector R.')\n    self.lhs = lhs\n    self.rhs = rhs\n    (lhs_u, lhs_s, lhs_vt) = np.linalg.svd(lhs.T, full_matrices=1)\n    self.lhs0 = lhs_u[:, len(lhs_s):]\n    self.lhs1 = lhs_u[:, 0:len(lhs_s)]\n    self.lhsf = np.hstack((self.lhs0, self.lhs1))\n    self.param0 = np.dot(self.lhs1, np.dot(lhs_vt, self.rhs) / lhs_s)\n    self._offset_increment = np.dot(exog, self.param0)\n    self.orig_exog = exog\n    self.exog_fulltrans = np.dot(exog, self.lhsf)",
        "mutated": [
            "def __init__(self, lhs, rhs, exog):\n    if False:\n        i = 10\n    '\\n        Parameters\\n        ----------\\n        lhs : ndarray\\n           A q x p matrix which is the left hand side of the\\n           constraint lhs * param = rhs.  The number of constraints is\\n           q >= 1 and p is the dimension of the parameter vector.\\n        rhs : ndarray\\n          A 1-dimensional vector of length q which is the right hand\\n          side of the constraint equation.\\n        exog : ndarray\\n          The n x p exognenous data for the full model.\\n        '\n    rhs = np.atleast_1d(rhs.squeeze())\n    if rhs.ndim > 1:\n        raise ValueError('The right hand side of the constraint must be a vector.')\n    if len(rhs) != lhs.shape[0]:\n        raise ValueError('The number of rows of the left hand side constraint matrix L must equal the length of the right hand side constraint vector R.')\n    self.lhs = lhs\n    self.rhs = rhs\n    (lhs_u, lhs_s, lhs_vt) = np.linalg.svd(lhs.T, full_matrices=1)\n    self.lhs0 = lhs_u[:, len(lhs_s):]\n    self.lhs1 = lhs_u[:, 0:len(lhs_s)]\n    self.lhsf = np.hstack((self.lhs0, self.lhs1))\n    self.param0 = np.dot(self.lhs1, np.dot(lhs_vt, self.rhs) / lhs_s)\n    self._offset_increment = np.dot(exog, self.param0)\n    self.orig_exog = exog\n    self.exog_fulltrans = np.dot(exog, self.lhsf)",
            "def __init__(self, lhs, rhs, exog):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Parameters\\n        ----------\\n        lhs : ndarray\\n           A q x p matrix which is the left hand side of the\\n           constraint lhs * param = rhs.  The number of constraints is\\n           q >= 1 and p is the dimension of the parameter vector.\\n        rhs : ndarray\\n          A 1-dimensional vector of length q which is the right hand\\n          side of the constraint equation.\\n        exog : ndarray\\n          The n x p exognenous data for the full model.\\n        '\n    rhs = np.atleast_1d(rhs.squeeze())\n    if rhs.ndim > 1:\n        raise ValueError('The right hand side of the constraint must be a vector.')\n    if len(rhs) != lhs.shape[0]:\n        raise ValueError('The number of rows of the left hand side constraint matrix L must equal the length of the right hand side constraint vector R.')\n    self.lhs = lhs\n    self.rhs = rhs\n    (lhs_u, lhs_s, lhs_vt) = np.linalg.svd(lhs.T, full_matrices=1)\n    self.lhs0 = lhs_u[:, len(lhs_s):]\n    self.lhs1 = lhs_u[:, 0:len(lhs_s)]\n    self.lhsf = np.hstack((self.lhs0, self.lhs1))\n    self.param0 = np.dot(self.lhs1, np.dot(lhs_vt, self.rhs) / lhs_s)\n    self._offset_increment = np.dot(exog, self.param0)\n    self.orig_exog = exog\n    self.exog_fulltrans = np.dot(exog, self.lhsf)",
            "def __init__(self, lhs, rhs, exog):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Parameters\\n        ----------\\n        lhs : ndarray\\n           A q x p matrix which is the left hand side of the\\n           constraint lhs * param = rhs.  The number of constraints is\\n           q >= 1 and p is the dimension of the parameter vector.\\n        rhs : ndarray\\n          A 1-dimensional vector of length q which is the right hand\\n          side of the constraint equation.\\n        exog : ndarray\\n          The n x p exognenous data for the full model.\\n        '\n    rhs = np.atleast_1d(rhs.squeeze())\n    if rhs.ndim > 1:\n        raise ValueError('The right hand side of the constraint must be a vector.')\n    if len(rhs) != lhs.shape[0]:\n        raise ValueError('The number of rows of the left hand side constraint matrix L must equal the length of the right hand side constraint vector R.')\n    self.lhs = lhs\n    self.rhs = rhs\n    (lhs_u, lhs_s, lhs_vt) = np.linalg.svd(lhs.T, full_matrices=1)\n    self.lhs0 = lhs_u[:, len(lhs_s):]\n    self.lhs1 = lhs_u[:, 0:len(lhs_s)]\n    self.lhsf = np.hstack((self.lhs0, self.lhs1))\n    self.param0 = np.dot(self.lhs1, np.dot(lhs_vt, self.rhs) / lhs_s)\n    self._offset_increment = np.dot(exog, self.param0)\n    self.orig_exog = exog\n    self.exog_fulltrans = np.dot(exog, self.lhsf)",
            "def __init__(self, lhs, rhs, exog):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Parameters\\n        ----------\\n        lhs : ndarray\\n           A q x p matrix which is the left hand side of the\\n           constraint lhs * param = rhs.  The number of constraints is\\n           q >= 1 and p is the dimension of the parameter vector.\\n        rhs : ndarray\\n          A 1-dimensional vector of length q which is the right hand\\n          side of the constraint equation.\\n        exog : ndarray\\n          The n x p exognenous data for the full model.\\n        '\n    rhs = np.atleast_1d(rhs.squeeze())\n    if rhs.ndim > 1:\n        raise ValueError('The right hand side of the constraint must be a vector.')\n    if len(rhs) != lhs.shape[0]:\n        raise ValueError('The number of rows of the left hand side constraint matrix L must equal the length of the right hand side constraint vector R.')\n    self.lhs = lhs\n    self.rhs = rhs\n    (lhs_u, lhs_s, lhs_vt) = np.linalg.svd(lhs.T, full_matrices=1)\n    self.lhs0 = lhs_u[:, len(lhs_s):]\n    self.lhs1 = lhs_u[:, 0:len(lhs_s)]\n    self.lhsf = np.hstack((self.lhs0, self.lhs1))\n    self.param0 = np.dot(self.lhs1, np.dot(lhs_vt, self.rhs) / lhs_s)\n    self._offset_increment = np.dot(exog, self.param0)\n    self.orig_exog = exog\n    self.exog_fulltrans = np.dot(exog, self.lhsf)",
            "def __init__(self, lhs, rhs, exog):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Parameters\\n        ----------\\n        lhs : ndarray\\n           A q x p matrix which is the left hand side of the\\n           constraint lhs * param = rhs.  The number of constraints is\\n           q >= 1 and p is the dimension of the parameter vector.\\n        rhs : ndarray\\n          A 1-dimensional vector of length q which is the right hand\\n          side of the constraint equation.\\n        exog : ndarray\\n          The n x p exognenous data for the full model.\\n        '\n    rhs = np.atleast_1d(rhs.squeeze())\n    if rhs.ndim > 1:\n        raise ValueError('The right hand side of the constraint must be a vector.')\n    if len(rhs) != lhs.shape[0]:\n        raise ValueError('The number of rows of the left hand side constraint matrix L must equal the length of the right hand side constraint vector R.')\n    self.lhs = lhs\n    self.rhs = rhs\n    (lhs_u, lhs_s, lhs_vt) = np.linalg.svd(lhs.T, full_matrices=1)\n    self.lhs0 = lhs_u[:, len(lhs_s):]\n    self.lhs1 = lhs_u[:, 0:len(lhs_s)]\n    self.lhsf = np.hstack((self.lhs0, self.lhs1))\n    self.param0 = np.dot(self.lhs1, np.dot(lhs_vt, self.rhs) / lhs_s)\n    self._offset_increment = np.dot(exog, self.param0)\n    self.orig_exog = exog\n    self.exog_fulltrans = np.dot(exog, self.lhsf)"
        ]
    },
    {
        "func_name": "offset_increment",
        "original": "def offset_increment(self):\n    \"\"\"\n        Returns a vector that should be added to the offset vector to\n        accommodate the constraint.\n\n        Parameters\n        ----------\n        exog : array_like\n           The exogeneous data for the model.\n        \"\"\"\n    return self._offset_increment",
        "mutated": [
            "def offset_increment(self):\n    if False:\n        i = 10\n    '\\n        Returns a vector that should be added to the offset vector to\\n        accommodate the constraint.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data for the model.\\n        '\n    return self._offset_increment",
            "def offset_increment(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns a vector that should be added to the offset vector to\\n        accommodate the constraint.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data for the model.\\n        '\n    return self._offset_increment",
            "def offset_increment(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns a vector that should be added to the offset vector to\\n        accommodate the constraint.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data for the model.\\n        '\n    return self._offset_increment",
            "def offset_increment(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns a vector that should be added to the offset vector to\\n        accommodate the constraint.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data for the model.\\n        '\n    return self._offset_increment",
            "def offset_increment(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns a vector that should be added to the offset vector to\\n        accommodate the constraint.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data for the model.\\n        '\n    return self._offset_increment"
        ]
    },
    {
        "func_name": "reduced_exog",
        "original": "def reduced_exog(self):\n    \"\"\"\n        Returns a linearly transformed exog matrix whose columns span\n        the constrained model space.\n\n        Parameters\n        ----------\n        exog : array_like\n           The exogeneous data for the model.\n        \"\"\"\n    return self.exog_fulltrans[:, 0:self.lhs0.shape[1]]",
        "mutated": [
            "def reduced_exog(self):\n    if False:\n        i = 10\n    '\\n        Returns a linearly transformed exog matrix whose columns span\\n        the constrained model space.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data for the model.\\n        '\n    return self.exog_fulltrans[:, 0:self.lhs0.shape[1]]",
            "def reduced_exog(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns a linearly transformed exog matrix whose columns span\\n        the constrained model space.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data for the model.\\n        '\n    return self.exog_fulltrans[:, 0:self.lhs0.shape[1]]",
            "def reduced_exog(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns a linearly transformed exog matrix whose columns span\\n        the constrained model space.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data for the model.\\n        '\n    return self.exog_fulltrans[:, 0:self.lhs0.shape[1]]",
            "def reduced_exog(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns a linearly transformed exog matrix whose columns span\\n        the constrained model space.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data for the model.\\n        '\n    return self.exog_fulltrans[:, 0:self.lhs0.shape[1]]",
            "def reduced_exog(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns a linearly transformed exog matrix whose columns span\\n        the constrained model space.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data for the model.\\n        '\n    return self.exog_fulltrans[:, 0:self.lhs0.shape[1]]"
        ]
    },
    {
        "func_name": "restore_exog",
        "original": "def restore_exog(self):\n    \"\"\"\n        Returns the full exog matrix before it was reduced to\n        satisfy the constraint.\n        \"\"\"\n    return self.orig_exog",
        "mutated": [
            "def restore_exog(self):\n    if False:\n        i = 10\n    '\\n        Returns the full exog matrix before it was reduced to\\n        satisfy the constraint.\\n        '\n    return self.orig_exog",
            "def restore_exog(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the full exog matrix before it was reduced to\\n        satisfy the constraint.\\n        '\n    return self.orig_exog",
            "def restore_exog(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the full exog matrix before it was reduced to\\n        satisfy the constraint.\\n        '\n    return self.orig_exog",
            "def restore_exog(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the full exog matrix before it was reduced to\\n        satisfy the constraint.\\n        '\n    return self.orig_exog",
            "def restore_exog(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the full exog matrix before it was reduced to\\n        satisfy the constraint.\\n        '\n    return self.orig_exog"
        ]
    },
    {
        "func_name": "unpack_param",
        "original": "def unpack_param(self, params):\n    \"\"\"\n        Converts the parameter vector `params` from reduced to full\n        coordinates.\n        \"\"\"\n    return self.param0 + np.dot(self.lhs0, params)",
        "mutated": [
            "def unpack_param(self, params):\n    if False:\n        i = 10\n    '\\n        Converts the parameter vector `params` from reduced to full\\n        coordinates.\\n        '\n    return self.param0 + np.dot(self.lhs0, params)",
            "def unpack_param(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Converts the parameter vector `params` from reduced to full\\n        coordinates.\\n        '\n    return self.param0 + np.dot(self.lhs0, params)",
            "def unpack_param(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Converts the parameter vector `params` from reduced to full\\n        coordinates.\\n        '\n    return self.param0 + np.dot(self.lhs0, params)",
            "def unpack_param(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Converts the parameter vector `params` from reduced to full\\n        coordinates.\\n        '\n    return self.param0 + np.dot(self.lhs0, params)",
            "def unpack_param(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Converts the parameter vector `params` from reduced to full\\n        coordinates.\\n        '\n    return self.param0 + np.dot(self.lhs0, params)"
        ]
    },
    {
        "func_name": "unpack_cov",
        "original": "def unpack_cov(self, bcov):\n    \"\"\"\n        Converts the covariance matrix `bcov` from reduced to full\n        coordinates.\n        \"\"\"\n    return np.dot(self.lhs0, np.dot(bcov, self.lhs0.T))",
        "mutated": [
            "def unpack_cov(self, bcov):\n    if False:\n        i = 10\n    '\\n        Converts the covariance matrix `bcov` from reduced to full\\n        coordinates.\\n        '\n    return np.dot(self.lhs0, np.dot(bcov, self.lhs0.T))",
            "def unpack_cov(self, bcov):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Converts the covariance matrix `bcov` from reduced to full\\n        coordinates.\\n        '\n    return np.dot(self.lhs0, np.dot(bcov, self.lhs0.T))",
            "def unpack_cov(self, bcov):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Converts the covariance matrix `bcov` from reduced to full\\n        coordinates.\\n        '\n    return np.dot(self.lhs0, np.dot(bcov, self.lhs0.T))",
            "def unpack_cov(self, bcov):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Converts the covariance matrix `bcov` from reduced to full\\n        coordinates.\\n        '\n    return np.dot(self.lhs0, np.dot(bcov, self.lhs0.T))",
            "def unpack_cov(self, bcov):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Converts the covariance matrix `bcov` from reduced to full\\n        coordinates.\\n        '\n    return np.dot(self.lhs0, np.dot(bcov, self.lhs0.T))"
        ]
    },
    {
        "func_name": "_check_args",
        "original": "def _check_args(endog, exog, groups, time, offset, exposure):\n    if endog.size != exog.shape[0]:\n        raise ValueError(\"Leading dimension of 'exog' should match length of 'endog'\")\n    if groups.size != endog.size:\n        raise ValueError(\"'groups' and 'endog' should have the same size\")\n    if time is not None and time.size != endog.size:\n        raise ValueError(\"'time' and 'endog' should have the same size\")\n    if offset is not None and offset.size != endog.size:\n        raise ValueError(\"'offset and 'endog' should have the same size\")\n    if exposure is not None and exposure.size != endog.size:\n        raise ValueError(\"'exposure' and 'endog' should have the same size\")",
        "mutated": [
            "def _check_args(endog, exog, groups, time, offset, exposure):\n    if False:\n        i = 10\n    if endog.size != exog.shape[0]:\n        raise ValueError(\"Leading dimension of 'exog' should match length of 'endog'\")\n    if groups.size != endog.size:\n        raise ValueError(\"'groups' and 'endog' should have the same size\")\n    if time is not None and time.size != endog.size:\n        raise ValueError(\"'time' and 'endog' should have the same size\")\n    if offset is not None and offset.size != endog.size:\n        raise ValueError(\"'offset and 'endog' should have the same size\")\n    if exposure is not None and exposure.size != endog.size:\n        raise ValueError(\"'exposure' and 'endog' should have the same size\")",
            "def _check_args(endog, exog, groups, time, offset, exposure):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if endog.size != exog.shape[0]:\n        raise ValueError(\"Leading dimension of 'exog' should match length of 'endog'\")\n    if groups.size != endog.size:\n        raise ValueError(\"'groups' and 'endog' should have the same size\")\n    if time is not None and time.size != endog.size:\n        raise ValueError(\"'time' and 'endog' should have the same size\")\n    if offset is not None and offset.size != endog.size:\n        raise ValueError(\"'offset and 'endog' should have the same size\")\n    if exposure is not None and exposure.size != endog.size:\n        raise ValueError(\"'exposure' and 'endog' should have the same size\")",
            "def _check_args(endog, exog, groups, time, offset, exposure):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if endog.size != exog.shape[0]:\n        raise ValueError(\"Leading dimension of 'exog' should match length of 'endog'\")\n    if groups.size != endog.size:\n        raise ValueError(\"'groups' and 'endog' should have the same size\")\n    if time is not None and time.size != endog.size:\n        raise ValueError(\"'time' and 'endog' should have the same size\")\n    if offset is not None and offset.size != endog.size:\n        raise ValueError(\"'offset and 'endog' should have the same size\")\n    if exposure is not None and exposure.size != endog.size:\n        raise ValueError(\"'exposure' and 'endog' should have the same size\")",
            "def _check_args(endog, exog, groups, time, offset, exposure):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if endog.size != exog.shape[0]:\n        raise ValueError(\"Leading dimension of 'exog' should match length of 'endog'\")\n    if groups.size != endog.size:\n        raise ValueError(\"'groups' and 'endog' should have the same size\")\n    if time is not None and time.size != endog.size:\n        raise ValueError(\"'time' and 'endog' should have the same size\")\n    if offset is not None and offset.size != endog.size:\n        raise ValueError(\"'offset and 'endog' should have the same size\")\n    if exposure is not None and exposure.size != endog.size:\n        raise ValueError(\"'exposure' and 'endog' should have the same size\")",
            "def _check_args(endog, exog, groups, time, offset, exposure):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if endog.size != exog.shape[0]:\n        raise ValueError(\"Leading dimension of 'exog' should match length of 'endog'\")\n    if groups.size != endog.size:\n        raise ValueError(\"'groups' and 'endog' should have the same size\")\n    if time is not None and time.size != endog.size:\n        raise ValueError(\"'time' and 'endog' should have the same size\")\n    if offset is not None and offset.size != endog.size:\n        raise ValueError(\"'offset and 'endog' should have the same size\")\n    if exposure is not None and exposure.size != endog.size:\n        raise ValueError(\"'exposure' and 'endog' should have the same size\")"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, exposure=None, dep_data=None, constraint=None, update_dep=True, weights=None, **kwargs):\n    if type(self) is GEE:\n        self._check_kwargs(kwargs)\n    if family is not None:\n        if not isinstance(family.link, tuple(family.safe_links)):\n            msg = 'The {0} link function does not respect the domain of the {1} family.'\n            warnings.warn(msg.format(family.link.__class__.__name__, family.__class__.__name__), DomainWarning)\n    groups = np.asarray(groups)\n    if 'missing_idx' in kwargs and kwargs['missing_idx'] is not None:\n        ii = ~kwargs['missing_idx']\n        groups = groups[ii]\n        if time is not None:\n            time = time[ii]\n        if offset is not None:\n            offset = offset[ii]\n        if exposure is not None:\n            exposure = exposure[ii]\n        del kwargs['missing_idx']\n    self.missing = missing\n    self.dep_data = dep_data\n    self.constraint = constraint\n    self.update_dep = update_dep\n    self._fit_history = defaultdict(list)\n    super(GEE, self).__init__(endog, exog, groups=groups, time=time, offset=offset, exposure=exposure, weights=weights, dep_data=dep_data, missing=missing, family=family, **kwargs)\n    _check_args(self.endog, self.exog, self.groups, self.time, getattr(self, 'offset', None), getattr(self, 'exposure', None))\n    self._init_keys.extend(['update_dep', 'constraint', 'family', 'cov_struct'])\n    try:\n        self._init_keys.remove('freq_weights')\n        self._init_keys.remove('var_weights')\n    except ValueError:\n        pass\n    if family is None:\n        family = families.Gaussian()\n    elif not issubclass(family.__class__, families.Family):\n        raise ValueError('GEE: `family` must be a genmod family instance')\n    self.family = family\n    if cov_struct is None:\n        cov_struct = cov_structs.Independence()\n    elif not issubclass(cov_struct.__class__, cov_structs.CovStruct):\n        raise ValueError('GEE: `cov_struct` must be a genmod cov_struct instance')\n    self.cov_struct = cov_struct\n    self.constraint = None\n    if constraint is not None:\n        if len(constraint) != 2:\n            raise ValueError('GEE: `constraint` must be a 2-tuple.')\n        if constraint[0].shape[1] != self.exog.shape[1]:\n            raise ValueError('GEE: the left hand side of the constraint must have the same number of columns as the exog matrix.')\n        self.constraint = ParameterConstraint(constraint[0], constraint[1], self.exog)\n        if self._offset_exposure is not None:\n            self._offset_exposure += self.constraint.offset_increment()\n        else:\n            self._offset_exposure = self.constraint.offset_increment().copy()\n        self.exog = self.constraint.reduced_exog()\n    (group_labels, ix) = np.unique(self.groups, return_inverse=True)\n    se = pd.Series(index=np.arange(len(ix)), dtype='int')\n    gb = se.groupby(ix).groups\n    dk = [(lb, np.asarray(gb[k])) for (k, lb) in enumerate(group_labels)]\n    self.group_indices = dict(dk)\n    self.group_labels = group_labels\n    self.endog_li = self.cluster_list(self.endog)\n    self.exog_li = self.cluster_list(self.exog)\n    if self.weights is not None:\n        self.weights_li = self.cluster_list(self.weights)\n    self.num_group = len(self.endog_li)\n    if self.time is not None:\n        if self.time.ndim == 1:\n            self.time = self.time[:, None]\n        self.time_li = self.cluster_list(self.time)\n    else:\n        self.time_li = [np.arange(len(y), dtype=np.float64)[:, None] for y in self.endog_li]\n        self.time = np.concatenate(self.time_li)\n    if self._offset_exposure is None or (np.isscalar(self._offset_exposure) and self._offset_exposure == 0.0):\n        self.offset_li = None\n    else:\n        self.offset_li = self.cluster_list(self._offset_exposure)\n    if constraint is not None:\n        self.constraint.exog_fulltrans_li = self.cluster_list(self.constraint.exog_fulltrans)\n    self.family = family\n    self.cov_struct.initialize(self)\n    group_ns = [len(y) for y in self.endog_li]\n    self.nobs = sum(group_ns)\n    self.df_model = self.exog.shape[1] - 1\n    self.df_resid = self.nobs - self.exog.shape[1]\n    maxgroup = max([len(x) for x in self.endog_li])\n    if maxgroup == 1:\n        self.update_dep = False",
        "mutated": [
            "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, exposure=None, dep_data=None, constraint=None, update_dep=True, weights=None, **kwargs):\n    if False:\n        i = 10\n    if type(self) is GEE:\n        self._check_kwargs(kwargs)\n    if family is not None:\n        if not isinstance(family.link, tuple(family.safe_links)):\n            msg = 'The {0} link function does not respect the domain of the {1} family.'\n            warnings.warn(msg.format(family.link.__class__.__name__, family.__class__.__name__), DomainWarning)\n    groups = np.asarray(groups)\n    if 'missing_idx' in kwargs and kwargs['missing_idx'] is not None:\n        ii = ~kwargs['missing_idx']\n        groups = groups[ii]\n        if time is not None:\n            time = time[ii]\n        if offset is not None:\n            offset = offset[ii]\n        if exposure is not None:\n            exposure = exposure[ii]\n        del kwargs['missing_idx']\n    self.missing = missing\n    self.dep_data = dep_data\n    self.constraint = constraint\n    self.update_dep = update_dep\n    self._fit_history = defaultdict(list)\n    super(GEE, self).__init__(endog, exog, groups=groups, time=time, offset=offset, exposure=exposure, weights=weights, dep_data=dep_data, missing=missing, family=family, **kwargs)\n    _check_args(self.endog, self.exog, self.groups, self.time, getattr(self, 'offset', None), getattr(self, 'exposure', None))\n    self._init_keys.extend(['update_dep', 'constraint', 'family', 'cov_struct'])\n    try:\n        self._init_keys.remove('freq_weights')\n        self._init_keys.remove('var_weights')\n    except ValueError:\n        pass\n    if family is None:\n        family = families.Gaussian()\n    elif not issubclass(family.__class__, families.Family):\n        raise ValueError('GEE: `family` must be a genmod family instance')\n    self.family = family\n    if cov_struct is None:\n        cov_struct = cov_structs.Independence()\n    elif not issubclass(cov_struct.__class__, cov_structs.CovStruct):\n        raise ValueError('GEE: `cov_struct` must be a genmod cov_struct instance')\n    self.cov_struct = cov_struct\n    self.constraint = None\n    if constraint is not None:\n        if len(constraint) != 2:\n            raise ValueError('GEE: `constraint` must be a 2-tuple.')\n        if constraint[0].shape[1] != self.exog.shape[1]:\n            raise ValueError('GEE: the left hand side of the constraint must have the same number of columns as the exog matrix.')\n        self.constraint = ParameterConstraint(constraint[0], constraint[1], self.exog)\n        if self._offset_exposure is not None:\n            self._offset_exposure += self.constraint.offset_increment()\n        else:\n            self._offset_exposure = self.constraint.offset_increment().copy()\n        self.exog = self.constraint.reduced_exog()\n    (group_labels, ix) = np.unique(self.groups, return_inverse=True)\n    se = pd.Series(index=np.arange(len(ix)), dtype='int')\n    gb = se.groupby(ix).groups\n    dk = [(lb, np.asarray(gb[k])) for (k, lb) in enumerate(group_labels)]\n    self.group_indices = dict(dk)\n    self.group_labels = group_labels\n    self.endog_li = self.cluster_list(self.endog)\n    self.exog_li = self.cluster_list(self.exog)\n    if self.weights is not None:\n        self.weights_li = self.cluster_list(self.weights)\n    self.num_group = len(self.endog_li)\n    if self.time is not None:\n        if self.time.ndim == 1:\n            self.time = self.time[:, None]\n        self.time_li = self.cluster_list(self.time)\n    else:\n        self.time_li = [np.arange(len(y), dtype=np.float64)[:, None] for y in self.endog_li]\n        self.time = np.concatenate(self.time_li)\n    if self._offset_exposure is None or (np.isscalar(self._offset_exposure) and self._offset_exposure == 0.0):\n        self.offset_li = None\n    else:\n        self.offset_li = self.cluster_list(self._offset_exposure)\n    if constraint is not None:\n        self.constraint.exog_fulltrans_li = self.cluster_list(self.constraint.exog_fulltrans)\n    self.family = family\n    self.cov_struct.initialize(self)\n    group_ns = [len(y) for y in self.endog_li]\n    self.nobs = sum(group_ns)\n    self.df_model = self.exog.shape[1] - 1\n    self.df_resid = self.nobs - self.exog.shape[1]\n    maxgroup = max([len(x) for x in self.endog_li])\n    if maxgroup == 1:\n        self.update_dep = False",
            "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, exposure=None, dep_data=None, constraint=None, update_dep=True, weights=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if type(self) is GEE:\n        self._check_kwargs(kwargs)\n    if family is not None:\n        if not isinstance(family.link, tuple(family.safe_links)):\n            msg = 'The {0} link function does not respect the domain of the {1} family.'\n            warnings.warn(msg.format(family.link.__class__.__name__, family.__class__.__name__), DomainWarning)\n    groups = np.asarray(groups)\n    if 'missing_idx' in kwargs and kwargs['missing_idx'] is not None:\n        ii = ~kwargs['missing_idx']\n        groups = groups[ii]\n        if time is not None:\n            time = time[ii]\n        if offset is not None:\n            offset = offset[ii]\n        if exposure is not None:\n            exposure = exposure[ii]\n        del kwargs['missing_idx']\n    self.missing = missing\n    self.dep_data = dep_data\n    self.constraint = constraint\n    self.update_dep = update_dep\n    self._fit_history = defaultdict(list)\n    super(GEE, self).__init__(endog, exog, groups=groups, time=time, offset=offset, exposure=exposure, weights=weights, dep_data=dep_data, missing=missing, family=family, **kwargs)\n    _check_args(self.endog, self.exog, self.groups, self.time, getattr(self, 'offset', None), getattr(self, 'exposure', None))\n    self._init_keys.extend(['update_dep', 'constraint', 'family', 'cov_struct'])\n    try:\n        self._init_keys.remove('freq_weights')\n        self._init_keys.remove('var_weights')\n    except ValueError:\n        pass\n    if family is None:\n        family = families.Gaussian()\n    elif not issubclass(family.__class__, families.Family):\n        raise ValueError('GEE: `family` must be a genmod family instance')\n    self.family = family\n    if cov_struct is None:\n        cov_struct = cov_structs.Independence()\n    elif not issubclass(cov_struct.__class__, cov_structs.CovStruct):\n        raise ValueError('GEE: `cov_struct` must be a genmod cov_struct instance')\n    self.cov_struct = cov_struct\n    self.constraint = None\n    if constraint is not None:\n        if len(constraint) != 2:\n            raise ValueError('GEE: `constraint` must be a 2-tuple.')\n        if constraint[0].shape[1] != self.exog.shape[1]:\n            raise ValueError('GEE: the left hand side of the constraint must have the same number of columns as the exog matrix.')\n        self.constraint = ParameterConstraint(constraint[0], constraint[1], self.exog)\n        if self._offset_exposure is not None:\n            self._offset_exposure += self.constraint.offset_increment()\n        else:\n            self._offset_exposure = self.constraint.offset_increment().copy()\n        self.exog = self.constraint.reduced_exog()\n    (group_labels, ix) = np.unique(self.groups, return_inverse=True)\n    se = pd.Series(index=np.arange(len(ix)), dtype='int')\n    gb = se.groupby(ix).groups\n    dk = [(lb, np.asarray(gb[k])) for (k, lb) in enumerate(group_labels)]\n    self.group_indices = dict(dk)\n    self.group_labels = group_labels\n    self.endog_li = self.cluster_list(self.endog)\n    self.exog_li = self.cluster_list(self.exog)\n    if self.weights is not None:\n        self.weights_li = self.cluster_list(self.weights)\n    self.num_group = len(self.endog_li)\n    if self.time is not None:\n        if self.time.ndim == 1:\n            self.time = self.time[:, None]\n        self.time_li = self.cluster_list(self.time)\n    else:\n        self.time_li = [np.arange(len(y), dtype=np.float64)[:, None] for y in self.endog_li]\n        self.time = np.concatenate(self.time_li)\n    if self._offset_exposure is None or (np.isscalar(self._offset_exposure) and self._offset_exposure == 0.0):\n        self.offset_li = None\n    else:\n        self.offset_li = self.cluster_list(self._offset_exposure)\n    if constraint is not None:\n        self.constraint.exog_fulltrans_li = self.cluster_list(self.constraint.exog_fulltrans)\n    self.family = family\n    self.cov_struct.initialize(self)\n    group_ns = [len(y) for y in self.endog_li]\n    self.nobs = sum(group_ns)\n    self.df_model = self.exog.shape[1] - 1\n    self.df_resid = self.nobs - self.exog.shape[1]\n    maxgroup = max([len(x) for x in self.endog_li])\n    if maxgroup == 1:\n        self.update_dep = False",
            "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, exposure=None, dep_data=None, constraint=None, update_dep=True, weights=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if type(self) is GEE:\n        self._check_kwargs(kwargs)\n    if family is not None:\n        if not isinstance(family.link, tuple(family.safe_links)):\n            msg = 'The {0} link function does not respect the domain of the {1} family.'\n            warnings.warn(msg.format(family.link.__class__.__name__, family.__class__.__name__), DomainWarning)\n    groups = np.asarray(groups)\n    if 'missing_idx' in kwargs and kwargs['missing_idx'] is not None:\n        ii = ~kwargs['missing_idx']\n        groups = groups[ii]\n        if time is not None:\n            time = time[ii]\n        if offset is not None:\n            offset = offset[ii]\n        if exposure is not None:\n            exposure = exposure[ii]\n        del kwargs['missing_idx']\n    self.missing = missing\n    self.dep_data = dep_data\n    self.constraint = constraint\n    self.update_dep = update_dep\n    self._fit_history = defaultdict(list)\n    super(GEE, self).__init__(endog, exog, groups=groups, time=time, offset=offset, exposure=exposure, weights=weights, dep_data=dep_data, missing=missing, family=family, **kwargs)\n    _check_args(self.endog, self.exog, self.groups, self.time, getattr(self, 'offset', None), getattr(self, 'exposure', None))\n    self._init_keys.extend(['update_dep', 'constraint', 'family', 'cov_struct'])\n    try:\n        self._init_keys.remove('freq_weights')\n        self._init_keys.remove('var_weights')\n    except ValueError:\n        pass\n    if family is None:\n        family = families.Gaussian()\n    elif not issubclass(family.__class__, families.Family):\n        raise ValueError('GEE: `family` must be a genmod family instance')\n    self.family = family\n    if cov_struct is None:\n        cov_struct = cov_structs.Independence()\n    elif not issubclass(cov_struct.__class__, cov_structs.CovStruct):\n        raise ValueError('GEE: `cov_struct` must be a genmod cov_struct instance')\n    self.cov_struct = cov_struct\n    self.constraint = None\n    if constraint is not None:\n        if len(constraint) != 2:\n            raise ValueError('GEE: `constraint` must be a 2-tuple.')\n        if constraint[0].shape[1] != self.exog.shape[1]:\n            raise ValueError('GEE: the left hand side of the constraint must have the same number of columns as the exog matrix.')\n        self.constraint = ParameterConstraint(constraint[0], constraint[1], self.exog)\n        if self._offset_exposure is not None:\n            self._offset_exposure += self.constraint.offset_increment()\n        else:\n            self._offset_exposure = self.constraint.offset_increment().copy()\n        self.exog = self.constraint.reduced_exog()\n    (group_labels, ix) = np.unique(self.groups, return_inverse=True)\n    se = pd.Series(index=np.arange(len(ix)), dtype='int')\n    gb = se.groupby(ix).groups\n    dk = [(lb, np.asarray(gb[k])) for (k, lb) in enumerate(group_labels)]\n    self.group_indices = dict(dk)\n    self.group_labels = group_labels\n    self.endog_li = self.cluster_list(self.endog)\n    self.exog_li = self.cluster_list(self.exog)\n    if self.weights is not None:\n        self.weights_li = self.cluster_list(self.weights)\n    self.num_group = len(self.endog_li)\n    if self.time is not None:\n        if self.time.ndim == 1:\n            self.time = self.time[:, None]\n        self.time_li = self.cluster_list(self.time)\n    else:\n        self.time_li = [np.arange(len(y), dtype=np.float64)[:, None] for y in self.endog_li]\n        self.time = np.concatenate(self.time_li)\n    if self._offset_exposure is None or (np.isscalar(self._offset_exposure) and self._offset_exposure == 0.0):\n        self.offset_li = None\n    else:\n        self.offset_li = self.cluster_list(self._offset_exposure)\n    if constraint is not None:\n        self.constraint.exog_fulltrans_li = self.cluster_list(self.constraint.exog_fulltrans)\n    self.family = family\n    self.cov_struct.initialize(self)\n    group_ns = [len(y) for y in self.endog_li]\n    self.nobs = sum(group_ns)\n    self.df_model = self.exog.shape[1] - 1\n    self.df_resid = self.nobs - self.exog.shape[1]\n    maxgroup = max([len(x) for x in self.endog_li])\n    if maxgroup == 1:\n        self.update_dep = False",
            "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, exposure=None, dep_data=None, constraint=None, update_dep=True, weights=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if type(self) is GEE:\n        self._check_kwargs(kwargs)\n    if family is not None:\n        if not isinstance(family.link, tuple(family.safe_links)):\n            msg = 'The {0} link function does not respect the domain of the {1} family.'\n            warnings.warn(msg.format(family.link.__class__.__name__, family.__class__.__name__), DomainWarning)\n    groups = np.asarray(groups)\n    if 'missing_idx' in kwargs and kwargs['missing_idx'] is not None:\n        ii = ~kwargs['missing_idx']\n        groups = groups[ii]\n        if time is not None:\n            time = time[ii]\n        if offset is not None:\n            offset = offset[ii]\n        if exposure is not None:\n            exposure = exposure[ii]\n        del kwargs['missing_idx']\n    self.missing = missing\n    self.dep_data = dep_data\n    self.constraint = constraint\n    self.update_dep = update_dep\n    self._fit_history = defaultdict(list)\n    super(GEE, self).__init__(endog, exog, groups=groups, time=time, offset=offset, exposure=exposure, weights=weights, dep_data=dep_data, missing=missing, family=family, **kwargs)\n    _check_args(self.endog, self.exog, self.groups, self.time, getattr(self, 'offset', None), getattr(self, 'exposure', None))\n    self._init_keys.extend(['update_dep', 'constraint', 'family', 'cov_struct'])\n    try:\n        self._init_keys.remove('freq_weights')\n        self._init_keys.remove('var_weights')\n    except ValueError:\n        pass\n    if family is None:\n        family = families.Gaussian()\n    elif not issubclass(family.__class__, families.Family):\n        raise ValueError('GEE: `family` must be a genmod family instance')\n    self.family = family\n    if cov_struct is None:\n        cov_struct = cov_structs.Independence()\n    elif not issubclass(cov_struct.__class__, cov_structs.CovStruct):\n        raise ValueError('GEE: `cov_struct` must be a genmod cov_struct instance')\n    self.cov_struct = cov_struct\n    self.constraint = None\n    if constraint is not None:\n        if len(constraint) != 2:\n            raise ValueError('GEE: `constraint` must be a 2-tuple.')\n        if constraint[0].shape[1] != self.exog.shape[1]:\n            raise ValueError('GEE: the left hand side of the constraint must have the same number of columns as the exog matrix.')\n        self.constraint = ParameterConstraint(constraint[0], constraint[1], self.exog)\n        if self._offset_exposure is not None:\n            self._offset_exposure += self.constraint.offset_increment()\n        else:\n            self._offset_exposure = self.constraint.offset_increment().copy()\n        self.exog = self.constraint.reduced_exog()\n    (group_labels, ix) = np.unique(self.groups, return_inverse=True)\n    se = pd.Series(index=np.arange(len(ix)), dtype='int')\n    gb = se.groupby(ix).groups\n    dk = [(lb, np.asarray(gb[k])) for (k, lb) in enumerate(group_labels)]\n    self.group_indices = dict(dk)\n    self.group_labels = group_labels\n    self.endog_li = self.cluster_list(self.endog)\n    self.exog_li = self.cluster_list(self.exog)\n    if self.weights is not None:\n        self.weights_li = self.cluster_list(self.weights)\n    self.num_group = len(self.endog_li)\n    if self.time is not None:\n        if self.time.ndim == 1:\n            self.time = self.time[:, None]\n        self.time_li = self.cluster_list(self.time)\n    else:\n        self.time_li = [np.arange(len(y), dtype=np.float64)[:, None] for y in self.endog_li]\n        self.time = np.concatenate(self.time_li)\n    if self._offset_exposure is None or (np.isscalar(self._offset_exposure) and self._offset_exposure == 0.0):\n        self.offset_li = None\n    else:\n        self.offset_li = self.cluster_list(self._offset_exposure)\n    if constraint is not None:\n        self.constraint.exog_fulltrans_li = self.cluster_list(self.constraint.exog_fulltrans)\n    self.family = family\n    self.cov_struct.initialize(self)\n    group_ns = [len(y) for y in self.endog_li]\n    self.nobs = sum(group_ns)\n    self.df_model = self.exog.shape[1] - 1\n    self.df_resid = self.nobs - self.exog.shape[1]\n    maxgroup = max([len(x) for x in self.endog_li])\n    if maxgroup == 1:\n        self.update_dep = False",
            "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, exposure=None, dep_data=None, constraint=None, update_dep=True, weights=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if type(self) is GEE:\n        self._check_kwargs(kwargs)\n    if family is not None:\n        if not isinstance(family.link, tuple(family.safe_links)):\n            msg = 'The {0} link function does not respect the domain of the {1} family.'\n            warnings.warn(msg.format(family.link.__class__.__name__, family.__class__.__name__), DomainWarning)\n    groups = np.asarray(groups)\n    if 'missing_idx' in kwargs and kwargs['missing_idx'] is not None:\n        ii = ~kwargs['missing_idx']\n        groups = groups[ii]\n        if time is not None:\n            time = time[ii]\n        if offset is not None:\n            offset = offset[ii]\n        if exposure is not None:\n            exposure = exposure[ii]\n        del kwargs['missing_idx']\n    self.missing = missing\n    self.dep_data = dep_data\n    self.constraint = constraint\n    self.update_dep = update_dep\n    self._fit_history = defaultdict(list)\n    super(GEE, self).__init__(endog, exog, groups=groups, time=time, offset=offset, exposure=exposure, weights=weights, dep_data=dep_data, missing=missing, family=family, **kwargs)\n    _check_args(self.endog, self.exog, self.groups, self.time, getattr(self, 'offset', None), getattr(self, 'exposure', None))\n    self._init_keys.extend(['update_dep', 'constraint', 'family', 'cov_struct'])\n    try:\n        self._init_keys.remove('freq_weights')\n        self._init_keys.remove('var_weights')\n    except ValueError:\n        pass\n    if family is None:\n        family = families.Gaussian()\n    elif not issubclass(family.__class__, families.Family):\n        raise ValueError('GEE: `family` must be a genmod family instance')\n    self.family = family\n    if cov_struct is None:\n        cov_struct = cov_structs.Independence()\n    elif not issubclass(cov_struct.__class__, cov_structs.CovStruct):\n        raise ValueError('GEE: `cov_struct` must be a genmod cov_struct instance')\n    self.cov_struct = cov_struct\n    self.constraint = None\n    if constraint is not None:\n        if len(constraint) != 2:\n            raise ValueError('GEE: `constraint` must be a 2-tuple.')\n        if constraint[0].shape[1] != self.exog.shape[1]:\n            raise ValueError('GEE: the left hand side of the constraint must have the same number of columns as the exog matrix.')\n        self.constraint = ParameterConstraint(constraint[0], constraint[1], self.exog)\n        if self._offset_exposure is not None:\n            self._offset_exposure += self.constraint.offset_increment()\n        else:\n            self._offset_exposure = self.constraint.offset_increment().copy()\n        self.exog = self.constraint.reduced_exog()\n    (group_labels, ix) = np.unique(self.groups, return_inverse=True)\n    se = pd.Series(index=np.arange(len(ix)), dtype='int')\n    gb = se.groupby(ix).groups\n    dk = [(lb, np.asarray(gb[k])) for (k, lb) in enumerate(group_labels)]\n    self.group_indices = dict(dk)\n    self.group_labels = group_labels\n    self.endog_li = self.cluster_list(self.endog)\n    self.exog_li = self.cluster_list(self.exog)\n    if self.weights is not None:\n        self.weights_li = self.cluster_list(self.weights)\n    self.num_group = len(self.endog_li)\n    if self.time is not None:\n        if self.time.ndim == 1:\n            self.time = self.time[:, None]\n        self.time_li = self.cluster_list(self.time)\n    else:\n        self.time_li = [np.arange(len(y), dtype=np.float64)[:, None] for y in self.endog_li]\n        self.time = np.concatenate(self.time_li)\n    if self._offset_exposure is None or (np.isscalar(self._offset_exposure) and self._offset_exposure == 0.0):\n        self.offset_li = None\n    else:\n        self.offset_li = self.cluster_list(self._offset_exposure)\n    if constraint is not None:\n        self.constraint.exog_fulltrans_li = self.cluster_list(self.constraint.exog_fulltrans)\n    self.family = family\n    self.cov_struct.initialize(self)\n    group_ns = [len(y) for y in self.endog_li]\n    self.nobs = sum(group_ns)\n    self.df_model = self.exog.shape[1] - 1\n    self.df_resid = self.nobs - self.exog.shape[1]\n    maxgroup = max([len(x) for x in self.endog_li])\n    if maxgroup == 1:\n        self.update_dep = False"
        ]
    },
    {
        "func_name": "from_formula",
        "original": "@classmethod\ndef from_formula(cls, formula, groups, data, subset=None, time=None, offset=None, exposure=None, *args, **kwargs):\n    '\\n        Create a GEE model instance from a formula and dataframe.\\n\\n        Parameters\\n        ----------\\n        formula : str or generic Formula object\\n            The formula specifying the model\\n        groups : array_like or string\\n            Array of grouping labels.  If a string, this is the name\\n            of a variable in `data` that contains the grouping labels.\\n        data : array_like\\n            The data for the model.\\n        subset : array_like\\n            An array-like object of booleans, integers, or index\\n            values that indicate the subset of the data to used when\\n            fitting the model.\\n        time : array_like or string\\n            The time values, used for dependence structures involving\\n            distances between observations.  If a string, this is the\\n            name of a variable in `data` that contains the time\\n            values.\\n        offset : array_like or string\\n            The offset values, added to the linear predictor.  If a\\n            string, this is the name of a variable in `data` that\\n            contains the offset values.\\n        exposure : array_like or string\\n            The exposure values, only used if the link function is the\\n            logarithm function, in which case the log of `exposure`\\n            is added to the offset (if any).  If a string, this is the\\n            name of a variable in `data` that contains the offset\\n            values.\\n        %(missing_param_doc)s\\n        args : extra arguments\\n            These are passed to the model\\n        kwargs : extra keyword arguments\\n            These are passed to the model with two exceptions. `dep_data`\\n            is processed as described below.  The ``eval_env`` keyword is\\n            passed to patsy. It can be either a\\n            :class:`patsy:patsy.EvalEnvironment` object or an integer\\n            indicating the depth of the namespace to use. For example, the\\n            default ``eval_env=0`` uses the calling namespace.\\n            If you wish to use a \"clean\" environment set ``eval_env=-1``.\\n\\n        Optional arguments\\n        ------------------\\n        dep_data : str or array_like\\n            Data used for estimating the dependence structure.  See\\n            specific dependence structure classes (e.g. Nested) for\\n            details.  If `dep_data` is a string, it is interpreted as\\n            a formula that is applied to `data`. If it is an array, it\\n            must be an array of strings corresponding to column names in\\n            `data`.  Otherwise it must be an array-like with the same\\n            number of rows as data.\\n\\n        Returns\\n        -------\\n        model : GEE model instance\\n\\n        Notes\\n        -----\\n        `data` must define __getitem__ with the keys in the formula\\n        terms args and kwargs are passed on to the model\\n        instantiation. E.g., a numpy structured or rec array, a\\n        dictionary, or a pandas DataFrame.\\n        ' % {'missing_param_doc': base._missing_param_doc}\n    groups_name = 'Groups'\n    if isinstance(groups, str):\n        groups_name = groups\n        groups = data[groups]\n    if isinstance(time, str):\n        time = data[time]\n    if isinstance(offset, str):\n        offset = data[offset]\n    if isinstance(exposure, str):\n        exposure = data[exposure]\n    dep_data = kwargs.get('dep_data')\n    dep_data_names = None\n    if dep_data is not None:\n        if isinstance(dep_data, str):\n            dep_data = patsy.dmatrix(dep_data, data, return_type='dataframe')\n            dep_data_names = dep_data.columns.tolist()\n        else:\n            dep_data_names = list(dep_data)\n            dep_data = data[dep_data]\n        kwargs['dep_data'] = np.asarray(dep_data)\n    family = None\n    if 'family' in kwargs:\n        family = kwargs['family']\n        del kwargs['family']\n    model = super(GEE, cls).from_formula(formula, *args, data=data, subset=subset, groups=groups, time=time, offset=offset, exposure=exposure, family=family, **kwargs)\n    if dep_data_names is not None:\n        model._dep_data_names = dep_data_names\n    model._groups_name = groups_name\n    return model",
        "mutated": [
            "@classmethod\ndef from_formula(cls, formula, groups, data, subset=None, time=None, offset=None, exposure=None, *args, **kwargs):\n    if False:\n        i = 10\n    '\\n        Create a GEE model instance from a formula and dataframe.\\n\\n        Parameters\\n        ----------\\n        formula : str or generic Formula object\\n            The formula specifying the model\\n        groups : array_like or string\\n            Array of grouping labels.  If a string, this is the name\\n            of a variable in `data` that contains the grouping labels.\\n        data : array_like\\n            The data for the model.\\n        subset : array_like\\n            An array-like object of booleans, integers, or index\\n            values that indicate the subset of the data to used when\\n            fitting the model.\\n        time : array_like or string\\n            The time values, used for dependence structures involving\\n            distances between observations.  If a string, this is the\\n            name of a variable in `data` that contains the time\\n            values.\\n        offset : array_like or string\\n            The offset values, added to the linear predictor.  If a\\n            string, this is the name of a variable in `data` that\\n            contains the offset values.\\n        exposure : array_like or string\\n            The exposure values, only used if the link function is the\\n            logarithm function, in which case the log of `exposure`\\n            is added to the offset (if any).  If a string, this is the\\n            name of a variable in `data` that contains the offset\\n            values.\\n        %(missing_param_doc)s\\n        args : extra arguments\\n            These are passed to the model\\n        kwargs : extra keyword arguments\\n            These are passed to the model with two exceptions. `dep_data`\\n            is processed as described below.  The ``eval_env`` keyword is\\n            passed to patsy. It can be either a\\n            :class:`patsy:patsy.EvalEnvironment` object or an integer\\n            indicating the depth of the namespace to use. For example, the\\n            default ``eval_env=0`` uses the calling namespace.\\n            If you wish to use a \"clean\" environment set ``eval_env=-1``.\\n\\n        Optional arguments\\n        ------------------\\n        dep_data : str or array_like\\n            Data used for estimating the dependence structure.  See\\n            specific dependence structure classes (e.g. Nested) for\\n            details.  If `dep_data` is a string, it is interpreted as\\n            a formula that is applied to `data`. If it is an array, it\\n            must be an array of strings corresponding to column names in\\n            `data`.  Otherwise it must be an array-like with the same\\n            number of rows as data.\\n\\n        Returns\\n        -------\\n        model : GEE model instance\\n\\n        Notes\\n        -----\\n        `data` must define __getitem__ with the keys in the formula\\n        terms args and kwargs are passed on to the model\\n        instantiation. E.g., a numpy structured or rec array, a\\n        dictionary, or a pandas DataFrame.\\n        ' % {'missing_param_doc': base._missing_param_doc}\n    groups_name = 'Groups'\n    if isinstance(groups, str):\n        groups_name = groups\n        groups = data[groups]\n    if isinstance(time, str):\n        time = data[time]\n    if isinstance(offset, str):\n        offset = data[offset]\n    if isinstance(exposure, str):\n        exposure = data[exposure]\n    dep_data = kwargs.get('dep_data')\n    dep_data_names = None\n    if dep_data is not None:\n        if isinstance(dep_data, str):\n            dep_data = patsy.dmatrix(dep_data, data, return_type='dataframe')\n            dep_data_names = dep_data.columns.tolist()\n        else:\n            dep_data_names = list(dep_data)\n            dep_data = data[dep_data]\n        kwargs['dep_data'] = np.asarray(dep_data)\n    family = None\n    if 'family' in kwargs:\n        family = kwargs['family']\n        del kwargs['family']\n    model = super(GEE, cls).from_formula(formula, *args, data=data, subset=subset, groups=groups, time=time, offset=offset, exposure=exposure, family=family, **kwargs)\n    if dep_data_names is not None:\n        model._dep_data_names = dep_data_names\n    model._groups_name = groups_name\n    return model",
            "@classmethod\ndef from_formula(cls, formula, groups, data, subset=None, time=None, offset=None, exposure=None, *args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Create a GEE model instance from a formula and dataframe.\\n\\n        Parameters\\n        ----------\\n        formula : str or generic Formula object\\n            The formula specifying the model\\n        groups : array_like or string\\n            Array of grouping labels.  If a string, this is the name\\n            of a variable in `data` that contains the grouping labels.\\n        data : array_like\\n            The data for the model.\\n        subset : array_like\\n            An array-like object of booleans, integers, or index\\n            values that indicate the subset of the data to used when\\n            fitting the model.\\n        time : array_like or string\\n            The time values, used for dependence structures involving\\n            distances between observations.  If a string, this is the\\n            name of a variable in `data` that contains the time\\n            values.\\n        offset : array_like or string\\n            The offset values, added to the linear predictor.  If a\\n            string, this is the name of a variable in `data` that\\n            contains the offset values.\\n        exposure : array_like or string\\n            The exposure values, only used if the link function is the\\n            logarithm function, in which case the log of `exposure`\\n            is added to the offset (if any).  If a string, this is the\\n            name of a variable in `data` that contains the offset\\n            values.\\n        %(missing_param_doc)s\\n        args : extra arguments\\n            These are passed to the model\\n        kwargs : extra keyword arguments\\n            These are passed to the model with two exceptions. `dep_data`\\n            is processed as described below.  The ``eval_env`` keyword is\\n            passed to patsy. It can be either a\\n            :class:`patsy:patsy.EvalEnvironment` object or an integer\\n            indicating the depth of the namespace to use. For example, the\\n            default ``eval_env=0`` uses the calling namespace.\\n            If you wish to use a \"clean\" environment set ``eval_env=-1``.\\n\\n        Optional arguments\\n        ------------------\\n        dep_data : str or array_like\\n            Data used for estimating the dependence structure.  See\\n            specific dependence structure classes (e.g. Nested) for\\n            details.  If `dep_data` is a string, it is interpreted as\\n            a formula that is applied to `data`. If it is an array, it\\n            must be an array of strings corresponding to column names in\\n            `data`.  Otherwise it must be an array-like with the same\\n            number of rows as data.\\n\\n        Returns\\n        -------\\n        model : GEE model instance\\n\\n        Notes\\n        -----\\n        `data` must define __getitem__ with the keys in the formula\\n        terms args and kwargs are passed on to the model\\n        instantiation. E.g., a numpy structured or rec array, a\\n        dictionary, or a pandas DataFrame.\\n        ' % {'missing_param_doc': base._missing_param_doc}\n    groups_name = 'Groups'\n    if isinstance(groups, str):\n        groups_name = groups\n        groups = data[groups]\n    if isinstance(time, str):\n        time = data[time]\n    if isinstance(offset, str):\n        offset = data[offset]\n    if isinstance(exposure, str):\n        exposure = data[exposure]\n    dep_data = kwargs.get('dep_data')\n    dep_data_names = None\n    if dep_data is not None:\n        if isinstance(dep_data, str):\n            dep_data = patsy.dmatrix(dep_data, data, return_type='dataframe')\n            dep_data_names = dep_data.columns.tolist()\n        else:\n            dep_data_names = list(dep_data)\n            dep_data = data[dep_data]\n        kwargs['dep_data'] = np.asarray(dep_data)\n    family = None\n    if 'family' in kwargs:\n        family = kwargs['family']\n        del kwargs['family']\n    model = super(GEE, cls).from_formula(formula, *args, data=data, subset=subset, groups=groups, time=time, offset=offset, exposure=exposure, family=family, **kwargs)\n    if dep_data_names is not None:\n        model._dep_data_names = dep_data_names\n    model._groups_name = groups_name\n    return model",
            "@classmethod\ndef from_formula(cls, formula, groups, data, subset=None, time=None, offset=None, exposure=None, *args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Create a GEE model instance from a formula and dataframe.\\n\\n        Parameters\\n        ----------\\n        formula : str or generic Formula object\\n            The formula specifying the model\\n        groups : array_like or string\\n            Array of grouping labels.  If a string, this is the name\\n            of a variable in `data` that contains the grouping labels.\\n        data : array_like\\n            The data for the model.\\n        subset : array_like\\n            An array-like object of booleans, integers, or index\\n            values that indicate the subset of the data to used when\\n            fitting the model.\\n        time : array_like or string\\n            The time values, used for dependence structures involving\\n            distances between observations.  If a string, this is the\\n            name of a variable in `data` that contains the time\\n            values.\\n        offset : array_like or string\\n            The offset values, added to the linear predictor.  If a\\n            string, this is the name of a variable in `data` that\\n            contains the offset values.\\n        exposure : array_like or string\\n            The exposure values, only used if the link function is the\\n            logarithm function, in which case the log of `exposure`\\n            is added to the offset (if any).  If a string, this is the\\n            name of a variable in `data` that contains the offset\\n            values.\\n        %(missing_param_doc)s\\n        args : extra arguments\\n            These are passed to the model\\n        kwargs : extra keyword arguments\\n            These are passed to the model with two exceptions. `dep_data`\\n            is processed as described below.  The ``eval_env`` keyword is\\n            passed to patsy. It can be either a\\n            :class:`patsy:patsy.EvalEnvironment` object or an integer\\n            indicating the depth of the namespace to use. For example, the\\n            default ``eval_env=0`` uses the calling namespace.\\n            If you wish to use a \"clean\" environment set ``eval_env=-1``.\\n\\n        Optional arguments\\n        ------------------\\n        dep_data : str or array_like\\n            Data used for estimating the dependence structure.  See\\n            specific dependence structure classes (e.g. Nested) for\\n            details.  If `dep_data` is a string, it is interpreted as\\n            a formula that is applied to `data`. If it is an array, it\\n            must be an array of strings corresponding to column names in\\n            `data`.  Otherwise it must be an array-like with the same\\n            number of rows as data.\\n\\n        Returns\\n        -------\\n        model : GEE model instance\\n\\n        Notes\\n        -----\\n        `data` must define __getitem__ with the keys in the formula\\n        terms args and kwargs are passed on to the model\\n        instantiation. E.g., a numpy structured or rec array, a\\n        dictionary, or a pandas DataFrame.\\n        ' % {'missing_param_doc': base._missing_param_doc}\n    groups_name = 'Groups'\n    if isinstance(groups, str):\n        groups_name = groups\n        groups = data[groups]\n    if isinstance(time, str):\n        time = data[time]\n    if isinstance(offset, str):\n        offset = data[offset]\n    if isinstance(exposure, str):\n        exposure = data[exposure]\n    dep_data = kwargs.get('dep_data')\n    dep_data_names = None\n    if dep_data is not None:\n        if isinstance(dep_data, str):\n            dep_data = patsy.dmatrix(dep_data, data, return_type='dataframe')\n            dep_data_names = dep_data.columns.tolist()\n        else:\n            dep_data_names = list(dep_data)\n            dep_data = data[dep_data]\n        kwargs['dep_data'] = np.asarray(dep_data)\n    family = None\n    if 'family' in kwargs:\n        family = kwargs['family']\n        del kwargs['family']\n    model = super(GEE, cls).from_formula(formula, *args, data=data, subset=subset, groups=groups, time=time, offset=offset, exposure=exposure, family=family, **kwargs)\n    if dep_data_names is not None:\n        model._dep_data_names = dep_data_names\n    model._groups_name = groups_name\n    return model",
            "@classmethod\ndef from_formula(cls, formula, groups, data, subset=None, time=None, offset=None, exposure=None, *args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Create a GEE model instance from a formula and dataframe.\\n\\n        Parameters\\n        ----------\\n        formula : str or generic Formula object\\n            The formula specifying the model\\n        groups : array_like or string\\n            Array of grouping labels.  If a string, this is the name\\n            of a variable in `data` that contains the grouping labels.\\n        data : array_like\\n            The data for the model.\\n        subset : array_like\\n            An array-like object of booleans, integers, or index\\n            values that indicate the subset of the data to used when\\n            fitting the model.\\n        time : array_like or string\\n            The time values, used for dependence structures involving\\n            distances between observations.  If a string, this is the\\n            name of a variable in `data` that contains the time\\n            values.\\n        offset : array_like or string\\n            The offset values, added to the linear predictor.  If a\\n            string, this is the name of a variable in `data` that\\n            contains the offset values.\\n        exposure : array_like or string\\n            The exposure values, only used if the link function is the\\n            logarithm function, in which case the log of `exposure`\\n            is added to the offset (if any).  If a string, this is the\\n            name of a variable in `data` that contains the offset\\n            values.\\n        %(missing_param_doc)s\\n        args : extra arguments\\n            These are passed to the model\\n        kwargs : extra keyword arguments\\n            These are passed to the model with two exceptions. `dep_data`\\n            is processed as described below.  The ``eval_env`` keyword is\\n            passed to patsy. It can be either a\\n            :class:`patsy:patsy.EvalEnvironment` object or an integer\\n            indicating the depth of the namespace to use. For example, the\\n            default ``eval_env=0`` uses the calling namespace.\\n            If you wish to use a \"clean\" environment set ``eval_env=-1``.\\n\\n        Optional arguments\\n        ------------------\\n        dep_data : str or array_like\\n            Data used for estimating the dependence structure.  See\\n            specific dependence structure classes (e.g. Nested) for\\n            details.  If `dep_data` is a string, it is interpreted as\\n            a formula that is applied to `data`. If it is an array, it\\n            must be an array of strings corresponding to column names in\\n            `data`.  Otherwise it must be an array-like with the same\\n            number of rows as data.\\n\\n        Returns\\n        -------\\n        model : GEE model instance\\n\\n        Notes\\n        -----\\n        `data` must define __getitem__ with the keys in the formula\\n        terms args and kwargs are passed on to the model\\n        instantiation. E.g., a numpy structured or rec array, a\\n        dictionary, or a pandas DataFrame.\\n        ' % {'missing_param_doc': base._missing_param_doc}\n    groups_name = 'Groups'\n    if isinstance(groups, str):\n        groups_name = groups\n        groups = data[groups]\n    if isinstance(time, str):\n        time = data[time]\n    if isinstance(offset, str):\n        offset = data[offset]\n    if isinstance(exposure, str):\n        exposure = data[exposure]\n    dep_data = kwargs.get('dep_data')\n    dep_data_names = None\n    if dep_data is not None:\n        if isinstance(dep_data, str):\n            dep_data = patsy.dmatrix(dep_data, data, return_type='dataframe')\n            dep_data_names = dep_data.columns.tolist()\n        else:\n            dep_data_names = list(dep_data)\n            dep_data = data[dep_data]\n        kwargs['dep_data'] = np.asarray(dep_data)\n    family = None\n    if 'family' in kwargs:\n        family = kwargs['family']\n        del kwargs['family']\n    model = super(GEE, cls).from_formula(formula, *args, data=data, subset=subset, groups=groups, time=time, offset=offset, exposure=exposure, family=family, **kwargs)\n    if dep_data_names is not None:\n        model._dep_data_names = dep_data_names\n    model._groups_name = groups_name\n    return model",
            "@classmethod\ndef from_formula(cls, formula, groups, data, subset=None, time=None, offset=None, exposure=None, *args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Create a GEE model instance from a formula and dataframe.\\n\\n        Parameters\\n        ----------\\n        formula : str or generic Formula object\\n            The formula specifying the model\\n        groups : array_like or string\\n            Array of grouping labels.  If a string, this is the name\\n            of a variable in `data` that contains the grouping labels.\\n        data : array_like\\n            The data for the model.\\n        subset : array_like\\n            An array-like object of booleans, integers, or index\\n            values that indicate the subset of the data to used when\\n            fitting the model.\\n        time : array_like or string\\n            The time values, used for dependence structures involving\\n            distances between observations.  If a string, this is the\\n            name of a variable in `data` that contains the time\\n            values.\\n        offset : array_like or string\\n            The offset values, added to the linear predictor.  If a\\n            string, this is the name of a variable in `data` that\\n            contains the offset values.\\n        exposure : array_like or string\\n            The exposure values, only used if the link function is the\\n            logarithm function, in which case the log of `exposure`\\n            is added to the offset (if any).  If a string, this is the\\n            name of a variable in `data` that contains the offset\\n            values.\\n        %(missing_param_doc)s\\n        args : extra arguments\\n            These are passed to the model\\n        kwargs : extra keyword arguments\\n            These are passed to the model with two exceptions. `dep_data`\\n            is processed as described below.  The ``eval_env`` keyword is\\n            passed to patsy. It can be either a\\n            :class:`patsy:patsy.EvalEnvironment` object or an integer\\n            indicating the depth of the namespace to use. For example, the\\n            default ``eval_env=0`` uses the calling namespace.\\n            If you wish to use a \"clean\" environment set ``eval_env=-1``.\\n\\n        Optional arguments\\n        ------------------\\n        dep_data : str or array_like\\n            Data used for estimating the dependence structure.  See\\n            specific dependence structure classes (e.g. Nested) for\\n            details.  If `dep_data` is a string, it is interpreted as\\n            a formula that is applied to `data`. If it is an array, it\\n            must be an array of strings corresponding to column names in\\n            `data`.  Otherwise it must be an array-like with the same\\n            number of rows as data.\\n\\n        Returns\\n        -------\\n        model : GEE model instance\\n\\n        Notes\\n        -----\\n        `data` must define __getitem__ with the keys in the formula\\n        terms args and kwargs are passed on to the model\\n        instantiation. E.g., a numpy structured or rec array, a\\n        dictionary, or a pandas DataFrame.\\n        ' % {'missing_param_doc': base._missing_param_doc}\n    groups_name = 'Groups'\n    if isinstance(groups, str):\n        groups_name = groups\n        groups = data[groups]\n    if isinstance(time, str):\n        time = data[time]\n    if isinstance(offset, str):\n        offset = data[offset]\n    if isinstance(exposure, str):\n        exposure = data[exposure]\n    dep_data = kwargs.get('dep_data')\n    dep_data_names = None\n    if dep_data is not None:\n        if isinstance(dep_data, str):\n            dep_data = patsy.dmatrix(dep_data, data, return_type='dataframe')\n            dep_data_names = dep_data.columns.tolist()\n        else:\n            dep_data_names = list(dep_data)\n            dep_data = data[dep_data]\n        kwargs['dep_data'] = np.asarray(dep_data)\n    family = None\n    if 'family' in kwargs:\n        family = kwargs['family']\n        del kwargs['family']\n    model = super(GEE, cls).from_formula(formula, *args, data=data, subset=subset, groups=groups, time=time, offset=offset, exposure=exposure, family=family, **kwargs)\n    if dep_data_names is not None:\n        model._dep_data_names = dep_data_names\n    model._groups_name = groups_name\n    return model"
        ]
    },
    {
        "func_name": "cluster_list",
        "original": "def cluster_list(self, array):\n    \"\"\"\n        Returns `array` split into subarrays corresponding to the\n        cluster structure.\n        \"\"\"\n    if array.ndim == 1:\n        return [np.array(array[self.group_indices[k]]) for k in self.group_labels]\n    else:\n        return [np.array(array[self.group_indices[k], :]) for k in self.group_labels]",
        "mutated": [
            "def cluster_list(self, array):\n    if False:\n        i = 10\n    '\\n        Returns `array` split into subarrays corresponding to the\\n        cluster structure.\\n        '\n    if array.ndim == 1:\n        return [np.array(array[self.group_indices[k]]) for k in self.group_labels]\n    else:\n        return [np.array(array[self.group_indices[k], :]) for k in self.group_labels]",
            "def cluster_list(self, array):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns `array` split into subarrays corresponding to the\\n        cluster structure.\\n        '\n    if array.ndim == 1:\n        return [np.array(array[self.group_indices[k]]) for k in self.group_labels]\n    else:\n        return [np.array(array[self.group_indices[k], :]) for k in self.group_labels]",
            "def cluster_list(self, array):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns `array` split into subarrays corresponding to the\\n        cluster structure.\\n        '\n    if array.ndim == 1:\n        return [np.array(array[self.group_indices[k]]) for k in self.group_labels]\n    else:\n        return [np.array(array[self.group_indices[k], :]) for k in self.group_labels]",
            "def cluster_list(self, array):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns `array` split into subarrays corresponding to the\\n        cluster structure.\\n        '\n    if array.ndim == 1:\n        return [np.array(array[self.group_indices[k]]) for k in self.group_labels]\n    else:\n        return [np.array(array[self.group_indices[k], :]) for k in self.group_labels]",
            "def cluster_list(self, array):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns `array` split into subarrays corresponding to the\\n        cluster structure.\\n        '\n    if array.ndim == 1:\n        return [np.array(array[self.group_indices[k]]) for k in self.group_labels]\n    else:\n        return [np.array(array[self.group_indices[k], :]) for k in self.group_labels]"
        ]
    },
    {
        "func_name": "compare_score_test",
        "original": "def compare_score_test(self, submodel):\n    \"\"\"\n        Perform a score test for the given submodel against this model.\n\n        Parameters\n        ----------\n        submodel : GEEResults instance\n            A fitted GEE model that is a submodel of this model.\n\n        Returns\n        -------\n        A dictionary with keys \"statistic\", \"p-value\", and \"df\",\n        containing the score test statistic, its chi^2 p-value,\n        and the degrees of freedom used to compute the p-value.\n\n        Notes\n        -----\n        The score test can be performed without calling 'fit' on the\n        larger model.  The provided submodel must be obtained from a\n        fitted GEE.\n\n        This method performs the same score test as can be obtained by\n        fitting the GEE with a linear constraint and calling `score_test`\n        on the results.\n\n        References\n        ----------\n        Xu Guo and Wei Pan (2002). \"Small sample performance of the score\n        test in GEE\".\n        http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf\n        \"\"\"\n    self.scaletype = submodel.model.scaletype\n    submod = submodel.model\n    if self.exog.shape[0] != submod.exog.shape[0]:\n        msg = 'Model and submodel have different numbers of cases.'\n        raise ValueError(msg)\n    if self.exog.shape[1] == submod.exog.shape[1]:\n        msg = 'Model and submodel have the same number of variables'\n        warnings.warn(msg)\n    if not isinstance(self.family, type(submod.family)):\n        msg = 'Model and submodel have different GLM families.'\n        warnings.warn(msg)\n    if not isinstance(self.cov_struct, type(submod.cov_struct)):\n        warnings.warn('Model and submodel have different GEE covariance structures.')\n    if not np.equal(self.weights, submod.weights).all():\n        msg = 'Model and submodel should have the same weights.'\n        warnings.warn(msg)\n    (qm, qc) = _score_test_submodel(self, submodel.model)\n    if qm is None:\n        msg = 'The provided model is not a submodel.'\n        raise ValueError(msg)\n    params_ex = np.dot(qm, submodel.params)\n    cov_struct_save = self.cov_struct\n    import copy\n    cached_means_save = copy.deepcopy(self.cached_means)\n    self.cov_struct = submodel.cov_struct\n    self.update_cached_means(params_ex)\n    (_, score) = self._update_mean_params()\n    if score is None:\n        msg = 'Singular matrix encountered in GEE score test'\n        warnings.warn(msg, ConvergenceWarning)\n        return None\n    if not hasattr(self, 'ddof_scale'):\n        self.ddof_scale = self.exog.shape[1]\n    if not hasattr(self, 'scaling_factor'):\n        self.scaling_factor = 1\n    (_, ncov1, cmat) = self._covmat()\n    score2 = np.dot(qc.T, score)\n    try:\n        amat = np.linalg.inv(ncov1)\n    except np.linalg.LinAlgError:\n        amat = np.linalg.pinv(ncov1)\n    bmat_11 = np.dot(qm.T, np.dot(cmat, qm))\n    bmat_22 = np.dot(qc.T, np.dot(cmat, qc))\n    bmat_12 = np.dot(qm.T, np.dot(cmat, qc))\n    amat_11 = np.dot(qm.T, np.dot(amat, qm))\n    amat_12 = np.dot(qm.T, np.dot(amat, qc))\n    try:\n        ab = np.linalg.solve(amat_11, bmat_12)\n    except np.linalg.LinAlgError:\n        ab = np.dot(np.linalg.pinv(amat_11), bmat_12)\n    score_cov = bmat_22 - np.dot(amat_12.T, ab)\n    try:\n        aa = np.linalg.solve(amat_11, amat_12)\n    except np.linalg.LinAlgError:\n        aa = np.dot(np.linalg.pinv(amat_11), amat_12)\n    score_cov -= np.dot(bmat_12.T, aa)\n    try:\n        ab = np.linalg.solve(amat_11, bmat_11)\n    except np.linalg.LinAlgError:\n        ab = np.dot(np.linalg.pinv(amat_11), bmat_11)\n    try:\n        aa = np.linalg.solve(amat_11, amat_12)\n    except np.linalg.LinAlgError:\n        aa = np.dot(np.linalg.pinv(amat_11), amat_12)\n    score_cov += np.dot(amat_12.T, np.dot(ab, aa))\n    self.cov_struct = cov_struct_save\n    self.cached_means = cached_means_save\n    from scipy.stats.distributions import chi2\n    try:\n        sc2 = np.linalg.solve(score_cov, score2)\n    except np.linalg.LinAlgError:\n        sc2 = np.dot(np.linalg.pinv(score_cov), score2)\n    score_statistic = np.dot(score2, sc2)\n    score_df = len(score2)\n    score_pvalue = 1 - chi2.cdf(score_statistic, score_df)\n    return {'statistic': score_statistic, 'df': score_df, 'p-value': score_pvalue}",
        "mutated": [
            "def compare_score_test(self, submodel):\n    if False:\n        i = 10\n    '\\n        Perform a score test for the given submodel against this model.\\n\\n        Parameters\\n        ----------\\n        submodel : GEEResults instance\\n            A fitted GEE model that is a submodel of this model.\\n\\n        Returns\\n        -------\\n        A dictionary with keys \"statistic\", \"p-value\", and \"df\",\\n        containing the score test statistic, its chi^2 p-value,\\n        and the degrees of freedom used to compute the p-value.\\n\\n        Notes\\n        -----\\n        The score test can be performed without calling \\'fit\\' on the\\n        larger model.  The provided submodel must be obtained from a\\n        fitted GEE.\\n\\n        This method performs the same score test as can be obtained by\\n        fitting the GEE with a linear constraint and calling `score_test`\\n        on the results.\\n\\n        References\\n        ----------\\n        Xu Guo and Wei Pan (2002). \"Small sample performance of the score\\n        test in GEE\".\\n        http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf\\n        '\n    self.scaletype = submodel.model.scaletype\n    submod = submodel.model\n    if self.exog.shape[0] != submod.exog.shape[0]:\n        msg = 'Model and submodel have different numbers of cases.'\n        raise ValueError(msg)\n    if self.exog.shape[1] == submod.exog.shape[1]:\n        msg = 'Model and submodel have the same number of variables'\n        warnings.warn(msg)\n    if not isinstance(self.family, type(submod.family)):\n        msg = 'Model and submodel have different GLM families.'\n        warnings.warn(msg)\n    if not isinstance(self.cov_struct, type(submod.cov_struct)):\n        warnings.warn('Model and submodel have different GEE covariance structures.')\n    if not np.equal(self.weights, submod.weights).all():\n        msg = 'Model and submodel should have the same weights.'\n        warnings.warn(msg)\n    (qm, qc) = _score_test_submodel(self, submodel.model)\n    if qm is None:\n        msg = 'The provided model is not a submodel.'\n        raise ValueError(msg)\n    params_ex = np.dot(qm, submodel.params)\n    cov_struct_save = self.cov_struct\n    import copy\n    cached_means_save = copy.deepcopy(self.cached_means)\n    self.cov_struct = submodel.cov_struct\n    self.update_cached_means(params_ex)\n    (_, score) = self._update_mean_params()\n    if score is None:\n        msg = 'Singular matrix encountered in GEE score test'\n        warnings.warn(msg, ConvergenceWarning)\n        return None\n    if not hasattr(self, 'ddof_scale'):\n        self.ddof_scale = self.exog.shape[1]\n    if not hasattr(self, 'scaling_factor'):\n        self.scaling_factor = 1\n    (_, ncov1, cmat) = self._covmat()\n    score2 = np.dot(qc.T, score)\n    try:\n        amat = np.linalg.inv(ncov1)\n    except np.linalg.LinAlgError:\n        amat = np.linalg.pinv(ncov1)\n    bmat_11 = np.dot(qm.T, np.dot(cmat, qm))\n    bmat_22 = np.dot(qc.T, np.dot(cmat, qc))\n    bmat_12 = np.dot(qm.T, np.dot(cmat, qc))\n    amat_11 = np.dot(qm.T, np.dot(amat, qm))\n    amat_12 = np.dot(qm.T, np.dot(amat, qc))\n    try:\n        ab = np.linalg.solve(amat_11, bmat_12)\n    except np.linalg.LinAlgError:\n        ab = np.dot(np.linalg.pinv(amat_11), bmat_12)\n    score_cov = bmat_22 - np.dot(amat_12.T, ab)\n    try:\n        aa = np.linalg.solve(amat_11, amat_12)\n    except np.linalg.LinAlgError:\n        aa = np.dot(np.linalg.pinv(amat_11), amat_12)\n    score_cov -= np.dot(bmat_12.T, aa)\n    try:\n        ab = np.linalg.solve(amat_11, bmat_11)\n    except np.linalg.LinAlgError:\n        ab = np.dot(np.linalg.pinv(amat_11), bmat_11)\n    try:\n        aa = np.linalg.solve(amat_11, amat_12)\n    except np.linalg.LinAlgError:\n        aa = np.dot(np.linalg.pinv(amat_11), amat_12)\n    score_cov += np.dot(amat_12.T, np.dot(ab, aa))\n    self.cov_struct = cov_struct_save\n    self.cached_means = cached_means_save\n    from scipy.stats.distributions import chi2\n    try:\n        sc2 = np.linalg.solve(score_cov, score2)\n    except np.linalg.LinAlgError:\n        sc2 = np.dot(np.linalg.pinv(score_cov), score2)\n    score_statistic = np.dot(score2, sc2)\n    score_df = len(score2)\n    score_pvalue = 1 - chi2.cdf(score_statistic, score_df)\n    return {'statistic': score_statistic, 'df': score_df, 'p-value': score_pvalue}",
            "def compare_score_test(self, submodel):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Perform a score test for the given submodel against this model.\\n\\n        Parameters\\n        ----------\\n        submodel : GEEResults instance\\n            A fitted GEE model that is a submodel of this model.\\n\\n        Returns\\n        -------\\n        A dictionary with keys \"statistic\", \"p-value\", and \"df\",\\n        containing the score test statistic, its chi^2 p-value,\\n        and the degrees of freedom used to compute the p-value.\\n\\n        Notes\\n        -----\\n        The score test can be performed without calling \\'fit\\' on the\\n        larger model.  The provided submodel must be obtained from a\\n        fitted GEE.\\n\\n        This method performs the same score test as can be obtained by\\n        fitting the GEE with a linear constraint and calling `score_test`\\n        on the results.\\n\\n        References\\n        ----------\\n        Xu Guo and Wei Pan (2002). \"Small sample performance of the score\\n        test in GEE\".\\n        http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf\\n        '\n    self.scaletype = submodel.model.scaletype\n    submod = submodel.model\n    if self.exog.shape[0] != submod.exog.shape[0]:\n        msg = 'Model and submodel have different numbers of cases.'\n        raise ValueError(msg)\n    if self.exog.shape[1] == submod.exog.shape[1]:\n        msg = 'Model and submodel have the same number of variables'\n        warnings.warn(msg)\n    if not isinstance(self.family, type(submod.family)):\n        msg = 'Model and submodel have different GLM families.'\n        warnings.warn(msg)\n    if not isinstance(self.cov_struct, type(submod.cov_struct)):\n        warnings.warn('Model and submodel have different GEE covariance structures.')\n    if not np.equal(self.weights, submod.weights).all():\n        msg = 'Model and submodel should have the same weights.'\n        warnings.warn(msg)\n    (qm, qc) = _score_test_submodel(self, submodel.model)\n    if qm is None:\n        msg = 'The provided model is not a submodel.'\n        raise ValueError(msg)\n    params_ex = np.dot(qm, submodel.params)\n    cov_struct_save = self.cov_struct\n    import copy\n    cached_means_save = copy.deepcopy(self.cached_means)\n    self.cov_struct = submodel.cov_struct\n    self.update_cached_means(params_ex)\n    (_, score) = self._update_mean_params()\n    if score is None:\n        msg = 'Singular matrix encountered in GEE score test'\n        warnings.warn(msg, ConvergenceWarning)\n        return None\n    if not hasattr(self, 'ddof_scale'):\n        self.ddof_scale = self.exog.shape[1]\n    if not hasattr(self, 'scaling_factor'):\n        self.scaling_factor = 1\n    (_, ncov1, cmat) = self._covmat()\n    score2 = np.dot(qc.T, score)\n    try:\n        amat = np.linalg.inv(ncov1)\n    except np.linalg.LinAlgError:\n        amat = np.linalg.pinv(ncov1)\n    bmat_11 = np.dot(qm.T, np.dot(cmat, qm))\n    bmat_22 = np.dot(qc.T, np.dot(cmat, qc))\n    bmat_12 = np.dot(qm.T, np.dot(cmat, qc))\n    amat_11 = np.dot(qm.T, np.dot(amat, qm))\n    amat_12 = np.dot(qm.T, np.dot(amat, qc))\n    try:\n        ab = np.linalg.solve(amat_11, bmat_12)\n    except np.linalg.LinAlgError:\n        ab = np.dot(np.linalg.pinv(amat_11), bmat_12)\n    score_cov = bmat_22 - np.dot(amat_12.T, ab)\n    try:\n        aa = np.linalg.solve(amat_11, amat_12)\n    except np.linalg.LinAlgError:\n        aa = np.dot(np.linalg.pinv(amat_11), amat_12)\n    score_cov -= np.dot(bmat_12.T, aa)\n    try:\n        ab = np.linalg.solve(amat_11, bmat_11)\n    except np.linalg.LinAlgError:\n        ab = np.dot(np.linalg.pinv(amat_11), bmat_11)\n    try:\n        aa = np.linalg.solve(amat_11, amat_12)\n    except np.linalg.LinAlgError:\n        aa = np.dot(np.linalg.pinv(amat_11), amat_12)\n    score_cov += np.dot(amat_12.T, np.dot(ab, aa))\n    self.cov_struct = cov_struct_save\n    self.cached_means = cached_means_save\n    from scipy.stats.distributions import chi2\n    try:\n        sc2 = np.linalg.solve(score_cov, score2)\n    except np.linalg.LinAlgError:\n        sc2 = np.dot(np.linalg.pinv(score_cov), score2)\n    score_statistic = np.dot(score2, sc2)\n    score_df = len(score2)\n    score_pvalue = 1 - chi2.cdf(score_statistic, score_df)\n    return {'statistic': score_statistic, 'df': score_df, 'p-value': score_pvalue}",
            "def compare_score_test(self, submodel):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Perform a score test for the given submodel against this model.\\n\\n        Parameters\\n        ----------\\n        submodel : GEEResults instance\\n            A fitted GEE model that is a submodel of this model.\\n\\n        Returns\\n        -------\\n        A dictionary with keys \"statistic\", \"p-value\", and \"df\",\\n        containing the score test statistic, its chi^2 p-value,\\n        and the degrees of freedom used to compute the p-value.\\n\\n        Notes\\n        -----\\n        The score test can be performed without calling \\'fit\\' on the\\n        larger model.  The provided submodel must be obtained from a\\n        fitted GEE.\\n\\n        This method performs the same score test as can be obtained by\\n        fitting the GEE with a linear constraint and calling `score_test`\\n        on the results.\\n\\n        References\\n        ----------\\n        Xu Guo and Wei Pan (2002). \"Small sample performance of the score\\n        test in GEE\".\\n        http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf\\n        '\n    self.scaletype = submodel.model.scaletype\n    submod = submodel.model\n    if self.exog.shape[0] != submod.exog.shape[0]:\n        msg = 'Model and submodel have different numbers of cases.'\n        raise ValueError(msg)\n    if self.exog.shape[1] == submod.exog.shape[1]:\n        msg = 'Model and submodel have the same number of variables'\n        warnings.warn(msg)\n    if not isinstance(self.family, type(submod.family)):\n        msg = 'Model and submodel have different GLM families.'\n        warnings.warn(msg)\n    if not isinstance(self.cov_struct, type(submod.cov_struct)):\n        warnings.warn('Model and submodel have different GEE covariance structures.')\n    if not np.equal(self.weights, submod.weights).all():\n        msg = 'Model and submodel should have the same weights.'\n        warnings.warn(msg)\n    (qm, qc) = _score_test_submodel(self, submodel.model)\n    if qm is None:\n        msg = 'The provided model is not a submodel.'\n        raise ValueError(msg)\n    params_ex = np.dot(qm, submodel.params)\n    cov_struct_save = self.cov_struct\n    import copy\n    cached_means_save = copy.deepcopy(self.cached_means)\n    self.cov_struct = submodel.cov_struct\n    self.update_cached_means(params_ex)\n    (_, score) = self._update_mean_params()\n    if score is None:\n        msg = 'Singular matrix encountered in GEE score test'\n        warnings.warn(msg, ConvergenceWarning)\n        return None\n    if not hasattr(self, 'ddof_scale'):\n        self.ddof_scale = self.exog.shape[1]\n    if not hasattr(self, 'scaling_factor'):\n        self.scaling_factor = 1\n    (_, ncov1, cmat) = self._covmat()\n    score2 = np.dot(qc.T, score)\n    try:\n        amat = np.linalg.inv(ncov1)\n    except np.linalg.LinAlgError:\n        amat = np.linalg.pinv(ncov1)\n    bmat_11 = np.dot(qm.T, np.dot(cmat, qm))\n    bmat_22 = np.dot(qc.T, np.dot(cmat, qc))\n    bmat_12 = np.dot(qm.T, np.dot(cmat, qc))\n    amat_11 = np.dot(qm.T, np.dot(amat, qm))\n    amat_12 = np.dot(qm.T, np.dot(amat, qc))\n    try:\n        ab = np.linalg.solve(amat_11, bmat_12)\n    except np.linalg.LinAlgError:\n        ab = np.dot(np.linalg.pinv(amat_11), bmat_12)\n    score_cov = bmat_22 - np.dot(amat_12.T, ab)\n    try:\n        aa = np.linalg.solve(amat_11, amat_12)\n    except np.linalg.LinAlgError:\n        aa = np.dot(np.linalg.pinv(amat_11), amat_12)\n    score_cov -= np.dot(bmat_12.T, aa)\n    try:\n        ab = np.linalg.solve(amat_11, bmat_11)\n    except np.linalg.LinAlgError:\n        ab = np.dot(np.linalg.pinv(amat_11), bmat_11)\n    try:\n        aa = np.linalg.solve(amat_11, amat_12)\n    except np.linalg.LinAlgError:\n        aa = np.dot(np.linalg.pinv(amat_11), amat_12)\n    score_cov += np.dot(amat_12.T, np.dot(ab, aa))\n    self.cov_struct = cov_struct_save\n    self.cached_means = cached_means_save\n    from scipy.stats.distributions import chi2\n    try:\n        sc2 = np.linalg.solve(score_cov, score2)\n    except np.linalg.LinAlgError:\n        sc2 = np.dot(np.linalg.pinv(score_cov), score2)\n    score_statistic = np.dot(score2, sc2)\n    score_df = len(score2)\n    score_pvalue = 1 - chi2.cdf(score_statistic, score_df)\n    return {'statistic': score_statistic, 'df': score_df, 'p-value': score_pvalue}",
            "def compare_score_test(self, submodel):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Perform a score test for the given submodel against this model.\\n\\n        Parameters\\n        ----------\\n        submodel : GEEResults instance\\n            A fitted GEE model that is a submodel of this model.\\n\\n        Returns\\n        -------\\n        A dictionary with keys \"statistic\", \"p-value\", and \"df\",\\n        containing the score test statistic, its chi^2 p-value,\\n        and the degrees of freedom used to compute the p-value.\\n\\n        Notes\\n        -----\\n        The score test can be performed without calling \\'fit\\' on the\\n        larger model.  The provided submodel must be obtained from a\\n        fitted GEE.\\n\\n        This method performs the same score test as can be obtained by\\n        fitting the GEE with a linear constraint and calling `score_test`\\n        on the results.\\n\\n        References\\n        ----------\\n        Xu Guo and Wei Pan (2002). \"Small sample performance of the score\\n        test in GEE\".\\n        http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf\\n        '\n    self.scaletype = submodel.model.scaletype\n    submod = submodel.model\n    if self.exog.shape[0] != submod.exog.shape[0]:\n        msg = 'Model and submodel have different numbers of cases.'\n        raise ValueError(msg)\n    if self.exog.shape[1] == submod.exog.shape[1]:\n        msg = 'Model and submodel have the same number of variables'\n        warnings.warn(msg)\n    if not isinstance(self.family, type(submod.family)):\n        msg = 'Model and submodel have different GLM families.'\n        warnings.warn(msg)\n    if not isinstance(self.cov_struct, type(submod.cov_struct)):\n        warnings.warn('Model and submodel have different GEE covariance structures.')\n    if not np.equal(self.weights, submod.weights).all():\n        msg = 'Model and submodel should have the same weights.'\n        warnings.warn(msg)\n    (qm, qc) = _score_test_submodel(self, submodel.model)\n    if qm is None:\n        msg = 'The provided model is not a submodel.'\n        raise ValueError(msg)\n    params_ex = np.dot(qm, submodel.params)\n    cov_struct_save = self.cov_struct\n    import copy\n    cached_means_save = copy.deepcopy(self.cached_means)\n    self.cov_struct = submodel.cov_struct\n    self.update_cached_means(params_ex)\n    (_, score) = self._update_mean_params()\n    if score is None:\n        msg = 'Singular matrix encountered in GEE score test'\n        warnings.warn(msg, ConvergenceWarning)\n        return None\n    if not hasattr(self, 'ddof_scale'):\n        self.ddof_scale = self.exog.shape[1]\n    if not hasattr(self, 'scaling_factor'):\n        self.scaling_factor = 1\n    (_, ncov1, cmat) = self._covmat()\n    score2 = np.dot(qc.T, score)\n    try:\n        amat = np.linalg.inv(ncov1)\n    except np.linalg.LinAlgError:\n        amat = np.linalg.pinv(ncov1)\n    bmat_11 = np.dot(qm.T, np.dot(cmat, qm))\n    bmat_22 = np.dot(qc.T, np.dot(cmat, qc))\n    bmat_12 = np.dot(qm.T, np.dot(cmat, qc))\n    amat_11 = np.dot(qm.T, np.dot(amat, qm))\n    amat_12 = np.dot(qm.T, np.dot(amat, qc))\n    try:\n        ab = np.linalg.solve(amat_11, bmat_12)\n    except np.linalg.LinAlgError:\n        ab = np.dot(np.linalg.pinv(amat_11), bmat_12)\n    score_cov = bmat_22 - np.dot(amat_12.T, ab)\n    try:\n        aa = np.linalg.solve(amat_11, amat_12)\n    except np.linalg.LinAlgError:\n        aa = np.dot(np.linalg.pinv(amat_11), amat_12)\n    score_cov -= np.dot(bmat_12.T, aa)\n    try:\n        ab = np.linalg.solve(amat_11, bmat_11)\n    except np.linalg.LinAlgError:\n        ab = np.dot(np.linalg.pinv(amat_11), bmat_11)\n    try:\n        aa = np.linalg.solve(amat_11, amat_12)\n    except np.linalg.LinAlgError:\n        aa = np.dot(np.linalg.pinv(amat_11), amat_12)\n    score_cov += np.dot(amat_12.T, np.dot(ab, aa))\n    self.cov_struct = cov_struct_save\n    self.cached_means = cached_means_save\n    from scipy.stats.distributions import chi2\n    try:\n        sc2 = np.linalg.solve(score_cov, score2)\n    except np.linalg.LinAlgError:\n        sc2 = np.dot(np.linalg.pinv(score_cov), score2)\n    score_statistic = np.dot(score2, sc2)\n    score_df = len(score2)\n    score_pvalue = 1 - chi2.cdf(score_statistic, score_df)\n    return {'statistic': score_statistic, 'df': score_df, 'p-value': score_pvalue}",
            "def compare_score_test(self, submodel):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Perform a score test for the given submodel against this model.\\n\\n        Parameters\\n        ----------\\n        submodel : GEEResults instance\\n            A fitted GEE model that is a submodel of this model.\\n\\n        Returns\\n        -------\\n        A dictionary with keys \"statistic\", \"p-value\", and \"df\",\\n        containing the score test statistic, its chi^2 p-value,\\n        and the degrees of freedom used to compute the p-value.\\n\\n        Notes\\n        -----\\n        The score test can be performed without calling \\'fit\\' on the\\n        larger model.  The provided submodel must be obtained from a\\n        fitted GEE.\\n\\n        This method performs the same score test as can be obtained by\\n        fitting the GEE with a linear constraint and calling `score_test`\\n        on the results.\\n\\n        References\\n        ----------\\n        Xu Guo and Wei Pan (2002). \"Small sample performance of the score\\n        test in GEE\".\\n        http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf\\n        '\n    self.scaletype = submodel.model.scaletype\n    submod = submodel.model\n    if self.exog.shape[0] != submod.exog.shape[0]:\n        msg = 'Model and submodel have different numbers of cases.'\n        raise ValueError(msg)\n    if self.exog.shape[1] == submod.exog.shape[1]:\n        msg = 'Model and submodel have the same number of variables'\n        warnings.warn(msg)\n    if not isinstance(self.family, type(submod.family)):\n        msg = 'Model and submodel have different GLM families.'\n        warnings.warn(msg)\n    if not isinstance(self.cov_struct, type(submod.cov_struct)):\n        warnings.warn('Model and submodel have different GEE covariance structures.')\n    if not np.equal(self.weights, submod.weights).all():\n        msg = 'Model and submodel should have the same weights.'\n        warnings.warn(msg)\n    (qm, qc) = _score_test_submodel(self, submodel.model)\n    if qm is None:\n        msg = 'The provided model is not a submodel.'\n        raise ValueError(msg)\n    params_ex = np.dot(qm, submodel.params)\n    cov_struct_save = self.cov_struct\n    import copy\n    cached_means_save = copy.deepcopy(self.cached_means)\n    self.cov_struct = submodel.cov_struct\n    self.update_cached_means(params_ex)\n    (_, score) = self._update_mean_params()\n    if score is None:\n        msg = 'Singular matrix encountered in GEE score test'\n        warnings.warn(msg, ConvergenceWarning)\n        return None\n    if not hasattr(self, 'ddof_scale'):\n        self.ddof_scale = self.exog.shape[1]\n    if not hasattr(self, 'scaling_factor'):\n        self.scaling_factor = 1\n    (_, ncov1, cmat) = self._covmat()\n    score2 = np.dot(qc.T, score)\n    try:\n        amat = np.linalg.inv(ncov1)\n    except np.linalg.LinAlgError:\n        amat = np.linalg.pinv(ncov1)\n    bmat_11 = np.dot(qm.T, np.dot(cmat, qm))\n    bmat_22 = np.dot(qc.T, np.dot(cmat, qc))\n    bmat_12 = np.dot(qm.T, np.dot(cmat, qc))\n    amat_11 = np.dot(qm.T, np.dot(amat, qm))\n    amat_12 = np.dot(qm.T, np.dot(amat, qc))\n    try:\n        ab = np.linalg.solve(amat_11, bmat_12)\n    except np.linalg.LinAlgError:\n        ab = np.dot(np.linalg.pinv(amat_11), bmat_12)\n    score_cov = bmat_22 - np.dot(amat_12.T, ab)\n    try:\n        aa = np.linalg.solve(amat_11, amat_12)\n    except np.linalg.LinAlgError:\n        aa = np.dot(np.linalg.pinv(amat_11), amat_12)\n    score_cov -= np.dot(bmat_12.T, aa)\n    try:\n        ab = np.linalg.solve(amat_11, bmat_11)\n    except np.linalg.LinAlgError:\n        ab = np.dot(np.linalg.pinv(amat_11), bmat_11)\n    try:\n        aa = np.linalg.solve(amat_11, amat_12)\n    except np.linalg.LinAlgError:\n        aa = np.dot(np.linalg.pinv(amat_11), amat_12)\n    score_cov += np.dot(amat_12.T, np.dot(ab, aa))\n    self.cov_struct = cov_struct_save\n    self.cached_means = cached_means_save\n    from scipy.stats.distributions import chi2\n    try:\n        sc2 = np.linalg.solve(score_cov, score2)\n    except np.linalg.LinAlgError:\n        sc2 = np.dot(np.linalg.pinv(score_cov), score2)\n    score_statistic = np.dot(score2, sc2)\n    score_df = len(score2)\n    score_pvalue = 1 - chi2.cdf(score_statistic, score_df)\n    return {'statistic': score_statistic, 'df': score_df, 'p-value': score_pvalue}"
        ]
    },
    {
        "func_name": "estimate_scale",
        "original": "def estimate_scale(self):\n    \"\"\"\n        Estimate the dispersion/scale.\n        \"\"\"\n    if self.scaletype is None:\n        if isinstance(self.family, (families.Binomial, families.Poisson, families.NegativeBinomial, _Multinomial)):\n            return 1.0\n    elif isinstance(self.scaletype, float):\n        return np.array(self.scaletype)\n    endog = self.endog_li\n    cached_means = self.cached_means\n    nobs = self.nobs\n    varfunc = self.family.variance\n    scale = 0.0\n    fsum = 0.0\n    for i in range(self.num_group):\n        if len(endog[i]) == 0:\n            continue\n        (expval, _) = cached_means[i]\n        sdev = np.sqrt(varfunc(expval))\n        resid = (endog[i] - expval) / sdev\n        if self.weights is not None:\n            f = self.weights_li[i]\n            scale += np.sum(f * resid ** 2)\n            fsum += f.sum()\n        else:\n            scale += np.sum(resid ** 2)\n            fsum += len(resid)\n    scale /= fsum * (nobs - self.ddof_scale) / float(nobs)\n    return scale",
        "mutated": [
            "def estimate_scale(self):\n    if False:\n        i = 10\n    '\\n        Estimate the dispersion/scale.\\n        '\n    if self.scaletype is None:\n        if isinstance(self.family, (families.Binomial, families.Poisson, families.NegativeBinomial, _Multinomial)):\n            return 1.0\n    elif isinstance(self.scaletype, float):\n        return np.array(self.scaletype)\n    endog = self.endog_li\n    cached_means = self.cached_means\n    nobs = self.nobs\n    varfunc = self.family.variance\n    scale = 0.0\n    fsum = 0.0\n    for i in range(self.num_group):\n        if len(endog[i]) == 0:\n            continue\n        (expval, _) = cached_means[i]\n        sdev = np.sqrt(varfunc(expval))\n        resid = (endog[i] - expval) / sdev\n        if self.weights is not None:\n            f = self.weights_li[i]\n            scale += np.sum(f * resid ** 2)\n            fsum += f.sum()\n        else:\n            scale += np.sum(resid ** 2)\n            fsum += len(resid)\n    scale /= fsum * (nobs - self.ddof_scale) / float(nobs)\n    return scale",
            "def estimate_scale(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Estimate the dispersion/scale.\\n        '\n    if self.scaletype is None:\n        if isinstance(self.family, (families.Binomial, families.Poisson, families.NegativeBinomial, _Multinomial)):\n            return 1.0\n    elif isinstance(self.scaletype, float):\n        return np.array(self.scaletype)\n    endog = self.endog_li\n    cached_means = self.cached_means\n    nobs = self.nobs\n    varfunc = self.family.variance\n    scale = 0.0\n    fsum = 0.0\n    for i in range(self.num_group):\n        if len(endog[i]) == 0:\n            continue\n        (expval, _) = cached_means[i]\n        sdev = np.sqrt(varfunc(expval))\n        resid = (endog[i] - expval) / sdev\n        if self.weights is not None:\n            f = self.weights_li[i]\n            scale += np.sum(f * resid ** 2)\n            fsum += f.sum()\n        else:\n            scale += np.sum(resid ** 2)\n            fsum += len(resid)\n    scale /= fsum * (nobs - self.ddof_scale) / float(nobs)\n    return scale",
            "def estimate_scale(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Estimate the dispersion/scale.\\n        '\n    if self.scaletype is None:\n        if isinstance(self.family, (families.Binomial, families.Poisson, families.NegativeBinomial, _Multinomial)):\n            return 1.0\n    elif isinstance(self.scaletype, float):\n        return np.array(self.scaletype)\n    endog = self.endog_li\n    cached_means = self.cached_means\n    nobs = self.nobs\n    varfunc = self.family.variance\n    scale = 0.0\n    fsum = 0.0\n    for i in range(self.num_group):\n        if len(endog[i]) == 0:\n            continue\n        (expval, _) = cached_means[i]\n        sdev = np.sqrt(varfunc(expval))\n        resid = (endog[i] - expval) / sdev\n        if self.weights is not None:\n            f = self.weights_li[i]\n            scale += np.sum(f * resid ** 2)\n            fsum += f.sum()\n        else:\n            scale += np.sum(resid ** 2)\n            fsum += len(resid)\n    scale /= fsum * (nobs - self.ddof_scale) / float(nobs)\n    return scale",
            "def estimate_scale(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Estimate the dispersion/scale.\\n        '\n    if self.scaletype is None:\n        if isinstance(self.family, (families.Binomial, families.Poisson, families.NegativeBinomial, _Multinomial)):\n            return 1.0\n    elif isinstance(self.scaletype, float):\n        return np.array(self.scaletype)\n    endog = self.endog_li\n    cached_means = self.cached_means\n    nobs = self.nobs\n    varfunc = self.family.variance\n    scale = 0.0\n    fsum = 0.0\n    for i in range(self.num_group):\n        if len(endog[i]) == 0:\n            continue\n        (expval, _) = cached_means[i]\n        sdev = np.sqrt(varfunc(expval))\n        resid = (endog[i] - expval) / sdev\n        if self.weights is not None:\n            f = self.weights_li[i]\n            scale += np.sum(f * resid ** 2)\n            fsum += f.sum()\n        else:\n            scale += np.sum(resid ** 2)\n            fsum += len(resid)\n    scale /= fsum * (nobs - self.ddof_scale) / float(nobs)\n    return scale",
            "def estimate_scale(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Estimate the dispersion/scale.\\n        '\n    if self.scaletype is None:\n        if isinstance(self.family, (families.Binomial, families.Poisson, families.NegativeBinomial, _Multinomial)):\n            return 1.0\n    elif isinstance(self.scaletype, float):\n        return np.array(self.scaletype)\n    endog = self.endog_li\n    cached_means = self.cached_means\n    nobs = self.nobs\n    varfunc = self.family.variance\n    scale = 0.0\n    fsum = 0.0\n    for i in range(self.num_group):\n        if len(endog[i]) == 0:\n            continue\n        (expval, _) = cached_means[i]\n        sdev = np.sqrt(varfunc(expval))\n        resid = (endog[i] - expval) / sdev\n        if self.weights is not None:\n            f = self.weights_li[i]\n            scale += np.sum(f * resid ** 2)\n            fsum += f.sum()\n        else:\n            scale += np.sum(resid ** 2)\n            fsum += len(resid)\n    scale /= fsum * (nobs - self.ddof_scale) / float(nobs)\n    return scale"
        ]
    },
    {
        "func_name": "mean_deriv",
        "original": "def mean_deriv(self, exog, lin_pred):\n    \"\"\"\n        Derivative of the expected endog with respect to the parameters.\n\n        Parameters\n        ----------\n        exog : array_like\n           The exogeneous data at which the derivative is computed.\n        lin_pred : array_like\n           The values of the linear predictor.\n\n        Returns\n        -------\n        The value of the derivative of the expected endog with respect\n        to the parameter vector.\n\n        Notes\n        -----\n        If there is an offset or exposure, it should be added to\n        `lin_pred` prior to calling this function.\n        \"\"\"\n    idl = self.family.link.inverse_deriv(lin_pred)\n    dmat = exog * idl[:, None]\n    return dmat",
        "mutated": [
            "def mean_deriv(self, exog, lin_pred):\n    if False:\n        i = 10\n    '\\n        Derivative of the expected endog with respect to the parameters.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data at which the derivative is computed.\\n        lin_pred : array_like\\n           The values of the linear predictor.\\n\\n        Returns\\n        -------\\n        The value of the derivative of the expected endog with respect\\n        to the parameter vector.\\n\\n        Notes\\n        -----\\n        If there is an offset or exposure, it should be added to\\n        `lin_pred` prior to calling this function.\\n        '\n    idl = self.family.link.inverse_deriv(lin_pred)\n    dmat = exog * idl[:, None]\n    return dmat",
            "def mean_deriv(self, exog, lin_pred):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Derivative of the expected endog with respect to the parameters.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data at which the derivative is computed.\\n        lin_pred : array_like\\n           The values of the linear predictor.\\n\\n        Returns\\n        -------\\n        The value of the derivative of the expected endog with respect\\n        to the parameter vector.\\n\\n        Notes\\n        -----\\n        If there is an offset or exposure, it should be added to\\n        `lin_pred` prior to calling this function.\\n        '\n    idl = self.family.link.inverse_deriv(lin_pred)\n    dmat = exog * idl[:, None]\n    return dmat",
            "def mean_deriv(self, exog, lin_pred):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Derivative of the expected endog with respect to the parameters.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data at which the derivative is computed.\\n        lin_pred : array_like\\n           The values of the linear predictor.\\n\\n        Returns\\n        -------\\n        The value of the derivative of the expected endog with respect\\n        to the parameter vector.\\n\\n        Notes\\n        -----\\n        If there is an offset or exposure, it should be added to\\n        `lin_pred` prior to calling this function.\\n        '\n    idl = self.family.link.inverse_deriv(lin_pred)\n    dmat = exog * idl[:, None]\n    return dmat",
            "def mean_deriv(self, exog, lin_pred):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Derivative of the expected endog with respect to the parameters.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data at which the derivative is computed.\\n        lin_pred : array_like\\n           The values of the linear predictor.\\n\\n        Returns\\n        -------\\n        The value of the derivative of the expected endog with respect\\n        to the parameter vector.\\n\\n        Notes\\n        -----\\n        If there is an offset or exposure, it should be added to\\n        `lin_pred` prior to calling this function.\\n        '\n    idl = self.family.link.inverse_deriv(lin_pred)\n    dmat = exog * idl[:, None]\n    return dmat",
            "def mean_deriv(self, exog, lin_pred):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Derivative of the expected endog with respect to the parameters.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data at which the derivative is computed.\\n        lin_pred : array_like\\n           The values of the linear predictor.\\n\\n        Returns\\n        -------\\n        The value of the derivative of the expected endog with respect\\n        to the parameter vector.\\n\\n        Notes\\n        -----\\n        If there is an offset or exposure, it should be added to\\n        `lin_pred` prior to calling this function.\\n        '\n    idl = self.family.link.inverse_deriv(lin_pred)\n    dmat = exog * idl[:, None]\n    return dmat"
        ]
    },
    {
        "func_name": "mean_deriv_exog",
        "original": "def mean_deriv_exog(self, exog, params, offset_exposure=None):\n    \"\"\"\n        Derivative of the expected endog with respect to exog.\n\n        Parameters\n        ----------\n        exog : array_like\n            Values of the independent variables at which the derivative\n            is calculated.\n        params : array_like\n            Parameter values at which the derivative is calculated.\n        offset_exposure : array_like, optional\n            Combined offset and exposure.\n\n        Returns\n        -------\n        The derivative of the expected endog with respect to exog.\n        \"\"\"\n    lin_pred = np.dot(exog, params)\n    if offset_exposure is not None:\n        lin_pred += offset_exposure\n    idl = self.family.link.inverse_deriv(lin_pred)\n    dmat = np.outer(idl, params)\n    return dmat",
        "mutated": [
            "def mean_deriv_exog(self, exog, params, offset_exposure=None):\n    if False:\n        i = 10\n    '\\n        Derivative of the expected endog with respect to exog.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n            Values of the independent variables at which the derivative\\n            is calculated.\\n        params : array_like\\n            Parameter values at which the derivative is calculated.\\n        offset_exposure : array_like, optional\\n            Combined offset and exposure.\\n\\n        Returns\\n        -------\\n        The derivative of the expected endog with respect to exog.\\n        '\n    lin_pred = np.dot(exog, params)\n    if offset_exposure is not None:\n        lin_pred += offset_exposure\n    idl = self.family.link.inverse_deriv(lin_pred)\n    dmat = np.outer(idl, params)\n    return dmat",
            "def mean_deriv_exog(self, exog, params, offset_exposure=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Derivative of the expected endog with respect to exog.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n            Values of the independent variables at which the derivative\\n            is calculated.\\n        params : array_like\\n            Parameter values at which the derivative is calculated.\\n        offset_exposure : array_like, optional\\n            Combined offset and exposure.\\n\\n        Returns\\n        -------\\n        The derivative of the expected endog with respect to exog.\\n        '\n    lin_pred = np.dot(exog, params)\n    if offset_exposure is not None:\n        lin_pred += offset_exposure\n    idl = self.family.link.inverse_deriv(lin_pred)\n    dmat = np.outer(idl, params)\n    return dmat",
            "def mean_deriv_exog(self, exog, params, offset_exposure=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Derivative of the expected endog with respect to exog.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n            Values of the independent variables at which the derivative\\n            is calculated.\\n        params : array_like\\n            Parameter values at which the derivative is calculated.\\n        offset_exposure : array_like, optional\\n            Combined offset and exposure.\\n\\n        Returns\\n        -------\\n        The derivative of the expected endog with respect to exog.\\n        '\n    lin_pred = np.dot(exog, params)\n    if offset_exposure is not None:\n        lin_pred += offset_exposure\n    idl = self.family.link.inverse_deriv(lin_pred)\n    dmat = np.outer(idl, params)\n    return dmat",
            "def mean_deriv_exog(self, exog, params, offset_exposure=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Derivative of the expected endog with respect to exog.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n            Values of the independent variables at which the derivative\\n            is calculated.\\n        params : array_like\\n            Parameter values at which the derivative is calculated.\\n        offset_exposure : array_like, optional\\n            Combined offset and exposure.\\n\\n        Returns\\n        -------\\n        The derivative of the expected endog with respect to exog.\\n        '\n    lin_pred = np.dot(exog, params)\n    if offset_exposure is not None:\n        lin_pred += offset_exposure\n    idl = self.family.link.inverse_deriv(lin_pred)\n    dmat = np.outer(idl, params)\n    return dmat",
            "def mean_deriv_exog(self, exog, params, offset_exposure=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Derivative of the expected endog with respect to exog.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n            Values of the independent variables at which the derivative\\n            is calculated.\\n        params : array_like\\n            Parameter values at which the derivative is calculated.\\n        offset_exposure : array_like, optional\\n            Combined offset and exposure.\\n\\n        Returns\\n        -------\\n        The derivative of the expected endog with respect to exog.\\n        '\n    lin_pred = np.dot(exog, params)\n    if offset_exposure is not None:\n        lin_pred += offset_exposure\n    idl = self.family.link.inverse_deriv(lin_pred)\n    dmat = np.outer(idl, params)\n    return dmat"
        ]
    },
    {
        "func_name": "_update_mean_params",
        "original": "def _update_mean_params(self):\n    \"\"\"\n        Returns\n        -------\n        update : array_like\n            The update vector such that params + update is the next\n            iterate when solving the score equations.\n        score : array_like\n            The current value of the score equations, not\n            incorporating the scale parameter.  If desired,\n            multiply this vector by the scale parameter to\n            incorporate the scale.\n        \"\"\"\n    endog = self.endog_li\n    exog = self.exog_li\n    weights = getattr(self, 'weights_li', None)\n    cached_means = self.cached_means\n    varfunc = self.family.variance\n    (bmat, score) = (0, 0)\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        if weights is not None:\n            w = weights[i]\n            wresid = resid * w\n            wdmat = dmat * w[:, None]\n        else:\n            wresid = resid\n            wdmat = dmat\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (wdmat, wresid))\n        if rslt is None:\n            return (None, None)\n        (vinv_d, vinv_resid) = tuple(rslt)\n        bmat += np.dot(dmat.T, vinv_d)\n        score += np.dot(dmat.T, vinv_resid)\n    try:\n        update = np.linalg.solve(bmat, score)\n    except np.linalg.LinAlgError:\n        update = np.dot(np.linalg.pinv(bmat), score)\n    self._fit_history['cov_adjust'].append(self.cov_struct.cov_adjust)\n    return (update, score)",
        "mutated": [
            "def _update_mean_params(self):\n    if False:\n        i = 10\n    '\\n        Returns\\n        -------\\n        update : array_like\\n            The update vector such that params + update is the next\\n            iterate when solving the score equations.\\n        score : array_like\\n            The current value of the score equations, not\\n            incorporating the scale parameter.  If desired,\\n            multiply this vector by the scale parameter to\\n            incorporate the scale.\\n        '\n    endog = self.endog_li\n    exog = self.exog_li\n    weights = getattr(self, 'weights_li', None)\n    cached_means = self.cached_means\n    varfunc = self.family.variance\n    (bmat, score) = (0, 0)\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        if weights is not None:\n            w = weights[i]\n            wresid = resid * w\n            wdmat = dmat * w[:, None]\n        else:\n            wresid = resid\n            wdmat = dmat\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (wdmat, wresid))\n        if rslt is None:\n            return (None, None)\n        (vinv_d, vinv_resid) = tuple(rslt)\n        bmat += np.dot(dmat.T, vinv_d)\n        score += np.dot(dmat.T, vinv_resid)\n    try:\n        update = np.linalg.solve(bmat, score)\n    except np.linalg.LinAlgError:\n        update = np.dot(np.linalg.pinv(bmat), score)\n    self._fit_history['cov_adjust'].append(self.cov_struct.cov_adjust)\n    return (update, score)",
            "def _update_mean_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns\\n        -------\\n        update : array_like\\n            The update vector such that params + update is the next\\n            iterate when solving the score equations.\\n        score : array_like\\n            The current value of the score equations, not\\n            incorporating the scale parameter.  If desired,\\n            multiply this vector by the scale parameter to\\n            incorporate the scale.\\n        '\n    endog = self.endog_li\n    exog = self.exog_li\n    weights = getattr(self, 'weights_li', None)\n    cached_means = self.cached_means\n    varfunc = self.family.variance\n    (bmat, score) = (0, 0)\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        if weights is not None:\n            w = weights[i]\n            wresid = resid * w\n            wdmat = dmat * w[:, None]\n        else:\n            wresid = resid\n            wdmat = dmat\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (wdmat, wresid))\n        if rslt is None:\n            return (None, None)\n        (vinv_d, vinv_resid) = tuple(rslt)\n        bmat += np.dot(dmat.T, vinv_d)\n        score += np.dot(dmat.T, vinv_resid)\n    try:\n        update = np.linalg.solve(bmat, score)\n    except np.linalg.LinAlgError:\n        update = np.dot(np.linalg.pinv(bmat), score)\n    self._fit_history['cov_adjust'].append(self.cov_struct.cov_adjust)\n    return (update, score)",
            "def _update_mean_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns\\n        -------\\n        update : array_like\\n            The update vector such that params + update is the next\\n            iterate when solving the score equations.\\n        score : array_like\\n            The current value of the score equations, not\\n            incorporating the scale parameter.  If desired,\\n            multiply this vector by the scale parameter to\\n            incorporate the scale.\\n        '\n    endog = self.endog_li\n    exog = self.exog_li\n    weights = getattr(self, 'weights_li', None)\n    cached_means = self.cached_means\n    varfunc = self.family.variance\n    (bmat, score) = (0, 0)\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        if weights is not None:\n            w = weights[i]\n            wresid = resid * w\n            wdmat = dmat * w[:, None]\n        else:\n            wresid = resid\n            wdmat = dmat\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (wdmat, wresid))\n        if rslt is None:\n            return (None, None)\n        (vinv_d, vinv_resid) = tuple(rslt)\n        bmat += np.dot(dmat.T, vinv_d)\n        score += np.dot(dmat.T, vinv_resid)\n    try:\n        update = np.linalg.solve(bmat, score)\n    except np.linalg.LinAlgError:\n        update = np.dot(np.linalg.pinv(bmat), score)\n    self._fit_history['cov_adjust'].append(self.cov_struct.cov_adjust)\n    return (update, score)",
            "def _update_mean_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns\\n        -------\\n        update : array_like\\n            The update vector such that params + update is the next\\n            iterate when solving the score equations.\\n        score : array_like\\n            The current value of the score equations, not\\n            incorporating the scale parameter.  If desired,\\n            multiply this vector by the scale parameter to\\n            incorporate the scale.\\n        '\n    endog = self.endog_li\n    exog = self.exog_li\n    weights = getattr(self, 'weights_li', None)\n    cached_means = self.cached_means\n    varfunc = self.family.variance\n    (bmat, score) = (0, 0)\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        if weights is not None:\n            w = weights[i]\n            wresid = resid * w\n            wdmat = dmat * w[:, None]\n        else:\n            wresid = resid\n            wdmat = dmat\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (wdmat, wresid))\n        if rslt is None:\n            return (None, None)\n        (vinv_d, vinv_resid) = tuple(rslt)\n        bmat += np.dot(dmat.T, vinv_d)\n        score += np.dot(dmat.T, vinv_resid)\n    try:\n        update = np.linalg.solve(bmat, score)\n    except np.linalg.LinAlgError:\n        update = np.dot(np.linalg.pinv(bmat), score)\n    self._fit_history['cov_adjust'].append(self.cov_struct.cov_adjust)\n    return (update, score)",
            "def _update_mean_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns\\n        -------\\n        update : array_like\\n            The update vector such that params + update is the next\\n            iterate when solving the score equations.\\n        score : array_like\\n            The current value of the score equations, not\\n            incorporating the scale parameter.  If desired,\\n            multiply this vector by the scale parameter to\\n            incorporate the scale.\\n        '\n    endog = self.endog_li\n    exog = self.exog_li\n    weights = getattr(self, 'weights_li', None)\n    cached_means = self.cached_means\n    varfunc = self.family.variance\n    (bmat, score) = (0, 0)\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        if weights is not None:\n            w = weights[i]\n            wresid = resid * w\n            wdmat = dmat * w[:, None]\n        else:\n            wresid = resid\n            wdmat = dmat\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (wdmat, wresid))\n        if rslt is None:\n            return (None, None)\n        (vinv_d, vinv_resid) = tuple(rslt)\n        bmat += np.dot(dmat.T, vinv_d)\n        score += np.dot(dmat.T, vinv_resid)\n    try:\n        update = np.linalg.solve(bmat, score)\n    except np.linalg.LinAlgError:\n        update = np.dot(np.linalg.pinv(bmat), score)\n    self._fit_history['cov_adjust'].append(self.cov_struct.cov_adjust)\n    return (update, score)"
        ]
    },
    {
        "func_name": "update_cached_means",
        "original": "def update_cached_means(self, mean_params):\n    \"\"\"\n        cached_means should always contain the most recent calculation\n        of the group-wise mean vectors.  This function should be\n        called every time the regression parameters are changed, to\n        keep the cached means up to date.\n        \"\"\"\n    endog = self.endog_li\n    exog = self.exog_li\n    offset = self.offset_li\n    linkinv = self.family.link.inverse\n    self.cached_means = []\n    for i in range(self.num_group):\n        if len(endog[i]) == 0:\n            continue\n        lpr = np.dot(exog[i], mean_params)\n        if offset is not None:\n            lpr += offset[i]\n        expval = linkinv(lpr)\n        self.cached_means.append((expval, lpr))",
        "mutated": [
            "def update_cached_means(self, mean_params):\n    if False:\n        i = 10\n    '\\n        cached_means should always contain the most recent calculation\\n        of the group-wise mean vectors.  This function should be\\n        called every time the regression parameters are changed, to\\n        keep the cached means up to date.\\n        '\n    endog = self.endog_li\n    exog = self.exog_li\n    offset = self.offset_li\n    linkinv = self.family.link.inverse\n    self.cached_means = []\n    for i in range(self.num_group):\n        if len(endog[i]) == 0:\n            continue\n        lpr = np.dot(exog[i], mean_params)\n        if offset is not None:\n            lpr += offset[i]\n        expval = linkinv(lpr)\n        self.cached_means.append((expval, lpr))",
            "def update_cached_means(self, mean_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        cached_means should always contain the most recent calculation\\n        of the group-wise mean vectors.  This function should be\\n        called every time the regression parameters are changed, to\\n        keep the cached means up to date.\\n        '\n    endog = self.endog_li\n    exog = self.exog_li\n    offset = self.offset_li\n    linkinv = self.family.link.inverse\n    self.cached_means = []\n    for i in range(self.num_group):\n        if len(endog[i]) == 0:\n            continue\n        lpr = np.dot(exog[i], mean_params)\n        if offset is not None:\n            lpr += offset[i]\n        expval = linkinv(lpr)\n        self.cached_means.append((expval, lpr))",
            "def update_cached_means(self, mean_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        cached_means should always contain the most recent calculation\\n        of the group-wise mean vectors.  This function should be\\n        called every time the regression parameters are changed, to\\n        keep the cached means up to date.\\n        '\n    endog = self.endog_li\n    exog = self.exog_li\n    offset = self.offset_li\n    linkinv = self.family.link.inverse\n    self.cached_means = []\n    for i in range(self.num_group):\n        if len(endog[i]) == 0:\n            continue\n        lpr = np.dot(exog[i], mean_params)\n        if offset is not None:\n            lpr += offset[i]\n        expval = linkinv(lpr)\n        self.cached_means.append((expval, lpr))",
            "def update_cached_means(self, mean_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        cached_means should always contain the most recent calculation\\n        of the group-wise mean vectors.  This function should be\\n        called every time the regression parameters are changed, to\\n        keep the cached means up to date.\\n        '\n    endog = self.endog_li\n    exog = self.exog_li\n    offset = self.offset_li\n    linkinv = self.family.link.inverse\n    self.cached_means = []\n    for i in range(self.num_group):\n        if len(endog[i]) == 0:\n            continue\n        lpr = np.dot(exog[i], mean_params)\n        if offset is not None:\n            lpr += offset[i]\n        expval = linkinv(lpr)\n        self.cached_means.append((expval, lpr))",
            "def update_cached_means(self, mean_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        cached_means should always contain the most recent calculation\\n        of the group-wise mean vectors.  This function should be\\n        called every time the regression parameters are changed, to\\n        keep the cached means up to date.\\n        '\n    endog = self.endog_li\n    exog = self.exog_li\n    offset = self.offset_li\n    linkinv = self.family.link.inverse\n    self.cached_means = []\n    for i in range(self.num_group):\n        if len(endog[i]) == 0:\n            continue\n        lpr = np.dot(exog[i], mean_params)\n        if offset is not None:\n            lpr += offset[i]\n        expval = linkinv(lpr)\n        self.cached_means.append((expval, lpr))"
        ]
    },
    {
        "func_name": "_covmat",
        "original": "def _covmat(self):\n    \"\"\"\n        Returns the sampling covariance matrix of the regression\n        parameters and related quantities.\n\n        Returns\n        -------\n        cov_robust : array_like\n           The robust, or sandwich estimate of the covariance, which\n           is meaningful even if the working covariance structure is\n           incorrectly specified.\n        cov_naive : array_like\n           The model-based estimate of the covariance, which is\n           meaningful if the covariance structure is correctly\n           specified.\n        cmat : array_like\n           The center matrix of the sandwich expression, used in\n           obtaining score test results.\n        \"\"\"\n    endog = self.endog_li\n    exog = self.exog_li\n    weights = getattr(self, 'weights_li', None)\n    varfunc = self.family.variance\n    cached_means = self.cached_means\n    (bmat, cmat) = (0, 0)\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        if weights is not None:\n            w = weights[i]\n            wresid = resid * w\n            wdmat = dmat * w[:, None]\n        else:\n            wresid = resid\n            wdmat = dmat\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (wdmat, wresid))\n        if rslt is None:\n            return (None, None, None, None)\n        (vinv_d, vinv_resid) = tuple(rslt)\n        bmat += np.dot(dmat.T, vinv_d)\n        dvinv_resid = np.dot(dmat.T, vinv_resid)\n        cmat += np.outer(dvinv_resid, dvinv_resid)\n    scale = self.estimate_scale()\n    try:\n        bmati = np.linalg.inv(bmat)\n    except np.linalg.LinAlgError:\n        bmati = np.linalg.pinv(bmat)\n    cov_naive = bmati * scale\n    cov_robust = np.dot(bmati, np.dot(cmat, bmati))\n    cov_naive *= self.scaling_factor\n    cov_robust *= self.scaling_factor\n    return (cov_robust, cov_naive, cmat)",
        "mutated": [
            "def _covmat(self):\n    if False:\n        i = 10\n    '\\n        Returns the sampling covariance matrix of the regression\\n        parameters and related quantities.\\n\\n        Returns\\n        -------\\n        cov_robust : array_like\\n           The robust, or sandwich estimate of the covariance, which\\n           is meaningful even if the working covariance structure is\\n           incorrectly specified.\\n        cov_naive : array_like\\n           The model-based estimate of the covariance, which is\\n           meaningful if the covariance structure is correctly\\n           specified.\\n        cmat : array_like\\n           The center matrix of the sandwich expression, used in\\n           obtaining score test results.\\n        '\n    endog = self.endog_li\n    exog = self.exog_li\n    weights = getattr(self, 'weights_li', None)\n    varfunc = self.family.variance\n    cached_means = self.cached_means\n    (bmat, cmat) = (0, 0)\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        if weights is not None:\n            w = weights[i]\n            wresid = resid * w\n            wdmat = dmat * w[:, None]\n        else:\n            wresid = resid\n            wdmat = dmat\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (wdmat, wresid))\n        if rslt is None:\n            return (None, None, None, None)\n        (vinv_d, vinv_resid) = tuple(rslt)\n        bmat += np.dot(dmat.T, vinv_d)\n        dvinv_resid = np.dot(dmat.T, vinv_resid)\n        cmat += np.outer(dvinv_resid, dvinv_resid)\n    scale = self.estimate_scale()\n    try:\n        bmati = np.linalg.inv(bmat)\n    except np.linalg.LinAlgError:\n        bmati = np.linalg.pinv(bmat)\n    cov_naive = bmati * scale\n    cov_robust = np.dot(bmati, np.dot(cmat, bmati))\n    cov_naive *= self.scaling_factor\n    cov_robust *= self.scaling_factor\n    return (cov_robust, cov_naive, cmat)",
            "def _covmat(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the sampling covariance matrix of the regression\\n        parameters and related quantities.\\n\\n        Returns\\n        -------\\n        cov_robust : array_like\\n           The robust, or sandwich estimate of the covariance, which\\n           is meaningful even if the working covariance structure is\\n           incorrectly specified.\\n        cov_naive : array_like\\n           The model-based estimate of the covariance, which is\\n           meaningful if the covariance structure is correctly\\n           specified.\\n        cmat : array_like\\n           The center matrix of the sandwich expression, used in\\n           obtaining score test results.\\n        '\n    endog = self.endog_li\n    exog = self.exog_li\n    weights = getattr(self, 'weights_li', None)\n    varfunc = self.family.variance\n    cached_means = self.cached_means\n    (bmat, cmat) = (0, 0)\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        if weights is not None:\n            w = weights[i]\n            wresid = resid * w\n            wdmat = dmat * w[:, None]\n        else:\n            wresid = resid\n            wdmat = dmat\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (wdmat, wresid))\n        if rslt is None:\n            return (None, None, None, None)\n        (vinv_d, vinv_resid) = tuple(rslt)\n        bmat += np.dot(dmat.T, vinv_d)\n        dvinv_resid = np.dot(dmat.T, vinv_resid)\n        cmat += np.outer(dvinv_resid, dvinv_resid)\n    scale = self.estimate_scale()\n    try:\n        bmati = np.linalg.inv(bmat)\n    except np.linalg.LinAlgError:\n        bmati = np.linalg.pinv(bmat)\n    cov_naive = bmati * scale\n    cov_robust = np.dot(bmati, np.dot(cmat, bmati))\n    cov_naive *= self.scaling_factor\n    cov_robust *= self.scaling_factor\n    return (cov_robust, cov_naive, cmat)",
            "def _covmat(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the sampling covariance matrix of the regression\\n        parameters and related quantities.\\n\\n        Returns\\n        -------\\n        cov_robust : array_like\\n           The robust, or sandwich estimate of the covariance, which\\n           is meaningful even if the working covariance structure is\\n           incorrectly specified.\\n        cov_naive : array_like\\n           The model-based estimate of the covariance, which is\\n           meaningful if the covariance structure is correctly\\n           specified.\\n        cmat : array_like\\n           The center matrix of the sandwich expression, used in\\n           obtaining score test results.\\n        '\n    endog = self.endog_li\n    exog = self.exog_li\n    weights = getattr(self, 'weights_li', None)\n    varfunc = self.family.variance\n    cached_means = self.cached_means\n    (bmat, cmat) = (0, 0)\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        if weights is not None:\n            w = weights[i]\n            wresid = resid * w\n            wdmat = dmat * w[:, None]\n        else:\n            wresid = resid\n            wdmat = dmat\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (wdmat, wresid))\n        if rslt is None:\n            return (None, None, None, None)\n        (vinv_d, vinv_resid) = tuple(rslt)\n        bmat += np.dot(dmat.T, vinv_d)\n        dvinv_resid = np.dot(dmat.T, vinv_resid)\n        cmat += np.outer(dvinv_resid, dvinv_resid)\n    scale = self.estimate_scale()\n    try:\n        bmati = np.linalg.inv(bmat)\n    except np.linalg.LinAlgError:\n        bmati = np.linalg.pinv(bmat)\n    cov_naive = bmati * scale\n    cov_robust = np.dot(bmati, np.dot(cmat, bmati))\n    cov_naive *= self.scaling_factor\n    cov_robust *= self.scaling_factor\n    return (cov_robust, cov_naive, cmat)",
            "def _covmat(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the sampling covariance matrix of the regression\\n        parameters and related quantities.\\n\\n        Returns\\n        -------\\n        cov_robust : array_like\\n           The robust, or sandwich estimate of the covariance, which\\n           is meaningful even if the working covariance structure is\\n           incorrectly specified.\\n        cov_naive : array_like\\n           The model-based estimate of the covariance, which is\\n           meaningful if the covariance structure is correctly\\n           specified.\\n        cmat : array_like\\n           The center matrix of the sandwich expression, used in\\n           obtaining score test results.\\n        '\n    endog = self.endog_li\n    exog = self.exog_li\n    weights = getattr(self, 'weights_li', None)\n    varfunc = self.family.variance\n    cached_means = self.cached_means\n    (bmat, cmat) = (0, 0)\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        if weights is not None:\n            w = weights[i]\n            wresid = resid * w\n            wdmat = dmat * w[:, None]\n        else:\n            wresid = resid\n            wdmat = dmat\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (wdmat, wresid))\n        if rslt is None:\n            return (None, None, None, None)\n        (vinv_d, vinv_resid) = tuple(rslt)\n        bmat += np.dot(dmat.T, vinv_d)\n        dvinv_resid = np.dot(dmat.T, vinv_resid)\n        cmat += np.outer(dvinv_resid, dvinv_resid)\n    scale = self.estimate_scale()\n    try:\n        bmati = np.linalg.inv(bmat)\n    except np.linalg.LinAlgError:\n        bmati = np.linalg.pinv(bmat)\n    cov_naive = bmati * scale\n    cov_robust = np.dot(bmati, np.dot(cmat, bmati))\n    cov_naive *= self.scaling_factor\n    cov_robust *= self.scaling_factor\n    return (cov_robust, cov_naive, cmat)",
            "def _covmat(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the sampling covariance matrix of the regression\\n        parameters and related quantities.\\n\\n        Returns\\n        -------\\n        cov_robust : array_like\\n           The robust, or sandwich estimate of the covariance, which\\n           is meaningful even if the working covariance structure is\\n           incorrectly specified.\\n        cov_naive : array_like\\n           The model-based estimate of the covariance, which is\\n           meaningful if the covariance structure is correctly\\n           specified.\\n        cmat : array_like\\n           The center matrix of the sandwich expression, used in\\n           obtaining score test results.\\n        '\n    endog = self.endog_li\n    exog = self.exog_li\n    weights = getattr(self, 'weights_li', None)\n    varfunc = self.family.variance\n    cached_means = self.cached_means\n    (bmat, cmat) = (0, 0)\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        if weights is not None:\n            w = weights[i]\n            wresid = resid * w\n            wdmat = dmat * w[:, None]\n        else:\n            wresid = resid\n            wdmat = dmat\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (wdmat, wresid))\n        if rslt is None:\n            return (None, None, None, None)\n        (vinv_d, vinv_resid) = tuple(rslt)\n        bmat += np.dot(dmat.T, vinv_d)\n        dvinv_resid = np.dot(dmat.T, vinv_resid)\n        cmat += np.outer(dvinv_resid, dvinv_resid)\n    scale = self.estimate_scale()\n    try:\n        bmati = np.linalg.inv(bmat)\n    except np.linalg.LinAlgError:\n        bmati = np.linalg.pinv(bmat)\n    cov_naive = bmati * scale\n    cov_robust = np.dot(bmati, np.dot(cmat, bmati))\n    cov_naive *= self.scaling_factor\n    cov_robust *= self.scaling_factor\n    return (cov_robust, cov_naive, cmat)"
        ]
    },
    {
        "func_name": "_bc_covmat",
        "original": "def _bc_covmat(self, cov_naive):\n    cov_naive = cov_naive / self.scaling_factor\n    endog = self.endog_li\n    exog = self.exog_li\n    varfunc = self.family.variance\n    cached_means = self.cached_means\n    scale = self.estimate_scale()\n    bcm = 0\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (dmat,))\n        if rslt is None:\n            return None\n        vinv_d = rslt[0]\n        vinv_d /= scale\n        hmat = np.dot(vinv_d, cov_naive)\n        hmat = np.dot(hmat, dmat.T).T\n        f = self.weights_li[i] if self.weights is not None else 1.0\n        aresid = np.linalg.solve(np.eye(len(resid)) - hmat, resid)\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (aresid,))\n        if rslt is None:\n            return None\n        srt = rslt[0]\n        srt = f * np.dot(dmat.T, srt) / scale\n        bcm += np.outer(srt, srt)\n    cov_robust_bc = np.dot(cov_naive, np.dot(bcm, cov_naive))\n    cov_robust_bc *= self.scaling_factor\n    return cov_robust_bc",
        "mutated": [
            "def _bc_covmat(self, cov_naive):\n    if False:\n        i = 10\n    cov_naive = cov_naive / self.scaling_factor\n    endog = self.endog_li\n    exog = self.exog_li\n    varfunc = self.family.variance\n    cached_means = self.cached_means\n    scale = self.estimate_scale()\n    bcm = 0\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (dmat,))\n        if rslt is None:\n            return None\n        vinv_d = rslt[0]\n        vinv_d /= scale\n        hmat = np.dot(vinv_d, cov_naive)\n        hmat = np.dot(hmat, dmat.T).T\n        f = self.weights_li[i] if self.weights is not None else 1.0\n        aresid = np.linalg.solve(np.eye(len(resid)) - hmat, resid)\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (aresid,))\n        if rslt is None:\n            return None\n        srt = rslt[0]\n        srt = f * np.dot(dmat.T, srt) / scale\n        bcm += np.outer(srt, srt)\n    cov_robust_bc = np.dot(cov_naive, np.dot(bcm, cov_naive))\n    cov_robust_bc *= self.scaling_factor\n    return cov_robust_bc",
            "def _bc_covmat(self, cov_naive):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    cov_naive = cov_naive / self.scaling_factor\n    endog = self.endog_li\n    exog = self.exog_li\n    varfunc = self.family.variance\n    cached_means = self.cached_means\n    scale = self.estimate_scale()\n    bcm = 0\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (dmat,))\n        if rslt is None:\n            return None\n        vinv_d = rslt[0]\n        vinv_d /= scale\n        hmat = np.dot(vinv_d, cov_naive)\n        hmat = np.dot(hmat, dmat.T).T\n        f = self.weights_li[i] if self.weights is not None else 1.0\n        aresid = np.linalg.solve(np.eye(len(resid)) - hmat, resid)\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (aresid,))\n        if rslt is None:\n            return None\n        srt = rslt[0]\n        srt = f * np.dot(dmat.T, srt) / scale\n        bcm += np.outer(srt, srt)\n    cov_robust_bc = np.dot(cov_naive, np.dot(bcm, cov_naive))\n    cov_robust_bc *= self.scaling_factor\n    return cov_robust_bc",
            "def _bc_covmat(self, cov_naive):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    cov_naive = cov_naive / self.scaling_factor\n    endog = self.endog_li\n    exog = self.exog_li\n    varfunc = self.family.variance\n    cached_means = self.cached_means\n    scale = self.estimate_scale()\n    bcm = 0\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (dmat,))\n        if rslt is None:\n            return None\n        vinv_d = rslt[0]\n        vinv_d /= scale\n        hmat = np.dot(vinv_d, cov_naive)\n        hmat = np.dot(hmat, dmat.T).T\n        f = self.weights_li[i] if self.weights is not None else 1.0\n        aresid = np.linalg.solve(np.eye(len(resid)) - hmat, resid)\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (aresid,))\n        if rslt is None:\n            return None\n        srt = rslt[0]\n        srt = f * np.dot(dmat.T, srt) / scale\n        bcm += np.outer(srt, srt)\n    cov_robust_bc = np.dot(cov_naive, np.dot(bcm, cov_naive))\n    cov_robust_bc *= self.scaling_factor\n    return cov_robust_bc",
            "def _bc_covmat(self, cov_naive):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    cov_naive = cov_naive / self.scaling_factor\n    endog = self.endog_li\n    exog = self.exog_li\n    varfunc = self.family.variance\n    cached_means = self.cached_means\n    scale = self.estimate_scale()\n    bcm = 0\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (dmat,))\n        if rslt is None:\n            return None\n        vinv_d = rslt[0]\n        vinv_d /= scale\n        hmat = np.dot(vinv_d, cov_naive)\n        hmat = np.dot(hmat, dmat.T).T\n        f = self.weights_li[i] if self.weights is not None else 1.0\n        aresid = np.linalg.solve(np.eye(len(resid)) - hmat, resid)\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (aresid,))\n        if rslt is None:\n            return None\n        srt = rslt[0]\n        srt = f * np.dot(dmat.T, srt) / scale\n        bcm += np.outer(srt, srt)\n    cov_robust_bc = np.dot(cov_naive, np.dot(bcm, cov_naive))\n    cov_robust_bc *= self.scaling_factor\n    return cov_robust_bc",
            "def _bc_covmat(self, cov_naive):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    cov_naive = cov_naive / self.scaling_factor\n    endog = self.endog_li\n    exog = self.exog_li\n    varfunc = self.family.variance\n    cached_means = self.cached_means\n    scale = self.estimate_scale()\n    bcm = 0\n    for i in range(self.num_group):\n        (expval, lpr) = cached_means[i]\n        resid = endog[i] - expval\n        dmat = self.mean_deriv(exog[i], lpr)\n        sdev = np.sqrt(varfunc(expval))\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (dmat,))\n        if rslt is None:\n            return None\n        vinv_d = rslt[0]\n        vinv_d /= scale\n        hmat = np.dot(vinv_d, cov_naive)\n        hmat = np.dot(hmat, dmat.T).T\n        f = self.weights_li[i] if self.weights is not None else 1.0\n        aresid = np.linalg.solve(np.eye(len(resid)) - hmat, resid)\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (aresid,))\n        if rslt is None:\n            return None\n        srt = rslt[0]\n        srt = f * np.dot(dmat.T, srt) / scale\n        bcm += np.outer(srt, srt)\n    cov_robust_bc = np.dot(cov_naive, np.dot(bcm, cov_naive))\n    cov_robust_bc *= self.scaling_factor\n    return cov_robust_bc"
        ]
    },
    {
        "func_name": "_starting_params",
        "original": "def _starting_params(self):\n    if np.isscalar(self._offset_exposure):\n        offset = None\n    else:\n        offset = self._offset_exposure\n    model = GLM(self.endog, self.exog, family=self.family, offset=offset, freq_weights=self.weights)\n    result = model.fit()\n    return result.params",
        "mutated": [
            "def _starting_params(self):\n    if False:\n        i = 10\n    if np.isscalar(self._offset_exposure):\n        offset = None\n    else:\n        offset = self._offset_exposure\n    model = GLM(self.endog, self.exog, family=self.family, offset=offset, freq_weights=self.weights)\n    result = model.fit()\n    return result.params",
            "def _starting_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if np.isscalar(self._offset_exposure):\n        offset = None\n    else:\n        offset = self._offset_exposure\n    model = GLM(self.endog, self.exog, family=self.family, offset=offset, freq_weights=self.weights)\n    result = model.fit()\n    return result.params",
            "def _starting_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if np.isscalar(self._offset_exposure):\n        offset = None\n    else:\n        offset = self._offset_exposure\n    model = GLM(self.endog, self.exog, family=self.family, offset=offset, freq_weights=self.weights)\n    result = model.fit()\n    return result.params",
            "def _starting_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if np.isscalar(self._offset_exposure):\n        offset = None\n    else:\n        offset = self._offset_exposure\n    model = GLM(self.endog, self.exog, family=self.family, offset=offset, freq_weights=self.weights)\n    result = model.fit()\n    return result.params",
            "def _starting_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if np.isscalar(self._offset_exposure):\n        offset = None\n    else:\n        offset = self._offset_exposure\n    model = GLM(self.endog, self.exog, family=self.family, offset=offset, freq_weights=self.weights)\n    result = model.fit()\n    return result.params"
        ]
    },
    {
        "func_name": "fit",
        "original": "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust', ddof_scale=None, scaling_factor=1.0, scale=None):\n    self.scaletype = scale\n    if ddof_scale is None:\n        self.ddof_scale = self.exog.shape[1]\n    else:\n        if not ddof_scale >= 0:\n            raise ValueError('ddof_scale must be a non-negative number or None')\n        self.ddof_scale = ddof_scale\n    self.scaling_factor = scaling_factor\n    self._fit_history = defaultdict(list)\n    if self.weights is not None and cov_type == 'naive':\n        raise ValueError('when using weights, cov_type may not be naive')\n    if start_params is None:\n        mean_params = self._starting_params()\n    else:\n        start_params = np.asarray(start_params)\n        mean_params = start_params.copy()\n    self.update_cached_means(mean_params)\n    del_params = -1.0\n    num_assoc_updates = 0\n    for itr in range(maxiter):\n        (update, score) = self._update_mean_params()\n        if update is None:\n            warnings.warn('Singular matrix encountered in GEE update', ConvergenceWarning)\n            break\n        mean_params += update\n        self.update_cached_means(mean_params)\n        del_params = np.sqrt(np.sum(score ** 2))\n        self._fit_history['params'].append(mean_params.copy())\n        self._fit_history['score'].append(score)\n        self._fit_history['dep_params'].append(self.cov_struct.dep_params)\n        if del_params < ctol and (num_assoc_updates > 0 or self.update_dep is False):\n            break\n        if self.update_dep and itr % params_niter == 0 and (itr >= first_dep_update):\n            self._update_assoc(mean_params)\n            num_assoc_updates += 1\n    if del_params >= ctol:\n        warnings.warn('Iteration limit reached prior to convergence', IterationLimitWarning)\n    if mean_params is None:\n        warnings.warn('Unable to estimate GEE parameters.', ConvergenceWarning)\n        return None\n    (bcov, ncov, _) = self._covmat()\n    if bcov is None:\n        warnings.warn('Estimated covariance structure for GEE estimates is singular', ConvergenceWarning)\n        return None\n    bc_cov = None\n    if cov_type == 'bias_reduced':\n        bc_cov = self._bc_covmat(ncov)\n    if self.constraint is not None:\n        x = mean_params.copy()\n        (mean_params, bcov) = self._handle_constraint(mean_params, bcov)\n        if mean_params is None:\n            warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n            return None\n        (y, ncov) = self._handle_constraint(x, ncov)\n        if y is None:\n            warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n            return None\n        if bc_cov is not None:\n            (y, bc_cov) = self._handle_constraint(x, bc_cov)\n            if x is None:\n                warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n                return None\n    scale = self.estimate_scale()\n    res_kwds = dict(cov_type=cov_type, cov_robust=bcov, cov_naive=ncov, cov_robust_bc=bc_cov)\n    results = GEEResults(self, mean_params, bcov / scale, scale, cov_type=cov_type, use_t=False, attr_kwds=res_kwds)\n    results.fit_history = self._fit_history\n    self.fit_history = defaultdict(list)\n    results.score_norm = del_params\n    results.converged = del_params < ctol\n    results.cov_struct = self.cov_struct\n    results.params_niter = params_niter\n    results.first_dep_update = first_dep_update\n    results.ctol = ctol\n    results.maxiter = maxiter\n    results._props = ['cov_type', 'use_t', 'cov_params_default', 'cov_robust', 'cov_naive', 'cov_robust_bc', 'fit_history', 'score_norm', 'converged', 'cov_struct', 'params_niter', 'first_dep_update', 'ctol', 'maxiter']\n    return GEEResultsWrapper(results)",
        "mutated": [
            "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust', ddof_scale=None, scaling_factor=1.0, scale=None):\n    if False:\n        i = 10\n    self.scaletype = scale\n    if ddof_scale is None:\n        self.ddof_scale = self.exog.shape[1]\n    else:\n        if not ddof_scale >= 0:\n            raise ValueError('ddof_scale must be a non-negative number or None')\n        self.ddof_scale = ddof_scale\n    self.scaling_factor = scaling_factor\n    self._fit_history = defaultdict(list)\n    if self.weights is not None and cov_type == 'naive':\n        raise ValueError('when using weights, cov_type may not be naive')\n    if start_params is None:\n        mean_params = self._starting_params()\n    else:\n        start_params = np.asarray(start_params)\n        mean_params = start_params.copy()\n    self.update_cached_means(mean_params)\n    del_params = -1.0\n    num_assoc_updates = 0\n    for itr in range(maxiter):\n        (update, score) = self._update_mean_params()\n        if update is None:\n            warnings.warn('Singular matrix encountered in GEE update', ConvergenceWarning)\n            break\n        mean_params += update\n        self.update_cached_means(mean_params)\n        del_params = np.sqrt(np.sum(score ** 2))\n        self._fit_history['params'].append(mean_params.copy())\n        self._fit_history['score'].append(score)\n        self._fit_history['dep_params'].append(self.cov_struct.dep_params)\n        if del_params < ctol and (num_assoc_updates > 0 or self.update_dep is False):\n            break\n        if self.update_dep and itr % params_niter == 0 and (itr >= first_dep_update):\n            self._update_assoc(mean_params)\n            num_assoc_updates += 1\n    if del_params >= ctol:\n        warnings.warn('Iteration limit reached prior to convergence', IterationLimitWarning)\n    if mean_params is None:\n        warnings.warn('Unable to estimate GEE parameters.', ConvergenceWarning)\n        return None\n    (bcov, ncov, _) = self._covmat()\n    if bcov is None:\n        warnings.warn('Estimated covariance structure for GEE estimates is singular', ConvergenceWarning)\n        return None\n    bc_cov = None\n    if cov_type == 'bias_reduced':\n        bc_cov = self._bc_covmat(ncov)\n    if self.constraint is not None:\n        x = mean_params.copy()\n        (mean_params, bcov) = self._handle_constraint(mean_params, bcov)\n        if mean_params is None:\n            warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n            return None\n        (y, ncov) = self._handle_constraint(x, ncov)\n        if y is None:\n            warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n            return None\n        if bc_cov is not None:\n            (y, bc_cov) = self._handle_constraint(x, bc_cov)\n            if x is None:\n                warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n                return None\n    scale = self.estimate_scale()\n    res_kwds = dict(cov_type=cov_type, cov_robust=bcov, cov_naive=ncov, cov_robust_bc=bc_cov)\n    results = GEEResults(self, mean_params, bcov / scale, scale, cov_type=cov_type, use_t=False, attr_kwds=res_kwds)\n    results.fit_history = self._fit_history\n    self.fit_history = defaultdict(list)\n    results.score_norm = del_params\n    results.converged = del_params < ctol\n    results.cov_struct = self.cov_struct\n    results.params_niter = params_niter\n    results.first_dep_update = first_dep_update\n    results.ctol = ctol\n    results.maxiter = maxiter\n    results._props = ['cov_type', 'use_t', 'cov_params_default', 'cov_robust', 'cov_naive', 'cov_robust_bc', 'fit_history', 'score_norm', 'converged', 'cov_struct', 'params_niter', 'first_dep_update', 'ctol', 'maxiter']\n    return GEEResultsWrapper(results)",
            "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust', ddof_scale=None, scaling_factor=1.0, scale=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.scaletype = scale\n    if ddof_scale is None:\n        self.ddof_scale = self.exog.shape[1]\n    else:\n        if not ddof_scale >= 0:\n            raise ValueError('ddof_scale must be a non-negative number or None')\n        self.ddof_scale = ddof_scale\n    self.scaling_factor = scaling_factor\n    self._fit_history = defaultdict(list)\n    if self.weights is not None and cov_type == 'naive':\n        raise ValueError('when using weights, cov_type may not be naive')\n    if start_params is None:\n        mean_params = self._starting_params()\n    else:\n        start_params = np.asarray(start_params)\n        mean_params = start_params.copy()\n    self.update_cached_means(mean_params)\n    del_params = -1.0\n    num_assoc_updates = 0\n    for itr in range(maxiter):\n        (update, score) = self._update_mean_params()\n        if update is None:\n            warnings.warn('Singular matrix encountered in GEE update', ConvergenceWarning)\n            break\n        mean_params += update\n        self.update_cached_means(mean_params)\n        del_params = np.sqrt(np.sum(score ** 2))\n        self._fit_history['params'].append(mean_params.copy())\n        self._fit_history['score'].append(score)\n        self._fit_history['dep_params'].append(self.cov_struct.dep_params)\n        if del_params < ctol and (num_assoc_updates > 0 or self.update_dep is False):\n            break\n        if self.update_dep and itr % params_niter == 0 and (itr >= first_dep_update):\n            self._update_assoc(mean_params)\n            num_assoc_updates += 1\n    if del_params >= ctol:\n        warnings.warn('Iteration limit reached prior to convergence', IterationLimitWarning)\n    if mean_params is None:\n        warnings.warn('Unable to estimate GEE parameters.', ConvergenceWarning)\n        return None\n    (bcov, ncov, _) = self._covmat()\n    if bcov is None:\n        warnings.warn('Estimated covariance structure for GEE estimates is singular', ConvergenceWarning)\n        return None\n    bc_cov = None\n    if cov_type == 'bias_reduced':\n        bc_cov = self._bc_covmat(ncov)\n    if self.constraint is not None:\n        x = mean_params.copy()\n        (mean_params, bcov) = self._handle_constraint(mean_params, bcov)\n        if mean_params is None:\n            warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n            return None\n        (y, ncov) = self._handle_constraint(x, ncov)\n        if y is None:\n            warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n            return None\n        if bc_cov is not None:\n            (y, bc_cov) = self._handle_constraint(x, bc_cov)\n            if x is None:\n                warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n                return None\n    scale = self.estimate_scale()\n    res_kwds = dict(cov_type=cov_type, cov_robust=bcov, cov_naive=ncov, cov_robust_bc=bc_cov)\n    results = GEEResults(self, mean_params, bcov / scale, scale, cov_type=cov_type, use_t=False, attr_kwds=res_kwds)\n    results.fit_history = self._fit_history\n    self.fit_history = defaultdict(list)\n    results.score_norm = del_params\n    results.converged = del_params < ctol\n    results.cov_struct = self.cov_struct\n    results.params_niter = params_niter\n    results.first_dep_update = first_dep_update\n    results.ctol = ctol\n    results.maxiter = maxiter\n    results._props = ['cov_type', 'use_t', 'cov_params_default', 'cov_robust', 'cov_naive', 'cov_robust_bc', 'fit_history', 'score_norm', 'converged', 'cov_struct', 'params_niter', 'first_dep_update', 'ctol', 'maxiter']\n    return GEEResultsWrapper(results)",
            "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust', ddof_scale=None, scaling_factor=1.0, scale=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.scaletype = scale\n    if ddof_scale is None:\n        self.ddof_scale = self.exog.shape[1]\n    else:\n        if not ddof_scale >= 0:\n            raise ValueError('ddof_scale must be a non-negative number or None')\n        self.ddof_scale = ddof_scale\n    self.scaling_factor = scaling_factor\n    self._fit_history = defaultdict(list)\n    if self.weights is not None and cov_type == 'naive':\n        raise ValueError('when using weights, cov_type may not be naive')\n    if start_params is None:\n        mean_params = self._starting_params()\n    else:\n        start_params = np.asarray(start_params)\n        mean_params = start_params.copy()\n    self.update_cached_means(mean_params)\n    del_params = -1.0\n    num_assoc_updates = 0\n    for itr in range(maxiter):\n        (update, score) = self._update_mean_params()\n        if update is None:\n            warnings.warn('Singular matrix encountered in GEE update', ConvergenceWarning)\n            break\n        mean_params += update\n        self.update_cached_means(mean_params)\n        del_params = np.sqrt(np.sum(score ** 2))\n        self._fit_history['params'].append(mean_params.copy())\n        self._fit_history['score'].append(score)\n        self._fit_history['dep_params'].append(self.cov_struct.dep_params)\n        if del_params < ctol and (num_assoc_updates > 0 or self.update_dep is False):\n            break\n        if self.update_dep and itr % params_niter == 0 and (itr >= first_dep_update):\n            self._update_assoc(mean_params)\n            num_assoc_updates += 1\n    if del_params >= ctol:\n        warnings.warn('Iteration limit reached prior to convergence', IterationLimitWarning)\n    if mean_params is None:\n        warnings.warn('Unable to estimate GEE parameters.', ConvergenceWarning)\n        return None\n    (bcov, ncov, _) = self._covmat()\n    if bcov is None:\n        warnings.warn('Estimated covariance structure for GEE estimates is singular', ConvergenceWarning)\n        return None\n    bc_cov = None\n    if cov_type == 'bias_reduced':\n        bc_cov = self._bc_covmat(ncov)\n    if self.constraint is not None:\n        x = mean_params.copy()\n        (mean_params, bcov) = self._handle_constraint(mean_params, bcov)\n        if mean_params is None:\n            warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n            return None\n        (y, ncov) = self._handle_constraint(x, ncov)\n        if y is None:\n            warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n            return None\n        if bc_cov is not None:\n            (y, bc_cov) = self._handle_constraint(x, bc_cov)\n            if x is None:\n                warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n                return None\n    scale = self.estimate_scale()\n    res_kwds = dict(cov_type=cov_type, cov_robust=bcov, cov_naive=ncov, cov_robust_bc=bc_cov)\n    results = GEEResults(self, mean_params, bcov / scale, scale, cov_type=cov_type, use_t=False, attr_kwds=res_kwds)\n    results.fit_history = self._fit_history\n    self.fit_history = defaultdict(list)\n    results.score_norm = del_params\n    results.converged = del_params < ctol\n    results.cov_struct = self.cov_struct\n    results.params_niter = params_niter\n    results.first_dep_update = first_dep_update\n    results.ctol = ctol\n    results.maxiter = maxiter\n    results._props = ['cov_type', 'use_t', 'cov_params_default', 'cov_robust', 'cov_naive', 'cov_robust_bc', 'fit_history', 'score_norm', 'converged', 'cov_struct', 'params_niter', 'first_dep_update', 'ctol', 'maxiter']\n    return GEEResultsWrapper(results)",
            "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust', ddof_scale=None, scaling_factor=1.0, scale=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.scaletype = scale\n    if ddof_scale is None:\n        self.ddof_scale = self.exog.shape[1]\n    else:\n        if not ddof_scale >= 0:\n            raise ValueError('ddof_scale must be a non-negative number or None')\n        self.ddof_scale = ddof_scale\n    self.scaling_factor = scaling_factor\n    self._fit_history = defaultdict(list)\n    if self.weights is not None and cov_type == 'naive':\n        raise ValueError('when using weights, cov_type may not be naive')\n    if start_params is None:\n        mean_params = self._starting_params()\n    else:\n        start_params = np.asarray(start_params)\n        mean_params = start_params.copy()\n    self.update_cached_means(mean_params)\n    del_params = -1.0\n    num_assoc_updates = 0\n    for itr in range(maxiter):\n        (update, score) = self._update_mean_params()\n        if update is None:\n            warnings.warn('Singular matrix encountered in GEE update', ConvergenceWarning)\n            break\n        mean_params += update\n        self.update_cached_means(mean_params)\n        del_params = np.sqrt(np.sum(score ** 2))\n        self._fit_history['params'].append(mean_params.copy())\n        self._fit_history['score'].append(score)\n        self._fit_history['dep_params'].append(self.cov_struct.dep_params)\n        if del_params < ctol and (num_assoc_updates > 0 or self.update_dep is False):\n            break\n        if self.update_dep and itr % params_niter == 0 and (itr >= first_dep_update):\n            self._update_assoc(mean_params)\n            num_assoc_updates += 1\n    if del_params >= ctol:\n        warnings.warn('Iteration limit reached prior to convergence', IterationLimitWarning)\n    if mean_params is None:\n        warnings.warn('Unable to estimate GEE parameters.', ConvergenceWarning)\n        return None\n    (bcov, ncov, _) = self._covmat()\n    if bcov is None:\n        warnings.warn('Estimated covariance structure for GEE estimates is singular', ConvergenceWarning)\n        return None\n    bc_cov = None\n    if cov_type == 'bias_reduced':\n        bc_cov = self._bc_covmat(ncov)\n    if self.constraint is not None:\n        x = mean_params.copy()\n        (mean_params, bcov) = self._handle_constraint(mean_params, bcov)\n        if mean_params is None:\n            warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n            return None\n        (y, ncov) = self._handle_constraint(x, ncov)\n        if y is None:\n            warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n            return None\n        if bc_cov is not None:\n            (y, bc_cov) = self._handle_constraint(x, bc_cov)\n            if x is None:\n                warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n                return None\n    scale = self.estimate_scale()\n    res_kwds = dict(cov_type=cov_type, cov_robust=bcov, cov_naive=ncov, cov_robust_bc=bc_cov)\n    results = GEEResults(self, mean_params, bcov / scale, scale, cov_type=cov_type, use_t=False, attr_kwds=res_kwds)\n    results.fit_history = self._fit_history\n    self.fit_history = defaultdict(list)\n    results.score_norm = del_params\n    results.converged = del_params < ctol\n    results.cov_struct = self.cov_struct\n    results.params_niter = params_niter\n    results.first_dep_update = first_dep_update\n    results.ctol = ctol\n    results.maxiter = maxiter\n    results._props = ['cov_type', 'use_t', 'cov_params_default', 'cov_robust', 'cov_naive', 'cov_robust_bc', 'fit_history', 'score_norm', 'converged', 'cov_struct', 'params_niter', 'first_dep_update', 'ctol', 'maxiter']\n    return GEEResultsWrapper(results)",
            "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust', ddof_scale=None, scaling_factor=1.0, scale=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.scaletype = scale\n    if ddof_scale is None:\n        self.ddof_scale = self.exog.shape[1]\n    else:\n        if not ddof_scale >= 0:\n            raise ValueError('ddof_scale must be a non-negative number or None')\n        self.ddof_scale = ddof_scale\n    self.scaling_factor = scaling_factor\n    self._fit_history = defaultdict(list)\n    if self.weights is not None and cov_type == 'naive':\n        raise ValueError('when using weights, cov_type may not be naive')\n    if start_params is None:\n        mean_params = self._starting_params()\n    else:\n        start_params = np.asarray(start_params)\n        mean_params = start_params.copy()\n    self.update_cached_means(mean_params)\n    del_params = -1.0\n    num_assoc_updates = 0\n    for itr in range(maxiter):\n        (update, score) = self._update_mean_params()\n        if update is None:\n            warnings.warn('Singular matrix encountered in GEE update', ConvergenceWarning)\n            break\n        mean_params += update\n        self.update_cached_means(mean_params)\n        del_params = np.sqrt(np.sum(score ** 2))\n        self._fit_history['params'].append(mean_params.copy())\n        self._fit_history['score'].append(score)\n        self._fit_history['dep_params'].append(self.cov_struct.dep_params)\n        if del_params < ctol and (num_assoc_updates > 0 or self.update_dep is False):\n            break\n        if self.update_dep and itr % params_niter == 0 and (itr >= first_dep_update):\n            self._update_assoc(mean_params)\n            num_assoc_updates += 1\n    if del_params >= ctol:\n        warnings.warn('Iteration limit reached prior to convergence', IterationLimitWarning)\n    if mean_params is None:\n        warnings.warn('Unable to estimate GEE parameters.', ConvergenceWarning)\n        return None\n    (bcov, ncov, _) = self._covmat()\n    if bcov is None:\n        warnings.warn('Estimated covariance structure for GEE estimates is singular', ConvergenceWarning)\n        return None\n    bc_cov = None\n    if cov_type == 'bias_reduced':\n        bc_cov = self._bc_covmat(ncov)\n    if self.constraint is not None:\n        x = mean_params.copy()\n        (mean_params, bcov) = self._handle_constraint(mean_params, bcov)\n        if mean_params is None:\n            warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n            return None\n        (y, ncov) = self._handle_constraint(x, ncov)\n        if y is None:\n            warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n            return None\n        if bc_cov is not None:\n            (y, bc_cov) = self._handle_constraint(x, bc_cov)\n            if x is None:\n                warnings.warn('Unable to estimate constrained GEE parameters.', ConvergenceWarning)\n                return None\n    scale = self.estimate_scale()\n    res_kwds = dict(cov_type=cov_type, cov_robust=bcov, cov_naive=ncov, cov_robust_bc=bc_cov)\n    results = GEEResults(self, mean_params, bcov / scale, scale, cov_type=cov_type, use_t=False, attr_kwds=res_kwds)\n    results.fit_history = self._fit_history\n    self.fit_history = defaultdict(list)\n    results.score_norm = del_params\n    results.converged = del_params < ctol\n    results.cov_struct = self.cov_struct\n    results.params_niter = params_niter\n    results.first_dep_update = first_dep_update\n    results.ctol = ctol\n    results.maxiter = maxiter\n    results._props = ['cov_type', 'use_t', 'cov_params_default', 'cov_robust', 'cov_naive', 'cov_robust_bc', 'fit_history', 'score_norm', 'converged', 'cov_struct', 'params_niter', 'first_dep_update', 'ctol', 'maxiter']\n    return GEEResultsWrapper(results)"
        ]
    },
    {
        "func_name": "_update_regularized",
        "original": "def _update_regularized(self, params, pen_wt, scad_param, eps):\n    (sn, hm) = (0, 0)\n    for i in range(self.num_group):\n        (expval, _) = self.cached_means[i]\n        resid = self.endog_li[i] - expval\n        sdev = np.sqrt(self.family.variance(expval))\n        ex = self.exog_li[i] * sdev[:, None] ** 2\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (resid, ex))\n        sn0 = rslt[0]\n        sn += np.dot(ex.T, sn0)\n        hm0 = rslt[1]\n        hm += np.dot(ex.T, hm0)\n    ap = np.abs(params)\n    clipped = np.clip(scad_param * pen_wt - ap, 0, np.inf)\n    en = pen_wt * clipped * (ap > pen_wt)\n    en /= (scad_param - 1) * pen_wt\n    en += pen_wt * (ap <= pen_wt)\n    en /= eps + ap\n    hm.flat[::hm.shape[0] + 1] += self.num_group * en\n    sn -= self.num_group * en * params\n    try:\n        update = np.linalg.solve(hm, sn)\n    except np.linalg.LinAlgError:\n        update = np.dot(np.linalg.pinv(hm), sn)\n        msg = 'Encountered singularity in regularized GEE update'\n        warnings.warn(msg)\n    hm *= self.estimate_scale()\n    return (update, hm)",
        "mutated": [
            "def _update_regularized(self, params, pen_wt, scad_param, eps):\n    if False:\n        i = 10\n    (sn, hm) = (0, 0)\n    for i in range(self.num_group):\n        (expval, _) = self.cached_means[i]\n        resid = self.endog_li[i] - expval\n        sdev = np.sqrt(self.family.variance(expval))\n        ex = self.exog_li[i] * sdev[:, None] ** 2\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (resid, ex))\n        sn0 = rslt[0]\n        sn += np.dot(ex.T, sn0)\n        hm0 = rslt[1]\n        hm += np.dot(ex.T, hm0)\n    ap = np.abs(params)\n    clipped = np.clip(scad_param * pen_wt - ap, 0, np.inf)\n    en = pen_wt * clipped * (ap > pen_wt)\n    en /= (scad_param - 1) * pen_wt\n    en += pen_wt * (ap <= pen_wt)\n    en /= eps + ap\n    hm.flat[::hm.shape[0] + 1] += self.num_group * en\n    sn -= self.num_group * en * params\n    try:\n        update = np.linalg.solve(hm, sn)\n    except np.linalg.LinAlgError:\n        update = np.dot(np.linalg.pinv(hm), sn)\n        msg = 'Encountered singularity in regularized GEE update'\n        warnings.warn(msg)\n    hm *= self.estimate_scale()\n    return (update, hm)",
            "def _update_regularized(self, params, pen_wt, scad_param, eps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (sn, hm) = (0, 0)\n    for i in range(self.num_group):\n        (expval, _) = self.cached_means[i]\n        resid = self.endog_li[i] - expval\n        sdev = np.sqrt(self.family.variance(expval))\n        ex = self.exog_li[i] * sdev[:, None] ** 2\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (resid, ex))\n        sn0 = rslt[0]\n        sn += np.dot(ex.T, sn0)\n        hm0 = rslt[1]\n        hm += np.dot(ex.T, hm0)\n    ap = np.abs(params)\n    clipped = np.clip(scad_param * pen_wt - ap, 0, np.inf)\n    en = pen_wt * clipped * (ap > pen_wt)\n    en /= (scad_param - 1) * pen_wt\n    en += pen_wt * (ap <= pen_wt)\n    en /= eps + ap\n    hm.flat[::hm.shape[0] + 1] += self.num_group * en\n    sn -= self.num_group * en * params\n    try:\n        update = np.linalg.solve(hm, sn)\n    except np.linalg.LinAlgError:\n        update = np.dot(np.linalg.pinv(hm), sn)\n        msg = 'Encountered singularity in regularized GEE update'\n        warnings.warn(msg)\n    hm *= self.estimate_scale()\n    return (update, hm)",
            "def _update_regularized(self, params, pen_wt, scad_param, eps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (sn, hm) = (0, 0)\n    for i in range(self.num_group):\n        (expval, _) = self.cached_means[i]\n        resid = self.endog_li[i] - expval\n        sdev = np.sqrt(self.family.variance(expval))\n        ex = self.exog_li[i] * sdev[:, None] ** 2\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (resid, ex))\n        sn0 = rslt[0]\n        sn += np.dot(ex.T, sn0)\n        hm0 = rslt[1]\n        hm += np.dot(ex.T, hm0)\n    ap = np.abs(params)\n    clipped = np.clip(scad_param * pen_wt - ap, 0, np.inf)\n    en = pen_wt * clipped * (ap > pen_wt)\n    en /= (scad_param - 1) * pen_wt\n    en += pen_wt * (ap <= pen_wt)\n    en /= eps + ap\n    hm.flat[::hm.shape[0] + 1] += self.num_group * en\n    sn -= self.num_group * en * params\n    try:\n        update = np.linalg.solve(hm, sn)\n    except np.linalg.LinAlgError:\n        update = np.dot(np.linalg.pinv(hm), sn)\n        msg = 'Encountered singularity in regularized GEE update'\n        warnings.warn(msg)\n    hm *= self.estimate_scale()\n    return (update, hm)",
            "def _update_regularized(self, params, pen_wt, scad_param, eps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (sn, hm) = (0, 0)\n    for i in range(self.num_group):\n        (expval, _) = self.cached_means[i]\n        resid = self.endog_li[i] - expval\n        sdev = np.sqrt(self.family.variance(expval))\n        ex = self.exog_li[i] * sdev[:, None] ** 2\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (resid, ex))\n        sn0 = rslt[0]\n        sn += np.dot(ex.T, sn0)\n        hm0 = rslt[1]\n        hm += np.dot(ex.T, hm0)\n    ap = np.abs(params)\n    clipped = np.clip(scad_param * pen_wt - ap, 0, np.inf)\n    en = pen_wt * clipped * (ap > pen_wt)\n    en /= (scad_param - 1) * pen_wt\n    en += pen_wt * (ap <= pen_wt)\n    en /= eps + ap\n    hm.flat[::hm.shape[0] + 1] += self.num_group * en\n    sn -= self.num_group * en * params\n    try:\n        update = np.linalg.solve(hm, sn)\n    except np.linalg.LinAlgError:\n        update = np.dot(np.linalg.pinv(hm), sn)\n        msg = 'Encountered singularity in regularized GEE update'\n        warnings.warn(msg)\n    hm *= self.estimate_scale()\n    return (update, hm)",
            "def _update_regularized(self, params, pen_wt, scad_param, eps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (sn, hm) = (0, 0)\n    for i in range(self.num_group):\n        (expval, _) = self.cached_means[i]\n        resid = self.endog_li[i] - expval\n        sdev = np.sqrt(self.family.variance(expval))\n        ex = self.exog_li[i] * sdev[:, None] ** 2\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (resid, ex))\n        sn0 = rslt[0]\n        sn += np.dot(ex.T, sn0)\n        hm0 = rslt[1]\n        hm += np.dot(ex.T, hm0)\n    ap = np.abs(params)\n    clipped = np.clip(scad_param * pen_wt - ap, 0, np.inf)\n    en = pen_wt * clipped * (ap > pen_wt)\n    en /= (scad_param - 1) * pen_wt\n    en += pen_wt * (ap <= pen_wt)\n    en /= eps + ap\n    hm.flat[::hm.shape[0] + 1] += self.num_group * en\n    sn -= self.num_group * en * params\n    try:\n        update = np.linalg.solve(hm, sn)\n    except np.linalg.LinAlgError:\n        update = np.dot(np.linalg.pinv(hm), sn)\n        msg = 'Encountered singularity in regularized GEE update'\n        warnings.warn(msg)\n    hm *= self.estimate_scale()\n    return (update, hm)"
        ]
    },
    {
        "func_name": "_regularized_covmat",
        "original": "def _regularized_covmat(self, mean_params):\n    self.update_cached_means(mean_params)\n    ma = 0\n    for i in range(self.num_group):\n        (expval, _) = self.cached_means[i]\n        resid = self.endog_li[i] - expval\n        sdev = np.sqrt(self.family.variance(expval))\n        ex = self.exog_li[i] * sdev[:, None] ** 2\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (resid,))\n        ma0 = np.dot(ex.T, rslt[0])\n        ma += np.outer(ma0, ma0)\n    return ma",
        "mutated": [
            "def _regularized_covmat(self, mean_params):\n    if False:\n        i = 10\n    self.update_cached_means(mean_params)\n    ma = 0\n    for i in range(self.num_group):\n        (expval, _) = self.cached_means[i]\n        resid = self.endog_li[i] - expval\n        sdev = np.sqrt(self.family.variance(expval))\n        ex = self.exog_li[i] * sdev[:, None] ** 2\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (resid,))\n        ma0 = np.dot(ex.T, rslt[0])\n        ma += np.outer(ma0, ma0)\n    return ma",
            "def _regularized_covmat(self, mean_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.update_cached_means(mean_params)\n    ma = 0\n    for i in range(self.num_group):\n        (expval, _) = self.cached_means[i]\n        resid = self.endog_li[i] - expval\n        sdev = np.sqrt(self.family.variance(expval))\n        ex = self.exog_li[i] * sdev[:, None] ** 2\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (resid,))\n        ma0 = np.dot(ex.T, rslt[0])\n        ma += np.outer(ma0, ma0)\n    return ma",
            "def _regularized_covmat(self, mean_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.update_cached_means(mean_params)\n    ma = 0\n    for i in range(self.num_group):\n        (expval, _) = self.cached_means[i]\n        resid = self.endog_li[i] - expval\n        sdev = np.sqrt(self.family.variance(expval))\n        ex = self.exog_li[i] * sdev[:, None] ** 2\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (resid,))\n        ma0 = np.dot(ex.T, rslt[0])\n        ma += np.outer(ma0, ma0)\n    return ma",
            "def _regularized_covmat(self, mean_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.update_cached_means(mean_params)\n    ma = 0\n    for i in range(self.num_group):\n        (expval, _) = self.cached_means[i]\n        resid = self.endog_li[i] - expval\n        sdev = np.sqrt(self.family.variance(expval))\n        ex = self.exog_li[i] * sdev[:, None] ** 2\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (resid,))\n        ma0 = np.dot(ex.T, rslt[0])\n        ma += np.outer(ma0, ma0)\n    return ma",
            "def _regularized_covmat(self, mean_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.update_cached_means(mean_params)\n    ma = 0\n    for i in range(self.num_group):\n        (expval, _) = self.cached_means[i]\n        resid = self.endog_li[i] - expval\n        sdev = np.sqrt(self.family.variance(expval))\n        ex = self.exog_li[i] * sdev[:, None] ** 2\n        rslt = self.cov_struct.covariance_matrix_solve(expval, i, sdev, (resid,))\n        ma0 = np.dot(ex.T, rslt[0])\n        ma += np.outer(ma0, ma0)\n    return ma"
        ]
    },
    {
        "func_name": "fit_regularized",
        "original": "def fit_regularized(self, pen_wt, scad_param=3.7, maxiter=100, ddof_scale=None, update_assoc=5, ctol=1e-05, ztol=0.001, eps=1e-06, scale=None):\n    \"\"\"\n        Regularized estimation for GEE.\n\n        Parameters\n        ----------\n        pen_wt : float\n            The penalty weight (a non-negative scalar).\n        scad_param : float\n            Non-negative scalar determining the shape of the Scad\n            penalty.\n        maxiter : int\n            The maximum number of iterations.\n        ddof_scale : int\n            Value to subtract from `nobs` when calculating the\n            denominator degrees of freedom for t-statistics, defaults\n            to the number of columns in `exog`.\n        update_assoc : int\n            The dependence parameters are updated every `update_assoc`\n            iterations of the mean structure parameter updates.\n        ctol : float\n            Convergence criterion, default is one order of magnitude\n            smaller than proposed in section 3.1 of Wang et al.\n        ztol : float\n            Coefficients smaller than this value are treated as\n            being zero, default is based on section 5 of Wang et al.\n        eps : non-negative scalar\n            Numerical constant, see section 3.2 of Wang et al.\n        scale : float or string\n            If a float, this value is used as the scale parameter.\n            If \"X2\", the scale parameter is always estimated using\n            Pearson's chi-square method (e.g. as in a quasi-Poisson\n            analysis).  If None, the default approach for the family\n            is used to estimate the scale parameter.\n\n        Returns\n        -------\n        GEEResults instance.  Note that not all methods of the results\n        class make sense when the model has been fit with regularization.\n\n        Notes\n        -----\n        This implementation assumes that the link is canonical.\n\n        References\n        ----------\n        Wang L, Zhou J, Qu A. (2012). Penalized generalized estimating\n        equations for high-dimensional longitudinal data analysis.\n        Biometrics. 2012 Jun;68(2):353-60.\n        doi: 10.1111/j.1541-0420.2011.01678.x.\n        https://www.ncbi.nlm.nih.gov/pubmed/21955051\n        http://users.stat.umn.edu/~wangx346/research/GEE_selection.pdf\n        \"\"\"\n    self.scaletype = scale\n    mean_params = np.zeros(self.exog.shape[1])\n    self.update_cached_means(mean_params)\n    converged = False\n    fit_history = defaultdict(list)\n    if ddof_scale is None:\n        self.ddof_scale = self.exog.shape[1]\n    else:\n        if not ddof_scale >= 0:\n            raise ValueError('ddof_scale must be a non-negative number or None')\n        self.ddof_scale = ddof_scale\n    miniter = 20\n    for itr in range(maxiter):\n        (update, hm) = self._update_regularized(mean_params, pen_wt, scad_param, eps)\n        if update is None:\n            msg = 'Singular matrix encountered in regularized GEE update'\n            warnings.warn(msg, ConvergenceWarning)\n            break\n        if itr > miniter and np.sqrt(np.sum(update ** 2)) < ctol:\n            converged = True\n            break\n        mean_params += update\n        fit_history['params'].append(mean_params.copy())\n        self.update_cached_means(mean_params)\n        if itr != 0 and itr % update_assoc == 0:\n            self._update_assoc(mean_params)\n    if not converged:\n        msg = 'GEE.fit_regularized did not converge'\n        warnings.warn(msg)\n    mean_params[np.abs(mean_params) < ztol] = 0\n    self._update_assoc(mean_params)\n    ma = self._regularized_covmat(mean_params)\n    cov = np.linalg.solve(hm, ma)\n    cov = np.linalg.solve(hm, cov.T)\n    res_kwds = dict(cov_type='robust', cov_robust=cov)\n    scale = self.estimate_scale()\n    rslt = GEEResults(self, mean_params, cov, scale, regularized=True, attr_kwds=res_kwds)\n    rslt.fit_history = fit_history\n    return GEEResultsWrapper(rslt)",
        "mutated": [
            "def fit_regularized(self, pen_wt, scad_param=3.7, maxiter=100, ddof_scale=None, update_assoc=5, ctol=1e-05, ztol=0.001, eps=1e-06, scale=None):\n    if False:\n        i = 10\n    '\\n        Regularized estimation for GEE.\\n\\n        Parameters\\n        ----------\\n        pen_wt : float\\n            The penalty weight (a non-negative scalar).\\n        scad_param : float\\n            Non-negative scalar determining the shape of the Scad\\n            penalty.\\n        maxiter : int\\n            The maximum number of iterations.\\n        ddof_scale : int\\n            Value to subtract from `nobs` when calculating the\\n            denominator degrees of freedom for t-statistics, defaults\\n            to the number of columns in `exog`.\\n        update_assoc : int\\n            The dependence parameters are updated every `update_assoc`\\n            iterations of the mean structure parameter updates.\\n        ctol : float\\n            Convergence criterion, default is one order of magnitude\\n            smaller than proposed in section 3.1 of Wang et al.\\n        ztol : float\\n            Coefficients smaller than this value are treated as\\n            being zero, default is based on section 5 of Wang et al.\\n        eps : non-negative scalar\\n            Numerical constant, see section 3.2 of Wang et al.\\n        scale : float or string\\n            If a float, this value is used as the scale parameter.\\n            If \"X2\", the scale parameter is always estimated using\\n            Pearson\\'s chi-square method (e.g. as in a quasi-Poisson\\n            analysis).  If None, the default approach for the family\\n            is used to estimate the scale parameter.\\n\\n        Returns\\n        -------\\n        GEEResults instance.  Note that not all methods of the results\\n        class make sense when the model has been fit with regularization.\\n\\n        Notes\\n        -----\\n        This implementation assumes that the link is canonical.\\n\\n        References\\n        ----------\\n        Wang L, Zhou J, Qu A. (2012). Penalized generalized estimating\\n        equations for high-dimensional longitudinal data analysis.\\n        Biometrics. 2012 Jun;68(2):353-60.\\n        doi: 10.1111/j.1541-0420.2011.01678.x.\\n        https://www.ncbi.nlm.nih.gov/pubmed/21955051\\n        http://users.stat.umn.edu/~wangx346/research/GEE_selection.pdf\\n        '\n    self.scaletype = scale\n    mean_params = np.zeros(self.exog.shape[1])\n    self.update_cached_means(mean_params)\n    converged = False\n    fit_history = defaultdict(list)\n    if ddof_scale is None:\n        self.ddof_scale = self.exog.shape[1]\n    else:\n        if not ddof_scale >= 0:\n            raise ValueError('ddof_scale must be a non-negative number or None')\n        self.ddof_scale = ddof_scale\n    miniter = 20\n    for itr in range(maxiter):\n        (update, hm) = self._update_regularized(mean_params, pen_wt, scad_param, eps)\n        if update is None:\n            msg = 'Singular matrix encountered in regularized GEE update'\n            warnings.warn(msg, ConvergenceWarning)\n            break\n        if itr > miniter and np.sqrt(np.sum(update ** 2)) < ctol:\n            converged = True\n            break\n        mean_params += update\n        fit_history['params'].append(mean_params.copy())\n        self.update_cached_means(mean_params)\n        if itr != 0 and itr % update_assoc == 0:\n            self._update_assoc(mean_params)\n    if not converged:\n        msg = 'GEE.fit_regularized did not converge'\n        warnings.warn(msg)\n    mean_params[np.abs(mean_params) < ztol] = 0\n    self._update_assoc(mean_params)\n    ma = self._regularized_covmat(mean_params)\n    cov = np.linalg.solve(hm, ma)\n    cov = np.linalg.solve(hm, cov.T)\n    res_kwds = dict(cov_type='robust', cov_robust=cov)\n    scale = self.estimate_scale()\n    rslt = GEEResults(self, mean_params, cov, scale, regularized=True, attr_kwds=res_kwds)\n    rslt.fit_history = fit_history\n    return GEEResultsWrapper(rslt)",
            "def fit_regularized(self, pen_wt, scad_param=3.7, maxiter=100, ddof_scale=None, update_assoc=5, ctol=1e-05, ztol=0.001, eps=1e-06, scale=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Regularized estimation for GEE.\\n\\n        Parameters\\n        ----------\\n        pen_wt : float\\n            The penalty weight (a non-negative scalar).\\n        scad_param : float\\n            Non-negative scalar determining the shape of the Scad\\n            penalty.\\n        maxiter : int\\n            The maximum number of iterations.\\n        ddof_scale : int\\n            Value to subtract from `nobs` when calculating the\\n            denominator degrees of freedom for t-statistics, defaults\\n            to the number of columns in `exog`.\\n        update_assoc : int\\n            The dependence parameters are updated every `update_assoc`\\n            iterations of the mean structure parameter updates.\\n        ctol : float\\n            Convergence criterion, default is one order of magnitude\\n            smaller than proposed in section 3.1 of Wang et al.\\n        ztol : float\\n            Coefficients smaller than this value are treated as\\n            being zero, default is based on section 5 of Wang et al.\\n        eps : non-negative scalar\\n            Numerical constant, see section 3.2 of Wang et al.\\n        scale : float or string\\n            If a float, this value is used as the scale parameter.\\n            If \"X2\", the scale parameter is always estimated using\\n            Pearson\\'s chi-square method (e.g. as in a quasi-Poisson\\n            analysis).  If None, the default approach for the family\\n            is used to estimate the scale parameter.\\n\\n        Returns\\n        -------\\n        GEEResults instance.  Note that not all methods of the results\\n        class make sense when the model has been fit with regularization.\\n\\n        Notes\\n        -----\\n        This implementation assumes that the link is canonical.\\n\\n        References\\n        ----------\\n        Wang L, Zhou J, Qu A. (2012). Penalized generalized estimating\\n        equations for high-dimensional longitudinal data analysis.\\n        Biometrics. 2012 Jun;68(2):353-60.\\n        doi: 10.1111/j.1541-0420.2011.01678.x.\\n        https://www.ncbi.nlm.nih.gov/pubmed/21955051\\n        http://users.stat.umn.edu/~wangx346/research/GEE_selection.pdf\\n        '\n    self.scaletype = scale\n    mean_params = np.zeros(self.exog.shape[1])\n    self.update_cached_means(mean_params)\n    converged = False\n    fit_history = defaultdict(list)\n    if ddof_scale is None:\n        self.ddof_scale = self.exog.shape[1]\n    else:\n        if not ddof_scale >= 0:\n            raise ValueError('ddof_scale must be a non-negative number or None')\n        self.ddof_scale = ddof_scale\n    miniter = 20\n    for itr in range(maxiter):\n        (update, hm) = self._update_regularized(mean_params, pen_wt, scad_param, eps)\n        if update is None:\n            msg = 'Singular matrix encountered in regularized GEE update'\n            warnings.warn(msg, ConvergenceWarning)\n            break\n        if itr > miniter and np.sqrt(np.sum(update ** 2)) < ctol:\n            converged = True\n            break\n        mean_params += update\n        fit_history['params'].append(mean_params.copy())\n        self.update_cached_means(mean_params)\n        if itr != 0 and itr % update_assoc == 0:\n            self._update_assoc(mean_params)\n    if not converged:\n        msg = 'GEE.fit_regularized did not converge'\n        warnings.warn(msg)\n    mean_params[np.abs(mean_params) < ztol] = 0\n    self._update_assoc(mean_params)\n    ma = self._regularized_covmat(mean_params)\n    cov = np.linalg.solve(hm, ma)\n    cov = np.linalg.solve(hm, cov.T)\n    res_kwds = dict(cov_type='robust', cov_robust=cov)\n    scale = self.estimate_scale()\n    rslt = GEEResults(self, mean_params, cov, scale, regularized=True, attr_kwds=res_kwds)\n    rslt.fit_history = fit_history\n    return GEEResultsWrapper(rslt)",
            "def fit_regularized(self, pen_wt, scad_param=3.7, maxiter=100, ddof_scale=None, update_assoc=5, ctol=1e-05, ztol=0.001, eps=1e-06, scale=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Regularized estimation for GEE.\\n\\n        Parameters\\n        ----------\\n        pen_wt : float\\n            The penalty weight (a non-negative scalar).\\n        scad_param : float\\n            Non-negative scalar determining the shape of the Scad\\n            penalty.\\n        maxiter : int\\n            The maximum number of iterations.\\n        ddof_scale : int\\n            Value to subtract from `nobs` when calculating the\\n            denominator degrees of freedom for t-statistics, defaults\\n            to the number of columns in `exog`.\\n        update_assoc : int\\n            The dependence parameters are updated every `update_assoc`\\n            iterations of the mean structure parameter updates.\\n        ctol : float\\n            Convergence criterion, default is one order of magnitude\\n            smaller than proposed in section 3.1 of Wang et al.\\n        ztol : float\\n            Coefficients smaller than this value are treated as\\n            being zero, default is based on section 5 of Wang et al.\\n        eps : non-negative scalar\\n            Numerical constant, see section 3.2 of Wang et al.\\n        scale : float or string\\n            If a float, this value is used as the scale parameter.\\n            If \"X2\", the scale parameter is always estimated using\\n            Pearson\\'s chi-square method (e.g. as in a quasi-Poisson\\n            analysis).  If None, the default approach for the family\\n            is used to estimate the scale parameter.\\n\\n        Returns\\n        -------\\n        GEEResults instance.  Note that not all methods of the results\\n        class make sense when the model has been fit with regularization.\\n\\n        Notes\\n        -----\\n        This implementation assumes that the link is canonical.\\n\\n        References\\n        ----------\\n        Wang L, Zhou J, Qu A. (2012). Penalized generalized estimating\\n        equations for high-dimensional longitudinal data analysis.\\n        Biometrics. 2012 Jun;68(2):353-60.\\n        doi: 10.1111/j.1541-0420.2011.01678.x.\\n        https://www.ncbi.nlm.nih.gov/pubmed/21955051\\n        http://users.stat.umn.edu/~wangx346/research/GEE_selection.pdf\\n        '\n    self.scaletype = scale\n    mean_params = np.zeros(self.exog.shape[1])\n    self.update_cached_means(mean_params)\n    converged = False\n    fit_history = defaultdict(list)\n    if ddof_scale is None:\n        self.ddof_scale = self.exog.shape[1]\n    else:\n        if not ddof_scale >= 0:\n            raise ValueError('ddof_scale must be a non-negative number or None')\n        self.ddof_scale = ddof_scale\n    miniter = 20\n    for itr in range(maxiter):\n        (update, hm) = self._update_regularized(mean_params, pen_wt, scad_param, eps)\n        if update is None:\n            msg = 'Singular matrix encountered in regularized GEE update'\n            warnings.warn(msg, ConvergenceWarning)\n            break\n        if itr > miniter and np.sqrt(np.sum(update ** 2)) < ctol:\n            converged = True\n            break\n        mean_params += update\n        fit_history['params'].append(mean_params.copy())\n        self.update_cached_means(mean_params)\n        if itr != 0 and itr % update_assoc == 0:\n            self._update_assoc(mean_params)\n    if not converged:\n        msg = 'GEE.fit_regularized did not converge'\n        warnings.warn(msg)\n    mean_params[np.abs(mean_params) < ztol] = 0\n    self._update_assoc(mean_params)\n    ma = self._regularized_covmat(mean_params)\n    cov = np.linalg.solve(hm, ma)\n    cov = np.linalg.solve(hm, cov.T)\n    res_kwds = dict(cov_type='robust', cov_robust=cov)\n    scale = self.estimate_scale()\n    rslt = GEEResults(self, mean_params, cov, scale, regularized=True, attr_kwds=res_kwds)\n    rslt.fit_history = fit_history\n    return GEEResultsWrapper(rslt)",
            "def fit_regularized(self, pen_wt, scad_param=3.7, maxiter=100, ddof_scale=None, update_assoc=5, ctol=1e-05, ztol=0.001, eps=1e-06, scale=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Regularized estimation for GEE.\\n\\n        Parameters\\n        ----------\\n        pen_wt : float\\n            The penalty weight (a non-negative scalar).\\n        scad_param : float\\n            Non-negative scalar determining the shape of the Scad\\n            penalty.\\n        maxiter : int\\n            The maximum number of iterations.\\n        ddof_scale : int\\n            Value to subtract from `nobs` when calculating the\\n            denominator degrees of freedom for t-statistics, defaults\\n            to the number of columns in `exog`.\\n        update_assoc : int\\n            The dependence parameters are updated every `update_assoc`\\n            iterations of the mean structure parameter updates.\\n        ctol : float\\n            Convergence criterion, default is one order of magnitude\\n            smaller than proposed in section 3.1 of Wang et al.\\n        ztol : float\\n            Coefficients smaller than this value are treated as\\n            being zero, default is based on section 5 of Wang et al.\\n        eps : non-negative scalar\\n            Numerical constant, see section 3.2 of Wang et al.\\n        scale : float or string\\n            If a float, this value is used as the scale parameter.\\n            If \"X2\", the scale parameter is always estimated using\\n            Pearson\\'s chi-square method (e.g. as in a quasi-Poisson\\n            analysis).  If None, the default approach for the family\\n            is used to estimate the scale parameter.\\n\\n        Returns\\n        -------\\n        GEEResults instance.  Note that not all methods of the results\\n        class make sense when the model has been fit with regularization.\\n\\n        Notes\\n        -----\\n        This implementation assumes that the link is canonical.\\n\\n        References\\n        ----------\\n        Wang L, Zhou J, Qu A. (2012). Penalized generalized estimating\\n        equations for high-dimensional longitudinal data analysis.\\n        Biometrics. 2012 Jun;68(2):353-60.\\n        doi: 10.1111/j.1541-0420.2011.01678.x.\\n        https://www.ncbi.nlm.nih.gov/pubmed/21955051\\n        http://users.stat.umn.edu/~wangx346/research/GEE_selection.pdf\\n        '\n    self.scaletype = scale\n    mean_params = np.zeros(self.exog.shape[1])\n    self.update_cached_means(mean_params)\n    converged = False\n    fit_history = defaultdict(list)\n    if ddof_scale is None:\n        self.ddof_scale = self.exog.shape[1]\n    else:\n        if not ddof_scale >= 0:\n            raise ValueError('ddof_scale must be a non-negative number or None')\n        self.ddof_scale = ddof_scale\n    miniter = 20\n    for itr in range(maxiter):\n        (update, hm) = self._update_regularized(mean_params, pen_wt, scad_param, eps)\n        if update is None:\n            msg = 'Singular matrix encountered in regularized GEE update'\n            warnings.warn(msg, ConvergenceWarning)\n            break\n        if itr > miniter and np.sqrt(np.sum(update ** 2)) < ctol:\n            converged = True\n            break\n        mean_params += update\n        fit_history['params'].append(mean_params.copy())\n        self.update_cached_means(mean_params)\n        if itr != 0 and itr % update_assoc == 0:\n            self._update_assoc(mean_params)\n    if not converged:\n        msg = 'GEE.fit_regularized did not converge'\n        warnings.warn(msg)\n    mean_params[np.abs(mean_params) < ztol] = 0\n    self._update_assoc(mean_params)\n    ma = self._regularized_covmat(mean_params)\n    cov = np.linalg.solve(hm, ma)\n    cov = np.linalg.solve(hm, cov.T)\n    res_kwds = dict(cov_type='robust', cov_robust=cov)\n    scale = self.estimate_scale()\n    rslt = GEEResults(self, mean_params, cov, scale, regularized=True, attr_kwds=res_kwds)\n    rslt.fit_history = fit_history\n    return GEEResultsWrapper(rslt)",
            "def fit_regularized(self, pen_wt, scad_param=3.7, maxiter=100, ddof_scale=None, update_assoc=5, ctol=1e-05, ztol=0.001, eps=1e-06, scale=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Regularized estimation for GEE.\\n\\n        Parameters\\n        ----------\\n        pen_wt : float\\n            The penalty weight (a non-negative scalar).\\n        scad_param : float\\n            Non-negative scalar determining the shape of the Scad\\n            penalty.\\n        maxiter : int\\n            The maximum number of iterations.\\n        ddof_scale : int\\n            Value to subtract from `nobs` when calculating the\\n            denominator degrees of freedom for t-statistics, defaults\\n            to the number of columns in `exog`.\\n        update_assoc : int\\n            The dependence parameters are updated every `update_assoc`\\n            iterations of the mean structure parameter updates.\\n        ctol : float\\n            Convergence criterion, default is one order of magnitude\\n            smaller than proposed in section 3.1 of Wang et al.\\n        ztol : float\\n            Coefficients smaller than this value are treated as\\n            being zero, default is based on section 5 of Wang et al.\\n        eps : non-negative scalar\\n            Numerical constant, see section 3.2 of Wang et al.\\n        scale : float or string\\n            If a float, this value is used as the scale parameter.\\n            If \"X2\", the scale parameter is always estimated using\\n            Pearson\\'s chi-square method (e.g. as in a quasi-Poisson\\n            analysis).  If None, the default approach for the family\\n            is used to estimate the scale parameter.\\n\\n        Returns\\n        -------\\n        GEEResults instance.  Note that not all methods of the results\\n        class make sense when the model has been fit with regularization.\\n\\n        Notes\\n        -----\\n        This implementation assumes that the link is canonical.\\n\\n        References\\n        ----------\\n        Wang L, Zhou J, Qu A. (2012). Penalized generalized estimating\\n        equations for high-dimensional longitudinal data analysis.\\n        Biometrics. 2012 Jun;68(2):353-60.\\n        doi: 10.1111/j.1541-0420.2011.01678.x.\\n        https://www.ncbi.nlm.nih.gov/pubmed/21955051\\n        http://users.stat.umn.edu/~wangx346/research/GEE_selection.pdf\\n        '\n    self.scaletype = scale\n    mean_params = np.zeros(self.exog.shape[1])\n    self.update_cached_means(mean_params)\n    converged = False\n    fit_history = defaultdict(list)\n    if ddof_scale is None:\n        self.ddof_scale = self.exog.shape[1]\n    else:\n        if not ddof_scale >= 0:\n            raise ValueError('ddof_scale must be a non-negative number or None')\n        self.ddof_scale = ddof_scale\n    miniter = 20\n    for itr in range(maxiter):\n        (update, hm) = self._update_regularized(mean_params, pen_wt, scad_param, eps)\n        if update is None:\n            msg = 'Singular matrix encountered in regularized GEE update'\n            warnings.warn(msg, ConvergenceWarning)\n            break\n        if itr > miniter and np.sqrt(np.sum(update ** 2)) < ctol:\n            converged = True\n            break\n        mean_params += update\n        fit_history['params'].append(mean_params.copy())\n        self.update_cached_means(mean_params)\n        if itr != 0 and itr % update_assoc == 0:\n            self._update_assoc(mean_params)\n    if not converged:\n        msg = 'GEE.fit_regularized did not converge'\n        warnings.warn(msg)\n    mean_params[np.abs(mean_params) < ztol] = 0\n    self._update_assoc(mean_params)\n    ma = self._regularized_covmat(mean_params)\n    cov = np.linalg.solve(hm, ma)\n    cov = np.linalg.solve(hm, cov.T)\n    res_kwds = dict(cov_type='robust', cov_robust=cov)\n    scale = self.estimate_scale()\n    rslt = GEEResults(self, mean_params, cov, scale, regularized=True, attr_kwds=res_kwds)\n    rslt.fit_history = fit_history\n    return GEEResultsWrapper(rslt)"
        ]
    },
    {
        "func_name": "_handle_constraint",
        "original": "def _handle_constraint(self, mean_params, bcov):\n    \"\"\"\n        Expand the parameter estimate `mean_params` and covariance matrix\n        `bcov` to the coordinate system of the unconstrained model.\n\n        Parameters\n        ----------\n        mean_params : array_like\n            A parameter vector estimate for the reduced model.\n        bcov : array_like\n            The covariance matrix of mean_params.\n\n        Returns\n        -------\n        mean_params : array_like\n            The input parameter vector mean_params, expanded to the\n            coordinate system of the full model\n        bcov : array_like\n            The input covariance matrix bcov, expanded to the\n            coordinate system of the full model\n        \"\"\"\n    red_p = len(mean_params)\n    full_p = self.constraint.lhs.shape[1]\n    mean_params0 = np.r_[mean_params, np.zeros(full_p - red_p)]\n    save_exog_li = self.exog_li\n    self.exog_li = self.constraint.exog_fulltrans_li\n    import copy\n    save_cached_means = copy.deepcopy(self.cached_means)\n    self.update_cached_means(mean_params0)\n    (_, score) = self._update_mean_params()\n    if score is None:\n        warnings.warn('Singular matrix encountered in GEE score test', ConvergenceWarning)\n        return (None, None)\n    (_, ncov1, cmat) = self._covmat()\n    scale = self.estimate_scale()\n    cmat = cmat / scale ** 2\n    score2 = score[red_p:] / scale\n    amat = np.linalg.inv(ncov1)\n    bmat_11 = cmat[0:red_p, 0:red_p]\n    bmat_22 = cmat[red_p:, red_p:]\n    bmat_12 = cmat[0:red_p, red_p:]\n    amat_11 = amat[0:red_p, 0:red_p]\n    amat_12 = amat[0:red_p, red_p:]\n    score_cov = bmat_22 - np.dot(amat_12.T, np.linalg.solve(amat_11, bmat_12))\n    score_cov -= np.dot(bmat_12.T, np.linalg.solve(amat_11, amat_12))\n    score_cov += np.dot(amat_12.T, np.dot(np.linalg.solve(amat_11, bmat_11), np.linalg.solve(amat_11, amat_12)))\n    from scipy.stats.distributions import chi2\n    score_statistic = np.dot(score2, np.linalg.solve(score_cov, score2))\n    score_df = len(score2)\n    score_pvalue = 1 - chi2.cdf(score_statistic, score_df)\n    self.score_test_results = {'statistic': score_statistic, 'df': score_df, 'p-value': score_pvalue}\n    mean_params = self.constraint.unpack_param(mean_params)\n    bcov = self.constraint.unpack_cov(bcov)\n    self.exog_li = save_exog_li\n    self.cached_means = save_cached_means\n    self.exog = self.constraint.restore_exog()\n    return (mean_params, bcov)",
        "mutated": [
            "def _handle_constraint(self, mean_params, bcov):\n    if False:\n        i = 10\n    '\\n        Expand the parameter estimate `mean_params` and covariance matrix\\n        `bcov` to the coordinate system of the unconstrained model.\\n\\n        Parameters\\n        ----------\\n        mean_params : array_like\\n            A parameter vector estimate for the reduced model.\\n        bcov : array_like\\n            The covariance matrix of mean_params.\\n\\n        Returns\\n        -------\\n        mean_params : array_like\\n            The input parameter vector mean_params, expanded to the\\n            coordinate system of the full model\\n        bcov : array_like\\n            The input covariance matrix bcov, expanded to the\\n            coordinate system of the full model\\n        '\n    red_p = len(mean_params)\n    full_p = self.constraint.lhs.shape[1]\n    mean_params0 = np.r_[mean_params, np.zeros(full_p - red_p)]\n    save_exog_li = self.exog_li\n    self.exog_li = self.constraint.exog_fulltrans_li\n    import copy\n    save_cached_means = copy.deepcopy(self.cached_means)\n    self.update_cached_means(mean_params0)\n    (_, score) = self._update_mean_params()\n    if score is None:\n        warnings.warn('Singular matrix encountered in GEE score test', ConvergenceWarning)\n        return (None, None)\n    (_, ncov1, cmat) = self._covmat()\n    scale = self.estimate_scale()\n    cmat = cmat / scale ** 2\n    score2 = score[red_p:] / scale\n    amat = np.linalg.inv(ncov1)\n    bmat_11 = cmat[0:red_p, 0:red_p]\n    bmat_22 = cmat[red_p:, red_p:]\n    bmat_12 = cmat[0:red_p, red_p:]\n    amat_11 = amat[0:red_p, 0:red_p]\n    amat_12 = amat[0:red_p, red_p:]\n    score_cov = bmat_22 - np.dot(amat_12.T, np.linalg.solve(amat_11, bmat_12))\n    score_cov -= np.dot(bmat_12.T, np.linalg.solve(amat_11, amat_12))\n    score_cov += np.dot(amat_12.T, np.dot(np.linalg.solve(amat_11, bmat_11), np.linalg.solve(amat_11, amat_12)))\n    from scipy.stats.distributions import chi2\n    score_statistic = np.dot(score2, np.linalg.solve(score_cov, score2))\n    score_df = len(score2)\n    score_pvalue = 1 - chi2.cdf(score_statistic, score_df)\n    self.score_test_results = {'statistic': score_statistic, 'df': score_df, 'p-value': score_pvalue}\n    mean_params = self.constraint.unpack_param(mean_params)\n    bcov = self.constraint.unpack_cov(bcov)\n    self.exog_li = save_exog_li\n    self.cached_means = save_cached_means\n    self.exog = self.constraint.restore_exog()\n    return (mean_params, bcov)",
            "def _handle_constraint(self, mean_params, bcov):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Expand the parameter estimate `mean_params` and covariance matrix\\n        `bcov` to the coordinate system of the unconstrained model.\\n\\n        Parameters\\n        ----------\\n        mean_params : array_like\\n            A parameter vector estimate for the reduced model.\\n        bcov : array_like\\n            The covariance matrix of mean_params.\\n\\n        Returns\\n        -------\\n        mean_params : array_like\\n            The input parameter vector mean_params, expanded to the\\n            coordinate system of the full model\\n        bcov : array_like\\n            The input covariance matrix bcov, expanded to the\\n            coordinate system of the full model\\n        '\n    red_p = len(mean_params)\n    full_p = self.constraint.lhs.shape[1]\n    mean_params0 = np.r_[mean_params, np.zeros(full_p - red_p)]\n    save_exog_li = self.exog_li\n    self.exog_li = self.constraint.exog_fulltrans_li\n    import copy\n    save_cached_means = copy.deepcopy(self.cached_means)\n    self.update_cached_means(mean_params0)\n    (_, score) = self._update_mean_params()\n    if score is None:\n        warnings.warn('Singular matrix encountered in GEE score test', ConvergenceWarning)\n        return (None, None)\n    (_, ncov1, cmat) = self._covmat()\n    scale = self.estimate_scale()\n    cmat = cmat / scale ** 2\n    score2 = score[red_p:] / scale\n    amat = np.linalg.inv(ncov1)\n    bmat_11 = cmat[0:red_p, 0:red_p]\n    bmat_22 = cmat[red_p:, red_p:]\n    bmat_12 = cmat[0:red_p, red_p:]\n    amat_11 = amat[0:red_p, 0:red_p]\n    amat_12 = amat[0:red_p, red_p:]\n    score_cov = bmat_22 - np.dot(amat_12.T, np.linalg.solve(amat_11, bmat_12))\n    score_cov -= np.dot(bmat_12.T, np.linalg.solve(amat_11, amat_12))\n    score_cov += np.dot(amat_12.T, np.dot(np.linalg.solve(amat_11, bmat_11), np.linalg.solve(amat_11, amat_12)))\n    from scipy.stats.distributions import chi2\n    score_statistic = np.dot(score2, np.linalg.solve(score_cov, score2))\n    score_df = len(score2)\n    score_pvalue = 1 - chi2.cdf(score_statistic, score_df)\n    self.score_test_results = {'statistic': score_statistic, 'df': score_df, 'p-value': score_pvalue}\n    mean_params = self.constraint.unpack_param(mean_params)\n    bcov = self.constraint.unpack_cov(bcov)\n    self.exog_li = save_exog_li\n    self.cached_means = save_cached_means\n    self.exog = self.constraint.restore_exog()\n    return (mean_params, bcov)",
            "def _handle_constraint(self, mean_params, bcov):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Expand the parameter estimate `mean_params` and covariance matrix\\n        `bcov` to the coordinate system of the unconstrained model.\\n\\n        Parameters\\n        ----------\\n        mean_params : array_like\\n            A parameter vector estimate for the reduced model.\\n        bcov : array_like\\n            The covariance matrix of mean_params.\\n\\n        Returns\\n        -------\\n        mean_params : array_like\\n            The input parameter vector mean_params, expanded to the\\n            coordinate system of the full model\\n        bcov : array_like\\n            The input covariance matrix bcov, expanded to the\\n            coordinate system of the full model\\n        '\n    red_p = len(mean_params)\n    full_p = self.constraint.lhs.shape[1]\n    mean_params0 = np.r_[mean_params, np.zeros(full_p - red_p)]\n    save_exog_li = self.exog_li\n    self.exog_li = self.constraint.exog_fulltrans_li\n    import copy\n    save_cached_means = copy.deepcopy(self.cached_means)\n    self.update_cached_means(mean_params0)\n    (_, score) = self._update_mean_params()\n    if score is None:\n        warnings.warn('Singular matrix encountered in GEE score test', ConvergenceWarning)\n        return (None, None)\n    (_, ncov1, cmat) = self._covmat()\n    scale = self.estimate_scale()\n    cmat = cmat / scale ** 2\n    score2 = score[red_p:] / scale\n    amat = np.linalg.inv(ncov1)\n    bmat_11 = cmat[0:red_p, 0:red_p]\n    bmat_22 = cmat[red_p:, red_p:]\n    bmat_12 = cmat[0:red_p, red_p:]\n    amat_11 = amat[0:red_p, 0:red_p]\n    amat_12 = amat[0:red_p, red_p:]\n    score_cov = bmat_22 - np.dot(amat_12.T, np.linalg.solve(amat_11, bmat_12))\n    score_cov -= np.dot(bmat_12.T, np.linalg.solve(amat_11, amat_12))\n    score_cov += np.dot(amat_12.T, np.dot(np.linalg.solve(amat_11, bmat_11), np.linalg.solve(amat_11, amat_12)))\n    from scipy.stats.distributions import chi2\n    score_statistic = np.dot(score2, np.linalg.solve(score_cov, score2))\n    score_df = len(score2)\n    score_pvalue = 1 - chi2.cdf(score_statistic, score_df)\n    self.score_test_results = {'statistic': score_statistic, 'df': score_df, 'p-value': score_pvalue}\n    mean_params = self.constraint.unpack_param(mean_params)\n    bcov = self.constraint.unpack_cov(bcov)\n    self.exog_li = save_exog_li\n    self.cached_means = save_cached_means\n    self.exog = self.constraint.restore_exog()\n    return (mean_params, bcov)",
            "def _handle_constraint(self, mean_params, bcov):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Expand the parameter estimate `mean_params` and covariance matrix\\n        `bcov` to the coordinate system of the unconstrained model.\\n\\n        Parameters\\n        ----------\\n        mean_params : array_like\\n            A parameter vector estimate for the reduced model.\\n        bcov : array_like\\n            The covariance matrix of mean_params.\\n\\n        Returns\\n        -------\\n        mean_params : array_like\\n            The input parameter vector mean_params, expanded to the\\n            coordinate system of the full model\\n        bcov : array_like\\n            The input covariance matrix bcov, expanded to the\\n            coordinate system of the full model\\n        '\n    red_p = len(mean_params)\n    full_p = self.constraint.lhs.shape[1]\n    mean_params0 = np.r_[mean_params, np.zeros(full_p - red_p)]\n    save_exog_li = self.exog_li\n    self.exog_li = self.constraint.exog_fulltrans_li\n    import copy\n    save_cached_means = copy.deepcopy(self.cached_means)\n    self.update_cached_means(mean_params0)\n    (_, score) = self._update_mean_params()\n    if score is None:\n        warnings.warn('Singular matrix encountered in GEE score test', ConvergenceWarning)\n        return (None, None)\n    (_, ncov1, cmat) = self._covmat()\n    scale = self.estimate_scale()\n    cmat = cmat / scale ** 2\n    score2 = score[red_p:] / scale\n    amat = np.linalg.inv(ncov1)\n    bmat_11 = cmat[0:red_p, 0:red_p]\n    bmat_22 = cmat[red_p:, red_p:]\n    bmat_12 = cmat[0:red_p, red_p:]\n    amat_11 = amat[0:red_p, 0:red_p]\n    amat_12 = amat[0:red_p, red_p:]\n    score_cov = bmat_22 - np.dot(amat_12.T, np.linalg.solve(amat_11, bmat_12))\n    score_cov -= np.dot(bmat_12.T, np.linalg.solve(amat_11, amat_12))\n    score_cov += np.dot(amat_12.T, np.dot(np.linalg.solve(amat_11, bmat_11), np.linalg.solve(amat_11, amat_12)))\n    from scipy.stats.distributions import chi2\n    score_statistic = np.dot(score2, np.linalg.solve(score_cov, score2))\n    score_df = len(score2)\n    score_pvalue = 1 - chi2.cdf(score_statistic, score_df)\n    self.score_test_results = {'statistic': score_statistic, 'df': score_df, 'p-value': score_pvalue}\n    mean_params = self.constraint.unpack_param(mean_params)\n    bcov = self.constraint.unpack_cov(bcov)\n    self.exog_li = save_exog_li\n    self.cached_means = save_cached_means\n    self.exog = self.constraint.restore_exog()\n    return (mean_params, bcov)",
            "def _handle_constraint(self, mean_params, bcov):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Expand the parameter estimate `mean_params` and covariance matrix\\n        `bcov` to the coordinate system of the unconstrained model.\\n\\n        Parameters\\n        ----------\\n        mean_params : array_like\\n            A parameter vector estimate for the reduced model.\\n        bcov : array_like\\n            The covariance matrix of mean_params.\\n\\n        Returns\\n        -------\\n        mean_params : array_like\\n            The input parameter vector mean_params, expanded to the\\n            coordinate system of the full model\\n        bcov : array_like\\n            The input covariance matrix bcov, expanded to the\\n            coordinate system of the full model\\n        '\n    red_p = len(mean_params)\n    full_p = self.constraint.lhs.shape[1]\n    mean_params0 = np.r_[mean_params, np.zeros(full_p - red_p)]\n    save_exog_li = self.exog_li\n    self.exog_li = self.constraint.exog_fulltrans_li\n    import copy\n    save_cached_means = copy.deepcopy(self.cached_means)\n    self.update_cached_means(mean_params0)\n    (_, score) = self._update_mean_params()\n    if score is None:\n        warnings.warn('Singular matrix encountered in GEE score test', ConvergenceWarning)\n        return (None, None)\n    (_, ncov1, cmat) = self._covmat()\n    scale = self.estimate_scale()\n    cmat = cmat / scale ** 2\n    score2 = score[red_p:] / scale\n    amat = np.linalg.inv(ncov1)\n    bmat_11 = cmat[0:red_p, 0:red_p]\n    bmat_22 = cmat[red_p:, red_p:]\n    bmat_12 = cmat[0:red_p, red_p:]\n    amat_11 = amat[0:red_p, 0:red_p]\n    amat_12 = amat[0:red_p, red_p:]\n    score_cov = bmat_22 - np.dot(amat_12.T, np.linalg.solve(amat_11, bmat_12))\n    score_cov -= np.dot(bmat_12.T, np.linalg.solve(amat_11, amat_12))\n    score_cov += np.dot(amat_12.T, np.dot(np.linalg.solve(amat_11, bmat_11), np.linalg.solve(amat_11, amat_12)))\n    from scipy.stats.distributions import chi2\n    score_statistic = np.dot(score2, np.linalg.solve(score_cov, score2))\n    score_df = len(score2)\n    score_pvalue = 1 - chi2.cdf(score_statistic, score_df)\n    self.score_test_results = {'statistic': score_statistic, 'df': score_df, 'p-value': score_pvalue}\n    mean_params = self.constraint.unpack_param(mean_params)\n    bcov = self.constraint.unpack_cov(bcov)\n    self.exog_li = save_exog_li\n    self.cached_means = save_cached_means\n    self.exog = self.constraint.restore_exog()\n    return (mean_params, bcov)"
        ]
    },
    {
        "func_name": "_update_assoc",
        "original": "def _update_assoc(self, params):\n    \"\"\"\n        Update the association parameters\n        \"\"\"\n    self.cov_struct.update(params)",
        "mutated": [
            "def _update_assoc(self, params):\n    if False:\n        i = 10\n    '\\n        Update the association parameters\\n        '\n    self.cov_struct.update(params)",
            "def _update_assoc(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Update the association parameters\\n        '\n    self.cov_struct.update(params)",
            "def _update_assoc(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Update the association parameters\\n        '\n    self.cov_struct.update(params)",
            "def _update_assoc(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Update the association parameters\\n        '\n    self.cov_struct.update(params)",
            "def _update_assoc(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Update the association parameters\\n        '\n    self.cov_struct.update(params)"
        ]
    },
    {
        "func_name": "_derivative_exog",
        "original": "def _derivative_exog(self, params, exog=None, transform='dydx', dummy_idx=None, count_idx=None):\n    \"\"\"\n        For computing marginal effects, returns dF(XB) / dX where F(.)\n        is the fitted mean.\n\n        transform can be 'dydx', 'dyex', 'eydx', or 'eyex'.\n\n        Not all of these make sense in the presence of discrete regressors,\n        but checks are done in the results in get_margeff.\n        \"\"\"\n    offset_exposure = None\n    if exog is None:\n        exog = self.exog\n        offset_exposure = self._offset_exposure\n    margeff = self.mean_deriv_exog(exog, params, offset_exposure)\n    if 'ex' in transform:\n        margeff *= exog\n    if 'ey' in transform:\n        margeff /= self.predict(params, exog)[:, None]\n    if count_idx is not None:\n        from statsmodels.discrete.discrete_margins import _get_count_effects\n        margeff = _get_count_effects(margeff, exog, count_idx, transform, self, params)\n    if dummy_idx is not None:\n        from statsmodels.discrete.discrete_margins import _get_dummy_effects\n        margeff = _get_dummy_effects(margeff, exog, dummy_idx, transform, self, params)\n    return margeff",
        "mutated": [
            "def _derivative_exog(self, params, exog=None, transform='dydx', dummy_idx=None, count_idx=None):\n    if False:\n        i = 10\n    \"\\n        For computing marginal effects, returns dF(XB) / dX where F(.)\\n        is the fitted mean.\\n\\n        transform can be 'dydx', 'dyex', 'eydx', or 'eyex'.\\n\\n        Not all of these make sense in the presence of discrete regressors,\\n        but checks are done in the results in get_margeff.\\n        \"\n    offset_exposure = None\n    if exog is None:\n        exog = self.exog\n        offset_exposure = self._offset_exposure\n    margeff = self.mean_deriv_exog(exog, params, offset_exposure)\n    if 'ex' in transform:\n        margeff *= exog\n    if 'ey' in transform:\n        margeff /= self.predict(params, exog)[:, None]\n    if count_idx is not None:\n        from statsmodels.discrete.discrete_margins import _get_count_effects\n        margeff = _get_count_effects(margeff, exog, count_idx, transform, self, params)\n    if dummy_idx is not None:\n        from statsmodels.discrete.discrete_margins import _get_dummy_effects\n        margeff = _get_dummy_effects(margeff, exog, dummy_idx, transform, self, params)\n    return margeff",
            "def _derivative_exog(self, params, exog=None, transform='dydx', dummy_idx=None, count_idx=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        For computing marginal effects, returns dF(XB) / dX where F(.)\\n        is the fitted mean.\\n\\n        transform can be 'dydx', 'dyex', 'eydx', or 'eyex'.\\n\\n        Not all of these make sense in the presence of discrete regressors,\\n        but checks are done in the results in get_margeff.\\n        \"\n    offset_exposure = None\n    if exog is None:\n        exog = self.exog\n        offset_exposure = self._offset_exposure\n    margeff = self.mean_deriv_exog(exog, params, offset_exposure)\n    if 'ex' in transform:\n        margeff *= exog\n    if 'ey' in transform:\n        margeff /= self.predict(params, exog)[:, None]\n    if count_idx is not None:\n        from statsmodels.discrete.discrete_margins import _get_count_effects\n        margeff = _get_count_effects(margeff, exog, count_idx, transform, self, params)\n    if dummy_idx is not None:\n        from statsmodels.discrete.discrete_margins import _get_dummy_effects\n        margeff = _get_dummy_effects(margeff, exog, dummy_idx, transform, self, params)\n    return margeff",
            "def _derivative_exog(self, params, exog=None, transform='dydx', dummy_idx=None, count_idx=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        For computing marginal effects, returns dF(XB) / dX where F(.)\\n        is the fitted mean.\\n\\n        transform can be 'dydx', 'dyex', 'eydx', or 'eyex'.\\n\\n        Not all of these make sense in the presence of discrete regressors,\\n        but checks are done in the results in get_margeff.\\n        \"\n    offset_exposure = None\n    if exog is None:\n        exog = self.exog\n        offset_exposure = self._offset_exposure\n    margeff = self.mean_deriv_exog(exog, params, offset_exposure)\n    if 'ex' in transform:\n        margeff *= exog\n    if 'ey' in transform:\n        margeff /= self.predict(params, exog)[:, None]\n    if count_idx is not None:\n        from statsmodels.discrete.discrete_margins import _get_count_effects\n        margeff = _get_count_effects(margeff, exog, count_idx, transform, self, params)\n    if dummy_idx is not None:\n        from statsmodels.discrete.discrete_margins import _get_dummy_effects\n        margeff = _get_dummy_effects(margeff, exog, dummy_idx, transform, self, params)\n    return margeff",
            "def _derivative_exog(self, params, exog=None, transform='dydx', dummy_idx=None, count_idx=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        For computing marginal effects, returns dF(XB) / dX where F(.)\\n        is the fitted mean.\\n\\n        transform can be 'dydx', 'dyex', 'eydx', or 'eyex'.\\n\\n        Not all of these make sense in the presence of discrete regressors,\\n        but checks are done in the results in get_margeff.\\n        \"\n    offset_exposure = None\n    if exog is None:\n        exog = self.exog\n        offset_exposure = self._offset_exposure\n    margeff = self.mean_deriv_exog(exog, params, offset_exposure)\n    if 'ex' in transform:\n        margeff *= exog\n    if 'ey' in transform:\n        margeff /= self.predict(params, exog)[:, None]\n    if count_idx is not None:\n        from statsmodels.discrete.discrete_margins import _get_count_effects\n        margeff = _get_count_effects(margeff, exog, count_idx, transform, self, params)\n    if dummy_idx is not None:\n        from statsmodels.discrete.discrete_margins import _get_dummy_effects\n        margeff = _get_dummy_effects(margeff, exog, dummy_idx, transform, self, params)\n    return margeff",
            "def _derivative_exog(self, params, exog=None, transform='dydx', dummy_idx=None, count_idx=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        For computing marginal effects, returns dF(XB) / dX where F(.)\\n        is the fitted mean.\\n\\n        transform can be 'dydx', 'dyex', 'eydx', or 'eyex'.\\n\\n        Not all of these make sense in the presence of discrete regressors,\\n        but checks are done in the results in get_margeff.\\n        \"\n    offset_exposure = None\n    if exog is None:\n        exog = self.exog\n        offset_exposure = self._offset_exposure\n    margeff = self.mean_deriv_exog(exog, params, offset_exposure)\n    if 'ex' in transform:\n        margeff *= exog\n    if 'ey' in transform:\n        margeff /= self.predict(params, exog)[:, None]\n    if count_idx is not None:\n        from statsmodels.discrete.discrete_margins import _get_count_effects\n        margeff = _get_count_effects(margeff, exog, count_idx, transform, self, params)\n    if dummy_idx is not None:\n        from statsmodels.discrete.discrete_margins import _get_dummy_effects\n        margeff = _get_dummy_effects(margeff, exog, dummy_idx, transform, self, params)\n    return margeff"
        ]
    },
    {
        "func_name": "qic",
        "original": "def qic(self, params, scale, cov_params, n_step=1000):\n    \"\"\"\n        Returns quasi-information criteria and quasi-likelihood values.\n\n        Parameters\n        ----------\n        params : array_like\n            The GEE estimates of the regression parameters.\n        scale : scalar\n            Estimated scale parameter\n        cov_params : array_like\n            An estimate of the covariance matrix for the\n            model parameters.  Conventionally this is the robust\n            covariance matrix.\n        n_step : integer\n            The number of points in the trapezoidal approximation\n            to the quasi-likelihood function.\n\n        Returns\n        -------\n        ql : scalar\n            The quasi-likelihood value\n        qic : scalar\n            A QIC that can be used to compare the mean and covariance\n            structures of the model.\n        qicu : scalar\n            A simplified QIC that can be used to compare mean structures\n            but not covariance structures\n\n        Notes\n        -----\n        The quasi-likelihood used here is obtained by numerically evaluating\n        Wedderburn's integral representation of the quasi-likelihood function.\n        This approach is valid for all families and  links.  Many other\n        packages use analytical expressions for quasi-likelihoods that are\n        valid in special cases where the link function is canonical.  These\n        analytical expressions may omit additive constants that only depend\n        on the data.  Therefore, the numerical values of our QL and QIC values\n        will differ from the values reported by other packages.  However only\n        the differences between two QIC values calculated for different models\n        using the same data are meaningful.  Our QIC should produce the same\n        QIC differences as other software.\n\n        When using the QIC for models with unknown scale parameter, use a\n        common estimate of the scale parameter for all models being compared.\n\n        References\n        ----------\n        .. [*] W. Pan (2001).  Akaike's information criterion in generalized\n               estimating equations.  Biometrics (57) 1.\n        \"\"\"\n    varfunc = self.family.variance\n    means = []\n    omega = 0.0\n    for i in range(self.num_group):\n        (expval, lpr) = self.cached_means[i]\n        means.append(expval)\n        dmat = self.mean_deriv(self.exog_li[i], lpr)\n        omega += np.dot(dmat.T, dmat) / scale\n    means = np.concatenate(means)\n    endog_li = np.concatenate(self.endog_li)\n    du = means - endog_li\n    qv = np.empty(n_step)\n    xv = np.linspace(-0.99999, 1, n_step)\n    for (i, g) in enumerate(xv):\n        u = endog_li + (g + 1) * du / 2.0\n        vu = varfunc(u)\n        qv[i] = -np.sum(du ** 2 * (g + 1) / vu)\n    qv /= 4 * scale\n    try:\n        from scipy.integrate import trapezoid\n    except ImportError:\n        from scipy.integrate import trapz as trapezoid\n    ql = trapezoid(qv, dx=xv[1] - xv[0])\n    qicu = -2 * ql + 2 * self.exog.shape[1]\n    qic = -2 * ql + 2 * np.trace(np.dot(omega, cov_params))\n    return (ql, qic, qicu)",
        "mutated": [
            "def qic(self, params, scale, cov_params, n_step=1000):\n    if False:\n        i = 10\n    \"\\n        Returns quasi-information criteria and quasi-likelihood values.\\n\\n        Parameters\\n        ----------\\n        params : array_like\\n            The GEE estimates of the regression parameters.\\n        scale : scalar\\n            Estimated scale parameter\\n        cov_params : array_like\\n            An estimate of the covariance matrix for the\\n            model parameters.  Conventionally this is the robust\\n            covariance matrix.\\n        n_step : integer\\n            The number of points in the trapezoidal approximation\\n            to the quasi-likelihood function.\\n\\n        Returns\\n        -------\\n        ql : scalar\\n            The quasi-likelihood value\\n        qic : scalar\\n            A QIC that can be used to compare the mean and covariance\\n            structures of the model.\\n        qicu : scalar\\n            A simplified QIC that can be used to compare mean structures\\n            but not covariance structures\\n\\n        Notes\\n        -----\\n        The quasi-likelihood used here is obtained by numerically evaluating\\n        Wedderburn's integral representation of the quasi-likelihood function.\\n        This approach is valid for all families and  links.  Many other\\n        packages use analytical expressions for quasi-likelihoods that are\\n        valid in special cases where the link function is canonical.  These\\n        analytical expressions may omit additive constants that only depend\\n        on the data.  Therefore, the numerical values of our QL and QIC values\\n        will differ from the values reported by other packages.  However only\\n        the differences between two QIC values calculated for different models\\n        using the same data are meaningful.  Our QIC should produce the same\\n        QIC differences as other software.\\n\\n        When using the QIC for models with unknown scale parameter, use a\\n        common estimate of the scale parameter for all models being compared.\\n\\n        References\\n        ----------\\n        .. [*] W. Pan (2001).  Akaike's information criterion in generalized\\n               estimating equations.  Biometrics (57) 1.\\n        \"\n    varfunc = self.family.variance\n    means = []\n    omega = 0.0\n    for i in range(self.num_group):\n        (expval, lpr) = self.cached_means[i]\n        means.append(expval)\n        dmat = self.mean_deriv(self.exog_li[i], lpr)\n        omega += np.dot(dmat.T, dmat) / scale\n    means = np.concatenate(means)\n    endog_li = np.concatenate(self.endog_li)\n    du = means - endog_li\n    qv = np.empty(n_step)\n    xv = np.linspace(-0.99999, 1, n_step)\n    for (i, g) in enumerate(xv):\n        u = endog_li + (g + 1) * du / 2.0\n        vu = varfunc(u)\n        qv[i] = -np.sum(du ** 2 * (g + 1) / vu)\n    qv /= 4 * scale\n    try:\n        from scipy.integrate import trapezoid\n    except ImportError:\n        from scipy.integrate import trapz as trapezoid\n    ql = trapezoid(qv, dx=xv[1] - xv[0])\n    qicu = -2 * ql + 2 * self.exog.shape[1]\n    qic = -2 * ql + 2 * np.trace(np.dot(omega, cov_params))\n    return (ql, qic, qicu)",
            "def qic(self, params, scale, cov_params, n_step=1000):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Returns quasi-information criteria and quasi-likelihood values.\\n\\n        Parameters\\n        ----------\\n        params : array_like\\n            The GEE estimates of the regression parameters.\\n        scale : scalar\\n            Estimated scale parameter\\n        cov_params : array_like\\n            An estimate of the covariance matrix for the\\n            model parameters.  Conventionally this is the robust\\n            covariance matrix.\\n        n_step : integer\\n            The number of points in the trapezoidal approximation\\n            to the quasi-likelihood function.\\n\\n        Returns\\n        -------\\n        ql : scalar\\n            The quasi-likelihood value\\n        qic : scalar\\n            A QIC that can be used to compare the mean and covariance\\n            structures of the model.\\n        qicu : scalar\\n            A simplified QIC that can be used to compare mean structures\\n            but not covariance structures\\n\\n        Notes\\n        -----\\n        The quasi-likelihood used here is obtained by numerically evaluating\\n        Wedderburn's integral representation of the quasi-likelihood function.\\n        This approach is valid for all families and  links.  Many other\\n        packages use analytical expressions for quasi-likelihoods that are\\n        valid in special cases where the link function is canonical.  These\\n        analytical expressions may omit additive constants that only depend\\n        on the data.  Therefore, the numerical values of our QL and QIC values\\n        will differ from the values reported by other packages.  However only\\n        the differences between two QIC values calculated for different models\\n        using the same data are meaningful.  Our QIC should produce the same\\n        QIC differences as other software.\\n\\n        When using the QIC for models with unknown scale parameter, use a\\n        common estimate of the scale parameter for all models being compared.\\n\\n        References\\n        ----------\\n        .. [*] W. Pan (2001).  Akaike's information criterion in generalized\\n               estimating equations.  Biometrics (57) 1.\\n        \"\n    varfunc = self.family.variance\n    means = []\n    omega = 0.0\n    for i in range(self.num_group):\n        (expval, lpr) = self.cached_means[i]\n        means.append(expval)\n        dmat = self.mean_deriv(self.exog_li[i], lpr)\n        omega += np.dot(dmat.T, dmat) / scale\n    means = np.concatenate(means)\n    endog_li = np.concatenate(self.endog_li)\n    du = means - endog_li\n    qv = np.empty(n_step)\n    xv = np.linspace(-0.99999, 1, n_step)\n    for (i, g) in enumerate(xv):\n        u = endog_li + (g + 1) * du / 2.0\n        vu = varfunc(u)\n        qv[i] = -np.sum(du ** 2 * (g + 1) / vu)\n    qv /= 4 * scale\n    try:\n        from scipy.integrate import trapezoid\n    except ImportError:\n        from scipy.integrate import trapz as trapezoid\n    ql = trapezoid(qv, dx=xv[1] - xv[0])\n    qicu = -2 * ql + 2 * self.exog.shape[1]\n    qic = -2 * ql + 2 * np.trace(np.dot(omega, cov_params))\n    return (ql, qic, qicu)",
            "def qic(self, params, scale, cov_params, n_step=1000):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Returns quasi-information criteria and quasi-likelihood values.\\n\\n        Parameters\\n        ----------\\n        params : array_like\\n            The GEE estimates of the regression parameters.\\n        scale : scalar\\n            Estimated scale parameter\\n        cov_params : array_like\\n            An estimate of the covariance matrix for the\\n            model parameters.  Conventionally this is the robust\\n            covariance matrix.\\n        n_step : integer\\n            The number of points in the trapezoidal approximation\\n            to the quasi-likelihood function.\\n\\n        Returns\\n        -------\\n        ql : scalar\\n            The quasi-likelihood value\\n        qic : scalar\\n            A QIC that can be used to compare the mean and covariance\\n            structures of the model.\\n        qicu : scalar\\n            A simplified QIC that can be used to compare mean structures\\n            but not covariance structures\\n\\n        Notes\\n        -----\\n        The quasi-likelihood used here is obtained by numerically evaluating\\n        Wedderburn's integral representation of the quasi-likelihood function.\\n        This approach is valid for all families and  links.  Many other\\n        packages use analytical expressions for quasi-likelihoods that are\\n        valid in special cases where the link function is canonical.  These\\n        analytical expressions may omit additive constants that only depend\\n        on the data.  Therefore, the numerical values of our QL and QIC values\\n        will differ from the values reported by other packages.  However only\\n        the differences between two QIC values calculated for different models\\n        using the same data are meaningful.  Our QIC should produce the same\\n        QIC differences as other software.\\n\\n        When using the QIC for models with unknown scale parameter, use a\\n        common estimate of the scale parameter for all models being compared.\\n\\n        References\\n        ----------\\n        .. [*] W. Pan (2001).  Akaike's information criterion in generalized\\n               estimating equations.  Biometrics (57) 1.\\n        \"\n    varfunc = self.family.variance\n    means = []\n    omega = 0.0\n    for i in range(self.num_group):\n        (expval, lpr) = self.cached_means[i]\n        means.append(expval)\n        dmat = self.mean_deriv(self.exog_li[i], lpr)\n        omega += np.dot(dmat.T, dmat) / scale\n    means = np.concatenate(means)\n    endog_li = np.concatenate(self.endog_li)\n    du = means - endog_li\n    qv = np.empty(n_step)\n    xv = np.linspace(-0.99999, 1, n_step)\n    for (i, g) in enumerate(xv):\n        u = endog_li + (g + 1) * du / 2.0\n        vu = varfunc(u)\n        qv[i] = -np.sum(du ** 2 * (g + 1) / vu)\n    qv /= 4 * scale\n    try:\n        from scipy.integrate import trapezoid\n    except ImportError:\n        from scipy.integrate import trapz as trapezoid\n    ql = trapezoid(qv, dx=xv[1] - xv[0])\n    qicu = -2 * ql + 2 * self.exog.shape[1]\n    qic = -2 * ql + 2 * np.trace(np.dot(omega, cov_params))\n    return (ql, qic, qicu)",
            "def qic(self, params, scale, cov_params, n_step=1000):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Returns quasi-information criteria and quasi-likelihood values.\\n\\n        Parameters\\n        ----------\\n        params : array_like\\n            The GEE estimates of the regression parameters.\\n        scale : scalar\\n            Estimated scale parameter\\n        cov_params : array_like\\n            An estimate of the covariance matrix for the\\n            model parameters.  Conventionally this is the robust\\n            covariance matrix.\\n        n_step : integer\\n            The number of points in the trapezoidal approximation\\n            to the quasi-likelihood function.\\n\\n        Returns\\n        -------\\n        ql : scalar\\n            The quasi-likelihood value\\n        qic : scalar\\n            A QIC that can be used to compare the mean and covariance\\n            structures of the model.\\n        qicu : scalar\\n            A simplified QIC that can be used to compare mean structures\\n            but not covariance structures\\n\\n        Notes\\n        -----\\n        The quasi-likelihood used here is obtained by numerically evaluating\\n        Wedderburn's integral representation of the quasi-likelihood function.\\n        This approach is valid for all families and  links.  Many other\\n        packages use analytical expressions for quasi-likelihoods that are\\n        valid in special cases where the link function is canonical.  These\\n        analytical expressions may omit additive constants that only depend\\n        on the data.  Therefore, the numerical values of our QL and QIC values\\n        will differ from the values reported by other packages.  However only\\n        the differences between two QIC values calculated for different models\\n        using the same data are meaningful.  Our QIC should produce the same\\n        QIC differences as other software.\\n\\n        When using the QIC for models with unknown scale parameter, use a\\n        common estimate of the scale parameter for all models being compared.\\n\\n        References\\n        ----------\\n        .. [*] W. Pan (2001).  Akaike's information criterion in generalized\\n               estimating equations.  Biometrics (57) 1.\\n        \"\n    varfunc = self.family.variance\n    means = []\n    omega = 0.0\n    for i in range(self.num_group):\n        (expval, lpr) = self.cached_means[i]\n        means.append(expval)\n        dmat = self.mean_deriv(self.exog_li[i], lpr)\n        omega += np.dot(dmat.T, dmat) / scale\n    means = np.concatenate(means)\n    endog_li = np.concatenate(self.endog_li)\n    du = means - endog_li\n    qv = np.empty(n_step)\n    xv = np.linspace(-0.99999, 1, n_step)\n    for (i, g) in enumerate(xv):\n        u = endog_li + (g + 1) * du / 2.0\n        vu = varfunc(u)\n        qv[i] = -np.sum(du ** 2 * (g + 1) / vu)\n    qv /= 4 * scale\n    try:\n        from scipy.integrate import trapezoid\n    except ImportError:\n        from scipy.integrate import trapz as trapezoid\n    ql = trapezoid(qv, dx=xv[1] - xv[0])\n    qicu = -2 * ql + 2 * self.exog.shape[1]\n    qic = -2 * ql + 2 * np.trace(np.dot(omega, cov_params))\n    return (ql, qic, qicu)",
            "def qic(self, params, scale, cov_params, n_step=1000):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Returns quasi-information criteria and quasi-likelihood values.\\n\\n        Parameters\\n        ----------\\n        params : array_like\\n            The GEE estimates of the regression parameters.\\n        scale : scalar\\n            Estimated scale parameter\\n        cov_params : array_like\\n            An estimate of the covariance matrix for the\\n            model parameters.  Conventionally this is the robust\\n            covariance matrix.\\n        n_step : integer\\n            The number of points in the trapezoidal approximation\\n            to the quasi-likelihood function.\\n\\n        Returns\\n        -------\\n        ql : scalar\\n            The quasi-likelihood value\\n        qic : scalar\\n            A QIC that can be used to compare the mean and covariance\\n            structures of the model.\\n        qicu : scalar\\n            A simplified QIC that can be used to compare mean structures\\n            but not covariance structures\\n\\n        Notes\\n        -----\\n        The quasi-likelihood used here is obtained by numerically evaluating\\n        Wedderburn's integral representation of the quasi-likelihood function.\\n        This approach is valid for all families and  links.  Many other\\n        packages use analytical expressions for quasi-likelihoods that are\\n        valid in special cases where the link function is canonical.  These\\n        analytical expressions may omit additive constants that only depend\\n        on the data.  Therefore, the numerical values of our QL and QIC values\\n        will differ from the values reported by other packages.  However only\\n        the differences between two QIC values calculated for different models\\n        using the same data are meaningful.  Our QIC should produce the same\\n        QIC differences as other software.\\n\\n        When using the QIC for models with unknown scale parameter, use a\\n        common estimate of the scale parameter for all models being compared.\\n\\n        References\\n        ----------\\n        .. [*] W. Pan (2001).  Akaike's information criterion in generalized\\n               estimating equations.  Biometrics (57) 1.\\n        \"\n    varfunc = self.family.variance\n    means = []\n    omega = 0.0\n    for i in range(self.num_group):\n        (expval, lpr) = self.cached_means[i]\n        means.append(expval)\n        dmat = self.mean_deriv(self.exog_li[i], lpr)\n        omega += np.dot(dmat.T, dmat) / scale\n    means = np.concatenate(means)\n    endog_li = np.concatenate(self.endog_li)\n    du = means - endog_li\n    qv = np.empty(n_step)\n    xv = np.linspace(-0.99999, 1, n_step)\n    for (i, g) in enumerate(xv):\n        u = endog_li + (g + 1) * du / 2.0\n        vu = varfunc(u)\n        qv[i] = -np.sum(du ** 2 * (g + 1) / vu)\n    qv /= 4 * scale\n    try:\n        from scipy.integrate import trapezoid\n    except ImportError:\n        from scipy.integrate import trapz as trapezoid\n    ql = trapezoid(qv, dx=xv[1] - xv[0])\n    qicu = -2 * ql + 2 * self.exog.shape[1]\n    qic = -2 * ql + 2 * np.trace(np.dot(omega, cov_params))\n    return (ql, qic, qicu)"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, model, params, cov_params, scale, cov_type='robust', use_t=False, regularized=False, **kwds):\n    super(GEEResults, self).__init__(model, params, normalized_cov_params=cov_params, scale=scale)\n    self.df_resid = model.df_resid\n    self.df_model = model.df_model\n    self.family = model.family\n    attr_kwds = kwds.pop('attr_kwds', {})\n    self.__dict__.update(attr_kwds)\n    if not (hasattr(self, 'cov_type') and hasattr(self, 'cov_params_default')):\n        self.cov_type = cov_type\n        covariance_type = self.cov_type.lower()\n        allowed_covariances = ['robust', 'naive', 'bias_reduced']\n        if covariance_type not in allowed_covariances:\n            msg = 'GEE: `cov_type` must be one of ' + ', '.join(allowed_covariances)\n            raise ValueError(msg)\n        if cov_type == 'robust':\n            cov = self.cov_robust\n        elif cov_type == 'naive':\n            cov = self.cov_naive\n        elif cov_type == 'bias_reduced':\n            cov = self.cov_robust_bc\n        self.cov_params_default = cov\n    elif self.cov_type != cov_type:\n        raise ValueError('cov_type in argument is different from already attached cov_type')",
        "mutated": [
            "def __init__(self, model, params, cov_params, scale, cov_type='robust', use_t=False, regularized=False, **kwds):\n    if False:\n        i = 10\n    super(GEEResults, self).__init__(model, params, normalized_cov_params=cov_params, scale=scale)\n    self.df_resid = model.df_resid\n    self.df_model = model.df_model\n    self.family = model.family\n    attr_kwds = kwds.pop('attr_kwds', {})\n    self.__dict__.update(attr_kwds)\n    if not (hasattr(self, 'cov_type') and hasattr(self, 'cov_params_default')):\n        self.cov_type = cov_type\n        covariance_type = self.cov_type.lower()\n        allowed_covariances = ['robust', 'naive', 'bias_reduced']\n        if covariance_type not in allowed_covariances:\n            msg = 'GEE: `cov_type` must be one of ' + ', '.join(allowed_covariances)\n            raise ValueError(msg)\n        if cov_type == 'robust':\n            cov = self.cov_robust\n        elif cov_type == 'naive':\n            cov = self.cov_naive\n        elif cov_type == 'bias_reduced':\n            cov = self.cov_robust_bc\n        self.cov_params_default = cov\n    elif self.cov_type != cov_type:\n        raise ValueError('cov_type in argument is different from already attached cov_type')",
            "def __init__(self, model, params, cov_params, scale, cov_type='robust', use_t=False, regularized=False, **kwds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super(GEEResults, self).__init__(model, params, normalized_cov_params=cov_params, scale=scale)\n    self.df_resid = model.df_resid\n    self.df_model = model.df_model\n    self.family = model.family\n    attr_kwds = kwds.pop('attr_kwds', {})\n    self.__dict__.update(attr_kwds)\n    if not (hasattr(self, 'cov_type') and hasattr(self, 'cov_params_default')):\n        self.cov_type = cov_type\n        covariance_type = self.cov_type.lower()\n        allowed_covariances = ['robust', 'naive', 'bias_reduced']\n        if covariance_type not in allowed_covariances:\n            msg = 'GEE: `cov_type` must be one of ' + ', '.join(allowed_covariances)\n            raise ValueError(msg)\n        if cov_type == 'robust':\n            cov = self.cov_robust\n        elif cov_type == 'naive':\n            cov = self.cov_naive\n        elif cov_type == 'bias_reduced':\n            cov = self.cov_robust_bc\n        self.cov_params_default = cov\n    elif self.cov_type != cov_type:\n        raise ValueError('cov_type in argument is different from already attached cov_type')",
            "def __init__(self, model, params, cov_params, scale, cov_type='robust', use_t=False, regularized=False, **kwds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super(GEEResults, self).__init__(model, params, normalized_cov_params=cov_params, scale=scale)\n    self.df_resid = model.df_resid\n    self.df_model = model.df_model\n    self.family = model.family\n    attr_kwds = kwds.pop('attr_kwds', {})\n    self.__dict__.update(attr_kwds)\n    if not (hasattr(self, 'cov_type') and hasattr(self, 'cov_params_default')):\n        self.cov_type = cov_type\n        covariance_type = self.cov_type.lower()\n        allowed_covariances = ['robust', 'naive', 'bias_reduced']\n        if covariance_type not in allowed_covariances:\n            msg = 'GEE: `cov_type` must be one of ' + ', '.join(allowed_covariances)\n            raise ValueError(msg)\n        if cov_type == 'robust':\n            cov = self.cov_robust\n        elif cov_type == 'naive':\n            cov = self.cov_naive\n        elif cov_type == 'bias_reduced':\n            cov = self.cov_robust_bc\n        self.cov_params_default = cov\n    elif self.cov_type != cov_type:\n        raise ValueError('cov_type in argument is different from already attached cov_type')",
            "def __init__(self, model, params, cov_params, scale, cov_type='robust', use_t=False, regularized=False, **kwds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super(GEEResults, self).__init__(model, params, normalized_cov_params=cov_params, scale=scale)\n    self.df_resid = model.df_resid\n    self.df_model = model.df_model\n    self.family = model.family\n    attr_kwds = kwds.pop('attr_kwds', {})\n    self.__dict__.update(attr_kwds)\n    if not (hasattr(self, 'cov_type') and hasattr(self, 'cov_params_default')):\n        self.cov_type = cov_type\n        covariance_type = self.cov_type.lower()\n        allowed_covariances = ['robust', 'naive', 'bias_reduced']\n        if covariance_type not in allowed_covariances:\n            msg = 'GEE: `cov_type` must be one of ' + ', '.join(allowed_covariances)\n            raise ValueError(msg)\n        if cov_type == 'robust':\n            cov = self.cov_robust\n        elif cov_type == 'naive':\n            cov = self.cov_naive\n        elif cov_type == 'bias_reduced':\n            cov = self.cov_robust_bc\n        self.cov_params_default = cov\n    elif self.cov_type != cov_type:\n        raise ValueError('cov_type in argument is different from already attached cov_type')",
            "def __init__(self, model, params, cov_params, scale, cov_type='robust', use_t=False, regularized=False, **kwds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super(GEEResults, self).__init__(model, params, normalized_cov_params=cov_params, scale=scale)\n    self.df_resid = model.df_resid\n    self.df_model = model.df_model\n    self.family = model.family\n    attr_kwds = kwds.pop('attr_kwds', {})\n    self.__dict__.update(attr_kwds)\n    if not (hasattr(self, 'cov_type') and hasattr(self, 'cov_params_default')):\n        self.cov_type = cov_type\n        covariance_type = self.cov_type.lower()\n        allowed_covariances = ['robust', 'naive', 'bias_reduced']\n        if covariance_type not in allowed_covariances:\n            msg = 'GEE: `cov_type` must be one of ' + ', '.join(allowed_covariances)\n            raise ValueError(msg)\n        if cov_type == 'robust':\n            cov = self.cov_robust\n        elif cov_type == 'naive':\n            cov = self.cov_naive\n        elif cov_type == 'bias_reduced':\n            cov = self.cov_robust_bc\n        self.cov_params_default = cov\n    elif self.cov_type != cov_type:\n        raise ValueError('cov_type in argument is different from already attached cov_type')"
        ]
    },
    {
        "func_name": "resid",
        "original": "@cache_readonly\ndef resid(self):\n    \"\"\"\n        The response residuals.\n        \"\"\"\n    return self.resid_response",
        "mutated": [
            "@cache_readonly\ndef resid(self):\n    if False:\n        i = 10\n    '\\n        The response residuals.\\n        '\n    return self.resid_response",
            "@cache_readonly\ndef resid(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        The response residuals.\\n        '\n    return self.resid_response",
            "@cache_readonly\ndef resid(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        The response residuals.\\n        '\n    return self.resid_response",
            "@cache_readonly\ndef resid(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        The response residuals.\\n        '\n    return self.resid_response",
            "@cache_readonly\ndef resid(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        The response residuals.\\n        '\n    return self.resid_response"
        ]
    },
    {
        "func_name": "standard_errors",
        "original": "def standard_errors(self, cov_type='robust'):\n    \"\"\"\n        This is a convenience function that returns the standard\n        errors for any covariance type.  The value of `bse` is the\n        standard errors for whichever covariance type is specified as\n        an argument to `fit` (defaults to \"robust\").\n\n        Parameters\n        ----------\n        cov_type : str\n            One of \"robust\", \"naive\", or \"bias_reduced\".  Determines\n            the covariance used to compute standard errors.  Defaults\n            to \"robust\".\n        \"\"\"\n    covariance_type = cov_type.lower()\n    allowed_covariances = ['robust', 'naive', 'bias_reduced']\n    if covariance_type not in allowed_covariances:\n        msg = 'GEE: `covariance_type` must be one of ' + ', '.join(allowed_covariances)\n        raise ValueError(msg)\n    if covariance_type == 'robust':\n        return np.sqrt(np.diag(self.cov_robust))\n    elif covariance_type == 'naive':\n        return np.sqrt(np.diag(self.cov_naive))\n    elif covariance_type == 'bias_reduced':\n        if self.cov_robust_bc is None:\n            raise ValueError('GEE: `bias_reduced` covariance not available')\n        return np.sqrt(np.diag(self.cov_robust_bc))",
        "mutated": [
            "def standard_errors(self, cov_type='robust'):\n    if False:\n        i = 10\n    '\\n        This is a convenience function that returns the standard\\n        errors for any covariance type.  The value of `bse` is the\\n        standard errors for whichever covariance type is specified as\\n        an argument to `fit` (defaults to \"robust\").\\n\\n        Parameters\\n        ----------\\n        cov_type : str\\n            One of \"robust\", \"naive\", or \"bias_reduced\".  Determines\\n            the covariance used to compute standard errors.  Defaults\\n            to \"robust\".\\n        '\n    covariance_type = cov_type.lower()\n    allowed_covariances = ['robust', 'naive', 'bias_reduced']\n    if covariance_type not in allowed_covariances:\n        msg = 'GEE: `covariance_type` must be one of ' + ', '.join(allowed_covariances)\n        raise ValueError(msg)\n    if covariance_type == 'robust':\n        return np.sqrt(np.diag(self.cov_robust))\n    elif covariance_type == 'naive':\n        return np.sqrt(np.diag(self.cov_naive))\n    elif covariance_type == 'bias_reduced':\n        if self.cov_robust_bc is None:\n            raise ValueError('GEE: `bias_reduced` covariance not available')\n        return np.sqrt(np.diag(self.cov_robust_bc))",
            "def standard_errors(self, cov_type='robust'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        This is a convenience function that returns the standard\\n        errors for any covariance type.  The value of `bse` is the\\n        standard errors for whichever covariance type is specified as\\n        an argument to `fit` (defaults to \"robust\").\\n\\n        Parameters\\n        ----------\\n        cov_type : str\\n            One of \"robust\", \"naive\", or \"bias_reduced\".  Determines\\n            the covariance used to compute standard errors.  Defaults\\n            to \"robust\".\\n        '\n    covariance_type = cov_type.lower()\n    allowed_covariances = ['robust', 'naive', 'bias_reduced']\n    if covariance_type not in allowed_covariances:\n        msg = 'GEE: `covariance_type` must be one of ' + ', '.join(allowed_covariances)\n        raise ValueError(msg)\n    if covariance_type == 'robust':\n        return np.sqrt(np.diag(self.cov_robust))\n    elif covariance_type == 'naive':\n        return np.sqrt(np.diag(self.cov_naive))\n    elif covariance_type == 'bias_reduced':\n        if self.cov_robust_bc is None:\n            raise ValueError('GEE: `bias_reduced` covariance not available')\n        return np.sqrt(np.diag(self.cov_robust_bc))",
            "def standard_errors(self, cov_type='robust'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        This is a convenience function that returns the standard\\n        errors for any covariance type.  The value of `bse` is the\\n        standard errors for whichever covariance type is specified as\\n        an argument to `fit` (defaults to \"robust\").\\n\\n        Parameters\\n        ----------\\n        cov_type : str\\n            One of \"robust\", \"naive\", or \"bias_reduced\".  Determines\\n            the covariance used to compute standard errors.  Defaults\\n            to \"robust\".\\n        '\n    covariance_type = cov_type.lower()\n    allowed_covariances = ['robust', 'naive', 'bias_reduced']\n    if covariance_type not in allowed_covariances:\n        msg = 'GEE: `covariance_type` must be one of ' + ', '.join(allowed_covariances)\n        raise ValueError(msg)\n    if covariance_type == 'robust':\n        return np.sqrt(np.diag(self.cov_robust))\n    elif covariance_type == 'naive':\n        return np.sqrt(np.diag(self.cov_naive))\n    elif covariance_type == 'bias_reduced':\n        if self.cov_robust_bc is None:\n            raise ValueError('GEE: `bias_reduced` covariance not available')\n        return np.sqrt(np.diag(self.cov_robust_bc))",
            "def standard_errors(self, cov_type='robust'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        This is a convenience function that returns the standard\\n        errors for any covariance type.  The value of `bse` is the\\n        standard errors for whichever covariance type is specified as\\n        an argument to `fit` (defaults to \"robust\").\\n\\n        Parameters\\n        ----------\\n        cov_type : str\\n            One of \"robust\", \"naive\", or \"bias_reduced\".  Determines\\n            the covariance used to compute standard errors.  Defaults\\n            to \"robust\".\\n        '\n    covariance_type = cov_type.lower()\n    allowed_covariances = ['robust', 'naive', 'bias_reduced']\n    if covariance_type not in allowed_covariances:\n        msg = 'GEE: `covariance_type` must be one of ' + ', '.join(allowed_covariances)\n        raise ValueError(msg)\n    if covariance_type == 'robust':\n        return np.sqrt(np.diag(self.cov_robust))\n    elif covariance_type == 'naive':\n        return np.sqrt(np.diag(self.cov_naive))\n    elif covariance_type == 'bias_reduced':\n        if self.cov_robust_bc is None:\n            raise ValueError('GEE: `bias_reduced` covariance not available')\n        return np.sqrt(np.diag(self.cov_robust_bc))",
            "def standard_errors(self, cov_type='robust'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        This is a convenience function that returns the standard\\n        errors for any covariance type.  The value of `bse` is the\\n        standard errors for whichever covariance type is specified as\\n        an argument to `fit` (defaults to \"robust\").\\n\\n        Parameters\\n        ----------\\n        cov_type : str\\n            One of \"robust\", \"naive\", or \"bias_reduced\".  Determines\\n            the covariance used to compute standard errors.  Defaults\\n            to \"robust\".\\n        '\n    covariance_type = cov_type.lower()\n    allowed_covariances = ['robust', 'naive', 'bias_reduced']\n    if covariance_type not in allowed_covariances:\n        msg = 'GEE: `covariance_type` must be one of ' + ', '.join(allowed_covariances)\n        raise ValueError(msg)\n    if covariance_type == 'robust':\n        return np.sqrt(np.diag(self.cov_robust))\n    elif covariance_type == 'naive':\n        return np.sqrt(np.diag(self.cov_naive))\n    elif covariance_type == 'bias_reduced':\n        if self.cov_robust_bc is None:\n            raise ValueError('GEE: `bias_reduced` covariance not available')\n        return np.sqrt(np.diag(self.cov_robust_bc))"
        ]
    },
    {
        "func_name": "bse",
        "original": "@cache_readonly\ndef bse(self):\n    return self.standard_errors(self.cov_type)",
        "mutated": [
            "@cache_readonly\ndef bse(self):\n    if False:\n        i = 10\n    return self.standard_errors(self.cov_type)",
            "@cache_readonly\ndef bse(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return self.standard_errors(self.cov_type)",
            "@cache_readonly\ndef bse(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return self.standard_errors(self.cov_type)",
            "@cache_readonly\ndef bse(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return self.standard_errors(self.cov_type)",
            "@cache_readonly\ndef bse(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return self.standard_errors(self.cov_type)"
        ]
    },
    {
        "func_name": "score_test",
        "original": "def score_test(self):\n    \"\"\"\n        Return the results of a score test for a linear constraint.\n\n        Returns\n        -------\n        A\\x7fdictionary containing the p-value, the test statistic,\n        and the degrees of freedom for the score test.\n\n        Notes\n        -----\n        See also GEE.compare_score_test for an alternative way to perform\n        a score test.  GEEResults.score_test is more general, in that it\n        supports testing arbitrary linear equality constraints.   However\n        GEE.compare_score_test might be easier to use when comparing\n        two explicit models.\n\n        References\n        ----------\n        Xu Guo and Wei Pan (2002). \"Small sample performance of the score\n        test in GEE\".\n        http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf\n        \"\"\"\n    if not hasattr(self.model, 'score_test_results'):\n        msg = 'score_test on results instance only available when '\n        msg += ' model was fit with constraints'\n        raise ValueError(msg)\n    return self.model.score_test_results",
        "mutated": [
            "def score_test(self):\n    if False:\n        i = 10\n    '\\n        Return the results of a score test for a linear constraint.\\n\\n        Returns\\n        -------\\n        A\\x7fdictionary containing the p-value, the test statistic,\\n        and the degrees of freedom for the score test.\\n\\n        Notes\\n        -----\\n        See also GEE.compare_score_test for an alternative way to perform\\n        a score test.  GEEResults.score_test is more general, in that it\\n        supports testing arbitrary linear equality constraints.   However\\n        GEE.compare_score_test might be easier to use when comparing\\n        two explicit models.\\n\\n        References\\n        ----------\\n        Xu Guo and Wei Pan (2002). \"Small sample performance of the score\\n        test in GEE\".\\n        http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf\\n        '\n    if not hasattr(self.model, 'score_test_results'):\n        msg = 'score_test on results instance only available when '\n        msg += ' model was fit with constraints'\n        raise ValueError(msg)\n    return self.model.score_test_results",
            "def score_test(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Return the results of a score test for a linear constraint.\\n\\n        Returns\\n        -------\\n        A\\x7fdictionary containing the p-value, the test statistic,\\n        and the degrees of freedom for the score test.\\n\\n        Notes\\n        -----\\n        See also GEE.compare_score_test for an alternative way to perform\\n        a score test.  GEEResults.score_test is more general, in that it\\n        supports testing arbitrary linear equality constraints.   However\\n        GEE.compare_score_test might be easier to use when comparing\\n        two explicit models.\\n\\n        References\\n        ----------\\n        Xu Guo and Wei Pan (2002). \"Small sample performance of the score\\n        test in GEE\".\\n        http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf\\n        '\n    if not hasattr(self.model, 'score_test_results'):\n        msg = 'score_test on results instance only available when '\n        msg += ' model was fit with constraints'\n        raise ValueError(msg)\n    return self.model.score_test_results",
            "def score_test(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Return the results of a score test for a linear constraint.\\n\\n        Returns\\n        -------\\n        A\\x7fdictionary containing the p-value, the test statistic,\\n        and the degrees of freedom for the score test.\\n\\n        Notes\\n        -----\\n        See also GEE.compare_score_test for an alternative way to perform\\n        a score test.  GEEResults.score_test is more general, in that it\\n        supports testing arbitrary linear equality constraints.   However\\n        GEE.compare_score_test might be easier to use when comparing\\n        two explicit models.\\n\\n        References\\n        ----------\\n        Xu Guo and Wei Pan (2002). \"Small sample performance of the score\\n        test in GEE\".\\n        http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf\\n        '\n    if not hasattr(self.model, 'score_test_results'):\n        msg = 'score_test on results instance only available when '\n        msg += ' model was fit with constraints'\n        raise ValueError(msg)\n    return self.model.score_test_results",
            "def score_test(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Return the results of a score test for a linear constraint.\\n\\n        Returns\\n        -------\\n        A\\x7fdictionary containing the p-value, the test statistic,\\n        and the degrees of freedom for the score test.\\n\\n        Notes\\n        -----\\n        See also GEE.compare_score_test for an alternative way to perform\\n        a score test.  GEEResults.score_test is more general, in that it\\n        supports testing arbitrary linear equality constraints.   However\\n        GEE.compare_score_test might be easier to use when comparing\\n        two explicit models.\\n\\n        References\\n        ----------\\n        Xu Guo and Wei Pan (2002). \"Small sample performance of the score\\n        test in GEE\".\\n        http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf\\n        '\n    if not hasattr(self.model, 'score_test_results'):\n        msg = 'score_test on results instance only available when '\n        msg += ' model was fit with constraints'\n        raise ValueError(msg)\n    return self.model.score_test_results",
            "def score_test(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Return the results of a score test for a linear constraint.\\n\\n        Returns\\n        -------\\n        A\\x7fdictionary containing the p-value, the test statistic,\\n        and the degrees of freedom for the score test.\\n\\n        Notes\\n        -----\\n        See also GEE.compare_score_test for an alternative way to perform\\n        a score test.  GEEResults.score_test is more general, in that it\\n        supports testing arbitrary linear equality constraints.   However\\n        GEE.compare_score_test might be easier to use when comparing\\n        two explicit models.\\n\\n        References\\n        ----------\\n        Xu Guo and Wei Pan (2002). \"Small sample performance of the score\\n        test in GEE\".\\n        http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf\\n        '\n    if not hasattr(self.model, 'score_test_results'):\n        msg = 'score_test on results instance only available when '\n        msg += ' model was fit with constraints'\n        raise ValueError(msg)\n    return self.model.score_test_results"
        ]
    },
    {
        "func_name": "resid_split",
        "original": "@cache_readonly\ndef resid_split(self):\n    \"\"\"\n        Returns the residuals, the endogeneous data minus the fitted\n        values from the model.  The residuals are returned as a list\n        of arrays containing the residuals for each cluster.\n        \"\"\"\n    sresid = []\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        sresid.append(self.resid[ii])\n    return sresid",
        "mutated": [
            "@cache_readonly\ndef resid_split(self):\n    if False:\n        i = 10\n    '\\n        Returns the residuals, the endogeneous data minus the fitted\\n        values from the model.  The residuals are returned as a list\\n        of arrays containing the residuals for each cluster.\\n        '\n    sresid = []\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        sresid.append(self.resid[ii])\n    return sresid",
            "@cache_readonly\ndef resid_split(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the residuals, the endogeneous data minus the fitted\\n        values from the model.  The residuals are returned as a list\\n        of arrays containing the residuals for each cluster.\\n        '\n    sresid = []\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        sresid.append(self.resid[ii])\n    return sresid",
            "@cache_readonly\ndef resid_split(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the residuals, the endogeneous data minus the fitted\\n        values from the model.  The residuals are returned as a list\\n        of arrays containing the residuals for each cluster.\\n        '\n    sresid = []\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        sresid.append(self.resid[ii])\n    return sresid",
            "@cache_readonly\ndef resid_split(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the residuals, the endogeneous data minus the fitted\\n        values from the model.  The residuals are returned as a list\\n        of arrays containing the residuals for each cluster.\\n        '\n    sresid = []\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        sresid.append(self.resid[ii])\n    return sresid",
            "@cache_readonly\ndef resid_split(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the residuals, the endogeneous data minus the fitted\\n        values from the model.  The residuals are returned as a list\\n        of arrays containing the residuals for each cluster.\\n        '\n    sresid = []\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        sresid.append(self.resid[ii])\n    return sresid"
        ]
    },
    {
        "func_name": "resid_centered",
        "original": "@cache_readonly\ndef resid_centered(self):\n    \"\"\"\n        Returns the residuals centered within each group.\n        \"\"\"\n    cresid = self.resid.copy()\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        cresid[ii] -= cresid[ii].mean()\n    return cresid",
        "mutated": [
            "@cache_readonly\ndef resid_centered(self):\n    if False:\n        i = 10\n    '\\n        Returns the residuals centered within each group.\\n        '\n    cresid = self.resid.copy()\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        cresid[ii] -= cresid[ii].mean()\n    return cresid",
            "@cache_readonly\ndef resid_centered(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the residuals centered within each group.\\n        '\n    cresid = self.resid.copy()\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        cresid[ii] -= cresid[ii].mean()\n    return cresid",
            "@cache_readonly\ndef resid_centered(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the residuals centered within each group.\\n        '\n    cresid = self.resid.copy()\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        cresid[ii] -= cresid[ii].mean()\n    return cresid",
            "@cache_readonly\ndef resid_centered(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the residuals centered within each group.\\n        '\n    cresid = self.resid.copy()\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        cresid[ii] -= cresid[ii].mean()\n    return cresid",
            "@cache_readonly\ndef resid_centered(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the residuals centered within each group.\\n        '\n    cresid = self.resid.copy()\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        cresid[ii] -= cresid[ii].mean()\n    return cresid"
        ]
    },
    {
        "func_name": "resid_centered_split",
        "original": "@cache_readonly\ndef resid_centered_split(self):\n    \"\"\"\n        Returns the residuals centered within each group.  The\n        residuals are returned as a list of arrays containing the\n        centered residuals for each cluster.\n        \"\"\"\n    sresid = []\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        sresid.append(self.centered_resid[ii])\n    return sresid",
        "mutated": [
            "@cache_readonly\ndef resid_centered_split(self):\n    if False:\n        i = 10\n    '\\n        Returns the residuals centered within each group.  The\\n        residuals are returned as a list of arrays containing the\\n        centered residuals for each cluster.\\n        '\n    sresid = []\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        sresid.append(self.centered_resid[ii])\n    return sresid",
            "@cache_readonly\ndef resid_centered_split(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the residuals centered within each group.  The\\n        residuals are returned as a list of arrays containing the\\n        centered residuals for each cluster.\\n        '\n    sresid = []\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        sresid.append(self.centered_resid[ii])\n    return sresid",
            "@cache_readonly\ndef resid_centered_split(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the residuals centered within each group.  The\\n        residuals are returned as a list of arrays containing the\\n        centered residuals for each cluster.\\n        '\n    sresid = []\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        sresid.append(self.centered_resid[ii])\n    return sresid",
            "@cache_readonly\ndef resid_centered_split(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the residuals centered within each group.  The\\n        residuals are returned as a list of arrays containing the\\n        centered residuals for each cluster.\\n        '\n    sresid = []\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        sresid.append(self.centered_resid[ii])\n    return sresid",
            "@cache_readonly\ndef resid_centered_split(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the residuals centered within each group.  The\\n        residuals are returned as a list of arrays containing the\\n        centered residuals for each cluster.\\n        '\n    sresid = []\n    for v in self.model.group_labels:\n        ii = self.model.group_indices[v]\n        sresid.append(self.centered_resid[ii])\n    return sresid"
        ]
    },
    {
        "func_name": "qic",
        "original": "def qic(self, scale=None, n_step=1000):\n    \"\"\"\n        Returns the QIC and QICu information criteria.\n\n        See GEE.qic for documentation.\n        \"\"\"\n    if scale is None:\n        warnings.warn('QIC values obtained using scale=None are not appropriate for comparing models')\n    if scale is None:\n        scale = self.scale\n    (_, qic, qicu) = self.model.qic(self.params, scale, self.cov_params(), n_step=n_step)\n    return (qic, qicu)",
        "mutated": [
            "def qic(self, scale=None, n_step=1000):\n    if False:\n        i = 10\n    '\\n        Returns the QIC and QICu information criteria.\\n\\n        See GEE.qic for documentation.\\n        '\n    if scale is None:\n        warnings.warn('QIC values obtained using scale=None are not appropriate for comparing models')\n    if scale is None:\n        scale = self.scale\n    (_, qic, qicu) = self.model.qic(self.params, scale, self.cov_params(), n_step=n_step)\n    return (qic, qicu)",
            "def qic(self, scale=None, n_step=1000):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the QIC and QICu information criteria.\\n\\n        See GEE.qic for documentation.\\n        '\n    if scale is None:\n        warnings.warn('QIC values obtained using scale=None are not appropriate for comparing models')\n    if scale is None:\n        scale = self.scale\n    (_, qic, qicu) = self.model.qic(self.params, scale, self.cov_params(), n_step=n_step)\n    return (qic, qicu)",
            "def qic(self, scale=None, n_step=1000):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the QIC and QICu information criteria.\\n\\n        See GEE.qic for documentation.\\n        '\n    if scale is None:\n        warnings.warn('QIC values obtained using scale=None are not appropriate for comparing models')\n    if scale is None:\n        scale = self.scale\n    (_, qic, qicu) = self.model.qic(self.params, scale, self.cov_params(), n_step=n_step)\n    return (qic, qicu)",
            "def qic(self, scale=None, n_step=1000):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the QIC and QICu information criteria.\\n\\n        See GEE.qic for documentation.\\n        '\n    if scale is None:\n        warnings.warn('QIC values obtained using scale=None are not appropriate for comparing models')\n    if scale is None:\n        scale = self.scale\n    (_, qic, qicu) = self.model.qic(self.params, scale, self.cov_params(), n_step=n_step)\n    return (qic, qicu)",
            "def qic(self, scale=None, n_step=1000):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the QIC and QICu information criteria.\\n\\n        See GEE.qic for documentation.\\n        '\n    if scale is None:\n        warnings.warn('QIC values obtained using scale=None are not appropriate for comparing models')\n    if scale is None:\n        scale = self.scale\n    (_, qic, qicu) = self.model.qic(self.params, scale, self.cov_params(), n_step=n_step)\n    return (qic, qicu)"
        ]
    },
    {
        "func_name": "plot_added_variable",
        "original": "@Appender(_plot_added_variable_doc % {'extra_params_doc': ''})\ndef plot_added_variable(self, focus_exog, resid_type=None, use_glm_weights=True, fit_kwargs=None, ax=None):\n    from statsmodels.graphics.regressionplots import plot_added_variable\n    fig = plot_added_variable(self, focus_exog, resid_type=resid_type, use_glm_weights=use_glm_weights, fit_kwargs=fit_kwargs, ax=ax)\n    return fig",
        "mutated": [
            "@Appender(_plot_added_variable_doc % {'extra_params_doc': ''})\ndef plot_added_variable(self, focus_exog, resid_type=None, use_glm_weights=True, fit_kwargs=None, ax=None):\n    if False:\n        i = 10\n    from statsmodels.graphics.regressionplots import plot_added_variable\n    fig = plot_added_variable(self, focus_exog, resid_type=resid_type, use_glm_weights=use_glm_weights, fit_kwargs=fit_kwargs, ax=ax)\n    return fig",
            "@Appender(_plot_added_variable_doc % {'extra_params_doc': ''})\ndef plot_added_variable(self, focus_exog, resid_type=None, use_glm_weights=True, fit_kwargs=None, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    from statsmodels.graphics.regressionplots import plot_added_variable\n    fig = plot_added_variable(self, focus_exog, resid_type=resid_type, use_glm_weights=use_glm_weights, fit_kwargs=fit_kwargs, ax=ax)\n    return fig",
            "@Appender(_plot_added_variable_doc % {'extra_params_doc': ''})\ndef plot_added_variable(self, focus_exog, resid_type=None, use_glm_weights=True, fit_kwargs=None, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    from statsmodels.graphics.regressionplots import plot_added_variable\n    fig = plot_added_variable(self, focus_exog, resid_type=resid_type, use_glm_weights=use_glm_weights, fit_kwargs=fit_kwargs, ax=ax)\n    return fig",
            "@Appender(_plot_added_variable_doc % {'extra_params_doc': ''})\ndef plot_added_variable(self, focus_exog, resid_type=None, use_glm_weights=True, fit_kwargs=None, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    from statsmodels.graphics.regressionplots import plot_added_variable\n    fig = plot_added_variable(self, focus_exog, resid_type=resid_type, use_glm_weights=use_glm_weights, fit_kwargs=fit_kwargs, ax=ax)\n    return fig",
            "@Appender(_plot_added_variable_doc % {'extra_params_doc': ''})\ndef plot_added_variable(self, focus_exog, resid_type=None, use_glm_weights=True, fit_kwargs=None, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    from statsmodels.graphics.regressionplots import plot_added_variable\n    fig = plot_added_variable(self, focus_exog, resid_type=resid_type, use_glm_weights=use_glm_weights, fit_kwargs=fit_kwargs, ax=ax)\n    return fig"
        ]
    },
    {
        "func_name": "plot_partial_residuals",
        "original": "@Appender(_plot_partial_residuals_doc % {'extra_params_doc': ''})\ndef plot_partial_residuals(self, focus_exog, ax=None):\n    from statsmodels.graphics.regressionplots import plot_partial_residuals\n    return plot_partial_residuals(self, focus_exog, ax=ax)",
        "mutated": [
            "@Appender(_plot_partial_residuals_doc % {'extra_params_doc': ''})\ndef plot_partial_residuals(self, focus_exog, ax=None):\n    if False:\n        i = 10\n    from statsmodels.graphics.regressionplots import plot_partial_residuals\n    return plot_partial_residuals(self, focus_exog, ax=ax)",
            "@Appender(_plot_partial_residuals_doc % {'extra_params_doc': ''})\ndef plot_partial_residuals(self, focus_exog, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    from statsmodels.graphics.regressionplots import plot_partial_residuals\n    return plot_partial_residuals(self, focus_exog, ax=ax)",
            "@Appender(_plot_partial_residuals_doc % {'extra_params_doc': ''})\ndef plot_partial_residuals(self, focus_exog, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    from statsmodels.graphics.regressionplots import plot_partial_residuals\n    return plot_partial_residuals(self, focus_exog, ax=ax)",
            "@Appender(_plot_partial_residuals_doc % {'extra_params_doc': ''})\ndef plot_partial_residuals(self, focus_exog, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    from statsmodels.graphics.regressionplots import plot_partial_residuals\n    return plot_partial_residuals(self, focus_exog, ax=ax)",
            "@Appender(_plot_partial_residuals_doc % {'extra_params_doc': ''})\ndef plot_partial_residuals(self, focus_exog, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    from statsmodels.graphics.regressionplots import plot_partial_residuals\n    return plot_partial_residuals(self, focus_exog, ax=ax)"
        ]
    },
    {
        "func_name": "plot_ceres_residuals",
        "original": "@Appender(_plot_ceres_residuals_doc % {'extra_params_doc': ''})\ndef plot_ceres_residuals(self, focus_exog, frac=0.66, cond_means=None, ax=None):\n    from statsmodels.graphics.regressionplots import plot_ceres_residuals\n    return plot_ceres_residuals(self, focus_exog, frac, cond_means=cond_means, ax=ax)",
        "mutated": [
            "@Appender(_plot_ceres_residuals_doc % {'extra_params_doc': ''})\ndef plot_ceres_residuals(self, focus_exog, frac=0.66, cond_means=None, ax=None):\n    if False:\n        i = 10\n    from statsmodels.graphics.regressionplots import plot_ceres_residuals\n    return plot_ceres_residuals(self, focus_exog, frac, cond_means=cond_means, ax=ax)",
            "@Appender(_plot_ceres_residuals_doc % {'extra_params_doc': ''})\ndef plot_ceres_residuals(self, focus_exog, frac=0.66, cond_means=None, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    from statsmodels.graphics.regressionplots import plot_ceres_residuals\n    return plot_ceres_residuals(self, focus_exog, frac, cond_means=cond_means, ax=ax)",
            "@Appender(_plot_ceres_residuals_doc % {'extra_params_doc': ''})\ndef plot_ceres_residuals(self, focus_exog, frac=0.66, cond_means=None, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    from statsmodels.graphics.regressionplots import plot_ceres_residuals\n    return plot_ceres_residuals(self, focus_exog, frac, cond_means=cond_means, ax=ax)",
            "@Appender(_plot_ceres_residuals_doc % {'extra_params_doc': ''})\ndef plot_ceres_residuals(self, focus_exog, frac=0.66, cond_means=None, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    from statsmodels.graphics.regressionplots import plot_ceres_residuals\n    return plot_ceres_residuals(self, focus_exog, frac, cond_means=cond_means, ax=ax)",
            "@Appender(_plot_ceres_residuals_doc % {'extra_params_doc': ''})\ndef plot_ceres_residuals(self, focus_exog, frac=0.66, cond_means=None, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    from statsmodels.graphics.regressionplots import plot_ceres_residuals\n    return plot_ceres_residuals(self, focus_exog, frac, cond_means=cond_means, ax=ax)"
        ]
    },
    {
        "func_name": "conf_int",
        "original": "def conf_int(self, alpha=0.05, cols=None, cov_type=None):\n    \"\"\"\n        Returns confidence intervals for the fitted parameters.\n\n        Parameters\n        ----------\n        alpha : float, optional\n             The `alpha` level for the confidence interval.  i.e., The\n             default `alpha` = .05 returns a 95% confidence interval.\n        cols : array_like, optional\n             `cols` specifies which confidence intervals to return\n        cov_type : str\n             The covariance type used for computing standard errors;\n             must be one of 'robust', 'naive', and 'bias reduced'.\n             See `GEE` for details.\n\n        Notes\n        -----\n        The confidence interval is based on the Gaussian distribution.\n        \"\"\"\n    if cov_type is None:\n        bse = self.bse\n    else:\n        bse = self.standard_errors(cov_type=cov_type)\n    params = self.params\n    dist = stats.norm\n    q = dist.ppf(1 - alpha / 2)\n    if cols is None:\n        lower = self.params - q * bse\n        upper = self.params + q * bse\n    else:\n        cols = np.asarray(cols)\n        lower = params[cols] - q * bse[cols]\n        upper = params[cols] + q * bse[cols]\n    return np.asarray(lzip(lower, upper))",
        "mutated": [
            "def conf_int(self, alpha=0.05, cols=None, cov_type=None):\n    if False:\n        i = 10\n    \"\\n        Returns confidence intervals for the fitted parameters.\\n\\n        Parameters\\n        ----------\\n        alpha : float, optional\\n             The `alpha` level for the confidence interval.  i.e., The\\n             default `alpha` = .05 returns a 95% confidence interval.\\n        cols : array_like, optional\\n             `cols` specifies which confidence intervals to return\\n        cov_type : str\\n             The covariance type used for computing standard errors;\\n             must be one of 'robust', 'naive', and 'bias reduced'.\\n             See `GEE` for details.\\n\\n        Notes\\n        -----\\n        The confidence interval is based on the Gaussian distribution.\\n        \"\n    if cov_type is None:\n        bse = self.bse\n    else:\n        bse = self.standard_errors(cov_type=cov_type)\n    params = self.params\n    dist = stats.norm\n    q = dist.ppf(1 - alpha / 2)\n    if cols is None:\n        lower = self.params - q * bse\n        upper = self.params + q * bse\n    else:\n        cols = np.asarray(cols)\n        lower = params[cols] - q * bse[cols]\n        upper = params[cols] + q * bse[cols]\n    return np.asarray(lzip(lower, upper))",
            "def conf_int(self, alpha=0.05, cols=None, cov_type=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Returns confidence intervals for the fitted parameters.\\n\\n        Parameters\\n        ----------\\n        alpha : float, optional\\n             The `alpha` level for the confidence interval.  i.e., The\\n             default `alpha` = .05 returns a 95% confidence interval.\\n        cols : array_like, optional\\n             `cols` specifies which confidence intervals to return\\n        cov_type : str\\n             The covariance type used for computing standard errors;\\n             must be one of 'robust', 'naive', and 'bias reduced'.\\n             See `GEE` for details.\\n\\n        Notes\\n        -----\\n        The confidence interval is based on the Gaussian distribution.\\n        \"\n    if cov_type is None:\n        bse = self.bse\n    else:\n        bse = self.standard_errors(cov_type=cov_type)\n    params = self.params\n    dist = stats.norm\n    q = dist.ppf(1 - alpha / 2)\n    if cols is None:\n        lower = self.params - q * bse\n        upper = self.params + q * bse\n    else:\n        cols = np.asarray(cols)\n        lower = params[cols] - q * bse[cols]\n        upper = params[cols] + q * bse[cols]\n    return np.asarray(lzip(lower, upper))",
            "def conf_int(self, alpha=0.05, cols=None, cov_type=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Returns confidence intervals for the fitted parameters.\\n\\n        Parameters\\n        ----------\\n        alpha : float, optional\\n             The `alpha` level for the confidence interval.  i.e., The\\n             default `alpha` = .05 returns a 95% confidence interval.\\n        cols : array_like, optional\\n             `cols` specifies which confidence intervals to return\\n        cov_type : str\\n             The covariance type used for computing standard errors;\\n             must be one of 'robust', 'naive', and 'bias reduced'.\\n             See `GEE` for details.\\n\\n        Notes\\n        -----\\n        The confidence interval is based on the Gaussian distribution.\\n        \"\n    if cov_type is None:\n        bse = self.bse\n    else:\n        bse = self.standard_errors(cov_type=cov_type)\n    params = self.params\n    dist = stats.norm\n    q = dist.ppf(1 - alpha / 2)\n    if cols is None:\n        lower = self.params - q * bse\n        upper = self.params + q * bse\n    else:\n        cols = np.asarray(cols)\n        lower = params[cols] - q * bse[cols]\n        upper = params[cols] + q * bse[cols]\n    return np.asarray(lzip(lower, upper))",
            "def conf_int(self, alpha=0.05, cols=None, cov_type=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Returns confidence intervals for the fitted parameters.\\n\\n        Parameters\\n        ----------\\n        alpha : float, optional\\n             The `alpha` level for the confidence interval.  i.e., The\\n             default `alpha` = .05 returns a 95% confidence interval.\\n        cols : array_like, optional\\n             `cols` specifies which confidence intervals to return\\n        cov_type : str\\n             The covariance type used for computing standard errors;\\n             must be one of 'robust', 'naive', and 'bias reduced'.\\n             See `GEE` for details.\\n\\n        Notes\\n        -----\\n        The confidence interval is based on the Gaussian distribution.\\n        \"\n    if cov_type is None:\n        bse = self.bse\n    else:\n        bse = self.standard_errors(cov_type=cov_type)\n    params = self.params\n    dist = stats.norm\n    q = dist.ppf(1 - alpha / 2)\n    if cols is None:\n        lower = self.params - q * bse\n        upper = self.params + q * bse\n    else:\n        cols = np.asarray(cols)\n        lower = params[cols] - q * bse[cols]\n        upper = params[cols] + q * bse[cols]\n    return np.asarray(lzip(lower, upper))",
            "def conf_int(self, alpha=0.05, cols=None, cov_type=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Returns confidence intervals for the fitted parameters.\\n\\n        Parameters\\n        ----------\\n        alpha : float, optional\\n             The `alpha` level for the confidence interval.  i.e., The\\n             default `alpha` = .05 returns a 95% confidence interval.\\n        cols : array_like, optional\\n             `cols` specifies which confidence intervals to return\\n        cov_type : str\\n             The covariance type used for computing standard errors;\\n             must be one of 'robust', 'naive', and 'bias reduced'.\\n             See `GEE` for details.\\n\\n        Notes\\n        -----\\n        The confidence interval is based on the Gaussian distribution.\\n        \"\n    if cov_type is None:\n        bse = self.bse\n    else:\n        bse = self.standard_errors(cov_type=cov_type)\n    params = self.params\n    dist = stats.norm\n    q = dist.ppf(1 - alpha / 2)\n    if cols is None:\n        lower = self.params - q * bse\n        upper = self.params + q * bse\n    else:\n        cols = np.asarray(cols)\n        lower = params[cols] - q * bse[cols]\n        upper = params[cols] + q * bse[cols]\n    return np.asarray(lzip(lower, upper))"
        ]
    },
    {
        "func_name": "summary",
        "original": "def summary(self, yname=None, xname=None, title=None, alpha=0.05):\n    \"\"\"\n        Summarize the GEE regression results\n\n        Parameters\n        ----------\n        yname : str, optional\n            Default is `y`\n        xname : list[str], optional\n            Names for the exogenous variables, default is `var_#` for ## in\n            the number of regressors. Must match the number of parameters in\n            the model\n        title : str, optional\n            Title for the top table. If not None, then this replaces\n            the default title\n        alpha : float\n            significance level for the confidence intervals\n        cov_type : str\n            The covariance type used to compute the standard errors;\n            one of 'robust' (the usual robust sandwich-type covariance\n            estimate), 'naive' (ignores dependence), and 'bias\n            reduced' (the Mancl/DeRouen estimate).\n\n        Returns\n        -------\n        smry : Summary instance\n            this holds the summary tables and text, which can be\n            printed or converted to various output formats.\n\n        See Also\n        --------\n        statsmodels.iolib.summary.Summary : class to hold summary results\n        \"\"\"\n    top_left = [('Dep. Variable:', None), ('Model:', None), ('Method:', ['Generalized']), ('', ['Estimating Equations']), ('Family:', [self.model.family.__class__.__name__]), ('Dependence structure:', [self.model.cov_struct.__class__.__name__]), ('Date:', None), ('Covariance type: ', [self.cov_type])]\n    NY = [len(y) for y in self.model.endog_li]\n    top_right = [('No. Observations:', [sum(NY)]), ('No. clusters:', [len(self.model.endog_li)]), ('Min. cluster size:', [min(NY)]), ('Max. cluster size:', [max(NY)]), ('Mean cluster size:', ['%.1f' % np.mean(NY)]), ('Num. iterations:', ['%d' % len(self.fit_history['params'])]), ('Scale:', ['%.3f' % self.scale]), ('Time:', None)]\n    skew1 = stats.skew(self.resid)\n    kurt1 = stats.kurtosis(self.resid)\n    skew2 = stats.skew(self.centered_resid)\n    kurt2 = stats.kurtosis(self.centered_resid)\n    diagn_left = [('Skew:', ['%12.4f' % skew1]), ('Centered skew:', ['%12.4f' % skew2])]\n    diagn_right = [('Kurtosis:', ['%12.4f' % kurt1]), ('Centered kurtosis:', ['%12.4f' % kurt2])]\n    if title is None:\n        title = self.model.__class__.__name__ + ' ' + 'Regression Results'\n    if xname is None:\n        xname = self.model.exog_names\n    if yname is None:\n        yname = self.model.endog_names\n    from statsmodels.iolib.summary import Summary\n    smry = Summary()\n    smry.add_table_2cols(self, gleft=top_left, gright=top_right, yname=yname, xname=xname, title=title)\n    smry.add_table_params(self, yname=yname, xname=xname, alpha=alpha, use_t=False)\n    smry.add_table_2cols(self, gleft=diagn_left, gright=diagn_right, yname=yname, xname=xname, title='')\n    return smry",
        "mutated": [
            "def summary(self, yname=None, xname=None, title=None, alpha=0.05):\n    if False:\n        i = 10\n    \"\\n        Summarize the GEE regression results\\n\\n        Parameters\\n        ----------\\n        yname : str, optional\\n            Default is `y`\\n        xname : list[str], optional\\n            Names for the exogenous variables, default is `var_#` for ## in\\n            the number of regressors. Must match the number of parameters in\\n            the model\\n        title : str, optional\\n            Title for the top table. If not None, then this replaces\\n            the default title\\n        alpha : float\\n            significance level for the confidence intervals\\n        cov_type : str\\n            The covariance type used to compute the standard errors;\\n            one of 'robust' (the usual robust sandwich-type covariance\\n            estimate), 'naive' (ignores dependence), and 'bias\\n            reduced' (the Mancl/DeRouen estimate).\\n\\n        Returns\\n        -------\\n        smry : Summary instance\\n            this holds the summary tables and text, which can be\\n            printed or converted to various output formats.\\n\\n        See Also\\n        --------\\n        statsmodels.iolib.summary.Summary : class to hold summary results\\n        \"\n    top_left = [('Dep. Variable:', None), ('Model:', None), ('Method:', ['Generalized']), ('', ['Estimating Equations']), ('Family:', [self.model.family.__class__.__name__]), ('Dependence structure:', [self.model.cov_struct.__class__.__name__]), ('Date:', None), ('Covariance type: ', [self.cov_type])]\n    NY = [len(y) for y in self.model.endog_li]\n    top_right = [('No. Observations:', [sum(NY)]), ('No. clusters:', [len(self.model.endog_li)]), ('Min. cluster size:', [min(NY)]), ('Max. cluster size:', [max(NY)]), ('Mean cluster size:', ['%.1f' % np.mean(NY)]), ('Num. iterations:', ['%d' % len(self.fit_history['params'])]), ('Scale:', ['%.3f' % self.scale]), ('Time:', None)]\n    skew1 = stats.skew(self.resid)\n    kurt1 = stats.kurtosis(self.resid)\n    skew2 = stats.skew(self.centered_resid)\n    kurt2 = stats.kurtosis(self.centered_resid)\n    diagn_left = [('Skew:', ['%12.4f' % skew1]), ('Centered skew:', ['%12.4f' % skew2])]\n    diagn_right = [('Kurtosis:', ['%12.4f' % kurt1]), ('Centered kurtosis:', ['%12.4f' % kurt2])]\n    if title is None:\n        title = self.model.__class__.__name__ + ' ' + 'Regression Results'\n    if xname is None:\n        xname = self.model.exog_names\n    if yname is None:\n        yname = self.model.endog_names\n    from statsmodels.iolib.summary import Summary\n    smry = Summary()\n    smry.add_table_2cols(self, gleft=top_left, gright=top_right, yname=yname, xname=xname, title=title)\n    smry.add_table_params(self, yname=yname, xname=xname, alpha=alpha, use_t=False)\n    smry.add_table_2cols(self, gleft=diagn_left, gright=diagn_right, yname=yname, xname=xname, title='')\n    return smry",
            "def summary(self, yname=None, xname=None, title=None, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Summarize the GEE regression results\\n\\n        Parameters\\n        ----------\\n        yname : str, optional\\n            Default is `y`\\n        xname : list[str], optional\\n            Names for the exogenous variables, default is `var_#` for ## in\\n            the number of regressors. Must match the number of parameters in\\n            the model\\n        title : str, optional\\n            Title for the top table. If not None, then this replaces\\n            the default title\\n        alpha : float\\n            significance level for the confidence intervals\\n        cov_type : str\\n            The covariance type used to compute the standard errors;\\n            one of 'robust' (the usual robust sandwich-type covariance\\n            estimate), 'naive' (ignores dependence), and 'bias\\n            reduced' (the Mancl/DeRouen estimate).\\n\\n        Returns\\n        -------\\n        smry : Summary instance\\n            this holds the summary tables and text, which can be\\n            printed or converted to various output formats.\\n\\n        See Also\\n        --------\\n        statsmodels.iolib.summary.Summary : class to hold summary results\\n        \"\n    top_left = [('Dep. Variable:', None), ('Model:', None), ('Method:', ['Generalized']), ('', ['Estimating Equations']), ('Family:', [self.model.family.__class__.__name__]), ('Dependence structure:', [self.model.cov_struct.__class__.__name__]), ('Date:', None), ('Covariance type: ', [self.cov_type])]\n    NY = [len(y) for y in self.model.endog_li]\n    top_right = [('No. Observations:', [sum(NY)]), ('No. clusters:', [len(self.model.endog_li)]), ('Min. cluster size:', [min(NY)]), ('Max. cluster size:', [max(NY)]), ('Mean cluster size:', ['%.1f' % np.mean(NY)]), ('Num. iterations:', ['%d' % len(self.fit_history['params'])]), ('Scale:', ['%.3f' % self.scale]), ('Time:', None)]\n    skew1 = stats.skew(self.resid)\n    kurt1 = stats.kurtosis(self.resid)\n    skew2 = stats.skew(self.centered_resid)\n    kurt2 = stats.kurtosis(self.centered_resid)\n    diagn_left = [('Skew:', ['%12.4f' % skew1]), ('Centered skew:', ['%12.4f' % skew2])]\n    diagn_right = [('Kurtosis:', ['%12.4f' % kurt1]), ('Centered kurtosis:', ['%12.4f' % kurt2])]\n    if title is None:\n        title = self.model.__class__.__name__ + ' ' + 'Regression Results'\n    if xname is None:\n        xname = self.model.exog_names\n    if yname is None:\n        yname = self.model.endog_names\n    from statsmodels.iolib.summary import Summary\n    smry = Summary()\n    smry.add_table_2cols(self, gleft=top_left, gright=top_right, yname=yname, xname=xname, title=title)\n    smry.add_table_params(self, yname=yname, xname=xname, alpha=alpha, use_t=False)\n    smry.add_table_2cols(self, gleft=diagn_left, gright=diagn_right, yname=yname, xname=xname, title='')\n    return smry",
            "def summary(self, yname=None, xname=None, title=None, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Summarize the GEE regression results\\n\\n        Parameters\\n        ----------\\n        yname : str, optional\\n            Default is `y`\\n        xname : list[str], optional\\n            Names for the exogenous variables, default is `var_#` for ## in\\n            the number of regressors. Must match the number of parameters in\\n            the model\\n        title : str, optional\\n            Title for the top table. If not None, then this replaces\\n            the default title\\n        alpha : float\\n            significance level for the confidence intervals\\n        cov_type : str\\n            The covariance type used to compute the standard errors;\\n            one of 'robust' (the usual robust sandwich-type covariance\\n            estimate), 'naive' (ignores dependence), and 'bias\\n            reduced' (the Mancl/DeRouen estimate).\\n\\n        Returns\\n        -------\\n        smry : Summary instance\\n            this holds the summary tables and text, which can be\\n            printed or converted to various output formats.\\n\\n        See Also\\n        --------\\n        statsmodels.iolib.summary.Summary : class to hold summary results\\n        \"\n    top_left = [('Dep. Variable:', None), ('Model:', None), ('Method:', ['Generalized']), ('', ['Estimating Equations']), ('Family:', [self.model.family.__class__.__name__]), ('Dependence structure:', [self.model.cov_struct.__class__.__name__]), ('Date:', None), ('Covariance type: ', [self.cov_type])]\n    NY = [len(y) for y in self.model.endog_li]\n    top_right = [('No. Observations:', [sum(NY)]), ('No. clusters:', [len(self.model.endog_li)]), ('Min. cluster size:', [min(NY)]), ('Max. cluster size:', [max(NY)]), ('Mean cluster size:', ['%.1f' % np.mean(NY)]), ('Num. iterations:', ['%d' % len(self.fit_history['params'])]), ('Scale:', ['%.3f' % self.scale]), ('Time:', None)]\n    skew1 = stats.skew(self.resid)\n    kurt1 = stats.kurtosis(self.resid)\n    skew2 = stats.skew(self.centered_resid)\n    kurt2 = stats.kurtosis(self.centered_resid)\n    diagn_left = [('Skew:', ['%12.4f' % skew1]), ('Centered skew:', ['%12.4f' % skew2])]\n    diagn_right = [('Kurtosis:', ['%12.4f' % kurt1]), ('Centered kurtosis:', ['%12.4f' % kurt2])]\n    if title is None:\n        title = self.model.__class__.__name__ + ' ' + 'Regression Results'\n    if xname is None:\n        xname = self.model.exog_names\n    if yname is None:\n        yname = self.model.endog_names\n    from statsmodels.iolib.summary import Summary\n    smry = Summary()\n    smry.add_table_2cols(self, gleft=top_left, gright=top_right, yname=yname, xname=xname, title=title)\n    smry.add_table_params(self, yname=yname, xname=xname, alpha=alpha, use_t=False)\n    smry.add_table_2cols(self, gleft=diagn_left, gright=diagn_right, yname=yname, xname=xname, title='')\n    return smry",
            "def summary(self, yname=None, xname=None, title=None, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Summarize the GEE regression results\\n\\n        Parameters\\n        ----------\\n        yname : str, optional\\n            Default is `y`\\n        xname : list[str], optional\\n            Names for the exogenous variables, default is `var_#` for ## in\\n            the number of regressors. Must match the number of parameters in\\n            the model\\n        title : str, optional\\n            Title for the top table. If not None, then this replaces\\n            the default title\\n        alpha : float\\n            significance level for the confidence intervals\\n        cov_type : str\\n            The covariance type used to compute the standard errors;\\n            one of 'robust' (the usual robust sandwich-type covariance\\n            estimate), 'naive' (ignores dependence), and 'bias\\n            reduced' (the Mancl/DeRouen estimate).\\n\\n        Returns\\n        -------\\n        smry : Summary instance\\n            this holds the summary tables and text, which can be\\n            printed or converted to various output formats.\\n\\n        See Also\\n        --------\\n        statsmodels.iolib.summary.Summary : class to hold summary results\\n        \"\n    top_left = [('Dep. Variable:', None), ('Model:', None), ('Method:', ['Generalized']), ('', ['Estimating Equations']), ('Family:', [self.model.family.__class__.__name__]), ('Dependence structure:', [self.model.cov_struct.__class__.__name__]), ('Date:', None), ('Covariance type: ', [self.cov_type])]\n    NY = [len(y) for y in self.model.endog_li]\n    top_right = [('No. Observations:', [sum(NY)]), ('No. clusters:', [len(self.model.endog_li)]), ('Min. cluster size:', [min(NY)]), ('Max. cluster size:', [max(NY)]), ('Mean cluster size:', ['%.1f' % np.mean(NY)]), ('Num. iterations:', ['%d' % len(self.fit_history['params'])]), ('Scale:', ['%.3f' % self.scale]), ('Time:', None)]\n    skew1 = stats.skew(self.resid)\n    kurt1 = stats.kurtosis(self.resid)\n    skew2 = stats.skew(self.centered_resid)\n    kurt2 = stats.kurtosis(self.centered_resid)\n    diagn_left = [('Skew:', ['%12.4f' % skew1]), ('Centered skew:', ['%12.4f' % skew2])]\n    diagn_right = [('Kurtosis:', ['%12.4f' % kurt1]), ('Centered kurtosis:', ['%12.4f' % kurt2])]\n    if title is None:\n        title = self.model.__class__.__name__ + ' ' + 'Regression Results'\n    if xname is None:\n        xname = self.model.exog_names\n    if yname is None:\n        yname = self.model.endog_names\n    from statsmodels.iolib.summary import Summary\n    smry = Summary()\n    smry.add_table_2cols(self, gleft=top_left, gright=top_right, yname=yname, xname=xname, title=title)\n    smry.add_table_params(self, yname=yname, xname=xname, alpha=alpha, use_t=False)\n    smry.add_table_2cols(self, gleft=diagn_left, gright=diagn_right, yname=yname, xname=xname, title='')\n    return smry",
            "def summary(self, yname=None, xname=None, title=None, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Summarize the GEE regression results\\n\\n        Parameters\\n        ----------\\n        yname : str, optional\\n            Default is `y`\\n        xname : list[str], optional\\n            Names for the exogenous variables, default is `var_#` for ## in\\n            the number of regressors. Must match the number of parameters in\\n            the model\\n        title : str, optional\\n            Title for the top table. If not None, then this replaces\\n            the default title\\n        alpha : float\\n            significance level for the confidence intervals\\n        cov_type : str\\n            The covariance type used to compute the standard errors;\\n            one of 'robust' (the usual robust sandwich-type covariance\\n            estimate), 'naive' (ignores dependence), and 'bias\\n            reduced' (the Mancl/DeRouen estimate).\\n\\n        Returns\\n        -------\\n        smry : Summary instance\\n            this holds the summary tables and text, which can be\\n            printed or converted to various output formats.\\n\\n        See Also\\n        --------\\n        statsmodels.iolib.summary.Summary : class to hold summary results\\n        \"\n    top_left = [('Dep. Variable:', None), ('Model:', None), ('Method:', ['Generalized']), ('', ['Estimating Equations']), ('Family:', [self.model.family.__class__.__name__]), ('Dependence structure:', [self.model.cov_struct.__class__.__name__]), ('Date:', None), ('Covariance type: ', [self.cov_type])]\n    NY = [len(y) for y in self.model.endog_li]\n    top_right = [('No. Observations:', [sum(NY)]), ('No. clusters:', [len(self.model.endog_li)]), ('Min. cluster size:', [min(NY)]), ('Max. cluster size:', [max(NY)]), ('Mean cluster size:', ['%.1f' % np.mean(NY)]), ('Num. iterations:', ['%d' % len(self.fit_history['params'])]), ('Scale:', ['%.3f' % self.scale]), ('Time:', None)]\n    skew1 = stats.skew(self.resid)\n    kurt1 = stats.kurtosis(self.resid)\n    skew2 = stats.skew(self.centered_resid)\n    kurt2 = stats.kurtosis(self.centered_resid)\n    diagn_left = [('Skew:', ['%12.4f' % skew1]), ('Centered skew:', ['%12.4f' % skew2])]\n    diagn_right = [('Kurtosis:', ['%12.4f' % kurt1]), ('Centered kurtosis:', ['%12.4f' % kurt2])]\n    if title is None:\n        title = self.model.__class__.__name__ + ' ' + 'Regression Results'\n    if xname is None:\n        xname = self.model.exog_names\n    if yname is None:\n        yname = self.model.endog_names\n    from statsmodels.iolib.summary import Summary\n    smry = Summary()\n    smry.add_table_2cols(self, gleft=top_left, gright=top_right, yname=yname, xname=xname, title=title)\n    smry.add_table_params(self, yname=yname, xname=xname, alpha=alpha, use_t=False)\n    smry.add_table_2cols(self, gleft=diagn_left, gright=diagn_right, yname=yname, xname=xname, title='')\n    return smry"
        ]
    },
    {
        "func_name": "get_margeff",
        "original": "def get_margeff(self, at='overall', method='dydx', atexog=None, dummy=False, count=False):\n    \"\"\"Get marginal effects of the fitted model.\n\n        Parameters\n        ----------\n        at : str, optional\n            Options are:\n\n            - 'overall', The average of the marginal effects at each\n              observation.\n            - 'mean', The marginal effects at the mean of each regressor.\n            - 'median', The marginal effects at the median of each regressor.\n            - 'zero', The marginal effects at zero for each regressor.\n            - 'all', The marginal effects at each observation. If `at` is 'all'\n              only margeff will be available.\n\n            Note that if `exog` is specified, then marginal effects for all\n            variables not specified by `exog` are calculated using the `at`\n            option.\n        method : str, optional\n            Options are:\n\n            - 'dydx' - dy/dx - No transformation is made and marginal effects\n              are returned.  This is the default.\n            - 'eyex' - estimate elasticities of variables in `exog` --\n              d(lny)/d(lnx)\n            - 'dyex' - estimate semi-elasticity -- dy/d(lnx)\n            - 'eydx' - estimate semi-elasticity -- d(lny)/dx\n\n            Note that tranformations are done after each observation is\n            calculated.  Semi-elasticities for binary variables are computed\n            using the midpoint method. 'dyex' and 'eyex' do not make sense\n            for discrete variables.\n        atexog : array_like, optional\n            Optionally, you can provide the exogenous variables over which to\n            get the marginal effects.  This should be a dictionary with the key\n            as the zero-indexed column number and the value of the dictionary.\n            Default is None for all independent variables less the constant.\n        dummy : bool, optional\n            If False, treats binary variables (if present) as continuous.  This\n            is the default.  Else if True, treats binary variables as\n            changing from 0 to 1.  Note that any variable that is either 0 or 1\n            is treated as binary.  Each binary variable is treated separately\n            for now.\n        count : bool, optional\n            If False, treats count variables (if present) as continuous.  This\n            is the default.  Else if True, the marginal effect is the\n            change in probabilities when each observation is increased by one.\n\n        Returns\n        -------\n        effects : ndarray\n            the marginal effect corresponding to the input options\n\n        Notes\n        -----\n        When using after Poisson, returns the expected number of events\n        per period, assuming that the model is loglinear.\n        \"\"\"\n    if self.model.constraint is not None:\n        warnings.warn('marginal effects ignore constraints', ValueWarning)\n    return GEEMargins(self, (at, method, atexog, dummy, count))",
        "mutated": [
            "def get_margeff(self, at='overall', method='dydx', atexog=None, dummy=False, count=False):\n    if False:\n        i = 10\n    \"Get marginal effects of the fitted model.\\n\\n        Parameters\\n        ----------\\n        at : str, optional\\n            Options are:\\n\\n            - 'overall', The average of the marginal effects at each\\n              observation.\\n            - 'mean', The marginal effects at the mean of each regressor.\\n            - 'median', The marginal effects at the median of each regressor.\\n            - 'zero', The marginal effects at zero for each regressor.\\n            - 'all', The marginal effects at each observation. If `at` is 'all'\\n              only margeff will be available.\\n\\n            Note that if `exog` is specified, then marginal effects for all\\n            variables not specified by `exog` are calculated using the `at`\\n            option.\\n        method : str, optional\\n            Options are:\\n\\n            - 'dydx' - dy/dx - No transformation is made and marginal effects\\n              are returned.  This is the default.\\n            - 'eyex' - estimate elasticities of variables in `exog` --\\n              d(lny)/d(lnx)\\n            - 'dyex' - estimate semi-elasticity -- dy/d(lnx)\\n            - 'eydx' - estimate semi-elasticity -- d(lny)/dx\\n\\n            Note that tranformations are done after each observation is\\n            calculated.  Semi-elasticities for binary variables are computed\\n            using the midpoint method. 'dyex' and 'eyex' do not make sense\\n            for discrete variables.\\n        atexog : array_like, optional\\n            Optionally, you can provide the exogenous variables over which to\\n            get the marginal effects.  This should be a dictionary with the key\\n            as the zero-indexed column number and the value of the dictionary.\\n            Default is None for all independent variables less the constant.\\n        dummy : bool, optional\\n            If False, treats binary variables (if present) as continuous.  This\\n            is the default.  Else if True, treats binary variables as\\n            changing from 0 to 1.  Note that any variable that is either 0 or 1\\n            is treated as binary.  Each binary variable is treated separately\\n            for now.\\n        count : bool, optional\\n            If False, treats count variables (if present) as continuous.  This\\n            is the default.  Else if True, the marginal effect is the\\n            change in probabilities when each observation is increased by one.\\n\\n        Returns\\n        -------\\n        effects : ndarray\\n            the marginal effect corresponding to the input options\\n\\n        Notes\\n        -----\\n        When using after Poisson, returns the expected number of events\\n        per period, assuming that the model is loglinear.\\n        \"\n    if self.model.constraint is not None:\n        warnings.warn('marginal effects ignore constraints', ValueWarning)\n    return GEEMargins(self, (at, method, atexog, dummy, count))",
            "def get_margeff(self, at='overall', method='dydx', atexog=None, dummy=False, count=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Get marginal effects of the fitted model.\\n\\n        Parameters\\n        ----------\\n        at : str, optional\\n            Options are:\\n\\n            - 'overall', The average of the marginal effects at each\\n              observation.\\n            - 'mean', The marginal effects at the mean of each regressor.\\n            - 'median', The marginal effects at the median of each regressor.\\n            - 'zero', The marginal effects at zero for each regressor.\\n            - 'all', The marginal effects at each observation. If `at` is 'all'\\n              only margeff will be available.\\n\\n            Note that if `exog` is specified, then marginal effects for all\\n            variables not specified by `exog` are calculated using the `at`\\n            option.\\n        method : str, optional\\n            Options are:\\n\\n            - 'dydx' - dy/dx - No transformation is made and marginal effects\\n              are returned.  This is the default.\\n            - 'eyex' - estimate elasticities of variables in `exog` --\\n              d(lny)/d(lnx)\\n            - 'dyex' - estimate semi-elasticity -- dy/d(lnx)\\n            - 'eydx' - estimate semi-elasticity -- d(lny)/dx\\n\\n            Note that tranformations are done after each observation is\\n            calculated.  Semi-elasticities for binary variables are computed\\n            using the midpoint method. 'dyex' and 'eyex' do not make sense\\n            for discrete variables.\\n        atexog : array_like, optional\\n            Optionally, you can provide the exogenous variables over which to\\n            get the marginal effects.  This should be a dictionary with the key\\n            as the zero-indexed column number and the value of the dictionary.\\n            Default is None for all independent variables less the constant.\\n        dummy : bool, optional\\n            If False, treats binary variables (if present) as continuous.  This\\n            is the default.  Else if True, treats binary variables as\\n            changing from 0 to 1.  Note that any variable that is either 0 or 1\\n            is treated as binary.  Each binary variable is treated separately\\n            for now.\\n        count : bool, optional\\n            If False, treats count variables (if present) as continuous.  This\\n            is the default.  Else if True, the marginal effect is the\\n            change in probabilities when each observation is increased by one.\\n\\n        Returns\\n        -------\\n        effects : ndarray\\n            the marginal effect corresponding to the input options\\n\\n        Notes\\n        -----\\n        When using after Poisson, returns the expected number of events\\n        per period, assuming that the model is loglinear.\\n        \"\n    if self.model.constraint is not None:\n        warnings.warn('marginal effects ignore constraints', ValueWarning)\n    return GEEMargins(self, (at, method, atexog, dummy, count))",
            "def get_margeff(self, at='overall', method='dydx', atexog=None, dummy=False, count=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Get marginal effects of the fitted model.\\n\\n        Parameters\\n        ----------\\n        at : str, optional\\n            Options are:\\n\\n            - 'overall', The average of the marginal effects at each\\n              observation.\\n            - 'mean', The marginal effects at the mean of each regressor.\\n            - 'median', The marginal effects at the median of each regressor.\\n            - 'zero', The marginal effects at zero for each regressor.\\n            - 'all', The marginal effects at each observation. If `at` is 'all'\\n              only margeff will be available.\\n\\n            Note that if `exog` is specified, then marginal effects for all\\n            variables not specified by `exog` are calculated using the `at`\\n            option.\\n        method : str, optional\\n            Options are:\\n\\n            - 'dydx' - dy/dx - No transformation is made and marginal effects\\n              are returned.  This is the default.\\n            - 'eyex' - estimate elasticities of variables in `exog` --\\n              d(lny)/d(lnx)\\n            - 'dyex' - estimate semi-elasticity -- dy/d(lnx)\\n            - 'eydx' - estimate semi-elasticity -- d(lny)/dx\\n\\n            Note that tranformations are done after each observation is\\n            calculated.  Semi-elasticities for binary variables are computed\\n            using the midpoint method. 'dyex' and 'eyex' do not make sense\\n            for discrete variables.\\n        atexog : array_like, optional\\n            Optionally, you can provide the exogenous variables over which to\\n            get the marginal effects.  This should be a dictionary with the key\\n            as the zero-indexed column number and the value of the dictionary.\\n            Default is None for all independent variables less the constant.\\n        dummy : bool, optional\\n            If False, treats binary variables (if present) as continuous.  This\\n            is the default.  Else if True, treats binary variables as\\n            changing from 0 to 1.  Note that any variable that is either 0 or 1\\n            is treated as binary.  Each binary variable is treated separately\\n            for now.\\n        count : bool, optional\\n            If False, treats count variables (if present) as continuous.  This\\n            is the default.  Else if True, the marginal effect is the\\n            change in probabilities when each observation is increased by one.\\n\\n        Returns\\n        -------\\n        effects : ndarray\\n            the marginal effect corresponding to the input options\\n\\n        Notes\\n        -----\\n        When using after Poisson, returns the expected number of events\\n        per period, assuming that the model is loglinear.\\n        \"\n    if self.model.constraint is not None:\n        warnings.warn('marginal effects ignore constraints', ValueWarning)\n    return GEEMargins(self, (at, method, atexog, dummy, count))",
            "def get_margeff(self, at='overall', method='dydx', atexog=None, dummy=False, count=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Get marginal effects of the fitted model.\\n\\n        Parameters\\n        ----------\\n        at : str, optional\\n            Options are:\\n\\n            - 'overall', The average of the marginal effects at each\\n              observation.\\n            - 'mean', The marginal effects at the mean of each regressor.\\n            - 'median', The marginal effects at the median of each regressor.\\n            - 'zero', The marginal effects at zero for each regressor.\\n            - 'all', The marginal effects at each observation. If `at` is 'all'\\n              only margeff will be available.\\n\\n            Note that if `exog` is specified, then marginal effects for all\\n            variables not specified by `exog` are calculated using the `at`\\n            option.\\n        method : str, optional\\n            Options are:\\n\\n            - 'dydx' - dy/dx - No transformation is made and marginal effects\\n              are returned.  This is the default.\\n            - 'eyex' - estimate elasticities of variables in `exog` --\\n              d(lny)/d(lnx)\\n            - 'dyex' - estimate semi-elasticity -- dy/d(lnx)\\n            - 'eydx' - estimate semi-elasticity -- d(lny)/dx\\n\\n            Note that tranformations are done after each observation is\\n            calculated.  Semi-elasticities for binary variables are computed\\n            using the midpoint method. 'dyex' and 'eyex' do not make sense\\n            for discrete variables.\\n        atexog : array_like, optional\\n            Optionally, you can provide the exogenous variables over which to\\n            get the marginal effects.  This should be a dictionary with the key\\n            as the zero-indexed column number and the value of the dictionary.\\n            Default is None for all independent variables less the constant.\\n        dummy : bool, optional\\n            If False, treats binary variables (if present) as continuous.  This\\n            is the default.  Else if True, treats binary variables as\\n            changing from 0 to 1.  Note that any variable that is either 0 or 1\\n            is treated as binary.  Each binary variable is treated separately\\n            for now.\\n        count : bool, optional\\n            If False, treats count variables (if present) as continuous.  This\\n            is the default.  Else if True, the marginal effect is the\\n            change in probabilities when each observation is increased by one.\\n\\n        Returns\\n        -------\\n        effects : ndarray\\n            the marginal effect corresponding to the input options\\n\\n        Notes\\n        -----\\n        When using after Poisson, returns the expected number of events\\n        per period, assuming that the model is loglinear.\\n        \"\n    if self.model.constraint is not None:\n        warnings.warn('marginal effects ignore constraints', ValueWarning)\n    return GEEMargins(self, (at, method, atexog, dummy, count))",
            "def get_margeff(self, at='overall', method='dydx', atexog=None, dummy=False, count=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Get marginal effects of the fitted model.\\n\\n        Parameters\\n        ----------\\n        at : str, optional\\n            Options are:\\n\\n            - 'overall', The average of the marginal effects at each\\n              observation.\\n            - 'mean', The marginal effects at the mean of each regressor.\\n            - 'median', The marginal effects at the median of each regressor.\\n            - 'zero', The marginal effects at zero for each regressor.\\n            - 'all', The marginal effects at each observation. If `at` is 'all'\\n              only margeff will be available.\\n\\n            Note that if `exog` is specified, then marginal effects for all\\n            variables not specified by `exog` are calculated using the `at`\\n            option.\\n        method : str, optional\\n            Options are:\\n\\n            - 'dydx' - dy/dx - No transformation is made and marginal effects\\n              are returned.  This is the default.\\n            - 'eyex' - estimate elasticities of variables in `exog` --\\n              d(lny)/d(lnx)\\n            - 'dyex' - estimate semi-elasticity -- dy/d(lnx)\\n            - 'eydx' - estimate semi-elasticity -- d(lny)/dx\\n\\n            Note that tranformations are done after each observation is\\n            calculated.  Semi-elasticities for binary variables are computed\\n            using the midpoint method. 'dyex' and 'eyex' do not make sense\\n            for discrete variables.\\n        atexog : array_like, optional\\n            Optionally, you can provide the exogenous variables over which to\\n            get the marginal effects.  This should be a dictionary with the key\\n            as the zero-indexed column number and the value of the dictionary.\\n            Default is None for all independent variables less the constant.\\n        dummy : bool, optional\\n            If False, treats binary variables (if present) as continuous.  This\\n            is the default.  Else if True, treats binary variables as\\n            changing from 0 to 1.  Note that any variable that is either 0 or 1\\n            is treated as binary.  Each binary variable is treated separately\\n            for now.\\n        count : bool, optional\\n            If False, treats count variables (if present) as continuous.  This\\n            is the default.  Else if True, the marginal effect is the\\n            change in probabilities when each observation is increased by one.\\n\\n        Returns\\n        -------\\n        effects : ndarray\\n            the marginal effect corresponding to the input options\\n\\n        Notes\\n        -----\\n        When using after Poisson, returns the expected number of events\\n        per period, assuming that the model is loglinear.\\n        \"\n    if self.model.constraint is not None:\n        warnings.warn('marginal effects ignore constraints', ValueWarning)\n    return GEEMargins(self, (at, method, atexog, dummy, count))"
        ]
    },
    {
        "func_name": "plot_isotropic_dependence",
        "original": "def plot_isotropic_dependence(self, ax=None, xpoints=10, min_n=50):\n    \"\"\"\n        Create a plot of the pairwise products of within-group\n        residuals against the corresponding time differences.  This\n        plot can be used to assess the possible form of an isotropic\n        covariance structure.\n\n        Parameters\n        ----------\n        ax : AxesSubplot\n            An axes on which to draw the graph.  If None, new\n            figure and axes objects are created\n        xpoints : scalar or array_like\n            If scalar, the number of points equally spaced points on\n            the time difference axis used to define bins for\n            calculating local means.  If an array, the specific points\n            that define the bins.\n        min_n : int\n            The minimum sample size in a bin for the mean residual\n            product to be included on the plot.\n        \"\"\"\n    from statsmodels.graphics import utils as gutils\n    resid = self.model.cluster_list(self.resid)\n    time = self.model.cluster_list(self.model.time)\n    (xre, xdt) = ([], [])\n    for (re, ti) in zip(resid, time):\n        ix = np.tril_indices(re.shape[0], 0)\n        re = re[ix[0]] * re[ix[1]] / self.scale ** 2\n        xre.append(re)\n        dists = np.sqrt(((ti[ix[0], :] - ti[ix[1], :]) ** 2).sum(1))\n        xdt.append(dists)\n    xre = np.concatenate(xre)\n    xdt = np.concatenate(xdt)\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    ii = np.flatnonzero(xdt == 0)\n    v0 = np.mean(xre[ii])\n    xre /= v0\n    if np.isscalar(xpoints):\n        xpoints = np.linspace(0, max(xdt), xpoints)\n    dg = np.digitize(xdt, xpoints)\n    dgu = np.unique(dg)\n    hist = np.asarray([np.sum(dg == k) for k in dgu])\n    ii = np.flatnonzero(hist >= min_n)\n    dgu = dgu[ii]\n    dgy = np.asarray([np.mean(xre[dg == k]) for k in dgu])\n    dgx = np.asarray([np.mean(xdt[dg == k]) for k in dgu])\n    ax.plot(dgx, dgy, '-', color='orange', lw=5)\n    ax.set_xlabel('Time difference')\n    ax.set_ylabel('Product of scaled residuals')\n    return fig",
        "mutated": [
            "def plot_isotropic_dependence(self, ax=None, xpoints=10, min_n=50):\n    if False:\n        i = 10\n    '\\n        Create a plot of the pairwise products of within-group\\n        residuals against the corresponding time differences.  This\\n        plot can be used to assess the possible form of an isotropic\\n        covariance structure.\\n\\n        Parameters\\n        ----------\\n        ax : AxesSubplot\\n            An axes on which to draw the graph.  If None, new\\n            figure and axes objects are created\\n        xpoints : scalar or array_like\\n            If scalar, the number of points equally spaced points on\\n            the time difference axis used to define bins for\\n            calculating local means.  If an array, the specific points\\n            that define the bins.\\n        min_n : int\\n            The minimum sample size in a bin for the mean residual\\n            product to be included on the plot.\\n        '\n    from statsmodels.graphics import utils as gutils\n    resid = self.model.cluster_list(self.resid)\n    time = self.model.cluster_list(self.model.time)\n    (xre, xdt) = ([], [])\n    for (re, ti) in zip(resid, time):\n        ix = np.tril_indices(re.shape[0], 0)\n        re = re[ix[0]] * re[ix[1]] / self.scale ** 2\n        xre.append(re)\n        dists = np.sqrt(((ti[ix[0], :] - ti[ix[1], :]) ** 2).sum(1))\n        xdt.append(dists)\n    xre = np.concatenate(xre)\n    xdt = np.concatenate(xdt)\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    ii = np.flatnonzero(xdt == 0)\n    v0 = np.mean(xre[ii])\n    xre /= v0\n    if np.isscalar(xpoints):\n        xpoints = np.linspace(0, max(xdt), xpoints)\n    dg = np.digitize(xdt, xpoints)\n    dgu = np.unique(dg)\n    hist = np.asarray([np.sum(dg == k) for k in dgu])\n    ii = np.flatnonzero(hist >= min_n)\n    dgu = dgu[ii]\n    dgy = np.asarray([np.mean(xre[dg == k]) for k in dgu])\n    dgx = np.asarray([np.mean(xdt[dg == k]) for k in dgu])\n    ax.plot(dgx, dgy, '-', color='orange', lw=5)\n    ax.set_xlabel('Time difference')\n    ax.set_ylabel('Product of scaled residuals')\n    return fig",
            "def plot_isotropic_dependence(self, ax=None, xpoints=10, min_n=50):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Create a plot of the pairwise products of within-group\\n        residuals against the corresponding time differences.  This\\n        plot can be used to assess the possible form of an isotropic\\n        covariance structure.\\n\\n        Parameters\\n        ----------\\n        ax : AxesSubplot\\n            An axes on which to draw the graph.  If None, new\\n            figure and axes objects are created\\n        xpoints : scalar or array_like\\n            If scalar, the number of points equally spaced points on\\n            the time difference axis used to define bins for\\n            calculating local means.  If an array, the specific points\\n            that define the bins.\\n        min_n : int\\n            The minimum sample size in a bin for the mean residual\\n            product to be included on the plot.\\n        '\n    from statsmodels.graphics import utils as gutils\n    resid = self.model.cluster_list(self.resid)\n    time = self.model.cluster_list(self.model.time)\n    (xre, xdt) = ([], [])\n    for (re, ti) in zip(resid, time):\n        ix = np.tril_indices(re.shape[0], 0)\n        re = re[ix[0]] * re[ix[1]] / self.scale ** 2\n        xre.append(re)\n        dists = np.sqrt(((ti[ix[0], :] - ti[ix[1], :]) ** 2).sum(1))\n        xdt.append(dists)\n    xre = np.concatenate(xre)\n    xdt = np.concatenate(xdt)\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    ii = np.flatnonzero(xdt == 0)\n    v0 = np.mean(xre[ii])\n    xre /= v0\n    if np.isscalar(xpoints):\n        xpoints = np.linspace(0, max(xdt), xpoints)\n    dg = np.digitize(xdt, xpoints)\n    dgu = np.unique(dg)\n    hist = np.asarray([np.sum(dg == k) for k in dgu])\n    ii = np.flatnonzero(hist >= min_n)\n    dgu = dgu[ii]\n    dgy = np.asarray([np.mean(xre[dg == k]) for k in dgu])\n    dgx = np.asarray([np.mean(xdt[dg == k]) for k in dgu])\n    ax.plot(dgx, dgy, '-', color='orange', lw=5)\n    ax.set_xlabel('Time difference')\n    ax.set_ylabel('Product of scaled residuals')\n    return fig",
            "def plot_isotropic_dependence(self, ax=None, xpoints=10, min_n=50):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Create a plot of the pairwise products of within-group\\n        residuals against the corresponding time differences.  This\\n        plot can be used to assess the possible form of an isotropic\\n        covariance structure.\\n\\n        Parameters\\n        ----------\\n        ax : AxesSubplot\\n            An axes on which to draw the graph.  If None, new\\n            figure and axes objects are created\\n        xpoints : scalar or array_like\\n            If scalar, the number of points equally spaced points on\\n            the time difference axis used to define bins for\\n            calculating local means.  If an array, the specific points\\n            that define the bins.\\n        min_n : int\\n            The minimum sample size in a bin for the mean residual\\n            product to be included on the plot.\\n        '\n    from statsmodels.graphics import utils as gutils\n    resid = self.model.cluster_list(self.resid)\n    time = self.model.cluster_list(self.model.time)\n    (xre, xdt) = ([], [])\n    for (re, ti) in zip(resid, time):\n        ix = np.tril_indices(re.shape[0], 0)\n        re = re[ix[0]] * re[ix[1]] / self.scale ** 2\n        xre.append(re)\n        dists = np.sqrt(((ti[ix[0], :] - ti[ix[1], :]) ** 2).sum(1))\n        xdt.append(dists)\n    xre = np.concatenate(xre)\n    xdt = np.concatenate(xdt)\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    ii = np.flatnonzero(xdt == 0)\n    v0 = np.mean(xre[ii])\n    xre /= v0\n    if np.isscalar(xpoints):\n        xpoints = np.linspace(0, max(xdt), xpoints)\n    dg = np.digitize(xdt, xpoints)\n    dgu = np.unique(dg)\n    hist = np.asarray([np.sum(dg == k) for k in dgu])\n    ii = np.flatnonzero(hist >= min_n)\n    dgu = dgu[ii]\n    dgy = np.asarray([np.mean(xre[dg == k]) for k in dgu])\n    dgx = np.asarray([np.mean(xdt[dg == k]) for k in dgu])\n    ax.plot(dgx, dgy, '-', color='orange', lw=5)\n    ax.set_xlabel('Time difference')\n    ax.set_ylabel('Product of scaled residuals')\n    return fig",
            "def plot_isotropic_dependence(self, ax=None, xpoints=10, min_n=50):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Create a plot of the pairwise products of within-group\\n        residuals against the corresponding time differences.  This\\n        plot can be used to assess the possible form of an isotropic\\n        covariance structure.\\n\\n        Parameters\\n        ----------\\n        ax : AxesSubplot\\n            An axes on which to draw the graph.  If None, new\\n            figure and axes objects are created\\n        xpoints : scalar or array_like\\n            If scalar, the number of points equally spaced points on\\n            the time difference axis used to define bins for\\n            calculating local means.  If an array, the specific points\\n            that define the bins.\\n        min_n : int\\n            The minimum sample size in a bin for the mean residual\\n            product to be included on the plot.\\n        '\n    from statsmodels.graphics import utils as gutils\n    resid = self.model.cluster_list(self.resid)\n    time = self.model.cluster_list(self.model.time)\n    (xre, xdt) = ([], [])\n    for (re, ti) in zip(resid, time):\n        ix = np.tril_indices(re.shape[0], 0)\n        re = re[ix[0]] * re[ix[1]] / self.scale ** 2\n        xre.append(re)\n        dists = np.sqrt(((ti[ix[0], :] - ti[ix[1], :]) ** 2).sum(1))\n        xdt.append(dists)\n    xre = np.concatenate(xre)\n    xdt = np.concatenate(xdt)\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    ii = np.flatnonzero(xdt == 0)\n    v0 = np.mean(xre[ii])\n    xre /= v0\n    if np.isscalar(xpoints):\n        xpoints = np.linspace(0, max(xdt), xpoints)\n    dg = np.digitize(xdt, xpoints)\n    dgu = np.unique(dg)\n    hist = np.asarray([np.sum(dg == k) for k in dgu])\n    ii = np.flatnonzero(hist >= min_n)\n    dgu = dgu[ii]\n    dgy = np.asarray([np.mean(xre[dg == k]) for k in dgu])\n    dgx = np.asarray([np.mean(xdt[dg == k]) for k in dgu])\n    ax.plot(dgx, dgy, '-', color='orange', lw=5)\n    ax.set_xlabel('Time difference')\n    ax.set_ylabel('Product of scaled residuals')\n    return fig",
            "def plot_isotropic_dependence(self, ax=None, xpoints=10, min_n=50):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Create a plot of the pairwise products of within-group\\n        residuals against the corresponding time differences.  This\\n        plot can be used to assess the possible form of an isotropic\\n        covariance structure.\\n\\n        Parameters\\n        ----------\\n        ax : AxesSubplot\\n            An axes on which to draw the graph.  If None, new\\n            figure and axes objects are created\\n        xpoints : scalar or array_like\\n            If scalar, the number of points equally spaced points on\\n            the time difference axis used to define bins for\\n            calculating local means.  If an array, the specific points\\n            that define the bins.\\n        min_n : int\\n            The minimum sample size in a bin for the mean residual\\n            product to be included on the plot.\\n        '\n    from statsmodels.graphics import utils as gutils\n    resid = self.model.cluster_list(self.resid)\n    time = self.model.cluster_list(self.model.time)\n    (xre, xdt) = ([], [])\n    for (re, ti) in zip(resid, time):\n        ix = np.tril_indices(re.shape[0], 0)\n        re = re[ix[0]] * re[ix[1]] / self.scale ** 2\n        xre.append(re)\n        dists = np.sqrt(((ti[ix[0], :] - ti[ix[1], :]) ** 2).sum(1))\n        xdt.append(dists)\n    xre = np.concatenate(xre)\n    xdt = np.concatenate(xdt)\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    ii = np.flatnonzero(xdt == 0)\n    v0 = np.mean(xre[ii])\n    xre /= v0\n    if np.isscalar(xpoints):\n        xpoints = np.linspace(0, max(xdt), xpoints)\n    dg = np.digitize(xdt, xpoints)\n    dgu = np.unique(dg)\n    hist = np.asarray([np.sum(dg == k) for k in dgu])\n    ii = np.flatnonzero(hist >= min_n)\n    dgu = dgu[ii]\n    dgy = np.asarray([np.mean(xre[dg == k]) for k in dgu])\n    dgx = np.asarray([np.mean(xdt[dg == k]) for k in dgu])\n    ax.plot(dgx, dgy, '-', color='orange', lw=5)\n    ax.set_xlabel('Time difference')\n    ax.set_ylabel('Product of scaled residuals')\n    return fig"
        ]
    },
    {
        "func_name": "sensitivity_params",
        "original": "def sensitivity_params(self, dep_params_first, dep_params_last, num_steps):\n    \"\"\"\n        Refits the GEE model using a sequence of values for the\n        dependence parameters.\n\n        Parameters\n        ----------\n        dep_params_first : array_like\n            The first dep_params in the sequence\n        dep_params_last : array_like\n            The last dep_params in the sequence\n        num_steps : int\n            The number of dep_params in the sequence\n\n        Returns\n        -------\n        results : array_like\n            The GEEResults objects resulting from the fits.\n        \"\"\"\n    model = self.model\n    import copy\n    cov_struct = copy.deepcopy(self.model.cov_struct)\n    update_dep = model.update_dep\n    model.update_dep = False\n    dep_params = []\n    results = []\n    for x in np.linspace(0, 1, num_steps):\n        dp = x * dep_params_last + (1 - x) * dep_params_first\n        dep_params.append(dp)\n        model.cov_struct = copy.deepcopy(cov_struct)\n        model.cov_struct.dep_params = dp\n        rslt = model.fit(start_params=self.params, ctol=self.ctol, params_niter=self.params_niter, first_dep_update=self.first_dep_update, cov_type=self.cov_type)\n        results.append(rslt)\n    model.update_dep = update_dep\n    return results",
        "mutated": [
            "def sensitivity_params(self, dep_params_first, dep_params_last, num_steps):\n    if False:\n        i = 10\n    '\\n        Refits the GEE model using a sequence of values for the\\n        dependence parameters.\\n\\n        Parameters\\n        ----------\\n        dep_params_first : array_like\\n            The first dep_params in the sequence\\n        dep_params_last : array_like\\n            The last dep_params in the sequence\\n        num_steps : int\\n            The number of dep_params in the sequence\\n\\n        Returns\\n        -------\\n        results : array_like\\n            The GEEResults objects resulting from the fits.\\n        '\n    model = self.model\n    import copy\n    cov_struct = copy.deepcopy(self.model.cov_struct)\n    update_dep = model.update_dep\n    model.update_dep = False\n    dep_params = []\n    results = []\n    for x in np.linspace(0, 1, num_steps):\n        dp = x * dep_params_last + (1 - x) * dep_params_first\n        dep_params.append(dp)\n        model.cov_struct = copy.deepcopy(cov_struct)\n        model.cov_struct.dep_params = dp\n        rslt = model.fit(start_params=self.params, ctol=self.ctol, params_niter=self.params_niter, first_dep_update=self.first_dep_update, cov_type=self.cov_type)\n        results.append(rslt)\n    model.update_dep = update_dep\n    return results",
            "def sensitivity_params(self, dep_params_first, dep_params_last, num_steps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Refits the GEE model using a sequence of values for the\\n        dependence parameters.\\n\\n        Parameters\\n        ----------\\n        dep_params_first : array_like\\n            The first dep_params in the sequence\\n        dep_params_last : array_like\\n            The last dep_params in the sequence\\n        num_steps : int\\n            The number of dep_params in the sequence\\n\\n        Returns\\n        -------\\n        results : array_like\\n            The GEEResults objects resulting from the fits.\\n        '\n    model = self.model\n    import copy\n    cov_struct = copy.deepcopy(self.model.cov_struct)\n    update_dep = model.update_dep\n    model.update_dep = False\n    dep_params = []\n    results = []\n    for x in np.linspace(0, 1, num_steps):\n        dp = x * dep_params_last + (1 - x) * dep_params_first\n        dep_params.append(dp)\n        model.cov_struct = copy.deepcopy(cov_struct)\n        model.cov_struct.dep_params = dp\n        rslt = model.fit(start_params=self.params, ctol=self.ctol, params_niter=self.params_niter, first_dep_update=self.first_dep_update, cov_type=self.cov_type)\n        results.append(rslt)\n    model.update_dep = update_dep\n    return results",
            "def sensitivity_params(self, dep_params_first, dep_params_last, num_steps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Refits the GEE model using a sequence of values for the\\n        dependence parameters.\\n\\n        Parameters\\n        ----------\\n        dep_params_first : array_like\\n            The first dep_params in the sequence\\n        dep_params_last : array_like\\n            The last dep_params in the sequence\\n        num_steps : int\\n            The number of dep_params in the sequence\\n\\n        Returns\\n        -------\\n        results : array_like\\n            The GEEResults objects resulting from the fits.\\n        '\n    model = self.model\n    import copy\n    cov_struct = copy.deepcopy(self.model.cov_struct)\n    update_dep = model.update_dep\n    model.update_dep = False\n    dep_params = []\n    results = []\n    for x in np.linspace(0, 1, num_steps):\n        dp = x * dep_params_last + (1 - x) * dep_params_first\n        dep_params.append(dp)\n        model.cov_struct = copy.deepcopy(cov_struct)\n        model.cov_struct.dep_params = dp\n        rslt = model.fit(start_params=self.params, ctol=self.ctol, params_niter=self.params_niter, first_dep_update=self.first_dep_update, cov_type=self.cov_type)\n        results.append(rslt)\n    model.update_dep = update_dep\n    return results",
            "def sensitivity_params(self, dep_params_first, dep_params_last, num_steps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Refits the GEE model using a sequence of values for the\\n        dependence parameters.\\n\\n        Parameters\\n        ----------\\n        dep_params_first : array_like\\n            The first dep_params in the sequence\\n        dep_params_last : array_like\\n            The last dep_params in the sequence\\n        num_steps : int\\n            The number of dep_params in the sequence\\n\\n        Returns\\n        -------\\n        results : array_like\\n            The GEEResults objects resulting from the fits.\\n        '\n    model = self.model\n    import copy\n    cov_struct = copy.deepcopy(self.model.cov_struct)\n    update_dep = model.update_dep\n    model.update_dep = False\n    dep_params = []\n    results = []\n    for x in np.linspace(0, 1, num_steps):\n        dp = x * dep_params_last + (1 - x) * dep_params_first\n        dep_params.append(dp)\n        model.cov_struct = copy.deepcopy(cov_struct)\n        model.cov_struct.dep_params = dp\n        rslt = model.fit(start_params=self.params, ctol=self.ctol, params_niter=self.params_niter, first_dep_update=self.first_dep_update, cov_type=self.cov_type)\n        results.append(rslt)\n    model.update_dep = update_dep\n    return results",
            "def sensitivity_params(self, dep_params_first, dep_params_last, num_steps):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Refits the GEE model using a sequence of values for the\\n        dependence parameters.\\n\\n        Parameters\\n        ----------\\n        dep_params_first : array_like\\n            The first dep_params in the sequence\\n        dep_params_last : array_like\\n            The last dep_params in the sequence\\n        num_steps : int\\n            The number of dep_params in the sequence\\n\\n        Returns\\n        -------\\n        results : array_like\\n            The GEEResults objects resulting from the fits.\\n        '\n    model = self.model\n    import copy\n    cov_struct = copy.deepcopy(self.model.cov_struct)\n    update_dep = model.update_dep\n    model.update_dep = False\n    dep_params = []\n    results = []\n    for x in np.linspace(0, 1, num_steps):\n        dp = x * dep_params_last + (1 - x) * dep_params_first\n        dep_params.append(dp)\n        model.cov_struct = copy.deepcopy(cov_struct)\n        model.cov_struct.dep_params = dp\n        rslt = model.fit(start_params=self.params, ctol=self.ctol, params_niter=self.params_niter, first_dep_update=self.first_dep_update, cov_type=self.cov_type)\n        results.append(rslt)\n    model.update_dep = update_dep\n    return results"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs):\n    if family is None:\n        family = families.Binomial()\n    elif not isinstance(family, families.Binomial):\n        raise ValueError('ordinal GEE must use a Binomial family')\n    if cov_struct is None:\n        cov_struct = cov_structs.OrdinalIndependence()\n    (endog, exog, groups, time, offset) = self.setup_ordinal(endog, exog, groups, time, offset)\n    super(OrdinalGEE, self).__init__(endog, exog, groups, time, family, cov_struct, missing, offset, dep_data, constraint)",
        "mutated": [
            "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs):\n    if False:\n        i = 10\n    if family is None:\n        family = families.Binomial()\n    elif not isinstance(family, families.Binomial):\n        raise ValueError('ordinal GEE must use a Binomial family')\n    if cov_struct is None:\n        cov_struct = cov_structs.OrdinalIndependence()\n    (endog, exog, groups, time, offset) = self.setup_ordinal(endog, exog, groups, time, offset)\n    super(OrdinalGEE, self).__init__(endog, exog, groups, time, family, cov_struct, missing, offset, dep_data, constraint)",
            "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if family is None:\n        family = families.Binomial()\n    elif not isinstance(family, families.Binomial):\n        raise ValueError('ordinal GEE must use a Binomial family')\n    if cov_struct is None:\n        cov_struct = cov_structs.OrdinalIndependence()\n    (endog, exog, groups, time, offset) = self.setup_ordinal(endog, exog, groups, time, offset)\n    super(OrdinalGEE, self).__init__(endog, exog, groups, time, family, cov_struct, missing, offset, dep_data, constraint)",
            "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if family is None:\n        family = families.Binomial()\n    elif not isinstance(family, families.Binomial):\n        raise ValueError('ordinal GEE must use a Binomial family')\n    if cov_struct is None:\n        cov_struct = cov_structs.OrdinalIndependence()\n    (endog, exog, groups, time, offset) = self.setup_ordinal(endog, exog, groups, time, offset)\n    super(OrdinalGEE, self).__init__(endog, exog, groups, time, family, cov_struct, missing, offset, dep_data, constraint)",
            "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if family is None:\n        family = families.Binomial()\n    elif not isinstance(family, families.Binomial):\n        raise ValueError('ordinal GEE must use a Binomial family')\n    if cov_struct is None:\n        cov_struct = cov_structs.OrdinalIndependence()\n    (endog, exog, groups, time, offset) = self.setup_ordinal(endog, exog, groups, time, offset)\n    super(OrdinalGEE, self).__init__(endog, exog, groups, time, family, cov_struct, missing, offset, dep_data, constraint)",
            "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if family is None:\n        family = families.Binomial()\n    elif not isinstance(family, families.Binomial):\n        raise ValueError('ordinal GEE must use a Binomial family')\n    if cov_struct is None:\n        cov_struct = cov_structs.OrdinalIndependence()\n    (endog, exog, groups, time, offset) = self.setup_ordinal(endog, exog, groups, time, offset)\n    super(OrdinalGEE, self).__init__(endog, exog, groups, time, family, cov_struct, missing, offset, dep_data, constraint)"
        ]
    },
    {
        "func_name": "setup_ordinal",
        "original": "def setup_ordinal(self, endog, exog, groups, time, offset):\n    \"\"\"\n        Restructure ordinal data as binary indicators so that they can\n        be analyzed using Generalized Estimating Equations.\n        \"\"\"\n    self.endog_orig = endog.copy()\n    self.exog_orig = exog.copy()\n    self.groups_orig = groups.copy()\n    if offset is not None:\n        self.offset_orig = offset.copy()\n    else:\n        self.offset_orig = None\n        offset = np.zeros(len(endog))\n    if time is not None:\n        self.time_orig = time.copy()\n    else:\n        self.time_orig = None\n        time = np.zeros((len(endog), 1))\n    exog = np.asarray(exog)\n    endog = np.asarray(endog)\n    groups = np.asarray(groups)\n    time = np.asarray(time)\n    offset = np.asarray(offset)\n    self.endog_values = np.unique(endog)\n    endog_cuts = self.endog_values[0:-1]\n    ncut = len(endog_cuts)\n    nrows = ncut * len(endog)\n    exog_out = np.zeros((nrows, exog.shape[1]), dtype=np.float64)\n    endog_out = np.zeros(nrows, dtype=np.float64)\n    intercepts = np.zeros((nrows, ncut), dtype=np.float64)\n    groups_out = np.zeros(nrows, dtype=groups.dtype)\n    time_out = np.zeros((nrows, time.shape[1]), dtype=np.float64)\n    offset_out = np.zeros(nrows, dtype=np.float64)\n    jrow = 0\n    zipper = zip(exog, endog, groups, time, offset)\n    for (exog_row, endog_value, group_value, time_value, offset_value) in zipper:\n        for (thresh_ix, thresh) in enumerate(endog_cuts):\n            exog_out[jrow, :] = exog_row\n            endog_out[jrow] = int(np.squeeze(endog_value > thresh))\n            intercepts[jrow, thresh_ix] = 1\n            groups_out[jrow] = group_value\n            time_out[jrow] = time_value\n            offset_out[jrow] = offset_value\n            jrow += 1\n    exog_out = np.concatenate((intercepts, exog_out), axis=1)\n    xnames = ['I(y>%.1f)' % v for v in endog_cuts]\n    if type(self.exog_orig) is pd.DataFrame:\n        xnames.extend(self.exog_orig.columns)\n    else:\n        xnames.extend(['x%d' % k for k in range(1, exog.shape[1] + 1)])\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    if type(self.endog_orig) is pd.Series:\n        endog_out = pd.Series(endog_out, name=self.endog_orig.name)\n    return (endog_out, exog_out, groups_out, time_out, offset_out)",
        "mutated": [
            "def setup_ordinal(self, endog, exog, groups, time, offset):\n    if False:\n        i = 10\n    '\\n        Restructure ordinal data as binary indicators so that they can\\n        be analyzed using Generalized Estimating Equations.\\n        '\n    self.endog_orig = endog.copy()\n    self.exog_orig = exog.copy()\n    self.groups_orig = groups.copy()\n    if offset is not None:\n        self.offset_orig = offset.copy()\n    else:\n        self.offset_orig = None\n        offset = np.zeros(len(endog))\n    if time is not None:\n        self.time_orig = time.copy()\n    else:\n        self.time_orig = None\n        time = np.zeros((len(endog), 1))\n    exog = np.asarray(exog)\n    endog = np.asarray(endog)\n    groups = np.asarray(groups)\n    time = np.asarray(time)\n    offset = np.asarray(offset)\n    self.endog_values = np.unique(endog)\n    endog_cuts = self.endog_values[0:-1]\n    ncut = len(endog_cuts)\n    nrows = ncut * len(endog)\n    exog_out = np.zeros((nrows, exog.shape[1]), dtype=np.float64)\n    endog_out = np.zeros(nrows, dtype=np.float64)\n    intercepts = np.zeros((nrows, ncut), dtype=np.float64)\n    groups_out = np.zeros(nrows, dtype=groups.dtype)\n    time_out = np.zeros((nrows, time.shape[1]), dtype=np.float64)\n    offset_out = np.zeros(nrows, dtype=np.float64)\n    jrow = 0\n    zipper = zip(exog, endog, groups, time, offset)\n    for (exog_row, endog_value, group_value, time_value, offset_value) in zipper:\n        for (thresh_ix, thresh) in enumerate(endog_cuts):\n            exog_out[jrow, :] = exog_row\n            endog_out[jrow] = int(np.squeeze(endog_value > thresh))\n            intercepts[jrow, thresh_ix] = 1\n            groups_out[jrow] = group_value\n            time_out[jrow] = time_value\n            offset_out[jrow] = offset_value\n            jrow += 1\n    exog_out = np.concatenate((intercepts, exog_out), axis=1)\n    xnames = ['I(y>%.1f)' % v for v in endog_cuts]\n    if type(self.exog_orig) is pd.DataFrame:\n        xnames.extend(self.exog_orig.columns)\n    else:\n        xnames.extend(['x%d' % k for k in range(1, exog.shape[1] + 1)])\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    if type(self.endog_orig) is pd.Series:\n        endog_out = pd.Series(endog_out, name=self.endog_orig.name)\n    return (endog_out, exog_out, groups_out, time_out, offset_out)",
            "def setup_ordinal(self, endog, exog, groups, time, offset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Restructure ordinal data as binary indicators so that they can\\n        be analyzed using Generalized Estimating Equations.\\n        '\n    self.endog_orig = endog.copy()\n    self.exog_orig = exog.copy()\n    self.groups_orig = groups.copy()\n    if offset is not None:\n        self.offset_orig = offset.copy()\n    else:\n        self.offset_orig = None\n        offset = np.zeros(len(endog))\n    if time is not None:\n        self.time_orig = time.copy()\n    else:\n        self.time_orig = None\n        time = np.zeros((len(endog), 1))\n    exog = np.asarray(exog)\n    endog = np.asarray(endog)\n    groups = np.asarray(groups)\n    time = np.asarray(time)\n    offset = np.asarray(offset)\n    self.endog_values = np.unique(endog)\n    endog_cuts = self.endog_values[0:-1]\n    ncut = len(endog_cuts)\n    nrows = ncut * len(endog)\n    exog_out = np.zeros((nrows, exog.shape[1]), dtype=np.float64)\n    endog_out = np.zeros(nrows, dtype=np.float64)\n    intercepts = np.zeros((nrows, ncut), dtype=np.float64)\n    groups_out = np.zeros(nrows, dtype=groups.dtype)\n    time_out = np.zeros((nrows, time.shape[1]), dtype=np.float64)\n    offset_out = np.zeros(nrows, dtype=np.float64)\n    jrow = 0\n    zipper = zip(exog, endog, groups, time, offset)\n    for (exog_row, endog_value, group_value, time_value, offset_value) in zipper:\n        for (thresh_ix, thresh) in enumerate(endog_cuts):\n            exog_out[jrow, :] = exog_row\n            endog_out[jrow] = int(np.squeeze(endog_value > thresh))\n            intercepts[jrow, thresh_ix] = 1\n            groups_out[jrow] = group_value\n            time_out[jrow] = time_value\n            offset_out[jrow] = offset_value\n            jrow += 1\n    exog_out = np.concatenate((intercepts, exog_out), axis=1)\n    xnames = ['I(y>%.1f)' % v for v in endog_cuts]\n    if type(self.exog_orig) is pd.DataFrame:\n        xnames.extend(self.exog_orig.columns)\n    else:\n        xnames.extend(['x%d' % k for k in range(1, exog.shape[1] + 1)])\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    if type(self.endog_orig) is pd.Series:\n        endog_out = pd.Series(endog_out, name=self.endog_orig.name)\n    return (endog_out, exog_out, groups_out, time_out, offset_out)",
            "def setup_ordinal(self, endog, exog, groups, time, offset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Restructure ordinal data as binary indicators so that they can\\n        be analyzed using Generalized Estimating Equations.\\n        '\n    self.endog_orig = endog.copy()\n    self.exog_orig = exog.copy()\n    self.groups_orig = groups.copy()\n    if offset is not None:\n        self.offset_orig = offset.copy()\n    else:\n        self.offset_orig = None\n        offset = np.zeros(len(endog))\n    if time is not None:\n        self.time_orig = time.copy()\n    else:\n        self.time_orig = None\n        time = np.zeros((len(endog), 1))\n    exog = np.asarray(exog)\n    endog = np.asarray(endog)\n    groups = np.asarray(groups)\n    time = np.asarray(time)\n    offset = np.asarray(offset)\n    self.endog_values = np.unique(endog)\n    endog_cuts = self.endog_values[0:-1]\n    ncut = len(endog_cuts)\n    nrows = ncut * len(endog)\n    exog_out = np.zeros((nrows, exog.shape[1]), dtype=np.float64)\n    endog_out = np.zeros(nrows, dtype=np.float64)\n    intercepts = np.zeros((nrows, ncut), dtype=np.float64)\n    groups_out = np.zeros(nrows, dtype=groups.dtype)\n    time_out = np.zeros((nrows, time.shape[1]), dtype=np.float64)\n    offset_out = np.zeros(nrows, dtype=np.float64)\n    jrow = 0\n    zipper = zip(exog, endog, groups, time, offset)\n    for (exog_row, endog_value, group_value, time_value, offset_value) in zipper:\n        for (thresh_ix, thresh) in enumerate(endog_cuts):\n            exog_out[jrow, :] = exog_row\n            endog_out[jrow] = int(np.squeeze(endog_value > thresh))\n            intercepts[jrow, thresh_ix] = 1\n            groups_out[jrow] = group_value\n            time_out[jrow] = time_value\n            offset_out[jrow] = offset_value\n            jrow += 1\n    exog_out = np.concatenate((intercepts, exog_out), axis=1)\n    xnames = ['I(y>%.1f)' % v for v in endog_cuts]\n    if type(self.exog_orig) is pd.DataFrame:\n        xnames.extend(self.exog_orig.columns)\n    else:\n        xnames.extend(['x%d' % k for k in range(1, exog.shape[1] + 1)])\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    if type(self.endog_orig) is pd.Series:\n        endog_out = pd.Series(endog_out, name=self.endog_orig.name)\n    return (endog_out, exog_out, groups_out, time_out, offset_out)",
            "def setup_ordinal(self, endog, exog, groups, time, offset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Restructure ordinal data as binary indicators so that they can\\n        be analyzed using Generalized Estimating Equations.\\n        '\n    self.endog_orig = endog.copy()\n    self.exog_orig = exog.copy()\n    self.groups_orig = groups.copy()\n    if offset is not None:\n        self.offset_orig = offset.copy()\n    else:\n        self.offset_orig = None\n        offset = np.zeros(len(endog))\n    if time is not None:\n        self.time_orig = time.copy()\n    else:\n        self.time_orig = None\n        time = np.zeros((len(endog), 1))\n    exog = np.asarray(exog)\n    endog = np.asarray(endog)\n    groups = np.asarray(groups)\n    time = np.asarray(time)\n    offset = np.asarray(offset)\n    self.endog_values = np.unique(endog)\n    endog_cuts = self.endog_values[0:-1]\n    ncut = len(endog_cuts)\n    nrows = ncut * len(endog)\n    exog_out = np.zeros((nrows, exog.shape[1]), dtype=np.float64)\n    endog_out = np.zeros(nrows, dtype=np.float64)\n    intercepts = np.zeros((nrows, ncut), dtype=np.float64)\n    groups_out = np.zeros(nrows, dtype=groups.dtype)\n    time_out = np.zeros((nrows, time.shape[1]), dtype=np.float64)\n    offset_out = np.zeros(nrows, dtype=np.float64)\n    jrow = 0\n    zipper = zip(exog, endog, groups, time, offset)\n    for (exog_row, endog_value, group_value, time_value, offset_value) in zipper:\n        for (thresh_ix, thresh) in enumerate(endog_cuts):\n            exog_out[jrow, :] = exog_row\n            endog_out[jrow] = int(np.squeeze(endog_value > thresh))\n            intercepts[jrow, thresh_ix] = 1\n            groups_out[jrow] = group_value\n            time_out[jrow] = time_value\n            offset_out[jrow] = offset_value\n            jrow += 1\n    exog_out = np.concatenate((intercepts, exog_out), axis=1)\n    xnames = ['I(y>%.1f)' % v for v in endog_cuts]\n    if type(self.exog_orig) is pd.DataFrame:\n        xnames.extend(self.exog_orig.columns)\n    else:\n        xnames.extend(['x%d' % k for k in range(1, exog.shape[1] + 1)])\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    if type(self.endog_orig) is pd.Series:\n        endog_out = pd.Series(endog_out, name=self.endog_orig.name)\n    return (endog_out, exog_out, groups_out, time_out, offset_out)",
            "def setup_ordinal(self, endog, exog, groups, time, offset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Restructure ordinal data as binary indicators so that they can\\n        be analyzed using Generalized Estimating Equations.\\n        '\n    self.endog_orig = endog.copy()\n    self.exog_orig = exog.copy()\n    self.groups_orig = groups.copy()\n    if offset is not None:\n        self.offset_orig = offset.copy()\n    else:\n        self.offset_orig = None\n        offset = np.zeros(len(endog))\n    if time is not None:\n        self.time_orig = time.copy()\n    else:\n        self.time_orig = None\n        time = np.zeros((len(endog), 1))\n    exog = np.asarray(exog)\n    endog = np.asarray(endog)\n    groups = np.asarray(groups)\n    time = np.asarray(time)\n    offset = np.asarray(offset)\n    self.endog_values = np.unique(endog)\n    endog_cuts = self.endog_values[0:-1]\n    ncut = len(endog_cuts)\n    nrows = ncut * len(endog)\n    exog_out = np.zeros((nrows, exog.shape[1]), dtype=np.float64)\n    endog_out = np.zeros(nrows, dtype=np.float64)\n    intercepts = np.zeros((nrows, ncut), dtype=np.float64)\n    groups_out = np.zeros(nrows, dtype=groups.dtype)\n    time_out = np.zeros((nrows, time.shape[1]), dtype=np.float64)\n    offset_out = np.zeros(nrows, dtype=np.float64)\n    jrow = 0\n    zipper = zip(exog, endog, groups, time, offset)\n    for (exog_row, endog_value, group_value, time_value, offset_value) in zipper:\n        for (thresh_ix, thresh) in enumerate(endog_cuts):\n            exog_out[jrow, :] = exog_row\n            endog_out[jrow] = int(np.squeeze(endog_value > thresh))\n            intercepts[jrow, thresh_ix] = 1\n            groups_out[jrow] = group_value\n            time_out[jrow] = time_value\n            offset_out[jrow] = offset_value\n            jrow += 1\n    exog_out = np.concatenate((intercepts, exog_out), axis=1)\n    xnames = ['I(y>%.1f)' % v for v in endog_cuts]\n    if type(self.exog_orig) is pd.DataFrame:\n        xnames.extend(self.exog_orig.columns)\n    else:\n        xnames.extend(['x%d' % k for k in range(1, exog.shape[1] + 1)])\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    if type(self.endog_orig) is pd.Series:\n        endog_out = pd.Series(endog_out, name=self.endog_orig.name)\n    return (endog_out, exog_out, groups_out, time_out, offset_out)"
        ]
    },
    {
        "func_name": "_starting_params",
        "original": "def _starting_params(self):\n    exposure = getattr(self, 'exposure', None)\n    model = GEE(self.endog, self.exog, self.groups, time=self.time, family=families.Binomial(), offset=self.offset, exposure=exposure)\n    result = model.fit()\n    return result.params",
        "mutated": [
            "def _starting_params(self):\n    if False:\n        i = 10\n    exposure = getattr(self, 'exposure', None)\n    model = GEE(self.endog, self.exog, self.groups, time=self.time, family=families.Binomial(), offset=self.offset, exposure=exposure)\n    result = model.fit()\n    return result.params",
            "def _starting_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    exposure = getattr(self, 'exposure', None)\n    model = GEE(self.endog, self.exog, self.groups, time=self.time, family=families.Binomial(), offset=self.offset, exposure=exposure)\n    result = model.fit()\n    return result.params",
            "def _starting_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    exposure = getattr(self, 'exposure', None)\n    model = GEE(self.endog, self.exog, self.groups, time=self.time, family=families.Binomial(), offset=self.offset, exposure=exposure)\n    result = model.fit()\n    return result.params",
            "def _starting_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    exposure = getattr(self, 'exposure', None)\n    model = GEE(self.endog, self.exog, self.groups, time=self.time, family=families.Binomial(), offset=self.offset, exposure=exposure)\n    result = model.fit()\n    return result.params",
            "def _starting_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    exposure = getattr(self, 'exposure', None)\n    model = GEE(self.endog, self.exog, self.groups, time=self.time, family=families.Binomial(), offset=self.offset, exposure=exposure)\n    result = model.fit()\n    return result.params"
        ]
    },
    {
        "func_name": "fit",
        "original": "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust'):\n    rslt = super(OrdinalGEE, self).fit(maxiter, ctol, start_params, params_niter, first_dep_update, cov_type=cov_type)\n    rslt = rslt._results\n    res_kwds = dict(((k, getattr(rslt, k)) for k in rslt._props))\n    ord_rslt = OrdinalGEEResults(self, rslt.params, rslt.cov_params() / rslt.scale, rslt.scale, cov_type=cov_type, attr_kwds=res_kwds)\n    return OrdinalGEEResultsWrapper(ord_rslt)",
        "mutated": [
            "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust'):\n    if False:\n        i = 10\n    rslt = super(OrdinalGEE, self).fit(maxiter, ctol, start_params, params_niter, first_dep_update, cov_type=cov_type)\n    rslt = rslt._results\n    res_kwds = dict(((k, getattr(rslt, k)) for k in rslt._props))\n    ord_rslt = OrdinalGEEResults(self, rslt.params, rslt.cov_params() / rslt.scale, rslt.scale, cov_type=cov_type, attr_kwds=res_kwds)\n    return OrdinalGEEResultsWrapper(ord_rslt)",
            "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    rslt = super(OrdinalGEE, self).fit(maxiter, ctol, start_params, params_niter, first_dep_update, cov_type=cov_type)\n    rslt = rslt._results\n    res_kwds = dict(((k, getattr(rslt, k)) for k in rslt._props))\n    ord_rslt = OrdinalGEEResults(self, rslt.params, rslt.cov_params() / rslt.scale, rslt.scale, cov_type=cov_type, attr_kwds=res_kwds)\n    return OrdinalGEEResultsWrapper(ord_rslt)",
            "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    rslt = super(OrdinalGEE, self).fit(maxiter, ctol, start_params, params_niter, first_dep_update, cov_type=cov_type)\n    rslt = rslt._results\n    res_kwds = dict(((k, getattr(rslt, k)) for k in rslt._props))\n    ord_rslt = OrdinalGEEResults(self, rslt.params, rslt.cov_params() / rslt.scale, rslt.scale, cov_type=cov_type, attr_kwds=res_kwds)\n    return OrdinalGEEResultsWrapper(ord_rslt)",
            "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    rslt = super(OrdinalGEE, self).fit(maxiter, ctol, start_params, params_niter, first_dep_update, cov_type=cov_type)\n    rslt = rslt._results\n    res_kwds = dict(((k, getattr(rslt, k)) for k in rslt._props))\n    ord_rslt = OrdinalGEEResults(self, rslt.params, rslt.cov_params() / rslt.scale, rslt.scale, cov_type=cov_type, attr_kwds=res_kwds)\n    return OrdinalGEEResultsWrapper(ord_rslt)",
            "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    rslt = super(OrdinalGEE, self).fit(maxiter, ctol, start_params, params_niter, first_dep_update, cov_type=cov_type)\n    rslt = rslt._results\n    res_kwds = dict(((k, getattr(rslt, k)) for k in rslt._props))\n    ord_rslt = OrdinalGEEResults(self, rslt.params, rslt.cov_params() / rslt.scale, rslt.scale, cov_type=cov_type, attr_kwds=res_kwds)\n    return OrdinalGEEResultsWrapper(ord_rslt)"
        ]
    },
    {
        "func_name": "plot_distribution",
        "original": "def plot_distribution(self, ax=None, exog_values=None):\n    \"\"\"\n        Plot the fitted probabilities of endog in an ordinal model,\n        for specified values of the predictors.\n\n        Parameters\n        ----------\n        ax : AxesSubplot\n            An axes on which to draw the graph.  If None, new\n            figure and axes objects are created\n        exog_values : array_like\n            A list of dictionaries, with each dictionary mapping\n            variable names to values at which the variable is held\n            fixed.  The values P(endog=y | exog) are plotted for all\n            possible values of y, at the given exog value.  Variables\n            not included in a dictionary are held fixed at the mean\n            value.\n\n        Example:\n        --------\n        We have a model with covariates 'age' and 'sex', and wish to\n        plot the probabilities P(endog=y | exog) for males (sex=0) and\n        for females (sex=1), as separate paths on the plot.  Since\n        'age' is not included below in the map, it is held fixed at\n        its mean value.\n\n        >>> ev = [{\"sex\": 1}, {\"sex\": 0}]\n        >>> rslt.distribution_plot(exog_values=ev)\n        \"\"\"\n    from statsmodels.graphics import utils as gutils\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    if exog_values is None:\n        exog_values = [{}]\n    exog_means = self.model.exog.mean(0)\n    ix_icept = [i for (i, x) in enumerate(self.model.exog_names) if x.startswith('I(')]\n    for ev in exog_values:\n        for k in ev.keys():\n            if k not in self.model.exog_names:\n                raise ValueError('%s is not a variable in the model' % k)\n        pr = []\n        for j in ix_icept:\n            xp = np.zeros_like(self.params)\n            xp[j] = 1.0\n            for (i, vn) in enumerate(self.model.exog_names):\n                if i in ix_icept:\n                    continue\n                if vn in ev:\n                    xp[i] = ev[vn]\n                else:\n                    xp[i] = exog_means[i]\n            p = 1 / (1 + np.exp(-np.dot(xp, self.params)))\n            pr.append(p)\n        pr.insert(0, 1)\n        pr.append(0)\n        pr = np.asarray(pr)\n        prd = -np.diff(pr)\n        ax.plot(self.model.endog_values, prd, 'o-')\n    ax.set_xlabel('Response value')\n    ax.set_ylabel('Probability')\n    ax.set_ylim(0, 1)\n    return fig",
        "mutated": [
            "def plot_distribution(self, ax=None, exog_values=None):\n    if False:\n        i = 10\n    '\\n        Plot the fitted probabilities of endog in an ordinal model,\\n        for specified values of the predictors.\\n\\n        Parameters\\n        ----------\\n        ax : AxesSubplot\\n            An axes on which to draw the graph.  If None, new\\n            figure and axes objects are created\\n        exog_values : array_like\\n            A list of dictionaries, with each dictionary mapping\\n            variable names to values at which the variable is held\\n            fixed.  The values P(endog=y | exog) are plotted for all\\n            possible values of y, at the given exog value.  Variables\\n            not included in a dictionary are held fixed at the mean\\n            value.\\n\\n        Example:\\n        --------\\n        We have a model with covariates \\'age\\' and \\'sex\\', and wish to\\n        plot the probabilities P(endog=y | exog) for males (sex=0) and\\n        for females (sex=1), as separate paths on the plot.  Since\\n        \\'age\\' is not included below in the map, it is held fixed at\\n        its mean value.\\n\\n        >>> ev = [{\"sex\": 1}, {\"sex\": 0}]\\n        >>> rslt.distribution_plot(exog_values=ev)\\n        '\n    from statsmodels.graphics import utils as gutils\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    if exog_values is None:\n        exog_values = [{}]\n    exog_means = self.model.exog.mean(0)\n    ix_icept = [i for (i, x) in enumerate(self.model.exog_names) if x.startswith('I(')]\n    for ev in exog_values:\n        for k in ev.keys():\n            if k not in self.model.exog_names:\n                raise ValueError('%s is not a variable in the model' % k)\n        pr = []\n        for j in ix_icept:\n            xp = np.zeros_like(self.params)\n            xp[j] = 1.0\n            for (i, vn) in enumerate(self.model.exog_names):\n                if i in ix_icept:\n                    continue\n                if vn in ev:\n                    xp[i] = ev[vn]\n                else:\n                    xp[i] = exog_means[i]\n            p = 1 / (1 + np.exp(-np.dot(xp, self.params)))\n            pr.append(p)\n        pr.insert(0, 1)\n        pr.append(0)\n        pr = np.asarray(pr)\n        prd = -np.diff(pr)\n        ax.plot(self.model.endog_values, prd, 'o-')\n    ax.set_xlabel('Response value')\n    ax.set_ylabel('Probability')\n    ax.set_ylim(0, 1)\n    return fig",
            "def plot_distribution(self, ax=None, exog_values=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Plot the fitted probabilities of endog in an ordinal model,\\n        for specified values of the predictors.\\n\\n        Parameters\\n        ----------\\n        ax : AxesSubplot\\n            An axes on which to draw the graph.  If None, new\\n            figure and axes objects are created\\n        exog_values : array_like\\n            A list of dictionaries, with each dictionary mapping\\n            variable names to values at which the variable is held\\n            fixed.  The values P(endog=y | exog) are plotted for all\\n            possible values of y, at the given exog value.  Variables\\n            not included in a dictionary are held fixed at the mean\\n            value.\\n\\n        Example:\\n        --------\\n        We have a model with covariates \\'age\\' and \\'sex\\', and wish to\\n        plot the probabilities P(endog=y | exog) for males (sex=0) and\\n        for females (sex=1), as separate paths on the plot.  Since\\n        \\'age\\' is not included below in the map, it is held fixed at\\n        its mean value.\\n\\n        >>> ev = [{\"sex\": 1}, {\"sex\": 0}]\\n        >>> rslt.distribution_plot(exog_values=ev)\\n        '\n    from statsmodels.graphics import utils as gutils\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    if exog_values is None:\n        exog_values = [{}]\n    exog_means = self.model.exog.mean(0)\n    ix_icept = [i for (i, x) in enumerate(self.model.exog_names) if x.startswith('I(')]\n    for ev in exog_values:\n        for k in ev.keys():\n            if k not in self.model.exog_names:\n                raise ValueError('%s is not a variable in the model' % k)\n        pr = []\n        for j in ix_icept:\n            xp = np.zeros_like(self.params)\n            xp[j] = 1.0\n            for (i, vn) in enumerate(self.model.exog_names):\n                if i in ix_icept:\n                    continue\n                if vn in ev:\n                    xp[i] = ev[vn]\n                else:\n                    xp[i] = exog_means[i]\n            p = 1 / (1 + np.exp(-np.dot(xp, self.params)))\n            pr.append(p)\n        pr.insert(0, 1)\n        pr.append(0)\n        pr = np.asarray(pr)\n        prd = -np.diff(pr)\n        ax.plot(self.model.endog_values, prd, 'o-')\n    ax.set_xlabel('Response value')\n    ax.set_ylabel('Probability')\n    ax.set_ylim(0, 1)\n    return fig",
            "def plot_distribution(self, ax=None, exog_values=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Plot the fitted probabilities of endog in an ordinal model,\\n        for specified values of the predictors.\\n\\n        Parameters\\n        ----------\\n        ax : AxesSubplot\\n            An axes on which to draw the graph.  If None, new\\n            figure and axes objects are created\\n        exog_values : array_like\\n            A list of dictionaries, with each dictionary mapping\\n            variable names to values at which the variable is held\\n            fixed.  The values P(endog=y | exog) are plotted for all\\n            possible values of y, at the given exog value.  Variables\\n            not included in a dictionary are held fixed at the mean\\n            value.\\n\\n        Example:\\n        --------\\n        We have a model with covariates \\'age\\' and \\'sex\\', and wish to\\n        plot the probabilities P(endog=y | exog) for males (sex=0) and\\n        for females (sex=1), as separate paths on the plot.  Since\\n        \\'age\\' is not included below in the map, it is held fixed at\\n        its mean value.\\n\\n        >>> ev = [{\"sex\": 1}, {\"sex\": 0}]\\n        >>> rslt.distribution_plot(exog_values=ev)\\n        '\n    from statsmodels.graphics import utils as gutils\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    if exog_values is None:\n        exog_values = [{}]\n    exog_means = self.model.exog.mean(0)\n    ix_icept = [i for (i, x) in enumerate(self.model.exog_names) if x.startswith('I(')]\n    for ev in exog_values:\n        for k in ev.keys():\n            if k not in self.model.exog_names:\n                raise ValueError('%s is not a variable in the model' % k)\n        pr = []\n        for j in ix_icept:\n            xp = np.zeros_like(self.params)\n            xp[j] = 1.0\n            for (i, vn) in enumerate(self.model.exog_names):\n                if i in ix_icept:\n                    continue\n                if vn in ev:\n                    xp[i] = ev[vn]\n                else:\n                    xp[i] = exog_means[i]\n            p = 1 / (1 + np.exp(-np.dot(xp, self.params)))\n            pr.append(p)\n        pr.insert(0, 1)\n        pr.append(0)\n        pr = np.asarray(pr)\n        prd = -np.diff(pr)\n        ax.plot(self.model.endog_values, prd, 'o-')\n    ax.set_xlabel('Response value')\n    ax.set_ylabel('Probability')\n    ax.set_ylim(0, 1)\n    return fig",
            "def plot_distribution(self, ax=None, exog_values=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Plot the fitted probabilities of endog in an ordinal model,\\n        for specified values of the predictors.\\n\\n        Parameters\\n        ----------\\n        ax : AxesSubplot\\n            An axes on which to draw the graph.  If None, new\\n            figure and axes objects are created\\n        exog_values : array_like\\n            A list of dictionaries, with each dictionary mapping\\n            variable names to values at which the variable is held\\n            fixed.  The values P(endog=y | exog) are plotted for all\\n            possible values of y, at the given exog value.  Variables\\n            not included in a dictionary are held fixed at the mean\\n            value.\\n\\n        Example:\\n        --------\\n        We have a model with covariates \\'age\\' and \\'sex\\', and wish to\\n        plot the probabilities P(endog=y | exog) for males (sex=0) and\\n        for females (sex=1), as separate paths on the plot.  Since\\n        \\'age\\' is not included below in the map, it is held fixed at\\n        its mean value.\\n\\n        >>> ev = [{\"sex\": 1}, {\"sex\": 0}]\\n        >>> rslt.distribution_plot(exog_values=ev)\\n        '\n    from statsmodels.graphics import utils as gutils\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    if exog_values is None:\n        exog_values = [{}]\n    exog_means = self.model.exog.mean(0)\n    ix_icept = [i for (i, x) in enumerate(self.model.exog_names) if x.startswith('I(')]\n    for ev in exog_values:\n        for k in ev.keys():\n            if k not in self.model.exog_names:\n                raise ValueError('%s is not a variable in the model' % k)\n        pr = []\n        for j in ix_icept:\n            xp = np.zeros_like(self.params)\n            xp[j] = 1.0\n            for (i, vn) in enumerate(self.model.exog_names):\n                if i in ix_icept:\n                    continue\n                if vn in ev:\n                    xp[i] = ev[vn]\n                else:\n                    xp[i] = exog_means[i]\n            p = 1 / (1 + np.exp(-np.dot(xp, self.params)))\n            pr.append(p)\n        pr.insert(0, 1)\n        pr.append(0)\n        pr = np.asarray(pr)\n        prd = -np.diff(pr)\n        ax.plot(self.model.endog_values, prd, 'o-')\n    ax.set_xlabel('Response value')\n    ax.set_ylabel('Probability')\n    ax.set_ylim(0, 1)\n    return fig",
            "def plot_distribution(self, ax=None, exog_values=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Plot the fitted probabilities of endog in an ordinal model,\\n        for specified values of the predictors.\\n\\n        Parameters\\n        ----------\\n        ax : AxesSubplot\\n            An axes on which to draw the graph.  If None, new\\n            figure and axes objects are created\\n        exog_values : array_like\\n            A list of dictionaries, with each dictionary mapping\\n            variable names to values at which the variable is held\\n            fixed.  The values P(endog=y | exog) are plotted for all\\n            possible values of y, at the given exog value.  Variables\\n            not included in a dictionary are held fixed at the mean\\n            value.\\n\\n        Example:\\n        --------\\n        We have a model with covariates \\'age\\' and \\'sex\\', and wish to\\n        plot the probabilities P(endog=y | exog) for males (sex=0) and\\n        for females (sex=1), as separate paths on the plot.  Since\\n        \\'age\\' is not included below in the map, it is held fixed at\\n        its mean value.\\n\\n        >>> ev = [{\"sex\": 1}, {\"sex\": 0}]\\n        >>> rslt.distribution_plot(exog_values=ev)\\n        '\n    from statsmodels.graphics import utils as gutils\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    if exog_values is None:\n        exog_values = [{}]\n    exog_means = self.model.exog.mean(0)\n    ix_icept = [i for (i, x) in enumerate(self.model.exog_names) if x.startswith('I(')]\n    for ev in exog_values:\n        for k in ev.keys():\n            if k not in self.model.exog_names:\n                raise ValueError('%s is not a variable in the model' % k)\n        pr = []\n        for j in ix_icept:\n            xp = np.zeros_like(self.params)\n            xp[j] = 1.0\n            for (i, vn) in enumerate(self.model.exog_names):\n                if i in ix_icept:\n                    continue\n                if vn in ev:\n                    xp[i] = ev[vn]\n                else:\n                    xp[i] = exog_means[i]\n            p = 1 / (1 + np.exp(-np.dot(xp, self.params)))\n            pr.append(p)\n        pr.insert(0, 1)\n        pr.append(0)\n        pr = np.asarray(pr)\n        prd = -np.diff(pr)\n        ax.plot(self.model.endog_values, prd, 'o-')\n    ax.set_xlabel('Response value')\n    ax.set_ylabel('Probability')\n    ax.set_ylim(0, 1)\n    return fig"
        ]
    },
    {
        "func_name": "_score_test_submodel",
        "original": "def _score_test_submodel(par, sub):\n    \"\"\"\n    Return transformation matrices for design matrices.\n\n    Parameters\n    ----------\n    par : instance\n        The parent model\n    sub : instance\n        The sub-model\n\n    Returns\n    -------\n    qm : array_like\n        Matrix mapping the design matrix of the parent to the design matrix\n        for the sub-model.\n    qc : array_like\n        Matrix mapping the design matrix of the parent to the orthogonal\n        complement of the columnspace of the submodel in the columnspace\n        of the parent.\n\n    Notes\n    -----\n    Returns None, None if the provided submodel is not actually a submodel.\n    \"\"\"\n    x1 = par.exog\n    x2 = sub.exog\n    (u, s, vt) = np.linalg.svd(x1, 0)\n    v = vt.T\n    (a, _) = np.linalg.qr(x2)\n    a = u - np.dot(a, np.dot(a.T, u))\n    (x2c, sb, _) = np.linalg.svd(a, 0)\n    x2c = x2c[:, sb > 1e-12]\n    ii = np.flatnonzero(np.abs(s) > 1e-12)\n    qm = np.dot(v[:, ii], np.dot(u[:, ii].T, x2) / s[ii, None])\n    e = np.max(np.abs(x2 - np.dot(x1, qm)))\n    if e > 1e-08:\n        return (None, None)\n    qc = np.dot(v[:, ii], np.dot(u[:, ii].T, x2c) / s[ii, None])\n    return (qm, qc)",
        "mutated": [
            "def _score_test_submodel(par, sub):\n    if False:\n        i = 10\n    '\\n    Return transformation matrices for design matrices.\\n\\n    Parameters\\n    ----------\\n    par : instance\\n        The parent model\\n    sub : instance\\n        The sub-model\\n\\n    Returns\\n    -------\\n    qm : array_like\\n        Matrix mapping the design matrix of the parent to the design matrix\\n        for the sub-model.\\n    qc : array_like\\n        Matrix mapping the design matrix of the parent to the orthogonal\\n        complement of the columnspace of the submodel in the columnspace\\n        of the parent.\\n\\n    Notes\\n    -----\\n    Returns None, None if the provided submodel is not actually a submodel.\\n    '\n    x1 = par.exog\n    x2 = sub.exog\n    (u, s, vt) = np.linalg.svd(x1, 0)\n    v = vt.T\n    (a, _) = np.linalg.qr(x2)\n    a = u - np.dot(a, np.dot(a.T, u))\n    (x2c, sb, _) = np.linalg.svd(a, 0)\n    x2c = x2c[:, sb > 1e-12]\n    ii = np.flatnonzero(np.abs(s) > 1e-12)\n    qm = np.dot(v[:, ii], np.dot(u[:, ii].T, x2) / s[ii, None])\n    e = np.max(np.abs(x2 - np.dot(x1, qm)))\n    if e > 1e-08:\n        return (None, None)\n    qc = np.dot(v[:, ii], np.dot(u[:, ii].T, x2c) / s[ii, None])\n    return (qm, qc)",
            "def _score_test_submodel(par, sub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Return transformation matrices for design matrices.\\n\\n    Parameters\\n    ----------\\n    par : instance\\n        The parent model\\n    sub : instance\\n        The sub-model\\n\\n    Returns\\n    -------\\n    qm : array_like\\n        Matrix mapping the design matrix of the parent to the design matrix\\n        for the sub-model.\\n    qc : array_like\\n        Matrix mapping the design matrix of the parent to the orthogonal\\n        complement of the columnspace of the submodel in the columnspace\\n        of the parent.\\n\\n    Notes\\n    -----\\n    Returns None, None if the provided submodel is not actually a submodel.\\n    '\n    x1 = par.exog\n    x2 = sub.exog\n    (u, s, vt) = np.linalg.svd(x1, 0)\n    v = vt.T\n    (a, _) = np.linalg.qr(x2)\n    a = u - np.dot(a, np.dot(a.T, u))\n    (x2c, sb, _) = np.linalg.svd(a, 0)\n    x2c = x2c[:, sb > 1e-12]\n    ii = np.flatnonzero(np.abs(s) > 1e-12)\n    qm = np.dot(v[:, ii], np.dot(u[:, ii].T, x2) / s[ii, None])\n    e = np.max(np.abs(x2 - np.dot(x1, qm)))\n    if e > 1e-08:\n        return (None, None)\n    qc = np.dot(v[:, ii], np.dot(u[:, ii].T, x2c) / s[ii, None])\n    return (qm, qc)",
            "def _score_test_submodel(par, sub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Return transformation matrices for design matrices.\\n\\n    Parameters\\n    ----------\\n    par : instance\\n        The parent model\\n    sub : instance\\n        The sub-model\\n\\n    Returns\\n    -------\\n    qm : array_like\\n        Matrix mapping the design matrix of the parent to the design matrix\\n        for the sub-model.\\n    qc : array_like\\n        Matrix mapping the design matrix of the parent to the orthogonal\\n        complement of the columnspace of the submodel in the columnspace\\n        of the parent.\\n\\n    Notes\\n    -----\\n    Returns None, None if the provided submodel is not actually a submodel.\\n    '\n    x1 = par.exog\n    x2 = sub.exog\n    (u, s, vt) = np.linalg.svd(x1, 0)\n    v = vt.T\n    (a, _) = np.linalg.qr(x2)\n    a = u - np.dot(a, np.dot(a.T, u))\n    (x2c, sb, _) = np.linalg.svd(a, 0)\n    x2c = x2c[:, sb > 1e-12]\n    ii = np.flatnonzero(np.abs(s) > 1e-12)\n    qm = np.dot(v[:, ii], np.dot(u[:, ii].T, x2) / s[ii, None])\n    e = np.max(np.abs(x2 - np.dot(x1, qm)))\n    if e > 1e-08:\n        return (None, None)\n    qc = np.dot(v[:, ii], np.dot(u[:, ii].T, x2c) / s[ii, None])\n    return (qm, qc)",
            "def _score_test_submodel(par, sub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Return transformation matrices for design matrices.\\n\\n    Parameters\\n    ----------\\n    par : instance\\n        The parent model\\n    sub : instance\\n        The sub-model\\n\\n    Returns\\n    -------\\n    qm : array_like\\n        Matrix mapping the design matrix of the parent to the design matrix\\n        for the sub-model.\\n    qc : array_like\\n        Matrix mapping the design matrix of the parent to the orthogonal\\n        complement of the columnspace of the submodel in the columnspace\\n        of the parent.\\n\\n    Notes\\n    -----\\n    Returns None, None if the provided submodel is not actually a submodel.\\n    '\n    x1 = par.exog\n    x2 = sub.exog\n    (u, s, vt) = np.linalg.svd(x1, 0)\n    v = vt.T\n    (a, _) = np.linalg.qr(x2)\n    a = u - np.dot(a, np.dot(a.T, u))\n    (x2c, sb, _) = np.linalg.svd(a, 0)\n    x2c = x2c[:, sb > 1e-12]\n    ii = np.flatnonzero(np.abs(s) > 1e-12)\n    qm = np.dot(v[:, ii], np.dot(u[:, ii].T, x2) / s[ii, None])\n    e = np.max(np.abs(x2 - np.dot(x1, qm)))\n    if e > 1e-08:\n        return (None, None)\n    qc = np.dot(v[:, ii], np.dot(u[:, ii].T, x2c) / s[ii, None])\n    return (qm, qc)",
            "def _score_test_submodel(par, sub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Return transformation matrices for design matrices.\\n\\n    Parameters\\n    ----------\\n    par : instance\\n        The parent model\\n    sub : instance\\n        The sub-model\\n\\n    Returns\\n    -------\\n    qm : array_like\\n        Matrix mapping the design matrix of the parent to the design matrix\\n        for the sub-model.\\n    qc : array_like\\n        Matrix mapping the design matrix of the parent to the orthogonal\\n        complement of the columnspace of the submodel in the columnspace\\n        of the parent.\\n\\n    Notes\\n    -----\\n    Returns None, None if the provided submodel is not actually a submodel.\\n    '\n    x1 = par.exog\n    x2 = sub.exog\n    (u, s, vt) = np.linalg.svd(x1, 0)\n    v = vt.T\n    (a, _) = np.linalg.qr(x2)\n    a = u - np.dot(a, np.dot(a.T, u))\n    (x2c, sb, _) = np.linalg.svd(a, 0)\n    x2c = x2c[:, sb > 1e-12]\n    ii = np.flatnonzero(np.abs(s) > 1e-12)\n    qm = np.dot(v[:, ii], np.dot(u[:, ii].T, x2) / s[ii, None])\n    e = np.max(np.abs(x2 - np.dot(x1, qm)))\n    if e > 1e-08:\n        return (None, None)\n    qc = np.dot(v[:, ii], np.dot(u[:, ii].T, x2c) / s[ii, None])\n    return (qm, qc)"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs):\n    (endog, exog, groups, time, offset) = self.setup_nominal(endog, exog, groups, time, offset)\n    if family is None:\n        family = _Multinomial(self.ncut + 1)\n    if cov_struct is None:\n        cov_struct = cov_structs.NominalIndependence()\n    super(NominalGEE, self).__init__(endog, exog, groups, time, family, cov_struct, missing, offset, dep_data, constraint)",
        "mutated": [
            "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs):\n    if False:\n        i = 10\n    (endog, exog, groups, time, offset) = self.setup_nominal(endog, exog, groups, time, offset)\n    if family is None:\n        family = _Multinomial(self.ncut + 1)\n    if cov_struct is None:\n        cov_struct = cov_structs.NominalIndependence()\n    super(NominalGEE, self).__init__(endog, exog, groups, time, family, cov_struct, missing, offset, dep_data, constraint)",
            "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (endog, exog, groups, time, offset) = self.setup_nominal(endog, exog, groups, time, offset)\n    if family is None:\n        family = _Multinomial(self.ncut + 1)\n    if cov_struct is None:\n        cov_struct = cov_structs.NominalIndependence()\n    super(NominalGEE, self).__init__(endog, exog, groups, time, family, cov_struct, missing, offset, dep_data, constraint)",
            "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (endog, exog, groups, time, offset) = self.setup_nominal(endog, exog, groups, time, offset)\n    if family is None:\n        family = _Multinomial(self.ncut + 1)\n    if cov_struct is None:\n        cov_struct = cov_structs.NominalIndependence()\n    super(NominalGEE, self).__init__(endog, exog, groups, time, family, cov_struct, missing, offset, dep_data, constraint)",
            "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (endog, exog, groups, time, offset) = self.setup_nominal(endog, exog, groups, time, offset)\n    if family is None:\n        family = _Multinomial(self.ncut + 1)\n    if cov_struct is None:\n        cov_struct = cov_structs.NominalIndependence()\n    super(NominalGEE, self).__init__(endog, exog, groups, time, family, cov_struct, missing, offset, dep_data, constraint)",
            "def __init__(self, endog, exog, groups, time=None, family=None, cov_struct=None, missing='none', offset=None, dep_data=None, constraint=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (endog, exog, groups, time, offset) = self.setup_nominal(endog, exog, groups, time, offset)\n    if family is None:\n        family = _Multinomial(self.ncut + 1)\n    if cov_struct is None:\n        cov_struct = cov_structs.NominalIndependence()\n    super(NominalGEE, self).__init__(endog, exog, groups, time, family, cov_struct, missing, offset, dep_data, constraint)"
        ]
    },
    {
        "func_name": "_starting_params",
        "original": "def _starting_params(self):\n    exposure = getattr(self, 'exposure', None)\n    model = GEE(self.endog, self.exog, self.groups, time=self.time, family=families.Binomial(), offset=self.offset, exposure=exposure)\n    result = model.fit()\n    return result.params",
        "mutated": [
            "def _starting_params(self):\n    if False:\n        i = 10\n    exposure = getattr(self, 'exposure', None)\n    model = GEE(self.endog, self.exog, self.groups, time=self.time, family=families.Binomial(), offset=self.offset, exposure=exposure)\n    result = model.fit()\n    return result.params",
            "def _starting_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    exposure = getattr(self, 'exposure', None)\n    model = GEE(self.endog, self.exog, self.groups, time=self.time, family=families.Binomial(), offset=self.offset, exposure=exposure)\n    result = model.fit()\n    return result.params",
            "def _starting_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    exposure = getattr(self, 'exposure', None)\n    model = GEE(self.endog, self.exog, self.groups, time=self.time, family=families.Binomial(), offset=self.offset, exposure=exposure)\n    result = model.fit()\n    return result.params",
            "def _starting_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    exposure = getattr(self, 'exposure', None)\n    model = GEE(self.endog, self.exog, self.groups, time=self.time, family=families.Binomial(), offset=self.offset, exposure=exposure)\n    result = model.fit()\n    return result.params",
            "def _starting_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    exposure = getattr(self, 'exposure', None)\n    model = GEE(self.endog, self.exog, self.groups, time=self.time, family=families.Binomial(), offset=self.offset, exposure=exposure)\n    result = model.fit()\n    return result.params"
        ]
    },
    {
        "func_name": "setup_nominal",
        "original": "def setup_nominal(self, endog, exog, groups, time, offset):\n    \"\"\"\n        Restructure nominal data as binary indicators so that they can\n        be analyzed using Generalized Estimating Equations.\n        \"\"\"\n    self.endog_orig = endog.copy()\n    self.exog_orig = exog.copy()\n    self.groups_orig = groups.copy()\n    if offset is not None:\n        self.offset_orig = offset.copy()\n    else:\n        self.offset_orig = None\n        offset = np.zeros(len(endog))\n    if time is not None:\n        self.time_orig = time.copy()\n    else:\n        self.time_orig = None\n        time = np.zeros((len(endog), 1))\n    exog = np.asarray(exog)\n    endog = np.asarray(endog)\n    groups = np.asarray(groups)\n    time = np.asarray(time)\n    offset = np.asarray(offset)\n    self.endog_values = np.unique(endog)\n    endog_cuts = self.endog_values[0:-1]\n    ncut = len(endog_cuts)\n    self.ncut = ncut\n    nrows = len(endog_cuts) * exog.shape[0]\n    ncols = len(endog_cuts) * exog.shape[1]\n    exog_out = np.zeros((nrows, ncols), dtype=np.float64)\n    endog_out = np.zeros(nrows, dtype=np.float64)\n    groups_out = np.zeros(nrows, dtype=np.float64)\n    time_out = np.zeros((nrows, time.shape[1]), dtype=np.float64)\n    offset_out = np.zeros(nrows, dtype=np.float64)\n    jrow = 0\n    zipper = zip(exog, endog, groups, time, offset)\n    for (exog_row, endog_value, group_value, time_value, offset_value) in zipper:\n        for (thresh_ix, thresh) in enumerate(endog_cuts):\n            u = np.zeros(len(endog_cuts), dtype=np.float64)\n            u[thresh_ix] = 1\n            exog_out[jrow, :] = np.kron(u, exog_row)\n            endog_out[jrow] = int(endog_value == thresh)\n            groups_out[jrow] = group_value\n            time_out[jrow] = time_value\n            offset_out[jrow] = offset_value\n            jrow += 1\n    if isinstance(self.exog_orig, pd.DataFrame):\n        xnames_in = self.exog_orig.columns\n    else:\n        xnames_in = ['x%d' % k for k in range(1, exog.shape[1] + 1)]\n    xnames = []\n    for tr in endog_cuts:\n        xnames.extend(['%s[%.1f]' % (v, tr) for v in xnames_in])\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    if isinstance(self.endog_orig, pd.Series):\n        endog_out = pd.Series(endog_out, name=self.endog_orig.name)\n    return (endog_out, exog_out, groups_out, time_out, offset_out)",
        "mutated": [
            "def setup_nominal(self, endog, exog, groups, time, offset):\n    if False:\n        i = 10\n    '\\n        Restructure nominal data as binary indicators so that they can\\n        be analyzed using Generalized Estimating Equations.\\n        '\n    self.endog_orig = endog.copy()\n    self.exog_orig = exog.copy()\n    self.groups_orig = groups.copy()\n    if offset is not None:\n        self.offset_orig = offset.copy()\n    else:\n        self.offset_orig = None\n        offset = np.zeros(len(endog))\n    if time is not None:\n        self.time_orig = time.copy()\n    else:\n        self.time_orig = None\n        time = np.zeros((len(endog), 1))\n    exog = np.asarray(exog)\n    endog = np.asarray(endog)\n    groups = np.asarray(groups)\n    time = np.asarray(time)\n    offset = np.asarray(offset)\n    self.endog_values = np.unique(endog)\n    endog_cuts = self.endog_values[0:-1]\n    ncut = len(endog_cuts)\n    self.ncut = ncut\n    nrows = len(endog_cuts) * exog.shape[0]\n    ncols = len(endog_cuts) * exog.shape[1]\n    exog_out = np.zeros((nrows, ncols), dtype=np.float64)\n    endog_out = np.zeros(nrows, dtype=np.float64)\n    groups_out = np.zeros(nrows, dtype=np.float64)\n    time_out = np.zeros((nrows, time.shape[1]), dtype=np.float64)\n    offset_out = np.zeros(nrows, dtype=np.float64)\n    jrow = 0\n    zipper = zip(exog, endog, groups, time, offset)\n    for (exog_row, endog_value, group_value, time_value, offset_value) in zipper:\n        for (thresh_ix, thresh) in enumerate(endog_cuts):\n            u = np.zeros(len(endog_cuts), dtype=np.float64)\n            u[thresh_ix] = 1\n            exog_out[jrow, :] = np.kron(u, exog_row)\n            endog_out[jrow] = int(endog_value == thresh)\n            groups_out[jrow] = group_value\n            time_out[jrow] = time_value\n            offset_out[jrow] = offset_value\n            jrow += 1\n    if isinstance(self.exog_orig, pd.DataFrame):\n        xnames_in = self.exog_orig.columns\n    else:\n        xnames_in = ['x%d' % k for k in range(1, exog.shape[1] + 1)]\n    xnames = []\n    for tr in endog_cuts:\n        xnames.extend(['%s[%.1f]' % (v, tr) for v in xnames_in])\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    if isinstance(self.endog_orig, pd.Series):\n        endog_out = pd.Series(endog_out, name=self.endog_orig.name)\n    return (endog_out, exog_out, groups_out, time_out, offset_out)",
            "def setup_nominal(self, endog, exog, groups, time, offset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Restructure nominal data as binary indicators so that they can\\n        be analyzed using Generalized Estimating Equations.\\n        '\n    self.endog_orig = endog.copy()\n    self.exog_orig = exog.copy()\n    self.groups_orig = groups.copy()\n    if offset is not None:\n        self.offset_orig = offset.copy()\n    else:\n        self.offset_orig = None\n        offset = np.zeros(len(endog))\n    if time is not None:\n        self.time_orig = time.copy()\n    else:\n        self.time_orig = None\n        time = np.zeros((len(endog), 1))\n    exog = np.asarray(exog)\n    endog = np.asarray(endog)\n    groups = np.asarray(groups)\n    time = np.asarray(time)\n    offset = np.asarray(offset)\n    self.endog_values = np.unique(endog)\n    endog_cuts = self.endog_values[0:-1]\n    ncut = len(endog_cuts)\n    self.ncut = ncut\n    nrows = len(endog_cuts) * exog.shape[0]\n    ncols = len(endog_cuts) * exog.shape[1]\n    exog_out = np.zeros((nrows, ncols), dtype=np.float64)\n    endog_out = np.zeros(nrows, dtype=np.float64)\n    groups_out = np.zeros(nrows, dtype=np.float64)\n    time_out = np.zeros((nrows, time.shape[1]), dtype=np.float64)\n    offset_out = np.zeros(nrows, dtype=np.float64)\n    jrow = 0\n    zipper = zip(exog, endog, groups, time, offset)\n    for (exog_row, endog_value, group_value, time_value, offset_value) in zipper:\n        for (thresh_ix, thresh) in enumerate(endog_cuts):\n            u = np.zeros(len(endog_cuts), dtype=np.float64)\n            u[thresh_ix] = 1\n            exog_out[jrow, :] = np.kron(u, exog_row)\n            endog_out[jrow] = int(endog_value == thresh)\n            groups_out[jrow] = group_value\n            time_out[jrow] = time_value\n            offset_out[jrow] = offset_value\n            jrow += 1\n    if isinstance(self.exog_orig, pd.DataFrame):\n        xnames_in = self.exog_orig.columns\n    else:\n        xnames_in = ['x%d' % k for k in range(1, exog.shape[1] + 1)]\n    xnames = []\n    for tr in endog_cuts:\n        xnames.extend(['%s[%.1f]' % (v, tr) for v in xnames_in])\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    if isinstance(self.endog_orig, pd.Series):\n        endog_out = pd.Series(endog_out, name=self.endog_orig.name)\n    return (endog_out, exog_out, groups_out, time_out, offset_out)",
            "def setup_nominal(self, endog, exog, groups, time, offset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Restructure nominal data as binary indicators so that they can\\n        be analyzed using Generalized Estimating Equations.\\n        '\n    self.endog_orig = endog.copy()\n    self.exog_orig = exog.copy()\n    self.groups_orig = groups.copy()\n    if offset is not None:\n        self.offset_orig = offset.copy()\n    else:\n        self.offset_orig = None\n        offset = np.zeros(len(endog))\n    if time is not None:\n        self.time_orig = time.copy()\n    else:\n        self.time_orig = None\n        time = np.zeros((len(endog), 1))\n    exog = np.asarray(exog)\n    endog = np.asarray(endog)\n    groups = np.asarray(groups)\n    time = np.asarray(time)\n    offset = np.asarray(offset)\n    self.endog_values = np.unique(endog)\n    endog_cuts = self.endog_values[0:-1]\n    ncut = len(endog_cuts)\n    self.ncut = ncut\n    nrows = len(endog_cuts) * exog.shape[0]\n    ncols = len(endog_cuts) * exog.shape[1]\n    exog_out = np.zeros((nrows, ncols), dtype=np.float64)\n    endog_out = np.zeros(nrows, dtype=np.float64)\n    groups_out = np.zeros(nrows, dtype=np.float64)\n    time_out = np.zeros((nrows, time.shape[1]), dtype=np.float64)\n    offset_out = np.zeros(nrows, dtype=np.float64)\n    jrow = 0\n    zipper = zip(exog, endog, groups, time, offset)\n    for (exog_row, endog_value, group_value, time_value, offset_value) in zipper:\n        for (thresh_ix, thresh) in enumerate(endog_cuts):\n            u = np.zeros(len(endog_cuts), dtype=np.float64)\n            u[thresh_ix] = 1\n            exog_out[jrow, :] = np.kron(u, exog_row)\n            endog_out[jrow] = int(endog_value == thresh)\n            groups_out[jrow] = group_value\n            time_out[jrow] = time_value\n            offset_out[jrow] = offset_value\n            jrow += 1\n    if isinstance(self.exog_orig, pd.DataFrame):\n        xnames_in = self.exog_orig.columns\n    else:\n        xnames_in = ['x%d' % k for k in range(1, exog.shape[1] + 1)]\n    xnames = []\n    for tr in endog_cuts:\n        xnames.extend(['%s[%.1f]' % (v, tr) for v in xnames_in])\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    if isinstance(self.endog_orig, pd.Series):\n        endog_out = pd.Series(endog_out, name=self.endog_orig.name)\n    return (endog_out, exog_out, groups_out, time_out, offset_out)",
            "def setup_nominal(self, endog, exog, groups, time, offset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Restructure nominal data as binary indicators so that they can\\n        be analyzed using Generalized Estimating Equations.\\n        '\n    self.endog_orig = endog.copy()\n    self.exog_orig = exog.copy()\n    self.groups_orig = groups.copy()\n    if offset is not None:\n        self.offset_orig = offset.copy()\n    else:\n        self.offset_orig = None\n        offset = np.zeros(len(endog))\n    if time is not None:\n        self.time_orig = time.copy()\n    else:\n        self.time_orig = None\n        time = np.zeros((len(endog), 1))\n    exog = np.asarray(exog)\n    endog = np.asarray(endog)\n    groups = np.asarray(groups)\n    time = np.asarray(time)\n    offset = np.asarray(offset)\n    self.endog_values = np.unique(endog)\n    endog_cuts = self.endog_values[0:-1]\n    ncut = len(endog_cuts)\n    self.ncut = ncut\n    nrows = len(endog_cuts) * exog.shape[0]\n    ncols = len(endog_cuts) * exog.shape[1]\n    exog_out = np.zeros((nrows, ncols), dtype=np.float64)\n    endog_out = np.zeros(nrows, dtype=np.float64)\n    groups_out = np.zeros(nrows, dtype=np.float64)\n    time_out = np.zeros((nrows, time.shape[1]), dtype=np.float64)\n    offset_out = np.zeros(nrows, dtype=np.float64)\n    jrow = 0\n    zipper = zip(exog, endog, groups, time, offset)\n    for (exog_row, endog_value, group_value, time_value, offset_value) in zipper:\n        for (thresh_ix, thresh) in enumerate(endog_cuts):\n            u = np.zeros(len(endog_cuts), dtype=np.float64)\n            u[thresh_ix] = 1\n            exog_out[jrow, :] = np.kron(u, exog_row)\n            endog_out[jrow] = int(endog_value == thresh)\n            groups_out[jrow] = group_value\n            time_out[jrow] = time_value\n            offset_out[jrow] = offset_value\n            jrow += 1\n    if isinstance(self.exog_orig, pd.DataFrame):\n        xnames_in = self.exog_orig.columns\n    else:\n        xnames_in = ['x%d' % k for k in range(1, exog.shape[1] + 1)]\n    xnames = []\n    for tr in endog_cuts:\n        xnames.extend(['%s[%.1f]' % (v, tr) for v in xnames_in])\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    if isinstance(self.endog_orig, pd.Series):\n        endog_out = pd.Series(endog_out, name=self.endog_orig.name)\n    return (endog_out, exog_out, groups_out, time_out, offset_out)",
            "def setup_nominal(self, endog, exog, groups, time, offset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Restructure nominal data as binary indicators so that they can\\n        be analyzed using Generalized Estimating Equations.\\n        '\n    self.endog_orig = endog.copy()\n    self.exog_orig = exog.copy()\n    self.groups_orig = groups.copy()\n    if offset is not None:\n        self.offset_orig = offset.copy()\n    else:\n        self.offset_orig = None\n        offset = np.zeros(len(endog))\n    if time is not None:\n        self.time_orig = time.copy()\n    else:\n        self.time_orig = None\n        time = np.zeros((len(endog), 1))\n    exog = np.asarray(exog)\n    endog = np.asarray(endog)\n    groups = np.asarray(groups)\n    time = np.asarray(time)\n    offset = np.asarray(offset)\n    self.endog_values = np.unique(endog)\n    endog_cuts = self.endog_values[0:-1]\n    ncut = len(endog_cuts)\n    self.ncut = ncut\n    nrows = len(endog_cuts) * exog.shape[0]\n    ncols = len(endog_cuts) * exog.shape[1]\n    exog_out = np.zeros((nrows, ncols), dtype=np.float64)\n    endog_out = np.zeros(nrows, dtype=np.float64)\n    groups_out = np.zeros(nrows, dtype=np.float64)\n    time_out = np.zeros((nrows, time.shape[1]), dtype=np.float64)\n    offset_out = np.zeros(nrows, dtype=np.float64)\n    jrow = 0\n    zipper = zip(exog, endog, groups, time, offset)\n    for (exog_row, endog_value, group_value, time_value, offset_value) in zipper:\n        for (thresh_ix, thresh) in enumerate(endog_cuts):\n            u = np.zeros(len(endog_cuts), dtype=np.float64)\n            u[thresh_ix] = 1\n            exog_out[jrow, :] = np.kron(u, exog_row)\n            endog_out[jrow] = int(endog_value == thresh)\n            groups_out[jrow] = group_value\n            time_out[jrow] = time_value\n            offset_out[jrow] = offset_value\n            jrow += 1\n    if isinstance(self.exog_orig, pd.DataFrame):\n        xnames_in = self.exog_orig.columns\n    else:\n        xnames_in = ['x%d' % k for k in range(1, exog.shape[1] + 1)]\n    xnames = []\n    for tr in endog_cuts:\n        xnames.extend(['%s[%.1f]' % (v, tr) for v in xnames_in])\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    exog_out = pd.DataFrame(exog_out, columns=xnames)\n    if isinstance(self.endog_orig, pd.Series):\n        endog_out = pd.Series(endog_out, name=self.endog_orig.name)\n    return (endog_out, exog_out, groups_out, time_out, offset_out)"
        ]
    },
    {
        "func_name": "mean_deriv",
        "original": "def mean_deriv(self, exog, lin_pred):\n    \"\"\"\n        Derivative of the expected endog with respect to the parameters.\n\n        Parameters\n        ----------\n        exog : array_like\n           The exogeneous data at which the derivative is computed,\n           number of rows must be a multiple of `ncut`.\n        lin_pred : array_like\n           The values of the linear predictor, length must be multiple\n           of `ncut`.\n\n        Returns\n        -------\n        The derivative of the expected endog with respect to the\n        parameters.\n        \"\"\"\n    expval = np.exp(lin_pred)\n    expval_m = np.reshape(expval, (len(expval) // self.ncut, self.ncut))\n    denom = 1 + expval_m.sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    mprob = expval / denom\n    dmat = mprob[:, None] * exog\n    ddenom = expval[:, None] * exog\n    dmat -= mprob[:, None] * ddenom / denom[:, None]\n    return dmat",
        "mutated": [
            "def mean_deriv(self, exog, lin_pred):\n    if False:\n        i = 10\n    '\\n        Derivative of the expected endog with respect to the parameters.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data at which the derivative is computed,\\n           number of rows must be a multiple of `ncut`.\\n        lin_pred : array_like\\n           The values of the linear predictor, length must be multiple\\n           of `ncut`.\\n\\n        Returns\\n        -------\\n        The derivative of the expected endog with respect to the\\n        parameters.\\n        '\n    expval = np.exp(lin_pred)\n    expval_m = np.reshape(expval, (len(expval) // self.ncut, self.ncut))\n    denom = 1 + expval_m.sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    mprob = expval / denom\n    dmat = mprob[:, None] * exog\n    ddenom = expval[:, None] * exog\n    dmat -= mprob[:, None] * ddenom / denom[:, None]\n    return dmat",
            "def mean_deriv(self, exog, lin_pred):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Derivative of the expected endog with respect to the parameters.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data at which the derivative is computed,\\n           number of rows must be a multiple of `ncut`.\\n        lin_pred : array_like\\n           The values of the linear predictor, length must be multiple\\n           of `ncut`.\\n\\n        Returns\\n        -------\\n        The derivative of the expected endog with respect to the\\n        parameters.\\n        '\n    expval = np.exp(lin_pred)\n    expval_m = np.reshape(expval, (len(expval) // self.ncut, self.ncut))\n    denom = 1 + expval_m.sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    mprob = expval / denom\n    dmat = mprob[:, None] * exog\n    ddenom = expval[:, None] * exog\n    dmat -= mprob[:, None] * ddenom / denom[:, None]\n    return dmat",
            "def mean_deriv(self, exog, lin_pred):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Derivative of the expected endog with respect to the parameters.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data at which the derivative is computed,\\n           number of rows must be a multiple of `ncut`.\\n        lin_pred : array_like\\n           The values of the linear predictor, length must be multiple\\n           of `ncut`.\\n\\n        Returns\\n        -------\\n        The derivative of the expected endog with respect to the\\n        parameters.\\n        '\n    expval = np.exp(lin_pred)\n    expval_m = np.reshape(expval, (len(expval) // self.ncut, self.ncut))\n    denom = 1 + expval_m.sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    mprob = expval / denom\n    dmat = mprob[:, None] * exog\n    ddenom = expval[:, None] * exog\n    dmat -= mprob[:, None] * ddenom / denom[:, None]\n    return dmat",
            "def mean_deriv(self, exog, lin_pred):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Derivative of the expected endog with respect to the parameters.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data at which the derivative is computed,\\n           number of rows must be a multiple of `ncut`.\\n        lin_pred : array_like\\n           The values of the linear predictor, length must be multiple\\n           of `ncut`.\\n\\n        Returns\\n        -------\\n        The derivative of the expected endog with respect to the\\n        parameters.\\n        '\n    expval = np.exp(lin_pred)\n    expval_m = np.reshape(expval, (len(expval) // self.ncut, self.ncut))\n    denom = 1 + expval_m.sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    mprob = expval / denom\n    dmat = mprob[:, None] * exog\n    ddenom = expval[:, None] * exog\n    dmat -= mprob[:, None] * ddenom / denom[:, None]\n    return dmat",
            "def mean_deriv(self, exog, lin_pred):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Derivative of the expected endog with respect to the parameters.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data at which the derivative is computed,\\n           number of rows must be a multiple of `ncut`.\\n        lin_pred : array_like\\n           The values of the linear predictor, length must be multiple\\n           of `ncut`.\\n\\n        Returns\\n        -------\\n        The derivative of the expected endog with respect to the\\n        parameters.\\n        '\n    expval = np.exp(lin_pred)\n    expval_m = np.reshape(expval, (len(expval) // self.ncut, self.ncut))\n    denom = 1 + expval_m.sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    mprob = expval / denom\n    dmat = mprob[:, None] * exog\n    ddenom = expval[:, None] * exog\n    dmat -= mprob[:, None] * ddenom / denom[:, None]\n    return dmat"
        ]
    },
    {
        "func_name": "mean_deriv_exog",
        "original": "def mean_deriv_exog(self, exog, params, offset_exposure=None):\n    \"\"\"\n        Derivative of the expected endog with respect to exog for the\n        multinomial model, used in analyzing marginal effects.\n\n        Parameters\n        ----------\n        exog : array_like\n           The exogeneous data at which the derivative is computed,\n           number of rows must be a multiple of `ncut`.\n        lpr : array_like\n           The linear predictor values, length must be multiple of\n           `ncut`.\n\n        Returns\n        -------\n        The value of the derivative of the expected endog with respect\n        to exog.\n\n        Notes\n        -----\n        offset_exposure must be set at None for the multinomial family.\n        \"\"\"\n    if offset_exposure is not None:\n        warnings.warn('Offset/exposure ignored for the multinomial family', ValueWarning)\n    lpr = np.dot(exog, params)\n    expval = np.exp(lpr)\n    expval_m = np.reshape(expval, (len(expval) // self.ncut, self.ncut))\n    denom = 1 + expval_m.sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    bmat0 = np.outer(np.ones(exog.shape[0]), params)\n    qmat = []\n    for j in range(self.ncut):\n        ee = np.zeros(self.ncut, dtype=np.float64)\n        ee[j] = 1\n        qmat.append(np.kron(ee, np.ones(len(params) // self.ncut)))\n    qmat = np.array(qmat)\n    qmat = np.kron(np.ones((exog.shape[0] // self.ncut, 1)), qmat)\n    bmat = bmat0 * qmat\n    dmat = expval[:, None] * bmat / denom[:, None]\n    expval_mb = np.kron(expval_m, np.ones((self.ncut, 1)))\n    expval_mb = np.kron(expval_mb, np.ones((1, self.ncut)))\n    dmat -= expval[:, None] * (bmat * expval_mb) / denom[:, None] ** 2\n    return dmat",
        "mutated": [
            "def mean_deriv_exog(self, exog, params, offset_exposure=None):\n    if False:\n        i = 10\n    '\\n        Derivative of the expected endog with respect to exog for the\\n        multinomial model, used in analyzing marginal effects.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data at which the derivative is computed,\\n           number of rows must be a multiple of `ncut`.\\n        lpr : array_like\\n           The linear predictor values, length must be multiple of\\n           `ncut`.\\n\\n        Returns\\n        -------\\n        The value of the derivative of the expected endog with respect\\n        to exog.\\n\\n        Notes\\n        -----\\n        offset_exposure must be set at None for the multinomial family.\\n        '\n    if offset_exposure is not None:\n        warnings.warn('Offset/exposure ignored for the multinomial family', ValueWarning)\n    lpr = np.dot(exog, params)\n    expval = np.exp(lpr)\n    expval_m = np.reshape(expval, (len(expval) // self.ncut, self.ncut))\n    denom = 1 + expval_m.sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    bmat0 = np.outer(np.ones(exog.shape[0]), params)\n    qmat = []\n    for j in range(self.ncut):\n        ee = np.zeros(self.ncut, dtype=np.float64)\n        ee[j] = 1\n        qmat.append(np.kron(ee, np.ones(len(params) // self.ncut)))\n    qmat = np.array(qmat)\n    qmat = np.kron(np.ones((exog.shape[0] // self.ncut, 1)), qmat)\n    bmat = bmat0 * qmat\n    dmat = expval[:, None] * bmat / denom[:, None]\n    expval_mb = np.kron(expval_m, np.ones((self.ncut, 1)))\n    expval_mb = np.kron(expval_mb, np.ones((1, self.ncut)))\n    dmat -= expval[:, None] * (bmat * expval_mb) / denom[:, None] ** 2\n    return dmat",
            "def mean_deriv_exog(self, exog, params, offset_exposure=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Derivative of the expected endog with respect to exog for the\\n        multinomial model, used in analyzing marginal effects.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data at which the derivative is computed,\\n           number of rows must be a multiple of `ncut`.\\n        lpr : array_like\\n           The linear predictor values, length must be multiple of\\n           `ncut`.\\n\\n        Returns\\n        -------\\n        The value of the derivative of the expected endog with respect\\n        to exog.\\n\\n        Notes\\n        -----\\n        offset_exposure must be set at None for the multinomial family.\\n        '\n    if offset_exposure is not None:\n        warnings.warn('Offset/exposure ignored for the multinomial family', ValueWarning)\n    lpr = np.dot(exog, params)\n    expval = np.exp(lpr)\n    expval_m = np.reshape(expval, (len(expval) // self.ncut, self.ncut))\n    denom = 1 + expval_m.sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    bmat0 = np.outer(np.ones(exog.shape[0]), params)\n    qmat = []\n    for j in range(self.ncut):\n        ee = np.zeros(self.ncut, dtype=np.float64)\n        ee[j] = 1\n        qmat.append(np.kron(ee, np.ones(len(params) // self.ncut)))\n    qmat = np.array(qmat)\n    qmat = np.kron(np.ones((exog.shape[0] // self.ncut, 1)), qmat)\n    bmat = bmat0 * qmat\n    dmat = expval[:, None] * bmat / denom[:, None]\n    expval_mb = np.kron(expval_m, np.ones((self.ncut, 1)))\n    expval_mb = np.kron(expval_mb, np.ones((1, self.ncut)))\n    dmat -= expval[:, None] * (bmat * expval_mb) / denom[:, None] ** 2\n    return dmat",
            "def mean_deriv_exog(self, exog, params, offset_exposure=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Derivative of the expected endog with respect to exog for the\\n        multinomial model, used in analyzing marginal effects.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data at which the derivative is computed,\\n           number of rows must be a multiple of `ncut`.\\n        lpr : array_like\\n           The linear predictor values, length must be multiple of\\n           `ncut`.\\n\\n        Returns\\n        -------\\n        The value of the derivative of the expected endog with respect\\n        to exog.\\n\\n        Notes\\n        -----\\n        offset_exposure must be set at None for the multinomial family.\\n        '\n    if offset_exposure is not None:\n        warnings.warn('Offset/exposure ignored for the multinomial family', ValueWarning)\n    lpr = np.dot(exog, params)\n    expval = np.exp(lpr)\n    expval_m = np.reshape(expval, (len(expval) // self.ncut, self.ncut))\n    denom = 1 + expval_m.sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    bmat0 = np.outer(np.ones(exog.shape[0]), params)\n    qmat = []\n    for j in range(self.ncut):\n        ee = np.zeros(self.ncut, dtype=np.float64)\n        ee[j] = 1\n        qmat.append(np.kron(ee, np.ones(len(params) // self.ncut)))\n    qmat = np.array(qmat)\n    qmat = np.kron(np.ones((exog.shape[0] // self.ncut, 1)), qmat)\n    bmat = bmat0 * qmat\n    dmat = expval[:, None] * bmat / denom[:, None]\n    expval_mb = np.kron(expval_m, np.ones((self.ncut, 1)))\n    expval_mb = np.kron(expval_mb, np.ones((1, self.ncut)))\n    dmat -= expval[:, None] * (bmat * expval_mb) / denom[:, None] ** 2\n    return dmat",
            "def mean_deriv_exog(self, exog, params, offset_exposure=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Derivative of the expected endog with respect to exog for the\\n        multinomial model, used in analyzing marginal effects.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data at which the derivative is computed,\\n           number of rows must be a multiple of `ncut`.\\n        lpr : array_like\\n           The linear predictor values, length must be multiple of\\n           `ncut`.\\n\\n        Returns\\n        -------\\n        The value of the derivative of the expected endog with respect\\n        to exog.\\n\\n        Notes\\n        -----\\n        offset_exposure must be set at None for the multinomial family.\\n        '\n    if offset_exposure is not None:\n        warnings.warn('Offset/exposure ignored for the multinomial family', ValueWarning)\n    lpr = np.dot(exog, params)\n    expval = np.exp(lpr)\n    expval_m = np.reshape(expval, (len(expval) // self.ncut, self.ncut))\n    denom = 1 + expval_m.sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    bmat0 = np.outer(np.ones(exog.shape[0]), params)\n    qmat = []\n    for j in range(self.ncut):\n        ee = np.zeros(self.ncut, dtype=np.float64)\n        ee[j] = 1\n        qmat.append(np.kron(ee, np.ones(len(params) // self.ncut)))\n    qmat = np.array(qmat)\n    qmat = np.kron(np.ones((exog.shape[0] // self.ncut, 1)), qmat)\n    bmat = bmat0 * qmat\n    dmat = expval[:, None] * bmat / denom[:, None]\n    expval_mb = np.kron(expval_m, np.ones((self.ncut, 1)))\n    expval_mb = np.kron(expval_mb, np.ones((1, self.ncut)))\n    dmat -= expval[:, None] * (bmat * expval_mb) / denom[:, None] ** 2\n    return dmat",
            "def mean_deriv_exog(self, exog, params, offset_exposure=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Derivative of the expected endog with respect to exog for the\\n        multinomial model, used in analyzing marginal effects.\\n\\n        Parameters\\n        ----------\\n        exog : array_like\\n           The exogeneous data at which the derivative is computed,\\n           number of rows must be a multiple of `ncut`.\\n        lpr : array_like\\n           The linear predictor values, length must be multiple of\\n           `ncut`.\\n\\n        Returns\\n        -------\\n        The value of the derivative of the expected endog with respect\\n        to exog.\\n\\n        Notes\\n        -----\\n        offset_exposure must be set at None for the multinomial family.\\n        '\n    if offset_exposure is not None:\n        warnings.warn('Offset/exposure ignored for the multinomial family', ValueWarning)\n    lpr = np.dot(exog, params)\n    expval = np.exp(lpr)\n    expval_m = np.reshape(expval, (len(expval) // self.ncut, self.ncut))\n    denom = 1 + expval_m.sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    bmat0 = np.outer(np.ones(exog.shape[0]), params)\n    qmat = []\n    for j in range(self.ncut):\n        ee = np.zeros(self.ncut, dtype=np.float64)\n        ee[j] = 1\n        qmat.append(np.kron(ee, np.ones(len(params) // self.ncut)))\n    qmat = np.array(qmat)\n    qmat = np.kron(np.ones((exog.shape[0] // self.ncut, 1)), qmat)\n    bmat = bmat0 * qmat\n    dmat = expval[:, None] * bmat / denom[:, None]\n    expval_mb = np.kron(expval_m, np.ones((self.ncut, 1)))\n    expval_mb = np.kron(expval_mb, np.ones((1, self.ncut)))\n    dmat -= expval[:, None] * (bmat * expval_mb) / denom[:, None] ** 2\n    return dmat"
        ]
    },
    {
        "func_name": "fit",
        "original": "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust'):\n    rslt = super(NominalGEE, self).fit(maxiter, ctol, start_params, params_niter, first_dep_update, cov_type=cov_type)\n    if rslt is None:\n        warnings.warn('GEE updates did not converge', ConvergenceWarning)\n        return None\n    rslt = rslt._results\n    res_kwds = dict(((k, getattr(rslt, k)) for k in rslt._props))\n    nom_rslt = NominalGEEResults(self, rslt.params, rslt.cov_params() / rslt.scale, rslt.scale, cov_type=cov_type, attr_kwds=res_kwds)\n    return NominalGEEResultsWrapper(nom_rslt)",
        "mutated": [
            "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust'):\n    if False:\n        i = 10\n    rslt = super(NominalGEE, self).fit(maxiter, ctol, start_params, params_niter, first_dep_update, cov_type=cov_type)\n    if rslt is None:\n        warnings.warn('GEE updates did not converge', ConvergenceWarning)\n        return None\n    rslt = rslt._results\n    res_kwds = dict(((k, getattr(rslt, k)) for k in rslt._props))\n    nom_rslt = NominalGEEResults(self, rslt.params, rslt.cov_params() / rslt.scale, rslt.scale, cov_type=cov_type, attr_kwds=res_kwds)\n    return NominalGEEResultsWrapper(nom_rslt)",
            "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    rslt = super(NominalGEE, self).fit(maxiter, ctol, start_params, params_niter, first_dep_update, cov_type=cov_type)\n    if rslt is None:\n        warnings.warn('GEE updates did not converge', ConvergenceWarning)\n        return None\n    rslt = rslt._results\n    res_kwds = dict(((k, getattr(rslt, k)) for k in rslt._props))\n    nom_rslt = NominalGEEResults(self, rslt.params, rslt.cov_params() / rslt.scale, rslt.scale, cov_type=cov_type, attr_kwds=res_kwds)\n    return NominalGEEResultsWrapper(nom_rslt)",
            "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    rslt = super(NominalGEE, self).fit(maxiter, ctol, start_params, params_niter, first_dep_update, cov_type=cov_type)\n    if rslt is None:\n        warnings.warn('GEE updates did not converge', ConvergenceWarning)\n        return None\n    rslt = rslt._results\n    res_kwds = dict(((k, getattr(rslt, k)) for k in rslt._props))\n    nom_rslt = NominalGEEResults(self, rslt.params, rslt.cov_params() / rslt.scale, rslt.scale, cov_type=cov_type, attr_kwds=res_kwds)\n    return NominalGEEResultsWrapper(nom_rslt)",
            "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    rslt = super(NominalGEE, self).fit(maxiter, ctol, start_params, params_niter, first_dep_update, cov_type=cov_type)\n    if rslt is None:\n        warnings.warn('GEE updates did not converge', ConvergenceWarning)\n        return None\n    rslt = rslt._results\n    res_kwds = dict(((k, getattr(rslt, k)) for k in rslt._props))\n    nom_rslt = NominalGEEResults(self, rslt.params, rslt.cov_params() / rslt.scale, rslt.scale, cov_type=cov_type, attr_kwds=res_kwds)\n    return NominalGEEResultsWrapper(nom_rslt)",
            "@Appender(_gee_fit_doc)\ndef fit(self, maxiter=60, ctol=1e-06, start_params=None, params_niter=1, first_dep_update=0, cov_type='robust'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    rslt = super(NominalGEE, self).fit(maxiter, ctol, start_params, params_niter, first_dep_update, cov_type=cov_type)\n    if rslt is None:\n        warnings.warn('GEE updates did not converge', ConvergenceWarning)\n        return None\n    rslt = rslt._results\n    res_kwds = dict(((k, getattr(rslt, k)) for k in rslt._props))\n    nom_rslt = NominalGEEResults(self, rslt.params, rslt.cov_params() / rslt.scale, rslt.scale, cov_type=cov_type, attr_kwds=res_kwds)\n    return NominalGEEResultsWrapper(nom_rslt)"
        ]
    },
    {
        "func_name": "plot_distribution",
        "original": "def plot_distribution(self, ax=None, exog_values=None):\n    \"\"\"\n        Plot the fitted probabilities of endog in an nominal model,\n        for specified values of the predictors.\n\n        Parameters\n        ----------\n        ax : AxesSubplot\n            An axes on which to draw the graph.  If None, new\n            figure and axes objects are created\n        exog_values : array_like\n            A list of dictionaries, with each dictionary mapping\n            variable names to values at which the variable is held\n            fixed.  The values P(endog=y | exog) are plotted for all\n            possible values of y, at the given exog value.  Variables\n            not included in a dictionary are held fixed at the mean\n            value.\n\n        Example:\n        --------\n        We have a model with covariates 'age' and 'sex', and wish to\n        plot the probabilities P(endog=y | exog) for males (sex=0) and\n        for females (sex=1), as separate paths on the plot.  Since\n        'age' is not included below in the map, it is held fixed at\n        its mean value.\n\n        >>> ex = [{\"sex\": 1}, {\"sex\": 0}]\n        >>> rslt.distribution_plot(exog_values=ex)\n        \"\"\"\n    from statsmodels.graphics import utils as gutils\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    if exog_values is None:\n        exog_values = [{}]\n    link = self.model.family.link.inverse\n    ncut = self.model.family.ncut\n    k = int(self.model.exog.shape[1] / ncut)\n    exog_means = self.model.exog.mean(0)[0:k]\n    exog_names = self.model.exog_names[0:k]\n    exog_names = [x.split('[')[0] for x in exog_names]\n    params = np.reshape(self.params, (ncut, len(self.params) // ncut))\n    for ev in exog_values:\n        exog = exog_means.copy()\n        for k in ev.keys():\n            if k not in exog_names:\n                raise ValueError('%s is not a variable in the model' % k)\n            ii = exog_names.index(k)\n            exog[ii] = ev[k]\n        lpr = np.dot(params, exog)\n        pr = link(lpr)\n        pr = np.r_[pr, 1 - pr.sum()]\n        ax.plot(self.model.endog_values, pr, 'o-')\n    ax.set_xlabel('Response value')\n    ax.set_ylabel('Probability')\n    ax.set_xticks(self.model.endog_values)\n    ax.set_xticklabels(self.model.endog_values)\n    ax.set_ylim(0, 1)\n    return fig",
        "mutated": [
            "def plot_distribution(self, ax=None, exog_values=None):\n    if False:\n        i = 10\n    '\\n        Plot the fitted probabilities of endog in an nominal model,\\n        for specified values of the predictors.\\n\\n        Parameters\\n        ----------\\n        ax : AxesSubplot\\n            An axes on which to draw the graph.  If None, new\\n            figure and axes objects are created\\n        exog_values : array_like\\n            A list of dictionaries, with each dictionary mapping\\n            variable names to values at which the variable is held\\n            fixed.  The values P(endog=y | exog) are plotted for all\\n            possible values of y, at the given exog value.  Variables\\n            not included in a dictionary are held fixed at the mean\\n            value.\\n\\n        Example:\\n        --------\\n        We have a model with covariates \\'age\\' and \\'sex\\', and wish to\\n        plot the probabilities P(endog=y | exog) for males (sex=0) and\\n        for females (sex=1), as separate paths on the plot.  Since\\n        \\'age\\' is not included below in the map, it is held fixed at\\n        its mean value.\\n\\n        >>> ex = [{\"sex\": 1}, {\"sex\": 0}]\\n        >>> rslt.distribution_plot(exog_values=ex)\\n        '\n    from statsmodels.graphics import utils as gutils\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    if exog_values is None:\n        exog_values = [{}]\n    link = self.model.family.link.inverse\n    ncut = self.model.family.ncut\n    k = int(self.model.exog.shape[1] / ncut)\n    exog_means = self.model.exog.mean(0)[0:k]\n    exog_names = self.model.exog_names[0:k]\n    exog_names = [x.split('[')[0] for x in exog_names]\n    params = np.reshape(self.params, (ncut, len(self.params) // ncut))\n    for ev in exog_values:\n        exog = exog_means.copy()\n        for k in ev.keys():\n            if k not in exog_names:\n                raise ValueError('%s is not a variable in the model' % k)\n            ii = exog_names.index(k)\n            exog[ii] = ev[k]\n        lpr = np.dot(params, exog)\n        pr = link(lpr)\n        pr = np.r_[pr, 1 - pr.sum()]\n        ax.plot(self.model.endog_values, pr, 'o-')\n    ax.set_xlabel('Response value')\n    ax.set_ylabel('Probability')\n    ax.set_xticks(self.model.endog_values)\n    ax.set_xticklabels(self.model.endog_values)\n    ax.set_ylim(0, 1)\n    return fig",
            "def plot_distribution(self, ax=None, exog_values=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Plot the fitted probabilities of endog in an nominal model,\\n        for specified values of the predictors.\\n\\n        Parameters\\n        ----------\\n        ax : AxesSubplot\\n            An axes on which to draw the graph.  If None, new\\n            figure and axes objects are created\\n        exog_values : array_like\\n            A list of dictionaries, with each dictionary mapping\\n            variable names to values at which the variable is held\\n            fixed.  The values P(endog=y | exog) are plotted for all\\n            possible values of y, at the given exog value.  Variables\\n            not included in a dictionary are held fixed at the mean\\n            value.\\n\\n        Example:\\n        --------\\n        We have a model with covariates \\'age\\' and \\'sex\\', and wish to\\n        plot the probabilities P(endog=y | exog) for males (sex=0) and\\n        for females (sex=1), as separate paths on the plot.  Since\\n        \\'age\\' is not included below in the map, it is held fixed at\\n        its mean value.\\n\\n        >>> ex = [{\"sex\": 1}, {\"sex\": 0}]\\n        >>> rslt.distribution_plot(exog_values=ex)\\n        '\n    from statsmodels.graphics import utils as gutils\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    if exog_values is None:\n        exog_values = [{}]\n    link = self.model.family.link.inverse\n    ncut = self.model.family.ncut\n    k = int(self.model.exog.shape[1] / ncut)\n    exog_means = self.model.exog.mean(0)[0:k]\n    exog_names = self.model.exog_names[0:k]\n    exog_names = [x.split('[')[0] for x in exog_names]\n    params = np.reshape(self.params, (ncut, len(self.params) // ncut))\n    for ev in exog_values:\n        exog = exog_means.copy()\n        for k in ev.keys():\n            if k not in exog_names:\n                raise ValueError('%s is not a variable in the model' % k)\n            ii = exog_names.index(k)\n            exog[ii] = ev[k]\n        lpr = np.dot(params, exog)\n        pr = link(lpr)\n        pr = np.r_[pr, 1 - pr.sum()]\n        ax.plot(self.model.endog_values, pr, 'o-')\n    ax.set_xlabel('Response value')\n    ax.set_ylabel('Probability')\n    ax.set_xticks(self.model.endog_values)\n    ax.set_xticklabels(self.model.endog_values)\n    ax.set_ylim(0, 1)\n    return fig",
            "def plot_distribution(self, ax=None, exog_values=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Plot the fitted probabilities of endog in an nominal model,\\n        for specified values of the predictors.\\n\\n        Parameters\\n        ----------\\n        ax : AxesSubplot\\n            An axes on which to draw the graph.  If None, new\\n            figure and axes objects are created\\n        exog_values : array_like\\n            A list of dictionaries, with each dictionary mapping\\n            variable names to values at which the variable is held\\n            fixed.  The values P(endog=y | exog) are plotted for all\\n            possible values of y, at the given exog value.  Variables\\n            not included in a dictionary are held fixed at the mean\\n            value.\\n\\n        Example:\\n        --------\\n        We have a model with covariates \\'age\\' and \\'sex\\', and wish to\\n        plot the probabilities P(endog=y | exog) for males (sex=0) and\\n        for females (sex=1), as separate paths on the plot.  Since\\n        \\'age\\' is not included below in the map, it is held fixed at\\n        its mean value.\\n\\n        >>> ex = [{\"sex\": 1}, {\"sex\": 0}]\\n        >>> rslt.distribution_plot(exog_values=ex)\\n        '\n    from statsmodels.graphics import utils as gutils\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    if exog_values is None:\n        exog_values = [{}]\n    link = self.model.family.link.inverse\n    ncut = self.model.family.ncut\n    k = int(self.model.exog.shape[1] / ncut)\n    exog_means = self.model.exog.mean(0)[0:k]\n    exog_names = self.model.exog_names[0:k]\n    exog_names = [x.split('[')[0] for x in exog_names]\n    params = np.reshape(self.params, (ncut, len(self.params) // ncut))\n    for ev in exog_values:\n        exog = exog_means.copy()\n        for k in ev.keys():\n            if k not in exog_names:\n                raise ValueError('%s is not a variable in the model' % k)\n            ii = exog_names.index(k)\n            exog[ii] = ev[k]\n        lpr = np.dot(params, exog)\n        pr = link(lpr)\n        pr = np.r_[pr, 1 - pr.sum()]\n        ax.plot(self.model.endog_values, pr, 'o-')\n    ax.set_xlabel('Response value')\n    ax.set_ylabel('Probability')\n    ax.set_xticks(self.model.endog_values)\n    ax.set_xticklabels(self.model.endog_values)\n    ax.set_ylim(0, 1)\n    return fig",
            "def plot_distribution(self, ax=None, exog_values=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Plot the fitted probabilities of endog in an nominal model,\\n        for specified values of the predictors.\\n\\n        Parameters\\n        ----------\\n        ax : AxesSubplot\\n            An axes on which to draw the graph.  If None, new\\n            figure and axes objects are created\\n        exog_values : array_like\\n            A list of dictionaries, with each dictionary mapping\\n            variable names to values at which the variable is held\\n            fixed.  The values P(endog=y | exog) are plotted for all\\n            possible values of y, at the given exog value.  Variables\\n            not included in a dictionary are held fixed at the mean\\n            value.\\n\\n        Example:\\n        --------\\n        We have a model with covariates \\'age\\' and \\'sex\\', and wish to\\n        plot the probabilities P(endog=y | exog) for males (sex=0) and\\n        for females (sex=1), as separate paths on the plot.  Since\\n        \\'age\\' is not included below in the map, it is held fixed at\\n        its mean value.\\n\\n        >>> ex = [{\"sex\": 1}, {\"sex\": 0}]\\n        >>> rslt.distribution_plot(exog_values=ex)\\n        '\n    from statsmodels.graphics import utils as gutils\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    if exog_values is None:\n        exog_values = [{}]\n    link = self.model.family.link.inverse\n    ncut = self.model.family.ncut\n    k = int(self.model.exog.shape[1] / ncut)\n    exog_means = self.model.exog.mean(0)[0:k]\n    exog_names = self.model.exog_names[0:k]\n    exog_names = [x.split('[')[0] for x in exog_names]\n    params = np.reshape(self.params, (ncut, len(self.params) // ncut))\n    for ev in exog_values:\n        exog = exog_means.copy()\n        for k in ev.keys():\n            if k not in exog_names:\n                raise ValueError('%s is not a variable in the model' % k)\n            ii = exog_names.index(k)\n            exog[ii] = ev[k]\n        lpr = np.dot(params, exog)\n        pr = link(lpr)\n        pr = np.r_[pr, 1 - pr.sum()]\n        ax.plot(self.model.endog_values, pr, 'o-')\n    ax.set_xlabel('Response value')\n    ax.set_ylabel('Probability')\n    ax.set_xticks(self.model.endog_values)\n    ax.set_xticklabels(self.model.endog_values)\n    ax.set_ylim(0, 1)\n    return fig",
            "def plot_distribution(self, ax=None, exog_values=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Plot the fitted probabilities of endog in an nominal model,\\n        for specified values of the predictors.\\n\\n        Parameters\\n        ----------\\n        ax : AxesSubplot\\n            An axes on which to draw the graph.  If None, new\\n            figure and axes objects are created\\n        exog_values : array_like\\n            A list of dictionaries, with each dictionary mapping\\n            variable names to values at which the variable is held\\n            fixed.  The values P(endog=y | exog) are plotted for all\\n            possible values of y, at the given exog value.  Variables\\n            not included in a dictionary are held fixed at the mean\\n            value.\\n\\n        Example:\\n        --------\\n        We have a model with covariates \\'age\\' and \\'sex\\', and wish to\\n        plot the probabilities P(endog=y | exog) for males (sex=0) and\\n        for females (sex=1), as separate paths on the plot.  Since\\n        \\'age\\' is not included below in the map, it is held fixed at\\n        its mean value.\\n\\n        >>> ex = [{\"sex\": 1}, {\"sex\": 0}]\\n        >>> rslt.distribution_plot(exog_values=ex)\\n        '\n    from statsmodels.graphics import utils as gutils\n    if ax is None:\n        (fig, ax) = gutils.create_mpl_ax(ax)\n    else:\n        fig = ax.get_figure()\n    if exog_values is None:\n        exog_values = [{}]\n    link = self.model.family.link.inverse\n    ncut = self.model.family.ncut\n    k = int(self.model.exog.shape[1] / ncut)\n    exog_means = self.model.exog.mean(0)[0:k]\n    exog_names = self.model.exog_names[0:k]\n    exog_names = [x.split('[')[0] for x in exog_names]\n    params = np.reshape(self.params, (ncut, len(self.params) // ncut))\n    for ev in exog_values:\n        exog = exog_means.copy()\n        for k in ev.keys():\n            if k not in exog_names:\n                raise ValueError('%s is not a variable in the model' % k)\n            ii = exog_names.index(k)\n            exog[ii] = ev[k]\n        lpr = np.dot(params, exog)\n        pr = link(lpr)\n        pr = np.r_[pr, 1 - pr.sum()]\n        ax.plot(self.model.endog_values, pr, 'o-')\n    ax.set_xlabel('Response value')\n    ax.set_ylabel('Probability')\n    ax.set_xticks(self.model.endog_values)\n    ax.set_xticklabels(self.model.endog_values)\n    ax.set_ylim(0, 1)\n    return fig"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, ncut):\n    self.ncut = ncut",
        "mutated": [
            "def __init__(self, ncut):\n    if False:\n        i = 10\n    self.ncut = ncut",
            "def __init__(self, ncut):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.ncut = ncut",
            "def __init__(self, ncut):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.ncut = ncut",
            "def __init__(self, ncut):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.ncut = ncut",
            "def __init__(self, ncut):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.ncut = ncut"
        ]
    },
    {
        "func_name": "inverse",
        "original": "def inverse(self, lpr):\n    \"\"\"\n        Inverse of the multinomial logit transform, which gives the\n        expected values of the data as a function of the linear\n        predictors.\n\n        Parameters\n        ----------\n        lpr : array_like (length must be divisible by `ncut`)\n            The linear predictors\n\n        Returns\n        -------\n        prob : ndarray\n            Probabilities, or expected values\n        \"\"\"\n    expval = np.exp(lpr)\n    denom = 1 + np.reshape(expval, (len(expval) // self.ncut, self.ncut)).sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    prob = expval / denom\n    return prob",
        "mutated": [
            "def inverse(self, lpr):\n    if False:\n        i = 10\n    '\\n        Inverse of the multinomial logit transform, which gives the\\n        expected values of the data as a function of the linear\\n        predictors.\\n\\n        Parameters\\n        ----------\\n        lpr : array_like (length must be divisible by `ncut`)\\n            The linear predictors\\n\\n        Returns\\n        -------\\n        prob : ndarray\\n            Probabilities, or expected values\\n        '\n    expval = np.exp(lpr)\n    denom = 1 + np.reshape(expval, (len(expval) // self.ncut, self.ncut)).sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    prob = expval / denom\n    return prob",
            "def inverse(self, lpr):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Inverse of the multinomial logit transform, which gives the\\n        expected values of the data as a function of the linear\\n        predictors.\\n\\n        Parameters\\n        ----------\\n        lpr : array_like (length must be divisible by `ncut`)\\n            The linear predictors\\n\\n        Returns\\n        -------\\n        prob : ndarray\\n            Probabilities, or expected values\\n        '\n    expval = np.exp(lpr)\n    denom = 1 + np.reshape(expval, (len(expval) // self.ncut, self.ncut)).sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    prob = expval / denom\n    return prob",
            "def inverse(self, lpr):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Inverse of the multinomial logit transform, which gives the\\n        expected values of the data as a function of the linear\\n        predictors.\\n\\n        Parameters\\n        ----------\\n        lpr : array_like (length must be divisible by `ncut`)\\n            The linear predictors\\n\\n        Returns\\n        -------\\n        prob : ndarray\\n            Probabilities, or expected values\\n        '\n    expval = np.exp(lpr)\n    denom = 1 + np.reshape(expval, (len(expval) // self.ncut, self.ncut)).sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    prob = expval / denom\n    return prob",
            "def inverse(self, lpr):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Inverse of the multinomial logit transform, which gives the\\n        expected values of the data as a function of the linear\\n        predictors.\\n\\n        Parameters\\n        ----------\\n        lpr : array_like (length must be divisible by `ncut`)\\n            The linear predictors\\n\\n        Returns\\n        -------\\n        prob : ndarray\\n            Probabilities, or expected values\\n        '\n    expval = np.exp(lpr)\n    denom = 1 + np.reshape(expval, (len(expval) // self.ncut, self.ncut)).sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    prob = expval / denom\n    return prob",
            "def inverse(self, lpr):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Inverse of the multinomial logit transform, which gives the\\n        expected values of the data as a function of the linear\\n        predictors.\\n\\n        Parameters\\n        ----------\\n        lpr : array_like (length must be divisible by `ncut`)\\n            The linear predictors\\n\\n        Returns\\n        -------\\n        prob : ndarray\\n            Probabilities, or expected values\\n        '\n    expval = np.exp(lpr)\n    denom = 1 + np.reshape(expval, (len(expval) // self.ncut, self.ncut)).sum(1)\n    denom = np.kron(denom, np.ones(self.ncut, dtype=np.float64))\n    prob = expval / denom\n    return prob"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, nlevels, check_link=True):\n    \"\"\"\n        Parameters\n        ----------\n        nlevels : int\n            The number of distinct categories for the multinomial\n            distribution.\n        \"\"\"\n    self._check_link = check_link\n    self.initialize(nlevels)",
        "mutated": [
            "def __init__(self, nlevels, check_link=True):\n    if False:\n        i = 10\n    '\\n        Parameters\\n        ----------\\n        nlevels : int\\n            The number of distinct categories for the multinomial\\n            distribution.\\n        '\n    self._check_link = check_link\n    self.initialize(nlevels)",
            "def __init__(self, nlevels, check_link=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Parameters\\n        ----------\\n        nlevels : int\\n            The number of distinct categories for the multinomial\\n            distribution.\\n        '\n    self._check_link = check_link\n    self.initialize(nlevels)",
            "def __init__(self, nlevels, check_link=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Parameters\\n        ----------\\n        nlevels : int\\n            The number of distinct categories for the multinomial\\n            distribution.\\n        '\n    self._check_link = check_link\n    self.initialize(nlevels)",
            "def __init__(self, nlevels, check_link=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Parameters\\n        ----------\\n        nlevels : int\\n            The number of distinct categories for the multinomial\\n            distribution.\\n        '\n    self._check_link = check_link\n    self.initialize(nlevels)",
            "def __init__(self, nlevels, check_link=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Parameters\\n        ----------\\n        nlevels : int\\n            The number of distinct categories for the multinomial\\n            distribution.\\n        '\n    self._check_link = check_link\n    self.initialize(nlevels)"
        ]
    },
    {
        "func_name": "initialize",
        "original": "def initialize(self, nlevels):\n    self.ncut = nlevels - 1\n    self.link = _MultinomialLogit(self.ncut)",
        "mutated": [
            "def initialize(self, nlevels):\n    if False:\n        i = 10\n    self.ncut = nlevels - 1\n    self.link = _MultinomialLogit(self.ncut)",
            "def initialize(self, nlevels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.ncut = nlevels - 1\n    self.link = _MultinomialLogit(self.ncut)",
            "def initialize(self, nlevels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.ncut = nlevels - 1\n    self.link = _MultinomialLogit(self.ncut)",
            "def initialize(self, nlevels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.ncut = nlevels - 1\n    self.link = _MultinomialLogit(self.ncut)",
            "def initialize(self, nlevels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.ncut = nlevels - 1\n    self.link = _MultinomialLogit(self.ncut)"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, results, args, kwargs={}):\n    self._cache = {}\n    self.results = results\n    self.get_margeff(*args, **kwargs)",
        "mutated": [
            "def __init__(self, results, args, kwargs={}):\n    if False:\n        i = 10\n    self._cache = {}\n    self.results = results\n    self.get_margeff(*args, **kwargs)",
            "def __init__(self, results, args, kwargs={}):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self._cache = {}\n    self.results = results\n    self.get_margeff(*args, **kwargs)",
            "def __init__(self, results, args, kwargs={}):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self._cache = {}\n    self.results = results\n    self.get_margeff(*args, **kwargs)",
            "def __init__(self, results, args, kwargs={}):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self._cache = {}\n    self.results = results\n    self.get_margeff(*args, **kwargs)",
            "def __init__(self, results, args, kwargs={}):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self._cache = {}\n    self.results = results\n    self.get_margeff(*args, **kwargs)"
        ]
    },
    {
        "func_name": "_reset",
        "original": "def _reset(self):\n    self._cache = {}",
        "mutated": [
            "def _reset(self):\n    if False:\n        i = 10\n    self._cache = {}",
            "def _reset(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self._cache = {}",
            "def _reset(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self._cache = {}",
            "def _reset(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self._cache = {}",
            "def _reset(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self._cache = {}"
        ]
    },
    {
        "func_name": "tvalues",
        "original": "@cache_readonly\ndef tvalues(self):\n    _check_at_is_all(self.margeff_options)\n    return self.margeff / self.margeff_se",
        "mutated": [
            "@cache_readonly\ndef tvalues(self):\n    if False:\n        i = 10\n    _check_at_is_all(self.margeff_options)\n    return self.margeff / self.margeff_se",
            "@cache_readonly\ndef tvalues(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    _check_at_is_all(self.margeff_options)\n    return self.margeff / self.margeff_se",
            "@cache_readonly\ndef tvalues(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    _check_at_is_all(self.margeff_options)\n    return self.margeff / self.margeff_se",
            "@cache_readonly\ndef tvalues(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    _check_at_is_all(self.margeff_options)\n    return self.margeff / self.margeff_se",
            "@cache_readonly\ndef tvalues(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    _check_at_is_all(self.margeff_options)\n    return self.margeff / self.margeff_se"
        ]
    },
    {
        "func_name": "summary_frame",
        "original": "def summary_frame(self, alpha=0.05):\n    \"\"\"\n        Returns a DataFrame summarizing the marginal effects.\n\n        Parameters\n        ----------\n        alpha : float\n            Number between 0 and 1. The confidence intervals have the\n            probability 1-alpha.\n\n        Returns\n        -------\n        frame : DataFrames\n            A DataFrame summarizing the marginal effects.\n        \"\"\"\n    _check_at_is_all(self.margeff_options)\n    from pandas import DataFrame\n    names = [_transform_names[self.margeff_options['method']], 'Std. Err.', 'z', 'Pr(>|z|)', 'Conf. Int. Low', 'Cont. Int. Hi.']\n    ind = self.results.model.exog.var(0) != 0\n    exog_names = self.results.model.exog_names\n    var_names = [name for (i, name) in enumerate(exog_names) if ind[i]]\n    table = np.column_stack((self.margeff, self.margeff_se, self.tvalues, self.pvalues, self.conf_int(alpha)))\n    return DataFrame(table, columns=names, index=var_names)",
        "mutated": [
            "def summary_frame(self, alpha=0.05):\n    if False:\n        i = 10\n    '\\n        Returns a DataFrame summarizing the marginal effects.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            Number between 0 and 1. The confidence intervals have the\\n            probability 1-alpha.\\n\\n        Returns\\n        -------\\n        frame : DataFrames\\n            A DataFrame summarizing the marginal effects.\\n        '\n    _check_at_is_all(self.margeff_options)\n    from pandas import DataFrame\n    names = [_transform_names[self.margeff_options['method']], 'Std. Err.', 'z', 'Pr(>|z|)', 'Conf. Int. Low', 'Cont. Int. Hi.']\n    ind = self.results.model.exog.var(0) != 0\n    exog_names = self.results.model.exog_names\n    var_names = [name for (i, name) in enumerate(exog_names) if ind[i]]\n    table = np.column_stack((self.margeff, self.margeff_se, self.tvalues, self.pvalues, self.conf_int(alpha)))\n    return DataFrame(table, columns=names, index=var_names)",
            "def summary_frame(self, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns a DataFrame summarizing the marginal effects.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            Number between 0 and 1. The confidence intervals have the\\n            probability 1-alpha.\\n\\n        Returns\\n        -------\\n        frame : DataFrames\\n            A DataFrame summarizing the marginal effects.\\n        '\n    _check_at_is_all(self.margeff_options)\n    from pandas import DataFrame\n    names = [_transform_names[self.margeff_options['method']], 'Std. Err.', 'z', 'Pr(>|z|)', 'Conf. Int. Low', 'Cont. Int. Hi.']\n    ind = self.results.model.exog.var(0) != 0\n    exog_names = self.results.model.exog_names\n    var_names = [name for (i, name) in enumerate(exog_names) if ind[i]]\n    table = np.column_stack((self.margeff, self.margeff_se, self.tvalues, self.pvalues, self.conf_int(alpha)))\n    return DataFrame(table, columns=names, index=var_names)",
            "def summary_frame(self, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns a DataFrame summarizing the marginal effects.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            Number between 0 and 1. The confidence intervals have the\\n            probability 1-alpha.\\n\\n        Returns\\n        -------\\n        frame : DataFrames\\n            A DataFrame summarizing the marginal effects.\\n        '\n    _check_at_is_all(self.margeff_options)\n    from pandas import DataFrame\n    names = [_transform_names[self.margeff_options['method']], 'Std. Err.', 'z', 'Pr(>|z|)', 'Conf. Int. Low', 'Cont. Int. Hi.']\n    ind = self.results.model.exog.var(0) != 0\n    exog_names = self.results.model.exog_names\n    var_names = [name for (i, name) in enumerate(exog_names) if ind[i]]\n    table = np.column_stack((self.margeff, self.margeff_se, self.tvalues, self.pvalues, self.conf_int(alpha)))\n    return DataFrame(table, columns=names, index=var_names)",
            "def summary_frame(self, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns a DataFrame summarizing the marginal effects.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            Number between 0 and 1. The confidence intervals have the\\n            probability 1-alpha.\\n\\n        Returns\\n        -------\\n        frame : DataFrames\\n            A DataFrame summarizing the marginal effects.\\n        '\n    _check_at_is_all(self.margeff_options)\n    from pandas import DataFrame\n    names = [_transform_names[self.margeff_options['method']], 'Std. Err.', 'z', 'Pr(>|z|)', 'Conf. Int. Low', 'Cont. Int. Hi.']\n    ind = self.results.model.exog.var(0) != 0\n    exog_names = self.results.model.exog_names\n    var_names = [name for (i, name) in enumerate(exog_names) if ind[i]]\n    table = np.column_stack((self.margeff, self.margeff_se, self.tvalues, self.pvalues, self.conf_int(alpha)))\n    return DataFrame(table, columns=names, index=var_names)",
            "def summary_frame(self, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns a DataFrame summarizing the marginal effects.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            Number between 0 and 1. The confidence intervals have the\\n            probability 1-alpha.\\n\\n        Returns\\n        -------\\n        frame : DataFrames\\n            A DataFrame summarizing the marginal effects.\\n        '\n    _check_at_is_all(self.margeff_options)\n    from pandas import DataFrame\n    names = [_transform_names[self.margeff_options['method']], 'Std. Err.', 'z', 'Pr(>|z|)', 'Conf. Int. Low', 'Cont. Int. Hi.']\n    ind = self.results.model.exog.var(0) != 0\n    exog_names = self.results.model.exog_names\n    var_names = [name for (i, name) in enumerate(exog_names) if ind[i]]\n    table = np.column_stack((self.margeff, self.margeff_se, self.tvalues, self.pvalues, self.conf_int(alpha)))\n    return DataFrame(table, columns=names, index=var_names)"
        ]
    },
    {
        "func_name": "pvalues",
        "original": "@cache_readonly\ndef pvalues(self):\n    _check_at_is_all(self.margeff_options)\n    return stats.norm.sf(np.abs(self.tvalues)) * 2",
        "mutated": [
            "@cache_readonly\ndef pvalues(self):\n    if False:\n        i = 10\n    _check_at_is_all(self.margeff_options)\n    return stats.norm.sf(np.abs(self.tvalues)) * 2",
            "@cache_readonly\ndef pvalues(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    _check_at_is_all(self.margeff_options)\n    return stats.norm.sf(np.abs(self.tvalues)) * 2",
            "@cache_readonly\ndef pvalues(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    _check_at_is_all(self.margeff_options)\n    return stats.norm.sf(np.abs(self.tvalues)) * 2",
            "@cache_readonly\ndef pvalues(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    _check_at_is_all(self.margeff_options)\n    return stats.norm.sf(np.abs(self.tvalues)) * 2",
            "@cache_readonly\ndef pvalues(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    _check_at_is_all(self.margeff_options)\n    return stats.norm.sf(np.abs(self.tvalues)) * 2"
        ]
    },
    {
        "func_name": "conf_int",
        "original": "def conf_int(self, alpha=0.05):\n    \"\"\"\n        Returns the confidence intervals of the marginal effects\n\n        Parameters\n        ----------\n        alpha : float\n            Number between 0 and 1. The confidence intervals have the\n            probability 1-alpha.\n\n        Returns\n        -------\n        conf_int : ndarray\n            An array with lower, upper confidence intervals for the marginal\n            effects.\n        \"\"\"\n    _check_at_is_all(self.margeff_options)\n    me_se = self.margeff_se\n    q = stats.norm.ppf(1 - alpha / 2)\n    lower = self.margeff - q * me_se\n    upper = self.margeff + q * me_se\n    return np.asarray(lzip(lower, upper))",
        "mutated": [
            "def conf_int(self, alpha=0.05):\n    if False:\n        i = 10\n    '\\n        Returns the confidence intervals of the marginal effects\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            Number between 0 and 1. The confidence intervals have the\\n            probability 1-alpha.\\n\\n        Returns\\n        -------\\n        conf_int : ndarray\\n            An array with lower, upper confidence intervals for the marginal\\n            effects.\\n        '\n    _check_at_is_all(self.margeff_options)\n    me_se = self.margeff_se\n    q = stats.norm.ppf(1 - alpha / 2)\n    lower = self.margeff - q * me_se\n    upper = self.margeff + q * me_se\n    return np.asarray(lzip(lower, upper))",
            "def conf_int(self, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns the confidence intervals of the marginal effects\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            Number between 0 and 1. The confidence intervals have the\\n            probability 1-alpha.\\n\\n        Returns\\n        -------\\n        conf_int : ndarray\\n            An array with lower, upper confidence intervals for the marginal\\n            effects.\\n        '\n    _check_at_is_all(self.margeff_options)\n    me_se = self.margeff_se\n    q = stats.norm.ppf(1 - alpha / 2)\n    lower = self.margeff - q * me_se\n    upper = self.margeff + q * me_se\n    return np.asarray(lzip(lower, upper))",
            "def conf_int(self, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns the confidence intervals of the marginal effects\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            Number between 0 and 1. The confidence intervals have the\\n            probability 1-alpha.\\n\\n        Returns\\n        -------\\n        conf_int : ndarray\\n            An array with lower, upper confidence intervals for the marginal\\n            effects.\\n        '\n    _check_at_is_all(self.margeff_options)\n    me_se = self.margeff_se\n    q = stats.norm.ppf(1 - alpha / 2)\n    lower = self.margeff - q * me_se\n    upper = self.margeff + q * me_se\n    return np.asarray(lzip(lower, upper))",
            "def conf_int(self, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns the confidence intervals of the marginal effects\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            Number between 0 and 1. The confidence intervals have the\\n            probability 1-alpha.\\n\\n        Returns\\n        -------\\n        conf_int : ndarray\\n            An array with lower, upper confidence intervals for the marginal\\n            effects.\\n        '\n    _check_at_is_all(self.margeff_options)\n    me_se = self.margeff_se\n    q = stats.norm.ppf(1 - alpha / 2)\n    lower = self.margeff - q * me_se\n    upper = self.margeff + q * me_se\n    return np.asarray(lzip(lower, upper))",
            "def conf_int(self, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns the confidence intervals of the marginal effects\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            Number between 0 and 1. The confidence intervals have the\\n            probability 1-alpha.\\n\\n        Returns\\n        -------\\n        conf_int : ndarray\\n            An array with lower, upper confidence intervals for the marginal\\n            effects.\\n        '\n    _check_at_is_all(self.margeff_options)\n    me_se = self.margeff_se\n    q = stats.norm.ppf(1 - alpha / 2)\n    lower = self.margeff - q * me_se\n    upper = self.margeff + q * me_se\n    return np.asarray(lzip(lower, upper))"
        ]
    },
    {
        "func_name": "summary",
        "original": "def summary(self, alpha=0.05):\n    \"\"\"\n        Returns a summary table for marginal effects\n\n        Parameters\n        ----------\n        alpha : float\n            Number between 0 and 1. The confidence intervals have the\n            probability 1-alpha.\n\n        Returns\n        -------\n        Summary : SummaryTable\n            A SummaryTable instance\n        \"\"\"\n    _check_at_is_all(self.margeff_options)\n    results = self.results\n    model = results.model\n    title = model.__class__.__name__ + ' Marginal Effects'\n    method = self.margeff_options['method']\n    top_left = [('Dep. Variable:', [model.endog_names]), ('Method:', [method]), ('At:', [self.margeff_options['at']])]\n    from statsmodels.iolib.summary import Summary, summary_params, table_extend\n    exog_names = model.exog_names[:]\n    smry = Summary()\n    const_idx = model.data.const_idx\n    if const_idx is not None:\n        exog_names.pop(const_idx)\n    J = int(getattr(model, 'J', 1))\n    if J > 1:\n        (yname, yname_list) = results._get_endog_name(model.endog_names, None, all=True)\n    else:\n        yname = model.endog_names\n        yname_list = [yname]\n    smry.add_table_2cols(self, gleft=top_left, gright=[], yname=yname, xname=exog_names, title=title)\n    table = []\n    conf_int = self.conf_int(alpha)\n    margeff = self.margeff\n    margeff_se = self.margeff_se\n    tvalues = self.tvalues\n    pvalues = self.pvalues\n    if J > 1:\n        for eq in range(J):\n            restup = (results, margeff[:, eq], margeff_se[:, eq], tvalues[:, eq], pvalues[:, eq], conf_int[:, :, eq])\n            tble = summary_params(restup, yname=yname_list[eq], xname=exog_names, alpha=alpha, use_t=False, skip_header=True)\n            tble.title = yname_list[eq]\n            header = ['', _transform_names[method], 'std err', 'z', 'P>|z|', '[%3.1f%% Conf. Int.]' % (100 - alpha * 100)]\n            tble.insert_header_row(0, header)\n            table.append(tble)\n        table = table_extend(table, keep_headers=True)\n    else:\n        restup = (results, margeff, margeff_se, tvalues, pvalues, conf_int)\n        table = summary_params(restup, yname=yname, xname=exog_names, alpha=alpha, use_t=False, skip_header=True)\n        header = ['', _transform_names[method], 'std err', 'z', 'P>|z|', '[%3.1f%% Conf. Int.]' % (100 - alpha * 100)]\n        table.insert_header_row(0, header)\n    smry.tables.append(table)\n    return smry",
        "mutated": [
            "def summary(self, alpha=0.05):\n    if False:\n        i = 10\n    '\\n        Returns a summary table for marginal effects\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            Number between 0 and 1. The confidence intervals have the\\n            probability 1-alpha.\\n\\n        Returns\\n        -------\\n        Summary : SummaryTable\\n            A SummaryTable instance\\n        '\n    _check_at_is_all(self.margeff_options)\n    results = self.results\n    model = results.model\n    title = model.__class__.__name__ + ' Marginal Effects'\n    method = self.margeff_options['method']\n    top_left = [('Dep. Variable:', [model.endog_names]), ('Method:', [method]), ('At:', [self.margeff_options['at']])]\n    from statsmodels.iolib.summary import Summary, summary_params, table_extend\n    exog_names = model.exog_names[:]\n    smry = Summary()\n    const_idx = model.data.const_idx\n    if const_idx is not None:\n        exog_names.pop(const_idx)\n    J = int(getattr(model, 'J', 1))\n    if J > 1:\n        (yname, yname_list) = results._get_endog_name(model.endog_names, None, all=True)\n    else:\n        yname = model.endog_names\n        yname_list = [yname]\n    smry.add_table_2cols(self, gleft=top_left, gright=[], yname=yname, xname=exog_names, title=title)\n    table = []\n    conf_int = self.conf_int(alpha)\n    margeff = self.margeff\n    margeff_se = self.margeff_se\n    tvalues = self.tvalues\n    pvalues = self.pvalues\n    if J > 1:\n        for eq in range(J):\n            restup = (results, margeff[:, eq], margeff_se[:, eq], tvalues[:, eq], pvalues[:, eq], conf_int[:, :, eq])\n            tble = summary_params(restup, yname=yname_list[eq], xname=exog_names, alpha=alpha, use_t=False, skip_header=True)\n            tble.title = yname_list[eq]\n            header = ['', _transform_names[method], 'std err', 'z', 'P>|z|', '[%3.1f%% Conf. Int.]' % (100 - alpha * 100)]\n            tble.insert_header_row(0, header)\n            table.append(tble)\n        table = table_extend(table, keep_headers=True)\n    else:\n        restup = (results, margeff, margeff_se, tvalues, pvalues, conf_int)\n        table = summary_params(restup, yname=yname, xname=exog_names, alpha=alpha, use_t=False, skip_header=True)\n        header = ['', _transform_names[method], 'std err', 'z', 'P>|z|', '[%3.1f%% Conf. Int.]' % (100 - alpha * 100)]\n        table.insert_header_row(0, header)\n    smry.tables.append(table)\n    return smry",
            "def summary(self, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns a summary table for marginal effects\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            Number between 0 and 1. The confidence intervals have the\\n            probability 1-alpha.\\n\\n        Returns\\n        -------\\n        Summary : SummaryTable\\n            A SummaryTable instance\\n        '\n    _check_at_is_all(self.margeff_options)\n    results = self.results\n    model = results.model\n    title = model.__class__.__name__ + ' Marginal Effects'\n    method = self.margeff_options['method']\n    top_left = [('Dep. Variable:', [model.endog_names]), ('Method:', [method]), ('At:', [self.margeff_options['at']])]\n    from statsmodels.iolib.summary import Summary, summary_params, table_extend\n    exog_names = model.exog_names[:]\n    smry = Summary()\n    const_idx = model.data.const_idx\n    if const_idx is not None:\n        exog_names.pop(const_idx)\n    J = int(getattr(model, 'J', 1))\n    if J > 1:\n        (yname, yname_list) = results._get_endog_name(model.endog_names, None, all=True)\n    else:\n        yname = model.endog_names\n        yname_list = [yname]\n    smry.add_table_2cols(self, gleft=top_left, gright=[], yname=yname, xname=exog_names, title=title)\n    table = []\n    conf_int = self.conf_int(alpha)\n    margeff = self.margeff\n    margeff_se = self.margeff_se\n    tvalues = self.tvalues\n    pvalues = self.pvalues\n    if J > 1:\n        for eq in range(J):\n            restup = (results, margeff[:, eq], margeff_se[:, eq], tvalues[:, eq], pvalues[:, eq], conf_int[:, :, eq])\n            tble = summary_params(restup, yname=yname_list[eq], xname=exog_names, alpha=alpha, use_t=False, skip_header=True)\n            tble.title = yname_list[eq]\n            header = ['', _transform_names[method], 'std err', 'z', 'P>|z|', '[%3.1f%% Conf. Int.]' % (100 - alpha * 100)]\n            tble.insert_header_row(0, header)\n            table.append(tble)\n        table = table_extend(table, keep_headers=True)\n    else:\n        restup = (results, margeff, margeff_se, tvalues, pvalues, conf_int)\n        table = summary_params(restup, yname=yname, xname=exog_names, alpha=alpha, use_t=False, skip_header=True)\n        header = ['', _transform_names[method], 'std err', 'z', 'P>|z|', '[%3.1f%% Conf. Int.]' % (100 - alpha * 100)]\n        table.insert_header_row(0, header)\n    smry.tables.append(table)\n    return smry",
            "def summary(self, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns a summary table for marginal effects\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            Number between 0 and 1. The confidence intervals have the\\n            probability 1-alpha.\\n\\n        Returns\\n        -------\\n        Summary : SummaryTable\\n            A SummaryTable instance\\n        '\n    _check_at_is_all(self.margeff_options)\n    results = self.results\n    model = results.model\n    title = model.__class__.__name__ + ' Marginal Effects'\n    method = self.margeff_options['method']\n    top_left = [('Dep. Variable:', [model.endog_names]), ('Method:', [method]), ('At:', [self.margeff_options['at']])]\n    from statsmodels.iolib.summary import Summary, summary_params, table_extend\n    exog_names = model.exog_names[:]\n    smry = Summary()\n    const_idx = model.data.const_idx\n    if const_idx is not None:\n        exog_names.pop(const_idx)\n    J = int(getattr(model, 'J', 1))\n    if J > 1:\n        (yname, yname_list) = results._get_endog_name(model.endog_names, None, all=True)\n    else:\n        yname = model.endog_names\n        yname_list = [yname]\n    smry.add_table_2cols(self, gleft=top_left, gright=[], yname=yname, xname=exog_names, title=title)\n    table = []\n    conf_int = self.conf_int(alpha)\n    margeff = self.margeff\n    margeff_se = self.margeff_se\n    tvalues = self.tvalues\n    pvalues = self.pvalues\n    if J > 1:\n        for eq in range(J):\n            restup = (results, margeff[:, eq], margeff_se[:, eq], tvalues[:, eq], pvalues[:, eq], conf_int[:, :, eq])\n            tble = summary_params(restup, yname=yname_list[eq], xname=exog_names, alpha=alpha, use_t=False, skip_header=True)\n            tble.title = yname_list[eq]\n            header = ['', _transform_names[method], 'std err', 'z', 'P>|z|', '[%3.1f%% Conf. Int.]' % (100 - alpha * 100)]\n            tble.insert_header_row(0, header)\n            table.append(tble)\n        table = table_extend(table, keep_headers=True)\n    else:\n        restup = (results, margeff, margeff_se, tvalues, pvalues, conf_int)\n        table = summary_params(restup, yname=yname, xname=exog_names, alpha=alpha, use_t=False, skip_header=True)\n        header = ['', _transform_names[method], 'std err', 'z', 'P>|z|', '[%3.1f%% Conf. Int.]' % (100 - alpha * 100)]\n        table.insert_header_row(0, header)\n    smry.tables.append(table)\n    return smry",
            "def summary(self, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns a summary table for marginal effects\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            Number between 0 and 1. The confidence intervals have the\\n            probability 1-alpha.\\n\\n        Returns\\n        -------\\n        Summary : SummaryTable\\n            A SummaryTable instance\\n        '\n    _check_at_is_all(self.margeff_options)\n    results = self.results\n    model = results.model\n    title = model.__class__.__name__ + ' Marginal Effects'\n    method = self.margeff_options['method']\n    top_left = [('Dep. Variable:', [model.endog_names]), ('Method:', [method]), ('At:', [self.margeff_options['at']])]\n    from statsmodels.iolib.summary import Summary, summary_params, table_extend\n    exog_names = model.exog_names[:]\n    smry = Summary()\n    const_idx = model.data.const_idx\n    if const_idx is not None:\n        exog_names.pop(const_idx)\n    J = int(getattr(model, 'J', 1))\n    if J > 1:\n        (yname, yname_list) = results._get_endog_name(model.endog_names, None, all=True)\n    else:\n        yname = model.endog_names\n        yname_list = [yname]\n    smry.add_table_2cols(self, gleft=top_left, gright=[], yname=yname, xname=exog_names, title=title)\n    table = []\n    conf_int = self.conf_int(alpha)\n    margeff = self.margeff\n    margeff_se = self.margeff_se\n    tvalues = self.tvalues\n    pvalues = self.pvalues\n    if J > 1:\n        for eq in range(J):\n            restup = (results, margeff[:, eq], margeff_se[:, eq], tvalues[:, eq], pvalues[:, eq], conf_int[:, :, eq])\n            tble = summary_params(restup, yname=yname_list[eq], xname=exog_names, alpha=alpha, use_t=False, skip_header=True)\n            tble.title = yname_list[eq]\n            header = ['', _transform_names[method], 'std err', 'z', 'P>|z|', '[%3.1f%% Conf. Int.]' % (100 - alpha * 100)]\n            tble.insert_header_row(0, header)\n            table.append(tble)\n        table = table_extend(table, keep_headers=True)\n    else:\n        restup = (results, margeff, margeff_se, tvalues, pvalues, conf_int)\n        table = summary_params(restup, yname=yname, xname=exog_names, alpha=alpha, use_t=False, skip_header=True)\n        header = ['', _transform_names[method], 'std err', 'z', 'P>|z|', '[%3.1f%% Conf. Int.]' % (100 - alpha * 100)]\n        table.insert_header_row(0, header)\n    smry.tables.append(table)\n    return smry",
            "def summary(self, alpha=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns a summary table for marginal effects\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            Number between 0 and 1. The confidence intervals have the\\n            probability 1-alpha.\\n\\n        Returns\\n        -------\\n        Summary : SummaryTable\\n            A SummaryTable instance\\n        '\n    _check_at_is_all(self.margeff_options)\n    results = self.results\n    model = results.model\n    title = model.__class__.__name__ + ' Marginal Effects'\n    method = self.margeff_options['method']\n    top_left = [('Dep. Variable:', [model.endog_names]), ('Method:', [method]), ('At:', [self.margeff_options['at']])]\n    from statsmodels.iolib.summary import Summary, summary_params, table_extend\n    exog_names = model.exog_names[:]\n    smry = Summary()\n    const_idx = model.data.const_idx\n    if const_idx is not None:\n        exog_names.pop(const_idx)\n    J = int(getattr(model, 'J', 1))\n    if J > 1:\n        (yname, yname_list) = results._get_endog_name(model.endog_names, None, all=True)\n    else:\n        yname = model.endog_names\n        yname_list = [yname]\n    smry.add_table_2cols(self, gleft=top_left, gright=[], yname=yname, xname=exog_names, title=title)\n    table = []\n    conf_int = self.conf_int(alpha)\n    margeff = self.margeff\n    margeff_se = self.margeff_se\n    tvalues = self.tvalues\n    pvalues = self.pvalues\n    if J > 1:\n        for eq in range(J):\n            restup = (results, margeff[:, eq], margeff_se[:, eq], tvalues[:, eq], pvalues[:, eq], conf_int[:, :, eq])\n            tble = summary_params(restup, yname=yname_list[eq], xname=exog_names, alpha=alpha, use_t=False, skip_header=True)\n            tble.title = yname_list[eq]\n            header = ['', _transform_names[method], 'std err', 'z', 'P>|z|', '[%3.1f%% Conf. Int.]' % (100 - alpha * 100)]\n            tble.insert_header_row(0, header)\n            table.append(tble)\n        table = table_extend(table, keep_headers=True)\n    else:\n        restup = (results, margeff, margeff_se, tvalues, pvalues, conf_int)\n        table = summary_params(restup, yname=yname, xname=exog_names, alpha=alpha, use_t=False, skip_header=True)\n        header = ['', _transform_names[method], 'std err', 'z', 'P>|z|', '[%3.1f%% Conf. Int.]' % (100 - alpha * 100)]\n        table.insert_header_row(0, header)\n    smry.tables.append(table)\n    return smry"
        ]
    },
    {
        "func_name": "get_margeff",
        "original": "def get_margeff(self, at='overall', method='dydx', atexog=None, dummy=False, count=False):\n    self._reset()\n    method = method.lower()\n    at = at.lower()\n    _check_margeff_args(at, method)\n    self.margeff_options = dict(method=method, at=at)\n    results = self.results\n    model = results.model\n    params = results.params\n    exog = model.exog.copy()\n    effects_idx = exog.var(0) != 0\n    const_idx = model.data.const_idx\n    if dummy:\n        _check_discrete_args(at, method)\n        (dummy_idx, dummy) = _get_dummy_index(exog, const_idx)\n    else:\n        dummy_idx = None\n    if count:\n        _check_discrete_args(at, method)\n        (count_idx, count) = _get_count_index(exog, const_idx)\n    else:\n        count_idx = None\n    exog = _get_margeff_exog(exog, at, atexog, effects_idx)\n    effects = model._derivative_exog(params, exog, method, dummy_idx, count_idx)\n    effects = _effects_at(effects, at)\n    if at == 'all':\n        self.margeff = effects[:, effects_idx]\n    else:\n        (margeff_cov, margeff_se) = margeff_cov_with_se(model, params, exog, results.cov_params(), at, model._derivative_exog, dummy_idx, count_idx, method, 1)\n        self.margeff_cov = margeff_cov[effects_idx][:, effects_idx]\n        self.margeff_se = margeff_se[effects_idx]\n        self.margeff = effects[effects_idx]",
        "mutated": [
            "def get_margeff(self, at='overall', method='dydx', atexog=None, dummy=False, count=False):\n    if False:\n        i = 10\n    self._reset()\n    method = method.lower()\n    at = at.lower()\n    _check_margeff_args(at, method)\n    self.margeff_options = dict(method=method, at=at)\n    results = self.results\n    model = results.model\n    params = results.params\n    exog = model.exog.copy()\n    effects_idx = exog.var(0) != 0\n    const_idx = model.data.const_idx\n    if dummy:\n        _check_discrete_args(at, method)\n        (dummy_idx, dummy) = _get_dummy_index(exog, const_idx)\n    else:\n        dummy_idx = None\n    if count:\n        _check_discrete_args(at, method)\n        (count_idx, count) = _get_count_index(exog, const_idx)\n    else:\n        count_idx = None\n    exog = _get_margeff_exog(exog, at, atexog, effects_idx)\n    effects = model._derivative_exog(params, exog, method, dummy_idx, count_idx)\n    effects = _effects_at(effects, at)\n    if at == 'all':\n        self.margeff = effects[:, effects_idx]\n    else:\n        (margeff_cov, margeff_se) = margeff_cov_with_se(model, params, exog, results.cov_params(), at, model._derivative_exog, dummy_idx, count_idx, method, 1)\n        self.margeff_cov = margeff_cov[effects_idx][:, effects_idx]\n        self.margeff_se = margeff_se[effects_idx]\n        self.margeff = effects[effects_idx]",
            "def get_margeff(self, at='overall', method='dydx', atexog=None, dummy=False, count=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self._reset()\n    method = method.lower()\n    at = at.lower()\n    _check_margeff_args(at, method)\n    self.margeff_options = dict(method=method, at=at)\n    results = self.results\n    model = results.model\n    params = results.params\n    exog = model.exog.copy()\n    effects_idx = exog.var(0) != 0\n    const_idx = model.data.const_idx\n    if dummy:\n        _check_discrete_args(at, method)\n        (dummy_idx, dummy) = _get_dummy_index(exog, const_idx)\n    else:\n        dummy_idx = None\n    if count:\n        _check_discrete_args(at, method)\n        (count_idx, count) = _get_count_index(exog, const_idx)\n    else:\n        count_idx = None\n    exog = _get_margeff_exog(exog, at, atexog, effects_idx)\n    effects = model._derivative_exog(params, exog, method, dummy_idx, count_idx)\n    effects = _effects_at(effects, at)\n    if at == 'all':\n        self.margeff = effects[:, effects_idx]\n    else:\n        (margeff_cov, margeff_se) = margeff_cov_with_se(model, params, exog, results.cov_params(), at, model._derivative_exog, dummy_idx, count_idx, method, 1)\n        self.margeff_cov = margeff_cov[effects_idx][:, effects_idx]\n        self.margeff_se = margeff_se[effects_idx]\n        self.margeff = effects[effects_idx]",
            "def get_margeff(self, at='overall', method='dydx', atexog=None, dummy=False, count=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self._reset()\n    method = method.lower()\n    at = at.lower()\n    _check_margeff_args(at, method)\n    self.margeff_options = dict(method=method, at=at)\n    results = self.results\n    model = results.model\n    params = results.params\n    exog = model.exog.copy()\n    effects_idx = exog.var(0) != 0\n    const_idx = model.data.const_idx\n    if dummy:\n        _check_discrete_args(at, method)\n        (dummy_idx, dummy) = _get_dummy_index(exog, const_idx)\n    else:\n        dummy_idx = None\n    if count:\n        _check_discrete_args(at, method)\n        (count_idx, count) = _get_count_index(exog, const_idx)\n    else:\n        count_idx = None\n    exog = _get_margeff_exog(exog, at, atexog, effects_idx)\n    effects = model._derivative_exog(params, exog, method, dummy_idx, count_idx)\n    effects = _effects_at(effects, at)\n    if at == 'all':\n        self.margeff = effects[:, effects_idx]\n    else:\n        (margeff_cov, margeff_se) = margeff_cov_with_se(model, params, exog, results.cov_params(), at, model._derivative_exog, dummy_idx, count_idx, method, 1)\n        self.margeff_cov = margeff_cov[effects_idx][:, effects_idx]\n        self.margeff_se = margeff_se[effects_idx]\n        self.margeff = effects[effects_idx]",
            "def get_margeff(self, at='overall', method='dydx', atexog=None, dummy=False, count=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self._reset()\n    method = method.lower()\n    at = at.lower()\n    _check_margeff_args(at, method)\n    self.margeff_options = dict(method=method, at=at)\n    results = self.results\n    model = results.model\n    params = results.params\n    exog = model.exog.copy()\n    effects_idx = exog.var(0) != 0\n    const_idx = model.data.const_idx\n    if dummy:\n        _check_discrete_args(at, method)\n        (dummy_idx, dummy) = _get_dummy_index(exog, const_idx)\n    else:\n        dummy_idx = None\n    if count:\n        _check_discrete_args(at, method)\n        (count_idx, count) = _get_count_index(exog, const_idx)\n    else:\n        count_idx = None\n    exog = _get_margeff_exog(exog, at, atexog, effects_idx)\n    effects = model._derivative_exog(params, exog, method, dummy_idx, count_idx)\n    effects = _effects_at(effects, at)\n    if at == 'all':\n        self.margeff = effects[:, effects_idx]\n    else:\n        (margeff_cov, margeff_se) = margeff_cov_with_se(model, params, exog, results.cov_params(), at, model._derivative_exog, dummy_idx, count_idx, method, 1)\n        self.margeff_cov = margeff_cov[effects_idx][:, effects_idx]\n        self.margeff_se = margeff_se[effects_idx]\n        self.margeff = effects[effects_idx]",
            "def get_margeff(self, at='overall', method='dydx', atexog=None, dummy=False, count=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self._reset()\n    method = method.lower()\n    at = at.lower()\n    _check_margeff_args(at, method)\n    self.margeff_options = dict(method=method, at=at)\n    results = self.results\n    model = results.model\n    params = results.params\n    exog = model.exog.copy()\n    effects_idx = exog.var(0) != 0\n    const_idx = model.data.const_idx\n    if dummy:\n        _check_discrete_args(at, method)\n        (dummy_idx, dummy) = _get_dummy_index(exog, const_idx)\n    else:\n        dummy_idx = None\n    if count:\n        _check_discrete_args(at, method)\n        (count_idx, count) = _get_count_index(exog, const_idx)\n    else:\n        count_idx = None\n    exog = _get_margeff_exog(exog, at, atexog, effects_idx)\n    effects = model._derivative_exog(params, exog, method, dummy_idx, count_idx)\n    effects = _effects_at(effects, at)\n    if at == 'all':\n        self.margeff = effects[:, effects_idx]\n    else:\n        (margeff_cov, margeff_se) = margeff_cov_with_se(model, params, exog, results.cov_params(), at, model._derivative_exog, dummy_idx, count_idx, method, 1)\n        self.margeff_cov = margeff_cov[effects_idx][:, effects_idx]\n        self.margeff_se = margeff_se[effects_idx]\n        self.margeff = effects[effects_idx]"
        ]
    }
]