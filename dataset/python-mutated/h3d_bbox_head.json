[
    {
        "func_name": "__init__",
        "original": "def __init__(self, num_classes, suface_matching_cfg, line_matching_cfg, bbox_coder, train_cfg=None, test_cfg=None, gt_per_seed=1, num_proposal=256, feat_channels=(128, 128), primitive_feat_refine_streams=2, primitive_refine_channels=[128, 128, 128], upper_thresh=100.0, surface_thresh=0.5, line_thresh=0.5, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, semantic_loss=None, cues_objectness_loss=None, cues_semantic_loss=None, proposal_objectness_loss=None, primitive_center_loss=None, init_cfg=None):\n    super(H3DBboxHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.gt_per_seed = gt_per_seed\n    self.num_proposal = num_proposal\n    self.with_angle = bbox_coder['with_rot']\n    self.upper_thresh = upper_thresh\n    self.surface_thresh = surface_thresh\n    self.line_thresh = line_thresh\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.size_class_loss = build_loss(size_class_loss)\n    self.size_res_loss = build_loss(size_res_loss)\n    self.semantic_loss = build_loss(semantic_loss)\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.cues_objectness_loss = build_loss(cues_objectness_loss)\n    self.cues_semantic_loss = build_loss(cues_semantic_loss)\n    self.proposal_objectness_loss = build_loss(proposal_objectness_loss)\n    self.primitive_center_loss = build_loss(primitive_center_loss)\n    assert suface_matching_cfg['mlp_channels'][-1] == line_matching_cfg['mlp_channels'][-1]\n    self.surface_center_matcher = build_sa_module(suface_matching_cfg)\n    self.line_center_matcher = build_sa_module(line_matching_cfg)\n    matching_feat_dims = suface_matching_cfg['mlp_channels'][-1]\n    self.matching_conv = ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True)\n    self.matching_pred = nn.Conv1d(matching_feat_dims, 2, 1)\n    self.semantic_matching_conv = ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True)\n    self.semantic_matching_pred = nn.Conv1d(matching_feat_dims, 2, 1)\n    self.surface_feats_aggregation = list()\n    for k in range(primitive_feat_refine_streams):\n        self.surface_feats_aggregation.append(ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True))\n    self.surface_feats_aggregation = nn.Sequential(*self.surface_feats_aggregation)\n    self.line_feats_aggregation = list()\n    for k in range(primitive_feat_refine_streams):\n        self.line_feats_aggregation.append(ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True))\n    self.line_feats_aggregation = nn.Sequential(*self.line_feats_aggregation)\n    prev_channel = 18 * matching_feat_dims\n    self.bbox_pred = nn.ModuleList()\n    for k in range(len(primitive_refine_channels)):\n        self.bbox_pred.append(ConvModule(prev_channel, primitive_refine_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=False))\n        prev_channel = primitive_refine_channels[k]\n    conv_out_channel = 2 + 3 + bbox_coder['num_dir_bins'] * 2 + bbox_coder['num_sizes'] * 4 + self.num_classes\n    self.bbox_pred.append(nn.Conv1d(prev_channel, conv_out_channel, 1))",
        "mutated": [
            "def __init__(self, num_classes, suface_matching_cfg, line_matching_cfg, bbox_coder, train_cfg=None, test_cfg=None, gt_per_seed=1, num_proposal=256, feat_channels=(128, 128), primitive_feat_refine_streams=2, primitive_refine_channels=[128, 128, 128], upper_thresh=100.0, surface_thresh=0.5, line_thresh=0.5, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, semantic_loss=None, cues_objectness_loss=None, cues_semantic_loss=None, proposal_objectness_loss=None, primitive_center_loss=None, init_cfg=None):\n    if False:\n        i = 10\n    super(H3DBboxHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.gt_per_seed = gt_per_seed\n    self.num_proposal = num_proposal\n    self.with_angle = bbox_coder['with_rot']\n    self.upper_thresh = upper_thresh\n    self.surface_thresh = surface_thresh\n    self.line_thresh = line_thresh\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.size_class_loss = build_loss(size_class_loss)\n    self.size_res_loss = build_loss(size_res_loss)\n    self.semantic_loss = build_loss(semantic_loss)\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.cues_objectness_loss = build_loss(cues_objectness_loss)\n    self.cues_semantic_loss = build_loss(cues_semantic_loss)\n    self.proposal_objectness_loss = build_loss(proposal_objectness_loss)\n    self.primitive_center_loss = build_loss(primitive_center_loss)\n    assert suface_matching_cfg['mlp_channels'][-1] == line_matching_cfg['mlp_channels'][-1]\n    self.surface_center_matcher = build_sa_module(suface_matching_cfg)\n    self.line_center_matcher = build_sa_module(line_matching_cfg)\n    matching_feat_dims = suface_matching_cfg['mlp_channels'][-1]\n    self.matching_conv = ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True)\n    self.matching_pred = nn.Conv1d(matching_feat_dims, 2, 1)\n    self.semantic_matching_conv = ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True)\n    self.semantic_matching_pred = nn.Conv1d(matching_feat_dims, 2, 1)\n    self.surface_feats_aggregation = list()\n    for k in range(primitive_feat_refine_streams):\n        self.surface_feats_aggregation.append(ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True))\n    self.surface_feats_aggregation = nn.Sequential(*self.surface_feats_aggregation)\n    self.line_feats_aggregation = list()\n    for k in range(primitive_feat_refine_streams):\n        self.line_feats_aggregation.append(ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True))\n    self.line_feats_aggregation = nn.Sequential(*self.line_feats_aggregation)\n    prev_channel = 18 * matching_feat_dims\n    self.bbox_pred = nn.ModuleList()\n    for k in range(len(primitive_refine_channels)):\n        self.bbox_pred.append(ConvModule(prev_channel, primitive_refine_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=False))\n        prev_channel = primitive_refine_channels[k]\n    conv_out_channel = 2 + 3 + bbox_coder['num_dir_bins'] * 2 + bbox_coder['num_sizes'] * 4 + self.num_classes\n    self.bbox_pred.append(nn.Conv1d(prev_channel, conv_out_channel, 1))",
            "def __init__(self, num_classes, suface_matching_cfg, line_matching_cfg, bbox_coder, train_cfg=None, test_cfg=None, gt_per_seed=1, num_proposal=256, feat_channels=(128, 128), primitive_feat_refine_streams=2, primitive_refine_channels=[128, 128, 128], upper_thresh=100.0, surface_thresh=0.5, line_thresh=0.5, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, semantic_loss=None, cues_objectness_loss=None, cues_semantic_loss=None, proposal_objectness_loss=None, primitive_center_loss=None, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super(H3DBboxHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.gt_per_seed = gt_per_seed\n    self.num_proposal = num_proposal\n    self.with_angle = bbox_coder['with_rot']\n    self.upper_thresh = upper_thresh\n    self.surface_thresh = surface_thresh\n    self.line_thresh = line_thresh\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.size_class_loss = build_loss(size_class_loss)\n    self.size_res_loss = build_loss(size_res_loss)\n    self.semantic_loss = build_loss(semantic_loss)\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.cues_objectness_loss = build_loss(cues_objectness_loss)\n    self.cues_semantic_loss = build_loss(cues_semantic_loss)\n    self.proposal_objectness_loss = build_loss(proposal_objectness_loss)\n    self.primitive_center_loss = build_loss(primitive_center_loss)\n    assert suface_matching_cfg['mlp_channels'][-1] == line_matching_cfg['mlp_channels'][-1]\n    self.surface_center_matcher = build_sa_module(suface_matching_cfg)\n    self.line_center_matcher = build_sa_module(line_matching_cfg)\n    matching_feat_dims = suface_matching_cfg['mlp_channels'][-1]\n    self.matching_conv = ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True)\n    self.matching_pred = nn.Conv1d(matching_feat_dims, 2, 1)\n    self.semantic_matching_conv = ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True)\n    self.semantic_matching_pred = nn.Conv1d(matching_feat_dims, 2, 1)\n    self.surface_feats_aggregation = list()\n    for k in range(primitive_feat_refine_streams):\n        self.surface_feats_aggregation.append(ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True))\n    self.surface_feats_aggregation = nn.Sequential(*self.surface_feats_aggregation)\n    self.line_feats_aggregation = list()\n    for k in range(primitive_feat_refine_streams):\n        self.line_feats_aggregation.append(ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True))\n    self.line_feats_aggregation = nn.Sequential(*self.line_feats_aggregation)\n    prev_channel = 18 * matching_feat_dims\n    self.bbox_pred = nn.ModuleList()\n    for k in range(len(primitive_refine_channels)):\n        self.bbox_pred.append(ConvModule(prev_channel, primitive_refine_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=False))\n        prev_channel = primitive_refine_channels[k]\n    conv_out_channel = 2 + 3 + bbox_coder['num_dir_bins'] * 2 + bbox_coder['num_sizes'] * 4 + self.num_classes\n    self.bbox_pred.append(nn.Conv1d(prev_channel, conv_out_channel, 1))",
            "def __init__(self, num_classes, suface_matching_cfg, line_matching_cfg, bbox_coder, train_cfg=None, test_cfg=None, gt_per_seed=1, num_proposal=256, feat_channels=(128, 128), primitive_feat_refine_streams=2, primitive_refine_channels=[128, 128, 128], upper_thresh=100.0, surface_thresh=0.5, line_thresh=0.5, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, semantic_loss=None, cues_objectness_loss=None, cues_semantic_loss=None, proposal_objectness_loss=None, primitive_center_loss=None, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super(H3DBboxHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.gt_per_seed = gt_per_seed\n    self.num_proposal = num_proposal\n    self.with_angle = bbox_coder['with_rot']\n    self.upper_thresh = upper_thresh\n    self.surface_thresh = surface_thresh\n    self.line_thresh = line_thresh\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.size_class_loss = build_loss(size_class_loss)\n    self.size_res_loss = build_loss(size_res_loss)\n    self.semantic_loss = build_loss(semantic_loss)\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.cues_objectness_loss = build_loss(cues_objectness_loss)\n    self.cues_semantic_loss = build_loss(cues_semantic_loss)\n    self.proposal_objectness_loss = build_loss(proposal_objectness_loss)\n    self.primitive_center_loss = build_loss(primitive_center_loss)\n    assert suface_matching_cfg['mlp_channels'][-1] == line_matching_cfg['mlp_channels'][-1]\n    self.surface_center_matcher = build_sa_module(suface_matching_cfg)\n    self.line_center_matcher = build_sa_module(line_matching_cfg)\n    matching_feat_dims = suface_matching_cfg['mlp_channels'][-1]\n    self.matching_conv = ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True)\n    self.matching_pred = nn.Conv1d(matching_feat_dims, 2, 1)\n    self.semantic_matching_conv = ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True)\n    self.semantic_matching_pred = nn.Conv1d(matching_feat_dims, 2, 1)\n    self.surface_feats_aggregation = list()\n    for k in range(primitive_feat_refine_streams):\n        self.surface_feats_aggregation.append(ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True))\n    self.surface_feats_aggregation = nn.Sequential(*self.surface_feats_aggregation)\n    self.line_feats_aggregation = list()\n    for k in range(primitive_feat_refine_streams):\n        self.line_feats_aggregation.append(ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True))\n    self.line_feats_aggregation = nn.Sequential(*self.line_feats_aggregation)\n    prev_channel = 18 * matching_feat_dims\n    self.bbox_pred = nn.ModuleList()\n    for k in range(len(primitive_refine_channels)):\n        self.bbox_pred.append(ConvModule(prev_channel, primitive_refine_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=False))\n        prev_channel = primitive_refine_channels[k]\n    conv_out_channel = 2 + 3 + bbox_coder['num_dir_bins'] * 2 + bbox_coder['num_sizes'] * 4 + self.num_classes\n    self.bbox_pred.append(nn.Conv1d(prev_channel, conv_out_channel, 1))",
            "def __init__(self, num_classes, suface_matching_cfg, line_matching_cfg, bbox_coder, train_cfg=None, test_cfg=None, gt_per_seed=1, num_proposal=256, feat_channels=(128, 128), primitive_feat_refine_streams=2, primitive_refine_channels=[128, 128, 128], upper_thresh=100.0, surface_thresh=0.5, line_thresh=0.5, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, semantic_loss=None, cues_objectness_loss=None, cues_semantic_loss=None, proposal_objectness_loss=None, primitive_center_loss=None, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super(H3DBboxHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.gt_per_seed = gt_per_seed\n    self.num_proposal = num_proposal\n    self.with_angle = bbox_coder['with_rot']\n    self.upper_thresh = upper_thresh\n    self.surface_thresh = surface_thresh\n    self.line_thresh = line_thresh\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.size_class_loss = build_loss(size_class_loss)\n    self.size_res_loss = build_loss(size_res_loss)\n    self.semantic_loss = build_loss(semantic_loss)\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.cues_objectness_loss = build_loss(cues_objectness_loss)\n    self.cues_semantic_loss = build_loss(cues_semantic_loss)\n    self.proposal_objectness_loss = build_loss(proposal_objectness_loss)\n    self.primitive_center_loss = build_loss(primitive_center_loss)\n    assert suface_matching_cfg['mlp_channels'][-1] == line_matching_cfg['mlp_channels'][-1]\n    self.surface_center_matcher = build_sa_module(suface_matching_cfg)\n    self.line_center_matcher = build_sa_module(line_matching_cfg)\n    matching_feat_dims = suface_matching_cfg['mlp_channels'][-1]\n    self.matching_conv = ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True)\n    self.matching_pred = nn.Conv1d(matching_feat_dims, 2, 1)\n    self.semantic_matching_conv = ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True)\n    self.semantic_matching_pred = nn.Conv1d(matching_feat_dims, 2, 1)\n    self.surface_feats_aggregation = list()\n    for k in range(primitive_feat_refine_streams):\n        self.surface_feats_aggregation.append(ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True))\n    self.surface_feats_aggregation = nn.Sequential(*self.surface_feats_aggregation)\n    self.line_feats_aggregation = list()\n    for k in range(primitive_feat_refine_streams):\n        self.line_feats_aggregation.append(ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True))\n    self.line_feats_aggregation = nn.Sequential(*self.line_feats_aggregation)\n    prev_channel = 18 * matching_feat_dims\n    self.bbox_pred = nn.ModuleList()\n    for k in range(len(primitive_refine_channels)):\n        self.bbox_pred.append(ConvModule(prev_channel, primitive_refine_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=False))\n        prev_channel = primitive_refine_channels[k]\n    conv_out_channel = 2 + 3 + bbox_coder['num_dir_bins'] * 2 + bbox_coder['num_sizes'] * 4 + self.num_classes\n    self.bbox_pred.append(nn.Conv1d(prev_channel, conv_out_channel, 1))",
            "def __init__(self, num_classes, suface_matching_cfg, line_matching_cfg, bbox_coder, train_cfg=None, test_cfg=None, gt_per_seed=1, num_proposal=256, feat_channels=(128, 128), primitive_feat_refine_streams=2, primitive_refine_channels=[128, 128, 128], upper_thresh=100.0, surface_thresh=0.5, line_thresh=0.5, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, semantic_loss=None, cues_objectness_loss=None, cues_semantic_loss=None, proposal_objectness_loss=None, primitive_center_loss=None, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super(H3DBboxHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.gt_per_seed = gt_per_seed\n    self.num_proposal = num_proposal\n    self.with_angle = bbox_coder['with_rot']\n    self.upper_thresh = upper_thresh\n    self.surface_thresh = surface_thresh\n    self.line_thresh = line_thresh\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.size_class_loss = build_loss(size_class_loss)\n    self.size_res_loss = build_loss(size_res_loss)\n    self.semantic_loss = build_loss(semantic_loss)\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.cues_objectness_loss = build_loss(cues_objectness_loss)\n    self.cues_semantic_loss = build_loss(cues_semantic_loss)\n    self.proposal_objectness_loss = build_loss(proposal_objectness_loss)\n    self.primitive_center_loss = build_loss(primitive_center_loss)\n    assert suface_matching_cfg['mlp_channels'][-1] == line_matching_cfg['mlp_channels'][-1]\n    self.surface_center_matcher = build_sa_module(suface_matching_cfg)\n    self.line_center_matcher = build_sa_module(line_matching_cfg)\n    matching_feat_dims = suface_matching_cfg['mlp_channels'][-1]\n    self.matching_conv = ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True)\n    self.matching_pred = nn.Conv1d(matching_feat_dims, 2, 1)\n    self.semantic_matching_conv = ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True)\n    self.semantic_matching_pred = nn.Conv1d(matching_feat_dims, 2, 1)\n    self.surface_feats_aggregation = list()\n    for k in range(primitive_feat_refine_streams):\n        self.surface_feats_aggregation.append(ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True))\n    self.surface_feats_aggregation = nn.Sequential(*self.surface_feats_aggregation)\n    self.line_feats_aggregation = list()\n    for k in range(primitive_feat_refine_streams):\n        self.line_feats_aggregation.append(ConvModule(matching_feat_dims, matching_feat_dims, 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=True))\n    self.line_feats_aggregation = nn.Sequential(*self.line_feats_aggregation)\n    prev_channel = 18 * matching_feat_dims\n    self.bbox_pred = nn.ModuleList()\n    for k in range(len(primitive_refine_channels)):\n        self.bbox_pred.append(ConvModule(prev_channel, primitive_refine_channels[k], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg, bias=True, inplace=False))\n        prev_channel = primitive_refine_channels[k]\n    conv_out_channel = 2 + 3 + bbox_coder['num_dir_bins'] * 2 + bbox_coder['num_sizes'] * 4 + self.num_classes\n    self.bbox_pred.append(nn.Conv1d(prev_channel, conv_out_channel, 1))"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, feats_dict, sample_mod):\n    \"\"\"Forward pass.\n\n        Args:\n            feats_dict (dict): Feature dict from backbone.\n            sample_mod (str): Sample mode for vote aggregation layer.\n                valid modes are \"vote\", \"seed\" and \"random\".\n\n        Returns:\n            dict: Predictions of vote head.\n        \"\"\"\n    ret_dict = {}\n    aggregated_points = feats_dict['aggregated_points']\n    original_feature = feats_dict['aggregated_features']\n    batch_size = original_feature.shape[0]\n    object_proposal = original_feature.shape[2]\n    z_center = feats_dict['pred_z_center']\n    xy_center = feats_dict['pred_xy_center']\n    z_semantic = feats_dict['sem_cls_scores_z']\n    xy_semantic = feats_dict['sem_cls_scores_xy']\n    z_feature = feats_dict['aggregated_features_z']\n    xy_feature = feats_dict['aggregated_features_xy']\n    line_center = feats_dict['pred_line_center']\n    line_feature = feats_dict['aggregated_features_line']\n    surface_center_pred = torch.cat((z_center, xy_center), dim=1)\n    ret_dict['surface_center_pred'] = surface_center_pred\n    ret_dict['surface_sem_pred'] = torch.cat((z_semantic, xy_semantic), dim=1)\n    rpn_proposals = feats_dict['proposal_list']\n    rpn_proposals_bbox = DepthInstance3DBoxes(rpn_proposals.reshape(-1, 7).clone(), box_dim=rpn_proposals.shape[-1], with_yaw=self.with_angle, origin=(0.5, 0.5, 0.5))\n    (obj_surface_center, obj_line_center) = rpn_proposals_bbox.get_surface_line_center()\n    obj_surface_center = obj_surface_center.reshape(batch_size, -1, 6, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    obj_line_center = obj_line_center.reshape(batch_size, -1, 12, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    ret_dict['surface_center_object'] = obj_surface_center\n    ret_dict['line_center_object'] = obj_line_center\n    surface_center_feature_pred = torch.cat((z_feature, xy_feature), dim=2)\n    surface_center_feature_pred = torch.cat((surface_center_feature_pred.new_zeros((batch_size, 6, surface_center_feature_pred.shape[2])), surface_center_feature_pred), dim=1)\n    (surface_xyz, surface_features, _) = self.surface_center_matcher(surface_center_pred, surface_center_feature_pred, target_xyz=obj_surface_center)\n    line_feature = torch.cat((line_feature.new_zeros((batch_size, 12, line_feature.shape[2])), line_feature), dim=1)\n    (line_xyz, line_features, _) = self.line_center_matcher(line_center, line_feature, target_xyz=obj_line_center)\n    combine_features = torch.cat((surface_features, line_features), dim=2)\n    matching_features = self.matching_conv(combine_features)\n    matching_score = self.matching_pred(matching_features)\n    ret_dict['matching_score'] = matching_score.transpose(2, 1)\n    semantic_matching_features = self.semantic_matching_conv(combine_features)\n    semantic_matching_score = self.semantic_matching_pred(semantic_matching_features)\n    ret_dict['semantic_matching_score'] = semantic_matching_score.transpose(2, 1)\n    surface_features = self.surface_feats_aggregation(surface_features)\n    line_features = self.line_feats_aggregation(line_features)\n    surface_features = surface_features.view(batch_size, -1, object_proposal)\n    line_features = line_features.view(batch_size, -1, object_proposal)\n    combine_feature = torch.cat((surface_features, line_features), dim=1)\n    bbox_predictions = self.bbox_pred[0](combine_feature)\n    bbox_predictions += original_feature\n    for conv_module in self.bbox_pred[1:]:\n        bbox_predictions = conv_module(bbox_predictions)\n    refine_decode_res = self.bbox_coder.split_pred(bbox_predictions[:, :self.num_classes + 2], bbox_predictions[:, self.num_classes + 2:], aggregated_points)\n    for key in refine_decode_res.keys():\n        ret_dict[key + '_optimized'] = refine_decode_res[key]\n    return ret_dict",
        "mutated": [
            "def forward(self, feats_dict, sample_mod):\n    if False:\n        i = 10\n    'Forward pass.\\n\\n        Args:\\n            feats_dict (dict): Feature dict from backbone.\\n            sample_mod (str): Sample mode for vote aggregation layer.\\n                valid modes are \"vote\", \"seed\" and \"random\".\\n\\n        Returns:\\n            dict: Predictions of vote head.\\n        '\n    ret_dict = {}\n    aggregated_points = feats_dict['aggregated_points']\n    original_feature = feats_dict['aggregated_features']\n    batch_size = original_feature.shape[0]\n    object_proposal = original_feature.shape[2]\n    z_center = feats_dict['pred_z_center']\n    xy_center = feats_dict['pred_xy_center']\n    z_semantic = feats_dict['sem_cls_scores_z']\n    xy_semantic = feats_dict['sem_cls_scores_xy']\n    z_feature = feats_dict['aggregated_features_z']\n    xy_feature = feats_dict['aggregated_features_xy']\n    line_center = feats_dict['pred_line_center']\n    line_feature = feats_dict['aggregated_features_line']\n    surface_center_pred = torch.cat((z_center, xy_center), dim=1)\n    ret_dict['surface_center_pred'] = surface_center_pred\n    ret_dict['surface_sem_pred'] = torch.cat((z_semantic, xy_semantic), dim=1)\n    rpn_proposals = feats_dict['proposal_list']\n    rpn_proposals_bbox = DepthInstance3DBoxes(rpn_proposals.reshape(-1, 7).clone(), box_dim=rpn_proposals.shape[-1], with_yaw=self.with_angle, origin=(0.5, 0.5, 0.5))\n    (obj_surface_center, obj_line_center) = rpn_proposals_bbox.get_surface_line_center()\n    obj_surface_center = obj_surface_center.reshape(batch_size, -1, 6, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    obj_line_center = obj_line_center.reshape(batch_size, -1, 12, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    ret_dict['surface_center_object'] = obj_surface_center\n    ret_dict['line_center_object'] = obj_line_center\n    surface_center_feature_pred = torch.cat((z_feature, xy_feature), dim=2)\n    surface_center_feature_pred = torch.cat((surface_center_feature_pred.new_zeros((batch_size, 6, surface_center_feature_pred.shape[2])), surface_center_feature_pred), dim=1)\n    (surface_xyz, surface_features, _) = self.surface_center_matcher(surface_center_pred, surface_center_feature_pred, target_xyz=obj_surface_center)\n    line_feature = torch.cat((line_feature.new_zeros((batch_size, 12, line_feature.shape[2])), line_feature), dim=1)\n    (line_xyz, line_features, _) = self.line_center_matcher(line_center, line_feature, target_xyz=obj_line_center)\n    combine_features = torch.cat((surface_features, line_features), dim=2)\n    matching_features = self.matching_conv(combine_features)\n    matching_score = self.matching_pred(matching_features)\n    ret_dict['matching_score'] = matching_score.transpose(2, 1)\n    semantic_matching_features = self.semantic_matching_conv(combine_features)\n    semantic_matching_score = self.semantic_matching_pred(semantic_matching_features)\n    ret_dict['semantic_matching_score'] = semantic_matching_score.transpose(2, 1)\n    surface_features = self.surface_feats_aggregation(surface_features)\n    line_features = self.line_feats_aggregation(line_features)\n    surface_features = surface_features.view(batch_size, -1, object_proposal)\n    line_features = line_features.view(batch_size, -1, object_proposal)\n    combine_feature = torch.cat((surface_features, line_features), dim=1)\n    bbox_predictions = self.bbox_pred[0](combine_feature)\n    bbox_predictions += original_feature\n    for conv_module in self.bbox_pred[1:]:\n        bbox_predictions = conv_module(bbox_predictions)\n    refine_decode_res = self.bbox_coder.split_pred(bbox_predictions[:, :self.num_classes + 2], bbox_predictions[:, self.num_classes + 2:], aggregated_points)\n    for key in refine_decode_res.keys():\n        ret_dict[key + '_optimized'] = refine_decode_res[key]\n    return ret_dict",
            "def forward(self, feats_dict, sample_mod):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Forward pass.\\n\\n        Args:\\n            feats_dict (dict): Feature dict from backbone.\\n            sample_mod (str): Sample mode for vote aggregation layer.\\n                valid modes are \"vote\", \"seed\" and \"random\".\\n\\n        Returns:\\n            dict: Predictions of vote head.\\n        '\n    ret_dict = {}\n    aggregated_points = feats_dict['aggregated_points']\n    original_feature = feats_dict['aggregated_features']\n    batch_size = original_feature.shape[0]\n    object_proposal = original_feature.shape[2]\n    z_center = feats_dict['pred_z_center']\n    xy_center = feats_dict['pred_xy_center']\n    z_semantic = feats_dict['sem_cls_scores_z']\n    xy_semantic = feats_dict['sem_cls_scores_xy']\n    z_feature = feats_dict['aggregated_features_z']\n    xy_feature = feats_dict['aggregated_features_xy']\n    line_center = feats_dict['pred_line_center']\n    line_feature = feats_dict['aggregated_features_line']\n    surface_center_pred = torch.cat((z_center, xy_center), dim=1)\n    ret_dict['surface_center_pred'] = surface_center_pred\n    ret_dict['surface_sem_pred'] = torch.cat((z_semantic, xy_semantic), dim=1)\n    rpn_proposals = feats_dict['proposal_list']\n    rpn_proposals_bbox = DepthInstance3DBoxes(rpn_proposals.reshape(-1, 7).clone(), box_dim=rpn_proposals.shape[-1], with_yaw=self.with_angle, origin=(0.5, 0.5, 0.5))\n    (obj_surface_center, obj_line_center) = rpn_proposals_bbox.get_surface_line_center()\n    obj_surface_center = obj_surface_center.reshape(batch_size, -1, 6, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    obj_line_center = obj_line_center.reshape(batch_size, -1, 12, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    ret_dict['surface_center_object'] = obj_surface_center\n    ret_dict['line_center_object'] = obj_line_center\n    surface_center_feature_pred = torch.cat((z_feature, xy_feature), dim=2)\n    surface_center_feature_pred = torch.cat((surface_center_feature_pred.new_zeros((batch_size, 6, surface_center_feature_pred.shape[2])), surface_center_feature_pred), dim=1)\n    (surface_xyz, surface_features, _) = self.surface_center_matcher(surface_center_pred, surface_center_feature_pred, target_xyz=obj_surface_center)\n    line_feature = torch.cat((line_feature.new_zeros((batch_size, 12, line_feature.shape[2])), line_feature), dim=1)\n    (line_xyz, line_features, _) = self.line_center_matcher(line_center, line_feature, target_xyz=obj_line_center)\n    combine_features = torch.cat((surface_features, line_features), dim=2)\n    matching_features = self.matching_conv(combine_features)\n    matching_score = self.matching_pred(matching_features)\n    ret_dict['matching_score'] = matching_score.transpose(2, 1)\n    semantic_matching_features = self.semantic_matching_conv(combine_features)\n    semantic_matching_score = self.semantic_matching_pred(semantic_matching_features)\n    ret_dict['semantic_matching_score'] = semantic_matching_score.transpose(2, 1)\n    surface_features = self.surface_feats_aggregation(surface_features)\n    line_features = self.line_feats_aggregation(line_features)\n    surface_features = surface_features.view(batch_size, -1, object_proposal)\n    line_features = line_features.view(batch_size, -1, object_proposal)\n    combine_feature = torch.cat((surface_features, line_features), dim=1)\n    bbox_predictions = self.bbox_pred[0](combine_feature)\n    bbox_predictions += original_feature\n    for conv_module in self.bbox_pred[1:]:\n        bbox_predictions = conv_module(bbox_predictions)\n    refine_decode_res = self.bbox_coder.split_pred(bbox_predictions[:, :self.num_classes + 2], bbox_predictions[:, self.num_classes + 2:], aggregated_points)\n    for key in refine_decode_res.keys():\n        ret_dict[key + '_optimized'] = refine_decode_res[key]\n    return ret_dict",
            "def forward(self, feats_dict, sample_mod):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Forward pass.\\n\\n        Args:\\n            feats_dict (dict): Feature dict from backbone.\\n            sample_mod (str): Sample mode for vote aggregation layer.\\n                valid modes are \"vote\", \"seed\" and \"random\".\\n\\n        Returns:\\n            dict: Predictions of vote head.\\n        '\n    ret_dict = {}\n    aggregated_points = feats_dict['aggregated_points']\n    original_feature = feats_dict['aggregated_features']\n    batch_size = original_feature.shape[0]\n    object_proposal = original_feature.shape[2]\n    z_center = feats_dict['pred_z_center']\n    xy_center = feats_dict['pred_xy_center']\n    z_semantic = feats_dict['sem_cls_scores_z']\n    xy_semantic = feats_dict['sem_cls_scores_xy']\n    z_feature = feats_dict['aggregated_features_z']\n    xy_feature = feats_dict['aggregated_features_xy']\n    line_center = feats_dict['pred_line_center']\n    line_feature = feats_dict['aggregated_features_line']\n    surface_center_pred = torch.cat((z_center, xy_center), dim=1)\n    ret_dict['surface_center_pred'] = surface_center_pred\n    ret_dict['surface_sem_pred'] = torch.cat((z_semantic, xy_semantic), dim=1)\n    rpn_proposals = feats_dict['proposal_list']\n    rpn_proposals_bbox = DepthInstance3DBoxes(rpn_proposals.reshape(-1, 7).clone(), box_dim=rpn_proposals.shape[-1], with_yaw=self.with_angle, origin=(0.5, 0.5, 0.5))\n    (obj_surface_center, obj_line_center) = rpn_proposals_bbox.get_surface_line_center()\n    obj_surface_center = obj_surface_center.reshape(batch_size, -1, 6, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    obj_line_center = obj_line_center.reshape(batch_size, -1, 12, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    ret_dict['surface_center_object'] = obj_surface_center\n    ret_dict['line_center_object'] = obj_line_center\n    surface_center_feature_pred = torch.cat((z_feature, xy_feature), dim=2)\n    surface_center_feature_pred = torch.cat((surface_center_feature_pred.new_zeros((batch_size, 6, surface_center_feature_pred.shape[2])), surface_center_feature_pred), dim=1)\n    (surface_xyz, surface_features, _) = self.surface_center_matcher(surface_center_pred, surface_center_feature_pred, target_xyz=obj_surface_center)\n    line_feature = torch.cat((line_feature.new_zeros((batch_size, 12, line_feature.shape[2])), line_feature), dim=1)\n    (line_xyz, line_features, _) = self.line_center_matcher(line_center, line_feature, target_xyz=obj_line_center)\n    combine_features = torch.cat((surface_features, line_features), dim=2)\n    matching_features = self.matching_conv(combine_features)\n    matching_score = self.matching_pred(matching_features)\n    ret_dict['matching_score'] = matching_score.transpose(2, 1)\n    semantic_matching_features = self.semantic_matching_conv(combine_features)\n    semantic_matching_score = self.semantic_matching_pred(semantic_matching_features)\n    ret_dict['semantic_matching_score'] = semantic_matching_score.transpose(2, 1)\n    surface_features = self.surface_feats_aggregation(surface_features)\n    line_features = self.line_feats_aggregation(line_features)\n    surface_features = surface_features.view(batch_size, -1, object_proposal)\n    line_features = line_features.view(batch_size, -1, object_proposal)\n    combine_feature = torch.cat((surface_features, line_features), dim=1)\n    bbox_predictions = self.bbox_pred[0](combine_feature)\n    bbox_predictions += original_feature\n    for conv_module in self.bbox_pred[1:]:\n        bbox_predictions = conv_module(bbox_predictions)\n    refine_decode_res = self.bbox_coder.split_pred(bbox_predictions[:, :self.num_classes + 2], bbox_predictions[:, self.num_classes + 2:], aggregated_points)\n    for key in refine_decode_res.keys():\n        ret_dict[key + '_optimized'] = refine_decode_res[key]\n    return ret_dict",
            "def forward(self, feats_dict, sample_mod):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Forward pass.\\n\\n        Args:\\n            feats_dict (dict): Feature dict from backbone.\\n            sample_mod (str): Sample mode for vote aggregation layer.\\n                valid modes are \"vote\", \"seed\" and \"random\".\\n\\n        Returns:\\n            dict: Predictions of vote head.\\n        '\n    ret_dict = {}\n    aggregated_points = feats_dict['aggregated_points']\n    original_feature = feats_dict['aggregated_features']\n    batch_size = original_feature.shape[0]\n    object_proposal = original_feature.shape[2]\n    z_center = feats_dict['pred_z_center']\n    xy_center = feats_dict['pred_xy_center']\n    z_semantic = feats_dict['sem_cls_scores_z']\n    xy_semantic = feats_dict['sem_cls_scores_xy']\n    z_feature = feats_dict['aggregated_features_z']\n    xy_feature = feats_dict['aggregated_features_xy']\n    line_center = feats_dict['pred_line_center']\n    line_feature = feats_dict['aggregated_features_line']\n    surface_center_pred = torch.cat((z_center, xy_center), dim=1)\n    ret_dict['surface_center_pred'] = surface_center_pred\n    ret_dict['surface_sem_pred'] = torch.cat((z_semantic, xy_semantic), dim=1)\n    rpn_proposals = feats_dict['proposal_list']\n    rpn_proposals_bbox = DepthInstance3DBoxes(rpn_proposals.reshape(-1, 7).clone(), box_dim=rpn_proposals.shape[-1], with_yaw=self.with_angle, origin=(0.5, 0.5, 0.5))\n    (obj_surface_center, obj_line_center) = rpn_proposals_bbox.get_surface_line_center()\n    obj_surface_center = obj_surface_center.reshape(batch_size, -1, 6, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    obj_line_center = obj_line_center.reshape(batch_size, -1, 12, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    ret_dict['surface_center_object'] = obj_surface_center\n    ret_dict['line_center_object'] = obj_line_center\n    surface_center_feature_pred = torch.cat((z_feature, xy_feature), dim=2)\n    surface_center_feature_pred = torch.cat((surface_center_feature_pred.new_zeros((batch_size, 6, surface_center_feature_pred.shape[2])), surface_center_feature_pred), dim=1)\n    (surface_xyz, surface_features, _) = self.surface_center_matcher(surface_center_pred, surface_center_feature_pred, target_xyz=obj_surface_center)\n    line_feature = torch.cat((line_feature.new_zeros((batch_size, 12, line_feature.shape[2])), line_feature), dim=1)\n    (line_xyz, line_features, _) = self.line_center_matcher(line_center, line_feature, target_xyz=obj_line_center)\n    combine_features = torch.cat((surface_features, line_features), dim=2)\n    matching_features = self.matching_conv(combine_features)\n    matching_score = self.matching_pred(matching_features)\n    ret_dict['matching_score'] = matching_score.transpose(2, 1)\n    semantic_matching_features = self.semantic_matching_conv(combine_features)\n    semantic_matching_score = self.semantic_matching_pred(semantic_matching_features)\n    ret_dict['semantic_matching_score'] = semantic_matching_score.transpose(2, 1)\n    surface_features = self.surface_feats_aggregation(surface_features)\n    line_features = self.line_feats_aggregation(line_features)\n    surface_features = surface_features.view(batch_size, -1, object_proposal)\n    line_features = line_features.view(batch_size, -1, object_proposal)\n    combine_feature = torch.cat((surface_features, line_features), dim=1)\n    bbox_predictions = self.bbox_pred[0](combine_feature)\n    bbox_predictions += original_feature\n    for conv_module in self.bbox_pred[1:]:\n        bbox_predictions = conv_module(bbox_predictions)\n    refine_decode_res = self.bbox_coder.split_pred(bbox_predictions[:, :self.num_classes + 2], bbox_predictions[:, self.num_classes + 2:], aggregated_points)\n    for key in refine_decode_res.keys():\n        ret_dict[key + '_optimized'] = refine_decode_res[key]\n    return ret_dict",
            "def forward(self, feats_dict, sample_mod):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Forward pass.\\n\\n        Args:\\n            feats_dict (dict): Feature dict from backbone.\\n            sample_mod (str): Sample mode for vote aggregation layer.\\n                valid modes are \"vote\", \"seed\" and \"random\".\\n\\n        Returns:\\n            dict: Predictions of vote head.\\n        '\n    ret_dict = {}\n    aggregated_points = feats_dict['aggregated_points']\n    original_feature = feats_dict['aggregated_features']\n    batch_size = original_feature.shape[0]\n    object_proposal = original_feature.shape[2]\n    z_center = feats_dict['pred_z_center']\n    xy_center = feats_dict['pred_xy_center']\n    z_semantic = feats_dict['sem_cls_scores_z']\n    xy_semantic = feats_dict['sem_cls_scores_xy']\n    z_feature = feats_dict['aggregated_features_z']\n    xy_feature = feats_dict['aggregated_features_xy']\n    line_center = feats_dict['pred_line_center']\n    line_feature = feats_dict['aggregated_features_line']\n    surface_center_pred = torch.cat((z_center, xy_center), dim=1)\n    ret_dict['surface_center_pred'] = surface_center_pred\n    ret_dict['surface_sem_pred'] = torch.cat((z_semantic, xy_semantic), dim=1)\n    rpn_proposals = feats_dict['proposal_list']\n    rpn_proposals_bbox = DepthInstance3DBoxes(rpn_proposals.reshape(-1, 7).clone(), box_dim=rpn_proposals.shape[-1], with_yaw=self.with_angle, origin=(0.5, 0.5, 0.5))\n    (obj_surface_center, obj_line_center) = rpn_proposals_bbox.get_surface_line_center()\n    obj_surface_center = obj_surface_center.reshape(batch_size, -1, 6, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    obj_line_center = obj_line_center.reshape(batch_size, -1, 12, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    ret_dict['surface_center_object'] = obj_surface_center\n    ret_dict['line_center_object'] = obj_line_center\n    surface_center_feature_pred = torch.cat((z_feature, xy_feature), dim=2)\n    surface_center_feature_pred = torch.cat((surface_center_feature_pred.new_zeros((batch_size, 6, surface_center_feature_pred.shape[2])), surface_center_feature_pred), dim=1)\n    (surface_xyz, surface_features, _) = self.surface_center_matcher(surface_center_pred, surface_center_feature_pred, target_xyz=obj_surface_center)\n    line_feature = torch.cat((line_feature.new_zeros((batch_size, 12, line_feature.shape[2])), line_feature), dim=1)\n    (line_xyz, line_features, _) = self.line_center_matcher(line_center, line_feature, target_xyz=obj_line_center)\n    combine_features = torch.cat((surface_features, line_features), dim=2)\n    matching_features = self.matching_conv(combine_features)\n    matching_score = self.matching_pred(matching_features)\n    ret_dict['matching_score'] = matching_score.transpose(2, 1)\n    semantic_matching_features = self.semantic_matching_conv(combine_features)\n    semantic_matching_score = self.semantic_matching_pred(semantic_matching_features)\n    ret_dict['semantic_matching_score'] = semantic_matching_score.transpose(2, 1)\n    surface_features = self.surface_feats_aggregation(surface_features)\n    line_features = self.line_feats_aggregation(line_features)\n    surface_features = surface_features.view(batch_size, -1, object_proposal)\n    line_features = line_features.view(batch_size, -1, object_proposal)\n    combine_feature = torch.cat((surface_features, line_features), dim=1)\n    bbox_predictions = self.bbox_pred[0](combine_feature)\n    bbox_predictions += original_feature\n    for conv_module in self.bbox_pred[1:]:\n        bbox_predictions = conv_module(bbox_predictions)\n    refine_decode_res = self.bbox_coder.split_pred(bbox_predictions[:, :self.num_classes + 2], bbox_predictions[:, self.num_classes + 2:], aggregated_points)\n    for key in refine_decode_res.keys():\n        ret_dict[key + '_optimized'] = refine_decode_res[key]\n    return ret_dict"
        ]
    },
    {
        "func_name": "loss",
        "original": "def loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, rpn_targets=None, gt_bboxes_ignore=None):\n    \"\"\"Compute loss.\n\n        Args:\n            bbox_preds (dict): Predictions from forward of h3d bbox head.\n            points (list[torch.Tensor]): Input points.\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\n                bboxes of each sample.\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\n                semantic mask.\n            pts_instance_mask (list[torch.Tensor]): Point-wise\n                instance mask.\n            img_metas (list[dict]): Contain pcd and img's meta info.\n            rpn_targets (Tuple) : Targets generated by rpn head.\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\n                which bounding.\n\n        Returns:\n            dict: Losses of H3dnet.\n        \"\"\"\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, _, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = rpn_targets\n    losses = {}\n    refined_proposal_loss = self.get_proposal_stage_loss(bbox_preds, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, mask_targets, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights, suffix='_optimized')\n    for key in refined_proposal_loss.keys():\n        losses[key + '_optimized'] = refined_proposal_loss[key]\n    bbox3d_optimized = self.bbox_coder.decode(bbox_preds, suffix='_optimized')\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center) = targets\n    objectness_scores = bbox_preds['matching_score']\n    objectness_scores_sem = bbox_preds['semantic_matching_score']\n    primitive_objectness_loss = self.cues_objectness_loss(objectness_scores.transpose(2, 1), cues_objectness_label, weight=cues_mask, avg_factor=cues_mask.sum() + 1e-06)\n    primitive_sem_loss = self.cues_semantic_loss(objectness_scores_sem.transpose(2, 1), cues_sem_label, weight=cues_mask, avg_factor=cues_mask.sum() + 1e-06)\n    objectness_scores = bbox_preds['obj_scores_optimized']\n    objectness_loss_refine = self.proposal_objectness_loss(objectness_scores.transpose(2, 1), proposal_objectness_label)\n    primitive_matching_loss = (objectness_loss_refine * cues_match_mask).sum() / (cues_match_mask.sum() + 1e-06) * 0.5\n    primitive_sem_matching_loss = (objectness_loss_refine * proposal_objectness_mask).sum() / (proposal_objectness_mask.sum() + 1e-06) * 0.5\n    (batch_size, object_proposal) = bbox3d_optimized.shape[:2]\n    refined_bbox = DepthInstance3DBoxes(bbox3d_optimized.reshape(-1, 7).clone(), box_dim=bbox3d_optimized.shape[-1], with_yaw=self.with_angle, origin=(0.5, 0.5, 0.5))\n    (pred_obj_surface_center, pred_obj_line_center) = refined_bbox.get_surface_line_center()\n    pred_obj_surface_center = pred_obj_surface_center.reshape(batch_size, -1, 6, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    pred_obj_line_center = pred_obj_line_center.reshape(batch_size, -1, 12, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    pred_surface_line_center = torch.cat((pred_obj_surface_center, pred_obj_line_center), 1)\n    square_dist = self.primitive_center_loss(pred_surface_line_center, obj_surface_line_center)\n    match_dist = torch.sqrt(square_dist.sum(dim=-1) + 1e-06)\n    primitive_centroid_reg_loss = torch.sum(match_dist * cues_matching_label) / (cues_matching_label.sum() + 1e-06)\n    refined_loss = dict(primitive_objectness_loss=primitive_objectness_loss, primitive_sem_loss=primitive_sem_loss, primitive_matching_loss=primitive_matching_loss, primitive_sem_matching_loss=primitive_sem_matching_loss, primitive_centroid_reg_loss=primitive_centroid_reg_loss)\n    losses.update(refined_loss)\n    return losses",
        "mutated": [
            "def loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, rpn_targets=None, gt_bboxes_ignore=None):\n    if False:\n        i = 10\n    \"Compute loss.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of h3d bbox head.\\n            points (list[torch.Tensor]): Input points.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each sample.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\\n                semantic mask.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise\\n                instance mask.\\n            img_metas (list[dict]): Contain pcd and img's meta info.\\n            rpn_targets (Tuple) : Targets generated by rpn head.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding.\\n\\n        Returns:\\n            dict: Losses of H3dnet.\\n        \"\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, _, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = rpn_targets\n    losses = {}\n    refined_proposal_loss = self.get_proposal_stage_loss(bbox_preds, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, mask_targets, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights, suffix='_optimized')\n    for key in refined_proposal_loss.keys():\n        losses[key + '_optimized'] = refined_proposal_loss[key]\n    bbox3d_optimized = self.bbox_coder.decode(bbox_preds, suffix='_optimized')\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center) = targets\n    objectness_scores = bbox_preds['matching_score']\n    objectness_scores_sem = bbox_preds['semantic_matching_score']\n    primitive_objectness_loss = self.cues_objectness_loss(objectness_scores.transpose(2, 1), cues_objectness_label, weight=cues_mask, avg_factor=cues_mask.sum() + 1e-06)\n    primitive_sem_loss = self.cues_semantic_loss(objectness_scores_sem.transpose(2, 1), cues_sem_label, weight=cues_mask, avg_factor=cues_mask.sum() + 1e-06)\n    objectness_scores = bbox_preds['obj_scores_optimized']\n    objectness_loss_refine = self.proposal_objectness_loss(objectness_scores.transpose(2, 1), proposal_objectness_label)\n    primitive_matching_loss = (objectness_loss_refine * cues_match_mask).sum() / (cues_match_mask.sum() + 1e-06) * 0.5\n    primitive_sem_matching_loss = (objectness_loss_refine * proposal_objectness_mask).sum() / (proposal_objectness_mask.sum() + 1e-06) * 0.5\n    (batch_size, object_proposal) = bbox3d_optimized.shape[:2]\n    refined_bbox = DepthInstance3DBoxes(bbox3d_optimized.reshape(-1, 7).clone(), box_dim=bbox3d_optimized.shape[-1], with_yaw=self.with_angle, origin=(0.5, 0.5, 0.5))\n    (pred_obj_surface_center, pred_obj_line_center) = refined_bbox.get_surface_line_center()\n    pred_obj_surface_center = pred_obj_surface_center.reshape(batch_size, -1, 6, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    pred_obj_line_center = pred_obj_line_center.reshape(batch_size, -1, 12, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    pred_surface_line_center = torch.cat((pred_obj_surface_center, pred_obj_line_center), 1)\n    square_dist = self.primitive_center_loss(pred_surface_line_center, obj_surface_line_center)\n    match_dist = torch.sqrt(square_dist.sum(dim=-1) + 1e-06)\n    primitive_centroid_reg_loss = torch.sum(match_dist * cues_matching_label) / (cues_matching_label.sum() + 1e-06)\n    refined_loss = dict(primitive_objectness_loss=primitive_objectness_loss, primitive_sem_loss=primitive_sem_loss, primitive_matching_loss=primitive_matching_loss, primitive_sem_matching_loss=primitive_sem_matching_loss, primitive_centroid_reg_loss=primitive_centroid_reg_loss)\n    losses.update(refined_loss)\n    return losses",
            "def loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, rpn_targets=None, gt_bboxes_ignore=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Compute loss.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of h3d bbox head.\\n            points (list[torch.Tensor]): Input points.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each sample.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\\n                semantic mask.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise\\n                instance mask.\\n            img_metas (list[dict]): Contain pcd and img's meta info.\\n            rpn_targets (Tuple) : Targets generated by rpn head.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding.\\n\\n        Returns:\\n            dict: Losses of H3dnet.\\n        \"\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, _, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = rpn_targets\n    losses = {}\n    refined_proposal_loss = self.get_proposal_stage_loss(bbox_preds, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, mask_targets, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights, suffix='_optimized')\n    for key in refined_proposal_loss.keys():\n        losses[key + '_optimized'] = refined_proposal_loss[key]\n    bbox3d_optimized = self.bbox_coder.decode(bbox_preds, suffix='_optimized')\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center) = targets\n    objectness_scores = bbox_preds['matching_score']\n    objectness_scores_sem = bbox_preds['semantic_matching_score']\n    primitive_objectness_loss = self.cues_objectness_loss(objectness_scores.transpose(2, 1), cues_objectness_label, weight=cues_mask, avg_factor=cues_mask.sum() + 1e-06)\n    primitive_sem_loss = self.cues_semantic_loss(objectness_scores_sem.transpose(2, 1), cues_sem_label, weight=cues_mask, avg_factor=cues_mask.sum() + 1e-06)\n    objectness_scores = bbox_preds['obj_scores_optimized']\n    objectness_loss_refine = self.proposal_objectness_loss(objectness_scores.transpose(2, 1), proposal_objectness_label)\n    primitive_matching_loss = (objectness_loss_refine * cues_match_mask).sum() / (cues_match_mask.sum() + 1e-06) * 0.5\n    primitive_sem_matching_loss = (objectness_loss_refine * proposal_objectness_mask).sum() / (proposal_objectness_mask.sum() + 1e-06) * 0.5\n    (batch_size, object_proposal) = bbox3d_optimized.shape[:2]\n    refined_bbox = DepthInstance3DBoxes(bbox3d_optimized.reshape(-1, 7).clone(), box_dim=bbox3d_optimized.shape[-1], with_yaw=self.with_angle, origin=(0.5, 0.5, 0.5))\n    (pred_obj_surface_center, pred_obj_line_center) = refined_bbox.get_surface_line_center()\n    pred_obj_surface_center = pred_obj_surface_center.reshape(batch_size, -1, 6, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    pred_obj_line_center = pred_obj_line_center.reshape(batch_size, -1, 12, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    pred_surface_line_center = torch.cat((pred_obj_surface_center, pred_obj_line_center), 1)\n    square_dist = self.primitive_center_loss(pred_surface_line_center, obj_surface_line_center)\n    match_dist = torch.sqrt(square_dist.sum(dim=-1) + 1e-06)\n    primitive_centroid_reg_loss = torch.sum(match_dist * cues_matching_label) / (cues_matching_label.sum() + 1e-06)\n    refined_loss = dict(primitive_objectness_loss=primitive_objectness_loss, primitive_sem_loss=primitive_sem_loss, primitive_matching_loss=primitive_matching_loss, primitive_sem_matching_loss=primitive_sem_matching_loss, primitive_centroid_reg_loss=primitive_centroid_reg_loss)\n    losses.update(refined_loss)\n    return losses",
            "def loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, rpn_targets=None, gt_bboxes_ignore=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Compute loss.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of h3d bbox head.\\n            points (list[torch.Tensor]): Input points.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each sample.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\\n                semantic mask.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise\\n                instance mask.\\n            img_metas (list[dict]): Contain pcd and img's meta info.\\n            rpn_targets (Tuple) : Targets generated by rpn head.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding.\\n\\n        Returns:\\n            dict: Losses of H3dnet.\\n        \"\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, _, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = rpn_targets\n    losses = {}\n    refined_proposal_loss = self.get_proposal_stage_loss(bbox_preds, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, mask_targets, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights, suffix='_optimized')\n    for key in refined_proposal_loss.keys():\n        losses[key + '_optimized'] = refined_proposal_loss[key]\n    bbox3d_optimized = self.bbox_coder.decode(bbox_preds, suffix='_optimized')\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center) = targets\n    objectness_scores = bbox_preds['matching_score']\n    objectness_scores_sem = bbox_preds['semantic_matching_score']\n    primitive_objectness_loss = self.cues_objectness_loss(objectness_scores.transpose(2, 1), cues_objectness_label, weight=cues_mask, avg_factor=cues_mask.sum() + 1e-06)\n    primitive_sem_loss = self.cues_semantic_loss(objectness_scores_sem.transpose(2, 1), cues_sem_label, weight=cues_mask, avg_factor=cues_mask.sum() + 1e-06)\n    objectness_scores = bbox_preds['obj_scores_optimized']\n    objectness_loss_refine = self.proposal_objectness_loss(objectness_scores.transpose(2, 1), proposal_objectness_label)\n    primitive_matching_loss = (objectness_loss_refine * cues_match_mask).sum() / (cues_match_mask.sum() + 1e-06) * 0.5\n    primitive_sem_matching_loss = (objectness_loss_refine * proposal_objectness_mask).sum() / (proposal_objectness_mask.sum() + 1e-06) * 0.5\n    (batch_size, object_proposal) = bbox3d_optimized.shape[:2]\n    refined_bbox = DepthInstance3DBoxes(bbox3d_optimized.reshape(-1, 7).clone(), box_dim=bbox3d_optimized.shape[-1], with_yaw=self.with_angle, origin=(0.5, 0.5, 0.5))\n    (pred_obj_surface_center, pred_obj_line_center) = refined_bbox.get_surface_line_center()\n    pred_obj_surface_center = pred_obj_surface_center.reshape(batch_size, -1, 6, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    pred_obj_line_center = pred_obj_line_center.reshape(batch_size, -1, 12, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    pred_surface_line_center = torch.cat((pred_obj_surface_center, pred_obj_line_center), 1)\n    square_dist = self.primitive_center_loss(pred_surface_line_center, obj_surface_line_center)\n    match_dist = torch.sqrt(square_dist.sum(dim=-1) + 1e-06)\n    primitive_centroid_reg_loss = torch.sum(match_dist * cues_matching_label) / (cues_matching_label.sum() + 1e-06)\n    refined_loss = dict(primitive_objectness_loss=primitive_objectness_loss, primitive_sem_loss=primitive_sem_loss, primitive_matching_loss=primitive_matching_loss, primitive_sem_matching_loss=primitive_sem_matching_loss, primitive_centroid_reg_loss=primitive_centroid_reg_loss)\n    losses.update(refined_loss)\n    return losses",
            "def loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, rpn_targets=None, gt_bboxes_ignore=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Compute loss.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of h3d bbox head.\\n            points (list[torch.Tensor]): Input points.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each sample.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\\n                semantic mask.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise\\n                instance mask.\\n            img_metas (list[dict]): Contain pcd and img's meta info.\\n            rpn_targets (Tuple) : Targets generated by rpn head.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding.\\n\\n        Returns:\\n            dict: Losses of H3dnet.\\n        \"\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, _, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = rpn_targets\n    losses = {}\n    refined_proposal_loss = self.get_proposal_stage_loss(bbox_preds, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, mask_targets, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights, suffix='_optimized')\n    for key in refined_proposal_loss.keys():\n        losses[key + '_optimized'] = refined_proposal_loss[key]\n    bbox3d_optimized = self.bbox_coder.decode(bbox_preds, suffix='_optimized')\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center) = targets\n    objectness_scores = bbox_preds['matching_score']\n    objectness_scores_sem = bbox_preds['semantic_matching_score']\n    primitive_objectness_loss = self.cues_objectness_loss(objectness_scores.transpose(2, 1), cues_objectness_label, weight=cues_mask, avg_factor=cues_mask.sum() + 1e-06)\n    primitive_sem_loss = self.cues_semantic_loss(objectness_scores_sem.transpose(2, 1), cues_sem_label, weight=cues_mask, avg_factor=cues_mask.sum() + 1e-06)\n    objectness_scores = bbox_preds['obj_scores_optimized']\n    objectness_loss_refine = self.proposal_objectness_loss(objectness_scores.transpose(2, 1), proposal_objectness_label)\n    primitive_matching_loss = (objectness_loss_refine * cues_match_mask).sum() / (cues_match_mask.sum() + 1e-06) * 0.5\n    primitive_sem_matching_loss = (objectness_loss_refine * proposal_objectness_mask).sum() / (proposal_objectness_mask.sum() + 1e-06) * 0.5\n    (batch_size, object_proposal) = bbox3d_optimized.shape[:2]\n    refined_bbox = DepthInstance3DBoxes(bbox3d_optimized.reshape(-1, 7).clone(), box_dim=bbox3d_optimized.shape[-1], with_yaw=self.with_angle, origin=(0.5, 0.5, 0.5))\n    (pred_obj_surface_center, pred_obj_line_center) = refined_bbox.get_surface_line_center()\n    pred_obj_surface_center = pred_obj_surface_center.reshape(batch_size, -1, 6, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    pred_obj_line_center = pred_obj_line_center.reshape(batch_size, -1, 12, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    pred_surface_line_center = torch.cat((pred_obj_surface_center, pred_obj_line_center), 1)\n    square_dist = self.primitive_center_loss(pred_surface_line_center, obj_surface_line_center)\n    match_dist = torch.sqrt(square_dist.sum(dim=-1) + 1e-06)\n    primitive_centroid_reg_loss = torch.sum(match_dist * cues_matching_label) / (cues_matching_label.sum() + 1e-06)\n    refined_loss = dict(primitive_objectness_loss=primitive_objectness_loss, primitive_sem_loss=primitive_sem_loss, primitive_matching_loss=primitive_matching_loss, primitive_sem_matching_loss=primitive_sem_matching_loss, primitive_centroid_reg_loss=primitive_centroid_reg_loss)\n    losses.update(refined_loss)\n    return losses",
            "def loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, rpn_targets=None, gt_bboxes_ignore=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Compute loss.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of h3d bbox head.\\n            points (list[torch.Tensor]): Input points.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each sample.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\\n                semantic mask.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise\\n                instance mask.\\n            img_metas (list[dict]): Contain pcd and img's meta info.\\n            rpn_targets (Tuple) : Targets generated by rpn head.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding.\\n\\n        Returns:\\n            dict: Losses of H3dnet.\\n        \"\n    (vote_targets, vote_target_masks, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, _, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = rpn_targets\n    losses = {}\n    refined_proposal_loss = self.get_proposal_stage_loss(bbox_preds, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, mask_targets, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights, suffix='_optimized')\n    for key in refined_proposal_loss.keys():\n        losses[key + '_optimized'] = refined_proposal_loss[key]\n    bbox3d_optimized = self.bbox_coder.decode(bbox_preds, suffix='_optimized')\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center) = targets\n    objectness_scores = bbox_preds['matching_score']\n    objectness_scores_sem = bbox_preds['semantic_matching_score']\n    primitive_objectness_loss = self.cues_objectness_loss(objectness_scores.transpose(2, 1), cues_objectness_label, weight=cues_mask, avg_factor=cues_mask.sum() + 1e-06)\n    primitive_sem_loss = self.cues_semantic_loss(objectness_scores_sem.transpose(2, 1), cues_sem_label, weight=cues_mask, avg_factor=cues_mask.sum() + 1e-06)\n    objectness_scores = bbox_preds['obj_scores_optimized']\n    objectness_loss_refine = self.proposal_objectness_loss(objectness_scores.transpose(2, 1), proposal_objectness_label)\n    primitive_matching_loss = (objectness_loss_refine * cues_match_mask).sum() / (cues_match_mask.sum() + 1e-06) * 0.5\n    primitive_sem_matching_loss = (objectness_loss_refine * proposal_objectness_mask).sum() / (proposal_objectness_mask.sum() + 1e-06) * 0.5\n    (batch_size, object_proposal) = bbox3d_optimized.shape[:2]\n    refined_bbox = DepthInstance3DBoxes(bbox3d_optimized.reshape(-1, 7).clone(), box_dim=bbox3d_optimized.shape[-1], with_yaw=self.with_angle, origin=(0.5, 0.5, 0.5))\n    (pred_obj_surface_center, pred_obj_line_center) = refined_bbox.get_surface_line_center()\n    pred_obj_surface_center = pred_obj_surface_center.reshape(batch_size, -1, 6, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    pred_obj_line_center = pred_obj_line_center.reshape(batch_size, -1, 12, 3).transpose(1, 2).reshape(batch_size, -1, 3)\n    pred_surface_line_center = torch.cat((pred_obj_surface_center, pred_obj_line_center), 1)\n    square_dist = self.primitive_center_loss(pred_surface_line_center, obj_surface_line_center)\n    match_dist = torch.sqrt(square_dist.sum(dim=-1) + 1e-06)\n    primitive_centroid_reg_loss = torch.sum(match_dist * cues_matching_label) / (cues_matching_label.sum() + 1e-06)\n    refined_loss = dict(primitive_objectness_loss=primitive_objectness_loss, primitive_sem_loss=primitive_sem_loss, primitive_matching_loss=primitive_matching_loss, primitive_sem_matching_loss=primitive_sem_matching_loss, primitive_centroid_reg_loss=primitive_centroid_reg_loss)\n    losses.update(refined_loss)\n    return losses"
        ]
    },
    {
        "func_name": "get_bboxes",
        "original": "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, suffix=''):\n    \"\"\"Generate bboxes from vote head predictions.\n\n        Args:\n            points (torch.Tensor): Input points.\n            bbox_preds (dict): Predictions from vote head.\n            input_metas (list[dict]): Point cloud and image's meta info.\n            rescale (bool): Whether to rescale bboxes.\n\n        Returns:\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\n        \"\"\"\n    obj_scores = F.softmax(bbox_preds['obj_scores' + suffix], dim=-1)[..., -1]\n    sem_scores = F.softmax(bbox_preds['sem_scores'], dim=-1)\n    prediction_collection = {}\n    prediction_collection['center'] = bbox_preds['center' + suffix]\n    prediction_collection['dir_class'] = bbox_preds['dir_class']\n    prediction_collection['dir_res'] = bbox_preds['dir_res' + suffix]\n    prediction_collection['size_class'] = bbox_preds['size_class']\n    prediction_collection['size_res'] = bbox_preds['size_res' + suffix]\n    bbox3d = self.bbox_coder.decode(prediction_collection)\n    batch_size = bbox3d.shape[0]\n    results = list()\n    for b in range(batch_size):\n        (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n        bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n        results.append((bbox, score_selected, labels))\n    return results",
        "mutated": [
            "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, suffix=''):\n    if False:\n        i = 10\n    \"Generate bboxes from vote head predictions.\\n\\n        Args:\\n            points (torch.Tensor): Input points.\\n            bbox_preds (dict): Predictions from vote head.\\n            input_metas (list[dict]): Point cloud and image's meta info.\\n            rescale (bool): Whether to rescale bboxes.\\n\\n        Returns:\\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\\n        \"\n    obj_scores = F.softmax(bbox_preds['obj_scores' + suffix], dim=-1)[..., -1]\n    sem_scores = F.softmax(bbox_preds['sem_scores'], dim=-1)\n    prediction_collection = {}\n    prediction_collection['center'] = bbox_preds['center' + suffix]\n    prediction_collection['dir_class'] = bbox_preds['dir_class']\n    prediction_collection['dir_res'] = bbox_preds['dir_res' + suffix]\n    prediction_collection['size_class'] = bbox_preds['size_class']\n    prediction_collection['size_res'] = bbox_preds['size_res' + suffix]\n    bbox3d = self.bbox_coder.decode(prediction_collection)\n    batch_size = bbox3d.shape[0]\n    results = list()\n    for b in range(batch_size):\n        (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n        bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n        results.append((bbox, score_selected, labels))\n    return results",
            "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, suffix=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Generate bboxes from vote head predictions.\\n\\n        Args:\\n            points (torch.Tensor): Input points.\\n            bbox_preds (dict): Predictions from vote head.\\n            input_metas (list[dict]): Point cloud and image's meta info.\\n            rescale (bool): Whether to rescale bboxes.\\n\\n        Returns:\\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\\n        \"\n    obj_scores = F.softmax(bbox_preds['obj_scores' + suffix], dim=-1)[..., -1]\n    sem_scores = F.softmax(bbox_preds['sem_scores'], dim=-1)\n    prediction_collection = {}\n    prediction_collection['center'] = bbox_preds['center' + suffix]\n    prediction_collection['dir_class'] = bbox_preds['dir_class']\n    prediction_collection['dir_res'] = bbox_preds['dir_res' + suffix]\n    prediction_collection['size_class'] = bbox_preds['size_class']\n    prediction_collection['size_res'] = bbox_preds['size_res' + suffix]\n    bbox3d = self.bbox_coder.decode(prediction_collection)\n    batch_size = bbox3d.shape[0]\n    results = list()\n    for b in range(batch_size):\n        (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n        bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n        results.append((bbox, score_selected, labels))\n    return results",
            "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, suffix=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Generate bboxes from vote head predictions.\\n\\n        Args:\\n            points (torch.Tensor): Input points.\\n            bbox_preds (dict): Predictions from vote head.\\n            input_metas (list[dict]): Point cloud and image's meta info.\\n            rescale (bool): Whether to rescale bboxes.\\n\\n        Returns:\\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\\n        \"\n    obj_scores = F.softmax(bbox_preds['obj_scores' + suffix], dim=-1)[..., -1]\n    sem_scores = F.softmax(bbox_preds['sem_scores'], dim=-1)\n    prediction_collection = {}\n    prediction_collection['center'] = bbox_preds['center' + suffix]\n    prediction_collection['dir_class'] = bbox_preds['dir_class']\n    prediction_collection['dir_res'] = bbox_preds['dir_res' + suffix]\n    prediction_collection['size_class'] = bbox_preds['size_class']\n    prediction_collection['size_res'] = bbox_preds['size_res' + suffix]\n    bbox3d = self.bbox_coder.decode(prediction_collection)\n    batch_size = bbox3d.shape[0]\n    results = list()\n    for b in range(batch_size):\n        (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n        bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n        results.append((bbox, score_selected, labels))\n    return results",
            "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, suffix=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Generate bboxes from vote head predictions.\\n\\n        Args:\\n            points (torch.Tensor): Input points.\\n            bbox_preds (dict): Predictions from vote head.\\n            input_metas (list[dict]): Point cloud and image's meta info.\\n            rescale (bool): Whether to rescale bboxes.\\n\\n        Returns:\\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\\n        \"\n    obj_scores = F.softmax(bbox_preds['obj_scores' + suffix], dim=-1)[..., -1]\n    sem_scores = F.softmax(bbox_preds['sem_scores'], dim=-1)\n    prediction_collection = {}\n    prediction_collection['center'] = bbox_preds['center' + suffix]\n    prediction_collection['dir_class'] = bbox_preds['dir_class']\n    prediction_collection['dir_res'] = bbox_preds['dir_res' + suffix]\n    prediction_collection['size_class'] = bbox_preds['size_class']\n    prediction_collection['size_res'] = bbox_preds['size_res' + suffix]\n    bbox3d = self.bbox_coder.decode(prediction_collection)\n    batch_size = bbox3d.shape[0]\n    results = list()\n    for b in range(batch_size):\n        (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n        bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n        results.append((bbox, score_selected, labels))\n    return results",
            "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, suffix=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Generate bboxes from vote head predictions.\\n\\n        Args:\\n            points (torch.Tensor): Input points.\\n            bbox_preds (dict): Predictions from vote head.\\n            input_metas (list[dict]): Point cloud and image's meta info.\\n            rescale (bool): Whether to rescale bboxes.\\n\\n        Returns:\\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\\n        \"\n    obj_scores = F.softmax(bbox_preds['obj_scores' + suffix], dim=-1)[..., -1]\n    sem_scores = F.softmax(bbox_preds['sem_scores'], dim=-1)\n    prediction_collection = {}\n    prediction_collection['center'] = bbox_preds['center' + suffix]\n    prediction_collection['dir_class'] = bbox_preds['dir_class']\n    prediction_collection['dir_res'] = bbox_preds['dir_res' + suffix]\n    prediction_collection['size_class'] = bbox_preds['size_class']\n    prediction_collection['size_res'] = bbox_preds['size_res' + suffix]\n    bbox3d = self.bbox_coder.decode(prediction_collection)\n    batch_size = bbox3d.shape[0]\n    results = list()\n    for b in range(batch_size):\n        (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n        bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n        results.append((bbox, score_selected, labels))\n    return results"
        ]
    },
    {
        "func_name": "multiclass_nms_single",
        "original": "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    \"\"\"Multi-class nms in single batch.\n\n        Args:\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\n            bbox (torch.Tensor): Predicted bounding boxes.\n            points (torch.Tensor): Input points.\n            input_meta (dict): Point cloud and image's meta info.\n\n        Returns:\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\n        \"\"\"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)",
        "mutated": [
            "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    if False:\n        i = 10\n    \"Multi-class nms in single batch.\\n\\n        Args:\\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\\n            bbox (torch.Tensor): Predicted bounding boxes.\\n            points (torch.Tensor): Input points.\\n            input_meta (dict): Point cloud and image's meta info.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\\n        \"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)",
            "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Multi-class nms in single batch.\\n\\n        Args:\\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\\n            bbox (torch.Tensor): Predicted bounding boxes.\\n            points (torch.Tensor): Input points.\\n            input_meta (dict): Point cloud and image's meta info.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\\n        \"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)",
            "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Multi-class nms in single batch.\\n\\n        Args:\\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\\n            bbox (torch.Tensor): Predicted bounding boxes.\\n            points (torch.Tensor): Input points.\\n            input_meta (dict): Point cloud and image's meta info.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\\n        \"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)",
            "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Multi-class nms in single batch.\\n\\n        Args:\\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\\n            bbox (torch.Tensor): Predicted bounding boxes.\\n            points (torch.Tensor): Input points.\\n            input_meta (dict): Point cloud and image's meta info.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\\n        \"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)",
            "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Multi-class nms in single batch.\\n\\n        Args:\\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\\n            bbox (torch.Tensor): Predicted bounding boxes.\\n            points (torch.Tensor): Input points.\\n            input_meta (dict): Point cloud and image's meta info.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\\n        \"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)"
        ]
    },
    {
        "func_name": "get_proposal_stage_loss",
        "original": "def get_proposal_stage_loss(self, bbox_preds, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, mask_targets, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights, suffix=''):\n    \"\"\"Compute loss for the aggregation module.\n\n        Args:\n            bbox_preds (dict): Predictions from forward of vote head.\n            size_class_targets (torch.Tensor): Ground truth\n                size class of each prediction bounding box.\n            size_res_targets (torch.Tensor): Ground truth\n                size residual of each prediction bounding box.\n            dir_class_targets (torch.Tensor): Ground truth\n                direction class of each prediction bounding box.\n            dir_res_targets (torch.Tensor): Ground truth\n                direction residual of each prediction bounding box.\n            center_targets (torch.Tensor): Ground truth center\n                of each prediction bounding box.\n            mask_targets (torch.Tensor): Validation of each\n                prediction bounding box.\n            objectness_targets (torch.Tensor): Ground truth\n                objectness label of each prediction bounding box.\n            objectness_weights (torch.Tensor): Weights of objectness\n                loss for each prediction bounding box.\n            box_loss_weights (torch.Tensor): Weights of regression\n                loss for each prediction bounding box.\n            valid_gt_weights (torch.Tensor): Validation of each\n                ground truth bounding box.\n\n        Returns:\n            dict: Losses of aggregation module.\n        \"\"\"\n    objectness_loss = self.objectness_loss(bbox_preds['obj_scores' + suffix].transpose(2, 1), objectness_targets, weight=objectness_weights)\n    (source2target_loss, target2source_loss) = self.center_loss(bbox_preds['center' + suffix], center_targets, src_weight=box_loss_weights, dst_weight=valid_gt_weights)\n    center_loss = source2target_loss + target2source_loss\n    dir_class_loss = self.dir_class_loss(bbox_preds['dir_class' + suffix].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    heading_label_one_hot = dir_class_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n    heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n    dir_res_norm = (bbox_preds['dir_res_norm' + suffix] * heading_label_one_hot).sum(dim=-1)\n    dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n    size_class_loss = self.size_class_loss(bbox_preds['size_class' + suffix].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n    one_hot_size_targets = box_loss_weights.new_zeros((batch_size, proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 1, 3)\n    size_residual_norm = (bbox_preds['size_res_norm' + suffix] * one_hot_size_targets_expand).sum(dim=2)\n    box_loss_weights_expand = box_loss_weights.unsqueeze(-1).repeat(1, 1, 3)\n    size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n    semantic_loss = self.semantic_loss(bbox_preds['sem_scores' + suffix].transpose(2, 1), mask_targets, weight=box_loss_weights)\n    losses = dict(objectness_loss=objectness_loss, semantic_loss=semantic_loss, center_loss=center_loss, dir_class_loss=dir_class_loss, dir_res_loss=dir_res_loss, size_class_loss=size_class_loss, size_res_loss=size_res_loss)\n    return losses",
        "mutated": [
            "def get_proposal_stage_loss(self, bbox_preds, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, mask_targets, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights, suffix=''):\n    if False:\n        i = 10\n    'Compute loss for the aggregation module.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of vote head.\\n            size_class_targets (torch.Tensor): Ground truth\\n                size class of each prediction bounding box.\\n            size_res_targets (torch.Tensor): Ground truth\\n                size residual of each prediction bounding box.\\n            dir_class_targets (torch.Tensor): Ground truth\\n                direction class of each prediction bounding box.\\n            dir_res_targets (torch.Tensor): Ground truth\\n                direction residual of each prediction bounding box.\\n            center_targets (torch.Tensor): Ground truth center\\n                of each prediction bounding box.\\n            mask_targets (torch.Tensor): Validation of each\\n                prediction bounding box.\\n            objectness_targets (torch.Tensor): Ground truth\\n                objectness label of each prediction bounding box.\\n            objectness_weights (torch.Tensor): Weights of objectness\\n                loss for each prediction bounding box.\\n            box_loss_weights (torch.Tensor): Weights of regression\\n                loss for each prediction bounding box.\\n            valid_gt_weights (torch.Tensor): Validation of each\\n                ground truth bounding box.\\n\\n        Returns:\\n            dict: Losses of aggregation module.\\n        '\n    objectness_loss = self.objectness_loss(bbox_preds['obj_scores' + suffix].transpose(2, 1), objectness_targets, weight=objectness_weights)\n    (source2target_loss, target2source_loss) = self.center_loss(bbox_preds['center' + suffix], center_targets, src_weight=box_loss_weights, dst_weight=valid_gt_weights)\n    center_loss = source2target_loss + target2source_loss\n    dir_class_loss = self.dir_class_loss(bbox_preds['dir_class' + suffix].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    heading_label_one_hot = dir_class_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n    heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n    dir_res_norm = (bbox_preds['dir_res_norm' + suffix] * heading_label_one_hot).sum(dim=-1)\n    dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n    size_class_loss = self.size_class_loss(bbox_preds['size_class' + suffix].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n    one_hot_size_targets = box_loss_weights.new_zeros((batch_size, proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 1, 3)\n    size_residual_norm = (bbox_preds['size_res_norm' + suffix] * one_hot_size_targets_expand).sum(dim=2)\n    box_loss_weights_expand = box_loss_weights.unsqueeze(-1).repeat(1, 1, 3)\n    size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n    semantic_loss = self.semantic_loss(bbox_preds['sem_scores' + suffix].transpose(2, 1), mask_targets, weight=box_loss_weights)\n    losses = dict(objectness_loss=objectness_loss, semantic_loss=semantic_loss, center_loss=center_loss, dir_class_loss=dir_class_loss, dir_res_loss=dir_res_loss, size_class_loss=size_class_loss, size_res_loss=size_res_loss)\n    return losses",
            "def get_proposal_stage_loss(self, bbox_preds, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, mask_targets, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights, suffix=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Compute loss for the aggregation module.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of vote head.\\n            size_class_targets (torch.Tensor): Ground truth\\n                size class of each prediction bounding box.\\n            size_res_targets (torch.Tensor): Ground truth\\n                size residual of each prediction bounding box.\\n            dir_class_targets (torch.Tensor): Ground truth\\n                direction class of each prediction bounding box.\\n            dir_res_targets (torch.Tensor): Ground truth\\n                direction residual of each prediction bounding box.\\n            center_targets (torch.Tensor): Ground truth center\\n                of each prediction bounding box.\\n            mask_targets (torch.Tensor): Validation of each\\n                prediction bounding box.\\n            objectness_targets (torch.Tensor): Ground truth\\n                objectness label of each prediction bounding box.\\n            objectness_weights (torch.Tensor): Weights of objectness\\n                loss for each prediction bounding box.\\n            box_loss_weights (torch.Tensor): Weights of regression\\n                loss for each prediction bounding box.\\n            valid_gt_weights (torch.Tensor): Validation of each\\n                ground truth bounding box.\\n\\n        Returns:\\n            dict: Losses of aggregation module.\\n        '\n    objectness_loss = self.objectness_loss(bbox_preds['obj_scores' + suffix].transpose(2, 1), objectness_targets, weight=objectness_weights)\n    (source2target_loss, target2source_loss) = self.center_loss(bbox_preds['center' + suffix], center_targets, src_weight=box_loss_weights, dst_weight=valid_gt_weights)\n    center_loss = source2target_loss + target2source_loss\n    dir_class_loss = self.dir_class_loss(bbox_preds['dir_class' + suffix].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    heading_label_one_hot = dir_class_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n    heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n    dir_res_norm = (bbox_preds['dir_res_norm' + suffix] * heading_label_one_hot).sum(dim=-1)\n    dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n    size_class_loss = self.size_class_loss(bbox_preds['size_class' + suffix].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n    one_hot_size_targets = box_loss_weights.new_zeros((batch_size, proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 1, 3)\n    size_residual_norm = (bbox_preds['size_res_norm' + suffix] * one_hot_size_targets_expand).sum(dim=2)\n    box_loss_weights_expand = box_loss_weights.unsqueeze(-1).repeat(1, 1, 3)\n    size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n    semantic_loss = self.semantic_loss(bbox_preds['sem_scores' + suffix].transpose(2, 1), mask_targets, weight=box_loss_weights)\n    losses = dict(objectness_loss=objectness_loss, semantic_loss=semantic_loss, center_loss=center_loss, dir_class_loss=dir_class_loss, dir_res_loss=dir_res_loss, size_class_loss=size_class_loss, size_res_loss=size_res_loss)\n    return losses",
            "def get_proposal_stage_loss(self, bbox_preds, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, mask_targets, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights, suffix=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Compute loss for the aggregation module.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of vote head.\\n            size_class_targets (torch.Tensor): Ground truth\\n                size class of each prediction bounding box.\\n            size_res_targets (torch.Tensor): Ground truth\\n                size residual of each prediction bounding box.\\n            dir_class_targets (torch.Tensor): Ground truth\\n                direction class of each prediction bounding box.\\n            dir_res_targets (torch.Tensor): Ground truth\\n                direction residual of each prediction bounding box.\\n            center_targets (torch.Tensor): Ground truth center\\n                of each prediction bounding box.\\n            mask_targets (torch.Tensor): Validation of each\\n                prediction bounding box.\\n            objectness_targets (torch.Tensor): Ground truth\\n                objectness label of each prediction bounding box.\\n            objectness_weights (torch.Tensor): Weights of objectness\\n                loss for each prediction bounding box.\\n            box_loss_weights (torch.Tensor): Weights of regression\\n                loss for each prediction bounding box.\\n            valid_gt_weights (torch.Tensor): Validation of each\\n                ground truth bounding box.\\n\\n        Returns:\\n            dict: Losses of aggregation module.\\n        '\n    objectness_loss = self.objectness_loss(bbox_preds['obj_scores' + suffix].transpose(2, 1), objectness_targets, weight=objectness_weights)\n    (source2target_loss, target2source_loss) = self.center_loss(bbox_preds['center' + suffix], center_targets, src_weight=box_loss_weights, dst_weight=valid_gt_weights)\n    center_loss = source2target_loss + target2source_loss\n    dir_class_loss = self.dir_class_loss(bbox_preds['dir_class' + suffix].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    heading_label_one_hot = dir_class_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n    heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n    dir_res_norm = (bbox_preds['dir_res_norm' + suffix] * heading_label_one_hot).sum(dim=-1)\n    dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n    size_class_loss = self.size_class_loss(bbox_preds['size_class' + suffix].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n    one_hot_size_targets = box_loss_weights.new_zeros((batch_size, proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 1, 3)\n    size_residual_norm = (bbox_preds['size_res_norm' + suffix] * one_hot_size_targets_expand).sum(dim=2)\n    box_loss_weights_expand = box_loss_weights.unsqueeze(-1).repeat(1, 1, 3)\n    size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n    semantic_loss = self.semantic_loss(bbox_preds['sem_scores' + suffix].transpose(2, 1), mask_targets, weight=box_loss_weights)\n    losses = dict(objectness_loss=objectness_loss, semantic_loss=semantic_loss, center_loss=center_loss, dir_class_loss=dir_class_loss, dir_res_loss=dir_res_loss, size_class_loss=size_class_loss, size_res_loss=size_res_loss)\n    return losses",
            "def get_proposal_stage_loss(self, bbox_preds, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, mask_targets, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights, suffix=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Compute loss for the aggregation module.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of vote head.\\n            size_class_targets (torch.Tensor): Ground truth\\n                size class of each prediction bounding box.\\n            size_res_targets (torch.Tensor): Ground truth\\n                size residual of each prediction bounding box.\\n            dir_class_targets (torch.Tensor): Ground truth\\n                direction class of each prediction bounding box.\\n            dir_res_targets (torch.Tensor): Ground truth\\n                direction residual of each prediction bounding box.\\n            center_targets (torch.Tensor): Ground truth center\\n                of each prediction bounding box.\\n            mask_targets (torch.Tensor): Validation of each\\n                prediction bounding box.\\n            objectness_targets (torch.Tensor): Ground truth\\n                objectness label of each prediction bounding box.\\n            objectness_weights (torch.Tensor): Weights of objectness\\n                loss for each prediction bounding box.\\n            box_loss_weights (torch.Tensor): Weights of regression\\n                loss for each prediction bounding box.\\n            valid_gt_weights (torch.Tensor): Validation of each\\n                ground truth bounding box.\\n\\n        Returns:\\n            dict: Losses of aggregation module.\\n        '\n    objectness_loss = self.objectness_loss(bbox_preds['obj_scores' + suffix].transpose(2, 1), objectness_targets, weight=objectness_weights)\n    (source2target_loss, target2source_loss) = self.center_loss(bbox_preds['center' + suffix], center_targets, src_weight=box_loss_weights, dst_weight=valid_gt_weights)\n    center_loss = source2target_loss + target2source_loss\n    dir_class_loss = self.dir_class_loss(bbox_preds['dir_class' + suffix].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    heading_label_one_hot = dir_class_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n    heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n    dir_res_norm = (bbox_preds['dir_res_norm' + suffix] * heading_label_one_hot).sum(dim=-1)\n    dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n    size_class_loss = self.size_class_loss(bbox_preds['size_class' + suffix].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n    one_hot_size_targets = box_loss_weights.new_zeros((batch_size, proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 1, 3)\n    size_residual_norm = (bbox_preds['size_res_norm' + suffix] * one_hot_size_targets_expand).sum(dim=2)\n    box_loss_weights_expand = box_loss_weights.unsqueeze(-1).repeat(1, 1, 3)\n    size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n    semantic_loss = self.semantic_loss(bbox_preds['sem_scores' + suffix].transpose(2, 1), mask_targets, weight=box_loss_weights)\n    losses = dict(objectness_loss=objectness_loss, semantic_loss=semantic_loss, center_loss=center_loss, dir_class_loss=dir_class_loss, dir_res_loss=dir_res_loss, size_class_loss=size_class_loss, size_res_loss=size_res_loss)\n    return losses",
            "def get_proposal_stage_loss(self, bbox_preds, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, mask_targets, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights, suffix=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Compute loss for the aggregation module.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of vote head.\\n            size_class_targets (torch.Tensor): Ground truth\\n                size class of each prediction bounding box.\\n            size_res_targets (torch.Tensor): Ground truth\\n                size residual of each prediction bounding box.\\n            dir_class_targets (torch.Tensor): Ground truth\\n                direction class of each prediction bounding box.\\n            dir_res_targets (torch.Tensor): Ground truth\\n                direction residual of each prediction bounding box.\\n            center_targets (torch.Tensor): Ground truth center\\n                of each prediction bounding box.\\n            mask_targets (torch.Tensor): Validation of each\\n                prediction bounding box.\\n            objectness_targets (torch.Tensor): Ground truth\\n                objectness label of each prediction bounding box.\\n            objectness_weights (torch.Tensor): Weights of objectness\\n                loss for each prediction bounding box.\\n            box_loss_weights (torch.Tensor): Weights of regression\\n                loss for each prediction bounding box.\\n            valid_gt_weights (torch.Tensor): Validation of each\\n                ground truth bounding box.\\n\\n        Returns:\\n            dict: Losses of aggregation module.\\n        '\n    objectness_loss = self.objectness_loss(bbox_preds['obj_scores' + suffix].transpose(2, 1), objectness_targets, weight=objectness_weights)\n    (source2target_loss, target2source_loss) = self.center_loss(bbox_preds['center' + suffix], center_targets, src_weight=box_loss_weights, dst_weight=valid_gt_weights)\n    center_loss = source2target_loss + target2source_loss\n    dir_class_loss = self.dir_class_loss(bbox_preds['dir_class' + suffix].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    heading_label_one_hot = dir_class_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n    heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n    dir_res_norm = (bbox_preds['dir_res_norm' + suffix] * heading_label_one_hot).sum(dim=-1)\n    dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n    size_class_loss = self.size_class_loss(bbox_preds['size_class' + suffix].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n    one_hot_size_targets = box_loss_weights.new_zeros((batch_size, proposal_num, self.num_sizes))\n    one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).repeat(1, 1, 1, 3)\n    size_residual_norm = (bbox_preds['size_res_norm' + suffix] * one_hot_size_targets_expand).sum(dim=2)\n    box_loss_weights_expand = box_loss_weights.unsqueeze(-1).repeat(1, 1, 3)\n    size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n    semantic_loss = self.semantic_loss(bbox_preds['sem_scores' + suffix].transpose(2, 1), mask_targets, weight=box_loss_weights)\n    losses = dict(objectness_loss=objectness_loss, semantic_loss=semantic_loss, center_loss=center_loss, dir_class_loss=dir_class_loss, dir_res_loss=dir_res_loss, size_class_loss=size_class_loss, size_res_loss=size_res_loss)\n    return losses"
        ]
    },
    {
        "func_name": "get_targets",
        "original": "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None):\n    \"\"\"Generate targets of proposal module.\n\n        Args:\n            points (list[torch.Tensor]): Points of each batch.\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\n                bboxes of each batch.\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\n                label of each batch.\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\n                label of each batch.\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\n\n        Returns:\n            tuple[torch.Tensor]: Targets of proposal module.\n        \"\"\"\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    aggregated_points = [bbox_preds['aggregated_points'][i] for i in range(len(gt_labels_3d))]\n    surface_center_pred = [bbox_preds['surface_center_pred'][i] for i in range(len(gt_labels_3d))]\n    line_center_pred = [bbox_preds['pred_line_center'][i] for i in range(len(gt_labels_3d))]\n    surface_center_object = [bbox_preds['surface_center_object'][i] for i in range(len(gt_labels_3d))]\n    line_center_object = [bbox_preds['line_center_object'][i] for i in range(len(gt_labels_3d))]\n    surface_sem_pred = [bbox_preds['surface_sem_pred'][i] for i in range(len(gt_labels_3d))]\n    line_sem_pred = [bbox_preds['sem_cls_scores_line'][i] for i in range(len(gt_labels_3d))]\n    (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, aggregated_points, surface_center_pred, line_center_pred, surface_center_object, line_center_object, surface_sem_pred, line_sem_pred)\n    cues_objectness_label = torch.stack(cues_objectness_label)\n    cues_sem_label = torch.stack(cues_sem_label)\n    proposal_objectness_label = torch.stack(proposal_objectness_label)\n    cues_mask = torch.stack(cues_mask)\n    cues_match_mask = torch.stack(cues_match_mask)\n    proposal_objectness_mask = torch.stack(proposal_objectness_mask)\n    cues_matching_label = torch.stack(cues_matching_label)\n    obj_surface_line_center = torch.stack(obj_surface_line_center)\n    return (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center)",
        "mutated": [
            "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None):\n    if False:\n        i = 10\n    'Generate targets of proposal module.\\n\\n        Args:\\n            points (list[torch.Tensor]): Points of each batch.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each batch.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\\n                label of each batch.\\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of proposal module.\\n        '\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    aggregated_points = [bbox_preds['aggregated_points'][i] for i in range(len(gt_labels_3d))]\n    surface_center_pred = [bbox_preds['surface_center_pred'][i] for i in range(len(gt_labels_3d))]\n    line_center_pred = [bbox_preds['pred_line_center'][i] for i in range(len(gt_labels_3d))]\n    surface_center_object = [bbox_preds['surface_center_object'][i] for i in range(len(gt_labels_3d))]\n    line_center_object = [bbox_preds['line_center_object'][i] for i in range(len(gt_labels_3d))]\n    surface_sem_pred = [bbox_preds['surface_sem_pred'][i] for i in range(len(gt_labels_3d))]\n    line_sem_pred = [bbox_preds['sem_cls_scores_line'][i] for i in range(len(gt_labels_3d))]\n    (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, aggregated_points, surface_center_pred, line_center_pred, surface_center_object, line_center_object, surface_sem_pred, line_sem_pred)\n    cues_objectness_label = torch.stack(cues_objectness_label)\n    cues_sem_label = torch.stack(cues_sem_label)\n    proposal_objectness_label = torch.stack(proposal_objectness_label)\n    cues_mask = torch.stack(cues_mask)\n    cues_match_mask = torch.stack(cues_match_mask)\n    proposal_objectness_mask = torch.stack(proposal_objectness_mask)\n    cues_matching_label = torch.stack(cues_matching_label)\n    obj_surface_line_center = torch.stack(obj_surface_line_center)\n    return (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center)",
            "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Generate targets of proposal module.\\n\\n        Args:\\n            points (list[torch.Tensor]): Points of each batch.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each batch.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\\n                label of each batch.\\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of proposal module.\\n        '\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    aggregated_points = [bbox_preds['aggregated_points'][i] for i in range(len(gt_labels_3d))]\n    surface_center_pred = [bbox_preds['surface_center_pred'][i] for i in range(len(gt_labels_3d))]\n    line_center_pred = [bbox_preds['pred_line_center'][i] for i in range(len(gt_labels_3d))]\n    surface_center_object = [bbox_preds['surface_center_object'][i] for i in range(len(gt_labels_3d))]\n    line_center_object = [bbox_preds['line_center_object'][i] for i in range(len(gt_labels_3d))]\n    surface_sem_pred = [bbox_preds['surface_sem_pred'][i] for i in range(len(gt_labels_3d))]\n    line_sem_pred = [bbox_preds['sem_cls_scores_line'][i] for i in range(len(gt_labels_3d))]\n    (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, aggregated_points, surface_center_pred, line_center_pred, surface_center_object, line_center_object, surface_sem_pred, line_sem_pred)\n    cues_objectness_label = torch.stack(cues_objectness_label)\n    cues_sem_label = torch.stack(cues_sem_label)\n    proposal_objectness_label = torch.stack(proposal_objectness_label)\n    cues_mask = torch.stack(cues_mask)\n    cues_match_mask = torch.stack(cues_match_mask)\n    proposal_objectness_mask = torch.stack(proposal_objectness_mask)\n    cues_matching_label = torch.stack(cues_matching_label)\n    obj_surface_line_center = torch.stack(obj_surface_line_center)\n    return (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center)",
            "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Generate targets of proposal module.\\n\\n        Args:\\n            points (list[torch.Tensor]): Points of each batch.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each batch.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\\n                label of each batch.\\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of proposal module.\\n        '\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    aggregated_points = [bbox_preds['aggregated_points'][i] for i in range(len(gt_labels_3d))]\n    surface_center_pred = [bbox_preds['surface_center_pred'][i] for i in range(len(gt_labels_3d))]\n    line_center_pred = [bbox_preds['pred_line_center'][i] for i in range(len(gt_labels_3d))]\n    surface_center_object = [bbox_preds['surface_center_object'][i] for i in range(len(gt_labels_3d))]\n    line_center_object = [bbox_preds['line_center_object'][i] for i in range(len(gt_labels_3d))]\n    surface_sem_pred = [bbox_preds['surface_sem_pred'][i] for i in range(len(gt_labels_3d))]\n    line_sem_pred = [bbox_preds['sem_cls_scores_line'][i] for i in range(len(gt_labels_3d))]\n    (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, aggregated_points, surface_center_pred, line_center_pred, surface_center_object, line_center_object, surface_sem_pred, line_sem_pred)\n    cues_objectness_label = torch.stack(cues_objectness_label)\n    cues_sem_label = torch.stack(cues_sem_label)\n    proposal_objectness_label = torch.stack(proposal_objectness_label)\n    cues_mask = torch.stack(cues_mask)\n    cues_match_mask = torch.stack(cues_match_mask)\n    proposal_objectness_mask = torch.stack(proposal_objectness_mask)\n    cues_matching_label = torch.stack(cues_matching_label)\n    obj_surface_line_center = torch.stack(obj_surface_line_center)\n    return (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center)",
            "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Generate targets of proposal module.\\n\\n        Args:\\n            points (list[torch.Tensor]): Points of each batch.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each batch.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\\n                label of each batch.\\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of proposal module.\\n        '\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    aggregated_points = [bbox_preds['aggregated_points'][i] for i in range(len(gt_labels_3d))]\n    surface_center_pred = [bbox_preds['surface_center_pred'][i] for i in range(len(gt_labels_3d))]\n    line_center_pred = [bbox_preds['pred_line_center'][i] for i in range(len(gt_labels_3d))]\n    surface_center_object = [bbox_preds['surface_center_object'][i] for i in range(len(gt_labels_3d))]\n    line_center_object = [bbox_preds['line_center_object'][i] for i in range(len(gt_labels_3d))]\n    surface_sem_pred = [bbox_preds['surface_sem_pred'][i] for i in range(len(gt_labels_3d))]\n    line_sem_pred = [bbox_preds['sem_cls_scores_line'][i] for i in range(len(gt_labels_3d))]\n    (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, aggregated_points, surface_center_pred, line_center_pred, surface_center_object, line_center_object, surface_sem_pred, line_sem_pred)\n    cues_objectness_label = torch.stack(cues_objectness_label)\n    cues_sem_label = torch.stack(cues_sem_label)\n    proposal_objectness_label = torch.stack(proposal_objectness_label)\n    cues_mask = torch.stack(cues_mask)\n    cues_match_mask = torch.stack(cues_match_mask)\n    proposal_objectness_mask = torch.stack(proposal_objectness_mask)\n    cues_matching_label = torch.stack(cues_matching_label)\n    obj_surface_line_center = torch.stack(obj_surface_line_center)\n    return (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center)",
            "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Generate targets of proposal module.\\n\\n        Args:\\n            points (list[torch.Tensor]): Points of each batch.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each batch.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\\n                label of each batch.\\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of proposal module.\\n        '\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    aggregated_points = [bbox_preds['aggregated_points'][i] for i in range(len(gt_labels_3d))]\n    surface_center_pred = [bbox_preds['surface_center_pred'][i] for i in range(len(gt_labels_3d))]\n    line_center_pred = [bbox_preds['pred_line_center'][i] for i in range(len(gt_labels_3d))]\n    surface_center_object = [bbox_preds['surface_center_object'][i] for i in range(len(gt_labels_3d))]\n    line_center_object = [bbox_preds['line_center_object'][i] for i in range(len(gt_labels_3d))]\n    surface_sem_pred = [bbox_preds['surface_sem_pred'][i] for i in range(len(gt_labels_3d))]\n    line_sem_pred = [bbox_preds['sem_cls_scores_line'][i] for i in range(len(gt_labels_3d))]\n    (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, aggregated_points, surface_center_pred, line_center_pred, surface_center_object, line_center_object, surface_sem_pred, line_sem_pred)\n    cues_objectness_label = torch.stack(cues_objectness_label)\n    cues_sem_label = torch.stack(cues_sem_label)\n    proposal_objectness_label = torch.stack(proposal_objectness_label)\n    cues_mask = torch.stack(cues_mask)\n    cues_match_mask = torch.stack(cues_match_mask)\n    proposal_objectness_mask = torch.stack(proposal_objectness_mask)\n    cues_matching_label = torch.stack(cues_matching_label)\n    obj_surface_line_center = torch.stack(obj_surface_line_center)\n    return (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center)"
        ]
    },
    {
        "func_name": "get_targets_single",
        "original": "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, aggregated_points=None, pred_surface_center=None, pred_line_center=None, pred_obj_surface_center=None, pred_obj_line_center=None, pred_surface_sem=None, pred_line_sem=None):\n    \"\"\"Generate targets for primitive cues for single batch.\n\n        Args:\n            points (torch.Tensor): Points of each batch.\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\n                boxes of each batch.\n            gt_labels_3d (torch.Tensor): Labels of each batch.\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\n                label of each batch.\n            pts_instance_mask (torch.Tensor): Point-wise instance\n                label of each batch.\n            aggregated_points (torch.Tensor): Aggregated points from\n                vote aggregation layer.\n            pred_surface_center (torch.Tensor): Prediction of surface center.\n            pred_line_center (torch.Tensor): Prediction of line center.\n            pred_obj_surface_center (torch.Tensor): Objectness prediction\n                of surface center.\n            pred_obj_line_center (torch.Tensor): Objectness prediction of\n                line center.\n            pred_surface_sem (torch.Tensor): Semantic prediction of\n                surface center.\n            pred_line_sem (torch.Tensor): Semantic prediction of line center.\n        Returns:\n            tuple[torch.Tensor]: Targets for primitive cues.\n        \"\"\"\n    device = points.device\n    gt_bboxes_3d = gt_bboxes_3d.to(device)\n    num_proposals = aggregated_points.shape[0]\n    gt_center = gt_bboxes_3d.gravity_center\n    (dist1, dist2, ind1, _) = chamfer_distance(aggregated_points.unsqueeze(0), gt_center.unsqueeze(0), reduction='none')\n    object_assignment = ind1.squeeze(0)\n    euclidean_dist1 = torch.sqrt(dist1.squeeze(0) + 1e-06)\n    proposal_objectness_label = euclidean_dist1.new_zeros(num_proposals, dtype=torch.long)\n    proposal_objectness_mask = euclidean_dist1.new_zeros(num_proposals)\n    gt_sem = gt_labels_3d[object_assignment]\n    (obj_surface_center, obj_line_center) = gt_bboxes_3d.get_surface_line_center()\n    obj_surface_center = obj_surface_center.reshape(-1, 6, 3).transpose(0, 1)\n    obj_line_center = obj_line_center.reshape(-1, 12, 3).transpose(0, 1)\n    obj_surface_center = obj_surface_center[:, object_assignment].reshape(1, -1, 3)\n    obj_line_center = obj_line_center[:, object_assignment].reshape(1, -1, 3)\n    surface_sem = torch.argmax(pred_surface_sem, dim=1).float()\n    line_sem = torch.argmax(pred_line_sem, dim=1).float()\n    (dist_surface, _, surface_ind, _) = chamfer_distance(obj_surface_center, pred_surface_center.unsqueeze(0), reduction='none')\n    (dist_line, _, line_ind, _) = chamfer_distance(obj_line_center, pred_line_center.unsqueeze(0), reduction='none')\n    surface_sel = pred_surface_center[surface_ind.squeeze(0)]\n    line_sel = pred_line_center[line_ind.squeeze(0)]\n    surface_sel_sem = surface_sem[surface_ind.squeeze(0)]\n    line_sel_sem = line_sem[line_ind.squeeze(0)]\n    surface_sel_sem_gt = gt_sem.repeat(6).float()\n    line_sel_sem_gt = gt_sem.repeat(12).float()\n    euclidean_dist_surface = torch.sqrt(dist_surface.squeeze(0) + 1e-06)\n    euclidean_dist_line = torch.sqrt(dist_line.squeeze(0) + 1e-06)\n    objectness_label_surface = euclidean_dist_line.new_zeros(num_proposals * 6, dtype=torch.long)\n    objectness_mask_surface = euclidean_dist_line.new_zeros(num_proposals * 6)\n    objectness_label_line = euclidean_dist_line.new_zeros(num_proposals * 12, dtype=torch.long)\n    objectness_mask_line = euclidean_dist_line.new_zeros(num_proposals * 12)\n    objectness_label_surface_sem = euclidean_dist_line.new_zeros(num_proposals * 6, dtype=torch.long)\n    objectness_label_line_sem = euclidean_dist_line.new_zeros(num_proposals * 12, dtype=torch.long)\n    euclidean_dist_obj_surface = torch.sqrt(((pred_obj_surface_center - surface_sel) ** 2).sum(dim=-1) + 1e-06)\n    euclidean_dist_obj_line = torch.sqrt(torch.sum((pred_obj_line_center - line_sel) ** 2, dim=-1) + 1e-06)\n    proposal_objectness_label[euclidean_dist1 < self.train_cfg['near_threshold']] = 1\n    proposal_objectness_mask[euclidean_dist1 < self.train_cfg['near_threshold']] = 1\n    proposal_objectness_mask[euclidean_dist1 > self.train_cfg['far_threshold']] = 1\n    objectness_label_surface[(euclidean_dist_obj_surface < self.train_cfg['label_surface_threshold']) * (euclidean_dist_surface < self.train_cfg['mask_surface_threshold'])] = 1\n    objectness_label_surface_sem[(euclidean_dist_obj_surface < self.train_cfg['label_surface_threshold']) * (euclidean_dist_surface < self.train_cfg['mask_surface_threshold']) * (surface_sel_sem == surface_sel_sem_gt)] = 1\n    objectness_label_line[(euclidean_dist_obj_line < self.train_cfg['label_line_threshold']) * (euclidean_dist_line < self.train_cfg['mask_line_threshold'])] = 1\n    objectness_label_line_sem[(euclidean_dist_obj_line < self.train_cfg['label_line_threshold']) * (euclidean_dist_line < self.train_cfg['mask_line_threshold']) * (line_sel_sem == line_sel_sem_gt)] = 1\n    objectness_label_surface_obj = proposal_objectness_label.repeat(6)\n    objectness_mask_surface_obj = proposal_objectness_mask.repeat(6)\n    objectness_label_line_obj = proposal_objectness_label.repeat(12)\n    objectness_mask_line_obj = proposal_objectness_mask.repeat(12)\n    objectness_mask_surface = objectness_mask_surface_obj\n    objectness_mask_line = objectness_mask_line_obj\n    cues_objectness_label = torch.cat((objectness_label_surface, objectness_label_line), 0)\n    cues_sem_label = torch.cat((objectness_label_surface_sem, objectness_label_line_sem), 0)\n    cues_mask = torch.cat((objectness_mask_surface, objectness_mask_line), 0)\n    objectness_label_surface *= objectness_label_surface_obj\n    objectness_label_line *= objectness_label_line_obj\n    cues_matching_label = torch.cat((objectness_label_surface, objectness_label_line), 0)\n    objectness_label_surface_sem *= objectness_label_surface_obj\n    objectness_label_line_sem *= objectness_label_line_obj\n    cues_match_mask = (torch.sum(cues_objectness_label.view(18, num_proposals), dim=0) >= 1).float()\n    obj_surface_line_center = torch.cat((obj_surface_center, obj_line_center), 1).squeeze(0)\n    return (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center)",
        "mutated": [
            "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, aggregated_points=None, pred_surface_center=None, pred_line_center=None, pred_obj_surface_center=None, pred_obj_line_center=None, pred_surface_sem=None, pred_line_sem=None):\n    if False:\n        i = 10\n    'Generate targets for primitive cues for single batch.\\n\\n        Args:\\n            points (torch.Tensor): Points of each batch.\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\\n                boxes of each batch.\\n            gt_labels_3d (torch.Tensor): Labels of each batch.\\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (torch.Tensor): Point-wise instance\\n                label of each batch.\\n            aggregated_points (torch.Tensor): Aggregated points from\\n                vote aggregation layer.\\n            pred_surface_center (torch.Tensor): Prediction of surface center.\\n            pred_line_center (torch.Tensor): Prediction of line center.\\n            pred_obj_surface_center (torch.Tensor): Objectness prediction\\n                of surface center.\\n            pred_obj_line_center (torch.Tensor): Objectness prediction of\\n                line center.\\n            pred_surface_sem (torch.Tensor): Semantic prediction of\\n                surface center.\\n            pred_line_sem (torch.Tensor): Semantic prediction of line center.\\n        Returns:\\n            tuple[torch.Tensor]: Targets for primitive cues.\\n        '\n    device = points.device\n    gt_bboxes_3d = gt_bboxes_3d.to(device)\n    num_proposals = aggregated_points.shape[0]\n    gt_center = gt_bboxes_3d.gravity_center\n    (dist1, dist2, ind1, _) = chamfer_distance(aggregated_points.unsqueeze(0), gt_center.unsqueeze(0), reduction='none')\n    object_assignment = ind1.squeeze(0)\n    euclidean_dist1 = torch.sqrt(dist1.squeeze(0) + 1e-06)\n    proposal_objectness_label = euclidean_dist1.new_zeros(num_proposals, dtype=torch.long)\n    proposal_objectness_mask = euclidean_dist1.new_zeros(num_proposals)\n    gt_sem = gt_labels_3d[object_assignment]\n    (obj_surface_center, obj_line_center) = gt_bboxes_3d.get_surface_line_center()\n    obj_surface_center = obj_surface_center.reshape(-1, 6, 3).transpose(0, 1)\n    obj_line_center = obj_line_center.reshape(-1, 12, 3).transpose(0, 1)\n    obj_surface_center = obj_surface_center[:, object_assignment].reshape(1, -1, 3)\n    obj_line_center = obj_line_center[:, object_assignment].reshape(1, -1, 3)\n    surface_sem = torch.argmax(pred_surface_sem, dim=1).float()\n    line_sem = torch.argmax(pred_line_sem, dim=1).float()\n    (dist_surface, _, surface_ind, _) = chamfer_distance(obj_surface_center, pred_surface_center.unsqueeze(0), reduction='none')\n    (dist_line, _, line_ind, _) = chamfer_distance(obj_line_center, pred_line_center.unsqueeze(0), reduction='none')\n    surface_sel = pred_surface_center[surface_ind.squeeze(0)]\n    line_sel = pred_line_center[line_ind.squeeze(0)]\n    surface_sel_sem = surface_sem[surface_ind.squeeze(0)]\n    line_sel_sem = line_sem[line_ind.squeeze(0)]\n    surface_sel_sem_gt = gt_sem.repeat(6).float()\n    line_sel_sem_gt = gt_sem.repeat(12).float()\n    euclidean_dist_surface = torch.sqrt(dist_surface.squeeze(0) + 1e-06)\n    euclidean_dist_line = torch.sqrt(dist_line.squeeze(0) + 1e-06)\n    objectness_label_surface = euclidean_dist_line.new_zeros(num_proposals * 6, dtype=torch.long)\n    objectness_mask_surface = euclidean_dist_line.new_zeros(num_proposals * 6)\n    objectness_label_line = euclidean_dist_line.new_zeros(num_proposals * 12, dtype=torch.long)\n    objectness_mask_line = euclidean_dist_line.new_zeros(num_proposals * 12)\n    objectness_label_surface_sem = euclidean_dist_line.new_zeros(num_proposals * 6, dtype=torch.long)\n    objectness_label_line_sem = euclidean_dist_line.new_zeros(num_proposals * 12, dtype=torch.long)\n    euclidean_dist_obj_surface = torch.sqrt(((pred_obj_surface_center - surface_sel) ** 2).sum(dim=-1) + 1e-06)\n    euclidean_dist_obj_line = torch.sqrt(torch.sum((pred_obj_line_center - line_sel) ** 2, dim=-1) + 1e-06)\n    proposal_objectness_label[euclidean_dist1 < self.train_cfg['near_threshold']] = 1\n    proposal_objectness_mask[euclidean_dist1 < self.train_cfg['near_threshold']] = 1\n    proposal_objectness_mask[euclidean_dist1 > self.train_cfg['far_threshold']] = 1\n    objectness_label_surface[(euclidean_dist_obj_surface < self.train_cfg['label_surface_threshold']) * (euclidean_dist_surface < self.train_cfg['mask_surface_threshold'])] = 1\n    objectness_label_surface_sem[(euclidean_dist_obj_surface < self.train_cfg['label_surface_threshold']) * (euclidean_dist_surface < self.train_cfg['mask_surface_threshold']) * (surface_sel_sem == surface_sel_sem_gt)] = 1\n    objectness_label_line[(euclidean_dist_obj_line < self.train_cfg['label_line_threshold']) * (euclidean_dist_line < self.train_cfg['mask_line_threshold'])] = 1\n    objectness_label_line_sem[(euclidean_dist_obj_line < self.train_cfg['label_line_threshold']) * (euclidean_dist_line < self.train_cfg['mask_line_threshold']) * (line_sel_sem == line_sel_sem_gt)] = 1\n    objectness_label_surface_obj = proposal_objectness_label.repeat(6)\n    objectness_mask_surface_obj = proposal_objectness_mask.repeat(6)\n    objectness_label_line_obj = proposal_objectness_label.repeat(12)\n    objectness_mask_line_obj = proposal_objectness_mask.repeat(12)\n    objectness_mask_surface = objectness_mask_surface_obj\n    objectness_mask_line = objectness_mask_line_obj\n    cues_objectness_label = torch.cat((objectness_label_surface, objectness_label_line), 0)\n    cues_sem_label = torch.cat((objectness_label_surface_sem, objectness_label_line_sem), 0)\n    cues_mask = torch.cat((objectness_mask_surface, objectness_mask_line), 0)\n    objectness_label_surface *= objectness_label_surface_obj\n    objectness_label_line *= objectness_label_line_obj\n    cues_matching_label = torch.cat((objectness_label_surface, objectness_label_line), 0)\n    objectness_label_surface_sem *= objectness_label_surface_obj\n    objectness_label_line_sem *= objectness_label_line_obj\n    cues_match_mask = (torch.sum(cues_objectness_label.view(18, num_proposals), dim=0) >= 1).float()\n    obj_surface_line_center = torch.cat((obj_surface_center, obj_line_center), 1).squeeze(0)\n    return (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center)",
            "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, aggregated_points=None, pred_surface_center=None, pred_line_center=None, pred_obj_surface_center=None, pred_obj_line_center=None, pred_surface_sem=None, pred_line_sem=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Generate targets for primitive cues for single batch.\\n\\n        Args:\\n            points (torch.Tensor): Points of each batch.\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\\n                boxes of each batch.\\n            gt_labels_3d (torch.Tensor): Labels of each batch.\\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (torch.Tensor): Point-wise instance\\n                label of each batch.\\n            aggregated_points (torch.Tensor): Aggregated points from\\n                vote aggregation layer.\\n            pred_surface_center (torch.Tensor): Prediction of surface center.\\n            pred_line_center (torch.Tensor): Prediction of line center.\\n            pred_obj_surface_center (torch.Tensor): Objectness prediction\\n                of surface center.\\n            pred_obj_line_center (torch.Tensor): Objectness prediction of\\n                line center.\\n            pred_surface_sem (torch.Tensor): Semantic prediction of\\n                surface center.\\n            pred_line_sem (torch.Tensor): Semantic prediction of line center.\\n        Returns:\\n            tuple[torch.Tensor]: Targets for primitive cues.\\n        '\n    device = points.device\n    gt_bboxes_3d = gt_bboxes_3d.to(device)\n    num_proposals = aggregated_points.shape[0]\n    gt_center = gt_bboxes_3d.gravity_center\n    (dist1, dist2, ind1, _) = chamfer_distance(aggregated_points.unsqueeze(0), gt_center.unsqueeze(0), reduction='none')\n    object_assignment = ind1.squeeze(0)\n    euclidean_dist1 = torch.sqrt(dist1.squeeze(0) + 1e-06)\n    proposal_objectness_label = euclidean_dist1.new_zeros(num_proposals, dtype=torch.long)\n    proposal_objectness_mask = euclidean_dist1.new_zeros(num_proposals)\n    gt_sem = gt_labels_3d[object_assignment]\n    (obj_surface_center, obj_line_center) = gt_bboxes_3d.get_surface_line_center()\n    obj_surface_center = obj_surface_center.reshape(-1, 6, 3).transpose(0, 1)\n    obj_line_center = obj_line_center.reshape(-1, 12, 3).transpose(0, 1)\n    obj_surface_center = obj_surface_center[:, object_assignment].reshape(1, -1, 3)\n    obj_line_center = obj_line_center[:, object_assignment].reshape(1, -1, 3)\n    surface_sem = torch.argmax(pred_surface_sem, dim=1).float()\n    line_sem = torch.argmax(pred_line_sem, dim=1).float()\n    (dist_surface, _, surface_ind, _) = chamfer_distance(obj_surface_center, pred_surface_center.unsqueeze(0), reduction='none')\n    (dist_line, _, line_ind, _) = chamfer_distance(obj_line_center, pred_line_center.unsqueeze(0), reduction='none')\n    surface_sel = pred_surface_center[surface_ind.squeeze(0)]\n    line_sel = pred_line_center[line_ind.squeeze(0)]\n    surface_sel_sem = surface_sem[surface_ind.squeeze(0)]\n    line_sel_sem = line_sem[line_ind.squeeze(0)]\n    surface_sel_sem_gt = gt_sem.repeat(6).float()\n    line_sel_sem_gt = gt_sem.repeat(12).float()\n    euclidean_dist_surface = torch.sqrt(dist_surface.squeeze(0) + 1e-06)\n    euclidean_dist_line = torch.sqrt(dist_line.squeeze(0) + 1e-06)\n    objectness_label_surface = euclidean_dist_line.new_zeros(num_proposals * 6, dtype=torch.long)\n    objectness_mask_surface = euclidean_dist_line.new_zeros(num_proposals * 6)\n    objectness_label_line = euclidean_dist_line.new_zeros(num_proposals * 12, dtype=torch.long)\n    objectness_mask_line = euclidean_dist_line.new_zeros(num_proposals * 12)\n    objectness_label_surface_sem = euclidean_dist_line.new_zeros(num_proposals * 6, dtype=torch.long)\n    objectness_label_line_sem = euclidean_dist_line.new_zeros(num_proposals * 12, dtype=torch.long)\n    euclidean_dist_obj_surface = torch.sqrt(((pred_obj_surface_center - surface_sel) ** 2).sum(dim=-1) + 1e-06)\n    euclidean_dist_obj_line = torch.sqrt(torch.sum((pred_obj_line_center - line_sel) ** 2, dim=-1) + 1e-06)\n    proposal_objectness_label[euclidean_dist1 < self.train_cfg['near_threshold']] = 1\n    proposal_objectness_mask[euclidean_dist1 < self.train_cfg['near_threshold']] = 1\n    proposal_objectness_mask[euclidean_dist1 > self.train_cfg['far_threshold']] = 1\n    objectness_label_surface[(euclidean_dist_obj_surface < self.train_cfg['label_surface_threshold']) * (euclidean_dist_surface < self.train_cfg['mask_surface_threshold'])] = 1\n    objectness_label_surface_sem[(euclidean_dist_obj_surface < self.train_cfg['label_surface_threshold']) * (euclidean_dist_surface < self.train_cfg['mask_surface_threshold']) * (surface_sel_sem == surface_sel_sem_gt)] = 1\n    objectness_label_line[(euclidean_dist_obj_line < self.train_cfg['label_line_threshold']) * (euclidean_dist_line < self.train_cfg['mask_line_threshold'])] = 1\n    objectness_label_line_sem[(euclidean_dist_obj_line < self.train_cfg['label_line_threshold']) * (euclidean_dist_line < self.train_cfg['mask_line_threshold']) * (line_sel_sem == line_sel_sem_gt)] = 1\n    objectness_label_surface_obj = proposal_objectness_label.repeat(6)\n    objectness_mask_surface_obj = proposal_objectness_mask.repeat(6)\n    objectness_label_line_obj = proposal_objectness_label.repeat(12)\n    objectness_mask_line_obj = proposal_objectness_mask.repeat(12)\n    objectness_mask_surface = objectness_mask_surface_obj\n    objectness_mask_line = objectness_mask_line_obj\n    cues_objectness_label = torch.cat((objectness_label_surface, objectness_label_line), 0)\n    cues_sem_label = torch.cat((objectness_label_surface_sem, objectness_label_line_sem), 0)\n    cues_mask = torch.cat((objectness_mask_surface, objectness_mask_line), 0)\n    objectness_label_surface *= objectness_label_surface_obj\n    objectness_label_line *= objectness_label_line_obj\n    cues_matching_label = torch.cat((objectness_label_surface, objectness_label_line), 0)\n    objectness_label_surface_sem *= objectness_label_surface_obj\n    objectness_label_line_sem *= objectness_label_line_obj\n    cues_match_mask = (torch.sum(cues_objectness_label.view(18, num_proposals), dim=0) >= 1).float()\n    obj_surface_line_center = torch.cat((obj_surface_center, obj_line_center), 1).squeeze(0)\n    return (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center)",
            "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, aggregated_points=None, pred_surface_center=None, pred_line_center=None, pred_obj_surface_center=None, pred_obj_line_center=None, pred_surface_sem=None, pred_line_sem=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Generate targets for primitive cues for single batch.\\n\\n        Args:\\n            points (torch.Tensor): Points of each batch.\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\\n                boxes of each batch.\\n            gt_labels_3d (torch.Tensor): Labels of each batch.\\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (torch.Tensor): Point-wise instance\\n                label of each batch.\\n            aggregated_points (torch.Tensor): Aggregated points from\\n                vote aggregation layer.\\n            pred_surface_center (torch.Tensor): Prediction of surface center.\\n            pred_line_center (torch.Tensor): Prediction of line center.\\n            pred_obj_surface_center (torch.Tensor): Objectness prediction\\n                of surface center.\\n            pred_obj_line_center (torch.Tensor): Objectness prediction of\\n                line center.\\n            pred_surface_sem (torch.Tensor): Semantic prediction of\\n                surface center.\\n            pred_line_sem (torch.Tensor): Semantic prediction of line center.\\n        Returns:\\n            tuple[torch.Tensor]: Targets for primitive cues.\\n        '\n    device = points.device\n    gt_bboxes_3d = gt_bboxes_3d.to(device)\n    num_proposals = aggregated_points.shape[0]\n    gt_center = gt_bboxes_3d.gravity_center\n    (dist1, dist2, ind1, _) = chamfer_distance(aggregated_points.unsqueeze(0), gt_center.unsqueeze(0), reduction='none')\n    object_assignment = ind1.squeeze(0)\n    euclidean_dist1 = torch.sqrt(dist1.squeeze(0) + 1e-06)\n    proposal_objectness_label = euclidean_dist1.new_zeros(num_proposals, dtype=torch.long)\n    proposal_objectness_mask = euclidean_dist1.new_zeros(num_proposals)\n    gt_sem = gt_labels_3d[object_assignment]\n    (obj_surface_center, obj_line_center) = gt_bboxes_3d.get_surface_line_center()\n    obj_surface_center = obj_surface_center.reshape(-1, 6, 3).transpose(0, 1)\n    obj_line_center = obj_line_center.reshape(-1, 12, 3).transpose(0, 1)\n    obj_surface_center = obj_surface_center[:, object_assignment].reshape(1, -1, 3)\n    obj_line_center = obj_line_center[:, object_assignment].reshape(1, -1, 3)\n    surface_sem = torch.argmax(pred_surface_sem, dim=1).float()\n    line_sem = torch.argmax(pred_line_sem, dim=1).float()\n    (dist_surface, _, surface_ind, _) = chamfer_distance(obj_surface_center, pred_surface_center.unsqueeze(0), reduction='none')\n    (dist_line, _, line_ind, _) = chamfer_distance(obj_line_center, pred_line_center.unsqueeze(0), reduction='none')\n    surface_sel = pred_surface_center[surface_ind.squeeze(0)]\n    line_sel = pred_line_center[line_ind.squeeze(0)]\n    surface_sel_sem = surface_sem[surface_ind.squeeze(0)]\n    line_sel_sem = line_sem[line_ind.squeeze(0)]\n    surface_sel_sem_gt = gt_sem.repeat(6).float()\n    line_sel_sem_gt = gt_sem.repeat(12).float()\n    euclidean_dist_surface = torch.sqrt(dist_surface.squeeze(0) + 1e-06)\n    euclidean_dist_line = torch.sqrt(dist_line.squeeze(0) + 1e-06)\n    objectness_label_surface = euclidean_dist_line.new_zeros(num_proposals * 6, dtype=torch.long)\n    objectness_mask_surface = euclidean_dist_line.new_zeros(num_proposals * 6)\n    objectness_label_line = euclidean_dist_line.new_zeros(num_proposals * 12, dtype=torch.long)\n    objectness_mask_line = euclidean_dist_line.new_zeros(num_proposals * 12)\n    objectness_label_surface_sem = euclidean_dist_line.new_zeros(num_proposals * 6, dtype=torch.long)\n    objectness_label_line_sem = euclidean_dist_line.new_zeros(num_proposals * 12, dtype=torch.long)\n    euclidean_dist_obj_surface = torch.sqrt(((pred_obj_surface_center - surface_sel) ** 2).sum(dim=-1) + 1e-06)\n    euclidean_dist_obj_line = torch.sqrt(torch.sum((pred_obj_line_center - line_sel) ** 2, dim=-1) + 1e-06)\n    proposal_objectness_label[euclidean_dist1 < self.train_cfg['near_threshold']] = 1\n    proposal_objectness_mask[euclidean_dist1 < self.train_cfg['near_threshold']] = 1\n    proposal_objectness_mask[euclidean_dist1 > self.train_cfg['far_threshold']] = 1\n    objectness_label_surface[(euclidean_dist_obj_surface < self.train_cfg['label_surface_threshold']) * (euclidean_dist_surface < self.train_cfg['mask_surface_threshold'])] = 1\n    objectness_label_surface_sem[(euclidean_dist_obj_surface < self.train_cfg['label_surface_threshold']) * (euclidean_dist_surface < self.train_cfg['mask_surface_threshold']) * (surface_sel_sem == surface_sel_sem_gt)] = 1\n    objectness_label_line[(euclidean_dist_obj_line < self.train_cfg['label_line_threshold']) * (euclidean_dist_line < self.train_cfg['mask_line_threshold'])] = 1\n    objectness_label_line_sem[(euclidean_dist_obj_line < self.train_cfg['label_line_threshold']) * (euclidean_dist_line < self.train_cfg['mask_line_threshold']) * (line_sel_sem == line_sel_sem_gt)] = 1\n    objectness_label_surface_obj = proposal_objectness_label.repeat(6)\n    objectness_mask_surface_obj = proposal_objectness_mask.repeat(6)\n    objectness_label_line_obj = proposal_objectness_label.repeat(12)\n    objectness_mask_line_obj = proposal_objectness_mask.repeat(12)\n    objectness_mask_surface = objectness_mask_surface_obj\n    objectness_mask_line = objectness_mask_line_obj\n    cues_objectness_label = torch.cat((objectness_label_surface, objectness_label_line), 0)\n    cues_sem_label = torch.cat((objectness_label_surface_sem, objectness_label_line_sem), 0)\n    cues_mask = torch.cat((objectness_mask_surface, objectness_mask_line), 0)\n    objectness_label_surface *= objectness_label_surface_obj\n    objectness_label_line *= objectness_label_line_obj\n    cues_matching_label = torch.cat((objectness_label_surface, objectness_label_line), 0)\n    objectness_label_surface_sem *= objectness_label_surface_obj\n    objectness_label_line_sem *= objectness_label_line_obj\n    cues_match_mask = (torch.sum(cues_objectness_label.view(18, num_proposals), dim=0) >= 1).float()\n    obj_surface_line_center = torch.cat((obj_surface_center, obj_line_center), 1).squeeze(0)\n    return (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center)",
            "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, aggregated_points=None, pred_surface_center=None, pred_line_center=None, pred_obj_surface_center=None, pred_obj_line_center=None, pred_surface_sem=None, pred_line_sem=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Generate targets for primitive cues for single batch.\\n\\n        Args:\\n            points (torch.Tensor): Points of each batch.\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\\n                boxes of each batch.\\n            gt_labels_3d (torch.Tensor): Labels of each batch.\\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (torch.Tensor): Point-wise instance\\n                label of each batch.\\n            aggregated_points (torch.Tensor): Aggregated points from\\n                vote aggregation layer.\\n            pred_surface_center (torch.Tensor): Prediction of surface center.\\n            pred_line_center (torch.Tensor): Prediction of line center.\\n            pred_obj_surface_center (torch.Tensor): Objectness prediction\\n                of surface center.\\n            pred_obj_line_center (torch.Tensor): Objectness prediction of\\n                line center.\\n            pred_surface_sem (torch.Tensor): Semantic prediction of\\n                surface center.\\n            pred_line_sem (torch.Tensor): Semantic prediction of line center.\\n        Returns:\\n            tuple[torch.Tensor]: Targets for primitive cues.\\n        '\n    device = points.device\n    gt_bboxes_3d = gt_bboxes_3d.to(device)\n    num_proposals = aggregated_points.shape[0]\n    gt_center = gt_bboxes_3d.gravity_center\n    (dist1, dist2, ind1, _) = chamfer_distance(aggregated_points.unsqueeze(0), gt_center.unsqueeze(0), reduction='none')\n    object_assignment = ind1.squeeze(0)\n    euclidean_dist1 = torch.sqrt(dist1.squeeze(0) + 1e-06)\n    proposal_objectness_label = euclidean_dist1.new_zeros(num_proposals, dtype=torch.long)\n    proposal_objectness_mask = euclidean_dist1.new_zeros(num_proposals)\n    gt_sem = gt_labels_3d[object_assignment]\n    (obj_surface_center, obj_line_center) = gt_bboxes_3d.get_surface_line_center()\n    obj_surface_center = obj_surface_center.reshape(-1, 6, 3).transpose(0, 1)\n    obj_line_center = obj_line_center.reshape(-1, 12, 3).transpose(0, 1)\n    obj_surface_center = obj_surface_center[:, object_assignment].reshape(1, -1, 3)\n    obj_line_center = obj_line_center[:, object_assignment].reshape(1, -1, 3)\n    surface_sem = torch.argmax(pred_surface_sem, dim=1).float()\n    line_sem = torch.argmax(pred_line_sem, dim=1).float()\n    (dist_surface, _, surface_ind, _) = chamfer_distance(obj_surface_center, pred_surface_center.unsqueeze(0), reduction='none')\n    (dist_line, _, line_ind, _) = chamfer_distance(obj_line_center, pred_line_center.unsqueeze(0), reduction='none')\n    surface_sel = pred_surface_center[surface_ind.squeeze(0)]\n    line_sel = pred_line_center[line_ind.squeeze(0)]\n    surface_sel_sem = surface_sem[surface_ind.squeeze(0)]\n    line_sel_sem = line_sem[line_ind.squeeze(0)]\n    surface_sel_sem_gt = gt_sem.repeat(6).float()\n    line_sel_sem_gt = gt_sem.repeat(12).float()\n    euclidean_dist_surface = torch.sqrt(dist_surface.squeeze(0) + 1e-06)\n    euclidean_dist_line = torch.sqrt(dist_line.squeeze(0) + 1e-06)\n    objectness_label_surface = euclidean_dist_line.new_zeros(num_proposals * 6, dtype=torch.long)\n    objectness_mask_surface = euclidean_dist_line.new_zeros(num_proposals * 6)\n    objectness_label_line = euclidean_dist_line.new_zeros(num_proposals * 12, dtype=torch.long)\n    objectness_mask_line = euclidean_dist_line.new_zeros(num_proposals * 12)\n    objectness_label_surface_sem = euclidean_dist_line.new_zeros(num_proposals * 6, dtype=torch.long)\n    objectness_label_line_sem = euclidean_dist_line.new_zeros(num_proposals * 12, dtype=torch.long)\n    euclidean_dist_obj_surface = torch.sqrt(((pred_obj_surface_center - surface_sel) ** 2).sum(dim=-1) + 1e-06)\n    euclidean_dist_obj_line = torch.sqrt(torch.sum((pred_obj_line_center - line_sel) ** 2, dim=-1) + 1e-06)\n    proposal_objectness_label[euclidean_dist1 < self.train_cfg['near_threshold']] = 1\n    proposal_objectness_mask[euclidean_dist1 < self.train_cfg['near_threshold']] = 1\n    proposal_objectness_mask[euclidean_dist1 > self.train_cfg['far_threshold']] = 1\n    objectness_label_surface[(euclidean_dist_obj_surface < self.train_cfg['label_surface_threshold']) * (euclidean_dist_surface < self.train_cfg['mask_surface_threshold'])] = 1\n    objectness_label_surface_sem[(euclidean_dist_obj_surface < self.train_cfg['label_surface_threshold']) * (euclidean_dist_surface < self.train_cfg['mask_surface_threshold']) * (surface_sel_sem == surface_sel_sem_gt)] = 1\n    objectness_label_line[(euclidean_dist_obj_line < self.train_cfg['label_line_threshold']) * (euclidean_dist_line < self.train_cfg['mask_line_threshold'])] = 1\n    objectness_label_line_sem[(euclidean_dist_obj_line < self.train_cfg['label_line_threshold']) * (euclidean_dist_line < self.train_cfg['mask_line_threshold']) * (line_sel_sem == line_sel_sem_gt)] = 1\n    objectness_label_surface_obj = proposal_objectness_label.repeat(6)\n    objectness_mask_surface_obj = proposal_objectness_mask.repeat(6)\n    objectness_label_line_obj = proposal_objectness_label.repeat(12)\n    objectness_mask_line_obj = proposal_objectness_mask.repeat(12)\n    objectness_mask_surface = objectness_mask_surface_obj\n    objectness_mask_line = objectness_mask_line_obj\n    cues_objectness_label = torch.cat((objectness_label_surface, objectness_label_line), 0)\n    cues_sem_label = torch.cat((objectness_label_surface_sem, objectness_label_line_sem), 0)\n    cues_mask = torch.cat((objectness_mask_surface, objectness_mask_line), 0)\n    objectness_label_surface *= objectness_label_surface_obj\n    objectness_label_line *= objectness_label_line_obj\n    cues_matching_label = torch.cat((objectness_label_surface, objectness_label_line), 0)\n    objectness_label_surface_sem *= objectness_label_surface_obj\n    objectness_label_line_sem *= objectness_label_line_obj\n    cues_match_mask = (torch.sum(cues_objectness_label.view(18, num_proposals), dim=0) >= 1).float()\n    obj_surface_line_center = torch.cat((obj_surface_center, obj_line_center), 1).squeeze(0)\n    return (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center)",
            "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, aggregated_points=None, pred_surface_center=None, pred_line_center=None, pred_obj_surface_center=None, pred_obj_line_center=None, pred_surface_sem=None, pred_line_sem=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Generate targets for primitive cues for single batch.\\n\\n        Args:\\n            points (torch.Tensor): Points of each batch.\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\\n                boxes of each batch.\\n            gt_labels_3d (torch.Tensor): Labels of each batch.\\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (torch.Tensor): Point-wise instance\\n                label of each batch.\\n            aggregated_points (torch.Tensor): Aggregated points from\\n                vote aggregation layer.\\n            pred_surface_center (torch.Tensor): Prediction of surface center.\\n            pred_line_center (torch.Tensor): Prediction of line center.\\n            pred_obj_surface_center (torch.Tensor): Objectness prediction\\n                of surface center.\\n            pred_obj_line_center (torch.Tensor): Objectness prediction of\\n                line center.\\n            pred_surface_sem (torch.Tensor): Semantic prediction of\\n                surface center.\\n            pred_line_sem (torch.Tensor): Semantic prediction of line center.\\n        Returns:\\n            tuple[torch.Tensor]: Targets for primitive cues.\\n        '\n    device = points.device\n    gt_bboxes_3d = gt_bboxes_3d.to(device)\n    num_proposals = aggregated_points.shape[0]\n    gt_center = gt_bboxes_3d.gravity_center\n    (dist1, dist2, ind1, _) = chamfer_distance(aggregated_points.unsqueeze(0), gt_center.unsqueeze(0), reduction='none')\n    object_assignment = ind1.squeeze(0)\n    euclidean_dist1 = torch.sqrt(dist1.squeeze(0) + 1e-06)\n    proposal_objectness_label = euclidean_dist1.new_zeros(num_proposals, dtype=torch.long)\n    proposal_objectness_mask = euclidean_dist1.new_zeros(num_proposals)\n    gt_sem = gt_labels_3d[object_assignment]\n    (obj_surface_center, obj_line_center) = gt_bboxes_3d.get_surface_line_center()\n    obj_surface_center = obj_surface_center.reshape(-1, 6, 3).transpose(0, 1)\n    obj_line_center = obj_line_center.reshape(-1, 12, 3).transpose(0, 1)\n    obj_surface_center = obj_surface_center[:, object_assignment].reshape(1, -1, 3)\n    obj_line_center = obj_line_center[:, object_assignment].reshape(1, -1, 3)\n    surface_sem = torch.argmax(pred_surface_sem, dim=1).float()\n    line_sem = torch.argmax(pred_line_sem, dim=1).float()\n    (dist_surface, _, surface_ind, _) = chamfer_distance(obj_surface_center, pred_surface_center.unsqueeze(0), reduction='none')\n    (dist_line, _, line_ind, _) = chamfer_distance(obj_line_center, pred_line_center.unsqueeze(0), reduction='none')\n    surface_sel = pred_surface_center[surface_ind.squeeze(0)]\n    line_sel = pred_line_center[line_ind.squeeze(0)]\n    surface_sel_sem = surface_sem[surface_ind.squeeze(0)]\n    line_sel_sem = line_sem[line_ind.squeeze(0)]\n    surface_sel_sem_gt = gt_sem.repeat(6).float()\n    line_sel_sem_gt = gt_sem.repeat(12).float()\n    euclidean_dist_surface = torch.sqrt(dist_surface.squeeze(0) + 1e-06)\n    euclidean_dist_line = torch.sqrt(dist_line.squeeze(0) + 1e-06)\n    objectness_label_surface = euclidean_dist_line.new_zeros(num_proposals * 6, dtype=torch.long)\n    objectness_mask_surface = euclidean_dist_line.new_zeros(num_proposals * 6)\n    objectness_label_line = euclidean_dist_line.new_zeros(num_proposals * 12, dtype=torch.long)\n    objectness_mask_line = euclidean_dist_line.new_zeros(num_proposals * 12)\n    objectness_label_surface_sem = euclidean_dist_line.new_zeros(num_proposals * 6, dtype=torch.long)\n    objectness_label_line_sem = euclidean_dist_line.new_zeros(num_proposals * 12, dtype=torch.long)\n    euclidean_dist_obj_surface = torch.sqrt(((pred_obj_surface_center - surface_sel) ** 2).sum(dim=-1) + 1e-06)\n    euclidean_dist_obj_line = torch.sqrt(torch.sum((pred_obj_line_center - line_sel) ** 2, dim=-1) + 1e-06)\n    proposal_objectness_label[euclidean_dist1 < self.train_cfg['near_threshold']] = 1\n    proposal_objectness_mask[euclidean_dist1 < self.train_cfg['near_threshold']] = 1\n    proposal_objectness_mask[euclidean_dist1 > self.train_cfg['far_threshold']] = 1\n    objectness_label_surface[(euclidean_dist_obj_surface < self.train_cfg['label_surface_threshold']) * (euclidean_dist_surface < self.train_cfg['mask_surface_threshold'])] = 1\n    objectness_label_surface_sem[(euclidean_dist_obj_surface < self.train_cfg['label_surface_threshold']) * (euclidean_dist_surface < self.train_cfg['mask_surface_threshold']) * (surface_sel_sem == surface_sel_sem_gt)] = 1\n    objectness_label_line[(euclidean_dist_obj_line < self.train_cfg['label_line_threshold']) * (euclidean_dist_line < self.train_cfg['mask_line_threshold'])] = 1\n    objectness_label_line_sem[(euclidean_dist_obj_line < self.train_cfg['label_line_threshold']) * (euclidean_dist_line < self.train_cfg['mask_line_threshold']) * (line_sel_sem == line_sel_sem_gt)] = 1\n    objectness_label_surface_obj = proposal_objectness_label.repeat(6)\n    objectness_mask_surface_obj = proposal_objectness_mask.repeat(6)\n    objectness_label_line_obj = proposal_objectness_label.repeat(12)\n    objectness_mask_line_obj = proposal_objectness_mask.repeat(12)\n    objectness_mask_surface = objectness_mask_surface_obj\n    objectness_mask_line = objectness_mask_line_obj\n    cues_objectness_label = torch.cat((objectness_label_surface, objectness_label_line), 0)\n    cues_sem_label = torch.cat((objectness_label_surface_sem, objectness_label_line_sem), 0)\n    cues_mask = torch.cat((objectness_mask_surface, objectness_mask_line), 0)\n    objectness_label_surface *= objectness_label_surface_obj\n    objectness_label_line *= objectness_label_line_obj\n    cues_matching_label = torch.cat((objectness_label_surface, objectness_label_line), 0)\n    objectness_label_surface_sem *= objectness_label_surface_obj\n    objectness_label_line_sem *= objectness_label_line_obj\n    cues_match_mask = (torch.sum(cues_objectness_label.view(18, num_proposals), dim=0) >= 1).float()\n    obj_surface_line_center = torch.cat((obj_surface_center, obj_line_center), 1).squeeze(0)\n    return (cues_objectness_label, cues_sem_label, proposal_objectness_label, cues_mask, cues_match_mask, proposal_objectness_mask, cues_matching_label, obj_surface_line_center)"
        ]
    }
]