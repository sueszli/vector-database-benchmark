[
    {
        "func_name": "__init__",
        "original": "def __init__(self, D, V, context_sz):\n    self.D = D\n    self.V = V\n    self.context_sz = context_sz",
        "mutated": [
            "def __init__(self, D, V, context_sz):\n    if False:\n        i = 10\n    self.D = D\n    self.V = V\n    self.context_sz = context_sz",
            "def __init__(self, D, V, context_sz):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.D = D\n    self.V = V\n    self.context_sz = context_sz",
            "def __init__(self, D, V, context_sz):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.D = D\n    self.V = V\n    self.context_sz = context_sz",
            "def __init__(self, D, V, context_sz):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.D = D\n    self.V = V\n    self.context_sz = context_sz",
            "def __init__(self, D, V, context_sz):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.D = D\n    self.V = V\n    self.context_sz = context_sz"
        ]
    },
    {
        "func_name": "fit",
        "original": "def fit(self, sentences, cc_matrix=None):\n    t0 = datetime.now()\n    V = self.V\n    D = self.D\n    if not os.path.exists(cc_matrix):\n        X = np.zeros((V, V))\n        N = len(sentences)\n        print('number of sentences to process:', N)\n        it = 0\n        for sentence in sentences:\n            it += 1\n            if it % 10000 == 0:\n                print('processed', it, '/', N)\n            n = len(sentence)\n            for i in range(n):\n                wi = sentence[i]\n                start = max(0, i - self.context_sz)\n                end = min(n, i + self.context_sz)\n                if i - self.context_sz < 0:\n                    points = 1.0 / (i + 1)\n                    X[wi, 0] += points\n                    X[0, wi] += points\n                if i + self.context_sz > n:\n                    points = 1.0 / (n - i)\n                    X[wi, 1] += points\n                    X[1, wi] += points\n                for j in range(start, i):\n                    wj = sentence[j]\n                    points = 1.0 / (i - j)\n                    X[wi, wj] += points\n                    X[wj, wi] += points\n                for j in range(i + 1, end):\n                    wj = sentence[j]\n                    points = 1.0 / (j - i)\n                    X[wi, wj] += points\n                    X[wj, wi] += points\n        np.save(cc_matrix, X)\n    else:\n        X = np.load(cc_matrix)\n    print('max in X:', X.max())\n    logX = np.log(X + 1)\n    print('max in log(X):', logX.max())\n    print('time to build co-occurrence matrix:', datetime.now() - t0)\n    mu = logX.mean()\n    model = TruncatedSVD(n_components=D)\n    Z = model.fit_transform(logX - mu)\n    S = np.diag(model.explained_variance_)\n    Sinv = np.linalg.inv(S)\n    self.W = Z.dot(Sinv)\n    self.U = model.components_.T\n    delta = self.W.dot(S).dot(self.U.T) + mu - logX\n    cost = (delta * delta).sum()\n    print('svd cost:', cost)",
        "mutated": [
            "def fit(self, sentences, cc_matrix=None):\n    if False:\n        i = 10\n    t0 = datetime.now()\n    V = self.V\n    D = self.D\n    if not os.path.exists(cc_matrix):\n        X = np.zeros((V, V))\n        N = len(sentences)\n        print('number of sentences to process:', N)\n        it = 0\n        for sentence in sentences:\n            it += 1\n            if it % 10000 == 0:\n                print('processed', it, '/', N)\n            n = len(sentence)\n            for i in range(n):\n                wi = sentence[i]\n                start = max(0, i - self.context_sz)\n                end = min(n, i + self.context_sz)\n                if i - self.context_sz < 0:\n                    points = 1.0 / (i + 1)\n                    X[wi, 0] += points\n                    X[0, wi] += points\n                if i + self.context_sz > n:\n                    points = 1.0 / (n - i)\n                    X[wi, 1] += points\n                    X[1, wi] += points\n                for j in range(start, i):\n                    wj = sentence[j]\n                    points = 1.0 / (i - j)\n                    X[wi, wj] += points\n                    X[wj, wi] += points\n                for j in range(i + 1, end):\n                    wj = sentence[j]\n                    points = 1.0 / (j - i)\n                    X[wi, wj] += points\n                    X[wj, wi] += points\n        np.save(cc_matrix, X)\n    else:\n        X = np.load(cc_matrix)\n    print('max in X:', X.max())\n    logX = np.log(X + 1)\n    print('max in log(X):', logX.max())\n    print('time to build co-occurrence matrix:', datetime.now() - t0)\n    mu = logX.mean()\n    model = TruncatedSVD(n_components=D)\n    Z = model.fit_transform(logX - mu)\n    S = np.diag(model.explained_variance_)\n    Sinv = np.linalg.inv(S)\n    self.W = Z.dot(Sinv)\n    self.U = model.components_.T\n    delta = self.W.dot(S).dot(self.U.T) + mu - logX\n    cost = (delta * delta).sum()\n    print('svd cost:', cost)",
            "def fit(self, sentences, cc_matrix=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    t0 = datetime.now()\n    V = self.V\n    D = self.D\n    if not os.path.exists(cc_matrix):\n        X = np.zeros((V, V))\n        N = len(sentences)\n        print('number of sentences to process:', N)\n        it = 0\n        for sentence in sentences:\n            it += 1\n            if it % 10000 == 0:\n                print('processed', it, '/', N)\n            n = len(sentence)\n            for i in range(n):\n                wi = sentence[i]\n                start = max(0, i - self.context_sz)\n                end = min(n, i + self.context_sz)\n                if i - self.context_sz < 0:\n                    points = 1.0 / (i + 1)\n                    X[wi, 0] += points\n                    X[0, wi] += points\n                if i + self.context_sz > n:\n                    points = 1.0 / (n - i)\n                    X[wi, 1] += points\n                    X[1, wi] += points\n                for j in range(start, i):\n                    wj = sentence[j]\n                    points = 1.0 / (i - j)\n                    X[wi, wj] += points\n                    X[wj, wi] += points\n                for j in range(i + 1, end):\n                    wj = sentence[j]\n                    points = 1.0 / (j - i)\n                    X[wi, wj] += points\n                    X[wj, wi] += points\n        np.save(cc_matrix, X)\n    else:\n        X = np.load(cc_matrix)\n    print('max in X:', X.max())\n    logX = np.log(X + 1)\n    print('max in log(X):', logX.max())\n    print('time to build co-occurrence matrix:', datetime.now() - t0)\n    mu = logX.mean()\n    model = TruncatedSVD(n_components=D)\n    Z = model.fit_transform(logX - mu)\n    S = np.diag(model.explained_variance_)\n    Sinv = np.linalg.inv(S)\n    self.W = Z.dot(Sinv)\n    self.U = model.components_.T\n    delta = self.W.dot(S).dot(self.U.T) + mu - logX\n    cost = (delta * delta).sum()\n    print('svd cost:', cost)",
            "def fit(self, sentences, cc_matrix=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    t0 = datetime.now()\n    V = self.V\n    D = self.D\n    if not os.path.exists(cc_matrix):\n        X = np.zeros((V, V))\n        N = len(sentences)\n        print('number of sentences to process:', N)\n        it = 0\n        for sentence in sentences:\n            it += 1\n            if it % 10000 == 0:\n                print('processed', it, '/', N)\n            n = len(sentence)\n            for i in range(n):\n                wi = sentence[i]\n                start = max(0, i - self.context_sz)\n                end = min(n, i + self.context_sz)\n                if i - self.context_sz < 0:\n                    points = 1.0 / (i + 1)\n                    X[wi, 0] += points\n                    X[0, wi] += points\n                if i + self.context_sz > n:\n                    points = 1.0 / (n - i)\n                    X[wi, 1] += points\n                    X[1, wi] += points\n                for j in range(start, i):\n                    wj = sentence[j]\n                    points = 1.0 / (i - j)\n                    X[wi, wj] += points\n                    X[wj, wi] += points\n                for j in range(i + 1, end):\n                    wj = sentence[j]\n                    points = 1.0 / (j - i)\n                    X[wi, wj] += points\n                    X[wj, wi] += points\n        np.save(cc_matrix, X)\n    else:\n        X = np.load(cc_matrix)\n    print('max in X:', X.max())\n    logX = np.log(X + 1)\n    print('max in log(X):', logX.max())\n    print('time to build co-occurrence matrix:', datetime.now() - t0)\n    mu = logX.mean()\n    model = TruncatedSVD(n_components=D)\n    Z = model.fit_transform(logX - mu)\n    S = np.diag(model.explained_variance_)\n    Sinv = np.linalg.inv(S)\n    self.W = Z.dot(Sinv)\n    self.U = model.components_.T\n    delta = self.W.dot(S).dot(self.U.T) + mu - logX\n    cost = (delta * delta).sum()\n    print('svd cost:', cost)",
            "def fit(self, sentences, cc_matrix=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    t0 = datetime.now()\n    V = self.V\n    D = self.D\n    if not os.path.exists(cc_matrix):\n        X = np.zeros((V, V))\n        N = len(sentences)\n        print('number of sentences to process:', N)\n        it = 0\n        for sentence in sentences:\n            it += 1\n            if it % 10000 == 0:\n                print('processed', it, '/', N)\n            n = len(sentence)\n            for i in range(n):\n                wi = sentence[i]\n                start = max(0, i - self.context_sz)\n                end = min(n, i + self.context_sz)\n                if i - self.context_sz < 0:\n                    points = 1.0 / (i + 1)\n                    X[wi, 0] += points\n                    X[0, wi] += points\n                if i + self.context_sz > n:\n                    points = 1.0 / (n - i)\n                    X[wi, 1] += points\n                    X[1, wi] += points\n                for j in range(start, i):\n                    wj = sentence[j]\n                    points = 1.0 / (i - j)\n                    X[wi, wj] += points\n                    X[wj, wi] += points\n                for j in range(i + 1, end):\n                    wj = sentence[j]\n                    points = 1.0 / (j - i)\n                    X[wi, wj] += points\n                    X[wj, wi] += points\n        np.save(cc_matrix, X)\n    else:\n        X = np.load(cc_matrix)\n    print('max in X:', X.max())\n    logX = np.log(X + 1)\n    print('max in log(X):', logX.max())\n    print('time to build co-occurrence matrix:', datetime.now() - t0)\n    mu = logX.mean()\n    model = TruncatedSVD(n_components=D)\n    Z = model.fit_transform(logX - mu)\n    S = np.diag(model.explained_variance_)\n    Sinv = np.linalg.inv(S)\n    self.W = Z.dot(Sinv)\n    self.U = model.components_.T\n    delta = self.W.dot(S).dot(self.U.T) + mu - logX\n    cost = (delta * delta).sum()\n    print('svd cost:', cost)",
            "def fit(self, sentences, cc_matrix=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    t0 = datetime.now()\n    V = self.V\n    D = self.D\n    if not os.path.exists(cc_matrix):\n        X = np.zeros((V, V))\n        N = len(sentences)\n        print('number of sentences to process:', N)\n        it = 0\n        for sentence in sentences:\n            it += 1\n            if it % 10000 == 0:\n                print('processed', it, '/', N)\n            n = len(sentence)\n            for i in range(n):\n                wi = sentence[i]\n                start = max(0, i - self.context_sz)\n                end = min(n, i + self.context_sz)\n                if i - self.context_sz < 0:\n                    points = 1.0 / (i + 1)\n                    X[wi, 0] += points\n                    X[0, wi] += points\n                if i + self.context_sz > n:\n                    points = 1.0 / (n - i)\n                    X[wi, 1] += points\n                    X[1, wi] += points\n                for j in range(start, i):\n                    wj = sentence[j]\n                    points = 1.0 / (i - j)\n                    X[wi, wj] += points\n                    X[wj, wi] += points\n                for j in range(i + 1, end):\n                    wj = sentence[j]\n                    points = 1.0 / (j - i)\n                    X[wi, wj] += points\n                    X[wj, wi] += points\n        np.save(cc_matrix, X)\n    else:\n        X = np.load(cc_matrix)\n    print('max in X:', X.max())\n    logX = np.log(X + 1)\n    print('max in log(X):', logX.max())\n    print('time to build co-occurrence matrix:', datetime.now() - t0)\n    mu = logX.mean()\n    model = TruncatedSVD(n_components=D)\n    Z = model.fit_transform(logX - mu)\n    S = np.diag(model.explained_variance_)\n    Sinv = np.linalg.inv(S)\n    self.W = Z.dot(Sinv)\n    self.U = model.components_.T\n    delta = self.W.dot(S).dot(self.U.T) + mu - logX\n    cost = (delta * delta).sum()\n    print('svd cost:', cost)"
        ]
    },
    {
        "func_name": "save",
        "original": "def save(self, fn):\n    arrays = [self.W, self.U.T]\n    np.savez(fn, *arrays)",
        "mutated": [
            "def save(self, fn):\n    if False:\n        i = 10\n    arrays = [self.W, self.U.T]\n    np.savez(fn, *arrays)",
            "def save(self, fn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    arrays = [self.W, self.U.T]\n    np.savez(fn, *arrays)",
            "def save(self, fn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    arrays = [self.W, self.U.T]\n    np.savez(fn, *arrays)",
            "def save(self, fn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    arrays = [self.W, self.U.T]\n    np.savez(fn, *arrays)",
            "def save(self, fn):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    arrays = [self.W, self.U.T]\n    np.savez(fn, *arrays)"
        ]
    },
    {
        "func_name": "main",
        "original": "def main(we_file, w2i_file, use_brown=True, n_files=100):\n    if use_brown:\n        cc_matrix = 'cc_matrix_brown.npy'\n    else:\n        cc_matrix = 'cc_matrix_%s.npy' % n_files\n    if os.path.exists(cc_matrix):\n        with open(w2i_file) as f:\n            word2idx = json.load(f)\n        sentences = []\n    else:\n        if use_brown:\n            keep_words = set(['king', 'man', 'woman', 'france', 'paris', 'london', 'rome', 'italy', 'britain', 'england', 'french', 'english', 'japan', 'japanese', 'chinese', 'italian', 'australia', 'australian', 'december', 'november', 'june', 'january', 'february', 'march', 'april', 'may', 'july', 'august', 'september', 'october'])\n            (sentences, word2idx) = get_sentences_with_word2idx_limit_vocab(n_vocab=5000, keep_words=keep_words)\n        else:\n            (sentences, word2idx) = get_wikipedia_data(n_files=n_files, n_vocab=2000)\n        with open(w2i_file, 'w') as f:\n            json.dump(word2idx, f)\n    V = len(word2idx)\n    model = Glove(100, V, 10)\n    model.fit(sentences, cc_matrix=cc_matrix)\n    model.save(we_file)",
        "mutated": [
            "def main(we_file, w2i_file, use_brown=True, n_files=100):\n    if False:\n        i = 10\n    if use_brown:\n        cc_matrix = 'cc_matrix_brown.npy'\n    else:\n        cc_matrix = 'cc_matrix_%s.npy' % n_files\n    if os.path.exists(cc_matrix):\n        with open(w2i_file) as f:\n            word2idx = json.load(f)\n        sentences = []\n    else:\n        if use_brown:\n            keep_words = set(['king', 'man', 'woman', 'france', 'paris', 'london', 'rome', 'italy', 'britain', 'england', 'french', 'english', 'japan', 'japanese', 'chinese', 'italian', 'australia', 'australian', 'december', 'november', 'june', 'january', 'february', 'march', 'april', 'may', 'july', 'august', 'september', 'october'])\n            (sentences, word2idx) = get_sentences_with_word2idx_limit_vocab(n_vocab=5000, keep_words=keep_words)\n        else:\n            (sentences, word2idx) = get_wikipedia_data(n_files=n_files, n_vocab=2000)\n        with open(w2i_file, 'w') as f:\n            json.dump(word2idx, f)\n    V = len(word2idx)\n    model = Glove(100, V, 10)\n    model.fit(sentences, cc_matrix=cc_matrix)\n    model.save(we_file)",
            "def main(we_file, w2i_file, use_brown=True, n_files=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if use_brown:\n        cc_matrix = 'cc_matrix_brown.npy'\n    else:\n        cc_matrix = 'cc_matrix_%s.npy' % n_files\n    if os.path.exists(cc_matrix):\n        with open(w2i_file) as f:\n            word2idx = json.load(f)\n        sentences = []\n    else:\n        if use_brown:\n            keep_words = set(['king', 'man', 'woman', 'france', 'paris', 'london', 'rome', 'italy', 'britain', 'england', 'french', 'english', 'japan', 'japanese', 'chinese', 'italian', 'australia', 'australian', 'december', 'november', 'june', 'january', 'february', 'march', 'april', 'may', 'july', 'august', 'september', 'october'])\n            (sentences, word2idx) = get_sentences_with_word2idx_limit_vocab(n_vocab=5000, keep_words=keep_words)\n        else:\n            (sentences, word2idx) = get_wikipedia_data(n_files=n_files, n_vocab=2000)\n        with open(w2i_file, 'w') as f:\n            json.dump(word2idx, f)\n    V = len(word2idx)\n    model = Glove(100, V, 10)\n    model.fit(sentences, cc_matrix=cc_matrix)\n    model.save(we_file)",
            "def main(we_file, w2i_file, use_brown=True, n_files=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if use_brown:\n        cc_matrix = 'cc_matrix_brown.npy'\n    else:\n        cc_matrix = 'cc_matrix_%s.npy' % n_files\n    if os.path.exists(cc_matrix):\n        with open(w2i_file) as f:\n            word2idx = json.load(f)\n        sentences = []\n    else:\n        if use_brown:\n            keep_words = set(['king', 'man', 'woman', 'france', 'paris', 'london', 'rome', 'italy', 'britain', 'england', 'french', 'english', 'japan', 'japanese', 'chinese', 'italian', 'australia', 'australian', 'december', 'november', 'june', 'january', 'february', 'march', 'april', 'may', 'july', 'august', 'september', 'october'])\n            (sentences, word2idx) = get_sentences_with_word2idx_limit_vocab(n_vocab=5000, keep_words=keep_words)\n        else:\n            (sentences, word2idx) = get_wikipedia_data(n_files=n_files, n_vocab=2000)\n        with open(w2i_file, 'w') as f:\n            json.dump(word2idx, f)\n    V = len(word2idx)\n    model = Glove(100, V, 10)\n    model.fit(sentences, cc_matrix=cc_matrix)\n    model.save(we_file)",
            "def main(we_file, w2i_file, use_brown=True, n_files=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if use_brown:\n        cc_matrix = 'cc_matrix_brown.npy'\n    else:\n        cc_matrix = 'cc_matrix_%s.npy' % n_files\n    if os.path.exists(cc_matrix):\n        with open(w2i_file) as f:\n            word2idx = json.load(f)\n        sentences = []\n    else:\n        if use_brown:\n            keep_words = set(['king', 'man', 'woman', 'france', 'paris', 'london', 'rome', 'italy', 'britain', 'england', 'french', 'english', 'japan', 'japanese', 'chinese', 'italian', 'australia', 'australian', 'december', 'november', 'june', 'january', 'february', 'march', 'april', 'may', 'july', 'august', 'september', 'october'])\n            (sentences, word2idx) = get_sentences_with_word2idx_limit_vocab(n_vocab=5000, keep_words=keep_words)\n        else:\n            (sentences, word2idx) = get_wikipedia_data(n_files=n_files, n_vocab=2000)\n        with open(w2i_file, 'w') as f:\n            json.dump(word2idx, f)\n    V = len(word2idx)\n    model = Glove(100, V, 10)\n    model.fit(sentences, cc_matrix=cc_matrix)\n    model.save(we_file)",
            "def main(we_file, w2i_file, use_brown=True, n_files=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if use_brown:\n        cc_matrix = 'cc_matrix_brown.npy'\n    else:\n        cc_matrix = 'cc_matrix_%s.npy' % n_files\n    if os.path.exists(cc_matrix):\n        with open(w2i_file) as f:\n            word2idx = json.load(f)\n        sentences = []\n    else:\n        if use_brown:\n            keep_words = set(['king', 'man', 'woman', 'france', 'paris', 'london', 'rome', 'italy', 'britain', 'england', 'french', 'english', 'japan', 'japanese', 'chinese', 'italian', 'australia', 'australian', 'december', 'november', 'june', 'january', 'february', 'march', 'april', 'may', 'july', 'august', 'september', 'october'])\n            (sentences, word2idx) = get_sentences_with_word2idx_limit_vocab(n_vocab=5000, keep_words=keep_words)\n        else:\n            (sentences, word2idx) = get_wikipedia_data(n_files=n_files, n_vocab=2000)\n        with open(w2i_file, 'w') as f:\n            json.dump(word2idx, f)\n    V = len(word2idx)\n    model = Glove(100, V, 10)\n    model.fit(sentences, cc_matrix=cc_matrix)\n    model.save(we_file)"
        ]
    }
]