[
    {
        "func_name": "test_uplift_compare",
        "original": "@unittest.skipIf(sys.version_info[0] < 3 or (sys.version_info[0] == 3 and sys.version_info[1] <= 5), 'Tested only on >3.5, causalml is not supported on lower python version')\ndef test_uplift_compare(self):\n    from causalml.inference.tree import UpliftRandomForestClassifier\n    from causalml.metrics import auuc_score, qini_score\n    h2o.init(strict_version_check=False)\n    treatment_column = 'treatment'\n    response_column = 'outcome'\n    feature_cols = ['feature_' + str(x) for x in range(1, 13)]\n    train_df = pd.read_csv(pyunit_utils.locate('smalldata/uplift/upliftml_train.csv'))\n    test_df = pd.read_csv(pyunit_utils.locate('smalldata/uplift/upliftml_test.csv'))\n    train = h2o.H2OFrame(train_df)\n    train[treatment_column] = train[treatment_column].asfactor()\n    train[response_column] = train[response_column].asfactor()\n    test = h2o.H2OFrame(test_df)\n    test[treatment_column] = test[treatment_column].asfactor()\n    test[response_column] = test[response_column].asfactor()\n    train_df[treatment_column].replace({1: 'treatment', 0: 'control'}, inplace=True)\n    test_df[treatment_column].replace({1: 'treatment', 0: 'control'}, inplace=True)\n    ntree = 30\n    max_depth = 10\n    auuc_types = ['qini', 'lift', 'gain']\n    h2o_drfs = [None] * len(auuc_types)\n    for i in range(len(auuc_types)):\n        drf = H2OUpliftRandomForestEstimator(ntrees=ntree, max_depth=max_depth, treatment_column=treatment_column, uplift_metric='euclidean', distribution='bernoulli', min_rows=5, nbins=1000, seed=42, auuc_type=auuc_types[i], sample_rate=0.9)\n        drf.train(y=response_column, x=feature_cols, training_frame=train)\n        h2o_drfs[i] = drf\n    uplift_model = UpliftRandomForestClassifier(n_estimators=ntree, max_depth=max_depth, evaluationFunction='ED', control_name='control', min_samples_leaf=5, min_samples_treatment=5, normalization=False, random_state=42)\n    uplift_model.fit(train_df[feature_cols].values, treatment=train_df[treatment_column].values, y=train_df[response_column].values)\n    testing_df = test\n    causal_preds = uplift_model.predict(test_df.values)\n    for i in range(len(h2o_drfs)):\n        preds_h2o = h2o_drfs[i].predict(testing_df)\n        preds_comp = preds_h2o['uplift_predict']\n        preds_comp.names = ['h2o']\n        preds_comp['causal'] = h2o.H2OFrame(causal_preds)\n        preds_comp['diff'] = abs(preds_comp['h2o'] - preds_comp['causal'])\n        preds_comp[treatment_column] = testing_df[treatment_column]\n        preds_comp[response_column] = testing_df[response_column]\n        preds_comp.summary()\n        mean_diff = preds_comp['diff'].mean(return_frame=False)[0]\n        print('Average difference: %f' % mean_diff)\n    results = preds_comp.as_data_frame()\n    results = results[['h2o', 'causal', response_column, treatment_column]]\n    mapping = {'control': 0, 'treatment': 1}\n    results = results.replace({treatment_column: mapping})\n    auuc = auuc_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=False)\n    auuc_normalized = auuc_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=True)\n    qini = qini_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=False)\n    perf_test = h2o_drfs[2].model_performance(testing_df)\n    h2o_auuc_qain_test = perf_test.auuc()\n    print('AUUC calculation:')\n    diff = abs(auuc['h2o'] - h2o_auuc_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (auuc['h2o'], h2o_auuc_qain_test, diff))\n    assert diff < 2, 'Absolute difference between causalML package and H2O AUUC calculation is higher than is expected: %f' % diff\n    diff = abs(auuc['causal'] - auuc['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (auuc['causal'], auuc['h2o'], diff))\n    h2o_auuc_normalized_qain_test = perf_test.auuc_normalized()\n    print('AUUC normalized calculation:')\n    diff = abs(auuc_normalized['h2o'] - h2o_auuc_normalized_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (auuc_normalized['h2o'], h2o_auuc_normalized_qain_test, diff))\n    assert diff < 0.01, 'Absolute difference between causalML package and H2O AUUC calculation is higher than is expected: %f' % diff\n    diff = abs(auuc_normalized['causal'] - auuc_normalized['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (auuc['causal'], auuc['h2o'], diff))\n    h2o_qini_qain_test = perf_test.qini()\n    print('Qini calculation:')\n    diff = abs(qini['h2o'] - h2o_qini_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (qini['h2o'], h2o_qini_qain_test, diff))\n    assert diff < 6, 'Absolute difference between causalML package and H2O Qini calculation is higher than is expected: %f' % diff\n    diff = abs(qini['causal'] - qini['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (qini['causal'], qini['h2o'], diff))\n    perf = h2o_drfs[0].model_performance(testing_df)\n    (n, uplift) = perf.plot_uplift(metric='gain', plot=False)\n    print(uplift)\n    print(perf.auuc())\n    print(h2o_drfs[0].auuc())\n    print(perf.auuc_table())\n    print(h2o_drfs[0].auuc_table())",
        "mutated": [
            "@unittest.skipIf(sys.version_info[0] < 3 or (sys.version_info[0] == 3 and sys.version_info[1] <= 5), 'Tested only on >3.5, causalml is not supported on lower python version')\ndef test_uplift_compare(self):\n    if False:\n        i = 10\n    from causalml.inference.tree import UpliftRandomForestClassifier\n    from causalml.metrics import auuc_score, qini_score\n    h2o.init(strict_version_check=False)\n    treatment_column = 'treatment'\n    response_column = 'outcome'\n    feature_cols = ['feature_' + str(x) for x in range(1, 13)]\n    train_df = pd.read_csv(pyunit_utils.locate('smalldata/uplift/upliftml_train.csv'))\n    test_df = pd.read_csv(pyunit_utils.locate('smalldata/uplift/upliftml_test.csv'))\n    train = h2o.H2OFrame(train_df)\n    train[treatment_column] = train[treatment_column].asfactor()\n    train[response_column] = train[response_column].asfactor()\n    test = h2o.H2OFrame(test_df)\n    test[treatment_column] = test[treatment_column].asfactor()\n    test[response_column] = test[response_column].asfactor()\n    train_df[treatment_column].replace({1: 'treatment', 0: 'control'}, inplace=True)\n    test_df[treatment_column].replace({1: 'treatment', 0: 'control'}, inplace=True)\n    ntree = 30\n    max_depth = 10\n    auuc_types = ['qini', 'lift', 'gain']\n    h2o_drfs = [None] * len(auuc_types)\n    for i in range(len(auuc_types)):\n        drf = H2OUpliftRandomForestEstimator(ntrees=ntree, max_depth=max_depth, treatment_column=treatment_column, uplift_metric='euclidean', distribution='bernoulli', min_rows=5, nbins=1000, seed=42, auuc_type=auuc_types[i], sample_rate=0.9)\n        drf.train(y=response_column, x=feature_cols, training_frame=train)\n        h2o_drfs[i] = drf\n    uplift_model = UpliftRandomForestClassifier(n_estimators=ntree, max_depth=max_depth, evaluationFunction='ED', control_name='control', min_samples_leaf=5, min_samples_treatment=5, normalization=False, random_state=42)\n    uplift_model.fit(train_df[feature_cols].values, treatment=train_df[treatment_column].values, y=train_df[response_column].values)\n    testing_df = test\n    causal_preds = uplift_model.predict(test_df.values)\n    for i in range(len(h2o_drfs)):\n        preds_h2o = h2o_drfs[i].predict(testing_df)\n        preds_comp = preds_h2o['uplift_predict']\n        preds_comp.names = ['h2o']\n        preds_comp['causal'] = h2o.H2OFrame(causal_preds)\n        preds_comp['diff'] = abs(preds_comp['h2o'] - preds_comp['causal'])\n        preds_comp[treatment_column] = testing_df[treatment_column]\n        preds_comp[response_column] = testing_df[response_column]\n        preds_comp.summary()\n        mean_diff = preds_comp['diff'].mean(return_frame=False)[0]\n        print('Average difference: %f' % mean_diff)\n    results = preds_comp.as_data_frame()\n    results = results[['h2o', 'causal', response_column, treatment_column]]\n    mapping = {'control': 0, 'treatment': 1}\n    results = results.replace({treatment_column: mapping})\n    auuc = auuc_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=False)\n    auuc_normalized = auuc_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=True)\n    qini = qini_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=False)\n    perf_test = h2o_drfs[2].model_performance(testing_df)\n    h2o_auuc_qain_test = perf_test.auuc()\n    print('AUUC calculation:')\n    diff = abs(auuc['h2o'] - h2o_auuc_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (auuc['h2o'], h2o_auuc_qain_test, diff))\n    assert diff < 2, 'Absolute difference between causalML package and H2O AUUC calculation is higher than is expected: %f' % diff\n    diff = abs(auuc['causal'] - auuc['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (auuc['causal'], auuc['h2o'], diff))\n    h2o_auuc_normalized_qain_test = perf_test.auuc_normalized()\n    print('AUUC normalized calculation:')\n    diff = abs(auuc_normalized['h2o'] - h2o_auuc_normalized_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (auuc_normalized['h2o'], h2o_auuc_normalized_qain_test, diff))\n    assert diff < 0.01, 'Absolute difference between causalML package and H2O AUUC calculation is higher than is expected: %f' % diff\n    diff = abs(auuc_normalized['causal'] - auuc_normalized['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (auuc['causal'], auuc['h2o'], diff))\n    h2o_qini_qain_test = perf_test.qini()\n    print('Qini calculation:')\n    diff = abs(qini['h2o'] - h2o_qini_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (qini['h2o'], h2o_qini_qain_test, diff))\n    assert diff < 6, 'Absolute difference between causalML package and H2O Qini calculation is higher than is expected: %f' % diff\n    diff = abs(qini['causal'] - qini['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (qini['causal'], qini['h2o'], diff))\n    perf = h2o_drfs[0].model_performance(testing_df)\n    (n, uplift) = perf.plot_uplift(metric='gain', plot=False)\n    print(uplift)\n    print(perf.auuc())\n    print(h2o_drfs[0].auuc())\n    print(perf.auuc_table())\n    print(h2o_drfs[0].auuc_table())",
            "@unittest.skipIf(sys.version_info[0] < 3 or (sys.version_info[0] == 3 and sys.version_info[1] <= 5), 'Tested only on >3.5, causalml is not supported on lower python version')\ndef test_uplift_compare(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    from causalml.inference.tree import UpliftRandomForestClassifier\n    from causalml.metrics import auuc_score, qini_score\n    h2o.init(strict_version_check=False)\n    treatment_column = 'treatment'\n    response_column = 'outcome'\n    feature_cols = ['feature_' + str(x) for x in range(1, 13)]\n    train_df = pd.read_csv(pyunit_utils.locate('smalldata/uplift/upliftml_train.csv'))\n    test_df = pd.read_csv(pyunit_utils.locate('smalldata/uplift/upliftml_test.csv'))\n    train = h2o.H2OFrame(train_df)\n    train[treatment_column] = train[treatment_column].asfactor()\n    train[response_column] = train[response_column].asfactor()\n    test = h2o.H2OFrame(test_df)\n    test[treatment_column] = test[treatment_column].asfactor()\n    test[response_column] = test[response_column].asfactor()\n    train_df[treatment_column].replace({1: 'treatment', 0: 'control'}, inplace=True)\n    test_df[treatment_column].replace({1: 'treatment', 0: 'control'}, inplace=True)\n    ntree = 30\n    max_depth = 10\n    auuc_types = ['qini', 'lift', 'gain']\n    h2o_drfs = [None] * len(auuc_types)\n    for i in range(len(auuc_types)):\n        drf = H2OUpliftRandomForestEstimator(ntrees=ntree, max_depth=max_depth, treatment_column=treatment_column, uplift_metric='euclidean', distribution='bernoulli', min_rows=5, nbins=1000, seed=42, auuc_type=auuc_types[i], sample_rate=0.9)\n        drf.train(y=response_column, x=feature_cols, training_frame=train)\n        h2o_drfs[i] = drf\n    uplift_model = UpliftRandomForestClassifier(n_estimators=ntree, max_depth=max_depth, evaluationFunction='ED', control_name='control', min_samples_leaf=5, min_samples_treatment=5, normalization=False, random_state=42)\n    uplift_model.fit(train_df[feature_cols].values, treatment=train_df[treatment_column].values, y=train_df[response_column].values)\n    testing_df = test\n    causal_preds = uplift_model.predict(test_df.values)\n    for i in range(len(h2o_drfs)):\n        preds_h2o = h2o_drfs[i].predict(testing_df)\n        preds_comp = preds_h2o['uplift_predict']\n        preds_comp.names = ['h2o']\n        preds_comp['causal'] = h2o.H2OFrame(causal_preds)\n        preds_comp['diff'] = abs(preds_comp['h2o'] - preds_comp['causal'])\n        preds_comp[treatment_column] = testing_df[treatment_column]\n        preds_comp[response_column] = testing_df[response_column]\n        preds_comp.summary()\n        mean_diff = preds_comp['diff'].mean(return_frame=False)[0]\n        print('Average difference: %f' % mean_diff)\n    results = preds_comp.as_data_frame()\n    results = results[['h2o', 'causal', response_column, treatment_column]]\n    mapping = {'control': 0, 'treatment': 1}\n    results = results.replace({treatment_column: mapping})\n    auuc = auuc_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=False)\n    auuc_normalized = auuc_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=True)\n    qini = qini_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=False)\n    perf_test = h2o_drfs[2].model_performance(testing_df)\n    h2o_auuc_qain_test = perf_test.auuc()\n    print('AUUC calculation:')\n    diff = abs(auuc['h2o'] - h2o_auuc_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (auuc['h2o'], h2o_auuc_qain_test, diff))\n    assert diff < 2, 'Absolute difference between causalML package and H2O AUUC calculation is higher than is expected: %f' % diff\n    diff = abs(auuc['causal'] - auuc['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (auuc['causal'], auuc['h2o'], diff))\n    h2o_auuc_normalized_qain_test = perf_test.auuc_normalized()\n    print('AUUC normalized calculation:')\n    diff = abs(auuc_normalized['h2o'] - h2o_auuc_normalized_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (auuc_normalized['h2o'], h2o_auuc_normalized_qain_test, diff))\n    assert diff < 0.01, 'Absolute difference between causalML package and H2O AUUC calculation is higher than is expected: %f' % diff\n    diff = abs(auuc_normalized['causal'] - auuc_normalized['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (auuc['causal'], auuc['h2o'], diff))\n    h2o_qini_qain_test = perf_test.qini()\n    print('Qini calculation:')\n    diff = abs(qini['h2o'] - h2o_qini_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (qini['h2o'], h2o_qini_qain_test, diff))\n    assert diff < 6, 'Absolute difference between causalML package and H2O Qini calculation is higher than is expected: %f' % diff\n    diff = abs(qini['causal'] - qini['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (qini['causal'], qini['h2o'], diff))\n    perf = h2o_drfs[0].model_performance(testing_df)\n    (n, uplift) = perf.plot_uplift(metric='gain', plot=False)\n    print(uplift)\n    print(perf.auuc())\n    print(h2o_drfs[0].auuc())\n    print(perf.auuc_table())\n    print(h2o_drfs[0].auuc_table())",
            "@unittest.skipIf(sys.version_info[0] < 3 or (sys.version_info[0] == 3 and sys.version_info[1] <= 5), 'Tested only on >3.5, causalml is not supported on lower python version')\ndef test_uplift_compare(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    from causalml.inference.tree import UpliftRandomForestClassifier\n    from causalml.metrics import auuc_score, qini_score\n    h2o.init(strict_version_check=False)\n    treatment_column = 'treatment'\n    response_column = 'outcome'\n    feature_cols = ['feature_' + str(x) for x in range(1, 13)]\n    train_df = pd.read_csv(pyunit_utils.locate('smalldata/uplift/upliftml_train.csv'))\n    test_df = pd.read_csv(pyunit_utils.locate('smalldata/uplift/upliftml_test.csv'))\n    train = h2o.H2OFrame(train_df)\n    train[treatment_column] = train[treatment_column].asfactor()\n    train[response_column] = train[response_column].asfactor()\n    test = h2o.H2OFrame(test_df)\n    test[treatment_column] = test[treatment_column].asfactor()\n    test[response_column] = test[response_column].asfactor()\n    train_df[treatment_column].replace({1: 'treatment', 0: 'control'}, inplace=True)\n    test_df[treatment_column].replace({1: 'treatment', 0: 'control'}, inplace=True)\n    ntree = 30\n    max_depth = 10\n    auuc_types = ['qini', 'lift', 'gain']\n    h2o_drfs = [None] * len(auuc_types)\n    for i in range(len(auuc_types)):\n        drf = H2OUpliftRandomForestEstimator(ntrees=ntree, max_depth=max_depth, treatment_column=treatment_column, uplift_metric='euclidean', distribution='bernoulli', min_rows=5, nbins=1000, seed=42, auuc_type=auuc_types[i], sample_rate=0.9)\n        drf.train(y=response_column, x=feature_cols, training_frame=train)\n        h2o_drfs[i] = drf\n    uplift_model = UpliftRandomForestClassifier(n_estimators=ntree, max_depth=max_depth, evaluationFunction='ED', control_name='control', min_samples_leaf=5, min_samples_treatment=5, normalization=False, random_state=42)\n    uplift_model.fit(train_df[feature_cols].values, treatment=train_df[treatment_column].values, y=train_df[response_column].values)\n    testing_df = test\n    causal_preds = uplift_model.predict(test_df.values)\n    for i in range(len(h2o_drfs)):\n        preds_h2o = h2o_drfs[i].predict(testing_df)\n        preds_comp = preds_h2o['uplift_predict']\n        preds_comp.names = ['h2o']\n        preds_comp['causal'] = h2o.H2OFrame(causal_preds)\n        preds_comp['diff'] = abs(preds_comp['h2o'] - preds_comp['causal'])\n        preds_comp[treatment_column] = testing_df[treatment_column]\n        preds_comp[response_column] = testing_df[response_column]\n        preds_comp.summary()\n        mean_diff = preds_comp['diff'].mean(return_frame=False)[0]\n        print('Average difference: %f' % mean_diff)\n    results = preds_comp.as_data_frame()\n    results = results[['h2o', 'causal', response_column, treatment_column]]\n    mapping = {'control': 0, 'treatment': 1}\n    results = results.replace({treatment_column: mapping})\n    auuc = auuc_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=False)\n    auuc_normalized = auuc_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=True)\n    qini = qini_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=False)\n    perf_test = h2o_drfs[2].model_performance(testing_df)\n    h2o_auuc_qain_test = perf_test.auuc()\n    print('AUUC calculation:')\n    diff = abs(auuc['h2o'] - h2o_auuc_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (auuc['h2o'], h2o_auuc_qain_test, diff))\n    assert diff < 2, 'Absolute difference between causalML package and H2O AUUC calculation is higher than is expected: %f' % diff\n    diff = abs(auuc['causal'] - auuc['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (auuc['causal'], auuc['h2o'], diff))\n    h2o_auuc_normalized_qain_test = perf_test.auuc_normalized()\n    print('AUUC normalized calculation:')\n    diff = abs(auuc_normalized['h2o'] - h2o_auuc_normalized_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (auuc_normalized['h2o'], h2o_auuc_normalized_qain_test, diff))\n    assert diff < 0.01, 'Absolute difference between causalML package and H2O AUUC calculation is higher than is expected: %f' % diff\n    diff = abs(auuc_normalized['causal'] - auuc_normalized['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (auuc['causal'], auuc['h2o'], diff))\n    h2o_qini_qain_test = perf_test.qini()\n    print('Qini calculation:')\n    diff = abs(qini['h2o'] - h2o_qini_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (qini['h2o'], h2o_qini_qain_test, diff))\n    assert diff < 6, 'Absolute difference between causalML package and H2O Qini calculation is higher than is expected: %f' % diff\n    diff = abs(qini['causal'] - qini['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (qini['causal'], qini['h2o'], diff))\n    perf = h2o_drfs[0].model_performance(testing_df)\n    (n, uplift) = perf.plot_uplift(metric='gain', plot=False)\n    print(uplift)\n    print(perf.auuc())\n    print(h2o_drfs[0].auuc())\n    print(perf.auuc_table())\n    print(h2o_drfs[0].auuc_table())",
            "@unittest.skipIf(sys.version_info[0] < 3 or (sys.version_info[0] == 3 and sys.version_info[1] <= 5), 'Tested only on >3.5, causalml is not supported on lower python version')\ndef test_uplift_compare(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    from causalml.inference.tree import UpliftRandomForestClassifier\n    from causalml.metrics import auuc_score, qini_score\n    h2o.init(strict_version_check=False)\n    treatment_column = 'treatment'\n    response_column = 'outcome'\n    feature_cols = ['feature_' + str(x) for x in range(1, 13)]\n    train_df = pd.read_csv(pyunit_utils.locate('smalldata/uplift/upliftml_train.csv'))\n    test_df = pd.read_csv(pyunit_utils.locate('smalldata/uplift/upliftml_test.csv'))\n    train = h2o.H2OFrame(train_df)\n    train[treatment_column] = train[treatment_column].asfactor()\n    train[response_column] = train[response_column].asfactor()\n    test = h2o.H2OFrame(test_df)\n    test[treatment_column] = test[treatment_column].asfactor()\n    test[response_column] = test[response_column].asfactor()\n    train_df[treatment_column].replace({1: 'treatment', 0: 'control'}, inplace=True)\n    test_df[treatment_column].replace({1: 'treatment', 0: 'control'}, inplace=True)\n    ntree = 30\n    max_depth = 10\n    auuc_types = ['qini', 'lift', 'gain']\n    h2o_drfs = [None] * len(auuc_types)\n    for i in range(len(auuc_types)):\n        drf = H2OUpliftRandomForestEstimator(ntrees=ntree, max_depth=max_depth, treatment_column=treatment_column, uplift_metric='euclidean', distribution='bernoulli', min_rows=5, nbins=1000, seed=42, auuc_type=auuc_types[i], sample_rate=0.9)\n        drf.train(y=response_column, x=feature_cols, training_frame=train)\n        h2o_drfs[i] = drf\n    uplift_model = UpliftRandomForestClassifier(n_estimators=ntree, max_depth=max_depth, evaluationFunction='ED', control_name='control', min_samples_leaf=5, min_samples_treatment=5, normalization=False, random_state=42)\n    uplift_model.fit(train_df[feature_cols].values, treatment=train_df[treatment_column].values, y=train_df[response_column].values)\n    testing_df = test\n    causal_preds = uplift_model.predict(test_df.values)\n    for i in range(len(h2o_drfs)):\n        preds_h2o = h2o_drfs[i].predict(testing_df)\n        preds_comp = preds_h2o['uplift_predict']\n        preds_comp.names = ['h2o']\n        preds_comp['causal'] = h2o.H2OFrame(causal_preds)\n        preds_comp['diff'] = abs(preds_comp['h2o'] - preds_comp['causal'])\n        preds_comp[treatment_column] = testing_df[treatment_column]\n        preds_comp[response_column] = testing_df[response_column]\n        preds_comp.summary()\n        mean_diff = preds_comp['diff'].mean(return_frame=False)[0]\n        print('Average difference: %f' % mean_diff)\n    results = preds_comp.as_data_frame()\n    results = results[['h2o', 'causal', response_column, treatment_column]]\n    mapping = {'control': 0, 'treatment': 1}\n    results = results.replace({treatment_column: mapping})\n    auuc = auuc_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=False)\n    auuc_normalized = auuc_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=True)\n    qini = qini_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=False)\n    perf_test = h2o_drfs[2].model_performance(testing_df)\n    h2o_auuc_qain_test = perf_test.auuc()\n    print('AUUC calculation:')\n    diff = abs(auuc['h2o'] - h2o_auuc_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (auuc['h2o'], h2o_auuc_qain_test, diff))\n    assert diff < 2, 'Absolute difference between causalML package and H2O AUUC calculation is higher than is expected: %f' % diff\n    diff = abs(auuc['causal'] - auuc['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (auuc['causal'], auuc['h2o'], diff))\n    h2o_auuc_normalized_qain_test = perf_test.auuc_normalized()\n    print('AUUC normalized calculation:')\n    diff = abs(auuc_normalized['h2o'] - h2o_auuc_normalized_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (auuc_normalized['h2o'], h2o_auuc_normalized_qain_test, diff))\n    assert diff < 0.01, 'Absolute difference between causalML package and H2O AUUC calculation is higher than is expected: %f' % diff\n    diff = abs(auuc_normalized['causal'] - auuc_normalized['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (auuc['causal'], auuc['h2o'], diff))\n    h2o_qini_qain_test = perf_test.qini()\n    print('Qini calculation:')\n    diff = abs(qini['h2o'] - h2o_qini_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (qini['h2o'], h2o_qini_qain_test, diff))\n    assert diff < 6, 'Absolute difference between causalML package and H2O Qini calculation is higher than is expected: %f' % diff\n    diff = abs(qini['causal'] - qini['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (qini['causal'], qini['h2o'], diff))\n    perf = h2o_drfs[0].model_performance(testing_df)\n    (n, uplift) = perf.plot_uplift(metric='gain', plot=False)\n    print(uplift)\n    print(perf.auuc())\n    print(h2o_drfs[0].auuc())\n    print(perf.auuc_table())\n    print(h2o_drfs[0].auuc_table())",
            "@unittest.skipIf(sys.version_info[0] < 3 or (sys.version_info[0] == 3 and sys.version_info[1] <= 5), 'Tested only on >3.5, causalml is not supported on lower python version')\ndef test_uplift_compare(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    from causalml.inference.tree import UpliftRandomForestClassifier\n    from causalml.metrics import auuc_score, qini_score\n    h2o.init(strict_version_check=False)\n    treatment_column = 'treatment'\n    response_column = 'outcome'\n    feature_cols = ['feature_' + str(x) for x in range(1, 13)]\n    train_df = pd.read_csv(pyunit_utils.locate('smalldata/uplift/upliftml_train.csv'))\n    test_df = pd.read_csv(pyunit_utils.locate('smalldata/uplift/upliftml_test.csv'))\n    train = h2o.H2OFrame(train_df)\n    train[treatment_column] = train[treatment_column].asfactor()\n    train[response_column] = train[response_column].asfactor()\n    test = h2o.H2OFrame(test_df)\n    test[treatment_column] = test[treatment_column].asfactor()\n    test[response_column] = test[response_column].asfactor()\n    train_df[treatment_column].replace({1: 'treatment', 0: 'control'}, inplace=True)\n    test_df[treatment_column].replace({1: 'treatment', 0: 'control'}, inplace=True)\n    ntree = 30\n    max_depth = 10\n    auuc_types = ['qini', 'lift', 'gain']\n    h2o_drfs = [None] * len(auuc_types)\n    for i in range(len(auuc_types)):\n        drf = H2OUpliftRandomForestEstimator(ntrees=ntree, max_depth=max_depth, treatment_column=treatment_column, uplift_metric='euclidean', distribution='bernoulli', min_rows=5, nbins=1000, seed=42, auuc_type=auuc_types[i], sample_rate=0.9)\n        drf.train(y=response_column, x=feature_cols, training_frame=train)\n        h2o_drfs[i] = drf\n    uplift_model = UpliftRandomForestClassifier(n_estimators=ntree, max_depth=max_depth, evaluationFunction='ED', control_name='control', min_samples_leaf=5, min_samples_treatment=5, normalization=False, random_state=42)\n    uplift_model.fit(train_df[feature_cols].values, treatment=train_df[treatment_column].values, y=train_df[response_column].values)\n    testing_df = test\n    causal_preds = uplift_model.predict(test_df.values)\n    for i in range(len(h2o_drfs)):\n        preds_h2o = h2o_drfs[i].predict(testing_df)\n        preds_comp = preds_h2o['uplift_predict']\n        preds_comp.names = ['h2o']\n        preds_comp['causal'] = h2o.H2OFrame(causal_preds)\n        preds_comp['diff'] = abs(preds_comp['h2o'] - preds_comp['causal'])\n        preds_comp[treatment_column] = testing_df[treatment_column]\n        preds_comp[response_column] = testing_df[response_column]\n        preds_comp.summary()\n        mean_diff = preds_comp['diff'].mean(return_frame=False)[0]\n        print('Average difference: %f' % mean_diff)\n    results = preds_comp.as_data_frame()\n    results = results[['h2o', 'causal', response_column, treatment_column]]\n    mapping = {'control': 0, 'treatment': 1}\n    results = results.replace({treatment_column: mapping})\n    auuc = auuc_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=False)\n    auuc_normalized = auuc_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=True)\n    qini = qini_score(results, outcome_col=response_column, treatment_col=treatment_column, normalize=False)\n    perf_test = h2o_drfs[2].model_performance(testing_df)\n    h2o_auuc_qain_test = perf_test.auuc()\n    print('AUUC calculation:')\n    diff = abs(auuc['h2o'] - h2o_auuc_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (auuc['h2o'], h2o_auuc_qain_test, diff))\n    assert diff < 2, 'Absolute difference between causalML package and H2O AUUC calculation is higher than is expected: %f' % diff\n    diff = abs(auuc['causal'] - auuc['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (auuc['causal'], auuc['h2o'], diff))\n    h2o_auuc_normalized_qain_test = perf_test.auuc_normalized()\n    print('AUUC normalized calculation:')\n    diff = abs(auuc_normalized['h2o'] - h2o_auuc_normalized_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (auuc_normalized['h2o'], h2o_auuc_normalized_qain_test, diff))\n    assert diff < 0.01, 'Absolute difference between causalML package and H2O AUUC calculation is higher than is expected: %f' % diff\n    diff = abs(auuc_normalized['causal'] - auuc_normalized['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (auuc['causal'], auuc['h2o'], diff))\n    h2o_qini_qain_test = perf_test.qini()\n    print('Qini calculation:')\n    diff = abs(qini['h2o'] - h2o_qini_qain_test)\n    print('CausalML H2O: %f H2O: %f diff: %f' % (qini['h2o'], h2o_qini_qain_test, diff))\n    assert diff < 6, 'Absolute difference between causalML package and H2O Qini calculation is higher than is expected: %f' % diff\n    diff = abs(qini['causal'] - qini['h2o'])\n    print('CausalML: %f H2O: %f diff: %f' % (qini['causal'], qini['h2o'], diff))\n    perf = h2o_drfs[0].model_performance(testing_df)\n    (n, uplift) = perf.plot_uplift(metric='gain', plot=False)\n    print(uplift)\n    print(perf.auuc())\n    print(h2o_drfs[0].auuc())\n    print(perf.auuc_table())\n    print(h2o_drfs[0].auuc_table())"
        ]
    }
]