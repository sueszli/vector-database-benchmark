[
    {
        "func_name": "run_dfs",
        "original": "def run_dfs(adj, msk, u, ind, nb_nodes):\n    if msk[u] == -1:\n        msk[u] = ind\n        for v in adj[u, :].nonzero()[1]:\n            run_dfs(adj, msk, v, ind, nb_nodes)",
        "mutated": [
            "def run_dfs(adj, msk, u, ind, nb_nodes):\n    if False:\n        i = 10\n    if msk[u] == -1:\n        msk[u] = ind\n        for v in adj[u, :].nonzero()[1]:\n            run_dfs(adj, msk, v, ind, nb_nodes)",
            "def run_dfs(adj, msk, u, ind, nb_nodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if msk[u] == -1:\n        msk[u] = ind\n        for v in adj[u, :].nonzero()[1]:\n            run_dfs(adj, msk, v, ind, nb_nodes)",
            "def run_dfs(adj, msk, u, ind, nb_nodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if msk[u] == -1:\n        msk[u] = ind\n        for v in adj[u, :].nonzero()[1]:\n            run_dfs(adj, msk, v, ind, nb_nodes)",
            "def run_dfs(adj, msk, u, ind, nb_nodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if msk[u] == -1:\n        msk[u] = ind\n        for v in adj[u, :].nonzero()[1]:\n            run_dfs(adj, msk, v, ind, nb_nodes)",
            "def run_dfs(adj, msk, u, ind, nb_nodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if msk[u] == -1:\n        msk[u] = ind\n        for v in adj[u, :].nonzero()[1]:\n            run_dfs(adj, msk, v, ind, nb_nodes)"
        ]
    },
    {
        "func_name": "dfs_split",
        "original": "def dfs_split(adj):\n    nb_nodes = adj.shape[0]\n    ret = np.full(nb_nodes, -1, dtype=np.int32)\n    graph_id = 0\n    for i in range(nb_nodes):\n        if ret[i] == -1:\n            run_dfs(adj, ret, i, graph_id, nb_nodes)\n            graph_id += 1\n    return ret",
        "mutated": [
            "def dfs_split(adj):\n    if False:\n        i = 10\n    nb_nodes = adj.shape[0]\n    ret = np.full(nb_nodes, -1, dtype=np.int32)\n    graph_id = 0\n    for i in range(nb_nodes):\n        if ret[i] == -1:\n            run_dfs(adj, ret, i, graph_id, nb_nodes)\n            graph_id += 1\n    return ret",
            "def dfs_split(adj):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    nb_nodes = adj.shape[0]\n    ret = np.full(nb_nodes, -1, dtype=np.int32)\n    graph_id = 0\n    for i in range(nb_nodes):\n        if ret[i] == -1:\n            run_dfs(adj, ret, i, graph_id, nb_nodes)\n            graph_id += 1\n    return ret",
            "def dfs_split(adj):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    nb_nodes = adj.shape[0]\n    ret = np.full(nb_nodes, -1, dtype=np.int32)\n    graph_id = 0\n    for i in range(nb_nodes):\n        if ret[i] == -1:\n            run_dfs(adj, ret, i, graph_id, nb_nodes)\n            graph_id += 1\n    return ret",
            "def dfs_split(adj):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    nb_nodes = adj.shape[0]\n    ret = np.full(nb_nodes, -1, dtype=np.int32)\n    graph_id = 0\n    for i in range(nb_nodes):\n        if ret[i] == -1:\n            run_dfs(adj, ret, i, graph_id, nb_nodes)\n            graph_id += 1\n    return ret",
            "def dfs_split(adj):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    nb_nodes = adj.shape[0]\n    ret = np.full(nb_nodes, -1, dtype=np.int32)\n    graph_id = 0\n    for i in range(nb_nodes):\n        if ret[i] == -1:\n            run_dfs(adj, ret, i, graph_id, nb_nodes)\n            graph_id += 1\n    return ret"
        ]
    },
    {
        "func_name": "test",
        "original": "def test(adj, mapping):\n    nb_nodes = adj.shape[0]\n    for i in range(nb_nodes):\n        for j in adj[i, :].nonzero()[1]:\n            if mapping[i] != mapping[j]:\n                return False\n    return True",
        "mutated": [
            "def test(adj, mapping):\n    if False:\n        i = 10\n    nb_nodes = adj.shape[0]\n    for i in range(nb_nodes):\n        for j in adj[i, :].nonzero()[1]:\n            if mapping[i] != mapping[j]:\n                return False\n    return True",
            "def test(adj, mapping):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    nb_nodes = adj.shape[0]\n    for i in range(nb_nodes):\n        for j in adj[i, :].nonzero()[1]:\n            if mapping[i] != mapping[j]:\n                return False\n    return True",
            "def test(adj, mapping):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    nb_nodes = adj.shape[0]\n    for i in range(nb_nodes):\n        for j in adj[i, :].nonzero()[1]:\n            if mapping[i] != mapping[j]:\n                return False\n    return True",
            "def test(adj, mapping):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    nb_nodes = adj.shape[0]\n    for i in range(nb_nodes):\n        for j in adj[i, :].nonzero()[1]:\n            if mapping[i] != mapping[j]:\n                return False\n    return True",
            "def test(adj, mapping):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    nb_nodes = adj.shape[0]\n    for i in range(nb_nodes):\n        for j in adj[i, :].nonzero()[1]:\n            if mapping[i] != mapping[j]:\n                return False\n    return True"
        ]
    },
    {
        "func_name": "find_split",
        "original": "def find_split(adj, mapping, ds_label):\n    nb_nodes = adj.shape[0]\n    dict_splits = {}\n    for i in range(nb_nodes):\n        for j in adj[i, :].nonzero()[1]:\n            if mapping[i] == 0 or mapping[j] == 0:\n                dict_splits[0] = None\n            elif mapping[i] == mapping[j]:\n                if ds_label[i]['val'] == ds_label[j]['val'] and ds_label[i]['test'] == ds_label[j]['test']:\n                    if mapping[i] not in dict_splits.keys():\n                        if ds_label[i]['val']:\n                            dict_splits[mapping[i]] = 'val'\n                        elif ds_label[i]['test']:\n                            dict_splits[mapping[i]] = 'test'\n                        else:\n                            dict_splits[mapping[i]] = 'train'\n                    else:\n                        if ds_label[i]['test']:\n                            ind_label = 'test'\n                        elif ds_label[i]['val']:\n                            ind_label = 'val'\n                        else:\n                            ind_label = 'train'\n                        if dict_splits[mapping[i]] != ind_label:\n                            print('inconsistent labels within a graph exiting!!!')\n                            return None\n                else:\n                    print('label of both nodes different, exiting!!')\n                    return None\n    return dict_splits",
        "mutated": [
            "def find_split(adj, mapping, ds_label):\n    if False:\n        i = 10\n    nb_nodes = adj.shape[0]\n    dict_splits = {}\n    for i in range(nb_nodes):\n        for j in adj[i, :].nonzero()[1]:\n            if mapping[i] == 0 or mapping[j] == 0:\n                dict_splits[0] = None\n            elif mapping[i] == mapping[j]:\n                if ds_label[i]['val'] == ds_label[j]['val'] and ds_label[i]['test'] == ds_label[j]['test']:\n                    if mapping[i] not in dict_splits.keys():\n                        if ds_label[i]['val']:\n                            dict_splits[mapping[i]] = 'val'\n                        elif ds_label[i]['test']:\n                            dict_splits[mapping[i]] = 'test'\n                        else:\n                            dict_splits[mapping[i]] = 'train'\n                    else:\n                        if ds_label[i]['test']:\n                            ind_label = 'test'\n                        elif ds_label[i]['val']:\n                            ind_label = 'val'\n                        else:\n                            ind_label = 'train'\n                        if dict_splits[mapping[i]] != ind_label:\n                            print('inconsistent labels within a graph exiting!!!')\n                            return None\n                else:\n                    print('label of both nodes different, exiting!!')\n                    return None\n    return dict_splits",
            "def find_split(adj, mapping, ds_label):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    nb_nodes = adj.shape[0]\n    dict_splits = {}\n    for i in range(nb_nodes):\n        for j in adj[i, :].nonzero()[1]:\n            if mapping[i] == 0 or mapping[j] == 0:\n                dict_splits[0] = None\n            elif mapping[i] == mapping[j]:\n                if ds_label[i]['val'] == ds_label[j]['val'] and ds_label[i]['test'] == ds_label[j]['test']:\n                    if mapping[i] not in dict_splits.keys():\n                        if ds_label[i]['val']:\n                            dict_splits[mapping[i]] = 'val'\n                        elif ds_label[i]['test']:\n                            dict_splits[mapping[i]] = 'test'\n                        else:\n                            dict_splits[mapping[i]] = 'train'\n                    else:\n                        if ds_label[i]['test']:\n                            ind_label = 'test'\n                        elif ds_label[i]['val']:\n                            ind_label = 'val'\n                        else:\n                            ind_label = 'train'\n                        if dict_splits[mapping[i]] != ind_label:\n                            print('inconsistent labels within a graph exiting!!!')\n                            return None\n                else:\n                    print('label of both nodes different, exiting!!')\n                    return None\n    return dict_splits",
            "def find_split(adj, mapping, ds_label):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    nb_nodes = adj.shape[0]\n    dict_splits = {}\n    for i in range(nb_nodes):\n        for j in adj[i, :].nonzero()[1]:\n            if mapping[i] == 0 or mapping[j] == 0:\n                dict_splits[0] = None\n            elif mapping[i] == mapping[j]:\n                if ds_label[i]['val'] == ds_label[j]['val'] and ds_label[i]['test'] == ds_label[j]['test']:\n                    if mapping[i] not in dict_splits.keys():\n                        if ds_label[i]['val']:\n                            dict_splits[mapping[i]] = 'val'\n                        elif ds_label[i]['test']:\n                            dict_splits[mapping[i]] = 'test'\n                        else:\n                            dict_splits[mapping[i]] = 'train'\n                    else:\n                        if ds_label[i]['test']:\n                            ind_label = 'test'\n                        elif ds_label[i]['val']:\n                            ind_label = 'val'\n                        else:\n                            ind_label = 'train'\n                        if dict_splits[mapping[i]] != ind_label:\n                            print('inconsistent labels within a graph exiting!!!')\n                            return None\n                else:\n                    print('label of both nodes different, exiting!!')\n                    return None\n    return dict_splits",
            "def find_split(adj, mapping, ds_label):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    nb_nodes = adj.shape[0]\n    dict_splits = {}\n    for i in range(nb_nodes):\n        for j in adj[i, :].nonzero()[1]:\n            if mapping[i] == 0 or mapping[j] == 0:\n                dict_splits[0] = None\n            elif mapping[i] == mapping[j]:\n                if ds_label[i]['val'] == ds_label[j]['val'] and ds_label[i]['test'] == ds_label[j]['test']:\n                    if mapping[i] not in dict_splits.keys():\n                        if ds_label[i]['val']:\n                            dict_splits[mapping[i]] = 'val'\n                        elif ds_label[i]['test']:\n                            dict_splits[mapping[i]] = 'test'\n                        else:\n                            dict_splits[mapping[i]] = 'train'\n                    else:\n                        if ds_label[i]['test']:\n                            ind_label = 'test'\n                        elif ds_label[i]['val']:\n                            ind_label = 'val'\n                        else:\n                            ind_label = 'train'\n                        if dict_splits[mapping[i]] != ind_label:\n                            print('inconsistent labels within a graph exiting!!!')\n                            return None\n                else:\n                    print('label of both nodes different, exiting!!')\n                    return None\n    return dict_splits",
            "def find_split(adj, mapping, ds_label):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    nb_nodes = adj.shape[0]\n    dict_splits = {}\n    for i in range(nb_nodes):\n        for j in adj[i, :].nonzero()[1]:\n            if mapping[i] == 0 or mapping[j] == 0:\n                dict_splits[0] = None\n            elif mapping[i] == mapping[j]:\n                if ds_label[i]['val'] == ds_label[j]['val'] and ds_label[i]['test'] == ds_label[j]['test']:\n                    if mapping[i] not in dict_splits.keys():\n                        if ds_label[i]['val']:\n                            dict_splits[mapping[i]] = 'val'\n                        elif ds_label[i]['test']:\n                            dict_splits[mapping[i]] = 'test'\n                        else:\n                            dict_splits[mapping[i]] = 'train'\n                    else:\n                        if ds_label[i]['test']:\n                            ind_label = 'test'\n                        elif ds_label[i]['val']:\n                            ind_label = 'val'\n                        else:\n                            ind_label = 'train'\n                        if dict_splits[mapping[i]] != ind_label:\n                            print('inconsistent labels within a graph exiting!!!')\n                            return None\n                else:\n                    print('label of both nodes different, exiting!!')\n                    return None\n    return dict_splits"
        ]
    },
    {
        "func_name": "process_p2p",
        "original": "def process_p2p():\n    print('Loading G...')\n    with open('p2p_dataset/ppi-G.json') as jsonfile:\n        g_data = json.load(jsonfile)\n    print(len(g_data))\n    G = json_graph.node_link_graph(g_data)\n    adj = nx.adjacency_matrix(G)\n    prev_key = ''\n    for (key, value) in g_data.items():\n        if prev_key != key:\n            print(key)\n            prev_key = key\n    print('Loading id_map...')\n    with open('p2p_dataset/ppi-id_map.json') as jsonfile:\n        id_map = json.load(jsonfile)\n    print(len(id_map))\n    id_map = {int(k): int(v) for (k, v) in id_map.items()}\n    for (key, value) in id_map.items():\n        id_map[key] = [value]\n    print(len(id_map))\n    print('Loading features...')\n    features_ = np.load('p2p_dataset/ppi-feats.npy')\n    print(features_.shape)\n    from sklearn.preprocessing import StandardScaler\n    train_ids = np.array([id_map[n] for n in G.nodes() if not G.node[n]['val'] and (not G.node[n]['test'])])\n    train_feats = features_[train_ids[:, 0]]\n    scaler = StandardScaler()\n    scaler.fit(train_feats)\n    features_ = scaler.transform(features_)\n    features = sp.csr_matrix(features_).tolil()\n    print('Loading class_map...')\n    class_map = {}\n    with open('p2p_dataset/ppi-class_map.json') as jsonfile:\n        class_map = json.load(jsonfile)\n    print(len(class_map))\n    print('Splitting graph...')\n    splits = dfs_split(adj)\n    print('Re-arranging sub-graph IDs...')\n    list_splits = splits.tolist()\n    group_inc = 1\n    for i in range(np.max(list_splits) + 1):\n        if list_splits.count(i) >= 3:\n            splits[np.array(list_splits) == i] = group_inc\n            group_inc += 1\n        else:\n            ind_nodes = np.argwhere(np.array(list_splits) == i)\n            ind_nodes = ind_nodes[:, 0].tolist()\n            split = None\n            for ind_node in ind_nodes:\n                if g_data['nodes'][ind_node]['val']:\n                    if split is None or split == 'val':\n                        splits[np.array(list_splits) == i] = 21\n                        split = 'val'\n                    else:\n                        raise ValueError('new node is VAL but previously was {}'.format(split))\n                elif g_data['nodes'][ind_node]['test']:\n                    if split is None or split == 'test':\n                        splits[np.array(list_splits) == i] = 23\n                        split = 'test'\n                    else:\n                        raise ValueError('new node is TEST but previously was {}'.format(split))\n                elif split is None or split == 'train':\n                    splits[np.array(list_splits) == i] = 1\n                    split = 'train'\n                else:\n                    pdb.set_trace()\n                    raise ValueError('new node is TRAIN but previously was {}'.format(split))\n    list_splits = splits.tolist()\n    nodes_per_graph = []\n    for i in range(1, np.max(list_splits) + 1):\n        nodes_per_graph.append(list_splits.count(i))\n    subgraph_nodes = np.max(nodes_per_graph)\n    adj_sub = np.empty((len(nodes_per_graph), subgraph_nodes, subgraph_nodes))\n    feat_sub = np.empty((len(nodes_per_graph), subgraph_nodes, features.shape[1]))\n    labels_sub = np.empty((len(nodes_per_graph), subgraph_nodes, 121))\n    for i in range(1, np.max(list_splits) + 1):\n        indexes = np.where(splits == i)[0]\n        subgraph_ = adj[indexes, :][:, indexes]\n        if subgraph_.shape[0] < subgraph_nodes or subgraph_.shape[1] < subgraph_nodes:\n            subgraph = np.identity(subgraph_nodes)\n            feats = np.zeros([subgraph_nodes, features.shape[1]])\n            labels = np.zeros([subgraph_nodes, 121])\n            subgraph = sp.csr_matrix(subgraph).tolil()\n            subgraph[0:subgraph_.shape[0], 0:subgraph_.shape[1]] = subgraph_\n            adj_sub[i - 1, :, :] = subgraph.todense()\n            feats[0:len(indexes)] = features[indexes, :].todense()\n            feat_sub[i - 1, :, :] = feats\n            for (j, node) in enumerate(indexes):\n                labels[j, :] = np.array(class_map[str(node)])\n            labels[indexes.shape[0]:subgraph_nodes, :] = np.zeros([121])\n            labels_sub[i - 1, :, :] = labels\n        else:\n            adj_sub[i - 1, :, :] = subgraph_.todense()\n            feat_sub[i - 1, :, :] = features[indexes, :].todense()\n            for (j, node) in enumerate(indexes):\n                labels[j, :] = np.array(class_map[str(node)])\n            labels_sub[i - 1, :, :] = labels\n    dict_splits = find_split(adj, splits, g_data['nodes'])\n    print('Are sub-graphs isolated?')\n    print(test(adj, splits))\n    train_split = []\n    val_split = []\n    test_split = []\n    for (key, value) in dict_splits.items():\n        if dict_splits[key] == 'train':\n            train_split.append(int(key) - 1)\n        elif dict_splits[key] == 'val':\n            val_split.append(int(key) - 1)\n        elif dict_splits[key] == 'test':\n            test_split.append(int(key) - 1)\n    train_adj = adj_sub[train_split, :, :]\n    val_adj = adj_sub[val_split, :, :]\n    test_adj = adj_sub[test_split, :, :]\n    train_feat = feat_sub[train_split, :, :]\n    val_feat = feat_sub[val_split, :, :]\n    test_feat = feat_sub[test_split, :, :]\n    train_labels = labels_sub[train_split, :, :]\n    val_labels = labels_sub[val_split, :, :]\n    test_labels = labels_sub[test_split, :, :]\n    train_nodes = np.array(nodes_per_graph[train_split[0]:train_split[-1] + 1])\n    val_nodes = np.array(nodes_per_graph[val_split[0]:val_split[-1] + 1])\n    test_nodes = np.array(nodes_per_graph[test_split[0]:test_split[-1] + 1])\n    tr_msk = np.zeros((len(nodes_per_graph[train_split[0]:train_split[-1] + 1]), subgraph_nodes))\n    vl_msk = np.zeros((len(nodes_per_graph[val_split[0]:val_split[-1] + 1]), subgraph_nodes))\n    ts_msk = np.zeros((len(nodes_per_graph[test_split[0]:test_split[-1] + 1]), subgraph_nodes))\n    for i in range(len(train_nodes)):\n        for j in range(train_nodes[i]):\n            tr_msk[i][j] = 1\n    for i in range(len(val_nodes)):\n        for j in range(val_nodes[i]):\n            vl_msk[i][j] = 1\n    for i in range(len(test_nodes)):\n        for j in range(test_nodes[i]):\n            ts_msk[i][j] = 1\n    return (train_adj, val_adj, test_adj, train_feat, val_feat, test_feat, train_labels, val_labels, test_labels, train_nodes, val_nodes, test_nodes, tr_msk, vl_msk, ts_msk)",
        "mutated": [
            "def process_p2p():\n    if False:\n        i = 10\n    print('Loading G...')\n    with open('p2p_dataset/ppi-G.json') as jsonfile:\n        g_data = json.load(jsonfile)\n    print(len(g_data))\n    G = json_graph.node_link_graph(g_data)\n    adj = nx.adjacency_matrix(G)\n    prev_key = ''\n    for (key, value) in g_data.items():\n        if prev_key != key:\n            print(key)\n            prev_key = key\n    print('Loading id_map...')\n    with open('p2p_dataset/ppi-id_map.json') as jsonfile:\n        id_map = json.load(jsonfile)\n    print(len(id_map))\n    id_map = {int(k): int(v) for (k, v) in id_map.items()}\n    for (key, value) in id_map.items():\n        id_map[key] = [value]\n    print(len(id_map))\n    print('Loading features...')\n    features_ = np.load('p2p_dataset/ppi-feats.npy')\n    print(features_.shape)\n    from sklearn.preprocessing import StandardScaler\n    train_ids = np.array([id_map[n] for n in G.nodes() if not G.node[n]['val'] and (not G.node[n]['test'])])\n    train_feats = features_[train_ids[:, 0]]\n    scaler = StandardScaler()\n    scaler.fit(train_feats)\n    features_ = scaler.transform(features_)\n    features = sp.csr_matrix(features_).tolil()\n    print('Loading class_map...')\n    class_map = {}\n    with open('p2p_dataset/ppi-class_map.json') as jsonfile:\n        class_map = json.load(jsonfile)\n    print(len(class_map))\n    print('Splitting graph...')\n    splits = dfs_split(adj)\n    print('Re-arranging sub-graph IDs...')\n    list_splits = splits.tolist()\n    group_inc = 1\n    for i in range(np.max(list_splits) + 1):\n        if list_splits.count(i) >= 3:\n            splits[np.array(list_splits) == i] = group_inc\n            group_inc += 1\n        else:\n            ind_nodes = np.argwhere(np.array(list_splits) == i)\n            ind_nodes = ind_nodes[:, 0].tolist()\n            split = None\n            for ind_node in ind_nodes:\n                if g_data['nodes'][ind_node]['val']:\n                    if split is None or split == 'val':\n                        splits[np.array(list_splits) == i] = 21\n                        split = 'val'\n                    else:\n                        raise ValueError('new node is VAL but previously was {}'.format(split))\n                elif g_data['nodes'][ind_node]['test']:\n                    if split is None or split == 'test':\n                        splits[np.array(list_splits) == i] = 23\n                        split = 'test'\n                    else:\n                        raise ValueError('new node is TEST but previously was {}'.format(split))\n                elif split is None or split == 'train':\n                    splits[np.array(list_splits) == i] = 1\n                    split = 'train'\n                else:\n                    pdb.set_trace()\n                    raise ValueError('new node is TRAIN but previously was {}'.format(split))\n    list_splits = splits.tolist()\n    nodes_per_graph = []\n    for i in range(1, np.max(list_splits) + 1):\n        nodes_per_graph.append(list_splits.count(i))\n    subgraph_nodes = np.max(nodes_per_graph)\n    adj_sub = np.empty((len(nodes_per_graph), subgraph_nodes, subgraph_nodes))\n    feat_sub = np.empty((len(nodes_per_graph), subgraph_nodes, features.shape[1]))\n    labels_sub = np.empty((len(nodes_per_graph), subgraph_nodes, 121))\n    for i in range(1, np.max(list_splits) + 1):\n        indexes = np.where(splits == i)[0]\n        subgraph_ = adj[indexes, :][:, indexes]\n        if subgraph_.shape[0] < subgraph_nodes or subgraph_.shape[1] < subgraph_nodes:\n            subgraph = np.identity(subgraph_nodes)\n            feats = np.zeros([subgraph_nodes, features.shape[1]])\n            labels = np.zeros([subgraph_nodes, 121])\n            subgraph = sp.csr_matrix(subgraph).tolil()\n            subgraph[0:subgraph_.shape[0], 0:subgraph_.shape[1]] = subgraph_\n            adj_sub[i - 1, :, :] = subgraph.todense()\n            feats[0:len(indexes)] = features[indexes, :].todense()\n            feat_sub[i - 1, :, :] = feats\n            for (j, node) in enumerate(indexes):\n                labels[j, :] = np.array(class_map[str(node)])\n            labels[indexes.shape[0]:subgraph_nodes, :] = np.zeros([121])\n            labels_sub[i - 1, :, :] = labels\n        else:\n            adj_sub[i - 1, :, :] = subgraph_.todense()\n            feat_sub[i - 1, :, :] = features[indexes, :].todense()\n            for (j, node) in enumerate(indexes):\n                labels[j, :] = np.array(class_map[str(node)])\n            labels_sub[i - 1, :, :] = labels\n    dict_splits = find_split(adj, splits, g_data['nodes'])\n    print('Are sub-graphs isolated?')\n    print(test(adj, splits))\n    train_split = []\n    val_split = []\n    test_split = []\n    for (key, value) in dict_splits.items():\n        if dict_splits[key] == 'train':\n            train_split.append(int(key) - 1)\n        elif dict_splits[key] == 'val':\n            val_split.append(int(key) - 1)\n        elif dict_splits[key] == 'test':\n            test_split.append(int(key) - 1)\n    train_adj = adj_sub[train_split, :, :]\n    val_adj = adj_sub[val_split, :, :]\n    test_adj = adj_sub[test_split, :, :]\n    train_feat = feat_sub[train_split, :, :]\n    val_feat = feat_sub[val_split, :, :]\n    test_feat = feat_sub[test_split, :, :]\n    train_labels = labels_sub[train_split, :, :]\n    val_labels = labels_sub[val_split, :, :]\n    test_labels = labels_sub[test_split, :, :]\n    train_nodes = np.array(nodes_per_graph[train_split[0]:train_split[-1] + 1])\n    val_nodes = np.array(nodes_per_graph[val_split[0]:val_split[-1] + 1])\n    test_nodes = np.array(nodes_per_graph[test_split[0]:test_split[-1] + 1])\n    tr_msk = np.zeros((len(nodes_per_graph[train_split[0]:train_split[-1] + 1]), subgraph_nodes))\n    vl_msk = np.zeros((len(nodes_per_graph[val_split[0]:val_split[-1] + 1]), subgraph_nodes))\n    ts_msk = np.zeros((len(nodes_per_graph[test_split[0]:test_split[-1] + 1]), subgraph_nodes))\n    for i in range(len(train_nodes)):\n        for j in range(train_nodes[i]):\n            tr_msk[i][j] = 1\n    for i in range(len(val_nodes)):\n        for j in range(val_nodes[i]):\n            vl_msk[i][j] = 1\n    for i in range(len(test_nodes)):\n        for j in range(test_nodes[i]):\n            ts_msk[i][j] = 1\n    return (train_adj, val_adj, test_adj, train_feat, val_feat, test_feat, train_labels, val_labels, test_labels, train_nodes, val_nodes, test_nodes, tr_msk, vl_msk, ts_msk)",
            "def process_p2p():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    print('Loading G...')\n    with open('p2p_dataset/ppi-G.json') as jsonfile:\n        g_data = json.load(jsonfile)\n    print(len(g_data))\n    G = json_graph.node_link_graph(g_data)\n    adj = nx.adjacency_matrix(G)\n    prev_key = ''\n    for (key, value) in g_data.items():\n        if prev_key != key:\n            print(key)\n            prev_key = key\n    print('Loading id_map...')\n    with open('p2p_dataset/ppi-id_map.json') as jsonfile:\n        id_map = json.load(jsonfile)\n    print(len(id_map))\n    id_map = {int(k): int(v) for (k, v) in id_map.items()}\n    for (key, value) in id_map.items():\n        id_map[key] = [value]\n    print(len(id_map))\n    print('Loading features...')\n    features_ = np.load('p2p_dataset/ppi-feats.npy')\n    print(features_.shape)\n    from sklearn.preprocessing import StandardScaler\n    train_ids = np.array([id_map[n] for n in G.nodes() if not G.node[n]['val'] and (not G.node[n]['test'])])\n    train_feats = features_[train_ids[:, 0]]\n    scaler = StandardScaler()\n    scaler.fit(train_feats)\n    features_ = scaler.transform(features_)\n    features = sp.csr_matrix(features_).tolil()\n    print('Loading class_map...')\n    class_map = {}\n    with open('p2p_dataset/ppi-class_map.json') as jsonfile:\n        class_map = json.load(jsonfile)\n    print(len(class_map))\n    print('Splitting graph...')\n    splits = dfs_split(adj)\n    print('Re-arranging sub-graph IDs...')\n    list_splits = splits.tolist()\n    group_inc = 1\n    for i in range(np.max(list_splits) + 1):\n        if list_splits.count(i) >= 3:\n            splits[np.array(list_splits) == i] = group_inc\n            group_inc += 1\n        else:\n            ind_nodes = np.argwhere(np.array(list_splits) == i)\n            ind_nodes = ind_nodes[:, 0].tolist()\n            split = None\n            for ind_node in ind_nodes:\n                if g_data['nodes'][ind_node]['val']:\n                    if split is None or split == 'val':\n                        splits[np.array(list_splits) == i] = 21\n                        split = 'val'\n                    else:\n                        raise ValueError('new node is VAL but previously was {}'.format(split))\n                elif g_data['nodes'][ind_node]['test']:\n                    if split is None or split == 'test':\n                        splits[np.array(list_splits) == i] = 23\n                        split = 'test'\n                    else:\n                        raise ValueError('new node is TEST but previously was {}'.format(split))\n                elif split is None or split == 'train':\n                    splits[np.array(list_splits) == i] = 1\n                    split = 'train'\n                else:\n                    pdb.set_trace()\n                    raise ValueError('new node is TRAIN but previously was {}'.format(split))\n    list_splits = splits.tolist()\n    nodes_per_graph = []\n    for i in range(1, np.max(list_splits) + 1):\n        nodes_per_graph.append(list_splits.count(i))\n    subgraph_nodes = np.max(nodes_per_graph)\n    adj_sub = np.empty((len(nodes_per_graph), subgraph_nodes, subgraph_nodes))\n    feat_sub = np.empty((len(nodes_per_graph), subgraph_nodes, features.shape[1]))\n    labels_sub = np.empty((len(nodes_per_graph), subgraph_nodes, 121))\n    for i in range(1, np.max(list_splits) + 1):\n        indexes = np.where(splits == i)[0]\n        subgraph_ = adj[indexes, :][:, indexes]\n        if subgraph_.shape[0] < subgraph_nodes or subgraph_.shape[1] < subgraph_nodes:\n            subgraph = np.identity(subgraph_nodes)\n            feats = np.zeros([subgraph_nodes, features.shape[1]])\n            labels = np.zeros([subgraph_nodes, 121])\n            subgraph = sp.csr_matrix(subgraph).tolil()\n            subgraph[0:subgraph_.shape[0], 0:subgraph_.shape[1]] = subgraph_\n            adj_sub[i - 1, :, :] = subgraph.todense()\n            feats[0:len(indexes)] = features[indexes, :].todense()\n            feat_sub[i - 1, :, :] = feats\n            for (j, node) in enumerate(indexes):\n                labels[j, :] = np.array(class_map[str(node)])\n            labels[indexes.shape[0]:subgraph_nodes, :] = np.zeros([121])\n            labels_sub[i - 1, :, :] = labels\n        else:\n            adj_sub[i - 1, :, :] = subgraph_.todense()\n            feat_sub[i - 1, :, :] = features[indexes, :].todense()\n            for (j, node) in enumerate(indexes):\n                labels[j, :] = np.array(class_map[str(node)])\n            labels_sub[i - 1, :, :] = labels\n    dict_splits = find_split(adj, splits, g_data['nodes'])\n    print('Are sub-graphs isolated?')\n    print(test(adj, splits))\n    train_split = []\n    val_split = []\n    test_split = []\n    for (key, value) in dict_splits.items():\n        if dict_splits[key] == 'train':\n            train_split.append(int(key) - 1)\n        elif dict_splits[key] == 'val':\n            val_split.append(int(key) - 1)\n        elif dict_splits[key] == 'test':\n            test_split.append(int(key) - 1)\n    train_adj = adj_sub[train_split, :, :]\n    val_adj = adj_sub[val_split, :, :]\n    test_adj = adj_sub[test_split, :, :]\n    train_feat = feat_sub[train_split, :, :]\n    val_feat = feat_sub[val_split, :, :]\n    test_feat = feat_sub[test_split, :, :]\n    train_labels = labels_sub[train_split, :, :]\n    val_labels = labels_sub[val_split, :, :]\n    test_labels = labels_sub[test_split, :, :]\n    train_nodes = np.array(nodes_per_graph[train_split[0]:train_split[-1] + 1])\n    val_nodes = np.array(nodes_per_graph[val_split[0]:val_split[-1] + 1])\n    test_nodes = np.array(nodes_per_graph[test_split[0]:test_split[-1] + 1])\n    tr_msk = np.zeros((len(nodes_per_graph[train_split[0]:train_split[-1] + 1]), subgraph_nodes))\n    vl_msk = np.zeros((len(nodes_per_graph[val_split[0]:val_split[-1] + 1]), subgraph_nodes))\n    ts_msk = np.zeros((len(nodes_per_graph[test_split[0]:test_split[-1] + 1]), subgraph_nodes))\n    for i in range(len(train_nodes)):\n        for j in range(train_nodes[i]):\n            tr_msk[i][j] = 1\n    for i in range(len(val_nodes)):\n        for j in range(val_nodes[i]):\n            vl_msk[i][j] = 1\n    for i in range(len(test_nodes)):\n        for j in range(test_nodes[i]):\n            ts_msk[i][j] = 1\n    return (train_adj, val_adj, test_adj, train_feat, val_feat, test_feat, train_labels, val_labels, test_labels, train_nodes, val_nodes, test_nodes, tr_msk, vl_msk, ts_msk)",
            "def process_p2p():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    print('Loading G...')\n    with open('p2p_dataset/ppi-G.json') as jsonfile:\n        g_data = json.load(jsonfile)\n    print(len(g_data))\n    G = json_graph.node_link_graph(g_data)\n    adj = nx.adjacency_matrix(G)\n    prev_key = ''\n    for (key, value) in g_data.items():\n        if prev_key != key:\n            print(key)\n            prev_key = key\n    print('Loading id_map...')\n    with open('p2p_dataset/ppi-id_map.json') as jsonfile:\n        id_map = json.load(jsonfile)\n    print(len(id_map))\n    id_map = {int(k): int(v) for (k, v) in id_map.items()}\n    for (key, value) in id_map.items():\n        id_map[key] = [value]\n    print(len(id_map))\n    print('Loading features...')\n    features_ = np.load('p2p_dataset/ppi-feats.npy')\n    print(features_.shape)\n    from sklearn.preprocessing import StandardScaler\n    train_ids = np.array([id_map[n] for n in G.nodes() if not G.node[n]['val'] and (not G.node[n]['test'])])\n    train_feats = features_[train_ids[:, 0]]\n    scaler = StandardScaler()\n    scaler.fit(train_feats)\n    features_ = scaler.transform(features_)\n    features = sp.csr_matrix(features_).tolil()\n    print('Loading class_map...')\n    class_map = {}\n    with open('p2p_dataset/ppi-class_map.json') as jsonfile:\n        class_map = json.load(jsonfile)\n    print(len(class_map))\n    print('Splitting graph...')\n    splits = dfs_split(adj)\n    print('Re-arranging sub-graph IDs...')\n    list_splits = splits.tolist()\n    group_inc = 1\n    for i in range(np.max(list_splits) + 1):\n        if list_splits.count(i) >= 3:\n            splits[np.array(list_splits) == i] = group_inc\n            group_inc += 1\n        else:\n            ind_nodes = np.argwhere(np.array(list_splits) == i)\n            ind_nodes = ind_nodes[:, 0].tolist()\n            split = None\n            for ind_node in ind_nodes:\n                if g_data['nodes'][ind_node]['val']:\n                    if split is None or split == 'val':\n                        splits[np.array(list_splits) == i] = 21\n                        split = 'val'\n                    else:\n                        raise ValueError('new node is VAL but previously was {}'.format(split))\n                elif g_data['nodes'][ind_node]['test']:\n                    if split is None or split == 'test':\n                        splits[np.array(list_splits) == i] = 23\n                        split = 'test'\n                    else:\n                        raise ValueError('new node is TEST but previously was {}'.format(split))\n                elif split is None or split == 'train':\n                    splits[np.array(list_splits) == i] = 1\n                    split = 'train'\n                else:\n                    pdb.set_trace()\n                    raise ValueError('new node is TRAIN but previously was {}'.format(split))\n    list_splits = splits.tolist()\n    nodes_per_graph = []\n    for i in range(1, np.max(list_splits) + 1):\n        nodes_per_graph.append(list_splits.count(i))\n    subgraph_nodes = np.max(nodes_per_graph)\n    adj_sub = np.empty((len(nodes_per_graph), subgraph_nodes, subgraph_nodes))\n    feat_sub = np.empty((len(nodes_per_graph), subgraph_nodes, features.shape[1]))\n    labels_sub = np.empty((len(nodes_per_graph), subgraph_nodes, 121))\n    for i in range(1, np.max(list_splits) + 1):\n        indexes = np.where(splits == i)[0]\n        subgraph_ = adj[indexes, :][:, indexes]\n        if subgraph_.shape[0] < subgraph_nodes or subgraph_.shape[1] < subgraph_nodes:\n            subgraph = np.identity(subgraph_nodes)\n            feats = np.zeros([subgraph_nodes, features.shape[1]])\n            labels = np.zeros([subgraph_nodes, 121])\n            subgraph = sp.csr_matrix(subgraph).tolil()\n            subgraph[0:subgraph_.shape[0], 0:subgraph_.shape[1]] = subgraph_\n            adj_sub[i - 1, :, :] = subgraph.todense()\n            feats[0:len(indexes)] = features[indexes, :].todense()\n            feat_sub[i - 1, :, :] = feats\n            for (j, node) in enumerate(indexes):\n                labels[j, :] = np.array(class_map[str(node)])\n            labels[indexes.shape[0]:subgraph_nodes, :] = np.zeros([121])\n            labels_sub[i - 1, :, :] = labels\n        else:\n            adj_sub[i - 1, :, :] = subgraph_.todense()\n            feat_sub[i - 1, :, :] = features[indexes, :].todense()\n            for (j, node) in enumerate(indexes):\n                labels[j, :] = np.array(class_map[str(node)])\n            labels_sub[i - 1, :, :] = labels\n    dict_splits = find_split(adj, splits, g_data['nodes'])\n    print('Are sub-graphs isolated?')\n    print(test(adj, splits))\n    train_split = []\n    val_split = []\n    test_split = []\n    for (key, value) in dict_splits.items():\n        if dict_splits[key] == 'train':\n            train_split.append(int(key) - 1)\n        elif dict_splits[key] == 'val':\n            val_split.append(int(key) - 1)\n        elif dict_splits[key] == 'test':\n            test_split.append(int(key) - 1)\n    train_adj = adj_sub[train_split, :, :]\n    val_adj = adj_sub[val_split, :, :]\n    test_adj = adj_sub[test_split, :, :]\n    train_feat = feat_sub[train_split, :, :]\n    val_feat = feat_sub[val_split, :, :]\n    test_feat = feat_sub[test_split, :, :]\n    train_labels = labels_sub[train_split, :, :]\n    val_labels = labels_sub[val_split, :, :]\n    test_labels = labels_sub[test_split, :, :]\n    train_nodes = np.array(nodes_per_graph[train_split[0]:train_split[-1] + 1])\n    val_nodes = np.array(nodes_per_graph[val_split[0]:val_split[-1] + 1])\n    test_nodes = np.array(nodes_per_graph[test_split[0]:test_split[-1] + 1])\n    tr_msk = np.zeros((len(nodes_per_graph[train_split[0]:train_split[-1] + 1]), subgraph_nodes))\n    vl_msk = np.zeros((len(nodes_per_graph[val_split[0]:val_split[-1] + 1]), subgraph_nodes))\n    ts_msk = np.zeros((len(nodes_per_graph[test_split[0]:test_split[-1] + 1]), subgraph_nodes))\n    for i in range(len(train_nodes)):\n        for j in range(train_nodes[i]):\n            tr_msk[i][j] = 1\n    for i in range(len(val_nodes)):\n        for j in range(val_nodes[i]):\n            vl_msk[i][j] = 1\n    for i in range(len(test_nodes)):\n        for j in range(test_nodes[i]):\n            ts_msk[i][j] = 1\n    return (train_adj, val_adj, test_adj, train_feat, val_feat, test_feat, train_labels, val_labels, test_labels, train_nodes, val_nodes, test_nodes, tr_msk, vl_msk, ts_msk)",
            "def process_p2p():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    print('Loading G...')\n    with open('p2p_dataset/ppi-G.json') as jsonfile:\n        g_data = json.load(jsonfile)\n    print(len(g_data))\n    G = json_graph.node_link_graph(g_data)\n    adj = nx.adjacency_matrix(G)\n    prev_key = ''\n    for (key, value) in g_data.items():\n        if prev_key != key:\n            print(key)\n            prev_key = key\n    print('Loading id_map...')\n    with open('p2p_dataset/ppi-id_map.json') as jsonfile:\n        id_map = json.load(jsonfile)\n    print(len(id_map))\n    id_map = {int(k): int(v) for (k, v) in id_map.items()}\n    for (key, value) in id_map.items():\n        id_map[key] = [value]\n    print(len(id_map))\n    print('Loading features...')\n    features_ = np.load('p2p_dataset/ppi-feats.npy')\n    print(features_.shape)\n    from sklearn.preprocessing import StandardScaler\n    train_ids = np.array([id_map[n] for n in G.nodes() if not G.node[n]['val'] and (not G.node[n]['test'])])\n    train_feats = features_[train_ids[:, 0]]\n    scaler = StandardScaler()\n    scaler.fit(train_feats)\n    features_ = scaler.transform(features_)\n    features = sp.csr_matrix(features_).tolil()\n    print('Loading class_map...')\n    class_map = {}\n    with open('p2p_dataset/ppi-class_map.json') as jsonfile:\n        class_map = json.load(jsonfile)\n    print(len(class_map))\n    print('Splitting graph...')\n    splits = dfs_split(adj)\n    print('Re-arranging sub-graph IDs...')\n    list_splits = splits.tolist()\n    group_inc = 1\n    for i in range(np.max(list_splits) + 1):\n        if list_splits.count(i) >= 3:\n            splits[np.array(list_splits) == i] = group_inc\n            group_inc += 1\n        else:\n            ind_nodes = np.argwhere(np.array(list_splits) == i)\n            ind_nodes = ind_nodes[:, 0].tolist()\n            split = None\n            for ind_node in ind_nodes:\n                if g_data['nodes'][ind_node]['val']:\n                    if split is None or split == 'val':\n                        splits[np.array(list_splits) == i] = 21\n                        split = 'val'\n                    else:\n                        raise ValueError('new node is VAL but previously was {}'.format(split))\n                elif g_data['nodes'][ind_node]['test']:\n                    if split is None or split == 'test':\n                        splits[np.array(list_splits) == i] = 23\n                        split = 'test'\n                    else:\n                        raise ValueError('new node is TEST but previously was {}'.format(split))\n                elif split is None or split == 'train':\n                    splits[np.array(list_splits) == i] = 1\n                    split = 'train'\n                else:\n                    pdb.set_trace()\n                    raise ValueError('new node is TRAIN but previously was {}'.format(split))\n    list_splits = splits.tolist()\n    nodes_per_graph = []\n    for i in range(1, np.max(list_splits) + 1):\n        nodes_per_graph.append(list_splits.count(i))\n    subgraph_nodes = np.max(nodes_per_graph)\n    adj_sub = np.empty((len(nodes_per_graph), subgraph_nodes, subgraph_nodes))\n    feat_sub = np.empty((len(nodes_per_graph), subgraph_nodes, features.shape[1]))\n    labels_sub = np.empty((len(nodes_per_graph), subgraph_nodes, 121))\n    for i in range(1, np.max(list_splits) + 1):\n        indexes = np.where(splits == i)[0]\n        subgraph_ = adj[indexes, :][:, indexes]\n        if subgraph_.shape[0] < subgraph_nodes or subgraph_.shape[1] < subgraph_nodes:\n            subgraph = np.identity(subgraph_nodes)\n            feats = np.zeros([subgraph_nodes, features.shape[1]])\n            labels = np.zeros([subgraph_nodes, 121])\n            subgraph = sp.csr_matrix(subgraph).tolil()\n            subgraph[0:subgraph_.shape[0], 0:subgraph_.shape[1]] = subgraph_\n            adj_sub[i - 1, :, :] = subgraph.todense()\n            feats[0:len(indexes)] = features[indexes, :].todense()\n            feat_sub[i - 1, :, :] = feats\n            for (j, node) in enumerate(indexes):\n                labels[j, :] = np.array(class_map[str(node)])\n            labels[indexes.shape[0]:subgraph_nodes, :] = np.zeros([121])\n            labels_sub[i - 1, :, :] = labels\n        else:\n            adj_sub[i - 1, :, :] = subgraph_.todense()\n            feat_sub[i - 1, :, :] = features[indexes, :].todense()\n            for (j, node) in enumerate(indexes):\n                labels[j, :] = np.array(class_map[str(node)])\n            labels_sub[i - 1, :, :] = labels\n    dict_splits = find_split(adj, splits, g_data['nodes'])\n    print('Are sub-graphs isolated?')\n    print(test(adj, splits))\n    train_split = []\n    val_split = []\n    test_split = []\n    for (key, value) in dict_splits.items():\n        if dict_splits[key] == 'train':\n            train_split.append(int(key) - 1)\n        elif dict_splits[key] == 'val':\n            val_split.append(int(key) - 1)\n        elif dict_splits[key] == 'test':\n            test_split.append(int(key) - 1)\n    train_adj = adj_sub[train_split, :, :]\n    val_adj = adj_sub[val_split, :, :]\n    test_adj = adj_sub[test_split, :, :]\n    train_feat = feat_sub[train_split, :, :]\n    val_feat = feat_sub[val_split, :, :]\n    test_feat = feat_sub[test_split, :, :]\n    train_labels = labels_sub[train_split, :, :]\n    val_labels = labels_sub[val_split, :, :]\n    test_labels = labels_sub[test_split, :, :]\n    train_nodes = np.array(nodes_per_graph[train_split[0]:train_split[-1] + 1])\n    val_nodes = np.array(nodes_per_graph[val_split[0]:val_split[-1] + 1])\n    test_nodes = np.array(nodes_per_graph[test_split[0]:test_split[-1] + 1])\n    tr_msk = np.zeros((len(nodes_per_graph[train_split[0]:train_split[-1] + 1]), subgraph_nodes))\n    vl_msk = np.zeros((len(nodes_per_graph[val_split[0]:val_split[-1] + 1]), subgraph_nodes))\n    ts_msk = np.zeros((len(nodes_per_graph[test_split[0]:test_split[-1] + 1]), subgraph_nodes))\n    for i in range(len(train_nodes)):\n        for j in range(train_nodes[i]):\n            tr_msk[i][j] = 1\n    for i in range(len(val_nodes)):\n        for j in range(val_nodes[i]):\n            vl_msk[i][j] = 1\n    for i in range(len(test_nodes)):\n        for j in range(test_nodes[i]):\n            ts_msk[i][j] = 1\n    return (train_adj, val_adj, test_adj, train_feat, val_feat, test_feat, train_labels, val_labels, test_labels, train_nodes, val_nodes, test_nodes, tr_msk, vl_msk, ts_msk)",
            "def process_p2p():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    print('Loading G...')\n    with open('p2p_dataset/ppi-G.json') as jsonfile:\n        g_data = json.load(jsonfile)\n    print(len(g_data))\n    G = json_graph.node_link_graph(g_data)\n    adj = nx.adjacency_matrix(G)\n    prev_key = ''\n    for (key, value) in g_data.items():\n        if prev_key != key:\n            print(key)\n            prev_key = key\n    print('Loading id_map...')\n    with open('p2p_dataset/ppi-id_map.json') as jsonfile:\n        id_map = json.load(jsonfile)\n    print(len(id_map))\n    id_map = {int(k): int(v) for (k, v) in id_map.items()}\n    for (key, value) in id_map.items():\n        id_map[key] = [value]\n    print(len(id_map))\n    print('Loading features...')\n    features_ = np.load('p2p_dataset/ppi-feats.npy')\n    print(features_.shape)\n    from sklearn.preprocessing import StandardScaler\n    train_ids = np.array([id_map[n] for n in G.nodes() if not G.node[n]['val'] and (not G.node[n]['test'])])\n    train_feats = features_[train_ids[:, 0]]\n    scaler = StandardScaler()\n    scaler.fit(train_feats)\n    features_ = scaler.transform(features_)\n    features = sp.csr_matrix(features_).tolil()\n    print('Loading class_map...')\n    class_map = {}\n    with open('p2p_dataset/ppi-class_map.json') as jsonfile:\n        class_map = json.load(jsonfile)\n    print(len(class_map))\n    print('Splitting graph...')\n    splits = dfs_split(adj)\n    print('Re-arranging sub-graph IDs...')\n    list_splits = splits.tolist()\n    group_inc = 1\n    for i in range(np.max(list_splits) + 1):\n        if list_splits.count(i) >= 3:\n            splits[np.array(list_splits) == i] = group_inc\n            group_inc += 1\n        else:\n            ind_nodes = np.argwhere(np.array(list_splits) == i)\n            ind_nodes = ind_nodes[:, 0].tolist()\n            split = None\n            for ind_node in ind_nodes:\n                if g_data['nodes'][ind_node]['val']:\n                    if split is None or split == 'val':\n                        splits[np.array(list_splits) == i] = 21\n                        split = 'val'\n                    else:\n                        raise ValueError('new node is VAL but previously was {}'.format(split))\n                elif g_data['nodes'][ind_node]['test']:\n                    if split is None or split == 'test':\n                        splits[np.array(list_splits) == i] = 23\n                        split = 'test'\n                    else:\n                        raise ValueError('new node is TEST but previously was {}'.format(split))\n                elif split is None or split == 'train':\n                    splits[np.array(list_splits) == i] = 1\n                    split = 'train'\n                else:\n                    pdb.set_trace()\n                    raise ValueError('new node is TRAIN but previously was {}'.format(split))\n    list_splits = splits.tolist()\n    nodes_per_graph = []\n    for i in range(1, np.max(list_splits) + 1):\n        nodes_per_graph.append(list_splits.count(i))\n    subgraph_nodes = np.max(nodes_per_graph)\n    adj_sub = np.empty((len(nodes_per_graph), subgraph_nodes, subgraph_nodes))\n    feat_sub = np.empty((len(nodes_per_graph), subgraph_nodes, features.shape[1]))\n    labels_sub = np.empty((len(nodes_per_graph), subgraph_nodes, 121))\n    for i in range(1, np.max(list_splits) + 1):\n        indexes = np.where(splits == i)[0]\n        subgraph_ = adj[indexes, :][:, indexes]\n        if subgraph_.shape[0] < subgraph_nodes or subgraph_.shape[1] < subgraph_nodes:\n            subgraph = np.identity(subgraph_nodes)\n            feats = np.zeros([subgraph_nodes, features.shape[1]])\n            labels = np.zeros([subgraph_nodes, 121])\n            subgraph = sp.csr_matrix(subgraph).tolil()\n            subgraph[0:subgraph_.shape[0], 0:subgraph_.shape[1]] = subgraph_\n            adj_sub[i - 1, :, :] = subgraph.todense()\n            feats[0:len(indexes)] = features[indexes, :].todense()\n            feat_sub[i - 1, :, :] = feats\n            for (j, node) in enumerate(indexes):\n                labels[j, :] = np.array(class_map[str(node)])\n            labels[indexes.shape[0]:subgraph_nodes, :] = np.zeros([121])\n            labels_sub[i - 1, :, :] = labels\n        else:\n            adj_sub[i - 1, :, :] = subgraph_.todense()\n            feat_sub[i - 1, :, :] = features[indexes, :].todense()\n            for (j, node) in enumerate(indexes):\n                labels[j, :] = np.array(class_map[str(node)])\n            labels_sub[i - 1, :, :] = labels\n    dict_splits = find_split(adj, splits, g_data['nodes'])\n    print('Are sub-graphs isolated?')\n    print(test(adj, splits))\n    train_split = []\n    val_split = []\n    test_split = []\n    for (key, value) in dict_splits.items():\n        if dict_splits[key] == 'train':\n            train_split.append(int(key) - 1)\n        elif dict_splits[key] == 'val':\n            val_split.append(int(key) - 1)\n        elif dict_splits[key] == 'test':\n            test_split.append(int(key) - 1)\n    train_adj = adj_sub[train_split, :, :]\n    val_adj = adj_sub[val_split, :, :]\n    test_adj = adj_sub[test_split, :, :]\n    train_feat = feat_sub[train_split, :, :]\n    val_feat = feat_sub[val_split, :, :]\n    test_feat = feat_sub[test_split, :, :]\n    train_labels = labels_sub[train_split, :, :]\n    val_labels = labels_sub[val_split, :, :]\n    test_labels = labels_sub[test_split, :, :]\n    train_nodes = np.array(nodes_per_graph[train_split[0]:train_split[-1] + 1])\n    val_nodes = np.array(nodes_per_graph[val_split[0]:val_split[-1] + 1])\n    test_nodes = np.array(nodes_per_graph[test_split[0]:test_split[-1] + 1])\n    tr_msk = np.zeros((len(nodes_per_graph[train_split[0]:train_split[-1] + 1]), subgraph_nodes))\n    vl_msk = np.zeros((len(nodes_per_graph[val_split[0]:val_split[-1] + 1]), subgraph_nodes))\n    ts_msk = np.zeros((len(nodes_per_graph[test_split[0]:test_split[-1] + 1]), subgraph_nodes))\n    for i in range(len(train_nodes)):\n        for j in range(train_nodes[i]):\n            tr_msk[i][j] = 1\n    for i in range(len(val_nodes)):\n        for j in range(val_nodes[i]):\n            vl_msk[i][j] = 1\n    for i in range(len(test_nodes)):\n        for j in range(test_nodes[i]):\n            ts_msk[i][j] = 1\n    return (train_adj, val_adj, test_adj, train_feat, val_feat, test_feat, train_labels, val_labels, test_labels, train_nodes, val_nodes, test_nodes, tr_msk, vl_msk, ts_msk)"
        ]
    }
]