[
    {
        "func_name": "get_config",
        "original": "def get_config(checkpoint_url):\n    config = Swin2SRConfig()\n    if 'Swin2SR_ClassicalSR_X4_64' in checkpoint_url:\n        config.upscale = 4\n    elif 'Swin2SR_CompressedSR_X4_48' in checkpoint_url:\n        config.upscale = 4\n        config.image_size = 48\n        config.upsampler = 'pixelshuffle_aux'\n    elif 'Swin2SR_Lightweight_X2_64' in checkpoint_url:\n        config.depths = [6, 6, 6, 6]\n        config.embed_dim = 60\n        config.num_heads = [6, 6, 6, 6]\n        config.upsampler = 'pixelshuffledirect'\n    elif 'Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR' in checkpoint_url:\n        config.upscale = 4\n        config.upsampler = 'nearest+conv'\n    elif 'Swin2SR_Jpeg_dynamic' in checkpoint_url:\n        config.num_channels = 1\n        config.upscale = 1\n        config.image_size = 126\n        config.window_size = 7\n        config.img_range = 255.0\n        config.upsampler = ''\n    return config",
        "mutated": [
            "def get_config(checkpoint_url):\n    if False:\n        i = 10\n    config = Swin2SRConfig()\n    if 'Swin2SR_ClassicalSR_X4_64' in checkpoint_url:\n        config.upscale = 4\n    elif 'Swin2SR_CompressedSR_X4_48' in checkpoint_url:\n        config.upscale = 4\n        config.image_size = 48\n        config.upsampler = 'pixelshuffle_aux'\n    elif 'Swin2SR_Lightweight_X2_64' in checkpoint_url:\n        config.depths = [6, 6, 6, 6]\n        config.embed_dim = 60\n        config.num_heads = [6, 6, 6, 6]\n        config.upsampler = 'pixelshuffledirect'\n    elif 'Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR' in checkpoint_url:\n        config.upscale = 4\n        config.upsampler = 'nearest+conv'\n    elif 'Swin2SR_Jpeg_dynamic' in checkpoint_url:\n        config.num_channels = 1\n        config.upscale = 1\n        config.image_size = 126\n        config.window_size = 7\n        config.img_range = 255.0\n        config.upsampler = ''\n    return config",
            "def get_config(checkpoint_url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    config = Swin2SRConfig()\n    if 'Swin2SR_ClassicalSR_X4_64' in checkpoint_url:\n        config.upscale = 4\n    elif 'Swin2SR_CompressedSR_X4_48' in checkpoint_url:\n        config.upscale = 4\n        config.image_size = 48\n        config.upsampler = 'pixelshuffle_aux'\n    elif 'Swin2SR_Lightweight_X2_64' in checkpoint_url:\n        config.depths = [6, 6, 6, 6]\n        config.embed_dim = 60\n        config.num_heads = [6, 6, 6, 6]\n        config.upsampler = 'pixelshuffledirect'\n    elif 'Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR' in checkpoint_url:\n        config.upscale = 4\n        config.upsampler = 'nearest+conv'\n    elif 'Swin2SR_Jpeg_dynamic' in checkpoint_url:\n        config.num_channels = 1\n        config.upscale = 1\n        config.image_size = 126\n        config.window_size = 7\n        config.img_range = 255.0\n        config.upsampler = ''\n    return config",
            "def get_config(checkpoint_url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    config = Swin2SRConfig()\n    if 'Swin2SR_ClassicalSR_X4_64' in checkpoint_url:\n        config.upscale = 4\n    elif 'Swin2SR_CompressedSR_X4_48' in checkpoint_url:\n        config.upscale = 4\n        config.image_size = 48\n        config.upsampler = 'pixelshuffle_aux'\n    elif 'Swin2SR_Lightweight_X2_64' in checkpoint_url:\n        config.depths = [6, 6, 6, 6]\n        config.embed_dim = 60\n        config.num_heads = [6, 6, 6, 6]\n        config.upsampler = 'pixelshuffledirect'\n    elif 'Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR' in checkpoint_url:\n        config.upscale = 4\n        config.upsampler = 'nearest+conv'\n    elif 'Swin2SR_Jpeg_dynamic' in checkpoint_url:\n        config.num_channels = 1\n        config.upscale = 1\n        config.image_size = 126\n        config.window_size = 7\n        config.img_range = 255.0\n        config.upsampler = ''\n    return config",
            "def get_config(checkpoint_url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    config = Swin2SRConfig()\n    if 'Swin2SR_ClassicalSR_X4_64' in checkpoint_url:\n        config.upscale = 4\n    elif 'Swin2SR_CompressedSR_X4_48' in checkpoint_url:\n        config.upscale = 4\n        config.image_size = 48\n        config.upsampler = 'pixelshuffle_aux'\n    elif 'Swin2SR_Lightweight_X2_64' in checkpoint_url:\n        config.depths = [6, 6, 6, 6]\n        config.embed_dim = 60\n        config.num_heads = [6, 6, 6, 6]\n        config.upsampler = 'pixelshuffledirect'\n    elif 'Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR' in checkpoint_url:\n        config.upscale = 4\n        config.upsampler = 'nearest+conv'\n    elif 'Swin2SR_Jpeg_dynamic' in checkpoint_url:\n        config.num_channels = 1\n        config.upscale = 1\n        config.image_size = 126\n        config.window_size = 7\n        config.img_range = 255.0\n        config.upsampler = ''\n    return config",
            "def get_config(checkpoint_url):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    config = Swin2SRConfig()\n    if 'Swin2SR_ClassicalSR_X4_64' in checkpoint_url:\n        config.upscale = 4\n    elif 'Swin2SR_CompressedSR_X4_48' in checkpoint_url:\n        config.upscale = 4\n        config.image_size = 48\n        config.upsampler = 'pixelshuffle_aux'\n    elif 'Swin2SR_Lightweight_X2_64' in checkpoint_url:\n        config.depths = [6, 6, 6, 6]\n        config.embed_dim = 60\n        config.num_heads = [6, 6, 6, 6]\n        config.upsampler = 'pixelshuffledirect'\n    elif 'Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR' in checkpoint_url:\n        config.upscale = 4\n        config.upsampler = 'nearest+conv'\n    elif 'Swin2SR_Jpeg_dynamic' in checkpoint_url:\n        config.num_channels = 1\n        config.upscale = 1\n        config.image_size = 126\n        config.window_size = 7\n        config.img_range = 255.0\n        config.upsampler = ''\n    return config"
        ]
    },
    {
        "func_name": "rename_key",
        "original": "def rename_key(name, config):\n    if 'patch_embed.proj' in name and 'layers' not in name:\n        name = name.replace('patch_embed.proj', 'embeddings.patch_embeddings.projection')\n    if 'patch_embed.norm' in name:\n        name = name.replace('patch_embed.norm', 'embeddings.patch_embeddings.layernorm')\n    if 'layers' in name:\n        name = name.replace('layers', 'encoder.stages')\n    if 'residual_group.blocks' in name:\n        name = name.replace('residual_group.blocks', 'layers')\n    if 'attn.proj' in name:\n        name = name.replace('attn.proj', 'attention.output.dense')\n    if 'attn' in name:\n        name = name.replace('attn', 'attention.self')\n    if 'norm1' in name:\n        name = name.replace('norm1', 'layernorm_before')\n    if 'norm2' in name:\n        name = name.replace('norm2', 'layernorm_after')\n    if 'mlp.fc1' in name:\n        name = name.replace('mlp.fc1', 'intermediate.dense')\n    if 'mlp.fc2' in name:\n        name = name.replace('mlp.fc2', 'output.dense')\n    if 'q_bias' in name:\n        name = name.replace('q_bias', 'query.bias')\n    if 'k_bias' in name:\n        name = name.replace('k_bias', 'key.bias')\n    if 'v_bias' in name:\n        name = name.replace('v_bias', 'value.bias')\n    if 'cpb_mlp' in name:\n        name = name.replace('cpb_mlp', 'continuous_position_bias_mlp')\n    if 'patch_embed.proj' in name:\n        name = name.replace('patch_embed.proj', 'patch_embed.projection')\n    if name == 'norm.weight':\n        name = 'layernorm.weight'\n    if name == 'norm.bias':\n        name = 'layernorm.bias'\n    if 'conv_first' in name:\n        name = name.replace('conv_first', 'first_convolution')\n    if 'upsample' in name or 'conv_before_upsample' in name or 'conv_bicubic' in name or ('conv_up' in name) or ('conv_hr' in name) or ('conv_last' in name) or ('aux' in name):\n        if 'conv_last' in name:\n            name = name.replace('conv_last', 'final_convolution')\n        if config.upsampler in ['pixelshuffle', 'pixelshuffle_aux', 'nearest+conv']:\n            if 'conv_before_upsample.0' in name:\n                name = name.replace('conv_before_upsample.0', 'conv_before_upsample')\n            if 'upsample.0' in name:\n                name = name.replace('upsample.0', 'upsample.convolution_0')\n            if 'upsample.2' in name:\n                name = name.replace('upsample.2', 'upsample.convolution_1')\n            name = 'upsample.' + name\n        elif config.upsampler == 'pixelshuffledirect':\n            name = name.replace('upsample.0.weight', 'upsample.conv.weight')\n            name = name.replace('upsample.0.bias', 'upsample.conv.bias')\n        else:\n            pass\n    else:\n        name = 'swin2sr.' + name\n    return name",
        "mutated": [
            "def rename_key(name, config):\n    if False:\n        i = 10\n    if 'patch_embed.proj' in name and 'layers' not in name:\n        name = name.replace('patch_embed.proj', 'embeddings.patch_embeddings.projection')\n    if 'patch_embed.norm' in name:\n        name = name.replace('patch_embed.norm', 'embeddings.patch_embeddings.layernorm')\n    if 'layers' in name:\n        name = name.replace('layers', 'encoder.stages')\n    if 'residual_group.blocks' in name:\n        name = name.replace('residual_group.blocks', 'layers')\n    if 'attn.proj' in name:\n        name = name.replace('attn.proj', 'attention.output.dense')\n    if 'attn' in name:\n        name = name.replace('attn', 'attention.self')\n    if 'norm1' in name:\n        name = name.replace('norm1', 'layernorm_before')\n    if 'norm2' in name:\n        name = name.replace('norm2', 'layernorm_after')\n    if 'mlp.fc1' in name:\n        name = name.replace('mlp.fc1', 'intermediate.dense')\n    if 'mlp.fc2' in name:\n        name = name.replace('mlp.fc2', 'output.dense')\n    if 'q_bias' in name:\n        name = name.replace('q_bias', 'query.bias')\n    if 'k_bias' in name:\n        name = name.replace('k_bias', 'key.bias')\n    if 'v_bias' in name:\n        name = name.replace('v_bias', 'value.bias')\n    if 'cpb_mlp' in name:\n        name = name.replace('cpb_mlp', 'continuous_position_bias_mlp')\n    if 'patch_embed.proj' in name:\n        name = name.replace('patch_embed.proj', 'patch_embed.projection')\n    if name == 'norm.weight':\n        name = 'layernorm.weight'\n    if name == 'norm.bias':\n        name = 'layernorm.bias'\n    if 'conv_first' in name:\n        name = name.replace('conv_first', 'first_convolution')\n    if 'upsample' in name or 'conv_before_upsample' in name or 'conv_bicubic' in name or ('conv_up' in name) or ('conv_hr' in name) or ('conv_last' in name) or ('aux' in name):\n        if 'conv_last' in name:\n            name = name.replace('conv_last', 'final_convolution')\n        if config.upsampler in ['pixelshuffle', 'pixelshuffle_aux', 'nearest+conv']:\n            if 'conv_before_upsample.0' in name:\n                name = name.replace('conv_before_upsample.0', 'conv_before_upsample')\n            if 'upsample.0' in name:\n                name = name.replace('upsample.0', 'upsample.convolution_0')\n            if 'upsample.2' in name:\n                name = name.replace('upsample.2', 'upsample.convolution_1')\n            name = 'upsample.' + name\n        elif config.upsampler == 'pixelshuffledirect':\n            name = name.replace('upsample.0.weight', 'upsample.conv.weight')\n            name = name.replace('upsample.0.bias', 'upsample.conv.bias')\n        else:\n            pass\n    else:\n        name = 'swin2sr.' + name\n    return name",
            "def rename_key(name, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if 'patch_embed.proj' in name and 'layers' not in name:\n        name = name.replace('patch_embed.proj', 'embeddings.patch_embeddings.projection')\n    if 'patch_embed.norm' in name:\n        name = name.replace('patch_embed.norm', 'embeddings.patch_embeddings.layernorm')\n    if 'layers' in name:\n        name = name.replace('layers', 'encoder.stages')\n    if 'residual_group.blocks' in name:\n        name = name.replace('residual_group.blocks', 'layers')\n    if 'attn.proj' in name:\n        name = name.replace('attn.proj', 'attention.output.dense')\n    if 'attn' in name:\n        name = name.replace('attn', 'attention.self')\n    if 'norm1' in name:\n        name = name.replace('norm1', 'layernorm_before')\n    if 'norm2' in name:\n        name = name.replace('norm2', 'layernorm_after')\n    if 'mlp.fc1' in name:\n        name = name.replace('mlp.fc1', 'intermediate.dense')\n    if 'mlp.fc2' in name:\n        name = name.replace('mlp.fc2', 'output.dense')\n    if 'q_bias' in name:\n        name = name.replace('q_bias', 'query.bias')\n    if 'k_bias' in name:\n        name = name.replace('k_bias', 'key.bias')\n    if 'v_bias' in name:\n        name = name.replace('v_bias', 'value.bias')\n    if 'cpb_mlp' in name:\n        name = name.replace('cpb_mlp', 'continuous_position_bias_mlp')\n    if 'patch_embed.proj' in name:\n        name = name.replace('patch_embed.proj', 'patch_embed.projection')\n    if name == 'norm.weight':\n        name = 'layernorm.weight'\n    if name == 'norm.bias':\n        name = 'layernorm.bias'\n    if 'conv_first' in name:\n        name = name.replace('conv_first', 'first_convolution')\n    if 'upsample' in name or 'conv_before_upsample' in name or 'conv_bicubic' in name or ('conv_up' in name) or ('conv_hr' in name) or ('conv_last' in name) or ('aux' in name):\n        if 'conv_last' in name:\n            name = name.replace('conv_last', 'final_convolution')\n        if config.upsampler in ['pixelshuffle', 'pixelshuffle_aux', 'nearest+conv']:\n            if 'conv_before_upsample.0' in name:\n                name = name.replace('conv_before_upsample.0', 'conv_before_upsample')\n            if 'upsample.0' in name:\n                name = name.replace('upsample.0', 'upsample.convolution_0')\n            if 'upsample.2' in name:\n                name = name.replace('upsample.2', 'upsample.convolution_1')\n            name = 'upsample.' + name\n        elif config.upsampler == 'pixelshuffledirect':\n            name = name.replace('upsample.0.weight', 'upsample.conv.weight')\n            name = name.replace('upsample.0.bias', 'upsample.conv.bias')\n        else:\n            pass\n    else:\n        name = 'swin2sr.' + name\n    return name",
            "def rename_key(name, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if 'patch_embed.proj' in name and 'layers' not in name:\n        name = name.replace('patch_embed.proj', 'embeddings.patch_embeddings.projection')\n    if 'patch_embed.norm' in name:\n        name = name.replace('patch_embed.norm', 'embeddings.patch_embeddings.layernorm')\n    if 'layers' in name:\n        name = name.replace('layers', 'encoder.stages')\n    if 'residual_group.blocks' in name:\n        name = name.replace('residual_group.blocks', 'layers')\n    if 'attn.proj' in name:\n        name = name.replace('attn.proj', 'attention.output.dense')\n    if 'attn' in name:\n        name = name.replace('attn', 'attention.self')\n    if 'norm1' in name:\n        name = name.replace('norm1', 'layernorm_before')\n    if 'norm2' in name:\n        name = name.replace('norm2', 'layernorm_after')\n    if 'mlp.fc1' in name:\n        name = name.replace('mlp.fc1', 'intermediate.dense')\n    if 'mlp.fc2' in name:\n        name = name.replace('mlp.fc2', 'output.dense')\n    if 'q_bias' in name:\n        name = name.replace('q_bias', 'query.bias')\n    if 'k_bias' in name:\n        name = name.replace('k_bias', 'key.bias')\n    if 'v_bias' in name:\n        name = name.replace('v_bias', 'value.bias')\n    if 'cpb_mlp' in name:\n        name = name.replace('cpb_mlp', 'continuous_position_bias_mlp')\n    if 'patch_embed.proj' in name:\n        name = name.replace('patch_embed.proj', 'patch_embed.projection')\n    if name == 'norm.weight':\n        name = 'layernorm.weight'\n    if name == 'norm.bias':\n        name = 'layernorm.bias'\n    if 'conv_first' in name:\n        name = name.replace('conv_first', 'first_convolution')\n    if 'upsample' in name or 'conv_before_upsample' in name or 'conv_bicubic' in name or ('conv_up' in name) or ('conv_hr' in name) or ('conv_last' in name) or ('aux' in name):\n        if 'conv_last' in name:\n            name = name.replace('conv_last', 'final_convolution')\n        if config.upsampler in ['pixelshuffle', 'pixelshuffle_aux', 'nearest+conv']:\n            if 'conv_before_upsample.0' in name:\n                name = name.replace('conv_before_upsample.0', 'conv_before_upsample')\n            if 'upsample.0' in name:\n                name = name.replace('upsample.0', 'upsample.convolution_0')\n            if 'upsample.2' in name:\n                name = name.replace('upsample.2', 'upsample.convolution_1')\n            name = 'upsample.' + name\n        elif config.upsampler == 'pixelshuffledirect':\n            name = name.replace('upsample.0.weight', 'upsample.conv.weight')\n            name = name.replace('upsample.0.bias', 'upsample.conv.bias')\n        else:\n            pass\n    else:\n        name = 'swin2sr.' + name\n    return name",
            "def rename_key(name, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if 'patch_embed.proj' in name and 'layers' not in name:\n        name = name.replace('patch_embed.proj', 'embeddings.patch_embeddings.projection')\n    if 'patch_embed.norm' in name:\n        name = name.replace('patch_embed.norm', 'embeddings.patch_embeddings.layernorm')\n    if 'layers' in name:\n        name = name.replace('layers', 'encoder.stages')\n    if 'residual_group.blocks' in name:\n        name = name.replace('residual_group.blocks', 'layers')\n    if 'attn.proj' in name:\n        name = name.replace('attn.proj', 'attention.output.dense')\n    if 'attn' in name:\n        name = name.replace('attn', 'attention.self')\n    if 'norm1' in name:\n        name = name.replace('norm1', 'layernorm_before')\n    if 'norm2' in name:\n        name = name.replace('norm2', 'layernorm_after')\n    if 'mlp.fc1' in name:\n        name = name.replace('mlp.fc1', 'intermediate.dense')\n    if 'mlp.fc2' in name:\n        name = name.replace('mlp.fc2', 'output.dense')\n    if 'q_bias' in name:\n        name = name.replace('q_bias', 'query.bias')\n    if 'k_bias' in name:\n        name = name.replace('k_bias', 'key.bias')\n    if 'v_bias' in name:\n        name = name.replace('v_bias', 'value.bias')\n    if 'cpb_mlp' in name:\n        name = name.replace('cpb_mlp', 'continuous_position_bias_mlp')\n    if 'patch_embed.proj' in name:\n        name = name.replace('patch_embed.proj', 'patch_embed.projection')\n    if name == 'norm.weight':\n        name = 'layernorm.weight'\n    if name == 'norm.bias':\n        name = 'layernorm.bias'\n    if 'conv_first' in name:\n        name = name.replace('conv_first', 'first_convolution')\n    if 'upsample' in name or 'conv_before_upsample' in name or 'conv_bicubic' in name or ('conv_up' in name) or ('conv_hr' in name) or ('conv_last' in name) or ('aux' in name):\n        if 'conv_last' in name:\n            name = name.replace('conv_last', 'final_convolution')\n        if config.upsampler in ['pixelshuffle', 'pixelshuffle_aux', 'nearest+conv']:\n            if 'conv_before_upsample.0' in name:\n                name = name.replace('conv_before_upsample.0', 'conv_before_upsample')\n            if 'upsample.0' in name:\n                name = name.replace('upsample.0', 'upsample.convolution_0')\n            if 'upsample.2' in name:\n                name = name.replace('upsample.2', 'upsample.convolution_1')\n            name = 'upsample.' + name\n        elif config.upsampler == 'pixelshuffledirect':\n            name = name.replace('upsample.0.weight', 'upsample.conv.weight')\n            name = name.replace('upsample.0.bias', 'upsample.conv.bias')\n        else:\n            pass\n    else:\n        name = 'swin2sr.' + name\n    return name",
            "def rename_key(name, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if 'patch_embed.proj' in name and 'layers' not in name:\n        name = name.replace('patch_embed.proj', 'embeddings.patch_embeddings.projection')\n    if 'patch_embed.norm' in name:\n        name = name.replace('patch_embed.norm', 'embeddings.patch_embeddings.layernorm')\n    if 'layers' in name:\n        name = name.replace('layers', 'encoder.stages')\n    if 'residual_group.blocks' in name:\n        name = name.replace('residual_group.blocks', 'layers')\n    if 'attn.proj' in name:\n        name = name.replace('attn.proj', 'attention.output.dense')\n    if 'attn' in name:\n        name = name.replace('attn', 'attention.self')\n    if 'norm1' in name:\n        name = name.replace('norm1', 'layernorm_before')\n    if 'norm2' in name:\n        name = name.replace('norm2', 'layernorm_after')\n    if 'mlp.fc1' in name:\n        name = name.replace('mlp.fc1', 'intermediate.dense')\n    if 'mlp.fc2' in name:\n        name = name.replace('mlp.fc2', 'output.dense')\n    if 'q_bias' in name:\n        name = name.replace('q_bias', 'query.bias')\n    if 'k_bias' in name:\n        name = name.replace('k_bias', 'key.bias')\n    if 'v_bias' in name:\n        name = name.replace('v_bias', 'value.bias')\n    if 'cpb_mlp' in name:\n        name = name.replace('cpb_mlp', 'continuous_position_bias_mlp')\n    if 'patch_embed.proj' in name:\n        name = name.replace('patch_embed.proj', 'patch_embed.projection')\n    if name == 'norm.weight':\n        name = 'layernorm.weight'\n    if name == 'norm.bias':\n        name = 'layernorm.bias'\n    if 'conv_first' in name:\n        name = name.replace('conv_first', 'first_convolution')\n    if 'upsample' in name or 'conv_before_upsample' in name or 'conv_bicubic' in name or ('conv_up' in name) or ('conv_hr' in name) or ('conv_last' in name) or ('aux' in name):\n        if 'conv_last' in name:\n            name = name.replace('conv_last', 'final_convolution')\n        if config.upsampler in ['pixelshuffle', 'pixelshuffle_aux', 'nearest+conv']:\n            if 'conv_before_upsample.0' in name:\n                name = name.replace('conv_before_upsample.0', 'conv_before_upsample')\n            if 'upsample.0' in name:\n                name = name.replace('upsample.0', 'upsample.convolution_0')\n            if 'upsample.2' in name:\n                name = name.replace('upsample.2', 'upsample.convolution_1')\n            name = 'upsample.' + name\n        elif config.upsampler == 'pixelshuffledirect':\n            name = name.replace('upsample.0.weight', 'upsample.conv.weight')\n            name = name.replace('upsample.0.bias', 'upsample.conv.bias')\n        else:\n            pass\n    else:\n        name = 'swin2sr.' + name\n    return name"
        ]
    },
    {
        "func_name": "convert_state_dict",
        "original": "def convert_state_dict(orig_state_dict, config):\n    for key in orig_state_dict.copy().keys():\n        val = orig_state_dict.pop(key)\n        if 'qkv' in key:\n            key_split = key.split('.')\n            stage_num = int(key_split[1])\n            block_num = int(key_split[4])\n            dim = config.embed_dim\n            if 'weight' in key:\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.query.weight'] = val[:dim, :]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.key.weight'] = val[dim:dim * 2, :]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.value.weight'] = val[-dim:, :]\n            else:\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.query.bias'] = val[:dim]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.key.bias'] = val[dim:dim * 2]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.value.bias'] = val[-dim:]\n            pass\n        else:\n            orig_state_dict[rename_key(key, config)] = val\n    return orig_state_dict",
        "mutated": [
            "def convert_state_dict(orig_state_dict, config):\n    if False:\n        i = 10\n    for key in orig_state_dict.copy().keys():\n        val = orig_state_dict.pop(key)\n        if 'qkv' in key:\n            key_split = key.split('.')\n            stage_num = int(key_split[1])\n            block_num = int(key_split[4])\n            dim = config.embed_dim\n            if 'weight' in key:\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.query.weight'] = val[:dim, :]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.key.weight'] = val[dim:dim * 2, :]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.value.weight'] = val[-dim:, :]\n            else:\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.query.bias'] = val[:dim]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.key.bias'] = val[dim:dim * 2]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.value.bias'] = val[-dim:]\n            pass\n        else:\n            orig_state_dict[rename_key(key, config)] = val\n    return orig_state_dict",
            "def convert_state_dict(orig_state_dict, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    for key in orig_state_dict.copy().keys():\n        val = orig_state_dict.pop(key)\n        if 'qkv' in key:\n            key_split = key.split('.')\n            stage_num = int(key_split[1])\n            block_num = int(key_split[4])\n            dim = config.embed_dim\n            if 'weight' in key:\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.query.weight'] = val[:dim, :]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.key.weight'] = val[dim:dim * 2, :]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.value.weight'] = val[-dim:, :]\n            else:\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.query.bias'] = val[:dim]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.key.bias'] = val[dim:dim * 2]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.value.bias'] = val[-dim:]\n            pass\n        else:\n            orig_state_dict[rename_key(key, config)] = val\n    return orig_state_dict",
            "def convert_state_dict(orig_state_dict, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    for key in orig_state_dict.copy().keys():\n        val = orig_state_dict.pop(key)\n        if 'qkv' in key:\n            key_split = key.split('.')\n            stage_num = int(key_split[1])\n            block_num = int(key_split[4])\n            dim = config.embed_dim\n            if 'weight' in key:\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.query.weight'] = val[:dim, :]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.key.weight'] = val[dim:dim * 2, :]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.value.weight'] = val[-dim:, :]\n            else:\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.query.bias'] = val[:dim]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.key.bias'] = val[dim:dim * 2]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.value.bias'] = val[-dim:]\n            pass\n        else:\n            orig_state_dict[rename_key(key, config)] = val\n    return orig_state_dict",
            "def convert_state_dict(orig_state_dict, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    for key in orig_state_dict.copy().keys():\n        val = orig_state_dict.pop(key)\n        if 'qkv' in key:\n            key_split = key.split('.')\n            stage_num = int(key_split[1])\n            block_num = int(key_split[4])\n            dim = config.embed_dim\n            if 'weight' in key:\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.query.weight'] = val[:dim, :]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.key.weight'] = val[dim:dim * 2, :]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.value.weight'] = val[-dim:, :]\n            else:\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.query.bias'] = val[:dim]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.key.bias'] = val[dim:dim * 2]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.value.bias'] = val[-dim:]\n            pass\n        else:\n            orig_state_dict[rename_key(key, config)] = val\n    return orig_state_dict",
            "def convert_state_dict(orig_state_dict, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    for key in orig_state_dict.copy().keys():\n        val = orig_state_dict.pop(key)\n        if 'qkv' in key:\n            key_split = key.split('.')\n            stage_num = int(key_split[1])\n            block_num = int(key_split[4])\n            dim = config.embed_dim\n            if 'weight' in key:\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.query.weight'] = val[:dim, :]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.key.weight'] = val[dim:dim * 2, :]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.value.weight'] = val[-dim:, :]\n            else:\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.query.bias'] = val[:dim]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.key.bias'] = val[dim:dim * 2]\n                orig_state_dict[f'swin2sr.encoder.stages.{stage_num}.layers.{block_num}.attention.self.value.bias'] = val[-dim:]\n            pass\n        else:\n            orig_state_dict[rename_key(key, config)] = val\n    return orig_state_dict"
        ]
    },
    {
        "func_name": "convert_swin2sr_checkpoint",
        "original": "def convert_swin2sr_checkpoint(checkpoint_url, pytorch_dump_folder_path, push_to_hub):\n    config = get_config(checkpoint_url)\n    model = Swin2SRForImageSuperResolution(config)\n    model.eval()\n    state_dict = torch.hub.load_state_dict_from_url(checkpoint_url, map_location='cpu')\n    new_state_dict = convert_state_dict(state_dict, config)\n    (missing_keys, unexpected_keys) = model.load_state_dict(new_state_dict, strict=False)\n    if len(missing_keys) > 0:\n        raise ValueError('Missing keys when converting: {}'.format(missing_keys))\n    for key in unexpected_keys:\n        if not ('relative_position_index' in key or 'relative_coords_table' in key or 'self_mask' in key):\n            raise ValueError(f'Unexpected key {key} in state_dict')\n    url = 'https://github.com/mv-lab/swin2sr/blob/main/testsets/real-inputs/shanghai.jpg?raw=true'\n    image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n    processor = Swin2SRImageProcessor()\n    image_size = 126 if 'Jpeg' in checkpoint_url else 256\n    transforms = Compose([Resize((image_size, image_size)), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n    pixel_values = transforms(image).unsqueeze(0)\n    if config.num_channels == 1:\n        pixel_values = pixel_values[:, 0, :, :].unsqueeze(1)\n    outputs = model(pixel_values)\n    if 'Swin2SR_ClassicalSR_X2_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 512, 512])\n        expected_slice = torch.tensor([[-0.7087, -0.7138, -0.6721], [-0.834, -0.8095, -0.7298], [-0.9149, -0.8414, -0.794]])\n    elif 'Swin2SR_ClassicalSR_X4_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.7775, -0.8105, -0.8933], [-0.7764, -0.8356, -0.9225], [-0.7976, -0.8686, -0.9579]])\n    elif 'Swin2SR_CompressedSR_X4_48' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.8035, -0.7504, -0.7491], [-0.8538, -0.8124, -0.7782], [-0.8804, -0.8651, -0.8493]])\n    elif 'Swin2SR_Lightweight_X2_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 512, 512])\n        expected_slice = torch.tensor([[-0.7669, -0.8662, -0.8767], [-0.881, -0.9962, -0.982], [-0.934, -1.0322, -1.1149]])\n    elif 'Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.5238, -0.5557, -0.6321], [-0.6016, -0.5903, -0.6391], [-0.6244, -0.6334, -0.6889]])\n    assert outputs.reconstruction.shape == expected_shape, f'Shape of reconstruction should be {expected_shape}, but is {outputs.reconstruction.shape}'\n    assert torch.allclose(outputs.reconstruction[0, 0, :3, :3], expected_slice, atol=0.001)\n    print('Looks ok!')\n    url_to_name = {'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_ClassicalSR_X2_64.pth': 'swin2SR-classical-sr-x2-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_ClassicalSR_X4_64.pth': 'swin2SR-classical-sr-x4-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_CompressedSR_X4_48.pth': 'swin2SR-compressed-sr-x4-48', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_Lightweight_X2_64.pth': 'swin2SR-lightweight-x2-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR.pth': 'swin2SR-realworld-sr-x4-64-bsrgan-psnr'}\n    model_name = url_to_name[checkpoint_url]\n    if pytorch_dump_folder_path is not None:\n        print(f'Saving model {model_name} to {pytorch_dump_folder_path}')\n        model.save_pretrained(pytorch_dump_folder_path)\n        print(f'Saving image processor to {pytorch_dump_folder_path}')\n        processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        model.push_to_hub(f'caidas/{model_name}')\n        processor.push_to_hub(f'caidas/{model_name}')",
        "mutated": [
            "def convert_swin2sr_checkpoint(checkpoint_url, pytorch_dump_folder_path, push_to_hub):\n    if False:\n        i = 10\n    config = get_config(checkpoint_url)\n    model = Swin2SRForImageSuperResolution(config)\n    model.eval()\n    state_dict = torch.hub.load_state_dict_from_url(checkpoint_url, map_location='cpu')\n    new_state_dict = convert_state_dict(state_dict, config)\n    (missing_keys, unexpected_keys) = model.load_state_dict(new_state_dict, strict=False)\n    if len(missing_keys) > 0:\n        raise ValueError('Missing keys when converting: {}'.format(missing_keys))\n    for key in unexpected_keys:\n        if not ('relative_position_index' in key or 'relative_coords_table' in key or 'self_mask' in key):\n            raise ValueError(f'Unexpected key {key} in state_dict')\n    url = 'https://github.com/mv-lab/swin2sr/blob/main/testsets/real-inputs/shanghai.jpg?raw=true'\n    image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n    processor = Swin2SRImageProcessor()\n    image_size = 126 if 'Jpeg' in checkpoint_url else 256\n    transforms = Compose([Resize((image_size, image_size)), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n    pixel_values = transforms(image).unsqueeze(0)\n    if config.num_channels == 1:\n        pixel_values = pixel_values[:, 0, :, :].unsqueeze(1)\n    outputs = model(pixel_values)\n    if 'Swin2SR_ClassicalSR_X2_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 512, 512])\n        expected_slice = torch.tensor([[-0.7087, -0.7138, -0.6721], [-0.834, -0.8095, -0.7298], [-0.9149, -0.8414, -0.794]])\n    elif 'Swin2SR_ClassicalSR_X4_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.7775, -0.8105, -0.8933], [-0.7764, -0.8356, -0.9225], [-0.7976, -0.8686, -0.9579]])\n    elif 'Swin2SR_CompressedSR_X4_48' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.8035, -0.7504, -0.7491], [-0.8538, -0.8124, -0.7782], [-0.8804, -0.8651, -0.8493]])\n    elif 'Swin2SR_Lightweight_X2_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 512, 512])\n        expected_slice = torch.tensor([[-0.7669, -0.8662, -0.8767], [-0.881, -0.9962, -0.982], [-0.934, -1.0322, -1.1149]])\n    elif 'Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.5238, -0.5557, -0.6321], [-0.6016, -0.5903, -0.6391], [-0.6244, -0.6334, -0.6889]])\n    assert outputs.reconstruction.shape == expected_shape, f'Shape of reconstruction should be {expected_shape}, but is {outputs.reconstruction.shape}'\n    assert torch.allclose(outputs.reconstruction[0, 0, :3, :3], expected_slice, atol=0.001)\n    print('Looks ok!')\n    url_to_name = {'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_ClassicalSR_X2_64.pth': 'swin2SR-classical-sr-x2-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_ClassicalSR_X4_64.pth': 'swin2SR-classical-sr-x4-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_CompressedSR_X4_48.pth': 'swin2SR-compressed-sr-x4-48', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_Lightweight_X2_64.pth': 'swin2SR-lightweight-x2-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR.pth': 'swin2SR-realworld-sr-x4-64-bsrgan-psnr'}\n    model_name = url_to_name[checkpoint_url]\n    if pytorch_dump_folder_path is not None:\n        print(f'Saving model {model_name} to {pytorch_dump_folder_path}')\n        model.save_pretrained(pytorch_dump_folder_path)\n        print(f'Saving image processor to {pytorch_dump_folder_path}')\n        processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        model.push_to_hub(f'caidas/{model_name}')\n        processor.push_to_hub(f'caidas/{model_name}')",
            "def convert_swin2sr_checkpoint(checkpoint_url, pytorch_dump_folder_path, push_to_hub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    config = get_config(checkpoint_url)\n    model = Swin2SRForImageSuperResolution(config)\n    model.eval()\n    state_dict = torch.hub.load_state_dict_from_url(checkpoint_url, map_location='cpu')\n    new_state_dict = convert_state_dict(state_dict, config)\n    (missing_keys, unexpected_keys) = model.load_state_dict(new_state_dict, strict=False)\n    if len(missing_keys) > 0:\n        raise ValueError('Missing keys when converting: {}'.format(missing_keys))\n    for key in unexpected_keys:\n        if not ('relative_position_index' in key or 'relative_coords_table' in key or 'self_mask' in key):\n            raise ValueError(f'Unexpected key {key} in state_dict')\n    url = 'https://github.com/mv-lab/swin2sr/blob/main/testsets/real-inputs/shanghai.jpg?raw=true'\n    image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n    processor = Swin2SRImageProcessor()\n    image_size = 126 if 'Jpeg' in checkpoint_url else 256\n    transforms = Compose([Resize((image_size, image_size)), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n    pixel_values = transforms(image).unsqueeze(0)\n    if config.num_channels == 1:\n        pixel_values = pixel_values[:, 0, :, :].unsqueeze(1)\n    outputs = model(pixel_values)\n    if 'Swin2SR_ClassicalSR_X2_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 512, 512])\n        expected_slice = torch.tensor([[-0.7087, -0.7138, -0.6721], [-0.834, -0.8095, -0.7298], [-0.9149, -0.8414, -0.794]])\n    elif 'Swin2SR_ClassicalSR_X4_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.7775, -0.8105, -0.8933], [-0.7764, -0.8356, -0.9225], [-0.7976, -0.8686, -0.9579]])\n    elif 'Swin2SR_CompressedSR_X4_48' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.8035, -0.7504, -0.7491], [-0.8538, -0.8124, -0.7782], [-0.8804, -0.8651, -0.8493]])\n    elif 'Swin2SR_Lightweight_X2_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 512, 512])\n        expected_slice = torch.tensor([[-0.7669, -0.8662, -0.8767], [-0.881, -0.9962, -0.982], [-0.934, -1.0322, -1.1149]])\n    elif 'Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.5238, -0.5557, -0.6321], [-0.6016, -0.5903, -0.6391], [-0.6244, -0.6334, -0.6889]])\n    assert outputs.reconstruction.shape == expected_shape, f'Shape of reconstruction should be {expected_shape}, but is {outputs.reconstruction.shape}'\n    assert torch.allclose(outputs.reconstruction[0, 0, :3, :3], expected_slice, atol=0.001)\n    print('Looks ok!')\n    url_to_name = {'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_ClassicalSR_X2_64.pth': 'swin2SR-classical-sr-x2-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_ClassicalSR_X4_64.pth': 'swin2SR-classical-sr-x4-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_CompressedSR_X4_48.pth': 'swin2SR-compressed-sr-x4-48', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_Lightweight_X2_64.pth': 'swin2SR-lightweight-x2-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR.pth': 'swin2SR-realworld-sr-x4-64-bsrgan-psnr'}\n    model_name = url_to_name[checkpoint_url]\n    if pytorch_dump_folder_path is not None:\n        print(f'Saving model {model_name} to {pytorch_dump_folder_path}')\n        model.save_pretrained(pytorch_dump_folder_path)\n        print(f'Saving image processor to {pytorch_dump_folder_path}')\n        processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        model.push_to_hub(f'caidas/{model_name}')\n        processor.push_to_hub(f'caidas/{model_name}')",
            "def convert_swin2sr_checkpoint(checkpoint_url, pytorch_dump_folder_path, push_to_hub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    config = get_config(checkpoint_url)\n    model = Swin2SRForImageSuperResolution(config)\n    model.eval()\n    state_dict = torch.hub.load_state_dict_from_url(checkpoint_url, map_location='cpu')\n    new_state_dict = convert_state_dict(state_dict, config)\n    (missing_keys, unexpected_keys) = model.load_state_dict(new_state_dict, strict=False)\n    if len(missing_keys) > 0:\n        raise ValueError('Missing keys when converting: {}'.format(missing_keys))\n    for key in unexpected_keys:\n        if not ('relative_position_index' in key or 'relative_coords_table' in key or 'self_mask' in key):\n            raise ValueError(f'Unexpected key {key} in state_dict')\n    url = 'https://github.com/mv-lab/swin2sr/blob/main/testsets/real-inputs/shanghai.jpg?raw=true'\n    image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n    processor = Swin2SRImageProcessor()\n    image_size = 126 if 'Jpeg' in checkpoint_url else 256\n    transforms = Compose([Resize((image_size, image_size)), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n    pixel_values = transforms(image).unsqueeze(0)\n    if config.num_channels == 1:\n        pixel_values = pixel_values[:, 0, :, :].unsqueeze(1)\n    outputs = model(pixel_values)\n    if 'Swin2SR_ClassicalSR_X2_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 512, 512])\n        expected_slice = torch.tensor([[-0.7087, -0.7138, -0.6721], [-0.834, -0.8095, -0.7298], [-0.9149, -0.8414, -0.794]])\n    elif 'Swin2SR_ClassicalSR_X4_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.7775, -0.8105, -0.8933], [-0.7764, -0.8356, -0.9225], [-0.7976, -0.8686, -0.9579]])\n    elif 'Swin2SR_CompressedSR_X4_48' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.8035, -0.7504, -0.7491], [-0.8538, -0.8124, -0.7782], [-0.8804, -0.8651, -0.8493]])\n    elif 'Swin2SR_Lightweight_X2_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 512, 512])\n        expected_slice = torch.tensor([[-0.7669, -0.8662, -0.8767], [-0.881, -0.9962, -0.982], [-0.934, -1.0322, -1.1149]])\n    elif 'Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.5238, -0.5557, -0.6321], [-0.6016, -0.5903, -0.6391], [-0.6244, -0.6334, -0.6889]])\n    assert outputs.reconstruction.shape == expected_shape, f'Shape of reconstruction should be {expected_shape}, but is {outputs.reconstruction.shape}'\n    assert torch.allclose(outputs.reconstruction[0, 0, :3, :3], expected_slice, atol=0.001)\n    print('Looks ok!')\n    url_to_name = {'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_ClassicalSR_X2_64.pth': 'swin2SR-classical-sr-x2-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_ClassicalSR_X4_64.pth': 'swin2SR-classical-sr-x4-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_CompressedSR_X4_48.pth': 'swin2SR-compressed-sr-x4-48', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_Lightweight_X2_64.pth': 'swin2SR-lightweight-x2-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR.pth': 'swin2SR-realworld-sr-x4-64-bsrgan-psnr'}\n    model_name = url_to_name[checkpoint_url]\n    if pytorch_dump_folder_path is not None:\n        print(f'Saving model {model_name} to {pytorch_dump_folder_path}')\n        model.save_pretrained(pytorch_dump_folder_path)\n        print(f'Saving image processor to {pytorch_dump_folder_path}')\n        processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        model.push_to_hub(f'caidas/{model_name}')\n        processor.push_to_hub(f'caidas/{model_name}')",
            "def convert_swin2sr_checkpoint(checkpoint_url, pytorch_dump_folder_path, push_to_hub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    config = get_config(checkpoint_url)\n    model = Swin2SRForImageSuperResolution(config)\n    model.eval()\n    state_dict = torch.hub.load_state_dict_from_url(checkpoint_url, map_location='cpu')\n    new_state_dict = convert_state_dict(state_dict, config)\n    (missing_keys, unexpected_keys) = model.load_state_dict(new_state_dict, strict=False)\n    if len(missing_keys) > 0:\n        raise ValueError('Missing keys when converting: {}'.format(missing_keys))\n    for key in unexpected_keys:\n        if not ('relative_position_index' in key or 'relative_coords_table' in key or 'self_mask' in key):\n            raise ValueError(f'Unexpected key {key} in state_dict')\n    url = 'https://github.com/mv-lab/swin2sr/blob/main/testsets/real-inputs/shanghai.jpg?raw=true'\n    image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n    processor = Swin2SRImageProcessor()\n    image_size = 126 if 'Jpeg' in checkpoint_url else 256\n    transforms = Compose([Resize((image_size, image_size)), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n    pixel_values = transforms(image).unsqueeze(0)\n    if config.num_channels == 1:\n        pixel_values = pixel_values[:, 0, :, :].unsqueeze(1)\n    outputs = model(pixel_values)\n    if 'Swin2SR_ClassicalSR_X2_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 512, 512])\n        expected_slice = torch.tensor([[-0.7087, -0.7138, -0.6721], [-0.834, -0.8095, -0.7298], [-0.9149, -0.8414, -0.794]])\n    elif 'Swin2SR_ClassicalSR_X4_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.7775, -0.8105, -0.8933], [-0.7764, -0.8356, -0.9225], [-0.7976, -0.8686, -0.9579]])\n    elif 'Swin2SR_CompressedSR_X4_48' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.8035, -0.7504, -0.7491], [-0.8538, -0.8124, -0.7782], [-0.8804, -0.8651, -0.8493]])\n    elif 'Swin2SR_Lightweight_X2_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 512, 512])\n        expected_slice = torch.tensor([[-0.7669, -0.8662, -0.8767], [-0.881, -0.9962, -0.982], [-0.934, -1.0322, -1.1149]])\n    elif 'Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.5238, -0.5557, -0.6321], [-0.6016, -0.5903, -0.6391], [-0.6244, -0.6334, -0.6889]])\n    assert outputs.reconstruction.shape == expected_shape, f'Shape of reconstruction should be {expected_shape}, but is {outputs.reconstruction.shape}'\n    assert torch.allclose(outputs.reconstruction[0, 0, :3, :3], expected_slice, atol=0.001)\n    print('Looks ok!')\n    url_to_name = {'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_ClassicalSR_X2_64.pth': 'swin2SR-classical-sr-x2-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_ClassicalSR_X4_64.pth': 'swin2SR-classical-sr-x4-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_CompressedSR_X4_48.pth': 'swin2SR-compressed-sr-x4-48', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_Lightweight_X2_64.pth': 'swin2SR-lightweight-x2-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR.pth': 'swin2SR-realworld-sr-x4-64-bsrgan-psnr'}\n    model_name = url_to_name[checkpoint_url]\n    if pytorch_dump_folder_path is not None:\n        print(f'Saving model {model_name} to {pytorch_dump_folder_path}')\n        model.save_pretrained(pytorch_dump_folder_path)\n        print(f'Saving image processor to {pytorch_dump_folder_path}')\n        processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        model.push_to_hub(f'caidas/{model_name}')\n        processor.push_to_hub(f'caidas/{model_name}')",
            "def convert_swin2sr_checkpoint(checkpoint_url, pytorch_dump_folder_path, push_to_hub):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    config = get_config(checkpoint_url)\n    model = Swin2SRForImageSuperResolution(config)\n    model.eval()\n    state_dict = torch.hub.load_state_dict_from_url(checkpoint_url, map_location='cpu')\n    new_state_dict = convert_state_dict(state_dict, config)\n    (missing_keys, unexpected_keys) = model.load_state_dict(new_state_dict, strict=False)\n    if len(missing_keys) > 0:\n        raise ValueError('Missing keys when converting: {}'.format(missing_keys))\n    for key in unexpected_keys:\n        if not ('relative_position_index' in key or 'relative_coords_table' in key or 'self_mask' in key):\n            raise ValueError(f'Unexpected key {key} in state_dict')\n    url = 'https://github.com/mv-lab/swin2sr/blob/main/testsets/real-inputs/shanghai.jpg?raw=true'\n    image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n    processor = Swin2SRImageProcessor()\n    image_size = 126 if 'Jpeg' in checkpoint_url else 256\n    transforms = Compose([Resize((image_size, image_size)), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n    pixel_values = transforms(image).unsqueeze(0)\n    if config.num_channels == 1:\n        pixel_values = pixel_values[:, 0, :, :].unsqueeze(1)\n    outputs = model(pixel_values)\n    if 'Swin2SR_ClassicalSR_X2_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 512, 512])\n        expected_slice = torch.tensor([[-0.7087, -0.7138, -0.6721], [-0.834, -0.8095, -0.7298], [-0.9149, -0.8414, -0.794]])\n    elif 'Swin2SR_ClassicalSR_X4_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.7775, -0.8105, -0.8933], [-0.7764, -0.8356, -0.9225], [-0.7976, -0.8686, -0.9579]])\n    elif 'Swin2SR_CompressedSR_X4_48' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.8035, -0.7504, -0.7491], [-0.8538, -0.8124, -0.7782], [-0.8804, -0.8651, -0.8493]])\n    elif 'Swin2SR_Lightweight_X2_64' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 512, 512])\n        expected_slice = torch.tensor([[-0.7669, -0.8662, -0.8767], [-0.881, -0.9962, -0.982], [-0.934, -1.0322, -1.1149]])\n    elif 'Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR' in checkpoint_url:\n        expected_shape = torch.Size([1, 3, 1024, 1024])\n        expected_slice = torch.tensor([[-0.5238, -0.5557, -0.6321], [-0.6016, -0.5903, -0.6391], [-0.6244, -0.6334, -0.6889]])\n    assert outputs.reconstruction.shape == expected_shape, f'Shape of reconstruction should be {expected_shape}, but is {outputs.reconstruction.shape}'\n    assert torch.allclose(outputs.reconstruction[0, 0, :3, :3], expected_slice, atol=0.001)\n    print('Looks ok!')\n    url_to_name = {'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_ClassicalSR_X2_64.pth': 'swin2SR-classical-sr-x2-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_ClassicalSR_X4_64.pth': 'swin2SR-classical-sr-x4-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_CompressedSR_X4_48.pth': 'swin2SR-compressed-sr-x4-48', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_Lightweight_X2_64.pth': 'swin2SR-lightweight-x2-64', 'https://github.com/mv-lab/swin2sr/releases/download/v0.0.1/Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR.pth': 'swin2SR-realworld-sr-x4-64-bsrgan-psnr'}\n    model_name = url_to_name[checkpoint_url]\n    if pytorch_dump_folder_path is not None:\n        print(f'Saving model {model_name} to {pytorch_dump_folder_path}')\n        model.save_pretrained(pytorch_dump_folder_path)\n        print(f'Saving image processor to {pytorch_dump_folder_path}')\n        processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        model.push_to_hub(f'caidas/{model_name}')\n        processor.push_to_hub(f'caidas/{model_name}')"
        ]
    }
]