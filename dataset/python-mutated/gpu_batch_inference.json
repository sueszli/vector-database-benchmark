[
    {
        "func_name": "preprocess",
        "original": "def preprocess(image_batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n    tensor_batch = torch.as_tensor(image_batch['image'], dtype=torch.float)\n    tensor_batch = tensor_batch.permute(0, 3, 1, 2)\n    transformed_batch = transform(tensor_batch).numpy()\n    return {'image': transformed_batch}",
        "mutated": [
            "def preprocess(image_batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n    if False:\n        i = 10\n    tensor_batch = torch.as_tensor(image_batch['image'], dtype=torch.float)\n    tensor_batch = tensor_batch.permute(0, 3, 1, 2)\n    transformed_batch = transform(tensor_batch).numpy()\n    return {'image': transformed_batch}",
            "def preprocess(image_batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    tensor_batch = torch.as_tensor(image_batch['image'], dtype=torch.float)\n    tensor_batch = tensor_batch.permute(0, 3, 1, 2)\n    transformed_batch = transform(tensor_batch).numpy()\n    return {'image': transformed_batch}",
            "def preprocess(image_batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    tensor_batch = torch.as_tensor(image_batch['image'], dtype=torch.float)\n    tensor_batch = tensor_batch.permute(0, 3, 1, 2)\n    transformed_batch = transform(tensor_batch).numpy()\n    return {'image': transformed_batch}",
            "def preprocess(image_batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    tensor_batch = torch.as_tensor(image_batch['image'], dtype=torch.float)\n    tensor_batch = tensor_batch.permute(0, 3, 1, 2)\n    transformed_batch = transform(tensor_batch).numpy()\n    return {'image': transformed_batch}",
            "def preprocess(image_batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    tensor_batch = torch.as_tensor(image_batch['image'], dtype=torch.float)\n    tensor_batch = tensor_batch.permute(0, 3, 1, 2)\n    transformed_batch = transform(tensor_batch).numpy()\n    return {'image': transformed_batch}"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, model):\n    self.model = ray.get(model)\n    self.model.eval()\n    self.model.to(device)",
        "mutated": [
            "def __init__(self, model):\n    if False:\n        i = 10\n    self.model = ray.get(model)\n    self.model.eval()\n    self.model.to(device)",
            "def __init__(self, model):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.model = ray.get(model)\n    self.model.eval()\n    self.model.to(device)",
            "def __init__(self, model):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.model = ray.get(model)\n    self.model.eval()\n    self.model.to(device)",
            "def __init__(self, model):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.model = ray.get(model)\n    self.model.eval()\n    self.model.to(device)",
            "def __init__(self, model):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.model = ray.get(model)\n    self.model.eval()\n    self.model.to(device)"
        ]
    },
    {
        "func_name": "__call__",
        "original": "def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n    with torch.inference_mode():\n        output = self.model(torch.as_tensor(batch['image'], device=device))\n        return {'predictions': output.cpu().numpy()}",
        "mutated": [
            "def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n    if False:\n        i = 10\n    with torch.inference_mode():\n        output = self.model(torch.as_tensor(batch['image'], device=device))\n        return {'predictions': output.cpu().numpy()}",
            "def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with torch.inference_mode():\n        output = self.model(torch.as_tensor(batch['image'], device=device))\n        return {'predictions': output.cpu().numpy()}",
            "def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with torch.inference_mode():\n        output = self.model(torch.as_tensor(batch['image'], device=device))\n        return {'predictions': output.cpu().numpy()}",
            "def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with torch.inference_mode():\n        output = self.model(torch.as_tensor(batch['image'], device=device))\n        return {'predictions': output.cpu().numpy()}",
            "def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with torch.inference_mode():\n        output = self.model(torch.as_tensor(batch['image'], device=device))\n        return {'predictions': output.cpu().numpy()}"
        ]
    },
    {
        "func_name": "main",
        "original": "@click.command(help='Run Batch prediction on Pytorch ResNet models.')\n@click.option('--data-directory', type=str, help='Name of the S3 directory in the air-example-data-2 bucket to load data from.')\n@click.option('--data-format', type=click.Choice(['parquet', 'raw'], case_sensitive=False), help='The format of the data. Can be either parquet or raw.')\n@click.option('--smoke-test', is_flag=True, default=False)\ndef main(data_directory: str, data_format: str, smoke_test: bool):\n    data_url = f's3://anonymous@air-example-data-2/{data_directory}'\n    print(f'Running GPU batch prediction with data from {data_url}')\n    BATCH_SIZE = 1000\n    device = 'cpu' if smoke_test else 'cuda'\n    weights = ResNet50_Weights.DEFAULT\n    model = resnet50(weights=weights)\n    model_ref = ray.put(model)\n    transform = weights.transforms()\n    start_time = time.time()\n    if data_format == 'raw':\n        if smoke_test:\n            data_url += '/dog_1.jpg'\n        ds = ray.data.read_images(data_url, size=(256, 256))\n    elif data_format == 'parquet':\n        if smoke_test:\n            data_url += '/8cc8856e16c343829ef320fef4b353b1_000000.parquet'\n        ds = ray.data.read_parquet(data_url)\n\n    def preprocess(image_batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        tensor_batch = torch.as_tensor(image_batch['image'], dtype=torch.float)\n        tensor_batch = tensor_batch.permute(0, 3, 1, 2)\n        transformed_batch = transform(tensor_batch).numpy()\n        return {'image': transformed_batch}\n\n    class Predictor:\n\n        def __init__(self, model):\n            self.model = ray.get(model)\n            self.model.eval()\n            self.model.to(device)\n\n        def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n            with torch.inference_mode():\n                output = self.model(torch.as_tensor(batch['image'], device=device))\n                return {'predictions': output.cpu().numpy()}\n    start_time_without_metadata_fetching = time.time()\n    if smoke_test:\n        actor_pool_size = 4\n        num_gpus = 0\n    else:\n        actor_pool_size = int(ray.cluster_resources().get('GPU'))\n        num_gpus = 1\n    ds = ds.map_batches(preprocess)\n    ds = ds.map_batches(Predictor, batch_size=BATCH_SIZE, compute=ActorPoolStrategy(size=actor_pool_size), num_gpus=num_gpus, fn_constructor_kwargs={'model': model_ref}, max_concurrency=2)\n    total_images = 0\n    for batch in ds.iter_batches(batch_size=None, batch_format='pyarrow'):\n        total_images += len(batch)\n    end_time = time.time()\n    total_time = end_time - start_time\n    throughput = total_images / total_time\n    total_time_without_metadata_fetch = end_time - start_time_without_metadata_fetching\n    throughput_without_metadata_fetch = total_images / total_time_without_metadata_fetch\n    print('Total time (sec): ', total_time)\n    print('Throughput (img/sec): ', throughput)\n    print('Total time w/o metadata fetching (sec): ', total_time_without_metadata_fetch)\n    print('Throughput w/o metadata fetching (img/sec): ', throughput_without_metadata_fetch)\n    results = {'data_directory': data_directory, 'data_format': data_format}\n    results['perf_metrics'] = {'total_time_s': {'perf_metric_name': 'total_time_s', 'perf_metric_value': total_time, 'perf_metric_type': 'LATENCY'}, 'throughput_images_s': {'perf_metric_name': 'throughput_images_s', 'perf_metric_value': throughput, 'perf_metric_type': 'THROUGHPUT'}, 'total_time_s_w/o_metadata_fetch': {'perf_metric_name': 'total_time_s_w/o_metadata_fetch', 'perf_metric_value': total_time_without_metadata_fetch, 'perf_metric_type': 'LATENCY'}, 'throughput_images_s_w/o_metadata_fetch': {'perf_metric_name': 'throughput_images_s_w/o_metadata_fetch', 'perf_metric_value': throughput_without_metadata_fetch, 'perf_metric_type': 'THROUGHPUT'}}\n    return results",
        "mutated": [
            "@click.command(help='Run Batch prediction on Pytorch ResNet models.')\n@click.option('--data-directory', type=str, help='Name of the S3 directory in the air-example-data-2 bucket to load data from.')\n@click.option('--data-format', type=click.Choice(['parquet', 'raw'], case_sensitive=False), help='The format of the data. Can be either parquet or raw.')\n@click.option('--smoke-test', is_flag=True, default=False)\ndef main(data_directory: str, data_format: str, smoke_test: bool):\n    if False:\n        i = 10\n    data_url = f's3://anonymous@air-example-data-2/{data_directory}'\n    print(f'Running GPU batch prediction with data from {data_url}')\n    BATCH_SIZE = 1000\n    device = 'cpu' if smoke_test else 'cuda'\n    weights = ResNet50_Weights.DEFAULT\n    model = resnet50(weights=weights)\n    model_ref = ray.put(model)\n    transform = weights.transforms()\n    start_time = time.time()\n    if data_format == 'raw':\n        if smoke_test:\n            data_url += '/dog_1.jpg'\n        ds = ray.data.read_images(data_url, size=(256, 256))\n    elif data_format == 'parquet':\n        if smoke_test:\n            data_url += '/8cc8856e16c343829ef320fef4b353b1_000000.parquet'\n        ds = ray.data.read_parquet(data_url)\n\n    def preprocess(image_batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        tensor_batch = torch.as_tensor(image_batch['image'], dtype=torch.float)\n        tensor_batch = tensor_batch.permute(0, 3, 1, 2)\n        transformed_batch = transform(tensor_batch).numpy()\n        return {'image': transformed_batch}\n\n    class Predictor:\n\n        def __init__(self, model):\n            self.model = ray.get(model)\n            self.model.eval()\n            self.model.to(device)\n\n        def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n            with torch.inference_mode():\n                output = self.model(torch.as_tensor(batch['image'], device=device))\n                return {'predictions': output.cpu().numpy()}\n    start_time_without_metadata_fetching = time.time()\n    if smoke_test:\n        actor_pool_size = 4\n        num_gpus = 0\n    else:\n        actor_pool_size = int(ray.cluster_resources().get('GPU'))\n        num_gpus = 1\n    ds = ds.map_batches(preprocess)\n    ds = ds.map_batches(Predictor, batch_size=BATCH_SIZE, compute=ActorPoolStrategy(size=actor_pool_size), num_gpus=num_gpus, fn_constructor_kwargs={'model': model_ref}, max_concurrency=2)\n    total_images = 0\n    for batch in ds.iter_batches(batch_size=None, batch_format='pyarrow'):\n        total_images += len(batch)\n    end_time = time.time()\n    total_time = end_time - start_time\n    throughput = total_images / total_time\n    total_time_without_metadata_fetch = end_time - start_time_without_metadata_fetching\n    throughput_without_metadata_fetch = total_images / total_time_without_metadata_fetch\n    print('Total time (sec): ', total_time)\n    print('Throughput (img/sec): ', throughput)\n    print('Total time w/o metadata fetching (sec): ', total_time_without_metadata_fetch)\n    print('Throughput w/o metadata fetching (img/sec): ', throughput_without_metadata_fetch)\n    results = {'data_directory': data_directory, 'data_format': data_format}\n    results['perf_metrics'] = {'total_time_s': {'perf_metric_name': 'total_time_s', 'perf_metric_value': total_time, 'perf_metric_type': 'LATENCY'}, 'throughput_images_s': {'perf_metric_name': 'throughput_images_s', 'perf_metric_value': throughput, 'perf_metric_type': 'THROUGHPUT'}, 'total_time_s_w/o_metadata_fetch': {'perf_metric_name': 'total_time_s_w/o_metadata_fetch', 'perf_metric_value': total_time_without_metadata_fetch, 'perf_metric_type': 'LATENCY'}, 'throughput_images_s_w/o_metadata_fetch': {'perf_metric_name': 'throughput_images_s_w/o_metadata_fetch', 'perf_metric_value': throughput_without_metadata_fetch, 'perf_metric_type': 'THROUGHPUT'}}\n    return results",
            "@click.command(help='Run Batch prediction on Pytorch ResNet models.')\n@click.option('--data-directory', type=str, help='Name of the S3 directory in the air-example-data-2 bucket to load data from.')\n@click.option('--data-format', type=click.Choice(['parquet', 'raw'], case_sensitive=False), help='The format of the data. Can be either parquet or raw.')\n@click.option('--smoke-test', is_flag=True, default=False)\ndef main(data_directory: str, data_format: str, smoke_test: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    data_url = f's3://anonymous@air-example-data-2/{data_directory}'\n    print(f'Running GPU batch prediction with data from {data_url}')\n    BATCH_SIZE = 1000\n    device = 'cpu' if smoke_test else 'cuda'\n    weights = ResNet50_Weights.DEFAULT\n    model = resnet50(weights=weights)\n    model_ref = ray.put(model)\n    transform = weights.transforms()\n    start_time = time.time()\n    if data_format == 'raw':\n        if smoke_test:\n            data_url += '/dog_1.jpg'\n        ds = ray.data.read_images(data_url, size=(256, 256))\n    elif data_format == 'parquet':\n        if smoke_test:\n            data_url += '/8cc8856e16c343829ef320fef4b353b1_000000.parquet'\n        ds = ray.data.read_parquet(data_url)\n\n    def preprocess(image_batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        tensor_batch = torch.as_tensor(image_batch['image'], dtype=torch.float)\n        tensor_batch = tensor_batch.permute(0, 3, 1, 2)\n        transformed_batch = transform(tensor_batch).numpy()\n        return {'image': transformed_batch}\n\n    class Predictor:\n\n        def __init__(self, model):\n            self.model = ray.get(model)\n            self.model.eval()\n            self.model.to(device)\n\n        def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n            with torch.inference_mode():\n                output = self.model(torch.as_tensor(batch['image'], device=device))\n                return {'predictions': output.cpu().numpy()}\n    start_time_without_metadata_fetching = time.time()\n    if smoke_test:\n        actor_pool_size = 4\n        num_gpus = 0\n    else:\n        actor_pool_size = int(ray.cluster_resources().get('GPU'))\n        num_gpus = 1\n    ds = ds.map_batches(preprocess)\n    ds = ds.map_batches(Predictor, batch_size=BATCH_SIZE, compute=ActorPoolStrategy(size=actor_pool_size), num_gpus=num_gpus, fn_constructor_kwargs={'model': model_ref}, max_concurrency=2)\n    total_images = 0\n    for batch in ds.iter_batches(batch_size=None, batch_format='pyarrow'):\n        total_images += len(batch)\n    end_time = time.time()\n    total_time = end_time - start_time\n    throughput = total_images / total_time\n    total_time_without_metadata_fetch = end_time - start_time_without_metadata_fetching\n    throughput_without_metadata_fetch = total_images / total_time_without_metadata_fetch\n    print('Total time (sec): ', total_time)\n    print('Throughput (img/sec): ', throughput)\n    print('Total time w/o metadata fetching (sec): ', total_time_without_metadata_fetch)\n    print('Throughput w/o metadata fetching (img/sec): ', throughput_without_metadata_fetch)\n    results = {'data_directory': data_directory, 'data_format': data_format}\n    results['perf_metrics'] = {'total_time_s': {'perf_metric_name': 'total_time_s', 'perf_metric_value': total_time, 'perf_metric_type': 'LATENCY'}, 'throughput_images_s': {'perf_metric_name': 'throughput_images_s', 'perf_metric_value': throughput, 'perf_metric_type': 'THROUGHPUT'}, 'total_time_s_w/o_metadata_fetch': {'perf_metric_name': 'total_time_s_w/o_metadata_fetch', 'perf_metric_value': total_time_without_metadata_fetch, 'perf_metric_type': 'LATENCY'}, 'throughput_images_s_w/o_metadata_fetch': {'perf_metric_name': 'throughput_images_s_w/o_metadata_fetch', 'perf_metric_value': throughput_without_metadata_fetch, 'perf_metric_type': 'THROUGHPUT'}}\n    return results",
            "@click.command(help='Run Batch prediction on Pytorch ResNet models.')\n@click.option('--data-directory', type=str, help='Name of the S3 directory in the air-example-data-2 bucket to load data from.')\n@click.option('--data-format', type=click.Choice(['parquet', 'raw'], case_sensitive=False), help='The format of the data. Can be either parquet or raw.')\n@click.option('--smoke-test', is_flag=True, default=False)\ndef main(data_directory: str, data_format: str, smoke_test: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    data_url = f's3://anonymous@air-example-data-2/{data_directory}'\n    print(f'Running GPU batch prediction with data from {data_url}')\n    BATCH_SIZE = 1000\n    device = 'cpu' if smoke_test else 'cuda'\n    weights = ResNet50_Weights.DEFAULT\n    model = resnet50(weights=weights)\n    model_ref = ray.put(model)\n    transform = weights.transforms()\n    start_time = time.time()\n    if data_format == 'raw':\n        if smoke_test:\n            data_url += '/dog_1.jpg'\n        ds = ray.data.read_images(data_url, size=(256, 256))\n    elif data_format == 'parquet':\n        if smoke_test:\n            data_url += '/8cc8856e16c343829ef320fef4b353b1_000000.parquet'\n        ds = ray.data.read_parquet(data_url)\n\n    def preprocess(image_batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        tensor_batch = torch.as_tensor(image_batch['image'], dtype=torch.float)\n        tensor_batch = tensor_batch.permute(0, 3, 1, 2)\n        transformed_batch = transform(tensor_batch).numpy()\n        return {'image': transformed_batch}\n\n    class Predictor:\n\n        def __init__(self, model):\n            self.model = ray.get(model)\n            self.model.eval()\n            self.model.to(device)\n\n        def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n            with torch.inference_mode():\n                output = self.model(torch.as_tensor(batch['image'], device=device))\n                return {'predictions': output.cpu().numpy()}\n    start_time_without_metadata_fetching = time.time()\n    if smoke_test:\n        actor_pool_size = 4\n        num_gpus = 0\n    else:\n        actor_pool_size = int(ray.cluster_resources().get('GPU'))\n        num_gpus = 1\n    ds = ds.map_batches(preprocess)\n    ds = ds.map_batches(Predictor, batch_size=BATCH_SIZE, compute=ActorPoolStrategy(size=actor_pool_size), num_gpus=num_gpus, fn_constructor_kwargs={'model': model_ref}, max_concurrency=2)\n    total_images = 0\n    for batch in ds.iter_batches(batch_size=None, batch_format='pyarrow'):\n        total_images += len(batch)\n    end_time = time.time()\n    total_time = end_time - start_time\n    throughput = total_images / total_time\n    total_time_without_metadata_fetch = end_time - start_time_without_metadata_fetching\n    throughput_without_metadata_fetch = total_images / total_time_without_metadata_fetch\n    print('Total time (sec): ', total_time)\n    print('Throughput (img/sec): ', throughput)\n    print('Total time w/o metadata fetching (sec): ', total_time_without_metadata_fetch)\n    print('Throughput w/o metadata fetching (img/sec): ', throughput_without_metadata_fetch)\n    results = {'data_directory': data_directory, 'data_format': data_format}\n    results['perf_metrics'] = {'total_time_s': {'perf_metric_name': 'total_time_s', 'perf_metric_value': total_time, 'perf_metric_type': 'LATENCY'}, 'throughput_images_s': {'perf_metric_name': 'throughput_images_s', 'perf_metric_value': throughput, 'perf_metric_type': 'THROUGHPUT'}, 'total_time_s_w/o_metadata_fetch': {'perf_metric_name': 'total_time_s_w/o_metadata_fetch', 'perf_metric_value': total_time_without_metadata_fetch, 'perf_metric_type': 'LATENCY'}, 'throughput_images_s_w/o_metadata_fetch': {'perf_metric_name': 'throughput_images_s_w/o_metadata_fetch', 'perf_metric_value': throughput_without_metadata_fetch, 'perf_metric_type': 'THROUGHPUT'}}\n    return results",
            "@click.command(help='Run Batch prediction on Pytorch ResNet models.')\n@click.option('--data-directory', type=str, help='Name of the S3 directory in the air-example-data-2 bucket to load data from.')\n@click.option('--data-format', type=click.Choice(['parquet', 'raw'], case_sensitive=False), help='The format of the data. Can be either parquet or raw.')\n@click.option('--smoke-test', is_flag=True, default=False)\ndef main(data_directory: str, data_format: str, smoke_test: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    data_url = f's3://anonymous@air-example-data-2/{data_directory}'\n    print(f'Running GPU batch prediction with data from {data_url}')\n    BATCH_SIZE = 1000\n    device = 'cpu' if smoke_test else 'cuda'\n    weights = ResNet50_Weights.DEFAULT\n    model = resnet50(weights=weights)\n    model_ref = ray.put(model)\n    transform = weights.transforms()\n    start_time = time.time()\n    if data_format == 'raw':\n        if smoke_test:\n            data_url += '/dog_1.jpg'\n        ds = ray.data.read_images(data_url, size=(256, 256))\n    elif data_format == 'parquet':\n        if smoke_test:\n            data_url += '/8cc8856e16c343829ef320fef4b353b1_000000.parquet'\n        ds = ray.data.read_parquet(data_url)\n\n    def preprocess(image_batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        tensor_batch = torch.as_tensor(image_batch['image'], dtype=torch.float)\n        tensor_batch = tensor_batch.permute(0, 3, 1, 2)\n        transformed_batch = transform(tensor_batch).numpy()\n        return {'image': transformed_batch}\n\n    class Predictor:\n\n        def __init__(self, model):\n            self.model = ray.get(model)\n            self.model.eval()\n            self.model.to(device)\n\n        def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n            with torch.inference_mode():\n                output = self.model(torch.as_tensor(batch['image'], device=device))\n                return {'predictions': output.cpu().numpy()}\n    start_time_without_metadata_fetching = time.time()\n    if smoke_test:\n        actor_pool_size = 4\n        num_gpus = 0\n    else:\n        actor_pool_size = int(ray.cluster_resources().get('GPU'))\n        num_gpus = 1\n    ds = ds.map_batches(preprocess)\n    ds = ds.map_batches(Predictor, batch_size=BATCH_SIZE, compute=ActorPoolStrategy(size=actor_pool_size), num_gpus=num_gpus, fn_constructor_kwargs={'model': model_ref}, max_concurrency=2)\n    total_images = 0\n    for batch in ds.iter_batches(batch_size=None, batch_format='pyarrow'):\n        total_images += len(batch)\n    end_time = time.time()\n    total_time = end_time - start_time\n    throughput = total_images / total_time\n    total_time_without_metadata_fetch = end_time - start_time_without_metadata_fetching\n    throughput_without_metadata_fetch = total_images / total_time_without_metadata_fetch\n    print('Total time (sec): ', total_time)\n    print('Throughput (img/sec): ', throughput)\n    print('Total time w/o metadata fetching (sec): ', total_time_without_metadata_fetch)\n    print('Throughput w/o metadata fetching (img/sec): ', throughput_without_metadata_fetch)\n    results = {'data_directory': data_directory, 'data_format': data_format}\n    results['perf_metrics'] = {'total_time_s': {'perf_metric_name': 'total_time_s', 'perf_metric_value': total_time, 'perf_metric_type': 'LATENCY'}, 'throughput_images_s': {'perf_metric_name': 'throughput_images_s', 'perf_metric_value': throughput, 'perf_metric_type': 'THROUGHPUT'}, 'total_time_s_w/o_metadata_fetch': {'perf_metric_name': 'total_time_s_w/o_metadata_fetch', 'perf_metric_value': total_time_without_metadata_fetch, 'perf_metric_type': 'LATENCY'}, 'throughput_images_s_w/o_metadata_fetch': {'perf_metric_name': 'throughput_images_s_w/o_metadata_fetch', 'perf_metric_value': throughput_without_metadata_fetch, 'perf_metric_type': 'THROUGHPUT'}}\n    return results",
            "@click.command(help='Run Batch prediction on Pytorch ResNet models.')\n@click.option('--data-directory', type=str, help='Name of the S3 directory in the air-example-data-2 bucket to load data from.')\n@click.option('--data-format', type=click.Choice(['parquet', 'raw'], case_sensitive=False), help='The format of the data. Can be either parquet or raw.')\n@click.option('--smoke-test', is_flag=True, default=False)\ndef main(data_directory: str, data_format: str, smoke_test: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    data_url = f's3://anonymous@air-example-data-2/{data_directory}'\n    print(f'Running GPU batch prediction with data from {data_url}')\n    BATCH_SIZE = 1000\n    device = 'cpu' if smoke_test else 'cuda'\n    weights = ResNet50_Weights.DEFAULT\n    model = resnet50(weights=weights)\n    model_ref = ray.put(model)\n    transform = weights.transforms()\n    start_time = time.time()\n    if data_format == 'raw':\n        if smoke_test:\n            data_url += '/dog_1.jpg'\n        ds = ray.data.read_images(data_url, size=(256, 256))\n    elif data_format == 'parquet':\n        if smoke_test:\n            data_url += '/8cc8856e16c343829ef320fef4b353b1_000000.parquet'\n        ds = ray.data.read_parquet(data_url)\n\n    def preprocess(image_batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        tensor_batch = torch.as_tensor(image_batch['image'], dtype=torch.float)\n        tensor_batch = tensor_batch.permute(0, 3, 1, 2)\n        transformed_batch = transform(tensor_batch).numpy()\n        return {'image': transformed_batch}\n\n    class Predictor:\n\n        def __init__(self, model):\n            self.model = ray.get(model)\n            self.model.eval()\n            self.model.to(device)\n\n        def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n            with torch.inference_mode():\n                output = self.model(torch.as_tensor(batch['image'], device=device))\n                return {'predictions': output.cpu().numpy()}\n    start_time_without_metadata_fetching = time.time()\n    if smoke_test:\n        actor_pool_size = 4\n        num_gpus = 0\n    else:\n        actor_pool_size = int(ray.cluster_resources().get('GPU'))\n        num_gpus = 1\n    ds = ds.map_batches(preprocess)\n    ds = ds.map_batches(Predictor, batch_size=BATCH_SIZE, compute=ActorPoolStrategy(size=actor_pool_size), num_gpus=num_gpus, fn_constructor_kwargs={'model': model_ref}, max_concurrency=2)\n    total_images = 0\n    for batch in ds.iter_batches(batch_size=None, batch_format='pyarrow'):\n        total_images += len(batch)\n    end_time = time.time()\n    total_time = end_time - start_time\n    throughput = total_images / total_time\n    total_time_without_metadata_fetch = end_time - start_time_without_metadata_fetching\n    throughput_without_metadata_fetch = total_images / total_time_without_metadata_fetch\n    print('Total time (sec): ', total_time)\n    print('Throughput (img/sec): ', throughput)\n    print('Total time w/o metadata fetching (sec): ', total_time_without_metadata_fetch)\n    print('Throughput w/o metadata fetching (img/sec): ', throughput_without_metadata_fetch)\n    results = {'data_directory': data_directory, 'data_format': data_format}\n    results['perf_metrics'] = {'total_time_s': {'perf_metric_name': 'total_time_s', 'perf_metric_value': total_time, 'perf_metric_type': 'LATENCY'}, 'throughput_images_s': {'perf_metric_name': 'throughput_images_s', 'perf_metric_value': throughput, 'perf_metric_type': 'THROUGHPUT'}, 'total_time_s_w/o_metadata_fetch': {'perf_metric_name': 'total_time_s_w/o_metadata_fetch', 'perf_metric_value': total_time_without_metadata_fetch, 'perf_metric_type': 'LATENCY'}, 'throughput_images_s_w/o_metadata_fetch': {'perf_metric_name': 'throughput_images_s_w/o_metadata_fetch', 'perf_metric_value': throughput_without_metadata_fetch, 'perf_metric_type': 'THROUGHPUT'}}\n    return results"
        ]
    }
]