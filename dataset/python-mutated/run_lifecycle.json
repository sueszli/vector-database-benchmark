[
    {
        "func_name": "_get_run",
        "original": "def _get_run(instance: DagsterInstance, run_id: str) -> DagsterRun:\n    run = instance.get_run_by_id(run_id)\n    if not run:\n        raise DagsterRunNotFoundError(invalid_run_id=run_id)\n    return cast(DagsterRun, run)",
        "mutated": [
            "def _get_run(instance: DagsterInstance, run_id: str) -> DagsterRun:\n    if False:\n        i = 10\n    run = instance.get_run_by_id(run_id)\n    if not run:\n        raise DagsterRunNotFoundError(invalid_run_id=run_id)\n    return cast(DagsterRun, run)",
            "def _get_run(instance: DagsterInstance, run_id: str) -> DagsterRun:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    run = instance.get_run_by_id(run_id)\n    if not run:\n        raise DagsterRunNotFoundError(invalid_run_id=run_id)\n    return cast(DagsterRun, run)",
            "def _get_run(instance: DagsterInstance, run_id: str) -> DagsterRun:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    run = instance.get_run_by_id(run_id)\n    if not run:\n        raise DagsterRunNotFoundError(invalid_run_id=run_id)\n    return cast(DagsterRun, run)",
            "def _get_run(instance: DagsterInstance, run_id: str) -> DagsterRun:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    run = instance.get_run_by_id(run_id)\n    if not run:\n        raise DagsterRunNotFoundError(invalid_run_id=run_id)\n    return cast(DagsterRun, run)",
            "def _get_run(instance: DagsterInstance, run_id: str) -> DagsterRun:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    run = instance.get_run_by_id(run_id)\n    if not run:\n        raise DagsterRunNotFoundError(invalid_run_id=run_id)\n    return cast(DagsterRun, run)"
        ]
    },
    {
        "func_name": "compute_step_keys_to_execute",
        "original": "def compute_step_keys_to_execute(graphene_info: 'ResolveInfo', execution_params: ExecutionParams) -> Tuple[Optional[Sequence[str]], Optional[KnownExecutionState]]:\n    check.inst_param(execution_params, 'execution_params', ExecutionParams)\n    instance = graphene_info.context.instance\n    if not execution_params.step_keys and is_resume_retry(execution_params):\n        parent_run_id = check.not_none(execution_params.execution_metadata.parent_run_id)\n        parent_run = _get_run(instance, parent_run_id)\n        return KnownExecutionState.build_resume_retry_reexecution(instance, parent_run)\n    else:\n        known_state = None\n        if execution_params.execution_metadata.parent_run_id and execution_params.step_keys:\n            parent_run = _get_run(instance, execution_params.execution_metadata.parent_run_id)\n            known_state = KnownExecutionState.build_for_reexecution(instance, parent_run).update_for_step_selection(execution_params.step_keys)\n        return (execution_params.step_keys, known_state)",
        "mutated": [
            "def compute_step_keys_to_execute(graphene_info: 'ResolveInfo', execution_params: ExecutionParams) -> Tuple[Optional[Sequence[str]], Optional[KnownExecutionState]]:\n    if False:\n        i = 10\n    check.inst_param(execution_params, 'execution_params', ExecutionParams)\n    instance = graphene_info.context.instance\n    if not execution_params.step_keys and is_resume_retry(execution_params):\n        parent_run_id = check.not_none(execution_params.execution_metadata.parent_run_id)\n        parent_run = _get_run(instance, parent_run_id)\n        return KnownExecutionState.build_resume_retry_reexecution(instance, parent_run)\n    else:\n        known_state = None\n        if execution_params.execution_metadata.parent_run_id and execution_params.step_keys:\n            parent_run = _get_run(instance, execution_params.execution_metadata.parent_run_id)\n            known_state = KnownExecutionState.build_for_reexecution(instance, parent_run).update_for_step_selection(execution_params.step_keys)\n        return (execution_params.step_keys, known_state)",
            "def compute_step_keys_to_execute(graphene_info: 'ResolveInfo', execution_params: ExecutionParams) -> Tuple[Optional[Sequence[str]], Optional[KnownExecutionState]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    check.inst_param(execution_params, 'execution_params', ExecutionParams)\n    instance = graphene_info.context.instance\n    if not execution_params.step_keys and is_resume_retry(execution_params):\n        parent_run_id = check.not_none(execution_params.execution_metadata.parent_run_id)\n        parent_run = _get_run(instance, parent_run_id)\n        return KnownExecutionState.build_resume_retry_reexecution(instance, parent_run)\n    else:\n        known_state = None\n        if execution_params.execution_metadata.parent_run_id and execution_params.step_keys:\n            parent_run = _get_run(instance, execution_params.execution_metadata.parent_run_id)\n            known_state = KnownExecutionState.build_for_reexecution(instance, parent_run).update_for_step_selection(execution_params.step_keys)\n        return (execution_params.step_keys, known_state)",
            "def compute_step_keys_to_execute(graphene_info: 'ResolveInfo', execution_params: ExecutionParams) -> Tuple[Optional[Sequence[str]], Optional[KnownExecutionState]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    check.inst_param(execution_params, 'execution_params', ExecutionParams)\n    instance = graphene_info.context.instance\n    if not execution_params.step_keys and is_resume_retry(execution_params):\n        parent_run_id = check.not_none(execution_params.execution_metadata.parent_run_id)\n        parent_run = _get_run(instance, parent_run_id)\n        return KnownExecutionState.build_resume_retry_reexecution(instance, parent_run)\n    else:\n        known_state = None\n        if execution_params.execution_metadata.parent_run_id and execution_params.step_keys:\n            parent_run = _get_run(instance, execution_params.execution_metadata.parent_run_id)\n            known_state = KnownExecutionState.build_for_reexecution(instance, parent_run).update_for_step_selection(execution_params.step_keys)\n        return (execution_params.step_keys, known_state)",
            "def compute_step_keys_to_execute(graphene_info: 'ResolveInfo', execution_params: ExecutionParams) -> Tuple[Optional[Sequence[str]], Optional[KnownExecutionState]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    check.inst_param(execution_params, 'execution_params', ExecutionParams)\n    instance = graphene_info.context.instance\n    if not execution_params.step_keys and is_resume_retry(execution_params):\n        parent_run_id = check.not_none(execution_params.execution_metadata.parent_run_id)\n        parent_run = _get_run(instance, parent_run_id)\n        return KnownExecutionState.build_resume_retry_reexecution(instance, parent_run)\n    else:\n        known_state = None\n        if execution_params.execution_metadata.parent_run_id and execution_params.step_keys:\n            parent_run = _get_run(instance, execution_params.execution_metadata.parent_run_id)\n            known_state = KnownExecutionState.build_for_reexecution(instance, parent_run).update_for_step_selection(execution_params.step_keys)\n        return (execution_params.step_keys, known_state)",
            "def compute_step_keys_to_execute(graphene_info: 'ResolveInfo', execution_params: ExecutionParams) -> Tuple[Optional[Sequence[str]], Optional[KnownExecutionState]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    check.inst_param(execution_params, 'execution_params', ExecutionParams)\n    instance = graphene_info.context.instance\n    if not execution_params.step_keys and is_resume_retry(execution_params):\n        parent_run_id = check.not_none(execution_params.execution_metadata.parent_run_id)\n        parent_run = _get_run(instance, parent_run_id)\n        return KnownExecutionState.build_resume_retry_reexecution(instance, parent_run)\n    else:\n        known_state = None\n        if execution_params.execution_metadata.parent_run_id and execution_params.step_keys:\n            parent_run = _get_run(instance, execution_params.execution_metadata.parent_run_id)\n            known_state = KnownExecutionState.build_for_reexecution(instance, parent_run).update_for_step_selection(execution_params.step_keys)\n        return (execution_params.step_keys, known_state)"
        ]
    },
    {
        "func_name": "is_resume_retry",
        "original": "def is_resume_retry(execution_params: ExecutionParams) -> bool:\n    check.inst_param(execution_params, 'execution_params', ExecutionParams)\n    return execution_params.execution_metadata.tags.get(RESUME_RETRY_TAG) == 'true'",
        "mutated": [
            "def is_resume_retry(execution_params: ExecutionParams) -> bool:\n    if False:\n        i = 10\n    check.inst_param(execution_params, 'execution_params', ExecutionParams)\n    return execution_params.execution_metadata.tags.get(RESUME_RETRY_TAG) == 'true'",
            "def is_resume_retry(execution_params: ExecutionParams) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    check.inst_param(execution_params, 'execution_params', ExecutionParams)\n    return execution_params.execution_metadata.tags.get(RESUME_RETRY_TAG) == 'true'",
            "def is_resume_retry(execution_params: ExecutionParams) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    check.inst_param(execution_params, 'execution_params', ExecutionParams)\n    return execution_params.execution_metadata.tags.get(RESUME_RETRY_TAG) == 'true'",
            "def is_resume_retry(execution_params: ExecutionParams) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    check.inst_param(execution_params, 'execution_params', ExecutionParams)\n    return execution_params.execution_metadata.tags.get(RESUME_RETRY_TAG) == 'true'",
            "def is_resume_retry(execution_params: ExecutionParams) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    check.inst_param(execution_params, 'execution_params', ExecutionParams)\n    return execution_params.execution_metadata.tags.get(RESUME_RETRY_TAG) == 'true'"
        ]
    },
    {
        "func_name": "create_valid_pipeline_run",
        "original": "def create_valid_pipeline_run(graphene_info: 'ResolveInfo', external_pipeline: ExternalJob, execution_params: ExecutionParams) -> DagsterRun:\n    ensure_valid_config(external_pipeline, execution_params.run_config)\n    (step_keys_to_execute, known_state) = compute_step_keys_to_execute(graphene_info, execution_params)\n    external_execution_plan = get_external_execution_plan_or_raise(graphene_info=graphene_info, external_pipeline=external_pipeline, run_config=execution_params.run_config, step_keys_to_execute=step_keys_to_execute, known_state=known_state)\n    tags = merge_dicts(external_pipeline.tags, execution_params.execution_metadata.tags)\n    dagster_run = graphene_info.context.instance.create_run(job_snapshot=external_pipeline.job_snapshot, execution_plan_snapshot=external_execution_plan.execution_plan_snapshot, parent_job_snapshot=external_pipeline.parent_job_snapshot, job_name=execution_params.selector.job_name, run_id=execution_params.execution_metadata.run_id if execution_params.execution_metadata.run_id else make_new_run_id(), asset_selection=frozenset(execution_params.selector.asset_selection) if execution_params.selector.asset_selection else None, asset_check_selection=frozenset(execution_params.selector.asset_check_selection) if execution_params.selector.asset_check_selection is not None else None, op_selection=execution_params.selector.op_selection, resolved_op_selection=frozenset(execution_params.selector.op_selection) if execution_params.selector.op_selection else None, run_config=execution_params.run_config, step_keys_to_execute=step_keys_to_execute, tags=tags, root_run_id=execution_params.execution_metadata.root_run_id, parent_run_id=execution_params.execution_metadata.parent_run_id, status=DagsterRunStatus.NOT_STARTED, external_job_origin=external_pipeline.get_external_origin(), job_code_origin=external_pipeline.get_python_origin())\n    return dagster_run",
        "mutated": [
            "def create_valid_pipeline_run(graphene_info: 'ResolveInfo', external_pipeline: ExternalJob, execution_params: ExecutionParams) -> DagsterRun:\n    if False:\n        i = 10\n    ensure_valid_config(external_pipeline, execution_params.run_config)\n    (step_keys_to_execute, known_state) = compute_step_keys_to_execute(graphene_info, execution_params)\n    external_execution_plan = get_external_execution_plan_or_raise(graphene_info=graphene_info, external_pipeline=external_pipeline, run_config=execution_params.run_config, step_keys_to_execute=step_keys_to_execute, known_state=known_state)\n    tags = merge_dicts(external_pipeline.tags, execution_params.execution_metadata.tags)\n    dagster_run = graphene_info.context.instance.create_run(job_snapshot=external_pipeline.job_snapshot, execution_plan_snapshot=external_execution_plan.execution_plan_snapshot, parent_job_snapshot=external_pipeline.parent_job_snapshot, job_name=execution_params.selector.job_name, run_id=execution_params.execution_metadata.run_id if execution_params.execution_metadata.run_id else make_new_run_id(), asset_selection=frozenset(execution_params.selector.asset_selection) if execution_params.selector.asset_selection else None, asset_check_selection=frozenset(execution_params.selector.asset_check_selection) if execution_params.selector.asset_check_selection is not None else None, op_selection=execution_params.selector.op_selection, resolved_op_selection=frozenset(execution_params.selector.op_selection) if execution_params.selector.op_selection else None, run_config=execution_params.run_config, step_keys_to_execute=step_keys_to_execute, tags=tags, root_run_id=execution_params.execution_metadata.root_run_id, parent_run_id=execution_params.execution_metadata.parent_run_id, status=DagsterRunStatus.NOT_STARTED, external_job_origin=external_pipeline.get_external_origin(), job_code_origin=external_pipeline.get_python_origin())\n    return dagster_run",
            "def create_valid_pipeline_run(graphene_info: 'ResolveInfo', external_pipeline: ExternalJob, execution_params: ExecutionParams) -> DagsterRun:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    ensure_valid_config(external_pipeline, execution_params.run_config)\n    (step_keys_to_execute, known_state) = compute_step_keys_to_execute(graphene_info, execution_params)\n    external_execution_plan = get_external_execution_plan_or_raise(graphene_info=graphene_info, external_pipeline=external_pipeline, run_config=execution_params.run_config, step_keys_to_execute=step_keys_to_execute, known_state=known_state)\n    tags = merge_dicts(external_pipeline.tags, execution_params.execution_metadata.tags)\n    dagster_run = graphene_info.context.instance.create_run(job_snapshot=external_pipeline.job_snapshot, execution_plan_snapshot=external_execution_plan.execution_plan_snapshot, parent_job_snapshot=external_pipeline.parent_job_snapshot, job_name=execution_params.selector.job_name, run_id=execution_params.execution_metadata.run_id if execution_params.execution_metadata.run_id else make_new_run_id(), asset_selection=frozenset(execution_params.selector.asset_selection) if execution_params.selector.asset_selection else None, asset_check_selection=frozenset(execution_params.selector.asset_check_selection) if execution_params.selector.asset_check_selection is not None else None, op_selection=execution_params.selector.op_selection, resolved_op_selection=frozenset(execution_params.selector.op_selection) if execution_params.selector.op_selection else None, run_config=execution_params.run_config, step_keys_to_execute=step_keys_to_execute, tags=tags, root_run_id=execution_params.execution_metadata.root_run_id, parent_run_id=execution_params.execution_metadata.parent_run_id, status=DagsterRunStatus.NOT_STARTED, external_job_origin=external_pipeline.get_external_origin(), job_code_origin=external_pipeline.get_python_origin())\n    return dagster_run",
            "def create_valid_pipeline_run(graphene_info: 'ResolveInfo', external_pipeline: ExternalJob, execution_params: ExecutionParams) -> DagsterRun:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    ensure_valid_config(external_pipeline, execution_params.run_config)\n    (step_keys_to_execute, known_state) = compute_step_keys_to_execute(graphene_info, execution_params)\n    external_execution_plan = get_external_execution_plan_or_raise(graphene_info=graphene_info, external_pipeline=external_pipeline, run_config=execution_params.run_config, step_keys_to_execute=step_keys_to_execute, known_state=known_state)\n    tags = merge_dicts(external_pipeline.tags, execution_params.execution_metadata.tags)\n    dagster_run = graphene_info.context.instance.create_run(job_snapshot=external_pipeline.job_snapshot, execution_plan_snapshot=external_execution_plan.execution_plan_snapshot, parent_job_snapshot=external_pipeline.parent_job_snapshot, job_name=execution_params.selector.job_name, run_id=execution_params.execution_metadata.run_id if execution_params.execution_metadata.run_id else make_new_run_id(), asset_selection=frozenset(execution_params.selector.asset_selection) if execution_params.selector.asset_selection else None, asset_check_selection=frozenset(execution_params.selector.asset_check_selection) if execution_params.selector.asset_check_selection is not None else None, op_selection=execution_params.selector.op_selection, resolved_op_selection=frozenset(execution_params.selector.op_selection) if execution_params.selector.op_selection else None, run_config=execution_params.run_config, step_keys_to_execute=step_keys_to_execute, tags=tags, root_run_id=execution_params.execution_metadata.root_run_id, parent_run_id=execution_params.execution_metadata.parent_run_id, status=DagsterRunStatus.NOT_STARTED, external_job_origin=external_pipeline.get_external_origin(), job_code_origin=external_pipeline.get_python_origin())\n    return dagster_run",
            "def create_valid_pipeline_run(graphene_info: 'ResolveInfo', external_pipeline: ExternalJob, execution_params: ExecutionParams) -> DagsterRun:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    ensure_valid_config(external_pipeline, execution_params.run_config)\n    (step_keys_to_execute, known_state) = compute_step_keys_to_execute(graphene_info, execution_params)\n    external_execution_plan = get_external_execution_plan_or_raise(graphene_info=graphene_info, external_pipeline=external_pipeline, run_config=execution_params.run_config, step_keys_to_execute=step_keys_to_execute, known_state=known_state)\n    tags = merge_dicts(external_pipeline.tags, execution_params.execution_metadata.tags)\n    dagster_run = graphene_info.context.instance.create_run(job_snapshot=external_pipeline.job_snapshot, execution_plan_snapshot=external_execution_plan.execution_plan_snapshot, parent_job_snapshot=external_pipeline.parent_job_snapshot, job_name=execution_params.selector.job_name, run_id=execution_params.execution_metadata.run_id if execution_params.execution_metadata.run_id else make_new_run_id(), asset_selection=frozenset(execution_params.selector.asset_selection) if execution_params.selector.asset_selection else None, asset_check_selection=frozenset(execution_params.selector.asset_check_selection) if execution_params.selector.asset_check_selection is not None else None, op_selection=execution_params.selector.op_selection, resolved_op_selection=frozenset(execution_params.selector.op_selection) if execution_params.selector.op_selection else None, run_config=execution_params.run_config, step_keys_to_execute=step_keys_to_execute, tags=tags, root_run_id=execution_params.execution_metadata.root_run_id, parent_run_id=execution_params.execution_metadata.parent_run_id, status=DagsterRunStatus.NOT_STARTED, external_job_origin=external_pipeline.get_external_origin(), job_code_origin=external_pipeline.get_python_origin())\n    return dagster_run",
            "def create_valid_pipeline_run(graphene_info: 'ResolveInfo', external_pipeline: ExternalJob, execution_params: ExecutionParams) -> DagsterRun:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    ensure_valid_config(external_pipeline, execution_params.run_config)\n    (step_keys_to_execute, known_state) = compute_step_keys_to_execute(graphene_info, execution_params)\n    external_execution_plan = get_external_execution_plan_or_raise(graphene_info=graphene_info, external_pipeline=external_pipeline, run_config=execution_params.run_config, step_keys_to_execute=step_keys_to_execute, known_state=known_state)\n    tags = merge_dicts(external_pipeline.tags, execution_params.execution_metadata.tags)\n    dagster_run = graphene_info.context.instance.create_run(job_snapshot=external_pipeline.job_snapshot, execution_plan_snapshot=external_execution_plan.execution_plan_snapshot, parent_job_snapshot=external_pipeline.parent_job_snapshot, job_name=execution_params.selector.job_name, run_id=execution_params.execution_metadata.run_id if execution_params.execution_metadata.run_id else make_new_run_id(), asset_selection=frozenset(execution_params.selector.asset_selection) if execution_params.selector.asset_selection else None, asset_check_selection=frozenset(execution_params.selector.asset_check_selection) if execution_params.selector.asset_check_selection is not None else None, op_selection=execution_params.selector.op_selection, resolved_op_selection=frozenset(execution_params.selector.op_selection) if execution_params.selector.op_selection else None, run_config=execution_params.run_config, step_keys_to_execute=step_keys_to_execute, tags=tags, root_run_id=execution_params.execution_metadata.root_run_id, parent_run_id=execution_params.execution_metadata.parent_run_id, status=DagsterRunStatus.NOT_STARTED, external_job_origin=external_pipeline.get_external_origin(), job_code_origin=external_pipeline.get_python_origin())\n    return dagster_run"
        ]
    }
]