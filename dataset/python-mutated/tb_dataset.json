[
    {
        "func_name": "load_ptb_dataset",
        "original": "def load_ptb_dataset(path='data'):\n    \"\"\"Load Penn TreeBank (PTB) dataset.\n\n    It is used in many LANGUAGE MODELING papers,\n    including \"Empirical Evaluation and Combination of Advanced Language\n    Modeling Techniques\", \"Recurrent Neural Network Regularization\".\n    It consists of 929k training words, 73k validation words, and 82k test\n    words. It has 10k words in its vocabulary.\n\n    Parameters\n    ----------\n    path : str\n        The path that the data is downloaded to, defaults is ``data/ptb/``.\n\n    Returns\n    --------\n    train_data, valid_data, test_data : list of int\n        The training, validating and testing data in integer format.\n    vocab_size : int\n        The vocabulary size.\n\n    Examples\n    --------\n    >>> train_data, valid_data, test_data, vocab_size = tl.files.load_ptb_dataset()\n\n    References\n    ---------------\n    - ``tensorflow.models.rnn.ptb import reader``\n    - `Manual download <http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz>`__\n\n    Notes\n    ------\n    - If you want to get the raw data, see the source code.\n\n    \"\"\"\n    path = os.path.join(path, 'ptb')\n    logging.info('Load or Download Penn TreeBank (PTB) dataset > {}'.format(path))\n    filename = 'simple-examples.tgz'\n    url = 'http://www.fit.vutbr.cz/~imikolov/rnnlm/'\n    maybe_download_and_extract(filename, path, url, extract=True)\n    data_path = os.path.join(path, 'simple-examples', 'data')\n    train_path = os.path.join(data_path, 'ptb.train.txt')\n    valid_path = os.path.join(data_path, 'ptb.valid.txt')\n    test_path = os.path.join(data_path, 'ptb.test.txt')\n    word_to_id = nlp.build_vocab(nlp.read_words(train_path))\n    train_data = nlp.words_to_word_ids(nlp.read_words(train_path), word_to_id)\n    valid_data = nlp.words_to_word_ids(nlp.read_words(valid_path), word_to_id)\n    test_data = nlp.words_to_word_ids(nlp.read_words(test_path), word_to_id)\n    vocab_size = len(word_to_id)\n    return (train_data, valid_data, test_data, vocab_size)",
        "mutated": [
            "def load_ptb_dataset(path='data'):\n    if False:\n        i = 10\n    'Load Penn TreeBank (PTB) dataset.\\n\\n    It is used in many LANGUAGE MODELING papers,\\n    including \"Empirical Evaluation and Combination of Advanced Language\\n    Modeling Techniques\", \"Recurrent Neural Network Regularization\".\\n    It consists of 929k training words, 73k validation words, and 82k test\\n    words. It has 10k words in its vocabulary.\\n\\n    Parameters\\n    ----------\\n    path : str\\n        The path that the data is downloaded to, defaults is ``data/ptb/``.\\n\\n    Returns\\n    --------\\n    train_data, valid_data, test_data : list of int\\n        The training, validating and testing data in integer format.\\n    vocab_size : int\\n        The vocabulary size.\\n\\n    Examples\\n    --------\\n    >>> train_data, valid_data, test_data, vocab_size = tl.files.load_ptb_dataset()\\n\\n    References\\n    ---------------\\n    - ``tensorflow.models.rnn.ptb import reader``\\n    - `Manual download <http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz>`__\\n\\n    Notes\\n    ------\\n    - If you want to get the raw data, see the source code.\\n\\n    '\n    path = os.path.join(path, 'ptb')\n    logging.info('Load or Download Penn TreeBank (PTB) dataset > {}'.format(path))\n    filename = 'simple-examples.tgz'\n    url = 'http://www.fit.vutbr.cz/~imikolov/rnnlm/'\n    maybe_download_and_extract(filename, path, url, extract=True)\n    data_path = os.path.join(path, 'simple-examples', 'data')\n    train_path = os.path.join(data_path, 'ptb.train.txt')\n    valid_path = os.path.join(data_path, 'ptb.valid.txt')\n    test_path = os.path.join(data_path, 'ptb.test.txt')\n    word_to_id = nlp.build_vocab(nlp.read_words(train_path))\n    train_data = nlp.words_to_word_ids(nlp.read_words(train_path), word_to_id)\n    valid_data = nlp.words_to_word_ids(nlp.read_words(valid_path), word_to_id)\n    test_data = nlp.words_to_word_ids(nlp.read_words(test_path), word_to_id)\n    vocab_size = len(word_to_id)\n    return (train_data, valid_data, test_data, vocab_size)",
            "def load_ptb_dataset(path='data'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Load Penn TreeBank (PTB) dataset.\\n\\n    It is used in many LANGUAGE MODELING papers,\\n    including \"Empirical Evaluation and Combination of Advanced Language\\n    Modeling Techniques\", \"Recurrent Neural Network Regularization\".\\n    It consists of 929k training words, 73k validation words, and 82k test\\n    words. It has 10k words in its vocabulary.\\n\\n    Parameters\\n    ----------\\n    path : str\\n        The path that the data is downloaded to, defaults is ``data/ptb/``.\\n\\n    Returns\\n    --------\\n    train_data, valid_data, test_data : list of int\\n        The training, validating and testing data in integer format.\\n    vocab_size : int\\n        The vocabulary size.\\n\\n    Examples\\n    --------\\n    >>> train_data, valid_data, test_data, vocab_size = tl.files.load_ptb_dataset()\\n\\n    References\\n    ---------------\\n    - ``tensorflow.models.rnn.ptb import reader``\\n    - `Manual download <http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz>`__\\n\\n    Notes\\n    ------\\n    - If you want to get the raw data, see the source code.\\n\\n    '\n    path = os.path.join(path, 'ptb')\n    logging.info('Load or Download Penn TreeBank (PTB) dataset > {}'.format(path))\n    filename = 'simple-examples.tgz'\n    url = 'http://www.fit.vutbr.cz/~imikolov/rnnlm/'\n    maybe_download_and_extract(filename, path, url, extract=True)\n    data_path = os.path.join(path, 'simple-examples', 'data')\n    train_path = os.path.join(data_path, 'ptb.train.txt')\n    valid_path = os.path.join(data_path, 'ptb.valid.txt')\n    test_path = os.path.join(data_path, 'ptb.test.txt')\n    word_to_id = nlp.build_vocab(nlp.read_words(train_path))\n    train_data = nlp.words_to_word_ids(nlp.read_words(train_path), word_to_id)\n    valid_data = nlp.words_to_word_ids(nlp.read_words(valid_path), word_to_id)\n    test_data = nlp.words_to_word_ids(nlp.read_words(test_path), word_to_id)\n    vocab_size = len(word_to_id)\n    return (train_data, valid_data, test_data, vocab_size)",
            "def load_ptb_dataset(path='data'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Load Penn TreeBank (PTB) dataset.\\n\\n    It is used in many LANGUAGE MODELING papers,\\n    including \"Empirical Evaluation and Combination of Advanced Language\\n    Modeling Techniques\", \"Recurrent Neural Network Regularization\".\\n    It consists of 929k training words, 73k validation words, and 82k test\\n    words. It has 10k words in its vocabulary.\\n\\n    Parameters\\n    ----------\\n    path : str\\n        The path that the data is downloaded to, defaults is ``data/ptb/``.\\n\\n    Returns\\n    --------\\n    train_data, valid_data, test_data : list of int\\n        The training, validating and testing data in integer format.\\n    vocab_size : int\\n        The vocabulary size.\\n\\n    Examples\\n    --------\\n    >>> train_data, valid_data, test_data, vocab_size = tl.files.load_ptb_dataset()\\n\\n    References\\n    ---------------\\n    - ``tensorflow.models.rnn.ptb import reader``\\n    - `Manual download <http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz>`__\\n\\n    Notes\\n    ------\\n    - If you want to get the raw data, see the source code.\\n\\n    '\n    path = os.path.join(path, 'ptb')\n    logging.info('Load or Download Penn TreeBank (PTB) dataset > {}'.format(path))\n    filename = 'simple-examples.tgz'\n    url = 'http://www.fit.vutbr.cz/~imikolov/rnnlm/'\n    maybe_download_and_extract(filename, path, url, extract=True)\n    data_path = os.path.join(path, 'simple-examples', 'data')\n    train_path = os.path.join(data_path, 'ptb.train.txt')\n    valid_path = os.path.join(data_path, 'ptb.valid.txt')\n    test_path = os.path.join(data_path, 'ptb.test.txt')\n    word_to_id = nlp.build_vocab(nlp.read_words(train_path))\n    train_data = nlp.words_to_word_ids(nlp.read_words(train_path), word_to_id)\n    valid_data = nlp.words_to_word_ids(nlp.read_words(valid_path), word_to_id)\n    test_data = nlp.words_to_word_ids(nlp.read_words(test_path), word_to_id)\n    vocab_size = len(word_to_id)\n    return (train_data, valid_data, test_data, vocab_size)",
            "def load_ptb_dataset(path='data'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Load Penn TreeBank (PTB) dataset.\\n\\n    It is used in many LANGUAGE MODELING papers,\\n    including \"Empirical Evaluation and Combination of Advanced Language\\n    Modeling Techniques\", \"Recurrent Neural Network Regularization\".\\n    It consists of 929k training words, 73k validation words, and 82k test\\n    words. It has 10k words in its vocabulary.\\n\\n    Parameters\\n    ----------\\n    path : str\\n        The path that the data is downloaded to, defaults is ``data/ptb/``.\\n\\n    Returns\\n    --------\\n    train_data, valid_data, test_data : list of int\\n        The training, validating and testing data in integer format.\\n    vocab_size : int\\n        The vocabulary size.\\n\\n    Examples\\n    --------\\n    >>> train_data, valid_data, test_data, vocab_size = tl.files.load_ptb_dataset()\\n\\n    References\\n    ---------------\\n    - ``tensorflow.models.rnn.ptb import reader``\\n    - `Manual download <http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz>`__\\n\\n    Notes\\n    ------\\n    - If you want to get the raw data, see the source code.\\n\\n    '\n    path = os.path.join(path, 'ptb')\n    logging.info('Load or Download Penn TreeBank (PTB) dataset > {}'.format(path))\n    filename = 'simple-examples.tgz'\n    url = 'http://www.fit.vutbr.cz/~imikolov/rnnlm/'\n    maybe_download_and_extract(filename, path, url, extract=True)\n    data_path = os.path.join(path, 'simple-examples', 'data')\n    train_path = os.path.join(data_path, 'ptb.train.txt')\n    valid_path = os.path.join(data_path, 'ptb.valid.txt')\n    test_path = os.path.join(data_path, 'ptb.test.txt')\n    word_to_id = nlp.build_vocab(nlp.read_words(train_path))\n    train_data = nlp.words_to_word_ids(nlp.read_words(train_path), word_to_id)\n    valid_data = nlp.words_to_word_ids(nlp.read_words(valid_path), word_to_id)\n    test_data = nlp.words_to_word_ids(nlp.read_words(test_path), word_to_id)\n    vocab_size = len(word_to_id)\n    return (train_data, valid_data, test_data, vocab_size)",
            "def load_ptb_dataset(path='data'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Load Penn TreeBank (PTB) dataset.\\n\\n    It is used in many LANGUAGE MODELING papers,\\n    including \"Empirical Evaluation and Combination of Advanced Language\\n    Modeling Techniques\", \"Recurrent Neural Network Regularization\".\\n    It consists of 929k training words, 73k validation words, and 82k test\\n    words. It has 10k words in its vocabulary.\\n\\n    Parameters\\n    ----------\\n    path : str\\n        The path that the data is downloaded to, defaults is ``data/ptb/``.\\n\\n    Returns\\n    --------\\n    train_data, valid_data, test_data : list of int\\n        The training, validating and testing data in integer format.\\n    vocab_size : int\\n        The vocabulary size.\\n\\n    Examples\\n    --------\\n    >>> train_data, valid_data, test_data, vocab_size = tl.files.load_ptb_dataset()\\n\\n    References\\n    ---------------\\n    - ``tensorflow.models.rnn.ptb import reader``\\n    - `Manual download <http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz>`__\\n\\n    Notes\\n    ------\\n    - If you want to get the raw data, see the source code.\\n\\n    '\n    path = os.path.join(path, 'ptb')\n    logging.info('Load or Download Penn TreeBank (PTB) dataset > {}'.format(path))\n    filename = 'simple-examples.tgz'\n    url = 'http://www.fit.vutbr.cz/~imikolov/rnnlm/'\n    maybe_download_and_extract(filename, path, url, extract=True)\n    data_path = os.path.join(path, 'simple-examples', 'data')\n    train_path = os.path.join(data_path, 'ptb.train.txt')\n    valid_path = os.path.join(data_path, 'ptb.valid.txt')\n    test_path = os.path.join(data_path, 'ptb.test.txt')\n    word_to_id = nlp.build_vocab(nlp.read_words(train_path))\n    train_data = nlp.words_to_word_ids(nlp.read_words(train_path), word_to_id)\n    valid_data = nlp.words_to_word_ids(nlp.read_words(valid_path), word_to_id)\n    test_data = nlp.words_to_word_ids(nlp.read_words(test_path), word_to_id)\n    vocab_size = len(word_to_id)\n    return (train_data, valid_data, test_data, vocab_size)"
        ]
    }
]