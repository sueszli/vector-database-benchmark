[
    {
        "func_name": "to_feather",
        "original": "@doc(storage_options=_shared_docs['storage_options'])\ndef to_feather(df: DataFrame, path: FilePath | WriteBuffer[bytes], storage_options: StorageOptions | None=None, **kwargs: Any) -> None:\n    \"\"\"\n    Write a DataFrame to the binary Feather format.\n\n    Parameters\n    ----------\n    df : DataFrame\n    path : str, path object, or file-like object\n    {storage_options}\n\n        .. versionadded:: 1.2.0\n\n    **kwargs :\n        Additional keywords passed to `pyarrow.feather.write_feather`.\n\n    \"\"\"\n    import_optional_dependency('pyarrow')\n    from pyarrow import feather\n    if not isinstance(df, DataFrame):\n        raise ValueError('feather only support IO with DataFrames')\n    with get_handle(path, 'wb', storage_options=storage_options, is_text=False) as handles:\n        feather.write_feather(df, handles.handle, **kwargs)",
        "mutated": [
            "@doc(storage_options=_shared_docs['storage_options'])\ndef to_feather(df: DataFrame, path: FilePath | WriteBuffer[bytes], storage_options: StorageOptions | None=None, **kwargs: Any) -> None:\n    if False:\n        i = 10\n    '\\n    Write a DataFrame to the binary Feather format.\\n\\n    Parameters\\n    ----------\\n    df : DataFrame\\n    path : str, path object, or file-like object\\n    {storage_options}\\n\\n        .. versionadded:: 1.2.0\\n\\n    **kwargs :\\n        Additional keywords passed to `pyarrow.feather.write_feather`.\\n\\n    '\n    import_optional_dependency('pyarrow')\n    from pyarrow import feather\n    if not isinstance(df, DataFrame):\n        raise ValueError('feather only support IO with DataFrames')\n    with get_handle(path, 'wb', storage_options=storage_options, is_text=False) as handles:\n        feather.write_feather(df, handles.handle, **kwargs)",
            "@doc(storage_options=_shared_docs['storage_options'])\ndef to_feather(df: DataFrame, path: FilePath | WriteBuffer[bytes], storage_options: StorageOptions | None=None, **kwargs: Any) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Write a DataFrame to the binary Feather format.\\n\\n    Parameters\\n    ----------\\n    df : DataFrame\\n    path : str, path object, or file-like object\\n    {storage_options}\\n\\n        .. versionadded:: 1.2.0\\n\\n    **kwargs :\\n        Additional keywords passed to `pyarrow.feather.write_feather`.\\n\\n    '\n    import_optional_dependency('pyarrow')\n    from pyarrow import feather\n    if not isinstance(df, DataFrame):\n        raise ValueError('feather only support IO with DataFrames')\n    with get_handle(path, 'wb', storage_options=storage_options, is_text=False) as handles:\n        feather.write_feather(df, handles.handle, **kwargs)",
            "@doc(storage_options=_shared_docs['storage_options'])\ndef to_feather(df: DataFrame, path: FilePath | WriteBuffer[bytes], storage_options: StorageOptions | None=None, **kwargs: Any) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Write a DataFrame to the binary Feather format.\\n\\n    Parameters\\n    ----------\\n    df : DataFrame\\n    path : str, path object, or file-like object\\n    {storage_options}\\n\\n        .. versionadded:: 1.2.0\\n\\n    **kwargs :\\n        Additional keywords passed to `pyarrow.feather.write_feather`.\\n\\n    '\n    import_optional_dependency('pyarrow')\n    from pyarrow import feather\n    if not isinstance(df, DataFrame):\n        raise ValueError('feather only support IO with DataFrames')\n    with get_handle(path, 'wb', storage_options=storage_options, is_text=False) as handles:\n        feather.write_feather(df, handles.handle, **kwargs)",
            "@doc(storage_options=_shared_docs['storage_options'])\ndef to_feather(df: DataFrame, path: FilePath | WriteBuffer[bytes], storage_options: StorageOptions | None=None, **kwargs: Any) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Write a DataFrame to the binary Feather format.\\n\\n    Parameters\\n    ----------\\n    df : DataFrame\\n    path : str, path object, or file-like object\\n    {storage_options}\\n\\n        .. versionadded:: 1.2.0\\n\\n    **kwargs :\\n        Additional keywords passed to `pyarrow.feather.write_feather`.\\n\\n    '\n    import_optional_dependency('pyarrow')\n    from pyarrow import feather\n    if not isinstance(df, DataFrame):\n        raise ValueError('feather only support IO with DataFrames')\n    with get_handle(path, 'wb', storage_options=storage_options, is_text=False) as handles:\n        feather.write_feather(df, handles.handle, **kwargs)",
            "@doc(storage_options=_shared_docs['storage_options'])\ndef to_feather(df: DataFrame, path: FilePath | WriteBuffer[bytes], storage_options: StorageOptions | None=None, **kwargs: Any) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Write a DataFrame to the binary Feather format.\\n\\n    Parameters\\n    ----------\\n    df : DataFrame\\n    path : str, path object, or file-like object\\n    {storage_options}\\n\\n        .. versionadded:: 1.2.0\\n\\n    **kwargs :\\n        Additional keywords passed to `pyarrow.feather.write_feather`.\\n\\n    '\n    import_optional_dependency('pyarrow')\n    from pyarrow import feather\n    if not isinstance(df, DataFrame):\n        raise ValueError('feather only support IO with DataFrames')\n    with get_handle(path, 'wb', storage_options=storage_options, is_text=False) as handles:\n        feather.write_feather(df, handles.handle, **kwargs)"
        ]
    },
    {
        "func_name": "read_feather",
        "original": "@doc(storage_options=_shared_docs['storage_options'])\ndef read_feather(path: FilePath | ReadBuffer[bytes], columns: Sequence[Hashable] | None=None, use_threads: bool=True, storage_options: StorageOptions | None=None, dtype_backend: DtypeBackend | lib.NoDefault=lib.no_default) -> DataFrame:\n    \"\"\"\n    Load a feather-format object from the file path.\n\n    Parameters\n    ----------\n    path : str, path object, or file-like object\n        String, path object (implementing ``os.PathLike[str]``), or file-like\n        object implementing a binary ``read()`` function. The string could be a URL.\n        Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is\n        expected. A local file could be: ``file://localhost/path/to/table.feather``.\n    columns : sequence, default None\n        If not provided, all columns are read.\n    use_threads : bool, default True\n        Whether to parallelize reading using multiple threads.\n    {storage_options}\n\n        .. versionadded:: 1.2.0\n\n    dtype_backend : {{'numpy_nullable', 'pyarrow'}}, default 'numpy_nullable'\n        Back-end data type applied to the resultant :class:`DataFrame`\n        (still experimental). Behaviour is as follows:\n\n        * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n          (default).\n        * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n          DataFrame.\n\n        .. versionadded:: 2.0\n\n    Returns\n    -------\n    type of object stored in file\n\n    Examples\n    --------\n    >>> df = pd.read_feather(\"path/to/file.feather\")  # doctest: +SKIP\n    \"\"\"\n    import_optional_dependency('pyarrow')\n    from pyarrow import feather\n    import pandas.core.arrays.arrow.extension_types\n    check_dtype_backend(dtype_backend)\n    with get_handle(path, 'rb', storage_options=storage_options, is_text=False) as handles:\n        if dtype_backend is lib.no_default and (not using_pyarrow_string_dtype()):\n            return feather.read_feather(handles.handle, columns=columns, use_threads=bool(use_threads))\n        pa_table = feather.read_table(handles.handle, columns=columns, use_threads=bool(use_threads))\n        if dtype_backend == 'numpy_nullable':\n            from pandas.io._util import _arrow_dtype_mapping\n            return pa_table.to_pandas(types_mapper=_arrow_dtype_mapping().get)\n        elif dtype_backend == 'pyarrow':\n            return pa_table.to_pandas(types_mapper=pd.ArrowDtype)\n        elif using_pyarrow_string_dtype():\n            return pa_table.to_pandas(types_mapper=arrow_string_types_mapper())\n        else:\n            raise NotImplementedError",
        "mutated": [
            "@doc(storage_options=_shared_docs['storage_options'])\ndef read_feather(path: FilePath | ReadBuffer[bytes], columns: Sequence[Hashable] | None=None, use_threads: bool=True, storage_options: StorageOptions | None=None, dtype_backend: DtypeBackend | lib.NoDefault=lib.no_default) -> DataFrame:\n    if False:\n        i = 10\n    '\\n    Load a feather-format object from the file path.\\n\\n    Parameters\\n    ----------\\n    path : str, path object, or file-like object\\n        String, path object (implementing ``os.PathLike[str]``), or file-like\\n        object implementing a binary ``read()`` function. The string could be a URL.\\n        Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is\\n        expected. A local file could be: ``file://localhost/path/to/table.feather``.\\n    columns : sequence, default None\\n        If not provided, all columns are read.\\n    use_threads : bool, default True\\n        Whether to parallelize reading using multiple threads.\\n    {storage_options}\\n\\n        .. versionadded:: 1.2.0\\n\\n    dtype_backend : {{\\'numpy_nullable\\', \\'pyarrow\\'}}, default \\'numpy_nullable\\'\\n        Back-end data type applied to the resultant :class:`DataFrame`\\n        (still experimental). Behaviour is as follows:\\n\\n        * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\\n          (default).\\n        * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\\n          DataFrame.\\n\\n        .. versionadded:: 2.0\\n\\n    Returns\\n    -------\\n    type of object stored in file\\n\\n    Examples\\n    --------\\n    >>> df = pd.read_feather(\"path/to/file.feather\")  # doctest: +SKIP\\n    '\n    import_optional_dependency('pyarrow')\n    from pyarrow import feather\n    import pandas.core.arrays.arrow.extension_types\n    check_dtype_backend(dtype_backend)\n    with get_handle(path, 'rb', storage_options=storage_options, is_text=False) as handles:\n        if dtype_backend is lib.no_default and (not using_pyarrow_string_dtype()):\n            return feather.read_feather(handles.handle, columns=columns, use_threads=bool(use_threads))\n        pa_table = feather.read_table(handles.handle, columns=columns, use_threads=bool(use_threads))\n        if dtype_backend == 'numpy_nullable':\n            from pandas.io._util import _arrow_dtype_mapping\n            return pa_table.to_pandas(types_mapper=_arrow_dtype_mapping().get)\n        elif dtype_backend == 'pyarrow':\n            return pa_table.to_pandas(types_mapper=pd.ArrowDtype)\n        elif using_pyarrow_string_dtype():\n            return pa_table.to_pandas(types_mapper=arrow_string_types_mapper())\n        else:\n            raise NotImplementedError",
            "@doc(storage_options=_shared_docs['storage_options'])\ndef read_feather(path: FilePath | ReadBuffer[bytes], columns: Sequence[Hashable] | None=None, use_threads: bool=True, storage_options: StorageOptions | None=None, dtype_backend: DtypeBackend | lib.NoDefault=lib.no_default) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Load a feather-format object from the file path.\\n\\n    Parameters\\n    ----------\\n    path : str, path object, or file-like object\\n        String, path object (implementing ``os.PathLike[str]``), or file-like\\n        object implementing a binary ``read()`` function. The string could be a URL.\\n        Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is\\n        expected. A local file could be: ``file://localhost/path/to/table.feather``.\\n    columns : sequence, default None\\n        If not provided, all columns are read.\\n    use_threads : bool, default True\\n        Whether to parallelize reading using multiple threads.\\n    {storage_options}\\n\\n        .. versionadded:: 1.2.0\\n\\n    dtype_backend : {{\\'numpy_nullable\\', \\'pyarrow\\'}}, default \\'numpy_nullable\\'\\n        Back-end data type applied to the resultant :class:`DataFrame`\\n        (still experimental). Behaviour is as follows:\\n\\n        * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\\n          (default).\\n        * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\\n          DataFrame.\\n\\n        .. versionadded:: 2.0\\n\\n    Returns\\n    -------\\n    type of object stored in file\\n\\n    Examples\\n    --------\\n    >>> df = pd.read_feather(\"path/to/file.feather\")  # doctest: +SKIP\\n    '\n    import_optional_dependency('pyarrow')\n    from pyarrow import feather\n    import pandas.core.arrays.arrow.extension_types\n    check_dtype_backend(dtype_backend)\n    with get_handle(path, 'rb', storage_options=storage_options, is_text=False) as handles:\n        if dtype_backend is lib.no_default and (not using_pyarrow_string_dtype()):\n            return feather.read_feather(handles.handle, columns=columns, use_threads=bool(use_threads))\n        pa_table = feather.read_table(handles.handle, columns=columns, use_threads=bool(use_threads))\n        if dtype_backend == 'numpy_nullable':\n            from pandas.io._util import _arrow_dtype_mapping\n            return pa_table.to_pandas(types_mapper=_arrow_dtype_mapping().get)\n        elif dtype_backend == 'pyarrow':\n            return pa_table.to_pandas(types_mapper=pd.ArrowDtype)\n        elif using_pyarrow_string_dtype():\n            return pa_table.to_pandas(types_mapper=arrow_string_types_mapper())\n        else:\n            raise NotImplementedError",
            "@doc(storage_options=_shared_docs['storage_options'])\ndef read_feather(path: FilePath | ReadBuffer[bytes], columns: Sequence[Hashable] | None=None, use_threads: bool=True, storage_options: StorageOptions | None=None, dtype_backend: DtypeBackend | lib.NoDefault=lib.no_default) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Load a feather-format object from the file path.\\n\\n    Parameters\\n    ----------\\n    path : str, path object, or file-like object\\n        String, path object (implementing ``os.PathLike[str]``), or file-like\\n        object implementing a binary ``read()`` function. The string could be a URL.\\n        Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is\\n        expected. A local file could be: ``file://localhost/path/to/table.feather``.\\n    columns : sequence, default None\\n        If not provided, all columns are read.\\n    use_threads : bool, default True\\n        Whether to parallelize reading using multiple threads.\\n    {storage_options}\\n\\n        .. versionadded:: 1.2.0\\n\\n    dtype_backend : {{\\'numpy_nullable\\', \\'pyarrow\\'}}, default \\'numpy_nullable\\'\\n        Back-end data type applied to the resultant :class:`DataFrame`\\n        (still experimental). Behaviour is as follows:\\n\\n        * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\\n          (default).\\n        * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\\n          DataFrame.\\n\\n        .. versionadded:: 2.0\\n\\n    Returns\\n    -------\\n    type of object stored in file\\n\\n    Examples\\n    --------\\n    >>> df = pd.read_feather(\"path/to/file.feather\")  # doctest: +SKIP\\n    '\n    import_optional_dependency('pyarrow')\n    from pyarrow import feather\n    import pandas.core.arrays.arrow.extension_types\n    check_dtype_backend(dtype_backend)\n    with get_handle(path, 'rb', storage_options=storage_options, is_text=False) as handles:\n        if dtype_backend is lib.no_default and (not using_pyarrow_string_dtype()):\n            return feather.read_feather(handles.handle, columns=columns, use_threads=bool(use_threads))\n        pa_table = feather.read_table(handles.handle, columns=columns, use_threads=bool(use_threads))\n        if dtype_backend == 'numpy_nullable':\n            from pandas.io._util import _arrow_dtype_mapping\n            return pa_table.to_pandas(types_mapper=_arrow_dtype_mapping().get)\n        elif dtype_backend == 'pyarrow':\n            return pa_table.to_pandas(types_mapper=pd.ArrowDtype)\n        elif using_pyarrow_string_dtype():\n            return pa_table.to_pandas(types_mapper=arrow_string_types_mapper())\n        else:\n            raise NotImplementedError",
            "@doc(storage_options=_shared_docs['storage_options'])\ndef read_feather(path: FilePath | ReadBuffer[bytes], columns: Sequence[Hashable] | None=None, use_threads: bool=True, storage_options: StorageOptions | None=None, dtype_backend: DtypeBackend | lib.NoDefault=lib.no_default) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Load a feather-format object from the file path.\\n\\n    Parameters\\n    ----------\\n    path : str, path object, or file-like object\\n        String, path object (implementing ``os.PathLike[str]``), or file-like\\n        object implementing a binary ``read()`` function. The string could be a URL.\\n        Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is\\n        expected. A local file could be: ``file://localhost/path/to/table.feather``.\\n    columns : sequence, default None\\n        If not provided, all columns are read.\\n    use_threads : bool, default True\\n        Whether to parallelize reading using multiple threads.\\n    {storage_options}\\n\\n        .. versionadded:: 1.2.0\\n\\n    dtype_backend : {{\\'numpy_nullable\\', \\'pyarrow\\'}}, default \\'numpy_nullable\\'\\n        Back-end data type applied to the resultant :class:`DataFrame`\\n        (still experimental). Behaviour is as follows:\\n\\n        * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\\n          (default).\\n        * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\\n          DataFrame.\\n\\n        .. versionadded:: 2.0\\n\\n    Returns\\n    -------\\n    type of object stored in file\\n\\n    Examples\\n    --------\\n    >>> df = pd.read_feather(\"path/to/file.feather\")  # doctest: +SKIP\\n    '\n    import_optional_dependency('pyarrow')\n    from pyarrow import feather\n    import pandas.core.arrays.arrow.extension_types\n    check_dtype_backend(dtype_backend)\n    with get_handle(path, 'rb', storage_options=storage_options, is_text=False) as handles:\n        if dtype_backend is lib.no_default and (not using_pyarrow_string_dtype()):\n            return feather.read_feather(handles.handle, columns=columns, use_threads=bool(use_threads))\n        pa_table = feather.read_table(handles.handle, columns=columns, use_threads=bool(use_threads))\n        if dtype_backend == 'numpy_nullable':\n            from pandas.io._util import _arrow_dtype_mapping\n            return pa_table.to_pandas(types_mapper=_arrow_dtype_mapping().get)\n        elif dtype_backend == 'pyarrow':\n            return pa_table.to_pandas(types_mapper=pd.ArrowDtype)\n        elif using_pyarrow_string_dtype():\n            return pa_table.to_pandas(types_mapper=arrow_string_types_mapper())\n        else:\n            raise NotImplementedError",
            "@doc(storage_options=_shared_docs['storage_options'])\ndef read_feather(path: FilePath | ReadBuffer[bytes], columns: Sequence[Hashable] | None=None, use_threads: bool=True, storage_options: StorageOptions | None=None, dtype_backend: DtypeBackend | lib.NoDefault=lib.no_default) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Load a feather-format object from the file path.\\n\\n    Parameters\\n    ----------\\n    path : str, path object, or file-like object\\n        String, path object (implementing ``os.PathLike[str]``), or file-like\\n        object implementing a binary ``read()`` function. The string could be a URL.\\n        Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is\\n        expected. A local file could be: ``file://localhost/path/to/table.feather``.\\n    columns : sequence, default None\\n        If not provided, all columns are read.\\n    use_threads : bool, default True\\n        Whether to parallelize reading using multiple threads.\\n    {storage_options}\\n\\n        .. versionadded:: 1.2.0\\n\\n    dtype_backend : {{\\'numpy_nullable\\', \\'pyarrow\\'}}, default \\'numpy_nullable\\'\\n        Back-end data type applied to the resultant :class:`DataFrame`\\n        (still experimental). Behaviour is as follows:\\n\\n        * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\\n          (default).\\n        * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\\n          DataFrame.\\n\\n        .. versionadded:: 2.0\\n\\n    Returns\\n    -------\\n    type of object stored in file\\n\\n    Examples\\n    --------\\n    >>> df = pd.read_feather(\"path/to/file.feather\")  # doctest: +SKIP\\n    '\n    import_optional_dependency('pyarrow')\n    from pyarrow import feather\n    import pandas.core.arrays.arrow.extension_types\n    check_dtype_backend(dtype_backend)\n    with get_handle(path, 'rb', storage_options=storage_options, is_text=False) as handles:\n        if dtype_backend is lib.no_default and (not using_pyarrow_string_dtype()):\n            return feather.read_feather(handles.handle, columns=columns, use_threads=bool(use_threads))\n        pa_table = feather.read_table(handles.handle, columns=columns, use_threads=bool(use_threads))\n        if dtype_backend == 'numpy_nullable':\n            from pandas.io._util import _arrow_dtype_mapping\n            return pa_table.to_pandas(types_mapper=_arrow_dtype_mapping().get)\n        elif dtype_backend == 'pyarrow':\n            return pa_table.to_pandas(types_mapper=pd.ArrowDtype)\n        elif using_pyarrow_string_dtype():\n            return pa_table.to_pandas(types_mapper=arrow_string_types_mapper())\n        else:\n            raise NotImplementedError"
        ]
    }
]