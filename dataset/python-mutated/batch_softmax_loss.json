[
    {
        "func_name": "__init__",
        "original": "def __init__(self, model, input_record, name='batch_softmax_loss', label_smoothing_matrix=None, label_prob=False, scale=1.0, average_by_batch_size=False, **kwargs):\n    super().__init__(model, name, input_record, **kwargs)\n    assert schema.is_schema_subset(schema.Struct(('label', schema.Scalar()), ('prediction', schema.Scalar())), input_record)\n    self.label_prob = label_prob\n    self.scale = scale\n    self.average_by_batch_size = average_by_batch_size\n    self.label_smoothing_matrix = label_smoothing_matrix\n    if self.label_smoothing_matrix is not None:\n        self.initialize_label_smoothing_constants()\n    self.output_schema = schema.Struct(('softmax', schema.Scalar(input_record.prediction.field_type(), self.get_next_blob_reference('softmax'))), ('loss', schema.Scalar(np.float32, self.get_next_blob_reference('loss'))))",
        "mutated": [
            "def __init__(self, model, input_record, name='batch_softmax_loss', label_smoothing_matrix=None, label_prob=False, scale=1.0, average_by_batch_size=False, **kwargs):\n    if False:\n        i = 10\n    super().__init__(model, name, input_record, **kwargs)\n    assert schema.is_schema_subset(schema.Struct(('label', schema.Scalar()), ('prediction', schema.Scalar())), input_record)\n    self.label_prob = label_prob\n    self.scale = scale\n    self.average_by_batch_size = average_by_batch_size\n    self.label_smoothing_matrix = label_smoothing_matrix\n    if self.label_smoothing_matrix is not None:\n        self.initialize_label_smoothing_constants()\n    self.output_schema = schema.Struct(('softmax', schema.Scalar(input_record.prediction.field_type(), self.get_next_blob_reference('softmax'))), ('loss', schema.Scalar(np.float32, self.get_next_blob_reference('loss'))))",
            "def __init__(self, model, input_record, name='batch_softmax_loss', label_smoothing_matrix=None, label_prob=False, scale=1.0, average_by_batch_size=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super().__init__(model, name, input_record, **kwargs)\n    assert schema.is_schema_subset(schema.Struct(('label', schema.Scalar()), ('prediction', schema.Scalar())), input_record)\n    self.label_prob = label_prob\n    self.scale = scale\n    self.average_by_batch_size = average_by_batch_size\n    self.label_smoothing_matrix = label_smoothing_matrix\n    if self.label_smoothing_matrix is not None:\n        self.initialize_label_smoothing_constants()\n    self.output_schema = schema.Struct(('softmax', schema.Scalar(input_record.prediction.field_type(), self.get_next_blob_reference('softmax'))), ('loss', schema.Scalar(np.float32, self.get_next_blob_reference('loss'))))",
            "def __init__(self, model, input_record, name='batch_softmax_loss', label_smoothing_matrix=None, label_prob=False, scale=1.0, average_by_batch_size=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super().__init__(model, name, input_record, **kwargs)\n    assert schema.is_schema_subset(schema.Struct(('label', schema.Scalar()), ('prediction', schema.Scalar())), input_record)\n    self.label_prob = label_prob\n    self.scale = scale\n    self.average_by_batch_size = average_by_batch_size\n    self.label_smoothing_matrix = label_smoothing_matrix\n    if self.label_smoothing_matrix is not None:\n        self.initialize_label_smoothing_constants()\n    self.output_schema = schema.Struct(('softmax', schema.Scalar(input_record.prediction.field_type(), self.get_next_blob_reference('softmax'))), ('loss', schema.Scalar(np.float32, self.get_next_blob_reference('loss'))))",
            "def __init__(self, model, input_record, name='batch_softmax_loss', label_smoothing_matrix=None, label_prob=False, scale=1.0, average_by_batch_size=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super().__init__(model, name, input_record, **kwargs)\n    assert schema.is_schema_subset(schema.Struct(('label', schema.Scalar()), ('prediction', schema.Scalar())), input_record)\n    self.label_prob = label_prob\n    self.scale = scale\n    self.average_by_batch_size = average_by_batch_size\n    self.label_smoothing_matrix = label_smoothing_matrix\n    if self.label_smoothing_matrix is not None:\n        self.initialize_label_smoothing_constants()\n    self.output_schema = schema.Struct(('softmax', schema.Scalar(input_record.prediction.field_type(), self.get_next_blob_reference('softmax'))), ('loss', schema.Scalar(np.float32, self.get_next_blob_reference('loss'))))",
            "def __init__(self, model, input_record, name='batch_softmax_loss', label_smoothing_matrix=None, label_prob=False, scale=1.0, average_by_batch_size=False, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super().__init__(model, name, input_record, **kwargs)\n    assert schema.is_schema_subset(schema.Struct(('label', schema.Scalar()), ('prediction', schema.Scalar())), input_record)\n    self.label_prob = label_prob\n    self.scale = scale\n    self.average_by_batch_size = average_by_batch_size\n    self.label_smoothing_matrix = label_smoothing_matrix\n    if self.label_smoothing_matrix is not None:\n        self.initialize_label_smoothing_constants()\n    self.output_schema = schema.Struct(('softmax', schema.Scalar(input_record.prediction.field_type(), self.get_next_blob_reference('softmax'))), ('loss', schema.Scalar(np.float32, self.get_next_blob_reference('loss'))))"
        ]
    },
    {
        "func_name": "initialize_label_smoothing_constants",
        "original": "def initialize_label_smoothing_constants(self):\n    assert self.label_smoothing_matrix is not None\n    self.label_smoothing_matrix = np.array(self.label_smoothing_matrix).astype(np.float32)\n    assert len(self.label_smoothing_matrix.shape) == 2\n    label_dim = self.label_smoothing_matrix.shape[0]\n    assert label_dim == self.label_smoothing_matrix.shape[1]\n    self.label_smoothing_matrix = self.model.add_global_constant('%s_label_smoothing_matrix' % self.name, array=self.label_smoothing_matrix, dtype=np.dtype(np.float32))\n    self.label_dim = self.model.add_global_constant('%s_label_dim' % self.name, array=label_dim, dtype=np.dtype(np.int64))\n    self.label_prob = True",
        "mutated": [
            "def initialize_label_smoothing_constants(self):\n    if False:\n        i = 10\n    assert self.label_smoothing_matrix is not None\n    self.label_smoothing_matrix = np.array(self.label_smoothing_matrix).astype(np.float32)\n    assert len(self.label_smoothing_matrix.shape) == 2\n    label_dim = self.label_smoothing_matrix.shape[0]\n    assert label_dim == self.label_smoothing_matrix.shape[1]\n    self.label_smoothing_matrix = self.model.add_global_constant('%s_label_smoothing_matrix' % self.name, array=self.label_smoothing_matrix, dtype=np.dtype(np.float32))\n    self.label_dim = self.model.add_global_constant('%s_label_dim' % self.name, array=label_dim, dtype=np.dtype(np.int64))\n    self.label_prob = True",
            "def initialize_label_smoothing_constants(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    assert self.label_smoothing_matrix is not None\n    self.label_smoothing_matrix = np.array(self.label_smoothing_matrix).astype(np.float32)\n    assert len(self.label_smoothing_matrix.shape) == 2\n    label_dim = self.label_smoothing_matrix.shape[0]\n    assert label_dim == self.label_smoothing_matrix.shape[1]\n    self.label_smoothing_matrix = self.model.add_global_constant('%s_label_smoothing_matrix' % self.name, array=self.label_smoothing_matrix, dtype=np.dtype(np.float32))\n    self.label_dim = self.model.add_global_constant('%s_label_dim' % self.name, array=label_dim, dtype=np.dtype(np.int64))\n    self.label_prob = True",
            "def initialize_label_smoothing_constants(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    assert self.label_smoothing_matrix is not None\n    self.label_smoothing_matrix = np.array(self.label_smoothing_matrix).astype(np.float32)\n    assert len(self.label_smoothing_matrix.shape) == 2\n    label_dim = self.label_smoothing_matrix.shape[0]\n    assert label_dim == self.label_smoothing_matrix.shape[1]\n    self.label_smoothing_matrix = self.model.add_global_constant('%s_label_smoothing_matrix' % self.name, array=self.label_smoothing_matrix, dtype=np.dtype(np.float32))\n    self.label_dim = self.model.add_global_constant('%s_label_dim' % self.name, array=label_dim, dtype=np.dtype(np.int64))\n    self.label_prob = True",
            "def initialize_label_smoothing_constants(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    assert self.label_smoothing_matrix is not None\n    self.label_smoothing_matrix = np.array(self.label_smoothing_matrix).astype(np.float32)\n    assert len(self.label_smoothing_matrix.shape) == 2\n    label_dim = self.label_smoothing_matrix.shape[0]\n    assert label_dim == self.label_smoothing_matrix.shape[1]\n    self.label_smoothing_matrix = self.model.add_global_constant('%s_label_smoothing_matrix' % self.name, array=self.label_smoothing_matrix, dtype=np.dtype(np.float32))\n    self.label_dim = self.model.add_global_constant('%s_label_dim' % self.name, array=label_dim, dtype=np.dtype(np.int64))\n    self.label_prob = True",
            "def initialize_label_smoothing_constants(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    assert self.label_smoothing_matrix is not None\n    self.label_smoothing_matrix = np.array(self.label_smoothing_matrix).astype(np.float32)\n    assert len(self.label_smoothing_matrix.shape) == 2\n    label_dim = self.label_smoothing_matrix.shape[0]\n    assert label_dim == self.label_smoothing_matrix.shape[1]\n    self.label_smoothing_matrix = self.model.add_global_constant('%s_label_smoothing_matrix' % self.name, array=self.label_smoothing_matrix, dtype=np.dtype(np.float32))\n    self.label_dim = self.model.add_global_constant('%s_label_dim' % self.name, array=label_dim, dtype=np.dtype(np.int64))\n    self.label_prob = True"
        ]
    },
    {
        "func_name": "compute_smoothed_label",
        "original": "def compute_smoothed_label(self, net):\n    assert self.label_smoothing_matrix is not None\n    label = self.input_record.label()\n    original_label_type = self.input_record.label.field_type()\n    if original_label_type.base != np.int64:\n        int64_label = net.NextScopedBlob('int64_label')\n        net.Cast([label], [int64_label], to=core.DataType.INT64)\n    else:\n        int64_label = label\n    one_hot_label = net.NextScopedBlob('one_hot_label')\n    smoothed_label = net.NextScopedBlob('smoothed_label')\n    net.OneHot([int64_label, self.label_dim], [one_hot_label])\n    net.MatMul([one_hot_label, self.label_smoothing_matrix], smoothed_label)\n    return smoothed_label",
        "mutated": [
            "def compute_smoothed_label(self, net):\n    if False:\n        i = 10\n    assert self.label_smoothing_matrix is not None\n    label = self.input_record.label()\n    original_label_type = self.input_record.label.field_type()\n    if original_label_type.base != np.int64:\n        int64_label = net.NextScopedBlob('int64_label')\n        net.Cast([label], [int64_label], to=core.DataType.INT64)\n    else:\n        int64_label = label\n    one_hot_label = net.NextScopedBlob('one_hot_label')\n    smoothed_label = net.NextScopedBlob('smoothed_label')\n    net.OneHot([int64_label, self.label_dim], [one_hot_label])\n    net.MatMul([one_hot_label, self.label_smoothing_matrix], smoothed_label)\n    return smoothed_label",
            "def compute_smoothed_label(self, net):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    assert self.label_smoothing_matrix is not None\n    label = self.input_record.label()\n    original_label_type = self.input_record.label.field_type()\n    if original_label_type.base != np.int64:\n        int64_label = net.NextScopedBlob('int64_label')\n        net.Cast([label], [int64_label], to=core.DataType.INT64)\n    else:\n        int64_label = label\n    one_hot_label = net.NextScopedBlob('one_hot_label')\n    smoothed_label = net.NextScopedBlob('smoothed_label')\n    net.OneHot([int64_label, self.label_dim], [one_hot_label])\n    net.MatMul([one_hot_label, self.label_smoothing_matrix], smoothed_label)\n    return smoothed_label",
            "def compute_smoothed_label(self, net):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    assert self.label_smoothing_matrix is not None\n    label = self.input_record.label()\n    original_label_type = self.input_record.label.field_type()\n    if original_label_type.base != np.int64:\n        int64_label = net.NextScopedBlob('int64_label')\n        net.Cast([label], [int64_label], to=core.DataType.INT64)\n    else:\n        int64_label = label\n    one_hot_label = net.NextScopedBlob('one_hot_label')\n    smoothed_label = net.NextScopedBlob('smoothed_label')\n    net.OneHot([int64_label, self.label_dim], [one_hot_label])\n    net.MatMul([one_hot_label, self.label_smoothing_matrix], smoothed_label)\n    return smoothed_label",
            "def compute_smoothed_label(self, net):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    assert self.label_smoothing_matrix is not None\n    label = self.input_record.label()\n    original_label_type = self.input_record.label.field_type()\n    if original_label_type.base != np.int64:\n        int64_label = net.NextScopedBlob('int64_label')\n        net.Cast([label], [int64_label], to=core.DataType.INT64)\n    else:\n        int64_label = label\n    one_hot_label = net.NextScopedBlob('one_hot_label')\n    smoothed_label = net.NextScopedBlob('smoothed_label')\n    net.OneHot([int64_label, self.label_dim], [one_hot_label])\n    net.MatMul([one_hot_label, self.label_smoothing_matrix], smoothed_label)\n    return smoothed_label",
            "def compute_smoothed_label(self, net):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    assert self.label_smoothing_matrix is not None\n    label = self.input_record.label()\n    original_label_type = self.input_record.label.field_type()\n    if original_label_type.base != np.int64:\n        int64_label = net.NextScopedBlob('int64_label')\n        net.Cast([label], [int64_label], to=core.DataType.INT64)\n    else:\n        int64_label = label\n    one_hot_label = net.NextScopedBlob('one_hot_label')\n    smoothed_label = net.NextScopedBlob('smoothed_label')\n    net.OneHot([int64_label, self.label_dim], [one_hot_label])\n    net.MatMul([one_hot_label, self.label_smoothing_matrix], smoothed_label)\n    return smoothed_label"
        ]
    },
    {
        "func_name": "add_ops",
        "original": "def add_ops(self, net):\n    label = self.input_record.label.field_blobs()\n    if self.label_smoothing_matrix is not None:\n        label = [self.compute_smoothed_label(net)]\n    elif not self.label_prob:\n        if self.input_record.label.field_types()[0].base != np.int32:\n            label = [net.Cast(label, net.NextScopedBlob('int32_label'), to=core.DataType.INT32)]\n    softmax_input = self.input_record.prediction.field_blobs() + label\n    if 'weight' in self.input_record:\n        weight_blob = self.input_record.weight()\n        if self.input_record.weight.field_type().base != np.float32:\n            weight_blob = net.Cast(weight_blob, weight_blob + '_float32', to=core.DataType.FLOAT)\n        softmax_input += [weight_blob]\n    net.SoftmaxWithLoss(softmax_input, self.output_schema.field_blobs(), label_prob=self.label_prob, scale=self.scale, average_by_batch_size=self.average_by_batch_size)",
        "mutated": [
            "def add_ops(self, net):\n    if False:\n        i = 10\n    label = self.input_record.label.field_blobs()\n    if self.label_smoothing_matrix is not None:\n        label = [self.compute_smoothed_label(net)]\n    elif not self.label_prob:\n        if self.input_record.label.field_types()[0].base != np.int32:\n            label = [net.Cast(label, net.NextScopedBlob('int32_label'), to=core.DataType.INT32)]\n    softmax_input = self.input_record.prediction.field_blobs() + label\n    if 'weight' in self.input_record:\n        weight_blob = self.input_record.weight()\n        if self.input_record.weight.field_type().base != np.float32:\n            weight_blob = net.Cast(weight_blob, weight_blob + '_float32', to=core.DataType.FLOAT)\n        softmax_input += [weight_blob]\n    net.SoftmaxWithLoss(softmax_input, self.output_schema.field_blobs(), label_prob=self.label_prob, scale=self.scale, average_by_batch_size=self.average_by_batch_size)",
            "def add_ops(self, net):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    label = self.input_record.label.field_blobs()\n    if self.label_smoothing_matrix is not None:\n        label = [self.compute_smoothed_label(net)]\n    elif not self.label_prob:\n        if self.input_record.label.field_types()[0].base != np.int32:\n            label = [net.Cast(label, net.NextScopedBlob('int32_label'), to=core.DataType.INT32)]\n    softmax_input = self.input_record.prediction.field_blobs() + label\n    if 'weight' in self.input_record:\n        weight_blob = self.input_record.weight()\n        if self.input_record.weight.field_type().base != np.float32:\n            weight_blob = net.Cast(weight_blob, weight_blob + '_float32', to=core.DataType.FLOAT)\n        softmax_input += [weight_blob]\n    net.SoftmaxWithLoss(softmax_input, self.output_schema.field_blobs(), label_prob=self.label_prob, scale=self.scale, average_by_batch_size=self.average_by_batch_size)",
            "def add_ops(self, net):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    label = self.input_record.label.field_blobs()\n    if self.label_smoothing_matrix is not None:\n        label = [self.compute_smoothed_label(net)]\n    elif not self.label_prob:\n        if self.input_record.label.field_types()[0].base != np.int32:\n            label = [net.Cast(label, net.NextScopedBlob('int32_label'), to=core.DataType.INT32)]\n    softmax_input = self.input_record.prediction.field_blobs() + label\n    if 'weight' in self.input_record:\n        weight_blob = self.input_record.weight()\n        if self.input_record.weight.field_type().base != np.float32:\n            weight_blob = net.Cast(weight_blob, weight_blob + '_float32', to=core.DataType.FLOAT)\n        softmax_input += [weight_blob]\n    net.SoftmaxWithLoss(softmax_input, self.output_schema.field_blobs(), label_prob=self.label_prob, scale=self.scale, average_by_batch_size=self.average_by_batch_size)",
            "def add_ops(self, net):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    label = self.input_record.label.field_blobs()\n    if self.label_smoothing_matrix is not None:\n        label = [self.compute_smoothed_label(net)]\n    elif not self.label_prob:\n        if self.input_record.label.field_types()[0].base != np.int32:\n            label = [net.Cast(label, net.NextScopedBlob('int32_label'), to=core.DataType.INT32)]\n    softmax_input = self.input_record.prediction.field_blobs() + label\n    if 'weight' in self.input_record:\n        weight_blob = self.input_record.weight()\n        if self.input_record.weight.field_type().base != np.float32:\n            weight_blob = net.Cast(weight_blob, weight_blob + '_float32', to=core.DataType.FLOAT)\n        softmax_input += [weight_blob]\n    net.SoftmaxWithLoss(softmax_input, self.output_schema.field_blobs(), label_prob=self.label_prob, scale=self.scale, average_by_batch_size=self.average_by_batch_size)",
            "def add_ops(self, net):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    label = self.input_record.label.field_blobs()\n    if self.label_smoothing_matrix is not None:\n        label = [self.compute_smoothed_label(net)]\n    elif not self.label_prob:\n        if self.input_record.label.field_types()[0].base != np.int32:\n            label = [net.Cast(label, net.NextScopedBlob('int32_label'), to=core.DataType.INT32)]\n    softmax_input = self.input_record.prediction.field_blobs() + label\n    if 'weight' in self.input_record:\n        weight_blob = self.input_record.weight()\n        if self.input_record.weight.field_type().base != np.float32:\n            weight_blob = net.Cast(weight_blob, weight_blob + '_float32', to=core.DataType.FLOAT)\n        softmax_input += [weight_blob]\n    net.SoftmaxWithLoss(softmax_input, self.output_schema.field_blobs(), label_prob=self.label_prob, scale=self.scale, average_by_batch_size=self.average_by_batch_size)"
        ]
    }
]