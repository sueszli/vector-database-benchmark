[
    {
        "func_name": "map_string2func",
        "original": "def map_string2func(funcname, clss, compute_capability):\n    \"\"\"\n    Helper function that converts string function names to function calls\n    \"\"\"\n    if '_get_' + funcname not in globals():\n        raise AttributeError(\"kernel type '\" + funcname + \"' not understood\")\n    return globals()['_get_' + funcname](clss, compute_capability)",
        "mutated": [
            "def map_string2func(funcname, clss, compute_capability):\n    if False:\n        i = 10\n    '\\n    Helper function that converts string function names to function calls\\n    '\n    if '_get_' + funcname not in globals():\n        raise AttributeError(\"kernel type '\" + funcname + \"' not understood\")\n    return globals()['_get_' + funcname](clss, compute_capability)",
            "def map_string2func(funcname, clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Helper function that converts string function names to function calls\\n    '\n    if '_get_' + funcname not in globals():\n        raise AttributeError(\"kernel type '\" + funcname + \"' not understood\")\n    return globals()['_get_' + funcname](clss, compute_capability)",
            "def map_string2func(funcname, clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Helper function that converts string function names to function calls\\n    '\n    if '_get_' + funcname not in globals():\n        raise AttributeError(\"kernel type '\" + funcname + \"' not understood\")\n    return globals()['_get_' + funcname](clss, compute_capability)",
            "def map_string2func(funcname, clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Helper function that converts string function names to function calls\\n    '\n    if '_get_' + funcname not in globals():\n        raise AttributeError(\"kernel type '\" + funcname + \"' not understood\")\n    return globals()['_get_' + funcname](clss, compute_capability)",
            "def map_string2func(funcname, clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Helper function that converts string function names to function calls\\n    '\n    if '_get_' + funcname not in globals():\n        raise AttributeError(\"kernel type '\" + funcname + \"' not understood\")\n    return globals()['_get_' + funcname](clss, compute_capability)"
        ]
    },
    {
        "func_name": "prepare_template_vals",
        "original": "def prepare_template_vals(dtype, compute_capability, rounding=False):\n    \"\"\"\n    Set up template code snippets that are reused across multiple kernels.\n    Most are data type conversion and statistics collection related.\n    \"\"\"\n    template_vals = dict()\n    for key in ('inits', 'finish', 'stats_args', 'mul_by_scale', 'atomic_max', 'cvt_out'):\n        template_vals[key] = ''\n    template_vals['common'] = _common_divmod\n    if rounding:\n        template_vals['common'] += _common_urand_gen\n        template_vals['common'] += _common_round['nearest'].get(dtype, '')\n        template_vals['inits'] += _init_rand_func + _init_rand_round_func\n        template_vals['finish'] += _finish_rand_func\n        mode = 'random'\n    else:\n        mode = 'nearest'\n    template_vals['common'] += _common_round[mode].get(dtype, '')\n    template_vals['common'] += _common_max_abs\n    if compute_capability[0] == 3 and compute_capability[1] < 5 or compute_capability[0] < 3:\n        template_vals['common'] += _common_kepler\n    template_vals['type'] = _ew_types[dtype]['type']\n    template_vals['cvt'] = _ew_types[dtype]['cvt']\n    if dtype == 'f2':\n        template_vals['common'] += _common_fp16_to_fp32\n        template_vals['cvt_out'] = 'fp32_to_fp16'\n    elif dtype == 'x2':\n        template_vals['stats_args'] += ', int* maxabs, float scale0'\n        template_vals['cvt'] = '(float)'\n        template_vals['cvt_out'] = 'fp32_to_int16'\n        template_vals['mul_by_scale'] += '1/scale0 *'\n        template_vals['atomic_max'] += atomic_max\n    elif dtype == 'f4':\n        pass\n    else:\n        raise ValueError('Did not understand clss dtype ' + str(dtype))\n    return template_vals",
        "mutated": [
            "def prepare_template_vals(dtype, compute_capability, rounding=False):\n    if False:\n        i = 10\n    '\\n    Set up template code snippets that are reused across multiple kernels.\\n    Most are data type conversion and statistics collection related.\\n    '\n    template_vals = dict()\n    for key in ('inits', 'finish', 'stats_args', 'mul_by_scale', 'atomic_max', 'cvt_out'):\n        template_vals[key] = ''\n    template_vals['common'] = _common_divmod\n    if rounding:\n        template_vals['common'] += _common_urand_gen\n        template_vals['common'] += _common_round['nearest'].get(dtype, '')\n        template_vals['inits'] += _init_rand_func + _init_rand_round_func\n        template_vals['finish'] += _finish_rand_func\n        mode = 'random'\n    else:\n        mode = 'nearest'\n    template_vals['common'] += _common_round[mode].get(dtype, '')\n    template_vals['common'] += _common_max_abs\n    if compute_capability[0] == 3 and compute_capability[1] < 5 or compute_capability[0] < 3:\n        template_vals['common'] += _common_kepler\n    template_vals['type'] = _ew_types[dtype]['type']\n    template_vals['cvt'] = _ew_types[dtype]['cvt']\n    if dtype == 'f2':\n        template_vals['common'] += _common_fp16_to_fp32\n        template_vals['cvt_out'] = 'fp32_to_fp16'\n    elif dtype == 'x2':\n        template_vals['stats_args'] += ', int* maxabs, float scale0'\n        template_vals['cvt'] = '(float)'\n        template_vals['cvt_out'] = 'fp32_to_int16'\n        template_vals['mul_by_scale'] += '1/scale0 *'\n        template_vals['atomic_max'] += atomic_max\n    elif dtype == 'f4':\n        pass\n    else:\n        raise ValueError('Did not understand clss dtype ' + str(dtype))\n    return template_vals",
            "def prepare_template_vals(dtype, compute_capability, rounding=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Set up template code snippets that are reused across multiple kernels.\\n    Most are data type conversion and statistics collection related.\\n    '\n    template_vals = dict()\n    for key in ('inits', 'finish', 'stats_args', 'mul_by_scale', 'atomic_max', 'cvt_out'):\n        template_vals[key] = ''\n    template_vals['common'] = _common_divmod\n    if rounding:\n        template_vals['common'] += _common_urand_gen\n        template_vals['common'] += _common_round['nearest'].get(dtype, '')\n        template_vals['inits'] += _init_rand_func + _init_rand_round_func\n        template_vals['finish'] += _finish_rand_func\n        mode = 'random'\n    else:\n        mode = 'nearest'\n    template_vals['common'] += _common_round[mode].get(dtype, '')\n    template_vals['common'] += _common_max_abs\n    if compute_capability[0] == 3 and compute_capability[1] < 5 or compute_capability[0] < 3:\n        template_vals['common'] += _common_kepler\n    template_vals['type'] = _ew_types[dtype]['type']\n    template_vals['cvt'] = _ew_types[dtype]['cvt']\n    if dtype == 'f2':\n        template_vals['common'] += _common_fp16_to_fp32\n        template_vals['cvt_out'] = 'fp32_to_fp16'\n    elif dtype == 'x2':\n        template_vals['stats_args'] += ', int* maxabs, float scale0'\n        template_vals['cvt'] = '(float)'\n        template_vals['cvt_out'] = 'fp32_to_int16'\n        template_vals['mul_by_scale'] += '1/scale0 *'\n        template_vals['atomic_max'] += atomic_max\n    elif dtype == 'f4':\n        pass\n    else:\n        raise ValueError('Did not understand clss dtype ' + str(dtype))\n    return template_vals",
            "def prepare_template_vals(dtype, compute_capability, rounding=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Set up template code snippets that are reused across multiple kernels.\\n    Most are data type conversion and statistics collection related.\\n    '\n    template_vals = dict()\n    for key in ('inits', 'finish', 'stats_args', 'mul_by_scale', 'atomic_max', 'cvt_out'):\n        template_vals[key] = ''\n    template_vals['common'] = _common_divmod\n    if rounding:\n        template_vals['common'] += _common_urand_gen\n        template_vals['common'] += _common_round['nearest'].get(dtype, '')\n        template_vals['inits'] += _init_rand_func + _init_rand_round_func\n        template_vals['finish'] += _finish_rand_func\n        mode = 'random'\n    else:\n        mode = 'nearest'\n    template_vals['common'] += _common_round[mode].get(dtype, '')\n    template_vals['common'] += _common_max_abs\n    if compute_capability[0] == 3 and compute_capability[1] < 5 or compute_capability[0] < 3:\n        template_vals['common'] += _common_kepler\n    template_vals['type'] = _ew_types[dtype]['type']\n    template_vals['cvt'] = _ew_types[dtype]['cvt']\n    if dtype == 'f2':\n        template_vals['common'] += _common_fp16_to_fp32\n        template_vals['cvt_out'] = 'fp32_to_fp16'\n    elif dtype == 'x2':\n        template_vals['stats_args'] += ', int* maxabs, float scale0'\n        template_vals['cvt'] = '(float)'\n        template_vals['cvt_out'] = 'fp32_to_int16'\n        template_vals['mul_by_scale'] += '1/scale0 *'\n        template_vals['atomic_max'] += atomic_max\n    elif dtype == 'f4':\n        pass\n    else:\n        raise ValueError('Did not understand clss dtype ' + str(dtype))\n    return template_vals",
            "def prepare_template_vals(dtype, compute_capability, rounding=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Set up template code snippets that are reused across multiple kernels.\\n    Most are data type conversion and statistics collection related.\\n    '\n    template_vals = dict()\n    for key in ('inits', 'finish', 'stats_args', 'mul_by_scale', 'atomic_max', 'cvt_out'):\n        template_vals[key] = ''\n    template_vals['common'] = _common_divmod\n    if rounding:\n        template_vals['common'] += _common_urand_gen\n        template_vals['common'] += _common_round['nearest'].get(dtype, '')\n        template_vals['inits'] += _init_rand_func + _init_rand_round_func\n        template_vals['finish'] += _finish_rand_func\n        mode = 'random'\n    else:\n        mode = 'nearest'\n    template_vals['common'] += _common_round[mode].get(dtype, '')\n    template_vals['common'] += _common_max_abs\n    if compute_capability[0] == 3 and compute_capability[1] < 5 or compute_capability[0] < 3:\n        template_vals['common'] += _common_kepler\n    template_vals['type'] = _ew_types[dtype]['type']\n    template_vals['cvt'] = _ew_types[dtype]['cvt']\n    if dtype == 'f2':\n        template_vals['common'] += _common_fp16_to_fp32\n        template_vals['cvt_out'] = 'fp32_to_fp16'\n    elif dtype == 'x2':\n        template_vals['stats_args'] += ', int* maxabs, float scale0'\n        template_vals['cvt'] = '(float)'\n        template_vals['cvt_out'] = 'fp32_to_int16'\n        template_vals['mul_by_scale'] += '1/scale0 *'\n        template_vals['atomic_max'] += atomic_max\n    elif dtype == 'f4':\n        pass\n    else:\n        raise ValueError('Did not understand clss dtype ' + str(dtype))\n    return template_vals",
            "def prepare_template_vals(dtype, compute_capability, rounding=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Set up template code snippets that are reused across multiple kernels.\\n    Most are data type conversion and statistics collection related.\\n    '\n    template_vals = dict()\n    for key in ('inits', 'finish', 'stats_args', 'mul_by_scale', 'atomic_max', 'cvt_out'):\n        template_vals[key] = ''\n    template_vals['common'] = _common_divmod\n    if rounding:\n        template_vals['common'] += _common_urand_gen\n        template_vals['common'] += _common_round['nearest'].get(dtype, '')\n        template_vals['inits'] += _init_rand_func + _init_rand_round_func\n        template_vals['finish'] += _finish_rand_func\n        mode = 'random'\n    else:\n        mode = 'nearest'\n    template_vals['common'] += _common_round[mode].get(dtype, '')\n    template_vals['common'] += _common_max_abs\n    if compute_capability[0] == 3 and compute_capability[1] < 5 or compute_capability[0] < 3:\n        template_vals['common'] += _common_kepler\n    template_vals['type'] = _ew_types[dtype]['type']\n    template_vals['cvt'] = _ew_types[dtype]['cvt']\n    if dtype == 'f2':\n        template_vals['common'] += _common_fp16_to_fp32\n        template_vals['cvt_out'] = 'fp32_to_fp16'\n    elif dtype == 'x2':\n        template_vals['stats_args'] += ', int* maxabs, float scale0'\n        template_vals['cvt'] = '(float)'\n        template_vals['cvt_out'] = 'fp32_to_int16'\n        template_vals['mul_by_scale'] += '1/scale0 *'\n        template_vals['atomic_max'] += atomic_max\n    elif dtype == 'f4':\n        pass\n    else:\n        raise ValueError('Did not understand clss dtype ' + str(dtype))\n    return template_vals"
        ]
    },
    {
        "func_name": "_get_fprop_max",
        "original": "@context_dependent_memoize\ndef _get_fprop_max(clss, compute_capability):\n    code = \"\\n#define FLT_MAX 3.402823466E+38F\\n\\n%(common)s\\n\\n__global__ void spool_fprop_max(\\n    const %(type)s* I, %(type)s* O, unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    extern __shared__ int lut[];\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    int offset = k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n    I += n;\\n    O += offset;\\n    A += offset;\\n\\n    float O_val = beta != 0.0f && p < P && q < Q && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc = min(maskN + 1, 32);\\n\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        int jrst = 0;\\n        int argmax = 0;\\n        float max = -FLT_MAX;\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int slice0 = lut[lut_offset + 0];\\n            int slice1 = lut[lut_offset + 1];\\n            int slice2 = lut[lut_offset + 2];\\n            int slice3 = lut[lut_offset + 3];\\n\\n            // val needs to stay in fp32 or can't be se to FLT_MAX\\n            float val0 = jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : -FLT_MAX;\\n            float val1 = jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : -FLT_MAX;\\n            float val2 = jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : -FLT_MAX;\\n            float val3 = jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : -FLT_MAX;\\n\\n            if (val0 > max) {\\n                max = val0;\\n                argmax = jrst + 0;\\n            }\\n            if (val1 > max) {\\n                max = val1;\\n                argmax = jrst + 1;\\n            }\\n            if (val2 > max) {\\n                max = val2;\\n                argmax = jrst + 2;\\n            }\\n            if (val3 > max) {\\n                max = val3;\\n                argmax = jrst + 3;\\n            }\\n\\n            jrst += 4;\\n        }\\n        // convert back to fp to write out\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (max*alpha + O_val*beta));\\n        if (!(flags & 1)) {\\n            *O = temp_out;\\n            *A = (unsigned char)argmax;\\n        }\\n\\n        intermediate_max = max_abs(0, temp_out);  // compute abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_fprop_max')\n    sig = '3P 2f 44I' + ('Pf' if clss[0] == 'x' else '')\n    kernel.prepare(sig)\n    return kernel",
        "mutated": [
            "@context_dependent_memoize\ndef _get_fprop_max(clss, compute_capability):\n    if False:\n        i = 10\n    code = \"\\n#define FLT_MAX 3.402823466E+38F\\n\\n%(common)s\\n\\n__global__ void spool_fprop_max(\\n    const %(type)s* I, %(type)s* O, unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    extern __shared__ int lut[];\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    int offset = k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n    I += n;\\n    O += offset;\\n    A += offset;\\n\\n    float O_val = beta != 0.0f && p < P && q < Q && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc = min(maskN + 1, 32);\\n\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        int jrst = 0;\\n        int argmax = 0;\\n        float max = -FLT_MAX;\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int slice0 = lut[lut_offset + 0];\\n            int slice1 = lut[lut_offset + 1];\\n            int slice2 = lut[lut_offset + 2];\\n            int slice3 = lut[lut_offset + 3];\\n\\n            // val needs to stay in fp32 or can't be se to FLT_MAX\\n            float val0 = jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : -FLT_MAX;\\n            float val1 = jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : -FLT_MAX;\\n            float val2 = jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : -FLT_MAX;\\n            float val3 = jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : -FLT_MAX;\\n\\n            if (val0 > max) {\\n                max = val0;\\n                argmax = jrst + 0;\\n            }\\n            if (val1 > max) {\\n                max = val1;\\n                argmax = jrst + 1;\\n            }\\n            if (val2 > max) {\\n                max = val2;\\n                argmax = jrst + 2;\\n            }\\n            if (val3 > max) {\\n                max = val3;\\n                argmax = jrst + 3;\\n            }\\n\\n            jrst += 4;\\n        }\\n        // convert back to fp to write out\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (max*alpha + O_val*beta));\\n        if (!(flags & 1)) {\\n            *O = temp_out;\\n            *A = (unsigned char)argmax;\\n        }\\n\\n        intermediate_max = max_abs(0, temp_out);  // compute abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_fprop_max')\n    sig = '3P 2f 44I' + ('Pf' if clss[0] == 'x' else '')\n    kernel.prepare(sig)\n    return kernel",
            "@context_dependent_memoize\ndef _get_fprop_max(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    code = \"\\n#define FLT_MAX 3.402823466E+38F\\n\\n%(common)s\\n\\n__global__ void spool_fprop_max(\\n    const %(type)s* I, %(type)s* O, unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    extern __shared__ int lut[];\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    int offset = k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n    I += n;\\n    O += offset;\\n    A += offset;\\n\\n    float O_val = beta != 0.0f && p < P && q < Q && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc = min(maskN + 1, 32);\\n\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        int jrst = 0;\\n        int argmax = 0;\\n        float max = -FLT_MAX;\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int slice0 = lut[lut_offset + 0];\\n            int slice1 = lut[lut_offset + 1];\\n            int slice2 = lut[lut_offset + 2];\\n            int slice3 = lut[lut_offset + 3];\\n\\n            // val needs to stay in fp32 or can't be se to FLT_MAX\\n            float val0 = jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : -FLT_MAX;\\n            float val1 = jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : -FLT_MAX;\\n            float val2 = jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : -FLT_MAX;\\n            float val3 = jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : -FLT_MAX;\\n\\n            if (val0 > max) {\\n                max = val0;\\n                argmax = jrst + 0;\\n            }\\n            if (val1 > max) {\\n                max = val1;\\n                argmax = jrst + 1;\\n            }\\n            if (val2 > max) {\\n                max = val2;\\n                argmax = jrst + 2;\\n            }\\n            if (val3 > max) {\\n                max = val3;\\n                argmax = jrst + 3;\\n            }\\n\\n            jrst += 4;\\n        }\\n        // convert back to fp to write out\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (max*alpha + O_val*beta));\\n        if (!(flags & 1)) {\\n            *O = temp_out;\\n            *A = (unsigned char)argmax;\\n        }\\n\\n        intermediate_max = max_abs(0, temp_out);  // compute abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_fprop_max')\n    sig = '3P 2f 44I' + ('Pf' if clss[0] == 'x' else '')\n    kernel.prepare(sig)\n    return kernel",
            "@context_dependent_memoize\ndef _get_fprop_max(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    code = \"\\n#define FLT_MAX 3.402823466E+38F\\n\\n%(common)s\\n\\n__global__ void spool_fprop_max(\\n    const %(type)s* I, %(type)s* O, unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    extern __shared__ int lut[];\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    int offset = k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n    I += n;\\n    O += offset;\\n    A += offset;\\n\\n    float O_val = beta != 0.0f && p < P && q < Q && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc = min(maskN + 1, 32);\\n\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        int jrst = 0;\\n        int argmax = 0;\\n        float max = -FLT_MAX;\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int slice0 = lut[lut_offset + 0];\\n            int slice1 = lut[lut_offset + 1];\\n            int slice2 = lut[lut_offset + 2];\\n            int slice3 = lut[lut_offset + 3];\\n\\n            // val needs to stay in fp32 or can't be se to FLT_MAX\\n            float val0 = jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : -FLT_MAX;\\n            float val1 = jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : -FLT_MAX;\\n            float val2 = jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : -FLT_MAX;\\n            float val3 = jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : -FLT_MAX;\\n\\n            if (val0 > max) {\\n                max = val0;\\n                argmax = jrst + 0;\\n            }\\n            if (val1 > max) {\\n                max = val1;\\n                argmax = jrst + 1;\\n            }\\n            if (val2 > max) {\\n                max = val2;\\n                argmax = jrst + 2;\\n            }\\n            if (val3 > max) {\\n                max = val3;\\n                argmax = jrst + 3;\\n            }\\n\\n            jrst += 4;\\n        }\\n        // convert back to fp to write out\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (max*alpha + O_val*beta));\\n        if (!(flags & 1)) {\\n            *O = temp_out;\\n            *A = (unsigned char)argmax;\\n        }\\n\\n        intermediate_max = max_abs(0, temp_out);  // compute abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_fprop_max')\n    sig = '3P 2f 44I' + ('Pf' if clss[0] == 'x' else '')\n    kernel.prepare(sig)\n    return kernel",
            "@context_dependent_memoize\ndef _get_fprop_max(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    code = \"\\n#define FLT_MAX 3.402823466E+38F\\n\\n%(common)s\\n\\n__global__ void spool_fprop_max(\\n    const %(type)s* I, %(type)s* O, unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    extern __shared__ int lut[];\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    int offset = k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n    I += n;\\n    O += offset;\\n    A += offset;\\n\\n    float O_val = beta != 0.0f && p < P && q < Q && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc = min(maskN + 1, 32);\\n\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        int jrst = 0;\\n        int argmax = 0;\\n        float max = -FLT_MAX;\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int slice0 = lut[lut_offset + 0];\\n            int slice1 = lut[lut_offset + 1];\\n            int slice2 = lut[lut_offset + 2];\\n            int slice3 = lut[lut_offset + 3];\\n\\n            // val needs to stay in fp32 or can't be se to FLT_MAX\\n            float val0 = jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : -FLT_MAX;\\n            float val1 = jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : -FLT_MAX;\\n            float val2 = jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : -FLT_MAX;\\n            float val3 = jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : -FLT_MAX;\\n\\n            if (val0 > max) {\\n                max = val0;\\n                argmax = jrst + 0;\\n            }\\n            if (val1 > max) {\\n                max = val1;\\n                argmax = jrst + 1;\\n            }\\n            if (val2 > max) {\\n                max = val2;\\n                argmax = jrst + 2;\\n            }\\n            if (val3 > max) {\\n                max = val3;\\n                argmax = jrst + 3;\\n            }\\n\\n            jrst += 4;\\n        }\\n        // convert back to fp to write out\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (max*alpha + O_val*beta));\\n        if (!(flags & 1)) {\\n            *O = temp_out;\\n            *A = (unsigned char)argmax;\\n        }\\n\\n        intermediate_max = max_abs(0, temp_out);  // compute abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_fprop_max')\n    sig = '3P 2f 44I' + ('Pf' if clss[0] == 'x' else '')\n    kernel.prepare(sig)\n    return kernel",
            "@context_dependent_memoize\ndef _get_fprop_max(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    code = \"\\n#define FLT_MAX 3.402823466E+38F\\n\\n%(common)s\\n\\n__global__ void spool_fprop_max(\\n    const %(type)s* I, %(type)s* O, unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    extern __shared__ int lut[];\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    int offset = k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n    I += n;\\n    O += offset;\\n    A += offset;\\n\\n    float O_val = beta != 0.0f && p < P && q < Q && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc = min(maskN + 1, 32);\\n\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        int jrst = 0;\\n        int argmax = 0;\\n        float max = -FLT_MAX;\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int slice0 = lut[lut_offset + 0];\\n            int slice1 = lut[lut_offset + 1];\\n            int slice2 = lut[lut_offset + 2];\\n            int slice3 = lut[lut_offset + 3];\\n\\n            // val needs to stay in fp32 or can't be se to FLT_MAX\\n            float val0 = jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : -FLT_MAX;\\n            float val1 = jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : -FLT_MAX;\\n            float val2 = jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : -FLT_MAX;\\n            float val3 = jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : -FLT_MAX;\\n\\n            if (val0 > max) {\\n                max = val0;\\n                argmax = jrst + 0;\\n            }\\n            if (val1 > max) {\\n                max = val1;\\n                argmax = jrst + 1;\\n            }\\n            if (val2 > max) {\\n                max = val2;\\n                argmax = jrst + 2;\\n            }\\n            if (val3 > max) {\\n                max = val3;\\n                argmax = jrst + 3;\\n            }\\n\\n            jrst += 4;\\n        }\\n        // convert back to fp to write out\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (max*alpha + O_val*beta));\\n        if (!(flags & 1)) {\\n            *O = temp_out;\\n            *A = (unsigned char)argmax;\\n        }\\n\\n        intermediate_max = max_abs(0, temp_out);  // compute abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_fprop_max')\n    sig = '3P 2f 44I' + ('Pf' if clss[0] == 'x' else '')\n    kernel.prepare(sig)\n    return kernel"
        ]
    },
    {
        "func_name": "_get_fprop_avg",
        "original": "@context_dependent_memoize\ndef _get_fprop_avg(clss, compute_capability):\n    code = '\\n%(common)s\\n\\n__global__ void spool_fprop_avg(\\n    const %(type)s* I, %(type)s* O, unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize[32];\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    O += k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n\\n    float O_val = beta != 0.0f && p < P && q < Q && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc    = min(maskN + 1, 32);\\n        int sbBits = 1 << min(shrN, 5);\\n        int sbMask = ~(-1 << sbBits) << mad16(sb, sbBits, 0);\\n\\n        int window_size = 0;\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(sbMask & __ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n\\n        // TODO confirm kepler OK\\n        unsigned int shrN_mask = (shrN < 32) ? max(0, ((1 << shrN) - 1)) : 0xffffffff;\\n        if((tid & shrN_mask) == 0)\\n            rcpWindowSize[sb] = 1.0f / (float)window_size;\\n    }\\n    __syncthreads();\\n\\n    float rcp_window_size = rcpWindowSize[sb];\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        int jrst = 0;\\n        float sum = 0.0f;\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int slice0 = lut[lut_offset + 0];\\n            int slice1 = lut[lut_offset + 1];\\n            int slice2 = lut[lut_offset + 2];\\n            int slice3 = lut[lut_offset + 3];\\n\\n            sum += jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : 0.0f;\\n            sum += jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : 0.0f;\\n            sum += jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : 0.0f;\\n            sum += jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : 0.0f;\\n\\n            jrst += 4;\\n        }\\n\\n        // convert back to fp to write out\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (sum*rcp_window_size*alpha + O_val*beta));\\n        if (!(flags & 1)) {\\n            *O = temp_out;\\n        }\\n        // collect max abs stats\\n        intermediate_max = max_abs(0, temp_out); // compute abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_fprop_avg')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
        "mutated": [
            "@context_dependent_memoize\ndef _get_fprop_avg(clss, compute_capability):\n    if False:\n        i = 10\n    code = '\\n%(common)s\\n\\n__global__ void spool_fprop_avg(\\n    const %(type)s* I, %(type)s* O, unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize[32];\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    O += k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n\\n    float O_val = beta != 0.0f && p < P && q < Q && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc    = min(maskN + 1, 32);\\n        int sbBits = 1 << min(shrN, 5);\\n        int sbMask = ~(-1 << sbBits) << mad16(sb, sbBits, 0);\\n\\n        int window_size = 0;\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(sbMask & __ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n\\n        // TODO confirm kepler OK\\n        unsigned int shrN_mask = (shrN < 32) ? max(0, ((1 << shrN) - 1)) : 0xffffffff;\\n        if((tid & shrN_mask) == 0)\\n            rcpWindowSize[sb] = 1.0f / (float)window_size;\\n    }\\n    __syncthreads();\\n\\n    float rcp_window_size = rcpWindowSize[sb];\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        int jrst = 0;\\n        float sum = 0.0f;\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int slice0 = lut[lut_offset + 0];\\n            int slice1 = lut[lut_offset + 1];\\n            int slice2 = lut[lut_offset + 2];\\n            int slice3 = lut[lut_offset + 3];\\n\\n            sum += jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : 0.0f;\\n            sum += jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : 0.0f;\\n            sum += jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : 0.0f;\\n            sum += jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : 0.0f;\\n\\n            jrst += 4;\\n        }\\n\\n        // convert back to fp to write out\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (sum*rcp_window_size*alpha + O_val*beta));\\n        if (!(flags & 1)) {\\n            *O = temp_out;\\n        }\\n        // collect max abs stats\\n        intermediate_max = max_abs(0, temp_out); // compute abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_fprop_avg')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_fprop_avg(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    code = '\\n%(common)s\\n\\n__global__ void spool_fprop_avg(\\n    const %(type)s* I, %(type)s* O, unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize[32];\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    O += k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n\\n    float O_val = beta != 0.0f && p < P && q < Q && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc    = min(maskN + 1, 32);\\n        int sbBits = 1 << min(shrN, 5);\\n        int sbMask = ~(-1 << sbBits) << mad16(sb, sbBits, 0);\\n\\n        int window_size = 0;\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(sbMask & __ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n\\n        // TODO confirm kepler OK\\n        unsigned int shrN_mask = (shrN < 32) ? max(0, ((1 << shrN) - 1)) : 0xffffffff;\\n        if((tid & shrN_mask) == 0)\\n            rcpWindowSize[sb] = 1.0f / (float)window_size;\\n    }\\n    __syncthreads();\\n\\n    float rcp_window_size = rcpWindowSize[sb];\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        int jrst = 0;\\n        float sum = 0.0f;\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int slice0 = lut[lut_offset + 0];\\n            int slice1 = lut[lut_offset + 1];\\n            int slice2 = lut[lut_offset + 2];\\n            int slice3 = lut[lut_offset + 3];\\n\\n            sum += jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : 0.0f;\\n            sum += jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : 0.0f;\\n            sum += jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : 0.0f;\\n            sum += jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : 0.0f;\\n\\n            jrst += 4;\\n        }\\n\\n        // convert back to fp to write out\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (sum*rcp_window_size*alpha + O_val*beta));\\n        if (!(flags & 1)) {\\n            *O = temp_out;\\n        }\\n        // collect max abs stats\\n        intermediate_max = max_abs(0, temp_out); // compute abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_fprop_avg')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_fprop_avg(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    code = '\\n%(common)s\\n\\n__global__ void spool_fprop_avg(\\n    const %(type)s* I, %(type)s* O, unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize[32];\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    O += k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n\\n    float O_val = beta != 0.0f && p < P && q < Q && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc    = min(maskN + 1, 32);\\n        int sbBits = 1 << min(shrN, 5);\\n        int sbMask = ~(-1 << sbBits) << mad16(sb, sbBits, 0);\\n\\n        int window_size = 0;\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(sbMask & __ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n\\n        // TODO confirm kepler OK\\n        unsigned int shrN_mask = (shrN < 32) ? max(0, ((1 << shrN) - 1)) : 0xffffffff;\\n        if((tid & shrN_mask) == 0)\\n            rcpWindowSize[sb] = 1.0f / (float)window_size;\\n    }\\n    __syncthreads();\\n\\n    float rcp_window_size = rcpWindowSize[sb];\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        int jrst = 0;\\n        float sum = 0.0f;\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int slice0 = lut[lut_offset + 0];\\n            int slice1 = lut[lut_offset + 1];\\n            int slice2 = lut[lut_offset + 2];\\n            int slice3 = lut[lut_offset + 3];\\n\\n            sum += jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : 0.0f;\\n            sum += jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : 0.0f;\\n            sum += jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : 0.0f;\\n            sum += jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : 0.0f;\\n\\n            jrst += 4;\\n        }\\n\\n        // convert back to fp to write out\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (sum*rcp_window_size*alpha + O_val*beta));\\n        if (!(flags & 1)) {\\n            *O = temp_out;\\n        }\\n        // collect max abs stats\\n        intermediate_max = max_abs(0, temp_out); // compute abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_fprop_avg')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_fprop_avg(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    code = '\\n%(common)s\\n\\n__global__ void spool_fprop_avg(\\n    const %(type)s* I, %(type)s* O, unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize[32];\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    O += k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n\\n    float O_val = beta != 0.0f && p < P && q < Q && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc    = min(maskN + 1, 32);\\n        int sbBits = 1 << min(shrN, 5);\\n        int sbMask = ~(-1 << sbBits) << mad16(sb, sbBits, 0);\\n\\n        int window_size = 0;\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(sbMask & __ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n\\n        // TODO confirm kepler OK\\n        unsigned int shrN_mask = (shrN < 32) ? max(0, ((1 << shrN) - 1)) : 0xffffffff;\\n        if((tid & shrN_mask) == 0)\\n            rcpWindowSize[sb] = 1.0f / (float)window_size;\\n    }\\n    __syncthreads();\\n\\n    float rcp_window_size = rcpWindowSize[sb];\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        int jrst = 0;\\n        float sum = 0.0f;\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int slice0 = lut[lut_offset + 0];\\n            int slice1 = lut[lut_offset + 1];\\n            int slice2 = lut[lut_offset + 2];\\n            int slice3 = lut[lut_offset + 3];\\n\\n            sum += jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : 0.0f;\\n            sum += jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : 0.0f;\\n            sum += jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : 0.0f;\\n            sum += jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : 0.0f;\\n\\n            jrst += 4;\\n        }\\n\\n        // convert back to fp to write out\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (sum*rcp_window_size*alpha + O_val*beta));\\n        if (!(flags & 1)) {\\n            *O = temp_out;\\n        }\\n        // collect max abs stats\\n        intermediate_max = max_abs(0, temp_out); // compute abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_fprop_avg')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_fprop_avg(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    code = '\\n%(common)s\\n\\n__global__ void spool_fprop_avg(\\n    const %(type)s* I, %(type)s* O, unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize[32];\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    O += k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n\\n    float O_val = beta != 0.0f && p < P && q < Q && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc    = min(maskN + 1, 32);\\n        int sbBits = 1 << min(shrN, 5);\\n        int sbMask = ~(-1 << sbBits) << mad16(sb, sbBits, 0);\\n\\n        int window_size = 0;\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(sbMask & __ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n\\n        // TODO confirm kepler OK\\n        unsigned int shrN_mask = (shrN < 32) ? max(0, ((1 << shrN) - 1)) : 0xffffffff;\\n        if((tid & shrN_mask) == 0)\\n            rcpWindowSize[sb] = 1.0f / (float)window_size;\\n    }\\n    __syncthreads();\\n\\n    float rcp_window_size = rcpWindowSize[sb];\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        int jrst = 0;\\n        float sum = 0.0f;\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int slice0 = lut[lut_offset + 0];\\n            int slice1 = lut[lut_offset + 1];\\n            int slice2 = lut[lut_offset + 2];\\n            int slice3 = lut[lut_offset + 3];\\n\\n            sum += jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : 0.0f;\\n            sum += jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : 0.0f;\\n            sum += jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : 0.0f;\\n            sum += jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : 0.0f;\\n\\n            jrst += 4;\\n        }\\n\\n        // convert back to fp to write out\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (sum*rcp_window_size*alpha + O_val*beta));\\n        if (!(flags & 1)) {\\n            *O = temp_out;\\n        }\\n        // collect max abs stats\\n        intermediate_max = max_abs(0, temp_out); // compute abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_fprop_avg')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel"
        ]
    },
    {
        "func_name": "_get_fprop_lrn",
        "original": "@context_dependent_memoize\ndef _get_fprop_lrn(clss, compute_capability):\n    \"\"\"\n    Local Response Normalization (LRN) layer.\n    Implementation based on fprop_avg kernel.\n\n    Implements the following operation:\n    for each output pixel\n        x' = x / response\n    where the response is\n        response = [1 + alpha/N * sum_neighbors x_neighbor**2 ]**beta\n    so we compute the pooling output\n    \"\"\"\n    code = \"\\n%(common)s\\n\\n__global__ void spool_fprop_lrn(\\n    const %(type)s* I, %(type)s* O, %(type)s* A,\\n    float alpha, float beta, float ascale, float bpower, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize;\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    // paralellism is over QMPK dimensions (output pixels and ofm's)\\n    int n  = tid;\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*P;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = Q - q - 1;\\n\\n    const %(type)s* IonO = I;  // input pixel at output location\\n    I += n;\\n    IonO += k*MPQN + m*PQN + p*QN + q*N + n;\\n    O += k*MPQN + m*PQN + p*QN + q*N + n;\\n    A += k*MPQN + m*PQN + p*QN + q*N + n;\\n\\n    float O_val = beta != 0.0f ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int window_size = 0;\\n        int jrst = tid;\\n        // this loop generates the LUT (same for pooling and normalization)\\n        while (jrst < JRST)\\n        {\\n            int j = jrst * magic_RST; j >>= shift_RST;\\n            int rst = jrst - j * RST;\\n\\n            int t = rst * magic_RS; t >>= shift_RS;\\n            int rs = rst - t * RS;\\n\\n            int r = rs * magic_S; r >>= shift_S;\\n            int s = rs - r*S;\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(__ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            lut[jrst] = in_bounds ? sliceI : -1;\\n            jrst += 32;\\n        }\\n\\n        if(tid == 0)\\n        {\\n            //rcpWindowSize = 1.0f / (float)window_size;\\n            rcpWindowSize = (float)RST/(float)JRST;\\n        }\\n    }\\n    __syncthreads();\\n\\n    float out = 0.0f;\\n    float denom;\\n    float sumsquare = 0.0f;\\n    float input = 0.0f;\\n    int jrst = 0;\\n    while (jrst < JRST)\\n    {\\n        int slice0 = lut[jrst + 0];\\n        int slice1 = lut[jrst + 1];\\n        int slice2 = lut[jrst + 2];\\n        int slice3 = lut[jrst + 3];\\n\\n        // TODO: May not need to load all slices if they are not used.\\n        input =      jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : 0.0f;\\n        sumsquare += jrst + 0 < JRST && slice0 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : 0.0f;\\n        sumsquare += jrst + 1 < JRST && slice1 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : 0.0f;\\n        sumsquare += jrst + 2 < JRST && slice2 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : 0.0f;\\n        sumsquare += jrst + 3 < JRST && slice3 >= 0 ? input * input: 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    denom = (1 + ascale*sumsquare*rcpWindowSize);\\n    out = %(cvt)s(__ldg(IonO)) / powf(denom, bpower);\\n\\n\\n    // convert back to fp to write out\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n\\n    // predicate write with no-op flag\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n        *A = %(cvt_out)s( %(mul_by_scale)s denom );  // write the denomiantor to address\\n    }\\n\\n    // collect max abs stats\\n    int intermediate_max = max_abs(0, temp_out); // compute abs\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_fprop_lrn')\n    kernel.prepare('3P 4f 34I 10I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
        "mutated": [
            "@context_dependent_memoize\ndef _get_fprop_lrn(clss, compute_capability):\n    if False:\n        i = 10\n    \"\\n    Local Response Normalization (LRN) layer.\\n    Implementation based on fprop_avg kernel.\\n\\n    Implements the following operation:\\n    for each output pixel\\n        x' = x / response\\n    where the response is\\n        response = [1 + alpha/N * sum_neighbors x_neighbor**2 ]**beta\\n    so we compute the pooling output\\n    \"\n    code = \"\\n%(common)s\\n\\n__global__ void spool_fprop_lrn(\\n    const %(type)s* I, %(type)s* O, %(type)s* A,\\n    float alpha, float beta, float ascale, float bpower, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize;\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    // paralellism is over QMPK dimensions (output pixels and ofm's)\\n    int n  = tid;\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*P;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = Q - q - 1;\\n\\n    const %(type)s* IonO = I;  // input pixel at output location\\n    I += n;\\n    IonO += k*MPQN + m*PQN + p*QN + q*N + n;\\n    O += k*MPQN + m*PQN + p*QN + q*N + n;\\n    A += k*MPQN + m*PQN + p*QN + q*N + n;\\n\\n    float O_val = beta != 0.0f ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int window_size = 0;\\n        int jrst = tid;\\n        // this loop generates the LUT (same for pooling and normalization)\\n        while (jrst < JRST)\\n        {\\n            int j = jrst * magic_RST; j >>= shift_RST;\\n            int rst = jrst - j * RST;\\n\\n            int t = rst * magic_RS; t >>= shift_RS;\\n            int rs = rst - t * RS;\\n\\n            int r = rs * magic_S; r >>= shift_S;\\n            int s = rs - r*S;\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(__ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            lut[jrst] = in_bounds ? sliceI : -1;\\n            jrst += 32;\\n        }\\n\\n        if(tid == 0)\\n        {\\n            //rcpWindowSize = 1.0f / (float)window_size;\\n            rcpWindowSize = (float)RST/(float)JRST;\\n        }\\n    }\\n    __syncthreads();\\n\\n    float out = 0.0f;\\n    float denom;\\n    float sumsquare = 0.0f;\\n    float input = 0.0f;\\n    int jrst = 0;\\n    while (jrst < JRST)\\n    {\\n        int slice0 = lut[jrst + 0];\\n        int slice1 = lut[jrst + 1];\\n        int slice2 = lut[jrst + 2];\\n        int slice3 = lut[jrst + 3];\\n\\n        // TODO: May not need to load all slices if they are not used.\\n        input =      jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : 0.0f;\\n        sumsquare += jrst + 0 < JRST && slice0 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : 0.0f;\\n        sumsquare += jrst + 1 < JRST && slice1 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : 0.0f;\\n        sumsquare += jrst + 2 < JRST && slice2 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : 0.0f;\\n        sumsquare += jrst + 3 < JRST && slice3 >= 0 ? input * input: 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    denom = (1 + ascale*sumsquare*rcpWindowSize);\\n    out = %(cvt)s(__ldg(IonO)) / powf(denom, bpower);\\n\\n\\n    // convert back to fp to write out\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n\\n    // predicate write with no-op flag\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n        *A = %(cvt_out)s( %(mul_by_scale)s denom );  // write the denomiantor to address\\n    }\\n\\n    // collect max abs stats\\n    int intermediate_max = max_abs(0, temp_out); // compute abs\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_fprop_lrn')\n    kernel.prepare('3P 4f 34I 10I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_fprop_lrn(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Local Response Normalization (LRN) layer.\\n    Implementation based on fprop_avg kernel.\\n\\n    Implements the following operation:\\n    for each output pixel\\n        x' = x / response\\n    where the response is\\n        response = [1 + alpha/N * sum_neighbors x_neighbor**2 ]**beta\\n    so we compute the pooling output\\n    \"\n    code = \"\\n%(common)s\\n\\n__global__ void spool_fprop_lrn(\\n    const %(type)s* I, %(type)s* O, %(type)s* A,\\n    float alpha, float beta, float ascale, float bpower, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize;\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    // paralellism is over QMPK dimensions (output pixels and ofm's)\\n    int n  = tid;\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*P;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = Q - q - 1;\\n\\n    const %(type)s* IonO = I;  // input pixel at output location\\n    I += n;\\n    IonO += k*MPQN + m*PQN + p*QN + q*N + n;\\n    O += k*MPQN + m*PQN + p*QN + q*N + n;\\n    A += k*MPQN + m*PQN + p*QN + q*N + n;\\n\\n    float O_val = beta != 0.0f ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int window_size = 0;\\n        int jrst = tid;\\n        // this loop generates the LUT (same for pooling and normalization)\\n        while (jrst < JRST)\\n        {\\n            int j = jrst * magic_RST; j >>= shift_RST;\\n            int rst = jrst - j * RST;\\n\\n            int t = rst * magic_RS; t >>= shift_RS;\\n            int rs = rst - t * RS;\\n\\n            int r = rs * magic_S; r >>= shift_S;\\n            int s = rs - r*S;\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(__ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            lut[jrst] = in_bounds ? sliceI : -1;\\n            jrst += 32;\\n        }\\n\\n        if(tid == 0)\\n        {\\n            //rcpWindowSize = 1.0f / (float)window_size;\\n            rcpWindowSize = (float)RST/(float)JRST;\\n        }\\n    }\\n    __syncthreads();\\n\\n    float out = 0.0f;\\n    float denom;\\n    float sumsquare = 0.0f;\\n    float input = 0.0f;\\n    int jrst = 0;\\n    while (jrst < JRST)\\n    {\\n        int slice0 = lut[jrst + 0];\\n        int slice1 = lut[jrst + 1];\\n        int slice2 = lut[jrst + 2];\\n        int slice3 = lut[jrst + 3];\\n\\n        // TODO: May not need to load all slices if they are not used.\\n        input =      jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : 0.0f;\\n        sumsquare += jrst + 0 < JRST && slice0 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : 0.0f;\\n        sumsquare += jrst + 1 < JRST && slice1 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : 0.0f;\\n        sumsquare += jrst + 2 < JRST && slice2 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : 0.0f;\\n        sumsquare += jrst + 3 < JRST && slice3 >= 0 ? input * input: 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    denom = (1 + ascale*sumsquare*rcpWindowSize);\\n    out = %(cvt)s(__ldg(IonO)) / powf(denom, bpower);\\n\\n\\n    // convert back to fp to write out\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n\\n    // predicate write with no-op flag\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n        *A = %(cvt_out)s( %(mul_by_scale)s denom );  // write the denomiantor to address\\n    }\\n\\n    // collect max abs stats\\n    int intermediate_max = max_abs(0, temp_out); // compute abs\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_fprop_lrn')\n    kernel.prepare('3P 4f 34I 10I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_fprop_lrn(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Local Response Normalization (LRN) layer.\\n    Implementation based on fprop_avg kernel.\\n\\n    Implements the following operation:\\n    for each output pixel\\n        x' = x / response\\n    where the response is\\n        response = [1 + alpha/N * sum_neighbors x_neighbor**2 ]**beta\\n    so we compute the pooling output\\n    \"\n    code = \"\\n%(common)s\\n\\n__global__ void spool_fprop_lrn(\\n    const %(type)s* I, %(type)s* O, %(type)s* A,\\n    float alpha, float beta, float ascale, float bpower, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize;\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    // paralellism is over QMPK dimensions (output pixels and ofm's)\\n    int n  = tid;\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*P;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = Q - q - 1;\\n\\n    const %(type)s* IonO = I;  // input pixel at output location\\n    I += n;\\n    IonO += k*MPQN + m*PQN + p*QN + q*N + n;\\n    O += k*MPQN + m*PQN + p*QN + q*N + n;\\n    A += k*MPQN + m*PQN + p*QN + q*N + n;\\n\\n    float O_val = beta != 0.0f ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int window_size = 0;\\n        int jrst = tid;\\n        // this loop generates the LUT (same for pooling and normalization)\\n        while (jrst < JRST)\\n        {\\n            int j = jrst * magic_RST; j >>= shift_RST;\\n            int rst = jrst - j * RST;\\n\\n            int t = rst * magic_RS; t >>= shift_RS;\\n            int rs = rst - t * RS;\\n\\n            int r = rs * magic_S; r >>= shift_S;\\n            int s = rs - r*S;\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(__ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            lut[jrst] = in_bounds ? sliceI : -1;\\n            jrst += 32;\\n        }\\n\\n        if(tid == 0)\\n        {\\n            //rcpWindowSize = 1.0f / (float)window_size;\\n            rcpWindowSize = (float)RST/(float)JRST;\\n        }\\n    }\\n    __syncthreads();\\n\\n    float out = 0.0f;\\n    float denom;\\n    float sumsquare = 0.0f;\\n    float input = 0.0f;\\n    int jrst = 0;\\n    while (jrst < JRST)\\n    {\\n        int slice0 = lut[jrst + 0];\\n        int slice1 = lut[jrst + 1];\\n        int slice2 = lut[jrst + 2];\\n        int slice3 = lut[jrst + 3];\\n\\n        // TODO: May not need to load all slices if they are not used.\\n        input =      jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : 0.0f;\\n        sumsquare += jrst + 0 < JRST && slice0 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : 0.0f;\\n        sumsquare += jrst + 1 < JRST && slice1 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : 0.0f;\\n        sumsquare += jrst + 2 < JRST && slice2 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : 0.0f;\\n        sumsquare += jrst + 3 < JRST && slice3 >= 0 ? input * input: 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    denom = (1 + ascale*sumsquare*rcpWindowSize);\\n    out = %(cvt)s(__ldg(IonO)) / powf(denom, bpower);\\n\\n\\n    // convert back to fp to write out\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n\\n    // predicate write with no-op flag\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n        *A = %(cvt_out)s( %(mul_by_scale)s denom );  // write the denomiantor to address\\n    }\\n\\n    // collect max abs stats\\n    int intermediate_max = max_abs(0, temp_out); // compute abs\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_fprop_lrn')\n    kernel.prepare('3P 4f 34I 10I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_fprop_lrn(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Local Response Normalization (LRN) layer.\\n    Implementation based on fprop_avg kernel.\\n\\n    Implements the following operation:\\n    for each output pixel\\n        x' = x / response\\n    where the response is\\n        response = [1 + alpha/N * sum_neighbors x_neighbor**2 ]**beta\\n    so we compute the pooling output\\n    \"\n    code = \"\\n%(common)s\\n\\n__global__ void spool_fprop_lrn(\\n    const %(type)s* I, %(type)s* O, %(type)s* A,\\n    float alpha, float beta, float ascale, float bpower, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize;\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    // paralellism is over QMPK dimensions (output pixels and ofm's)\\n    int n  = tid;\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*P;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = Q - q - 1;\\n\\n    const %(type)s* IonO = I;  // input pixel at output location\\n    I += n;\\n    IonO += k*MPQN + m*PQN + p*QN + q*N + n;\\n    O += k*MPQN + m*PQN + p*QN + q*N + n;\\n    A += k*MPQN + m*PQN + p*QN + q*N + n;\\n\\n    float O_val = beta != 0.0f ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int window_size = 0;\\n        int jrst = tid;\\n        // this loop generates the LUT (same for pooling and normalization)\\n        while (jrst < JRST)\\n        {\\n            int j = jrst * magic_RST; j >>= shift_RST;\\n            int rst = jrst - j * RST;\\n\\n            int t = rst * magic_RS; t >>= shift_RS;\\n            int rs = rst - t * RS;\\n\\n            int r = rs * magic_S; r >>= shift_S;\\n            int s = rs - r*S;\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(__ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            lut[jrst] = in_bounds ? sliceI : -1;\\n            jrst += 32;\\n        }\\n\\n        if(tid == 0)\\n        {\\n            //rcpWindowSize = 1.0f / (float)window_size;\\n            rcpWindowSize = (float)RST/(float)JRST;\\n        }\\n    }\\n    __syncthreads();\\n\\n    float out = 0.0f;\\n    float denom;\\n    float sumsquare = 0.0f;\\n    float input = 0.0f;\\n    int jrst = 0;\\n    while (jrst < JRST)\\n    {\\n        int slice0 = lut[jrst + 0];\\n        int slice1 = lut[jrst + 1];\\n        int slice2 = lut[jrst + 2];\\n        int slice3 = lut[jrst + 3];\\n\\n        // TODO: May not need to load all slices if they are not used.\\n        input =      jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : 0.0f;\\n        sumsquare += jrst + 0 < JRST && slice0 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : 0.0f;\\n        sumsquare += jrst + 1 < JRST && slice1 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : 0.0f;\\n        sumsquare += jrst + 2 < JRST && slice2 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : 0.0f;\\n        sumsquare += jrst + 3 < JRST && slice3 >= 0 ? input * input: 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    denom = (1 + ascale*sumsquare*rcpWindowSize);\\n    out = %(cvt)s(__ldg(IonO)) / powf(denom, bpower);\\n\\n\\n    // convert back to fp to write out\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n\\n    // predicate write with no-op flag\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n        *A = %(cvt_out)s( %(mul_by_scale)s denom );  // write the denomiantor to address\\n    }\\n\\n    // collect max abs stats\\n    int intermediate_max = max_abs(0, temp_out); // compute abs\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_fprop_lrn')\n    kernel.prepare('3P 4f 34I 10I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_fprop_lrn(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Local Response Normalization (LRN) layer.\\n    Implementation based on fprop_avg kernel.\\n\\n    Implements the following operation:\\n    for each output pixel\\n        x' = x / response\\n    where the response is\\n        response = [1 + alpha/N * sum_neighbors x_neighbor**2 ]**beta\\n    so we compute the pooling output\\n    \"\n    code = \"\\n%(common)s\\n\\n__global__ void spool_fprop_lrn(\\n    const %(type)s* I, %(type)s* O, %(type)s* A,\\n    float alpha, float beta, float ascale, float bpower, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize;\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    // paralellism is over QMPK dimensions (output pixels and ofm's)\\n    int n  = tid;\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*P;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = Q - q - 1;\\n\\n    const %(type)s* IonO = I;  // input pixel at output location\\n    I += n;\\n    IonO += k*MPQN + m*PQN + p*QN + q*N + n;\\n    O += k*MPQN + m*PQN + p*QN + q*N + n;\\n    A += k*MPQN + m*PQN + p*QN + q*N + n;\\n\\n    float O_val = beta != 0.0f ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int window_size = 0;\\n        int jrst = tid;\\n        // this loop generates the LUT (same for pooling and normalization)\\n        while (jrst < JRST)\\n        {\\n            int j = jrst * magic_RST; j >>= shift_RST;\\n            int rst = jrst - j * RST;\\n\\n            int t = rst * magic_RS; t >>= shift_RS;\\n            int rs = rst - t * RS;\\n\\n            int r = rs * magic_S; r >>= shift_S;\\n            int s = rs - r*S;\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(__ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            lut[jrst] = in_bounds ? sliceI : -1;\\n            jrst += 32;\\n        }\\n\\n        if(tid == 0)\\n        {\\n            //rcpWindowSize = 1.0f / (float)window_size;\\n            rcpWindowSize = (float)RST/(float)JRST;\\n        }\\n    }\\n    __syncthreads();\\n\\n    float out = 0.0f;\\n    float denom;\\n    float sumsquare = 0.0f;\\n    float input = 0.0f;\\n    int jrst = 0;\\n    while (jrst < JRST)\\n    {\\n        int slice0 = lut[jrst + 0];\\n        int slice1 = lut[jrst + 1];\\n        int slice2 = lut[jrst + 2];\\n        int slice3 = lut[jrst + 3];\\n\\n        // TODO: May not need to load all slices if they are not used.\\n        input =      jrst + 0 < JRST && slice0 >= 0 ? %(cvt)s(__ldg(I + slice0)) : 0.0f;\\n        sumsquare += jrst + 0 < JRST && slice0 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 1 < JRST && slice1 >= 0 ? %(cvt)s(__ldg(I + slice1)) : 0.0f;\\n        sumsquare += jrst + 1 < JRST && slice1 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 2 < JRST && slice2 >= 0 ? %(cvt)s(__ldg(I + slice2)) : 0.0f;\\n        sumsquare += jrst + 2 < JRST && slice2 >= 0 ? input * input: 0.0f;\\n        input =      jrst + 3 < JRST && slice3 >= 0 ? %(cvt)s(__ldg(I + slice3)) : 0.0f;\\n        sumsquare += jrst + 3 < JRST && slice3 >= 0 ? input * input: 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    denom = (1 + ascale*sumsquare*rcpWindowSize);\\n    out = %(cvt)s(__ldg(IonO)) / powf(denom, bpower);\\n\\n\\n    // convert back to fp to write out\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n\\n    // predicate write with no-op flag\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n        *A = %(cvt_out)s( %(mul_by_scale)s denom );  // write the denomiantor to address\\n    }\\n\\n    // collect max abs stats\\n    int intermediate_max = max_abs(0, temp_out); // compute abs\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_fprop_lrn')\n    kernel.prepare('3P 4f 34I 10I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel"
        ]
    },
    {
        "func_name": "_get_bprop_lrn_overlap",
        "original": "@context_dependent_memoize\ndef _get_bprop_lrn_overlap(clss, compute_capability):\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_lrn_overlap(\\n    const %(type)s* I, const %(type)s* O, const %(type)s* E, %(type)s* delta, const %(type)s* A,\\n    float alpha, float beta, float ascale, float bpower, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n    __shared__ float rcpWindowSize;\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    // O E A used inside JRST loop\\n    O += n;  // output\\n    E += n;  // error\\n    A += n;  // denom\\n\\n    // I E A used for output\\n    const %(type)s* E_out = E;\\n    const %(type)s* A_out = A;\\n    delta += c*DHWN + z*HWN + y*WN + x*N + n;\\n    I     += c*DHWN + z*HWN + y*WN + x*N + n;\\n    E_out += c*DHWN + z*HWN + y*WN + x*N;\\n    A_out += c*DHWN + z*HWN + y*WN + x*N;\\n\\n    float delta_val = (beta != 0.0f) ? %(cvt)s(__ldg(delta)) : 0.0f;\\n\\n    // build the lookup table\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j = jrst * magic_RST; j >>= shift_RST;\\n            int rst = jrst - j * RST;\\n\\n            int t = rst * magic_RS; t >>= shift_RS;\\n            int rs = rst - t * RS;\\n\\n            int r = rs * magic_S; r >>= shift_S;\\n            int s = rs - r*S;\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int k     = k_prime * magic_str_c; k >>= shift_str_c;\\n            int k_mod = k_prime - k*str_c;\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int m     = m_prime * magic_str_d; m >>= shift_str_d;\\n            int m_mod = m_prime - m*str_d;\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int p     = p_prime * magic_str_h; p >>= shift_str_h;\\n            int p_mod = p_prime - p*str_h;\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int q     = q_prime * magic_str_w; q >>= shift_str_w;\\n            int q_mod = q_prime - q*str_w;\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            int j_prime = c - k_prime + pad_c;\\n            int t_prime = z - m_prime + pad_d;\\n            int r_prime = y - p_prime + pad_h;\\n            int s_prime = x - q_prime + pad_w;\\n\\n            int sliceI  = k*MPQN + m*PQN + p*QN + q*N;\\n            int argmaxI = j_prime*RST + t_prime*RS + r_prime*S + s_prime;\\n\\n            LutEntry entry;\\n            entry.data.slice  = sliceI;\\n            entry.data.argmax = in_bounds ? argmaxI : -1;\\n\\n            lut[jrst] = entry.data2;\\n            jrst += 32;\\n        }\\n\\n        if(tid == 0)\\n        {\\n            rcpWindowSize = (float)RST/(float)JRST;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int jrst = 0;\\n    // float out = 0.0f;\\n    float array_delta = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < JRST)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        array_delta += (jrst + 0 < JRST && entry0.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry0.data.slice)) * %(cvt)s(__ldg(E + entry0.data.slice)) / %(cvt)s(__ldg(A + entry0.data.slice)) : 0.0f;\\n        array_delta += (jrst + 1 < JRST && entry1.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry1.data.slice)) * %(cvt)s(__ldg(E + entry1.data.slice)) / %(cvt)s(__ldg(A + entry1.data.slice)) : 0.0f;\\n        array_delta += (jrst + 2 < JRST && entry2.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry2.data.slice)) * %(cvt)s(__ldg(E + entry2.data.slice)) / %(cvt)s(__ldg(A + entry2.data.slice)) : 0.0f;\\n        array_delta += (jrst + 3 < JRST && entry3.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry3.data.slice)) * %(cvt)s(__ldg(E + entry3.data.slice)) / %(cvt)s(__ldg(A + entry3.data.slice)) : 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    array_delta = -2 * bpower * ascale * __ldg(I) * array_delta * rcpWindowSize + (__ldg(E_out) * powf(__ldg(A_out), -bpower));\\n\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (array_delta*alpha + delta_val*beta));\\n    if (!(flags & 1)) {\\n        *delta = temp_out;\\n    }\\n\\n    // compute max-abs\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_lrn_overlap')\n    kernel.prepare('5P 4f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
        "mutated": [
            "@context_dependent_memoize\ndef _get_bprop_lrn_overlap(clss, compute_capability):\n    if False:\n        i = 10\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_lrn_overlap(\\n    const %(type)s* I, const %(type)s* O, const %(type)s* E, %(type)s* delta, const %(type)s* A,\\n    float alpha, float beta, float ascale, float bpower, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n    __shared__ float rcpWindowSize;\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    // O E A used inside JRST loop\\n    O += n;  // output\\n    E += n;  // error\\n    A += n;  // denom\\n\\n    // I E A used for output\\n    const %(type)s* E_out = E;\\n    const %(type)s* A_out = A;\\n    delta += c*DHWN + z*HWN + y*WN + x*N + n;\\n    I     += c*DHWN + z*HWN + y*WN + x*N + n;\\n    E_out += c*DHWN + z*HWN + y*WN + x*N;\\n    A_out += c*DHWN + z*HWN + y*WN + x*N;\\n\\n    float delta_val = (beta != 0.0f) ? %(cvt)s(__ldg(delta)) : 0.0f;\\n\\n    // build the lookup table\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j = jrst * magic_RST; j >>= shift_RST;\\n            int rst = jrst - j * RST;\\n\\n            int t = rst * magic_RS; t >>= shift_RS;\\n            int rs = rst - t * RS;\\n\\n            int r = rs * magic_S; r >>= shift_S;\\n            int s = rs - r*S;\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int k     = k_prime * magic_str_c; k >>= shift_str_c;\\n            int k_mod = k_prime - k*str_c;\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int m     = m_prime * magic_str_d; m >>= shift_str_d;\\n            int m_mod = m_prime - m*str_d;\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int p     = p_prime * magic_str_h; p >>= shift_str_h;\\n            int p_mod = p_prime - p*str_h;\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int q     = q_prime * magic_str_w; q >>= shift_str_w;\\n            int q_mod = q_prime - q*str_w;\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            int j_prime = c - k_prime + pad_c;\\n            int t_prime = z - m_prime + pad_d;\\n            int r_prime = y - p_prime + pad_h;\\n            int s_prime = x - q_prime + pad_w;\\n\\n            int sliceI  = k*MPQN + m*PQN + p*QN + q*N;\\n            int argmaxI = j_prime*RST + t_prime*RS + r_prime*S + s_prime;\\n\\n            LutEntry entry;\\n            entry.data.slice  = sliceI;\\n            entry.data.argmax = in_bounds ? argmaxI : -1;\\n\\n            lut[jrst] = entry.data2;\\n            jrst += 32;\\n        }\\n\\n        if(tid == 0)\\n        {\\n            rcpWindowSize = (float)RST/(float)JRST;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int jrst = 0;\\n    // float out = 0.0f;\\n    float array_delta = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < JRST)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        array_delta += (jrst + 0 < JRST && entry0.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry0.data.slice)) * %(cvt)s(__ldg(E + entry0.data.slice)) / %(cvt)s(__ldg(A + entry0.data.slice)) : 0.0f;\\n        array_delta += (jrst + 1 < JRST && entry1.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry1.data.slice)) * %(cvt)s(__ldg(E + entry1.data.slice)) / %(cvt)s(__ldg(A + entry1.data.slice)) : 0.0f;\\n        array_delta += (jrst + 2 < JRST && entry2.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry2.data.slice)) * %(cvt)s(__ldg(E + entry2.data.slice)) / %(cvt)s(__ldg(A + entry2.data.slice)) : 0.0f;\\n        array_delta += (jrst + 3 < JRST && entry3.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry3.data.slice)) * %(cvt)s(__ldg(E + entry3.data.slice)) / %(cvt)s(__ldg(A + entry3.data.slice)) : 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    array_delta = -2 * bpower * ascale * __ldg(I) * array_delta * rcpWindowSize + (__ldg(E_out) * powf(__ldg(A_out), -bpower));\\n\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (array_delta*alpha + delta_val*beta));\\n    if (!(flags & 1)) {\\n        *delta = temp_out;\\n    }\\n\\n    // compute max-abs\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_lrn_overlap')\n    kernel.prepare('5P 4f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_lrn_overlap(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_lrn_overlap(\\n    const %(type)s* I, const %(type)s* O, const %(type)s* E, %(type)s* delta, const %(type)s* A,\\n    float alpha, float beta, float ascale, float bpower, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n    __shared__ float rcpWindowSize;\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    // O E A used inside JRST loop\\n    O += n;  // output\\n    E += n;  // error\\n    A += n;  // denom\\n\\n    // I E A used for output\\n    const %(type)s* E_out = E;\\n    const %(type)s* A_out = A;\\n    delta += c*DHWN + z*HWN + y*WN + x*N + n;\\n    I     += c*DHWN + z*HWN + y*WN + x*N + n;\\n    E_out += c*DHWN + z*HWN + y*WN + x*N;\\n    A_out += c*DHWN + z*HWN + y*WN + x*N;\\n\\n    float delta_val = (beta != 0.0f) ? %(cvt)s(__ldg(delta)) : 0.0f;\\n\\n    // build the lookup table\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j = jrst * magic_RST; j >>= shift_RST;\\n            int rst = jrst - j * RST;\\n\\n            int t = rst * magic_RS; t >>= shift_RS;\\n            int rs = rst - t * RS;\\n\\n            int r = rs * magic_S; r >>= shift_S;\\n            int s = rs - r*S;\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int k     = k_prime * magic_str_c; k >>= shift_str_c;\\n            int k_mod = k_prime - k*str_c;\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int m     = m_prime * magic_str_d; m >>= shift_str_d;\\n            int m_mod = m_prime - m*str_d;\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int p     = p_prime * magic_str_h; p >>= shift_str_h;\\n            int p_mod = p_prime - p*str_h;\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int q     = q_prime * magic_str_w; q >>= shift_str_w;\\n            int q_mod = q_prime - q*str_w;\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            int j_prime = c - k_prime + pad_c;\\n            int t_prime = z - m_prime + pad_d;\\n            int r_prime = y - p_prime + pad_h;\\n            int s_prime = x - q_prime + pad_w;\\n\\n            int sliceI  = k*MPQN + m*PQN + p*QN + q*N;\\n            int argmaxI = j_prime*RST + t_prime*RS + r_prime*S + s_prime;\\n\\n            LutEntry entry;\\n            entry.data.slice  = sliceI;\\n            entry.data.argmax = in_bounds ? argmaxI : -1;\\n\\n            lut[jrst] = entry.data2;\\n            jrst += 32;\\n        }\\n\\n        if(tid == 0)\\n        {\\n            rcpWindowSize = (float)RST/(float)JRST;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int jrst = 0;\\n    // float out = 0.0f;\\n    float array_delta = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < JRST)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        array_delta += (jrst + 0 < JRST && entry0.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry0.data.slice)) * %(cvt)s(__ldg(E + entry0.data.slice)) / %(cvt)s(__ldg(A + entry0.data.slice)) : 0.0f;\\n        array_delta += (jrst + 1 < JRST && entry1.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry1.data.slice)) * %(cvt)s(__ldg(E + entry1.data.slice)) / %(cvt)s(__ldg(A + entry1.data.slice)) : 0.0f;\\n        array_delta += (jrst + 2 < JRST && entry2.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry2.data.slice)) * %(cvt)s(__ldg(E + entry2.data.slice)) / %(cvt)s(__ldg(A + entry2.data.slice)) : 0.0f;\\n        array_delta += (jrst + 3 < JRST && entry3.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry3.data.slice)) * %(cvt)s(__ldg(E + entry3.data.slice)) / %(cvt)s(__ldg(A + entry3.data.slice)) : 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    array_delta = -2 * bpower * ascale * __ldg(I) * array_delta * rcpWindowSize + (__ldg(E_out) * powf(__ldg(A_out), -bpower));\\n\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (array_delta*alpha + delta_val*beta));\\n    if (!(flags & 1)) {\\n        *delta = temp_out;\\n    }\\n\\n    // compute max-abs\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_lrn_overlap')\n    kernel.prepare('5P 4f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_lrn_overlap(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_lrn_overlap(\\n    const %(type)s* I, const %(type)s* O, const %(type)s* E, %(type)s* delta, const %(type)s* A,\\n    float alpha, float beta, float ascale, float bpower, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n    __shared__ float rcpWindowSize;\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    // O E A used inside JRST loop\\n    O += n;  // output\\n    E += n;  // error\\n    A += n;  // denom\\n\\n    // I E A used for output\\n    const %(type)s* E_out = E;\\n    const %(type)s* A_out = A;\\n    delta += c*DHWN + z*HWN + y*WN + x*N + n;\\n    I     += c*DHWN + z*HWN + y*WN + x*N + n;\\n    E_out += c*DHWN + z*HWN + y*WN + x*N;\\n    A_out += c*DHWN + z*HWN + y*WN + x*N;\\n\\n    float delta_val = (beta != 0.0f) ? %(cvt)s(__ldg(delta)) : 0.0f;\\n\\n    // build the lookup table\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j = jrst * magic_RST; j >>= shift_RST;\\n            int rst = jrst - j * RST;\\n\\n            int t = rst * magic_RS; t >>= shift_RS;\\n            int rs = rst - t * RS;\\n\\n            int r = rs * magic_S; r >>= shift_S;\\n            int s = rs - r*S;\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int k     = k_prime * magic_str_c; k >>= shift_str_c;\\n            int k_mod = k_prime - k*str_c;\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int m     = m_prime * magic_str_d; m >>= shift_str_d;\\n            int m_mod = m_prime - m*str_d;\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int p     = p_prime * magic_str_h; p >>= shift_str_h;\\n            int p_mod = p_prime - p*str_h;\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int q     = q_prime * magic_str_w; q >>= shift_str_w;\\n            int q_mod = q_prime - q*str_w;\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            int j_prime = c - k_prime + pad_c;\\n            int t_prime = z - m_prime + pad_d;\\n            int r_prime = y - p_prime + pad_h;\\n            int s_prime = x - q_prime + pad_w;\\n\\n            int sliceI  = k*MPQN + m*PQN + p*QN + q*N;\\n            int argmaxI = j_prime*RST + t_prime*RS + r_prime*S + s_prime;\\n\\n            LutEntry entry;\\n            entry.data.slice  = sliceI;\\n            entry.data.argmax = in_bounds ? argmaxI : -1;\\n\\n            lut[jrst] = entry.data2;\\n            jrst += 32;\\n        }\\n\\n        if(tid == 0)\\n        {\\n            rcpWindowSize = (float)RST/(float)JRST;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int jrst = 0;\\n    // float out = 0.0f;\\n    float array_delta = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < JRST)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        array_delta += (jrst + 0 < JRST && entry0.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry0.data.slice)) * %(cvt)s(__ldg(E + entry0.data.slice)) / %(cvt)s(__ldg(A + entry0.data.slice)) : 0.0f;\\n        array_delta += (jrst + 1 < JRST && entry1.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry1.data.slice)) * %(cvt)s(__ldg(E + entry1.data.slice)) / %(cvt)s(__ldg(A + entry1.data.slice)) : 0.0f;\\n        array_delta += (jrst + 2 < JRST && entry2.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry2.data.slice)) * %(cvt)s(__ldg(E + entry2.data.slice)) / %(cvt)s(__ldg(A + entry2.data.slice)) : 0.0f;\\n        array_delta += (jrst + 3 < JRST && entry3.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry3.data.slice)) * %(cvt)s(__ldg(E + entry3.data.slice)) / %(cvt)s(__ldg(A + entry3.data.slice)) : 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    array_delta = -2 * bpower * ascale * __ldg(I) * array_delta * rcpWindowSize + (__ldg(E_out) * powf(__ldg(A_out), -bpower));\\n\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (array_delta*alpha + delta_val*beta));\\n    if (!(flags & 1)) {\\n        *delta = temp_out;\\n    }\\n\\n    // compute max-abs\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_lrn_overlap')\n    kernel.prepare('5P 4f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_lrn_overlap(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_lrn_overlap(\\n    const %(type)s* I, const %(type)s* O, const %(type)s* E, %(type)s* delta, const %(type)s* A,\\n    float alpha, float beta, float ascale, float bpower, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n    __shared__ float rcpWindowSize;\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    // O E A used inside JRST loop\\n    O += n;  // output\\n    E += n;  // error\\n    A += n;  // denom\\n\\n    // I E A used for output\\n    const %(type)s* E_out = E;\\n    const %(type)s* A_out = A;\\n    delta += c*DHWN + z*HWN + y*WN + x*N + n;\\n    I     += c*DHWN + z*HWN + y*WN + x*N + n;\\n    E_out += c*DHWN + z*HWN + y*WN + x*N;\\n    A_out += c*DHWN + z*HWN + y*WN + x*N;\\n\\n    float delta_val = (beta != 0.0f) ? %(cvt)s(__ldg(delta)) : 0.0f;\\n\\n    // build the lookup table\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j = jrst * magic_RST; j >>= shift_RST;\\n            int rst = jrst - j * RST;\\n\\n            int t = rst * magic_RS; t >>= shift_RS;\\n            int rs = rst - t * RS;\\n\\n            int r = rs * magic_S; r >>= shift_S;\\n            int s = rs - r*S;\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int k     = k_prime * magic_str_c; k >>= shift_str_c;\\n            int k_mod = k_prime - k*str_c;\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int m     = m_prime * magic_str_d; m >>= shift_str_d;\\n            int m_mod = m_prime - m*str_d;\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int p     = p_prime * magic_str_h; p >>= shift_str_h;\\n            int p_mod = p_prime - p*str_h;\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int q     = q_prime * magic_str_w; q >>= shift_str_w;\\n            int q_mod = q_prime - q*str_w;\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            int j_prime = c - k_prime + pad_c;\\n            int t_prime = z - m_prime + pad_d;\\n            int r_prime = y - p_prime + pad_h;\\n            int s_prime = x - q_prime + pad_w;\\n\\n            int sliceI  = k*MPQN + m*PQN + p*QN + q*N;\\n            int argmaxI = j_prime*RST + t_prime*RS + r_prime*S + s_prime;\\n\\n            LutEntry entry;\\n            entry.data.slice  = sliceI;\\n            entry.data.argmax = in_bounds ? argmaxI : -1;\\n\\n            lut[jrst] = entry.data2;\\n            jrst += 32;\\n        }\\n\\n        if(tid == 0)\\n        {\\n            rcpWindowSize = (float)RST/(float)JRST;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int jrst = 0;\\n    // float out = 0.0f;\\n    float array_delta = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < JRST)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        array_delta += (jrst + 0 < JRST && entry0.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry0.data.slice)) * %(cvt)s(__ldg(E + entry0.data.slice)) / %(cvt)s(__ldg(A + entry0.data.slice)) : 0.0f;\\n        array_delta += (jrst + 1 < JRST && entry1.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry1.data.slice)) * %(cvt)s(__ldg(E + entry1.data.slice)) / %(cvt)s(__ldg(A + entry1.data.slice)) : 0.0f;\\n        array_delta += (jrst + 2 < JRST && entry2.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry2.data.slice)) * %(cvt)s(__ldg(E + entry2.data.slice)) / %(cvt)s(__ldg(A + entry2.data.slice)) : 0.0f;\\n        array_delta += (jrst + 3 < JRST && entry3.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry3.data.slice)) * %(cvt)s(__ldg(E + entry3.data.slice)) / %(cvt)s(__ldg(A + entry3.data.slice)) : 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    array_delta = -2 * bpower * ascale * __ldg(I) * array_delta * rcpWindowSize + (__ldg(E_out) * powf(__ldg(A_out), -bpower));\\n\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (array_delta*alpha + delta_val*beta));\\n    if (!(flags & 1)) {\\n        *delta = temp_out;\\n    }\\n\\n    // compute max-abs\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_lrn_overlap')\n    kernel.prepare('5P 4f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_lrn_overlap(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_lrn_overlap(\\n    const %(type)s* I, const %(type)s* O, const %(type)s* E, %(type)s* delta, const %(type)s* A,\\n    float alpha, float beta, float ascale, float bpower, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n    __shared__ float rcpWindowSize;\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    // O E A used inside JRST loop\\n    O += n;  // output\\n    E += n;  // error\\n    A += n;  // denom\\n\\n    // I E A used for output\\n    const %(type)s* E_out = E;\\n    const %(type)s* A_out = A;\\n    delta += c*DHWN + z*HWN + y*WN + x*N + n;\\n    I     += c*DHWN + z*HWN + y*WN + x*N + n;\\n    E_out += c*DHWN + z*HWN + y*WN + x*N;\\n    A_out += c*DHWN + z*HWN + y*WN + x*N;\\n\\n    float delta_val = (beta != 0.0f) ? %(cvt)s(__ldg(delta)) : 0.0f;\\n\\n    // build the lookup table\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j = jrst * magic_RST; j >>= shift_RST;\\n            int rst = jrst - j * RST;\\n\\n            int t = rst * magic_RS; t >>= shift_RS;\\n            int rs = rst - t * RS;\\n\\n            int r = rs * magic_S; r >>= shift_S;\\n            int s = rs - r*S;\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int k     = k_prime * magic_str_c; k >>= shift_str_c;\\n            int k_mod = k_prime - k*str_c;\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int m     = m_prime * magic_str_d; m >>= shift_str_d;\\n            int m_mod = m_prime - m*str_d;\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int p     = p_prime * magic_str_h; p >>= shift_str_h;\\n            int p_mod = p_prime - p*str_h;\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int q     = q_prime * magic_str_w; q >>= shift_str_w;\\n            int q_mod = q_prime - q*str_w;\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            int j_prime = c - k_prime + pad_c;\\n            int t_prime = z - m_prime + pad_d;\\n            int r_prime = y - p_prime + pad_h;\\n            int s_prime = x - q_prime + pad_w;\\n\\n            int sliceI  = k*MPQN + m*PQN + p*QN + q*N;\\n            int argmaxI = j_prime*RST + t_prime*RS + r_prime*S + s_prime;\\n\\n            LutEntry entry;\\n            entry.data.slice  = sliceI;\\n            entry.data.argmax = in_bounds ? argmaxI : -1;\\n\\n            lut[jrst] = entry.data2;\\n            jrst += 32;\\n        }\\n\\n        if(tid == 0)\\n        {\\n            rcpWindowSize = (float)RST/(float)JRST;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int jrst = 0;\\n    // float out = 0.0f;\\n    float array_delta = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < JRST)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        array_delta += (jrst + 0 < JRST && entry0.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry0.data.slice)) * %(cvt)s(__ldg(E + entry0.data.slice)) / %(cvt)s(__ldg(A + entry0.data.slice)) : 0.0f;\\n        array_delta += (jrst + 1 < JRST && entry1.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry1.data.slice)) * %(cvt)s(__ldg(E + entry1.data.slice)) / %(cvt)s(__ldg(A + entry1.data.slice)) : 0.0f;\\n        array_delta += (jrst + 2 < JRST && entry2.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry2.data.slice)) * %(cvt)s(__ldg(E + entry2.data.slice)) / %(cvt)s(__ldg(A + entry2.data.slice)) : 0.0f;\\n        array_delta += (jrst + 3 < JRST && entry3.data.argmax >= 0) ? %(cvt)s(__ldg(O + entry3.data.slice)) * %(cvt)s(__ldg(E + entry3.data.slice)) / %(cvt)s(__ldg(A + entry3.data.slice)) : 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    array_delta = -2 * bpower * ascale * __ldg(I) * array_delta * rcpWindowSize + (__ldg(E_out) * powf(__ldg(A_out), -bpower));\\n\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (array_delta*alpha + delta_val*beta));\\n    if (!(flags & 1)) {\\n        *delta = temp_out;\\n    }\\n\\n    // compute max-abs\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_lrn_overlap')\n    kernel.prepare('5P 4f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel"
        ]
    },
    {
        "func_name": "_get_bprop_max",
        "original": "@context_dependent_memoize\ndef _get_bprop_max(clss, compute_capability):\n    code = \"\\n\\n%(common)s\\n\\n__global__ void spool_bprop_max(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    int offset = k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n    O += n;\\n    I += offset;\\n    A += offset;\\n\\n    float delta = 0.0f;\\n    int argmax  = -1;\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta  = %(cvt)s(__ldg(I));\\n        argmax = __ldg(A);\\n    }\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc = min(maskN + 1, 32);\\n\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta *= alpha;\\n        bool load_beta = beta != 0.0f;\\n        int jrst = 0;\\n\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int offset0 = lut[lut_offset + 0];\\n            int offset1 = lut[lut_offset + 1];\\n            int offset2 = lut[lut_offset + 2];\\n            int offset3 = lut[lut_offset + 3];\\n\\n            // need to figure out how to write into output. Can't be float * if we write fp16\\n            // load fp16 from O, so it's an fp16 pointer\\n            %(type)s* out0 = O + offset0;\\n            %(type)s* out1 = O + offset1;\\n            %(type)s* out2 = O + offset2;\\n            %(type)s* out3 = O + offset3;\\n\\n            bool valid0 = jrst + 0 < JRST && offset0 >= 0;\\n            bool valid1 = jrst + 1 < JRST && offset1 >= 0;\\n            bool valid2 = jrst + 2 < JRST && offset2 >= 0;\\n            bool valid3 = jrst + 3 < JRST && offset3 >= 0;\\n\\n            // load input dtype, convert to float32.\\n            float beta0 = valid0 && load_beta ? %(cvt)s(__ldg(out0)) * beta : 0.0f;\\n            float beta1 = valid1 && load_beta ? %(cvt)s(__ldg(out1)) * beta : 0.0f;\\n            float beta2 = valid2 && load_beta ? %(cvt)s(__ldg(out2)) * beta : 0.0f;\\n            float beta3 = valid3 && load_beta ? %(cvt)s(__ldg(out3)) * beta : 0.0f;\\n\\n            // convert float32 back into input format to write out\\n            %(type)s temp_out0 = valid0 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 0 == argmax ? delta + beta0 : beta0)) : 0.0f;\\n            %(type)s temp_out1 = valid1 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 1 == argmax ? delta + beta1 : beta1)) : 0.0f;\\n            %(type)s temp_out2 = valid2 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 2 == argmax ? delta + beta2 : beta2)) : 0.0f;\\n            %(type)s temp_out3 = valid3 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 3 == argmax ? delta + beta3 : beta3)) : 0.0f;\\n\\n            // predicate writes with no-op flag.\\n            if (!(flags & 1)) {\\n                if (valid0) *out0 = temp_out0;\\n                if (valid1) *out1 = temp_out1;\\n                if (valid2) *out2 = temp_out2;\\n                if (valid3) *out3 = temp_out3;\\n            }\\n            intermediate_max = max_abs(intermediate_max, temp_out0);\\n            intermediate_max = max_abs(intermediate_max, temp_out1);\\n            intermediate_max = max_abs(intermediate_max, temp_out2);\\n            intermediate_max = max_abs(intermediate_max, temp_out3);\\n\\n            jrst += 4;\\n        }\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
        "mutated": [
            "@context_dependent_memoize\ndef _get_bprop_max(clss, compute_capability):\n    if False:\n        i = 10\n    code = \"\\n\\n%(common)s\\n\\n__global__ void spool_bprop_max(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    int offset = k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n    O += n;\\n    I += offset;\\n    A += offset;\\n\\n    float delta = 0.0f;\\n    int argmax  = -1;\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta  = %(cvt)s(__ldg(I));\\n        argmax = __ldg(A);\\n    }\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc = min(maskN + 1, 32);\\n\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta *= alpha;\\n        bool load_beta = beta != 0.0f;\\n        int jrst = 0;\\n\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int offset0 = lut[lut_offset + 0];\\n            int offset1 = lut[lut_offset + 1];\\n            int offset2 = lut[lut_offset + 2];\\n            int offset3 = lut[lut_offset + 3];\\n\\n            // need to figure out how to write into output. Can't be float * if we write fp16\\n            // load fp16 from O, so it's an fp16 pointer\\n            %(type)s* out0 = O + offset0;\\n            %(type)s* out1 = O + offset1;\\n            %(type)s* out2 = O + offset2;\\n            %(type)s* out3 = O + offset3;\\n\\n            bool valid0 = jrst + 0 < JRST && offset0 >= 0;\\n            bool valid1 = jrst + 1 < JRST && offset1 >= 0;\\n            bool valid2 = jrst + 2 < JRST && offset2 >= 0;\\n            bool valid3 = jrst + 3 < JRST && offset3 >= 0;\\n\\n            // load input dtype, convert to float32.\\n            float beta0 = valid0 && load_beta ? %(cvt)s(__ldg(out0)) * beta : 0.0f;\\n            float beta1 = valid1 && load_beta ? %(cvt)s(__ldg(out1)) * beta : 0.0f;\\n            float beta2 = valid2 && load_beta ? %(cvt)s(__ldg(out2)) * beta : 0.0f;\\n            float beta3 = valid3 && load_beta ? %(cvt)s(__ldg(out3)) * beta : 0.0f;\\n\\n            // convert float32 back into input format to write out\\n            %(type)s temp_out0 = valid0 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 0 == argmax ? delta + beta0 : beta0)) : 0.0f;\\n            %(type)s temp_out1 = valid1 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 1 == argmax ? delta + beta1 : beta1)) : 0.0f;\\n            %(type)s temp_out2 = valid2 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 2 == argmax ? delta + beta2 : beta2)) : 0.0f;\\n            %(type)s temp_out3 = valid3 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 3 == argmax ? delta + beta3 : beta3)) : 0.0f;\\n\\n            // predicate writes with no-op flag.\\n            if (!(flags & 1)) {\\n                if (valid0) *out0 = temp_out0;\\n                if (valid1) *out1 = temp_out1;\\n                if (valid2) *out2 = temp_out2;\\n                if (valid3) *out3 = temp_out3;\\n            }\\n            intermediate_max = max_abs(intermediate_max, temp_out0);\\n            intermediate_max = max_abs(intermediate_max, temp_out1);\\n            intermediate_max = max_abs(intermediate_max, temp_out2);\\n            intermediate_max = max_abs(intermediate_max, temp_out3);\\n\\n            jrst += 4;\\n        }\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_max(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    code = \"\\n\\n%(common)s\\n\\n__global__ void spool_bprop_max(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    int offset = k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n    O += n;\\n    I += offset;\\n    A += offset;\\n\\n    float delta = 0.0f;\\n    int argmax  = -1;\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta  = %(cvt)s(__ldg(I));\\n        argmax = __ldg(A);\\n    }\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc = min(maskN + 1, 32);\\n\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta *= alpha;\\n        bool load_beta = beta != 0.0f;\\n        int jrst = 0;\\n\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int offset0 = lut[lut_offset + 0];\\n            int offset1 = lut[lut_offset + 1];\\n            int offset2 = lut[lut_offset + 2];\\n            int offset3 = lut[lut_offset + 3];\\n\\n            // need to figure out how to write into output. Can't be float * if we write fp16\\n            // load fp16 from O, so it's an fp16 pointer\\n            %(type)s* out0 = O + offset0;\\n            %(type)s* out1 = O + offset1;\\n            %(type)s* out2 = O + offset2;\\n            %(type)s* out3 = O + offset3;\\n\\n            bool valid0 = jrst + 0 < JRST && offset0 >= 0;\\n            bool valid1 = jrst + 1 < JRST && offset1 >= 0;\\n            bool valid2 = jrst + 2 < JRST && offset2 >= 0;\\n            bool valid3 = jrst + 3 < JRST && offset3 >= 0;\\n\\n            // load input dtype, convert to float32.\\n            float beta0 = valid0 && load_beta ? %(cvt)s(__ldg(out0)) * beta : 0.0f;\\n            float beta1 = valid1 && load_beta ? %(cvt)s(__ldg(out1)) * beta : 0.0f;\\n            float beta2 = valid2 && load_beta ? %(cvt)s(__ldg(out2)) * beta : 0.0f;\\n            float beta3 = valid3 && load_beta ? %(cvt)s(__ldg(out3)) * beta : 0.0f;\\n\\n            // convert float32 back into input format to write out\\n            %(type)s temp_out0 = valid0 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 0 == argmax ? delta + beta0 : beta0)) : 0.0f;\\n            %(type)s temp_out1 = valid1 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 1 == argmax ? delta + beta1 : beta1)) : 0.0f;\\n            %(type)s temp_out2 = valid2 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 2 == argmax ? delta + beta2 : beta2)) : 0.0f;\\n            %(type)s temp_out3 = valid3 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 3 == argmax ? delta + beta3 : beta3)) : 0.0f;\\n\\n            // predicate writes with no-op flag.\\n            if (!(flags & 1)) {\\n                if (valid0) *out0 = temp_out0;\\n                if (valid1) *out1 = temp_out1;\\n                if (valid2) *out2 = temp_out2;\\n                if (valid3) *out3 = temp_out3;\\n            }\\n            intermediate_max = max_abs(intermediate_max, temp_out0);\\n            intermediate_max = max_abs(intermediate_max, temp_out1);\\n            intermediate_max = max_abs(intermediate_max, temp_out2);\\n            intermediate_max = max_abs(intermediate_max, temp_out3);\\n\\n            jrst += 4;\\n        }\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_max(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    code = \"\\n\\n%(common)s\\n\\n__global__ void spool_bprop_max(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    int offset = k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n    O += n;\\n    I += offset;\\n    A += offset;\\n\\n    float delta = 0.0f;\\n    int argmax  = -1;\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta  = %(cvt)s(__ldg(I));\\n        argmax = __ldg(A);\\n    }\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc = min(maskN + 1, 32);\\n\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta *= alpha;\\n        bool load_beta = beta != 0.0f;\\n        int jrst = 0;\\n\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int offset0 = lut[lut_offset + 0];\\n            int offset1 = lut[lut_offset + 1];\\n            int offset2 = lut[lut_offset + 2];\\n            int offset3 = lut[lut_offset + 3];\\n\\n            // need to figure out how to write into output. Can't be float * if we write fp16\\n            // load fp16 from O, so it's an fp16 pointer\\n            %(type)s* out0 = O + offset0;\\n            %(type)s* out1 = O + offset1;\\n            %(type)s* out2 = O + offset2;\\n            %(type)s* out3 = O + offset3;\\n\\n            bool valid0 = jrst + 0 < JRST && offset0 >= 0;\\n            bool valid1 = jrst + 1 < JRST && offset1 >= 0;\\n            bool valid2 = jrst + 2 < JRST && offset2 >= 0;\\n            bool valid3 = jrst + 3 < JRST && offset3 >= 0;\\n\\n            // load input dtype, convert to float32.\\n            float beta0 = valid0 && load_beta ? %(cvt)s(__ldg(out0)) * beta : 0.0f;\\n            float beta1 = valid1 && load_beta ? %(cvt)s(__ldg(out1)) * beta : 0.0f;\\n            float beta2 = valid2 && load_beta ? %(cvt)s(__ldg(out2)) * beta : 0.0f;\\n            float beta3 = valid3 && load_beta ? %(cvt)s(__ldg(out3)) * beta : 0.0f;\\n\\n            // convert float32 back into input format to write out\\n            %(type)s temp_out0 = valid0 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 0 == argmax ? delta + beta0 : beta0)) : 0.0f;\\n            %(type)s temp_out1 = valid1 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 1 == argmax ? delta + beta1 : beta1)) : 0.0f;\\n            %(type)s temp_out2 = valid2 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 2 == argmax ? delta + beta2 : beta2)) : 0.0f;\\n            %(type)s temp_out3 = valid3 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 3 == argmax ? delta + beta3 : beta3)) : 0.0f;\\n\\n            // predicate writes with no-op flag.\\n            if (!(flags & 1)) {\\n                if (valid0) *out0 = temp_out0;\\n                if (valid1) *out1 = temp_out1;\\n                if (valid2) *out2 = temp_out2;\\n                if (valid3) *out3 = temp_out3;\\n            }\\n            intermediate_max = max_abs(intermediate_max, temp_out0);\\n            intermediate_max = max_abs(intermediate_max, temp_out1);\\n            intermediate_max = max_abs(intermediate_max, temp_out2);\\n            intermediate_max = max_abs(intermediate_max, temp_out3);\\n\\n            jrst += 4;\\n        }\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_max(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    code = \"\\n\\n%(common)s\\n\\n__global__ void spool_bprop_max(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    int offset = k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n    O += n;\\n    I += offset;\\n    A += offset;\\n\\n    float delta = 0.0f;\\n    int argmax  = -1;\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta  = %(cvt)s(__ldg(I));\\n        argmax = __ldg(A);\\n    }\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc = min(maskN + 1, 32);\\n\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta *= alpha;\\n        bool load_beta = beta != 0.0f;\\n        int jrst = 0;\\n\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int offset0 = lut[lut_offset + 0];\\n            int offset1 = lut[lut_offset + 1];\\n            int offset2 = lut[lut_offset + 2];\\n            int offset3 = lut[lut_offset + 3];\\n\\n            // need to figure out how to write into output. Can't be float * if we write fp16\\n            // load fp16 from O, so it's an fp16 pointer\\n            %(type)s* out0 = O + offset0;\\n            %(type)s* out1 = O + offset1;\\n            %(type)s* out2 = O + offset2;\\n            %(type)s* out3 = O + offset3;\\n\\n            bool valid0 = jrst + 0 < JRST && offset0 >= 0;\\n            bool valid1 = jrst + 1 < JRST && offset1 >= 0;\\n            bool valid2 = jrst + 2 < JRST && offset2 >= 0;\\n            bool valid3 = jrst + 3 < JRST && offset3 >= 0;\\n\\n            // load input dtype, convert to float32.\\n            float beta0 = valid0 && load_beta ? %(cvt)s(__ldg(out0)) * beta : 0.0f;\\n            float beta1 = valid1 && load_beta ? %(cvt)s(__ldg(out1)) * beta : 0.0f;\\n            float beta2 = valid2 && load_beta ? %(cvt)s(__ldg(out2)) * beta : 0.0f;\\n            float beta3 = valid3 && load_beta ? %(cvt)s(__ldg(out3)) * beta : 0.0f;\\n\\n            // convert float32 back into input format to write out\\n            %(type)s temp_out0 = valid0 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 0 == argmax ? delta + beta0 : beta0)) : 0.0f;\\n            %(type)s temp_out1 = valid1 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 1 == argmax ? delta + beta1 : beta1)) : 0.0f;\\n            %(type)s temp_out2 = valid2 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 2 == argmax ? delta + beta2 : beta2)) : 0.0f;\\n            %(type)s temp_out3 = valid3 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 3 == argmax ? delta + beta3 : beta3)) : 0.0f;\\n\\n            // predicate writes with no-op flag.\\n            if (!(flags & 1)) {\\n                if (valid0) *out0 = temp_out0;\\n                if (valid1) *out1 = temp_out1;\\n                if (valid2) *out2 = temp_out2;\\n                if (valid3) *out3 = temp_out3;\\n            }\\n            intermediate_max = max_abs(intermediate_max, temp_out0);\\n            intermediate_max = max_abs(intermediate_max, temp_out1);\\n            intermediate_max = max_abs(intermediate_max, temp_out2);\\n            intermediate_max = max_abs(intermediate_max, temp_out3);\\n\\n            jrst += 4;\\n        }\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_max(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    code = \"\\n\\n%(common)s\\n\\n__global__ void spool_bprop_max(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    int offset = k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n    O += n;\\n    I += offset;\\n    A += offset;\\n\\n    float delta = 0.0f;\\n    int argmax  = -1;\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta  = %(cvt)s(__ldg(I));\\n        argmax = __ldg(A);\\n    }\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc = min(maskN + 1, 32);\\n\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta *= alpha;\\n        bool load_beta = beta != 0.0f;\\n        int jrst = 0;\\n\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int offset0 = lut[lut_offset + 0];\\n            int offset1 = lut[lut_offset + 1];\\n            int offset2 = lut[lut_offset + 2];\\n            int offset3 = lut[lut_offset + 3];\\n\\n            // need to figure out how to write into output. Can't be float * if we write fp16\\n            // load fp16 from O, so it's an fp16 pointer\\n            %(type)s* out0 = O + offset0;\\n            %(type)s* out1 = O + offset1;\\n            %(type)s* out2 = O + offset2;\\n            %(type)s* out3 = O + offset3;\\n\\n            bool valid0 = jrst + 0 < JRST && offset0 >= 0;\\n            bool valid1 = jrst + 1 < JRST && offset1 >= 0;\\n            bool valid2 = jrst + 2 < JRST && offset2 >= 0;\\n            bool valid3 = jrst + 3 < JRST && offset3 >= 0;\\n\\n            // load input dtype, convert to float32.\\n            float beta0 = valid0 && load_beta ? %(cvt)s(__ldg(out0)) * beta : 0.0f;\\n            float beta1 = valid1 && load_beta ? %(cvt)s(__ldg(out1)) * beta : 0.0f;\\n            float beta2 = valid2 && load_beta ? %(cvt)s(__ldg(out2)) * beta : 0.0f;\\n            float beta3 = valid3 && load_beta ? %(cvt)s(__ldg(out3)) * beta : 0.0f;\\n\\n            // convert float32 back into input format to write out\\n            %(type)s temp_out0 = valid0 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 0 == argmax ? delta + beta0 : beta0)) : 0.0f;\\n            %(type)s temp_out1 = valid1 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 1 == argmax ? delta + beta1 : beta1)) : 0.0f;\\n            %(type)s temp_out2 = valid2 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 2 == argmax ? delta + beta2 : beta2)) : 0.0f;\\n            %(type)s temp_out3 = valid3 ? %(cvt_out)s(%(mul_by_scale)s(jrst + 3 == argmax ? delta + beta3 : beta3)) : 0.0f;\\n\\n            // predicate writes with no-op flag.\\n            if (!(flags & 1)) {\\n                if (valid0) *out0 = temp_out0;\\n                if (valid1) *out1 = temp_out1;\\n                if (valid2) *out2 = temp_out2;\\n                if (valid3) *out3 = temp_out3;\\n            }\\n            intermediate_max = max_abs(intermediate_max, temp_out0);\\n            intermediate_max = max_abs(intermediate_max, temp_out1);\\n            intermediate_max = max_abs(intermediate_max, temp_out2);\\n            intermediate_max = max_abs(intermediate_max, temp_out3);\\n\\n            jrst += 4;\\n        }\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n\"\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel"
        ]
    },
    {
        "func_name": "_get_bprop_avg",
        "original": "@context_dependent_memoize\ndef _get_bprop_avg(clss, compute_capability):\n    code = '\\n\\n%(common)s\\n\\n__global__ void spool_bprop_avg(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize[32];\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    O += n;\\n    I += k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n\\n    float delta = 0.0f;\\n    if (p < P && q < Q && n < N)\\n        delta  = %(cvt)s(__ldg(I));\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc    = min(maskN + 1, 32);\\n        int sbBits = 1 << min(shrN, 5);\\n        int sbMask = ~(-1 << sbBits) << mad16(sb, sbBits, 0);\\n\\n        int window_size = 0;\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(sbMask & __ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n        // TODO confirm kepler OK\\n        unsigned int shrN_mask = (shrN < 32) ? max(0, ((1 << shrN) - 1)) : 0xffffffff;\\n        if((tid & shrN_mask) == 0)\\n            rcpWindowSize[sb] = 1.0f / (float)window_size;\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta *= alpha * rcpWindowSize[sb];\\n        bool load_beta = beta != 0.0f;\\n        int jrst = 0;\\n\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int offset0 = lut[lut_offset + 0];\\n            int offset1 = lut[lut_offset + 1];\\n            int offset2 = lut[lut_offset + 2];\\n            int offset3 = lut[lut_offset + 3];\\n\\n            %(type)s* out0 = O + offset0;\\n            %(type)s* out1 = O + offset1;\\n            %(type)s* out2 = O + offset2;\\n            %(type)s* out3 = O + offset3;\\n\\n            bool valid0 = jrst + 0 < JRST && offset0 >= 0;\\n            bool valid1 = jrst + 1 < JRST && offset1 >= 0;\\n            bool valid2 = jrst + 2 < JRST && offset2 >= 0;\\n            bool valid3 = jrst + 3 < JRST && offset3 >= 0;\\n\\n            float beta0 = valid0 && load_beta ? %(cvt)s(__ldg(out0)) * beta : 0.0f;\\n            float beta1 = valid1 && load_beta ? %(cvt)s(__ldg(out1)) * beta : 0.0f;\\n            float beta2 = valid2 && load_beta ? %(cvt)s(__ldg(out2)) * beta : 0.0f;\\n            float beta3 = valid3 && load_beta ? %(cvt)s(__ldg(out3)) * beta : 0.0f;\\n\\n            %(type)s temp_out0 = valid0 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta0)) : 0.0f;\\n            %(type)s temp_out1 = valid1 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta1)) : 0.0f;\\n            %(type)s temp_out2 = valid2 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta2)) : 0.0f;\\n            %(type)s temp_out3 = valid3 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta3)) : 0.0f;\\n\\n            // predicate writes with no-op flag.\\n            if (!(flags & 1)) {\\n                if (valid0) *out0 = temp_out0;\\n                if (valid1) *out1 = temp_out1;\\n                if (valid2) *out2 = temp_out2;\\n                if (valid3) *out3 = temp_out3;\\n            }\\n            intermediate_max = max_abs(intermediate_max, temp_out0);\\n            intermediate_max = max_abs(intermediate_max, temp_out1);\\n            intermediate_max = max_abs(intermediate_max, temp_out2);\\n            intermediate_max = max_abs(intermediate_max, temp_out3);\\n\\n            jrst += 4;\\n        }\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
        "mutated": [
            "@context_dependent_memoize\ndef _get_bprop_avg(clss, compute_capability):\n    if False:\n        i = 10\n    code = '\\n\\n%(common)s\\n\\n__global__ void spool_bprop_avg(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize[32];\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    O += n;\\n    I += k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n\\n    float delta = 0.0f;\\n    if (p < P && q < Q && n < N)\\n        delta  = %(cvt)s(__ldg(I));\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc    = min(maskN + 1, 32);\\n        int sbBits = 1 << min(shrN, 5);\\n        int sbMask = ~(-1 << sbBits) << mad16(sb, sbBits, 0);\\n\\n        int window_size = 0;\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(sbMask & __ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n        // TODO confirm kepler OK\\n        unsigned int shrN_mask = (shrN < 32) ? max(0, ((1 << shrN) - 1)) : 0xffffffff;\\n        if((tid & shrN_mask) == 0)\\n            rcpWindowSize[sb] = 1.0f / (float)window_size;\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta *= alpha * rcpWindowSize[sb];\\n        bool load_beta = beta != 0.0f;\\n        int jrst = 0;\\n\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int offset0 = lut[lut_offset + 0];\\n            int offset1 = lut[lut_offset + 1];\\n            int offset2 = lut[lut_offset + 2];\\n            int offset3 = lut[lut_offset + 3];\\n\\n            %(type)s* out0 = O + offset0;\\n            %(type)s* out1 = O + offset1;\\n            %(type)s* out2 = O + offset2;\\n            %(type)s* out3 = O + offset3;\\n\\n            bool valid0 = jrst + 0 < JRST && offset0 >= 0;\\n            bool valid1 = jrst + 1 < JRST && offset1 >= 0;\\n            bool valid2 = jrst + 2 < JRST && offset2 >= 0;\\n            bool valid3 = jrst + 3 < JRST && offset3 >= 0;\\n\\n            float beta0 = valid0 && load_beta ? %(cvt)s(__ldg(out0)) * beta : 0.0f;\\n            float beta1 = valid1 && load_beta ? %(cvt)s(__ldg(out1)) * beta : 0.0f;\\n            float beta2 = valid2 && load_beta ? %(cvt)s(__ldg(out2)) * beta : 0.0f;\\n            float beta3 = valid3 && load_beta ? %(cvt)s(__ldg(out3)) * beta : 0.0f;\\n\\n            %(type)s temp_out0 = valid0 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta0)) : 0.0f;\\n            %(type)s temp_out1 = valid1 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta1)) : 0.0f;\\n            %(type)s temp_out2 = valid2 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta2)) : 0.0f;\\n            %(type)s temp_out3 = valid3 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta3)) : 0.0f;\\n\\n            // predicate writes with no-op flag.\\n            if (!(flags & 1)) {\\n                if (valid0) *out0 = temp_out0;\\n                if (valid1) *out1 = temp_out1;\\n                if (valid2) *out2 = temp_out2;\\n                if (valid3) *out3 = temp_out3;\\n            }\\n            intermediate_max = max_abs(intermediate_max, temp_out0);\\n            intermediate_max = max_abs(intermediate_max, temp_out1);\\n            intermediate_max = max_abs(intermediate_max, temp_out2);\\n            intermediate_max = max_abs(intermediate_max, temp_out3);\\n\\n            jrst += 4;\\n        }\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_avg(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    code = '\\n\\n%(common)s\\n\\n__global__ void spool_bprop_avg(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize[32];\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    O += n;\\n    I += k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n\\n    float delta = 0.0f;\\n    if (p < P && q < Q && n < N)\\n        delta  = %(cvt)s(__ldg(I));\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc    = min(maskN + 1, 32);\\n        int sbBits = 1 << min(shrN, 5);\\n        int sbMask = ~(-1 << sbBits) << mad16(sb, sbBits, 0);\\n\\n        int window_size = 0;\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(sbMask & __ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n        // TODO confirm kepler OK\\n        unsigned int shrN_mask = (shrN < 32) ? max(0, ((1 << shrN) - 1)) : 0xffffffff;\\n        if((tid & shrN_mask) == 0)\\n            rcpWindowSize[sb] = 1.0f / (float)window_size;\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta *= alpha * rcpWindowSize[sb];\\n        bool load_beta = beta != 0.0f;\\n        int jrst = 0;\\n\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int offset0 = lut[lut_offset + 0];\\n            int offset1 = lut[lut_offset + 1];\\n            int offset2 = lut[lut_offset + 2];\\n            int offset3 = lut[lut_offset + 3];\\n\\n            %(type)s* out0 = O + offset0;\\n            %(type)s* out1 = O + offset1;\\n            %(type)s* out2 = O + offset2;\\n            %(type)s* out3 = O + offset3;\\n\\n            bool valid0 = jrst + 0 < JRST && offset0 >= 0;\\n            bool valid1 = jrst + 1 < JRST && offset1 >= 0;\\n            bool valid2 = jrst + 2 < JRST && offset2 >= 0;\\n            bool valid3 = jrst + 3 < JRST && offset3 >= 0;\\n\\n            float beta0 = valid0 && load_beta ? %(cvt)s(__ldg(out0)) * beta : 0.0f;\\n            float beta1 = valid1 && load_beta ? %(cvt)s(__ldg(out1)) * beta : 0.0f;\\n            float beta2 = valid2 && load_beta ? %(cvt)s(__ldg(out2)) * beta : 0.0f;\\n            float beta3 = valid3 && load_beta ? %(cvt)s(__ldg(out3)) * beta : 0.0f;\\n\\n            %(type)s temp_out0 = valid0 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta0)) : 0.0f;\\n            %(type)s temp_out1 = valid1 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta1)) : 0.0f;\\n            %(type)s temp_out2 = valid2 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta2)) : 0.0f;\\n            %(type)s temp_out3 = valid3 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta3)) : 0.0f;\\n\\n            // predicate writes with no-op flag.\\n            if (!(flags & 1)) {\\n                if (valid0) *out0 = temp_out0;\\n                if (valid1) *out1 = temp_out1;\\n                if (valid2) *out2 = temp_out2;\\n                if (valid3) *out3 = temp_out3;\\n            }\\n            intermediate_max = max_abs(intermediate_max, temp_out0);\\n            intermediate_max = max_abs(intermediate_max, temp_out1);\\n            intermediate_max = max_abs(intermediate_max, temp_out2);\\n            intermediate_max = max_abs(intermediate_max, temp_out3);\\n\\n            jrst += 4;\\n        }\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_avg(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    code = '\\n\\n%(common)s\\n\\n__global__ void spool_bprop_avg(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize[32];\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    O += n;\\n    I += k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n\\n    float delta = 0.0f;\\n    if (p < P && q < Q && n < N)\\n        delta  = %(cvt)s(__ldg(I));\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc    = min(maskN + 1, 32);\\n        int sbBits = 1 << min(shrN, 5);\\n        int sbMask = ~(-1 << sbBits) << mad16(sb, sbBits, 0);\\n\\n        int window_size = 0;\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(sbMask & __ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n        // TODO confirm kepler OK\\n        unsigned int shrN_mask = (shrN < 32) ? max(0, ((1 << shrN) - 1)) : 0xffffffff;\\n        if((tid & shrN_mask) == 0)\\n            rcpWindowSize[sb] = 1.0f / (float)window_size;\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta *= alpha * rcpWindowSize[sb];\\n        bool load_beta = beta != 0.0f;\\n        int jrst = 0;\\n\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int offset0 = lut[lut_offset + 0];\\n            int offset1 = lut[lut_offset + 1];\\n            int offset2 = lut[lut_offset + 2];\\n            int offset3 = lut[lut_offset + 3];\\n\\n            %(type)s* out0 = O + offset0;\\n            %(type)s* out1 = O + offset1;\\n            %(type)s* out2 = O + offset2;\\n            %(type)s* out3 = O + offset3;\\n\\n            bool valid0 = jrst + 0 < JRST && offset0 >= 0;\\n            bool valid1 = jrst + 1 < JRST && offset1 >= 0;\\n            bool valid2 = jrst + 2 < JRST && offset2 >= 0;\\n            bool valid3 = jrst + 3 < JRST && offset3 >= 0;\\n\\n            float beta0 = valid0 && load_beta ? %(cvt)s(__ldg(out0)) * beta : 0.0f;\\n            float beta1 = valid1 && load_beta ? %(cvt)s(__ldg(out1)) * beta : 0.0f;\\n            float beta2 = valid2 && load_beta ? %(cvt)s(__ldg(out2)) * beta : 0.0f;\\n            float beta3 = valid3 && load_beta ? %(cvt)s(__ldg(out3)) * beta : 0.0f;\\n\\n            %(type)s temp_out0 = valid0 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta0)) : 0.0f;\\n            %(type)s temp_out1 = valid1 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta1)) : 0.0f;\\n            %(type)s temp_out2 = valid2 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta2)) : 0.0f;\\n            %(type)s temp_out3 = valid3 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta3)) : 0.0f;\\n\\n            // predicate writes with no-op flag.\\n            if (!(flags & 1)) {\\n                if (valid0) *out0 = temp_out0;\\n                if (valid1) *out1 = temp_out1;\\n                if (valid2) *out2 = temp_out2;\\n                if (valid3) *out3 = temp_out3;\\n            }\\n            intermediate_max = max_abs(intermediate_max, temp_out0);\\n            intermediate_max = max_abs(intermediate_max, temp_out1);\\n            intermediate_max = max_abs(intermediate_max, temp_out2);\\n            intermediate_max = max_abs(intermediate_max, temp_out3);\\n\\n            jrst += 4;\\n        }\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_avg(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    code = '\\n\\n%(common)s\\n\\n__global__ void spool_bprop_avg(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize[32];\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    O += n;\\n    I += k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n\\n    float delta = 0.0f;\\n    if (p < P && q < Q && n < N)\\n        delta  = %(cvt)s(__ldg(I));\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc    = min(maskN + 1, 32);\\n        int sbBits = 1 << min(shrN, 5);\\n        int sbMask = ~(-1 << sbBits) << mad16(sb, sbBits, 0);\\n\\n        int window_size = 0;\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(sbMask & __ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n        // TODO confirm kepler OK\\n        unsigned int shrN_mask = (shrN < 32) ? max(0, ((1 << shrN) - 1)) : 0xffffffff;\\n        if((tid & shrN_mask) == 0)\\n            rcpWindowSize[sb] = 1.0f / (float)window_size;\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta *= alpha * rcpWindowSize[sb];\\n        bool load_beta = beta != 0.0f;\\n        int jrst = 0;\\n\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int offset0 = lut[lut_offset + 0];\\n            int offset1 = lut[lut_offset + 1];\\n            int offset2 = lut[lut_offset + 2];\\n            int offset3 = lut[lut_offset + 3];\\n\\n            %(type)s* out0 = O + offset0;\\n            %(type)s* out1 = O + offset1;\\n            %(type)s* out2 = O + offset2;\\n            %(type)s* out3 = O + offset3;\\n\\n            bool valid0 = jrst + 0 < JRST && offset0 >= 0;\\n            bool valid1 = jrst + 1 < JRST && offset1 >= 0;\\n            bool valid2 = jrst + 2 < JRST && offset2 >= 0;\\n            bool valid3 = jrst + 3 < JRST && offset3 >= 0;\\n\\n            float beta0 = valid0 && load_beta ? %(cvt)s(__ldg(out0)) * beta : 0.0f;\\n            float beta1 = valid1 && load_beta ? %(cvt)s(__ldg(out1)) * beta : 0.0f;\\n            float beta2 = valid2 && load_beta ? %(cvt)s(__ldg(out2)) * beta : 0.0f;\\n            float beta3 = valid3 && load_beta ? %(cvt)s(__ldg(out3)) * beta : 0.0f;\\n\\n            %(type)s temp_out0 = valid0 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta0)) : 0.0f;\\n            %(type)s temp_out1 = valid1 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta1)) : 0.0f;\\n            %(type)s temp_out2 = valid2 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta2)) : 0.0f;\\n            %(type)s temp_out3 = valid3 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta3)) : 0.0f;\\n\\n            // predicate writes with no-op flag.\\n            if (!(flags & 1)) {\\n                if (valid0) *out0 = temp_out0;\\n                if (valid1) *out1 = temp_out1;\\n                if (valid2) *out2 = temp_out2;\\n                if (valid3) *out3 = temp_out3;\\n            }\\n            intermediate_max = max_abs(intermediate_max, temp_out0);\\n            intermediate_max = max_abs(intermediate_max, temp_out1);\\n            intermediate_max = max_abs(intermediate_max, temp_out2);\\n            intermediate_max = max_abs(intermediate_max, temp_out3);\\n\\n            jrst += 4;\\n        }\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_avg(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    code = '\\n\\n%(common)s\\n\\n__global__ void spool_bprop_avg(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN, int P, int Q,\\n    int magic_P, int shift_P, int QN, int PQN, int MPQN,\\n    int pad_c, int pad_d, int pad_h, int pad_w,\\n    int str_c, int str_d, int str_h, int str_w,\\n    int S, int RS, int RST, int JRST,\\n    int magic_S, int shift_S,\\n    int magic_RS, int shift_RS, int magic_RST, int shift_RST,\\n    int supP, int supQ, int shlP, int maskP, int shrP,\\n    int shlQ, int maskQ, int shrQ, int maskN, int shrN\\n    %(stats_args)s\\n    )\\n{\\n    __shared__ float rcpWindowSize[32];\\n    extern __shared__ int lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int q  = blockIdx.x;\\n    int mp = blockIdx.y;\\n    int k  = blockIdx.z;\\n\\n    int m = mp * magic_P; m >>= shift_P;\\n    int p = mp - m*supP;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (p & 1)\\n        q = supQ - q - 1;\\n\\n    // Superblock P and Q\\n    p = (p << shlP) + ((tid & maskP) >> shrP);\\n    q = (q << shlQ) + ((tid & maskQ) >> shrQ);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    O += n;\\n    I += k*MPQN + m*PQN + p*QN + mad16(q, N, n);\\n\\n    float delta = 0.0f;\\n    if (p < P && q < Q && n < N)\\n        delta  = %(cvt)s(__ldg(I));\\n\\n    if (tid < 32)\\n    {\\n        int kj = k * str_c - pad_c;\\n        int mt = m * str_d - pad_d;\\n        int pr = p * str_h - pad_h;\\n        int qs = q * str_w - pad_w;\\n\\n        int inc    = min(maskN + 1, 32);\\n        int sbBits = 1 << min(shrN, 5);\\n        int sbMask = ~(-1 << sbBits) << mad16(sb, sbBits, 0);\\n\\n        int window_size = 0;\\n        int jrst = n;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int x = qs + s;\\n            int y = pr + r;\\n            int z = mt + t;\\n            int c = kj + j;\\n\\n            bool bounds_x  = x >= 0 && x < W;\\n            bool bounds_y  = y >= 0 && y < H;\\n            bool bounds_z  = z >= 0 && z < D;\\n            bool bounds_c  = c >= 0 && c < C;\\n            bool in_bounds = bounds_x && bounds_y && bounds_z && bounds_c;\\n\\n            // Count the total valid slices\\n            window_size += __popc(sbMask & __ballot(in_bounds));\\n\\n            int sliceI  = c*DHWN + z*HWN + y*WN + x*N;\\n\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            lut[lut_offset] = in_bounds ? sliceI : -1;\\n            jrst += inc;\\n        }\\n        // TODO confirm kepler OK\\n        unsigned int shrN_mask = (shrN < 32) ? max(0, ((1 << shrN) - 1)) : 0xffffffff;\\n        if((tid & shrN_mask) == 0)\\n            rcpWindowSize[sb] = 1.0f / (float)window_size;\\n    }\\n    __syncthreads();\\n\\n    int intermediate_max = 0;\\n\\n    if (p < P && q < Q && n < N)\\n    {\\n        delta *= alpha * rcpWindowSize[sb];\\n        bool load_beta = beta != 0.0f;\\n        int jrst = 0;\\n\\n        while (jrst < JRST)\\n        {\\n            int lut_offset = mad16(sb, JRST, jrst);\\n\\n            int offset0 = lut[lut_offset + 0];\\n            int offset1 = lut[lut_offset + 1];\\n            int offset2 = lut[lut_offset + 2];\\n            int offset3 = lut[lut_offset + 3];\\n\\n            %(type)s* out0 = O + offset0;\\n            %(type)s* out1 = O + offset1;\\n            %(type)s* out2 = O + offset2;\\n            %(type)s* out3 = O + offset3;\\n\\n            bool valid0 = jrst + 0 < JRST && offset0 >= 0;\\n            bool valid1 = jrst + 1 < JRST && offset1 >= 0;\\n            bool valid2 = jrst + 2 < JRST && offset2 >= 0;\\n            bool valid3 = jrst + 3 < JRST && offset3 >= 0;\\n\\n            float beta0 = valid0 && load_beta ? %(cvt)s(__ldg(out0)) * beta : 0.0f;\\n            float beta1 = valid1 && load_beta ? %(cvt)s(__ldg(out1)) * beta : 0.0f;\\n            float beta2 = valid2 && load_beta ? %(cvt)s(__ldg(out2)) * beta : 0.0f;\\n            float beta3 = valid3 && load_beta ? %(cvt)s(__ldg(out3)) * beta : 0.0f;\\n\\n            %(type)s temp_out0 = valid0 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta0)) : 0.0f;\\n            %(type)s temp_out1 = valid1 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta1)) : 0.0f;\\n            %(type)s temp_out2 = valid2 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta2)) : 0.0f;\\n            %(type)s temp_out3 = valid3 ? %(cvt_out)s(%(mul_by_scale)s(delta + beta3)) : 0.0f;\\n\\n            // predicate writes with no-op flag.\\n            if (!(flags & 1)) {\\n                if (valid0) *out0 = temp_out0;\\n                if (valid1) *out1 = temp_out1;\\n                if (valid2) *out2 = temp_out2;\\n                if (valid3) *out3 = temp_out3;\\n            }\\n            intermediate_max = max_abs(intermediate_max, temp_out0);\\n            intermediate_max = max_abs(intermediate_max, temp_out1);\\n            intermediate_max = max_abs(intermediate_max, temp_out2);\\n            intermediate_max = max_abs(intermediate_max, temp_out3);\\n\\n            jrst += 4;\\n        }\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg')\n    kernel.prepare('3P 2f 44I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel"
        ]
    },
    {
        "func_name": "_get_bprop_max_overlap",
        "original": "@context_dependent_memoize\ndef _get_bprop_max_overlap(clss, compute_capability):\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_max_overlap(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    int __shared__ lutSize;\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    I += n;\\n    A += n;\\n    O += c*DHWN + z*HWN + y*WN + x*N + n;\\n\\n    float O_val = (beta != 0.0f) ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int lut_size;\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        unsigned dep_thd_mask = 0xffffffff;\\n        dep_thd_mask >>= 32 - tid;\\n\\n        lut_size = 0;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n            int  k_mod    = mod16(k_prime, k, str_c);\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n            int  m_mod    = mod16(m_prime, m, str_d);\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n            int  p_mod    = mod16(p_prime, p, str_h);\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n            int  q_mod    = mod16(q_prime, q, str_w);\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            // Get a mask of all valid slices in the warp\\n            unsigned ballot = __ballot(in_bounds);\\n\\n            // Count the total valid slices\\n            unsigned warp_slices = __popc(ballot);\\n\\n            if (in_bounds)\\n            {\\n                // Count all the valid slices below this threadid\\n                unsigned dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n                int j_prime = c - k_prime + pad_c;\\n                int t_prime = z - m_prime + pad_d;\\n                int r_prime = y - p_prime + pad_h;\\n                int s_prime = x - q_prime + pad_w;\\n\\n                LutEntry entry;\\n                entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n                entry.data.argmax = j_prime*RST + mad16(t_prime, RS, mad16(r_prime, S, s_prime));\\n\\n                lut[lut_size + dep_thd_cnt] = entry.data2;\\n            }\\n            lut_size += warp_slices;\\n            jrst += 32;\\n        }\\n        if(tid == 0)\\n            lutSize = lut_size;\\n    }\\n    __syncthreads();\\n\\n    lut_size = lutSize;\\n\\n    int jrst = 0;\\n    float out = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < lut_size)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        // argmax\\n        int fprop_argmax0 = jrst + 0 < lut_size ? __ldg(A + entry0.data.slice) : -2;\\n        int fprop_argmax1 = jrst + 1 < lut_size ? __ldg(A + entry1.data.slice) : -2;\\n        int fprop_argmax2 = jrst + 2 < lut_size ? __ldg(A + entry2.data.slice) : -2;\\n        int fprop_argmax3 = jrst + 3 < lut_size ? __ldg(A + entry3.data.slice) : -2;\\n\\n        out += jrst + 0 < lut_size && fprop_argmax0 == entry0.data.argmax ? %(cvt)s(__ldg(I + entry0.data.slice)) : 0.0f;\\n        out += jrst + 1 < lut_size && fprop_argmax1 == entry1.data.argmax ? %(cvt)s(__ldg(I + entry1.data.slice)) : 0.0f;\\n        out += jrst + 2 < lut_size && fprop_argmax2 == entry2.data.argmax ? %(cvt)s(__ldg(I + entry2.data.slice)) : 0.0f;\\n        out += jrst + 3 < lut_size && fprop_argmax3 == entry3.data.argmax ? %(cvt)s(__ldg(I + entry3.data.slice)) : 0.0f;\\n\\n        jrst += 4;\\n    }\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n    }\\n    // compute max-abs\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max_overlap')\n    kernel.prepare('3P 2f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
        "mutated": [
            "@context_dependent_memoize\ndef _get_bprop_max_overlap(clss, compute_capability):\n    if False:\n        i = 10\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_max_overlap(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    int __shared__ lutSize;\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    I += n;\\n    A += n;\\n    O += c*DHWN + z*HWN + y*WN + x*N + n;\\n\\n    float O_val = (beta != 0.0f) ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int lut_size;\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        unsigned dep_thd_mask = 0xffffffff;\\n        dep_thd_mask >>= 32 - tid;\\n\\n        lut_size = 0;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n            int  k_mod    = mod16(k_prime, k, str_c);\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n            int  m_mod    = mod16(m_prime, m, str_d);\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n            int  p_mod    = mod16(p_prime, p, str_h);\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n            int  q_mod    = mod16(q_prime, q, str_w);\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            // Get a mask of all valid slices in the warp\\n            unsigned ballot = __ballot(in_bounds);\\n\\n            // Count the total valid slices\\n            unsigned warp_slices = __popc(ballot);\\n\\n            if (in_bounds)\\n            {\\n                // Count all the valid slices below this threadid\\n                unsigned dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n                int j_prime = c - k_prime + pad_c;\\n                int t_prime = z - m_prime + pad_d;\\n                int r_prime = y - p_prime + pad_h;\\n                int s_prime = x - q_prime + pad_w;\\n\\n                LutEntry entry;\\n                entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n                entry.data.argmax = j_prime*RST + mad16(t_prime, RS, mad16(r_prime, S, s_prime));\\n\\n                lut[lut_size + dep_thd_cnt] = entry.data2;\\n            }\\n            lut_size += warp_slices;\\n            jrst += 32;\\n        }\\n        if(tid == 0)\\n            lutSize = lut_size;\\n    }\\n    __syncthreads();\\n\\n    lut_size = lutSize;\\n\\n    int jrst = 0;\\n    float out = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < lut_size)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        // argmax\\n        int fprop_argmax0 = jrst + 0 < lut_size ? __ldg(A + entry0.data.slice) : -2;\\n        int fprop_argmax1 = jrst + 1 < lut_size ? __ldg(A + entry1.data.slice) : -2;\\n        int fprop_argmax2 = jrst + 2 < lut_size ? __ldg(A + entry2.data.slice) : -2;\\n        int fprop_argmax3 = jrst + 3 < lut_size ? __ldg(A + entry3.data.slice) : -2;\\n\\n        out += jrst + 0 < lut_size && fprop_argmax0 == entry0.data.argmax ? %(cvt)s(__ldg(I + entry0.data.slice)) : 0.0f;\\n        out += jrst + 1 < lut_size && fprop_argmax1 == entry1.data.argmax ? %(cvt)s(__ldg(I + entry1.data.slice)) : 0.0f;\\n        out += jrst + 2 < lut_size && fprop_argmax2 == entry2.data.argmax ? %(cvt)s(__ldg(I + entry2.data.slice)) : 0.0f;\\n        out += jrst + 3 < lut_size && fprop_argmax3 == entry3.data.argmax ? %(cvt)s(__ldg(I + entry3.data.slice)) : 0.0f;\\n\\n        jrst += 4;\\n    }\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n    }\\n    // compute max-abs\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max_overlap')\n    kernel.prepare('3P 2f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_max_overlap(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_max_overlap(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    int __shared__ lutSize;\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    I += n;\\n    A += n;\\n    O += c*DHWN + z*HWN + y*WN + x*N + n;\\n\\n    float O_val = (beta != 0.0f) ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int lut_size;\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        unsigned dep_thd_mask = 0xffffffff;\\n        dep_thd_mask >>= 32 - tid;\\n\\n        lut_size = 0;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n            int  k_mod    = mod16(k_prime, k, str_c);\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n            int  m_mod    = mod16(m_prime, m, str_d);\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n            int  p_mod    = mod16(p_prime, p, str_h);\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n            int  q_mod    = mod16(q_prime, q, str_w);\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            // Get a mask of all valid slices in the warp\\n            unsigned ballot = __ballot(in_bounds);\\n\\n            // Count the total valid slices\\n            unsigned warp_slices = __popc(ballot);\\n\\n            if (in_bounds)\\n            {\\n                // Count all the valid slices below this threadid\\n                unsigned dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n                int j_prime = c - k_prime + pad_c;\\n                int t_prime = z - m_prime + pad_d;\\n                int r_prime = y - p_prime + pad_h;\\n                int s_prime = x - q_prime + pad_w;\\n\\n                LutEntry entry;\\n                entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n                entry.data.argmax = j_prime*RST + mad16(t_prime, RS, mad16(r_prime, S, s_prime));\\n\\n                lut[lut_size + dep_thd_cnt] = entry.data2;\\n            }\\n            lut_size += warp_slices;\\n            jrst += 32;\\n        }\\n        if(tid == 0)\\n            lutSize = lut_size;\\n    }\\n    __syncthreads();\\n\\n    lut_size = lutSize;\\n\\n    int jrst = 0;\\n    float out = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < lut_size)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        // argmax\\n        int fprop_argmax0 = jrst + 0 < lut_size ? __ldg(A + entry0.data.slice) : -2;\\n        int fprop_argmax1 = jrst + 1 < lut_size ? __ldg(A + entry1.data.slice) : -2;\\n        int fprop_argmax2 = jrst + 2 < lut_size ? __ldg(A + entry2.data.slice) : -2;\\n        int fprop_argmax3 = jrst + 3 < lut_size ? __ldg(A + entry3.data.slice) : -2;\\n\\n        out += jrst + 0 < lut_size && fprop_argmax0 == entry0.data.argmax ? %(cvt)s(__ldg(I + entry0.data.slice)) : 0.0f;\\n        out += jrst + 1 < lut_size && fprop_argmax1 == entry1.data.argmax ? %(cvt)s(__ldg(I + entry1.data.slice)) : 0.0f;\\n        out += jrst + 2 < lut_size && fprop_argmax2 == entry2.data.argmax ? %(cvt)s(__ldg(I + entry2.data.slice)) : 0.0f;\\n        out += jrst + 3 < lut_size && fprop_argmax3 == entry3.data.argmax ? %(cvt)s(__ldg(I + entry3.data.slice)) : 0.0f;\\n\\n        jrst += 4;\\n    }\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n    }\\n    // compute max-abs\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max_overlap')\n    kernel.prepare('3P 2f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_max_overlap(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_max_overlap(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    int __shared__ lutSize;\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    I += n;\\n    A += n;\\n    O += c*DHWN + z*HWN + y*WN + x*N + n;\\n\\n    float O_val = (beta != 0.0f) ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int lut_size;\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        unsigned dep_thd_mask = 0xffffffff;\\n        dep_thd_mask >>= 32 - tid;\\n\\n        lut_size = 0;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n            int  k_mod    = mod16(k_prime, k, str_c);\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n            int  m_mod    = mod16(m_prime, m, str_d);\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n            int  p_mod    = mod16(p_prime, p, str_h);\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n            int  q_mod    = mod16(q_prime, q, str_w);\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            // Get a mask of all valid slices in the warp\\n            unsigned ballot = __ballot(in_bounds);\\n\\n            // Count the total valid slices\\n            unsigned warp_slices = __popc(ballot);\\n\\n            if (in_bounds)\\n            {\\n                // Count all the valid slices below this threadid\\n                unsigned dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n                int j_prime = c - k_prime + pad_c;\\n                int t_prime = z - m_prime + pad_d;\\n                int r_prime = y - p_prime + pad_h;\\n                int s_prime = x - q_prime + pad_w;\\n\\n                LutEntry entry;\\n                entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n                entry.data.argmax = j_prime*RST + mad16(t_prime, RS, mad16(r_prime, S, s_prime));\\n\\n                lut[lut_size + dep_thd_cnt] = entry.data2;\\n            }\\n            lut_size += warp_slices;\\n            jrst += 32;\\n        }\\n        if(tid == 0)\\n            lutSize = lut_size;\\n    }\\n    __syncthreads();\\n\\n    lut_size = lutSize;\\n\\n    int jrst = 0;\\n    float out = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < lut_size)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        // argmax\\n        int fprop_argmax0 = jrst + 0 < lut_size ? __ldg(A + entry0.data.slice) : -2;\\n        int fprop_argmax1 = jrst + 1 < lut_size ? __ldg(A + entry1.data.slice) : -2;\\n        int fprop_argmax2 = jrst + 2 < lut_size ? __ldg(A + entry2.data.slice) : -2;\\n        int fprop_argmax3 = jrst + 3 < lut_size ? __ldg(A + entry3.data.slice) : -2;\\n\\n        out += jrst + 0 < lut_size && fprop_argmax0 == entry0.data.argmax ? %(cvt)s(__ldg(I + entry0.data.slice)) : 0.0f;\\n        out += jrst + 1 < lut_size && fprop_argmax1 == entry1.data.argmax ? %(cvt)s(__ldg(I + entry1.data.slice)) : 0.0f;\\n        out += jrst + 2 < lut_size && fprop_argmax2 == entry2.data.argmax ? %(cvt)s(__ldg(I + entry2.data.slice)) : 0.0f;\\n        out += jrst + 3 < lut_size && fprop_argmax3 == entry3.data.argmax ? %(cvt)s(__ldg(I + entry3.data.slice)) : 0.0f;\\n\\n        jrst += 4;\\n    }\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n    }\\n    // compute max-abs\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max_overlap')\n    kernel.prepare('3P 2f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_max_overlap(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_max_overlap(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    int __shared__ lutSize;\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    I += n;\\n    A += n;\\n    O += c*DHWN + z*HWN + y*WN + x*N + n;\\n\\n    float O_val = (beta != 0.0f) ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int lut_size;\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        unsigned dep_thd_mask = 0xffffffff;\\n        dep_thd_mask >>= 32 - tid;\\n\\n        lut_size = 0;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n            int  k_mod    = mod16(k_prime, k, str_c);\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n            int  m_mod    = mod16(m_prime, m, str_d);\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n            int  p_mod    = mod16(p_prime, p, str_h);\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n            int  q_mod    = mod16(q_prime, q, str_w);\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            // Get a mask of all valid slices in the warp\\n            unsigned ballot = __ballot(in_bounds);\\n\\n            // Count the total valid slices\\n            unsigned warp_slices = __popc(ballot);\\n\\n            if (in_bounds)\\n            {\\n                // Count all the valid slices below this threadid\\n                unsigned dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n                int j_prime = c - k_prime + pad_c;\\n                int t_prime = z - m_prime + pad_d;\\n                int r_prime = y - p_prime + pad_h;\\n                int s_prime = x - q_prime + pad_w;\\n\\n                LutEntry entry;\\n                entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n                entry.data.argmax = j_prime*RST + mad16(t_prime, RS, mad16(r_prime, S, s_prime));\\n\\n                lut[lut_size + dep_thd_cnt] = entry.data2;\\n            }\\n            lut_size += warp_slices;\\n            jrst += 32;\\n        }\\n        if(tid == 0)\\n            lutSize = lut_size;\\n    }\\n    __syncthreads();\\n\\n    lut_size = lutSize;\\n\\n    int jrst = 0;\\n    float out = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < lut_size)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        // argmax\\n        int fprop_argmax0 = jrst + 0 < lut_size ? __ldg(A + entry0.data.slice) : -2;\\n        int fprop_argmax1 = jrst + 1 < lut_size ? __ldg(A + entry1.data.slice) : -2;\\n        int fprop_argmax2 = jrst + 2 < lut_size ? __ldg(A + entry2.data.slice) : -2;\\n        int fprop_argmax3 = jrst + 3 < lut_size ? __ldg(A + entry3.data.slice) : -2;\\n\\n        out += jrst + 0 < lut_size && fprop_argmax0 == entry0.data.argmax ? %(cvt)s(__ldg(I + entry0.data.slice)) : 0.0f;\\n        out += jrst + 1 < lut_size && fprop_argmax1 == entry1.data.argmax ? %(cvt)s(__ldg(I + entry1.data.slice)) : 0.0f;\\n        out += jrst + 2 < lut_size && fprop_argmax2 == entry2.data.argmax ? %(cvt)s(__ldg(I + entry2.data.slice)) : 0.0f;\\n        out += jrst + 3 < lut_size && fprop_argmax3 == entry3.data.argmax ? %(cvt)s(__ldg(I + entry3.data.slice)) : 0.0f;\\n\\n        jrst += 4;\\n    }\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n    }\\n    // compute max-abs\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max_overlap')\n    kernel.prepare('3P 2f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_max_overlap(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_max_overlap(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    int __shared__ lutSize;\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    I += n;\\n    A += n;\\n    O += c*DHWN + z*HWN + y*WN + x*N + n;\\n\\n    float O_val = (beta != 0.0f) ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int lut_size;\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        unsigned dep_thd_mask = 0xffffffff;\\n        dep_thd_mask >>= 32 - tid;\\n\\n        lut_size = 0;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n            int  k_mod    = mod16(k_prime, k, str_c);\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n            int  m_mod    = mod16(m_prime, m, str_d);\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n            int  p_mod    = mod16(p_prime, p, str_h);\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n            int  q_mod    = mod16(q_prime, q, str_w);\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            // Get a mask of all valid slices in the warp\\n            unsigned ballot = __ballot(in_bounds);\\n\\n            // Count the total valid slices\\n            unsigned warp_slices = __popc(ballot);\\n\\n            if (in_bounds)\\n            {\\n                // Count all the valid slices below this threadid\\n                unsigned dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n                int j_prime = c - k_prime + pad_c;\\n                int t_prime = z - m_prime + pad_d;\\n                int r_prime = y - p_prime + pad_h;\\n                int s_prime = x - q_prime + pad_w;\\n\\n                LutEntry entry;\\n                entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n                entry.data.argmax = j_prime*RST + mad16(t_prime, RS, mad16(r_prime, S, s_prime));\\n\\n                lut[lut_size + dep_thd_cnt] = entry.data2;\\n            }\\n            lut_size += warp_slices;\\n            jrst += 32;\\n        }\\n        if(tid == 0)\\n            lutSize = lut_size;\\n    }\\n    __syncthreads();\\n\\n    lut_size = lutSize;\\n\\n    int jrst = 0;\\n    float out = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < lut_size)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        // argmax\\n        int fprop_argmax0 = jrst + 0 < lut_size ? __ldg(A + entry0.data.slice) : -2;\\n        int fprop_argmax1 = jrst + 1 < lut_size ? __ldg(A + entry1.data.slice) : -2;\\n        int fprop_argmax2 = jrst + 2 < lut_size ? __ldg(A + entry2.data.slice) : -2;\\n        int fprop_argmax3 = jrst + 3 < lut_size ? __ldg(A + entry3.data.slice) : -2;\\n\\n        out += jrst + 0 < lut_size && fprop_argmax0 == entry0.data.argmax ? %(cvt)s(__ldg(I + entry0.data.slice)) : 0.0f;\\n        out += jrst + 1 < lut_size && fprop_argmax1 == entry1.data.argmax ? %(cvt)s(__ldg(I + entry1.data.slice)) : 0.0f;\\n        out += jrst + 2 < lut_size && fprop_argmax2 == entry2.data.argmax ? %(cvt)s(__ldg(I + entry2.data.slice)) : 0.0f;\\n        out += jrst + 3 < lut_size && fprop_argmax3 == entry3.data.argmax ? %(cvt)s(__ldg(I + entry3.data.slice)) : 0.0f;\\n\\n        jrst += 4;\\n    }\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n    }\\n    // compute max-abs\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max_overlap')\n    kernel.prepare('3P 2f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel"
        ]
    },
    {
        "func_name": "_get_bprop_avg_overlap",
        "original": "@context_dependent_memoize\ndef _get_bprop_avg_overlap(clss, compute_capability):\n    code = '\\n\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int   slice;\\n        float rcp_in;\\n    } data;\\n    int2 data2;\\n};\\n\\n__device__ __forceinline__ int imin(int val1, int val2)\\n{\\n    int ret;\\n    asm(\"min.s32 %%0, %%1, %%2;\" : \"=r\"(ret) : \"r\"(val1), \"r\"(val2));\\n    return ret;\\n}\\n\\n__global__ void spool_bprop_avg_overlap(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    int    __shared__ lutSize;\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    I += n;\\n    O += c*DHWN + z*HWN + y*WN + x*N + n;\\n\\n    float O_val = beta != 0.0f ? %(cvt)s(__ldg(O)) : 0.0f;\\n    int lut_size;\\n\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        unsigned dep_thd_mask = 0xffffffff;\\n        dep_thd_mask >>= 32 - tid;\\n\\n        lut_size = 0;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n            int  k_mod    = mod16(k_prime, k, str_c);\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n            int  m_mod    = mod16(m_prime, m, str_d);\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n            int  p_mod    = mod16(p_prime, p, str_h);\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n            int  q_mod    = mod16(q_prime, q, str_w);\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            // Get a mask of all valid slices in the warp\\n            unsigned ballot = __ballot(in_bounds);\\n\\n            // Count the total valid slices\\n            unsigned warp_slices = __popc(ballot);\\n\\n            if (in_bounds)\\n            {\\n                // Count all the valid slices below this threadid\\n                unsigned dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n                int c_left = msub16(k, str_c, pad_c);\\n                int z_left = msub16(m, str_d, pad_d);\\n                int y_left = msub16(p, str_h, pad_h);\\n                int x_left = msub16(q, str_w, pad_w);\\n\\n                float k_in = (float)imin( imin(J + c_left, J), imin(C - c_left, J) );\\n                float m_in = (float)imin( imin(T + z_left, T), imin(D - z_left, T) );\\n                float p_in = (float)imin( imin(R + y_left, R), imin(H - y_left, R) );\\n                float q_in = (float)imin( imin(S + x_left, S), imin(W - x_left, S) );\\n\\n                float total_in = q_in * p_in * m_in * k_in;\\n\\n                float rcp_in = total_in > 0.0f ? 1.0f / total_in : 0.0f;\\n\\n                LutEntry entry;\\n                entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n                entry.data.rcp_in = rcp_in;\\n\\n                lut[lut_size + dep_thd_cnt] = entry.data2;\\n            }\\n            lut_size += warp_slices;\\n            jrst += 32;\\n        }\\n        if(tid==0)\\n            lutSize = lut_size;\\n    }\\n    __syncthreads();\\n\\n    lut_size = lutSize;\\n\\n    int jrst = 0;\\n    float out = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < lut_size)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        out += jrst + 0 < lut_size ? %(cvt)s(__ldg(I + entry0.data.slice)) * entry0.data.rcp_in : 0.0f;\\n        out += jrst + 1 < lut_size ? %(cvt)s(__ldg(I + entry1.data.slice)) * entry1.data.rcp_in : 0.0f;\\n        out += jrst + 2 < lut_size ? %(cvt)s(__ldg(I + entry2.data.slice)) * entry2.data.rcp_in : 0.0f;\\n        out += jrst + 3 < lut_size ? %(cvt)s(__ldg(I + entry3.data.slice)) * entry3.data.rcp_in : 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n    }\\n\\n    // max-abs over unrolls\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n\\n    %(atomic_max)s\\n\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg_overlap')\n    kernel.prepare('3P 2f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
        "mutated": [
            "@context_dependent_memoize\ndef _get_bprop_avg_overlap(clss, compute_capability):\n    if False:\n        i = 10\n    code = '\\n\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int   slice;\\n        float rcp_in;\\n    } data;\\n    int2 data2;\\n};\\n\\n__device__ __forceinline__ int imin(int val1, int val2)\\n{\\n    int ret;\\n    asm(\"min.s32 %%0, %%1, %%2;\" : \"=r\"(ret) : \"r\"(val1), \"r\"(val2));\\n    return ret;\\n}\\n\\n__global__ void spool_bprop_avg_overlap(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    int    __shared__ lutSize;\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    I += n;\\n    O += c*DHWN + z*HWN + y*WN + x*N + n;\\n\\n    float O_val = beta != 0.0f ? %(cvt)s(__ldg(O)) : 0.0f;\\n    int lut_size;\\n\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        unsigned dep_thd_mask = 0xffffffff;\\n        dep_thd_mask >>= 32 - tid;\\n\\n        lut_size = 0;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n            int  k_mod    = mod16(k_prime, k, str_c);\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n            int  m_mod    = mod16(m_prime, m, str_d);\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n            int  p_mod    = mod16(p_prime, p, str_h);\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n            int  q_mod    = mod16(q_prime, q, str_w);\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            // Get a mask of all valid slices in the warp\\n            unsigned ballot = __ballot(in_bounds);\\n\\n            // Count the total valid slices\\n            unsigned warp_slices = __popc(ballot);\\n\\n            if (in_bounds)\\n            {\\n                // Count all the valid slices below this threadid\\n                unsigned dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n                int c_left = msub16(k, str_c, pad_c);\\n                int z_left = msub16(m, str_d, pad_d);\\n                int y_left = msub16(p, str_h, pad_h);\\n                int x_left = msub16(q, str_w, pad_w);\\n\\n                float k_in = (float)imin( imin(J + c_left, J), imin(C - c_left, J) );\\n                float m_in = (float)imin( imin(T + z_left, T), imin(D - z_left, T) );\\n                float p_in = (float)imin( imin(R + y_left, R), imin(H - y_left, R) );\\n                float q_in = (float)imin( imin(S + x_left, S), imin(W - x_left, S) );\\n\\n                float total_in = q_in * p_in * m_in * k_in;\\n\\n                float rcp_in = total_in > 0.0f ? 1.0f / total_in : 0.0f;\\n\\n                LutEntry entry;\\n                entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n                entry.data.rcp_in = rcp_in;\\n\\n                lut[lut_size + dep_thd_cnt] = entry.data2;\\n            }\\n            lut_size += warp_slices;\\n            jrst += 32;\\n        }\\n        if(tid==0)\\n            lutSize = lut_size;\\n    }\\n    __syncthreads();\\n\\n    lut_size = lutSize;\\n\\n    int jrst = 0;\\n    float out = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < lut_size)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        out += jrst + 0 < lut_size ? %(cvt)s(__ldg(I + entry0.data.slice)) * entry0.data.rcp_in : 0.0f;\\n        out += jrst + 1 < lut_size ? %(cvt)s(__ldg(I + entry1.data.slice)) * entry1.data.rcp_in : 0.0f;\\n        out += jrst + 2 < lut_size ? %(cvt)s(__ldg(I + entry2.data.slice)) * entry2.data.rcp_in : 0.0f;\\n        out += jrst + 3 < lut_size ? %(cvt)s(__ldg(I + entry3.data.slice)) * entry3.data.rcp_in : 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n    }\\n\\n    // max-abs over unrolls\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n\\n    %(atomic_max)s\\n\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg_overlap')\n    kernel.prepare('3P 2f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_avg_overlap(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    code = '\\n\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int   slice;\\n        float rcp_in;\\n    } data;\\n    int2 data2;\\n};\\n\\n__device__ __forceinline__ int imin(int val1, int val2)\\n{\\n    int ret;\\n    asm(\"min.s32 %%0, %%1, %%2;\" : \"=r\"(ret) : \"r\"(val1), \"r\"(val2));\\n    return ret;\\n}\\n\\n__global__ void spool_bprop_avg_overlap(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    int    __shared__ lutSize;\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    I += n;\\n    O += c*DHWN + z*HWN + y*WN + x*N + n;\\n\\n    float O_val = beta != 0.0f ? %(cvt)s(__ldg(O)) : 0.0f;\\n    int lut_size;\\n\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        unsigned dep_thd_mask = 0xffffffff;\\n        dep_thd_mask >>= 32 - tid;\\n\\n        lut_size = 0;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n            int  k_mod    = mod16(k_prime, k, str_c);\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n            int  m_mod    = mod16(m_prime, m, str_d);\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n            int  p_mod    = mod16(p_prime, p, str_h);\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n            int  q_mod    = mod16(q_prime, q, str_w);\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            // Get a mask of all valid slices in the warp\\n            unsigned ballot = __ballot(in_bounds);\\n\\n            // Count the total valid slices\\n            unsigned warp_slices = __popc(ballot);\\n\\n            if (in_bounds)\\n            {\\n                // Count all the valid slices below this threadid\\n                unsigned dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n                int c_left = msub16(k, str_c, pad_c);\\n                int z_left = msub16(m, str_d, pad_d);\\n                int y_left = msub16(p, str_h, pad_h);\\n                int x_left = msub16(q, str_w, pad_w);\\n\\n                float k_in = (float)imin( imin(J + c_left, J), imin(C - c_left, J) );\\n                float m_in = (float)imin( imin(T + z_left, T), imin(D - z_left, T) );\\n                float p_in = (float)imin( imin(R + y_left, R), imin(H - y_left, R) );\\n                float q_in = (float)imin( imin(S + x_left, S), imin(W - x_left, S) );\\n\\n                float total_in = q_in * p_in * m_in * k_in;\\n\\n                float rcp_in = total_in > 0.0f ? 1.0f / total_in : 0.0f;\\n\\n                LutEntry entry;\\n                entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n                entry.data.rcp_in = rcp_in;\\n\\n                lut[lut_size + dep_thd_cnt] = entry.data2;\\n            }\\n            lut_size += warp_slices;\\n            jrst += 32;\\n        }\\n        if(tid==0)\\n            lutSize = lut_size;\\n    }\\n    __syncthreads();\\n\\n    lut_size = lutSize;\\n\\n    int jrst = 0;\\n    float out = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < lut_size)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        out += jrst + 0 < lut_size ? %(cvt)s(__ldg(I + entry0.data.slice)) * entry0.data.rcp_in : 0.0f;\\n        out += jrst + 1 < lut_size ? %(cvt)s(__ldg(I + entry1.data.slice)) * entry1.data.rcp_in : 0.0f;\\n        out += jrst + 2 < lut_size ? %(cvt)s(__ldg(I + entry2.data.slice)) * entry2.data.rcp_in : 0.0f;\\n        out += jrst + 3 < lut_size ? %(cvt)s(__ldg(I + entry3.data.slice)) * entry3.data.rcp_in : 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n    }\\n\\n    // max-abs over unrolls\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n\\n    %(atomic_max)s\\n\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg_overlap')\n    kernel.prepare('3P 2f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_avg_overlap(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    code = '\\n\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int   slice;\\n        float rcp_in;\\n    } data;\\n    int2 data2;\\n};\\n\\n__device__ __forceinline__ int imin(int val1, int val2)\\n{\\n    int ret;\\n    asm(\"min.s32 %%0, %%1, %%2;\" : \"=r\"(ret) : \"r\"(val1), \"r\"(val2));\\n    return ret;\\n}\\n\\n__global__ void spool_bprop_avg_overlap(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    int    __shared__ lutSize;\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    I += n;\\n    O += c*DHWN + z*HWN + y*WN + x*N + n;\\n\\n    float O_val = beta != 0.0f ? %(cvt)s(__ldg(O)) : 0.0f;\\n    int lut_size;\\n\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        unsigned dep_thd_mask = 0xffffffff;\\n        dep_thd_mask >>= 32 - tid;\\n\\n        lut_size = 0;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n            int  k_mod    = mod16(k_prime, k, str_c);\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n            int  m_mod    = mod16(m_prime, m, str_d);\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n            int  p_mod    = mod16(p_prime, p, str_h);\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n            int  q_mod    = mod16(q_prime, q, str_w);\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            // Get a mask of all valid slices in the warp\\n            unsigned ballot = __ballot(in_bounds);\\n\\n            // Count the total valid slices\\n            unsigned warp_slices = __popc(ballot);\\n\\n            if (in_bounds)\\n            {\\n                // Count all the valid slices below this threadid\\n                unsigned dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n                int c_left = msub16(k, str_c, pad_c);\\n                int z_left = msub16(m, str_d, pad_d);\\n                int y_left = msub16(p, str_h, pad_h);\\n                int x_left = msub16(q, str_w, pad_w);\\n\\n                float k_in = (float)imin( imin(J + c_left, J), imin(C - c_left, J) );\\n                float m_in = (float)imin( imin(T + z_left, T), imin(D - z_left, T) );\\n                float p_in = (float)imin( imin(R + y_left, R), imin(H - y_left, R) );\\n                float q_in = (float)imin( imin(S + x_left, S), imin(W - x_left, S) );\\n\\n                float total_in = q_in * p_in * m_in * k_in;\\n\\n                float rcp_in = total_in > 0.0f ? 1.0f / total_in : 0.0f;\\n\\n                LutEntry entry;\\n                entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n                entry.data.rcp_in = rcp_in;\\n\\n                lut[lut_size + dep_thd_cnt] = entry.data2;\\n            }\\n            lut_size += warp_slices;\\n            jrst += 32;\\n        }\\n        if(tid==0)\\n            lutSize = lut_size;\\n    }\\n    __syncthreads();\\n\\n    lut_size = lutSize;\\n\\n    int jrst = 0;\\n    float out = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < lut_size)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        out += jrst + 0 < lut_size ? %(cvt)s(__ldg(I + entry0.data.slice)) * entry0.data.rcp_in : 0.0f;\\n        out += jrst + 1 < lut_size ? %(cvt)s(__ldg(I + entry1.data.slice)) * entry1.data.rcp_in : 0.0f;\\n        out += jrst + 2 < lut_size ? %(cvt)s(__ldg(I + entry2.data.slice)) * entry2.data.rcp_in : 0.0f;\\n        out += jrst + 3 < lut_size ? %(cvt)s(__ldg(I + entry3.data.slice)) * entry3.data.rcp_in : 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n    }\\n\\n    // max-abs over unrolls\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n\\n    %(atomic_max)s\\n\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg_overlap')\n    kernel.prepare('3P 2f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_avg_overlap(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    code = '\\n\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int   slice;\\n        float rcp_in;\\n    } data;\\n    int2 data2;\\n};\\n\\n__device__ __forceinline__ int imin(int val1, int val2)\\n{\\n    int ret;\\n    asm(\"min.s32 %%0, %%1, %%2;\" : \"=r\"(ret) : \"r\"(val1), \"r\"(val2));\\n    return ret;\\n}\\n\\n__global__ void spool_bprop_avg_overlap(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    int    __shared__ lutSize;\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    I += n;\\n    O += c*DHWN + z*HWN + y*WN + x*N + n;\\n\\n    float O_val = beta != 0.0f ? %(cvt)s(__ldg(O)) : 0.0f;\\n    int lut_size;\\n\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        unsigned dep_thd_mask = 0xffffffff;\\n        dep_thd_mask >>= 32 - tid;\\n\\n        lut_size = 0;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n            int  k_mod    = mod16(k_prime, k, str_c);\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n            int  m_mod    = mod16(m_prime, m, str_d);\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n            int  p_mod    = mod16(p_prime, p, str_h);\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n            int  q_mod    = mod16(q_prime, q, str_w);\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            // Get a mask of all valid slices in the warp\\n            unsigned ballot = __ballot(in_bounds);\\n\\n            // Count the total valid slices\\n            unsigned warp_slices = __popc(ballot);\\n\\n            if (in_bounds)\\n            {\\n                // Count all the valid slices below this threadid\\n                unsigned dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n                int c_left = msub16(k, str_c, pad_c);\\n                int z_left = msub16(m, str_d, pad_d);\\n                int y_left = msub16(p, str_h, pad_h);\\n                int x_left = msub16(q, str_w, pad_w);\\n\\n                float k_in = (float)imin( imin(J + c_left, J), imin(C - c_left, J) );\\n                float m_in = (float)imin( imin(T + z_left, T), imin(D - z_left, T) );\\n                float p_in = (float)imin( imin(R + y_left, R), imin(H - y_left, R) );\\n                float q_in = (float)imin( imin(S + x_left, S), imin(W - x_left, S) );\\n\\n                float total_in = q_in * p_in * m_in * k_in;\\n\\n                float rcp_in = total_in > 0.0f ? 1.0f / total_in : 0.0f;\\n\\n                LutEntry entry;\\n                entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n                entry.data.rcp_in = rcp_in;\\n\\n                lut[lut_size + dep_thd_cnt] = entry.data2;\\n            }\\n            lut_size += warp_slices;\\n            jrst += 32;\\n        }\\n        if(tid==0)\\n            lutSize = lut_size;\\n    }\\n    __syncthreads();\\n\\n    lut_size = lutSize;\\n\\n    int jrst = 0;\\n    float out = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < lut_size)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        out += jrst + 0 < lut_size ? %(cvt)s(__ldg(I + entry0.data.slice)) * entry0.data.rcp_in : 0.0f;\\n        out += jrst + 1 < lut_size ? %(cvt)s(__ldg(I + entry1.data.slice)) * entry1.data.rcp_in : 0.0f;\\n        out += jrst + 2 < lut_size ? %(cvt)s(__ldg(I + entry2.data.slice)) * entry2.data.rcp_in : 0.0f;\\n        out += jrst + 3 < lut_size ? %(cvt)s(__ldg(I + entry3.data.slice)) * entry3.data.rcp_in : 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n    }\\n\\n    // max-abs over unrolls\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n\\n    %(atomic_max)s\\n\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg_overlap')\n    kernel.prepare('3P 2f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_avg_overlap(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    code = '\\n\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int   slice;\\n        float rcp_in;\\n    } data;\\n    int2 data2;\\n};\\n\\n__device__ __forceinline__ int imin(int val1, int val2)\\n{\\n    int ret;\\n    asm(\"min.s32 %%0, %%1, %%2;\" : \"=r\"(ret) : \"r\"(val1), \"r\"(val2));\\n    return ret;\\n}\\n\\n__global__ void spool_bprop_avg_overlap(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    int    __shared__ lutSize;\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int n  = tid;\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*H;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = W - x - 1;\\n\\n    I += n;\\n    O += c*DHWN + z*HWN + y*WN + x*N + n;\\n\\n    float O_val = beta != 0.0f ? %(cvt)s(__ldg(O)) : 0.0f;\\n    int lut_size;\\n\\n    if (tid < 32)\\n    {\\n        int kj = c - J + pad_c + 1;\\n        int mt = z - T + pad_d + 1;\\n        int pr = y - R + pad_h + 1;\\n        int qs = x - S + pad_w + 1;\\n\\n        unsigned dep_thd_mask = 0xffffffff;\\n        dep_thd_mask >>= 32 - tid;\\n\\n        lut_size = 0;\\n\\n        int jrst = tid;\\n        while (jrst < JRST)\\n        {\\n            int j   = div16(jrst, magic_RST, shift_RST);\\n            int rst = mod16(jrst, j, RST);\\n\\n            int t   = div16(rst, magic_RS, shift_RS);\\n            int rs  = mod16(rst, t, RS);\\n\\n            int r   = div16(rs, magic_S, shift_S);\\n            int s   = mod16(rs, r, S);\\n\\n            int k_prime = kj + j;\\n            int m_prime = mt + t;\\n            int p_prime = pr + r;\\n            int q_prime = qs + s;\\n\\n            int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n            int  k_mod    = mod16(k_prime, k, str_c);\\n            bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n            int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n            int  m_mod    = mod16(m_prime, m, str_d);\\n            bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n            int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n            int  p_mod    = mod16(p_prime, p, str_h);\\n            bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n            int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n            int  q_mod    = mod16(q_prime, q, str_w);\\n            bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n            bool in_bounds = k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n            // Get a mask of all valid slices in the warp\\n            unsigned ballot = __ballot(in_bounds);\\n\\n            // Count the total valid slices\\n            unsigned warp_slices = __popc(ballot);\\n\\n            if (in_bounds)\\n            {\\n                // Count all the valid slices below this threadid\\n                unsigned dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n                int c_left = msub16(k, str_c, pad_c);\\n                int z_left = msub16(m, str_d, pad_d);\\n                int y_left = msub16(p, str_h, pad_h);\\n                int x_left = msub16(q, str_w, pad_w);\\n\\n                float k_in = (float)imin( imin(J + c_left, J), imin(C - c_left, J) );\\n                float m_in = (float)imin( imin(T + z_left, T), imin(D - z_left, T) );\\n                float p_in = (float)imin( imin(R + y_left, R), imin(H - y_left, R) );\\n                float q_in = (float)imin( imin(S + x_left, S), imin(W - x_left, S) );\\n\\n                float total_in = q_in * p_in * m_in * k_in;\\n\\n                float rcp_in = total_in > 0.0f ? 1.0f / total_in : 0.0f;\\n\\n                LutEntry entry;\\n                entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n                entry.data.rcp_in = rcp_in;\\n\\n                lut[lut_size + dep_thd_cnt] = entry.data2;\\n            }\\n            lut_size += warp_slices;\\n            jrst += 32;\\n        }\\n        if(tid==0)\\n            lutSize = lut_size;\\n    }\\n    __syncthreads();\\n\\n    lut_size = lutSize;\\n\\n    int jrst = 0;\\n    float out = 0.0f;\\n    int intermediate_max = 0;\\n\\n    while (jrst < lut_size)\\n    {\\n        LutEntry entry0;\\n        LutEntry entry1;\\n        LutEntry entry2;\\n        LutEntry entry3;\\n\\n        entry0.data2 = lut[jrst + 0];\\n        entry1.data2 = lut[jrst + 1];\\n        entry2.data2 = lut[jrst + 2];\\n        entry3.data2 = lut[jrst + 3];\\n\\n        out += jrst + 0 < lut_size ? %(cvt)s(__ldg(I + entry0.data.slice)) * entry0.data.rcp_in : 0.0f;\\n        out += jrst + 1 < lut_size ? %(cvt)s(__ldg(I + entry1.data.slice)) * entry1.data.rcp_in : 0.0f;\\n        out += jrst + 2 < lut_size ? %(cvt)s(__ldg(I + entry2.data.slice)) * entry2.data.rcp_in : 0.0f;\\n        out += jrst + 3 < lut_size ? %(cvt)s(__ldg(I + entry3.data.slice)) * entry3.data.rcp_in : 0.0f;\\n\\n        jrst += 4;\\n    }\\n\\n    %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n    if (!(flags & 1)) {\\n        *O = temp_out;\\n    }\\n\\n    // max-abs over unrolls\\n    intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n\\n    %(atomic_max)s\\n\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg_overlap')\n    kernel.prepare('3P 2f 47I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel"
        ]
    },
    {
        "func_name": "_get_bprop_max_overlap_smallN",
        "original": "@context_dependent_memoize\ndef _get_bprop_max_overlap_smallN(clss, compute_capability):\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_max_overlap_smallN(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN,\\n    int supH, int supW, int shlH, int maskH, int shrH,\\n    int shlW, int maskW, int shrW, int maskN, int shrN, int maxLutSize\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*supH;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = supW - x - 1;\\n\\n    // Superblock H and W\\n    y = (y << shlH) + ((tid & maskH) >> shrH);\\n    x = (x << shlW) + ((tid & maskW) >> shrW);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    A += n;\\n    O += c*DHWN + z*HWN + y*WN + mad16(x, N, n);\\n\\n    float O_val = beta != 0.0f && y < H && x < W && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int kj = c - J + pad_c + 1;\\n    int mt = z - T + pad_d + 1;\\n    int pr = y - R + pad_h + 1;\\n    int qs = x - S + pad_w + 1;\\n\\n    int sbSize = maskN + 1;\\n    int sbBits = mad16(sb, sbSize, 0);\\n    unsigned sbMask = ~(0xffffffff << sbSize) << sbBits;\\n    unsigned dep_thd_mask = (0xffffffff >> (32 - n)) << sbBits;\\n\\n    int lut_offset = mad16(sb, maxLutSize, 0);\\n    int lut_size = 0;\\n    int jrst = n;\\n    int JRSTend = JRST;\\n    if (JRSTend & maskN)\\n        JRSTend += sbSize - (JRSTend & maskN);\\n\\n    while (jrst < JRSTend)\\n    {\\n        int j   = div16(jrst, magic_RST, shift_RST);\\n        int rst = mod16(jrst, j, RST);\\n\\n        int t   = div16(rst, magic_RS, shift_RS);\\n        int rs  = mod16(rst, t, RS);\\n\\n        int r   = div16(rs, magic_S, shift_S);\\n        int s   = mod16(rs, r, S);\\n\\n        int k_prime = kj + j;\\n        int m_prime = mt + t;\\n        int p_prime = pr + r;\\n        int q_prime = qs + s;\\n\\n        int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n        int  k_mod    = mod16(k_prime, k, str_c);\\n        bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n        int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n        int  m_mod    = mod16(m_prime, m, str_d);\\n        bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n        int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n        int  p_mod    = mod16(p_prime, p, str_h);\\n        bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n        int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n        int  q_mod    = mod16(q_prime, q, str_w);\\n        bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n        bool in_bounds = jrst < JRST && k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n        // Get a mask of all valid slices in the warp\\n        unsigned ballot = __ballot(in_bounds);\\n\\n        // Count the total valid slices in this superblock\\n        int sb_slices = __popc(sbMask & ballot);\\n\\n        if (in_bounds)\\n        {\\n            // Count all the valid slices below this threadid\\n            int dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n            int j_prime = c - k_prime + pad_c;\\n            int t_prime = z - m_prime + pad_d;\\n            int r_prime = y - p_prime + pad_h;\\n            int s_prime = x - q_prime + pad_w;\\n\\n            int sliceI  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n            int argmaxI = j_prime*RST + mad16(t_prime, RS, mad16(r_prime, S, s_prime));\\n\\n            LutEntry entry;\\n            entry.data.slice  = sliceI;\\n            entry.data.argmax = argmaxI;\\n\\n            lut[lut_offset + lut_size + dep_thd_cnt] = entry.data2;\\n        }\\n        lut_size += sb_slices;\\n        jrst += sbSize;\\n    }\\n\\n    int intermediate_max = 0;\\n\\n    if (y < H && x < W && n < N)\\n    {\\n        int jrst = 0;\\n        float out = 0.0f;\\n\\n        while (jrst < maxLutSize)\\n        {\\n            LutEntry entry0;\\n            LutEntry entry1;\\n            LutEntry entry2;\\n            LutEntry entry3;\\n\\n            lut_offset = mad16(sb, maxLutSize, jrst);\\n\\n            entry0.data2 = lut[lut_offset + 0];\\n            entry1.data2 = lut[lut_offset + 1];\\n            entry2.data2 = lut[lut_offset + 2];\\n            entry3.data2 = lut[lut_offset + 3];\\n\\n            // argmax\\n            int fprop_argmax0 = jrst + 0 < lut_size ? __ldg(A + entry0.data.slice) : -2;\\n            int fprop_argmax1 = jrst + 1 < lut_size ? __ldg(A + entry1.data.slice) : -2;\\n            int fprop_argmax2 = jrst + 2 < lut_size ? __ldg(A + entry2.data.slice) : -2;\\n            int fprop_argmax3 = jrst + 3 < lut_size ? __ldg(A + entry3.data.slice) : -2;\\n\\n            out += jrst + 0 < lut_size && fprop_argmax0 == entry0.data.argmax ? %(cvt)s(__ldg(I + entry0.data.slice)) : 0.0f;\\n            out += jrst + 1 < lut_size && fprop_argmax1 == entry1.data.argmax ? %(cvt)s(__ldg(I + entry1.data.slice)) : 0.0f;\\n            out += jrst + 2 < lut_size && fprop_argmax2 == entry2.data.argmax ? %(cvt)s(__ldg(I + entry2.data.slice)) : 0.0f;\\n            out += jrst + 3 < lut_size && fprop_argmax3 == entry3.data.argmax ? %(cvt)s(__ldg(I + entry3.data.slice)) : 0.0f;\\n\\n            jrst += 4;\\n        }\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n        if (!(flags & 1))\\n            *O = temp_out;\\n\\n        // compute max-abs\\n        intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max_overlap_smallN')\n    kernel.prepare('3P 2f 58I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
        "mutated": [
            "@context_dependent_memoize\ndef _get_bprop_max_overlap_smallN(clss, compute_capability):\n    if False:\n        i = 10\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_max_overlap_smallN(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN,\\n    int supH, int supW, int shlH, int maskH, int shrH,\\n    int shlW, int maskW, int shrW, int maskN, int shrN, int maxLutSize\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*supH;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = supW - x - 1;\\n\\n    // Superblock H and W\\n    y = (y << shlH) + ((tid & maskH) >> shrH);\\n    x = (x << shlW) + ((tid & maskW) >> shrW);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    A += n;\\n    O += c*DHWN + z*HWN + y*WN + mad16(x, N, n);\\n\\n    float O_val = beta != 0.0f && y < H && x < W && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int kj = c - J + pad_c + 1;\\n    int mt = z - T + pad_d + 1;\\n    int pr = y - R + pad_h + 1;\\n    int qs = x - S + pad_w + 1;\\n\\n    int sbSize = maskN + 1;\\n    int sbBits = mad16(sb, sbSize, 0);\\n    unsigned sbMask = ~(0xffffffff << sbSize) << sbBits;\\n    unsigned dep_thd_mask = (0xffffffff >> (32 - n)) << sbBits;\\n\\n    int lut_offset = mad16(sb, maxLutSize, 0);\\n    int lut_size = 0;\\n    int jrst = n;\\n    int JRSTend = JRST;\\n    if (JRSTend & maskN)\\n        JRSTend += sbSize - (JRSTend & maskN);\\n\\n    while (jrst < JRSTend)\\n    {\\n        int j   = div16(jrst, magic_RST, shift_RST);\\n        int rst = mod16(jrst, j, RST);\\n\\n        int t   = div16(rst, magic_RS, shift_RS);\\n        int rs  = mod16(rst, t, RS);\\n\\n        int r   = div16(rs, magic_S, shift_S);\\n        int s   = mod16(rs, r, S);\\n\\n        int k_prime = kj + j;\\n        int m_prime = mt + t;\\n        int p_prime = pr + r;\\n        int q_prime = qs + s;\\n\\n        int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n        int  k_mod    = mod16(k_prime, k, str_c);\\n        bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n        int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n        int  m_mod    = mod16(m_prime, m, str_d);\\n        bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n        int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n        int  p_mod    = mod16(p_prime, p, str_h);\\n        bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n        int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n        int  q_mod    = mod16(q_prime, q, str_w);\\n        bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n        bool in_bounds = jrst < JRST && k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n        // Get a mask of all valid slices in the warp\\n        unsigned ballot = __ballot(in_bounds);\\n\\n        // Count the total valid slices in this superblock\\n        int sb_slices = __popc(sbMask & ballot);\\n\\n        if (in_bounds)\\n        {\\n            // Count all the valid slices below this threadid\\n            int dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n            int j_prime = c - k_prime + pad_c;\\n            int t_prime = z - m_prime + pad_d;\\n            int r_prime = y - p_prime + pad_h;\\n            int s_prime = x - q_prime + pad_w;\\n\\n            int sliceI  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n            int argmaxI = j_prime*RST + mad16(t_prime, RS, mad16(r_prime, S, s_prime));\\n\\n            LutEntry entry;\\n            entry.data.slice  = sliceI;\\n            entry.data.argmax = argmaxI;\\n\\n            lut[lut_offset + lut_size + dep_thd_cnt] = entry.data2;\\n        }\\n        lut_size += sb_slices;\\n        jrst += sbSize;\\n    }\\n\\n    int intermediate_max = 0;\\n\\n    if (y < H && x < W && n < N)\\n    {\\n        int jrst = 0;\\n        float out = 0.0f;\\n\\n        while (jrst < maxLutSize)\\n        {\\n            LutEntry entry0;\\n            LutEntry entry1;\\n            LutEntry entry2;\\n            LutEntry entry3;\\n\\n            lut_offset = mad16(sb, maxLutSize, jrst);\\n\\n            entry0.data2 = lut[lut_offset + 0];\\n            entry1.data2 = lut[lut_offset + 1];\\n            entry2.data2 = lut[lut_offset + 2];\\n            entry3.data2 = lut[lut_offset + 3];\\n\\n            // argmax\\n            int fprop_argmax0 = jrst + 0 < lut_size ? __ldg(A + entry0.data.slice) : -2;\\n            int fprop_argmax1 = jrst + 1 < lut_size ? __ldg(A + entry1.data.slice) : -2;\\n            int fprop_argmax2 = jrst + 2 < lut_size ? __ldg(A + entry2.data.slice) : -2;\\n            int fprop_argmax3 = jrst + 3 < lut_size ? __ldg(A + entry3.data.slice) : -2;\\n\\n            out += jrst + 0 < lut_size && fprop_argmax0 == entry0.data.argmax ? %(cvt)s(__ldg(I + entry0.data.slice)) : 0.0f;\\n            out += jrst + 1 < lut_size && fprop_argmax1 == entry1.data.argmax ? %(cvt)s(__ldg(I + entry1.data.slice)) : 0.0f;\\n            out += jrst + 2 < lut_size && fprop_argmax2 == entry2.data.argmax ? %(cvt)s(__ldg(I + entry2.data.slice)) : 0.0f;\\n            out += jrst + 3 < lut_size && fprop_argmax3 == entry3.data.argmax ? %(cvt)s(__ldg(I + entry3.data.slice)) : 0.0f;\\n\\n            jrst += 4;\\n        }\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n        if (!(flags & 1))\\n            *O = temp_out;\\n\\n        // compute max-abs\\n        intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max_overlap_smallN')\n    kernel.prepare('3P 2f 58I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_max_overlap_smallN(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_max_overlap_smallN(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN,\\n    int supH, int supW, int shlH, int maskH, int shrH,\\n    int shlW, int maskW, int shrW, int maskN, int shrN, int maxLutSize\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*supH;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = supW - x - 1;\\n\\n    // Superblock H and W\\n    y = (y << shlH) + ((tid & maskH) >> shrH);\\n    x = (x << shlW) + ((tid & maskW) >> shrW);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    A += n;\\n    O += c*DHWN + z*HWN + y*WN + mad16(x, N, n);\\n\\n    float O_val = beta != 0.0f && y < H && x < W && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int kj = c - J + pad_c + 1;\\n    int mt = z - T + pad_d + 1;\\n    int pr = y - R + pad_h + 1;\\n    int qs = x - S + pad_w + 1;\\n\\n    int sbSize = maskN + 1;\\n    int sbBits = mad16(sb, sbSize, 0);\\n    unsigned sbMask = ~(0xffffffff << sbSize) << sbBits;\\n    unsigned dep_thd_mask = (0xffffffff >> (32 - n)) << sbBits;\\n\\n    int lut_offset = mad16(sb, maxLutSize, 0);\\n    int lut_size = 0;\\n    int jrst = n;\\n    int JRSTend = JRST;\\n    if (JRSTend & maskN)\\n        JRSTend += sbSize - (JRSTend & maskN);\\n\\n    while (jrst < JRSTend)\\n    {\\n        int j   = div16(jrst, magic_RST, shift_RST);\\n        int rst = mod16(jrst, j, RST);\\n\\n        int t   = div16(rst, magic_RS, shift_RS);\\n        int rs  = mod16(rst, t, RS);\\n\\n        int r   = div16(rs, magic_S, shift_S);\\n        int s   = mod16(rs, r, S);\\n\\n        int k_prime = kj + j;\\n        int m_prime = mt + t;\\n        int p_prime = pr + r;\\n        int q_prime = qs + s;\\n\\n        int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n        int  k_mod    = mod16(k_prime, k, str_c);\\n        bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n        int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n        int  m_mod    = mod16(m_prime, m, str_d);\\n        bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n        int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n        int  p_mod    = mod16(p_prime, p, str_h);\\n        bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n        int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n        int  q_mod    = mod16(q_prime, q, str_w);\\n        bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n        bool in_bounds = jrst < JRST && k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n        // Get a mask of all valid slices in the warp\\n        unsigned ballot = __ballot(in_bounds);\\n\\n        // Count the total valid slices in this superblock\\n        int sb_slices = __popc(sbMask & ballot);\\n\\n        if (in_bounds)\\n        {\\n            // Count all the valid slices below this threadid\\n            int dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n            int j_prime = c - k_prime + pad_c;\\n            int t_prime = z - m_prime + pad_d;\\n            int r_prime = y - p_prime + pad_h;\\n            int s_prime = x - q_prime + pad_w;\\n\\n            int sliceI  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n            int argmaxI = j_prime*RST + mad16(t_prime, RS, mad16(r_prime, S, s_prime));\\n\\n            LutEntry entry;\\n            entry.data.slice  = sliceI;\\n            entry.data.argmax = argmaxI;\\n\\n            lut[lut_offset + lut_size + dep_thd_cnt] = entry.data2;\\n        }\\n        lut_size += sb_slices;\\n        jrst += sbSize;\\n    }\\n\\n    int intermediate_max = 0;\\n\\n    if (y < H && x < W && n < N)\\n    {\\n        int jrst = 0;\\n        float out = 0.0f;\\n\\n        while (jrst < maxLutSize)\\n        {\\n            LutEntry entry0;\\n            LutEntry entry1;\\n            LutEntry entry2;\\n            LutEntry entry3;\\n\\n            lut_offset = mad16(sb, maxLutSize, jrst);\\n\\n            entry0.data2 = lut[lut_offset + 0];\\n            entry1.data2 = lut[lut_offset + 1];\\n            entry2.data2 = lut[lut_offset + 2];\\n            entry3.data2 = lut[lut_offset + 3];\\n\\n            // argmax\\n            int fprop_argmax0 = jrst + 0 < lut_size ? __ldg(A + entry0.data.slice) : -2;\\n            int fprop_argmax1 = jrst + 1 < lut_size ? __ldg(A + entry1.data.slice) : -2;\\n            int fprop_argmax2 = jrst + 2 < lut_size ? __ldg(A + entry2.data.slice) : -2;\\n            int fprop_argmax3 = jrst + 3 < lut_size ? __ldg(A + entry3.data.slice) : -2;\\n\\n            out += jrst + 0 < lut_size && fprop_argmax0 == entry0.data.argmax ? %(cvt)s(__ldg(I + entry0.data.slice)) : 0.0f;\\n            out += jrst + 1 < lut_size && fprop_argmax1 == entry1.data.argmax ? %(cvt)s(__ldg(I + entry1.data.slice)) : 0.0f;\\n            out += jrst + 2 < lut_size && fprop_argmax2 == entry2.data.argmax ? %(cvt)s(__ldg(I + entry2.data.slice)) : 0.0f;\\n            out += jrst + 3 < lut_size && fprop_argmax3 == entry3.data.argmax ? %(cvt)s(__ldg(I + entry3.data.slice)) : 0.0f;\\n\\n            jrst += 4;\\n        }\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n        if (!(flags & 1))\\n            *O = temp_out;\\n\\n        // compute max-abs\\n        intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max_overlap_smallN')\n    kernel.prepare('3P 2f 58I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_max_overlap_smallN(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_max_overlap_smallN(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN,\\n    int supH, int supW, int shlH, int maskH, int shrH,\\n    int shlW, int maskW, int shrW, int maskN, int shrN, int maxLutSize\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*supH;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = supW - x - 1;\\n\\n    // Superblock H and W\\n    y = (y << shlH) + ((tid & maskH) >> shrH);\\n    x = (x << shlW) + ((tid & maskW) >> shrW);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    A += n;\\n    O += c*DHWN + z*HWN + y*WN + mad16(x, N, n);\\n\\n    float O_val = beta != 0.0f && y < H && x < W && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int kj = c - J + pad_c + 1;\\n    int mt = z - T + pad_d + 1;\\n    int pr = y - R + pad_h + 1;\\n    int qs = x - S + pad_w + 1;\\n\\n    int sbSize = maskN + 1;\\n    int sbBits = mad16(sb, sbSize, 0);\\n    unsigned sbMask = ~(0xffffffff << sbSize) << sbBits;\\n    unsigned dep_thd_mask = (0xffffffff >> (32 - n)) << sbBits;\\n\\n    int lut_offset = mad16(sb, maxLutSize, 0);\\n    int lut_size = 0;\\n    int jrst = n;\\n    int JRSTend = JRST;\\n    if (JRSTend & maskN)\\n        JRSTend += sbSize - (JRSTend & maskN);\\n\\n    while (jrst < JRSTend)\\n    {\\n        int j   = div16(jrst, magic_RST, shift_RST);\\n        int rst = mod16(jrst, j, RST);\\n\\n        int t   = div16(rst, magic_RS, shift_RS);\\n        int rs  = mod16(rst, t, RS);\\n\\n        int r   = div16(rs, magic_S, shift_S);\\n        int s   = mod16(rs, r, S);\\n\\n        int k_prime = kj + j;\\n        int m_prime = mt + t;\\n        int p_prime = pr + r;\\n        int q_prime = qs + s;\\n\\n        int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n        int  k_mod    = mod16(k_prime, k, str_c);\\n        bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n        int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n        int  m_mod    = mod16(m_prime, m, str_d);\\n        bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n        int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n        int  p_mod    = mod16(p_prime, p, str_h);\\n        bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n        int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n        int  q_mod    = mod16(q_prime, q, str_w);\\n        bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n        bool in_bounds = jrst < JRST && k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n        // Get a mask of all valid slices in the warp\\n        unsigned ballot = __ballot(in_bounds);\\n\\n        // Count the total valid slices in this superblock\\n        int sb_slices = __popc(sbMask & ballot);\\n\\n        if (in_bounds)\\n        {\\n            // Count all the valid slices below this threadid\\n            int dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n            int j_prime = c - k_prime + pad_c;\\n            int t_prime = z - m_prime + pad_d;\\n            int r_prime = y - p_prime + pad_h;\\n            int s_prime = x - q_prime + pad_w;\\n\\n            int sliceI  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n            int argmaxI = j_prime*RST + mad16(t_prime, RS, mad16(r_prime, S, s_prime));\\n\\n            LutEntry entry;\\n            entry.data.slice  = sliceI;\\n            entry.data.argmax = argmaxI;\\n\\n            lut[lut_offset + lut_size + dep_thd_cnt] = entry.data2;\\n        }\\n        lut_size += sb_slices;\\n        jrst += sbSize;\\n    }\\n\\n    int intermediate_max = 0;\\n\\n    if (y < H && x < W && n < N)\\n    {\\n        int jrst = 0;\\n        float out = 0.0f;\\n\\n        while (jrst < maxLutSize)\\n        {\\n            LutEntry entry0;\\n            LutEntry entry1;\\n            LutEntry entry2;\\n            LutEntry entry3;\\n\\n            lut_offset = mad16(sb, maxLutSize, jrst);\\n\\n            entry0.data2 = lut[lut_offset + 0];\\n            entry1.data2 = lut[lut_offset + 1];\\n            entry2.data2 = lut[lut_offset + 2];\\n            entry3.data2 = lut[lut_offset + 3];\\n\\n            // argmax\\n            int fprop_argmax0 = jrst + 0 < lut_size ? __ldg(A + entry0.data.slice) : -2;\\n            int fprop_argmax1 = jrst + 1 < lut_size ? __ldg(A + entry1.data.slice) : -2;\\n            int fprop_argmax2 = jrst + 2 < lut_size ? __ldg(A + entry2.data.slice) : -2;\\n            int fprop_argmax3 = jrst + 3 < lut_size ? __ldg(A + entry3.data.slice) : -2;\\n\\n            out += jrst + 0 < lut_size && fprop_argmax0 == entry0.data.argmax ? %(cvt)s(__ldg(I + entry0.data.slice)) : 0.0f;\\n            out += jrst + 1 < lut_size && fprop_argmax1 == entry1.data.argmax ? %(cvt)s(__ldg(I + entry1.data.slice)) : 0.0f;\\n            out += jrst + 2 < lut_size && fprop_argmax2 == entry2.data.argmax ? %(cvt)s(__ldg(I + entry2.data.slice)) : 0.0f;\\n            out += jrst + 3 < lut_size && fprop_argmax3 == entry3.data.argmax ? %(cvt)s(__ldg(I + entry3.data.slice)) : 0.0f;\\n\\n            jrst += 4;\\n        }\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n        if (!(flags & 1))\\n            *O = temp_out;\\n\\n        // compute max-abs\\n        intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max_overlap_smallN')\n    kernel.prepare('3P 2f 58I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_max_overlap_smallN(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_max_overlap_smallN(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN,\\n    int supH, int supW, int shlH, int maskH, int shrH,\\n    int shlW, int maskW, int shrW, int maskN, int shrN, int maxLutSize\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*supH;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = supW - x - 1;\\n\\n    // Superblock H and W\\n    y = (y << shlH) + ((tid & maskH) >> shrH);\\n    x = (x << shlW) + ((tid & maskW) >> shrW);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    A += n;\\n    O += c*DHWN + z*HWN + y*WN + mad16(x, N, n);\\n\\n    float O_val = beta != 0.0f && y < H && x < W && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int kj = c - J + pad_c + 1;\\n    int mt = z - T + pad_d + 1;\\n    int pr = y - R + pad_h + 1;\\n    int qs = x - S + pad_w + 1;\\n\\n    int sbSize = maskN + 1;\\n    int sbBits = mad16(sb, sbSize, 0);\\n    unsigned sbMask = ~(0xffffffff << sbSize) << sbBits;\\n    unsigned dep_thd_mask = (0xffffffff >> (32 - n)) << sbBits;\\n\\n    int lut_offset = mad16(sb, maxLutSize, 0);\\n    int lut_size = 0;\\n    int jrst = n;\\n    int JRSTend = JRST;\\n    if (JRSTend & maskN)\\n        JRSTend += sbSize - (JRSTend & maskN);\\n\\n    while (jrst < JRSTend)\\n    {\\n        int j   = div16(jrst, magic_RST, shift_RST);\\n        int rst = mod16(jrst, j, RST);\\n\\n        int t   = div16(rst, magic_RS, shift_RS);\\n        int rs  = mod16(rst, t, RS);\\n\\n        int r   = div16(rs, magic_S, shift_S);\\n        int s   = mod16(rs, r, S);\\n\\n        int k_prime = kj + j;\\n        int m_prime = mt + t;\\n        int p_prime = pr + r;\\n        int q_prime = qs + s;\\n\\n        int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n        int  k_mod    = mod16(k_prime, k, str_c);\\n        bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n        int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n        int  m_mod    = mod16(m_prime, m, str_d);\\n        bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n        int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n        int  p_mod    = mod16(p_prime, p, str_h);\\n        bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n        int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n        int  q_mod    = mod16(q_prime, q, str_w);\\n        bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n        bool in_bounds = jrst < JRST && k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n        // Get a mask of all valid slices in the warp\\n        unsigned ballot = __ballot(in_bounds);\\n\\n        // Count the total valid slices in this superblock\\n        int sb_slices = __popc(sbMask & ballot);\\n\\n        if (in_bounds)\\n        {\\n            // Count all the valid slices below this threadid\\n            int dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n            int j_prime = c - k_prime + pad_c;\\n            int t_prime = z - m_prime + pad_d;\\n            int r_prime = y - p_prime + pad_h;\\n            int s_prime = x - q_prime + pad_w;\\n\\n            int sliceI  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n            int argmaxI = j_prime*RST + mad16(t_prime, RS, mad16(r_prime, S, s_prime));\\n\\n            LutEntry entry;\\n            entry.data.slice  = sliceI;\\n            entry.data.argmax = argmaxI;\\n\\n            lut[lut_offset + lut_size + dep_thd_cnt] = entry.data2;\\n        }\\n        lut_size += sb_slices;\\n        jrst += sbSize;\\n    }\\n\\n    int intermediate_max = 0;\\n\\n    if (y < H && x < W && n < N)\\n    {\\n        int jrst = 0;\\n        float out = 0.0f;\\n\\n        while (jrst < maxLutSize)\\n        {\\n            LutEntry entry0;\\n            LutEntry entry1;\\n            LutEntry entry2;\\n            LutEntry entry3;\\n\\n            lut_offset = mad16(sb, maxLutSize, jrst);\\n\\n            entry0.data2 = lut[lut_offset + 0];\\n            entry1.data2 = lut[lut_offset + 1];\\n            entry2.data2 = lut[lut_offset + 2];\\n            entry3.data2 = lut[lut_offset + 3];\\n\\n            // argmax\\n            int fprop_argmax0 = jrst + 0 < lut_size ? __ldg(A + entry0.data.slice) : -2;\\n            int fprop_argmax1 = jrst + 1 < lut_size ? __ldg(A + entry1.data.slice) : -2;\\n            int fprop_argmax2 = jrst + 2 < lut_size ? __ldg(A + entry2.data.slice) : -2;\\n            int fprop_argmax3 = jrst + 3 < lut_size ? __ldg(A + entry3.data.slice) : -2;\\n\\n            out += jrst + 0 < lut_size && fprop_argmax0 == entry0.data.argmax ? %(cvt)s(__ldg(I + entry0.data.slice)) : 0.0f;\\n            out += jrst + 1 < lut_size && fprop_argmax1 == entry1.data.argmax ? %(cvt)s(__ldg(I + entry1.data.slice)) : 0.0f;\\n            out += jrst + 2 < lut_size && fprop_argmax2 == entry2.data.argmax ? %(cvt)s(__ldg(I + entry2.data.slice)) : 0.0f;\\n            out += jrst + 3 < lut_size && fprop_argmax3 == entry3.data.argmax ? %(cvt)s(__ldg(I + entry3.data.slice)) : 0.0f;\\n\\n            jrst += 4;\\n        }\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n        if (!(flags & 1))\\n            *O = temp_out;\\n\\n        // compute max-abs\\n        intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max_overlap_smallN')\n    kernel.prepare('3P 2f 58I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_max_overlap_smallN(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    code = '\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int slice;\\n        int argmax;\\n    } data;\\n    int2 data2;\\n};\\n\\n__global__ void spool_bprop_max_overlap_smallN(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN,\\n    int supH, int supW, int shlH, int maskH, int shrH,\\n    int shlW, int maskW, int shrW, int maskN, int shrN, int maxLutSize\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*supH;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = supW - x - 1;\\n\\n    // Superblock H and W\\n    y = (y << shlH) + ((tid & maskH) >> shrH);\\n    x = (x << shlW) + ((tid & maskW) >> shrW);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    A += n;\\n    O += c*DHWN + z*HWN + y*WN + mad16(x, N, n);\\n\\n    float O_val = beta != 0.0f && y < H && x < W && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int kj = c - J + pad_c + 1;\\n    int mt = z - T + pad_d + 1;\\n    int pr = y - R + pad_h + 1;\\n    int qs = x - S + pad_w + 1;\\n\\n    int sbSize = maskN + 1;\\n    int sbBits = mad16(sb, sbSize, 0);\\n    unsigned sbMask = ~(0xffffffff << sbSize) << sbBits;\\n    unsigned dep_thd_mask = (0xffffffff >> (32 - n)) << sbBits;\\n\\n    int lut_offset = mad16(sb, maxLutSize, 0);\\n    int lut_size = 0;\\n    int jrst = n;\\n    int JRSTend = JRST;\\n    if (JRSTend & maskN)\\n        JRSTend += sbSize - (JRSTend & maskN);\\n\\n    while (jrst < JRSTend)\\n    {\\n        int j   = div16(jrst, magic_RST, shift_RST);\\n        int rst = mod16(jrst, j, RST);\\n\\n        int t   = div16(rst, magic_RS, shift_RS);\\n        int rs  = mod16(rst, t, RS);\\n\\n        int r   = div16(rs, magic_S, shift_S);\\n        int s   = mod16(rs, r, S);\\n\\n        int k_prime = kj + j;\\n        int m_prime = mt + t;\\n        int p_prime = pr + r;\\n        int q_prime = qs + s;\\n\\n        int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n        int  k_mod    = mod16(k_prime, k, str_c);\\n        bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n        int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n        int  m_mod    = mod16(m_prime, m, str_d);\\n        bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n        int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n        int  p_mod    = mod16(p_prime, p, str_h);\\n        bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n        int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n        int  q_mod    = mod16(q_prime, q, str_w);\\n        bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n        bool in_bounds = jrst < JRST && k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n        // Get a mask of all valid slices in the warp\\n        unsigned ballot = __ballot(in_bounds);\\n\\n        // Count the total valid slices in this superblock\\n        int sb_slices = __popc(sbMask & ballot);\\n\\n        if (in_bounds)\\n        {\\n            // Count all the valid slices below this threadid\\n            int dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n            int j_prime = c - k_prime + pad_c;\\n            int t_prime = z - m_prime + pad_d;\\n            int r_prime = y - p_prime + pad_h;\\n            int s_prime = x - q_prime + pad_w;\\n\\n            int sliceI  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n            int argmaxI = j_prime*RST + mad16(t_prime, RS, mad16(r_prime, S, s_prime));\\n\\n            LutEntry entry;\\n            entry.data.slice  = sliceI;\\n            entry.data.argmax = argmaxI;\\n\\n            lut[lut_offset + lut_size + dep_thd_cnt] = entry.data2;\\n        }\\n        lut_size += sb_slices;\\n        jrst += sbSize;\\n    }\\n\\n    int intermediate_max = 0;\\n\\n    if (y < H && x < W && n < N)\\n    {\\n        int jrst = 0;\\n        float out = 0.0f;\\n\\n        while (jrst < maxLutSize)\\n        {\\n            LutEntry entry0;\\n            LutEntry entry1;\\n            LutEntry entry2;\\n            LutEntry entry3;\\n\\n            lut_offset = mad16(sb, maxLutSize, jrst);\\n\\n            entry0.data2 = lut[lut_offset + 0];\\n            entry1.data2 = lut[lut_offset + 1];\\n            entry2.data2 = lut[lut_offset + 2];\\n            entry3.data2 = lut[lut_offset + 3];\\n\\n            // argmax\\n            int fprop_argmax0 = jrst + 0 < lut_size ? __ldg(A + entry0.data.slice) : -2;\\n            int fprop_argmax1 = jrst + 1 < lut_size ? __ldg(A + entry1.data.slice) : -2;\\n            int fprop_argmax2 = jrst + 2 < lut_size ? __ldg(A + entry2.data.slice) : -2;\\n            int fprop_argmax3 = jrst + 3 < lut_size ? __ldg(A + entry3.data.slice) : -2;\\n\\n            out += jrst + 0 < lut_size && fprop_argmax0 == entry0.data.argmax ? %(cvt)s(__ldg(I + entry0.data.slice)) : 0.0f;\\n            out += jrst + 1 < lut_size && fprop_argmax1 == entry1.data.argmax ? %(cvt)s(__ldg(I + entry1.data.slice)) : 0.0f;\\n            out += jrst + 2 < lut_size && fprop_argmax2 == entry2.data.argmax ? %(cvt)s(__ldg(I + entry2.data.slice)) : 0.0f;\\n            out += jrst + 3 < lut_size && fprop_argmax3 == entry3.data.argmax ? %(cvt)s(__ldg(I + entry3.data.slice)) : 0.0f;\\n\\n            jrst += 4;\\n        }\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n        if (!(flags & 1))\\n            *O = temp_out;\\n\\n        // compute max-abs\\n        intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code)\n    kernel = module.get_function('spool_bprop_max_overlap_smallN')\n    kernel.prepare('3P 2f 58I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel"
        ]
    },
    {
        "func_name": "_get_bprop_avg_overlap_smallN",
        "original": "@context_dependent_memoize\ndef _get_bprop_avg_overlap_smallN(clss, compute_capability):\n    code = '\\n\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int   slice;\\n        float rcp_in;\\n    } data;\\n    int2 data2;\\n};\\n\\n__device__ __forceinline__ int imin(int val1, int val2)\\n{\\n    int ret;\\n    asm(\"min.s32 %%0, %%1, %%2;\" : \"=r\"(ret) : \"r\"(val1), \"r\"(val2));\\n    return ret;\\n}\\n\\n__global__ void spool_bprop_avg_overlap_smallN(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN,\\n    int supH, int supW, int shlH, int maskH, int shrH,\\n    int shlW, int maskW, int shrW, int maskN, int shrN, int maxLutSize\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*supH;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = supW - x - 1;\\n\\n    // Superblock H and W\\n    y = (y << shlH) + ((tid & maskH) >> shrH);\\n    x = (x << shlW) + ((tid & maskW) >> shrW);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    O += c*DHWN + z*HWN + y*WN + mad16(x, N, n);\\n\\n    float O_val = beta != 0.0f && y < H && x < W && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int kj = c - J + pad_c + 1;\\n    int mt = z - T + pad_d + 1;\\n    int pr = y - R + pad_h + 1;\\n    int qs = x - S + pad_w + 1;\\n\\n    int sbSize = maskN + 1;\\n    int sbBits = mad16(sb, sbSize, 0);\\n    unsigned sbMask = ~(0xffffffff << sbSize) << sbBits;\\n    unsigned dep_thd_mask = (0xffffffff >> (32 - n)) << sbBits;\\n\\n    int lut_offset = mad16(sb, maxLutSize, 0);\\n    int lut_size = 0;\\n    int jrst = n;\\n    int JRSTend = JRST;\\n    if (JRSTend & maskN)\\n        JRSTend += sbSize - (JRSTend & maskN);\\n\\n    while (jrst < JRSTend)\\n    {\\n        int j   = div16(jrst, magic_RST, shift_RST);\\n        int rst = mod16(jrst, j, RST);\\n\\n        int t   = div16(rst, magic_RS, shift_RS);\\n        int rs  = mod16(rst, t, RS);\\n\\n        int r   = div16(rs, magic_S, shift_S);\\n        int s   = mod16(rs, r, S);\\n\\n        int k_prime = kj + j;\\n        int m_prime = mt + t;\\n        int p_prime = pr + r;\\n        int q_prime = qs + s;\\n\\n        int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n        int  k_mod    = mod16(k_prime, k, str_c);\\n        bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n        int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n        int  m_mod    = mod16(m_prime, m, str_d);\\n        bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n        int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n        int  p_mod    = mod16(p_prime, p, str_h);\\n        bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n        int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n        int  q_mod    = mod16(q_prime, q, str_w);\\n        bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n        bool in_bounds = jrst < JRST && k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n        // Get a mask of all valid slices in the warp\\n        unsigned ballot = __ballot(in_bounds);\\n\\n        // Count the total valid slices in this superblock\\n        int sb_slices = __popc(sbMask & ballot);\\n\\n        if (in_bounds)\\n        {\\n            // Count all the valid slices below this threadid\\n            int dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n            int c_left = msub16(k, str_c, pad_c);\\n            int z_left = msub16(m, str_d, pad_d);\\n            int y_left = msub16(p, str_h, pad_h);\\n            int x_left = msub16(q, str_w, pad_w);\\n\\n            float k_in = (float)imin( imin(J + c_left, J), imin(C - c_left, J) );\\n            float m_in = (float)imin( imin(T + z_left, T), imin(D - z_left, T) );\\n            float p_in = (float)imin( imin(R + y_left, R), imin(H - y_left, R) );\\n            float q_in = (float)imin( imin(S + x_left, S), imin(W - x_left, S) );\\n\\n            float total_in = q_in * p_in * m_in * k_in;\\n\\n            LutEntry entry;\\n            entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n            entry.data.rcp_in = total_in > 0.0f ? 1.0f / total_in : 0.0f;\\n\\n            lut[lut_offset + lut_size + dep_thd_cnt] = entry.data2;\\n        }\\n        lut_size += sb_slices;\\n        jrst += sbSize;\\n    }\\n\\n    int intermediate_max = 0;\\n\\n    if (y < H && x < W && n < N)\\n    {\\n        int jrst = 0;\\n        float out = 0.0f;\\n\\n        while (jrst < maxLutSize)\\n        {\\n            LutEntry entry0;\\n            LutEntry entry1;\\n            LutEntry entry2;\\n            LutEntry entry3;\\n\\n            lut_offset = mad16(sb, maxLutSize, jrst);\\n\\n            entry0.data2 = lut[lut_offset + 0];\\n            entry1.data2 = lut[lut_offset + 1];\\n            entry2.data2 = lut[lut_offset + 2];\\n            entry3.data2 = lut[lut_offset + 3];\\n\\n            out += jrst + 0 < lut_size ? %(cvt)s(__ldg(I + entry0.data.slice)) * entry0.data.rcp_in : 0.0f;\\n            out += jrst + 1 < lut_size ? %(cvt)s(__ldg(I + entry1.data.slice)) * entry1.data.rcp_in : 0.0f;\\n            out += jrst + 2 < lut_size ? %(cvt)s(__ldg(I + entry2.data.slice)) * entry2.data.rcp_in : 0.0f;\\n            out += jrst + 3 < lut_size ? %(cvt)s(__ldg(I + entry3.data.slice)) * entry3.data.rcp_in : 0.0f;\\n\\n            jrst += 4;\\n        }\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n        if (!(flags & 1))\\n            *O = temp_out;\\n\\n        // max-abs over unrolls\\n        intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg_overlap_smallN')\n    kernel.prepare('3P 2f 58I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
        "mutated": [
            "@context_dependent_memoize\ndef _get_bprop_avg_overlap_smallN(clss, compute_capability):\n    if False:\n        i = 10\n    code = '\\n\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int   slice;\\n        float rcp_in;\\n    } data;\\n    int2 data2;\\n};\\n\\n__device__ __forceinline__ int imin(int val1, int val2)\\n{\\n    int ret;\\n    asm(\"min.s32 %%0, %%1, %%2;\" : \"=r\"(ret) : \"r\"(val1), \"r\"(val2));\\n    return ret;\\n}\\n\\n__global__ void spool_bprop_avg_overlap_smallN(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN,\\n    int supH, int supW, int shlH, int maskH, int shrH,\\n    int shlW, int maskW, int shrW, int maskN, int shrN, int maxLutSize\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*supH;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = supW - x - 1;\\n\\n    // Superblock H and W\\n    y = (y << shlH) + ((tid & maskH) >> shrH);\\n    x = (x << shlW) + ((tid & maskW) >> shrW);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    O += c*DHWN + z*HWN + y*WN + mad16(x, N, n);\\n\\n    float O_val = beta != 0.0f && y < H && x < W && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int kj = c - J + pad_c + 1;\\n    int mt = z - T + pad_d + 1;\\n    int pr = y - R + pad_h + 1;\\n    int qs = x - S + pad_w + 1;\\n\\n    int sbSize = maskN + 1;\\n    int sbBits = mad16(sb, sbSize, 0);\\n    unsigned sbMask = ~(0xffffffff << sbSize) << sbBits;\\n    unsigned dep_thd_mask = (0xffffffff >> (32 - n)) << sbBits;\\n\\n    int lut_offset = mad16(sb, maxLutSize, 0);\\n    int lut_size = 0;\\n    int jrst = n;\\n    int JRSTend = JRST;\\n    if (JRSTend & maskN)\\n        JRSTend += sbSize - (JRSTend & maskN);\\n\\n    while (jrst < JRSTend)\\n    {\\n        int j   = div16(jrst, magic_RST, shift_RST);\\n        int rst = mod16(jrst, j, RST);\\n\\n        int t   = div16(rst, magic_RS, shift_RS);\\n        int rs  = mod16(rst, t, RS);\\n\\n        int r   = div16(rs, magic_S, shift_S);\\n        int s   = mod16(rs, r, S);\\n\\n        int k_prime = kj + j;\\n        int m_prime = mt + t;\\n        int p_prime = pr + r;\\n        int q_prime = qs + s;\\n\\n        int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n        int  k_mod    = mod16(k_prime, k, str_c);\\n        bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n        int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n        int  m_mod    = mod16(m_prime, m, str_d);\\n        bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n        int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n        int  p_mod    = mod16(p_prime, p, str_h);\\n        bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n        int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n        int  q_mod    = mod16(q_prime, q, str_w);\\n        bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n        bool in_bounds = jrst < JRST && k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n        // Get a mask of all valid slices in the warp\\n        unsigned ballot = __ballot(in_bounds);\\n\\n        // Count the total valid slices in this superblock\\n        int sb_slices = __popc(sbMask & ballot);\\n\\n        if (in_bounds)\\n        {\\n            // Count all the valid slices below this threadid\\n            int dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n            int c_left = msub16(k, str_c, pad_c);\\n            int z_left = msub16(m, str_d, pad_d);\\n            int y_left = msub16(p, str_h, pad_h);\\n            int x_left = msub16(q, str_w, pad_w);\\n\\n            float k_in = (float)imin( imin(J + c_left, J), imin(C - c_left, J) );\\n            float m_in = (float)imin( imin(T + z_left, T), imin(D - z_left, T) );\\n            float p_in = (float)imin( imin(R + y_left, R), imin(H - y_left, R) );\\n            float q_in = (float)imin( imin(S + x_left, S), imin(W - x_left, S) );\\n\\n            float total_in = q_in * p_in * m_in * k_in;\\n\\n            LutEntry entry;\\n            entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n            entry.data.rcp_in = total_in > 0.0f ? 1.0f / total_in : 0.0f;\\n\\n            lut[lut_offset + lut_size + dep_thd_cnt] = entry.data2;\\n        }\\n        lut_size += sb_slices;\\n        jrst += sbSize;\\n    }\\n\\n    int intermediate_max = 0;\\n\\n    if (y < H && x < W && n < N)\\n    {\\n        int jrst = 0;\\n        float out = 0.0f;\\n\\n        while (jrst < maxLutSize)\\n        {\\n            LutEntry entry0;\\n            LutEntry entry1;\\n            LutEntry entry2;\\n            LutEntry entry3;\\n\\n            lut_offset = mad16(sb, maxLutSize, jrst);\\n\\n            entry0.data2 = lut[lut_offset + 0];\\n            entry1.data2 = lut[lut_offset + 1];\\n            entry2.data2 = lut[lut_offset + 2];\\n            entry3.data2 = lut[lut_offset + 3];\\n\\n            out += jrst + 0 < lut_size ? %(cvt)s(__ldg(I + entry0.data.slice)) * entry0.data.rcp_in : 0.0f;\\n            out += jrst + 1 < lut_size ? %(cvt)s(__ldg(I + entry1.data.slice)) * entry1.data.rcp_in : 0.0f;\\n            out += jrst + 2 < lut_size ? %(cvt)s(__ldg(I + entry2.data.slice)) * entry2.data.rcp_in : 0.0f;\\n            out += jrst + 3 < lut_size ? %(cvt)s(__ldg(I + entry3.data.slice)) * entry3.data.rcp_in : 0.0f;\\n\\n            jrst += 4;\\n        }\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n        if (!(flags & 1))\\n            *O = temp_out;\\n\\n        // max-abs over unrolls\\n        intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg_overlap_smallN')\n    kernel.prepare('3P 2f 58I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_avg_overlap_smallN(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    code = '\\n\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int   slice;\\n        float rcp_in;\\n    } data;\\n    int2 data2;\\n};\\n\\n__device__ __forceinline__ int imin(int val1, int val2)\\n{\\n    int ret;\\n    asm(\"min.s32 %%0, %%1, %%2;\" : \"=r\"(ret) : \"r\"(val1), \"r\"(val2));\\n    return ret;\\n}\\n\\n__global__ void spool_bprop_avg_overlap_smallN(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN,\\n    int supH, int supW, int shlH, int maskH, int shrH,\\n    int shlW, int maskW, int shrW, int maskN, int shrN, int maxLutSize\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*supH;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = supW - x - 1;\\n\\n    // Superblock H and W\\n    y = (y << shlH) + ((tid & maskH) >> shrH);\\n    x = (x << shlW) + ((tid & maskW) >> shrW);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    O += c*DHWN + z*HWN + y*WN + mad16(x, N, n);\\n\\n    float O_val = beta != 0.0f && y < H && x < W && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int kj = c - J + pad_c + 1;\\n    int mt = z - T + pad_d + 1;\\n    int pr = y - R + pad_h + 1;\\n    int qs = x - S + pad_w + 1;\\n\\n    int sbSize = maskN + 1;\\n    int sbBits = mad16(sb, sbSize, 0);\\n    unsigned sbMask = ~(0xffffffff << sbSize) << sbBits;\\n    unsigned dep_thd_mask = (0xffffffff >> (32 - n)) << sbBits;\\n\\n    int lut_offset = mad16(sb, maxLutSize, 0);\\n    int lut_size = 0;\\n    int jrst = n;\\n    int JRSTend = JRST;\\n    if (JRSTend & maskN)\\n        JRSTend += sbSize - (JRSTend & maskN);\\n\\n    while (jrst < JRSTend)\\n    {\\n        int j   = div16(jrst, magic_RST, shift_RST);\\n        int rst = mod16(jrst, j, RST);\\n\\n        int t   = div16(rst, magic_RS, shift_RS);\\n        int rs  = mod16(rst, t, RS);\\n\\n        int r   = div16(rs, magic_S, shift_S);\\n        int s   = mod16(rs, r, S);\\n\\n        int k_prime = kj + j;\\n        int m_prime = mt + t;\\n        int p_prime = pr + r;\\n        int q_prime = qs + s;\\n\\n        int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n        int  k_mod    = mod16(k_prime, k, str_c);\\n        bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n        int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n        int  m_mod    = mod16(m_prime, m, str_d);\\n        bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n        int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n        int  p_mod    = mod16(p_prime, p, str_h);\\n        bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n        int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n        int  q_mod    = mod16(q_prime, q, str_w);\\n        bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n        bool in_bounds = jrst < JRST && k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n        // Get a mask of all valid slices in the warp\\n        unsigned ballot = __ballot(in_bounds);\\n\\n        // Count the total valid slices in this superblock\\n        int sb_slices = __popc(sbMask & ballot);\\n\\n        if (in_bounds)\\n        {\\n            // Count all the valid slices below this threadid\\n            int dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n            int c_left = msub16(k, str_c, pad_c);\\n            int z_left = msub16(m, str_d, pad_d);\\n            int y_left = msub16(p, str_h, pad_h);\\n            int x_left = msub16(q, str_w, pad_w);\\n\\n            float k_in = (float)imin( imin(J + c_left, J), imin(C - c_left, J) );\\n            float m_in = (float)imin( imin(T + z_left, T), imin(D - z_left, T) );\\n            float p_in = (float)imin( imin(R + y_left, R), imin(H - y_left, R) );\\n            float q_in = (float)imin( imin(S + x_left, S), imin(W - x_left, S) );\\n\\n            float total_in = q_in * p_in * m_in * k_in;\\n\\n            LutEntry entry;\\n            entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n            entry.data.rcp_in = total_in > 0.0f ? 1.0f / total_in : 0.0f;\\n\\n            lut[lut_offset + lut_size + dep_thd_cnt] = entry.data2;\\n        }\\n        lut_size += sb_slices;\\n        jrst += sbSize;\\n    }\\n\\n    int intermediate_max = 0;\\n\\n    if (y < H && x < W && n < N)\\n    {\\n        int jrst = 0;\\n        float out = 0.0f;\\n\\n        while (jrst < maxLutSize)\\n        {\\n            LutEntry entry0;\\n            LutEntry entry1;\\n            LutEntry entry2;\\n            LutEntry entry3;\\n\\n            lut_offset = mad16(sb, maxLutSize, jrst);\\n\\n            entry0.data2 = lut[lut_offset + 0];\\n            entry1.data2 = lut[lut_offset + 1];\\n            entry2.data2 = lut[lut_offset + 2];\\n            entry3.data2 = lut[lut_offset + 3];\\n\\n            out += jrst + 0 < lut_size ? %(cvt)s(__ldg(I + entry0.data.slice)) * entry0.data.rcp_in : 0.0f;\\n            out += jrst + 1 < lut_size ? %(cvt)s(__ldg(I + entry1.data.slice)) * entry1.data.rcp_in : 0.0f;\\n            out += jrst + 2 < lut_size ? %(cvt)s(__ldg(I + entry2.data.slice)) * entry2.data.rcp_in : 0.0f;\\n            out += jrst + 3 < lut_size ? %(cvt)s(__ldg(I + entry3.data.slice)) * entry3.data.rcp_in : 0.0f;\\n\\n            jrst += 4;\\n        }\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n        if (!(flags & 1))\\n            *O = temp_out;\\n\\n        // max-abs over unrolls\\n        intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg_overlap_smallN')\n    kernel.prepare('3P 2f 58I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_avg_overlap_smallN(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    code = '\\n\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int   slice;\\n        float rcp_in;\\n    } data;\\n    int2 data2;\\n};\\n\\n__device__ __forceinline__ int imin(int val1, int val2)\\n{\\n    int ret;\\n    asm(\"min.s32 %%0, %%1, %%2;\" : \"=r\"(ret) : \"r\"(val1), \"r\"(val2));\\n    return ret;\\n}\\n\\n__global__ void spool_bprop_avg_overlap_smallN(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN,\\n    int supH, int supW, int shlH, int maskH, int shrH,\\n    int shlW, int maskW, int shrW, int maskN, int shrN, int maxLutSize\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*supH;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = supW - x - 1;\\n\\n    // Superblock H and W\\n    y = (y << shlH) + ((tid & maskH) >> shrH);\\n    x = (x << shlW) + ((tid & maskW) >> shrW);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    O += c*DHWN + z*HWN + y*WN + mad16(x, N, n);\\n\\n    float O_val = beta != 0.0f && y < H && x < W && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int kj = c - J + pad_c + 1;\\n    int mt = z - T + pad_d + 1;\\n    int pr = y - R + pad_h + 1;\\n    int qs = x - S + pad_w + 1;\\n\\n    int sbSize = maskN + 1;\\n    int sbBits = mad16(sb, sbSize, 0);\\n    unsigned sbMask = ~(0xffffffff << sbSize) << sbBits;\\n    unsigned dep_thd_mask = (0xffffffff >> (32 - n)) << sbBits;\\n\\n    int lut_offset = mad16(sb, maxLutSize, 0);\\n    int lut_size = 0;\\n    int jrst = n;\\n    int JRSTend = JRST;\\n    if (JRSTend & maskN)\\n        JRSTend += sbSize - (JRSTend & maskN);\\n\\n    while (jrst < JRSTend)\\n    {\\n        int j   = div16(jrst, magic_RST, shift_RST);\\n        int rst = mod16(jrst, j, RST);\\n\\n        int t   = div16(rst, magic_RS, shift_RS);\\n        int rs  = mod16(rst, t, RS);\\n\\n        int r   = div16(rs, magic_S, shift_S);\\n        int s   = mod16(rs, r, S);\\n\\n        int k_prime = kj + j;\\n        int m_prime = mt + t;\\n        int p_prime = pr + r;\\n        int q_prime = qs + s;\\n\\n        int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n        int  k_mod    = mod16(k_prime, k, str_c);\\n        bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n        int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n        int  m_mod    = mod16(m_prime, m, str_d);\\n        bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n        int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n        int  p_mod    = mod16(p_prime, p, str_h);\\n        bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n        int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n        int  q_mod    = mod16(q_prime, q, str_w);\\n        bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n        bool in_bounds = jrst < JRST && k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n        // Get a mask of all valid slices in the warp\\n        unsigned ballot = __ballot(in_bounds);\\n\\n        // Count the total valid slices in this superblock\\n        int sb_slices = __popc(sbMask & ballot);\\n\\n        if (in_bounds)\\n        {\\n            // Count all the valid slices below this threadid\\n            int dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n            int c_left = msub16(k, str_c, pad_c);\\n            int z_left = msub16(m, str_d, pad_d);\\n            int y_left = msub16(p, str_h, pad_h);\\n            int x_left = msub16(q, str_w, pad_w);\\n\\n            float k_in = (float)imin( imin(J + c_left, J), imin(C - c_left, J) );\\n            float m_in = (float)imin( imin(T + z_left, T), imin(D - z_left, T) );\\n            float p_in = (float)imin( imin(R + y_left, R), imin(H - y_left, R) );\\n            float q_in = (float)imin( imin(S + x_left, S), imin(W - x_left, S) );\\n\\n            float total_in = q_in * p_in * m_in * k_in;\\n\\n            LutEntry entry;\\n            entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n            entry.data.rcp_in = total_in > 0.0f ? 1.0f / total_in : 0.0f;\\n\\n            lut[lut_offset + lut_size + dep_thd_cnt] = entry.data2;\\n        }\\n        lut_size += sb_slices;\\n        jrst += sbSize;\\n    }\\n\\n    int intermediate_max = 0;\\n\\n    if (y < H && x < W && n < N)\\n    {\\n        int jrst = 0;\\n        float out = 0.0f;\\n\\n        while (jrst < maxLutSize)\\n        {\\n            LutEntry entry0;\\n            LutEntry entry1;\\n            LutEntry entry2;\\n            LutEntry entry3;\\n\\n            lut_offset = mad16(sb, maxLutSize, jrst);\\n\\n            entry0.data2 = lut[lut_offset + 0];\\n            entry1.data2 = lut[lut_offset + 1];\\n            entry2.data2 = lut[lut_offset + 2];\\n            entry3.data2 = lut[lut_offset + 3];\\n\\n            out += jrst + 0 < lut_size ? %(cvt)s(__ldg(I + entry0.data.slice)) * entry0.data.rcp_in : 0.0f;\\n            out += jrst + 1 < lut_size ? %(cvt)s(__ldg(I + entry1.data.slice)) * entry1.data.rcp_in : 0.0f;\\n            out += jrst + 2 < lut_size ? %(cvt)s(__ldg(I + entry2.data.slice)) * entry2.data.rcp_in : 0.0f;\\n            out += jrst + 3 < lut_size ? %(cvt)s(__ldg(I + entry3.data.slice)) * entry3.data.rcp_in : 0.0f;\\n\\n            jrst += 4;\\n        }\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n        if (!(flags & 1))\\n            *O = temp_out;\\n\\n        // max-abs over unrolls\\n        intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg_overlap_smallN')\n    kernel.prepare('3P 2f 58I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_avg_overlap_smallN(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    code = '\\n\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int   slice;\\n        float rcp_in;\\n    } data;\\n    int2 data2;\\n};\\n\\n__device__ __forceinline__ int imin(int val1, int val2)\\n{\\n    int ret;\\n    asm(\"min.s32 %%0, %%1, %%2;\" : \"=r\"(ret) : \"r\"(val1), \"r\"(val2));\\n    return ret;\\n}\\n\\n__global__ void spool_bprop_avg_overlap_smallN(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN,\\n    int supH, int supW, int shlH, int maskH, int shrH,\\n    int shlW, int maskW, int shrW, int maskN, int shrN, int maxLutSize\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*supH;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = supW - x - 1;\\n\\n    // Superblock H and W\\n    y = (y << shlH) + ((tid & maskH) >> shrH);\\n    x = (x << shlW) + ((tid & maskW) >> shrW);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    O += c*DHWN + z*HWN + y*WN + mad16(x, N, n);\\n\\n    float O_val = beta != 0.0f && y < H && x < W && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int kj = c - J + pad_c + 1;\\n    int mt = z - T + pad_d + 1;\\n    int pr = y - R + pad_h + 1;\\n    int qs = x - S + pad_w + 1;\\n\\n    int sbSize = maskN + 1;\\n    int sbBits = mad16(sb, sbSize, 0);\\n    unsigned sbMask = ~(0xffffffff << sbSize) << sbBits;\\n    unsigned dep_thd_mask = (0xffffffff >> (32 - n)) << sbBits;\\n\\n    int lut_offset = mad16(sb, maxLutSize, 0);\\n    int lut_size = 0;\\n    int jrst = n;\\n    int JRSTend = JRST;\\n    if (JRSTend & maskN)\\n        JRSTend += sbSize - (JRSTend & maskN);\\n\\n    while (jrst < JRSTend)\\n    {\\n        int j   = div16(jrst, magic_RST, shift_RST);\\n        int rst = mod16(jrst, j, RST);\\n\\n        int t   = div16(rst, magic_RS, shift_RS);\\n        int rs  = mod16(rst, t, RS);\\n\\n        int r   = div16(rs, magic_S, shift_S);\\n        int s   = mod16(rs, r, S);\\n\\n        int k_prime = kj + j;\\n        int m_prime = mt + t;\\n        int p_prime = pr + r;\\n        int q_prime = qs + s;\\n\\n        int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n        int  k_mod    = mod16(k_prime, k, str_c);\\n        bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n        int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n        int  m_mod    = mod16(m_prime, m, str_d);\\n        bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n        int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n        int  p_mod    = mod16(p_prime, p, str_h);\\n        bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n        int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n        int  q_mod    = mod16(q_prime, q, str_w);\\n        bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n        bool in_bounds = jrst < JRST && k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n        // Get a mask of all valid slices in the warp\\n        unsigned ballot = __ballot(in_bounds);\\n\\n        // Count the total valid slices in this superblock\\n        int sb_slices = __popc(sbMask & ballot);\\n\\n        if (in_bounds)\\n        {\\n            // Count all the valid slices below this threadid\\n            int dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n            int c_left = msub16(k, str_c, pad_c);\\n            int z_left = msub16(m, str_d, pad_d);\\n            int y_left = msub16(p, str_h, pad_h);\\n            int x_left = msub16(q, str_w, pad_w);\\n\\n            float k_in = (float)imin( imin(J + c_left, J), imin(C - c_left, J) );\\n            float m_in = (float)imin( imin(T + z_left, T), imin(D - z_left, T) );\\n            float p_in = (float)imin( imin(R + y_left, R), imin(H - y_left, R) );\\n            float q_in = (float)imin( imin(S + x_left, S), imin(W - x_left, S) );\\n\\n            float total_in = q_in * p_in * m_in * k_in;\\n\\n            LutEntry entry;\\n            entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n            entry.data.rcp_in = total_in > 0.0f ? 1.0f / total_in : 0.0f;\\n\\n            lut[lut_offset + lut_size + dep_thd_cnt] = entry.data2;\\n        }\\n        lut_size += sb_slices;\\n        jrst += sbSize;\\n    }\\n\\n    int intermediate_max = 0;\\n\\n    if (y < H && x < W && n < N)\\n    {\\n        int jrst = 0;\\n        float out = 0.0f;\\n\\n        while (jrst < maxLutSize)\\n        {\\n            LutEntry entry0;\\n            LutEntry entry1;\\n            LutEntry entry2;\\n            LutEntry entry3;\\n\\n            lut_offset = mad16(sb, maxLutSize, jrst);\\n\\n            entry0.data2 = lut[lut_offset + 0];\\n            entry1.data2 = lut[lut_offset + 1];\\n            entry2.data2 = lut[lut_offset + 2];\\n            entry3.data2 = lut[lut_offset + 3];\\n\\n            out += jrst + 0 < lut_size ? %(cvt)s(__ldg(I + entry0.data.slice)) * entry0.data.rcp_in : 0.0f;\\n            out += jrst + 1 < lut_size ? %(cvt)s(__ldg(I + entry1.data.slice)) * entry1.data.rcp_in : 0.0f;\\n            out += jrst + 2 < lut_size ? %(cvt)s(__ldg(I + entry2.data.slice)) * entry2.data.rcp_in : 0.0f;\\n            out += jrst + 3 < lut_size ? %(cvt)s(__ldg(I + entry3.data.slice)) * entry3.data.rcp_in : 0.0f;\\n\\n            jrst += 4;\\n        }\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n        if (!(flags & 1))\\n            *O = temp_out;\\n\\n        // max-abs over unrolls\\n        intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg_overlap_smallN')\n    kernel.prepare('3P 2f 58I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel",
            "@context_dependent_memoize\ndef _get_bprop_avg_overlap_smallN(clss, compute_capability):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    code = '\\n\\n%(common)s\\n\\nunion LutEntry {\\n    struct {\\n        int   slice;\\n        float rcp_in;\\n    } data;\\n    int2 data2;\\n};\\n\\n__device__ __forceinline__ int imin(int val1, int val2)\\n{\\n    int ret;\\n    asm(\"min.s32 %%0, %%1, %%2;\" : \"=r\"(ret) : \"r\"(val1), \"r\"(val2));\\n    return ret;\\n}\\n\\n__global__ void spool_bprop_avg_overlap_smallN(\\n    const %(type)s* I, %(type)s* O, const unsigned char* A,\\n    float alpha, float beta, int flags,\\n    int N, int W, int H, int D, int C,\\n    int WN, int HWN, int DHWN,\\n    int magic_H, int shift_H,\\n    int pad_w, int pad_h, int pad_d, int pad_c,\\n    int str_w, int str_h, int str_d, int str_c,\\n    int magic_str_w, int shift_str_w,\\n    int magic_str_h, int shift_str_h,\\n    int magic_str_d, int shift_str_d,\\n    int magic_str_c, int shift_str_c,\\n    int S, int R, int T, int J, int RS, int RST, int JRST,\\n    int magic_S, int shift_S, int magic_RS, int shift_RS,\\n    int magic_RST, int shift_RST,\\n    int Q, int P, int M, int K, int QN, int PQN, int MPQN,\\n    int supH, int supW, int shlH, int maskH, int shrH,\\n    int shlW, int maskW, int shrW, int maskN, int shrN, int maxLutSize\\n    %(stats_args)s  // template for \"int* maxabs, float scale0\"\\n    )\\n{\\n    extern __shared__ int2 lut[];\\n\\n    int tid = threadIdx.x;\\n\\n    int x  = blockIdx.x;\\n    int yz = blockIdx.y;\\n    int c  = blockIdx.z;\\n\\n    int z = yz * magic_H; z >>= shift_H;\\n    int y = yz - z*supH;\\n\\n    // zigzag q back and forth to improve L2 cache perf\\n    if (y & 1)\\n        x = supW - x - 1;\\n\\n    // Superblock H and W\\n    y = (y << shlH) + ((tid & maskH) >> shrH);\\n    x = (x << shlW) + ((tid & maskW) >> shrW);\\n    int n = tid & maskN;\\n\\n    int sb = tid >> shrN;\\n\\n    I += n;\\n    O += c*DHWN + z*HWN + y*WN + mad16(x, N, n);\\n\\n    float O_val = beta != 0.0f && y < H && x < W && n < N ? %(cvt)s(__ldg(O)) : 0.0f;\\n\\n    int kj = c - J + pad_c + 1;\\n    int mt = z - T + pad_d + 1;\\n    int pr = y - R + pad_h + 1;\\n    int qs = x - S + pad_w + 1;\\n\\n    int sbSize = maskN + 1;\\n    int sbBits = mad16(sb, sbSize, 0);\\n    unsigned sbMask = ~(0xffffffff << sbSize) << sbBits;\\n    unsigned dep_thd_mask = (0xffffffff >> (32 - n)) << sbBits;\\n\\n    int lut_offset = mad16(sb, maxLutSize, 0);\\n    int lut_size = 0;\\n    int jrst = n;\\n    int JRSTend = JRST;\\n    if (JRSTend & maskN)\\n        JRSTend += sbSize - (JRSTend & maskN);\\n\\n    while (jrst < JRSTend)\\n    {\\n        int j   = div16(jrst, magic_RST, shift_RST);\\n        int rst = mod16(jrst, j, RST);\\n\\n        int t   = div16(rst, magic_RS, shift_RS);\\n        int rs  = mod16(rst, t, RS);\\n\\n        int r   = div16(rs, magic_S, shift_S);\\n        int s   = mod16(rs, r, S);\\n\\n        int k_prime = kj + j;\\n        int m_prime = mt + t;\\n        int p_prime = pr + r;\\n        int q_prime = qs + s;\\n\\n        int  k        = div16(k_prime, magic_str_c, shift_str_c);\\n        int  k_mod    = mod16(k_prime, k, str_c);\\n        bool k_bounds = k_mod == 0 && k >= 0 && k < K;\\n\\n        int  m        = div16(m_prime, magic_str_d, shift_str_d);\\n        int  m_mod    = mod16(m_prime, m, str_d);\\n        bool m_bounds = m_mod == 0 && m >= 0 && m < M;\\n\\n        int  p        = div16(p_prime, magic_str_h, shift_str_h);\\n        int  p_mod    = mod16(p_prime, p, str_h);\\n        bool p_bounds = p_mod == 0 && p >= 0 && p < P;\\n\\n        int  q        = div16(q_prime, magic_str_w, shift_str_w);\\n        int  q_mod    = mod16(q_prime, q, str_w);\\n        bool q_bounds = q_mod == 0 && q >= 0 && q < Q;\\n\\n        bool in_bounds = jrst < JRST && k_bounds && m_bounds && p_bounds && q_bounds;\\n\\n        // Get a mask of all valid slices in the warp\\n        unsigned ballot = __ballot(in_bounds);\\n\\n        // Count the total valid slices in this superblock\\n        int sb_slices = __popc(sbMask & ballot);\\n\\n        if (in_bounds)\\n        {\\n            // Count all the valid slices below this threadid\\n            int dep_thd_cnt = __popc(dep_thd_mask & ballot);\\n\\n            int c_left = msub16(k, str_c, pad_c);\\n            int z_left = msub16(m, str_d, pad_d);\\n            int y_left = msub16(p, str_h, pad_h);\\n            int x_left = msub16(q, str_w, pad_w);\\n\\n            float k_in = (float)imin( imin(J + c_left, J), imin(C - c_left, J) );\\n            float m_in = (float)imin( imin(T + z_left, T), imin(D - z_left, T) );\\n            float p_in = (float)imin( imin(R + y_left, R), imin(H - y_left, R) );\\n            float q_in = (float)imin( imin(S + x_left, S), imin(W - x_left, S) );\\n\\n            float total_in = q_in * p_in * m_in * k_in;\\n\\n            LutEntry entry;\\n            entry.data.slice  = k*MPQN + m*PQN + p*QN + mad16(q, N, 0);\\n            entry.data.rcp_in = total_in > 0.0f ? 1.0f / total_in : 0.0f;\\n\\n            lut[lut_offset + lut_size + dep_thd_cnt] = entry.data2;\\n        }\\n        lut_size += sb_slices;\\n        jrst += sbSize;\\n    }\\n\\n    int intermediate_max = 0;\\n\\n    if (y < H && x < W && n < N)\\n    {\\n        int jrst = 0;\\n        float out = 0.0f;\\n\\n        while (jrst < maxLutSize)\\n        {\\n            LutEntry entry0;\\n            LutEntry entry1;\\n            LutEntry entry2;\\n            LutEntry entry3;\\n\\n            lut_offset = mad16(sb, maxLutSize, jrst);\\n\\n            entry0.data2 = lut[lut_offset + 0];\\n            entry1.data2 = lut[lut_offset + 1];\\n            entry2.data2 = lut[lut_offset + 2];\\n            entry3.data2 = lut[lut_offset + 3];\\n\\n            out += jrst + 0 < lut_size ? %(cvt)s(__ldg(I + entry0.data.slice)) * entry0.data.rcp_in : 0.0f;\\n            out += jrst + 1 < lut_size ? %(cvt)s(__ldg(I + entry1.data.slice)) * entry1.data.rcp_in : 0.0f;\\n            out += jrst + 2 < lut_size ? %(cvt)s(__ldg(I + entry2.data.slice)) * entry2.data.rcp_in : 0.0f;\\n            out += jrst + 3 < lut_size ? %(cvt)s(__ldg(I + entry3.data.slice)) * entry3.data.rcp_in : 0.0f;\\n\\n            jrst += 4;\\n        }\\n        %(type)s temp_out = %(cvt_out)s( %(mul_by_scale)s (out*alpha + O_val*beta));\\n        if (!(flags & 1))\\n            *O = temp_out;\\n\\n        // max-abs over unrolls\\n        intermediate_max = max_abs(intermediate_max, temp_out);  // used for abs\\n    }\\n    intermediate_max += 0;\\n    %(atomic_max)s\\n\\n}\\n'\n    template_vals = prepare_template_vals(clss, compute_capability)\n    code = code % template_vals\n    module = SourceModule(code, options=['--use_fast_math'])\n    kernel = module.get_function('spool_bprop_avg_overlap_smallN')\n    kernel.prepare('3P 2f 58I' + ('Pf' if clss[0] == 'x' else ''))\n    return kernel"
        ]
    }
]