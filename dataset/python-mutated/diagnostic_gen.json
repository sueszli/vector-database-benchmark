[
    {
        "func_name": "test_chisquare_binning",
        "original": "def test_chisquare_binning(counts, expected, sort_var=None, bins=10, df=None, ordered=False, sort_method='quicksort', alpha_nc=0.05):\n    \"\"\"chisquare gof test with binning of data, Hosmer-Lemeshow type\n\n    ``observed`` and ``expected`` are observation specific and should have\n    observations in rows and choices in columns\n\n    Parameters\n    ----------\n    counts : array_like\n        Observed frequency, i.e. counts for all choices\n    expected : array_like\n        Expected counts or probability. If expected are counts, then they\n        need to sum to the same total count as the sum of observed.\n        If those sums are unequal and all expected values are smaller or equal\n        to 1, then they are interpreted as probabilities and will be rescaled\n        to match counts.\n    sort_var : array_like\n        1-dimensional array for binning. Groups will be formed according to\n        quantiles of the sorted array ``sort_var``, so that group sizes have\n        equal or approximately equal sizes.\n\n    Returns\n    -------\n    Holdertuple instance\n        This instance contains the results of the chisquare test and some\n        information about the data\n\n        - statistic : chisquare statistic of the goodness-of-fit test\n        - pvalue : pvalue of the chisquare test\n        = df : degrees of freedom of the test\n\n    Notes\n    -----\n    Degrees of freedom for Hosmer-Lemeshow tests are given by\n\n    g groups, c choices\n\n    - binary: `df = (g - 2)` for insample,\n         Stata uses `df = g` for outsample\n    - multinomial: `df = (g\u22122) *(c\u22121)`, reduces to (g-2) for binary c=2,\n         (Fagerland, Hosmer, Bofin SIM 2008)\n    - ordinal: `df = (g - 2) * (c - 1) + (c - 2)`, reduces to (g-2) for c=2,\n         (Hosmer, ... ?)\n\n    Note: If there are ties in the ``sort_var`` array, then the split of\n    observations into groups will depend on the sort algorithm.\n    \"\"\"\n    observed = np.asarray(counts)\n    expected = np.asarray(expected)\n    n_observed = counts.sum()\n    n_expected = expected.sum()\n    if not np.allclose(n_observed, n_expected, atol=1e-13):\n        if np.max(expected) < 1 + 1e-13:\n            import warnings\n            warnings.warn('sum of expected and of observed differ, rescaling ``expected``')\n            expected = expected / n_expected * n_observed\n        else:\n            raise ValueError('total counts of expected and observed differ')\n    if sort_var is not None:\n        argsort = np.argsort(sort_var, kind=sort_method)\n    else:\n        argsort = np.arange(observed.shape[0])\n    indices = np.array_split(argsort, bins, axis=0)\n    freqs = np.array([observed[idx].sum(0) for idx in indices])\n    probs = np.array([expected[idx].sum(0) for idx in indices])\n    resid_pearson = (freqs - probs) / np.sqrt(probs)\n    chi2_stat_groups = ((freqs - probs) ** 2 / probs).sum(1)\n    chi2_stat = chi2_stat_groups.sum()\n    if df is None:\n        (g, c) = freqs.shape\n        if ordered is True:\n            df = (g - 2) * (c - 1) + (c - 2)\n        else:\n            df = (g - 2) * (c - 1)\n    pvalue = stats.chi2.sf(chi2_stat, df)\n    noncentrality = _noncentrality_chisquare(chi2_stat, df, alpha=alpha_nc)\n    res = HolderTuple(statistic=chi2_stat, pvalue=pvalue, df=df, freqs=freqs, probs=probs, noncentrality=noncentrality, resid_pearson=resid_pearson, chi2_stat_groups=chi2_stat_groups, indices=indices)\n    return res",
        "mutated": [
            "def test_chisquare_binning(counts, expected, sort_var=None, bins=10, df=None, ordered=False, sort_method='quicksort', alpha_nc=0.05):\n    if False:\n        i = 10\n    'chisquare gof test with binning of data, Hosmer-Lemeshow type\\n\\n    ``observed`` and ``expected`` are observation specific and should have\\n    observations in rows and choices in columns\\n\\n    Parameters\\n    ----------\\n    counts : array_like\\n        Observed frequency, i.e. counts for all choices\\n    expected : array_like\\n        Expected counts or probability. If expected are counts, then they\\n        need to sum to the same total count as the sum of observed.\\n        If those sums are unequal and all expected values are smaller or equal\\n        to 1, then they are interpreted as probabilities and will be rescaled\\n        to match counts.\\n    sort_var : array_like\\n        1-dimensional array for binning. Groups will be formed according to\\n        quantiles of the sorted array ``sort_var``, so that group sizes have\\n        equal or approximately equal sizes.\\n\\n    Returns\\n    -------\\n    Holdertuple instance\\n        This instance contains the results of the chisquare test and some\\n        information about the data\\n\\n        - statistic : chisquare statistic of the goodness-of-fit test\\n        - pvalue : pvalue of the chisquare test\\n        = df : degrees of freedom of the test\\n\\n    Notes\\n    -----\\n    Degrees of freedom for Hosmer-Lemeshow tests are given by\\n\\n    g groups, c choices\\n\\n    - binary: `df = (g - 2)` for insample,\\n         Stata uses `df = g` for outsample\\n    - multinomial: `df = (g\u22122) *(c\u22121)`, reduces to (g-2) for binary c=2,\\n         (Fagerland, Hosmer, Bofin SIM 2008)\\n    - ordinal: `df = (g - 2) * (c - 1) + (c - 2)`, reduces to (g-2) for c=2,\\n         (Hosmer, ... ?)\\n\\n    Note: If there are ties in the ``sort_var`` array, then the split of\\n    observations into groups will depend on the sort algorithm.\\n    '\n    observed = np.asarray(counts)\n    expected = np.asarray(expected)\n    n_observed = counts.sum()\n    n_expected = expected.sum()\n    if not np.allclose(n_observed, n_expected, atol=1e-13):\n        if np.max(expected) < 1 + 1e-13:\n            import warnings\n            warnings.warn('sum of expected and of observed differ, rescaling ``expected``')\n            expected = expected / n_expected * n_observed\n        else:\n            raise ValueError('total counts of expected and observed differ')\n    if sort_var is not None:\n        argsort = np.argsort(sort_var, kind=sort_method)\n    else:\n        argsort = np.arange(observed.shape[0])\n    indices = np.array_split(argsort, bins, axis=0)\n    freqs = np.array([observed[idx].sum(0) for idx in indices])\n    probs = np.array([expected[idx].sum(0) for idx in indices])\n    resid_pearson = (freqs - probs) / np.sqrt(probs)\n    chi2_stat_groups = ((freqs - probs) ** 2 / probs).sum(1)\n    chi2_stat = chi2_stat_groups.sum()\n    if df is None:\n        (g, c) = freqs.shape\n        if ordered is True:\n            df = (g - 2) * (c - 1) + (c - 2)\n        else:\n            df = (g - 2) * (c - 1)\n    pvalue = stats.chi2.sf(chi2_stat, df)\n    noncentrality = _noncentrality_chisquare(chi2_stat, df, alpha=alpha_nc)\n    res = HolderTuple(statistic=chi2_stat, pvalue=pvalue, df=df, freqs=freqs, probs=probs, noncentrality=noncentrality, resid_pearson=resid_pearson, chi2_stat_groups=chi2_stat_groups, indices=indices)\n    return res",
            "def test_chisquare_binning(counts, expected, sort_var=None, bins=10, df=None, ordered=False, sort_method='quicksort', alpha_nc=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'chisquare gof test with binning of data, Hosmer-Lemeshow type\\n\\n    ``observed`` and ``expected`` are observation specific and should have\\n    observations in rows and choices in columns\\n\\n    Parameters\\n    ----------\\n    counts : array_like\\n        Observed frequency, i.e. counts for all choices\\n    expected : array_like\\n        Expected counts or probability. If expected are counts, then they\\n        need to sum to the same total count as the sum of observed.\\n        If those sums are unequal and all expected values are smaller or equal\\n        to 1, then they are interpreted as probabilities and will be rescaled\\n        to match counts.\\n    sort_var : array_like\\n        1-dimensional array for binning. Groups will be formed according to\\n        quantiles of the sorted array ``sort_var``, so that group sizes have\\n        equal or approximately equal sizes.\\n\\n    Returns\\n    -------\\n    Holdertuple instance\\n        This instance contains the results of the chisquare test and some\\n        information about the data\\n\\n        - statistic : chisquare statistic of the goodness-of-fit test\\n        - pvalue : pvalue of the chisquare test\\n        = df : degrees of freedom of the test\\n\\n    Notes\\n    -----\\n    Degrees of freedom for Hosmer-Lemeshow tests are given by\\n\\n    g groups, c choices\\n\\n    - binary: `df = (g - 2)` for insample,\\n         Stata uses `df = g` for outsample\\n    - multinomial: `df = (g\u22122) *(c\u22121)`, reduces to (g-2) for binary c=2,\\n         (Fagerland, Hosmer, Bofin SIM 2008)\\n    - ordinal: `df = (g - 2) * (c - 1) + (c - 2)`, reduces to (g-2) for c=2,\\n         (Hosmer, ... ?)\\n\\n    Note: If there are ties in the ``sort_var`` array, then the split of\\n    observations into groups will depend on the sort algorithm.\\n    '\n    observed = np.asarray(counts)\n    expected = np.asarray(expected)\n    n_observed = counts.sum()\n    n_expected = expected.sum()\n    if not np.allclose(n_observed, n_expected, atol=1e-13):\n        if np.max(expected) < 1 + 1e-13:\n            import warnings\n            warnings.warn('sum of expected and of observed differ, rescaling ``expected``')\n            expected = expected / n_expected * n_observed\n        else:\n            raise ValueError('total counts of expected and observed differ')\n    if sort_var is not None:\n        argsort = np.argsort(sort_var, kind=sort_method)\n    else:\n        argsort = np.arange(observed.shape[0])\n    indices = np.array_split(argsort, bins, axis=0)\n    freqs = np.array([observed[idx].sum(0) for idx in indices])\n    probs = np.array([expected[idx].sum(0) for idx in indices])\n    resid_pearson = (freqs - probs) / np.sqrt(probs)\n    chi2_stat_groups = ((freqs - probs) ** 2 / probs).sum(1)\n    chi2_stat = chi2_stat_groups.sum()\n    if df is None:\n        (g, c) = freqs.shape\n        if ordered is True:\n            df = (g - 2) * (c - 1) + (c - 2)\n        else:\n            df = (g - 2) * (c - 1)\n    pvalue = stats.chi2.sf(chi2_stat, df)\n    noncentrality = _noncentrality_chisquare(chi2_stat, df, alpha=alpha_nc)\n    res = HolderTuple(statistic=chi2_stat, pvalue=pvalue, df=df, freqs=freqs, probs=probs, noncentrality=noncentrality, resid_pearson=resid_pearson, chi2_stat_groups=chi2_stat_groups, indices=indices)\n    return res",
            "def test_chisquare_binning(counts, expected, sort_var=None, bins=10, df=None, ordered=False, sort_method='quicksort', alpha_nc=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'chisquare gof test with binning of data, Hosmer-Lemeshow type\\n\\n    ``observed`` and ``expected`` are observation specific and should have\\n    observations in rows and choices in columns\\n\\n    Parameters\\n    ----------\\n    counts : array_like\\n        Observed frequency, i.e. counts for all choices\\n    expected : array_like\\n        Expected counts or probability. If expected are counts, then they\\n        need to sum to the same total count as the sum of observed.\\n        If those sums are unequal and all expected values are smaller or equal\\n        to 1, then they are interpreted as probabilities and will be rescaled\\n        to match counts.\\n    sort_var : array_like\\n        1-dimensional array for binning. Groups will be formed according to\\n        quantiles of the sorted array ``sort_var``, so that group sizes have\\n        equal or approximately equal sizes.\\n\\n    Returns\\n    -------\\n    Holdertuple instance\\n        This instance contains the results of the chisquare test and some\\n        information about the data\\n\\n        - statistic : chisquare statistic of the goodness-of-fit test\\n        - pvalue : pvalue of the chisquare test\\n        = df : degrees of freedom of the test\\n\\n    Notes\\n    -----\\n    Degrees of freedom for Hosmer-Lemeshow tests are given by\\n\\n    g groups, c choices\\n\\n    - binary: `df = (g - 2)` for insample,\\n         Stata uses `df = g` for outsample\\n    - multinomial: `df = (g\u22122) *(c\u22121)`, reduces to (g-2) for binary c=2,\\n         (Fagerland, Hosmer, Bofin SIM 2008)\\n    - ordinal: `df = (g - 2) * (c - 1) + (c - 2)`, reduces to (g-2) for c=2,\\n         (Hosmer, ... ?)\\n\\n    Note: If there are ties in the ``sort_var`` array, then the split of\\n    observations into groups will depend on the sort algorithm.\\n    '\n    observed = np.asarray(counts)\n    expected = np.asarray(expected)\n    n_observed = counts.sum()\n    n_expected = expected.sum()\n    if not np.allclose(n_observed, n_expected, atol=1e-13):\n        if np.max(expected) < 1 + 1e-13:\n            import warnings\n            warnings.warn('sum of expected and of observed differ, rescaling ``expected``')\n            expected = expected / n_expected * n_observed\n        else:\n            raise ValueError('total counts of expected and observed differ')\n    if sort_var is not None:\n        argsort = np.argsort(sort_var, kind=sort_method)\n    else:\n        argsort = np.arange(observed.shape[0])\n    indices = np.array_split(argsort, bins, axis=0)\n    freqs = np.array([observed[idx].sum(0) for idx in indices])\n    probs = np.array([expected[idx].sum(0) for idx in indices])\n    resid_pearson = (freqs - probs) / np.sqrt(probs)\n    chi2_stat_groups = ((freqs - probs) ** 2 / probs).sum(1)\n    chi2_stat = chi2_stat_groups.sum()\n    if df is None:\n        (g, c) = freqs.shape\n        if ordered is True:\n            df = (g - 2) * (c - 1) + (c - 2)\n        else:\n            df = (g - 2) * (c - 1)\n    pvalue = stats.chi2.sf(chi2_stat, df)\n    noncentrality = _noncentrality_chisquare(chi2_stat, df, alpha=alpha_nc)\n    res = HolderTuple(statistic=chi2_stat, pvalue=pvalue, df=df, freqs=freqs, probs=probs, noncentrality=noncentrality, resid_pearson=resid_pearson, chi2_stat_groups=chi2_stat_groups, indices=indices)\n    return res",
            "def test_chisquare_binning(counts, expected, sort_var=None, bins=10, df=None, ordered=False, sort_method='quicksort', alpha_nc=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'chisquare gof test with binning of data, Hosmer-Lemeshow type\\n\\n    ``observed`` and ``expected`` are observation specific and should have\\n    observations in rows and choices in columns\\n\\n    Parameters\\n    ----------\\n    counts : array_like\\n        Observed frequency, i.e. counts for all choices\\n    expected : array_like\\n        Expected counts or probability. If expected are counts, then they\\n        need to sum to the same total count as the sum of observed.\\n        If those sums are unequal and all expected values are smaller or equal\\n        to 1, then they are interpreted as probabilities and will be rescaled\\n        to match counts.\\n    sort_var : array_like\\n        1-dimensional array for binning. Groups will be formed according to\\n        quantiles of the sorted array ``sort_var``, so that group sizes have\\n        equal or approximately equal sizes.\\n\\n    Returns\\n    -------\\n    Holdertuple instance\\n        This instance contains the results of the chisquare test and some\\n        information about the data\\n\\n        - statistic : chisquare statistic of the goodness-of-fit test\\n        - pvalue : pvalue of the chisquare test\\n        = df : degrees of freedom of the test\\n\\n    Notes\\n    -----\\n    Degrees of freedom for Hosmer-Lemeshow tests are given by\\n\\n    g groups, c choices\\n\\n    - binary: `df = (g - 2)` for insample,\\n         Stata uses `df = g` for outsample\\n    - multinomial: `df = (g\u22122) *(c\u22121)`, reduces to (g-2) for binary c=2,\\n         (Fagerland, Hosmer, Bofin SIM 2008)\\n    - ordinal: `df = (g - 2) * (c - 1) + (c - 2)`, reduces to (g-2) for c=2,\\n         (Hosmer, ... ?)\\n\\n    Note: If there are ties in the ``sort_var`` array, then the split of\\n    observations into groups will depend on the sort algorithm.\\n    '\n    observed = np.asarray(counts)\n    expected = np.asarray(expected)\n    n_observed = counts.sum()\n    n_expected = expected.sum()\n    if not np.allclose(n_observed, n_expected, atol=1e-13):\n        if np.max(expected) < 1 + 1e-13:\n            import warnings\n            warnings.warn('sum of expected and of observed differ, rescaling ``expected``')\n            expected = expected / n_expected * n_observed\n        else:\n            raise ValueError('total counts of expected and observed differ')\n    if sort_var is not None:\n        argsort = np.argsort(sort_var, kind=sort_method)\n    else:\n        argsort = np.arange(observed.shape[0])\n    indices = np.array_split(argsort, bins, axis=0)\n    freqs = np.array([observed[idx].sum(0) for idx in indices])\n    probs = np.array([expected[idx].sum(0) for idx in indices])\n    resid_pearson = (freqs - probs) / np.sqrt(probs)\n    chi2_stat_groups = ((freqs - probs) ** 2 / probs).sum(1)\n    chi2_stat = chi2_stat_groups.sum()\n    if df is None:\n        (g, c) = freqs.shape\n        if ordered is True:\n            df = (g - 2) * (c - 1) + (c - 2)\n        else:\n            df = (g - 2) * (c - 1)\n    pvalue = stats.chi2.sf(chi2_stat, df)\n    noncentrality = _noncentrality_chisquare(chi2_stat, df, alpha=alpha_nc)\n    res = HolderTuple(statistic=chi2_stat, pvalue=pvalue, df=df, freqs=freqs, probs=probs, noncentrality=noncentrality, resid_pearson=resid_pearson, chi2_stat_groups=chi2_stat_groups, indices=indices)\n    return res",
            "def test_chisquare_binning(counts, expected, sort_var=None, bins=10, df=None, ordered=False, sort_method='quicksort', alpha_nc=0.05):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'chisquare gof test with binning of data, Hosmer-Lemeshow type\\n\\n    ``observed`` and ``expected`` are observation specific and should have\\n    observations in rows and choices in columns\\n\\n    Parameters\\n    ----------\\n    counts : array_like\\n        Observed frequency, i.e. counts for all choices\\n    expected : array_like\\n        Expected counts or probability. If expected are counts, then they\\n        need to sum to the same total count as the sum of observed.\\n        If those sums are unequal and all expected values are smaller or equal\\n        to 1, then they are interpreted as probabilities and will be rescaled\\n        to match counts.\\n    sort_var : array_like\\n        1-dimensional array for binning. Groups will be formed according to\\n        quantiles of the sorted array ``sort_var``, so that group sizes have\\n        equal or approximately equal sizes.\\n\\n    Returns\\n    -------\\n    Holdertuple instance\\n        This instance contains the results of the chisquare test and some\\n        information about the data\\n\\n        - statistic : chisquare statistic of the goodness-of-fit test\\n        - pvalue : pvalue of the chisquare test\\n        = df : degrees of freedom of the test\\n\\n    Notes\\n    -----\\n    Degrees of freedom for Hosmer-Lemeshow tests are given by\\n\\n    g groups, c choices\\n\\n    - binary: `df = (g - 2)` for insample,\\n         Stata uses `df = g` for outsample\\n    - multinomial: `df = (g\u22122) *(c\u22121)`, reduces to (g-2) for binary c=2,\\n         (Fagerland, Hosmer, Bofin SIM 2008)\\n    - ordinal: `df = (g - 2) * (c - 1) + (c - 2)`, reduces to (g-2) for c=2,\\n         (Hosmer, ... ?)\\n\\n    Note: If there are ties in the ``sort_var`` array, then the split of\\n    observations into groups will depend on the sort algorithm.\\n    '\n    observed = np.asarray(counts)\n    expected = np.asarray(expected)\n    n_observed = counts.sum()\n    n_expected = expected.sum()\n    if not np.allclose(n_observed, n_expected, atol=1e-13):\n        if np.max(expected) < 1 + 1e-13:\n            import warnings\n            warnings.warn('sum of expected and of observed differ, rescaling ``expected``')\n            expected = expected / n_expected * n_observed\n        else:\n            raise ValueError('total counts of expected and observed differ')\n    if sort_var is not None:\n        argsort = np.argsort(sort_var, kind=sort_method)\n    else:\n        argsort = np.arange(observed.shape[0])\n    indices = np.array_split(argsort, bins, axis=0)\n    freqs = np.array([observed[idx].sum(0) for idx in indices])\n    probs = np.array([expected[idx].sum(0) for idx in indices])\n    resid_pearson = (freqs - probs) / np.sqrt(probs)\n    chi2_stat_groups = ((freqs - probs) ** 2 / probs).sum(1)\n    chi2_stat = chi2_stat_groups.sum()\n    if df is None:\n        (g, c) = freqs.shape\n        if ordered is True:\n            df = (g - 2) * (c - 1) + (c - 2)\n        else:\n            df = (g - 2) * (c - 1)\n    pvalue = stats.chi2.sf(chi2_stat, df)\n    noncentrality = _noncentrality_chisquare(chi2_stat, df, alpha=alpha_nc)\n    res = HolderTuple(statistic=chi2_stat, pvalue=pvalue, df=df, freqs=freqs, probs=probs, noncentrality=noncentrality, resid_pearson=resid_pearson, chi2_stat_groups=chi2_stat_groups, indices=indices)\n    return res"
        ]
    },
    {
        "func_name": "prob_larger_ordinal_choice",
        "original": "def prob_larger_ordinal_choice(prob):\n    \"\"\"probability that observed category is larger than distribution prob\n\n    This is a helper function for Ordinal models, where endog is a 1-dim\n    categorical variable and predicted probabilities are 2-dimensional with\n    observations in rows and choices in columns.\n\n    Parameter\n    ---------\n    prob : array_like\n        Expected probabilities for ordinal choices, e.g. from prediction of\n        an ordinal model with observations in rows and choices in columns.\n\n    Returns\n    -------\n    cdf_mid : ndarray\n        mid cdf, i.e ``P(x < y) + 0.5 P(x=y)``\n    r : ndarray\n        Probability residual ``P(x > y) - P(x < y)`` for all possible choices.\n        Computed as ``r = cdf_mid * 2 - 1``\n\n    References\n    ----------\n    .. [2] Li, Chun, and Bryan E. Shepherd. 2012. \u201cA New Residual for Ordinal\n       Outcomes.\u201d Biometrika 99 (2): 473\u201380.\n\n    See Also\n    --------\n    `statsmodels.stats.nonparametric.rank_compare_2ordinal`\n\n    \"\"\"\n    prob = np.asarray(prob)\n    cdf = prob.cumsum(-1)\n    if cdf.ndim == 1:\n        cdf_ = np.concatenate(([0], cdf))\n    elif cdf.ndim == 2:\n        cdf_ = np.concatenate((np.zeros((len(cdf), 1)), cdf), axis=1)\n    cdf_mid = (cdf_[..., 1:] + cdf_[..., :-1]) / 2\n    r = cdf_mid * 2 - 1\n    return (cdf_mid, r)",
        "mutated": [
            "def prob_larger_ordinal_choice(prob):\n    if False:\n        i = 10\n    'probability that observed category is larger than distribution prob\\n\\n    This is a helper function for Ordinal models, where endog is a 1-dim\\n    categorical variable and predicted probabilities are 2-dimensional with\\n    observations in rows and choices in columns.\\n\\n    Parameter\\n    ---------\\n    prob : array_like\\n        Expected probabilities for ordinal choices, e.g. from prediction of\\n        an ordinal model with observations in rows and choices in columns.\\n\\n    Returns\\n    -------\\n    cdf_mid : ndarray\\n        mid cdf, i.e ``P(x < y) + 0.5 P(x=y)``\\n    r : ndarray\\n        Probability residual ``P(x > y) - P(x < y)`` for all possible choices.\\n        Computed as ``r = cdf_mid * 2 - 1``\\n\\n    References\\n    ----------\\n    .. [2] Li, Chun, and Bryan E. Shepherd. 2012. \u201cA New Residual for Ordinal\\n       Outcomes.\u201d Biometrika 99 (2): 473\u201380.\\n\\n    See Also\\n    --------\\n    `statsmodels.stats.nonparametric.rank_compare_2ordinal`\\n\\n    '\n    prob = np.asarray(prob)\n    cdf = prob.cumsum(-1)\n    if cdf.ndim == 1:\n        cdf_ = np.concatenate(([0], cdf))\n    elif cdf.ndim == 2:\n        cdf_ = np.concatenate((np.zeros((len(cdf), 1)), cdf), axis=1)\n    cdf_mid = (cdf_[..., 1:] + cdf_[..., :-1]) / 2\n    r = cdf_mid * 2 - 1\n    return (cdf_mid, r)",
            "def prob_larger_ordinal_choice(prob):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'probability that observed category is larger than distribution prob\\n\\n    This is a helper function for Ordinal models, where endog is a 1-dim\\n    categorical variable and predicted probabilities are 2-dimensional with\\n    observations in rows and choices in columns.\\n\\n    Parameter\\n    ---------\\n    prob : array_like\\n        Expected probabilities for ordinal choices, e.g. from prediction of\\n        an ordinal model with observations in rows and choices in columns.\\n\\n    Returns\\n    -------\\n    cdf_mid : ndarray\\n        mid cdf, i.e ``P(x < y) + 0.5 P(x=y)``\\n    r : ndarray\\n        Probability residual ``P(x > y) - P(x < y)`` for all possible choices.\\n        Computed as ``r = cdf_mid * 2 - 1``\\n\\n    References\\n    ----------\\n    .. [2] Li, Chun, and Bryan E. Shepherd. 2012. \u201cA New Residual for Ordinal\\n       Outcomes.\u201d Biometrika 99 (2): 473\u201380.\\n\\n    See Also\\n    --------\\n    `statsmodels.stats.nonparametric.rank_compare_2ordinal`\\n\\n    '\n    prob = np.asarray(prob)\n    cdf = prob.cumsum(-1)\n    if cdf.ndim == 1:\n        cdf_ = np.concatenate(([0], cdf))\n    elif cdf.ndim == 2:\n        cdf_ = np.concatenate((np.zeros((len(cdf), 1)), cdf), axis=1)\n    cdf_mid = (cdf_[..., 1:] + cdf_[..., :-1]) / 2\n    r = cdf_mid * 2 - 1\n    return (cdf_mid, r)",
            "def prob_larger_ordinal_choice(prob):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'probability that observed category is larger than distribution prob\\n\\n    This is a helper function for Ordinal models, where endog is a 1-dim\\n    categorical variable and predicted probabilities are 2-dimensional with\\n    observations in rows and choices in columns.\\n\\n    Parameter\\n    ---------\\n    prob : array_like\\n        Expected probabilities for ordinal choices, e.g. from prediction of\\n        an ordinal model with observations in rows and choices in columns.\\n\\n    Returns\\n    -------\\n    cdf_mid : ndarray\\n        mid cdf, i.e ``P(x < y) + 0.5 P(x=y)``\\n    r : ndarray\\n        Probability residual ``P(x > y) - P(x < y)`` for all possible choices.\\n        Computed as ``r = cdf_mid * 2 - 1``\\n\\n    References\\n    ----------\\n    .. [2] Li, Chun, and Bryan E. Shepherd. 2012. \u201cA New Residual for Ordinal\\n       Outcomes.\u201d Biometrika 99 (2): 473\u201380.\\n\\n    See Also\\n    --------\\n    `statsmodels.stats.nonparametric.rank_compare_2ordinal`\\n\\n    '\n    prob = np.asarray(prob)\n    cdf = prob.cumsum(-1)\n    if cdf.ndim == 1:\n        cdf_ = np.concatenate(([0], cdf))\n    elif cdf.ndim == 2:\n        cdf_ = np.concatenate((np.zeros((len(cdf), 1)), cdf), axis=1)\n    cdf_mid = (cdf_[..., 1:] + cdf_[..., :-1]) / 2\n    r = cdf_mid * 2 - 1\n    return (cdf_mid, r)",
            "def prob_larger_ordinal_choice(prob):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'probability that observed category is larger than distribution prob\\n\\n    This is a helper function for Ordinal models, where endog is a 1-dim\\n    categorical variable and predicted probabilities are 2-dimensional with\\n    observations in rows and choices in columns.\\n\\n    Parameter\\n    ---------\\n    prob : array_like\\n        Expected probabilities for ordinal choices, e.g. from prediction of\\n        an ordinal model with observations in rows and choices in columns.\\n\\n    Returns\\n    -------\\n    cdf_mid : ndarray\\n        mid cdf, i.e ``P(x < y) + 0.5 P(x=y)``\\n    r : ndarray\\n        Probability residual ``P(x > y) - P(x < y)`` for all possible choices.\\n        Computed as ``r = cdf_mid * 2 - 1``\\n\\n    References\\n    ----------\\n    .. [2] Li, Chun, and Bryan E. Shepherd. 2012. \u201cA New Residual for Ordinal\\n       Outcomes.\u201d Biometrika 99 (2): 473\u201380.\\n\\n    See Also\\n    --------\\n    `statsmodels.stats.nonparametric.rank_compare_2ordinal`\\n\\n    '\n    prob = np.asarray(prob)\n    cdf = prob.cumsum(-1)\n    if cdf.ndim == 1:\n        cdf_ = np.concatenate(([0], cdf))\n    elif cdf.ndim == 2:\n        cdf_ = np.concatenate((np.zeros((len(cdf), 1)), cdf), axis=1)\n    cdf_mid = (cdf_[..., 1:] + cdf_[..., :-1]) / 2\n    r = cdf_mid * 2 - 1\n    return (cdf_mid, r)",
            "def prob_larger_ordinal_choice(prob):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'probability that observed category is larger than distribution prob\\n\\n    This is a helper function for Ordinal models, where endog is a 1-dim\\n    categorical variable and predicted probabilities are 2-dimensional with\\n    observations in rows and choices in columns.\\n\\n    Parameter\\n    ---------\\n    prob : array_like\\n        Expected probabilities for ordinal choices, e.g. from prediction of\\n        an ordinal model with observations in rows and choices in columns.\\n\\n    Returns\\n    -------\\n    cdf_mid : ndarray\\n        mid cdf, i.e ``P(x < y) + 0.5 P(x=y)``\\n    r : ndarray\\n        Probability residual ``P(x > y) - P(x < y)`` for all possible choices.\\n        Computed as ``r = cdf_mid * 2 - 1``\\n\\n    References\\n    ----------\\n    .. [2] Li, Chun, and Bryan E. Shepherd. 2012. \u201cA New Residual for Ordinal\\n       Outcomes.\u201d Biometrika 99 (2): 473\u201380.\\n\\n    See Also\\n    --------\\n    `statsmodels.stats.nonparametric.rank_compare_2ordinal`\\n\\n    '\n    prob = np.asarray(prob)\n    cdf = prob.cumsum(-1)\n    if cdf.ndim == 1:\n        cdf_ = np.concatenate(([0], cdf))\n    elif cdf.ndim == 2:\n        cdf_ = np.concatenate((np.zeros((len(cdf), 1)), cdf), axis=1)\n    cdf_mid = (cdf_[..., 1:] + cdf_[..., :-1]) / 2\n    r = cdf_mid * 2 - 1\n    return (cdf_mid, r)"
        ]
    },
    {
        "func_name": "prob_larger_2ordinal",
        "original": "def prob_larger_2ordinal(probs1, probs2):\n    \"\"\"Stochastically large probability for two ordinal distributions\n\n    Computes Pr(x1 > x2) + 0.5 * Pr(x1 = x2) for two ordered multinomial\n    (ordinal) distributed random variables x1 and x2.\n\n    This is vectorized with choices along last axis.\n    Broadcasting if freq2 is 1-dim also seems to work correctly.\n\n    Returns\n    -------\n    prob1 : float\n        Probability that random draw from distribution 1 is larger than a\n        random draw from distribution 2. Pr(x1 > x2) + 0.5 * Pr(x1 = x2)\n    prob2 : float\n        prob2 = 1 - prob1 = Pr(x1 < x2) + 0.5 * Pr(x1 = x2)\n    \"\"\"\n    freq1 = np.asarray(probs1)\n    freq2 = np.asarray(probs2)\n    freq1_ = np.concatenate((np.zeros(freq1.shape[:-1] + (1,)), freq1), axis=-1)\n    freq2_ = np.concatenate((np.zeros(freq2.shape[:-1] + (1,)), freq2), axis=-1)\n    cdf1 = freq1_.cumsum(axis=-1)\n    cdf2 = freq2_.cumsum(axis=-1)\n    cdfm1 = (cdf1[..., 1:] + cdf1[..., :-1]) / 2\n    cdfm2 = (cdf2[..., 1:] + cdf2[..., :-1]) / 2\n    prob1 = (cdfm2 * freq1).sum(-1)\n    prob2 = (cdfm1 * freq2).sum(-1)\n    return (prob1, prob2)",
        "mutated": [
            "def prob_larger_2ordinal(probs1, probs2):\n    if False:\n        i = 10\n    'Stochastically large probability for two ordinal distributions\\n\\n    Computes Pr(x1 > x2) + 0.5 * Pr(x1 = x2) for two ordered multinomial\\n    (ordinal) distributed random variables x1 and x2.\\n\\n    This is vectorized with choices along last axis.\\n    Broadcasting if freq2 is 1-dim also seems to work correctly.\\n\\n    Returns\\n    -------\\n    prob1 : float\\n        Probability that random draw from distribution 1 is larger than a\\n        random draw from distribution 2. Pr(x1 > x2) + 0.5 * Pr(x1 = x2)\\n    prob2 : float\\n        prob2 = 1 - prob1 = Pr(x1 < x2) + 0.5 * Pr(x1 = x2)\\n    '\n    freq1 = np.asarray(probs1)\n    freq2 = np.asarray(probs2)\n    freq1_ = np.concatenate((np.zeros(freq1.shape[:-1] + (1,)), freq1), axis=-1)\n    freq2_ = np.concatenate((np.zeros(freq2.shape[:-1] + (1,)), freq2), axis=-1)\n    cdf1 = freq1_.cumsum(axis=-1)\n    cdf2 = freq2_.cumsum(axis=-1)\n    cdfm1 = (cdf1[..., 1:] + cdf1[..., :-1]) / 2\n    cdfm2 = (cdf2[..., 1:] + cdf2[..., :-1]) / 2\n    prob1 = (cdfm2 * freq1).sum(-1)\n    prob2 = (cdfm1 * freq2).sum(-1)\n    return (prob1, prob2)",
            "def prob_larger_2ordinal(probs1, probs2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Stochastically large probability for two ordinal distributions\\n\\n    Computes Pr(x1 > x2) + 0.5 * Pr(x1 = x2) for two ordered multinomial\\n    (ordinal) distributed random variables x1 and x2.\\n\\n    This is vectorized with choices along last axis.\\n    Broadcasting if freq2 is 1-dim also seems to work correctly.\\n\\n    Returns\\n    -------\\n    prob1 : float\\n        Probability that random draw from distribution 1 is larger than a\\n        random draw from distribution 2. Pr(x1 > x2) + 0.5 * Pr(x1 = x2)\\n    prob2 : float\\n        prob2 = 1 - prob1 = Pr(x1 < x2) + 0.5 * Pr(x1 = x2)\\n    '\n    freq1 = np.asarray(probs1)\n    freq2 = np.asarray(probs2)\n    freq1_ = np.concatenate((np.zeros(freq1.shape[:-1] + (1,)), freq1), axis=-1)\n    freq2_ = np.concatenate((np.zeros(freq2.shape[:-1] + (1,)), freq2), axis=-1)\n    cdf1 = freq1_.cumsum(axis=-1)\n    cdf2 = freq2_.cumsum(axis=-1)\n    cdfm1 = (cdf1[..., 1:] + cdf1[..., :-1]) / 2\n    cdfm2 = (cdf2[..., 1:] + cdf2[..., :-1]) / 2\n    prob1 = (cdfm2 * freq1).sum(-1)\n    prob2 = (cdfm1 * freq2).sum(-1)\n    return (prob1, prob2)",
            "def prob_larger_2ordinal(probs1, probs2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Stochastically large probability for two ordinal distributions\\n\\n    Computes Pr(x1 > x2) + 0.5 * Pr(x1 = x2) for two ordered multinomial\\n    (ordinal) distributed random variables x1 and x2.\\n\\n    This is vectorized with choices along last axis.\\n    Broadcasting if freq2 is 1-dim also seems to work correctly.\\n\\n    Returns\\n    -------\\n    prob1 : float\\n        Probability that random draw from distribution 1 is larger than a\\n        random draw from distribution 2. Pr(x1 > x2) + 0.5 * Pr(x1 = x2)\\n    prob2 : float\\n        prob2 = 1 - prob1 = Pr(x1 < x2) + 0.5 * Pr(x1 = x2)\\n    '\n    freq1 = np.asarray(probs1)\n    freq2 = np.asarray(probs2)\n    freq1_ = np.concatenate((np.zeros(freq1.shape[:-1] + (1,)), freq1), axis=-1)\n    freq2_ = np.concatenate((np.zeros(freq2.shape[:-1] + (1,)), freq2), axis=-1)\n    cdf1 = freq1_.cumsum(axis=-1)\n    cdf2 = freq2_.cumsum(axis=-1)\n    cdfm1 = (cdf1[..., 1:] + cdf1[..., :-1]) / 2\n    cdfm2 = (cdf2[..., 1:] + cdf2[..., :-1]) / 2\n    prob1 = (cdfm2 * freq1).sum(-1)\n    prob2 = (cdfm1 * freq2).sum(-1)\n    return (prob1, prob2)",
            "def prob_larger_2ordinal(probs1, probs2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Stochastically large probability for two ordinal distributions\\n\\n    Computes Pr(x1 > x2) + 0.5 * Pr(x1 = x2) for two ordered multinomial\\n    (ordinal) distributed random variables x1 and x2.\\n\\n    This is vectorized with choices along last axis.\\n    Broadcasting if freq2 is 1-dim also seems to work correctly.\\n\\n    Returns\\n    -------\\n    prob1 : float\\n        Probability that random draw from distribution 1 is larger than a\\n        random draw from distribution 2. Pr(x1 > x2) + 0.5 * Pr(x1 = x2)\\n    prob2 : float\\n        prob2 = 1 - prob1 = Pr(x1 < x2) + 0.5 * Pr(x1 = x2)\\n    '\n    freq1 = np.asarray(probs1)\n    freq2 = np.asarray(probs2)\n    freq1_ = np.concatenate((np.zeros(freq1.shape[:-1] + (1,)), freq1), axis=-1)\n    freq2_ = np.concatenate((np.zeros(freq2.shape[:-1] + (1,)), freq2), axis=-1)\n    cdf1 = freq1_.cumsum(axis=-1)\n    cdf2 = freq2_.cumsum(axis=-1)\n    cdfm1 = (cdf1[..., 1:] + cdf1[..., :-1]) / 2\n    cdfm2 = (cdf2[..., 1:] + cdf2[..., :-1]) / 2\n    prob1 = (cdfm2 * freq1).sum(-1)\n    prob2 = (cdfm1 * freq2).sum(-1)\n    return (prob1, prob2)",
            "def prob_larger_2ordinal(probs1, probs2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Stochastically large probability for two ordinal distributions\\n\\n    Computes Pr(x1 > x2) + 0.5 * Pr(x1 = x2) for two ordered multinomial\\n    (ordinal) distributed random variables x1 and x2.\\n\\n    This is vectorized with choices along last axis.\\n    Broadcasting if freq2 is 1-dim also seems to work correctly.\\n\\n    Returns\\n    -------\\n    prob1 : float\\n        Probability that random draw from distribution 1 is larger than a\\n        random draw from distribution 2. Pr(x1 > x2) + 0.5 * Pr(x1 = x2)\\n    prob2 : float\\n        prob2 = 1 - prob1 = Pr(x1 < x2) + 0.5 * Pr(x1 = x2)\\n    '\n    freq1 = np.asarray(probs1)\n    freq2 = np.asarray(probs2)\n    freq1_ = np.concatenate((np.zeros(freq1.shape[:-1] + (1,)), freq1), axis=-1)\n    freq2_ = np.concatenate((np.zeros(freq2.shape[:-1] + (1,)), freq2), axis=-1)\n    cdf1 = freq1_.cumsum(axis=-1)\n    cdf2 = freq2_.cumsum(axis=-1)\n    cdfm1 = (cdf1[..., 1:] + cdf1[..., :-1]) / 2\n    cdfm2 = (cdf2[..., 1:] + cdf2[..., :-1]) / 2\n    prob1 = (cdfm2 * freq1).sum(-1)\n    prob2 = (cdfm1 * freq2).sum(-1)\n    return (prob1, prob2)"
        ]
    },
    {
        "func_name": "cov_multinomial",
        "original": "def cov_multinomial(probs):\n    \"\"\"covariance matrix of multinomial distribution\n\n    This is vectorized with choices along last axis.\n\n    cov = diag(probs) - outer(probs, probs)\n\n    \"\"\"\n    k = probs.shape[-1]\n    di = np.diag_indices(k, 2)\n    cov = probs[..., None] * probs[..., None, :]\n    cov *= -1\n    cov[..., di[0], di[1]] += probs\n    return cov",
        "mutated": [
            "def cov_multinomial(probs):\n    if False:\n        i = 10\n    'covariance matrix of multinomial distribution\\n\\n    This is vectorized with choices along last axis.\\n\\n    cov = diag(probs) - outer(probs, probs)\\n\\n    '\n    k = probs.shape[-1]\n    di = np.diag_indices(k, 2)\n    cov = probs[..., None] * probs[..., None, :]\n    cov *= -1\n    cov[..., di[0], di[1]] += probs\n    return cov",
            "def cov_multinomial(probs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'covariance matrix of multinomial distribution\\n\\n    This is vectorized with choices along last axis.\\n\\n    cov = diag(probs) - outer(probs, probs)\\n\\n    '\n    k = probs.shape[-1]\n    di = np.diag_indices(k, 2)\n    cov = probs[..., None] * probs[..., None, :]\n    cov *= -1\n    cov[..., di[0], di[1]] += probs\n    return cov",
            "def cov_multinomial(probs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'covariance matrix of multinomial distribution\\n\\n    This is vectorized with choices along last axis.\\n\\n    cov = diag(probs) - outer(probs, probs)\\n\\n    '\n    k = probs.shape[-1]\n    di = np.diag_indices(k, 2)\n    cov = probs[..., None] * probs[..., None, :]\n    cov *= -1\n    cov[..., di[0], di[1]] += probs\n    return cov",
            "def cov_multinomial(probs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'covariance matrix of multinomial distribution\\n\\n    This is vectorized with choices along last axis.\\n\\n    cov = diag(probs) - outer(probs, probs)\\n\\n    '\n    k = probs.shape[-1]\n    di = np.diag_indices(k, 2)\n    cov = probs[..., None] * probs[..., None, :]\n    cov *= -1\n    cov[..., di[0], di[1]] += probs\n    return cov",
            "def cov_multinomial(probs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'covariance matrix of multinomial distribution\\n\\n    This is vectorized with choices along last axis.\\n\\n    cov = diag(probs) - outer(probs, probs)\\n\\n    '\n    k = probs.shape[-1]\n    di = np.diag_indices(k, 2)\n    cov = probs[..., None] * probs[..., None, :]\n    cov *= -1\n    cov[..., di[0], di[1]] += probs\n    return cov"
        ]
    },
    {
        "func_name": "var_multinomial",
        "original": "def var_multinomial(probs):\n    \"\"\"variance of multinomial distribution\n\n    var = probs * (1 - probs)\n\n    \"\"\"\n    var = probs * (1 - probs)\n    return var",
        "mutated": [
            "def var_multinomial(probs):\n    if False:\n        i = 10\n    'variance of multinomial distribution\\n\\n    var = probs * (1 - probs)\\n\\n    '\n    var = probs * (1 - probs)\n    return var",
            "def var_multinomial(probs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'variance of multinomial distribution\\n\\n    var = probs * (1 - probs)\\n\\n    '\n    var = probs * (1 - probs)\n    return var",
            "def var_multinomial(probs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'variance of multinomial distribution\\n\\n    var = probs * (1 - probs)\\n\\n    '\n    var = probs * (1 - probs)\n    return var",
            "def var_multinomial(probs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'variance of multinomial distribution\\n\\n    var = probs * (1 - probs)\\n\\n    '\n    var = probs * (1 - probs)\n    return var",
            "def var_multinomial(probs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'variance of multinomial distribution\\n\\n    var = probs * (1 - probs)\\n\\n    '\n    var = probs * (1 - probs)\n    return var"
        ]
    }
]