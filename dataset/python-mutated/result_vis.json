[
    {
        "func_name": "check_point_in_img",
        "original": "def check_point_in_img(points, height, width):\n    valid = np.logical_and(points[:, 0] >= 0, points[:, 1] >= 0)\n    valid = np.logical_and(valid, np.logical_and(points[:, 0] < width, points[:, 1] < height))\n    return valid",
        "mutated": [
            "def check_point_in_img(points, height, width):\n    if False:\n        i = 10\n    valid = np.logical_and(points[:, 0] >= 0, points[:, 1] >= 0)\n    valid = np.logical_and(valid, np.logical_and(points[:, 0] < width, points[:, 1] < height))\n    return valid",
            "def check_point_in_img(points, height, width):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    valid = np.logical_and(points[:, 0] >= 0, points[:, 1] >= 0)\n    valid = np.logical_and(valid, np.logical_and(points[:, 0] < width, points[:, 1] < height))\n    return valid",
            "def check_point_in_img(points, height, width):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    valid = np.logical_and(points[:, 0] >= 0, points[:, 1] >= 0)\n    valid = np.logical_and(valid, np.logical_and(points[:, 0] < width, points[:, 1] < height))\n    return valid",
            "def check_point_in_img(points, height, width):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    valid = np.logical_and(points[:, 0] >= 0, points[:, 1] >= 0)\n    valid = np.logical_and(valid, np.logical_and(points[:, 0] < width, points[:, 1] < height))\n    return valid",
            "def check_point_in_img(points, height, width):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    valid = np.logical_and(points[:, 0] >= 0, points[:, 1] >= 0)\n    valid = np.logical_and(valid, np.logical_and(points[:, 0] < width, points[:, 1] < height))\n    return valid"
        ]
    },
    {
        "func_name": "depth2color",
        "original": "def depth2color(depth):\n    gray = max(0, min((depth + 2.5) / 3.0, 1.0))\n    max_lumi = 200\n    colors = np.array([[max_lumi, 0, max_lumi], [max_lumi, 0, 0], [max_lumi, max_lumi, 0], [0, max_lumi, 0], [0, max_lumi, max_lumi], [0, 0, max_lumi]], dtype=np.float32)\n    if gray == 1:\n        return tuple(colors[-1].tolist())\n    num_rank = len(colors) - 1\n    rank = np.floor(gray * num_rank).astype(int)\n    diff = (gray - rank / num_rank) * num_rank\n    tmp = colors[rank + 1] - colors[rank]\n    return tuple((colors[rank] + tmp * diff).tolist())",
        "mutated": [
            "def depth2color(depth):\n    if False:\n        i = 10\n    gray = max(0, min((depth + 2.5) / 3.0, 1.0))\n    max_lumi = 200\n    colors = np.array([[max_lumi, 0, max_lumi], [max_lumi, 0, 0], [max_lumi, max_lumi, 0], [0, max_lumi, 0], [0, max_lumi, max_lumi], [0, 0, max_lumi]], dtype=np.float32)\n    if gray == 1:\n        return tuple(colors[-1].tolist())\n    num_rank = len(colors) - 1\n    rank = np.floor(gray * num_rank).astype(int)\n    diff = (gray - rank / num_rank) * num_rank\n    tmp = colors[rank + 1] - colors[rank]\n    return tuple((colors[rank] + tmp * diff).tolist())",
            "def depth2color(depth):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    gray = max(0, min((depth + 2.5) / 3.0, 1.0))\n    max_lumi = 200\n    colors = np.array([[max_lumi, 0, max_lumi], [max_lumi, 0, 0], [max_lumi, max_lumi, 0], [0, max_lumi, 0], [0, max_lumi, max_lumi], [0, 0, max_lumi]], dtype=np.float32)\n    if gray == 1:\n        return tuple(colors[-1].tolist())\n    num_rank = len(colors) - 1\n    rank = np.floor(gray * num_rank).astype(int)\n    diff = (gray - rank / num_rank) * num_rank\n    tmp = colors[rank + 1] - colors[rank]\n    return tuple((colors[rank] + tmp * diff).tolist())",
            "def depth2color(depth):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    gray = max(0, min((depth + 2.5) / 3.0, 1.0))\n    max_lumi = 200\n    colors = np.array([[max_lumi, 0, max_lumi], [max_lumi, 0, 0], [max_lumi, max_lumi, 0], [0, max_lumi, 0], [0, max_lumi, max_lumi], [0, 0, max_lumi]], dtype=np.float32)\n    if gray == 1:\n        return tuple(colors[-1].tolist())\n    num_rank = len(colors) - 1\n    rank = np.floor(gray * num_rank).astype(int)\n    diff = (gray - rank / num_rank) * num_rank\n    tmp = colors[rank + 1] - colors[rank]\n    return tuple((colors[rank] + tmp * diff).tolist())",
            "def depth2color(depth):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    gray = max(0, min((depth + 2.5) / 3.0, 1.0))\n    max_lumi = 200\n    colors = np.array([[max_lumi, 0, max_lumi], [max_lumi, 0, 0], [max_lumi, max_lumi, 0], [0, max_lumi, 0], [0, max_lumi, max_lumi], [0, 0, max_lumi]], dtype=np.float32)\n    if gray == 1:\n        return tuple(colors[-1].tolist())\n    num_rank = len(colors) - 1\n    rank = np.floor(gray * num_rank).astype(int)\n    diff = (gray - rank / num_rank) * num_rank\n    tmp = colors[rank + 1] - colors[rank]\n    return tuple((colors[rank] + tmp * diff).tolist())",
            "def depth2color(depth):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    gray = max(0, min((depth + 2.5) / 3.0, 1.0))\n    max_lumi = 200\n    colors = np.array([[max_lumi, 0, max_lumi], [max_lumi, 0, 0], [max_lumi, max_lumi, 0], [0, max_lumi, 0], [0, max_lumi, max_lumi], [0, 0, max_lumi]], dtype=np.float32)\n    if gray == 1:\n        return tuple(colors[-1].tolist())\n    num_rank = len(colors) - 1\n    rank = np.floor(gray * num_rank).astype(int)\n    diff = (gray - rank / num_rank) * num_rank\n    tmp = colors[rank + 1] - colors[rank]\n    return tuple((colors[rank] + tmp * diff).tolist())"
        ]
    },
    {
        "func_name": "lidar2img",
        "original": "def lidar2img(points_lidar, camrera_info):\n    points_lidar_homogeneous = np.concatenate([points_lidar, np.ones((points_lidar.shape[0], 1), dtype=points_lidar.dtype)], axis=1)\n    camera2lidar = np.eye(4, dtype=np.float32)\n    camera2lidar[:3, :3] = camrera_info['sensor2lidar_rotation']\n    camera2lidar[:3, 3] = camrera_info['sensor2lidar_translation']\n    lidar2camera = np.linalg.inv(camera2lidar)\n    points_camera_homogeneous = points_lidar_homogeneous @ lidar2camera.T\n    points_camera = points_camera_homogeneous[:, :3]\n    valid = np.ones(points_camera.shape[0], dtype=bool)\n    valid = np.logical_and(points_camera[:, -1] > 0.5, valid)\n    points_camera = points_camera / points_camera[:, 2:3]\n    camera2img = camrera_info['cam_intrinsic']\n    points_img = points_camera @ camera2img.T\n    points_img = points_img[:, :2]\n    return (points_img, valid)",
        "mutated": [
            "def lidar2img(points_lidar, camrera_info):\n    if False:\n        i = 10\n    points_lidar_homogeneous = np.concatenate([points_lidar, np.ones((points_lidar.shape[0], 1), dtype=points_lidar.dtype)], axis=1)\n    camera2lidar = np.eye(4, dtype=np.float32)\n    camera2lidar[:3, :3] = camrera_info['sensor2lidar_rotation']\n    camera2lidar[:3, 3] = camrera_info['sensor2lidar_translation']\n    lidar2camera = np.linalg.inv(camera2lidar)\n    points_camera_homogeneous = points_lidar_homogeneous @ lidar2camera.T\n    points_camera = points_camera_homogeneous[:, :3]\n    valid = np.ones(points_camera.shape[0], dtype=bool)\n    valid = np.logical_and(points_camera[:, -1] > 0.5, valid)\n    points_camera = points_camera / points_camera[:, 2:3]\n    camera2img = camrera_info['cam_intrinsic']\n    points_img = points_camera @ camera2img.T\n    points_img = points_img[:, :2]\n    return (points_img, valid)",
            "def lidar2img(points_lidar, camrera_info):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    points_lidar_homogeneous = np.concatenate([points_lidar, np.ones((points_lidar.shape[0], 1), dtype=points_lidar.dtype)], axis=1)\n    camera2lidar = np.eye(4, dtype=np.float32)\n    camera2lidar[:3, :3] = camrera_info['sensor2lidar_rotation']\n    camera2lidar[:3, 3] = camrera_info['sensor2lidar_translation']\n    lidar2camera = np.linalg.inv(camera2lidar)\n    points_camera_homogeneous = points_lidar_homogeneous @ lidar2camera.T\n    points_camera = points_camera_homogeneous[:, :3]\n    valid = np.ones(points_camera.shape[0], dtype=bool)\n    valid = np.logical_and(points_camera[:, -1] > 0.5, valid)\n    points_camera = points_camera / points_camera[:, 2:3]\n    camera2img = camrera_info['cam_intrinsic']\n    points_img = points_camera @ camera2img.T\n    points_img = points_img[:, :2]\n    return (points_img, valid)",
            "def lidar2img(points_lidar, camrera_info):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    points_lidar_homogeneous = np.concatenate([points_lidar, np.ones((points_lidar.shape[0], 1), dtype=points_lidar.dtype)], axis=1)\n    camera2lidar = np.eye(4, dtype=np.float32)\n    camera2lidar[:3, :3] = camrera_info['sensor2lidar_rotation']\n    camera2lidar[:3, 3] = camrera_info['sensor2lidar_translation']\n    lidar2camera = np.linalg.inv(camera2lidar)\n    points_camera_homogeneous = points_lidar_homogeneous @ lidar2camera.T\n    points_camera = points_camera_homogeneous[:, :3]\n    valid = np.ones(points_camera.shape[0], dtype=bool)\n    valid = np.logical_and(points_camera[:, -1] > 0.5, valid)\n    points_camera = points_camera / points_camera[:, 2:3]\n    camera2img = camrera_info['cam_intrinsic']\n    points_img = points_camera @ camera2img.T\n    points_img = points_img[:, :2]\n    return (points_img, valid)",
            "def lidar2img(points_lidar, camrera_info):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    points_lidar_homogeneous = np.concatenate([points_lidar, np.ones((points_lidar.shape[0], 1), dtype=points_lidar.dtype)], axis=1)\n    camera2lidar = np.eye(4, dtype=np.float32)\n    camera2lidar[:3, :3] = camrera_info['sensor2lidar_rotation']\n    camera2lidar[:3, 3] = camrera_info['sensor2lidar_translation']\n    lidar2camera = np.linalg.inv(camera2lidar)\n    points_camera_homogeneous = points_lidar_homogeneous @ lidar2camera.T\n    points_camera = points_camera_homogeneous[:, :3]\n    valid = np.ones(points_camera.shape[0], dtype=bool)\n    valid = np.logical_and(points_camera[:, -1] > 0.5, valid)\n    points_camera = points_camera / points_camera[:, 2:3]\n    camera2img = camrera_info['cam_intrinsic']\n    points_img = points_camera @ camera2img.T\n    points_img = points_img[:, :2]\n    return (points_img, valid)",
            "def lidar2img(points_lidar, camrera_info):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    points_lidar_homogeneous = np.concatenate([points_lidar, np.ones((points_lidar.shape[0], 1), dtype=points_lidar.dtype)], axis=1)\n    camera2lidar = np.eye(4, dtype=np.float32)\n    camera2lidar[:3, :3] = camrera_info['sensor2lidar_rotation']\n    camera2lidar[:3, 3] = camrera_info['sensor2lidar_translation']\n    lidar2camera = np.linalg.inv(camera2lidar)\n    points_camera_homogeneous = points_lidar_homogeneous @ lidar2camera.T\n    points_camera = points_camera_homogeneous[:, :3]\n    valid = np.ones(points_camera.shape[0], dtype=bool)\n    valid = np.logical_and(points_camera[:, -1] > 0.5, valid)\n    points_camera = points_camera / points_camera[:, 2:3]\n    camera2img = camrera_info['cam_intrinsic']\n    points_img = points_camera @ camera2img.T\n    points_img = points_img[:, :2]\n    return (points_img, valid)"
        ]
    },
    {
        "func_name": "get_lidar2global",
        "original": "def get_lidar2global(infos):\n    lidar2ego = np.eye(4, dtype=np.float32)\n    lidar2ego[:3, :3] = Quaternion(infos['lidar2ego_rotation']).rotation_matrix\n    lidar2ego[:3, 3] = infos['lidar2ego_translation']\n    ego2global = np.eye(4, dtype=np.float32)\n    ego2global[:3, :3] = Quaternion(infos['ego2global_rotation']).rotation_matrix\n    ego2global[:3, 3] = infos['ego2global_translation']\n    return ego2global @ lidar2ego",
        "mutated": [
            "def get_lidar2global(infos):\n    if False:\n        i = 10\n    lidar2ego = np.eye(4, dtype=np.float32)\n    lidar2ego[:3, :3] = Quaternion(infos['lidar2ego_rotation']).rotation_matrix\n    lidar2ego[:3, 3] = infos['lidar2ego_translation']\n    ego2global = np.eye(4, dtype=np.float32)\n    ego2global[:3, :3] = Quaternion(infos['ego2global_rotation']).rotation_matrix\n    ego2global[:3, 3] = infos['ego2global_translation']\n    return ego2global @ lidar2ego",
            "def get_lidar2global(infos):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    lidar2ego = np.eye(4, dtype=np.float32)\n    lidar2ego[:3, :3] = Quaternion(infos['lidar2ego_rotation']).rotation_matrix\n    lidar2ego[:3, 3] = infos['lidar2ego_translation']\n    ego2global = np.eye(4, dtype=np.float32)\n    ego2global[:3, :3] = Quaternion(infos['ego2global_rotation']).rotation_matrix\n    ego2global[:3, 3] = infos['ego2global_translation']\n    return ego2global @ lidar2ego",
            "def get_lidar2global(infos):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    lidar2ego = np.eye(4, dtype=np.float32)\n    lidar2ego[:3, :3] = Quaternion(infos['lidar2ego_rotation']).rotation_matrix\n    lidar2ego[:3, 3] = infos['lidar2ego_translation']\n    ego2global = np.eye(4, dtype=np.float32)\n    ego2global[:3, :3] = Quaternion(infos['ego2global_rotation']).rotation_matrix\n    ego2global[:3, 3] = infos['ego2global_translation']\n    return ego2global @ lidar2ego",
            "def get_lidar2global(infos):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    lidar2ego = np.eye(4, dtype=np.float32)\n    lidar2ego[:3, :3] = Quaternion(infos['lidar2ego_rotation']).rotation_matrix\n    lidar2ego[:3, 3] = infos['lidar2ego_translation']\n    ego2global = np.eye(4, dtype=np.float32)\n    ego2global[:3, :3] = Quaternion(infos['ego2global_rotation']).rotation_matrix\n    ego2global[:3, 3] = infos['ego2global_translation']\n    return ego2global @ lidar2ego",
            "def get_lidar2global(infos):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    lidar2ego = np.eye(4, dtype=np.float32)\n    lidar2ego[:3, :3] = Quaternion(infos['lidar2ego_rotation']).rotation_matrix\n    lidar2ego[:3, 3] = infos['lidar2ego_translation']\n    ego2global = np.eye(4, dtype=np.float32)\n    ego2global[:3, :3] = Quaternion(infos['ego2global_rotation']).rotation_matrix\n    ego2global[:3, 3] = infos['ego2global_translation']\n    return ego2global @ lidar2ego"
        ]
    },
    {
        "func_name": "plot_result",
        "original": "def plot_result(res_path, vis_thred=0.3, version='val', draw_gt=True, save_format='image'):\n    img_list = []\n    root_path = '/data/Dataset/nuScenes'\n    show_range = 50\n    canva_size = 1000\n    vis_frames = 500\n    scale_factor = 2\n    fps = 5\n    vis_dir = './video_result'\n    color_map = {0: (255, 255, 0), 1: (0, 255, 255)}\n    res = json.load(open(res_path, 'r'))\n    info_path = os.path.join(root_path, f'mmdet3d_nuscenes_30f_infos_{version}.pkl')\n    with open(info_path, 'rb') as f:\n        dataset = pickle.load(f)\n    if save_format == 'video' and (not os.path.exists(vis_dir)):\n        os.makedirs(vis_dir)\n        fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n        vout = cv2.VideoWriter(os.path.join(vis_dir, 'vis.mp4'), fourcc, fps, (int(1600 / scale_factor * 3), int(900 / scale_factor * 2 + canva_size)))\n    draw_boxes_indexes_bev = [(0, 1), (1, 2), (2, 3), (3, 0)]\n    draw_boxes_indexes_img_view = [(0, 1), (1, 2), (2, 3), (3, 0), (4, 5), (5, 6), (6, 7), (7, 4), (0, 4), (1, 5), (2, 6), (3, 7)]\n    views = ['CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT']\n    dataset_dict = {}\n    for sample in dataset['infos']:\n        if sample['token'] not in dataset_dict:\n            dataset_dict[sample['token']] = sample\n    for (cnt, rst_token) in enumerate(res['results']):\n        if cnt >= vis_frames:\n            break\n        pred_res = res['results'][rst_token]\n        infos = dataset_dict[rst_token]\n        pred_boxes = [pred_res[rid]['translation'] + pred_res[rid]['size'] + [Quaternion(pred_res[rid]['rotation']).yaw_pitch_roll[0] + np.pi / 2] for rid in range(len(pred_res))]\n        if len(pred_boxes) == 0:\n            corners_lidar = np.zeros((0, 3), dtype=np.float32)\n        else:\n            pred_boxes = np.array(pred_boxes, dtype=np.float32)\n            boxes = LB(pred_boxes, origin=(0.5, 0.5, 0.5))\n            corners_global = boxes.corners.numpy().reshape(-1, 3)\n            corners_global = np.concatenate([corners_global, np.ones([corners_global.shape[0], 1])], axis=1)\n            l2g = get_lidar2global(infos)\n            corners_lidar = corners_global @ np.linalg.inv(l2g).T\n            corners_lidar = corners_lidar[:, :3]\n        pred_flag = np.ones((corners_lidar.shape[0] // 8,), dtype=bool)\n        scores = [pred_res[rid]['detection_score'] for rid in range(len(pred_res))]\n        if draw_gt:\n            gt_boxes = infos['gt_boxes']\n            gt_boxes[:, -1] = gt_boxes[:, -1] + np.pi / 2\n            width = gt_boxes[:, 4].copy()\n            gt_boxes[:, 4] = gt_boxes[:, 3]\n            gt_boxes[:, 3] = width\n            corners_lidar_gt = LB(infos['gt_boxes'], origin=(0.5, 0.5, 0.5)).corners.numpy().reshape(-1, 3)\n            corners_lidar = np.concatenate([corners_lidar, corners_lidar_gt], axis=0)\n            gt_flag = np.ones(corners_lidar_gt.shape[0] // 8, dtype=bool)\n            pred_flag = np.concatenate([pred_flag, np.logical_not(gt_flag)], axis=0)\n            scores = scores + [0 for _ in range(infos['gt_boxes'].shape[0])]\n        scores = np.array(scores, dtype=np.float32)\n        sort_ids = np.argsort(scores)\n        imgs = []\n        for view in views:\n            img = cv2.imread(infos['cams'][view]['data_path'])\n            (corners_img, valid) = lidar2img(corners_lidar, infos['cams'][view])\n            valid = np.logical_and(valid, check_point_in_img(corners_img, img.shape[0], img.shape[1]))\n            valid = valid.reshape(-1, 8)\n            corners_img = corners_img.reshape(-1, 8, 2).astype(int)\n            for aid in range(valid.shape[0]):\n                if scores[aid] < vis_thred and pred_flag[aid]:\n                    continue\n                for index in draw_boxes_indexes_img_view:\n                    if valid[aid, index[0]] and valid[aid, index[1]]:\n                        cv2.line(img, corners_img[aid, index[0]], corners_img[aid, index[1]], color=color_map[int(pred_flag[aid])], thickness=scale_factor)\n            imgs.append(img)\n        canvas = np.zeros((int(canva_size), int(canva_size), 3), dtype=np.uint8)\n        lidar_points = np.fromfile(infos['lidar_path'], dtype=np.float32)\n        lidar_points = lidar_points.reshape(-1, 5)[:, :3]\n        lidar_points[:, 1] = -lidar_points[:, 1]\n        lidar_points[:, :2] = (lidar_points[:, :2] + show_range) / show_range / 2.0 * canva_size\n        for p in lidar_points:\n            if check_point_in_img(p.reshape(1, 3), canvas.shape[1], canvas.shape[0])[0]:\n                color = depth2color(p[2])\n                cv2.circle(canvas, (int(p[0]), int(p[1])), radius=0, color=color, thickness=1)\n        corners_lidar = corners_lidar.reshape(-1, 8, 3)\n        corners_lidar[:, :, 1] = -corners_lidar[:, :, 1]\n        bottom_corners_bev = corners_lidar[:, [0, 3, 7, 4], :2]\n        bottom_corners_bev = (bottom_corners_bev + show_range) / show_range / 2.0 * canva_size\n        bottom_corners_bev = np.round(bottom_corners_bev).astype(np.int32)\n        center_bev = corners_lidar[:, [0, 3, 7, 4], :2].mean(axis=1)\n        head_bev = corners_lidar[:, [0, 4], :2].mean(axis=1)\n        canter_canvas = (center_bev + show_range) / show_range / 2.0 * canva_size\n        center_canvas = canter_canvas.astype(np.int32)\n        head_canvas = (head_bev + show_range) / show_range / 2.0 * canva_size\n        head_canvas = head_canvas.astype(np.int32)\n        for rid in sort_ids:\n            score = scores[rid]\n            if score < vis_thred and pred_flag[rid]:\n                continue\n            score = min(score * 2.0, 1.0) if pred_flag[rid] else 1.0\n            color = color_map[int(pred_flag[rid])]\n            for index in draw_boxes_indexes_bev:\n                cv2.line(canvas, bottom_corners_bev[rid, index[0]], bottom_corners_bev[rid, index[1]], [color[0] * score, color[1] * score, color[2] * score], thickness=1)\n            cv2.line(canvas, center_canvas[rid], head_canvas[rid], [color[0] * score, color[1] * score, color[2] * score], 1, lineType=8)\n        img = np.zeros((900 * 2 + canva_size * scale_factor, 1600 * 3, 3), dtype=np.uint8)\n        img[:900, :, :] = np.concatenate(imgs[:3], axis=1)\n        img_back = np.concatenate([imgs[3][:, ::-1, :], imgs[4][:, ::-1, :], imgs[5][:, ::-1, :]], axis=1)\n        img[900 + canva_size * scale_factor:, :, :] = img_back\n        img = cv2.resize(img, (int(1600 / scale_factor * 3), int(900 / scale_factor * 2 + canva_size)))\n        w_begin = int((1600 * 3 / scale_factor - canva_size) // 2)\n        img[int(900 / scale_factor):int(900 / scale_factor) + canva_size, w_begin:w_begin + canva_size, :] = canvas\n        if save_format == 'image':\n            img_list += [img]\n        elif save_format == 'video':\n            vout.write(img)\n    if save_format == 'video':\n        vout.release()\n    return img_list",
        "mutated": [
            "def plot_result(res_path, vis_thred=0.3, version='val', draw_gt=True, save_format='image'):\n    if False:\n        i = 10\n    img_list = []\n    root_path = '/data/Dataset/nuScenes'\n    show_range = 50\n    canva_size = 1000\n    vis_frames = 500\n    scale_factor = 2\n    fps = 5\n    vis_dir = './video_result'\n    color_map = {0: (255, 255, 0), 1: (0, 255, 255)}\n    res = json.load(open(res_path, 'r'))\n    info_path = os.path.join(root_path, f'mmdet3d_nuscenes_30f_infos_{version}.pkl')\n    with open(info_path, 'rb') as f:\n        dataset = pickle.load(f)\n    if save_format == 'video' and (not os.path.exists(vis_dir)):\n        os.makedirs(vis_dir)\n        fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n        vout = cv2.VideoWriter(os.path.join(vis_dir, 'vis.mp4'), fourcc, fps, (int(1600 / scale_factor * 3), int(900 / scale_factor * 2 + canva_size)))\n    draw_boxes_indexes_bev = [(0, 1), (1, 2), (2, 3), (3, 0)]\n    draw_boxes_indexes_img_view = [(0, 1), (1, 2), (2, 3), (3, 0), (4, 5), (5, 6), (6, 7), (7, 4), (0, 4), (1, 5), (2, 6), (3, 7)]\n    views = ['CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT']\n    dataset_dict = {}\n    for sample in dataset['infos']:\n        if sample['token'] not in dataset_dict:\n            dataset_dict[sample['token']] = sample\n    for (cnt, rst_token) in enumerate(res['results']):\n        if cnt >= vis_frames:\n            break\n        pred_res = res['results'][rst_token]\n        infos = dataset_dict[rst_token]\n        pred_boxes = [pred_res[rid]['translation'] + pred_res[rid]['size'] + [Quaternion(pred_res[rid]['rotation']).yaw_pitch_roll[0] + np.pi / 2] for rid in range(len(pred_res))]\n        if len(pred_boxes) == 0:\n            corners_lidar = np.zeros((0, 3), dtype=np.float32)\n        else:\n            pred_boxes = np.array(pred_boxes, dtype=np.float32)\n            boxes = LB(pred_boxes, origin=(0.5, 0.5, 0.5))\n            corners_global = boxes.corners.numpy().reshape(-1, 3)\n            corners_global = np.concatenate([corners_global, np.ones([corners_global.shape[0], 1])], axis=1)\n            l2g = get_lidar2global(infos)\n            corners_lidar = corners_global @ np.linalg.inv(l2g).T\n            corners_lidar = corners_lidar[:, :3]\n        pred_flag = np.ones((corners_lidar.shape[0] // 8,), dtype=bool)\n        scores = [pred_res[rid]['detection_score'] for rid in range(len(pred_res))]\n        if draw_gt:\n            gt_boxes = infos['gt_boxes']\n            gt_boxes[:, -1] = gt_boxes[:, -1] + np.pi / 2\n            width = gt_boxes[:, 4].copy()\n            gt_boxes[:, 4] = gt_boxes[:, 3]\n            gt_boxes[:, 3] = width\n            corners_lidar_gt = LB(infos['gt_boxes'], origin=(0.5, 0.5, 0.5)).corners.numpy().reshape(-1, 3)\n            corners_lidar = np.concatenate([corners_lidar, corners_lidar_gt], axis=0)\n            gt_flag = np.ones(corners_lidar_gt.shape[0] // 8, dtype=bool)\n            pred_flag = np.concatenate([pred_flag, np.logical_not(gt_flag)], axis=0)\n            scores = scores + [0 for _ in range(infos['gt_boxes'].shape[0])]\n        scores = np.array(scores, dtype=np.float32)\n        sort_ids = np.argsort(scores)\n        imgs = []\n        for view in views:\n            img = cv2.imread(infos['cams'][view]['data_path'])\n            (corners_img, valid) = lidar2img(corners_lidar, infos['cams'][view])\n            valid = np.logical_and(valid, check_point_in_img(corners_img, img.shape[0], img.shape[1]))\n            valid = valid.reshape(-1, 8)\n            corners_img = corners_img.reshape(-1, 8, 2).astype(int)\n            for aid in range(valid.shape[0]):\n                if scores[aid] < vis_thred and pred_flag[aid]:\n                    continue\n                for index in draw_boxes_indexes_img_view:\n                    if valid[aid, index[0]] and valid[aid, index[1]]:\n                        cv2.line(img, corners_img[aid, index[0]], corners_img[aid, index[1]], color=color_map[int(pred_flag[aid])], thickness=scale_factor)\n            imgs.append(img)\n        canvas = np.zeros((int(canva_size), int(canva_size), 3), dtype=np.uint8)\n        lidar_points = np.fromfile(infos['lidar_path'], dtype=np.float32)\n        lidar_points = lidar_points.reshape(-1, 5)[:, :3]\n        lidar_points[:, 1] = -lidar_points[:, 1]\n        lidar_points[:, :2] = (lidar_points[:, :2] + show_range) / show_range / 2.0 * canva_size\n        for p in lidar_points:\n            if check_point_in_img(p.reshape(1, 3), canvas.shape[1], canvas.shape[0])[0]:\n                color = depth2color(p[2])\n                cv2.circle(canvas, (int(p[0]), int(p[1])), radius=0, color=color, thickness=1)\n        corners_lidar = corners_lidar.reshape(-1, 8, 3)\n        corners_lidar[:, :, 1] = -corners_lidar[:, :, 1]\n        bottom_corners_bev = corners_lidar[:, [0, 3, 7, 4], :2]\n        bottom_corners_bev = (bottom_corners_bev + show_range) / show_range / 2.0 * canva_size\n        bottom_corners_bev = np.round(bottom_corners_bev).astype(np.int32)\n        center_bev = corners_lidar[:, [0, 3, 7, 4], :2].mean(axis=1)\n        head_bev = corners_lidar[:, [0, 4], :2].mean(axis=1)\n        canter_canvas = (center_bev + show_range) / show_range / 2.0 * canva_size\n        center_canvas = canter_canvas.astype(np.int32)\n        head_canvas = (head_bev + show_range) / show_range / 2.0 * canva_size\n        head_canvas = head_canvas.astype(np.int32)\n        for rid in sort_ids:\n            score = scores[rid]\n            if score < vis_thred and pred_flag[rid]:\n                continue\n            score = min(score * 2.0, 1.0) if pred_flag[rid] else 1.0\n            color = color_map[int(pred_flag[rid])]\n            for index in draw_boxes_indexes_bev:\n                cv2.line(canvas, bottom_corners_bev[rid, index[0]], bottom_corners_bev[rid, index[1]], [color[0] * score, color[1] * score, color[2] * score], thickness=1)\n            cv2.line(canvas, center_canvas[rid], head_canvas[rid], [color[0] * score, color[1] * score, color[2] * score], 1, lineType=8)\n        img = np.zeros((900 * 2 + canva_size * scale_factor, 1600 * 3, 3), dtype=np.uint8)\n        img[:900, :, :] = np.concatenate(imgs[:3], axis=1)\n        img_back = np.concatenate([imgs[3][:, ::-1, :], imgs[4][:, ::-1, :], imgs[5][:, ::-1, :]], axis=1)\n        img[900 + canva_size * scale_factor:, :, :] = img_back\n        img = cv2.resize(img, (int(1600 / scale_factor * 3), int(900 / scale_factor * 2 + canva_size)))\n        w_begin = int((1600 * 3 / scale_factor - canva_size) // 2)\n        img[int(900 / scale_factor):int(900 / scale_factor) + canva_size, w_begin:w_begin + canva_size, :] = canvas\n        if save_format == 'image':\n            img_list += [img]\n        elif save_format == 'video':\n            vout.write(img)\n    if save_format == 'video':\n        vout.release()\n    return img_list",
            "def plot_result(res_path, vis_thred=0.3, version='val', draw_gt=True, save_format='image'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    img_list = []\n    root_path = '/data/Dataset/nuScenes'\n    show_range = 50\n    canva_size = 1000\n    vis_frames = 500\n    scale_factor = 2\n    fps = 5\n    vis_dir = './video_result'\n    color_map = {0: (255, 255, 0), 1: (0, 255, 255)}\n    res = json.load(open(res_path, 'r'))\n    info_path = os.path.join(root_path, f'mmdet3d_nuscenes_30f_infos_{version}.pkl')\n    with open(info_path, 'rb') as f:\n        dataset = pickle.load(f)\n    if save_format == 'video' and (not os.path.exists(vis_dir)):\n        os.makedirs(vis_dir)\n        fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n        vout = cv2.VideoWriter(os.path.join(vis_dir, 'vis.mp4'), fourcc, fps, (int(1600 / scale_factor * 3), int(900 / scale_factor * 2 + canva_size)))\n    draw_boxes_indexes_bev = [(0, 1), (1, 2), (2, 3), (3, 0)]\n    draw_boxes_indexes_img_view = [(0, 1), (1, 2), (2, 3), (3, 0), (4, 5), (5, 6), (6, 7), (7, 4), (0, 4), (1, 5), (2, 6), (3, 7)]\n    views = ['CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT']\n    dataset_dict = {}\n    for sample in dataset['infos']:\n        if sample['token'] not in dataset_dict:\n            dataset_dict[sample['token']] = sample\n    for (cnt, rst_token) in enumerate(res['results']):\n        if cnt >= vis_frames:\n            break\n        pred_res = res['results'][rst_token]\n        infos = dataset_dict[rst_token]\n        pred_boxes = [pred_res[rid]['translation'] + pred_res[rid]['size'] + [Quaternion(pred_res[rid]['rotation']).yaw_pitch_roll[0] + np.pi / 2] for rid in range(len(pred_res))]\n        if len(pred_boxes) == 0:\n            corners_lidar = np.zeros((0, 3), dtype=np.float32)\n        else:\n            pred_boxes = np.array(pred_boxes, dtype=np.float32)\n            boxes = LB(pred_boxes, origin=(0.5, 0.5, 0.5))\n            corners_global = boxes.corners.numpy().reshape(-1, 3)\n            corners_global = np.concatenate([corners_global, np.ones([corners_global.shape[0], 1])], axis=1)\n            l2g = get_lidar2global(infos)\n            corners_lidar = corners_global @ np.linalg.inv(l2g).T\n            corners_lidar = corners_lidar[:, :3]\n        pred_flag = np.ones((corners_lidar.shape[0] // 8,), dtype=bool)\n        scores = [pred_res[rid]['detection_score'] for rid in range(len(pred_res))]\n        if draw_gt:\n            gt_boxes = infos['gt_boxes']\n            gt_boxes[:, -1] = gt_boxes[:, -1] + np.pi / 2\n            width = gt_boxes[:, 4].copy()\n            gt_boxes[:, 4] = gt_boxes[:, 3]\n            gt_boxes[:, 3] = width\n            corners_lidar_gt = LB(infos['gt_boxes'], origin=(0.5, 0.5, 0.5)).corners.numpy().reshape(-1, 3)\n            corners_lidar = np.concatenate([corners_lidar, corners_lidar_gt], axis=0)\n            gt_flag = np.ones(corners_lidar_gt.shape[0] // 8, dtype=bool)\n            pred_flag = np.concatenate([pred_flag, np.logical_not(gt_flag)], axis=0)\n            scores = scores + [0 for _ in range(infos['gt_boxes'].shape[0])]\n        scores = np.array(scores, dtype=np.float32)\n        sort_ids = np.argsort(scores)\n        imgs = []\n        for view in views:\n            img = cv2.imread(infos['cams'][view]['data_path'])\n            (corners_img, valid) = lidar2img(corners_lidar, infos['cams'][view])\n            valid = np.logical_and(valid, check_point_in_img(corners_img, img.shape[0], img.shape[1]))\n            valid = valid.reshape(-1, 8)\n            corners_img = corners_img.reshape(-1, 8, 2).astype(int)\n            for aid in range(valid.shape[0]):\n                if scores[aid] < vis_thred and pred_flag[aid]:\n                    continue\n                for index in draw_boxes_indexes_img_view:\n                    if valid[aid, index[0]] and valid[aid, index[1]]:\n                        cv2.line(img, corners_img[aid, index[0]], corners_img[aid, index[1]], color=color_map[int(pred_flag[aid])], thickness=scale_factor)\n            imgs.append(img)\n        canvas = np.zeros((int(canva_size), int(canva_size), 3), dtype=np.uint8)\n        lidar_points = np.fromfile(infos['lidar_path'], dtype=np.float32)\n        lidar_points = lidar_points.reshape(-1, 5)[:, :3]\n        lidar_points[:, 1] = -lidar_points[:, 1]\n        lidar_points[:, :2] = (lidar_points[:, :2] + show_range) / show_range / 2.0 * canva_size\n        for p in lidar_points:\n            if check_point_in_img(p.reshape(1, 3), canvas.shape[1], canvas.shape[0])[0]:\n                color = depth2color(p[2])\n                cv2.circle(canvas, (int(p[0]), int(p[1])), radius=0, color=color, thickness=1)\n        corners_lidar = corners_lidar.reshape(-1, 8, 3)\n        corners_lidar[:, :, 1] = -corners_lidar[:, :, 1]\n        bottom_corners_bev = corners_lidar[:, [0, 3, 7, 4], :2]\n        bottom_corners_bev = (bottom_corners_bev + show_range) / show_range / 2.0 * canva_size\n        bottom_corners_bev = np.round(bottom_corners_bev).astype(np.int32)\n        center_bev = corners_lidar[:, [0, 3, 7, 4], :2].mean(axis=1)\n        head_bev = corners_lidar[:, [0, 4], :2].mean(axis=1)\n        canter_canvas = (center_bev + show_range) / show_range / 2.0 * canva_size\n        center_canvas = canter_canvas.astype(np.int32)\n        head_canvas = (head_bev + show_range) / show_range / 2.0 * canva_size\n        head_canvas = head_canvas.astype(np.int32)\n        for rid in sort_ids:\n            score = scores[rid]\n            if score < vis_thred and pred_flag[rid]:\n                continue\n            score = min(score * 2.0, 1.0) if pred_flag[rid] else 1.0\n            color = color_map[int(pred_flag[rid])]\n            for index in draw_boxes_indexes_bev:\n                cv2.line(canvas, bottom_corners_bev[rid, index[0]], bottom_corners_bev[rid, index[1]], [color[0] * score, color[1] * score, color[2] * score], thickness=1)\n            cv2.line(canvas, center_canvas[rid], head_canvas[rid], [color[0] * score, color[1] * score, color[2] * score], 1, lineType=8)\n        img = np.zeros((900 * 2 + canva_size * scale_factor, 1600 * 3, 3), dtype=np.uint8)\n        img[:900, :, :] = np.concatenate(imgs[:3], axis=1)\n        img_back = np.concatenate([imgs[3][:, ::-1, :], imgs[4][:, ::-1, :], imgs[5][:, ::-1, :]], axis=1)\n        img[900 + canva_size * scale_factor:, :, :] = img_back\n        img = cv2.resize(img, (int(1600 / scale_factor * 3), int(900 / scale_factor * 2 + canva_size)))\n        w_begin = int((1600 * 3 / scale_factor - canva_size) // 2)\n        img[int(900 / scale_factor):int(900 / scale_factor) + canva_size, w_begin:w_begin + canva_size, :] = canvas\n        if save_format == 'image':\n            img_list += [img]\n        elif save_format == 'video':\n            vout.write(img)\n    if save_format == 'video':\n        vout.release()\n    return img_list",
            "def plot_result(res_path, vis_thred=0.3, version='val', draw_gt=True, save_format='image'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    img_list = []\n    root_path = '/data/Dataset/nuScenes'\n    show_range = 50\n    canva_size = 1000\n    vis_frames = 500\n    scale_factor = 2\n    fps = 5\n    vis_dir = './video_result'\n    color_map = {0: (255, 255, 0), 1: (0, 255, 255)}\n    res = json.load(open(res_path, 'r'))\n    info_path = os.path.join(root_path, f'mmdet3d_nuscenes_30f_infos_{version}.pkl')\n    with open(info_path, 'rb') as f:\n        dataset = pickle.load(f)\n    if save_format == 'video' and (not os.path.exists(vis_dir)):\n        os.makedirs(vis_dir)\n        fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n        vout = cv2.VideoWriter(os.path.join(vis_dir, 'vis.mp4'), fourcc, fps, (int(1600 / scale_factor * 3), int(900 / scale_factor * 2 + canva_size)))\n    draw_boxes_indexes_bev = [(0, 1), (1, 2), (2, 3), (3, 0)]\n    draw_boxes_indexes_img_view = [(0, 1), (1, 2), (2, 3), (3, 0), (4, 5), (5, 6), (6, 7), (7, 4), (0, 4), (1, 5), (2, 6), (3, 7)]\n    views = ['CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT']\n    dataset_dict = {}\n    for sample in dataset['infos']:\n        if sample['token'] not in dataset_dict:\n            dataset_dict[sample['token']] = sample\n    for (cnt, rst_token) in enumerate(res['results']):\n        if cnt >= vis_frames:\n            break\n        pred_res = res['results'][rst_token]\n        infos = dataset_dict[rst_token]\n        pred_boxes = [pred_res[rid]['translation'] + pred_res[rid]['size'] + [Quaternion(pred_res[rid]['rotation']).yaw_pitch_roll[0] + np.pi / 2] for rid in range(len(pred_res))]\n        if len(pred_boxes) == 0:\n            corners_lidar = np.zeros((0, 3), dtype=np.float32)\n        else:\n            pred_boxes = np.array(pred_boxes, dtype=np.float32)\n            boxes = LB(pred_boxes, origin=(0.5, 0.5, 0.5))\n            corners_global = boxes.corners.numpy().reshape(-1, 3)\n            corners_global = np.concatenate([corners_global, np.ones([corners_global.shape[0], 1])], axis=1)\n            l2g = get_lidar2global(infos)\n            corners_lidar = corners_global @ np.linalg.inv(l2g).T\n            corners_lidar = corners_lidar[:, :3]\n        pred_flag = np.ones((corners_lidar.shape[0] // 8,), dtype=bool)\n        scores = [pred_res[rid]['detection_score'] for rid in range(len(pred_res))]\n        if draw_gt:\n            gt_boxes = infos['gt_boxes']\n            gt_boxes[:, -1] = gt_boxes[:, -1] + np.pi / 2\n            width = gt_boxes[:, 4].copy()\n            gt_boxes[:, 4] = gt_boxes[:, 3]\n            gt_boxes[:, 3] = width\n            corners_lidar_gt = LB(infos['gt_boxes'], origin=(0.5, 0.5, 0.5)).corners.numpy().reshape(-1, 3)\n            corners_lidar = np.concatenate([corners_lidar, corners_lidar_gt], axis=0)\n            gt_flag = np.ones(corners_lidar_gt.shape[0] // 8, dtype=bool)\n            pred_flag = np.concatenate([pred_flag, np.logical_not(gt_flag)], axis=0)\n            scores = scores + [0 for _ in range(infos['gt_boxes'].shape[0])]\n        scores = np.array(scores, dtype=np.float32)\n        sort_ids = np.argsort(scores)\n        imgs = []\n        for view in views:\n            img = cv2.imread(infos['cams'][view]['data_path'])\n            (corners_img, valid) = lidar2img(corners_lidar, infos['cams'][view])\n            valid = np.logical_and(valid, check_point_in_img(corners_img, img.shape[0], img.shape[1]))\n            valid = valid.reshape(-1, 8)\n            corners_img = corners_img.reshape(-1, 8, 2).astype(int)\n            for aid in range(valid.shape[0]):\n                if scores[aid] < vis_thred and pred_flag[aid]:\n                    continue\n                for index in draw_boxes_indexes_img_view:\n                    if valid[aid, index[0]] and valid[aid, index[1]]:\n                        cv2.line(img, corners_img[aid, index[0]], corners_img[aid, index[1]], color=color_map[int(pred_flag[aid])], thickness=scale_factor)\n            imgs.append(img)\n        canvas = np.zeros((int(canva_size), int(canva_size), 3), dtype=np.uint8)\n        lidar_points = np.fromfile(infos['lidar_path'], dtype=np.float32)\n        lidar_points = lidar_points.reshape(-1, 5)[:, :3]\n        lidar_points[:, 1] = -lidar_points[:, 1]\n        lidar_points[:, :2] = (lidar_points[:, :2] + show_range) / show_range / 2.0 * canva_size\n        for p in lidar_points:\n            if check_point_in_img(p.reshape(1, 3), canvas.shape[1], canvas.shape[0])[0]:\n                color = depth2color(p[2])\n                cv2.circle(canvas, (int(p[0]), int(p[1])), radius=0, color=color, thickness=1)\n        corners_lidar = corners_lidar.reshape(-1, 8, 3)\n        corners_lidar[:, :, 1] = -corners_lidar[:, :, 1]\n        bottom_corners_bev = corners_lidar[:, [0, 3, 7, 4], :2]\n        bottom_corners_bev = (bottom_corners_bev + show_range) / show_range / 2.0 * canva_size\n        bottom_corners_bev = np.round(bottom_corners_bev).astype(np.int32)\n        center_bev = corners_lidar[:, [0, 3, 7, 4], :2].mean(axis=1)\n        head_bev = corners_lidar[:, [0, 4], :2].mean(axis=1)\n        canter_canvas = (center_bev + show_range) / show_range / 2.0 * canva_size\n        center_canvas = canter_canvas.astype(np.int32)\n        head_canvas = (head_bev + show_range) / show_range / 2.0 * canva_size\n        head_canvas = head_canvas.astype(np.int32)\n        for rid in sort_ids:\n            score = scores[rid]\n            if score < vis_thred and pred_flag[rid]:\n                continue\n            score = min(score * 2.0, 1.0) if pred_flag[rid] else 1.0\n            color = color_map[int(pred_flag[rid])]\n            for index in draw_boxes_indexes_bev:\n                cv2.line(canvas, bottom_corners_bev[rid, index[0]], bottom_corners_bev[rid, index[1]], [color[0] * score, color[1] * score, color[2] * score], thickness=1)\n            cv2.line(canvas, center_canvas[rid], head_canvas[rid], [color[0] * score, color[1] * score, color[2] * score], 1, lineType=8)\n        img = np.zeros((900 * 2 + canva_size * scale_factor, 1600 * 3, 3), dtype=np.uint8)\n        img[:900, :, :] = np.concatenate(imgs[:3], axis=1)\n        img_back = np.concatenate([imgs[3][:, ::-1, :], imgs[4][:, ::-1, :], imgs[5][:, ::-1, :]], axis=1)\n        img[900 + canva_size * scale_factor:, :, :] = img_back\n        img = cv2.resize(img, (int(1600 / scale_factor * 3), int(900 / scale_factor * 2 + canva_size)))\n        w_begin = int((1600 * 3 / scale_factor - canva_size) // 2)\n        img[int(900 / scale_factor):int(900 / scale_factor) + canva_size, w_begin:w_begin + canva_size, :] = canvas\n        if save_format == 'image':\n            img_list += [img]\n        elif save_format == 'video':\n            vout.write(img)\n    if save_format == 'video':\n        vout.release()\n    return img_list",
            "def plot_result(res_path, vis_thred=0.3, version='val', draw_gt=True, save_format='image'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    img_list = []\n    root_path = '/data/Dataset/nuScenes'\n    show_range = 50\n    canva_size = 1000\n    vis_frames = 500\n    scale_factor = 2\n    fps = 5\n    vis_dir = './video_result'\n    color_map = {0: (255, 255, 0), 1: (0, 255, 255)}\n    res = json.load(open(res_path, 'r'))\n    info_path = os.path.join(root_path, f'mmdet3d_nuscenes_30f_infos_{version}.pkl')\n    with open(info_path, 'rb') as f:\n        dataset = pickle.load(f)\n    if save_format == 'video' and (not os.path.exists(vis_dir)):\n        os.makedirs(vis_dir)\n        fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n        vout = cv2.VideoWriter(os.path.join(vis_dir, 'vis.mp4'), fourcc, fps, (int(1600 / scale_factor * 3), int(900 / scale_factor * 2 + canva_size)))\n    draw_boxes_indexes_bev = [(0, 1), (1, 2), (2, 3), (3, 0)]\n    draw_boxes_indexes_img_view = [(0, 1), (1, 2), (2, 3), (3, 0), (4, 5), (5, 6), (6, 7), (7, 4), (0, 4), (1, 5), (2, 6), (3, 7)]\n    views = ['CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT']\n    dataset_dict = {}\n    for sample in dataset['infos']:\n        if sample['token'] not in dataset_dict:\n            dataset_dict[sample['token']] = sample\n    for (cnt, rst_token) in enumerate(res['results']):\n        if cnt >= vis_frames:\n            break\n        pred_res = res['results'][rst_token]\n        infos = dataset_dict[rst_token]\n        pred_boxes = [pred_res[rid]['translation'] + pred_res[rid]['size'] + [Quaternion(pred_res[rid]['rotation']).yaw_pitch_roll[0] + np.pi / 2] for rid in range(len(pred_res))]\n        if len(pred_boxes) == 0:\n            corners_lidar = np.zeros((0, 3), dtype=np.float32)\n        else:\n            pred_boxes = np.array(pred_boxes, dtype=np.float32)\n            boxes = LB(pred_boxes, origin=(0.5, 0.5, 0.5))\n            corners_global = boxes.corners.numpy().reshape(-1, 3)\n            corners_global = np.concatenate([corners_global, np.ones([corners_global.shape[0], 1])], axis=1)\n            l2g = get_lidar2global(infos)\n            corners_lidar = corners_global @ np.linalg.inv(l2g).T\n            corners_lidar = corners_lidar[:, :3]\n        pred_flag = np.ones((corners_lidar.shape[0] // 8,), dtype=bool)\n        scores = [pred_res[rid]['detection_score'] for rid in range(len(pred_res))]\n        if draw_gt:\n            gt_boxes = infos['gt_boxes']\n            gt_boxes[:, -1] = gt_boxes[:, -1] + np.pi / 2\n            width = gt_boxes[:, 4].copy()\n            gt_boxes[:, 4] = gt_boxes[:, 3]\n            gt_boxes[:, 3] = width\n            corners_lidar_gt = LB(infos['gt_boxes'], origin=(0.5, 0.5, 0.5)).corners.numpy().reshape(-1, 3)\n            corners_lidar = np.concatenate([corners_lidar, corners_lidar_gt], axis=0)\n            gt_flag = np.ones(corners_lidar_gt.shape[0] // 8, dtype=bool)\n            pred_flag = np.concatenate([pred_flag, np.logical_not(gt_flag)], axis=0)\n            scores = scores + [0 for _ in range(infos['gt_boxes'].shape[0])]\n        scores = np.array(scores, dtype=np.float32)\n        sort_ids = np.argsort(scores)\n        imgs = []\n        for view in views:\n            img = cv2.imread(infos['cams'][view]['data_path'])\n            (corners_img, valid) = lidar2img(corners_lidar, infos['cams'][view])\n            valid = np.logical_and(valid, check_point_in_img(corners_img, img.shape[0], img.shape[1]))\n            valid = valid.reshape(-1, 8)\n            corners_img = corners_img.reshape(-1, 8, 2).astype(int)\n            for aid in range(valid.shape[0]):\n                if scores[aid] < vis_thred and pred_flag[aid]:\n                    continue\n                for index in draw_boxes_indexes_img_view:\n                    if valid[aid, index[0]] and valid[aid, index[1]]:\n                        cv2.line(img, corners_img[aid, index[0]], corners_img[aid, index[1]], color=color_map[int(pred_flag[aid])], thickness=scale_factor)\n            imgs.append(img)\n        canvas = np.zeros((int(canva_size), int(canva_size), 3), dtype=np.uint8)\n        lidar_points = np.fromfile(infos['lidar_path'], dtype=np.float32)\n        lidar_points = lidar_points.reshape(-1, 5)[:, :3]\n        lidar_points[:, 1] = -lidar_points[:, 1]\n        lidar_points[:, :2] = (lidar_points[:, :2] + show_range) / show_range / 2.0 * canva_size\n        for p in lidar_points:\n            if check_point_in_img(p.reshape(1, 3), canvas.shape[1], canvas.shape[0])[0]:\n                color = depth2color(p[2])\n                cv2.circle(canvas, (int(p[0]), int(p[1])), radius=0, color=color, thickness=1)\n        corners_lidar = corners_lidar.reshape(-1, 8, 3)\n        corners_lidar[:, :, 1] = -corners_lidar[:, :, 1]\n        bottom_corners_bev = corners_lidar[:, [0, 3, 7, 4], :2]\n        bottom_corners_bev = (bottom_corners_bev + show_range) / show_range / 2.0 * canva_size\n        bottom_corners_bev = np.round(bottom_corners_bev).astype(np.int32)\n        center_bev = corners_lidar[:, [0, 3, 7, 4], :2].mean(axis=1)\n        head_bev = corners_lidar[:, [0, 4], :2].mean(axis=1)\n        canter_canvas = (center_bev + show_range) / show_range / 2.0 * canva_size\n        center_canvas = canter_canvas.astype(np.int32)\n        head_canvas = (head_bev + show_range) / show_range / 2.0 * canva_size\n        head_canvas = head_canvas.astype(np.int32)\n        for rid in sort_ids:\n            score = scores[rid]\n            if score < vis_thred and pred_flag[rid]:\n                continue\n            score = min(score * 2.0, 1.0) if pred_flag[rid] else 1.0\n            color = color_map[int(pred_flag[rid])]\n            for index in draw_boxes_indexes_bev:\n                cv2.line(canvas, bottom_corners_bev[rid, index[0]], bottom_corners_bev[rid, index[1]], [color[0] * score, color[1] * score, color[2] * score], thickness=1)\n            cv2.line(canvas, center_canvas[rid], head_canvas[rid], [color[0] * score, color[1] * score, color[2] * score], 1, lineType=8)\n        img = np.zeros((900 * 2 + canva_size * scale_factor, 1600 * 3, 3), dtype=np.uint8)\n        img[:900, :, :] = np.concatenate(imgs[:3], axis=1)\n        img_back = np.concatenate([imgs[3][:, ::-1, :], imgs[4][:, ::-1, :], imgs[5][:, ::-1, :]], axis=1)\n        img[900 + canva_size * scale_factor:, :, :] = img_back\n        img = cv2.resize(img, (int(1600 / scale_factor * 3), int(900 / scale_factor * 2 + canva_size)))\n        w_begin = int((1600 * 3 / scale_factor - canva_size) // 2)\n        img[int(900 / scale_factor):int(900 / scale_factor) + canva_size, w_begin:w_begin + canva_size, :] = canvas\n        if save_format == 'image':\n            img_list += [img]\n        elif save_format == 'video':\n            vout.write(img)\n    if save_format == 'video':\n        vout.release()\n    return img_list",
            "def plot_result(res_path, vis_thred=0.3, version='val', draw_gt=True, save_format='image'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    img_list = []\n    root_path = '/data/Dataset/nuScenes'\n    show_range = 50\n    canva_size = 1000\n    vis_frames = 500\n    scale_factor = 2\n    fps = 5\n    vis_dir = './video_result'\n    color_map = {0: (255, 255, 0), 1: (0, 255, 255)}\n    res = json.load(open(res_path, 'r'))\n    info_path = os.path.join(root_path, f'mmdet3d_nuscenes_30f_infos_{version}.pkl')\n    with open(info_path, 'rb') as f:\n        dataset = pickle.load(f)\n    if save_format == 'video' and (not os.path.exists(vis_dir)):\n        os.makedirs(vis_dir)\n        fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n        vout = cv2.VideoWriter(os.path.join(vis_dir, 'vis.mp4'), fourcc, fps, (int(1600 / scale_factor * 3), int(900 / scale_factor * 2 + canva_size)))\n    draw_boxes_indexes_bev = [(0, 1), (1, 2), (2, 3), (3, 0)]\n    draw_boxes_indexes_img_view = [(0, 1), (1, 2), (2, 3), (3, 0), (4, 5), (5, 6), (6, 7), (7, 4), (0, 4), (1, 5), (2, 6), (3, 7)]\n    views = ['CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT']\n    dataset_dict = {}\n    for sample in dataset['infos']:\n        if sample['token'] not in dataset_dict:\n            dataset_dict[sample['token']] = sample\n    for (cnt, rst_token) in enumerate(res['results']):\n        if cnt >= vis_frames:\n            break\n        pred_res = res['results'][rst_token]\n        infos = dataset_dict[rst_token]\n        pred_boxes = [pred_res[rid]['translation'] + pred_res[rid]['size'] + [Quaternion(pred_res[rid]['rotation']).yaw_pitch_roll[0] + np.pi / 2] for rid in range(len(pred_res))]\n        if len(pred_boxes) == 0:\n            corners_lidar = np.zeros((0, 3), dtype=np.float32)\n        else:\n            pred_boxes = np.array(pred_boxes, dtype=np.float32)\n            boxes = LB(pred_boxes, origin=(0.5, 0.5, 0.5))\n            corners_global = boxes.corners.numpy().reshape(-1, 3)\n            corners_global = np.concatenate([corners_global, np.ones([corners_global.shape[0], 1])], axis=1)\n            l2g = get_lidar2global(infos)\n            corners_lidar = corners_global @ np.linalg.inv(l2g).T\n            corners_lidar = corners_lidar[:, :3]\n        pred_flag = np.ones((corners_lidar.shape[0] // 8,), dtype=bool)\n        scores = [pred_res[rid]['detection_score'] for rid in range(len(pred_res))]\n        if draw_gt:\n            gt_boxes = infos['gt_boxes']\n            gt_boxes[:, -1] = gt_boxes[:, -1] + np.pi / 2\n            width = gt_boxes[:, 4].copy()\n            gt_boxes[:, 4] = gt_boxes[:, 3]\n            gt_boxes[:, 3] = width\n            corners_lidar_gt = LB(infos['gt_boxes'], origin=(0.5, 0.5, 0.5)).corners.numpy().reshape(-1, 3)\n            corners_lidar = np.concatenate([corners_lidar, corners_lidar_gt], axis=0)\n            gt_flag = np.ones(corners_lidar_gt.shape[0] // 8, dtype=bool)\n            pred_flag = np.concatenate([pred_flag, np.logical_not(gt_flag)], axis=0)\n            scores = scores + [0 for _ in range(infos['gt_boxes'].shape[0])]\n        scores = np.array(scores, dtype=np.float32)\n        sort_ids = np.argsort(scores)\n        imgs = []\n        for view in views:\n            img = cv2.imread(infos['cams'][view]['data_path'])\n            (corners_img, valid) = lidar2img(corners_lidar, infos['cams'][view])\n            valid = np.logical_and(valid, check_point_in_img(corners_img, img.shape[0], img.shape[1]))\n            valid = valid.reshape(-1, 8)\n            corners_img = corners_img.reshape(-1, 8, 2).astype(int)\n            for aid in range(valid.shape[0]):\n                if scores[aid] < vis_thred and pred_flag[aid]:\n                    continue\n                for index in draw_boxes_indexes_img_view:\n                    if valid[aid, index[0]] and valid[aid, index[1]]:\n                        cv2.line(img, corners_img[aid, index[0]], corners_img[aid, index[1]], color=color_map[int(pred_flag[aid])], thickness=scale_factor)\n            imgs.append(img)\n        canvas = np.zeros((int(canva_size), int(canva_size), 3), dtype=np.uint8)\n        lidar_points = np.fromfile(infos['lidar_path'], dtype=np.float32)\n        lidar_points = lidar_points.reshape(-1, 5)[:, :3]\n        lidar_points[:, 1] = -lidar_points[:, 1]\n        lidar_points[:, :2] = (lidar_points[:, :2] + show_range) / show_range / 2.0 * canva_size\n        for p in lidar_points:\n            if check_point_in_img(p.reshape(1, 3), canvas.shape[1], canvas.shape[0])[0]:\n                color = depth2color(p[2])\n                cv2.circle(canvas, (int(p[0]), int(p[1])), radius=0, color=color, thickness=1)\n        corners_lidar = corners_lidar.reshape(-1, 8, 3)\n        corners_lidar[:, :, 1] = -corners_lidar[:, :, 1]\n        bottom_corners_bev = corners_lidar[:, [0, 3, 7, 4], :2]\n        bottom_corners_bev = (bottom_corners_bev + show_range) / show_range / 2.0 * canva_size\n        bottom_corners_bev = np.round(bottom_corners_bev).astype(np.int32)\n        center_bev = corners_lidar[:, [0, 3, 7, 4], :2].mean(axis=1)\n        head_bev = corners_lidar[:, [0, 4], :2].mean(axis=1)\n        canter_canvas = (center_bev + show_range) / show_range / 2.0 * canva_size\n        center_canvas = canter_canvas.astype(np.int32)\n        head_canvas = (head_bev + show_range) / show_range / 2.0 * canva_size\n        head_canvas = head_canvas.astype(np.int32)\n        for rid in sort_ids:\n            score = scores[rid]\n            if score < vis_thred and pred_flag[rid]:\n                continue\n            score = min(score * 2.0, 1.0) if pred_flag[rid] else 1.0\n            color = color_map[int(pred_flag[rid])]\n            for index in draw_boxes_indexes_bev:\n                cv2.line(canvas, bottom_corners_bev[rid, index[0]], bottom_corners_bev[rid, index[1]], [color[0] * score, color[1] * score, color[2] * score], thickness=1)\n            cv2.line(canvas, center_canvas[rid], head_canvas[rid], [color[0] * score, color[1] * score, color[2] * score], 1, lineType=8)\n        img = np.zeros((900 * 2 + canva_size * scale_factor, 1600 * 3, 3), dtype=np.uint8)\n        img[:900, :, :] = np.concatenate(imgs[:3], axis=1)\n        img_back = np.concatenate([imgs[3][:, ::-1, :], imgs[4][:, ::-1, :], imgs[5][:, ::-1, :]], axis=1)\n        img[900 + canva_size * scale_factor:, :, :] = img_back\n        img = cv2.resize(img, (int(1600 / scale_factor * 3), int(900 / scale_factor * 2 + canva_size)))\n        w_begin = int((1600 * 3 / scale_factor - canva_size) // 2)\n        img[int(900 / scale_factor):int(900 / scale_factor) + canva_size, w_begin:w_begin + canva_size, :] = canvas\n        if save_format == 'image':\n            img_list += [img]\n        elif save_format == 'video':\n            vout.write(img)\n    if save_format == 'video':\n        vout.release()\n    return img_list"
        ]
    }
]