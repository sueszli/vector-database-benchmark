[
    {
        "func_name": "run_forward",
        "original": "def run_forward(model, **batch):\n    \"\"\"The purpose of this function is to time the forward run of the model.\n    The model forward happens a 100 times and each pass is timed. The average\n    of this 100 runs is returned as avg_time.\n    \"\"\"\n    time_list = []\n    (X, lS_o, lS_i) = (batch['X'], batch['lS_o'], batch['lS_i'])\n    for _ in range(100):\n        start = time.time()\n        with torch.no_grad():\n            model(X, lS_o, lS_i)\n        end = time.time()\n        time_taken = end - start\n        time_list.append(time_taken)\n    avg_time = np.mean(time_list[1:])\n    return avg_time",
        "mutated": [
            "def run_forward(model, **batch):\n    if False:\n        i = 10\n    'The purpose of this function is to time the forward run of the model.\\n    The model forward happens a 100 times and each pass is timed. The average\\n    of this 100 runs is returned as avg_time.\\n    '\n    time_list = []\n    (X, lS_o, lS_i) = (batch['X'], batch['lS_o'], batch['lS_i'])\n    for _ in range(100):\n        start = time.time()\n        with torch.no_grad():\n            model(X, lS_o, lS_i)\n        end = time.time()\n        time_taken = end - start\n        time_list.append(time_taken)\n    avg_time = np.mean(time_list[1:])\n    return avg_time",
            "def run_forward(model, **batch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'The purpose of this function is to time the forward run of the model.\\n    The model forward happens a 100 times and each pass is timed. The average\\n    of this 100 runs is returned as avg_time.\\n    '\n    time_list = []\n    (X, lS_o, lS_i) = (batch['X'], batch['lS_o'], batch['lS_i'])\n    for _ in range(100):\n        start = time.time()\n        with torch.no_grad():\n            model(X, lS_o, lS_i)\n        end = time.time()\n        time_taken = end - start\n        time_list.append(time_taken)\n    avg_time = np.mean(time_list[1:])\n    return avg_time",
            "def run_forward(model, **batch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'The purpose of this function is to time the forward run of the model.\\n    The model forward happens a 100 times and each pass is timed. The average\\n    of this 100 runs is returned as avg_time.\\n    '\n    time_list = []\n    (X, lS_o, lS_i) = (batch['X'], batch['lS_o'], batch['lS_i'])\n    for _ in range(100):\n        start = time.time()\n        with torch.no_grad():\n            model(X, lS_o, lS_i)\n        end = time.time()\n        time_taken = end - start\n        time_list.append(time_taken)\n    avg_time = np.mean(time_list[1:])\n    return avg_time",
            "def run_forward(model, **batch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'The purpose of this function is to time the forward run of the model.\\n    The model forward happens a 100 times and each pass is timed. The average\\n    of this 100 runs is returned as avg_time.\\n    '\n    time_list = []\n    (X, lS_o, lS_i) = (batch['X'], batch['lS_o'], batch['lS_i'])\n    for _ in range(100):\n        start = time.time()\n        with torch.no_grad():\n            model(X, lS_o, lS_i)\n        end = time.time()\n        time_taken = end - start\n        time_list.append(time_taken)\n    avg_time = np.mean(time_list[1:])\n    return avg_time",
            "def run_forward(model, **batch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'The purpose of this function is to time the forward run of the model.\\n    The model forward happens a 100 times and each pass is timed. The average\\n    of this 100 runs is returned as avg_time.\\n    '\n    time_list = []\n    (X, lS_o, lS_i) = (batch['X'], batch['lS_o'], batch['lS_i'])\n    for _ in range(100):\n        start = time.time()\n        with torch.no_grad():\n            model(X, lS_o, lS_i)\n        end = time.time()\n        time_taken = end - start\n        time_list.append(time_taken)\n    avg_time = np.mean(time_list[1:])\n    return avg_time"
        ]
    },
    {
        "func_name": "make_sample_test_batch",
        "original": "def make_sample_test_batch(raw_data_path, processed_data_path, device):\n    \"\"\"Create the test_data_loader and sample a batch from it. This batch will be used\n    to measure the forward pass of the model throughout this experiment.\n    \"\"\"\n    test_data_loader = make_test_data_loader(raw_data_path, processed_data_path)\n    test_iter = iter(test_data_loader)\n    test_batch = next(test_iter)\n    (X_test, lS_o_test, lS_i_test, _, _, _) = unpack_batch(test_batch)\n    (X, lS_o, lS_i) = dlrm_wrap(X_test, lS_o_test, lS_i_test, device)\n    batch = {'X': X, 'lS_o': lS_o, 'lS_i': lS_i}\n    return batch",
        "mutated": [
            "def make_sample_test_batch(raw_data_path, processed_data_path, device):\n    if False:\n        i = 10\n    'Create the test_data_loader and sample a batch from it. This batch will be used\\n    to measure the forward pass of the model throughout this experiment.\\n    '\n    test_data_loader = make_test_data_loader(raw_data_path, processed_data_path)\n    test_iter = iter(test_data_loader)\n    test_batch = next(test_iter)\n    (X_test, lS_o_test, lS_i_test, _, _, _) = unpack_batch(test_batch)\n    (X, lS_o, lS_i) = dlrm_wrap(X_test, lS_o_test, lS_i_test, device)\n    batch = {'X': X, 'lS_o': lS_o, 'lS_i': lS_i}\n    return batch",
            "def make_sample_test_batch(raw_data_path, processed_data_path, device):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Create the test_data_loader and sample a batch from it. This batch will be used\\n    to measure the forward pass of the model throughout this experiment.\\n    '\n    test_data_loader = make_test_data_loader(raw_data_path, processed_data_path)\n    test_iter = iter(test_data_loader)\n    test_batch = next(test_iter)\n    (X_test, lS_o_test, lS_i_test, _, _, _) = unpack_batch(test_batch)\n    (X, lS_o, lS_i) = dlrm_wrap(X_test, lS_o_test, lS_i_test, device)\n    batch = {'X': X, 'lS_o': lS_o, 'lS_i': lS_i}\n    return batch",
            "def make_sample_test_batch(raw_data_path, processed_data_path, device):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Create the test_data_loader and sample a batch from it. This batch will be used\\n    to measure the forward pass of the model throughout this experiment.\\n    '\n    test_data_loader = make_test_data_loader(raw_data_path, processed_data_path)\n    test_iter = iter(test_data_loader)\n    test_batch = next(test_iter)\n    (X_test, lS_o_test, lS_i_test, _, _, _) = unpack_batch(test_batch)\n    (X, lS_o, lS_i) = dlrm_wrap(X_test, lS_o_test, lS_i_test, device)\n    batch = {'X': X, 'lS_o': lS_o, 'lS_i': lS_i}\n    return batch",
            "def make_sample_test_batch(raw_data_path, processed_data_path, device):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Create the test_data_loader and sample a batch from it. This batch will be used\\n    to measure the forward pass of the model throughout this experiment.\\n    '\n    test_data_loader = make_test_data_loader(raw_data_path, processed_data_path)\n    test_iter = iter(test_data_loader)\n    test_batch = next(test_iter)\n    (X_test, lS_o_test, lS_i_test, _, _, _) = unpack_batch(test_batch)\n    (X, lS_o, lS_i) = dlrm_wrap(X_test, lS_o_test, lS_i_test, device)\n    batch = {'X': X, 'lS_o': lS_o, 'lS_i': lS_i}\n    return batch",
            "def make_sample_test_batch(raw_data_path, processed_data_path, device):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Create the test_data_loader and sample a batch from it. This batch will be used\\n    to measure the forward pass of the model throughout this experiment.\\n    '\n    test_data_loader = make_test_data_loader(raw_data_path, processed_data_path)\n    test_iter = iter(test_data_loader)\n    test_batch = next(test_iter)\n    (X_test, lS_o_test, lS_i_test, _, _, _) = unpack_batch(test_batch)\n    (X, lS_o, lS_i) = dlrm_wrap(X_test, lS_o_test, lS_i_test, device)\n    batch = {'X': X, 'lS_o': lS_o, 'lS_i': lS_i}\n    return batch"
        ]
    },
    {
        "func_name": "measure_forward_pass",
        "original": "def measure_forward_pass(sparse_model_metadata, device, sparse_dlrm, **batch):\n    \"\"\"Measures and tracks the forward pass of the model for all the sparsity levels, block shapes and norms\n    available in sparse_model_metadata file.\n    If sparse_dlrm=True, then the SparseDLRM model is loaded, otherwise the standard one is.\n    \"\"\"\n    time_taken_dict: Dict[str, List] = {'norm': [], 'sparse_block_shape': [], 'sparsity_level': [], 'time_taken': []}\n    metadata = pd.read_csv(sparse_model_metadata)\n    for (_, row) in metadata.iterrows():\n        (norm, sbs, sl) = (row['norm'], row['sparse_block_shape'], row['sparsity_level'])\n        model_path = row['path']\n        model = fetch_model(model_path, device, sparse_dlrm=sparse_dlrm)\n        time_taken = run_forward(model, **batch)\n        out_str = f'{norm}_{sbs}_{sl}={time_taken}'\n        print(out_str)\n        time_taken_dict['norm'].append(norm)\n        time_taken_dict['sparse_block_shape'].append(sbs)\n        time_taken_dict['sparsity_level'].append(sl)\n        time_taken_dict['time_taken'].append(time_taken)\n    time_df = pd.DataFrame(time_taken_dict)\n    if sparse_dlrm:\n        time_df['dlrm_type'] = 'with_torch_sparse'\n    else:\n        time_df['dlrm_type'] = 'without_torch_sparse'\n    return time_df",
        "mutated": [
            "def measure_forward_pass(sparse_model_metadata, device, sparse_dlrm, **batch):\n    if False:\n        i = 10\n    'Measures and tracks the forward pass of the model for all the sparsity levels, block shapes and norms\\n    available in sparse_model_metadata file.\\n    If sparse_dlrm=True, then the SparseDLRM model is loaded, otherwise the standard one is.\\n    '\n    time_taken_dict: Dict[str, List] = {'norm': [], 'sparse_block_shape': [], 'sparsity_level': [], 'time_taken': []}\n    metadata = pd.read_csv(sparse_model_metadata)\n    for (_, row) in metadata.iterrows():\n        (norm, sbs, sl) = (row['norm'], row['sparse_block_shape'], row['sparsity_level'])\n        model_path = row['path']\n        model = fetch_model(model_path, device, sparse_dlrm=sparse_dlrm)\n        time_taken = run_forward(model, **batch)\n        out_str = f'{norm}_{sbs}_{sl}={time_taken}'\n        print(out_str)\n        time_taken_dict['norm'].append(norm)\n        time_taken_dict['sparse_block_shape'].append(sbs)\n        time_taken_dict['sparsity_level'].append(sl)\n        time_taken_dict['time_taken'].append(time_taken)\n    time_df = pd.DataFrame(time_taken_dict)\n    if sparse_dlrm:\n        time_df['dlrm_type'] = 'with_torch_sparse'\n    else:\n        time_df['dlrm_type'] = 'without_torch_sparse'\n    return time_df",
            "def measure_forward_pass(sparse_model_metadata, device, sparse_dlrm, **batch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Measures and tracks the forward pass of the model for all the sparsity levels, block shapes and norms\\n    available in sparse_model_metadata file.\\n    If sparse_dlrm=True, then the SparseDLRM model is loaded, otherwise the standard one is.\\n    '\n    time_taken_dict: Dict[str, List] = {'norm': [], 'sparse_block_shape': [], 'sparsity_level': [], 'time_taken': []}\n    metadata = pd.read_csv(sparse_model_metadata)\n    for (_, row) in metadata.iterrows():\n        (norm, sbs, sl) = (row['norm'], row['sparse_block_shape'], row['sparsity_level'])\n        model_path = row['path']\n        model = fetch_model(model_path, device, sparse_dlrm=sparse_dlrm)\n        time_taken = run_forward(model, **batch)\n        out_str = f'{norm}_{sbs}_{sl}={time_taken}'\n        print(out_str)\n        time_taken_dict['norm'].append(norm)\n        time_taken_dict['sparse_block_shape'].append(sbs)\n        time_taken_dict['sparsity_level'].append(sl)\n        time_taken_dict['time_taken'].append(time_taken)\n    time_df = pd.DataFrame(time_taken_dict)\n    if sparse_dlrm:\n        time_df['dlrm_type'] = 'with_torch_sparse'\n    else:\n        time_df['dlrm_type'] = 'without_torch_sparse'\n    return time_df",
            "def measure_forward_pass(sparse_model_metadata, device, sparse_dlrm, **batch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Measures and tracks the forward pass of the model for all the sparsity levels, block shapes and norms\\n    available in sparse_model_metadata file.\\n    If sparse_dlrm=True, then the SparseDLRM model is loaded, otherwise the standard one is.\\n    '\n    time_taken_dict: Dict[str, List] = {'norm': [], 'sparse_block_shape': [], 'sparsity_level': [], 'time_taken': []}\n    metadata = pd.read_csv(sparse_model_metadata)\n    for (_, row) in metadata.iterrows():\n        (norm, sbs, sl) = (row['norm'], row['sparse_block_shape'], row['sparsity_level'])\n        model_path = row['path']\n        model = fetch_model(model_path, device, sparse_dlrm=sparse_dlrm)\n        time_taken = run_forward(model, **batch)\n        out_str = f'{norm}_{sbs}_{sl}={time_taken}'\n        print(out_str)\n        time_taken_dict['norm'].append(norm)\n        time_taken_dict['sparse_block_shape'].append(sbs)\n        time_taken_dict['sparsity_level'].append(sl)\n        time_taken_dict['time_taken'].append(time_taken)\n    time_df = pd.DataFrame(time_taken_dict)\n    if sparse_dlrm:\n        time_df['dlrm_type'] = 'with_torch_sparse'\n    else:\n        time_df['dlrm_type'] = 'without_torch_sparse'\n    return time_df",
            "def measure_forward_pass(sparse_model_metadata, device, sparse_dlrm, **batch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Measures and tracks the forward pass of the model for all the sparsity levels, block shapes and norms\\n    available in sparse_model_metadata file.\\n    If sparse_dlrm=True, then the SparseDLRM model is loaded, otherwise the standard one is.\\n    '\n    time_taken_dict: Dict[str, List] = {'norm': [], 'sparse_block_shape': [], 'sparsity_level': [], 'time_taken': []}\n    metadata = pd.read_csv(sparse_model_metadata)\n    for (_, row) in metadata.iterrows():\n        (norm, sbs, sl) = (row['norm'], row['sparse_block_shape'], row['sparsity_level'])\n        model_path = row['path']\n        model = fetch_model(model_path, device, sparse_dlrm=sparse_dlrm)\n        time_taken = run_forward(model, **batch)\n        out_str = f'{norm}_{sbs}_{sl}={time_taken}'\n        print(out_str)\n        time_taken_dict['norm'].append(norm)\n        time_taken_dict['sparse_block_shape'].append(sbs)\n        time_taken_dict['sparsity_level'].append(sl)\n        time_taken_dict['time_taken'].append(time_taken)\n    time_df = pd.DataFrame(time_taken_dict)\n    if sparse_dlrm:\n        time_df['dlrm_type'] = 'with_torch_sparse'\n    else:\n        time_df['dlrm_type'] = 'without_torch_sparse'\n    return time_df",
            "def measure_forward_pass(sparse_model_metadata, device, sparse_dlrm, **batch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Measures and tracks the forward pass of the model for all the sparsity levels, block shapes and norms\\n    available in sparse_model_metadata file.\\n    If sparse_dlrm=True, then the SparseDLRM model is loaded, otherwise the standard one is.\\n    '\n    time_taken_dict: Dict[str, List] = {'norm': [], 'sparse_block_shape': [], 'sparsity_level': [], 'time_taken': []}\n    metadata = pd.read_csv(sparse_model_metadata)\n    for (_, row) in metadata.iterrows():\n        (norm, sbs, sl) = (row['norm'], row['sparse_block_shape'], row['sparsity_level'])\n        model_path = row['path']\n        model = fetch_model(model_path, device, sparse_dlrm=sparse_dlrm)\n        time_taken = run_forward(model, **batch)\n        out_str = f'{norm}_{sbs}_{sl}={time_taken}'\n        print(out_str)\n        time_taken_dict['norm'].append(norm)\n        time_taken_dict['sparse_block_shape'].append(sbs)\n        time_taken_dict['sparsity_level'].append(sl)\n        time_taken_dict['time_taken'].append(time_taken)\n    time_df = pd.DataFrame(time_taken_dict)\n    if sparse_dlrm:\n        time_df['dlrm_type'] = 'with_torch_sparse'\n    else:\n        time_df['dlrm_type'] = 'without_torch_sparse'\n    return time_df"
        ]
    }
]