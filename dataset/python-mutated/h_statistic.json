[
    {
        "func_name": "_h",
        "original": "def _h(self, frame, variables):\n    \"\"\"\n        Calculates Friedman and Popescu's H statistics, in order to test for the presence of an interaction between specified variables in h2o gbm and xgb models.\n        H varies from 0 to 1. It will have a value of 0 if the model exhibits no interaction between specified variables and a correspondingly larger value for a \n        stronger interaction effect between them. NaN is returned if a computation is spoiled by weak main effects and rounding errors.\n        \n        This statistic can be calculated only for numerical variables. Missing values are supported.\n        \n        See Jerome H. Friedman and Bogdan E. Popescu, 2008, \"Predictive learning via rule ensembles\", *Ann. Appl. Stat.*\n        **2**:916-954, http://projecteuclid.org/download/pdfview_1/euclid.aoas/1223908046, s. 8.1.\n\n        \n        :param frame: the frame that current model has been fitted to\n        :param variables: variables of the interest\n        :return: H statistic of the variables \n        \n        :examples:\n        >>> prostate_train = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/logreg/prostate_train.csv\")\n        >>> prostate_train[\"CAPSULE\"] = prostate_train[\"CAPSULE\"].asfactor()\n        >>> gbm_h2o = H2OGradientBoostingEstimator(ntrees=100, learn_rate=0.1,\n        >>>                                 max_depth=5,\n        >>>                                 min_rows=10,\n        >>>                                 distribution=\"bernoulli\")\n        >>> gbm_h2o.train(x=list(range(1,prostate_train.ncol)),y=\"CAPSULE\", training_frame=prostate_train)\n        >>> h = gbm_h2o.h(prostate_train, ['DPROS','DCAPS'])\n        \"\"\"\n    kwargs = dict(model_id=self.model_id, frame=frame.key, variables=variables)\n    json = h2o.api('POST /3/FriedmansPopescusH', data=kwargs)\n    return json['h']",
        "mutated": [
            "def _h(self, frame, variables):\n    if False:\n        i = 10\n    '\\n        Calculates Friedman and Popescu\\'s H statistics, in order to test for the presence of an interaction between specified variables in h2o gbm and xgb models.\\n        H varies from 0 to 1. It will have a value of 0 if the model exhibits no interaction between specified variables and a correspondingly larger value for a \\n        stronger interaction effect between them. NaN is returned if a computation is spoiled by weak main effects and rounding errors.\\n        \\n        This statistic can be calculated only for numerical variables. Missing values are supported.\\n        \\n        See Jerome H. Friedman and Bogdan E. Popescu, 2008, \"Predictive learning via rule ensembles\", *Ann. Appl. Stat.*\\n        **2**:916-954, http://projecteuclid.org/download/pdfview_1/euclid.aoas/1223908046, s. 8.1.\\n\\n        \\n        :param frame: the frame that current model has been fitted to\\n        :param variables: variables of the interest\\n        :return: H statistic of the variables \\n        \\n        :examples:\\n        >>> prostate_train = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/logreg/prostate_train.csv\")\\n        >>> prostate_train[\"CAPSULE\"] = prostate_train[\"CAPSULE\"].asfactor()\\n        >>> gbm_h2o = H2OGradientBoostingEstimator(ntrees=100, learn_rate=0.1,\\n        >>>                                 max_depth=5,\\n        >>>                                 min_rows=10,\\n        >>>                                 distribution=\"bernoulli\")\\n        >>> gbm_h2o.train(x=list(range(1,prostate_train.ncol)),y=\"CAPSULE\", training_frame=prostate_train)\\n        >>> h = gbm_h2o.h(prostate_train, [\\'DPROS\\',\\'DCAPS\\'])\\n        '\n    kwargs = dict(model_id=self.model_id, frame=frame.key, variables=variables)\n    json = h2o.api('POST /3/FriedmansPopescusH', data=kwargs)\n    return json['h']",
            "def _h(self, frame, variables):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Calculates Friedman and Popescu\\'s H statistics, in order to test for the presence of an interaction between specified variables in h2o gbm and xgb models.\\n        H varies from 0 to 1. It will have a value of 0 if the model exhibits no interaction between specified variables and a correspondingly larger value for a \\n        stronger interaction effect between them. NaN is returned if a computation is spoiled by weak main effects and rounding errors.\\n        \\n        This statistic can be calculated only for numerical variables. Missing values are supported.\\n        \\n        See Jerome H. Friedman and Bogdan E. Popescu, 2008, \"Predictive learning via rule ensembles\", *Ann. Appl. Stat.*\\n        **2**:916-954, http://projecteuclid.org/download/pdfview_1/euclid.aoas/1223908046, s. 8.1.\\n\\n        \\n        :param frame: the frame that current model has been fitted to\\n        :param variables: variables of the interest\\n        :return: H statistic of the variables \\n        \\n        :examples:\\n        >>> prostate_train = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/logreg/prostate_train.csv\")\\n        >>> prostate_train[\"CAPSULE\"] = prostate_train[\"CAPSULE\"].asfactor()\\n        >>> gbm_h2o = H2OGradientBoostingEstimator(ntrees=100, learn_rate=0.1,\\n        >>>                                 max_depth=5,\\n        >>>                                 min_rows=10,\\n        >>>                                 distribution=\"bernoulli\")\\n        >>> gbm_h2o.train(x=list(range(1,prostate_train.ncol)),y=\"CAPSULE\", training_frame=prostate_train)\\n        >>> h = gbm_h2o.h(prostate_train, [\\'DPROS\\',\\'DCAPS\\'])\\n        '\n    kwargs = dict(model_id=self.model_id, frame=frame.key, variables=variables)\n    json = h2o.api('POST /3/FriedmansPopescusH', data=kwargs)\n    return json['h']",
            "def _h(self, frame, variables):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Calculates Friedman and Popescu\\'s H statistics, in order to test for the presence of an interaction between specified variables in h2o gbm and xgb models.\\n        H varies from 0 to 1. It will have a value of 0 if the model exhibits no interaction between specified variables and a correspondingly larger value for a \\n        stronger interaction effect between them. NaN is returned if a computation is spoiled by weak main effects and rounding errors.\\n        \\n        This statistic can be calculated only for numerical variables. Missing values are supported.\\n        \\n        See Jerome H. Friedman and Bogdan E. Popescu, 2008, \"Predictive learning via rule ensembles\", *Ann. Appl. Stat.*\\n        **2**:916-954, http://projecteuclid.org/download/pdfview_1/euclid.aoas/1223908046, s. 8.1.\\n\\n        \\n        :param frame: the frame that current model has been fitted to\\n        :param variables: variables of the interest\\n        :return: H statistic of the variables \\n        \\n        :examples:\\n        >>> prostate_train = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/logreg/prostate_train.csv\")\\n        >>> prostate_train[\"CAPSULE\"] = prostate_train[\"CAPSULE\"].asfactor()\\n        >>> gbm_h2o = H2OGradientBoostingEstimator(ntrees=100, learn_rate=0.1,\\n        >>>                                 max_depth=5,\\n        >>>                                 min_rows=10,\\n        >>>                                 distribution=\"bernoulli\")\\n        >>> gbm_h2o.train(x=list(range(1,prostate_train.ncol)),y=\"CAPSULE\", training_frame=prostate_train)\\n        >>> h = gbm_h2o.h(prostate_train, [\\'DPROS\\',\\'DCAPS\\'])\\n        '\n    kwargs = dict(model_id=self.model_id, frame=frame.key, variables=variables)\n    json = h2o.api('POST /3/FriedmansPopescusH', data=kwargs)\n    return json['h']",
            "def _h(self, frame, variables):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Calculates Friedman and Popescu\\'s H statistics, in order to test for the presence of an interaction between specified variables in h2o gbm and xgb models.\\n        H varies from 0 to 1. It will have a value of 0 if the model exhibits no interaction between specified variables and a correspondingly larger value for a \\n        stronger interaction effect between them. NaN is returned if a computation is spoiled by weak main effects and rounding errors.\\n        \\n        This statistic can be calculated only for numerical variables. Missing values are supported.\\n        \\n        See Jerome H. Friedman and Bogdan E. Popescu, 2008, \"Predictive learning via rule ensembles\", *Ann. Appl. Stat.*\\n        **2**:916-954, http://projecteuclid.org/download/pdfview_1/euclid.aoas/1223908046, s. 8.1.\\n\\n        \\n        :param frame: the frame that current model has been fitted to\\n        :param variables: variables of the interest\\n        :return: H statistic of the variables \\n        \\n        :examples:\\n        >>> prostate_train = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/logreg/prostate_train.csv\")\\n        >>> prostate_train[\"CAPSULE\"] = prostate_train[\"CAPSULE\"].asfactor()\\n        >>> gbm_h2o = H2OGradientBoostingEstimator(ntrees=100, learn_rate=0.1,\\n        >>>                                 max_depth=5,\\n        >>>                                 min_rows=10,\\n        >>>                                 distribution=\"bernoulli\")\\n        >>> gbm_h2o.train(x=list(range(1,prostate_train.ncol)),y=\"CAPSULE\", training_frame=prostate_train)\\n        >>> h = gbm_h2o.h(prostate_train, [\\'DPROS\\',\\'DCAPS\\'])\\n        '\n    kwargs = dict(model_id=self.model_id, frame=frame.key, variables=variables)\n    json = h2o.api('POST /3/FriedmansPopescusH', data=kwargs)\n    return json['h']",
            "def _h(self, frame, variables):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Calculates Friedman and Popescu\\'s H statistics, in order to test for the presence of an interaction between specified variables in h2o gbm and xgb models.\\n        H varies from 0 to 1. It will have a value of 0 if the model exhibits no interaction between specified variables and a correspondingly larger value for a \\n        stronger interaction effect between them. NaN is returned if a computation is spoiled by weak main effects and rounding errors.\\n        \\n        This statistic can be calculated only for numerical variables. Missing values are supported.\\n        \\n        See Jerome H. Friedman and Bogdan E. Popescu, 2008, \"Predictive learning via rule ensembles\", *Ann. Appl. Stat.*\\n        **2**:916-954, http://projecteuclid.org/download/pdfview_1/euclid.aoas/1223908046, s. 8.1.\\n\\n        \\n        :param frame: the frame that current model has been fitted to\\n        :param variables: variables of the interest\\n        :return: H statistic of the variables \\n        \\n        :examples:\\n        >>> prostate_train = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/logreg/prostate_train.csv\")\\n        >>> prostate_train[\"CAPSULE\"] = prostate_train[\"CAPSULE\"].asfactor()\\n        >>> gbm_h2o = H2OGradientBoostingEstimator(ntrees=100, learn_rate=0.1,\\n        >>>                                 max_depth=5,\\n        >>>                                 min_rows=10,\\n        >>>                                 distribution=\"bernoulli\")\\n        >>> gbm_h2o.train(x=list(range(1,prostate_train.ncol)),y=\"CAPSULE\", training_frame=prostate_train)\\n        >>> h = gbm_h2o.h(prostate_train, [\\'DPROS\\',\\'DCAPS\\'])\\n        '\n    kwargs = dict(model_id=self.model_id, frame=frame.key, variables=variables)\n    json = h2o.api('POST /3/FriedmansPopescusH', data=kwargs)\n    return json['h']"
        ]
    }
]