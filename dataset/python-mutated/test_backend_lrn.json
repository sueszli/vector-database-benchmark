[
    {
        "func_name": "slicable",
        "original": "def slicable(dim, pad=0):\n    dim0 = np.prod(dim[:-1]) + pad\n    return (dim0, dim[-1])",
        "mutated": [
            "def slicable(dim, pad=0):\n    if False:\n        i = 10\n    dim0 = np.prod(dim[:-1]) + pad\n    return (dim0, dim[-1])",
            "def slicable(dim, pad=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    dim0 = np.prod(dim[:-1]) + pad\n    return (dim0, dim[-1])",
            "def slicable(dim, pad=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    dim0 = np.prod(dim[:-1]) + pad\n    return (dim0, dim[-1])",
            "def slicable(dim, pad=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    dim0 = np.prod(dim[:-1]) + pad\n    return (dim0, dim[-1])",
            "def slicable(dim, pad=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    dim0 = np.prod(dim[:-1]) + pad\n    return (dim0, dim[-1])"
        ]
    },
    {
        "func_name": "test_pooling_mkl",
        "original": "def test_pooling_mkl(backend_pair_bench_mkl):\n    (nm, nc) = backend_pair_bench_mkl\n    layer_args = dict(dtype=np.float32, N=122, C=16, D=1, H=32, W=32, J=5)\n    pool_test_args = dict(ones=0, cpu=1, nm=nm, nc=nc, alpha=1.0, ascale=1.2, beta=0.0, bpower=0.5, layer_m=nm.lrn_layer(**layer_args), layer_c=nc.lrn_layer(**layer_args), **layer_args)\n    lrn_helper_mkl(**pool_test_args)",
        "mutated": [
            "def test_pooling_mkl(backend_pair_bench_mkl):\n    if False:\n        i = 10\n    (nm, nc) = backend_pair_bench_mkl\n    layer_args = dict(dtype=np.float32, N=122, C=16, D=1, H=32, W=32, J=5)\n    pool_test_args = dict(ones=0, cpu=1, nm=nm, nc=nc, alpha=1.0, ascale=1.2, beta=0.0, bpower=0.5, layer_m=nm.lrn_layer(**layer_args), layer_c=nc.lrn_layer(**layer_args), **layer_args)\n    lrn_helper_mkl(**pool_test_args)",
            "def test_pooling_mkl(backend_pair_bench_mkl):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (nm, nc) = backend_pair_bench_mkl\n    layer_args = dict(dtype=np.float32, N=122, C=16, D=1, H=32, W=32, J=5)\n    pool_test_args = dict(ones=0, cpu=1, nm=nm, nc=nc, alpha=1.0, ascale=1.2, beta=0.0, bpower=0.5, layer_m=nm.lrn_layer(**layer_args), layer_c=nc.lrn_layer(**layer_args), **layer_args)\n    lrn_helper_mkl(**pool_test_args)",
            "def test_pooling_mkl(backend_pair_bench_mkl):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (nm, nc) = backend_pair_bench_mkl\n    layer_args = dict(dtype=np.float32, N=122, C=16, D=1, H=32, W=32, J=5)\n    pool_test_args = dict(ones=0, cpu=1, nm=nm, nc=nc, alpha=1.0, ascale=1.2, beta=0.0, bpower=0.5, layer_m=nm.lrn_layer(**layer_args), layer_c=nc.lrn_layer(**layer_args), **layer_args)\n    lrn_helper_mkl(**pool_test_args)",
            "def test_pooling_mkl(backend_pair_bench_mkl):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (nm, nc) = backend_pair_bench_mkl\n    layer_args = dict(dtype=np.float32, N=122, C=16, D=1, H=32, W=32, J=5)\n    pool_test_args = dict(ones=0, cpu=1, nm=nm, nc=nc, alpha=1.0, ascale=1.2, beta=0.0, bpower=0.5, layer_m=nm.lrn_layer(**layer_args), layer_c=nc.lrn_layer(**layer_args), **layer_args)\n    lrn_helper_mkl(**pool_test_args)",
            "def test_pooling_mkl(backend_pair_bench_mkl):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (nm, nc) = backend_pair_bench_mkl\n    layer_args = dict(dtype=np.float32, N=122, C=16, D=1, H=32, W=32, J=5)\n    pool_test_args = dict(ones=0, cpu=1, nm=nm, nc=nc, alpha=1.0, ascale=1.2, beta=0.0, bpower=0.5, layer_m=nm.lrn_layer(**layer_args), layer_c=nc.lrn_layer(**layer_args), **layer_args)\n    lrn_helper_mkl(**pool_test_args)"
        ]
    },
    {
        "func_name": "lrn_helper_mkl",
        "original": "def lrn_helper_mkl(dtype, ones, cpu, alpha, beta, ascale, bpower, nm, nc, layer_m, layer_c, N, C, D, H, W, J):\n    dimI = layer_m.dimI\n    dimO = layer_m.dimO\n    if ones:\n        cpuI = np.ones(slicable(dimI), dtype=np.float32)\n        cpuB = np.ones(slicable(dimI), dtype=np.float32)\n        cpuE = np.ones(dimO, dtype=np.float32)\n        cpuO = np.ones(dimO, dtype=np.float32)\n    else:\n        cpuI = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuB = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuE = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n        cpuO = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n    devI = nm.array(cpuI.reshape(dimI), dtype=dtype)\n    devB = nm.array(cpuB.reshape(dimI), dtype=dtype)\n    devE = nm.array(cpuE, dtype=dtype)\n    devO = nm.array(cpuO, dtype=dtype)\n    devD = nm.empty(dimO, dtype=dtype)\n    cccI = nc.array(cpuI.reshape(dimI), dtype=dtype)\n    cccB = nc.array(cpuB.reshape(dimI), dtype=dtype)\n    cccE = nc.array(cpuE, dtype=dtype)\n    cccO = nc.array(cpuO, dtype=dtype)\n    cccD = nc.empty(dimO, dtype=dtype)\n    nm.fprop_lrn(layer_m, devI, devO, devD, alpha, beta, ascale, bpower)\n    nc.fprop_lrn(layer_c, cccI, cccO, cccD, None, None, ascale, bpower)\n    neon_logger.display('== denom ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL fprop')\n    neon_logger.display(devD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('== output ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL fprop')\n    neon_logger.display(devO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    nm.bprop_lrn(layer_m, devI, devO, devE, devB, devD, alpha, beta, ascale, bpower)\n    nc.bprop_lrn(layer_c, cccI, cccO, cccE, cccB, cccD, None, None, ascale, bpower)\n    neon_logger.display('== bprop ==')\n    neon_logger.display('CPU bprop')\n    neon_logger.display(cccB.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL bprop')\n    neon_logger.display(devB.get().reshape(C * D * H * W, N)[0:4, 0:4])",
        "mutated": [
            "def lrn_helper_mkl(dtype, ones, cpu, alpha, beta, ascale, bpower, nm, nc, layer_m, layer_c, N, C, D, H, W, J):\n    if False:\n        i = 10\n    dimI = layer_m.dimI\n    dimO = layer_m.dimO\n    if ones:\n        cpuI = np.ones(slicable(dimI), dtype=np.float32)\n        cpuB = np.ones(slicable(dimI), dtype=np.float32)\n        cpuE = np.ones(dimO, dtype=np.float32)\n        cpuO = np.ones(dimO, dtype=np.float32)\n    else:\n        cpuI = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuB = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuE = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n        cpuO = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n    devI = nm.array(cpuI.reshape(dimI), dtype=dtype)\n    devB = nm.array(cpuB.reshape(dimI), dtype=dtype)\n    devE = nm.array(cpuE, dtype=dtype)\n    devO = nm.array(cpuO, dtype=dtype)\n    devD = nm.empty(dimO, dtype=dtype)\n    cccI = nc.array(cpuI.reshape(dimI), dtype=dtype)\n    cccB = nc.array(cpuB.reshape(dimI), dtype=dtype)\n    cccE = nc.array(cpuE, dtype=dtype)\n    cccO = nc.array(cpuO, dtype=dtype)\n    cccD = nc.empty(dimO, dtype=dtype)\n    nm.fprop_lrn(layer_m, devI, devO, devD, alpha, beta, ascale, bpower)\n    nc.fprop_lrn(layer_c, cccI, cccO, cccD, None, None, ascale, bpower)\n    neon_logger.display('== denom ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL fprop')\n    neon_logger.display(devD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('== output ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL fprop')\n    neon_logger.display(devO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    nm.bprop_lrn(layer_m, devI, devO, devE, devB, devD, alpha, beta, ascale, bpower)\n    nc.bprop_lrn(layer_c, cccI, cccO, cccE, cccB, cccD, None, None, ascale, bpower)\n    neon_logger.display('== bprop ==')\n    neon_logger.display('CPU bprop')\n    neon_logger.display(cccB.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL bprop')\n    neon_logger.display(devB.get().reshape(C * D * H * W, N)[0:4, 0:4])",
            "def lrn_helper_mkl(dtype, ones, cpu, alpha, beta, ascale, bpower, nm, nc, layer_m, layer_c, N, C, D, H, W, J):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    dimI = layer_m.dimI\n    dimO = layer_m.dimO\n    if ones:\n        cpuI = np.ones(slicable(dimI), dtype=np.float32)\n        cpuB = np.ones(slicable(dimI), dtype=np.float32)\n        cpuE = np.ones(dimO, dtype=np.float32)\n        cpuO = np.ones(dimO, dtype=np.float32)\n    else:\n        cpuI = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuB = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuE = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n        cpuO = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n    devI = nm.array(cpuI.reshape(dimI), dtype=dtype)\n    devB = nm.array(cpuB.reshape(dimI), dtype=dtype)\n    devE = nm.array(cpuE, dtype=dtype)\n    devO = nm.array(cpuO, dtype=dtype)\n    devD = nm.empty(dimO, dtype=dtype)\n    cccI = nc.array(cpuI.reshape(dimI), dtype=dtype)\n    cccB = nc.array(cpuB.reshape(dimI), dtype=dtype)\n    cccE = nc.array(cpuE, dtype=dtype)\n    cccO = nc.array(cpuO, dtype=dtype)\n    cccD = nc.empty(dimO, dtype=dtype)\n    nm.fprop_lrn(layer_m, devI, devO, devD, alpha, beta, ascale, bpower)\n    nc.fprop_lrn(layer_c, cccI, cccO, cccD, None, None, ascale, bpower)\n    neon_logger.display('== denom ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL fprop')\n    neon_logger.display(devD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('== output ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL fprop')\n    neon_logger.display(devO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    nm.bprop_lrn(layer_m, devI, devO, devE, devB, devD, alpha, beta, ascale, bpower)\n    nc.bprop_lrn(layer_c, cccI, cccO, cccE, cccB, cccD, None, None, ascale, bpower)\n    neon_logger.display('== bprop ==')\n    neon_logger.display('CPU bprop')\n    neon_logger.display(cccB.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL bprop')\n    neon_logger.display(devB.get().reshape(C * D * H * W, N)[0:4, 0:4])",
            "def lrn_helper_mkl(dtype, ones, cpu, alpha, beta, ascale, bpower, nm, nc, layer_m, layer_c, N, C, D, H, W, J):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    dimI = layer_m.dimI\n    dimO = layer_m.dimO\n    if ones:\n        cpuI = np.ones(slicable(dimI), dtype=np.float32)\n        cpuB = np.ones(slicable(dimI), dtype=np.float32)\n        cpuE = np.ones(dimO, dtype=np.float32)\n        cpuO = np.ones(dimO, dtype=np.float32)\n    else:\n        cpuI = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuB = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuE = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n        cpuO = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n    devI = nm.array(cpuI.reshape(dimI), dtype=dtype)\n    devB = nm.array(cpuB.reshape(dimI), dtype=dtype)\n    devE = nm.array(cpuE, dtype=dtype)\n    devO = nm.array(cpuO, dtype=dtype)\n    devD = nm.empty(dimO, dtype=dtype)\n    cccI = nc.array(cpuI.reshape(dimI), dtype=dtype)\n    cccB = nc.array(cpuB.reshape(dimI), dtype=dtype)\n    cccE = nc.array(cpuE, dtype=dtype)\n    cccO = nc.array(cpuO, dtype=dtype)\n    cccD = nc.empty(dimO, dtype=dtype)\n    nm.fprop_lrn(layer_m, devI, devO, devD, alpha, beta, ascale, bpower)\n    nc.fprop_lrn(layer_c, cccI, cccO, cccD, None, None, ascale, bpower)\n    neon_logger.display('== denom ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL fprop')\n    neon_logger.display(devD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('== output ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL fprop')\n    neon_logger.display(devO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    nm.bprop_lrn(layer_m, devI, devO, devE, devB, devD, alpha, beta, ascale, bpower)\n    nc.bprop_lrn(layer_c, cccI, cccO, cccE, cccB, cccD, None, None, ascale, bpower)\n    neon_logger.display('== bprop ==')\n    neon_logger.display('CPU bprop')\n    neon_logger.display(cccB.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL bprop')\n    neon_logger.display(devB.get().reshape(C * D * H * W, N)[0:4, 0:4])",
            "def lrn_helper_mkl(dtype, ones, cpu, alpha, beta, ascale, bpower, nm, nc, layer_m, layer_c, N, C, D, H, W, J):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    dimI = layer_m.dimI\n    dimO = layer_m.dimO\n    if ones:\n        cpuI = np.ones(slicable(dimI), dtype=np.float32)\n        cpuB = np.ones(slicable(dimI), dtype=np.float32)\n        cpuE = np.ones(dimO, dtype=np.float32)\n        cpuO = np.ones(dimO, dtype=np.float32)\n    else:\n        cpuI = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuB = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuE = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n        cpuO = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n    devI = nm.array(cpuI.reshape(dimI), dtype=dtype)\n    devB = nm.array(cpuB.reshape(dimI), dtype=dtype)\n    devE = nm.array(cpuE, dtype=dtype)\n    devO = nm.array(cpuO, dtype=dtype)\n    devD = nm.empty(dimO, dtype=dtype)\n    cccI = nc.array(cpuI.reshape(dimI), dtype=dtype)\n    cccB = nc.array(cpuB.reshape(dimI), dtype=dtype)\n    cccE = nc.array(cpuE, dtype=dtype)\n    cccO = nc.array(cpuO, dtype=dtype)\n    cccD = nc.empty(dimO, dtype=dtype)\n    nm.fprop_lrn(layer_m, devI, devO, devD, alpha, beta, ascale, bpower)\n    nc.fprop_lrn(layer_c, cccI, cccO, cccD, None, None, ascale, bpower)\n    neon_logger.display('== denom ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL fprop')\n    neon_logger.display(devD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('== output ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL fprop')\n    neon_logger.display(devO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    nm.bprop_lrn(layer_m, devI, devO, devE, devB, devD, alpha, beta, ascale, bpower)\n    nc.bprop_lrn(layer_c, cccI, cccO, cccE, cccB, cccD, None, None, ascale, bpower)\n    neon_logger.display('== bprop ==')\n    neon_logger.display('CPU bprop')\n    neon_logger.display(cccB.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL bprop')\n    neon_logger.display(devB.get().reshape(C * D * H * W, N)[0:4, 0:4])",
            "def lrn_helper_mkl(dtype, ones, cpu, alpha, beta, ascale, bpower, nm, nc, layer_m, layer_c, N, C, D, H, W, J):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    dimI = layer_m.dimI\n    dimO = layer_m.dimO\n    if ones:\n        cpuI = np.ones(slicable(dimI), dtype=np.float32)\n        cpuB = np.ones(slicable(dimI), dtype=np.float32)\n        cpuE = np.ones(dimO, dtype=np.float32)\n        cpuO = np.ones(dimO, dtype=np.float32)\n    else:\n        cpuI = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuB = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuE = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n        cpuO = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n    devI = nm.array(cpuI.reshape(dimI), dtype=dtype)\n    devB = nm.array(cpuB.reshape(dimI), dtype=dtype)\n    devE = nm.array(cpuE, dtype=dtype)\n    devO = nm.array(cpuO, dtype=dtype)\n    devD = nm.empty(dimO, dtype=dtype)\n    cccI = nc.array(cpuI.reshape(dimI), dtype=dtype)\n    cccB = nc.array(cpuB.reshape(dimI), dtype=dtype)\n    cccE = nc.array(cpuE, dtype=dtype)\n    cccO = nc.array(cpuO, dtype=dtype)\n    cccD = nc.empty(dimO, dtype=dtype)\n    nm.fprop_lrn(layer_m, devI, devO, devD, alpha, beta, ascale, bpower)\n    nc.fprop_lrn(layer_c, cccI, cccO, cccD, None, None, ascale, bpower)\n    neon_logger.display('== denom ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL fprop')\n    neon_logger.display(devD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('== output ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL fprop')\n    neon_logger.display(devO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    nm.bprop_lrn(layer_m, devI, devO, devE, devB, devD, alpha, beta, ascale, bpower)\n    nc.bprop_lrn(layer_c, cccI, cccO, cccE, cccB, cccD, None, None, ascale, bpower)\n    neon_logger.display('== bprop ==')\n    neon_logger.display('CPU bprop')\n    neon_logger.display(cccB.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('MKL bprop')\n    neon_logger.display(devB.get().reshape(C * D * H * W, N)[0:4, 0:4])"
        ]
    },
    {
        "func_name": "test_pooling",
        "original": "@pytest.mark.hasgpu\ndef test_pooling(backend_pair_bench):\n    (ng, nc) = backend_pair_bench\n    layer_args = dict(dtype=np.float32, N=122, C=16, D=1, H=32, W=32, J=5)\n    pool_test_args = dict(ones=0, cpu=1, ng=ng, nc=nc, alpha=1.0, ascale=1.2, beta=0.0, bpower=0.5, layer_g=ng.lrn_layer(**layer_args), layer_c=nc.lrn_layer(**layer_args), **layer_args)\n    lrn_helper(**pool_test_args)",
        "mutated": [
            "@pytest.mark.hasgpu\ndef test_pooling(backend_pair_bench):\n    if False:\n        i = 10\n    (ng, nc) = backend_pair_bench\n    layer_args = dict(dtype=np.float32, N=122, C=16, D=1, H=32, W=32, J=5)\n    pool_test_args = dict(ones=0, cpu=1, ng=ng, nc=nc, alpha=1.0, ascale=1.2, beta=0.0, bpower=0.5, layer_g=ng.lrn_layer(**layer_args), layer_c=nc.lrn_layer(**layer_args), **layer_args)\n    lrn_helper(**pool_test_args)",
            "@pytest.mark.hasgpu\ndef test_pooling(backend_pair_bench):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (ng, nc) = backend_pair_bench\n    layer_args = dict(dtype=np.float32, N=122, C=16, D=1, H=32, W=32, J=5)\n    pool_test_args = dict(ones=0, cpu=1, ng=ng, nc=nc, alpha=1.0, ascale=1.2, beta=0.0, bpower=0.5, layer_g=ng.lrn_layer(**layer_args), layer_c=nc.lrn_layer(**layer_args), **layer_args)\n    lrn_helper(**pool_test_args)",
            "@pytest.mark.hasgpu\ndef test_pooling(backend_pair_bench):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (ng, nc) = backend_pair_bench\n    layer_args = dict(dtype=np.float32, N=122, C=16, D=1, H=32, W=32, J=5)\n    pool_test_args = dict(ones=0, cpu=1, ng=ng, nc=nc, alpha=1.0, ascale=1.2, beta=0.0, bpower=0.5, layer_g=ng.lrn_layer(**layer_args), layer_c=nc.lrn_layer(**layer_args), **layer_args)\n    lrn_helper(**pool_test_args)",
            "@pytest.mark.hasgpu\ndef test_pooling(backend_pair_bench):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (ng, nc) = backend_pair_bench\n    layer_args = dict(dtype=np.float32, N=122, C=16, D=1, H=32, W=32, J=5)\n    pool_test_args = dict(ones=0, cpu=1, ng=ng, nc=nc, alpha=1.0, ascale=1.2, beta=0.0, bpower=0.5, layer_g=ng.lrn_layer(**layer_args), layer_c=nc.lrn_layer(**layer_args), **layer_args)\n    lrn_helper(**pool_test_args)",
            "@pytest.mark.hasgpu\ndef test_pooling(backend_pair_bench):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (ng, nc) = backend_pair_bench\n    layer_args = dict(dtype=np.float32, N=122, C=16, D=1, H=32, W=32, J=5)\n    pool_test_args = dict(ones=0, cpu=1, ng=ng, nc=nc, alpha=1.0, ascale=1.2, beta=0.0, bpower=0.5, layer_g=ng.lrn_layer(**layer_args), layer_c=nc.lrn_layer(**layer_args), **layer_args)\n    lrn_helper(**pool_test_args)"
        ]
    },
    {
        "func_name": "lrn_helper",
        "original": "def lrn_helper(dtype, ones, cpu, alpha, beta, ascale, bpower, ng, nc, layer_g, layer_c, N, C, D, H, W, J):\n    dimI = layer_g.dimI\n    dimO = layer_g.dimO\n    if ones:\n        cpuI = np.ones(slicable(dimI), dtype=np.float32)\n        cpuB = np.ones(slicable(dimI), dtype=np.float32)\n        cpuE = np.ones(dimO, dtype=np.float32)\n        cpuO = np.ones(dimO, dtype=np.float32)\n    else:\n        cpuI = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuB = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuE = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n        cpuO = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n    devI = ng.array(cpuI.reshape(dimI), dtype=dtype)\n    devB = ng.array(cpuB.reshape(dimI), dtype=dtype)\n    devE = ng.array(cpuE, dtype=dtype)\n    devO = ng.array(cpuO, dtype=dtype)\n    devD = ng.empty(dimO, dtype=dtype)\n    cccI = nc.array(cpuI.reshape(dimI), dtype=dtype)\n    cccB = nc.array(cpuB.reshape(dimI), dtype=dtype)\n    cccE = nc.array(cpuE, dtype=dtype)\n    cccO = nc.array(cpuO, dtype=dtype)\n    cccD = nc.empty(dimO, dtype=dtype)\n    ng.fprop_lrn(layer_g, devI, devO, devD, alpha, beta, ascale, bpower)\n    nc.fprop_lrn(layer_c, cccI, cccO, cccD, None, None, ascale, bpower)\n    neon_logger.display('== denom ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU fprop')\n    neon_logger.display(devD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('== output ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU fprop')\n    neon_logger.display(devO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    ng.bprop_lrn(layer_g, devI, devO, devE, devB, devD, alpha, beta, ascale, bpower)\n    nc.bprop_lrn(layer_c, cccI, cccO, cccE, cccB, cccD, None, None, ascale, bpower)\n    neon_logger.display('== bprop ==')\n    neon_logger.display('CPU bprop')\n    neon_logger.display(cccB.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU bprop')\n    neon_logger.display(devB.get().reshape(C * D * H * W, N)[0:4, 0:4])",
        "mutated": [
            "def lrn_helper(dtype, ones, cpu, alpha, beta, ascale, bpower, ng, nc, layer_g, layer_c, N, C, D, H, W, J):\n    if False:\n        i = 10\n    dimI = layer_g.dimI\n    dimO = layer_g.dimO\n    if ones:\n        cpuI = np.ones(slicable(dimI), dtype=np.float32)\n        cpuB = np.ones(slicable(dimI), dtype=np.float32)\n        cpuE = np.ones(dimO, dtype=np.float32)\n        cpuO = np.ones(dimO, dtype=np.float32)\n    else:\n        cpuI = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuB = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuE = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n        cpuO = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n    devI = ng.array(cpuI.reshape(dimI), dtype=dtype)\n    devB = ng.array(cpuB.reshape(dimI), dtype=dtype)\n    devE = ng.array(cpuE, dtype=dtype)\n    devO = ng.array(cpuO, dtype=dtype)\n    devD = ng.empty(dimO, dtype=dtype)\n    cccI = nc.array(cpuI.reshape(dimI), dtype=dtype)\n    cccB = nc.array(cpuB.reshape(dimI), dtype=dtype)\n    cccE = nc.array(cpuE, dtype=dtype)\n    cccO = nc.array(cpuO, dtype=dtype)\n    cccD = nc.empty(dimO, dtype=dtype)\n    ng.fprop_lrn(layer_g, devI, devO, devD, alpha, beta, ascale, bpower)\n    nc.fprop_lrn(layer_c, cccI, cccO, cccD, None, None, ascale, bpower)\n    neon_logger.display('== denom ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU fprop')\n    neon_logger.display(devD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('== output ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU fprop')\n    neon_logger.display(devO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    ng.bprop_lrn(layer_g, devI, devO, devE, devB, devD, alpha, beta, ascale, bpower)\n    nc.bprop_lrn(layer_c, cccI, cccO, cccE, cccB, cccD, None, None, ascale, bpower)\n    neon_logger.display('== bprop ==')\n    neon_logger.display('CPU bprop')\n    neon_logger.display(cccB.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU bprop')\n    neon_logger.display(devB.get().reshape(C * D * H * W, N)[0:4, 0:4])",
            "def lrn_helper(dtype, ones, cpu, alpha, beta, ascale, bpower, ng, nc, layer_g, layer_c, N, C, D, H, W, J):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    dimI = layer_g.dimI\n    dimO = layer_g.dimO\n    if ones:\n        cpuI = np.ones(slicable(dimI), dtype=np.float32)\n        cpuB = np.ones(slicable(dimI), dtype=np.float32)\n        cpuE = np.ones(dimO, dtype=np.float32)\n        cpuO = np.ones(dimO, dtype=np.float32)\n    else:\n        cpuI = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuB = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuE = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n        cpuO = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n    devI = ng.array(cpuI.reshape(dimI), dtype=dtype)\n    devB = ng.array(cpuB.reshape(dimI), dtype=dtype)\n    devE = ng.array(cpuE, dtype=dtype)\n    devO = ng.array(cpuO, dtype=dtype)\n    devD = ng.empty(dimO, dtype=dtype)\n    cccI = nc.array(cpuI.reshape(dimI), dtype=dtype)\n    cccB = nc.array(cpuB.reshape(dimI), dtype=dtype)\n    cccE = nc.array(cpuE, dtype=dtype)\n    cccO = nc.array(cpuO, dtype=dtype)\n    cccD = nc.empty(dimO, dtype=dtype)\n    ng.fprop_lrn(layer_g, devI, devO, devD, alpha, beta, ascale, bpower)\n    nc.fprop_lrn(layer_c, cccI, cccO, cccD, None, None, ascale, bpower)\n    neon_logger.display('== denom ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU fprop')\n    neon_logger.display(devD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('== output ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU fprop')\n    neon_logger.display(devO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    ng.bprop_lrn(layer_g, devI, devO, devE, devB, devD, alpha, beta, ascale, bpower)\n    nc.bprop_lrn(layer_c, cccI, cccO, cccE, cccB, cccD, None, None, ascale, bpower)\n    neon_logger.display('== bprop ==')\n    neon_logger.display('CPU bprop')\n    neon_logger.display(cccB.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU bprop')\n    neon_logger.display(devB.get().reshape(C * D * H * W, N)[0:4, 0:4])",
            "def lrn_helper(dtype, ones, cpu, alpha, beta, ascale, bpower, ng, nc, layer_g, layer_c, N, C, D, H, W, J):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    dimI = layer_g.dimI\n    dimO = layer_g.dimO\n    if ones:\n        cpuI = np.ones(slicable(dimI), dtype=np.float32)\n        cpuB = np.ones(slicable(dimI), dtype=np.float32)\n        cpuE = np.ones(dimO, dtype=np.float32)\n        cpuO = np.ones(dimO, dtype=np.float32)\n    else:\n        cpuI = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuB = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuE = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n        cpuO = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n    devI = ng.array(cpuI.reshape(dimI), dtype=dtype)\n    devB = ng.array(cpuB.reshape(dimI), dtype=dtype)\n    devE = ng.array(cpuE, dtype=dtype)\n    devO = ng.array(cpuO, dtype=dtype)\n    devD = ng.empty(dimO, dtype=dtype)\n    cccI = nc.array(cpuI.reshape(dimI), dtype=dtype)\n    cccB = nc.array(cpuB.reshape(dimI), dtype=dtype)\n    cccE = nc.array(cpuE, dtype=dtype)\n    cccO = nc.array(cpuO, dtype=dtype)\n    cccD = nc.empty(dimO, dtype=dtype)\n    ng.fprop_lrn(layer_g, devI, devO, devD, alpha, beta, ascale, bpower)\n    nc.fprop_lrn(layer_c, cccI, cccO, cccD, None, None, ascale, bpower)\n    neon_logger.display('== denom ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU fprop')\n    neon_logger.display(devD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('== output ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU fprop')\n    neon_logger.display(devO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    ng.bprop_lrn(layer_g, devI, devO, devE, devB, devD, alpha, beta, ascale, bpower)\n    nc.bprop_lrn(layer_c, cccI, cccO, cccE, cccB, cccD, None, None, ascale, bpower)\n    neon_logger.display('== bprop ==')\n    neon_logger.display('CPU bprop')\n    neon_logger.display(cccB.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU bprop')\n    neon_logger.display(devB.get().reshape(C * D * H * W, N)[0:4, 0:4])",
            "def lrn_helper(dtype, ones, cpu, alpha, beta, ascale, bpower, ng, nc, layer_g, layer_c, N, C, D, H, W, J):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    dimI = layer_g.dimI\n    dimO = layer_g.dimO\n    if ones:\n        cpuI = np.ones(slicable(dimI), dtype=np.float32)\n        cpuB = np.ones(slicable(dimI), dtype=np.float32)\n        cpuE = np.ones(dimO, dtype=np.float32)\n        cpuO = np.ones(dimO, dtype=np.float32)\n    else:\n        cpuI = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuB = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuE = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n        cpuO = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n    devI = ng.array(cpuI.reshape(dimI), dtype=dtype)\n    devB = ng.array(cpuB.reshape(dimI), dtype=dtype)\n    devE = ng.array(cpuE, dtype=dtype)\n    devO = ng.array(cpuO, dtype=dtype)\n    devD = ng.empty(dimO, dtype=dtype)\n    cccI = nc.array(cpuI.reshape(dimI), dtype=dtype)\n    cccB = nc.array(cpuB.reshape(dimI), dtype=dtype)\n    cccE = nc.array(cpuE, dtype=dtype)\n    cccO = nc.array(cpuO, dtype=dtype)\n    cccD = nc.empty(dimO, dtype=dtype)\n    ng.fprop_lrn(layer_g, devI, devO, devD, alpha, beta, ascale, bpower)\n    nc.fprop_lrn(layer_c, cccI, cccO, cccD, None, None, ascale, bpower)\n    neon_logger.display('== denom ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU fprop')\n    neon_logger.display(devD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('== output ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU fprop')\n    neon_logger.display(devO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    ng.bprop_lrn(layer_g, devI, devO, devE, devB, devD, alpha, beta, ascale, bpower)\n    nc.bprop_lrn(layer_c, cccI, cccO, cccE, cccB, cccD, None, None, ascale, bpower)\n    neon_logger.display('== bprop ==')\n    neon_logger.display('CPU bprop')\n    neon_logger.display(cccB.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU bprop')\n    neon_logger.display(devB.get().reshape(C * D * H * W, N)[0:4, 0:4])",
            "def lrn_helper(dtype, ones, cpu, alpha, beta, ascale, bpower, ng, nc, layer_g, layer_c, N, C, D, H, W, J):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    dimI = layer_g.dimI\n    dimO = layer_g.dimO\n    if ones:\n        cpuI = np.ones(slicable(dimI), dtype=np.float32)\n        cpuB = np.ones(slicable(dimI), dtype=np.float32)\n        cpuE = np.ones(dimO, dtype=np.float32)\n        cpuO = np.ones(dimO, dtype=np.float32)\n    else:\n        cpuI = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuB = np.random.uniform(-1.0, 1.0, slicable(dimI)).astype(np.float16).astype(np.float32)\n        cpuE = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n        cpuO = np.random.uniform(-1.0, 1.0, dimO).astype(np.float16).astype(np.float32)\n    devI = ng.array(cpuI.reshape(dimI), dtype=dtype)\n    devB = ng.array(cpuB.reshape(dimI), dtype=dtype)\n    devE = ng.array(cpuE, dtype=dtype)\n    devO = ng.array(cpuO, dtype=dtype)\n    devD = ng.empty(dimO, dtype=dtype)\n    cccI = nc.array(cpuI.reshape(dimI), dtype=dtype)\n    cccB = nc.array(cpuB.reshape(dimI), dtype=dtype)\n    cccE = nc.array(cpuE, dtype=dtype)\n    cccO = nc.array(cpuO, dtype=dtype)\n    cccD = nc.empty(dimO, dtype=dtype)\n    ng.fprop_lrn(layer_g, devI, devO, devD, alpha, beta, ascale, bpower)\n    nc.fprop_lrn(layer_c, cccI, cccO, cccD, None, None, ascale, bpower)\n    neon_logger.display('== denom ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU fprop')\n    neon_logger.display(devD.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('== output ==')\n    neon_logger.display('CPU fprop')\n    neon_logger.display(cccO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU fprop')\n    neon_logger.display(devO.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    ng.bprop_lrn(layer_g, devI, devO, devE, devB, devD, alpha, beta, ascale, bpower)\n    nc.bprop_lrn(layer_c, cccI, cccO, cccE, cccB, cccD, None, None, ascale, bpower)\n    neon_logger.display('== bprop ==')\n    neon_logger.display('CPU bprop')\n    neon_logger.display(cccB.get().reshape(C * D * H * W, N)[0:4, 0:4])\n    neon_logger.display('GPU bprop')\n    neon_logger.display(devB.get().reshape(C * D * H * W, N)[0:4, 0:4])"
        ]
    }
]