[
    {
        "func_name": "update_realmauditlog_values",
        "original": "def update_realmauditlog_values(apps: StateApps, schema_editor: BaseDatabaseSchemaEditor) -> None:\n    \"\"\"\n    This migration fixes two issues with the RealmAuditLog format for certain event types:\n    * The notifications_stream and signup_notifications_stream fields had the\n      Stream objects passed into `ujson.dumps()` and thus marshalled as a giant\n      JSON object, when the intent was to store the stream ID.\n    * The default_sending_stream would also been marshalled wrong, but are part\n      of a feature that nobody should be using, so we simply assert that's the case.\n    * Changes the structure of the extra_data JSON dictionaries for those\n      RealmAuditLog entries with a sub-property field from:\n      {\n          OLD_VALUE: {\"property\": property, \"value\": old_value},\n          NEW_VALUE: {\"property\": property, \"value\": new_value},\n      }\n\n      to the more natural:\n\n      {\n          OLD_VALUE: old_value,\n          NEW_VALUE: new_value,\n          \"property\": property,\n      }\n    \"\"\"\n    RealmAuditLog = apps.get_model('zerver', 'RealmAuditLog')\n    USER_DEFAULT_SENDING_STREAM_CHANGED = 129\n    USER_DEFAULT_REGISTER_STREAM_CHANGED = 130\n    USER_DEFAULT_ALL_PUBLIC_STREAMS_CHANGED = 131\n    USER_NOTIFICATION_SETTINGS_CHANGED = 132\n    REALM_PROPERTY_CHANGED = 207\n    SUBSCRIPTION_PROPERTY_CHANGED = 304\n    OLD_VALUE = '1'\n    NEW_VALUE = '2'\n    unlikely_event_types = [USER_DEFAULT_SENDING_STREAM_CHANGED, USER_DEFAULT_REGISTER_STREAM_CHANGED, USER_DEFAULT_ALL_PUBLIC_STREAMS_CHANGED]\n    affected_event_types = [REALM_PROPERTY_CHANGED, USER_NOTIFICATION_SETTINGS_CHANGED, SUBSCRIPTION_PROPERTY_CHANGED]\n    improperly_marshalled_properties = ['notifications_stream', 'signup_notifications_stream']\n    assert not RealmAuditLog.objects.filter(event_type__in=unlikely_event_types).exists()\n    for ra in RealmAuditLog.objects.filter(event_type__in=affected_event_types):\n        extra_data = json.loads(ra.extra_data)\n        old_key = extra_data[OLD_VALUE]\n        new_key = extra_data[NEW_VALUE]\n        if not isinstance(old_key, dict) and (not isinstance(new_key, dict)):\n            continue\n        if 'value' not in old_key or 'value' not in new_key:\n            continue\n        old_value = old_key['value']\n        new_value = new_key['value']\n        prop = old_key['property']\n        if prop != 'authentication_methods':\n            if isinstance(old_value, dict):\n                assert prop in improperly_marshalled_properties\n                old_value = old_value['id']\n            if isinstance(new_value, dict):\n                assert prop in improperly_marshalled_properties\n                new_value = new_value['id']\n        assert set(extra_data.keys()) <= {OLD_VALUE, NEW_VALUE}\n        ra.extra_data = json.dumps({OLD_VALUE: old_value, NEW_VALUE: new_value, 'property': prop})\n        ra.save(update_fields=['extra_data'])",
        "mutated": [
            "def update_realmauditlog_values(apps: StateApps, schema_editor: BaseDatabaseSchemaEditor) -> None:\n    if False:\n        i = 10\n    '\\n    This migration fixes two issues with the RealmAuditLog format for certain event types:\\n    * The notifications_stream and signup_notifications_stream fields had the\\n      Stream objects passed into `ujson.dumps()` and thus marshalled as a giant\\n      JSON object, when the intent was to store the stream ID.\\n    * The default_sending_stream would also been marshalled wrong, but are part\\n      of a feature that nobody should be using, so we simply assert that\\'s the case.\\n    * Changes the structure of the extra_data JSON dictionaries for those\\n      RealmAuditLog entries with a sub-property field from:\\n      {\\n          OLD_VALUE: {\"property\": property, \"value\": old_value},\\n          NEW_VALUE: {\"property\": property, \"value\": new_value},\\n      }\\n\\n      to the more natural:\\n\\n      {\\n          OLD_VALUE: old_value,\\n          NEW_VALUE: new_value,\\n          \"property\": property,\\n      }\\n    '\n    RealmAuditLog = apps.get_model('zerver', 'RealmAuditLog')\n    USER_DEFAULT_SENDING_STREAM_CHANGED = 129\n    USER_DEFAULT_REGISTER_STREAM_CHANGED = 130\n    USER_DEFAULT_ALL_PUBLIC_STREAMS_CHANGED = 131\n    USER_NOTIFICATION_SETTINGS_CHANGED = 132\n    REALM_PROPERTY_CHANGED = 207\n    SUBSCRIPTION_PROPERTY_CHANGED = 304\n    OLD_VALUE = '1'\n    NEW_VALUE = '2'\n    unlikely_event_types = [USER_DEFAULT_SENDING_STREAM_CHANGED, USER_DEFAULT_REGISTER_STREAM_CHANGED, USER_DEFAULT_ALL_PUBLIC_STREAMS_CHANGED]\n    affected_event_types = [REALM_PROPERTY_CHANGED, USER_NOTIFICATION_SETTINGS_CHANGED, SUBSCRIPTION_PROPERTY_CHANGED]\n    improperly_marshalled_properties = ['notifications_stream', 'signup_notifications_stream']\n    assert not RealmAuditLog.objects.filter(event_type__in=unlikely_event_types).exists()\n    for ra in RealmAuditLog.objects.filter(event_type__in=affected_event_types):\n        extra_data = json.loads(ra.extra_data)\n        old_key = extra_data[OLD_VALUE]\n        new_key = extra_data[NEW_VALUE]\n        if not isinstance(old_key, dict) and (not isinstance(new_key, dict)):\n            continue\n        if 'value' not in old_key or 'value' not in new_key:\n            continue\n        old_value = old_key['value']\n        new_value = new_key['value']\n        prop = old_key['property']\n        if prop != 'authentication_methods':\n            if isinstance(old_value, dict):\n                assert prop in improperly_marshalled_properties\n                old_value = old_value['id']\n            if isinstance(new_value, dict):\n                assert prop in improperly_marshalled_properties\n                new_value = new_value['id']\n        assert set(extra_data.keys()) <= {OLD_VALUE, NEW_VALUE}\n        ra.extra_data = json.dumps({OLD_VALUE: old_value, NEW_VALUE: new_value, 'property': prop})\n        ra.save(update_fields=['extra_data'])",
            "def update_realmauditlog_values(apps: StateApps, schema_editor: BaseDatabaseSchemaEditor) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    This migration fixes two issues with the RealmAuditLog format for certain event types:\\n    * The notifications_stream and signup_notifications_stream fields had the\\n      Stream objects passed into `ujson.dumps()` and thus marshalled as a giant\\n      JSON object, when the intent was to store the stream ID.\\n    * The default_sending_stream would also been marshalled wrong, but are part\\n      of a feature that nobody should be using, so we simply assert that\\'s the case.\\n    * Changes the structure of the extra_data JSON dictionaries for those\\n      RealmAuditLog entries with a sub-property field from:\\n      {\\n          OLD_VALUE: {\"property\": property, \"value\": old_value},\\n          NEW_VALUE: {\"property\": property, \"value\": new_value},\\n      }\\n\\n      to the more natural:\\n\\n      {\\n          OLD_VALUE: old_value,\\n          NEW_VALUE: new_value,\\n          \"property\": property,\\n      }\\n    '\n    RealmAuditLog = apps.get_model('zerver', 'RealmAuditLog')\n    USER_DEFAULT_SENDING_STREAM_CHANGED = 129\n    USER_DEFAULT_REGISTER_STREAM_CHANGED = 130\n    USER_DEFAULT_ALL_PUBLIC_STREAMS_CHANGED = 131\n    USER_NOTIFICATION_SETTINGS_CHANGED = 132\n    REALM_PROPERTY_CHANGED = 207\n    SUBSCRIPTION_PROPERTY_CHANGED = 304\n    OLD_VALUE = '1'\n    NEW_VALUE = '2'\n    unlikely_event_types = [USER_DEFAULT_SENDING_STREAM_CHANGED, USER_DEFAULT_REGISTER_STREAM_CHANGED, USER_DEFAULT_ALL_PUBLIC_STREAMS_CHANGED]\n    affected_event_types = [REALM_PROPERTY_CHANGED, USER_NOTIFICATION_SETTINGS_CHANGED, SUBSCRIPTION_PROPERTY_CHANGED]\n    improperly_marshalled_properties = ['notifications_stream', 'signup_notifications_stream']\n    assert not RealmAuditLog.objects.filter(event_type__in=unlikely_event_types).exists()\n    for ra in RealmAuditLog.objects.filter(event_type__in=affected_event_types):\n        extra_data = json.loads(ra.extra_data)\n        old_key = extra_data[OLD_VALUE]\n        new_key = extra_data[NEW_VALUE]\n        if not isinstance(old_key, dict) and (not isinstance(new_key, dict)):\n            continue\n        if 'value' not in old_key or 'value' not in new_key:\n            continue\n        old_value = old_key['value']\n        new_value = new_key['value']\n        prop = old_key['property']\n        if prop != 'authentication_methods':\n            if isinstance(old_value, dict):\n                assert prop in improperly_marshalled_properties\n                old_value = old_value['id']\n            if isinstance(new_value, dict):\n                assert prop in improperly_marshalled_properties\n                new_value = new_value['id']\n        assert set(extra_data.keys()) <= {OLD_VALUE, NEW_VALUE}\n        ra.extra_data = json.dumps({OLD_VALUE: old_value, NEW_VALUE: new_value, 'property': prop})\n        ra.save(update_fields=['extra_data'])",
            "def update_realmauditlog_values(apps: StateApps, schema_editor: BaseDatabaseSchemaEditor) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    This migration fixes two issues with the RealmAuditLog format for certain event types:\\n    * The notifications_stream and signup_notifications_stream fields had the\\n      Stream objects passed into `ujson.dumps()` and thus marshalled as a giant\\n      JSON object, when the intent was to store the stream ID.\\n    * The default_sending_stream would also been marshalled wrong, but are part\\n      of a feature that nobody should be using, so we simply assert that\\'s the case.\\n    * Changes the structure of the extra_data JSON dictionaries for those\\n      RealmAuditLog entries with a sub-property field from:\\n      {\\n          OLD_VALUE: {\"property\": property, \"value\": old_value},\\n          NEW_VALUE: {\"property\": property, \"value\": new_value},\\n      }\\n\\n      to the more natural:\\n\\n      {\\n          OLD_VALUE: old_value,\\n          NEW_VALUE: new_value,\\n          \"property\": property,\\n      }\\n    '\n    RealmAuditLog = apps.get_model('zerver', 'RealmAuditLog')\n    USER_DEFAULT_SENDING_STREAM_CHANGED = 129\n    USER_DEFAULT_REGISTER_STREAM_CHANGED = 130\n    USER_DEFAULT_ALL_PUBLIC_STREAMS_CHANGED = 131\n    USER_NOTIFICATION_SETTINGS_CHANGED = 132\n    REALM_PROPERTY_CHANGED = 207\n    SUBSCRIPTION_PROPERTY_CHANGED = 304\n    OLD_VALUE = '1'\n    NEW_VALUE = '2'\n    unlikely_event_types = [USER_DEFAULT_SENDING_STREAM_CHANGED, USER_DEFAULT_REGISTER_STREAM_CHANGED, USER_DEFAULT_ALL_PUBLIC_STREAMS_CHANGED]\n    affected_event_types = [REALM_PROPERTY_CHANGED, USER_NOTIFICATION_SETTINGS_CHANGED, SUBSCRIPTION_PROPERTY_CHANGED]\n    improperly_marshalled_properties = ['notifications_stream', 'signup_notifications_stream']\n    assert not RealmAuditLog.objects.filter(event_type__in=unlikely_event_types).exists()\n    for ra in RealmAuditLog.objects.filter(event_type__in=affected_event_types):\n        extra_data = json.loads(ra.extra_data)\n        old_key = extra_data[OLD_VALUE]\n        new_key = extra_data[NEW_VALUE]\n        if not isinstance(old_key, dict) and (not isinstance(new_key, dict)):\n            continue\n        if 'value' not in old_key or 'value' not in new_key:\n            continue\n        old_value = old_key['value']\n        new_value = new_key['value']\n        prop = old_key['property']\n        if prop != 'authentication_methods':\n            if isinstance(old_value, dict):\n                assert prop in improperly_marshalled_properties\n                old_value = old_value['id']\n            if isinstance(new_value, dict):\n                assert prop in improperly_marshalled_properties\n                new_value = new_value['id']\n        assert set(extra_data.keys()) <= {OLD_VALUE, NEW_VALUE}\n        ra.extra_data = json.dumps({OLD_VALUE: old_value, NEW_VALUE: new_value, 'property': prop})\n        ra.save(update_fields=['extra_data'])",
            "def update_realmauditlog_values(apps: StateApps, schema_editor: BaseDatabaseSchemaEditor) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    This migration fixes two issues with the RealmAuditLog format for certain event types:\\n    * The notifications_stream and signup_notifications_stream fields had the\\n      Stream objects passed into `ujson.dumps()` and thus marshalled as a giant\\n      JSON object, when the intent was to store the stream ID.\\n    * The default_sending_stream would also been marshalled wrong, but are part\\n      of a feature that nobody should be using, so we simply assert that\\'s the case.\\n    * Changes the structure of the extra_data JSON dictionaries for those\\n      RealmAuditLog entries with a sub-property field from:\\n      {\\n          OLD_VALUE: {\"property\": property, \"value\": old_value},\\n          NEW_VALUE: {\"property\": property, \"value\": new_value},\\n      }\\n\\n      to the more natural:\\n\\n      {\\n          OLD_VALUE: old_value,\\n          NEW_VALUE: new_value,\\n          \"property\": property,\\n      }\\n    '\n    RealmAuditLog = apps.get_model('zerver', 'RealmAuditLog')\n    USER_DEFAULT_SENDING_STREAM_CHANGED = 129\n    USER_DEFAULT_REGISTER_STREAM_CHANGED = 130\n    USER_DEFAULT_ALL_PUBLIC_STREAMS_CHANGED = 131\n    USER_NOTIFICATION_SETTINGS_CHANGED = 132\n    REALM_PROPERTY_CHANGED = 207\n    SUBSCRIPTION_PROPERTY_CHANGED = 304\n    OLD_VALUE = '1'\n    NEW_VALUE = '2'\n    unlikely_event_types = [USER_DEFAULT_SENDING_STREAM_CHANGED, USER_DEFAULT_REGISTER_STREAM_CHANGED, USER_DEFAULT_ALL_PUBLIC_STREAMS_CHANGED]\n    affected_event_types = [REALM_PROPERTY_CHANGED, USER_NOTIFICATION_SETTINGS_CHANGED, SUBSCRIPTION_PROPERTY_CHANGED]\n    improperly_marshalled_properties = ['notifications_stream', 'signup_notifications_stream']\n    assert not RealmAuditLog.objects.filter(event_type__in=unlikely_event_types).exists()\n    for ra in RealmAuditLog.objects.filter(event_type__in=affected_event_types):\n        extra_data = json.loads(ra.extra_data)\n        old_key = extra_data[OLD_VALUE]\n        new_key = extra_data[NEW_VALUE]\n        if not isinstance(old_key, dict) and (not isinstance(new_key, dict)):\n            continue\n        if 'value' not in old_key or 'value' not in new_key:\n            continue\n        old_value = old_key['value']\n        new_value = new_key['value']\n        prop = old_key['property']\n        if prop != 'authentication_methods':\n            if isinstance(old_value, dict):\n                assert prop in improperly_marshalled_properties\n                old_value = old_value['id']\n            if isinstance(new_value, dict):\n                assert prop in improperly_marshalled_properties\n                new_value = new_value['id']\n        assert set(extra_data.keys()) <= {OLD_VALUE, NEW_VALUE}\n        ra.extra_data = json.dumps({OLD_VALUE: old_value, NEW_VALUE: new_value, 'property': prop})\n        ra.save(update_fields=['extra_data'])",
            "def update_realmauditlog_values(apps: StateApps, schema_editor: BaseDatabaseSchemaEditor) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    This migration fixes two issues with the RealmAuditLog format for certain event types:\\n    * The notifications_stream and signup_notifications_stream fields had the\\n      Stream objects passed into `ujson.dumps()` and thus marshalled as a giant\\n      JSON object, when the intent was to store the stream ID.\\n    * The default_sending_stream would also been marshalled wrong, but are part\\n      of a feature that nobody should be using, so we simply assert that\\'s the case.\\n    * Changes the structure of the extra_data JSON dictionaries for those\\n      RealmAuditLog entries with a sub-property field from:\\n      {\\n          OLD_VALUE: {\"property\": property, \"value\": old_value},\\n          NEW_VALUE: {\"property\": property, \"value\": new_value},\\n      }\\n\\n      to the more natural:\\n\\n      {\\n          OLD_VALUE: old_value,\\n          NEW_VALUE: new_value,\\n          \"property\": property,\\n      }\\n    '\n    RealmAuditLog = apps.get_model('zerver', 'RealmAuditLog')\n    USER_DEFAULT_SENDING_STREAM_CHANGED = 129\n    USER_DEFAULT_REGISTER_STREAM_CHANGED = 130\n    USER_DEFAULT_ALL_PUBLIC_STREAMS_CHANGED = 131\n    USER_NOTIFICATION_SETTINGS_CHANGED = 132\n    REALM_PROPERTY_CHANGED = 207\n    SUBSCRIPTION_PROPERTY_CHANGED = 304\n    OLD_VALUE = '1'\n    NEW_VALUE = '2'\n    unlikely_event_types = [USER_DEFAULT_SENDING_STREAM_CHANGED, USER_DEFAULT_REGISTER_STREAM_CHANGED, USER_DEFAULT_ALL_PUBLIC_STREAMS_CHANGED]\n    affected_event_types = [REALM_PROPERTY_CHANGED, USER_NOTIFICATION_SETTINGS_CHANGED, SUBSCRIPTION_PROPERTY_CHANGED]\n    improperly_marshalled_properties = ['notifications_stream', 'signup_notifications_stream']\n    assert not RealmAuditLog.objects.filter(event_type__in=unlikely_event_types).exists()\n    for ra in RealmAuditLog.objects.filter(event_type__in=affected_event_types):\n        extra_data = json.loads(ra.extra_data)\n        old_key = extra_data[OLD_VALUE]\n        new_key = extra_data[NEW_VALUE]\n        if not isinstance(old_key, dict) and (not isinstance(new_key, dict)):\n            continue\n        if 'value' not in old_key or 'value' not in new_key:\n            continue\n        old_value = old_key['value']\n        new_value = new_key['value']\n        prop = old_key['property']\n        if prop != 'authentication_methods':\n            if isinstance(old_value, dict):\n                assert prop in improperly_marshalled_properties\n                old_value = old_value['id']\n            if isinstance(new_value, dict):\n                assert prop in improperly_marshalled_properties\n                new_value = new_value['id']\n        assert set(extra_data.keys()) <= {OLD_VALUE, NEW_VALUE}\n        ra.extra_data = json.dumps({OLD_VALUE: old_value, NEW_VALUE: new_value, 'property': prop})\n        ra.save(update_fields=['extra_data'])"
        ]
    }
]