[
    {
        "func_name": "batch_iou",
        "original": "def batch_iou(boxes1, boxes2):\n    \"\"\"Calculates the overlap between proposal and ground truth boxes.\n\n  Some `boxes2` may have been padded.  The returned `iou` tensor for these\n  boxes will be -1.\n\n  Args:\n    boxes1: a tensor with a shape of [batch_size, N, 4]. N is the number of\n      proposals before groundtruth assignment. The last dimension is the pixel\n      coordinates in [ymin, xmin, ymax, xmax] form.\n    boxes2: a tensor with a shape of [batch_size, MAX_NUM_INSTANCES, 4]. This\n      tensor might have paddings with a negative value.\n\n  Returns:\n    iou: a tensor with as a shape of [batch_size, N, MAX_NUM_INSTANCES].\n  \"\"\"\n    with tf.name_scope('BatchIOU'):\n        (y1_min, x1_min, y1_max, x1_max) = tf.split(value=boxes1, num_or_size_splits=4, axis=2)\n        (y2_min, x2_min, y2_max, x2_max) = tf.split(value=boxes2, num_or_size_splits=4, axis=2)\n        intersection_xmin = tf.maximum(x1_min, tf.transpose(x2_min, [0, 2, 1]))\n        intersection_xmax = tf.minimum(x1_max, tf.transpose(x2_max, [0, 2, 1]))\n        intersection_ymin = tf.maximum(y1_min, tf.transpose(y2_min, [0, 2, 1]))\n        intersection_ymax = tf.minimum(y1_max, tf.transpose(y2_max, [0, 2, 1]))\n        intersection_area = tf.maximum(intersection_xmax - intersection_xmin, 0) * tf.maximum(intersection_ymax - intersection_ymin, 0)\n        area1 = (y1_max - y1_min) * (x1_max - x1_min)\n        area2 = (y2_max - y2_min) * (x2_max - x2_min)\n        union_area = area1 + tf.transpose(area2, [0, 2, 1]) - intersection_area + 1e-08\n        iou = intersection_area / union_area\n        padding_mask = tf.logical_and(tf.less(intersection_xmax, 0), tf.less(intersection_ymax, 0))\n        iou = tf.where(padding_mask, -tf.ones_like(iou), iou)\n        return iou",
        "mutated": [
            "def batch_iou(boxes1, boxes2):\n    if False:\n        i = 10\n    'Calculates the overlap between proposal and ground truth boxes.\\n\\n  Some `boxes2` may have been padded.  The returned `iou` tensor for these\\n  boxes will be -1.\\n\\n  Args:\\n    boxes1: a tensor with a shape of [batch_size, N, 4]. N is the number of\\n      proposals before groundtruth assignment. The last dimension is the pixel\\n      coordinates in [ymin, xmin, ymax, xmax] form.\\n    boxes2: a tensor with a shape of [batch_size, MAX_NUM_INSTANCES, 4]. This\\n      tensor might have paddings with a negative value.\\n\\n  Returns:\\n    iou: a tensor with as a shape of [batch_size, N, MAX_NUM_INSTANCES].\\n  '\n    with tf.name_scope('BatchIOU'):\n        (y1_min, x1_min, y1_max, x1_max) = tf.split(value=boxes1, num_or_size_splits=4, axis=2)\n        (y2_min, x2_min, y2_max, x2_max) = tf.split(value=boxes2, num_or_size_splits=4, axis=2)\n        intersection_xmin = tf.maximum(x1_min, tf.transpose(x2_min, [0, 2, 1]))\n        intersection_xmax = tf.minimum(x1_max, tf.transpose(x2_max, [0, 2, 1]))\n        intersection_ymin = tf.maximum(y1_min, tf.transpose(y2_min, [0, 2, 1]))\n        intersection_ymax = tf.minimum(y1_max, tf.transpose(y2_max, [0, 2, 1]))\n        intersection_area = tf.maximum(intersection_xmax - intersection_xmin, 0) * tf.maximum(intersection_ymax - intersection_ymin, 0)\n        area1 = (y1_max - y1_min) * (x1_max - x1_min)\n        area2 = (y2_max - y2_min) * (x2_max - x2_min)\n        union_area = area1 + tf.transpose(area2, [0, 2, 1]) - intersection_area + 1e-08\n        iou = intersection_area / union_area\n        padding_mask = tf.logical_and(tf.less(intersection_xmax, 0), tf.less(intersection_ymax, 0))\n        iou = tf.where(padding_mask, -tf.ones_like(iou), iou)\n        return iou",
            "def batch_iou(boxes1, boxes2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Calculates the overlap between proposal and ground truth boxes.\\n\\n  Some `boxes2` may have been padded.  The returned `iou` tensor for these\\n  boxes will be -1.\\n\\n  Args:\\n    boxes1: a tensor with a shape of [batch_size, N, 4]. N is the number of\\n      proposals before groundtruth assignment. The last dimension is the pixel\\n      coordinates in [ymin, xmin, ymax, xmax] form.\\n    boxes2: a tensor with a shape of [batch_size, MAX_NUM_INSTANCES, 4]. This\\n      tensor might have paddings with a negative value.\\n\\n  Returns:\\n    iou: a tensor with as a shape of [batch_size, N, MAX_NUM_INSTANCES].\\n  '\n    with tf.name_scope('BatchIOU'):\n        (y1_min, x1_min, y1_max, x1_max) = tf.split(value=boxes1, num_or_size_splits=4, axis=2)\n        (y2_min, x2_min, y2_max, x2_max) = tf.split(value=boxes2, num_or_size_splits=4, axis=2)\n        intersection_xmin = tf.maximum(x1_min, tf.transpose(x2_min, [0, 2, 1]))\n        intersection_xmax = tf.minimum(x1_max, tf.transpose(x2_max, [0, 2, 1]))\n        intersection_ymin = tf.maximum(y1_min, tf.transpose(y2_min, [0, 2, 1]))\n        intersection_ymax = tf.minimum(y1_max, tf.transpose(y2_max, [0, 2, 1]))\n        intersection_area = tf.maximum(intersection_xmax - intersection_xmin, 0) * tf.maximum(intersection_ymax - intersection_ymin, 0)\n        area1 = (y1_max - y1_min) * (x1_max - x1_min)\n        area2 = (y2_max - y2_min) * (x2_max - x2_min)\n        union_area = area1 + tf.transpose(area2, [0, 2, 1]) - intersection_area + 1e-08\n        iou = intersection_area / union_area\n        padding_mask = tf.logical_and(tf.less(intersection_xmax, 0), tf.less(intersection_ymax, 0))\n        iou = tf.where(padding_mask, -tf.ones_like(iou), iou)\n        return iou",
            "def batch_iou(boxes1, boxes2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Calculates the overlap between proposal and ground truth boxes.\\n\\n  Some `boxes2` may have been padded.  The returned `iou` tensor for these\\n  boxes will be -1.\\n\\n  Args:\\n    boxes1: a tensor with a shape of [batch_size, N, 4]. N is the number of\\n      proposals before groundtruth assignment. The last dimension is the pixel\\n      coordinates in [ymin, xmin, ymax, xmax] form.\\n    boxes2: a tensor with a shape of [batch_size, MAX_NUM_INSTANCES, 4]. This\\n      tensor might have paddings with a negative value.\\n\\n  Returns:\\n    iou: a tensor with as a shape of [batch_size, N, MAX_NUM_INSTANCES].\\n  '\n    with tf.name_scope('BatchIOU'):\n        (y1_min, x1_min, y1_max, x1_max) = tf.split(value=boxes1, num_or_size_splits=4, axis=2)\n        (y2_min, x2_min, y2_max, x2_max) = tf.split(value=boxes2, num_or_size_splits=4, axis=2)\n        intersection_xmin = tf.maximum(x1_min, tf.transpose(x2_min, [0, 2, 1]))\n        intersection_xmax = tf.minimum(x1_max, tf.transpose(x2_max, [0, 2, 1]))\n        intersection_ymin = tf.maximum(y1_min, tf.transpose(y2_min, [0, 2, 1]))\n        intersection_ymax = tf.minimum(y1_max, tf.transpose(y2_max, [0, 2, 1]))\n        intersection_area = tf.maximum(intersection_xmax - intersection_xmin, 0) * tf.maximum(intersection_ymax - intersection_ymin, 0)\n        area1 = (y1_max - y1_min) * (x1_max - x1_min)\n        area2 = (y2_max - y2_min) * (x2_max - x2_min)\n        union_area = area1 + tf.transpose(area2, [0, 2, 1]) - intersection_area + 1e-08\n        iou = intersection_area / union_area\n        padding_mask = tf.logical_and(tf.less(intersection_xmax, 0), tf.less(intersection_ymax, 0))\n        iou = tf.where(padding_mask, -tf.ones_like(iou), iou)\n        return iou",
            "def batch_iou(boxes1, boxes2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Calculates the overlap between proposal and ground truth boxes.\\n\\n  Some `boxes2` may have been padded.  The returned `iou` tensor for these\\n  boxes will be -1.\\n\\n  Args:\\n    boxes1: a tensor with a shape of [batch_size, N, 4]. N is the number of\\n      proposals before groundtruth assignment. The last dimension is the pixel\\n      coordinates in [ymin, xmin, ymax, xmax] form.\\n    boxes2: a tensor with a shape of [batch_size, MAX_NUM_INSTANCES, 4]. This\\n      tensor might have paddings with a negative value.\\n\\n  Returns:\\n    iou: a tensor with as a shape of [batch_size, N, MAX_NUM_INSTANCES].\\n  '\n    with tf.name_scope('BatchIOU'):\n        (y1_min, x1_min, y1_max, x1_max) = tf.split(value=boxes1, num_or_size_splits=4, axis=2)\n        (y2_min, x2_min, y2_max, x2_max) = tf.split(value=boxes2, num_or_size_splits=4, axis=2)\n        intersection_xmin = tf.maximum(x1_min, tf.transpose(x2_min, [0, 2, 1]))\n        intersection_xmax = tf.minimum(x1_max, tf.transpose(x2_max, [0, 2, 1]))\n        intersection_ymin = tf.maximum(y1_min, tf.transpose(y2_min, [0, 2, 1]))\n        intersection_ymax = tf.minimum(y1_max, tf.transpose(y2_max, [0, 2, 1]))\n        intersection_area = tf.maximum(intersection_xmax - intersection_xmin, 0) * tf.maximum(intersection_ymax - intersection_ymin, 0)\n        area1 = (y1_max - y1_min) * (x1_max - x1_min)\n        area2 = (y2_max - y2_min) * (x2_max - x2_min)\n        union_area = area1 + tf.transpose(area2, [0, 2, 1]) - intersection_area + 1e-08\n        iou = intersection_area / union_area\n        padding_mask = tf.logical_and(tf.less(intersection_xmax, 0), tf.less(intersection_ymax, 0))\n        iou = tf.where(padding_mask, -tf.ones_like(iou), iou)\n        return iou",
            "def batch_iou(boxes1, boxes2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Calculates the overlap between proposal and ground truth boxes.\\n\\n  Some `boxes2` may have been padded.  The returned `iou` tensor for these\\n  boxes will be -1.\\n\\n  Args:\\n    boxes1: a tensor with a shape of [batch_size, N, 4]. N is the number of\\n      proposals before groundtruth assignment. The last dimension is the pixel\\n      coordinates in [ymin, xmin, ymax, xmax] form.\\n    boxes2: a tensor with a shape of [batch_size, MAX_NUM_INSTANCES, 4]. This\\n      tensor might have paddings with a negative value.\\n\\n  Returns:\\n    iou: a tensor with as a shape of [batch_size, N, MAX_NUM_INSTANCES].\\n  '\n    with tf.name_scope('BatchIOU'):\n        (y1_min, x1_min, y1_max, x1_max) = tf.split(value=boxes1, num_or_size_splits=4, axis=2)\n        (y2_min, x2_min, y2_max, x2_max) = tf.split(value=boxes2, num_or_size_splits=4, axis=2)\n        intersection_xmin = tf.maximum(x1_min, tf.transpose(x2_min, [0, 2, 1]))\n        intersection_xmax = tf.minimum(x1_max, tf.transpose(x2_max, [0, 2, 1]))\n        intersection_ymin = tf.maximum(y1_min, tf.transpose(y2_min, [0, 2, 1]))\n        intersection_ymax = tf.minimum(y1_max, tf.transpose(y2_max, [0, 2, 1]))\n        intersection_area = tf.maximum(intersection_xmax - intersection_xmin, 0) * tf.maximum(intersection_ymax - intersection_ymin, 0)\n        area1 = (y1_max - y1_min) * (x1_max - x1_min)\n        area2 = (y2_max - y2_min) * (x2_max - x2_min)\n        union_area = area1 + tf.transpose(area2, [0, 2, 1]) - intersection_area + 1e-08\n        iou = intersection_area / union_area\n        padding_mask = tf.logical_and(tf.less(intersection_xmax, 0), tf.less(intersection_ymax, 0))\n        iou = tf.where(padding_mask, -tf.ones_like(iou), iou)\n        return iou"
        ]
    },
    {
        "func_name": "_self_suppression",
        "original": "def _self_suppression(iou, iou_threshold, loop_condition, iou_sum):\n    \"\"\"Bounding-boxes self-suppression loop body.\n\n  Args:\n    iou: A float Tensor with shape [1, num_boxes, max_num_instance]: IOUs.\n    iou_threshold: A scalar, representing IOU threshold.\n    loop_condition: The loop condition returned from last iteration.\n    iou_sum: iou_sum_new returned from last iteration.\n\n  Returns:\n    iou_suppressed: A float Tensor with shape [1, num_boxes, max_num_instance],\n                    IOU after suppression.\n    iou_threshold: A scalar, representing IOU threshold.\n    loop_condition: Bool Tensor of shape [], the loop condition.\n    iou_sum_new: The new IOU sum.\n  \"\"\"\n    del loop_condition\n    can_suppress_others = tf.cast(tf.reshape(tf.reduce_max(iou, 1) <= iou_threshold, [1, -1, 1]), iou.dtype)\n    iou_suppressed = tf.reshape(tf.cast(tf.reduce_max(can_suppress_others * iou, 1) <= iou_threshold, iou.dtype), [1, -1, 1]) * iou\n    iou_sum_new = tf.reduce_sum(iou_suppressed, [1, 2])\n    return [iou_suppressed, iou_threshold, tf.reduce_any(iou_sum - iou_sum_new > iou_threshold), iou_sum_new]",
        "mutated": [
            "def _self_suppression(iou, iou_threshold, loop_condition, iou_sum):\n    if False:\n        i = 10\n    'Bounding-boxes self-suppression loop body.\\n\\n  Args:\\n    iou: A float Tensor with shape [1, num_boxes, max_num_instance]: IOUs.\\n    iou_threshold: A scalar, representing IOU threshold.\\n    loop_condition: The loop condition returned from last iteration.\\n    iou_sum: iou_sum_new returned from last iteration.\\n\\n  Returns:\\n    iou_suppressed: A float Tensor with shape [1, num_boxes, max_num_instance],\\n                    IOU after suppression.\\n    iou_threshold: A scalar, representing IOU threshold.\\n    loop_condition: Bool Tensor of shape [], the loop condition.\\n    iou_sum_new: The new IOU sum.\\n  '\n    del loop_condition\n    can_suppress_others = tf.cast(tf.reshape(tf.reduce_max(iou, 1) <= iou_threshold, [1, -1, 1]), iou.dtype)\n    iou_suppressed = tf.reshape(tf.cast(tf.reduce_max(can_suppress_others * iou, 1) <= iou_threshold, iou.dtype), [1, -1, 1]) * iou\n    iou_sum_new = tf.reduce_sum(iou_suppressed, [1, 2])\n    return [iou_suppressed, iou_threshold, tf.reduce_any(iou_sum - iou_sum_new > iou_threshold), iou_sum_new]",
            "def _self_suppression(iou, iou_threshold, loop_condition, iou_sum):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Bounding-boxes self-suppression loop body.\\n\\n  Args:\\n    iou: A float Tensor with shape [1, num_boxes, max_num_instance]: IOUs.\\n    iou_threshold: A scalar, representing IOU threshold.\\n    loop_condition: The loop condition returned from last iteration.\\n    iou_sum: iou_sum_new returned from last iteration.\\n\\n  Returns:\\n    iou_suppressed: A float Tensor with shape [1, num_boxes, max_num_instance],\\n                    IOU after suppression.\\n    iou_threshold: A scalar, representing IOU threshold.\\n    loop_condition: Bool Tensor of shape [], the loop condition.\\n    iou_sum_new: The new IOU sum.\\n  '\n    del loop_condition\n    can_suppress_others = tf.cast(tf.reshape(tf.reduce_max(iou, 1) <= iou_threshold, [1, -1, 1]), iou.dtype)\n    iou_suppressed = tf.reshape(tf.cast(tf.reduce_max(can_suppress_others * iou, 1) <= iou_threshold, iou.dtype), [1, -1, 1]) * iou\n    iou_sum_new = tf.reduce_sum(iou_suppressed, [1, 2])\n    return [iou_suppressed, iou_threshold, tf.reduce_any(iou_sum - iou_sum_new > iou_threshold), iou_sum_new]",
            "def _self_suppression(iou, iou_threshold, loop_condition, iou_sum):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Bounding-boxes self-suppression loop body.\\n\\n  Args:\\n    iou: A float Tensor with shape [1, num_boxes, max_num_instance]: IOUs.\\n    iou_threshold: A scalar, representing IOU threshold.\\n    loop_condition: The loop condition returned from last iteration.\\n    iou_sum: iou_sum_new returned from last iteration.\\n\\n  Returns:\\n    iou_suppressed: A float Tensor with shape [1, num_boxes, max_num_instance],\\n                    IOU after suppression.\\n    iou_threshold: A scalar, representing IOU threshold.\\n    loop_condition: Bool Tensor of shape [], the loop condition.\\n    iou_sum_new: The new IOU sum.\\n  '\n    del loop_condition\n    can_suppress_others = tf.cast(tf.reshape(tf.reduce_max(iou, 1) <= iou_threshold, [1, -1, 1]), iou.dtype)\n    iou_suppressed = tf.reshape(tf.cast(tf.reduce_max(can_suppress_others * iou, 1) <= iou_threshold, iou.dtype), [1, -1, 1]) * iou\n    iou_sum_new = tf.reduce_sum(iou_suppressed, [1, 2])\n    return [iou_suppressed, iou_threshold, tf.reduce_any(iou_sum - iou_sum_new > iou_threshold), iou_sum_new]",
            "def _self_suppression(iou, iou_threshold, loop_condition, iou_sum):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Bounding-boxes self-suppression loop body.\\n\\n  Args:\\n    iou: A float Tensor with shape [1, num_boxes, max_num_instance]: IOUs.\\n    iou_threshold: A scalar, representing IOU threshold.\\n    loop_condition: The loop condition returned from last iteration.\\n    iou_sum: iou_sum_new returned from last iteration.\\n\\n  Returns:\\n    iou_suppressed: A float Tensor with shape [1, num_boxes, max_num_instance],\\n                    IOU after suppression.\\n    iou_threshold: A scalar, representing IOU threshold.\\n    loop_condition: Bool Tensor of shape [], the loop condition.\\n    iou_sum_new: The new IOU sum.\\n  '\n    del loop_condition\n    can_suppress_others = tf.cast(tf.reshape(tf.reduce_max(iou, 1) <= iou_threshold, [1, -1, 1]), iou.dtype)\n    iou_suppressed = tf.reshape(tf.cast(tf.reduce_max(can_suppress_others * iou, 1) <= iou_threshold, iou.dtype), [1, -1, 1]) * iou\n    iou_sum_new = tf.reduce_sum(iou_suppressed, [1, 2])\n    return [iou_suppressed, iou_threshold, tf.reduce_any(iou_sum - iou_sum_new > iou_threshold), iou_sum_new]",
            "def _self_suppression(iou, iou_threshold, loop_condition, iou_sum):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Bounding-boxes self-suppression loop body.\\n\\n  Args:\\n    iou: A float Tensor with shape [1, num_boxes, max_num_instance]: IOUs.\\n    iou_threshold: A scalar, representing IOU threshold.\\n    loop_condition: The loop condition returned from last iteration.\\n    iou_sum: iou_sum_new returned from last iteration.\\n\\n  Returns:\\n    iou_suppressed: A float Tensor with shape [1, num_boxes, max_num_instance],\\n                    IOU after suppression.\\n    iou_threshold: A scalar, representing IOU threshold.\\n    loop_condition: Bool Tensor of shape [], the loop condition.\\n    iou_sum_new: The new IOU sum.\\n  '\n    del loop_condition\n    can_suppress_others = tf.cast(tf.reshape(tf.reduce_max(iou, 1) <= iou_threshold, [1, -1, 1]), iou.dtype)\n    iou_suppressed = tf.reshape(tf.cast(tf.reduce_max(can_suppress_others * iou, 1) <= iou_threshold, iou.dtype), [1, -1, 1]) * iou\n    iou_sum_new = tf.reduce_sum(iou_suppressed, [1, 2])\n    return [iou_suppressed, iou_threshold, tf.reduce_any(iou_sum - iou_sum_new > iou_threshold), iou_sum_new]"
        ]
    },
    {
        "func_name": "_cross_suppression",
        "original": "def _cross_suppression(boxes, box_slice, iou_threshold, inner_idx):\n    \"\"\"Bounding-boxes cross-suppression loop body.\n\n  Args:\n    boxes: A float Tensor of shape [1, anchors, 4], representing boxes.\n    box_slice: A float Tensor of shape [1, _NMS_TILE_SIZE, 4], the box tile\n      returned from last iteration\n    iou_threshold: A scalar, representing IOU threshold.\n    inner_idx: A scalar, representing inner index.\n\n  Returns:\n    boxes: A float Tensor of shape [1, anchors, 4], representing boxes.\n    ret_slice: A float Tensor of shape [1, _NMS_TILE_SIZE, 4], the box tile\n               after suppression\n    iou_threshold: A scalar, representing IOU threshold.\n    inner_idx: A scalar, inner index incremented.\n  \"\"\"\n    new_slice = tf.slice(boxes, [0, inner_idx * _NMS_TILE_SIZE, 0], [1, _NMS_TILE_SIZE, 4])\n    iou = batch_iou(new_slice, box_slice)\n    ret_slice = tf.expand_dims(tf.cast(tf.reduce_all(iou < iou_threshold, [1]), box_slice.dtype), 2) * box_slice\n    return (boxes, ret_slice, iou_threshold, inner_idx + 1)",
        "mutated": [
            "def _cross_suppression(boxes, box_slice, iou_threshold, inner_idx):\n    if False:\n        i = 10\n    'Bounding-boxes cross-suppression loop body.\\n\\n  Args:\\n    boxes: A float Tensor of shape [1, anchors, 4], representing boxes.\\n    box_slice: A float Tensor of shape [1, _NMS_TILE_SIZE, 4], the box tile\\n      returned from last iteration\\n    iou_threshold: A scalar, representing IOU threshold.\\n    inner_idx: A scalar, representing inner index.\\n\\n  Returns:\\n    boxes: A float Tensor of shape [1, anchors, 4], representing boxes.\\n    ret_slice: A float Tensor of shape [1, _NMS_TILE_SIZE, 4], the box tile\\n               after suppression\\n    iou_threshold: A scalar, representing IOU threshold.\\n    inner_idx: A scalar, inner index incremented.\\n  '\n    new_slice = tf.slice(boxes, [0, inner_idx * _NMS_TILE_SIZE, 0], [1, _NMS_TILE_SIZE, 4])\n    iou = batch_iou(new_slice, box_slice)\n    ret_slice = tf.expand_dims(tf.cast(tf.reduce_all(iou < iou_threshold, [1]), box_slice.dtype), 2) * box_slice\n    return (boxes, ret_slice, iou_threshold, inner_idx + 1)",
            "def _cross_suppression(boxes, box_slice, iou_threshold, inner_idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Bounding-boxes cross-suppression loop body.\\n\\n  Args:\\n    boxes: A float Tensor of shape [1, anchors, 4], representing boxes.\\n    box_slice: A float Tensor of shape [1, _NMS_TILE_SIZE, 4], the box tile\\n      returned from last iteration\\n    iou_threshold: A scalar, representing IOU threshold.\\n    inner_idx: A scalar, representing inner index.\\n\\n  Returns:\\n    boxes: A float Tensor of shape [1, anchors, 4], representing boxes.\\n    ret_slice: A float Tensor of shape [1, _NMS_TILE_SIZE, 4], the box tile\\n               after suppression\\n    iou_threshold: A scalar, representing IOU threshold.\\n    inner_idx: A scalar, inner index incremented.\\n  '\n    new_slice = tf.slice(boxes, [0, inner_idx * _NMS_TILE_SIZE, 0], [1, _NMS_TILE_SIZE, 4])\n    iou = batch_iou(new_slice, box_slice)\n    ret_slice = tf.expand_dims(tf.cast(tf.reduce_all(iou < iou_threshold, [1]), box_slice.dtype), 2) * box_slice\n    return (boxes, ret_slice, iou_threshold, inner_idx + 1)",
            "def _cross_suppression(boxes, box_slice, iou_threshold, inner_idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Bounding-boxes cross-suppression loop body.\\n\\n  Args:\\n    boxes: A float Tensor of shape [1, anchors, 4], representing boxes.\\n    box_slice: A float Tensor of shape [1, _NMS_TILE_SIZE, 4], the box tile\\n      returned from last iteration\\n    iou_threshold: A scalar, representing IOU threshold.\\n    inner_idx: A scalar, representing inner index.\\n\\n  Returns:\\n    boxes: A float Tensor of shape [1, anchors, 4], representing boxes.\\n    ret_slice: A float Tensor of shape [1, _NMS_TILE_SIZE, 4], the box tile\\n               after suppression\\n    iou_threshold: A scalar, representing IOU threshold.\\n    inner_idx: A scalar, inner index incremented.\\n  '\n    new_slice = tf.slice(boxes, [0, inner_idx * _NMS_TILE_SIZE, 0], [1, _NMS_TILE_SIZE, 4])\n    iou = batch_iou(new_slice, box_slice)\n    ret_slice = tf.expand_dims(tf.cast(tf.reduce_all(iou < iou_threshold, [1]), box_slice.dtype), 2) * box_slice\n    return (boxes, ret_slice, iou_threshold, inner_idx + 1)",
            "def _cross_suppression(boxes, box_slice, iou_threshold, inner_idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Bounding-boxes cross-suppression loop body.\\n\\n  Args:\\n    boxes: A float Tensor of shape [1, anchors, 4], representing boxes.\\n    box_slice: A float Tensor of shape [1, _NMS_TILE_SIZE, 4], the box tile\\n      returned from last iteration\\n    iou_threshold: A scalar, representing IOU threshold.\\n    inner_idx: A scalar, representing inner index.\\n\\n  Returns:\\n    boxes: A float Tensor of shape [1, anchors, 4], representing boxes.\\n    ret_slice: A float Tensor of shape [1, _NMS_TILE_SIZE, 4], the box tile\\n               after suppression\\n    iou_threshold: A scalar, representing IOU threshold.\\n    inner_idx: A scalar, inner index incremented.\\n  '\n    new_slice = tf.slice(boxes, [0, inner_idx * _NMS_TILE_SIZE, 0], [1, _NMS_TILE_SIZE, 4])\n    iou = batch_iou(new_slice, box_slice)\n    ret_slice = tf.expand_dims(tf.cast(tf.reduce_all(iou < iou_threshold, [1]), box_slice.dtype), 2) * box_slice\n    return (boxes, ret_slice, iou_threshold, inner_idx + 1)",
            "def _cross_suppression(boxes, box_slice, iou_threshold, inner_idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Bounding-boxes cross-suppression loop body.\\n\\n  Args:\\n    boxes: A float Tensor of shape [1, anchors, 4], representing boxes.\\n    box_slice: A float Tensor of shape [1, _NMS_TILE_SIZE, 4], the box tile\\n      returned from last iteration\\n    iou_threshold: A scalar, representing IOU threshold.\\n    inner_idx: A scalar, representing inner index.\\n\\n  Returns:\\n    boxes: A float Tensor of shape [1, anchors, 4], representing boxes.\\n    ret_slice: A float Tensor of shape [1, _NMS_TILE_SIZE, 4], the box tile\\n               after suppression\\n    iou_threshold: A scalar, representing IOU threshold.\\n    inner_idx: A scalar, inner index incremented.\\n  '\n    new_slice = tf.slice(boxes, [0, inner_idx * _NMS_TILE_SIZE, 0], [1, _NMS_TILE_SIZE, 4])\n    iou = batch_iou(new_slice, box_slice)\n    ret_slice = tf.expand_dims(tf.cast(tf.reduce_all(iou < iou_threshold, [1]), box_slice.dtype), 2) * box_slice\n    return (boxes, ret_slice, iou_threshold, inner_idx + 1)"
        ]
    },
    {
        "func_name": "_suppression_loop_body",
        "original": "def _suppression_loop_body(boxes, iou_threshold, output_size, idx):\n    \"\"\"Process boxes in the range [idx*_NMS_TILE_SIZE, (idx+1)*_NMS_TILE_SIZE).\n\n  Args:\n    boxes: a tensor with a shape of [1, anchors, 4].\n    iou_threshold: a float representing the threshold for deciding whether boxes\n      overlap too much with respect to IOU.\n    output_size: an int32 tensor of size [1]. Representing the number of\n      selected boxes.\n    idx: an integer scalar representing induction variable.\n\n  Returns:\n    boxes: updated boxes.\n    iou_threshold: pass down iou_threshold to the next iteration.\n    output_size: the updated output_size.\n    idx: the updated induction variable.\n  \"\"\"\n    num_tiles = tf.shape(boxes)[1] // _NMS_TILE_SIZE\n    box_slice = tf.slice(boxes, [0, idx * _NMS_TILE_SIZE, 0], [1, _NMS_TILE_SIZE, 4])\n    (_, box_slice, _, _) = tf.while_loop(lambda _boxes, _box_slice, _threshold, inner_idx: inner_idx < idx, _cross_suppression, [boxes, box_slice, iou_threshold, tf.constant(0)])\n    iou = batch_iou(box_slice, box_slice)\n    mask = tf.expand_dims(tf.reshape(tf.range(_NMS_TILE_SIZE), [1, -1]) > tf.reshape(tf.range(_NMS_TILE_SIZE), [-1, 1]), 0)\n    iou *= tf.cast(tf.logical_and(mask, iou >= iou_threshold), iou.dtype)\n    (suppressed_iou, _, _, _) = tf.while_loop(lambda _iou, _threshold, loop_condition, _iou_sum: loop_condition, _self_suppression, [iou, iou_threshold, tf.constant(True), tf.reduce_sum(iou, [1, 2])])\n    suppressed_box = tf.reduce_sum(suppressed_iou, 1) > 0\n    box_slice *= tf.expand_dims(1.0 - tf.cast(suppressed_box, box_slice.dtype), 2)\n    mask = tf.reshape(tf.cast(tf.equal(tf.range(num_tiles), idx), boxes.dtype), [1, -1, 1, 1])\n    boxes = tf.tile(tf.expand_dims(box_slice, [1]), [1, num_tiles, 1, 1]) * mask + tf.reshape(boxes, [1, num_tiles, _NMS_TILE_SIZE, 4]) * (1 - mask)\n    boxes = tf.reshape(boxes, [1, -1, 4])\n    output_size += tf.reduce_sum(tf.cast(tf.reduce_any(box_slice > 0, [2]), tf.int32), [1])\n    return (boxes, iou_threshold, output_size, idx + 1)",
        "mutated": [
            "def _suppression_loop_body(boxes, iou_threshold, output_size, idx):\n    if False:\n        i = 10\n    'Process boxes in the range [idx*_NMS_TILE_SIZE, (idx+1)*_NMS_TILE_SIZE).\\n\\n  Args:\\n    boxes: a tensor with a shape of [1, anchors, 4].\\n    iou_threshold: a float representing the threshold for deciding whether boxes\\n      overlap too much with respect to IOU.\\n    output_size: an int32 tensor of size [1]. Representing the number of\\n      selected boxes.\\n    idx: an integer scalar representing induction variable.\\n\\n  Returns:\\n    boxes: updated boxes.\\n    iou_threshold: pass down iou_threshold to the next iteration.\\n    output_size: the updated output_size.\\n    idx: the updated induction variable.\\n  '\n    num_tiles = tf.shape(boxes)[1] // _NMS_TILE_SIZE\n    box_slice = tf.slice(boxes, [0, idx * _NMS_TILE_SIZE, 0], [1, _NMS_TILE_SIZE, 4])\n    (_, box_slice, _, _) = tf.while_loop(lambda _boxes, _box_slice, _threshold, inner_idx: inner_idx < idx, _cross_suppression, [boxes, box_slice, iou_threshold, tf.constant(0)])\n    iou = batch_iou(box_slice, box_slice)\n    mask = tf.expand_dims(tf.reshape(tf.range(_NMS_TILE_SIZE), [1, -1]) > tf.reshape(tf.range(_NMS_TILE_SIZE), [-1, 1]), 0)\n    iou *= tf.cast(tf.logical_and(mask, iou >= iou_threshold), iou.dtype)\n    (suppressed_iou, _, _, _) = tf.while_loop(lambda _iou, _threshold, loop_condition, _iou_sum: loop_condition, _self_suppression, [iou, iou_threshold, tf.constant(True), tf.reduce_sum(iou, [1, 2])])\n    suppressed_box = tf.reduce_sum(suppressed_iou, 1) > 0\n    box_slice *= tf.expand_dims(1.0 - tf.cast(suppressed_box, box_slice.dtype), 2)\n    mask = tf.reshape(tf.cast(tf.equal(tf.range(num_tiles), idx), boxes.dtype), [1, -1, 1, 1])\n    boxes = tf.tile(tf.expand_dims(box_slice, [1]), [1, num_tiles, 1, 1]) * mask + tf.reshape(boxes, [1, num_tiles, _NMS_TILE_SIZE, 4]) * (1 - mask)\n    boxes = tf.reshape(boxes, [1, -1, 4])\n    output_size += tf.reduce_sum(tf.cast(tf.reduce_any(box_slice > 0, [2]), tf.int32), [1])\n    return (boxes, iou_threshold, output_size, idx + 1)",
            "def _suppression_loop_body(boxes, iou_threshold, output_size, idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Process boxes in the range [idx*_NMS_TILE_SIZE, (idx+1)*_NMS_TILE_SIZE).\\n\\n  Args:\\n    boxes: a tensor with a shape of [1, anchors, 4].\\n    iou_threshold: a float representing the threshold for deciding whether boxes\\n      overlap too much with respect to IOU.\\n    output_size: an int32 tensor of size [1]. Representing the number of\\n      selected boxes.\\n    idx: an integer scalar representing induction variable.\\n\\n  Returns:\\n    boxes: updated boxes.\\n    iou_threshold: pass down iou_threshold to the next iteration.\\n    output_size: the updated output_size.\\n    idx: the updated induction variable.\\n  '\n    num_tiles = tf.shape(boxes)[1] // _NMS_TILE_SIZE\n    box_slice = tf.slice(boxes, [0, idx * _NMS_TILE_SIZE, 0], [1, _NMS_TILE_SIZE, 4])\n    (_, box_slice, _, _) = tf.while_loop(lambda _boxes, _box_slice, _threshold, inner_idx: inner_idx < idx, _cross_suppression, [boxes, box_slice, iou_threshold, tf.constant(0)])\n    iou = batch_iou(box_slice, box_slice)\n    mask = tf.expand_dims(tf.reshape(tf.range(_NMS_TILE_SIZE), [1, -1]) > tf.reshape(tf.range(_NMS_TILE_SIZE), [-1, 1]), 0)\n    iou *= tf.cast(tf.logical_and(mask, iou >= iou_threshold), iou.dtype)\n    (suppressed_iou, _, _, _) = tf.while_loop(lambda _iou, _threshold, loop_condition, _iou_sum: loop_condition, _self_suppression, [iou, iou_threshold, tf.constant(True), tf.reduce_sum(iou, [1, 2])])\n    suppressed_box = tf.reduce_sum(suppressed_iou, 1) > 0\n    box_slice *= tf.expand_dims(1.0 - tf.cast(suppressed_box, box_slice.dtype), 2)\n    mask = tf.reshape(tf.cast(tf.equal(tf.range(num_tiles), idx), boxes.dtype), [1, -1, 1, 1])\n    boxes = tf.tile(tf.expand_dims(box_slice, [1]), [1, num_tiles, 1, 1]) * mask + tf.reshape(boxes, [1, num_tiles, _NMS_TILE_SIZE, 4]) * (1 - mask)\n    boxes = tf.reshape(boxes, [1, -1, 4])\n    output_size += tf.reduce_sum(tf.cast(tf.reduce_any(box_slice > 0, [2]), tf.int32), [1])\n    return (boxes, iou_threshold, output_size, idx + 1)",
            "def _suppression_loop_body(boxes, iou_threshold, output_size, idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Process boxes in the range [idx*_NMS_TILE_SIZE, (idx+1)*_NMS_TILE_SIZE).\\n\\n  Args:\\n    boxes: a tensor with a shape of [1, anchors, 4].\\n    iou_threshold: a float representing the threshold for deciding whether boxes\\n      overlap too much with respect to IOU.\\n    output_size: an int32 tensor of size [1]. Representing the number of\\n      selected boxes.\\n    idx: an integer scalar representing induction variable.\\n\\n  Returns:\\n    boxes: updated boxes.\\n    iou_threshold: pass down iou_threshold to the next iteration.\\n    output_size: the updated output_size.\\n    idx: the updated induction variable.\\n  '\n    num_tiles = tf.shape(boxes)[1] // _NMS_TILE_SIZE\n    box_slice = tf.slice(boxes, [0, idx * _NMS_TILE_SIZE, 0], [1, _NMS_TILE_SIZE, 4])\n    (_, box_slice, _, _) = tf.while_loop(lambda _boxes, _box_slice, _threshold, inner_idx: inner_idx < idx, _cross_suppression, [boxes, box_slice, iou_threshold, tf.constant(0)])\n    iou = batch_iou(box_slice, box_slice)\n    mask = tf.expand_dims(tf.reshape(tf.range(_NMS_TILE_SIZE), [1, -1]) > tf.reshape(tf.range(_NMS_TILE_SIZE), [-1, 1]), 0)\n    iou *= tf.cast(tf.logical_and(mask, iou >= iou_threshold), iou.dtype)\n    (suppressed_iou, _, _, _) = tf.while_loop(lambda _iou, _threshold, loop_condition, _iou_sum: loop_condition, _self_suppression, [iou, iou_threshold, tf.constant(True), tf.reduce_sum(iou, [1, 2])])\n    suppressed_box = tf.reduce_sum(suppressed_iou, 1) > 0\n    box_slice *= tf.expand_dims(1.0 - tf.cast(suppressed_box, box_slice.dtype), 2)\n    mask = tf.reshape(tf.cast(tf.equal(tf.range(num_tiles), idx), boxes.dtype), [1, -1, 1, 1])\n    boxes = tf.tile(tf.expand_dims(box_slice, [1]), [1, num_tiles, 1, 1]) * mask + tf.reshape(boxes, [1, num_tiles, _NMS_TILE_SIZE, 4]) * (1 - mask)\n    boxes = tf.reshape(boxes, [1, -1, 4])\n    output_size += tf.reduce_sum(tf.cast(tf.reduce_any(box_slice > 0, [2]), tf.int32), [1])\n    return (boxes, iou_threshold, output_size, idx + 1)",
            "def _suppression_loop_body(boxes, iou_threshold, output_size, idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Process boxes in the range [idx*_NMS_TILE_SIZE, (idx+1)*_NMS_TILE_SIZE).\\n\\n  Args:\\n    boxes: a tensor with a shape of [1, anchors, 4].\\n    iou_threshold: a float representing the threshold for deciding whether boxes\\n      overlap too much with respect to IOU.\\n    output_size: an int32 tensor of size [1]. Representing the number of\\n      selected boxes.\\n    idx: an integer scalar representing induction variable.\\n\\n  Returns:\\n    boxes: updated boxes.\\n    iou_threshold: pass down iou_threshold to the next iteration.\\n    output_size: the updated output_size.\\n    idx: the updated induction variable.\\n  '\n    num_tiles = tf.shape(boxes)[1] // _NMS_TILE_SIZE\n    box_slice = tf.slice(boxes, [0, idx * _NMS_TILE_SIZE, 0], [1, _NMS_TILE_SIZE, 4])\n    (_, box_slice, _, _) = tf.while_loop(lambda _boxes, _box_slice, _threshold, inner_idx: inner_idx < idx, _cross_suppression, [boxes, box_slice, iou_threshold, tf.constant(0)])\n    iou = batch_iou(box_slice, box_slice)\n    mask = tf.expand_dims(tf.reshape(tf.range(_NMS_TILE_SIZE), [1, -1]) > tf.reshape(tf.range(_NMS_TILE_SIZE), [-1, 1]), 0)\n    iou *= tf.cast(tf.logical_and(mask, iou >= iou_threshold), iou.dtype)\n    (suppressed_iou, _, _, _) = tf.while_loop(lambda _iou, _threshold, loop_condition, _iou_sum: loop_condition, _self_suppression, [iou, iou_threshold, tf.constant(True), tf.reduce_sum(iou, [1, 2])])\n    suppressed_box = tf.reduce_sum(suppressed_iou, 1) > 0\n    box_slice *= tf.expand_dims(1.0 - tf.cast(suppressed_box, box_slice.dtype), 2)\n    mask = tf.reshape(tf.cast(tf.equal(tf.range(num_tiles), idx), boxes.dtype), [1, -1, 1, 1])\n    boxes = tf.tile(tf.expand_dims(box_slice, [1]), [1, num_tiles, 1, 1]) * mask + tf.reshape(boxes, [1, num_tiles, _NMS_TILE_SIZE, 4]) * (1 - mask)\n    boxes = tf.reshape(boxes, [1, -1, 4])\n    output_size += tf.reduce_sum(tf.cast(tf.reduce_any(box_slice > 0, [2]), tf.int32), [1])\n    return (boxes, iou_threshold, output_size, idx + 1)",
            "def _suppression_loop_body(boxes, iou_threshold, output_size, idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Process boxes in the range [idx*_NMS_TILE_SIZE, (idx+1)*_NMS_TILE_SIZE).\\n\\n  Args:\\n    boxes: a tensor with a shape of [1, anchors, 4].\\n    iou_threshold: a float representing the threshold for deciding whether boxes\\n      overlap too much with respect to IOU.\\n    output_size: an int32 tensor of size [1]. Representing the number of\\n      selected boxes.\\n    idx: an integer scalar representing induction variable.\\n\\n  Returns:\\n    boxes: updated boxes.\\n    iou_threshold: pass down iou_threshold to the next iteration.\\n    output_size: the updated output_size.\\n    idx: the updated induction variable.\\n  '\n    num_tiles = tf.shape(boxes)[1] // _NMS_TILE_SIZE\n    box_slice = tf.slice(boxes, [0, idx * _NMS_TILE_SIZE, 0], [1, _NMS_TILE_SIZE, 4])\n    (_, box_slice, _, _) = tf.while_loop(lambda _boxes, _box_slice, _threshold, inner_idx: inner_idx < idx, _cross_suppression, [boxes, box_slice, iou_threshold, tf.constant(0)])\n    iou = batch_iou(box_slice, box_slice)\n    mask = tf.expand_dims(tf.reshape(tf.range(_NMS_TILE_SIZE), [1, -1]) > tf.reshape(tf.range(_NMS_TILE_SIZE), [-1, 1]), 0)\n    iou *= tf.cast(tf.logical_and(mask, iou >= iou_threshold), iou.dtype)\n    (suppressed_iou, _, _, _) = tf.while_loop(lambda _iou, _threshold, loop_condition, _iou_sum: loop_condition, _self_suppression, [iou, iou_threshold, tf.constant(True), tf.reduce_sum(iou, [1, 2])])\n    suppressed_box = tf.reduce_sum(suppressed_iou, 1) > 0\n    box_slice *= tf.expand_dims(1.0 - tf.cast(suppressed_box, box_slice.dtype), 2)\n    mask = tf.reshape(tf.cast(tf.equal(tf.range(num_tiles), idx), boxes.dtype), [1, -1, 1, 1])\n    boxes = tf.tile(tf.expand_dims(box_slice, [1]), [1, num_tiles, 1, 1]) * mask + tf.reshape(boxes, [1, num_tiles, _NMS_TILE_SIZE, 4]) * (1 - mask)\n    boxes = tf.reshape(boxes, [1, -1, 4])\n    output_size += tf.reduce_sum(tf.cast(tf.reduce_any(box_slice > 0, [2]), tf.int32), [1])\n    return (boxes, iou_threshold, output_size, idx + 1)"
        ]
    },
    {
        "func_name": "_loop_cond",
        "original": "def _loop_cond(unused_boxes, unused_threshold, output_size, idx):\n    return tf.logical_and(tf.reduce_min(output_size) < max_output_size, idx < num_boxes // _NMS_TILE_SIZE)",
        "mutated": [
            "def _loop_cond(unused_boxes, unused_threshold, output_size, idx):\n    if False:\n        i = 10\n    return tf.logical_and(tf.reduce_min(output_size) < max_output_size, idx < num_boxes // _NMS_TILE_SIZE)",
            "def _loop_cond(unused_boxes, unused_threshold, output_size, idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return tf.logical_and(tf.reduce_min(output_size) < max_output_size, idx < num_boxes // _NMS_TILE_SIZE)",
            "def _loop_cond(unused_boxes, unused_threshold, output_size, idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return tf.logical_and(tf.reduce_min(output_size) < max_output_size, idx < num_boxes // _NMS_TILE_SIZE)",
            "def _loop_cond(unused_boxes, unused_threshold, output_size, idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return tf.logical_and(tf.reduce_min(output_size) < max_output_size, idx < num_boxes // _NMS_TILE_SIZE)",
            "def _loop_cond(unused_boxes, unused_threshold, output_size, idx):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return tf.logical_and(tf.reduce_min(output_size) < max_output_size, idx < num_boxes // _NMS_TILE_SIZE)"
        ]
    },
    {
        "func_name": "partitioned_non_max_suppression_padded",
        "original": "def partitioned_non_max_suppression_padded(boxes, scores, max_output_size, iou_threshold=0.5, score_threshold=float('-inf')):\n    \"\"\"A tiled version of [`tf.image.non_max_suppression_padded`](https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression_padded).\n\n  The overall design of the algorithm is to handle boxes tile-by-tile:\n\n  boxes = boxes.pad_to_multiple_of(tile_size)\n  num_tiles = len(boxes) // tile_size\n  output_boxes = []\n  for i in range(num_tiles):\n    box_tile = boxes[i*tile_size : (i+1)*tile_size]\n    for j in range(i - 1):\n      suppressing_tile = boxes[j*tile_size : (j+1)*tile_size]\n      iou = batch_iou(box_tile, suppressing_tile)\n      # if the box is suppressed in iou, clear it to a dot\n      box_tile *= _update_boxes(iou)\n    # Iteratively handle the diagonal tile.\n    iou = _box_overlap(box_tile, box_tile)\n    iou_changed = True\n    while iou_changed:\n      # boxes that are not suppressed by anything else\n      suppressing_boxes = _get_suppressing_boxes(iou)\n      # boxes that are suppressed by suppressing_boxes\n      suppressed_boxes = _get_suppressed_boxes(iou, suppressing_boxes)\n      # clear iou to 0 for boxes that are suppressed, as they cannot be used\n      # to suppress other boxes any more\n      new_iou = _clear_iou(iou, suppressed_boxes)\n      iou_changed = (new_iou != iou)\n      iou = new_iou\n    # remaining boxes that can still suppress others, are selected boxes.\n    output_boxes.append(_get_suppressing_boxes(iou))\n    if len(output_boxes) >= max_output_size:\n      break\n\n  Args:\n    boxes: A 2-D float `Tensor` of shape `[num_boxes, 4]`.\n    scores: A 1-D float `Tensor` of shape `[num_boxes]` representing a single\n      score corresponding to each box (each row of boxes).\n    max_output_size: a scalar integer `Tensor` representing the maximum number\n      of boxes to be selected by non max suppression.\n    iou_threshold: a float representing the threshold for deciding whether boxes\n      overlap too much with respect to IOU.\n    score_threshold: A float representing the threshold for deciding when to\n      remove boxes based on score.\n\n  Returns:\n    selected_indices: a tensor of shape [anchors].\n    num_valid_boxes: a scalar int tensor.\n    nms_proposals: a tensor with a shape of [anchors, 4]. It has\n      same dtype as input boxes.\n    nms_scores: a tensor with a shape of [anchors]. It has same\n      dtype as input scores.\n    argsort_ids: a tensor of shape [anchors], mapping from input order of boxes\n      to output order of boxes.\n  \"\"\"\n    num_boxes = tf.shape(boxes)[0]\n    pad = tf.cast(tf.ceil(tf.cast(num_boxes, tf.float32) / _NMS_TILE_SIZE), tf.int32) * _NMS_TILE_SIZE - num_boxes\n    (scores, argsort_ids) = tf.nn.top_k(scores, k=num_boxes, sorted=True)\n    boxes = tf.gather(boxes, argsort_ids)\n    num_boxes = tf.shape(boxes)[0]\n    num_boxes += pad\n    boxes = tf.pad(tf.cast(boxes, tf.float32), [[0, pad], [0, 0]], constant_values=-1)\n    scores = tf.pad(tf.cast(scores, tf.float32), [[0, pad]])\n    scores_mask = tf.expand_dims(tf.cast(scores > score_threshold, boxes.dtype), axis=1)\n    boxes = (boxes + 1.0) * scores_mask - 1.0\n    boxes = tf.expand_dims(boxes, axis=0)\n    scores = tf.expand_dims(scores, axis=0)\n\n    def _loop_cond(unused_boxes, unused_threshold, output_size, idx):\n        return tf.logical_and(tf.reduce_min(output_size) < max_output_size, idx < num_boxes // _NMS_TILE_SIZE)\n    (selected_boxes, _, output_size, _) = tf.while_loop(_loop_cond, _suppression_loop_body, [boxes, iou_threshold, tf.zeros([1], tf.int32), tf.constant(0)])\n    idx = num_boxes - tf.cast(tf.nn.top_k(tf.cast(tf.reduce_any(selected_boxes > 0, [2]), tf.int32) * tf.expand_dims(tf.range(num_boxes, 0, -1), 0), max_output_size)[0], tf.int32)\n    idx = tf.minimum(idx, num_boxes - 1 - pad)\n    idx = tf.reshape(idx + tf.reshape(tf.range(1) * num_boxes, [-1, 1]), [-1])\n    num_valid_boxes = tf.reduce_sum(output_size)\n    return (idx, num_valid_boxes, tf.reshape(boxes, [-1, 4]), tf.reshape(scores, [-1]), argsort_ids)",
        "mutated": [
            "def partitioned_non_max_suppression_padded(boxes, scores, max_output_size, iou_threshold=0.5, score_threshold=float('-inf')):\n    if False:\n        i = 10\n    'A tiled version of [`tf.image.non_max_suppression_padded`](https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression_padded).\\n\\n  The overall design of the algorithm is to handle boxes tile-by-tile:\\n\\n  boxes = boxes.pad_to_multiple_of(tile_size)\\n  num_tiles = len(boxes) // tile_size\\n  output_boxes = []\\n  for i in range(num_tiles):\\n    box_tile = boxes[i*tile_size : (i+1)*tile_size]\\n    for j in range(i - 1):\\n      suppressing_tile = boxes[j*tile_size : (j+1)*tile_size]\\n      iou = batch_iou(box_tile, suppressing_tile)\\n      # if the box is suppressed in iou, clear it to a dot\\n      box_tile *= _update_boxes(iou)\\n    # Iteratively handle the diagonal tile.\\n    iou = _box_overlap(box_tile, box_tile)\\n    iou_changed = True\\n    while iou_changed:\\n      # boxes that are not suppressed by anything else\\n      suppressing_boxes = _get_suppressing_boxes(iou)\\n      # boxes that are suppressed by suppressing_boxes\\n      suppressed_boxes = _get_suppressed_boxes(iou, suppressing_boxes)\\n      # clear iou to 0 for boxes that are suppressed, as they cannot be used\\n      # to suppress other boxes any more\\n      new_iou = _clear_iou(iou, suppressed_boxes)\\n      iou_changed = (new_iou != iou)\\n      iou = new_iou\\n    # remaining boxes that can still suppress others, are selected boxes.\\n    output_boxes.append(_get_suppressing_boxes(iou))\\n    if len(output_boxes) >= max_output_size:\\n      break\\n\\n  Args:\\n    boxes: A 2-D float `Tensor` of shape `[num_boxes, 4]`.\\n    scores: A 1-D float `Tensor` of shape `[num_boxes]` representing a single\\n      score corresponding to each box (each row of boxes).\\n    max_output_size: a scalar integer `Tensor` representing the maximum number\\n      of boxes to be selected by non max suppression.\\n    iou_threshold: a float representing the threshold for deciding whether boxes\\n      overlap too much with respect to IOU.\\n    score_threshold: A float representing the threshold for deciding when to\\n      remove boxes based on score.\\n\\n  Returns:\\n    selected_indices: a tensor of shape [anchors].\\n    num_valid_boxes: a scalar int tensor.\\n    nms_proposals: a tensor with a shape of [anchors, 4]. It has\\n      same dtype as input boxes.\\n    nms_scores: a tensor with a shape of [anchors]. It has same\\n      dtype as input scores.\\n    argsort_ids: a tensor of shape [anchors], mapping from input order of boxes\\n      to output order of boxes.\\n  '\n    num_boxes = tf.shape(boxes)[0]\n    pad = tf.cast(tf.ceil(tf.cast(num_boxes, tf.float32) / _NMS_TILE_SIZE), tf.int32) * _NMS_TILE_SIZE - num_boxes\n    (scores, argsort_ids) = tf.nn.top_k(scores, k=num_boxes, sorted=True)\n    boxes = tf.gather(boxes, argsort_ids)\n    num_boxes = tf.shape(boxes)[0]\n    num_boxes += pad\n    boxes = tf.pad(tf.cast(boxes, tf.float32), [[0, pad], [0, 0]], constant_values=-1)\n    scores = tf.pad(tf.cast(scores, tf.float32), [[0, pad]])\n    scores_mask = tf.expand_dims(tf.cast(scores > score_threshold, boxes.dtype), axis=1)\n    boxes = (boxes + 1.0) * scores_mask - 1.0\n    boxes = tf.expand_dims(boxes, axis=0)\n    scores = tf.expand_dims(scores, axis=0)\n\n    def _loop_cond(unused_boxes, unused_threshold, output_size, idx):\n        return tf.logical_and(tf.reduce_min(output_size) < max_output_size, idx < num_boxes // _NMS_TILE_SIZE)\n    (selected_boxes, _, output_size, _) = tf.while_loop(_loop_cond, _suppression_loop_body, [boxes, iou_threshold, tf.zeros([1], tf.int32), tf.constant(0)])\n    idx = num_boxes - tf.cast(tf.nn.top_k(tf.cast(tf.reduce_any(selected_boxes > 0, [2]), tf.int32) * tf.expand_dims(tf.range(num_boxes, 0, -1), 0), max_output_size)[0], tf.int32)\n    idx = tf.minimum(idx, num_boxes - 1 - pad)\n    idx = tf.reshape(idx + tf.reshape(tf.range(1) * num_boxes, [-1, 1]), [-1])\n    num_valid_boxes = tf.reduce_sum(output_size)\n    return (idx, num_valid_boxes, tf.reshape(boxes, [-1, 4]), tf.reshape(scores, [-1]), argsort_ids)",
            "def partitioned_non_max_suppression_padded(boxes, scores, max_output_size, iou_threshold=0.5, score_threshold=float('-inf')):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'A tiled version of [`tf.image.non_max_suppression_padded`](https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression_padded).\\n\\n  The overall design of the algorithm is to handle boxes tile-by-tile:\\n\\n  boxes = boxes.pad_to_multiple_of(tile_size)\\n  num_tiles = len(boxes) // tile_size\\n  output_boxes = []\\n  for i in range(num_tiles):\\n    box_tile = boxes[i*tile_size : (i+1)*tile_size]\\n    for j in range(i - 1):\\n      suppressing_tile = boxes[j*tile_size : (j+1)*tile_size]\\n      iou = batch_iou(box_tile, suppressing_tile)\\n      # if the box is suppressed in iou, clear it to a dot\\n      box_tile *= _update_boxes(iou)\\n    # Iteratively handle the diagonal tile.\\n    iou = _box_overlap(box_tile, box_tile)\\n    iou_changed = True\\n    while iou_changed:\\n      # boxes that are not suppressed by anything else\\n      suppressing_boxes = _get_suppressing_boxes(iou)\\n      # boxes that are suppressed by suppressing_boxes\\n      suppressed_boxes = _get_suppressed_boxes(iou, suppressing_boxes)\\n      # clear iou to 0 for boxes that are suppressed, as they cannot be used\\n      # to suppress other boxes any more\\n      new_iou = _clear_iou(iou, suppressed_boxes)\\n      iou_changed = (new_iou != iou)\\n      iou = new_iou\\n    # remaining boxes that can still suppress others, are selected boxes.\\n    output_boxes.append(_get_suppressing_boxes(iou))\\n    if len(output_boxes) >= max_output_size:\\n      break\\n\\n  Args:\\n    boxes: A 2-D float `Tensor` of shape `[num_boxes, 4]`.\\n    scores: A 1-D float `Tensor` of shape `[num_boxes]` representing a single\\n      score corresponding to each box (each row of boxes).\\n    max_output_size: a scalar integer `Tensor` representing the maximum number\\n      of boxes to be selected by non max suppression.\\n    iou_threshold: a float representing the threshold for deciding whether boxes\\n      overlap too much with respect to IOU.\\n    score_threshold: A float representing the threshold for deciding when to\\n      remove boxes based on score.\\n\\n  Returns:\\n    selected_indices: a tensor of shape [anchors].\\n    num_valid_boxes: a scalar int tensor.\\n    nms_proposals: a tensor with a shape of [anchors, 4]. It has\\n      same dtype as input boxes.\\n    nms_scores: a tensor with a shape of [anchors]. It has same\\n      dtype as input scores.\\n    argsort_ids: a tensor of shape [anchors], mapping from input order of boxes\\n      to output order of boxes.\\n  '\n    num_boxes = tf.shape(boxes)[0]\n    pad = tf.cast(tf.ceil(tf.cast(num_boxes, tf.float32) / _NMS_TILE_SIZE), tf.int32) * _NMS_TILE_SIZE - num_boxes\n    (scores, argsort_ids) = tf.nn.top_k(scores, k=num_boxes, sorted=True)\n    boxes = tf.gather(boxes, argsort_ids)\n    num_boxes = tf.shape(boxes)[0]\n    num_boxes += pad\n    boxes = tf.pad(tf.cast(boxes, tf.float32), [[0, pad], [0, 0]], constant_values=-1)\n    scores = tf.pad(tf.cast(scores, tf.float32), [[0, pad]])\n    scores_mask = tf.expand_dims(tf.cast(scores > score_threshold, boxes.dtype), axis=1)\n    boxes = (boxes + 1.0) * scores_mask - 1.0\n    boxes = tf.expand_dims(boxes, axis=0)\n    scores = tf.expand_dims(scores, axis=0)\n\n    def _loop_cond(unused_boxes, unused_threshold, output_size, idx):\n        return tf.logical_and(tf.reduce_min(output_size) < max_output_size, idx < num_boxes // _NMS_TILE_SIZE)\n    (selected_boxes, _, output_size, _) = tf.while_loop(_loop_cond, _suppression_loop_body, [boxes, iou_threshold, tf.zeros([1], tf.int32), tf.constant(0)])\n    idx = num_boxes - tf.cast(tf.nn.top_k(tf.cast(tf.reduce_any(selected_boxes > 0, [2]), tf.int32) * tf.expand_dims(tf.range(num_boxes, 0, -1), 0), max_output_size)[0], tf.int32)\n    idx = tf.minimum(idx, num_boxes - 1 - pad)\n    idx = tf.reshape(idx + tf.reshape(tf.range(1) * num_boxes, [-1, 1]), [-1])\n    num_valid_boxes = tf.reduce_sum(output_size)\n    return (idx, num_valid_boxes, tf.reshape(boxes, [-1, 4]), tf.reshape(scores, [-1]), argsort_ids)",
            "def partitioned_non_max_suppression_padded(boxes, scores, max_output_size, iou_threshold=0.5, score_threshold=float('-inf')):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'A tiled version of [`tf.image.non_max_suppression_padded`](https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression_padded).\\n\\n  The overall design of the algorithm is to handle boxes tile-by-tile:\\n\\n  boxes = boxes.pad_to_multiple_of(tile_size)\\n  num_tiles = len(boxes) // tile_size\\n  output_boxes = []\\n  for i in range(num_tiles):\\n    box_tile = boxes[i*tile_size : (i+1)*tile_size]\\n    for j in range(i - 1):\\n      suppressing_tile = boxes[j*tile_size : (j+1)*tile_size]\\n      iou = batch_iou(box_tile, suppressing_tile)\\n      # if the box is suppressed in iou, clear it to a dot\\n      box_tile *= _update_boxes(iou)\\n    # Iteratively handle the diagonal tile.\\n    iou = _box_overlap(box_tile, box_tile)\\n    iou_changed = True\\n    while iou_changed:\\n      # boxes that are not suppressed by anything else\\n      suppressing_boxes = _get_suppressing_boxes(iou)\\n      # boxes that are suppressed by suppressing_boxes\\n      suppressed_boxes = _get_suppressed_boxes(iou, suppressing_boxes)\\n      # clear iou to 0 for boxes that are suppressed, as they cannot be used\\n      # to suppress other boxes any more\\n      new_iou = _clear_iou(iou, suppressed_boxes)\\n      iou_changed = (new_iou != iou)\\n      iou = new_iou\\n    # remaining boxes that can still suppress others, are selected boxes.\\n    output_boxes.append(_get_suppressing_boxes(iou))\\n    if len(output_boxes) >= max_output_size:\\n      break\\n\\n  Args:\\n    boxes: A 2-D float `Tensor` of shape `[num_boxes, 4]`.\\n    scores: A 1-D float `Tensor` of shape `[num_boxes]` representing a single\\n      score corresponding to each box (each row of boxes).\\n    max_output_size: a scalar integer `Tensor` representing the maximum number\\n      of boxes to be selected by non max suppression.\\n    iou_threshold: a float representing the threshold for deciding whether boxes\\n      overlap too much with respect to IOU.\\n    score_threshold: A float representing the threshold for deciding when to\\n      remove boxes based on score.\\n\\n  Returns:\\n    selected_indices: a tensor of shape [anchors].\\n    num_valid_boxes: a scalar int tensor.\\n    nms_proposals: a tensor with a shape of [anchors, 4]. It has\\n      same dtype as input boxes.\\n    nms_scores: a tensor with a shape of [anchors]. It has same\\n      dtype as input scores.\\n    argsort_ids: a tensor of shape [anchors], mapping from input order of boxes\\n      to output order of boxes.\\n  '\n    num_boxes = tf.shape(boxes)[0]\n    pad = tf.cast(tf.ceil(tf.cast(num_boxes, tf.float32) / _NMS_TILE_SIZE), tf.int32) * _NMS_TILE_SIZE - num_boxes\n    (scores, argsort_ids) = tf.nn.top_k(scores, k=num_boxes, sorted=True)\n    boxes = tf.gather(boxes, argsort_ids)\n    num_boxes = tf.shape(boxes)[0]\n    num_boxes += pad\n    boxes = tf.pad(tf.cast(boxes, tf.float32), [[0, pad], [0, 0]], constant_values=-1)\n    scores = tf.pad(tf.cast(scores, tf.float32), [[0, pad]])\n    scores_mask = tf.expand_dims(tf.cast(scores > score_threshold, boxes.dtype), axis=1)\n    boxes = (boxes + 1.0) * scores_mask - 1.0\n    boxes = tf.expand_dims(boxes, axis=0)\n    scores = tf.expand_dims(scores, axis=0)\n\n    def _loop_cond(unused_boxes, unused_threshold, output_size, idx):\n        return tf.logical_and(tf.reduce_min(output_size) < max_output_size, idx < num_boxes // _NMS_TILE_SIZE)\n    (selected_boxes, _, output_size, _) = tf.while_loop(_loop_cond, _suppression_loop_body, [boxes, iou_threshold, tf.zeros([1], tf.int32), tf.constant(0)])\n    idx = num_boxes - tf.cast(tf.nn.top_k(tf.cast(tf.reduce_any(selected_boxes > 0, [2]), tf.int32) * tf.expand_dims(tf.range(num_boxes, 0, -1), 0), max_output_size)[0], tf.int32)\n    idx = tf.minimum(idx, num_boxes - 1 - pad)\n    idx = tf.reshape(idx + tf.reshape(tf.range(1) * num_boxes, [-1, 1]), [-1])\n    num_valid_boxes = tf.reduce_sum(output_size)\n    return (idx, num_valid_boxes, tf.reshape(boxes, [-1, 4]), tf.reshape(scores, [-1]), argsort_ids)",
            "def partitioned_non_max_suppression_padded(boxes, scores, max_output_size, iou_threshold=0.5, score_threshold=float('-inf')):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'A tiled version of [`tf.image.non_max_suppression_padded`](https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression_padded).\\n\\n  The overall design of the algorithm is to handle boxes tile-by-tile:\\n\\n  boxes = boxes.pad_to_multiple_of(tile_size)\\n  num_tiles = len(boxes) // tile_size\\n  output_boxes = []\\n  for i in range(num_tiles):\\n    box_tile = boxes[i*tile_size : (i+1)*tile_size]\\n    for j in range(i - 1):\\n      suppressing_tile = boxes[j*tile_size : (j+1)*tile_size]\\n      iou = batch_iou(box_tile, suppressing_tile)\\n      # if the box is suppressed in iou, clear it to a dot\\n      box_tile *= _update_boxes(iou)\\n    # Iteratively handle the diagonal tile.\\n    iou = _box_overlap(box_tile, box_tile)\\n    iou_changed = True\\n    while iou_changed:\\n      # boxes that are not suppressed by anything else\\n      suppressing_boxes = _get_suppressing_boxes(iou)\\n      # boxes that are suppressed by suppressing_boxes\\n      suppressed_boxes = _get_suppressed_boxes(iou, suppressing_boxes)\\n      # clear iou to 0 for boxes that are suppressed, as they cannot be used\\n      # to suppress other boxes any more\\n      new_iou = _clear_iou(iou, suppressed_boxes)\\n      iou_changed = (new_iou != iou)\\n      iou = new_iou\\n    # remaining boxes that can still suppress others, are selected boxes.\\n    output_boxes.append(_get_suppressing_boxes(iou))\\n    if len(output_boxes) >= max_output_size:\\n      break\\n\\n  Args:\\n    boxes: A 2-D float `Tensor` of shape `[num_boxes, 4]`.\\n    scores: A 1-D float `Tensor` of shape `[num_boxes]` representing a single\\n      score corresponding to each box (each row of boxes).\\n    max_output_size: a scalar integer `Tensor` representing the maximum number\\n      of boxes to be selected by non max suppression.\\n    iou_threshold: a float representing the threshold for deciding whether boxes\\n      overlap too much with respect to IOU.\\n    score_threshold: A float representing the threshold for deciding when to\\n      remove boxes based on score.\\n\\n  Returns:\\n    selected_indices: a tensor of shape [anchors].\\n    num_valid_boxes: a scalar int tensor.\\n    nms_proposals: a tensor with a shape of [anchors, 4]. It has\\n      same dtype as input boxes.\\n    nms_scores: a tensor with a shape of [anchors]. It has same\\n      dtype as input scores.\\n    argsort_ids: a tensor of shape [anchors], mapping from input order of boxes\\n      to output order of boxes.\\n  '\n    num_boxes = tf.shape(boxes)[0]\n    pad = tf.cast(tf.ceil(tf.cast(num_boxes, tf.float32) / _NMS_TILE_SIZE), tf.int32) * _NMS_TILE_SIZE - num_boxes\n    (scores, argsort_ids) = tf.nn.top_k(scores, k=num_boxes, sorted=True)\n    boxes = tf.gather(boxes, argsort_ids)\n    num_boxes = tf.shape(boxes)[0]\n    num_boxes += pad\n    boxes = tf.pad(tf.cast(boxes, tf.float32), [[0, pad], [0, 0]], constant_values=-1)\n    scores = tf.pad(tf.cast(scores, tf.float32), [[0, pad]])\n    scores_mask = tf.expand_dims(tf.cast(scores > score_threshold, boxes.dtype), axis=1)\n    boxes = (boxes + 1.0) * scores_mask - 1.0\n    boxes = tf.expand_dims(boxes, axis=0)\n    scores = tf.expand_dims(scores, axis=0)\n\n    def _loop_cond(unused_boxes, unused_threshold, output_size, idx):\n        return tf.logical_and(tf.reduce_min(output_size) < max_output_size, idx < num_boxes // _NMS_TILE_SIZE)\n    (selected_boxes, _, output_size, _) = tf.while_loop(_loop_cond, _suppression_loop_body, [boxes, iou_threshold, tf.zeros([1], tf.int32), tf.constant(0)])\n    idx = num_boxes - tf.cast(tf.nn.top_k(tf.cast(tf.reduce_any(selected_boxes > 0, [2]), tf.int32) * tf.expand_dims(tf.range(num_boxes, 0, -1), 0), max_output_size)[0], tf.int32)\n    idx = tf.minimum(idx, num_boxes - 1 - pad)\n    idx = tf.reshape(idx + tf.reshape(tf.range(1) * num_boxes, [-1, 1]), [-1])\n    num_valid_boxes = tf.reduce_sum(output_size)\n    return (idx, num_valid_boxes, tf.reshape(boxes, [-1, 4]), tf.reshape(scores, [-1]), argsort_ids)",
            "def partitioned_non_max_suppression_padded(boxes, scores, max_output_size, iou_threshold=0.5, score_threshold=float('-inf')):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'A tiled version of [`tf.image.non_max_suppression_padded`](https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression_padded).\\n\\n  The overall design of the algorithm is to handle boxes tile-by-tile:\\n\\n  boxes = boxes.pad_to_multiple_of(tile_size)\\n  num_tiles = len(boxes) // tile_size\\n  output_boxes = []\\n  for i in range(num_tiles):\\n    box_tile = boxes[i*tile_size : (i+1)*tile_size]\\n    for j in range(i - 1):\\n      suppressing_tile = boxes[j*tile_size : (j+1)*tile_size]\\n      iou = batch_iou(box_tile, suppressing_tile)\\n      # if the box is suppressed in iou, clear it to a dot\\n      box_tile *= _update_boxes(iou)\\n    # Iteratively handle the diagonal tile.\\n    iou = _box_overlap(box_tile, box_tile)\\n    iou_changed = True\\n    while iou_changed:\\n      # boxes that are not suppressed by anything else\\n      suppressing_boxes = _get_suppressing_boxes(iou)\\n      # boxes that are suppressed by suppressing_boxes\\n      suppressed_boxes = _get_suppressed_boxes(iou, suppressing_boxes)\\n      # clear iou to 0 for boxes that are suppressed, as they cannot be used\\n      # to suppress other boxes any more\\n      new_iou = _clear_iou(iou, suppressed_boxes)\\n      iou_changed = (new_iou != iou)\\n      iou = new_iou\\n    # remaining boxes that can still suppress others, are selected boxes.\\n    output_boxes.append(_get_suppressing_boxes(iou))\\n    if len(output_boxes) >= max_output_size:\\n      break\\n\\n  Args:\\n    boxes: A 2-D float `Tensor` of shape `[num_boxes, 4]`.\\n    scores: A 1-D float `Tensor` of shape `[num_boxes]` representing a single\\n      score corresponding to each box (each row of boxes).\\n    max_output_size: a scalar integer `Tensor` representing the maximum number\\n      of boxes to be selected by non max suppression.\\n    iou_threshold: a float representing the threshold for deciding whether boxes\\n      overlap too much with respect to IOU.\\n    score_threshold: A float representing the threshold for deciding when to\\n      remove boxes based on score.\\n\\n  Returns:\\n    selected_indices: a tensor of shape [anchors].\\n    num_valid_boxes: a scalar int tensor.\\n    nms_proposals: a tensor with a shape of [anchors, 4]. It has\\n      same dtype as input boxes.\\n    nms_scores: a tensor with a shape of [anchors]. It has same\\n      dtype as input scores.\\n    argsort_ids: a tensor of shape [anchors], mapping from input order of boxes\\n      to output order of boxes.\\n  '\n    num_boxes = tf.shape(boxes)[0]\n    pad = tf.cast(tf.ceil(tf.cast(num_boxes, tf.float32) / _NMS_TILE_SIZE), tf.int32) * _NMS_TILE_SIZE - num_boxes\n    (scores, argsort_ids) = tf.nn.top_k(scores, k=num_boxes, sorted=True)\n    boxes = tf.gather(boxes, argsort_ids)\n    num_boxes = tf.shape(boxes)[0]\n    num_boxes += pad\n    boxes = tf.pad(tf.cast(boxes, tf.float32), [[0, pad], [0, 0]], constant_values=-1)\n    scores = tf.pad(tf.cast(scores, tf.float32), [[0, pad]])\n    scores_mask = tf.expand_dims(tf.cast(scores > score_threshold, boxes.dtype), axis=1)\n    boxes = (boxes + 1.0) * scores_mask - 1.0\n    boxes = tf.expand_dims(boxes, axis=0)\n    scores = tf.expand_dims(scores, axis=0)\n\n    def _loop_cond(unused_boxes, unused_threshold, output_size, idx):\n        return tf.logical_and(tf.reduce_min(output_size) < max_output_size, idx < num_boxes // _NMS_TILE_SIZE)\n    (selected_boxes, _, output_size, _) = tf.while_loop(_loop_cond, _suppression_loop_body, [boxes, iou_threshold, tf.zeros([1], tf.int32), tf.constant(0)])\n    idx = num_boxes - tf.cast(tf.nn.top_k(tf.cast(tf.reduce_any(selected_boxes > 0, [2]), tf.int32) * tf.expand_dims(tf.range(num_boxes, 0, -1), 0), max_output_size)[0], tf.int32)\n    idx = tf.minimum(idx, num_boxes - 1 - pad)\n    idx = tf.reshape(idx + tf.reshape(tf.range(1) * num_boxes, [-1, 1]), [-1])\n    num_valid_boxes = tf.reduce_sum(output_size)\n    return (idx, num_valid_boxes, tf.reshape(boxes, [-1, 4]), tf.reshape(scores, [-1]), argsort_ids)"
        ]
    },
    {
        "func_name": "_validate_boxes_scores_iou_thresh",
        "original": "def _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window):\n    \"\"\"Validates boxes, scores and iou_thresh.\n\n  This function validates the boxes, scores, iou_thresh\n     and if change_coordinate_frame is True, clip_window must be specified.\n\n  Args:\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\n      number of classes or 1 depending on whether a separate box is predicted\n      per class.\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\n      the k detections. The scores have to be non-negative when\n      pad_to_max_output_size is True.\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\n      with previously selected boxes are removed).\n    change_coordinate_frame: Whether to normalize coordinates after clipping\n      relative to clip_window (this can only be set to True if a clip_window is\n      provided)\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\n      representing the window to clip and normalize boxes to before performing\n      non-max suppression.\n\n  Raises:\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not\n    have a valid scores field.\n  \"\"\"\n    if not 0 <= iou_thresh <= 1.0:\n        raise ValueError('iou_thresh must be between 0 and 1')\n    if scores.shape.ndims != 2:\n        raise ValueError('scores field must be of rank 2')\n    if shape_utils.get_dim_as_int(scores.shape[1]) is None:\n        raise ValueError('scores must have statically defined second dimension')\n    if boxes.shape.ndims != 3:\n        raise ValueError('boxes must be of rank 3.')\n    if not (shape_utils.get_dim_as_int(boxes.shape[1]) == shape_utils.get_dim_as_int(scores.shape[1]) or shape_utils.get_dim_as_int(boxes.shape[1]) == 1):\n        raise ValueError('second dimension of boxes must be either 1 or equal to the second dimension of scores')\n    if shape_utils.get_dim_as_int(boxes.shape[2]) != 4:\n        raise ValueError('last dimension of boxes must be of size 4.')\n    if change_coordinate_frame and clip_window is None:\n        raise ValueError('if change_coordinate_frame is True, then a clip_windowmust be specified.')",
        "mutated": [
            "def _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window):\n    if False:\n        i = 10\n    'Validates boxes, scores and iou_thresh.\\n\\n  This function validates the boxes, scores, iou_thresh\\n     and if change_coordinate_frame is True, clip_window must be specified.\\n\\n  Args:\\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\\n      number of classes or 1 depending on whether a separate box is predicted\\n      per class.\\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\\n      the k detections. The scores have to be non-negative when\\n      pad_to_max_output_size is True.\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided)\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n\\n  Raises:\\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not\\n    have a valid scores field.\\n  '\n    if not 0 <= iou_thresh <= 1.0:\n        raise ValueError('iou_thresh must be between 0 and 1')\n    if scores.shape.ndims != 2:\n        raise ValueError('scores field must be of rank 2')\n    if shape_utils.get_dim_as_int(scores.shape[1]) is None:\n        raise ValueError('scores must have statically defined second dimension')\n    if boxes.shape.ndims != 3:\n        raise ValueError('boxes must be of rank 3.')\n    if not (shape_utils.get_dim_as_int(boxes.shape[1]) == shape_utils.get_dim_as_int(scores.shape[1]) or shape_utils.get_dim_as_int(boxes.shape[1]) == 1):\n        raise ValueError('second dimension of boxes must be either 1 or equal to the second dimension of scores')\n    if shape_utils.get_dim_as_int(boxes.shape[2]) != 4:\n        raise ValueError('last dimension of boxes must be of size 4.')\n    if change_coordinate_frame and clip_window is None:\n        raise ValueError('if change_coordinate_frame is True, then a clip_windowmust be specified.')",
            "def _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Validates boxes, scores and iou_thresh.\\n\\n  This function validates the boxes, scores, iou_thresh\\n     and if change_coordinate_frame is True, clip_window must be specified.\\n\\n  Args:\\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\\n      number of classes or 1 depending on whether a separate box is predicted\\n      per class.\\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\\n      the k detections. The scores have to be non-negative when\\n      pad_to_max_output_size is True.\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided)\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n\\n  Raises:\\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not\\n    have a valid scores field.\\n  '\n    if not 0 <= iou_thresh <= 1.0:\n        raise ValueError('iou_thresh must be between 0 and 1')\n    if scores.shape.ndims != 2:\n        raise ValueError('scores field must be of rank 2')\n    if shape_utils.get_dim_as_int(scores.shape[1]) is None:\n        raise ValueError('scores must have statically defined second dimension')\n    if boxes.shape.ndims != 3:\n        raise ValueError('boxes must be of rank 3.')\n    if not (shape_utils.get_dim_as_int(boxes.shape[1]) == shape_utils.get_dim_as_int(scores.shape[1]) or shape_utils.get_dim_as_int(boxes.shape[1]) == 1):\n        raise ValueError('second dimension of boxes must be either 1 or equal to the second dimension of scores')\n    if shape_utils.get_dim_as_int(boxes.shape[2]) != 4:\n        raise ValueError('last dimension of boxes must be of size 4.')\n    if change_coordinate_frame and clip_window is None:\n        raise ValueError('if change_coordinate_frame is True, then a clip_windowmust be specified.')",
            "def _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Validates boxes, scores and iou_thresh.\\n\\n  This function validates the boxes, scores, iou_thresh\\n     and if change_coordinate_frame is True, clip_window must be specified.\\n\\n  Args:\\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\\n      number of classes or 1 depending on whether a separate box is predicted\\n      per class.\\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\\n      the k detections. The scores have to be non-negative when\\n      pad_to_max_output_size is True.\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided)\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n\\n  Raises:\\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not\\n    have a valid scores field.\\n  '\n    if not 0 <= iou_thresh <= 1.0:\n        raise ValueError('iou_thresh must be between 0 and 1')\n    if scores.shape.ndims != 2:\n        raise ValueError('scores field must be of rank 2')\n    if shape_utils.get_dim_as_int(scores.shape[1]) is None:\n        raise ValueError('scores must have statically defined second dimension')\n    if boxes.shape.ndims != 3:\n        raise ValueError('boxes must be of rank 3.')\n    if not (shape_utils.get_dim_as_int(boxes.shape[1]) == shape_utils.get_dim_as_int(scores.shape[1]) or shape_utils.get_dim_as_int(boxes.shape[1]) == 1):\n        raise ValueError('second dimension of boxes must be either 1 or equal to the second dimension of scores')\n    if shape_utils.get_dim_as_int(boxes.shape[2]) != 4:\n        raise ValueError('last dimension of boxes must be of size 4.')\n    if change_coordinate_frame and clip_window is None:\n        raise ValueError('if change_coordinate_frame is True, then a clip_windowmust be specified.')",
            "def _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Validates boxes, scores and iou_thresh.\\n\\n  This function validates the boxes, scores, iou_thresh\\n     and if change_coordinate_frame is True, clip_window must be specified.\\n\\n  Args:\\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\\n      number of classes or 1 depending on whether a separate box is predicted\\n      per class.\\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\\n      the k detections. The scores have to be non-negative when\\n      pad_to_max_output_size is True.\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided)\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n\\n  Raises:\\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not\\n    have a valid scores field.\\n  '\n    if not 0 <= iou_thresh <= 1.0:\n        raise ValueError('iou_thresh must be between 0 and 1')\n    if scores.shape.ndims != 2:\n        raise ValueError('scores field must be of rank 2')\n    if shape_utils.get_dim_as_int(scores.shape[1]) is None:\n        raise ValueError('scores must have statically defined second dimension')\n    if boxes.shape.ndims != 3:\n        raise ValueError('boxes must be of rank 3.')\n    if not (shape_utils.get_dim_as_int(boxes.shape[1]) == shape_utils.get_dim_as_int(scores.shape[1]) or shape_utils.get_dim_as_int(boxes.shape[1]) == 1):\n        raise ValueError('second dimension of boxes must be either 1 or equal to the second dimension of scores')\n    if shape_utils.get_dim_as_int(boxes.shape[2]) != 4:\n        raise ValueError('last dimension of boxes must be of size 4.')\n    if change_coordinate_frame and clip_window is None:\n        raise ValueError('if change_coordinate_frame is True, then a clip_windowmust be specified.')",
            "def _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Validates boxes, scores and iou_thresh.\\n\\n  This function validates the boxes, scores, iou_thresh\\n     and if change_coordinate_frame is True, clip_window must be specified.\\n\\n  Args:\\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\\n      number of classes or 1 depending on whether a separate box is predicted\\n      per class.\\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\\n      the k detections. The scores have to be non-negative when\\n      pad_to_max_output_size is True.\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided)\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n\\n  Raises:\\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not\\n    have a valid scores field.\\n  '\n    if not 0 <= iou_thresh <= 1.0:\n        raise ValueError('iou_thresh must be between 0 and 1')\n    if scores.shape.ndims != 2:\n        raise ValueError('scores field must be of rank 2')\n    if shape_utils.get_dim_as_int(scores.shape[1]) is None:\n        raise ValueError('scores must have statically defined second dimension')\n    if boxes.shape.ndims != 3:\n        raise ValueError('boxes must be of rank 3.')\n    if not (shape_utils.get_dim_as_int(boxes.shape[1]) == shape_utils.get_dim_as_int(scores.shape[1]) or shape_utils.get_dim_as_int(boxes.shape[1]) == 1):\n        raise ValueError('second dimension of boxes must be either 1 or equal to the second dimension of scores')\n    if shape_utils.get_dim_as_int(boxes.shape[2]) != 4:\n        raise ValueError('last dimension of boxes must be of size 4.')\n    if change_coordinate_frame and clip_window is None:\n        raise ValueError('if change_coordinate_frame is True, then a clip_windowmust be specified.')"
        ]
    },
    {
        "func_name": "_clip_window_prune_boxes",
        "original": "def _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame):\n    \"\"\"Prune boxes with zero area.\n\n  Args:\n    sorted_boxes: A BoxList containing k detections.\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\n      representing the window to clip and normalize boxes to before performing\n      non-max suppression.\n    pad_to_max_output_size: flag indicating whether to pad to max output size or\n      not.\n    change_coordinate_frame: Whether to normalize coordinates after clipping\n      relative to clip_window (this can only be set to True if a clip_window is\n      provided).\n\n  Returns:\n    sorted_boxes: A BoxList containing k detections after pruning.\n    num_valid_nms_boxes_cumulative: Number of valid NMS boxes\n  \"\"\"\n    sorted_boxes = box_list_ops.clip_to_window(sorted_boxes, clip_window, filter_nonoverlapping=not pad_to_max_output_size)\n    sorted_boxes_size = tf.shape(sorted_boxes.get())[0]\n    non_zero_box_area = tf.cast(box_list_ops.area(sorted_boxes), tf.bool)\n    sorted_boxes_scores = tf.where(non_zero_box_area, sorted_boxes.get_field(fields.BoxListFields.scores), -1 * tf.ones(sorted_boxes_size))\n    sorted_boxes.add_field(fields.BoxListFields.scores, sorted_boxes_scores)\n    num_valid_nms_boxes_cumulative = tf.reduce_sum(tf.cast(tf.greater_equal(sorted_boxes_scores, 0), tf.int32))\n    sorted_boxes = box_list_ops.sort_by_field(sorted_boxes, fields.BoxListFields.scores)\n    if change_coordinate_frame:\n        sorted_boxes = box_list_ops.change_coordinate_frame(sorted_boxes, clip_window)\n    return (sorted_boxes, num_valid_nms_boxes_cumulative)",
        "mutated": [
            "def _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame):\n    if False:\n        i = 10\n    'Prune boxes with zero area.\\n\\n  Args:\\n    sorted_boxes: A BoxList containing k detections.\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n    pad_to_max_output_size: flag indicating whether to pad to max output size or\\n      not.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided).\\n\\n  Returns:\\n    sorted_boxes: A BoxList containing k detections after pruning.\\n    num_valid_nms_boxes_cumulative: Number of valid NMS boxes\\n  '\n    sorted_boxes = box_list_ops.clip_to_window(sorted_boxes, clip_window, filter_nonoverlapping=not pad_to_max_output_size)\n    sorted_boxes_size = tf.shape(sorted_boxes.get())[0]\n    non_zero_box_area = tf.cast(box_list_ops.area(sorted_boxes), tf.bool)\n    sorted_boxes_scores = tf.where(non_zero_box_area, sorted_boxes.get_field(fields.BoxListFields.scores), -1 * tf.ones(sorted_boxes_size))\n    sorted_boxes.add_field(fields.BoxListFields.scores, sorted_boxes_scores)\n    num_valid_nms_boxes_cumulative = tf.reduce_sum(tf.cast(tf.greater_equal(sorted_boxes_scores, 0), tf.int32))\n    sorted_boxes = box_list_ops.sort_by_field(sorted_boxes, fields.BoxListFields.scores)\n    if change_coordinate_frame:\n        sorted_boxes = box_list_ops.change_coordinate_frame(sorted_boxes, clip_window)\n    return (sorted_boxes, num_valid_nms_boxes_cumulative)",
            "def _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Prune boxes with zero area.\\n\\n  Args:\\n    sorted_boxes: A BoxList containing k detections.\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n    pad_to_max_output_size: flag indicating whether to pad to max output size or\\n      not.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided).\\n\\n  Returns:\\n    sorted_boxes: A BoxList containing k detections after pruning.\\n    num_valid_nms_boxes_cumulative: Number of valid NMS boxes\\n  '\n    sorted_boxes = box_list_ops.clip_to_window(sorted_boxes, clip_window, filter_nonoverlapping=not pad_to_max_output_size)\n    sorted_boxes_size = tf.shape(sorted_boxes.get())[0]\n    non_zero_box_area = tf.cast(box_list_ops.area(sorted_boxes), tf.bool)\n    sorted_boxes_scores = tf.where(non_zero_box_area, sorted_boxes.get_field(fields.BoxListFields.scores), -1 * tf.ones(sorted_boxes_size))\n    sorted_boxes.add_field(fields.BoxListFields.scores, sorted_boxes_scores)\n    num_valid_nms_boxes_cumulative = tf.reduce_sum(tf.cast(tf.greater_equal(sorted_boxes_scores, 0), tf.int32))\n    sorted_boxes = box_list_ops.sort_by_field(sorted_boxes, fields.BoxListFields.scores)\n    if change_coordinate_frame:\n        sorted_boxes = box_list_ops.change_coordinate_frame(sorted_boxes, clip_window)\n    return (sorted_boxes, num_valid_nms_boxes_cumulative)",
            "def _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Prune boxes with zero area.\\n\\n  Args:\\n    sorted_boxes: A BoxList containing k detections.\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n    pad_to_max_output_size: flag indicating whether to pad to max output size or\\n      not.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided).\\n\\n  Returns:\\n    sorted_boxes: A BoxList containing k detections after pruning.\\n    num_valid_nms_boxes_cumulative: Number of valid NMS boxes\\n  '\n    sorted_boxes = box_list_ops.clip_to_window(sorted_boxes, clip_window, filter_nonoverlapping=not pad_to_max_output_size)\n    sorted_boxes_size = tf.shape(sorted_boxes.get())[0]\n    non_zero_box_area = tf.cast(box_list_ops.area(sorted_boxes), tf.bool)\n    sorted_boxes_scores = tf.where(non_zero_box_area, sorted_boxes.get_field(fields.BoxListFields.scores), -1 * tf.ones(sorted_boxes_size))\n    sorted_boxes.add_field(fields.BoxListFields.scores, sorted_boxes_scores)\n    num_valid_nms_boxes_cumulative = tf.reduce_sum(tf.cast(tf.greater_equal(sorted_boxes_scores, 0), tf.int32))\n    sorted_boxes = box_list_ops.sort_by_field(sorted_boxes, fields.BoxListFields.scores)\n    if change_coordinate_frame:\n        sorted_boxes = box_list_ops.change_coordinate_frame(sorted_boxes, clip_window)\n    return (sorted_boxes, num_valid_nms_boxes_cumulative)",
            "def _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Prune boxes with zero area.\\n\\n  Args:\\n    sorted_boxes: A BoxList containing k detections.\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n    pad_to_max_output_size: flag indicating whether to pad to max output size or\\n      not.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided).\\n\\n  Returns:\\n    sorted_boxes: A BoxList containing k detections after pruning.\\n    num_valid_nms_boxes_cumulative: Number of valid NMS boxes\\n  '\n    sorted_boxes = box_list_ops.clip_to_window(sorted_boxes, clip_window, filter_nonoverlapping=not pad_to_max_output_size)\n    sorted_boxes_size = tf.shape(sorted_boxes.get())[0]\n    non_zero_box_area = tf.cast(box_list_ops.area(sorted_boxes), tf.bool)\n    sorted_boxes_scores = tf.where(non_zero_box_area, sorted_boxes.get_field(fields.BoxListFields.scores), -1 * tf.ones(sorted_boxes_size))\n    sorted_boxes.add_field(fields.BoxListFields.scores, sorted_boxes_scores)\n    num_valid_nms_boxes_cumulative = tf.reduce_sum(tf.cast(tf.greater_equal(sorted_boxes_scores, 0), tf.int32))\n    sorted_boxes = box_list_ops.sort_by_field(sorted_boxes, fields.BoxListFields.scores)\n    if change_coordinate_frame:\n        sorted_boxes = box_list_ops.change_coordinate_frame(sorted_boxes, clip_window)\n    return (sorted_boxes, num_valid_nms_boxes_cumulative)",
            "def _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Prune boxes with zero area.\\n\\n  Args:\\n    sorted_boxes: A BoxList containing k detections.\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n    pad_to_max_output_size: flag indicating whether to pad to max output size or\\n      not.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided).\\n\\n  Returns:\\n    sorted_boxes: A BoxList containing k detections after pruning.\\n    num_valid_nms_boxes_cumulative: Number of valid NMS boxes\\n  '\n    sorted_boxes = box_list_ops.clip_to_window(sorted_boxes, clip_window, filter_nonoverlapping=not pad_to_max_output_size)\n    sorted_boxes_size = tf.shape(sorted_boxes.get())[0]\n    non_zero_box_area = tf.cast(box_list_ops.area(sorted_boxes), tf.bool)\n    sorted_boxes_scores = tf.where(non_zero_box_area, sorted_boxes.get_field(fields.BoxListFields.scores), -1 * tf.ones(sorted_boxes_size))\n    sorted_boxes.add_field(fields.BoxListFields.scores, sorted_boxes_scores)\n    num_valid_nms_boxes_cumulative = tf.reduce_sum(tf.cast(tf.greater_equal(sorted_boxes_scores, 0), tf.int32))\n    sorted_boxes = box_list_ops.sort_by_field(sorted_boxes, fields.BoxListFields.scores)\n    if change_coordinate_frame:\n        sorted_boxes = box_list_ops.change_coordinate_frame(sorted_boxes, clip_window)\n    return (sorted_boxes, num_valid_nms_boxes_cumulative)"
        ]
    },
    {
        "func_name": "multiclass_non_max_suppression",
        "original": "def multiclass_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_size_per_class, max_total_size=0, clip_window=None, change_coordinate_frame=False, masks=None, boundaries=None, pad_to_max_output_size=False, use_partitioned_nms=False, additional_fields=None, soft_nms_sigma=0.0, scope=None):\n    \"\"\"Multi-class version of non maximum suppression.\n\n  This op greedily selects a subset of detection bounding boxes, pruning\n  away boxes that have high IOU (intersection over union) overlap (> thresh)\n  with already selected boxes.  It operates independently for each class for\n  which scores are provided (via the scores field of the input box_list),\n  pruning boxes with score less than a provided threshold prior to\n  applying NMS.\n\n  Please note that this operation is performed on *all* classes, therefore any\n  background classes should be removed prior to calling this function.\n\n  Selected boxes are guaranteed to be sorted in decreasing order by score (but\n  the sort is not guaranteed to be stable).\n\n  Args:\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\n      number of classes or 1 depending on whether a separate box is predicted\n      per class.\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\n      the k detections. The scores have to be non-negative when\n      pad_to_max_output_size is True.\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\n      with previously selected boxes are removed).\n    max_size_per_class: maximum number of retained boxes per class.\n    max_total_size: maximum number of boxes retained over all classes. By\n      default returns all boxes retained after capping boxes per class.\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\n      representing the window to clip and normalize boxes to before performing\n      non-max suppression.\n    change_coordinate_frame: Whether to normalize coordinates after clipping\n      relative to clip_window (this can only be set to True if a clip_window\n      is provided)\n    masks: (optional) a [k, q, mask_height, mask_width] float32 tensor\n      containing box masks. `q` can be either number of classes or 1 depending\n      on whether a separate mask is predicted per class.\n    boundaries: (optional) a [k, q, boundary_height, boundary_width] float32\n      tensor containing box boundaries. `q` can be either number of classes or 1\n      depending on whether a separate boundary is predicted per class.\n    pad_to_max_output_size: If true, the output nmsed boxes are padded to be of\n      length `max_size_per_class`. Defaults to false.\n    use_partitioned_nms: If true, use partitioned version of\n      non_max_suppression.\n    additional_fields: (optional) If not None, a dictionary that maps keys to\n      tensors whose first dimensions are all of size `k`. After non-maximum\n      suppression, all tensors corresponding to the selected boxes will be\n      added to resulting BoxList.\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\n      False.\n    scope: name scope.\n\n  Returns:\n    A tuple of sorted_boxes and num_valid_nms_boxes. The sorted_boxes is a\n      BoxList holds M boxes with a rank-1 scores field representing\n      corresponding scores for each box with scores sorted in decreasing order\n      and a rank-1 classes field representing a class label for each box. The\n      num_valid_nms_boxes is a 0-D integer tensor representing the number of\n      valid elements in `BoxList`, with the valid elements appearing first.\n\n  Raises:\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have\n      a valid scores field.\n    ValueError: if Soft NMS (tf.image.non_max_suppression_with_scores) is not\n      supported in the current TF version and `soft_nms_sigma` is nonzero.\n  \"\"\"\n    _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window)\n    if pad_to_max_output_size and soft_nms_sigma != 0.0:\n        raise ValueError('Soft NMS (soft_nms_sigma != 0.0) is currently not supported when pad_to_max_output_size is True.')\n    with tf.name_scope(scope, 'MultiClassNonMaxSuppression'):\n        num_scores = tf.shape(scores)[0]\n        num_classes = shape_utils.get_dim_as_int(scores.get_shape()[1])\n        selected_boxes_list = []\n        num_valid_nms_boxes_cumulative = tf.constant(0)\n        per_class_boxes_list = tf.unstack(boxes, axis=1)\n        if masks is not None:\n            per_class_masks_list = tf.unstack(masks, axis=1)\n        if boundaries is not None:\n            per_class_boundaries_list = tf.unstack(boundaries, axis=1)\n        boxes_ids = range(num_classes) if len(per_class_boxes_list) > 1 else [0] * num_classes\n        for (class_idx, boxes_idx) in zip(range(num_classes), boxes_ids):\n            per_class_boxes = per_class_boxes_list[boxes_idx]\n            boxlist_and_class_scores = box_list.BoxList(per_class_boxes)\n            class_scores = tf.reshape(tf.slice(scores, [0, class_idx], tf.stack([num_scores, 1])), [-1])\n            boxlist_and_class_scores.add_field(fields.BoxListFields.scores, class_scores)\n            if masks is not None:\n                per_class_masks = per_class_masks_list[boxes_idx]\n                boxlist_and_class_scores.add_field(fields.BoxListFields.masks, per_class_masks)\n            if boundaries is not None:\n                per_class_boundaries = per_class_boundaries_list[boxes_idx]\n                boxlist_and_class_scores.add_field(fields.BoxListFields.boundaries, per_class_boundaries)\n            if additional_fields is not None:\n                for (key, tensor) in additional_fields.items():\n                    boxlist_and_class_scores.add_field(key, tensor)\n            nms_result = None\n            selected_scores = None\n            if pad_to_max_output_size:\n                max_selection_size = max_size_per_class\n                if use_partitioned_nms:\n                    (selected_indices, num_valid_nms_boxes, boxlist_and_class_scores.data['boxes'], boxlist_and_class_scores.data['scores'], _) = partitioned_non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                else:\n                    (selected_indices, num_valid_nms_boxes) = tf.image.non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_to_max_output_size=True)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n            else:\n                max_selection_size = tf.minimum(max_size_per_class, boxlist_and_class_scores.num_boxes())\n                if hasattr(tf.image, 'non_max_suppression_with_scores') and tf.compat.forward_compatible(2019, 6, 6):\n                    (selected_indices, selected_scores) = tf.image.non_max_suppression_with_scores(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, soft_nms_sigma=soft_nms_sigma)\n                    num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                    selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                    selected_scores = tf.concat([selected_scores, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.float32)], -1)\n                    nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                else:\n                    if soft_nms_sigma != 0:\n                        raise ValueError('Soft NMS not supported in current TF version!')\n                    selected_indices = tf.image.non_max_suppression(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                    num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                    selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                    nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                    selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n            valid_nms_boxes_indices = tf.less(tf.range(max_selection_size), num_valid_nms_boxes)\n            nms_result.add_field(fields.BoxListFields.scores, tf.where(valid_nms_boxes_indices, selected_scores, -1 * tf.ones(max_selection_size)))\n            num_valid_nms_boxes_cumulative += num_valid_nms_boxes\n            nms_result.add_field(fields.BoxListFields.classes, tf.zeros_like(nms_result.get_field(fields.BoxListFields.scores)) + class_idx)\n            selected_boxes_list.append(nms_result)\n        selected_boxes = box_list_ops.concatenate(selected_boxes_list)\n        sorted_boxes = box_list_ops.sort_by_field(selected_boxes, fields.BoxListFields.scores)\n        if clip_window is not None:\n            (sorted_boxes, num_valid_nms_boxes_cumulative) = _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame)\n        if max_total_size:\n            max_total_size = tf.minimum(max_total_size, sorted_boxes.num_boxes())\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(max_total_size))\n            num_valid_nms_boxes_cumulative = tf.where(max_total_size > num_valid_nms_boxes_cumulative, num_valid_nms_boxes_cumulative, max_total_size)\n        if not pad_to_max_output_size:\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(num_valid_nms_boxes_cumulative))\n        return (sorted_boxes, num_valid_nms_boxes_cumulative)",
        "mutated": [
            "def multiclass_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_size_per_class, max_total_size=0, clip_window=None, change_coordinate_frame=False, masks=None, boundaries=None, pad_to_max_output_size=False, use_partitioned_nms=False, additional_fields=None, soft_nms_sigma=0.0, scope=None):\n    if False:\n        i = 10\n    'Multi-class version of non maximum suppression.\\n\\n  This op greedily selects a subset of detection bounding boxes, pruning\\n  away boxes that have high IOU (intersection over union) overlap (> thresh)\\n  with already selected boxes.  It operates independently for each class for\\n  which scores are provided (via the scores field of the input box_list),\\n  pruning boxes with score less than a provided threshold prior to\\n  applying NMS.\\n\\n  Please note that this operation is performed on *all* classes, therefore any\\n  background classes should be removed prior to calling this function.\\n\\n  Selected boxes are guaranteed to be sorted in decreasing order by score (but\\n  the sort is not guaranteed to be stable).\\n\\n  Args:\\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\\n      number of classes or 1 depending on whether a separate box is predicted\\n      per class.\\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\\n      the k detections. The scores have to be non-negative when\\n      pad_to_max_output_size is True.\\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    max_size_per_class: maximum number of retained boxes per class.\\n    max_total_size: maximum number of boxes retained over all classes. By\\n      default returns all boxes retained after capping boxes per class.\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window\\n      is provided)\\n    masks: (optional) a [k, q, mask_height, mask_width] float32 tensor\\n      containing box masks. `q` can be either number of classes or 1 depending\\n      on whether a separate mask is predicted per class.\\n    boundaries: (optional) a [k, q, boundary_height, boundary_width] float32\\n      tensor containing box boundaries. `q` can be either number of classes or 1\\n      depending on whether a separate boundary is predicted per class.\\n    pad_to_max_output_size: If true, the output nmsed boxes are padded to be of\\n      length `max_size_per_class`. Defaults to false.\\n    use_partitioned_nms: If true, use partitioned version of\\n      non_max_suppression.\\n    additional_fields: (optional) If not None, a dictionary that maps keys to\\n      tensors whose first dimensions are all of size `k`. After non-maximum\\n      suppression, all tensors corresponding to the selected boxes will be\\n      added to resulting BoxList.\\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\\n      False.\\n    scope: name scope.\\n\\n  Returns:\\n    A tuple of sorted_boxes and num_valid_nms_boxes. The sorted_boxes is a\\n      BoxList holds M boxes with a rank-1 scores field representing\\n      corresponding scores for each box with scores sorted in decreasing order\\n      and a rank-1 classes field representing a class label for each box. The\\n      num_valid_nms_boxes is a 0-D integer tensor representing the number of\\n      valid elements in `BoxList`, with the valid elements appearing first.\\n\\n  Raises:\\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have\\n      a valid scores field.\\n    ValueError: if Soft NMS (tf.image.non_max_suppression_with_scores) is not\\n      supported in the current TF version and `soft_nms_sigma` is nonzero.\\n  '\n    _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window)\n    if pad_to_max_output_size and soft_nms_sigma != 0.0:\n        raise ValueError('Soft NMS (soft_nms_sigma != 0.0) is currently not supported when pad_to_max_output_size is True.')\n    with tf.name_scope(scope, 'MultiClassNonMaxSuppression'):\n        num_scores = tf.shape(scores)[0]\n        num_classes = shape_utils.get_dim_as_int(scores.get_shape()[1])\n        selected_boxes_list = []\n        num_valid_nms_boxes_cumulative = tf.constant(0)\n        per_class_boxes_list = tf.unstack(boxes, axis=1)\n        if masks is not None:\n            per_class_masks_list = tf.unstack(masks, axis=1)\n        if boundaries is not None:\n            per_class_boundaries_list = tf.unstack(boundaries, axis=1)\n        boxes_ids = range(num_classes) if len(per_class_boxes_list) > 1 else [0] * num_classes\n        for (class_idx, boxes_idx) in zip(range(num_classes), boxes_ids):\n            per_class_boxes = per_class_boxes_list[boxes_idx]\n            boxlist_and_class_scores = box_list.BoxList(per_class_boxes)\n            class_scores = tf.reshape(tf.slice(scores, [0, class_idx], tf.stack([num_scores, 1])), [-1])\n            boxlist_and_class_scores.add_field(fields.BoxListFields.scores, class_scores)\n            if masks is not None:\n                per_class_masks = per_class_masks_list[boxes_idx]\n                boxlist_and_class_scores.add_field(fields.BoxListFields.masks, per_class_masks)\n            if boundaries is not None:\n                per_class_boundaries = per_class_boundaries_list[boxes_idx]\n                boxlist_and_class_scores.add_field(fields.BoxListFields.boundaries, per_class_boundaries)\n            if additional_fields is not None:\n                for (key, tensor) in additional_fields.items():\n                    boxlist_and_class_scores.add_field(key, tensor)\n            nms_result = None\n            selected_scores = None\n            if pad_to_max_output_size:\n                max_selection_size = max_size_per_class\n                if use_partitioned_nms:\n                    (selected_indices, num_valid_nms_boxes, boxlist_and_class_scores.data['boxes'], boxlist_and_class_scores.data['scores'], _) = partitioned_non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                else:\n                    (selected_indices, num_valid_nms_boxes) = tf.image.non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_to_max_output_size=True)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n            else:\n                max_selection_size = tf.minimum(max_size_per_class, boxlist_and_class_scores.num_boxes())\n                if hasattr(tf.image, 'non_max_suppression_with_scores') and tf.compat.forward_compatible(2019, 6, 6):\n                    (selected_indices, selected_scores) = tf.image.non_max_suppression_with_scores(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, soft_nms_sigma=soft_nms_sigma)\n                    num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                    selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                    selected_scores = tf.concat([selected_scores, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.float32)], -1)\n                    nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                else:\n                    if soft_nms_sigma != 0:\n                        raise ValueError('Soft NMS not supported in current TF version!')\n                    selected_indices = tf.image.non_max_suppression(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                    num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                    selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                    nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                    selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n            valid_nms_boxes_indices = tf.less(tf.range(max_selection_size), num_valid_nms_boxes)\n            nms_result.add_field(fields.BoxListFields.scores, tf.where(valid_nms_boxes_indices, selected_scores, -1 * tf.ones(max_selection_size)))\n            num_valid_nms_boxes_cumulative += num_valid_nms_boxes\n            nms_result.add_field(fields.BoxListFields.classes, tf.zeros_like(nms_result.get_field(fields.BoxListFields.scores)) + class_idx)\n            selected_boxes_list.append(nms_result)\n        selected_boxes = box_list_ops.concatenate(selected_boxes_list)\n        sorted_boxes = box_list_ops.sort_by_field(selected_boxes, fields.BoxListFields.scores)\n        if clip_window is not None:\n            (sorted_boxes, num_valid_nms_boxes_cumulative) = _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame)\n        if max_total_size:\n            max_total_size = tf.minimum(max_total_size, sorted_boxes.num_boxes())\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(max_total_size))\n            num_valid_nms_boxes_cumulative = tf.where(max_total_size > num_valid_nms_boxes_cumulative, num_valid_nms_boxes_cumulative, max_total_size)\n        if not pad_to_max_output_size:\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(num_valid_nms_boxes_cumulative))\n        return (sorted_boxes, num_valid_nms_boxes_cumulative)",
            "def multiclass_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_size_per_class, max_total_size=0, clip_window=None, change_coordinate_frame=False, masks=None, boundaries=None, pad_to_max_output_size=False, use_partitioned_nms=False, additional_fields=None, soft_nms_sigma=0.0, scope=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Multi-class version of non maximum suppression.\\n\\n  This op greedily selects a subset of detection bounding boxes, pruning\\n  away boxes that have high IOU (intersection over union) overlap (> thresh)\\n  with already selected boxes.  It operates independently for each class for\\n  which scores are provided (via the scores field of the input box_list),\\n  pruning boxes with score less than a provided threshold prior to\\n  applying NMS.\\n\\n  Please note that this operation is performed on *all* classes, therefore any\\n  background classes should be removed prior to calling this function.\\n\\n  Selected boxes are guaranteed to be sorted in decreasing order by score (but\\n  the sort is not guaranteed to be stable).\\n\\n  Args:\\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\\n      number of classes or 1 depending on whether a separate box is predicted\\n      per class.\\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\\n      the k detections. The scores have to be non-negative when\\n      pad_to_max_output_size is True.\\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    max_size_per_class: maximum number of retained boxes per class.\\n    max_total_size: maximum number of boxes retained over all classes. By\\n      default returns all boxes retained after capping boxes per class.\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window\\n      is provided)\\n    masks: (optional) a [k, q, mask_height, mask_width] float32 tensor\\n      containing box masks. `q` can be either number of classes or 1 depending\\n      on whether a separate mask is predicted per class.\\n    boundaries: (optional) a [k, q, boundary_height, boundary_width] float32\\n      tensor containing box boundaries. `q` can be either number of classes or 1\\n      depending on whether a separate boundary is predicted per class.\\n    pad_to_max_output_size: If true, the output nmsed boxes are padded to be of\\n      length `max_size_per_class`. Defaults to false.\\n    use_partitioned_nms: If true, use partitioned version of\\n      non_max_suppression.\\n    additional_fields: (optional) If not None, a dictionary that maps keys to\\n      tensors whose first dimensions are all of size `k`. After non-maximum\\n      suppression, all tensors corresponding to the selected boxes will be\\n      added to resulting BoxList.\\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\\n      False.\\n    scope: name scope.\\n\\n  Returns:\\n    A tuple of sorted_boxes and num_valid_nms_boxes. The sorted_boxes is a\\n      BoxList holds M boxes with a rank-1 scores field representing\\n      corresponding scores for each box with scores sorted in decreasing order\\n      and a rank-1 classes field representing a class label for each box. The\\n      num_valid_nms_boxes is a 0-D integer tensor representing the number of\\n      valid elements in `BoxList`, with the valid elements appearing first.\\n\\n  Raises:\\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have\\n      a valid scores field.\\n    ValueError: if Soft NMS (tf.image.non_max_suppression_with_scores) is not\\n      supported in the current TF version and `soft_nms_sigma` is nonzero.\\n  '\n    _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window)\n    if pad_to_max_output_size and soft_nms_sigma != 0.0:\n        raise ValueError('Soft NMS (soft_nms_sigma != 0.0) is currently not supported when pad_to_max_output_size is True.')\n    with tf.name_scope(scope, 'MultiClassNonMaxSuppression'):\n        num_scores = tf.shape(scores)[0]\n        num_classes = shape_utils.get_dim_as_int(scores.get_shape()[1])\n        selected_boxes_list = []\n        num_valid_nms_boxes_cumulative = tf.constant(0)\n        per_class_boxes_list = tf.unstack(boxes, axis=1)\n        if masks is not None:\n            per_class_masks_list = tf.unstack(masks, axis=1)\n        if boundaries is not None:\n            per_class_boundaries_list = tf.unstack(boundaries, axis=1)\n        boxes_ids = range(num_classes) if len(per_class_boxes_list) > 1 else [0] * num_classes\n        for (class_idx, boxes_idx) in zip(range(num_classes), boxes_ids):\n            per_class_boxes = per_class_boxes_list[boxes_idx]\n            boxlist_and_class_scores = box_list.BoxList(per_class_boxes)\n            class_scores = tf.reshape(tf.slice(scores, [0, class_idx], tf.stack([num_scores, 1])), [-1])\n            boxlist_and_class_scores.add_field(fields.BoxListFields.scores, class_scores)\n            if masks is not None:\n                per_class_masks = per_class_masks_list[boxes_idx]\n                boxlist_and_class_scores.add_field(fields.BoxListFields.masks, per_class_masks)\n            if boundaries is not None:\n                per_class_boundaries = per_class_boundaries_list[boxes_idx]\n                boxlist_and_class_scores.add_field(fields.BoxListFields.boundaries, per_class_boundaries)\n            if additional_fields is not None:\n                for (key, tensor) in additional_fields.items():\n                    boxlist_and_class_scores.add_field(key, tensor)\n            nms_result = None\n            selected_scores = None\n            if pad_to_max_output_size:\n                max_selection_size = max_size_per_class\n                if use_partitioned_nms:\n                    (selected_indices, num_valid_nms_boxes, boxlist_and_class_scores.data['boxes'], boxlist_and_class_scores.data['scores'], _) = partitioned_non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                else:\n                    (selected_indices, num_valid_nms_boxes) = tf.image.non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_to_max_output_size=True)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n            else:\n                max_selection_size = tf.minimum(max_size_per_class, boxlist_and_class_scores.num_boxes())\n                if hasattr(tf.image, 'non_max_suppression_with_scores') and tf.compat.forward_compatible(2019, 6, 6):\n                    (selected_indices, selected_scores) = tf.image.non_max_suppression_with_scores(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, soft_nms_sigma=soft_nms_sigma)\n                    num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                    selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                    selected_scores = tf.concat([selected_scores, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.float32)], -1)\n                    nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                else:\n                    if soft_nms_sigma != 0:\n                        raise ValueError('Soft NMS not supported in current TF version!')\n                    selected_indices = tf.image.non_max_suppression(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                    num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                    selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                    nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                    selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n            valid_nms_boxes_indices = tf.less(tf.range(max_selection_size), num_valid_nms_boxes)\n            nms_result.add_field(fields.BoxListFields.scores, tf.where(valid_nms_boxes_indices, selected_scores, -1 * tf.ones(max_selection_size)))\n            num_valid_nms_boxes_cumulative += num_valid_nms_boxes\n            nms_result.add_field(fields.BoxListFields.classes, tf.zeros_like(nms_result.get_field(fields.BoxListFields.scores)) + class_idx)\n            selected_boxes_list.append(nms_result)\n        selected_boxes = box_list_ops.concatenate(selected_boxes_list)\n        sorted_boxes = box_list_ops.sort_by_field(selected_boxes, fields.BoxListFields.scores)\n        if clip_window is not None:\n            (sorted_boxes, num_valid_nms_boxes_cumulative) = _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame)\n        if max_total_size:\n            max_total_size = tf.minimum(max_total_size, sorted_boxes.num_boxes())\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(max_total_size))\n            num_valid_nms_boxes_cumulative = tf.where(max_total_size > num_valid_nms_boxes_cumulative, num_valid_nms_boxes_cumulative, max_total_size)\n        if not pad_to_max_output_size:\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(num_valid_nms_boxes_cumulative))\n        return (sorted_boxes, num_valid_nms_boxes_cumulative)",
            "def multiclass_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_size_per_class, max_total_size=0, clip_window=None, change_coordinate_frame=False, masks=None, boundaries=None, pad_to_max_output_size=False, use_partitioned_nms=False, additional_fields=None, soft_nms_sigma=0.0, scope=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Multi-class version of non maximum suppression.\\n\\n  This op greedily selects a subset of detection bounding boxes, pruning\\n  away boxes that have high IOU (intersection over union) overlap (> thresh)\\n  with already selected boxes.  It operates independently for each class for\\n  which scores are provided (via the scores field of the input box_list),\\n  pruning boxes with score less than a provided threshold prior to\\n  applying NMS.\\n\\n  Please note that this operation is performed on *all* classes, therefore any\\n  background classes should be removed prior to calling this function.\\n\\n  Selected boxes are guaranteed to be sorted in decreasing order by score (but\\n  the sort is not guaranteed to be stable).\\n\\n  Args:\\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\\n      number of classes or 1 depending on whether a separate box is predicted\\n      per class.\\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\\n      the k detections. The scores have to be non-negative when\\n      pad_to_max_output_size is True.\\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    max_size_per_class: maximum number of retained boxes per class.\\n    max_total_size: maximum number of boxes retained over all classes. By\\n      default returns all boxes retained after capping boxes per class.\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window\\n      is provided)\\n    masks: (optional) a [k, q, mask_height, mask_width] float32 tensor\\n      containing box masks. `q` can be either number of classes or 1 depending\\n      on whether a separate mask is predicted per class.\\n    boundaries: (optional) a [k, q, boundary_height, boundary_width] float32\\n      tensor containing box boundaries. `q` can be either number of classes or 1\\n      depending on whether a separate boundary is predicted per class.\\n    pad_to_max_output_size: If true, the output nmsed boxes are padded to be of\\n      length `max_size_per_class`. Defaults to false.\\n    use_partitioned_nms: If true, use partitioned version of\\n      non_max_suppression.\\n    additional_fields: (optional) If not None, a dictionary that maps keys to\\n      tensors whose first dimensions are all of size `k`. After non-maximum\\n      suppression, all tensors corresponding to the selected boxes will be\\n      added to resulting BoxList.\\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\\n      False.\\n    scope: name scope.\\n\\n  Returns:\\n    A tuple of sorted_boxes and num_valid_nms_boxes. The sorted_boxes is a\\n      BoxList holds M boxes with a rank-1 scores field representing\\n      corresponding scores for each box with scores sorted in decreasing order\\n      and a rank-1 classes field representing a class label for each box. The\\n      num_valid_nms_boxes is a 0-D integer tensor representing the number of\\n      valid elements in `BoxList`, with the valid elements appearing first.\\n\\n  Raises:\\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have\\n      a valid scores field.\\n    ValueError: if Soft NMS (tf.image.non_max_suppression_with_scores) is not\\n      supported in the current TF version and `soft_nms_sigma` is nonzero.\\n  '\n    _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window)\n    if pad_to_max_output_size and soft_nms_sigma != 0.0:\n        raise ValueError('Soft NMS (soft_nms_sigma != 0.0) is currently not supported when pad_to_max_output_size is True.')\n    with tf.name_scope(scope, 'MultiClassNonMaxSuppression'):\n        num_scores = tf.shape(scores)[0]\n        num_classes = shape_utils.get_dim_as_int(scores.get_shape()[1])\n        selected_boxes_list = []\n        num_valid_nms_boxes_cumulative = tf.constant(0)\n        per_class_boxes_list = tf.unstack(boxes, axis=1)\n        if masks is not None:\n            per_class_masks_list = tf.unstack(masks, axis=1)\n        if boundaries is not None:\n            per_class_boundaries_list = tf.unstack(boundaries, axis=1)\n        boxes_ids = range(num_classes) if len(per_class_boxes_list) > 1 else [0] * num_classes\n        for (class_idx, boxes_idx) in zip(range(num_classes), boxes_ids):\n            per_class_boxes = per_class_boxes_list[boxes_idx]\n            boxlist_and_class_scores = box_list.BoxList(per_class_boxes)\n            class_scores = tf.reshape(tf.slice(scores, [0, class_idx], tf.stack([num_scores, 1])), [-1])\n            boxlist_and_class_scores.add_field(fields.BoxListFields.scores, class_scores)\n            if masks is not None:\n                per_class_masks = per_class_masks_list[boxes_idx]\n                boxlist_and_class_scores.add_field(fields.BoxListFields.masks, per_class_masks)\n            if boundaries is not None:\n                per_class_boundaries = per_class_boundaries_list[boxes_idx]\n                boxlist_and_class_scores.add_field(fields.BoxListFields.boundaries, per_class_boundaries)\n            if additional_fields is not None:\n                for (key, tensor) in additional_fields.items():\n                    boxlist_and_class_scores.add_field(key, tensor)\n            nms_result = None\n            selected_scores = None\n            if pad_to_max_output_size:\n                max_selection_size = max_size_per_class\n                if use_partitioned_nms:\n                    (selected_indices, num_valid_nms_boxes, boxlist_and_class_scores.data['boxes'], boxlist_and_class_scores.data['scores'], _) = partitioned_non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                else:\n                    (selected_indices, num_valid_nms_boxes) = tf.image.non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_to_max_output_size=True)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n            else:\n                max_selection_size = tf.minimum(max_size_per_class, boxlist_and_class_scores.num_boxes())\n                if hasattr(tf.image, 'non_max_suppression_with_scores') and tf.compat.forward_compatible(2019, 6, 6):\n                    (selected_indices, selected_scores) = tf.image.non_max_suppression_with_scores(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, soft_nms_sigma=soft_nms_sigma)\n                    num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                    selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                    selected_scores = tf.concat([selected_scores, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.float32)], -1)\n                    nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                else:\n                    if soft_nms_sigma != 0:\n                        raise ValueError('Soft NMS not supported in current TF version!')\n                    selected_indices = tf.image.non_max_suppression(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                    num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                    selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                    nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                    selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n            valid_nms_boxes_indices = tf.less(tf.range(max_selection_size), num_valid_nms_boxes)\n            nms_result.add_field(fields.BoxListFields.scores, tf.where(valid_nms_boxes_indices, selected_scores, -1 * tf.ones(max_selection_size)))\n            num_valid_nms_boxes_cumulative += num_valid_nms_boxes\n            nms_result.add_field(fields.BoxListFields.classes, tf.zeros_like(nms_result.get_field(fields.BoxListFields.scores)) + class_idx)\n            selected_boxes_list.append(nms_result)\n        selected_boxes = box_list_ops.concatenate(selected_boxes_list)\n        sorted_boxes = box_list_ops.sort_by_field(selected_boxes, fields.BoxListFields.scores)\n        if clip_window is not None:\n            (sorted_boxes, num_valid_nms_boxes_cumulative) = _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame)\n        if max_total_size:\n            max_total_size = tf.minimum(max_total_size, sorted_boxes.num_boxes())\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(max_total_size))\n            num_valid_nms_boxes_cumulative = tf.where(max_total_size > num_valid_nms_boxes_cumulative, num_valid_nms_boxes_cumulative, max_total_size)\n        if not pad_to_max_output_size:\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(num_valid_nms_boxes_cumulative))\n        return (sorted_boxes, num_valid_nms_boxes_cumulative)",
            "def multiclass_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_size_per_class, max_total_size=0, clip_window=None, change_coordinate_frame=False, masks=None, boundaries=None, pad_to_max_output_size=False, use_partitioned_nms=False, additional_fields=None, soft_nms_sigma=0.0, scope=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Multi-class version of non maximum suppression.\\n\\n  This op greedily selects a subset of detection bounding boxes, pruning\\n  away boxes that have high IOU (intersection over union) overlap (> thresh)\\n  with already selected boxes.  It operates independently for each class for\\n  which scores are provided (via the scores field of the input box_list),\\n  pruning boxes with score less than a provided threshold prior to\\n  applying NMS.\\n\\n  Please note that this operation is performed on *all* classes, therefore any\\n  background classes should be removed prior to calling this function.\\n\\n  Selected boxes are guaranteed to be sorted in decreasing order by score (but\\n  the sort is not guaranteed to be stable).\\n\\n  Args:\\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\\n      number of classes or 1 depending on whether a separate box is predicted\\n      per class.\\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\\n      the k detections. The scores have to be non-negative when\\n      pad_to_max_output_size is True.\\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    max_size_per_class: maximum number of retained boxes per class.\\n    max_total_size: maximum number of boxes retained over all classes. By\\n      default returns all boxes retained after capping boxes per class.\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window\\n      is provided)\\n    masks: (optional) a [k, q, mask_height, mask_width] float32 tensor\\n      containing box masks. `q` can be either number of classes or 1 depending\\n      on whether a separate mask is predicted per class.\\n    boundaries: (optional) a [k, q, boundary_height, boundary_width] float32\\n      tensor containing box boundaries. `q` can be either number of classes or 1\\n      depending on whether a separate boundary is predicted per class.\\n    pad_to_max_output_size: If true, the output nmsed boxes are padded to be of\\n      length `max_size_per_class`. Defaults to false.\\n    use_partitioned_nms: If true, use partitioned version of\\n      non_max_suppression.\\n    additional_fields: (optional) If not None, a dictionary that maps keys to\\n      tensors whose first dimensions are all of size `k`. After non-maximum\\n      suppression, all tensors corresponding to the selected boxes will be\\n      added to resulting BoxList.\\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\\n      False.\\n    scope: name scope.\\n\\n  Returns:\\n    A tuple of sorted_boxes and num_valid_nms_boxes. The sorted_boxes is a\\n      BoxList holds M boxes with a rank-1 scores field representing\\n      corresponding scores for each box with scores sorted in decreasing order\\n      and a rank-1 classes field representing a class label for each box. The\\n      num_valid_nms_boxes is a 0-D integer tensor representing the number of\\n      valid elements in `BoxList`, with the valid elements appearing first.\\n\\n  Raises:\\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have\\n      a valid scores field.\\n    ValueError: if Soft NMS (tf.image.non_max_suppression_with_scores) is not\\n      supported in the current TF version and `soft_nms_sigma` is nonzero.\\n  '\n    _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window)\n    if pad_to_max_output_size and soft_nms_sigma != 0.0:\n        raise ValueError('Soft NMS (soft_nms_sigma != 0.0) is currently not supported when pad_to_max_output_size is True.')\n    with tf.name_scope(scope, 'MultiClassNonMaxSuppression'):\n        num_scores = tf.shape(scores)[0]\n        num_classes = shape_utils.get_dim_as_int(scores.get_shape()[1])\n        selected_boxes_list = []\n        num_valid_nms_boxes_cumulative = tf.constant(0)\n        per_class_boxes_list = tf.unstack(boxes, axis=1)\n        if masks is not None:\n            per_class_masks_list = tf.unstack(masks, axis=1)\n        if boundaries is not None:\n            per_class_boundaries_list = tf.unstack(boundaries, axis=1)\n        boxes_ids = range(num_classes) if len(per_class_boxes_list) > 1 else [0] * num_classes\n        for (class_idx, boxes_idx) in zip(range(num_classes), boxes_ids):\n            per_class_boxes = per_class_boxes_list[boxes_idx]\n            boxlist_and_class_scores = box_list.BoxList(per_class_boxes)\n            class_scores = tf.reshape(tf.slice(scores, [0, class_idx], tf.stack([num_scores, 1])), [-1])\n            boxlist_and_class_scores.add_field(fields.BoxListFields.scores, class_scores)\n            if masks is not None:\n                per_class_masks = per_class_masks_list[boxes_idx]\n                boxlist_and_class_scores.add_field(fields.BoxListFields.masks, per_class_masks)\n            if boundaries is not None:\n                per_class_boundaries = per_class_boundaries_list[boxes_idx]\n                boxlist_and_class_scores.add_field(fields.BoxListFields.boundaries, per_class_boundaries)\n            if additional_fields is not None:\n                for (key, tensor) in additional_fields.items():\n                    boxlist_and_class_scores.add_field(key, tensor)\n            nms_result = None\n            selected_scores = None\n            if pad_to_max_output_size:\n                max_selection_size = max_size_per_class\n                if use_partitioned_nms:\n                    (selected_indices, num_valid_nms_boxes, boxlist_and_class_scores.data['boxes'], boxlist_and_class_scores.data['scores'], _) = partitioned_non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                else:\n                    (selected_indices, num_valid_nms_boxes) = tf.image.non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_to_max_output_size=True)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n            else:\n                max_selection_size = tf.minimum(max_size_per_class, boxlist_and_class_scores.num_boxes())\n                if hasattr(tf.image, 'non_max_suppression_with_scores') and tf.compat.forward_compatible(2019, 6, 6):\n                    (selected_indices, selected_scores) = tf.image.non_max_suppression_with_scores(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, soft_nms_sigma=soft_nms_sigma)\n                    num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                    selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                    selected_scores = tf.concat([selected_scores, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.float32)], -1)\n                    nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                else:\n                    if soft_nms_sigma != 0:\n                        raise ValueError('Soft NMS not supported in current TF version!')\n                    selected_indices = tf.image.non_max_suppression(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                    num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                    selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                    nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                    selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n            valid_nms_boxes_indices = tf.less(tf.range(max_selection_size), num_valid_nms_boxes)\n            nms_result.add_field(fields.BoxListFields.scores, tf.where(valid_nms_boxes_indices, selected_scores, -1 * tf.ones(max_selection_size)))\n            num_valid_nms_boxes_cumulative += num_valid_nms_boxes\n            nms_result.add_field(fields.BoxListFields.classes, tf.zeros_like(nms_result.get_field(fields.BoxListFields.scores)) + class_idx)\n            selected_boxes_list.append(nms_result)\n        selected_boxes = box_list_ops.concatenate(selected_boxes_list)\n        sorted_boxes = box_list_ops.sort_by_field(selected_boxes, fields.BoxListFields.scores)\n        if clip_window is not None:\n            (sorted_boxes, num_valid_nms_boxes_cumulative) = _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame)\n        if max_total_size:\n            max_total_size = tf.minimum(max_total_size, sorted_boxes.num_boxes())\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(max_total_size))\n            num_valid_nms_boxes_cumulative = tf.where(max_total_size > num_valid_nms_boxes_cumulative, num_valid_nms_boxes_cumulative, max_total_size)\n        if not pad_to_max_output_size:\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(num_valid_nms_boxes_cumulative))\n        return (sorted_boxes, num_valid_nms_boxes_cumulative)",
            "def multiclass_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_size_per_class, max_total_size=0, clip_window=None, change_coordinate_frame=False, masks=None, boundaries=None, pad_to_max_output_size=False, use_partitioned_nms=False, additional_fields=None, soft_nms_sigma=0.0, scope=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Multi-class version of non maximum suppression.\\n\\n  This op greedily selects a subset of detection bounding boxes, pruning\\n  away boxes that have high IOU (intersection over union) overlap (> thresh)\\n  with already selected boxes.  It operates independently for each class for\\n  which scores are provided (via the scores field of the input box_list),\\n  pruning boxes with score less than a provided threshold prior to\\n  applying NMS.\\n\\n  Please note that this operation is performed on *all* classes, therefore any\\n  background classes should be removed prior to calling this function.\\n\\n  Selected boxes are guaranteed to be sorted in decreasing order by score (but\\n  the sort is not guaranteed to be stable).\\n\\n  Args:\\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\\n      number of classes or 1 depending on whether a separate box is predicted\\n      per class.\\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\\n      the k detections. The scores have to be non-negative when\\n      pad_to_max_output_size is True.\\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    max_size_per_class: maximum number of retained boxes per class.\\n    max_total_size: maximum number of boxes retained over all classes. By\\n      default returns all boxes retained after capping boxes per class.\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window\\n      is provided)\\n    masks: (optional) a [k, q, mask_height, mask_width] float32 tensor\\n      containing box masks. `q` can be either number of classes or 1 depending\\n      on whether a separate mask is predicted per class.\\n    boundaries: (optional) a [k, q, boundary_height, boundary_width] float32\\n      tensor containing box boundaries. `q` can be either number of classes or 1\\n      depending on whether a separate boundary is predicted per class.\\n    pad_to_max_output_size: If true, the output nmsed boxes are padded to be of\\n      length `max_size_per_class`. Defaults to false.\\n    use_partitioned_nms: If true, use partitioned version of\\n      non_max_suppression.\\n    additional_fields: (optional) If not None, a dictionary that maps keys to\\n      tensors whose first dimensions are all of size `k`. After non-maximum\\n      suppression, all tensors corresponding to the selected boxes will be\\n      added to resulting BoxList.\\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\\n      False.\\n    scope: name scope.\\n\\n  Returns:\\n    A tuple of sorted_boxes and num_valid_nms_boxes. The sorted_boxes is a\\n      BoxList holds M boxes with a rank-1 scores field representing\\n      corresponding scores for each box with scores sorted in decreasing order\\n      and a rank-1 classes field representing a class label for each box. The\\n      num_valid_nms_boxes is a 0-D integer tensor representing the number of\\n      valid elements in `BoxList`, with the valid elements appearing first.\\n\\n  Raises:\\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have\\n      a valid scores field.\\n    ValueError: if Soft NMS (tf.image.non_max_suppression_with_scores) is not\\n      supported in the current TF version and `soft_nms_sigma` is nonzero.\\n  '\n    _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window)\n    if pad_to_max_output_size and soft_nms_sigma != 0.0:\n        raise ValueError('Soft NMS (soft_nms_sigma != 0.0) is currently not supported when pad_to_max_output_size is True.')\n    with tf.name_scope(scope, 'MultiClassNonMaxSuppression'):\n        num_scores = tf.shape(scores)[0]\n        num_classes = shape_utils.get_dim_as_int(scores.get_shape()[1])\n        selected_boxes_list = []\n        num_valid_nms_boxes_cumulative = tf.constant(0)\n        per_class_boxes_list = tf.unstack(boxes, axis=1)\n        if masks is not None:\n            per_class_masks_list = tf.unstack(masks, axis=1)\n        if boundaries is not None:\n            per_class_boundaries_list = tf.unstack(boundaries, axis=1)\n        boxes_ids = range(num_classes) if len(per_class_boxes_list) > 1 else [0] * num_classes\n        for (class_idx, boxes_idx) in zip(range(num_classes), boxes_ids):\n            per_class_boxes = per_class_boxes_list[boxes_idx]\n            boxlist_and_class_scores = box_list.BoxList(per_class_boxes)\n            class_scores = tf.reshape(tf.slice(scores, [0, class_idx], tf.stack([num_scores, 1])), [-1])\n            boxlist_and_class_scores.add_field(fields.BoxListFields.scores, class_scores)\n            if masks is not None:\n                per_class_masks = per_class_masks_list[boxes_idx]\n                boxlist_and_class_scores.add_field(fields.BoxListFields.masks, per_class_masks)\n            if boundaries is not None:\n                per_class_boundaries = per_class_boundaries_list[boxes_idx]\n                boxlist_and_class_scores.add_field(fields.BoxListFields.boundaries, per_class_boundaries)\n            if additional_fields is not None:\n                for (key, tensor) in additional_fields.items():\n                    boxlist_and_class_scores.add_field(key, tensor)\n            nms_result = None\n            selected_scores = None\n            if pad_to_max_output_size:\n                max_selection_size = max_size_per_class\n                if use_partitioned_nms:\n                    (selected_indices, num_valid_nms_boxes, boxlist_and_class_scores.data['boxes'], boxlist_and_class_scores.data['scores'], _) = partitioned_non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                else:\n                    (selected_indices, num_valid_nms_boxes) = tf.image.non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_to_max_output_size=True)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n            else:\n                max_selection_size = tf.minimum(max_size_per_class, boxlist_and_class_scores.num_boxes())\n                if hasattr(tf.image, 'non_max_suppression_with_scores') and tf.compat.forward_compatible(2019, 6, 6):\n                    (selected_indices, selected_scores) = tf.image.non_max_suppression_with_scores(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, soft_nms_sigma=soft_nms_sigma)\n                    num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                    selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                    selected_scores = tf.concat([selected_scores, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.float32)], -1)\n                    nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                else:\n                    if soft_nms_sigma != 0:\n                        raise ValueError('Soft NMS not supported in current TF version!')\n                    selected_indices = tf.image.non_max_suppression(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                    num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                    selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                    nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                    selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n            valid_nms_boxes_indices = tf.less(tf.range(max_selection_size), num_valid_nms_boxes)\n            nms_result.add_field(fields.BoxListFields.scores, tf.where(valid_nms_boxes_indices, selected_scores, -1 * tf.ones(max_selection_size)))\n            num_valid_nms_boxes_cumulative += num_valid_nms_boxes\n            nms_result.add_field(fields.BoxListFields.classes, tf.zeros_like(nms_result.get_field(fields.BoxListFields.scores)) + class_idx)\n            selected_boxes_list.append(nms_result)\n        selected_boxes = box_list_ops.concatenate(selected_boxes_list)\n        sorted_boxes = box_list_ops.sort_by_field(selected_boxes, fields.BoxListFields.scores)\n        if clip_window is not None:\n            (sorted_boxes, num_valid_nms_boxes_cumulative) = _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame)\n        if max_total_size:\n            max_total_size = tf.minimum(max_total_size, sorted_boxes.num_boxes())\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(max_total_size))\n            num_valid_nms_boxes_cumulative = tf.where(max_total_size > num_valid_nms_boxes_cumulative, num_valid_nms_boxes_cumulative, max_total_size)\n        if not pad_to_max_output_size:\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(num_valid_nms_boxes_cumulative))\n        return (sorted_boxes, num_valid_nms_boxes_cumulative)"
        ]
    },
    {
        "func_name": "class_agnostic_non_max_suppression",
        "original": "def class_agnostic_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_classes_per_detection=1, max_total_size=0, clip_window=None, change_coordinate_frame=False, masks=None, boundaries=None, pad_to_max_output_size=False, use_partitioned_nms=False, additional_fields=None, soft_nms_sigma=0.0, scope=None):\n    \"\"\"Class-agnostic version of non maximum suppression.\n\n  This op greedily selects a subset of detection bounding boxes, pruning\n  away boxes that have high IOU (intersection over union) overlap (> thresh)\n  with already selected boxes.  It operates on all the boxes using\n  max scores across all classes for which scores are provided (via the scores\n  field of the input box_list), pruning boxes with score less than a provided\n  threshold prior to applying NMS.\n\n  Please note that this operation is performed in a class-agnostic way,\n  therefore any background classes should be removed prior to calling this\n  function.\n\n  Selected boxes are guaranteed to be sorted in decreasing order by score (but\n  the sort is not guaranteed to be stable).\n\n  Args:\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\n      number of classes or 1 depending on whether a separate box is predicted\n      per class.\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\n      the k detections. The scores have to be non-negative when\n      pad_to_max_output_size is True.\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\n      with previously selected boxes are removed).\n    max_classes_per_detection: maximum number of retained classes per detection\n      box in class-agnostic NMS.\n    max_total_size: maximum number of boxes retained over all classes. By\n      default returns all boxes retained after capping boxes per class.\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\n      representing the window to clip and normalize boxes to before performing\n      non-max suppression.\n    change_coordinate_frame: Whether to normalize coordinates after clipping\n      relative to clip_window (this can only be set to True if a clip_window is\n      provided)\n    masks: (optional) a [k, q, mask_height, mask_width] float32 tensor\n      containing box masks. `q` can be either number of classes or 1 depending\n      on whether a separate mask is predicted per class.\n    boundaries: (optional) a [k, q, boundary_height, boundary_width] float32\n      tensor containing box boundaries. `q` can be either number of classes or 1\n      depending on whether a separate boundary is predicted per class.\n    pad_to_max_output_size: If true, the output nmsed boxes are padded to be of\n      length `max_size_per_class`. Defaults to false.\n    use_partitioned_nms: If true, use partitioned version of\n      non_max_suppression.\n    additional_fields: (optional) If not None, a dictionary that maps keys to\n      tensors whose first dimensions are all of size `k`. After non-maximum\n      suppression, all tensors corresponding to the selected boxes will be added\n      to resulting BoxList.\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\n      False.\n    scope: name scope.\n\n  Returns:\n    A tuple of sorted_boxes and num_valid_nms_boxes. The sorted_boxes is a\n      BoxList holds M boxes with a rank-1 scores field representing\n      corresponding scores for each box with scores sorted in decreasing order\n      and a rank-1 classes field representing a class label for each box. The\n      num_valid_nms_boxes is a 0-D integer tensor representing the number of\n      valid elements in `BoxList`, with the valid elements appearing first.\n\n  Raises:\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have\n      a valid scores field or if non-zero soft_nms_sigma is provided when\n      pad_to_max_output_size is True.\n  \"\"\"\n    _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window)\n    if pad_to_max_output_size and soft_nms_sigma != 0.0:\n        raise ValueError('Soft NMS (soft_nms_sigma != 0.0) is currently not supported when pad_to_max_output_size is True.')\n    if max_classes_per_detection > 1:\n        raise ValueError('Max classes per detection box >1 not supported.')\n    q = shape_utils.get_dim_as_int(boxes.shape[1])\n    if q > 1:\n        class_ids = tf.expand_dims(tf.argmax(scores, axis=1, output_type=tf.int32), axis=1)\n        boxes = tf.batch_gather(boxes, class_ids)\n        if masks is not None:\n            masks = tf.batch_gather(masks, class_ids)\n        if boundaries is not None:\n            boundaries = tf.batch_gather(boundaries, class_ids)\n    boxes = tf.squeeze(boxes, axis=[1])\n    if masks is not None:\n        masks = tf.squeeze(masks, axis=[1])\n    if boundaries is not None:\n        boundaries = tf.squeeze(boundaries, axis=[1])\n    with tf.name_scope(scope, 'ClassAgnosticNonMaxSuppression'):\n        boxlist_and_class_scores = box_list.BoxList(boxes)\n        max_scores = tf.reduce_max(scores, axis=-1)\n        classes_with_max_scores = tf.argmax(scores, axis=-1)\n        boxlist_and_class_scores.add_field(fields.BoxListFields.scores, max_scores)\n        if masks is not None:\n            boxlist_and_class_scores.add_field(fields.BoxListFields.masks, masks)\n        if boundaries is not None:\n            boxlist_and_class_scores.add_field(fields.BoxListFields.boundaries, boundaries)\n        if additional_fields is not None:\n            for (key, tensor) in additional_fields.items():\n                boxlist_and_class_scores.add_field(key, tensor)\n        nms_result = None\n        selected_scores = None\n        if pad_to_max_output_size:\n            max_selection_size = max_total_size\n            if use_partitioned_nms:\n                (selected_indices, num_valid_nms_boxes, boxlist_and_class_scores.data['boxes'], boxlist_and_class_scores.data['scores'], argsort_ids) = partitioned_non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                classes_with_max_scores = tf.gather(classes_with_max_scores, argsort_ids)\n            else:\n                (selected_indices, num_valid_nms_boxes) = tf.image.non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_to_max_output_size=True)\n            nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n            selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n        else:\n            max_selection_size = tf.minimum(max_total_size, boxlist_and_class_scores.num_boxes())\n            if hasattr(tf.image, 'non_max_suppression_with_scores') and tf.compat.forward_compatible(2019, 6, 6):\n                (selected_indices, selected_scores) = tf.image.non_max_suppression_with_scores(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, soft_nms_sigma=soft_nms_sigma)\n                num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                selected_scores = tf.concat([selected_scores, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.float32)], -1)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n            else:\n                if soft_nms_sigma != 0:\n                    raise ValueError('Soft NMS not supported in current TF version!')\n                selected_indices = tf.image.non_max_suppression(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n        valid_nms_boxes_indices = tf.less(tf.range(max_selection_size), num_valid_nms_boxes)\n        nms_result.add_field(fields.BoxListFields.scores, tf.where(valid_nms_boxes_indices, selected_scores, -1 * tf.ones(max_selection_size)))\n        selected_classes = tf.gather(classes_with_max_scores, selected_indices)\n        selected_classes = tf.cast(selected_classes, tf.float32)\n        nms_result.add_field(fields.BoxListFields.classes, selected_classes)\n        selected_boxes = nms_result\n        sorted_boxes = box_list_ops.sort_by_field(selected_boxes, fields.BoxListFields.scores)\n        if clip_window is not None:\n            (sorted_boxes, num_valid_nms_boxes) = _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame)\n        if max_total_size:\n            max_total_size = tf.minimum(max_total_size, sorted_boxes.num_boxes())\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(max_total_size))\n            num_valid_nms_boxes = tf.where(max_total_size > num_valid_nms_boxes, num_valid_nms_boxes, max_total_size)\n        if not pad_to_max_output_size:\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(num_valid_nms_boxes))\n        return (sorted_boxes, num_valid_nms_boxes)",
        "mutated": [
            "def class_agnostic_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_classes_per_detection=1, max_total_size=0, clip_window=None, change_coordinate_frame=False, masks=None, boundaries=None, pad_to_max_output_size=False, use_partitioned_nms=False, additional_fields=None, soft_nms_sigma=0.0, scope=None):\n    if False:\n        i = 10\n    'Class-agnostic version of non maximum suppression.\\n\\n  This op greedily selects a subset of detection bounding boxes, pruning\\n  away boxes that have high IOU (intersection over union) overlap (> thresh)\\n  with already selected boxes.  It operates on all the boxes using\\n  max scores across all classes for which scores are provided (via the scores\\n  field of the input box_list), pruning boxes with score less than a provided\\n  threshold prior to applying NMS.\\n\\n  Please note that this operation is performed in a class-agnostic way,\\n  therefore any background classes should be removed prior to calling this\\n  function.\\n\\n  Selected boxes are guaranteed to be sorted in decreasing order by score (but\\n  the sort is not guaranteed to be stable).\\n\\n  Args:\\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\\n      number of classes or 1 depending on whether a separate box is predicted\\n      per class.\\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\\n      the k detections. The scores have to be non-negative when\\n      pad_to_max_output_size is True.\\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    max_classes_per_detection: maximum number of retained classes per detection\\n      box in class-agnostic NMS.\\n    max_total_size: maximum number of boxes retained over all classes. By\\n      default returns all boxes retained after capping boxes per class.\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided)\\n    masks: (optional) a [k, q, mask_height, mask_width] float32 tensor\\n      containing box masks. `q` can be either number of classes or 1 depending\\n      on whether a separate mask is predicted per class.\\n    boundaries: (optional) a [k, q, boundary_height, boundary_width] float32\\n      tensor containing box boundaries. `q` can be either number of classes or 1\\n      depending on whether a separate boundary is predicted per class.\\n    pad_to_max_output_size: If true, the output nmsed boxes are padded to be of\\n      length `max_size_per_class`. Defaults to false.\\n    use_partitioned_nms: If true, use partitioned version of\\n      non_max_suppression.\\n    additional_fields: (optional) If not None, a dictionary that maps keys to\\n      tensors whose first dimensions are all of size `k`. After non-maximum\\n      suppression, all tensors corresponding to the selected boxes will be added\\n      to resulting BoxList.\\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\\n      False.\\n    scope: name scope.\\n\\n  Returns:\\n    A tuple of sorted_boxes and num_valid_nms_boxes. The sorted_boxes is a\\n      BoxList holds M boxes with a rank-1 scores field representing\\n      corresponding scores for each box with scores sorted in decreasing order\\n      and a rank-1 classes field representing a class label for each box. The\\n      num_valid_nms_boxes is a 0-D integer tensor representing the number of\\n      valid elements in `BoxList`, with the valid elements appearing first.\\n\\n  Raises:\\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have\\n      a valid scores field or if non-zero soft_nms_sigma is provided when\\n      pad_to_max_output_size is True.\\n  '\n    _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window)\n    if pad_to_max_output_size and soft_nms_sigma != 0.0:\n        raise ValueError('Soft NMS (soft_nms_sigma != 0.0) is currently not supported when pad_to_max_output_size is True.')\n    if max_classes_per_detection > 1:\n        raise ValueError('Max classes per detection box >1 not supported.')\n    q = shape_utils.get_dim_as_int(boxes.shape[1])\n    if q > 1:\n        class_ids = tf.expand_dims(tf.argmax(scores, axis=1, output_type=tf.int32), axis=1)\n        boxes = tf.batch_gather(boxes, class_ids)\n        if masks is not None:\n            masks = tf.batch_gather(masks, class_ids)\n        if boundaries is not None:\n            boundaries = tf.batch_gather(boundaries, class_ids)\n    boxes = tf.squeeze(boxes, axis=[1])\n    if masks is not None:\n        masks = tf.squeeze(masks, axis=[1])\n    if boundaries is not None:\n        boundaries = tf.squeeze(boundaries, axis=[1])\n    with tf.name_scope(scope, 'ClassAgnosticNonMaxSuppression'):\n        boxlist_and_class_scores = box_list.BoxList(boxes)\n        max_scores = tf.reduce_max(scores, axis=-1)\n        classes_with_max_scores = tf.argmax(scores, axis=-1)\n        boxlist_and_class_scores.add_field(fields.BoxListFields.scores, max_scores)\n        if masks is not None:\n            boxlist_and_class_scores.add_field(fields.BoxListFields.masks, masks)\n        if boundaries is not None:\n            boxlist_and_class_scores.add_field(fields.BoxListFields.boundaries, boundaries)\n        if additional_fields is not None:\n            for (key, tensor) in additional_fields.items():\n                boxlist_and_class_scores.add_field(key, tensor)\n        nms_result = None\n        selected_scores = None\n        if pad_to_max_output_size:\n            max_selection_size = max_total_size\n            if use_partitioned_nms:\n                (selected_indices, num_valid_nms_boxes, boxlist_and_class_scores.data['boxes'], boxlist_and_class_scores.data['scores'], argsort_ids) = partitioned_non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                classes_with_max_scores = tf.gather(classes_with_max_scores, argsort_ids)\n            else:\n                (selected_indices, num_valid_nms_boxes) = tf.image.non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_to_max_output_size=True)\n            nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n            selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n        else:\n            max_selection_size = tf.minimum(max_total_size, boxlist_and_class_scores.num_boxes())\n            if hasattr(tf.image, 'non_max_suppression_with_scores') and tf.compat.forward_compatible(2019, 6, 6):\n                (selected_indices, selected_scores) = tf.image.non_max_suppression_with_scores(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, soft_nms_sigma=soft_nms_sigma)\n                num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                selected_scores = tf.concat([selected_scores, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.float32)], -1)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n            else:\n                if soft_nms_sigma != 0:\n                    raise ValueError('Soft NMS not supported in current TF version!')\n                selected_indices = tf.image.non_max_suppression(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n        valid_nms_boxes_indices = tf.less(tf.range(max_selection_size), num_valid_nms_boxes)\n        nms_result.add_field(fields.BoxListFields.scores, tf.where(valid_nms_boxes_indices, selected_scores, -1 * tf.ones(max_selection_size)))\n        selected_classes = tf.gather(classes_with_max_scores, selected_indices)\n        selected_classes = tf.cast(selected_classes, tf.float32)\n        nms_result.add_field(fields.BoxListFields.classes, selected_classes)\n        selected_boxes = nms_result\n        sorted_boxes = box_list_ops.sort_by_field(selected_boxes, fields.BoxListFields.scores)\n        if clip_window is not None:\n            (sorted_boxes, num_valid_nms_boxes) = _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame)\n        if max_total_size:\n            max_total_size = tf.minimum(max_total_size, sorted_boxes.num_boxes())\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(max_total_size))\n            num_valid_nms_boxes = tf.where(max_total_size > num_valid_nms_boxes, num_valid_nms_boxes, max_total_size)\n        if not pad_to_max_output_size:\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(num_valid_nms_boxes))\n        return (sorted_boxes, num_valid_nms_boxes)",
            "def class_agnostic_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_classes_per_detection=1, max_total_size=0, clip_window=None, change_coordinate_frame=False, masks=None, boundaries=None, pad_to_max_output_size=False, use_partitioned_nms=False, additional_fields=None, soft_nms_sigma=0.0, scope=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Class-agnostic version of non maximum suppression.\\n\\n  This op greedily selects a subset of detection bounding boxes, pruning\\n  away boxes that have high IOU (intersection over union) overlap (> thresh)\\n  with already selected boxes.  It operates on all the boxes using\\n  max scores across all classes for which scores are provided (via the scores\\n  field of the input box_list), pruning boxes with score less than a provided\\n  threshold prior to applying NMS.\\n\\n  Please note that this operation is performed in a class-agnostic way,\\n  therefore any background classes should be removed prior to calling this\\n  function.\\n\\n  Selected boxes are guaranteed to be sorted in decreasing order by score (but\\n  the sort is not guaranteed to be stable).\\n\\n  Args:\\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\\n      number of classes or 1 depending on whether a separate box is predicted\\n      per class.\\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\\n      the k detections. The scores have to be non-negative when\\n      pad_to_max_output_size is True.\\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    max_classes_per_detection: maximum number of retained classes per detection\\n      box in class-agnostic NMS.\\n    max_total_size: maximum number of boxes retained over all classes. By\\n      default returns all boxes retained after capping boxes per class.\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided)\\n    masks: (optional) a [k, q, mask_height, mask_width] float32 tensor\\n      containing box masks. `q` can be either number of classes or 1 depending\\n      on whether a separate mask is predicted per class.\\n    boundaries: (optional) a [k, q, boundary_height, boundary_width] float32\\n      tensor containing box boundaries. `q` can be either number of classes or 1\\n      depending on whether a separate boundary is predicted per class.\\n    pad_to_max_output_size: If true, the output nmsed boxes are padded to be of\\n      length `max_size_per_class`. Defaults to false.\\n    use_partitioned_nms: If true, use partitioned version of\\n      non_max_suppression.\\n    additional_fields: (optional) If not None, a dictionary that maps keys to\\n      tensors whose first dimensions are all of size `k`. After non-maximum\\n      suppression, all tensors corresponding to the selected boxes will be added\\n      to resulting BoxList.\\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\\n      False.\\n    scope: name scope.\\n\\n  Returns:\\n    A tuple of sorted_boxes and num_valid_nms_boxes. The sorted_boxes is a\\n      BoxList holds M boxes with a rank-1 scores field representing\\n      corresponding scores for each box with scores sorted in decreasing order\\n      and a rank-1 classes field representing a class label for each box. The\\n      num_valid_nms_boxes is a 0-D integer tensor representing the number of\\n      valid elements in `BoxList`, with the valid elements appearing first.\\n\\n  Raises:\\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have\\n      a valid scores field or if non-zero soft_nms_sigma is provided when\\n      pad_to_max_output_size is True.\\n  '\n    _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window)\n    if pad_to_max_output_size and soft_nms_sigma != 0.0:\n        raise ValueError('Soft NMS (soft_nms_sigma != 0.0) is currently not supported when pad_to_max_output_size is True.')\n    if max_classes_per_detection > 1:\n        raise ValueError('Max classes per detection box >1 not supported.')\n    q = shape_utils.get_dim_as_int(boxes.shape[1])\n    if q > 1:\n        class_ids = tf.expand_dims(tf.argmax(scores, axis=1, output_type=tf.int32), axis=1)\n        boxes = tf.batch_gather(boxes, class_ids)\n        if masks is not None:\n            masks = tf.batch_gather(masks, class_ids)\n        if boundaries is not None:\n            boundaries = tf.batch_gather(boundaries, class_ids)\n    boxes = tf.squeeze(boxes, axis=[1])\n    if masks is not None:\n        masks = tf.squeeze(masks, axis=[1])\n    if boundaries is not None:\n        boundaries = tf.squeeze(boundaries, axis=[1])\n    with tf.name_scope(scope, 'ClassAgnosticNonMaxSuppression'):\n        boxlist_and_class_scores = box_list.BoxList(boxes)\n        max_scores = tf.reduce_max(scores, axis=-1)\n        classes_with_max_scores = tf.argmax(scores, axis=-1)\n        boxlist_and_class_scores.add_field(fields.BoxListFields.scores, max_scores)\n        if masks is not None:\n            boxlist_and_class_scores.add_field(fields.BoxListFields.masks, masks)\n        if boundaries is not None:\n            boxlist_and_class_scores.add_field(fields.BoxListFields.boundaries, boundaries)\n        if additional_fields is not None:\n            for (key, tensor) in additional_fields.items():\n                boxlist_and_class_scores.add_field(key, tensor)\n        nms_result = None\n        selected_scores = None\n        if pad_to_max_output_size:\n            max_selection_size = max_total_size\n            if use_partitioned_nms:\n                (selected_indices, num_valid_nms_boxes, boxlist_and_class_scores.data['boxes'], boxlist_and_class_scores.data['scores'], argsort_ids) = partitioned_non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                classes_with_max_scores = tf.gather(classes_with_max_scores, argsort_ids)\n            else:\n                (selected_indices, num_valid_nms_boxes) = tf.image.non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_to_max_output_size=True)\n            nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n            selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n        else:\n            max_selection_size = tf.minimum(max_total_size, boxlist_and_class_scores.num_boxes())\n            if hasattr(tf.image, 'non_max_suppression_with_scores') and tf.compat.forward_compatible(2019, 6, 6):\n                (selected_indices, selected_scores) = tf.image.non_max_suppression_with_scores(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, soft_nms_sigma=soft_nms_sigma)\n                num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                selected_scores = tf.concat([selected_scores, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.float32)], -1)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n            else:\n                if soft_nms_sigma != 0:\n                    raise ValueError('Soft NMS not supported in current TF version!')\n                selected_indices = tf.image.non_max_suppression(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n        valid_nms_boxes_indices = tf.less(tf.range(max_selection_size), num_valid_nms_boxes)\n        nms_result.add_field(fields.BoxListFields.scores, tf.where(valid_nms_boxes_indices, selected_scores, -1 * tf.ones(max_selection_size)))\n        selected_classes = tf.gather(classes_with_max_scores, selected_indices)\n        selected_classes = tf.cast(selected_classes, tf.float32)\n        nms_result.add_field(fields.BoxListFields.classes, selected_classes)\n        selected_boxes = nms_result\n        sorted_boxes = box_list_ops.sort_by_field(selected_boxes, fields.BoxListFields.scores)\n        if clip_window is not None:\n            (sorted_boxes, num_valid_nms_boxes) = _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame)\n        if max_total_size:\n            max_total_size = tf.minimum(max_total_size, sorted_boxes.num_boxes())\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(max_total_size))\n            num_valid_nms_boxes = tf.where(max_total_size > num_valid_nms_boxes, num_valid_nms_boxes, max_total_size)\n        if not pad_to_max_output_size:\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(num_valid_nms_boxes))\n        return (sorted_boxes, num_valid_nms_boxes)",
            "def class_agnostic_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_classes_per_detection=1, max_total_size=0, clip_window=None, change_coordinate_frame=False, masks=None, boundaries=None, pad_to_max_output_size=False, use_partitioned_nms=False, additional_fields=None, soft_nms_sigma=0.0, scope=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Class-agnostic version of non maximum suppression.\\n\\n  This op greedily selects a subset of detection bounding boxes, pruning\\n  away boxes that have high IOU (intersection over union) overlap (> thresh)\\n  with already selected boxes.  It operates on all the boxes using\\n  max scores across all classes for which scores are provided (via the scores\\n  field of the input box_list), pruning boxes with score less than a provided\\n  threshold prior to applying NMS.\\n\\n  Please note that this operation is performed in a class-agnostic way,\\n  therefore any background classes should be removed prior to calling this\\n  function.\\n\\n  Selected boxes are guaranteed to be sorted in decreasing order by score (but\\n  the sort is not guaranteed to be stable).\\n\\n  Args:\\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\\n      number of classes or 1 depending on whether a separate box is predicted\\n      per class.\\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\\n      the k detections. The scores have to be non-negative when\\n      pad_to_max_output_size is True.\\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    max_classes_per_detection: maximum number of retained classes per detection\\n      box in class-agnostic NMS.\\n    max_total_size: maximum number of boxes retained over all classes. By\\n      default returns all boxes retained after capping boxes per class.\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided)\\n    masks: (optional) a [k, q, mask_height, mask_width] float32 tensor\\n      containing box masks. `q` can be either number of classes or 1 depending\\n      on whether a separate mask is predicted per class.\\n    boundaries: (optional) a [k, q, boundary_height, boundary_width] float32\\n      tensor containing box boundaries. `q` can be either number of classes or 1\\n      depending on whether a separate boundary is predicted per class.\\n    pad_to_max_output_size: If true, the output nmsed boxes are padded to be of\\n      length `max_size_per_class`. Defaults to false.\\n    use_partitioned_nms: If true, use partitioned version of\\n      non_max_suppression.\\n    additional_fields: (optional) If not None, a dictionary that maps keys to\\n      tensors whose first dimensions are all of size `k`. After non-maximum\\n      suppression, all tensors corresponding to the selected boxes will be added\\n      to resulting BoxList.\\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\\n      False.\\n    scope: name scope.\\n\\n  Returns:\\n    A tuple of sorted_boxes and num_valid_nms_boxes. The sorted_boxes is a\\n      BoxList holds M boxes with a rank-1 scores field representing\\n      corresponding scores for each box with scores sorted in decreasing order\\n      and a rank-1 classes field representing a class label for each box. The\\n      num_valid_nms_boxes is a 0-D integer tensor representing the number of\\n      valid elements in `BoxList`, with the valid elements appearing first.\\n\\n  Raises:\\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have\\n      a valid scores field or if non-zero soft_nms_sigma is provided when\\n      pad_to_max_output_size is True.\\n  '\n    _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window)\n    if pad_to_max_output_size and soft_nms_sigma != 0.0:\n        raise ValueError('Soft NMS (soft_nms_sigma != 0.0) is currently not supported when pad_to_max_output_size is True.')\n    if max_classes_per_detection > 1:\n        raise ValueError('Max classes per detection box >1 not supported.')\n    q = shape_utils.get_dim_as_int(boxes.shape[1])\n    if q > 1:\n        class_ids = tf.expand_dims(tf.argmax(scores, axis=1, output_type=tf.int32), axis=1)\n        boxes = tf.batch_gather(boxes, class_ids)\n        if masks is not None:\n            masks = tf.batch_gather(masks, class_ids)\n        if boundaries is not None:\n            boundaries = tf.batch_gather(boundaries, class_ids)\n    boxes = tf.squeeze(boxes, axis=[1])\n    if masks is not None:\n        masks = tf.squeeze(masks, axis=[1])\n    if boundaries is not None:\n        boundaries = tf.squeeze(boundaries, axis=[1])\n    with tf.name_scope(scope, 'ClassAgnosticNonMaxSuppression'):\n        boxlist_and_class_scores = box_list.BoxList(boxes)\n        max_scores = tf.reduce_max(scores, axis=-1)\n        classes_with_max_scores = tf.argmax(scores, axis=-1)\n        boxlist_and_class_scores.add_field(fields.BoxListFields.scores, max_scores)\n        if masks is not None:\n            boxlist_and_class_scores.add_field(fields.BoxListFields.masks, masks)\n        if boundaries is not None:\n            boxlist_and_class_scores.add_field(fields.BoxListFields.boundaries, boundaries)\n        if additional_fields is not None:\n            for (key, tensor) in additional_fields.items():\n                boxlist_and_class_scores.add_field(key, tensor)\n        nms_result = None\n        selected_scores = None\n        if pad_to_max_output_size:\n            max_selection_size = max_total_size\n            if use_partitioned_nms:\n                (selected_indices, num_valid_nms_boxes, boxlist_and_class_scores.data['boxes'], boxlist_and_class_scores.data['scores'], argsort_ids) = partitioned_non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                classes_with_max_scores = tf.gather(classes_with_max_scores, argsort_ids)\n            else:\n                (selected_indices, num_valid_nms_boxes) = tf.image.non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_to_max_output_size=True)\n            nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n            selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n        else:\n            max_selection_size = tf.minimum(max_total_size, boxlist_and_class_scores.num_boxes())\n            if hasattr(tf.image, 'non_max_suppression_with_scores') and tf.compat.forward_compatible(2019, 6, 6):\n                (selected_indices, selected_scores) = tf.image.non_max_suppression_with_scores(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, soft_nms_sigma=soft_nms_sigma)\n                num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                selected_scores = tf.concat([selected_scores, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.float32)], -1)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n            else:\n                if soft_nms_sigma != 0:\n                    raise ValueError('Soft NMS not supported in current TF version!')\n                selected_indices = tf.image.non_max_suppression(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n        valid_nms_boxes_indices = tf.less(tf.range(max_selection_size), num_valid_nms_boxes)\n        nms_result.add_field(fields.BoxListFields.scores, tf.where(valid_nms_boxes_indices, selected_scores, -1 * tf.ones(max_selection_size)))\n        selected_classes = tf.gather(classes_with_max_scores, selected_indices)\n        selected_classes = tf.cast(selected_classes, tf.float32)\n        nms_result.add_field(fields.BoxListFields.classes, selected_classes)\n        selected_boxes = nms_result\n        sorted_boxes = box_list_ops.sort_by_field(selected_boxes, fields.BoxListFields.scores)\n        if clip_window is not None:\n            (sorted_boxes, num_valid_nms_boxes) = _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame)\n        if max_total_size:\n            max_total_size = tf.minimum(max_total_size, sorted_boxes.num_boxes())\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(max_total_size))\n            num_valid_nms_boxes = tf.where(max_total_size > num_valid_nms_boxes, num_valid_nms_boxes, max_total_size)\n        if not pad_to_max_output_size:\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(num_valid_nms_boxes))\n        return (sorted_boxes, num_valid_nms_boxes)",
            "def class_agnostic_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_classes_per_detection=1, max_total_size=0, clip_window=None, change_coordinate_frame=False, masks=None, boundaries=None, pad_to_max_output_size=False, use_partitioned_nms=False, additional_fields=None, soft_nms_sigma=0.0, scope=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Class-agnostic version of non maximum suppression.\\n\\n  This op greedily selects a subset of detection bounding boxes, pruning\\n  away boxes that have high IOU (intersection over union) overlap (> thresh)\\n  with already selected boxes.  It operates on all the boxes using\\n  max scores across all classes for which scores are provided (via the scores\\n  field of the input box_list), pruning boxes with score less than a provided\\n  threshold prior to applying NMS.\\n\\n  Please note that this operation is performed in a class-agnostic way,\\n  therefore any background classes should be removed prior to calling this\\n  function.\\n\\n  Selected boxes are guaranteed to be sorted in decreasing order by score (but\\n  the sort is not guaranteed to be stable).\\n\\n  Args:\\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\\n      number of classes or 1 depending on whether a separate box is predicted\\n      per class.\\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\\n      the k detections. The scores have to be non-negative when\\n      pad_to_max_output_size is True.\\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    max_classes_per_detection: maximum number of retained classes per detection\\n      box in class-agnostic NMS.\\n    max_total_size: maximum number of boxes retained over all classes. By\\n      default returns all boxes retained after capping boxes per class.\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided)\\n    masks: (optional) a [k, q, mask_height, mask_width] float32 tensor\\n      containing box masks. `q` can be either number of classes or 1 depending\\n      on whether a separate mask is predicted per class.\\n    boundaries: (optional) a [k, q, boundary_height, boundary_width] float32\\n      tensor containing box boundaries. `q` can be either number of classes or 1\\n      depending on whether a separate boundary is predicted per class.\\n    pad_to_max_output_size: If true, the output nmsed boxes are padded to be of\\n      length `max_size_per_class`. Defaults to false.\\n    use_partitioned_nms: If true, use partitioned version of\\n      non_max_suppression.\\n    additional_fields: (optional) If not None, a dictionary that maps keys to\\n      tensors whose first dimensions are all of size `k`. After non-maximum\\n      suppression, all tensors corresponding to the selected boxes will be added\\n      to resulting BoxList.\\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\\n      False.\\n    scope: name scope.\\n\\n  Returns:\\n    A tuple of sorted_boxes and num_valid_nms_boxes. The sorted_boxes is a\\n      BoxList holds M boxes with a rank-1 scores field representing\\n      corresponding scores for each box with scores sorted in decreasing order\\n      and a rank-1 classes field representing a class label for each box. The\\n      num_valid_nms_boxes is a 0-D integer tensor representing the number of\\n      valid elements in `BoxList`, with the valid elements appearing first.\\n\\n  Raises:\\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have\\n      a valid scores field or if non-zero soft_nms_sigma is provided when\\n      pad_to_max_output_size is True.\\n  '\n    _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window)\n    if pad_to_max_output_size and soft_nms_sigma != 0.0:\n        raise ValueError('Soft NMS (soft_nms_sigma != 0.0) is currently not supported when pad_to_max_output_size is True.')\n    if max_classes_per_detection > 1:\n        raise ValueError('Max classes per detection box >1 not supported.')\n    q = shape_utils.get_dim_as_int(boxes.shape[1])\n    if q > 1:\n        class_ids = tf.expand_dims(tf.argmax(scores, axis=1, output_type=tf.int32), axis=1)\n        boxes = tf.batch_gather(boxes, class_ids)\n        if masks is not None:\n            masks = tf.batch_gather(masks, class_ids)\n        if boundaries is not None:\n            boundaries = tf.batch_gather(boundaries, class_ids)\n    boxes = tf.squeeze(boxes, axis=[1])\n    if masks is not None:\n        masks = tf.squeeze(masks, axis=[1])\n    if boundaries is not None:\n        boundaries = tf.squeeze(boundaries, axis=[1])\n    with tf.name_scope(scope, 'ClassAgnosticNonMaxSuppression'):\n        boxlist_and_class_scores = box_list.BoxList(boxes)\n        max_scores = tf.reduce_max(scores, axis=-1)\n        classes_with_max_scores = tf.argmax(scores, axis=-1)\n        boxlist_and_class_scores.add_field(fields.BoxListFields.scores, max_scores)\n        if masks is not None:\n            boxlist_and_class_scores.add_field(fields.BoxListFields.masks, masks)\n        if boundaries is not None:\n            boxlist_and_class_scores.add_field(fields.BoxListFields.boundaries, boundaries)\n        if additional_fields is not None:\n            for (key, tensor) in additional_fields.items():\n                boxlist_and_class_scores.add_field(key, tensor)\n        nms_result = None\n        selected_scores = None\n        if pad_to_max_output_size:\n            max_selection_size = max_total_size\n            if use_partitioned_nms:\n                (selected_indices, num_valid_nms_boxes, boxlist_and_class_scores.data['boxes'], boxlist_and_class_scores.data['scores'], argsort_ids) = partitioned_non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                classes_with_max_scores = tf.gather(classes_with_max_scores, argsort_ids)\n            else:\n                (selected_indices, num_valid_nms_boxes) = tf.image.non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_to_max_output_size=True)\n            nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n            selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n        else:\n            max_selection_size = tf.minimum(max_total_size, boxlist_and_class_scores.num_boxes())\n            if hasattr(tf.image, 'non_max_suppression_with_scores') and tf.compat.forward_compatible(2019, 6, 6):\n                (selected_indices, selected_scores) = tf.image.non_max_suppression_with_scores(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, soft_nms_sigma=soft_nms_sigma)\n                num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                selected_scores = tf.concat([selected_scores, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.float32)], -1)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n            else:\n                if soft_nms_sigma != 0:\n                    raise ValueError('Soft NMS not supported in current TF version!')\n                selected_indices = tf.image.non_max_suppression(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n        valid_nms_boxes_indices = tf.less(tf.range(max_selection_size), num_valid_nms_boxes)\n        nms_result.add_field(fields.BoxListFields.scores, tf.where(valid_nms_boxes_indices, selected_scores, -1 * tf.ones(max_selection_size)))\n        selected_classes = tf.gather(classes_with_max_scores, selected_indices)\n        selected_classes = tf.cast(selected_classes, tf.float32)\n        nms_result.add_field(fields.BoxListFields.classes, selected_classes)\n        selected_boxes = nms_result\n        sorted_boxes = box_list_ops.sort_by_field(selected_boxes, fields.BoxListFields.scores)\n        if clip_window is not None:\n            (sorted_boxes, num_valid_nms_boxes) = _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame)\n        if max_total_size:\n            max_total_size = tf.minimum(max_total_size, sorted_boxes.num_boxes())\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(max_total_size))\n            num_valid_nms_boxes = tf.where(max_total_size > num_valid_nms_boxes, num_valid_nms_boxes, max_total_size)\n        if not pad_to_max_output_size:\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(num_valid_nms_boxes))\n        return (sorted_boxes, num_valid_nms_boxes)",
            "def class_agnostic_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_classes_per_detection=1, max_total_size=0, clip_window=None, change_coordinate_frame=False, masks=None, boundaries=None, pad_to_max_output_size=False, use_partitioned_nms=False, additional_fields=None, soft_nms_sigma=0.0, scope=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Class-agnostic version of non maximum suppression.\\n\\n  This op greedily selects a subset of detection bounding boxes, pruning\\n  away boxes that have high IOU (intersection over union) overlap (> thresh)\\n  with already selected boxes.  It operates on all the boxes using\\n  max scores across all classes for which scores are provided (via the scores\\n  field of the input box_list), pruning boxes with score less than a provided\\n  threshold prior to applying NMS.\\n\\n  Please note that this operation is performed in a class-agnostic way,\\n  therefore any background classes should be removed prior to calling this\\n  function.\\n\\n  Selected boxes are guaranteed to be sorted in decreasing order by score (but\\n  the sort is not guaranteed to be stable).\\n\\n  Args:\\n    boxes: A [k, q, 4] float32 tensor containing k detections. `q` can be either\\n      number of classes or 1 depending on whether a separate box is predicted\\n      per class.\\n    scores: A [k, num_classes] float32 tensor containing the scores for each of\\n      the k detections. The scores have to be non-negative when\\n      pad_to_max_output_size is True.\\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    max_classes_per_detection: maximum number of retained classes per detection\\n      box in class-agnostic NMS.\\n    max_total_size: maximum number of boxes retained over all classes. By\\n      default returns all boxes retained after capping boxes per class.\\n    clip_window: A float32 tensor of the form [y_min, x_min, y_max, x_max]\\n      representing the window to clip and normalize boxes to before performing\\n      non-max suppression.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided)\\n    masks: (optional) a [k, q, mask_height, mask_width] float32 tensor\\n      containing box masks. `q` can be either number of classes or 1 depending\\n      on whether a separate mask is predicted per class.\\n    boundaries: (optional) a [k, q, boundary_height, boundary_width] float32\\n      tensor containing box boundaries. `q` can be either number of classes or 1\\n      depending on whether a separate boundary is predicted per class.\\n    pad_to_max_output_size: If true, the output nmsed boxes are padded to be of\\n      length `max_size_per_class`. Defaults to false.\\n    use_partitioned_nms: If true, use partitioned version of\\n      non_max_suppression.\\n    additional_fields: (optional) If not None, a dictionary that maps keys to\\n      tensors whose first dimensions are all of size `k`. After non-maximum\\n      suppression, all tensors corresponding to the selected boxes will be added\\n      to resulting BoxList.\\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\\n      False.\\n    scope: name scope.\\n\\n  Returns:\\n    A tuple of sorted_boxes and num_valid_nms_boxes. The sorted_boxes is a\\n      BoxList holds M boxes with a rank-1 scores field representing\\n      corresponding scores for each box with scores sorted in decreasing order\\n      and a rank-1 classes field representing a class label for each box. The\\n      num_valid_nms_boxes is a 0-D integer tensor representing the number of\\n      valid elements in `BoxList`, with the valid elements appearing first.\\n\\n  Raises:\\n    ValueError: if iou_thresh is not in [0, 1] or if input boxlist does not have\\n      a valid scores field or if non-zero soft_nms_sigma is provided when\\n      pad_to_max_output_size is True.\\n  '\n    _validate_boxes_scores_iou_thresh(boxes, scores, iou_thresh, change_coordinate_frame, clip_window)\n    if pad_to_max_output_size and soft_nms_sigma != 0.0:\n        raise ValueError('Soft NMS (soft_nms_sigma != 0.0) is currently not supported when pad_to_max_output_size is True.')\n    if max_classes_per_detection > 1:\n        raise ValueError('Max classes per detection box >1 not supported.')\n    q = shape_utils.get_dim_as_int(boxes.shape[1])\n    if q > 1:\n        class_ids = tf.expand_dims(tf.argmax(scores, axis=1, output_type=tf.int32), axis=1)\n        boxes = tf.batch_gather(boxes, class_ids)\n        if masks is not None:\n            masks = tf.batch_gather(masks, class_ids)\n        if boundaries is not None:\n            boundaries = tf.batch_gather(boundaries, class_ids)\n    boxes = tf.squeeze(boxes, axis=[1])\n    if masks is not None:\n        masks = tf.squeeze(masks, axis=[1])\n    if boundaries is not None:\n        boundaries = tf.squeeze(boundaries, axis=[1])\n    with tf.name_scope(scope, 'ClassAgnosticNonMaxSuppression'):\n        boxlist_and_class_scores = box_list.BoxList(boxes)\n        max_scores = tf.reduce_max(scores, axis=-1)\n        classes_with_max_scores = tf.argmax(scores, axis=-1)\n        boxlist_and_class_scores.add_field(fields.BoxListFields.scores, max_scores)\n        if masks is not None:\n            boxlist_and_class_scores.add_field(fields.BoxListFields.masks, masks)\n        if boundaries is not None:\n            boxlist_and_class_scores.add_field(fields.BoxListFields.boundaries, boundaries)\n        if additional_fields is not None:\n            for (key, tensor) in additional_fields.items():\n                boxlist_and_class_scores.add_field(key, tensor)\n        nms_result = None\n        selected_scores = None\n        if pad_to_max_output_size:\n            max_selection_size = max_total_size\n            if use_partitioned_nms:\n                (selected_indices, num_valid_nms_boxes, boxlist_and_class_scores.data['boxes'], boxlist_and_class_scores.data['scores'], argsort_ids) = partitioned_non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                classes_with_max_scores = tf.gather(classes_with_max_scores, argsort_ids)\n            else:\n                (selected_indices, num_valid_nms_boxes) = tf.image.non_max_suppression_padded(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_to_max_output_size=True)\n            nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n            selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n        else:\n            max_selection_size = tf.minimum(max_total_size, boxlist_and_class_scores.num_boxes())\n            if hasattr(tf.image, 'non_max_suppression_with_scores') and tf.compat.forward_compatible(2019, 6, 6):\n                (selected_indices, selected_scores) = tf.image.non_max_suppression_with_scores(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh, soft_nms_sigma=soft_nms_sigma)\n                num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                selected_scores = tf.concat([selected_scores, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.float32)], -1)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n            else:\n                if soft_nms_sigma != 0:\n                    raise ValueError('Soft NMS not supported in current TF version!')\n                selected_indices = tf.image.non_max_suppression(boxlist_and_class_scores.get(), boxlist_and_class_scores.get_field(fields.BoxListFields.scores), max_selection_size, iou_threshold=iou_thresh, score_threshold=score_thresh)\n                num_valid_nms_boxes = tf.shape(selected_indices)[0]\n                selected_indices = tf.concat([selected_indices, tf.zeros(max_selection_size - num_valid_nms_boxes, tf.int32)], 0)\n                nms_result = box_list_ops.gather(boxlist_and_class_scores, selected_indices)\n                selected_scores = nms_result.get_field(fields.BoxListFields.scores)\n        valid_nms_boxes_indices = tf.less(tf.range(max_selection_size), num_valid_nms_boxes)\n        nms_result.add_field(fields.BoxListFields.scores, tf.where(valid_nms_boxes_indices, selected_scores, -1 * tf.ones(max_selection_size)))\n        selected_classes = tf.gather(classes_with_max_scores, selected_indices)\n        selected_classes = tf.cast(selected_classes, tf.float32)\n        nms_result.add_field(fields.BoxListFields.classes, selected_classes)\n        selected_boxes = nms_result\n        sorted_boxes = box_list_ops.sort_by_field(selected_boxes, fields.BoxListFields.scores)\n        if clip_window is not None:\n            (sorted_boxes, num_valid_nms_boxes) = _clip_window_prune_boxes(sorted_boxes, clip_window, pad_to_max_output_size, change_coordinate_frame)\n        if max_total_size:\n            max_total_size = tf.minimum(max_total_size, sorted_boxes.num_boxes())\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(max_total_size))\n            num_valid_nms_boxes = tf.where(max_total_size > num_valid_nms_boxes, num_valid_nms_boxes, max_total_size)\n        if not pad_to_max_output_size:\n            sorted_boxes = box_list_ops.gather(sorted_boxes, tf.range(num_valid_nms_boxes))\n        return (sorted_boxes, num_valid_nms_boxes)"
        ]
    },
    {
        "func_name": "_single_image_nms_fn",
        "original": "def _single_image_nms_fn(args):\n    \"\"\"Runs NMS on a single image and returns padded output.\n\n      Args:\n        args: A list of tensors consisting of the following:\n          per_image_boxes - A [num_anchors, q, 4] float32 tensor containing\n            detections. If `q` is 1 then same boxes are used for all classes\n            otherwise, if `q` is equal to number of classes, class-specific\n            boxes are used.\n          per_image_scores - A [num_anchors, num_classes] float32 tensor\n            containing the scores for each of the `num_anchors` detections.\n          per_image_masks - A [num_anchors, q, mask_height, mask_width] float32\n            tensor containing box masks. `q` can be either number of classes\n            or 1 depending on whether a separate mask is predicted per class.\n          per_image_clip_window - A 1D float32 tensor of the form\n            [ymin, xmin, ymax, xmax] representing the window to clip the boxes\n            to.\n          per_image_additional_fields - (optional) A variable number of float32\n            tensors each with size [num_anchors, ...].\n          per_image_num_valid_boxes - A tensor of type `int32`. A 1-D tensor of\n            shape [batch_size] representing the number of valid boxes to be\n            considered for each image in the batch.  This parameter allows for\n            ignoring zero paddings.\n\n      Returns:\n        'nmsed_boxes': A [max_detections, 4] float32 tensor containing the\n          non-max suppressed boxes.\n        'nmsed_scores': A [max_detections] float32 tensor containing the scores\n          for the boxes.\n        'nmsed_classes': A [max_detections] float32 tensor containing the class\n          for boxes.\n        'nmsed_masks': (optional) a [max_detections, mask_height, mask_width]\n          float32 tensor containing masks for each selected box. This is set to\n          None if input `masks` is None.\n        'nmsed_additional_fields':  (optional) A variable number of float32\n          tensors each with size [max_detections, ...] corresponding to the\n          input `per_image_additional_fields`.\n        'num_detections': A [batch_size] int32 tensor indicating the number of\n          valid detections per batch item. Only the top num_detections[i]\n          entries in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The\n          rest of the entries are zero paddings.\n      \"\"\"\n    per_image_boxes = args[0]\n    per_image_scores = args[1]\n    per_image_masks = args[2]\n    per_image_clip_window = args[3]\n    per_image_additional_fields = {key: value for (key, value) in zip(ordered_additional_fields, args[4:-1])}\n    per_image_num_valid_boxes = args[-1]\n    if use_static_shapes:\n        total_proposals = tf.shape(per_image_scores)\n        per_image_scores = tf.where(tf.less(tf.range(total_proposals[0]), per_image_num_valid_boxes), per_image_scores, tf.fill(total_proposals, np.finfo('float32').min))\n    else:\n        per_image_boxes = tf.reshape(tf.slice(per_image_boxes, 3 * [0], tf.stack([per_image_num_valid_boxes, -1, -1])), [-1, q, 4])\n        per_image_scores = tf.reshape(tf.slice(per_image_scores, [0, 0], tf.stack([per_image_num_valid_boxes, -1])), [-1, num_classes])\n        per_image_masks = tf.reshape(tf.slice(per_image_masks, 4 * [0], tf.stack([per_image_num_valid_boxes, -1, -1, -1])), [-1, q, shape_utils.get_dim_as_int(per_image_masks.shape[2]), shape_utils.get_dim_as_int(per_image_masks.shape[3])])\n        if per_image_additional_fields is not None:\n            for (key, tensor) in per_image_additional_fields.items():\n                additional_field_shape = tensor.get_shape()\n                additional_field_dim = len(additional_field_shape)\n                per_image_additional_fields[key] = tf.reshape(tf.slice(per_image_additional_fields[key], additional_field_dim * [0], tf.stack([per_image_num_valid_boxes] + (additional_field_dim - 1) * [-1])), [-1] + [shape_utils.get_dim_as_int(dim) for dim in additional_field_shape[1:]])\n    if use_class_agnostic_nms:\n        (nmsed_boxlist, num_valid_nms_boxes) = class_agnostic_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_classes_per_detection, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n    else:\n        (nmsed_boxlist, num_valid_nms_boxes) = multiclass_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_size_per_class, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n    if not use_static_shapes:\n        nmsed_boxlist = box_list_ops.pad_or_clip_box_list(nmsed_boxlist, max_total_size)\n    num_detections = num_valid_nms_boxes\n    nmsed_boxes = nmsed_boxlist.get()\n    nmsed_scores = nmsed_boxlist.get_field(fields.BoxListFields.scores)\n    nmsed_classes = nmsed_boxlist.get_field(fields.BoxListFields.classes)\n    nmsed_masks = nmsed_boxlist.get_field(fields.BoxListFields.masks)\n    nmsed_additional_fields = []\n    for key in sorted(per_image_additional_fields.keys()):\n        nmsed_additional_fields.append(nmsed_boxlist.get_field(key))\n    return [nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_masks] + nmsed_additional_fields + [num_detections]",
        "mutated": [
            "def _single_image_nms_fn(args):\n    if False:\n        i = 10\n    \"Runs NMS on a single image and returns padded output.\\n\\n      Args:\\n        args: A list of tensors consisting of the following:\\n          per_image_boxes - A [num_anchors, q, 4] float32 tensor containing\\n            detections. If `q` is 1 then same boxes are used for all classes\\n            otherwise, if `q` is equal to number of classes, class-specific\\n            boxes are used.\\n          per_image_scores - A [num_anchors, num_classes] float32 tensor\\n            containing the scores for each of the `num_anchors` detections.\\n          per_image_masks - A [num_anchors, q, mask_height, mask_width] float32\\n            tensor containing box masks. `q` can be either number of classes\\n            or 1 depending on whether a separate mask is predicted per class.\\n          per_image_clip_window - A 1D float32 tensor of the form\\n            [ymin, xmin, ymax, xmax] representing the window to clip the boxes\\n            to.\\n          per_image_additional_fields - (optional) A variable number of float32\\n            tensors each with size [num_anchors, ...].\\n          per_image_num_valid_boxes - A tensor of type `int32`. A 1-D tensor of\\n            shape [batch_size] representing the number of valid boxes to be\\n            considered for each image in the batch.  This parameter allows for\\n            ignoring zero paddings.\\n\\n      Returns:\\n        'nmsed_boxes': A [max_detections, 4] float32 tensor containing the\\n          non-max suppressed boxes.\\n        'nmsed_scores': A [max_detections] float32 tensor containing the scores\\n          for the boxes.\\n        'nmsed_classes': A [max_detections] float32 tensor containing the class\\n          for boxes.\\n        'nmsed_masks': (optional) a [max_detections, mask_height, mask_width]\\n          float32 tensor containing masks for each selected box. This is set to\\n          None if input `masks` is None.\\n        'nmsed_additional_fields':  (optional) A variable number of float32\\n          tensors each with size [max_detections, ...] corresponding to the\\n          input `per_image_additional_fields`.\\n        'num_detections': A [batch_size] int32 tensor indicating the number of\\n          valid detections per batch item. Only the top num_detections[i]\\n          entries in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The\\n          rest of the entries are zero paddings.\\n      \"\n    per_image_boxes = args[0]\n    per_image_scores = args[1]\n    per_image_masks = args[2]\n    per_image_clip_window = args[3]\n    per_image_additional_fields = {key: value for (key, value) in zip(ordered_additional_fields, args[4:-1])}\n    per_image_num_valid_boxes = args[-1]\n    if use_static_shapes:\n        total_proposals = tf.shape(per_image_scores)\n        per_image_scores = tf.where(tf.less(tf.range(total_proposals[0]), per_image_num_valid_boxes), per_image_scores, tf.fill(total_proposals, np.finfo('float32').min))\n    else:\n        per_image_boxes = tf.reshape(tf.slice(per_image_boxes, 3 * [0], tf.stack([per_image_num_valid_boxes, -1, -1])), [-1, q, 4])\n        per_image_scores = tf.reshape(tf.slice(per_image_scores, [0, 0], tf.stack([per_image_num_valid_boxes, -1])), [-1, num_classes])\n        per_image_masks = tf.reshape(tf.slice(per_image_masks, 4 * [0], tf.stack([per_image_num_valid_boxes, -1, -1, -1])), [-1, q, shape_utils.get_dim_as_int(per_image_masks.shape[2]), shape_utils.get_dim_as_int(per_image_masks.shape[3])])\n        if per_image_additional_fields is not None:\n            for (key, tensor) in per_image_additional_fields.items():\n                additional_field_shape = tensor.get_shape()\n                additional_field_dim = len(additional_field_shape)\n                per_image_additional_fields[key] = tf.reshape(tf.slice(per_image_additional_fields[key], additional_field_dim * [0], tf.stack([per_image_num_valid_boxes] + (additional_field_dim - 1) * [-1])), [-1] + [shape_utils.get_dim_as_int(dim) for dim in additional_field_shape[1:]])\n    if use_class_agnostic_nms:\n        (nmsed_boxlist, num_valid_nms_boxes) = class_agnostic_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_classes_per_detection, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n    else:\n        (nmsed_boxlist, num_valid_nms_boxes) = multiclass_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_size_per_class, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n    if not use_static_shapes:\n        nmsed_boxlist = box_list_ops.pad_or_clip_box_list(nmsed_boxlist, max_total_size)\n    num_detections = num_valid_nms_boxes\n    nmsed_boxes = nmsed_boxlist.get()\n    nmsed_scores = nmsed_boxlist.get_field(fields.BoxListFields.scores)\n    nmsed_classes = nmsed_boxlist.get_field(fields.BoxListFields.classes)\n    nmsed_masks = nmsed_boxlist.get_field(fields.BoxListFields.masks)\n    nmsed_additional_fields = []\n    for key in sorted(per_image_additional_fields.keys()):\n        nmsed_additional_fields.append(nmsed_boxlist.get_field(key))\n    return [nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_masks] + nmsed_additional_fields + [num_detections]",
            "def _single_image_nms_fn(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Runs NMS on a single image and returns padded output.\\n\\n      Args:\\n        args: A list of tensors consisting of the following:\\n          per_image_boxes - A [num_anchors, q, 4] float32 tensor containing\\n            detections. If `q` is 1 then same boxes are used for all classes\\n            otherwise, if `q` is equal to number of classes, class-specific\\n            boxes are used.\\n          per_image_scores - A [num_anchors, num_classes] float32 tensor\\n            containing the scores for each of the `num_anchors` detections.\\n          per_image_masks - A [num_anchors, q, mask_height, mask_width] float32\\n            tensor containing box masks. `q` can be either number of classes\\n            or 1 depending on whether a separate mask is predicted per class.\\n          per_image_clip_window - A 1D float32 tensor of the form\\n            [ymin, xmin, ymax, xmax] representing the window to clip the boxes\\n            to.\\n          per_image_additional_fields - (optional) A variable number of float32\\n            tensors each with size [num_anchors, ...].\\n          per_image_num_valid_boxes - A tensor of type `int32`. A 1-D tensor of\\n            shape [batch_size] representing the number of valid boxes to be\\n            considered for each image in the batch.  This parameter allows for\\n            ignoring zero paddings.\\n\\n      Returns:\\n        'nmsed_boxes': A [max_detections, 4] float32 tensor containing the\\n          non-max suppressed boxes.\\n        'nmsed_scores': A [max_detections] float32 tensor containing the scores\\n          for the boxes.\\n        'nmsed_classes': A [max_detections] float32 tensor containing the class\\n          for boxes.\\n        'nmsed_masks': (optional) a [max_detections, mask_height, mask_width]\\n          float32 tensor containing masks for each selected box. This is set to\\n          None if input `masks` is None.\\n        'nmsed_additional_fields':  (optional) A variable number of float32\\n          tensors each with size [max_detections, ...] corresponding to the\\n          input `per_image_additional_fields`.\\n        'num_detections': A [batch_size] int32 tensor indicating the number of\\n          valid detections per batch item. Only the top num_detections[i]\\n          entries in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The\\n          rest of the entries are zero paddings.\\n      \"\n    per_image_boxes = args[0]\n    per_image_scores = args[1]\n    per_image_masks = args[2]\n    per_image_clip_window = args[3]\n    per_image_additional_fields = {key: value for (key, value) in zip(ordered_additional_fields, args[4:-1])}\n    per_image_num_valid_boxes = args[-1]\n    if use_static_shapes:\n        total_proposals = tf.shape(per_image_scores)\n        per_image_scores = tf.where(tf.less(tf.range(total_proposals[0]), per_image_num_valid_boxes), per_image_scores, tf.fill(total_proposals, np.finfo('float32').min))\n    else:\n        per_image_boxes = tf.reshape(tf.slice(per_image_boxes, 3 * [0], tf.stack([per_image_num_valid_boxes, -1, -1])), [-1, q, 4])\n        per_image_scores = tf.reshape(tf.slice(per_image_scores, [0, 0], tf.stack([per_image_num_valid_boxes, -1])), [-1, num_classes])\n        per_image_masks = tf.reshape(tf.slice(per_image_masks, 4 * [0], tf.stack([per_image_num_valid_boxes, -1, -1, -1])), [-1, q, shape_utils.get_dim_as_int(per_image_masks.shape[2]), shape_utils.get_dim_as_int(per_image_masks.shape[3])])\n        if per_image_additional_fields is not None:\n            for (key, tensor) in per_image_additional_fields.items():\n                additional_field_shape = tensor.get_shape()\n                additional_field_dim = len(additional_field_shape)\n                per_image_additional_fields[key] = tf.reshape(tf.slice(per_image_additional_fields[key], additional_field_dim * [0], tf.stack([per_image_num_valid_boxes] + (additional_field_dim - 1) * [-1])), [-1] + [shape_utils.get_dim_as_int(dim) for dim in additional_field_shape[1:]])\n    if use_class_agnostic_nms:\n        (nmsed_boxlist, num_valid_nms_boxes) = class_agnostic_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_classes_per_detection, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n    else:\n        (nmsed_boxlist, num_valid_nms_boxes) = multiclass_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_size_per_class, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n    if not use_static_shapes:\n        nmsed_boxlist = box_list_ops.pad_or_clip_box_list(nmsed_boxlist, max_total_size)\n    num_detections = num_valid_nms_boxes\n    nmsed_boxes = nmsed_boxlist.get()\n    nmsed_scores = nmsed_boxlist.get_field(fields.BoxListFields.scores)\n    nmsed_classes = nmsed_boxlist.get_field(fields.BoxListFields.classes)\n    nmsed_masks = nmsed_boxlist.get_field(fields.BoxListFields.masks)\n    nmsed_additional_fields = []\n    for key in sorted(per_image_additional_fields.keys()):\n        nmsed_additional_fields.append(nmsed_boxlist.get_field(key))\n    return [nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_masks] + nmsed_additional_fields + [num_detections]",
            "def _single_image_nms_fn(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Runs NMS on a single image and returns padded output.\\n\\n      Args:\\n        args: A list of tensors consisting of the following:\\n          per_image_boxes - A [num_anchors, q, 4] float32 tensor containing\\n            detections. If `q` is 1 then same boxes are used for all classes\\n            otherwise, if `q` is equal to number of classes, class-specific\\n            boxes are used.\\n          per_image_scores - A [num_anchors, num_classes] float32 tensor\\n            containing the scores for each of the `num_anchors` detections.\\n          per_image_masks - A [num_anchors, q, mask_height, mask_width] float32\\n            tensor containing box masks. `q` can be either number of classes\\n            or 1 depending on whether a separate mask is predicted per class.\\n          per_image_clip_window - A 1D float32 tensor of the form\\n            [ymin, xmin, ymax, xmax] representing the window to clip the boxes\\n            to.\\n          per_image_additional_fields - (optional) A variable number of float32\\n            tensors each with size [num_anchors, ...].\\n          per_image_num_valid_boxes - A tensor of type `int32`. A 1-D tensor of\\n            shape [batch_size] representing the number of valid boxes to be\\n            considered for each image in the batch.  This parameter allows for\\n            ignoring zero paddings.\\n\\n      Returns:\\n        'nmsed_boxes': A [max_detections, 4] float32 tensor containing the\\n          non-max suppressed boxes.\\n        'nmsed_scores': A [max_detections] float32 tensor containing the scores\\n          for the boxes.\\n        'nmsed_classes': A [max_detections] float32 tensor containing the class\\n          for boxes.\\n        'nmsed_masks': (optional) a [max_detections, mask_height, mask_width]\\n          float32 tensor containing masks for each selected box. This is set to\\n          None if input `masks` is None.\\n        'nmsed_additional_fields':  (optional) A variable number of float32\\n          tensors each with size [max_detections, ...] corresponding to the\\n          input `per_image_additional_fields`.\\n        'num_detections': A [batch_size] int32 tensor indicating the number of\\n          valid detections per batch item. Only the top num_detections[i]\\n          entries in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The\\n          rest of the entries are zero paddings.\\n      \"\n    per_image_boxes = args[0]\n    per_image_scores = args[1]\n    per_image_masks = args[2]\n    per_image_clip_window = args[3]\n    per_image_additional_fields = {key: value for (key, value) in zip(ordered_additional_fields, args[4:-1])}\n    per_image_num_valid_boxes = args[-1]\n    if use_static_shapes:\n        total_proposals = tf.shape(per_image_scores)\n        per_image_scores = tf.where(tf.less(tf.range(total_proposals[0]), per_image_num_valid_boxes), per_image_scores, tf.fill(total_proposals, np.finfo('float32').min))\n    else:\n        per_image_boxes = tf.reshape(tf.slice(per_image_boxes, 3 * [0], tf.stack([per_image_num_valid_boxes, -1, -1])), [-1, q, 4])\n        per_image_scores = tf.reshape(tf.slice(per_image_scores, [0, 0], tf.stack([per_image_num_valid_boxes, -1])), [-1, num_classes])\n        per_image_masks = tf.reshape(tf.slice(per_image_masks, 4 * [0], tf.stack([per_image_num_valid_boxes, -1, -1, -1])), [-1, q, shape_utils.get_dim_as_int(per_image_masks.shape[2]), shape_utils.get_dim_as_int(per_image_masks.shape[3])])\n        if per_image_additional_fields is not None:\n            for (key, tensor) in per_image_additional_fields.items():\n                additional_field_shape = tensor.get_shape()\n                additional_field_dim = len(additional_field_shape)\n                per_image_additional_fields[key] = tf.reshape(tf.slice(per_image_additional_fields[key], additional_field_dim * [0], tf.stack([per_image_num_valid_boxes] + (additional_field_dim - 1) * [-1])), [-1] + [shape_utils.get_dim_as_int(dim) for dim in additional_field_shape[1:]])\n    if use_class_agnostic_nms:\n        (nmsed_boxlist, num_valid_nms_boxes) = class_agnostic_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_classes_per_detection, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n    else:\n        (nmsed_boxlist, num_valid_nms_boxes) = multiclass_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_size_per_class, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n    if not use_static_shapes:\n        nmsed_boxlist = box_list_ops.pad_or_clip_box_list(nmsed_boxlist, max_total_size)\n    num_detections = num_valid_nms_boxes\n    nmsed_boxes = nmsed_boxlist.get()\n    nmsed_scores = nmsed_boxlist.get_field(fields.BoxListFields.scores)\n    nmsed_classes = nmsed_boxlist.get_field(fields.BoxListFields.classes)\n    nmsed_masks = nmsed_boxlist.get_field(fields.BoxListFields.masks)\n    nmsed_additional_fields = []\n    for key in sorted(per_image_additional_fields.keys()):\n        nmsed_additional_fields.append(nmsed_boxlist.get_field(key))\n    return [nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_masks] + nmsed_additional_fields + [num_detections]",
            "def _single_image_nms_fn(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Runs NMS on a single image and returns padded output.\\n\\n      Args:\\n        args: A list of tensors consisting of the following:\\n          per_image_boxes - A [num_anchors, q, 4] float32 tensor containing\\n            detections. If `q` is 1 then same boxes are used for all classes\\n            otherwise, if `q` is equal to number of classes, class-specific\\n            boxes are used.\\n          per_image_scores - A [num_anchors, num_classes] float32 tensor\\n            containing the scores for each of the `num_anchors` detections.\\n          per_image_masks - A [num_anchors, q, mask_height, mask_width] float32\\n            tensor containing box masks. `q` can be either number of classes\\n            or 1 depending on whether a separate mask is predicted per class.\\n          per_image_clip_window - A 1D float32 tensor of the form\\n            [ymin, xmin, ymax, xmax] representing the window to clip the boxes\\n            to.\\n          per_image_additional_fields - (optional) A variable number of float32\\n            tensors each with size [num_anchors, ...].\\n          per_image_num_valid_boxes - A tensor of type `int32`. A 1-D tensor of\\n            shape [batch_size] representing the number of valid boxes to be\\n            considered for each image in the batch.  This parameter allows for\\n            ignoring zero paddings.\\n\\n      Returns:\\n        'nmsed_boxes': A [max_detections, 4] float32 tensor containing the\\n          non-max suppressed boxes.\\n        'nmsed_scores': A [max_detections] float32 tensor containing the scores\\n          for the boxes.\\n        'nmsed_classes': A [max_detections] float32 tensor containing the class\\n          for boxes.\\n        'nmsed_masks': (optional) a [max_detections, mask_height, mask_width]\\n          float32 tensor containing masks for each selected box. This is set to\\n          None if input `masks` is None.\\n        'nmsed_additional_fields':  (optional) A variable number of float32\\n          tensors each with size [max_detections, ...] corresponding to the\\n          input `per_image_additional_fields`.\\n        'num_detections': A [batch_size] int32 tensor indicating the number of\\n          valid detections per batch item. Only the top num_detections[i]\\n          entries in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The\\n          rest of the entries are zero paddings.\\n      \"\n    per_image_boxes = args[0]\n    per_image_scores = args[1]\n    per_image_masks = args[2]\n    per_image_clip_window = args[3]\n    per_image_additional_fields = {key: value for (key, value) in zip(ordered_additional_fields, args[4:-1])}\n    per_image_num_valid_boxes = args[-1]\n    if use_static_shapes:\n        total_proposals = tf.shape(per_image_scores)\n        per_image_scores = tf.where(tf.less(tf.range(total_proposals[0]), per_image_num_valid_boxes), per_image_scores, tf.fill(total_proposals, np.finfo('float32').min))\n    else:\n        per_image_boxes = tf.reshape(tf.slice(per_image_boxes, 3 * [0], tf.stack([per_image_num_valid_boxes, -1, -1])), [-1, q, 4])\n        per_image_scores = tf.reshape(tf.slice(per_image_scores, [0, 0], tf.stack([per_image_num_valid_boxes, -1])), [-1, num_classes])\n        per_image_masks = tf.reshape(tf.slice(per_image_masks, 4 * [0], tf.stack([per_image_num_valid_boxes, -1, -1, -1])), [-1, q, shape_utils.get_dim_as_int(per_image_masks.shape[2]), shape_utils.get_dim_as_int(per_image_masks.shape[3])])\n        if per_image_additional_fields is not None:\n            for (key, tensor) in per_image_additional_fields.items():\n                additional_field_shape = tensor.get_shape()\n                additional_field_dim = len(additional_field_shape)\n                per_image_additional_fields[key] = tf.reshape(tf.slice(per_image_additional_fields[key], additional_field_dim * [0], tf.stack([per_image_num_valid_boxes] + (additional_field_dim - 1) * [-1])), [-1] + [shape_utils.get_dim_as_int(dim) for dim in additional_field_shape[1:]])\n    if use_class_agnostic_nms:\n        (nmsed_boxlist, num_valid_nms_boxes) = class_agnostic_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_classes_per_detection, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n    else:\n        (nmsed_boxlist, num_valid_nms_boxes) = multiclass_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_size_per_class, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n    if not use_static_shapes:\n        nmsed_boxlist = box_list_ops.pad_or_clip_box_list(nmsed_boxlist, max_total_size)\n    num_detections = num_valid_nms_boxes\n    nmsed_boxes = nmsed_boxlist.get()\n    nmsed_scores = nmsed_boxlist.get_field(fields.BoxListFields.scores)\n    nmsed_classes = nmsed_boxlist.get_field(fields.BoxListFields.classes)\n    nmsed_masks = nmsed_boxlist.get_field(fields.BoxListFields.masks)\n    nmsed_additional_fields = []\n    for key in sorted(per_image_additional_fields.keys()):\n        nmsed_additional_fields.append(nmsed_boxlist.get_field(key))\n    return [nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_masks] + nmsed_additional_fields + [num_detections]",
            "def _single_image_nms_fn(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Runs NMS on a single image and returns padded output.\\n\\n      Args:\\n        args: A list of tensors consisting of the following:\\n          per_image_boxes - A [num_anchors, q, 4] float32 tensor containing\\n            detections. If `q` is 1 then same boxes are used for all classes\\n            otherwise, if `q` is equal to number of classes, class-specific\\n            boxes are used.\\n          per_image_scores - A [num_anchors, num_classes] float32 tensor\\n            containing the scores for each of the `num_anchors` detections.\\n          per_image_masks - A [num_anchors, q, mask_height, mask_width] float32\\n            tensor containing box masks. `q` can be either number of classes\\n            or 1 depending on whether a separate mask is predicted per class.\\n          per_image_clip_window - A 1D float32 tensor of the form\\n            [ymin, xmin, ymax, xmax] representing the window to clip the boxes\\n            to.\\n          per_image_additional_fields - (optional) A variable number of float32\\n            tensors each with size [num_anchors, ...].\\n          per_image_num_valid_boxes - A tensor of type `int32`. A 1-D tensor of\\n            shape [batch_size] representing the number of valid boxes to be\\n            considered for each image in the batch.  This parameter allows for\\n            ignoring zero paddings.\\n\\n      Returns:\\n        'nmsed_boxes': A [max_detections, 4] float32 tensor containing the\\n          non-max suppressed boxes.\\n        'nmsed_scores': A [max_detections] float32 tensor containing the scores\\n          for the boxes.\\n        'nmsed_classes': A [max_detections] float32 tensor containing the class\\n          for boxes.\\n        'nmsed_masks': (optional) a [max_detections, mask_height, mask_width]\\n          float32 tensor containing masks for each selected box. This is set to\\n          None if input `masks` is None.\\n        'nmsed_additional_fields':  (optional) A variable number of float32\\n          tensors each with size [max_detections, ...] corresponding to the\\n          input `per_image_additional_fields`.\\n        'num_detections': A [batch_size] int32 tensor indicating the number of\\n          valid detections per batch item. Only the top num_detections[i]\\n          entries in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The\\n          rest of the entries are zero paddings.\\n      \"\n    per_image_boxes = args[0]\n    per_image_scores = args[1]\n    per_image_masks = args[2]\n    per_image_clip_window = args[3]\n    per_image_additional_fields = {key: value for (key, value) in zip(ordered_additional_fields, args[4:-1])}\n    per_image_num_valid_boxes = args[-1]\n    if use_static_shapes:\n        total_proposals = tf.shape(per_image_scores)\n        per_image_scores = tf.where(tf.less(tf.range(total_proposals[0]), per_image_num_valid_boxes), per_image_scores, tf.fill(total_proposals, np.finfo('float32').min))\n    else:\n        per_image_boxes = tf.reshape(tf.slice(per_image_boxes, 3 * [0], tf.stack([per_image_num_valid_boxes, -1, -1])), [-1, q, 4])\n        per_image_scores = tf.reshape(tf.slice(per_image_scores, [0, 0], tf.stack([per_image_num_valid_boxes, -1])), [-1, num_classes])\n        per_image_masks = tf.reshape(tf.slice(per_image_masks, 4 * [0], tf.stack([per_image_num_valid_boxes, -1, -1, -1])), [-1, q, shape_utils.get_dim_as_int(per_image_masks.shape[2]), shape_utils.get_dim_as_int(per_image_masks.shape[3])])\n        if per_image_additional_fields is not None:\n            for (key, tensor) in per_image_additional_fields.items():\n                additional_field_shape = tensor.get_shape()\n                additional_field_dim = len(additional_field_shape)\n                per_image_additional_fields[key] = tf.reshape(tf.slice(per_image_additional_fields[key], additional_field_dim * [0], tf.stack([per_image_num_valid_boxes] + (additional_field_dim - 1) * [-1])), [-1] + [shape_utils.get_dim_as_int(dim) for dim in additional_field_shape[1:]])\n    if use_class_agnostic_nms:\n        (nmsed_boxlist, num_valid_nms_boxes) = class_agnostic_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_classes_per_detection, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n    else:\n        (nmsed_boxlist, num_valid_nms_boxes) = multiclass_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_size_per_class, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n    if not use_static_shapes:\n        nmsed_boxlist = box_list_ops.pad_or_clip_box_list(nmsed_boxlist, max_total_size)\n    num_detections = num_valid_nms_boxes\n    nmsed_boxes = nmsed_boxlist.get()\n    nmsed_scores = nmsed_boxlist.get_field(fields.BoxListFields.scores)\n    nmsed_classes = nmsed_boxlist.get_field(fields.BoxListFields.classes)\n    nmsed_masks = nmsed_boxlist.get_field(fields.BoxListFields.masks)\n    nmsed_additional_fields = []\n    for key in sorted(per_image_additional_fields.keys()):\n        nmsed_additional_fields.append(nmsed_boxlist.get_field(key))\n    return [nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_masks] + nmsed_additional_fields + [num_detections]"
        ]
    },
    {
        "func_name": "batch_multiclass_non_max_suppression",
        "original": "def batch_multiclass_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_size_per_class, max_total_size=0, clip_window=None, change_coordinate_frame=False, num_valid_boxes=None, masks=None, additional_fields=None, soft_nms_sigma=0.0, scope=None, use_static_shapes=False, use_partitioned_nms=False, parallel_iterations=32, use_class_agnostic_nms=False, max_classes_per_detection=1, use_dynamic_map_fn=False, use_combined_nms=False):\n    \"\"\"Multi-class version of non maximum suppression that operates on a batch.\n\n  This op is similar to `multiclass_non_max_suppression` but operates on a batch\n  of boxes and scores. See documentation for `multiclass_non_max_suppression`\n  for details.\n\n  Args:\n    boxes: A [batch_size, num_anchors, q, 4] float32 tensor containing\n      detections. If `q` is 1 then same boxes are used for all classes\n      otherwise, if `q` is equal to number of classes, class-specific boxes are\n      used.\n    scores: A [batch_size, num_anchors, num_classes] float32 tensor containing\n      the scores for each of the `num_anchors` detections. The scores have to be\n      non-negative when use_static_shapes is set True.\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\n      with previously selected boxes are removed).\n    max_size_per_class: maximum number of retained boxes per class.\n    max_total_size: maximum number of boxes retained over all classes. By\n      default returns all boxes retained after capping boxes per class.\n    clip_window: A float32 tensor of shape [batch_size, 4]  where each entry is\n      of the form [y_min, x_min, y_max, x_max] representing the window to clip\n      boxes to before performing non-max suppression. This argument can also be\n      a tensor of shape [4] in which case, the same clip window is applied to\n      all images in the batch. If clip_widow is None, all boxes are used to\n      perform non-max suppression.\n    change_coordinate_frame: Whether to normalize coordinates after clipping\n      relative to clip_window (this can only be set to True if a clip_window is\n      provided)\n    num_valid_boxes: (optional) a Tensor of type `int32`. A 1-D tensor of shape\n      [batch_size] representing the number of valid boxes to be considered for\n      each image in the batch.  This parameter allows for ignoring zero\n      paddings.\n    masks: (optional) a [batch_size, num_anchors, q, mask_height, mask_width]\n      float32 tensor containing box masks. `q` can be either number of classes\n      or 1 depending on whether a separate mask is predicted per class.\n    additional_fields: (optional) If not None, a dictionary that maps keys to\n      tensors whose dimensions are [batch_size, num_anchors, ...].\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\n      False.\n    scope: tf scope name.\n    use_static_shapes: If true, the output nmsed boxes are padded to be of\n      length `max_size_per_class` and it doesn't clip boxes to max_total_size.\n      Defaults to false.\n    use_partitioned_nms: If true, use partitioned version of\n      non_max_suppression.\n    parallel_iterations: (optional) number of batch items to process in\n      parallel.\n    use_class_agnostic_nms: If true, this uses class-agnostic non max\n      suppression\n    max_classes_per_detection: Maximum number of retained classes per detection\n      box in class-agnostic NMS.\n    use_dynamic_map_fn: If true, images in the batch will be processed within a\n      dynamic loop. Otherwise, a static loop will be used if possible.\n    use_combined_nms: If true, it uses tf.image.combined_non_max_suppression (\n      multi-class version of NMS that operates on a batch).\n      It greedily selects a subset of detection bounding boxes, pruning away\n      boxes that have high IOU (intersection over union) overlap (> thresh) with\n      already selected boxes. It operates independently for each batch.\n      Within each batch, it operates independently for each class for which\n      scores are provided (via the scores field of the input box_list),\n      pruning boxes with score less than a provided threshold prior to applying\n      NMS. This operation is performed on *all* batches and *all* classes\n      in the batch, therefore any background classes should be removed prior to\n      calling this function.\n      Masks and additional fields are not supported.\n      See argument checks in the code below for unsupported arguments.\n\n  Returns:\n    'nmsed_boxes': A [batch_size, max_detections, 4] float32 tensor\n      containing the non-max suppressed boxes.\n    'nmsed_scores': A [batch_size, max_detections] float32 tensor containing\n      the scores for the boxes.\n    'nmsed_classes': A [batch_size, max_detections] float32 tensor\n      containing the class for boxes.\n    'nmsed_masks': (optional) a\n      [batch_size, max_detections, mask_height, mask_width] float32 tensor\n      containing masks for each selected box. This is set to None if input\n      `masks` is None.\n    'nmsed_additional_fields': (optional) a dictionary of\n      [batch_size, max_detections, ...] float32 tensors corresponding to the\n      tensors specified in the input `additional_fields`. This is not returned\n      if input `additional_fields` is None.\n    'num_detections': A [batch_size] int32 tensor indicating the number of\n      valid detections per batch item. Only the top num_detections[i] entries in\n      nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The rest of the\n      entries are zero paddings.\n\n  Raises:\n    ValueError: if `q` in boxes.shape is not 1 or not equal to number of\n      classes as inferred from scores.shape.\n  \"\"\"\n    if use_combined_nms:\n        if change_coordinate_frame:\n            raise ValueError('change_coordinate_frame (normalizing coordinates relative to clip_window) is not supported by combined_nms.')\n        if num_valid_boxes is not None:\n            raise ValueError('num_valid_boxes is not supported by combined_nms.')\n        if masks is not None:\n            raise ValueError('masks is not supported by combined_nms.')\n        if soft_nms_sigma != 0.0:\n            raise ValueError('Soft NMS is not supported by combined_nms.')\n        if use_class_agnostic_nms:\n            raise ValueError('class-agnostic NMS is not supported by combined_nms.')\n        if clip_window is not None:\n            tf.compat.v1.logging.warning('clip_window is not supported by combined_nms unless it is [0. 0. 1. 1.] for each image.')\n        if additional_fields is not None:\n            tf.compat.v1.logging.warning('additional_fields is not supported by combined_nms.')\n        if parallel_iterations != 32:\n            tf.compat.v1.logging.warning('Number of batch items to be processed in parallel is not configurable by combined_nms.')\n        if max_classes_per_detection > 1:\n            tf.compat.v1.logging.warning('max_classes_per_detection is not configurable by combined_nms.')\n        with tf.name_scope(scope, 'CombinedNonMaxSuppression'):\n            (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_num_detections) = tf.image.combined_non_max_suppression(boxes=boxes, scores=scores, max_output_size_per_class=max_size_per_class, max_total_size=max_total_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_per_class=use_static_shapes)\n            batch_nmsed_masks = None\n            batch_nmsed_additional_fields = None\n            return (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_nmsed_masks, batch_nmsed_additional_fields, batch_num_detections)\n    q = shape_utils.get_dim_as_int(boxes.shape[2])\n    num_classes = shape_utils.get_dim_as_int(scores.shape[2])\n    if q != 1 and q != num_classes:\n        raise ValueError('third dimension of boxes must be either 1 or equal to the third dimension of scores.')\n    if change_coordinate_frame and clip_window is None:\n        raise ValueError('if change_coordinate_frame is True, then a clip_windowmust be specified.')\n    original_masks = masks\n    if additional_fields is None:\n        ordered_additional_fields = {}\n    else:\n        ordered_additional_fields = collections.OrderedDict(sorted(additional_fields.items(), key=lambda item: item[0]))\n    del additional_fields\n    with tf.name_scope(scope, 'BatchMultiClassNonMaxSuppression'):\n        boxes_shape = boxes.shape\n        batch_size = shape_utils.get_dim_as_int(boxes_shape[0])\n        num_anchors = shape_utils.get_dim_as_int(boxes_shape[1])\n        if batch_size is None:\n            batch_size = tf.shape(boxes)[0]\n        if num_anchors is None:\n            num_anchors = tf.shape(boxes)[1]\n        if num_valid_boxes is None:\n            num_valid_boxes = tf.ones([batch_size], dtype=tf.int32) * num_anchors\n        if masks is None:\n            masks_shape = tf.stack([batch_size, num_anchors, q, 1, 1])\n            masks = tf.zeros(masks_shape)\n        if clip_window is None:\n            clip_window = tf.stack([tf.reduce_min(boxes[:, :, :, 0]), tf.reduce_min(boxes[:, :, :, 1]), tf.reduce_max(boxes[:, :, :, 2]), tf.reduce_max(boxes[:, :, :, 3])])\n        if clip_window.shape.ndims == 1:\n            clip_window = tf.tile(tf.expand_dims(clip_window, 0), [batch_size, 1])\n\n        def _single_image_nms_fn(args):\n            \"\"\"Runs NMS on a single image and returns padded output.\n\n      Args:\n        args: A list of tensors consisting of the following:\n          per_image_boxes - A [num_anchors, q, 4] float32 tensor containing\n            detections. If `q` is 1 then same boxes are used for all classes\n            otherwise, if `q` is equal to number of classes, class-specific\n            boxes are used.\n          per_image_scores - A [num_anchors, num_classes] float32 tensor\n            containing the scores for each of the `num_anchors` detections.\n          per_image_masks - A [num_anchors, q, mask_height, mask_width] float32\n            tensor containing box masks. `q` can be either number of classes\n            or 1 depending on whether a separate mask is predicted per class.\n          per_image_clip_window - A 1D float32 tensor of the form\n            [ymin, xmin, ymax, xmax] representing the window to clip the boxes\n            to.\n          per_image_additional_fields - (optional) A variable number of float32\n            tensors each with size [num_anchors, ...].\n          per_image_num_valid_boxes - A tensor of type `int32`. A 1-D tensor of\n            shape [batch_size] representing the number of valid boxes to be\n            considered for each image in the batch.  This parameter allows for\n            ignoring zero paddings.\n\n      Returns:\n        'nmsed_boxes': A [max_detections, 4] float32 tensor containing the\n          non-max suppressed boxes.\n        'nmsed_scores': A [max_detections] float32 tensor containing the scores\n          for the boxes.\n        'nmsed_classes': A [max_detections] float32 tensor containing the class\n          for boxes.\n        'nmsed_masks': (optional) a [max_detections, mask_height, mask_width]\n          float32 tensor containing masks for each selected box. This is set to\n          None if input `masks` is None.\n        'nmsed_additional_fields':  (optional) A variable number of float32\n          tensors each with size [max_detections, ...] corresponding to the\n          input `per_image_additional_fields`.\n        'num_detections': A [batch_size] int32 tensor indicating the number of\n          valid detections per batch item. Only the top num_detections[i]\n          entries in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The\n          rest of the entries are zero paddings.\n      \"\"\"\n            per_image_boxes = args[0]\n            per_image_scores = args[1]\n            per_image_masks = args[2]\n            per_image_clip_window = args[3]\n            per_image_additional_fields = {key: value for (key, value) in zip(ordered_additional_fields, args[4:-1])}\n            per_image_num_valid_boxes = args[-1]\n            if use_static_shapes:\n                total_proposals = tf.shape(per_image_scores)\n                per_image_scores = tf.where(tf.less(tf.range(total_proposals[0]), per_image_num_valid_boxes), per_image_scores, tf.fill(total_proposals, np.finfo('float32').min))\n            else:\n                per_image_boxes = tf.reshape(tf.slice(per_image_boxes, 3 * [0], tf.stack([per_image_num_valid_boxes, -1, -1])), [-1, q, 4])\n                per_image_scores = tf.reshape(tf.slice(per_image_scores, [0, 0], tf.stack([per_image_num_valid_boxes, -1])), [-1, num_classes])\n                per_image_masks = tf.reshape(tf.slice(per_image_masks, 4 * [0], tf.stack([per_image_num_valid_boxes, -1, -1, -1])), [-1, q, shape_utils.get_dim_as_int(per_image_masks.shape[2]), shape_utils.get_dim_as_int(per_image_masks.shape[3])])\n                if per_image_additional_fields is not None:\n                    for (key, tensor) in per_image_additional_fields.items():\n                        additional_field_shape = tensor.get_shape()\n                        additional_field_dim = len(additional_field_shape)\n                        per_image_additional_fields[key] = tf.reshape(tf.slice(per_image_additional_fields[key], additional_field_dim * [0], tf.stack([per_image_num_valid_boxes] + (additional_field_dim - 1) * [-1])), [-1] + [shape_utils.get_dim_as_int(dim) for dim in additional_field_shape[1:]])\n            if use_class_agnostic_nms:\n                (nmsed_boxlist, num_valid_nms_boxes) = class_agnostic_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_classes_per_detection, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n            else:\n                (nmsed_boxlist, num_valid_nms_boxes) = multiclass_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_size_per_class, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n            if not use_static_shapes:\n                nmsed_boxlist = box_list_ops.pad_or_clip_box_list(nmsed_boxlist, max_total_size)\n            num_detections = num_valid_nms_boxes\n            nmsed_boxes = nmsed_boxlist.get()\n            nmsed_scores = nmsed_boxlist.get_field(fields.BoxListFields.scores)\n            nmsed_classes = nmsed_boxlist.get_field(fields.BoxListFields.classes)\n            nmsed_masks = nmsed_boxlist.get_field(fields.BoxListFields.masks)\n            nmsed_additional_fields = []\n            for key in sorted(per_image_additional_fields.keys()):\n                nmsed_additional_fields.append(nmsed_boxlist.get_field(key))\n            return [nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_masks] + nmsed_additional_fields + [num_detections]\n        num_additional_fields = 0\n        if ordered_additional_fields:\n            num_additional_fields = len(ordered_additional_fields)\n        num_nmsed_outputs = 4 + num_additional_fields\n        if use_dynamic_map_fn:\n            map_fn = tf.map_fn\n        else:\n            map_fn = shape_utils.static_or_dynamic_map_fn\n        batch_outputs = map_fn(_single_image_nms_fn, elems=[boxes, scores, masks, clip_window] + list(ordered_additional_fields.values()) + [num_valid_boxes], dtype=num_nmsed_outputs * [tf.float32] + [tf.int32], parallel_iterations=parallel_iterations)\n        batch_nmsed_boxes = batch_outputs[0]\n        batch_nmsed_scores = batch_outputs[1]\n        batch_nmsed_classes = batch_outputs[2]\n        batch_nmsed_masks = batch_outputs[3]\n        batch_nmsed_values = batch_outputs[4:-1]\n        batch_nmsed_additional_fields = {}\n        if num_additional_fields > 0:\n            batch_nmsed_keys = list(ordered_additional_fields.keys())\n            for i in range(len(batch_nmsed_keys)):\n                batch_nmsed_additional_fields[batch_nmsed_keys[i]] = batch_nmsed_values[i]\n        batch_num_detections = batch_outputs[-1]\n        if original_masks is None:\n            batch_nmsed_masks = None\n        if not ordered_additional_fields:\n            batch_nmsed_additional_fields = None\n        return (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_nmsed_masks, batch_nmsed_additional_fields, batch_num_detections)",
        "mutated": [
            "def batch_multiclass_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_size_per_class, max_total_size=0, clip_window=None, change_coordinate_frame=False, num_valid_boxes=None, masks=None, additional_fields=None, soft_nms_sigma=0.0, scope=None, use_static_shapes=False, use_partitioned_nms=False, parallel_iterations=32, use_class_agnostic_nms=False, max_classes_per_detection=1, use_dynamic_map_fn=False, use_combined_nms=False):\n    if False:\n        i = 10\n    \"Multi-class version of non maximum suppression that operates on a batch.\\n\\n  This op is similar to `multiclass_non_max_suppression` but operates on a batch\\n  of boxes and scores. See documentation for `multiclass_non_max_suppression`\\n  for details.\\n\\n  Args:\\n    boxes: A [batch_size, num_anchors, q, 4] float32 tensor containing\\n      detections. If `q` is 1 then same boxes are used for all classes\\n      otherwise, if `q` is equal to number of classes, class-specific boxes are\\n      used.\\n    scores: A [batch_size, num_anchors, num_classes] float32 tensor containing\\n      the scores for each of the `num_anchors` detections. The scores have to be\\n      non-negative when use_static_shapes is set True.\\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    max_size_per_class: maximum number of retained boxes per class.\\n    max_total_size: maximum number of boxes retained over all classes. By\\n      default returns all boxes retained after capping boxes per class.\\n    clip_window: A float32 tensor of shape [batch_size, 4]  where each entry is\\n      of the form [y_min, x_min, y_max, x_max] representing the window to clip\\n      boxes to before performing non-max suppression. This argument can also be\\n      a tensor of shape [4] in which case, the same clip window is applied to\\n      all images in the batch. If clip_widow is None, all boxes are used to\\n      perform non-max suppression.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided)\\n    num_valid_boxes: (optional) a Tensor of type `int32`. A 1-D tensor of shape\\n      [batch_size] representing the number of valid boxes to be considered for\\n      each image in the batch.  This parameter allows for ignoring zero\\n      paddings.\\n    masks: (optional) a [batch_size, num_anchors, q, mask_height, mask_width]\\n      float32 tensor containing box masks. `q` can be either number of classes\\n      or 1 depending on whether a separate mask is predicted per class.\\n    additional_fields: (optional) If not None, a dictionary that maps keys to\\n      tensors whose dimensions are [batch_size, num_anchors, ...].\\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\\n      False.\\n    scope: tf scope name.\\n    use_static_shapes: If true, the output nmsed boxes are padded to be of\\n      length `max_size_per_class` and it doesn't clip boxes to max_total_size.\\n      Defaults to false.\\n    use_partitioned_nms: If true, use partitioned version of\\n      non_max_suppression.\\n    parallel_iterations: (optional) number of batch items to process in\\n      parallel.\\n    use_class_agnostic_nms: If true, this uses class-agnostic non max\\n      suppression\\n    max_classes_per_detection: Maximum number of retained classes per detection\\n      box in class-agnostic NMS.\\n    use_dynamic_map_fn: If true, images in the batch will be processed within a\\n      dynamic loop. Otherwise, a static loop will be used if possible.\\n    use_combined_nms: If true, it uses tf.image.combined_non_max_suppression (\\n      multi-class version of NMS that operates on a batch).\\n      It greedily selects a subset of detection bounding boxes, pruning away\\n      boxes that have high IOU (intersection over union) overlap (> thresh) with\\n      already selected boxes. It operates independently for each batch.\\n      Within each batch, it operates independently for each class for which\\n      scores are provided (via the scores field of the input box_list),\\n      pruning boxes with score less than a provided threshold prior to applying\\n      NMS. This operation is performed on *all* batches and *all* classes\\n      in the batch, therefore any background classes should be removed prior to\\n      calling this function.\\n      Masks and additional fields are not supported.\\n      See argument checks in the code below for unsupported arguments.\\n\\n  Returns:\\n    'nmsed_boxes': A [batch_size, max_detections, 4] float32 tensor\\n      containing the non-max suppressed boxes.\\n    'nmsed_scores': A [batch_size, max_detections] float32 tensor containing\\n      the scores for the boxes.\\n    'nmsed_classes': A [batch_size, max_detections] float32 tensor\\n      containing the class for boxes.\\n    'nmsed_masks': (optional) a\\n      [batch_size, max_detections, mask_height, mask_width] float32 tensor\\n      containing masks for each selected box. This is set to None if input\\n      `masks` is None.\\n    'nmsed_additional_fields': (optional) a dictionary of\\n      [batch_size, max_detections, ...] float32 tensors corresponding to the\\n      tensors specified in the input `additional_fields`. This is not returned\\n      if input `additional_fields` is None.\\n    'num_detections': A [batch_size] int32 tensor indicating the number of\\n      valid detections per batch item. Only the top num_detections[i] entries in\\n      nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The rest of the\\n      entries are zero paddings.\\n\\n  Raises:\\n    ValueError: if `q` in boxes.shape is not 1 or not equal to number of\\n      classes as inferred from scores.shape.\\n  \"\n    if use_combined_nms:\n        if change_coordinate_frame:\n            raise ValueError('change_coordinate_frame (normalizing coordinates relative to clip_window) is not supported by combined_nms.')\n        if num_valid_boxes is not None:\n            raise ValueError('num_valid_boxes is not supported by combined_nms.')\n        if masks is not None:\n            raise ValueError('masks is not supported by combined_nms.')\n        if soft_nms_sigma != 0.0:\n            raise ValueError('Soft NMS is not supported by combined_nms.')\n        if use_class_agnostic_nms:\n            raise ValueError('class-agnostic NMS is not supported by combined_nms.')\n        if clip_window is not None:\n            tf.compat.v1.logging.warning('clip_window is not supported by combined_nms unless it is [0. 0. 1. 1.] for each image.')\n        if additional_fields is not None:\n            tf.compat.v1.logging.warning('additional_fields is not supported by combined_nms.')\n        if parallel_iterations != 32:\n            tf.compat.v1.logging.warning('Number of batch items to be processed in parallel is not configurable by combined_nms.')\n        if max_classes_per_detection > 1:\n            tf.compat.v1.logging.warning('max_classes_per_detection is not configurable by combined_nms.')\n        with tf.name_scope(scope, 'CombinedNonMaxSuppression'):\n            (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_num_detections) = tf.image.combined_non_max_suppression(boxes=boxes, scores=scores, max_output_size_per_class=max_size_per_class, max_total_size=max_total_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_per_class=use_static_shapes)\n            batch_nmsed_masks = None\n            batch_nmsed_additional_fields = None\n            return (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_nmsed_masks, batch_nmsed_additional_fields, batch_num_detections)\n    q = shape_utils.get_dim_as_int(boxes.shape[2])\n    num_classes = shape_utils.get_dim_as_int(scores.shape[2])\n    if q != 1 and q != num_classes:\n        raise ValueError('third dimension of boxes must be either 1 or equal to the third dimension of scores.')\n    if change_coordinate_frame and clip_window is None:\n        raise ValueError('if change_coordinate_frame is True, then a clip_windowmust be specified.')\n    original_masks = masks\n    if additional_fields is None:\n        ordered_additional_fields = {}\n    else:\n        ordered_additional_fields = collections.OrderedDict(sorted(additional_fields.items(), key=lambda item: item[0]))\n    del additional_fields\n    with tf.name_scope(scope, 'BatchMultiClassNonMaxSuppression'):\n        boxes_shape = boxes.shape\n        batch_size = shape_utils.get_dim_as_int(boxes_shape[0])\n        num_anchors = shape_utils.get_dim_as_int(boxes_shape[1])\n        if batch_size is None:\n            batch_size = tf.shape(boxes)[0]\n        if num_anchors is None:\n            num_anchors = tf.shape(boxes)[1]\n        if num_valid_boxes is None:\n            num_valid_boxes = tf.ones([batch_size], dtype=tf.int32) * num_anchors\n        if masks is None:\n            masks_shape = tf.stack([batch_size, num_anchors, q, 1, 1])\n            masks = tf.zeros(masks_shape)\n        if clip_window is None:\n            clip_window = tf.stack([tf.reduce_min(boxes[:, :, :, 0]), tf.reduce_min(boxes[:, :, :, 1]), tf.reduce_max(boxes[:, :, :, 2]), tf.reduce_max(boxes[:, :, :, 3])])\n        if clip_window.shape.ndims == 1:\n            clip_window = tf.tile(tf.expand_dims(clip_window, 0), [batch_size, 1])\n\n        def _single_image_nms_fn(args):\n            \"\"\"Runs NMS on a single image and returns padded output.\n\n      Args:\n        args: A list of tensors consisting of the following:\n          per_image_boxes - A [num_anchors, q, 4] float32 tensor containing\n            detections. If `q` is 1 then same boxes are used for all classes\n            otherwise, if `q` is equal to number of classes, class-specific\n            boxes are used.\n          per_image_scores - A [num_anchors, num_classes] float32 tensor\n            containing the scores for each of the `num_anchors` detections.\n          per_image_masks - A [num_anchors, q, mask_height, mask_width] float32\n            tensor containing box masks. `q` can be either number of classes\n            or 1 depending on whether a separate mask is predicted per class.\n          per_image_clip_window - A 1D float32 tensor of the form\n            [ymin, xmin, ymax, xmax] representing the window to clip the boxes\n            to.\n          per_image_additional_fields - (optional) A variable number of float32\n            tensors each with size [num_anchors, ...].\n          per_image_num_valid_boxes - A tensor of type `int32`. A 1-D tensor of\n            shape [batch_size] representing the number of valid boxes to be\n            considered for each image in the batch.  This parameter allows for\n            ignoring zero paddings.\n\n      Returns:\n        'nmsed_boxes': A [max_detections, 4] float32 tensor containing the\n          non-max suppressed boxes.\n        'nmsed_scores': A [max_detections] float32 tensor containing the scores\n          for the boxes.\n        'nmsed_classes': A [max_detections] float32 tensor containing the class\n          for boxes.\n        'nmsed_masks': (optional) a [max_detections, mask_height, mask_width]\n          float32 tensor containing masks for each selected box. This is set to\n          None if input `masks` is None.\n        'nmsed_additional_fields':  (optional) A variable number of float32\n          tensors each with size [max_detections, ...] corresponding to the\n          input `per_image_additional_fields`.\n        'num_detections': A [batch_size] int32 tensor indicating the number of\n          valid detections per batch item. Only the top num_detections[i]\n          entries in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The\n          rest of the entries are zero paddings.\n      \"\"\"\n            per_image_boxes = args[0]\n            per_image_scores = args[1]\n            per_image_masks = args[2]\n            per_image_clip_window = args[3]\n            per_image_additional_fields = {key: value for (key, value) in zip(ordered_additional_fields, args[4:-1])}\n            per_image_num_valid_boxes = args[-1]\n            if use_static_shapes:\n                total_proposals = tf.shape(per_image_scores)\n                per_image_scores = tf.where(tf.less(tf.range(total_proposals[0]), per_image_num_valid_boxes), per_image_scores, tf.fill(total_proposals, np.finfo('float32').min))\n            else:\n                per_image_boxes = tf.reshape(tf.slice(per_image_boxes, 3 * [0], tf.stack([per_image_num_valid_boxes, -1, -1])), [-1, q, 4])\n                per_image_scores = tf.reshape(tf.slice(per_image_scores, [0, 0], tf.stack([per_image_num_valid_boxes, -1])), [-1, num_classes])\n                per_image_masks = tf.reshape(tf.slice(per_image_masks, 4 * [0], tf.stack([per_image_num_valid_boxes, -1, -1, -1])), [-1, q, shape_utils.get_dim_as_int(per_image_masks.shape[2]), shape_utils.get_dim_as_int(per_image_masks.shape[3])])\n                if per_image_additional_fields is not None:\n                    for (key, tensor) in per_image_additional_fields.items():\n                        additional_field_shape = tensor.get_shape()\n                        additional_field_dim = len(additional_field_shape)\n                        per_image_additional_fields[key] = tf.reshape(tf.slice(per_image_additional_fields[key], additional_field_dim * [0], tf.stack([per_image_num_valid_boxes] + (additional_field_dim - 1) * [-1])), [-1] + [shape_utils.get_dim_as_int(dim) for dim in additional_field_shape[1:]])\n            if use_class_agnostic_nms:\n                (nmsed_boxlist, num_valid_nms_boxes) = class_agnostic_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_classes_per_detection, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n            else:\n                (nmsed_boxlist, num_valid_nms_boxes) = multiclass_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_size_per_class, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n            if not use_static_shapes:\n                nmsed_boxlist = box_list_ops.pad_or_clip_box_list(nmsed_boxlist, max_total_size)\n            num_detections = num_valid_nms_boxes\n            nmsed_boxes = nmsed_boxlist.get()\n            nmsed_scores = nmsed_boxlist.get_field(fields.BoxListFields.scores)\n            nmsed_classes = nmsed_boxlist.get_field(fields.BoxListFields.classes)\n            nmsed_masks = nmsed_boxlist.get_field(fields.BoxListFields.masks)\n            nmsed_additional_fields = []\n            for key in sorted(per_image_additional_fields.keys()):\n                nmsed_additional_fields.append(nmsed_boxlist.get_field(key))\n            return [nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_masks] + nmsed_additional_fields + [num_detections]\n        num_additional_fields = 0\n        if ordered_additional_fields:\n            num_additional_fields = len(ordered_additional_fields)\n        num_nmsed_outputs = 4 + num_additional_fields\n        if use_dynamic_map_fn:\n            map_fn = tf.map_fn\n        else:\n            map_fn = shape_utils.static_or_dynamic_map_fn\n        batch_outputs = map_fn(_single_image_nms_fn, elems=[boxes, scores, masks, clip_window] + list(ordered_additional_fields.values()) + [num_valid_boxes], dtype=num_nmsed_outputs * [tf.float32] + [tf.int32], parallel_iterations=parallel_iterations)\n        batch_nmsed_boxes = batch_outputs[0]\n        batch_nmsed_scores = batch_outputs[1]\n        batch_nmsed_classes = batch_outputs[2]\n        batch_nmsed_masks = batch_outputs[3]\n        batch_nmsed_values = batch_outputs[4:-1]\n        batch_nmsed_additional_fields = {}\n        if num_additional_fields > 0:\n            batch_nmsed_keys = list(ordered_additional_fields.keys())\n            for i in range(len(batch_nmsed_keys)):\n                batch_nmsed_additional_fields[batch_nmsed_keys[i]] = batch_nmsed_values[i]\n        batch_num_detections = batch_outputs[-1]\n        if original_masks is None:\n            batch_nmsed_masks = None\n        if not ordered_additional_fields:\n            batch_nmsed_additional_fields = None\n        return (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_nmsed_masks, batch_nmsed_additional_fields, batch_num_detections)",
            "def batch_multiclass_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_size_per_class, max_total_size=0, clip_window=None, change_coordinate_frame=False, num_valid_boxes=None, masks=None, additional_fields=None, soft_nms_sigma=0.0, scope=None, use_static_shapes=False, use_partitioned_nms=False, parallel_iterations=32, use_class_agnostic_nms=False, max_classes_per_detection=1, use_dynamic_map_fn=False, use_combined_nms=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Multi-class version of non maximum suppression that operates on a batch.\\n\\n  This op is similar to `multiclass_non_max_suppression` but operates on a batch\\n  of boxes and scores. See documentation for `multiclass_non_max_suppression`\\n  for details.\\n\\n  Args:\\n    boxes: A [batch_size, num_anchors, q, 4] float32 tensor containing\\n      detections. If `q` is 1 then same boxes are used for all classes\\n      otherwise, if `q` is equal to number of classes, class-specific boxes are\\n      used.\\n    scores: A [batch_size, num_anchors, num_classes] float32 tensor containing\\n      the scores for each of the `num_anchors` detections. The scores have to be\\n      non-negative when use_static_shapes is set True.\\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    max_size_per_class: maximum number of retained boxes per class.\\n    max_total_size: maximum number of boxes retained over all classes. By\\n      default returns all boxes retained after capping boxes per class.\\n    clip_window: A float32 tensor of shape [batch_size, 4]  where each entry is\\n      of the form [y_min, x_min, y_max, x_max] representing the window to clip\\n      boxes to before performing non-max suppression. This argument can also be\\n      a tensor of shape [4] in which case, the same clip window is applied to\\n      all images in the batch. If clip_widow is None, all boxes are used to\\n      perform non-max suppression.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided)\\n    num_valid_boxes: (optional) a Tensor of type `int32`. A 1-D tensor of shape\\n      [batch_size] representing the number of valid boxes to be considered for\\n      each image in the batch.  This parameter allows for ignoring zero\\n      paddings.\\n    masks: (optional) a [batch_size, num_anchors, q, mask_height, mask_width]\\n      float32 tensor containing box masks. `q` can be either number of classes\\n      or 1 depending on whether a separate mask is predicted per class.\\n    additional_fields: (optional) If not None, a dictionary that maps keys to\\n      tensors whose dimensions are [batch_size, num_anchors, ...].\\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\\n      False.\\n    scope: tf scope name.\\n    use_static_shapes: If true, the output nmsed boxes are padded to be of\\n      length `max_size_per_class` and it doesn't clip boxes to max_total_size.\\n      Defaults to false.\\n    use_partitioned_nms: If true, use partitioned version of\\n      non_max_suppression.\\n    parallel_iterations: (optional) number of batch items to process in\\n      parallel.\\n    use_class_agnostic_nms: If true, this uses class-agnostic non max\\n      suppression\\n    max_classes_per_detection: Maximum number of retained classes per detection\\n      box in class-agnostic NMS.\\n    use_dynamic_map_fn: If true, images in the batch will be processed within a\\n      dynamic loop. Otherwise, a static loop will be used if possible.\\n    use_combined_nms: If true, it uses tf.image.combined_non_max_suppression (\\n      multi-class version of NMS that operates on a batch).\\n      It greedily selects a subset of detection bounding boxes, pruning away\\n      boxes that have high IOU (intersection over union) overlap (> thresh) with\\n      already selected boxes. It operates independently for each batch.\\n      Within each batch, it operates independently for each class for which\\n      scores are provided (via the scores field of the input box_list),\\n      pruning boxes with score less than a provided threshold prior to applying\\n      NMS. This operation is performed on *all* batches and *all* classes\\n      in the batch, therefore any background classes should be removed prior to\\n      calling this function.\\n      Masks and additional fields are not supported.\\n      See argument checks in the code below for unsupported arguments.\\n\\n  Returns:\\n    'nmsed_boxes': A [batch_size, max_detections, 4] float32 tensor\\n      containing the non-max suppressed boxes.\\n    'nmsed_scores': A [batch_size, max_detections] float32 tensor containing\\n      the scores for the boxes.\\n    'nmsed_classes': A [batch_size, max_detections] float32 tensor\\n      containing the class for boxes.\\n    'nmsed_masks': (optional) a\\n      [batch_size, max_detections, mask_height, mask_width] float32 tensor\\n      containing masks for each selected box. This is set to None if input\\n      `masks` is None.\\n    'nmsed_additional_fields': (optional) a dictionary of\\n      [batch_size, max_detections, ...] float32 tensors corresponding to the\\n      tensors specified in the input `additional_fields`. This is not returned\\n      if input `additional_fields` is None.\\n    'num_detections': A [batch_size] int32 tensor indicating the number of\\n      valid detections per batch item. Only the top num_detections[i] entries in\\n      nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The rest of the\\n      entries are zero paddings.\\n\\n  Raises:\\n    ValueError: if `q` in boxes.shape is not 1 or not equal to number of\\n      classes as inferred from scores.shape.\\n  \"\n    if use_combined_nms:\n        if change_coordinate_frame:\n            raise ValueError('change_coordinate_frame (normalizing coordinates relative to clip_window) is not supported by combined_nms.')\n        if num_valid_boxes is not None:\n            raise ValueError('num_valid_boxes is not supported by combined_nms.')\n        if masks is not None:\n            raise ValueError('masks is not supported by combined_nms.')\n        if soft_nms_sigma != 0.0:\n            raise ValueError('Soft NMS is not supported by combined_nms.')\n        if use_class_agnostic_nms:\n            raise ValueError('class-agnostic NMS is not supported by combined_nms.')\n        if clip_window is not None:\n            tf.compat.v1.logging.warning('clip_window is not supported by combined_nms unless it is [0. 0. 1. 1.] for each image.')\n        if additional_fields is not None:\n            tf.compat.v1.logging.warning('additional_fields is not supported by combined_nms.')\n        if parallel_iterations != 32:\n            tf.compat.v1.logging.warning('Number of batch items to be processed in parallel is not configurable by combined_nms.')\n        if max_classes_per_detection > 1:\n            tf.compat.v1.logging.warning('max_classes_per_detection is not configurable by combined_nms.')\n        with tf.name_scope(scope, 'CombinedNonMaxSuppression'):\n            (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_num_detections) = tf.image.combined_non_max_suppression(boxes=boxes, scores=scores, max_output_size_per_class=max_size_per_class, max_total_size=max_total_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_per_class=use_static_shapes)\n            batch_nmsed_masks = None\n            batch_nmsed_additional_fields = None\n            return (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_nmsed_masks, batch_nmsed_additional_fields, batch_num_detections)\n    q = shape_utils.get_dim_as_int(boxes.shape[2])\n    num_classes = shape_utils.get_dim_as_int(scores.shape[2])\n    if q != 1 and q != num_classes:\n        raise ValueError('third dimension of boxes must be either 1 or equal to the third dimension of scores.')\n    if change_coordinate_frame and clip_window is None:\n        raise ValueError('if change_coordinate_frame is True, then a clip_windowmust be specified.')\n    original_masks = masks\n    if additional_fields is None:\n        ordered_additional_fields = {}\n    else:\n        ordered_additional_fields = collections.OrderedDict(sorted(additional_fields.items(), key=lambda item: item[0]))\n    del additional_fields\n    with tf.name_scope(scope, 'BatchMultiClassNonMaxSuppression'):\n        boxes_shape = boxes.shape\n        batch_size = shape_utils.get_dim_as_int(boxes_shape[0])\n        num_anchors = shape_utils.get_dim_as_int(boxes_shape[1])\n        if batch_size is None:\n            batch_size = tf.shape(boxes)[0]\n        if num_anchors is None:\n            num_anchors = tf.shape(boxes)[1]\n        if num_valid_boxes is None:\n            num_valid_boxes = tf.ones([batch_size], dtype=tf.int32) * num_anchors\n        if masks is None:\n            masks_shape = tf.stack([batch_size, num_anchors, q, 1, 1])\n            masks = tf.zeros(masks_shape)\n        if clip_window is None:\n            clip_window = tf.stack([tf.reduce_min(boxes[:, :, :, 0]), tf.reduce_min(boxes[:, :, :, 1]), tf.reduce_max(boxes[:, :, :, 2]), tf.reduce_max(boxes[:, :, :, 3])])\n        if clip_window.shape.ndims == 1:\n            clip_window = tf.tile(tf.expand_dims(clip_window, 0), [batch_size, 1])\n\n        def _single_image_nms_fn(args):\n            \"\"\"Runs NMS on a single image and returns padded output.\n\n      Args:\n        args: A list of tensors consisting of the following:\n          per_image_boxes - A [num_anchors, q, 4] float32 tensor containing\n            detections. If `q` is 1 then same boxes are used for all classes\n            otherwise, if `q` is equal to number of classes, class-specific\n            boxes are used.\n          per_image_scores - A [num_anchors, num_classes] float32 tensor\n            containing the scores for each of the `num_anchors` detections.\n          per_image_masks - A [num_anchors, q, mask_height, mask_width] float32\n            tensor containing box masks. `q` can be either number of classes\n            or 1 depending on whether a separate mask is predicted per class.\n          per_image_clip_window - A 1D float32 tensor of the form\n            [ymin, xmin, ymax, xmax] representing the window to clip the boxes\n            to.\n          per_image_additional_fields - (optional) A variable number of float32\n            tensors each with size [num_anchors, ...].\n          per_image_num_valid_boxes - A tensor of type `int32`. A 1-D tensor of\n            shape [batch_size] representing the number of valid boxes to be\n            considered for each image in the batch.  This parameter allows for\n            ignoring zero paddings.\n\n      Returns:\n        'nmsed_boxes': A [max_detections, 4] float32 tensor containing the\n          non-max suppressed boxes.\n        'nmsed_scores': A [max_detections] float32 tensor containing the scores\n          for the boxes.\n        'nmsed_classes': A [max_detections] float32 tensor containing the class\n          for boxes.\n        'nmsed_masks': (optional) a [max_detections, mask_height, mask_width]\n          float32 tensor containing masks for each selected box. This is set to\n          None if input `masks` is None.\n        'nmsed_additional_fields':  (optional) A variable number of float32\n          tensors each with size [max_detections, ...] corresponding to the\n          input `per_image_additional_fields`.\n        'num_detections': A [batch_size] int32 tensor indicating the number of\n          valid detections per batch item. Only the top num_detections[i]\n          entries in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The\n          rest of the entries are zero paddings.\n      \"\"\"\n            per_image_boxes = args[0]\n            per_image_scores = args[1]\n            per_image_masks = args[2]\n            per_image_clip_window = args[3]\n            per_image_additional_fields = {key: value for (key, value) in zip(ordered_additional_fields, args[4:-1])}\n            per_image_num_valid_boxes = args[-1]\n            if use_static_shapes:\n                total_proposals = tf.shape(per_image_scores)\n                per_image_scores = tf.where(tf.less(tf.range(total_proposals[0]), per_image_num_valid_boxes), per_image_scores, tf.fill(total_proposals, np.finfo('float32').min))\n            else:\n                per_image_boxes = tf.reshape(tf.slice(per_image_boxes, 3 * [0], tf.stack([per_image_num_valid_boxes, -1, -1])), [-1, q, 4])\n                per_image_scores = tf.reshape(tf.slice(per_image_scores, [0, 0], tf.stack([per_image_num_valid_boxes, -1])), [-1, num_classes])\n                per_image_masks = tf.reshape(tf.slice(per_image_masks, 4 * [0], tf.stack([per_image_num_valid_boxes, -1, -1, -1])), [-1, q, shape_utils.get_dim_as_int(per_image_masks.shape[2]), shape_utils.get_dim_as_int(per_image_masks.shape[3])])\n                if per_image_additional_fields is not None:\n                    for (key, tensor) in per_image_additional_fields.items():\n                        additional_field_shape = tensor.get_shape()\n                        additional_field_dim = len(additional_field_shape)\n                        per_image_additional_fields[key] = tf.reshape(tf.slice(per_image_additional_fields[key], additional_field_dim * [0], tf.stack([per_image_num_valid_boxes] + (additional_field_dim - 1) * [-1])), [-1] + [shape_utils.get_dim_as_int(dim) for dim in additional_field_shape[1:]])\n            if use_class_agnostic_nms:\n                (nmsed_boxlist, num_valid_nms_boxes) = class_agnostic_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_classes_per_detection, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n            else:\n                (nmsed_boxlist, num_valid_nms_boxes) = multiclass_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_size_per_class, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n            if not use_static_shapes:\n                nmsed_boxlist = box_list_ops.pad_or_clip_box_list(nmsed_boxlist, max_total_size)\n            num_detections = num_valid_nms_boxes\n            nmsed_boxes = nmsed_boxlist.get()\n            nmsed_scores = nmsed_boxlist.get_field(fields.BoxListFields.scores)\n            nmsed_classes = nmsed_boxlist.get_field(fields.BoxListFields.classes)\n            nmsed_masks = nmsed_boxlist.get_field(fields.BoxListFields.masks)\n            nmsed_additional_fields = []\n            for key in sorted(per_image_additional_fields.keys()):\n                nmsed_additional_fields.append(nmsed_boxlist.get_field(key))\n            return [nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_masks] + nmsed_additional_fields + [num_detections]\n        num_additional_fields = 0\n        if ordered_additional_fields:\n            num_additional_fields = len(ordered_additional_fields)\n        num_nmsed_outputs = 4 + num_additional_fields\n        if use_dynamic_map_fn:\n            map_fn = tf.map_fn\n        else:\n            map_fn = shape_utils.static_or_dynamic_map_fn\n        batch_outputs = map_fn(_single_image_nms_fn, elems=[boxes, scores, masks, clip_window] + list(ordered_additional_fields.values()) + [num_valid_boxes], dtype=num_nmsed_outputs * [tf.float32] + [tf.int32], parallel_iterations=parallel_iterations)\n        batch_nmsed_boxes = batch_outputs[0]\n        batch_nmsed_scores = batch_outputs[1]\n        batch_nmsed_classes = batch_outputs[2]\n        batch_nmsed_masks = batch_outputs[3]\n        batch_nmsed_values = batch_outputs[4:-1]\n        batch_nmsed_additional_fields = {}\n        if num_additional_fields > 0:\n            batch_nmsed_keys = list(ordered_additional_fields.keys())\n            for i in range(len(batch_nmsed_keys)):\n                batch_nmsed_additional_fields[batch_nmsed_keys[i]] = batch_nmsed_values[i]\n        batch_num_detections = batch_outputs[-1]\n        if original_masks is None:\n            batch_nmsed_masks = None\n        if not ordered_additional_fields:\n            batch_nmsed_additional_fields = None\n        return (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_nmsed_masks, batch_nmsed_additional_fields, batch_num_detections)",
            "def batch_multiclass_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_size_per_class, max_total_size=0, clip_window=None, change_coordinate_frame=False, num_valid_boxes=None, masks=None, additional_fields=None, soft_nms_sigma=0.0, scope=None, use_static_shapes=False, use_partitioned_nms=False, parallel_iterations=32, use_class_agnostic_nms=False, max_classes_per_detection=1, use_dynamic_map_fn=False, use_combined_nms=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Multi-class version of non maximum suppression that operates on a batch.\\n\\n  This op is similar to `multiclass_non_max_suppression` but operates on a batch\\n  of boxes and scores. See documentation for `multiclass_non_max_suppression`\\n  for details.\\n\\n  Args:\\n    boxes: A [batch_size, num_anchors, q, 4] float32 tensor containing\\n      detections. If `q` is 1 then same boxes are used for all classes\\n      otherwise, if `q` is equal to number of classes, class-specific boxes are\\n      used.\\n    scores: A [batch_size, num_anchors, num_classes] float32 tensor containing\\n      the scores for each of the `num_anchors` detections. The scores have to be\\n      non-negative when use_static_shapes is set True.\\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    max_size_per_class: maximum number of retained boxes per class.\\n    max_total_size: maximum number of boxes retained over all classes. By\\n      default returns all boxes retained after capping boxes per class.\\n    clip_window: A float32 tensor of shape [batch_size, 4]  where each entry is\\n      of the form [y_min, x_min, y_max, x_max] representing the window to clip\\n      boxes to before performing non-max suppression. This argument can also be\\n      a tensor of shape [4] in which case, the same clip window is applied to\\n      all images in the batch. If clip_widow is None, all boxes are used to\\n      perform non-max suppression.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided)\\n    num_valid_boxes: (optional) a Tensor of type `int32`. A 1-D tensor of shape\\n      [batch_size] representing the number of valid boxes to be considered for\\n      each image in the batch.  This parameter allows for ignoring zero\\n      paddings.\\n    masks: (optional) a [batch_size, num_anchors, q, mask_height, mask_width]\\n      float32 tensor containing box masks. `q` can be either number of classes\\n      or 1 depending on whether a separate mask is predicted per class.\\n    additional_fields: (optional) If not None, a dictionary that maps keys to\\n      tensors whose dimensions are [batch_size, num_anchors, ...].\\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\\n      False.\\n    scope: tf scope name.\\n    use_static_shapes: If true, the output nmsed boxes are padded to be of\\n      length `max_size_per_class` and it doesn't clip boxes to max_total_size.\\n      Defaults to false.\\n    use_partitioned_nms: If true, use partitioned version of\\n      non_max_suppression.\\n    parallel_iterations: (optional) number of batch items to process in\\n      parallel.\\n    use_class_agnostic_nms: If true, this uses class-agnostic non max\\n      suppression\\n    max_classes_per_detection: Maximum number of retained classes per detection\\n      box in class-agnostic NMS.\\n    use_dynamic_map_fn: If true, images in the batch will be processed within a\\n      dynamic loop. Otherwise, a static loop will be used if possible.\\n    use_combined_nms: If true, it uses tf.image.combined_non_max_suppression (\\n      multi-class version of NMS that operates on a batch).\\n      It greedily selects a subset of detection bounding boxes, pruning away\\n      boxes that have high IOU (intersection over union) overlap (> thresh) with\\n      already selected boxes. It operates independently for each batch.\\n      Within each batch, it operates independently for each class for which\\n      scores are provided (via the scores field of the input box_list),\\n      pruning boxes with score less than a provided threshold prior to applying\\n      NMS. This operation is performed on *all* batches and *all* classes\\n      in the batch, therefore any background classes should be removed prior to\\n      calling this function.\\n      Masks and additional fields are not supported.\\n      See argument checks in the code below for unsupported arguments.\\n\\n  Returns:\\n    'nmsed_boxes': A [batch_size, max_detections, 4] float32 tensor\\n      containing the non-max suppressed boxes.\\n    'nmsed_scores': A [batch_size, max_detections] float32 tensor containing\\n      the scores for the boxes.\\n    'nmsed_classes': A [batch_size, max_detections] float32 tensor\\n      containing the class for boxes.\\n    'nmsed_masks': (optional) a\\n      [batch_size, max_detections, mask_height, mask_width] float32 tensor\\n      containing masks for each selected box. This is set to None if input\\n      `masks` is None.\\n    'nmsed_additional_fields': (optional) a dictionary of\\n      [batch_size, max_detections, ...] float32 tensors corresponding to the\\n      tensors specified in the input `additional_fields`. This is not returned\\n      if input `additional_fields` is None.\\n    'num_detections': A [batch_size] int32 tensor indicating the number of\\n      valid detections per batch item. Only the top num_detections[i] entries in\\n      nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The rest of the\\n      entries are zero paddings.\\n\\n  Raises:\\n    ValueError: if `q` in boxes.shape is not 1 or not equal to number of\\n      classes as inferred from scores.shape.\\n  \"\n    if use_combined_nms:\n        if change_coordinate_frame:\n            raise ValueError('change_coordinate_frame (normalizing coordinates relative to clip_window) is not supported by combined_nms.')\n        if num_valid_boxes is not None:\n            raise ValueError('num_valid_boxes is not supported by combined_nms.')\n        if masks is not None:\n            raise ValueError('masks is not supported by combined_nms.')\n        if soft_nms_sigma != 0.0:\n            raise ValueError('Soft NMS is not supported by combined_nms.')\n        if use_class_agnostic_nms:\n            raise ValueError('class-agnostic NMS is not supported by combined_nms.')\n        if clip_window is not None:\n            tf.compat.v1.logging.warning('clip_window is not supported by combined_nms unless it is [0. 0. 1. 1.] for each image.')\n        if additional_fields is not None:\n            tf.compat.v1.logging.warning('additional_fields is not supported by combined_nms.')\n        if parallel_iterations != 32:\n            tf.compat.v1.logging.warning('Number of batch items to be processed in parallel is not configurable by combined_nms.')\n        if max_classes_per_detection > 1:\n            tf.compat.v1.logging.warning('max_classes_per_detection is not configurable by combined_nms.')\n        with tf.name_scope(scope, 'CombinedNonMaxSuppression'):\n            (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_num_detections) = tf.image.combined_non_max_suppression(boxes=boxes, scores=scores, max_output_size_per_class=max_size_per_class, max_total_size=max_total_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_per_class=use_static_shapes)\n            batch_nmsed_masks = None\n            batch_nmsed_additional_fields = None\n            return (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_nmsed_masks, batch_nmsed_additional_fields, batch_num_detections)\n    q = shape_utils.get_dim_as_int(boxes.shape[2])\n    num_classes = shape_utils.get_dim_as_int(scores.shape[2])\n    if q != 1 and q != num_classes:\n        raise ValueError('third dimension of boxes must be either 1 or equal to the third dimension of scores.')\n    if change_coordinate_frame and clip_window is None:\n        raise ValueError('if change_coordinate_frame is True, then a clip_windowmust be specified.')\n    original_masks = masks\n    if additional_fields is None:\n        ordered_additional_fields = {}\n    else:\n        ordered_additional_fields = collections.OrderedDict(sorted(additional_fields.items(), key=lambda item: item[0]))\n    del additional_fields\n    with tf.name_scope(scope, 'BatchMultiClassNonMaxSuppression'):\n        boxes_shape = boxes.shape\n        batch_size = shape_utils.get_dim_as_int(boxes_shape[0])\n        num_anchors = shape_utils.get_dim_as_int(boxes_shape[1])\n        if batch_size is None:\n            batch_size = tf.shape(boxes)[0]\n        if num_anchors is None:\n            num_anchors = tf.shape(boxes)[1]\n        if num_valid_boxes is None:\n            num_valid_boxes = tf.ones([batch_size], dtype=tf.int32) * num_anchors\n        if masks is None:\n            masks_shape = tf.stack([batch_size, num_anchors, q, 1, 1])\n            masks = tf.zeros(masks_shape)\n        if clip_window is None:\n            clip_window = tf.stack([tf.reduce_min(boxes[:, :, :, 0]), tf.reduce_min(boxes[:, :, :, 1]), tf.reduce_max(boxes[:, :, :, 2]), tf.reduce_max(boxes[:, :, :, 3])])\n        if clip_window.shape.ndims == 1:\n            clip_window = tf.tile(tf.expand_dims(clip_window, 0), [batch_size, 1])\n\n        def _single_image_nms_fn(args):\n            \"\"\"Runs NMS on a single image and returns padded output.\n\n      Args:\n        args: A list of tensors consisting of the following:\n          per_image_boxes - A [num_anchors, q, 4] float32 tensor containing\n            detections. If `q` is 1 then same boxes are used for all classes\n            otherwise, if `q` is equal to number of classes, class-specific\n            boxes are used.\n          per_image_scores - A [num_anchors, num_classes] float32 tensor\n            containing the scores for each of the `num_anchors` detections.\n          per_image_masks - A [num_anchors, q, mask_height, mask_width] float32\n            tensor containing box masks. `q` can be either number of classes\n            or 1 depending on whether a separate mask is predicted per class.\n          per_image_clip_window - A 1D float32 tensor of the form\n            [ymin, xmin, ymax, xmax] representing the window to clip the boxes\n            to.\n          per_image_additional_fields - (optional) A variable number of float32\n            tensors each with size [num_anchors, ...].\n          per_image_num_valid_boxes - A tensor of type `int32`. A 1-D tensor of\n            shape [batch_size] representing the number of valid boxes to be\n            considered for each image in the batch.  This parameter allows for\n            ignoring zero paddings.\n\n      Returns:\n        'nmsed_boxes': A [max_detections, 4] float32 tensor containing the\n          non-max suppressed boxes.\n        'nmsed_scores': A [max_detections] float32 tensor containing the scores\n          for the boxes.\n        'nmsed_classes': A [max_detections] float32 tensor containing the class\n          for boxes.\n        'nmsed_masks': (optional) a [max_detections, mask_height, mask_width]\n          float32 tensor containing masks for each selected box. This is set to\n          None if input `masks` is None.\n        'nmsed_additional_fields':  (optional) A variable number of float32\n          tensors each with size [max_detections, ...] corresponding to the\n          input `per_image_additional_fields`.\n        'num_detections': A [batch_size] int32 tensor indicating the number of\n          valid detections per batch item. Only the top num_detections[i]\n          entries in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The\n          rest of the entries are zero paddings.\n      \"\"\"\n            per_image_boxes = args[0]\n            per_image_scores = args[1]\n            per_image_masks = args[2]\n            per_image_clip_window = args[3]\n            per_image_additional_fields = {key: value for (key, value) in zip(ordered_additional_fields, args[4:-1])}\n            per_image_num_valid_boxes = args[-1]\n            if use_static_shapes:\n                total_proposals = tf.shape(per_image_scores)\n                per_image_scores = tf.where(tf.less(tf.range(total_proposals[0]), per_image_num_valid_boxes), per_image_scores, tf.fill(total_proposals, np.finfo('float32').min))\n            else:\n                per_image_boxes = tf.reshape(tf.slice(per_image_boxes, 3 * [0], tf.stack([per_image_num_valid_boxes, -1, -1])), [-1, q, 4])\n                per_image_scores = tf.reshape(tf.slice(per_image_scores, [0, 0], tf.stack([per_image_num_valid_boxes, -1])), [-1, num_classes])\n                per_image_masks = tf.reshape(tf.slice(per_image_masks, 4 * [0], tf.stack([per_image_num_valid_boxes, -1, -1, -1])), [-1, q, shape_utils.get_dim_as_int(per_image_masks.shape[2]), shape_utils.get_dim_as_int(per_image_masks.shape[3])])\n                if per_image_additional_fields is not None:\n                    for (key, tensor) in per_image_additional_fields.items():\n                        additional_field_shape = tensor.get_shape()\n                        additional_field_dim = len(additional_field_shape)\n                        per_image_additional_fields[key] = tf.reshape(tf.slice(per_image_additional_fields[key], additional_field_dim * [0], tf.stack([per_image_num_valid_boxes] + (additional_field_dim - 1) * [-1])), [-1] + [shape_utils.get_dim_as_int(dim) for dim in additional_field_shape[1:]])\n            if use_class_agnostic_nms:\n                (nmsed_boxlist, num_valid_nms_boxes) = class_agnostic_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_classes_per_detection, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n            else:\n                (nmsed_boxlist, num_valid_nms_boxes) = multiclass_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_size_per_class, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n            if not use_static_shapes:\n                nmsed_boxlist = box_list_ops.pad_or_clip_box_list(nmsed_boxlist, max_total_size)\n            num_detections = num_valid_nms_boxes\n            nmsed_boxes = nmsed_boxlist.get()\n            nmsed_scores = nmsed_boxlist.get_field(fields.BoxListFields.scores)\n            nmsed_classes = nmsed_boxlist.get_field(fields.BoxListFields.classes)\n            nmsed_masks = nmsed_boxlist.get_field(fields.BoxListFields.masks)\n            nmsed_additional_fields = []\n            for key in sorted(per_image_additional_fields.keys()):\n                nmsed_additional_fields.append(nmsed_boxlist.get_field(key))\n            return [nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_masks] + nmsed_additional_fields + [num_detections]\n        num_additional_fields = 0\n        if ordered_additional_fields:\n            num_additional_fields = len(ordered_additional_fields)\n        num_nmsed_outputs = 4 + num_additional_fields\n        if use_dynamic_map_fn:\n            map_fn = tf.map_fn\n        else:\n            map_fn = shape_utils.static_or_dynamic_map_fn\n        batch_outputs = map_fn(_single_image_nms_fn, elems=[boxes, scores, masks, clip_window] + list(ordered_additional_fields.values()) + [num_valid_boxes], dtype=num_nmsed_outputs * [tf.float32] + [tf.int32], parallel_iterations=parallel_iterations)\n        batch_nmsed_boxes = batch_outputs[0]\n        batch_nmsed_scores = batch_outputs[1]\n        batch_nmsed_classes = batch_outputs[2]\n        batch_nmsed_masks = batch_outputs[3]\n        batch_nmsed_values = batch_outputs[4:-1]\n        batch_nmsed_additional_fields = {}\n        if num_additional_fields > 0:\n            batch_nmsed_keys = list(ordered_additional_fields.keys())\n            for i in range(len(batch_nmsed_keys)):\n                batch_nmsed_additional_fields[batch_nmsed_keys[i]] = batch_nmsed_values[i]\n        batch_num_detections = batch_outputs[-1]\n        if original_masks is None:\n            batch_nmsed_masks = None\n        if not ordered_additional_fields:\n            batch_nmsed_additional_fields = None\n        return (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_nmsed_masks, batch_nmsed_additional_fields, batch_num_detections)",
            "def batch_multiclass_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_size_per_class, max_total_size=0, clip_window=None, change_coordinate_frame=False, num_valid_boxes=None, masks=None, additional_fields=None, soft_nms_sigma=0.0, scope=None, use_static_shapes=False, use_partitioned_nms=False, parallel_iterations=32, use_class_agnostic_nms=False, max_classes_per_detection=1, use_dynamic_map_fn=False, use_combined_nms=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Multi-class version of non maximum suppression that operates on a batch.\\n\\n  This op is similar to `multiclass_non_max_suppression` but operates on a batch\\n  of boxes and scores. See documentation for `multiclass_non_max_suppression`\\n  for details.\\n\\n  Args:\\n    boxes: A [batch_size, num_anchors, q, 4] float32 tensor containing\\n      detections. If `q` is 1 then same boxes are used for all classes\\n      otherwise, if `q` is equal to number of classes, class-specific boxes are\\n      used.\\n    scores: A [batch_size, num_anchors, num_classes] float32 tensor containing\\n      the scores for each of the `num_anchors` detections. The scores have to be\\n      non-negative when use_static_shapes is set True.\\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    max_size_per_class: maximum number of retained boxes per class.\\n    max_total_size: maximum number of boxes retained over all classes. By\\n      default returns all boxes retained after capping boxes per class.\\n    clip_window: A float32 tensor of shape [batch_size, 4]  where each entry is\\n      of the form [y_min, x_min, y_max, x_max] representing the window to clip\\n      boxes to before performing non-max suppression. This argument can also be\\n      a tensor of shape [4] in which case, the same clip window is applied to\\n      all images in the batch. If clip_widow is None, all boxes are used to\\n      perform non-max suppression.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided)\\n    num_valid_boxes: (optional) a Tensor of type `int32`. A 1-D tensor of shape\\n      [batch_size] representing the number of valid boxes to be considered for\\n      each image in the batch.  This parameter allows for ignoring zero\\n      paddings.\\n    masks: (optional) a [batch_size, num_anchors, q, mask_height, mask_width]\\n      float32 tensor containing box masks. `q` can be either number of classes\\n      or 1 depending on whether a separate mask is predicted per class.\\n    additional_fields: (optional) If not None, a dictionary that maps keys to\\n      tensors whose dimensions are [batch_size, num_anchors, ...].\\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\\n      False.\\n    scope: tf scope name.\\n    use_static_shapes: If true, the output nmsed boxes are padded to be of\\n      length `max_size_per_class` and it doesn't clip boxes to max_total_size.\\n      Defaults to false.\\n    use_partitioned_nms: If true, use partitioned version of\\n      non_max_suppression.\\n    parallel_iterations: (optional) number of batch items to process in\\n      parallel.\\n    use_class_agnostic_nms: If true, this uses class-agnostic non max\\n      suppression\\n    max_classes_per_detection: Maximum number of retained classes per detection\\n      box in class-agnostic NMS.\\n    use_dynamic_map_fn: If true, images in the batch will be processed within a\\n      dynamic loop. Otherwise, a static loop will be used if possible.\\n    use_combined_nms: If true, it uses tf.image.combined_non_max_suppression (\\n      multi-class version of NMS that operates on a batch).\\n      It greedily selects a subset of detection bounding boxes, pruning away\\n      boxes that have high IOU (intersection over union) overlap (> thresh) with\\n      already selected boxes. It operates independently for each batch.\\n      Within each batch, it operates independently for each class for which\\n      scores are provided (via the scores field of the input box_list),\\n      pruning boxes with score less than a provided threshold prior to applying\\n      NMS. This operation is performed on *all* batches and *all* classes\\n      in the batch, therefore any background classes should be removed prior to\\n      calling this function.\\n      Masks and additional fields are not supported.\\n      See argument checks in the code below for unsupported arguments.\\n\\n  Returns:\\n    'nmsed_boxes': A [batch_size, max_detections, 4] float32 tensor\\n      containing the non-max suppressed boxes.\\n    'nmsed_scores': A [batch_size, max_detections] float32 tensor containing\\n      the scores for the boxes.\\n    'nmsed_classes': A [batch_size, max_detections] float32 tensor\\n      containing the class for boxes.\\n    'nmsed_masks': (optional) a\\n      [batch_size, max_detections, mask_height, mask_width] float32 tensor\\n      containing masks for each selected box. This is set to None if input\\n      `masks` is None.\\n    'nmsed_additional_fields': (optional) a dictionary of\\n      [batch_size, max_detections, ...] float32 tensors corresponding to the\\n      tensors specified in the input `additional_fields`. This is not returned\\n      if input `additional_fields` is None.\\n    'num_detections': A [batch_size] int32 tensor indicating the number of\\n      valid detections per batch item. Only the top num_detections[i] entries in\\n      nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The rest of the\\n      entries are zero paddings.\\n\\n  Raises:\\n    ValueError: if `q` in boxes.shape is not 1 or not equal to number of\\n      classes as inferred from scores.shape.\\n  \"\n    if use_combined_nms:\n        if change_coordinate_frame:\n            raise ValueError('change_coordinate_frame (normalizing coordinates relative to clip_window) is not supported by combined_nms.')\n        if num_valid_boxes is not None:\n            raise ValueError('num_valid_boxes is not supported by combined_nms.')\n        if masks is not None:\n            raise ValueError('masks is not supported by combined_nms.')\n        if soft_nms_sigma != 0.0:\n            raise ValueError('Soft NMS is not supported by combined_nms.')\n        if use_class_agnostic_nms:\n            raise ValueError('class-agnostic NMS is not supported by combined_nms.')\n        if clip_window is not None:\n            tf.compat.v1.logging.warning('clip_window is not supported by combined_nms unless it is [0. 0. 1. 1.] for each image.')\n        if additional_fields is not None:\n            tf.compat.v1.logging.warning('additional_fields is not supported by combined_nms.')\n        if parallel_iterations != 32:\n            tf.compat.v1.logging.warning('Number of batch items to be processed in parallel is not configurable by combined_nms.')\n        if max_classes_per_detection > 1:\n            tf.compat.v1.logging.warning('max_classes_per_detection is not configurable by combined_nms.')\n        with tf.name_scope(scope, 'CombinedNonMaxSuppression'):\n            (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_num_detections) = tf.image.combined_non_max_suppression(boxes=boxes, scores=scores, max_output_size_per_class=max_size_per_class, max_total_size=max_total_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_per_class=use_static_shapes)\n            batch_nmsed_masks = None\n            batch_nmsed_additional_fields = None\n            return (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_nmsed_masks, batch_nmsed_additional_fields, batch_num_detections)\n    q = shape_utils.get_dim_as_int(boxes.shape[2])\n    num_classes = shape_utils.get_dim_as_int(scores.shape[2])\n    if q != 1 and q != num_classes:\n        raise ValueError('third dimension of boxes must be either 1 or equal to the third dimension of scores.')\n    if change_coordinate_frame and clip_window is None:\n        raise ValueError('if change_coordinate_frame is True, then a clip_windowmust be specified.')\n    original_masks = masks\n    if additional_fields is None:\n        ordered_additional_fields = {}\n    else:\n        ordered_additional_fields = collections.OrderedDict(sorted(additional_fields.items(), key=lambda item: item[0]))\n    del additional_fields\n    with tf.name_scope(scope, 'BatchMultiClassNonMaxSuppression'):\n        boxes_shape = boxes.shape\n        batch_size = shape_utils.get_dim_as_int(boxes_shape[0])\n        num_anchors = shape_utils.get_dim_as_int(boxes_shape[1])\n        if batch_size is None:\n            batch_size = tf.shape(boxes)[0]\n        if num_anchors is None:\n            num_anchors = tf.shape(boxes)[1]\n        if num_valid_boxes is None:\n            num_valid_boxes = tf.ones([batch_size], dtype=tf.int32) * num_anchors\n        if masks is None:\n            masks_shape = tf.stack([batch_size, num_anchors, q, 1, 1])\n            masks = tf.zeros(masks_shape)\n        if clip_window is None:\n            clip_window = tf.stack([tf.reduce_min(boxes[:, :, :, 0]), tf.reduce_min(boxes[:, :, :, 1]), tf.reduce_max(boxes[:, :, :, 2]), tf.reduce_max(boxes[:, :, :, 3])])\n        if clip_window.shape.ndims == 1:\n            clip_window = tf.tile(tf.expand_dims(clip_window, 0), [batch_size, 1])\n\n        def _single_image_nms_fn(args):\n            \"\"\"Runs NMS on a single image and returns padded output.\n\n      Args:\n        args: A list of tensors consisting of the following:\n          per_image_boxes - A [num_anchors, q, 4] float32 tensor containing\n            detections. If `q` is 1 then same boxes are used for all classes\n            otherwise, if `q` is equal to number of classes, class-specific\n            boxes are used.\n          per_image_scores - A [num_anchors, num_classes] float32 tensor\n            containing the scores for each of the `num_anchors` detections.\n          per_image_masks - A [num_anchors, q, mask_height, mask_width] float32\n            tensor containing box masks. `q` can be either number of classes\n            or 1 depending on whether a separate mask is predicted per class.\n          per_image_clip_window - A 1D float32 tensor of the form\n            [ymin, xmin, ymax, xmax] representing the window to clip the boxes\n            to.\n          per_image_additional_fields - (optional) A variable number of float32\n            tensors each with size [num_anchors, ...].\n          per_image_num_valid_boxes - A tensor of type `int32`. A 1-D tensor of\n            shape [batch_size] representing the number of valid boxes to be\n            considered for each image in the batch.  This parameter allows for\n            ignoring zero paddings.\n\n      Returns:\n        'nmsed_boxes': A [max_detections, 4] float32 tensor containing the\n          non-max suppressed boxes.\n        'nmsed_scores': A [max_detections] float32 tensor containing the scores\n          for the boxes.\n        'nmsed_classes': A [max_detections] float32 tensor containing the class\n          for boxes.\n        'nmsed_masks': (optional) a [max_detections, mask_height, mask_width]\n          float32 tensor containing masks for each selected box. This is set to\n          None if input `masks` is None.\n        'nmsed_additional_fields':  (optional) A variable number of float32\n          tensors each with size [max_detections, ...] corresponding to the\n          input `per_image_additional_fields`.\n        'num_detections': A [batch_size] int32 tensor indicating the number of\n          valid detections per batch item. Only the top num_detections[i]\n          entries in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The\n          rest of the entries are zero paddings.\n      \"\"\"\n            per_image_boxes = args[0]\n            per_image_scores = args[1]\n            per_image_masks = args[2]\n            per_image_clip_window = args[3]\n            per_image_additional_fields = {key: value for (key, value) in zip(ordered_additional_fields, args[4:-1])}\n            per_image_num_valid_boxes = args[-1]\n            if use_static_shapes:\n                total_proposals = tf.shape(per_image_scores)\n                per_image_scores = tf.where(tf.less(tf.range(total_proposals[0]), per_image_num_valid_boxes), per_image_scores, tf.fill(total_proposals, np.finfo('float32').min))\n            else:\n                per_image_boxes = tf.reshape(tf.slice(per_image_boxes, 3 * [0], tf.stack([per_image_num_valid_boxes, -1, -1])), [-1, q, 4])\n                per_image_scores = tf.reshape(tf.slice(per_image_scores, [0, 0], tf.stack([per_image_num_valid_boxes, -1])), [-1, num_classes])\n                per_image_masks = tf.reshape(tf.slice(per_image_masks, 4 * [0], tf.stack([per_image_num_valid_boxes, -1, -1, -1])), [-1, q, shape_utils.get_dim_as_int(per_image_masks.shape[2]), shape_utils.get_dim_as_int(per_image_masks.shape[3])])\n                if per_image_additional_fields is not None:\n                    for (key, tensor) in per_image_additional_fields.items():\n                        additional_field_shape = tensor.get_shape()\n                        additional_field_dim = len(additional_field_shape)\n                        per_image_additional_fields[key] = tf.reshape(tf.slice(per_image_additional_fields[key], additional_field_dim * [0], tf.stack([per_image_num_valid_boxes] + (additional_field_dim - 1) * [-1])), [-1] + [shape_utils.get_dim_as_int(dim) for dim in additional_field_shape[1:]])\n            if use_class_agnostic_nms:\n                (nmsed_boxlist, num_valid_nms_boxes) = class_agnostic_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_classes_per_detection, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n            else:\n                (nmsed_boxlist, num_valid_nms_boxes) = multiclass_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_size_per_class, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n            if not use_static_shapes:\n                nmsed_boxlist = box_list_ops.pad_or_clip_box_list(nmsed_boxlist, max_total_size)\n            num_detections = num_valid_nms_boxes\n            nmsed_boxes = nmsed_boxlist.get()\n            nmsed_scores = nmsed_boxlist.get_field(fields.BoxListFields.scores)\n            nmsed_classes = nmsed_boxlist.get_field(fields.BoxListFields.classes)\n            nmsed_masks = nmsed_boxlist.get_field(fields.BoxListFields.masks)\n            nmsed_additional_fields = []\n            for key in sorted(per_image_additional_fields.keys()):\n                nmsed_additional_fields.append(nmsed_boxlist.get_field(key))\n            return [nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_masks] + nmsed_additional_fields + [num_detections]\n        num_additional_fields = 0\n        if ordered_additional_fields:\n            num_additional_fields = len(ordered_additional_fields)\n        num_nmsed_outputs = 4 + num_additional_fields\n        if use_dynamic_map_fn:\n            map_fn = tf.map_fn\n        else:\n            map_fn = shape_utils.static_or_dynamic_map_fn\n        batch_outputs = map_fn(_single_image_nms_fn, elems=[boxes, scores, masks, clip_window] + list(ordered_additional_fields.values()) + [num_valid_boxes], dtype=num_nmsed_outputs * [tf.float32] + [tf.int32], parallel_iterations=parallel_iterations)\n        batch_nmsed_boxes = batch_outputs[0]\n        batch_nmsed_scores = batch_outputs[1]\n        batch_nmsed_classes = batch_outputs[2]\n        batch_nmsed_masks = batch_outputs[3]\n        batch_nmsed_values = batch_outputs[4:-1]\n        batch_nmsed_additional_fields = {}\n        if num_additional_fields > 0:\n            batch_nmsed_keys = list(ordered_additional_fields.keys())\n            for i in range(len(batch_nmsed_keys)):\n                batch_nmsed_additional_fields[batch_nmsed_keys[i]] = batch_nmsed_values[i]\n        batch_num_detections = batch_outputs[-1]\n        if original_masks is None:\n            batch_nmsed_masks = None\n        if not ordered_additional_fields:\n            batch_nmsed_additional_fields = None\n        return (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_nmsed_masks, batch_nmsed_additional_fields, batch_num_detections)",
            "def batch_multiclass_non_max_suppression(boxes, scores, score_thresh, iou_thresh, max_size_per_class, max_total_size=0, clip_window=None, change_coordinate_frame=False, num_valid_boxes=None, masks=None, additional_fields=None, soft_nms_sigma=0.0, scope=None, use_static_shapes=False, use_partitioned_nms=False, parallel_iterations=32, use_class_agnostic_nms=False, max_classes_per_detection=1, use_dynamic_map_fn=False, use_combined_nms=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Multi-class version of non maximum suppression that operates on a batch.\\n\\n  This op is similar to `multiclass_non_max_suppression` but operates on a batch\\n  of boxes and scores. See documentation for `multiclass_non_max_suppression`\\n  for details.\\n\\n  Args:\\n    boxes: A [batch_size, num_anchors, q, 4] float32 tensor containing\\n      detections. If `q` is 1 then same boxes are used for all classes\\n      otherwise, if `q` is equal to number of classes, class-specific boxes are\\n      used.\\n    scores: A [batch_size, num_anchors, num_classes] float32 tensor containing\\n      the scores for each of the `num_anchors` detections. The scores have to be\\n      non-negative when use_static_shapes is set True.\\n    score_thresh: scalar threshold for score (low scoring boxes are removed).\\n    iou_thresh: scalar threshold for IOU (new boxes that have high IOU overlap\\n      with previously selected boxes are removed).\\n    max_size_per_class: maximum number of retained boxes per class.\\n    max_total_size: maximum number of boxes retained over all classes. By\\n      default returns all boxes retained after capping boxes per class.\\n    clip_window: A float32 tensor of shape [batch_size, 4]  where each entry is\\n      of the form [y_min, x_min, y_max, x_max] representing the window to clip\\n      boxes to before performing non-max suppression. This argument can also be\\n      a tensor of shape [4] in which case, the same clip window is applied to\\n      all images in the batch. If clip_widow is None, all boxes are used to\\n      perform non-max suppression.\\n    change_coordinate_frame: Whether to normalize coordinates after clipping\\n      relative to clip_window (this can only be set to True if a clip_window is\\n      provided)\\n    num_valid_boxes: (optional) a Tensor of type `int32`. A 1-D tensor of shape\\n      [batch_size] representing the number of valid boxes to be considered for\\n      each image in the batch.  This parameter allows for ignoring zero\\n      paddings.\\n    masks: (optional) a [batch_size, num_anchors, q, mask_height, mask_width]\\n      float32 tensor containing box masks. `q` can be either number of classes\\n      or 1 depending on whether a separate mask is predicted per class.\\n    additional_fields: (optional) If not None, a dictionary that maps keys to\\n      tensors whose dimensions are [batch_size, num_anchors, ...].\\n    soft_nms_sigma: A scalar float representing the Soft NMS sigma parameter;\\n      See Bodla et al, https://arxiv.org/abs/1704.04503).  When\\n      `soft_nms_sigma=0.0` (which is default), we fall back to standard (hard)\\n      NMS.  Soft NMS is currently only supported when pad_to_max_output_size is\\n      False.\\n    scope: tf scope name.\\n    use_static_shapes: If true, the output nmsed boxes are padded to be of\\n      length `max_size_per_class` and it doesn't clip boxes to max_total_size.\\n      Defaults to false.\\n    use_partitioned_nms: If true, use partitioned version of\\n      non_max_suppression.\\n    parallel_iterations: (optional) number of batch items to process in\\n      parallel.\\n    use_class_agnostic_nms: If true, this uses class-agnostic non max\\n      suppression\\n    max_classes_per_detection: Maximum number of retained classes per detection\\n      box in class-agnostic NMS.\\n    use_dynamic_map_fn: If true, images in the batch will be processed within a\\n      dynamic loop. Otherwise, a static loop will be used if possible.\\n    use_combined_nms: If true, it uses tf.image.combined_non_max_suppression (\\n      multi-class version of NMS that operates on a batch).\\n      It greedily selects a subset of detection bounding boxes, pruning away\\n      boxes that have high IOU (intersection over union) overlap (> thresh) with\\n      already selected boxes. It operates independently for each batch.\\n      Within each batch, it operates independently for each class for which\\n      scores are provided (via the scores field of the input box_list),\\n      pruning boxes with score less than a provided threshold prior to applying\\n      NMS. This operation is performed on *all* batches and *all* classes\\n      in the batch, therefore any background classes should be removed prior to\\n      calling this function.\\n      Masks and additional fields are not supported.\\n      See argument checks in the code below for unsupported arguments.\\n\\n  Returns:\\n    'nmsed_boxes': A [batch_size, max_detections, 4] float32 tensor\\n      containing the non-max suppressed boxes.\\n    'nmsed_scores': A [batch_size, max_detections] float32 tensor containing\\n      the scores for the boxes.\\n    'nmsed_classes': A [batch_size, max_detections] float32 tensor\\n      containing the class for boxes.\\n    'nmsed_masks': (optional) a\\n      [batch_size, max_detections, mask_height, mask_width] float32 tensor\\n      containing masks for each selected box. This is set to None if input\\n      `masks` is None.\\n    'nmsed_additional_fields': (optional) a dictionary of\\n      [batch_size, max_detections, ...] float32 tensors corresponding to the\\n      tensors specified in the input `additional_fields`. This is not returned\\n      if input `additional_fields` is None.\\n    'num_detections': A [batch_size] int32 tensor indicating the number of\\n      valid detections per batch item. Only the top num_detections[i] entries in\\n      nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The rest of the\\n      entries are zero paddings.\\n\\n  Raises:\\n    ValueError: if `q` in boxes.shape is not 1 or not equal to number of\\n      classes as inferred from scores.shape.\\n  \"\n    if use_combined_nms:\n        if change_coordinate_frame:\n            raise ValueError('change_coordinate_frame (normalizing coordinates relative to clip_window) is not supported by combined_nms.')\n        if num_valid_boxes is not None:\n            raise ValueError('num_valid_boxes is not supported by combined_nms.')\n        if masks is not None:\n            raise ValueError('masks is not supported by combined_nms.')\n        if soft_nms_sigma != 0.0:\n            raise ValueError('Soft NMS is not supported by combined_nms.')\n        if use_class_agnostic_nms:\n            raise ValueError('class-agnostic NMS is not supported by combined_nms.')\n        if clip_window is not None:\n            tf.compat.v1.logging.warning('clip_window is not supported by combined_nms unless it is [0. 0. 1. 1.] for each image.')\n        if additional_fields is not None:\n            tf.compat.v1.logging.warning('additional_fields is not supported by combined_nms.')\n        if parallel_iterations != 32:\n            tf.compat.v1.logging.warning('Number of batch items to be processed in parallel is not configurable by combined_nms.')\n        if max_classes_per_detection > 1:\n            tf.compat.v1.logging.warning('max_classes_per_detection is not configurable by combined_nms.')\n        with tf.name_scope(scope, 'CombinedNonMaxSuppression'):\n            (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_num_detections) = tf.image.combined_non_max_suppression(boxes=boxes, scores=scores, max_output_size_per_class=max_size_per_class, max_total_size=max_total_size, iou_threshold=iou_thresh, score_threshold=score_thresh, pad_per_class=use_static_shapes)\n            batch_nmsed_masks = None\n            batch_nmsed_additional_fields = None\n            return (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_nmsed_masks, batch_nmsed_additional_fields, batch_num_detections)\n    q = shape_utils.get_dim_as_int(boxes.shape[2])\n    num_classes = shape_utils.get_dim_as_int(scores.shape[2])\n    if q != 1 and q != num_classes:\n        raise ValueError('third dimension of boxes must be either 1 or equal to the third dimension of scores.')\n    if change_coordinate_frame and clip_window is None:\n        raise ValueError('if change_coordinate_frame is True, then a clip_windowmust be specified.')\n    original_masks = masks\n    if additional_fields is None:\n        ordered_additional_fields = {}\n    else:\n        ordered_additional_fields = collections.OrderedDict(sorted(additional_fields.items(), key=lambda item: item[0]))\n    del additional_fields\n    with tf.name_scope(scope, 'BatchMultiClassNonMaxSuppression'):\n        boxes_shape = boxes.shape\n        batch_size = shape_utils.get_dim_as_int(boxes_shape[0])\n        num_anchors = shape_utils.get_dim_as_int(boxes_shape[1])\n        if batch_size is None:\n            batch_size = tf.shape(boxes)[0]\n        if num_anchors is None:\n            num_anchors = tf.shape(boxes)[1]\n        if num_valid_boxes is None:\n            num_valid_boxes = tf.ones([batch_size], dtype=tf.int32) * num_anchors\n        if masks is None:\n            masks_shape = tf.stack([batch_size, num_anchors, q, 1, 1])\n            masks = tf.zeros(masks_shape)\n        if clip_window is None:\n            clip_window = tf.stack([tf.reduce_min(boxes[:, :, :, 0]), tf.reduce_min(boxes[:, :, :, 1]), tf.reduce_max(boxes[:, :, :, 2]), tf.reduce_max(boxes[:, :, :, 3])])\n        if clip_window.shape.ndims == 1:\n            clip_window = tf.tile(tf.expand_dims(clip_window, 0), [batch_size, 1])\n\n        def _single_image_nms_fn(args):\n            \"\"\"Runs NMS on a single image and returns padded output.\n\n      Args:\n        args: A list of tensors consisting of the following:\n          per_image_boxes - A [num_anchors, q, 4] float32 tensor containing\n            detections. If `q` is 1 then same boxes are used for all classes\n            otherwise, if `q` is equal to number of classes, class-specific\n            boxes are used.\n          per_image_scores - A [num_anchors, num_classes] float32 tensor\n            containing the scores for each of the `num_anchors` detections.\n          per_image_masks - A [num_anchors, q, mask_height, mask_width] float32\n            tensor containing box masks. `q` can be either number of classes\n            or 1 depending on whether a separate mask is predicted per class.\n          per_image_clip_window - A 1D float32 tensor of the form\n            [ymin, xmin, ymax, xmax] representing the window to clip the boxes\n            to.\n          per_image_additional_fields - (optional) A variable number of float32\n            tensors each with size [num_anchors, ...].\n          per_image_num_valid_boxes - A tensor of type `int32`. A 1-D tensor of\n            shape [batch_size] representing the number of valid boxes to be\n            considered for each image in the batch.  This parameter allows for\n            ignoring zero paddings.\n\n      Returns:\n        'nmsed_boxes': A [max_detections, 4] float32 tensor containing the\n          non-max suppressed boxes.\n        'nmsed_scores': A [max_detections] float32 tensor containing the scores\n          for the boxes.\n        'nmsed_classes': A [max_detections] float32 tensor containing the class\n          for boxes.\n        'nmsed_masks': (optional) a [max_detections, mask_height, mask_width]\n          float32 tensor containing masks for each selected box. This is set to\n          None if input `masks` is None.\n        'nmsed_additional_fields':  (optional) A variable number of float32\n          tensors each with size [max_detections, ...] corresponding to the\n          input `per_image_additional_fields`.\n        'num_detections': A [batch_size] int32 tensor indicating the number of\n          valid detections per batch item. Only the top num_detections[i]\n          entries in nms_boxes[i], nms_scores[i] and nms_class[i] are valid. The\n          rest of the entries are zero paddings.\n      \"\"\"\n            per_image_boxes = args[0]\n            per_image_scores = args[1]\n            per_image_masks = args[2]\n            per_image_clip_window = args[3]\n            per_image_additional_fields = {key: value for (key, value) in zip(ordered_additional_fields, args[4:-1])}\n            per_image_num_valid_boxes = args[-1]\n            if use_static_shapes:\n                total_proposals = tf.shape(per_image_scores)\n                per_image_scores = tf.where(tf.less(tf.range(total_proposals[0]), per_image_num_valid_boxes), per_image_scores, tf.fill(total_proposals, np.finfo('float32').min))\n            else:\n                per_image_boxes = tf.reshape(tf.slice(per_image_boxes, 3 * [0], tf.stack([per_image_num_valid_boxes, -1, -1])), [-1, q, 4])\n                per_image_scores = tf.reshape(tf.slice(per_image_scores, [0, 0], tf.stack([per_image_num_valid_boxes, -1])), [-1, num_classes])\n                per_image_masks = tf.reshape(tf.slice(per_image_masks, 4 * [0], tf.stack([per_image_num_valid_boxes, -1, -1, -1])), [-1, q, shape_utils.get_dim_as_int(per_image_masks.shape[2]), shape_utils.get_dim_as_int(per_image_masks.shape[3])])\n                if per_image_additional_fields is not None:\n                    for (key, tensor) in per_image_additional_fields.items():\n                        additional_field_shape = tensor.get_shape()\n                        additional_field_dim = len(additional_field_shape)\n                        per_image_additional_fields[key] = tf.reshape(tf.slice(per_image_additional_fields[key], additional_field_dim * [0], tf.stack([per_image_num_valid_boxes] + (additional_field_dim - 1) * [-1])), [-1] + [shape_utils.get_dim_as_int(dim) for dim in additional_field_shape[1:]])\n            if use_class_agnostic_nms:\n                (nmsed_boxlist, num_valid_nms_boxes) = class_agnostic_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_classes_per_detection, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n            else:\n                (nmsed_boxlist, num_valid_nms_boxes) = multiclass_non_max_suppression(per_image_boxes, per_image_scores, score_thresh, iou_thresh, max_size_per_class, max_total_size, clip_window=per_image_clip_window, change_coordinate_frame=change_coordinate_frame, masks=per_image_masks, pad_to_max_output_size=use_static_shapes, use_partitioned_nms=use_partitioned_nms, additional_fields=per_image_additional_fields, soft_nms_sigma=soft_nms_sigma)\n            if not use_static_shapes:\n                nmsed_boxlist = box_list_ops.pad_or_clip_box_list(nmsed_boxlist, max_total_size)\n            num_detections = num_valid_nms_boxes\n            nmsed_boxes = nmsed_boxlist.get()\n            nmsed_scores = nmsed_boxlist.get_field(fields.BoxListFields.scores)\n            nmsed_classes = nmsed_boxlist.get_field(fields.BoxListFields.classes)\n            nmsed_masks = nmsed_boxlist.get_field(fields.BoxListFields.masks)\n            nmsed_additional_fields = []\n            for key in sorted(per_image_additional_fields.keys()):\n                nmsed_additional_fields.append(nmsed_boxlist.get_field(key))\n            return [nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_masks] + nmsed_additional_fields + [num_detections]\n        num_additional_fields = 0\n        if ordered_additional_fields:\n            num_additional_fields = len(ordered_additional_fields)\n        num_nmsed_outputs = 4 + num_additional_fields\n        if use_dynamic_map_fn:\n            map_fn = tf.map_fn\n        else:\n            map_fn = shape_utils.static_or_dynamic_map_fn\n        batch_outputs = map_fn(_single_image_nms_fn, elems=[boxes, scores, masks, clip_window] + list(ordered_additional_fields.values()) + [num_valid_boxes], dtype=num_nmsed_outputs * [tf.float32] + [tf.int32], parallel_iterations=parallel_iterations)\n        batch_nmsed_boxes = batch_outputs[0]\n        batch_nmsed_scores = batch_outputs[1]\n        batch_nmsed_classes = batch_outputs[2]\n        batch_nmsed_masks = batch_outputs[3]\n        batch_nmsed_values = batch_outputs[4:-1]\n        batch_nmsed_additional_fields = {}\n        if num_additional_fields > 0:\n            batch_nmsed_keys = list(ordered_additional_fields.keys())\n            for i in range(len(batch_nmsed_keys)):\n                batch_nmsed_additional_fields[batch_nmsed_keys[i]] = batch_nmsed_values[i]\n        batch_num_detections = batch_outputs[-1]\n        if original_masks is None:\n            batch_nmsed_masks = None\n        if not ordered_additional_fields:\n            batch_nmsed_additional_fields = None\n        return (batch_nmsed_boxes, batch_nmsed_scores, batch_nmsed_classes, batch_nmsed_masks, batch_nmsed_additional_fields, batch_num_detections)"
        ]
    }
]