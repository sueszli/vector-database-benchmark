[
    {
        "func_name": "test_scannet_pipeline",
        "original": "def test_scannet_pipeline():\n    class_names = ('cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refrigerator', 'showercurtrain', 'toilet', 'sink', 'bathtub', 'garbagebin')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=True, load_dim=6, use_dim=[0, 1, 2]), dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_mask_3d=True, with_seg_3d=True), dict(type='GlobalAlignment', rotation_axis=2), dict(type='PointSegClassMapping', valid_cat_ids=(3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39)), dict(type='PointSample', num_points=5), dict(type='RandomFlip3D', sync_2d=False, flip_ratio_bev_horizontal=1.0, flip_ratio_bev_vertical=1.0), dict(type='GlobalRotScaleTrans', rot_range=[-0.087266, 0.087266], scale_ratio_range=[1.0, 1.0], shift_height=True), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d', 'pts_semantic_mask', 'pts_instance_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/scannet/scannet_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/scannet'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    if info['annos']['gt_num'] != 0:\n        scannet_gt_bboxes_3d = info['annos']['gt_boxes_upright_depth'].astype(np.float32)\n        scannet_gt_labels_3d = info['annos']['class'].astype(np.int64)\n    else:\n        scannet_gt_bboxes_3d = np.zeros((1, 6), dtype=np.float32)\n        scannet_gt_labels_3d = np.zeros((1,), dtype=np.int64)\n    results['ann_info'] = dict()\n    results['ann_info']['pts_instance_mask_path'] = osp.join(data_path, info['pts_instance_mask_path'])\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['ann_info']['gt_bboxes_3d'] = DepthInstance3DBoxes(scannet_gt_bboxes_3d, box_dim=6, with_yaw=False)\n    results['ann_info']['gt_labels_3d'] = scannet_gt_labels_3d\n    results['ann_info']['axis_align_matrix'] = info['annos']['axis_align_matrix']\n    results['img_fields'] = []\n    results['bbox3d_fields'] = []\n    results['pts_mask_fields'] = []\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    gt_bboxes_3d = results['gt_bboxes_3d']._data\n    gt_labels_3d = results['gt_labels_3d']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    pts_instance_mask = results['pts_instance_mask']._data\n    expected_points = torch.tensor([[1.8339, 2.1093, 2.29, 2.3895], [3.6079, 0.14592, 2.0687, 2.1682], [4.1886, 5.0614, -0.10841, -0.0088736], [6.879, 1.5086, -0.093154, 0.0063816], [4.8253, 0.26668, 1.4917, 1.5912]])\n    expected_gt_bboxes_3d = torch.tensor([[-1.1835, -3.6317, 1.8565, 1.7577, 0.3761, 0.5724, 0.0], [-3.1832, 3.2269, 1.5268, 0.6727, 0.2251, 0.6715, 0.0], [-0.9598, -2.2864, 0.6165, 0.7506, 2.5709, 1.2145, 0.0], [-2.6988, -2.7354, 0.9722, 0.768, 1.8877, 0.287, 0.0], [3.2989, 0.2885, 1.0712, 0.76, 3.8814, 2.1603, 0.0]])\n    expected_gt_labels_3d = np.array([6, 6, 4, 9, 11, 11, 10, 0, 15, 17, 17, 17, 3, 12, 4, 4, 14, 1, 0, 0, 0, 0, 0, 0, 5, 5, 5])\n    expected_pts_semantic_mask = np.array([0, 18, 18, 18, 18])\n    expected_pts_instance_mask = np.array([44, 22, 10, 10, 57])\n    assert torch.allclose(points, expected_points, 0.01)\n    assert torch.allclose(gt_bboxes_3d.tensor[:5, :], expected_gt_bboxes_3d, 0.01)\n    assert np.all(gt_labels_3d.numpy() == expected_gt_labels_3d)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)\n    assert np.all(pts_instance_mask.numpy() == expected_pts_instance_mask)",
        "mutated": [
            "def test_scannet_pipeline():\n    if False:\n        i = 10\n    class_names = ('cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refrigerator', 'showercurtrain', 'toilet', 'sink', 'bathtub', 'garbagebin')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=True, load_dim=6, use_dim=[0, 1, 2]), dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_mask_3d=True, with_seg_3d=True), dict(type='GlobalAlignment', rotation_axis=2), dict(type='PointSegClassMapping', valid_cat_ids=(3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39)), dict(type='PointSample', num_points=5), dict(type='RandomFlip3D', sync_2d=False, flip_ratio_bev_horizontal=1.0, flip_ratio_bev_vertical=1.0), dict(type='GlobalRotScaleTrans', rot_range=[-0.087266, 0.087266], scale_ratio_range=[1.0, 1.0], shift_height=True), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d', 'pts_semantic_mask', 'pts_instance_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/scannet/scannet_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/scannet'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    if info['annos']['gt_num'] != 0:\n        scannet_gt_bboxes_3d = info['annos']['gt_boxes_upright_depth'].astype(np.float32)\n        scannet_gt_labels_3d = info['annos']['class'].astype(np.int64)\n    else:\n        scannet_gt_bboxes_3d = np.zeros((1, 6), dtype=np.float32)\n        scannet_gt_labels_3d = np.zeros((1,), dtype=np.int64)\n    results['ann_info'] = dict()\n    results['ann_info']['pts_instance_mask_path'] = osp.join(data_path, info['pts_instance_mask_path'])\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['ann_info']['gt_bboxes_3d'] = DepthInstance3DBoxes(scannet_gt_bboxes_3d, box_dim=6, with_yaw=False)\n    results['ann_info']['gt_labels_3d'] = scannet_gt_labels_3d\n    results['ann_info']['axis_align_matrix'] = info['annos']['axis_align_matrix']\n    results['img_fields'] = []\n    results['bbox3d_fields'] = []\n    results['pts_mask_fields'] = []\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    gt_bboxes_3d = results['gt_bboxes_3d']._data\n    gt_labels_3d = results['gt_labels_3d']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    pts_instance_mask = results['pts_instance_mask']._data\n    expected_points = torch.tensor([[1.8339, 2.1093, 2.29, 2.3895], [3.6079, 0.14592, 2.0687, 2.1682], [4.1886, 5.0614, -0.10841, -0.0088736], [6.879, 1.5086, -0.093154, 0.0063816], [4.8253, 0.26668, 1.4917, 1.5912]])\n    expected_gt_bboxes_3d = torch.tensor([[-1.1835, -3.6317, 1.8565, 1.7577, 0.3761, 0.5724, 0.0], [-3.1832, 3.2269, 1.5268, 0.6727, 0.2251, 0.6715, 0.0], [-0.9598, -2.2864, 0.6165, 0.7506, 2.5709, 1.2145, 0.0], [-2.6988, -2.7354, 0.9722, 0.768, 1.8877, 0.287, 0.0], [3.2989, 0.2885, 1.0712, 0.76, 3.8814, 2.1603, 0.0]])\n    expected_gt_labels_3d = np.array([6, 6, 4, 9, 11, 11, 10, 0, 15, 17, 17, 17, 3, 12, 4, 4, 14, 1, 0, 0, 0, 0, 0, 0, 5, 5, 5])\n    expected_pts_semantic_mask = np.array([0, 18, 18, 18, 18])\n    expected_pts_instance_mask = np.array([44, 22, 10, 10, 57])\n    assert torch.allclose(points, expected_points, 0.01)\n    assert torch.allclose(gt_bboxes_3d.tensor[:5, :], expected_gt_bboxes_3d, 0.01)\n    assert np.all(gt_labels_3d.numpy() == expected_gt_labels_3d)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)\n    assert np.all(pts_instance_mask.numpy() == expected_pts_instance_mask)",
            "def test_scannet_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    class_names = ('cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refrigerator', 'showercurtrain', 'toilet', 'sink', 'bathtub', 'garbagebin')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=True, load_dim=6, use_dim=[0, 1, 2]), dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_mask_3d=True, with_seg_3d=True), dict(type='GlobalAlignment', rotation_axis=2), dict(type='PointSegClassMapping', valid_cat_ids=(3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39)), dict(type='PointSample', num_points=5), dict(type='RandomFlip3D', sync_2d=False, flip_ratio_bev_horizontal=1.0, flip_ratio_bev_vertical=1.0), dict(type='GlobalRotScaleTrans', rot_range=[-0.087266, 0.087266], scale_ratio_range=[1.0, 1.0], shift_height=True), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d', 'pts_semantic_mask', 'pts_instance_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/scannet/scannet_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/scannet'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    if info['annos']['gt_num'] != 0:\n        scannet_gt_bboxes_3d = info['annos']['gt_boxes_upright_depth'].astype(np.float32)\n        scannet_gt_labels_3d = info['annos']['class'].astype(np.int64)\n    else:\n        scannet_gt_bboxes_3d = np.zeros((1, 6), dtype=np.float32)\n        scannet_gt_labels_3d = np.zeros((1,), dtype=np.int64)\n    results['ann_info'] = dict()\n    results['ann_info']['pts_instance_mask_path'] = osp.join(data_path, info['pts_instance_mask_path'])\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['ann_info']['gt_bboxes_3d'] = DepthInstance3DBoxes(scannet_gt_bboxes_3d, box_dim=6, with_yaw=False)\n    results['ann_info']['gt_labels_3d'] = scannet_gt_labels_3d\n    results['ann_info']['axis_align_matrix'] = info['annos']['axis_align_matrix']\n    results['img_fields'] = []\n    results['bbox3d_fields'] = []\n    results['pts_mask_fields'] = []\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    gt_bboxes_3d = results['gt_bboxes_3d']._data\n    gt_labels_3d = results['gt_labels_3d']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    pts_instance_mask = results['pts_instance_mask']._data\n    expected_points = torch.tensor([[1.8339, 2.1093, 2.29, 2.3895], [3.6079, 0.14592, 2.0687, 2.1682], [4.1886, 5.0614, -0.10841, -0.0088736], [6.879, 1.5086, -0.093154, 0.0063816], [4.8253, 0.26668, 1.4917, 1.5912]])\n    expected_gt_bboxes_3d = torch.tensor([[-1.1835, -3.6317, 1.8565, 1.7577, 0.3761, 0.5724, 0.0], [-3.1832, 3.2269, 1.5268, 0.6727, 0.2251, 0.6715, 0.0], [-0.9598, -2.2864, 0.6165, 0.7506, 2.5709, 1.2145, 0.0], [-2.6988, -2.7354, 0.9722, 0.768, 1.8877, 0.287, 0.0], [3.2989, 0.2885, 1.0712, 0.76, 3.8814, 2.1603, 0.0]])\n    expected_gt_labels_3d = np.array([6, 6, 4, 9, 11, 11, 10, 0, 15, 17, 17, 17, 3, 12, 4, 4, 14, 1, 0, 0, 0, 0, 0, 0, 5, 5, 5])\n    expected_pts_semantic_mask = np.array([0, 18, 18, 18, 18])\n    expected_pts_instance_mask = np.array([44, 22, 10, 10, 57])\n    assert torch.allclose(points, expected_points, 0.01)\n    assert torch.allclose(gt_bboxes_3d.tensor[:5, :], expected_gt_bboxes_3d, 0.01)\n    assert np.all(gt_labels_3d.numpy() == expected_gt_labels_3d)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)\n    assert np.all(pts_instance_mask.numpy() == expected_pts_instance_mask)",
            "def test_scannet_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    class_names = ('cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refrigerator', 'showercurtrain', 'toilet', 'sink', 'bathtub', 'garbagebin')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=True, load_dim=6, use_dim=[0, 1, 2]), dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_mask_3d=True, with_seg_3d=True), dict(type='GlobalAlignment', rotation_axis=2), dict(type='PointSegClassMapping', valid_cat_ids=(3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39)), dict(type='PointSample', num_points=5), dict(type='RandomFlip3D', sync_2d=False, flip_ratio_bev_horizontal=1.0, flip_ratio_bev_vertical=1.0), dict(type='GlobalRotScaleTrans', rot_range=[-0.087266, 0.087266], scale_ratio_range=[1.0, 1.0], shift_height=True), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d', 'pts_semantic_mask', 'pts_instance_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/scannet/scannet_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/scannet'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    if info['annos']['gt_num'] != 0:\n        scannet_gt_bboxes_3d = info['annos']['gt_boxes_upright_depth'].astype(np.float32)\n        scannet_gt_labels_3d = info['annos']['class'].astype(np.int64)\n    else:\n        scannet_gt_bboxes_3d = np.zeros((1, 6), dtype=np.float32)\n        scannet_gt_labels_3d = np.zeros((1,), dtype=np.int64)\n    results['ann_info'] = dict()\n    results['ann_info']['pts_instance_mask_path'] = osp.join(data_path, info['pts_instance_mask_path'])\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['ann_info']['gt_bboxes_3d'] = DepthInstance3DBoxes(scannet_gt_bboxes_3d, box_dim=6, with_yaw=False)\n    results['ann_info']['gt_labels_3d'] = scannet_gt_labels_3d\n    results['ann_info']['axis_align_matrix'] = info['annos']['axis_align_matrix']\n    results['img_fields'] = []\n    results['bbox3d_fields'] = []\n    results['pts_mask_fields'] = []\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    gt_bboxes_3d = results['gt_bboxes_3d']._data\n    gt_labels_3d = results['gt_labels_3d']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    pts_instance_mask = results['pts_instance_mask']._data\n    expected_points = torch.tensor([[1.8339, 2.1093, 2.29, 2.3895], [3.6079, 0.14592, 2.0687, 2.1682], [4.1886, 5.0614, -0.10841, -0.0088736], [6.879, 1.5086, -0.093154, 0.0063816], [4.8253, 0.26668, 1.4917, 1.5912]])\n    expected_gt_bboxes_3d = torch.tensor([[-1.1835, -3.6317, 1.8565, 1.7577, 0.3761, 0.5724, 0.0], [-3.1832, 3.2269, 1.5268, 0.6727, 0.2251, 0.6715, 0.0], [-0.9598, -2.2864, 0.6165, 0.7506, 2.5709, 1.2145, 0.0], [-2.6988, -2.7354, 0.9722, 0.768, 1.8877, 0.287, 0.0], [3.2989, 0.2885, 1.0712, 0.76, 3.8814, 2.1603, 0.0]])\n    expected_gt_labels_3d = np.array([6, 6, 4, 9, 11, 11, 10, 0, 15, 17, 17, 17, 3, 12, 4, 4, 14, 1, 0, 0, 0, 0, 0, 0, 5, 5, 5])\n    expected_pts_semantic_mask = np.array([0, 18, 18, 18, 18])\n    expected_pts_instance_mask = np.array([44, 22, 10, 10, 57])\n    assert torch.allclose(points, expected_points, 0.01)\n    assert torch.allclose(gt_bboxes_3d.tensor[:5, :], expected_gt_bboxes_3d, 0.01)\n    assert np.all(gt_labels_3d.numpy() == expected_gt_labels_3d)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)\n    assert np.all(pts_instance_mask.numpy() == expected_pts_instance_mask)",
            "def test_scannet_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    class_names = ('cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refrigerator', 'showercurtrain', 'toilet', 'sink', 'bathtub', 'garbagebin')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=True, load_dim=6, use_dim=[0, 1, 2]), dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_mask_3d=True, with_seg_3d=True), dict(type='GlobalAlignment', rotation_axis=2), dict(type='PointSegClassMapping', valid_cat_ids=(3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39)), dict(type='PointSample', num_points=5), dict(type='RandomFlip3D', sync_2d=False, flip_ratio_bev_horizontal=1.0, flip_ratio_bev_vertical=1.0), dict(type='GlobalRotScaleTrans', rot_range=[-0.087266, 0.087266], scale_ratio_range=[1.0, 1.0], shift_height=True), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d', 'pts_semantic_mask', 'pts_instance_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/scannet/scannet_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/scannet'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    if info['annos']['gt_num'] != 0:\n        scannet_gt_bboxes_3d = info['annos']['gt_boxes_upright_depth'].astype(np.float32)\n        scannet_gt_labels_3d = info['annos']['class'].astype(np.int64)\n    else:\n        scannet_gt_bboxes_3d = np.zeros((1, 6), dtype=np.float32)\n        scannet_gt_labels_3d = np.zeros((1,), dtype=np.int64)\n    results['ann_info'] = dict()\n    results['ann_info']['pts_instance_mask_path'] = osp.join(data_path, info['pts_instance_mask_path'])\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['ann_info']['gt_bboxes_3d'] = DepthInstance3DBoxes(scannet_gt_bboxes_3d, box_dim=6, with_yaw=False)\n    results['ann_info']['gt_labels_3d'] = scannet_gt_labels_3d\n    results['ann_info']['axis_align_matrix'] = info['annos']['axis_align_matrix']\n    results['img_fields'] = []\n    results['bbox3d_fields'] = []\n    results['pts_mask_fields'] = []\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    gt_bboxes_3d = results['gt_bboxes_3d']._data\n    gt_labels_3d = results['gt_labels_3d']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    pts_instance_mask = results['pts_instance_mask']._data\n    expected_points = torch.tensor([[1.8339, 2.1093, 2.29, 2.3895], [3.6079, 0.14592, 2.0687, 2.1682], [4.1886, 5.0614, -0.10841, -0.0088736], [6.879, 1.5086, -0.093154, 0.0063816], [4.8253, 0.26668, 1.4917, 1.5912]])\n    expected_gt_bboxes_3d = torch.tensor([[-1.1835, -3.6317, 1.8565, 1.7577, 0.3761, 0.5724, 0.0], [-3.1832, 3.2269, 1.5268, 0.6727, 0.2251, 0.6715, 0.0], [-0.9598, -2.2864, 0.6165, 0.7506, 2.5709, 1.2145, 0.0], [-2.6988, -2.7354, 0.9722, 0.768, 1.8877, 0.287, 0.0], [3.2989, 0.2885, 1.0712, 0.76, 3.8814, 2.1603, 0.0]])\n    expected_gt_labels_3d = np.array([6, 6, 4, 9, 11, 11, 10, 0, 15, 17, 17, 17, 3, 12, 4, 4, 14, 1, 0, 0, 0, 0, 0, 0, 5, 5, 5])\n    expected_pts_semantic_mask = np.array([0, 18, 18, 18, 18])\n    expected_pts_instance_mask = np.array([44, 22, 10, 10, 57])\n    assert torch.allclose(points, expected_points, 0.01)\n    assert torch.allclose(gt_bboxes_3d.tensor[:5, :], expected_gt_bboxes_3d, 0.01)\n    assert np.all(gt_labels_3d.numpy() == expected_gt_labels_3d)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)\n    assert np.all(pts_instance_mask.numpy() == expected_pts_instance_mask)",
            "def test_scannet_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    class_names = ('cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refrigerator', 'showercurtrain', 'toilet', 'sink', 'bathtub', 'garbagebin')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=True, load_dim=6, use_dim=[0, 1, 2]), dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True, with_mask_3d=True, with_seg_3d=True), dict(type='GlobalAlignment', rotation_axis=2), dict(type='PointSegClassMapping', valid_cat_ids=(3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39)), dict(type='PointSample', num_points=5), dict(type='RandomFlip3D', sync_2d=False, flip_ratio_bev_horizontal=1.0, flip_ratio_bev_vertical=1.0), dict(type='GlobalRotScaleTrans', rot_range=[-0.087266, 0.087266], scale_ratio_range=[1.0, 1.0], shift_height=True), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d', 'pts_semantic_mask', 'pts_instance_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/scannet/scannet_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/scannet'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    if info['annos']['gt_num'] != 0:\n        scannet_gt_bboxes_3d = info['annos']['gt_boxes_upright_depth'].astype(np.float32)\n        scannet_gt_labels_3d = info['annos']['class'].astype(np.int64)\n    else:\n        scannet_gt_bboxes_3d = np.zeros((1, 6), dtype=np.float32)\n        scannet_gt_labels_3d = np.zeros((1,), dtype=np.int64)\n    results['ann_info'] = dict()\n    results['ann_info']['pts_instance_mask_path'] = osp.join(data_path, info['pts_instance_mask_path'])\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['ann_info']['gt_bboxes_3d'] = DepthInstance3DBoxes(scannet_gt_bboxes_3d, box_dim=6, with_yaw=False)\n    results['ann_info']['gt_labels_3d'] = scannet_gt_labels_3d\n    results['ann_info']['axis_align_matrix'] = info['annos']['axis_align_matrix']\n    results['img_fields'] = []\n    results['bbox3d_fields'] = []\n    results['pts_mask_fields'] = []\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    gt_bboxes_3d = results['gt_bboxes_3d']._data\n    gt_labels_3d = results['gt_labels_3d']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    pts_instance_mask = results['pts_instance_mask']._data\n    expected_points = torch.tensor([[1.8339, 2.1093, 2.29, 2.3895], [3.6079, 0.14592, 2.0687, 2.1682], [4.1886, 5.0614, -0.10841, -0.0088736], [6.879, 1.5086, -0.093154, 0.0063816], [4.8253, 0.26668, 1.4917, 1.5912]])\n    expected_gt_bboxes_3d = torch.tensor([[-1.1835, -3.6317, 1.8565, 1.7577, 0.3761, 0.5724, 0.0], [-3.1832, 3.2269, 1.5268, 0.6727, 0.2251, 0.6715, 0.0], [-0.9598, -2.2864, 0.6165, 0.7506, 2.5709, 1.2145, 0.0], [-2.6988, -2.7354, 0.9722, 0.768, 1.8877, 0.287, 0.0], [3.2989, 0.2885, 1.0712, 0.76, 3.8814, 2.1603, 0.0]])\n    expected_gt_labels_3d = np.array([6, 6, 4, 9, 11, 11, 10, 0, 15, 17, 17, 17, 3, 12, 4, 4, 14, 1, 0, 0, 0, 0, 0, 0, 5, 5, 5])\n    expected_pts_semantic_mask = np.array([0, 18, 18, 18, 18])\n    expected_pts_instance_mask = np.array([44, 22, 10, 10, 57])\n    assert torch.allclose(points, expected_points, 0.01)\n    assert torch.allclose(gt_bboxes_3d.tensor[:5, :], expected_gt_bboxes_3d, 0.01)\n    assert np.all(gt_labels_3d.numpy() == expected_gt_labels_3d)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)\n    assert np.all(pts_instance_mask.numpy() == expected_pts_instance_mask)"
        ]
    },
    {
        "func_name": "test_scannet_seg_pipeline",
        "original": "def test_scannet_seg_pipeline():\n    class_names = ('wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refrigerator', 'showercurtrain', 'toilet', 'sink', 'bathtub', 'otherfurniture')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=False, use_color=True, load_dim=6, use_dim=[0, 1, 2, 3, 4, 5]), dict(type='LoadAnnotations3D', with_bbox_3d=False, with_label_3d=False, with_mask_3d=False, with_seg_3d=True), dict(type='PointSegClassMapping', valid_cat_ids=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39), max_cat_id=40), dict(type='IndoorPatchPointSample', num_points=5, block_size=1.5, ignore_index=len(class_names), use_normalized_coord=True, enlarge_size=0.2, min_unique_num=None), dict(type='NormalizePointsColor', color_mean=None), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'pts_semantic_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/scannet/scannet_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/scannet'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    results['ann_info'] = dict()\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    scannet_points = np.fromfile(osp.join(data_path, info['pts_path']), dtype=np.float32).reshape((-1, 6))\n    scannet_choices = np.array([87, 34, 58, 9, 18])\n    scannet_center = np.array([-2.1772466, -3.4789145, 1.242711])\n    scannet_center[2] = 0.0\n    scannet_coord_max = np.amax(scannet_points[:, :3], axis=0)\n    expected_points = np.concatenate([scannet_points[scannet_choices, :3] - scannet_center, scannet_points[scannet_choices, 3:] / 255.0, scannet_points[scannet_choices, :3] / scannet_coord_max], axis=1)\n    expected_pts_semantic_mask = np.array([13, 13, 12, 2, 0])\n    assert np.allclose(points.numpy(), expected_points, atol=1e-06)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)",
        "mutated": [
            "def test_scannet_seg_pipeline():\n    if False:\n        i = 10\n    class_names = ('wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refrigerator', 'showercurtrain', 'toilet', 'sink', 'bathtub', 'otherfurniture')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=False, use_color=True, load_dim=6, use_dim=[0, 1, 2, 3, 4, 5]), dict(type='LoadAnnotations3D', with_bbox_3d=False, with_label_3d=False, with_mask_3d=False, with_seg_3d=True), dict(type='PointSegClassMapping', valid_cat_ids=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39), max_cat_id=40), dict(type='IndoorPatchPointSample', num_points=5, block_size=1.5, ignore_index=len(class_names), use_normalized_coord=True, enlarge_size=0.2, min_unique_num=None), dict(type='NormalizePointsColor', color_mean=None), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'pts_semantic_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/scannet/scannet_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/scannet'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    results['ann_info'] = dict()\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    scannet_points = np.fromfile(osp.join(data_path, info['pts_path']), dtype=np.float32).reshape((-1, 6))\n    scannet_choices = np.array([87, 34, 58, 9, 18])\n    scannet_center = np.array([-2.1772466, -3.4789145, 1.242711])\n    scannet_center[2] = 0.0\n    scannet_coord_max = np.amax(scannet_points[:, :3], axis=0)\n    expected_points = np.concatenate([scannet_points[scannet_choices, :3] - scannet_center, scannet_points[scannet_choices, 3:] / 255.0, scannet_points[scannet_choices, :3] / scannet_coord_max], axis=1)\n    expected_pts_semantic_mask = np.array([13, 13, 12, 2, 0])\n    assert np.allclose(points.numpy(), expected_points, atol=1e-06)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)",
            "def test_scannet_seg_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    class_names = ('wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refrigerator', 'showercurtrain', 'toilet', 'sink', 'bathtub', 'otherfurniture')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=False, use_color=True, load_dim=6, use_dim=[0, 1, 2, 3, 4, 5]), dict(type='LoadAnnotations3D', with_bbox_3d=False, with_label_3d=False, with_mask_3d=False, with_seg_3d=True), dict(type='PointSegClassMapping', valid_cat_ids=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39), max_cat_id=40), dict(type='IndoorPatchPointSample', num_points=5, block_size=1.5, ignore_index=len(class_names), use_normalized_coord=True, enlarge_size=0.2, min_unique_num=None), dict(type='NormalizePointsColor', color_mean=None), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'pts_semantic_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/scannet/scannet_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/scannet'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    results['ann_info'] = dict()\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    scannet_points = np.fromfile(osp.join(data_path, info['pts_path']), dtype=np.float32).reshape((-1, 6))\n    scannet_choices = np.array([87, 34, 58, 9, 18])\n    scannet_center = np.array([-2.1772466, -3.4789145, 1.242711])\n    scannet_center[2] = 0.0\n    scannet_coord_max = np.amax(scannet_points[:, :3], axis=0)\n    expected_points = np.concatenate([scannet_points[scannet_choices, :3] - scannet_center, scannet_points[scannet_choices, 3:] / 255.0, scannet_points[scannet_choices, :3] / scannet_coord_max], axis=1)\n    expected_pts_semantic_mask = np.array([13, 13, 12, 2, 0])\n    assert np.allclose(points.numpy(), expected_points, atol=1e-06)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)",
            "def test_scannet_seg_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    class_names = ('wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refrigerator', 'showercurtrain', 'toilet', 'sink', 'bathtub', 'otherfurniture')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=False, use_color=True, load_dim=6, use_dim=[0, 1, 2, 3, 4, 5]), dict(type='LoadAnnotations3D', with_bbox_3d=False, with_label_3d=False, with_mask_3d=False, with_seg_3d=True), dict(type='PointSegClassMapping', valid_cat_ids=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39), max_cat_id=40), dict(type='IndoorPatchPointSample', num_points=5, block_size=1.5, ignore_index=len(class_names), use_normalized_coord=True, enlarge_size=0.2, min_unique_num=None), dict(type='NormalizePointsColor', color_mean=None), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'pts_semantic_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/scannet/scannet_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/scannet'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    results['ann_info'] = dict()\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    scannet_points = np.fromfile(osp.join(data_path, info['pts_path']), dtype=np.float32).reshape((-1, 6))\n    scannet_choices = np.array([87, 34, 58, 9, 18])\n    scannet_center = np.array([-2.1772466, -3.4789145, 1.242711])\n    scannet_center[2] = 0.0\n    scannet_coord_max = np.amax(scannet_points[:, :3], axis=0)\n    expected_points = np.concatenate([scannet_points[scannet_choices, :3] - scannet_center, scannet_points[scannet_choices, 3:] / 255.0, scannet_points[scannet_choices, :3] / scannet_coord_max], axis=1)\n    expected_pts_semantic_mask = np.array([13, 13, 12, 2, 0])\n    assert np.allclose(points.numpy(), expected_points, atol=1e-06)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)",
            "def test_scannet_seg_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    class_names = ('wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refrigerator', 'showercurtrain', 'toilet', 'sink', 'bathtub', 'otherfurniture')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=False, use_color=True, load_dim=6, use_dim=[0, 1, 2, 3, 4, 5]), dict(type='LoadAnnotations3D', with_bbox_3d=False, with_label_3d=False, with_mask_3d=False, with_seg_3d=True), dict(type='PointSegClassMapping', valid_cat_ids=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39), max_cat_id=40), dict(type='IndoorPatchPointSample', num_points=5, block_size=1.5, ignore_index=len(class_names), use_normalized_coord=True, enlarge_size=0.2, min_unique_num=None), dict(type='NormalizePointsColor', color_mean=None), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'pts_semantic_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/scannet/scannet_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/scannet'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    results['ann_info'] = dict()\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    scannet_points = np.fromfile(osp.join(data_path, info['pts_path']), dtype=np.float32).reshape((-1, 6))\n    scannet_choices = np.array([87, 34, 58, 9, 18])\n    scannet_center = np.array([-2.1772466, -3.4789145, 1.242711])\n    scannet_center[2] = 0.0\n    scannet_coord_max = np.amax(scannet_points[:, :3], axis=0)\n    expected_points = np.concatenate([scannet_points[scannet_choices, :3] - scannet_center, scannet_points[scannet_choices, 3:] / 255.0, scannet_points[scannet_choices, :3] / scannet_coord_max], axis=1)\n    expected_pts_semantic_mask = np.array([13, 13, 12, 2, 0])\n    assert np.allclose(points.numpy(), expected_points, atol=1e-06)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)",
            "def test_scannet_seg_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    class_names = ('wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refrigerator', 'showercurtrain', 'toilet', 'sink', 'bathtub', 'otherfurniture')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=False, use_color=True, load_dim=6, use_dim=[0, 1, 2, 3, 4, 5]), dict(type='LoadAnnotations3D', with_bbox_3d=False, with_label_3d=False, with_mask_3d=False, with_seg_3d=True), dict(type='PointSegClassMapping', valid_cat_ids=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39), max_cat_id=40), dict(type='IndoorPatchPointSample', num_points=5, block_size=1.5, ignore_index=len(class_names), use_normalized_coord=True, enlarge_size=0.2, min_unique_num=None), dict(type='NormalizePointsColor', color_mean=None), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'pts_semantic_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/scannet/scannet_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/scannet'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    results['ann_info'] = dict()\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    scannet_points = np.fromfile(osp.join(data_path, info['pts_path']), dtype=np.float32).reshape((-1, 6))\n    scannet_choices = np.array([87, 34, 58, 9, 18])\n    scannet_center = np.array([-2.1772466, -3.4789145, 1.242711])\n    scannet_center[2] = 0.0\n    scannet_coord_max = np.amax(scannet_points[:, :3], axis=0)\n    expected_points = np.concatenate([scannet_points[scannet_choices, :3] - scannet_center, scannet_points[scannet_choices, 3:] / 255.0, scannet_points[scannet_choices, :3] / scannet_coord_max], axis=1)\n    expected_pts_semantic_mask = np.array([13, 13, 12, 2, 0])\n    assert np.allclose(points.numpy(), expected_points, atol=1e-06)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)"
        ]
    },
    {
        "func_name": "test_s3dis_seg_pipeline",
        "original": "def test_s3dis_seg_pipeline():\n    class_names = ('ceiling', 'floor', 'wall', 'beam', 'column', 'window', 'door', 'table', 'chair', 'sofa', 'bookcase', 'board', 'clutter')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=False, use_color=True, load_dim=6, use_dim=[0, 1, 2, 3, 4, 5]), dict(type='LoadAnnotations3D', with_bbox_3d=False, with_label_3d=False, with_mask_3d=False, with_seg_3d=True), dict(type='PointSegClassMapping', valid_cat_ids=tuple(range(len(class_names))), max_cat_id=13), dict(type='IndoorPatchPointSample', num_points=5, block_size=1.0, ignore_index=len(class_names), use_normalized_coord=True, enlarge_size=0.2, min_unique_num=None), dict(type='NormalizePointsColor', color_mean=None), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'pts_semantic_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/s3dis/s3dis_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/s3dis'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    results['ann_info'] = dict()\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    s3dis_points = np.fromfile(osp.join(data_path, info['pts_path']), dtype=np.float32).reshape((-1, 6))\n    s3dis_choices = np.array([87, 37, 60, 18, 31])\n    s3dis_center = np.array([2.691, 2.231, 3.172])\n    s3dis_center[2] = 0.0\n    s3dis_coord_max = np.amax(s3dis_points[:, :3], axis=0)\n    expected_points = np.concatenate([s3dis_points[s3dis_choices, :3] - s3dis_center, s3dis_points[s3dis_choices, 3:] / 255.0, s3dis_points[s3dis_choices, :3] / s3dis_coord_max], axis=1)\n    expected_pts_semantic_mask = np.array([0, 1, 0, 8, 0])\n    assert np.allclose(points.numpy(), expected_points, atol=1e-06)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)",
        "mutated": [
            "def test_s3dis_seg_pipeline():\n    if False:\n        i = 10\n    class_names = ('ceiling', 'floor', 'wall', 'beam', 'column', 'window', 'door', 'table', 'chair', 'sofa', 'bookcase', 'board', 'clutter')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=False, use_color=True, load_dim=6, use_dim=[0, 1, 2, 3, 4, 5]), dict(type='LoadAnnotations3D', with_bbox_3d=False, with_label_3d=False, with_mask_3d=False, with_seg_3d=True), dict(type='PointSegClassMapping', valid_cat_ids=tuple(range(len(class_names))), max_cat_id=13), dict(type='IndoorPatchPointSample', num_points=5, block_size=1.0, ignore_index=len(class_names), use_normalized_coord=True, enlarge_size=0.2, min_unique_num=None), dict(type='NormalizePointsColor', color_mean=None), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'pts_semantic_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/s3dis/s3dis_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/s3dis'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    results['ann_info'] = dict()\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    s3dis_points = np.fromfile(osp.join(data_path, info['pts_path']), dtype=np.float32).reshape((-1, 6))\n    s3dis_choices = np.array([87, 37, 60, 18, 31])\n    s3dis_center = np.array([2.691, 2.231, 3.172])\n    s3dis_center[2] = 0.0\n    s3dis_coord_max = np.amax(s3dis_points[:, :3], axis=0)\n    expected_points = np.concatenate([s3dis_points[s3dis_choices, :3] - s3dis_center, s3dis_points[s3dis_choices, 3:] / 255.0, s3dis_points[s3dis_choices, :3] / s3dis_coord_max], axis=1)\n    expected_pts_semantic_mask = np.array([0, 1, 0, 8, 0])\n    assert np.allclose(points.numpy(), expected_points, atol=1e-06)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)",
            "def test_s3dis_seg_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    class_names = ('ceiling', 'floor', 'wall', 'beam', 'column', 'window', 'door', 'table', 'chair', 'sofa', 'bookcase', 'board', 'clutter')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=False, use_color=True, load_dim=6, use_dim=[0, 1, 2, 3, 4, 5]), dict(type='LoadAnnotations3D', with_bbox_3d=False, with_label_3d=False, with_mask_3d=False, with_seg_3d=True), dict(type='PointSegClassMapping', valid_cat_ids=tuple(range(len(class_names))), max_cat_id=13), dict(type='IndoorPatchPointSample', num_points=5, block_size=1.0, ignore_index=len(class_names), use_normalized_coord=True, enlarge_size=0.2, min_unique_num=None), dict(type='NormalizePointsColor', color_mean=None), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'pts_semantic_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/s3dis/s3dis_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/s3dis'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    results['ann_info'] = dict()\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    s3dis_points = np.fromfile(osp.join(data_path, info['pts_path']), dtype=np.float32).reshape((-1, 6))\n    s3dis_choices = np.array([87, 37, 60, 18, 31])\n    s3dis_center = np.array([2.691, 2.231, 3.172])\n    s3dis_center[2] = 0.0\n    s3dis_coord_max = np.amax(s3dis_points[:, :3], axis=0)\n    expected_points = np.concatenate([s3dis_points[s3dis_choices, :3] - s3dis_center, s3dis_points[s3dis_choices, 3:] / 255.0, s3dis_points[s3dis_choices, :3] / s3dis_coord_max], axis=1)\n    expected_pts_semantic_mask = np.array([0, 1, 0, 8, 0])\n    assert np.allclose(points.numpy(), expected_points, atol=1e-06)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)",
            "def test_s3dis_seg_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    class_names = ('ceiling', 'floor', 'wall', 'beam', 'column', 'window', 'door', 'table', 'chair', 'sofa', 'bookcase', 'board', 'clutter')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=False, use_color=True, load_dim=6, use_dim=[0, 1, 2, 3, 4, 5]), dict(type='LoadAnnotations3D', with_bbox_3d=False, with_label_3d=False, with_mask_3d=False, with_seg_3d=True), dict(type='PointSegClassMapping', valid_cat_ids=tuple(range(len(class_names))), max_cat_id=13), dict(type='IndoorPatchPointSample', num_points=5, block_size=1.0, ignore_index=len(class_names), use_normalized_coord=True, enlarge_size=0.2, min_unique_num=None), dict(type='NormalizePointsColor', color_mean=None), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'pts_semantic_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/s3dis/s3dis_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/s3dis'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    results['ann_info'] = dict()\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    s3dis_points = np.fromfile(osp.join(data_path, info['pts_path']), dtype=np.float32).reshape((-1, 6))\n    s3dis_choices = np.array([87, 37, 60, 18, 31])\n    s3dis_center = np.array([2.691, 2.231, 3.172])\n    s3dis_center[2] = 0.0\n    s3dis_coord_max = np.amax(s3dis_points[:, :3], axis=0)\n    expected_points = np.concatenate([s3dis_points[s3dis_choices, :3] - s3dis_center, s3dis_points[s3dis_choices, 3:] / 255.0, s3dis_points[s3dis_choices, :3] / s3dis_coord_max], axis=1)\n    expected_pts_semantic_mask = np.array([0, 1, 0, 8, 0])\n    assert np.allclose(points.numpy(), expected_points, atol=1e-06)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)",
            "def test_s3dis_seg_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    class_names = ('ceiling', 'floor', 'wall', 'beam', 'column', 'window', 'door', 'table', 'chair', 'sofa', 'bookcase', 'board', 'clutter')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=False, use_color=True, load_dim=6, use_dim=[0, 1, 2, 3, 4, 5]), dict(type='LoadAnnotations3D', with_bbox_3d=False, with_label_3d=False, with_mask_3d=False, with_seg_3d=True), dict(type='PointSegClassMapping', valid_cat_ids=tuple(range(len(class_names))), max_cat_id=13), dict(type='IndoorPatchPointSample', num_points=5, block_size=1.0, ignore_index=len(class_names), use_normalized_coord=True, enlarge_size=0.2, min_unique_num=None), dict(type='NormalizePointsColor', color_mean=None), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'pts_semantic_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/s3dis/s3dis_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/s3dis'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    results['ann_info'] = dict()\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    s3dis_points = np.fromfile(osp.join(data_path, info['pts_path']), dtype=np.float32).reshape((-1, 6))\n    s3dis_choices = np.array([87, 37, 60, 18, 31])\n    s3dis_center = np.array([2.691, 2.231, 3.172])\n    s3dis_center[2] = 0.0\n    s3dis_coord_max = np.amax(s3dis_points[:, :3], axis=0)\n    expected_points = np.concatenate([s3dis_points[s3dis_choices, :3] - s3dis_center, s3dis_points[s3dis_choices, 3:] / 255.0, s3dis_points[s3dis_choices, :3] / s3dis_coord_max], axis=1)\n    expected_pts_semantic_mask = np.array([0, 1, 0, 8, 0])\n    assert np.allclose(points.numpy(), expected_points, atol=1e-06)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)",
            "def test_s3dis_seg_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    class_names = ('ceiling', 'floor', 'wall', 'beam', 'column', 'window', 'door', 'table', 'chair', 'sofa', 'bookcase', 'board', 'clutter')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=False, use_color=True, load_dim=6, use_dim=[0, 1, 2, 3, 4, 5]), dict(type='LoadAnnotations3D', with_bbox_3d=False, with_label_3d=False, with_mask_3d=False, with_seg_3d=True), dict(type='PointSegClassMapping', valid_cat_ids=tuple(range(len(class_names))), max_cat_id=13), dict(type='IndoorPatchPointSample', num_points=5, block_size=1.0, ignore_index=len(class_names), use_normalized_coord=True, enlarge_size=0.2, min_unique_num=None), dict(type='NormalizePointsColor', color_mean=None), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'pts_semantic_mask'])]\n    pipeline = Compose(pipelines)\n    info = mmcv.load('./tests/data/s3dis/s3dis_infos.pkl')[0]\n    results = dict()\n    data_path = './tests/data/s3dis'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    results['ann_info'] = dict()\n    results['ann_info']['pts_semantic_mask_path'] = osp.join(data_path, info['pts_semantic_mask_path'])\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    pts_semantic_mask = results['pts_semantic_mask']._data\n    s3dis_points = np.fromfile(osp.join(data_path, info['pts_path']), dtype=np.float32).reshape((-1, 6))\n    s3dis_choices = np.array([87, 37, 60, 18, 31])\n    s3dis_center = np.array([2.691, 2.231, 3.172])\n    s3dis_center[2] = 0.0\n    s3dis_coord_max = np.amax(s3dis_points[:, :3], axis=0)\n    expected_points = np.concatenate([s3dis_points[s3dis_choices, :3] - s3dis_center, s3dis_points[s3dis_choices, 3:] / 255.0, s3dis_points[s3dis_choices, :3] / s3dis_coord_max], axis=1)\n    expected_pts_semantic_mask = np.array([0, 1, 0, 8, 0])\n    assert np.allclose(points.numpy(), expected_points, atol=1e-06)\n    assert np.all(pts_semantic_mask.numpy() == expected_pts_semantic_mask)"
        ]
    },
    {
        "func_name": "test_sunrgbd_pipeline",
        "original": "def test_sunrgbd_pipeline():\n    class_names = ('bed', 'table', 'sofa', 'chair', 'toilet', 'desk', 'dresser', 'night_stand', 'bookshelf', 'bathtub')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=True, load_dim=6, use_dim=[0, 1, 2]), dict(type='LoadAnnotations3D'), dict(type='RandomFlip3D', sync_2d=False, flip_ratio_bev_horizontal=1.0), dict(type='GlobalRotScaleTrans', rot_range=[-0.523599, 0.523599], scale_ratio_range=[0.85, 1.15], shift_height=True), dict(type='PointSample', num_points=5), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])]\n    pipeline = Compose(pipelines)\n    results = dict()\n    info = mmcv.load('./tests/data/sunrgbd/sunrgbd_infos.pkl')[0]\n    data_path = './tests/data/sunrgbd'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    if info['annos']['gt_num'] != 0:\n        gt_bboxes_3d = info['annos']['gt_boxes_upright_depth'].astype(np.float32)\n        gt_labels_3d = info['annos']['class'].astype(np.int64)\n    else:\n        gt_bboxes_3d = np.zeros((1, 7), dtype=np.float32)\n        gt_labels_3d = np.zeros((1,), dtype=np.int64)\n    results['ann_info'] = dict()\n    results['ann_info']['gt_bboxes_3d'] = DepthInstance3DBoxes(gt_bboxes_3d)\n    results['ann_info']['gt_labels_3d'] = gt_labels_3d\n    results['img_fields'] = []\n    results['bbox3d_fields'] = []\n    results['pts_mask_fields'] = []\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    gt_bboxes_3d = results['gt_bboxes_3d']._data\n    gt_labels_3d = results['gt_labels_3d']._data\n    expected_points = torch.tensor([[0.8678, 1.347, 0.1105, 0.0905], [0.8707, 1.3635, 0.0437, 0.0238], [0.8636, 1.3511, 0.0504, 0.0304], [0.869, 1.3461, 0.1265, 0.1065], [0.8668, 1.3434, 0.1216, 0.1017]])\n    rotation_angle = info['annos']['rotation_y']\n    expected_gt_bboxes_3d = torch.tensor([[-1.2136, 4.0206, -0.2412, 2.2493, 1.8444, 1.9245, 1.3989 + 0.047001579467984445 * 2 - 2 * rotation_angle[0]], [-2.742, 4.5777, -0.7686, 0.5718, 0.8629, 0.951, 1.4446 + 0.047001579467984445 * 2 - 2 * rotation_angle[1]], [0.9729, 1.9087, -0.1443, 0.6965, 1.5273, 2.0563, 2.9924 + 0.047001579467984445 * 2 - 2 * rotation_angle[2]]]).float()\n    expected_gt_labels_3d = np.array([0, 7, 6])\n    assert torch.allclose(gt_bboxes_3d.tensor, expected_gt_bboxes_3d, 0.001)\n    assert np.allclose(gt_labels_3d.flatten(), expected_gt_labels_3d)\n    assert torch.allclose(points, expected_points, 0.01)",
        "mutated": [
            "def test_sunrgbd_pipeline():\n    if False:\n        i = 10\n    class_names = ('bed', 'table', 'sofa', 'chair', 'toilet', 'desk', 'dresser', 'night_stand', 'bookshelf', 'bathtub')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=True, load_dim=6, use_dim=[0, 1, 2]), dict(type='LoadAnnotations3D'), dict(type='RandomFlip3D', sync_2d=False, flip_ratio_bev_horizontal=1.0), dict(type='GlobalRotScaleTrans', rot_range=[-0.523599, 0.523599], scale_ratio_range=[0.85, 1.15], shift_height=True), dict(type='PointSample', num_points=5), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])]\n    pipeline = Compose(pipelines)\n    results = dict()\n    info = mmcv.load('./tests/data/sunrgbd/sunrgbd_infos.pkl')[0]\n    data_path = './tests/data/sunrgbd'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    if info['annos']['gt_num'] != 0:\n        gt_bboxes_3d = info['annos']['gt_boxes_upright_depth'].astype(np.float32)\n        gt_labels_3d = info['annos']['class'].astype(np.int64)\n    else:\n        gt_bboxes_3d = np.zeros((1, 7), dtype=np.float32)\n        gt_labels_3d = np.zeros((1,), dtype=np.int64)\n    results['ann_info'] = dict()\n    results['ann_info']['gt_bboxes_3d'] = DepthInstance3DBoxes(gt_bboxes_3d)\n    results['ann_info']['gt_labels_3d'] = gt_labels_3d\n    results['img_fields'] = []\n    results['bbox3d_fields'] = []\n    results['pts_mask_fields'] = []\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    gt_bboxes_3d = results['gt_bboxes_3d']._data\n    gt_labels_3d = results['gt_labels_3d']._data\n    expected_points = torch.tensor([[0.8678, 1.347, 0.1105, 0.0905], [0.8707, 1.3635, 0.0437, 0.0238], [0.8636, 1.3511, 0.0504, 0.0304], [0.869, 1.3461, 0.1265, 0.1065], [0.8668, 1.3434, 0.1216, 0.1017]])\n    rotation_angle = info['annos']['rotation_y']\n    expected_gt_bboxes_3d = torch.tensor([[-1.2136, 4.0206, -0.2412, 2.2493, 1.8444, 1.9245, 1.3989 + 0.047001579467984445 * 2 - 2 * rotation_angle[0]], [-2.742, 4.5777, -0.7686, 0.5718, 0.8629, 0.951, 1.4446 + 0.047001579467984445 * 2 - 2 * rotation_angle[1]], [0.9729, 1.9087, -0.1443, 0.6965, 1.5273, 2.0563, 2.9924 + 0.047001579467984445 * 2 - 2 * rotation_angle[2]]]).float()\n    expected_gt_labels_3d = np.array([0, 7, 6])\n    assert torch.allclose(gt_bboxes_3d.tensor, expected_gt_bboxes_3d, 0.001)\n    assert np.allclose(gt_labels_3d.flatten(), expected_gt_labels_3d)\n    assert torch.allclose(points, expected_points, 0.01)",
            "def test_sunrgbd_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    class_names = ('bed', 'table', 'sofa', 'chair', 'toilet', 'desk', 'dresser', 'night_stand', 'bookshelf', 'bathtub')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=True, load_dim=6, use_dim=[0, 1, 2]), dict(type='LoadAnnotations3D'), dict(type='RandomFlip3D', sync_2d=False, flip_ratio_bev_horizontal=1.0), dict(type='GlobalRotScaleTrans', rot_range=[-0.523599, 0.523599], scale_ratio_range=[0.85, 1.15], shift_height=True), dict(type='PointSample', num_points=5), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])]\n    pipeline = Compose(pipelines)\n    results = dict()\n    info = mmcv.load('./tests/data/sunrgbd/sunrgbd_infos.pkl')[0]\n    data_path = './tests/data/sunrgbd'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    if info['annos']['gt_num'] != 0:\n        gt_bboxes_3d = info['annos']['gt_boxes_upright_depth'].astype(np.float32)\n        gt_labels_3d = info['annos']['class'].astype(np.int64)\n    else:\n        gt_bboxes_3d = np.zeros((1, 7), dtype=np.float32)\n        gt_labels_3d = np.zeros((1,), dtype=np.int64)\n    results['ann_info'] = dict()\n    results['ann_info']['gt_bboxes_3d'] = DepthInstance3DBoxes(gt_bboxes_3d)\n    results['ann_info']['gt_labels_3d'] = gt_labels_3d\n    results['img_fields'] = []\n    results['bbox3d_fields'] = []\n    results['pts_mask_fields'] = []\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    gt_bboxes_3d = results['gt_bboxes_3d']._data\n    gt_labels_3d = results['gt_labels_3d']._data\n    expected_points = torch.tensor([[0.8678, 1.347, 0.1105, 0.0905], [0.8707, 1.3635, 0.0437, 0.0238], [0.8636, 1.3511, 0.0504, 0.0304], [0.869, 1.3461, 0.1265, 0.1065], [0.8668, 1.3434, 0.1216, 0.1017]])\n    rotation_angle = info['annos']['rotation_y']\n    expected_gt_bboxes_3d = torch.tensor([[-1.2136, 4.0206, -0.2412, 2.2493, 1.8444, 1.9245, 1.3989 + 0.047001579467984445 * 2 - 2 * rotation_angle[0]], [-2.742, 4.5777, -0.7686, 0.5718, 0.8629, 0.951, 1.4446 + 0.047001579467984445 * 2 - 2 * rotation_angle[1]], [0.9729, 1.9087, -0.1443, 0.6965, 1.5273, 2.0563, 2.9924 + 0.047001579467984445 * 2 - 2 * rotation_angle[2]]]).float()\n    expected_gt_labels_3d = np.array([0, 7, 6])\n    assert torch.allclose(gt_bboxes_3d.tensor, expected_gt_bboxes_3d, 0.001)\n    assert np.allclose(gt_labels_3d.flatten(), expected_gt_labels_3d)\n    assert torch.allclose(points, expected_points, 0.01)",
            "def test_sunrgbd_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    class_names = ('bed', 'table', 'sofa', 'chair', 'toilet', 'desk', 'dresser', 'night_stand', 'bookshelf', 'bathtub')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=True, load_dim=6, use_dim=[0, 1, 2]), dict(type='LoadAnnotations3D'), dict(type='RandomFlip3D', sync_2d=False, flip_ratio_bev_horizontal=1.0), dict(type='GlobalRotScaleTrans', rot_range=[-0.523599, 0.523599], scale_ratio_range=[0.85, 1.15], shift_height=True), dict(type='PointSample', num_points=5), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])]\n    pipeline = Compose(pipelines)\n    results = dict()\n    info = mmcv.load('./tests/data/sunrgbd/sunrgbd_infos.pkl')[0]\n    data_path = './tests/data/sunrgbd'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    if info['annos']['gt_num'] != 0:\n        gt_bboxes_3d = info['annos']['gt_boxes_upright_depth'].astype(np.float32)\n        gt_labels_3d = info['annos']['class'].astype(np.int64)\n    else:\n        gt_bboxes_3d = np.zeros((1, 7), dtype=np.float32)\n        gt_labels_3d = np.zeros((1,), dtype=np.int64)\n    results['ann_info'] = dict()\n    results['ann_info']['gt_bboxes_3d'] = DepthInstance3DBoxes(gt_bboxes_3d)\n    results['ann_info']['gt_labels_3d'] = gt_labels_3d\n    results['img_fields'] = []\n    results['bbox3d_fields'] = []\n    results['pts_mask_fields'] = []\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    gt_bboxes_3d = results['gt_bboxes_3d']._data\n    gt_labels_3d = results['gt_labels_3d']._data\n    expected_points = torch.tensor([[0.8678, 1.347, 0.1105, 0.0905], [0.8707, 1.3635, 0.0437, 0.0238], [0.8636, 1.3511, 0.0504, 0.0304], [0.869, 1.3461, 0.1265, 0.1065], [0.8668, 1.3434, 0.1216, 0.1017]])\n    rotation_angle = info['annos']['rotation_y']\n    expected_gt_bboxes_3d = torch.tensor([[-1.2136, 4.0206, -0.2412, 2.2493, 1.8444, 1.9245, 1.3989 + 0.047001579467984445 * 2 - 2 * rotation_angle[0]], [-2.742, 4.5777, -0.7686, 0.5718, 0.8629, 0.951, 1.4446 + 0.047001579467984445 * 2 - 2 * rotation_angle[1]], [0.9729, 1.9087, -0.1443, 0.6965, 1.5273, 2.0563, 2.9924 + 0.047001579467984445 * 2 - 2 * rotation_angle[2]]]).float()\n    expected_gt_labels_3d = np.array([0, 7, 6])\n    assert torch.allclose(gt_bboxes_3d.tensor, expected_gt_bboxes_3d, 0.001)\n    assert np.allclose(gt_labels_3d.flatten(), expected_gt_labels_3d)\n    assert torch.allclose(points, expected_points, 0.01)",
            "def test_sunrgbd_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    class_names = ('bed', 'table', 'sofa', 'chair', 'toilet', 'desk', 'dresser', 'night_stand', 'bookshelf', 'bathtub')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=True, load_dim=6, use_dim=[0, 1, 2]), dict(type='LoadAnnotations3D'), dict(type='RandomFlip3D', sync_2d=False, flip_ratio_bev_horizontal=1.0), dict(type='GlobalRotScaleTrans', rot_range=[-0.523599, 0.523599], scale_ratio_range=[0.85, 1.15], shift_height=True), dict(type='PointSample', num_points=5), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])]\n    pipeline = Compose(pipelines)\n    results = dict()\n    info = mmcv.load('./tests/data/sunrgbd/sunrgbd_infos.pkl')[0]\n    data_path = './tests/data/sunrgbd'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    if info['annos']['gt_num'] != 0:\n        gt_bboxes_3d = info['annos']['gt_boxes_upright_depth'].astype(np.float32)\n        gt_labels_3d = info['annos']['class'].astype(np.int64)\n    else:\n        gt_bboxes_3d = np.zeros((1, 7), dtype=np.float32)\n        gt_labels_3d = np.zeros((1,), dtype=np.int64)\n    results['ann_info'] = dict()\n    results['ann_info']['gt_bboxes_3d'] = DepthInstance3DBoxes(gt_bboxes_3d)\n    results['ann_info']['gt_labels_3d'] = gt_labels_3d\n    results['img_fields'] = []\n    results['bbox3d_fields'] = []\n    results['pts_mask_fields'] = []\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    gt_bboxes_3d = results['gt_bboxes_3d']._data\n    gt_labels_3d = results['gt_labels_3d']._data\n    expected_points = torch.tensor([[0.8678, 1.347, 0.1105, 0.0905], [0.8707, 1.3635, 0.0437, 0.0238], [0.8636, 1.3511, 0.0504, 0.0304], [0.869, 1.3461, 0.1265, 0.1065], [0.8668, 1.3434, 0.1216, 0.1017]])\n    rotation_angle = info['annos']['rotation_y']\n    expected_gt_bboxes_3d = torch.tensor([[-1.2136, 4.0206, -0.2412, 2.2493, 1.8444, 1.9245, 1.3989 + 0.047001579467984445 * 2 - 2 * rotation_angle[0]], [-2.742, 4.5777, -0.7686, 0.5718, 0.8629, 0.951, 1.4446 + 0.047001579467984445 * 2 - 2 * rotation_angle[1]], [0.9729, 1.9087, -0.1443, 0.6965, 1.5273, 2.0563, 2.9924 + 0.047001579467984445 * 2 - 2 * rotation_angle[2]]]).float()\n    expected_gt_labels_3d = np.array([0, 7, 6])\n    assert torch.allclose(gt_bboxes_3d.tensor, expected_gt_bboxes_3d, 0.001)\n    assert np.allclose(gt_labels_3d.flatten(), expected_gt_labels_3d)\n    assert torch.allclose(points, expected_points, 0.01)",
            "def test_sunrgbd_pipeline():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    class_names = ('bed', 'table', 'sofa', 'chair', 'toilet', 'desk', 'dresser', 'night_stand', 'bookshelf', 'bathtub')\n    np.random.seed(0)\n    pipelines = [dict(type='LoadPointsFromFile', coord_type='DEPTH', shift_height=True, load_dim=6, use_dim=[0, 1, 2]), dict(type='LoadAnnotations3D'), dict(type='RandomFlip3D', sync_2d=False, flip_ratio_bev_horizontal=1.0), dict(type='GlobalRotScaleTrans', rot_range=[-0.523599, 0.523599], scale_ratio_range=[0.85, 1.15], shift_height=True), dict(type='PointSample', num_points=5), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])]\n    pipeline = Compose(pipelines)\n    results = dict()\n    info = mmcv.load('./tests/data/sunrgbd/sunrgbd_infos.pkl')[0]\n    data_path = './tests/data/sunrgbd'\n    results['pts_filename'] = osp.join(data_path, info['pts_path'])\n    if info['annos']['gt_num'] != 0:\n        gt_bboxes_3d = info['annos']['gt_boxes_upright_depth'].astype(np.float32)\n        gt_labels_3d = info['annos']['class'].astype(np.int64)\n    else:\n        gt_bboxes_3d = np.zeros((1, 7), dtype=np.float32)\n        gt_labels_3d = np.zeros((1,), dtype=np.int64)\n    results['ann_info'] = dict()\n    results['ann_info']['gt_bboxes_3d'] = DepthInstance3DBoxes(gt_bboxes_3d)\n    results['ann_info']['gt_labels_3d'] = gt_labels_3d\n    results['img_fields'] = []\n    results['bbox3d_fields'] = []\n    results['pts_mask_fields'] = []\n    results['pts_seg_fields'] = []\n    results = pipeline(results)\n    points = results['points']._data\n    gt_bboxes_3d = results['gt_bboxes_3d']._data\n    gt_labels_3d = results['gt_labels_3d']._data\n    expected_points = torch.tensor([[0.8678, 1.347, 0.1105, 0.0905], [0.8707, 1.3635, 0.0437, 0.0238], [0.8636, 1.3511, 0.0504, 0.0304], [0.869, 1.3461, 0.1265, 0.1065], [0.8668, 1.3434, 0.1216, 0.1017]])\n    rotation_angle = info['annos']['rotation_y']\n    expected_gt_bboxes_3d = torch.tensor([[-1.2136, 4.0206, -0.2412, 2.2493, 1.8444, 1.9245, 1.3989 + 0.047001579467984445 * 2 - 2 * rotation_angle[0]], [-2.742, 4.5777, -0.7686, 0.5718, 0.8629, 0.951, 1.4446 + 0.047001579467984445 * 2 - 2 * rotation_angle[1]], [0.9729, 1.9087, -0.1443, 0.6965, 1.5273, 2.0563, 2.9924 + 0.047001579467984445 * 2 - 2 * rotation_angle[2]]]).float()\n    expected_gt_labels_3d = np.array([0, 7, 6])\n    assert torch.allclose(gt_bboxes_3d.tensor, expected_gt_bboxes_3d, 0.001)\n    assert np.allclose(gt_labels_3d.flatten(), expected_gt_labels_3d)\n    assert torch.allclose(points, expected_points, 0.01)"
        ]
    }
]