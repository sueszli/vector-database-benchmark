[
    {
        "func_name": "__init__",
        "original": "def __init__(self, config):\n    self.config = config\n    self.curGame = 0\n    self.curTime = 0\n    self.totIterPlayed = 0\n    self.players = self.createAgent()\n    self.T = 0\n    self.demand = []\n    self.ifOptimalSolExist = self.config.ifOptimalSolExist\n    self.getOptimalSol()\n    self.totRew = 0\n    self.resultTest = []\n    self.runnerMidlResults = []\n    self.runnerFinlResults = []\n    self.middleTestResult = []\n    self.runNumber = 0\n    self.strNum = 0",
        "mutated": [
            "def __init__(self, config):\n    if False:\n        i = 10\n    self.config = config\n    self.curGame = 0\n    self.curTime = 0\n    self.totIterPlayed = 0\n    self.players = self.createAgent()\n    self.T = 0\n    self.demand = []\n    self.ifOptimalSolExist = self.config.ifOptimalSolExist\n    self.getOptimalSol()\n    self.totRew = 0\n    self.resultTest = []\n    self.runnerMidlResults = []\n    self.runnerFinlResults = []\n    self.middleTestResult = []\n    self.runNumber = 0\n    self.strNum = 0",
            "def __init__(self, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.config = config\n    self.curGame = 0\n    self.curTime = 0\n    self.totIterPlayed = 0\n    self.players = self.createAgent()\n    self.T = 0\n    self.demand = []\n    self.ifOptimalSolExist = self.config.ifOptimalSolExist\n    self.getOptimalSol()\n    self.totRew = 0\n    self.resultTest = []\n    self.runnerMidlResults = []\n    self.runnerFinlResults = []\n    self.middleTestResult = []\n    self.runNumber = 0\n    self.strNum = 0",
            "def __init__(self, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.config = config\n    self.curGame = 0\n    self.curTime = 0\n    self.totIterPlayed = 0\n    self.players = self.createAgent()\n    self.T = 0\n    self.demand = []\n    self.ifOptimalSolExist = self.config.ifOptimalSolExist\n    self.getOptimalSol()\n    self.totRew = 0\n    self.resultTest = []\n    self.runnerMidlResults = []\n    self.runnerFinlResults = []\n    self.middleTestResult = []\n    self.runNumber = 0\n    self.strNum = 0",
            "def __init__(self, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.config = config\n    self.curGame = 0\n    self.curTime = 0\n    self.totIterPlayed = 0\n    self.players = self.createAgent()\n    self.T = 0\n    self.demand = []\n    self.ifOptimalSolExist = self.config.ifOptimalSolExist\n    self.getOptimalSol()\n    self.totRew = 0\n    self.resultTest = []\n    self.runnerMidlResults = []\n    self.runnerFinlResults = []\n    self.middleTestResult = []\n    self.runNumber = 0\n    self.strNum = 0",
            "def __init__(self, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.config = config\n    self.curGame = 0\n    self.curTime = 0\n    self.totIterPlayed = 0\n    self.players = self.createAgent()\n    self.T = 0\n    self.demand = []\n    self.ifOptimalSolExist = self.config.ifOptimalSolExist\n    self.getOptimalSol()\n    self.totRew = 0\n    self.resultTest = []\n    self.runnerMidlResults = []\n    self.runnerFinlResults = []\n    self.middleTestResult = []\n    self.runNumber = 0\n    self.strNum = 0"
        ]
    },
    {
        "func_name": "createAgent",
        "original": "def createAgent(self):\n    agentTypes = self.config.agentTypes\n    return [Agent(i, self.config.ILInit[i], self.config.AOInit, self.config.ASInit[i], self.config.c_h[i], self.config.c_p[i], self.config.eta[i], agentTypes[i], self.config) for i in range(self.config.NoAgent)]",
        "mutated": [
            "def createAgent(self):\n    if False:\n        i = 10\n    agentTypes = self.config.agentTypes\n    return [Agent(i, self.config.ILInit[i], self.config.AOInit, self.config.ASInit[i], self.config.c_h[i], self.config.c_p[i], self.config.eta[i], agentTypes[i], self.config) for i in range(self.config.NoAgent)]",
            "def createAgent(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    agentTypes = self.config.agentTypes\n    return [Agent(i, self.config.ILInit[i], self.config.AOInit, self.config.ASInit[i], self.config.c_h[i], self.config.c_p[i], self.config.eta[i], agentTypes[i], self.config) for i in range(self.config.NoAgent)]",
            "def createAgent(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    agentTypes = self.config.agentTypes\n    return [Agent(i, self.config.ILInit[i], self.config.AOInit, self.config.ASInit[i], self.config.c_h[i], self.config.c_p[i], self.config.eta[i], agentTypes[i], self.config) for i in range(self.config.NoAgent)]",
            "def createAgent(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    agentTypes = self.config.agentTypes\n    return [Agent(i, self.config.ILInit[i], self.config.AOInit, self.config.ASInit[i], self.config.c_h[i], self.config.c_p[i], self.config.eta[i], agentTypes[i], self.config) for i in range(self.config.NoAgent)]",
            "def createAgent(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    agentTypes = self.config.agentTypes\n    return [Agent(i, self.config.ILInit[i], self.config.AOInit, self.config.ASInit[i], self.config.c_h[i], self.config.c_p[i], self.config.eta[i], agentTypes[i], self.config) for i in range(self.config.NoAgent)]"
        ]
    },
    {
        "func_name": "planHorizon",
        "original": "def planHorizon(self):\n    return randint(self.config.TLow, self.config.TUp)",
        "mutated": [
            "def planHorizon(self):\n    if False:\n        i = 10\n    return randint(self.config.TLow, self.config.TUp)",
            "def planHorizon(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return randint(self.config.TLow, self.config.TUp)",
            "def planHorizon(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return randint(self.config.TLow, self.config.TUp)",
            "def planHorizon(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return randint(self.config.TLow, self.config.TUp)",
            "def planHorizon(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return randint(self.config.TLow, self.config.TUp)"
        ]
    },
    {
        "func_name": "resetGame",
        "original": "def resetGame(self, demand: np.ndarray):\n    self.demand = demand\n    self.curTime = 0\n    self.curGame += 1\n    self.totIterPlayed += self.T\n    self.T = self.planHorizon()\n    for k in range(0, self.config.NoAgent):\n        self.players[k].resetPlayer(self.T)\n    self.update_OO()",
        "mutated": [
            "def resetGame(self, demand: np.ndarray):\n    if False:\n        i = 10\n    self.demand = demand\n    self.curTime = 0\n    self.curGame += 1\n    self.totIterPlayed += self.T\n    self.T = self.planHorizon()\n    for k in range(0, self.config.NoAgent):\n        self.players[k].resetPlayer(self.T)\n    self.update_OO()",
            "def resetGame(self, demand: np.ndarray):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.demand = demand\n    self.curTime = 0\n    self.curGame += 1\n    self.totIterPlayed += self.T\n    self.T = self.planHorizon()\n    for k in range(0, self.config.NoAgent):\n        self.players[k].resetPlayer(self.T)\n    self.update_OO()",
            "def resetGame(self, demand: np.ndarray):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.demand = demand\n    self.curTime = 0\n    self.curGame += 1\n    self.totIterPlayed += self.T\n    self.T = self.planHorizon()\n    for k in range(0, self.config.NoAgent):\n        self.players[k].resetPlayer(self.T)\n    self.update_OO()",
            "def resetGame(self, demand: np.ndarray):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.demand = demand\n    self.curTime = 0\n    self.curGame += 1\n    self.totIterPlayed += self.T\n    self.T = self.planHorizon()\n    for k in range(0, self.config.NoAgent):\n        self.players[k].resetPlayer(self.T)\n    self.update_OO()",
            "def resetGame(self, demand: np.ndarray):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.demand = demand\n    self.curTime = 0\n    self.curGame += 1\n    self.totIterPlayed += self.T\n    self.T = self.planHorizon()\n    for k in range(0, self.config.NoAgent):\n        self.players[k].resetPlayer(self.T)\n    self.update_OO()"
        ]
    },
    {
        "func_name": "getTotRew",
        "original": "def getTotRew(self):\n    totRew = 0\n    for i in range(self.config.NoAgent):\n        totRew += self.players[i].cumReward\n    for i in range(self.config.NoAgent):\n        self.players[i].curReward += self.players[i].eta * (totRew - self.players[i].cumReward)",
        "mutated": [
            "def getTotRew(self):\n    if False:\n        i = 10\n    totRew = 0\n    for i in range(self.config.NoAgent):\n        totRew += self.players[i].cumReward\n    for i in range(self.config.NoAgent):\n        self.players[i].curReward += self.players[i].eta * (totRew - self.players[i].cumReward)",
            "def getTotRew(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    totRew = 0\n    for i in range(self.config.NoAgent):\n        totRew += self.players[i].cumReward\n    for i in range(self.config.NoAgent):\n        self.players[i].curReward += self.players[i].eta * (totRew - self.players[i].cumReward)",
            "def getTotRew(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    totRew = 0\n    for i in range(self.config.NoAgent):\n        totRew += self.players[i].cumReward\n    for i in range(self.config.NoAgent):\n        self.players[i].curReward += self.players[i].eta * (totRew - self.players[i].cumReward)",
            "def getTotRew(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    totRew = 0\n    for i in range(self.config.NoAgent):\n        totRew += self.players[i].cumReward\n    for i in range(self.config.NoAgent):\n        self.players[i].curReward += self.players[i].eta * (totRew - self.players[i].cumReward)",
            "def getTotRew(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    totRew = 0\n    for i in range(self.config.NoAgent):\n        totRew += self.players[i].cumReward\n    for i in range(self.config.NoAgent):\n        self.players[i].curReward += self.players[i].eta * (totRew - self.players[i].cumReward)"
        ]
    },
    {
        "func_name": "distTotReward",
        "original": "def distTotReward(self, role: int):\n    totRew = 0\n    optRew = 0.1\n    for i in range(self.config.NoAgent):\n        totRew += self.players[i].cumReward\n    totRew += optRew\n    return (totRew, self.players[role].cumReward)",
        "mutated": [
            "def distTotReward(self, role: int):\n    if False:\n        i = 10\n    totRew = 0\n    optRew = 0.1\n    for i in range(self.config.NoAgent):\n        totRew += self.players[i].cumReward\n    totRew += optRew\n    return (totRew, self.players[role].cumReward)",
            "def distTotReward(self, role: int):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    totRew = 0\n    optRew = 0.1\n    for i in range(self.config.NoAgent):\n        totRew += self.players[i].cumReward\n    totRew += optRew\n    return (totRew, self.players[role].cumReward)",
            "def distTotReward(self, role: int):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    totRew = 0\n    optRew = 0.1\n    for i in range(self.config.NoAgent):\n        totRew += self.players[i].cumReward\n    totRew += optRew\n    return (totRew, self.players[role].cumReward)",
            "def distTotReward(self, role: int):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    totRew = 0\n    optRew = 0.1\n    for i in range(self.config.NoAgent):\n        totRew += self.players[i].cumReward\n    totRew += optRew\n    return (totRew, self.players[role].cumReward)",
            "def distTotReward(self, role: int):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    totRew = 0\n    optRew = 0.1\n    for i in range(self.config.NoAgent):\n        totRew += self.players[i].cumReward\n    totRew += optRew\n    return (totRew, self.players[role].cumReward)"
        ]
    },
    {
        "func_name": "getAction",
        "original": "def getAction(self, k: int, action: np.ndarray, playType='train'):\n    if playType == 'train':\n        if self.players[k].compType == 'srdqn':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            self.players[k].action[action] = 1\n        elif self.players[k].compType == 'Strm':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, round(self.players[k].AO[self.curTime] + self.players[k].alpha_b * (self.players[k].IL - self.players[k].a_b) + self.players[k].betta_b * (self.players[k].OO - self.players[k].b_b)))))] = 1\n        elif self.players[k].compType == 'rnd':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            a = np.random.randint(self.config.actionListLen)\n            self.players[k].action[a] = 1\n        elif self.players[k].compType == 'bs':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            if self.config.demandDistribution == 2:\n                if self.curTime and self.config.use_initial_BS <= 4:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].int_bslBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n                else:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n            else:\n                self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n    elif playType == 'test':\n        if self.players[k].compTypeTest == 'srdqn':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            self.players[k].action = self.players[k].brain.getDNNAction(self.playType)\n        elif self.players[k].compTypeTest == 'Strm':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, round(self.players[k].AO[self.curTime] + self.players[k].alpha_b * (self.players[k].IL - self.players[k].a_b) + self.players[k].betta_b * (self.players[k].OO - self.players[k].b_b)))))] = 1\n        elif self.players[k].compTypeTest == 'rnd':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            a = np.random.randint(self.config.actionListLen)\n            self.players[k].action[a] = 1\n        elif self.players[k].compTypeTest == 'bs':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            if self.config.demandDistribution == 2:\n                if self.curTime and self.config.use_initial_BS <= 4:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].int_bslBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n                else:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n            else:\n                self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n    else:\n        raise Exception('The player type is not defined or it is not a valid type.!')",
        "mutated": [
            "def getAction(self, k: int, action: np.ndarray, playType='train'):\n    if False:\n        i = 10\n    if playType == 'train':\n        if self.players[k].compType == 'srdqn':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            self.players[k].action[action] = 1\n        elif self.players[k].compType == 'Strm':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, round(self.players[k].AO[self.curTime] + self.players[k].alpha_b * (self.players[k].IL - self.players[k].a_b) + self.players[k].betta_b * (self.players[k].OO - self.players[k].b_b)))))] = 1\n        elif self.players[k].compType == 'rnd':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            a = np.random.randint(self.config.actionListLen)\n            self.players[k].action[a] = 1\n        elif self.players[k].compType == 'bs':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            if self.config.demandDistribution == 2:\n                if self.curTime and self.config.use_initial_BS <= 4:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].int_bslBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n                else:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n            else:\n                self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n    elif playType == 'test':\n        if self.players[k].compTypeTest == 'srdqn':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            self.players[k].action = self.players[k].brain.getDNNAction(self.playType)\n        elif self.players[k].compTypeTest == 'Strm':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, round(self.players[k].AO[self.curTime] + self.players[k].alpha_b * (self.players[k].IL - self.players[k].a_b) + self.players[k].betta_b * (self.players[k].OO - self.players[k].b_b)))))] = 1\n        elif self.players[k].compTypeTest == 'rnd':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            a = np.random.randint(self.config.actionListLen)\n            self.players[k].action[a] = 1\n        elif self.players[k].compTypeTest == 'bs':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            if self.config.demandDistribution == 2:\n                if self.curTime and self.config.use_initial_BS <= 4:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].int_bslBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n                else:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n            else:\n                self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n    else:\n        raise Exception('The player type is not defined or it is not a valid type.!')",
            "def getAction(self, k: int, action: np.ndarray, playType='train'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if playType == 'train':\n        if self.players[k].compType == 'srdqn':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            self.players[k].action[action] = 1\n        elif self.players[k].compType == 'Strm':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, round(self.players[k].AO[self.curTime] + self.players[k].alpha_b * (self.players[k].IL - self.players[k].a_b) + self.players[k].betta_b * (self.players[k].OO - self.players[k].b_b)))))] = 1\n        elif self.players[k].compType == 'rnd':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            a = np.random.randint(self.config.actionListLen)\n            self.players[k].action[a] = 1\n        elif self.players[k].compType == 'bs':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            if self.config.demandDistribution == 2:\n                if self.curTime and self.config.use_initial_BS <= 4:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].int_bslBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n                else:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n            else:\n                self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n    elif playType == 'test':\n        if self.players[k].compTypeTest == 'srdqn':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            self.players[k].action = self.players[k].brain.getDNNAction(self.playType)\n        elif self.players[k].compTypeTest == 'Strm':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, round(self.players[k].AO[self.curTime] + self.players[k].alpha_b * (self.players[k].IL - self.players[k].a_b) + self.players[k].betta_b * (self.players[k].OO - self.players[k].b_b)))))] = 1\n        elif self.players[k].compTypeTest == 'rnd':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            a = np.random.randint(self.config.actionListLen)\n            self.players[k].action[a] = 1\n        elif self.players[k].compTypeTest == 'bs':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            if self.config.demandDistribution == 2:\n                if self.curTime and self.config.use_initial_BS <= 4:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].int_bslBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n                else:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n            else:\n                self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n    else:\n        raise Exception('The player type is not defined or it is not a valid type.!')",
            "def getAction(self, k: int, action: np.ndarray, playType='train'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if playType == 'train':\n        if self.players[k].compType == 'srdqn':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            self.players[k].action[action] = 1\n        elif self.players[k].compType == 'Strm':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, round(self.players[k].AO[self.curTime] + self.players[k].alpha_b * (self.players[k].IL - self.players[k].a_b) + self.players[k].betta_b * (self.players[k].OO - self.players[k].b_b)))))] = 1\n        elif self.players[k].compType == 'rnd':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            a = np.random.randint(self.config.actionListLen)\n            self.players[k].action[a] = 1\n        elif self.players[k].compType == 'bs':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            if self.config.demandDistribution == 2:\n                if self.curTime and self.config.use_initial_BS <= 4:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].int_bslBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n                else:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n            else:\n                self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n    elif playType == 'test':\n        if self.players[k].compTypeTest == 'srdqn':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            self.players[k].action = self.players[k].brain.getDNNAction(self.playType)\n        elif self.players[k].compTypeTest == 'Strm':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, round(self.players[k].AO[self.curTime] + self.players[k].alpha_b * (self.players[k].IL - self.players[k].a_b) + self.players[k].betta_b * (self.players[k].OO - self.players[k].b_b)))))] = 1\n        elif self.players[k].compTypeTest == 'rnd':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            a = np.random.randint(self.config.actionListLen)\n            self.players[k].action[a] = 1\n        elif self.players[k].compTypeTest == 'bs':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            if self.config.demandDistribution == 2:\n                if self.curTime and self.config.use_initial_BS <= 4:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].int_bslBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n                else:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n            else:\n                self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n    else:\n        raise Exception('The player type is not defined or it is not a valid type.!')",
            "def getAction(self, k: int, action: np.ndarray, playType='train'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if playType == 'train':\n        if self.players[k].compType == 'srdqn':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            self.players[k].action[action] = 1\n        elif self.players[k].compType == 'Strm':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, round(self.players[k].AO[self.curTime] + self.players[k].alpha_b * (self.players[k].IL - self.players[k].a_b) + self.players[k].betta_b * (self.players[k].OO - self.players[k].b_b)))))] = 1\n        elif self.players[k].compType == 'rnd':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            a = np.random.randint(self.config.actionListLen)\n            self.players[k].action[a] = 1\n        elif self.players[k].compType == 'bs':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            if self.config.demandDistribution == 2:\n                if self.curTime and self.config.use_initial_BS <= 4:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].int_bslBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n                else:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n            else:\n                self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n    elif playType == 'test':\n        if self.players[k].compTypeTest == 'srdqn':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            self.players[k].action = self.players[k].brain.getDNNAction(self.playType)\n        elif self.players[k].compTypeTest == 'Strm':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, round(self.players[k].AO[self.curTime] + self.players[k].alpha_b * (self.players[k].IL - self.players[k].a_b) + self.players[k].betta_b * (self.players[k].OO - self.players[k].b_b)))))] = 1\n        elif self.players[k].compTypeTest == 'rnd':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            a = np.random.randint(self.config.actionListLen)\n            self.players[k].action[a] = 1\n        elif self.players[k].compTypeTest == 'bs':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            if self.config.demandDistribution == 2:\n                if self.curTime and self.config.use_initial_BS <= 4:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].int_bslBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n                else:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n            else:\n                self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n    else:\n        raise Exception('The player type is not defined or it is not a valid type.!')",
            "def getAction(self, k: int, action: np.ndarray, playType='train'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if playType == 'train':\n        if self.players[k].compType == 'srdqn':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            self.players[k].action[action] = 1\n        elif self.players[k].compType == 'Strm':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, round(self.players[k].AO[self.curTime] + self.players[k].alpha_b * (self.players[k].IL - self.players[k].a_b) + self.players[k].betta_b * (self.players[k].OO - self.players[k].b_b)))))] = 1\n        elif self.players[k].compType == 'rnd':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            a = np.random.randint(self.config.actionListLen)\n            self.players[k].action[a] = 1\n        elif self.players[k].compType == 'bs':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            if self.config.demandDistribution == 2:\n                if self.curTime and self.config.use_initial_BS <= 4:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].int_bslBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n                else:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n            else:\n                self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n    elif playType == 'test':\n        if self.players[k].compTypeTest == 'srdqn':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            self.players[k].action = self.players[k].brain.getDNNAction(self.playType)\n        elif self.players[k].compTypeTest == 'Strm':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, round(self.players[k].AO[self.curTime] + self.players[k].alpha_b * (self.players[k].IL - self.players[k].a_b) + self.players[k].betta_b * (self.players[k].OO - self.players[k].b_b)))))] = 1\n        elif self.players[k].compTypeTest == 'rnd':\n            self.players[k].action = np.zeros(self.config.actionListLen)\n            a = np.random.randint(self.config.actionListLen)\n            self.players[k].action[a] = 1\n        elif self.players[k].compTypeTest == 'bs':\n            self.players[k].action = np.zeros(self.config.actionListLenOpt)\n            if self.config.demandDistribution == 2:\n                if self.curTime and self.config.use_initial_BS <= 4:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].int_bslBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n                else:\n                    self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n            else:\n                self.players[k].action[np.argmin(np.abs(np.array(self.config.actionListOpt) - max(0, self.players[k].bsBaseStock - (self.players[k].IL + self.players[k].OO - self.players[k].AO[self.curTime]))))] = 1\n    else:\n        raise Exception('The player type is not defined or it is not a valid type.!')"
        ]
    },
    {
        "func_name": "next",
        "original": "def next(self):\n    leadTimeIn = randint(self.config.leadRecItemLow[self.config.NoAgent - 1], self.config.leadRecItemUp[self.config.NoAgent - 1])\n    self.players[self.config.NoAgent - 1].AS[self.curTime + leadTimeIn] += self.players[self.config.NoAgent - 1].actionValue(self.curTime)\n    for k in range(self.config.NoAgent - 1, -1, -1):\n        current_IL = max(0, self.players[k].IL)\n        current_backorder = max(0, -self.players[k].IL)\n        self.players[k].recieveItems(self.curTime)\n        possible_shipment = min(current_IL + self.players[k].AS[self.curTime], current_backorder + self.players[k].AO[self.curTime])\n        if self.players[k].agentNum > 0:\n            leadTimeIn = randint(self.config.leadRecItemLow[k - 1], self.config.leadRecItemUp[k - 1])\n            self.players[k - 1].AS[self.curTime + leadTimeIn] += possible_shipment\n        self.players[k].IL -= self.players[k].AO[self.curTime]\n        self.players[k].getReward()\n        self.players[k].hist[-1][-2] = self.players[k].curReward\n        self.players[k].hist2[-1][-2] = self.players[k].curReward\n        self.players[k].nextObservation = self.players[k].getCurState(self.curTime + 1)\n    if self.config.ifUseTotalReward:\n        if self.curTime == self.T:\n            self.getTotRew()\n    self.curTime += 1",
        "mutated": [
            "def next(self):\n    if False:\n        i = 10\n    leadTimeIn = randint(self.config.leadRecItemLow[self.config.NoAgent - 1], self.config.leadRecItemUp[self.config.NoAgent - 1])\n    self.players[self.config.NoAgent - 1].AS[self.curTime + leadTimeIn] += self.players[self.config.NoAgent - 1].actionValue(self.curTime)\n    for k in range(self.config.NoAgent - 1, -1, -1):\n        current_IL = max(0, self.players[k].IL)\n        current_backorder = max(0, -self.players[k].IL)\n        self.players[k].recieveItems(self.curTime)\n        possible_shipment = min(current_IL + self.players[k].AS[self.curTime], current_backorder + self.players[k].AO[self.curTime])\n        if self.players[k].agentNum > 0:\n            leadTimeIn = randint(self.config.leadRecItemLow[k - 1], self.config.leadRecItemUp[k - 1])\n            self.players[k - 1].AS[self.curTime + leadTimeIn] += possible_shipment\n        self.players[k].IL -= self.players[k].AO[self.curTime]\n        self.players[k].getReward()\n        self.players[k].hist[-1][-2] = self.players[k].curReward\n        self.players[k].hist2[-1][-2] = self.players[k].curReward\n        self.players[k].nextObservation = self.players[k].getCurState(self.curTime + 1)\n    if self.config.ifUseTotalReward:\n        if self.curTime == self.T:\n            self.getTotRew()\n    self.curTime += 1",
            "def next(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    leadTimeIn = randint(self.config.leadRecItemLow[self.config.NoAgent - 1], self.config.leadRecItemUp[self.config.NoAgent - 1])\n    self.players[self.config.NoAgent - 1].AS[self.curTime + leadTimeIn] += self.players[self.config.NoAgent - 1].actionValue(self.curTime)\n    for k in range(self.config.NoAgent - 1, -1, -1):\n        current_IL = max(0, self.players[k].IL)\n        current_backorder = max(0, -self.players[k].IL)\n        self.players[k].recieveItems(self.curTime)\n        possible_shipment = min(current_IL + self.players[k].AS[self.curTime], current_backorder + self.players[k].AO[self.curTime])\n        if self.players[k].agentNum > 0:\n            leadTimeIn = randint(self.config.leadRecItemLow[k - 1], self.config.leadRecItemUp[k - 1])\n            self.players[k - 1].AS[self.curTime + leadTimeIn] += possible_shipment\n        self.players[k].IL -= self.players[k].AO[self.curTime]\n        self.players[k].getReward()\n        self.players[k].hist[-1][-2] = self.players[k].curReward\n        self.players[k].hist2[-1][-2] = self.players[k].curReward\n        self.players[k].nextObservation = self.players[k].getCurState(self.curTime + 1)\n    if self.config.ifUseTotalReward:\n        if self.curTime == self.T:\n            self.getTotRew()\n    self.curTime += 1",
            "def next(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    leadTimeIn = randint(self.config.leadRecItemLow[self.config.NoAgent - 1], self.config.leadRecItemUp[self.config.NoAgent - 1])\n    self.players[self.config.NoAgent - 1].AS[self.curTime + leadTimeIn] += self.players[self.config.NoAgent - 1].actionValue(self.curTime)\n    for k in range(self.config.NoAgent - 1, -1, -1):\n        current_IL = max(0, self.players[k].IL)\n        current_backorder = max(0, -self.players[k].IL)\n        self.players[k].recieveItems(self.curTime)\n        possible_shipment = min(current_IL + self.players[k].AS[self.curTime], current_backorder + self.players[k].AO[self.curTime])\n        if self.players[k].agentNum > 0:\n            leadTimeIn = randint(self.config.leadRecItemLow[k - 1], self.config.leadRecItemUp[k - 1])\n            self.players[k - 1].AS[self.curTime + leadTimeIn] += possible_shipment\n        self.players[k].IL -= self.players[k].AO[self.curTime]\n        self.players[k].getReward()\n        self.players[k].hist[-1][-2] = self.players[k].curReward\n        self.players[k].hist2[-1][-2] = self.players[k].curReward\n        self.players[k].nextObservation = self.players[k].getCurState(self.curTime + 1)\n    if self.config.ifUseTotalReward:\n        if self.curTime == self.T:\n            self.getTotRew()\n    self.curTime += 1",
            "def next(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    leadTimeIn = randint(self.config.leadRecItemLow[self.config.NoAgent - 1], self.config.leadRecItemUp[self.config.NoAgent - 1])\n    self.players[self.config.NoAgent - 1].AS[self.curTime + leadTimeIn] += self.players[self.config.NoAgent - 1].actionValue(self.curTime)\n    for k in range(self.config.NoAgent - 1, -1, -1):\n        current_IL = max(0, self.players[k].IL)\n        current_backorder = max(0, -self.players[k].IL)\n        self.players[k].recieveItems(self.curTime)\n        possible_shipment = min(current_IL + self.players[k].AS[self.curTime], current_backorder + self.players[k].AO[self.curTime])\n        if self.players[k].agentNum > 0:\n            leadTimeIn = randint(self.config.leadRecItemLow[k - 1], self.config.leadRecItemUp[k - 1])\n            self.players[k - 1].AS[self.curTime + leadTimeIn] += possible_shipment\n        self.players[k].IL -= self.players[k].AO[self.curTime]\n        self.players[k].getReward()\n        self.players[k].hist[-1][-2] = self.players[k].curReward\n        self.players[k].hist2[-1][-2] = self.players[k].curReward\n        self.players[k].nextObservation = self.players[k].getCurState(self.curTime + 1)\n    if self.config.ifUseTotalReward:\n        if self.curTime == self.T:\n            self.getTotRew()\n    self.curTime += 1",
            "def next(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    leadTimeIn = randint(self.config.leadRecItemLow[self.config.NoAgent - 1], self.config.leadRecItemUp[self.config.NoAgent - 1])\n    self.players[self.config.NoAgent - 1].AS[self.curTime + leadTimeIn] += self.players[self.config.NoAgent - 1].actionValue(self.curTime)\n    for k in range(self.config.NoAgent - 1, -1, -1):\n        current_IL = max(0, self.players[k].IL)\n        current_backorder = max(0, -self.players[k].IL)\n        self.players[k].recieveItems(self.curTime)\n        possible_shipment = min(current_IL + self.players[k].AS[self.curTime], current_backorder + self.players[k].AO[self.curTime])\n        if self.players[k].agentNum > 0:\n            leadTimeIn = randint(self.config.leadRecItemLow[k - 1], self.config.leadRecItemUp[k - 1])\n            self.players[k - 1].AS[self.curTime + leadTimeIn] += possible_shipment\n        self.players[k].IL -= self.players[k].AO[self.curTime]\n        self.players[k].getReward()\n        self.players[k].hist[-1][-2] = self.players[k].curReward\n        self.players[k].hist2[-1][-2] = self.players[k].curReward\n        self.players[k].nextObservation = self.players[k].getCurState(self.curTime + 1)\n    if self.config.ifUseTotalReward:\n        if self.curTime == self.T:\n            self.getTotRew()\n    self.curTime += 1"
        ]
    },
    {
        "func_name": "handelAction",
        "original": "def handelAction(self, action: np.ndarray, playType='train'):\n    leadTime = randint(self.config.leadRecOrderLow[0], self.config.leadRecOrderUp[0])\n    self.players[0].AO[self.curTime] += self.demand[self.curTime]\n    for k in range(0, self.config.NoAgent):\n        self.getAction(k, action, playType)\n        self.players[k].srdqnBaseStock += [self.players[k].actionValue(self.curTime) + self.players[k].IL + self.players[k].OO]\n        self.players[k].hist += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].actionValue(self.curTime), self.players[k].curReward, self.players[k].srdqnBaseStock[-1]]]\n        if self.players[k].compType == 'srdqn':\n            self.players[k].hist2 += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].AO[self.curTime], self.players[k].AS[self.curTime], self.players[k].actionValue(self.curTime), self.players[k].curReward, self.config.actionList[np.argmax(self.players[k].action)]]]\n        else:\n            self.players[k].hist2 += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].AO[self.curTime], self.players[k].AS[self.curTime], self.players[k].actionValue(self.curTime), self.players[k].curReward, 0]]\n        self.players[k].OO += self.players[k].actionValue(self.curTime)\n        leadTime = randint(self.config.leadRecOrderLow[k], self.config.leadRecOrderUp[k])\n        if self.players[k].agentNum < self.config.NoAgent - 1:\n            self.players[k + 1].AO[self.curTime + leadTime] += self.players[k].actionValue(self.curTime)",
        "mutated": [
            "def handelAction(self, action: np.ndarray, playType='train'):\n    if False:\n        i = 10\n    leadTime = randint(self.config.leadRecOrderLow[0], self.config.leadRecOrderUp[0])\n    self.players[0].AO[self.curTime] += self.demand[self.curTime]\n    for k in range(0, self.config.NoAgent):\n        self.getAction(k, action, playType)\n        self.players[k].srdqnBaseStock += [self.players[k].actionValue(self.curTime) + self.players[k].IL + self.players[k].OO]\n        self.players[k].hist += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].actionValue(self.curTime), self.players[k].curReward, self.players[k].srdqnBaseStock[-1]]]\n        if self.players[k].compType == 'srdqn':\n            self.players[k].hist2 += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].AO[self.curTime], self.players[k].AS[self.curTime], self.players[k].actionValue(self.curTime), self.players[k].curReward, self.config.actionList[np.argmax(self.players[k].action)]]]\n        else:\n            self.players[k].hist2 += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].AO[self.curTime], self.players[k].AS[self.curTime], self.players[k].actionValue(self.curTime), self.players[k].curReward, 0]]\n        self.players[k].OO += self.players[k].actionValue(self.curTime)\n        leadTime = randint(self.config.leadRecOrderLow[k], self.config.leadRecOrderUp[k])\n        if self.players[k].agentNum < self.config.NoAgent - 1:\n            self.players[k + 1].AO[self.curTime + leadTime] += self.players[k].actionValue(self.curTime)",
            "def handelAction(self, action: np.ndarray, playType='train'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    leadTime = randint(self.config.leadRecOrderLow[0], self.config.leadRecOrderUp[0])\n    self.players[0].AO[self.curTime] += self.demand[self.curTime]\n    for k in range(0, self.config.NoAgent):\n        self.getAction(k, action, playType)\n        self.players[k].srdqnBaseStock += [self.players[k].actionValue(self.curTime) + self.players[k].IL + self.players[k].OO]\n        self.players[k].hist += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].actionValue(self.curTime), self.players[k].curReward, self.players[k].srdqnBaseStock[-1]]]\n        if self.players[k].compType == 'srdqn':\n            self.players[k].hist2 += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].AO[self.curTime], self.players[k].AS[self.curTime], self.players[k].actionValue(self.curTime), self.players[k].curReward, self.config.actionList[np.argmax(self.players[k].action)]]]\n        else:\n            self.players[k].hist2 += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].AO[self.curTime], self.players[k].AS[self.curTime], self.players[k].actionValue(self.curTime), self.players[k].curReward, 0]]\n        self.players[k].OO += self.players[k].actionValue(self.curTime)\n        leadTime = randint(self.config.leadRecOrderLow[k], self.config.leadRecOrderUp[k])\n        if self.players[k].agentNum < self.config.NoAgent - 1:\n            self.players[k + 1].AO[self.curTime + leadTime] += self.players[k].actionValue(self.curTime)",
            "def handelAction(self, action: np.ndarray, playType='train'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    leadTime = randint(self.config.leadRecOrderLow[0], self.config.leadRecOrderUp[0])\n    self.players[0].AO[self.curTime] += self.demand[self.curTime]\n    for k in range(0, self.config.NoAgent):\n        self.getAction(k, action, playType)\n        self.players[k].srdqnBaseStock += [self.players[k].actionValue(self.curTime) + self.players[k].IL + self.players[k].OO]\n        self.players[k].hist += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].actionValue(self.curTime), self.players[k].curReward, self.players[k].srdqnBaseStock[-1]]]\n        if self.players[k].compType == 'srdqn':\n            self.players[k].hist2 += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].AO[self.curTime], self.players[k].AS[self.curTime], self.players[k].actionValue(self.curTime), self.players[k].curReward, self.config.actionList[np.argmax(self.players[k].action)]]]\n        else:\n            self.players[k].hist2 += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].AO[self.curTime], self.players[k].AS[self.curTime], self.players[k].actionValue(self.curTime), self.players[k].curReward, 0]]\n        self.players[k].OO += self.players[k].actionValue(self.curTime)\n        leadTime = randint(self.config.leadRecOrderLow[k], self.config.leadRecOrderUp[k])\n        if self.players[k].agentNum < self.config.NoAgent - 1:\n            self.players[k + 1].AO[self.curTime + leadTime] += self.players[k].actionValue(self.curTime)",
            "def handelAction(self, action: np.ndarray, playType='train'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    leadTime = randint(self.config.leadRecOrderLow[0], self.config.leadRecOrderUp[0])\n    self.players[0].AO[self.curTime] += self.demand[self.curTime]\n    for k in range(0, self.config.NoAgent):\n        self.getAction(k, action, playType)\n        self.players[k].srdqnBaseStock += [self.players[k].actionValue(self.curTime) + self.players[k].IL + self.players[k].OO]\n        self.players[k].hist += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].actionValue(self.curTime), self.players[k].curReward, self.players[k].srdqnBaseStock[-1]]]\n        if self.players[k].compType == 'srdqn':\n            self.players[k].hist2 += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].AO[self.curTime], self.players[k].AS[self.curTime], self.players[k].actionValue(self.curTime), self.players[k].curReward, self.config.actionList[np.argmax(self.players[k].action)]]]\n        else:\n            self.players[k].hist2 += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].AO[self.curTime], self.players[k].AS[self.curTime], self.players[k].actionValue(self.curTime), self.players[k].curReward, 0]]\n        self.players[k].OO += self.players[k].actionValue(self.curTime)\n        leadTime = randint(self.config.leadRecOrderLow[k], self.config.leadRecOrderUp[k])\n        if self.players[k].agentNum < self.config.NoAgent - 1:\n            self.players[k + 1].AO[self.curTime + leadTime] += self.players[k].actionValue(self.curTime)",
            "def handelAction(self, action: np.ndarray, playType='train'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    leadTime = randint(self.config.leadRecOrderLow[0], self.config.leadRecOrderUp[0])\n    self.players[0].AO[self.curTime] += self.demand[self.curTime]\n    for k in range(0, self.config.NoAgent):\n        self.getAction(k, action, playType)\n        self.players[k].srdqnBaseStock += [self.players[k].actionValue(self.curTime) + self.players[k].IL + self.players[k].OO]\n        self.players[k].hist += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].actionValue(self.curTime), self.players[k].curReward, self.players[k].srdqnBaseStock[-1]]]\n        if self.players[k].compType == 'srdqn':\n            self.players[k].hist2 += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].AO[self.curTime], self.players[k].AS[self.curTime], self.players[k].actionValue(self.curTime), self.players[k].curReward, self.config.actionList[np.argmax(self.players[k].action)]]]\n        else:\n            self.players[k].hist2 += [[self.curTime, self.players[k].IL, self.players[k].OO, self.players[k].AO[self.curTime], self.players[k].AS[self.curTime], self.players[k].actionValue(self.curTime), self.players[k].curReward, 0]]\n        self.players[k].OO += self.players[k].actionValue(self.curTime)\n        leadTime = randint(self.config.leadRecOrderLow[k], self.config.leadRecOrderUp[k])\n        if self.players[k].agentNum < self.config.NoAgent - 1:\n            self.players[k + 1].AO[self.curTime + leadTime] += self.players[k].actionValue(self.curTime)"
        ]
    },
    {
        "func_name": "getOptimalSol",
        "original": "def getOptimalSol(self):\n    if self.config.NoAgent != 1 and 1 == 2:\n        for k in range(self.config.NoAgent - 1):\n            if not (self.players[k].c_h == self.players[k + 1].c_h and self.players[k + 1].c_p == 0):\n                self.ifOptimalSolExist = False\n        if self.ifOptimalSolExist == True:\n            calculations = np.zeros((7, self.config.NoAgent))\n            for k in range(self.config.NoAgent):\n                calculations[0][k] = ((self.config.leadRecItemLow + self.config.leadRecItemUp + 2) / 2 + (self.config.leadRecOrderLow + self.config.leadRecOrderUp + 2) / 2) * (self.config.demandUp - self.config.demandLow - 1)\n                if k > 0:\n                    calculations[0][k] += calculations[0][k - 1]\n                nominator_ch = 0\n                low_denominator_ch = 0\n                for j in range(k, self.config.NoAgent):\n                    if j < self.config.NoAgent - 1:\n                        nominator_ch += self.players[j + 1].c_h\n                    low_denominator_ch += self.players[j].c_h\n                if k == 0:\n                    high_denominator_ch = low_denominator_ch\n                calculations[2][k] = (self.players[0].c_p + nominator_ch) / (self.players[0].c_p + low_denominator_ch + 0.0)\n                calculations[3][k] = (self.players[0].c_p + nominator_ch) / (self.players[0].c_p + high_denominator_ch + 0.0)\n            calculations[4] = np.round(np.multiply(calculations[0], calculations[2]))\n            calculations[5] = np.round(np.multiply(calculations[0], calculations[3]))\n            calculations[6] = np.round(np.mean(calculations[4:6], axis=0))\n            for k in range(self.config.NoAgent):\n                if k == 0:\n                    self.players[k].bsBaseStock = calculations[6][k]\n                else:\n                    self.players[k].bsBaseStock = calculations[6][k] - calculations[6][k - 1]\n                    if self.players[k].bsBaseStock < 0:\n                        self.players[k].bsBaseStock = 0\n    elif self.config.NoAgent == 1:\n        if self.config.demandDistribution == 0:\n            self.players[0].bsBaseStock = np.ceil(self.config.c_h[0] / (self.config.c_h[0] + self.config.c_p[0] + 0.0)) * ((self.config.demandUp - self.config.demandLow - 1) / 2) * self.config.leadRecItemUp\n    elif 1 == 1:\n        f = self.config.f\n        f_init = self.config.f_init\n        for k in range(self.config.NoAgent):\n            self.players[k].bsBaseStock = f[k]\n            self.players[k].int_bslBaseStock = f_init[k]",
        "mutated": [
            "def getOptimalSol(self):\n    if False:\n        i = 10\n    if self.config.NoAgent != 1 and 1 == 2:\n        for k in range(self.config.NoAgent - 1):\n            if not (self.players[k].c_h == self.players[k + 1].c_h and self.players[k + 1].c_p == 0):\n                self.ifOptimalSolExist = False\n        if self.ifOptimalSolExist == True:\n            calculations = np.zeros((7, self.config.NoAgent))\n            for k in range(self.config.NoAgent):\n                calculations[0][k] = ((self.config.leadRecItemLow + self.config.leadRecItemUp + 2) / 2 + (self.config.leadRecOrderLow + self.config.leadRecOrderUp + 2) / 2) * (self.config.demandUp - self.config.demandLow - 1)\n                if k > 0:\n                    calculations[0][k] += calculations[0][k - 1]\n                nominator_ch = 0\n                low_denominator_ch = 0\n                for j in range(k, self.config.NoAgent):\n                    if j < self.config.NoAgent - 1:\n                        nominator_ch += self.players[j + 1].c_h\n                    low_denominator_ch += self.players[j].c_h\n                if k == 0:\n                    high_denominator_ch = low_denominator_ch\n                calculations[2][k] = (self.players[0].c_p + nominator_ch) / (self.players[0].c_p + low_denominator_ch + 0.0)\n                calculations[3][k] = (self.players[0].c_p + nominator_ch) / (self.players[0].c_p + high_denominator_ch + 0.0)\n            calculations[4] = np.round(np.multiply(calculations[0], calculations[2]))\n            calculations[5] = np.round(np.multiply(calculations[0], calculations[3]))\n            calculations[6] = np.round(np.mean(calculations[4:6], axis=0))\n            for k in range(self.config.NoAgent):\n                if k == 0:\n                    self.players[k].bsBaseStock = calculations[6][k]\n                else:\n                    self.players[k].bsBaseStock = calculations[6][k] - calculations[6][k - 1]\n                    if self.players[k].bsBaseStock < 0:\n                        self.players[k].bsBaseStock = 0\n    elif self.config.NoAgent == 1:\n        if self.config.demandDistribution == 0:\n            self.players[0].bsBaseStock = np.ceil(self.config.c_h[0] / (self.config.c_h[0] + self.config.c_p[0] + 0.0)) * ((self.config.demandUp - self.config.demandLow - 1) / 2) * self.config.leadRecItemUp\n    elif 1 == 1:\n        f = self.config.f\n        f_init = self.config.f_init\n        for k in range(self.config.NoAgent):\n            self.players[k].bsBaseStock = f[k]\n            self.players[k].int_bslBaseStock = f_init[k]",
            "def getOptimalSol(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if self.config.NoAgent != 1 and 1 == 2:\n        for k in range(self.config.NoAgent - 1):\n            if not (self.players[k].c_h == self.players[k + 1].c_h and self.players[k + 1].c_p == 0):\n                self.ifOptimalSolExist = False\n        if self.ifOptimalSolExist == True:\n            calculations = np.zeros((7, self.config.NoAgent))\n            for k in range(self.config.NoAgent):\n                calculations[0][k] = ((self.config.leadRecItemLow + self.config.leadRecItemUp + 2) / 2 + (self.config.leadRecOrderLow + self.config.leadRecOrderUp + 2) / 2) * (self.config.demandUp - self.config.demandLow - 1)\n                if k > 0:\n                    calculations[0][k] += calculations[0][k - 1]\n                nominator_ch = 0\n                low_denominator_ch = 0\n                for j in range(k, self.config.NoAgent):\n                    if j < self.config.NoAgent - 1:\n                        nominator_ch += self.players[j + 1].c_h\n                    low_denominator_ch += self.players[j].c_h\n                if k == 0:\n                    high_denominator_ch = low_denominator_ch\n                calculations[2][k] = (self.players[0].c_p + nominator_ch) / (self.players[0].c_p + low_denominator_ch + 0.0)\n                calculations[3][k] = (self.players[0].c_p + nominator_ch) / (self.players[0].c_p + high_denominator_ch + 0.0)\n            calculations[4] = np.round(np.multiply(calculations[0], calculations[2]))\n            calculations[5] = np.round(np.multiply(calculations[0], calculations[3]))\n            calculations[6] = np.round(np.mean(calculations[4:6], axis=0))\n            for k in range(self.config.NoAgent):\n                if k == 0:\n                    self.players[k].bsBaseStock = calculations[6][k]\n                else:\n                    self.players[k].bsBaseStock = calculations[6][k] - calculations[6][k - 1]\n                    if self.players[k].bsBaseStock < 0:\n                        self.players[k].bsBaseStock = 0\n    elif self.config.NoAgent == 1:\n        if self.config.demandDistribution == 0:\n            self.players[0].bsBaseStock = np.ceil(self.config.c_h[0] / (self.config.c_h[0] + self.config.c_p[0] + 0.0)) * ((self.config.demandUp - self.config.demandLow - 1) / 2) * self.config.leadRecItemUp\n    elif 1 == 1:\n        f = self.config.f\n        f_init = self.config.f_init\n        for k in range(self.config.NoAgent):\n            self.players[k].bsBaseStock = f[k]\n            self.players[k].int_bslBaseStock = f_init[k]",
            "def getOptimalSol(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if self.config.NoAgent != 1 and 1 == 2:\n        for k in range(self.config.NoAgent - 1):\n            if not (self.players[k].c_h == self.players[k + 1].c_h and self.players[k + 1].c_p == 0):\n                self.ifOptimalSolExist = False\n        if self.ifOptimalSolExist == True:\n            calculations = np.zeros((7, self.config.NoAgent))\n            for k in range(self.config.NoAgent):\n                calculations[0][k] = ((self.config.leadRecItemLow + self.config.leadRecItemUp + 2) / 2 + (self.config.leadRecOrderLow + self.config.leadRecOrderUp + 2) / 2) * (self.config.demandUp - self.config.demandLow - 1)\n                if k > 0:\n                    calculations[0][k] += calculations[0][k - 1]\n                nominator_ch = 0\n                low_denominator_ch = 0\n                for j in range(k, self.config.NoAgent):\n                    if j < self.config.NoAgent - 1:\n                        nominator_ch += self.players[j + 1].c_h\n                    low_denominator_ch += self.players[j].c_h\n                if k == 0:\n                    high_denominator_ch = low_denominator_ch\n                calculations[2][k] = (self.players[0].c_p + nominator_ch) / (self.players[0].c_p + low_denominator_ch + 0.0)\n                calculations[3][k] = (self.players[0].c_p + nominator_ch) / (self.players[0].c_p + high_denominator_ch + 0.0)\n            calculations[4] = np.round(np.multiply(calculations[0], calculations[2]))\n            calculations[5] = np.round(np.multiply(calculations[0], calculations[3]))\n            calculations[6] = np.round(np.mean(calculations[4:6], axis=0))\n            for k in range(self.config.NoAgent):\n                if k == 0:\n                    self.players[k].bsBaseStock = calculations[6][k]\n                else:\n                    self.players[k].bsBaseStock = calculations[6][k] - calculations[6][k - 1]\n                    if self.players[k].bsBaseStock < 0:\n                        self.players[k].bsBaseStock = 0\n    elif self.config.NoAgent == 1:\n        if self.config.demandDistribution == 0:\n            self.players[0].bsBaseStock = np.ceil(self.config.c_h[0] / (self.config.c_h[0] + self.config.c_p[0] + 0.0)) * ((self.config.demandUp - self.config.demandLow - 1) / 2) * self.config.leadRecItemUp\n    elif 1 == 1:\n        f = self.config.f\n        f_init = self.config.f_init\n        for k in range(self.config.NoAgent):\n            self.players[k].bsBaseStock = f[k]\n            self.players[k].int_bslBaseStock = f_init[k]",
            "def getOptimalSol(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if self.config.NoAgent != 1 and 1 == 2:\n        for k in range(self.config.NoAgent - 1):\n            if not (self.players[k].c_h == self.players[k + 1].c_h and self.players[k + 1].c_p == 0):\n                self.ifOptimalSolExist = False\n        if self.ifOptimalSolExist == True:\n            calculations = np.zeros((7, self.config.NoAgent))\n            for k in range(self.config.NoAgent):\n                calculations[0][k] = ((self.config.leadRecItemLow + self.config.leadRecItemUp + 2) / 2 + (self.config.leadRecOrderLow + self.config.leadRecOrderUp + 2) / 2) * (self.config.demandUp - self.config.demandLow - 1)\n                if k > 0:\n                    calculations[0][k] += calculations[0][k - 1]\n                nominator_ch = 0\n                low_denominator_ch = 0\n                for j in range(k, self.config.NoAgent):\n                    if j < self.config.NoAgent - 1:\n                        nominator_ch += self.players[j + 1].c_h\n                    low_denominator_ch += self.players[j].c_h\n                if k == 0:\n                    high_denominator_ch = low_denominator_ch\n                calculations[2][k] = (self.players[0].c_p + nominator_ch) / (self.players[0].c_p + low_denominator_ch + 0.0)\n                calculations[3][k] = (self.players[0].c_p + nominator_ch) / (self.players[0].c_p + high_denominator_ch + 0.0)\n            calculations[4] = np.round(np.multiply(calculations[0], calculations[2]))\n            calculations[5] = np.round(np.multiply(calculations[0], calculations[3]))\n            calculations[6] = np.round(np.mean(calculations[4:6], axis=0))\n            for k in range(self.config.NoAgent):\n                if k == 0:\n                    self.players[k].bsBaseStock = calculations[6][k]\n                else:\n                    self.players[k].bsBaseStock = calculations[6][k] - calculations[6][k - 1]\n                    if self.players[k].bsBaseStock < 0:\n                        self.players[k].bsBaseStock = 0\n    elif self.config.NoAgent == 1:\n        if self.config.demandDistribution == 0:\n            self.players[0].bsBaseStock = np.ceil(self.config.c_h[0] / (self.config.c_h[0] + self.config.c_p[0] + 0.0)) * ((self.config.demandUp - self.config.demandLow - 1) / 2) * self.config.leadRecItemUp\n    elif 1 == 1:\n        f = self.config.f\n        f_init = self.config.f_init\n        for k in range(self.config.NoAgent):\n            self.players[k].bsBaseStock = f[k]\n            self.players[k].int_bslBaseStock = f_init[k]",
            "def getOptimalSol(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if self.config.NoAgent != 1 and 1 == 2:\n        for k in range(self.config.NoAgent - 1):\n            if not (self.players[k].c_h == self.players[k + 1].c_h and self.players[k + 1].c_p == 0):\n                self.ifOptimalSolExist = False\n        if self.ifOptimalSolExist == True:\n            calculations = np.zeros((7, self.config.NoAgent))\n            for k in range(self.config.NoAgent):\n                calculations[0][k] = ((self.config.leadRecItemLow + self.config.leadRecItemUp + 2) / 2 + (self.config.leadRecOrderLow + self.config.leadRecOrderUp + 2) / 2) * (self.config.demandUp - self.config.demandLow - 1)\n                if k > 0:\n                    calculations[0][k] += calculations[0][k - 1]\n                nominator_ch = 0\n                low_denominator_ch = 0\n                for j in range(k, self.config.NoAgent):\n                    if j < self.config.NoAgent - 1:\n                        nominator_ch += self.players[j + 1].c_h\n                    low_denominator_ch += self.players[j].c_h\n                if k == 0:\n                    high_denominator_ch = low_denominator_ch\n                calculations[2][k] = (self.players[0].c_p + nominator_ch) / (self.players[0].c_p + low_denominator_ch + 0.0)\n                calculations[3][k] = (self.players[0].c_p + nominator_ch) / (self.players[0].c_p + high_denominator_ch + 0.0)\n            calculations[4] = np.round(np.multiply(calculations[0], calculations[2]))\n            calculations[5] = np.round(np.multiply(calculations[0], calculations[3]))\n            calculations[6] = np.round(np.mean(calculations[4:6], axis=0))\n            for k in range(self.config.NoAgent):\n                if k == 0:\n                    self.players[k].bsBaseStock = calculations[6][k]\n                else:\n                    self.players[k].bsBaseStock = calculations[6][k] - calculations[6][k - 1]\n                    if self.players[k].bsBaseStock < 0:\n                        self.players[k].bsBaseStock = 0\n    elif self.config.NoAgent == 1:\n        if self.config.demandDistribution == 0:\n            self.players[0].bsBaseStock = np.ceil(self.config.c_h[0] / (self.config.c_h[0] + self.config.c_p[0] + 0.0)) * ((self.config.demandUp - self.config.demandLow - 1) / 2) * self.config.leadRecItemUp\n    elif 1 == 1:\n        f = self.config.f\n        f_init = self.config.f_init\n        for k in range(self.config.NoAgent):\n            self.players[k].bsBaseStock = f[k]\n            self.players[k].int_bslBaseStock = f_init[k]"
        ]
    },
    {
        "func_name": "update_OO",
        "original": "def update_OO(self):\n    for k in range(0, self.config.NoAgent):\n        if k < self.config.NoAgent - 1:\n            self.players[k].OO = sum(self.players[k + 1].AO) + sum(self.players[k].AS)\n        else:\n            self.players[k].OO = sum(self.players[k].AS)",
        "mutated": [
            "def update_OO(self):\n    if False:\n        i = 10\n    for k in range(0, self.config.NoAgent):\n        if k < self.config.NoAgent - 1:\n            self.players[k].OO = sum(self.players[k + 1].AO) + sum(self.players[k].AS)\n        else:\n            self.players[k].OO = sum(self.players[k].AS)",
            "def update_OO(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    for k in range(0, self.config.NoAgent):\n        if k < self.config.NoAgent - 1:\n            self.players[k].OO = sum(self.players[k + 1].AO) + sum(self.players[k].AS)\n        else:\n            self.players[k].OO = sum(self.players[k].AS)",
            "def update_OO(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    for k in range(0, self.config.NoAgent):\n        if k < self.config.NoAgent - 1:\n            self.players[k].OO = sum(self.players[k + 1].AO) + sum(self.players[k].AS)\n        else:\n            self.players[k].OO = sum(self.players[k].AS)",
            "def update_OO(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    for k in range(0, self.config.NoAgent):\n        if k < self.config.NoAgent - 1:\n            self.players[k].OO = sum(self.players[k + 1].AO) + sum(self.players[k].AS)\n        else:\n            self.players[k].OO = sum(self.players[k].AS)",
            "def update_OO(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    for k in range(0, self.config.NoAgent):\n        if k < self.config.NoAgent - 1:\n            self.players[k].OO = sum(self.players[k + 1].AO) + sum(self.players[k].AS)\n        else:\n            self.players[k].OO = sum(self.players[k].AS)"
        ]
    },
    {
        "func_name": "doTestMid",
        "original": "def doTestMid(self, demandTs):\n    self.resultTest = []\n    m = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n    self.doTest(m, demandTs)\n    print('---------------------------------------------------------------------------------------')\n    resultSummary = np.array(self.resultTest).mean(axis=0).tolist()\n    result_srdqn = ', '.join(map('{:.2f}'.format, resultSummary[0]))\n    result_rand = ', '.join(map('{:.2f}'.format, resultSummary[1]))\n    result_strm = ', '.join(map('{:.2f}'.format, resultSummary[2]))\n    if self.ifOptimalSolExist:\n        result_bs = ', '.join(map('{:.2f}'.format, resultSummary[3]))\n        print('SUMMARY; {0:s}; ITER= {1:d}; OURPOLICY= [{2:s}]; SUM = {3:2.4f}; Rand= [{4:s}]; SUM = {5:2.4f}; STRM= [{6:s}]; SUM = {7:2.4f}; BS= [{8:s}]; SUM = {9:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), self.curGame, result_srdqn, sum(resultSummary[0]), result_rand, sum(resultSummary[1]), result_strm, sum(resultSummary[2]), result_bs, sum(resultSummary[3])))\n    else:\n        print('SUMMARY; {0:s}; ITER= {1:d}; OURPOLICY= [{2:s}]; SUM = {3:2.4f}; Rand= [{4:s}]; SUM = {5:2.4f}; STRM= [{6:s}]; SUM = {7:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), self.curGame, result_srdqn, sum(resultSummary[0]), result_rand, sum(resultSummary[1]), result_strm, sum(resultSummary[2])))\n    print('=======================================================================================')",
        "mutated": [
            "def doTestMid(self, demandTs):\n    if False:\n        i = 10\n    self.resultTest = []\n    m = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n    self.doTest(m, demandTs)\n    print('---------------------------------------------------------------------------------------')\n    resultSummary = np.array(self.resultTest).mean(axis=0).tolist()\n    result_srdqn = ', '.join(map('{:.2f}'.format, resultSummary[0]))\n    result_rand = ', '.join(map('{:.2f}'.format, resultSummary[1]))\n    result_strm = ', '.join(map('{:.2f}'.format, resultSummary[2]))\n    if self.ifOptimalSolExist:\n        result_bs = ', '.join(map('{:.2f}'.format, resultSummary[3]))\n        print('SUMMARY; {0:s}; ITER= {1:d}; OURPOLICY= [{2:s}]; SUM = {3:2.4f}; Rand= [{4:s}]; SUM = {5:2.4f}; STRM= [{6:s}]; SUM = {7:2.4f}; BS= [{8:s}]; SUM = {9:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), self.curGame, result_srdqn, sum(resultSummary[0]), result_rand, sum(resultSummary[1]), result_strm, sum(resultSummary[2]), result_bs, sum(resultSummary[3])))\n    else:\n        print('SUMMARY; {0:s}; ITER= {1:d}; OURPOLICY= [{2:s}]; SUM = {3:2.4f}; Rand= [{4:s}]; SUM = {5:2.4f}; STRM= [{6:s}]; SUM = {7:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), self.curGame, result_srdqn, sum(resultSummary[0]), result_rand, sum(resultSummary[1]), result_strm, sum(resultSummary[2])))\n    print('=======================================================================================')",
            "def doTestMid(self, demandTs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.resultTest = []\n    m = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n    self.doTest(m, demandTs)\n    print('---------------------------------------------------------------------------------------')\n    resultSummary = np.array(self.resultTest).mean(axis=0).tolist()\n    result_srdqn = ', '.join(map('{:.2f}'.format, resultSummary[0]))\n    result_rand = ', '.join(map('{:.2f}'.format, resultSummary[1]))\n    result_strm = ', '.join(map('{:.2f}'.format, resultSummary[2]))\n    if self.ifOptimalSolExist:\n        result_bs = ', '.join(map('{:.2f}'.format, resultSummary[3]))\n        print('SUMMARY; {0:s}; ITER= {1:d}; OURPOLICY= [{2:s}]; SUM = {3:2.4f}; Rand= [{4:s}]; SUM = {5:2.4f}; STRM= [{6:s}]; SUM = {7:2.4f}; BS= [{8:s}]; SUM = {9:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), self.curGame, result_srdqn, sum(resultSummary[0]), result_rand, sum(resultSummary[1]), result_strm, sum(resultSummary[2]), result_bs, sum(resultSummary[3])))\n    else:\n        print('SUMMARY; {0:s}; ITER= {1:d}; OURPOLICY= [{2:s}]; SUM = {3:2.4f}; Rand= [{4:s}]; SUM = {5:2.4f}; STRM= [{6:s}]; SUM = {7:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), self.curGame, result_srdqn, sum(resultSummary[0]), result_rand, sum(resultSummary[1]), result_strm, sum(resultSummary[2])))\n    print('=======================================================================================')",
            "def doTestMid(self, demandTs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.resultTest = []\n    m = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n    self.doTest(m, demandTs)\n    print('---------------------------------------------------------------------------------------')\n    resultSummary = np.array(self.resultTest).mean(axis=0).tolist()\n    result_srdqn = ', '.join(map('{:.2f}'.format, resultSummary[0]))\n    result_rand = ', '.join(map('{:.2f}'.format, resultSummary[1]))\n    result_strm = ', '.join(map('{:.2f}'.format, resultSummary[2]))\n    if self.ifOptimalSolExist:\n        result_bs = ', '.join(map('{:.2f}'.format, resultSummary[3]))\n        print('SUMMARY; {0:s}; ITER= {1:d}; OURPOLICY= [{2:s}]; SUM = {3:2.4f}; Rand= [{4:s}]; SUM = {5:2.4f}; STRM= [{6:s}]; SUM = {7:2.4f}; BS= [{8:s}]; SUM = {9:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), self.curGame, result_srdqn, sum(resultSummary[0]), result_rand, sum(resultSummary[1]), result_strm, sum(resultSummary[2]), result_bs, sum(resultSummary[3])))\n    else:\n        print('SUMMARY; {0:s}; ITER= {1:d}; OURPOLICY= [{2:s}]; SUM = {3:2.4f}; Rand= [{4:s}]; SUM = {5:2.4f}; STRM= [{6:s}]; SUM = {7:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), self.curGame, result_srdqn, sum(resultSummary[0]), result_rand, sum(resultSummary[1]), result_strm, sum(resultSummary[2])))\n    print('=======================================================================================')",
            "def doTestMid(self, demandTs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.resultTest = []\n    m = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n    self.doTest(m, demandTs)\n    print('---------------------------------------------------------------------------------------')\n    resultSummary = np.array(self.resultTest).mean(axis=0).tolist()\n    result_srdqn = ', '.join(map('{:.2f}'.format, resultSummary[0]))\n    result_rand = ', '.join(map('{:.2f}'.format, resultSummary[1]))\n    result_strm = ', '.join(map('{:.2f}'.format, resultSummary[2]))\n    if self.ifOptimalSolExist:\n        result_bs = ', '.join(map('{:.2f}'.format, resultSummary[3]))\n        print('SUMMARY; {0:s}; ITER= {1:d}; OURPOLICY= [{2:s}]; SUM = {3:2.4f}; Rand= [{4:s}]; SUM = {5:2.4f}; STRM= [{6:s}]; SUM = {7:2.4f}; BS= [{8:s}]; SUM = {9:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), self.curGame, result_srdqn, sum(resultSummary[0]), result_rand, sum(resultSummary[1]), result_strm, sum(resultSummary[2]), result_bs, sum(resultSummary[3])))\n    else:\n        print('SUMMARY; {0:s}; ITER= {1:d}; OURPOLICY= [{2:s}]; SUM = {3:2.4f}; Rand= [{4:s}]; SUM = {5:2.4f}; STRM= [{6:s}]; SUM = {7:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), self.curGame, result_srdqn, sum(resultSummary[0]), result_rand, sum(resultSummary[1]), result_strm, sum(resultSummary[2])))\n    print('=======================================================================================')",
            "def doTestMid(self, demandTs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.resultTest = []\n    m = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n    self.doTest(m, demandTs)\n    print('---------------------------------------------------------------------------------------')\n    resultSummary = np.array(self.resultTest).mean(axis=0).tolist()\n    result_srdqn = ', '.join(map('{:.2f}'.format, resultSummary[0]))\n    result_rand = ', '.join(map('{:.2f}'.format, resultSummary[1]))\n    result_strm = ', '.join(map('{:.2f}'.format, resultSummary[2]))\n    if self.ifOptimalSolExist:\n        result_bs = ', '.join(map('{:.2f}'.format, resultSummary[3]))\n        print('SUMMARY; {0:s}; ITER= {1:d}; OURPOLICY= [{2:s}]; SUM = {3:2.4f}; Rand= [{4:s}]; SUM = {5:2.4f}; STRM= [{6:s}]; SUM = {7:2.4f}; BS= [{8:s}]; SUM = {9:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), self.curGame, result_srdqn, sum(resultSummary[0]), result_rand, sum(resultSummary[1]), result_strm, sum(resultSummary[2]), result_bs, sum(resultSummary[3])))\n    else:\n        print('SUMMARY; {0:s}; ITER= {1:d}; OURPOLICY= [{2:s}]; SUM = {3:2.4f}; Rand= [{4:s}]; SUM = {5:2.4f}; STRM= [{6:s}]; SUM = {7:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), self.curGame, result_srdqn, sum(resultSummary[0]), result_rand, sum(resultSummary[1]), result_strm, sum(resultSummary[2])))\n    print('=======================================================================================')"
        ]
    },
    {
        "func_name": "doTest",
        "original": "def doTest(self, m, demand):\n    import matplotlib.pyplot as plt\n    if self.config.ifSaveFigure:\n        plt.figure(self.curGame, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n        (Rsltdnn, plt) = self.tester(self.config.agentTypes, plt, 'b', 'OurPolicy', m)\n        baseStockdata = self.players[0].srdqnBaseStock\n        (RsltRnd, plt) = self.tester(['rnd', 'rnd', 'rnd', 'rnd'], plt, 'y', 'RAND', m)\n        (RsltStrm, plt) = self.tester(['Strm', 'Strm', 'Strm', 'Strm'], plt, 'g', 'Strm', m)\n        if self.ifOptimalSolExist:\n            if self.config.agentTypes == ['srdqn', 'Strm', 'Strm', 'Strm']:\n                (Rsltbs, plt) = self.tester(['bs', 'Strm', 'Strm', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'srdqn', 'Strm', 'Strm']:\n                (Rsltbs, plt) = self.tester(['Strm', 'bs', 'Strm', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'Strm', 'srdqn', 'Strm']:\n                (Rsltbs, plt) = self.tester(['Strm', 'Strm', 'bs', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'Strm', 'Strm', 'srdqn']:\n                (Rsltbs, plt) = self.tester(['Strm', 'Strm', 'Strm', 'bs'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['srdqn', 'rnd', 'rnd', 'rnd']:\n                (Rsltbs, plt) = self.tester(['bs', 'rnd', 'rnd', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'srdqn', 'rnd', 'rnd']:\n                (Rsltbs, plt) = self.tester(['rnd', 'bs', 'rnd', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'rnd', 'srdqn', 'rnd']:\n                (Rsltbs, plt) = self.tester(['rnd', 'rnd', 'bs', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'rnd', 'rnd', 'srdqn']:\n                (Rsltbs, plt) = self.tester(['rnd', 'rnd', 'rnd', 'bs'], plt, 'r', 'RND-BS', m)\n            else:\n                (Rsltbs, plt) = self.tester(['bs', 'bs', 'bs', 'bs'], plt, 'r', 'BS', m)\n            self.middleTestResult += [[RsltRnd, RsltStrm, Rsltbs]]\n        else:\n            self.middleTestResult += [[RsltRnd, RsltStrm]]\n    else:\n        RsltRnd = self.middleTestResult[m][0]\n        RsltStrm = self.middleTestResult[m][1]\n        if self.ifOptimalSolExist:\n            Rsltbs = self.middleTestResult[m][2]\n    if self.config.ifSaveFigure:\n        savePlot(self.players, self.curGame, Rsltdnn, RsltStrm, Rsltbs, RsltRnd, self.config, m)\n        plt.close()\n    result_srdqn = ', '.join(map('{:.2f}'.format, Rsltdnn))\n    result_rand = ', '.join(map('{:.2f}'.format, RsltRnd))\n    result_strm = ', '.join(map('{:.2f}'.format, RsltStrm))\n    if self.ifOptimalSolExist:\n        result_bs = ', '.join(map('{:.2f}'.format, Rsltbs))\n        print('output; {0:s}; Iter= {1:s}; SRDQN= [{2:s}]; sum = {3:2.4f}; Rand= [{4:s}]; sum = {5:2.4f}; Strm= [{6:s}]; sum = {7:2.4f}; BS= [{8:s}]; sum = {9:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), str(str(self.curGame) + '-' + str(m)), result_srdqn, sum(Rsltdnn), result_rand, sum(RsltRnd), result_strm, sum(RsltStrm), result_bs, sum(Rsltbs)))\n        self.resultTest += [[Rsltdnn, RsltRnd, RsltStrm, Rsltbs]]\n    else:\n        print('output; {0:s}; Iter= {1:s}; SRDQN= [{2:s}]; sum = {3:2.4f}; Rand= [{4:s}]; sum = {5:2.4f}; Strm= [{6:s}]; sum = {7:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), str(str(self.curGame) + '-' + str(m)), result_srdqn, sum(Rsltdnn), result_rand, sum(RsltRnd), result_strm, sum(RsltStrm)))\n        self.resultTest += [[Rsltdnn, RsltRnd, RsltStrm]]\n    return sum(Rsltdnn)",
        "mutated": [
            "def doTest(self, m, demand):\n    if False:\n        i = 10\n    import matplotlib.pyplot as plt\n    if self.config.ifSaveFigure:\n        plt.figure(self.curGame, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n        (Rsltdnn, plt) = self.tester(self.config.agentTypes, plt, 'b', 'OurPolicy', m)\n        baseStockdata = self.players[0].srdqnBaseStock\n        (RsltRnd, plt) = self.tester(['rnd', 'rnd', 'rnd', 'rnd'], plt, 'y', 'RAND', m)\n        (RsltStrm, plt) = self.tester(['Strm', 'Strm', 'Strm', 'Strm'], plt, 'g', 'Strm', m)\n        if self.ifOptimalSolExist:\n            if self.config.agentTypes == ['srdqn', 'Strm', 'Strm', 'Strm']:\n                (Rsltbs, plt) = self.tester(['bs', 'Strm', 'Strm', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'srdqn', 'Strm', 'Strm']:\n                (Rsltbs, plt) = self.tester(['Strm', 'bs', 'Strm', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'Strm', 'srdqn', 'Strm']:\n                (Rsltbs, plt) = self.tester(['Strm', 'Strm', 'bs', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'Strm', 'Strm', 'srdqn']:\n                (Rsltbs, plt) = self.tester(['Strm', 'Strm', 'Strm', 'bs'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['srdqn', 'rnd', 'rnd', 'rnd']:\n                (Rsltbs, plt) = self.tester(['bs', 'rnd', 'rnd', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'srdqn', 'rnd', 'rnd']:\n                (Rsltbs, plt) = self.tester(['rnd', 'bs', 'rnd', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'rnd', 'srdqn', 'rnd']:\n                (Rsltbs, plt) = self.tester(['rnd', 'rnd', 'bs', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'rnd', 'rnd', 'srdqn']:\n                (Rsltbs, plt) = self.tester(['rnd', 'rnd', 'rnd', 'bs'], plt, 'r', 'RND-BS', m)\n            else:\n                (Rsltbs, plt) = self.tester(['bs', 'bs', 'bs', 'bs'], plt, 'r', 'BS', m)\n            self.middleTestResult += [[RsltRnd, RsltStrm, Rsltbs]]\n        else:\n            self.middleTestResult += [[RsltRnd, RsltStrm]]\n    else:\n        RsltRnd = self.middleTestResult[m][0]\n        RsltStrm = self.middleTestResult[m][1]\n        if self.ifOptimalSolExist:\n            Rsltbs = self.middleTestResult[m][2]\n    if self.config.ifSaveFigure:\n        savePlot(self.players, self.curGame, Rsltdnn, RsltStrm, Rsltbs, RsltRnd, self.config, m)\n        plt.close()\n    result_srdqn = ', '.join(map('{:.2f}'.format, Rsltdnn))\n    result_rand = ', '.join(map('{:.2f}'.format, RsltRnd))\n    result_strm = ', '.join(map('{:.2f}'.format, RsltStrm))\n    if self.ifOptimalSolExist:\n        result_bs = ', '.join(map('{:.2f}'.format, Rsltbs))\n        print('output; {0:s}; Iter= {1:s}; SRDQN= [{2:s}]; sum = {3:2.4f}; Rand= [{4:s}]; sum = {5:2.4f}; Strm= [{6:s}]; sum = {7:2.4f}; BS= [{8:s}]; sum = {9:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), str(str(self.curGame) + '-' + str(m)), result_srdqn, sum(Rsltdnn), result_rand, sum(RsltRnd), result_strm, sum(RsltStrm), result_bs, sum(Rsltbs)))\n        self.resultTest += [[Rsltdnn, RsltRnd, RsltStrm, Rsltbs]]\n    else:\n        print('output; {0:s}; Iter= {1:s}; SRDQN= [{2:s}]; sum = {3:2.4f}; Rand= [{4:s}]; sum = {5:2.4f}; Strm= [{6:s}]; sum = {7:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), str(str(self.curGame) + '-' + str(m)), result_srdqn, sum(Rsltdnn), result_rand, sum(RsltRnd), result_strm, sum(RsltStrm)))\n        self.resultTest += [[Rsltdnn, RsltRnd, RsltStrm]]\n    return sum(Rsltdnn)",
            "def doTest(self, m, demand):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    import matplotlib.pyplot as plt\n    if self.config.ifSaveFigure:\n        plt.figure(self.curGame, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n        (Rsltdnn, plt) = self.tester(self.config.agentTypes, plt, 'b', 'OurPolicy', m)\n        baseStockdata = self.players[0].srdqnBaseStock\n        (RsltRnd, plt) = self.tester(['rnd', 'rnd', 'rnd', 'rnd'], plt, 'y', 'RAND', m)\n        (RsltStrm, plt) = self.tester(['Strm', 'Strm', 'Strm', 'Strm'], plt, 'g', 'Strm', m)\n        if self.ifOptimalSolExist:\n            if self.config.agentTypes == ['srdqn', 'Strm', 'Strm', 'Strm']:\n                (Rsltbs, plt) = self.tester(['bs', 'Strm', 'Strm', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'srdqn', 'Strm', 'Strm']:\n                (Rsltbs, plt) = self.tester(['Strm', 'bs', 'Strm', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'Strm', 'srdqn', 'Strm']:\n                (Rsltbs, plt) = self.tester(['Strm', 'Strm', 'bs', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'Strm', 'Strm', 'srdqn']:\n                (Rsltbs, plt) = self.tester(['Strm', 'Strm', 'Strm', 'bs'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['srdqn', 'rnd', 'rnd', 'rnd']:\n                (Rsltbs, plt) = self.tester(['bs', 'rnd', 'rnd', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'srdqn', 'rnd', 'rnd']:\n                (Rsltbs, plt) = self.tester(['rnd', 'bs', 'rnd', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'rnd', 'srdqn', 'rnd']:\n                (Rsltbs, plt) = self.tester(['rnd', 'rnd', 'bs', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'rnd', 'rnd', 'srdqn']:\n                (Rsltbs, plt) = self.tester(['rnd', 'rnd', 'rnd', 'bs'], plt, 'r', 'RND-BS', m)\n            else:\n                (Rsltbs, plt) = self.tester(['bs', 'bs', 'bs', 'bs'], plt, 'r', 'BS', m)\n            self.middleTestResult += [[RsltRnd, RsltStrm, Rsltbs]]\n        else:\n            self.middleTestResult += [[RsltRnd, RsltStrm]]\n    else:\n        RsltRnd = self.middleTestResult[m][0]\n        RsltStrm = self.middleTestResult[m][1]\n        if self.ifOptimalSolExist:\n            Rsltbs = self.middleTestResult[m][2]\n    if self.config.ifSaveFigure:\n        savePlot(self.players, self.curGame, Rsltdnn, RsltStrm, Rsltbs, RsltRnd, self.config, m)\n        plt.close()\n    result_srdqn = ', '.join(map('{:.2f}'.format, Rsltdnn))\n    result_rand = ', '.join(map('{:.2f}'.format, RsltRnd))\n    result_strm = ', '.join(map('{:.2f}'.format, RsltStrm))\n    if self.ifOptimalSolExist:\n        result_bs = ', '.join(map('{:.2f}'.format, Rsltbs))\n        print('output; {0:s}; Iter= {1:s}; SRDQN= [{2:s}]; sum = {3:2.4f}; Rand= [{4:s}]; sum = {5:2.4f}; Strm= [{6:s}]; sum = {7:2.4f}; BS= [{8:s}]; sum = {9:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), str(str(self.curGame) + '-' + str(m)), result_srdqn, sum(Rsltdnn), result_rand, sum(RsltRnd), result_strm, sum(RsltStrm), result_bs, sum(Rsltbs)))\n        self.resultTest += [[Rsltdnn, RsltRnd, RsltStrm, Rsltbs]]\n    else:\n        print('output; {0:s}; Iter= {1:s}; SRDQN= [{2:s}]; sum = {3:2.4f}; Rand= [{4:s}]; sum = {5:2.4f}; Strm= [{6:s}]; sum = {7:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), str(str(self.curGame) + '-' + str(m)), result_srdqn, sum(Rsltdnn), result_rand, sum(RsltRnd), result_strm, sum(RsltStrm)))\n        self.resultTest += [[Rsltdnn, RsltRnd, RsltStrm]]\n    return sum(Rsltdnn)",
            "def doTest(self, m, demand):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    import matplotlib.pyplot as plt\n    if self.config.ifSaveFigure:\n        plt.figure(self.curGame, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n        (Rsltdnn, plt) = self.tester(self.config.agentTypes, plt, 'b', 'OurPolicy', m)\n        baseStockdata = self.players[0].srdqnBaseStock\n        (RsltRnd, plt) = self.tester(['rnd', 'rnd', 'rnd', 'rnd'], plt, 'y', 'RAND', m)\n        (RsltStrm, plt) = self.tester(['Strm', 'Strm', 'Strm', 'Strm'], plt, 'g', 'Strm', m)\n        if self.ifOptimalSolExist:\n            if self.config.agentTypes == ['srdqn', 'Strm', 'Strm', 'Strm']:\n                (Rsltbs, plt) = self.tester(['bs', 'Strm', 'Strm', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'srdqn', 'Strm', 'Strm']:\n                (Rsltbs, plt) = self.tester(['Strm', 'bs', 'Strm', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'Strm', 'srdqn', 'Strm']:\n                (Rsltbs, plt) = self.tester(['Strm', 'Strm', 'bs', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'Strm', 'Strm', 'srdqn']:\n                (Rsltbs, plt) = self.tester(['Strm', 'Strm', 'Strm', 'bs'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['srdqn', 'rnd', 'rnd', 'rnd']:\n                (Rsltbs, plt) = self.tester(['bs', 'rnd', 'rnd', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'srdqn', 'rnd', 'rnd']:\n                (Rsltbs, plt) = self.tester(['rnd', 'bs', 'rnd', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'rnd', 'srdqn', 'rnd']:\n                (Rsltbs, plt) = self.tester(['rnd', 'rnd', 'bs', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'rnd', 'rnd', 'srdqn']:\n                (Rsltbs, plt) = self.tester(['rnd', 'rnd', 'rnd', 'bs'], plt, 'r', 'RND-BS', m)\n            else:\n                (Rsltbs, plt) = self.tester(['bs', 'bs', 'bs', 'bs'], plt, 'r', 'BS', m)\n            self.middleTestResult += [[RsltRnd, RsltStrm, Rsltbs]]\n        else:\n            self.middleTestResult += [[RsltRnd, RsltStrm]]\n    else:\n        RsltRnd = self.middleTestResult[m][0]\n        RsltStrm = self.middleTestResult[m][1]\n        if self.ifOptimalSolExist:\n            Rsltbs = self.middleTestResult[m][2]\n    if self.config.ifSaveFigure:\n        savePlot(self.players, self.curGame, Rsltdnn, RsltStrm, Rsltbs, RsltRnd, self.config, m)\n        plt.close()\n    result_srdqn = ', '.join(map('{:.2f}'.format, Rsltdnn))\n    result_rand = ', '.join(map('{:.2f}'.format, RsltRnd))\n    result_strm = ', '.join(map('{:.2f}'.format, RsltStrm))\n    if self.ifOptimalSolExist:\n        result_bs = ', '.join(map('{:.2f}'.format, Rsltbs))\n        print('output; {0:s}; Iter= {1:s}; SRDQN= [{2:s}]; sum = {3:2.4f}; Rand= [{4:s}]; sum = {5:2.4f}; Strm= [{6:s}]; sum = {7:2.4f}; BS= [{8:s}]; sum = {9:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), str(str(self.curGame) + '-' + str(m)), result_srdqn, sum(Rsltdnn), result_rand, sum(RsltRnd), result_strm, sum(RsltStrm), result_bs, sum(Rsltbs)))\n        self.resultTest += [[Rsltdnn, RsltRnd, RsltStrm, Rsltbs]]\n    else:\n        print('output; {0:s}; Iter= {1:s}; SRDQN= [{2:s}]; sum = {3:2.4f}; Rand= [{4:s}]; sum = {5:2.4f}; Strm= [{6:s}]; sum = {7:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), str(str(self.curGame) + '-' + str(m)), result_srdqn, sum(Rsltdnn), result_rand, sum(RsltRnd), result_strm, sum(RsltStrm)))\n        self.resultTest += [[Rsltdnn, RsltRnd, RsltStrm]]\n    return sum(Rsltdnn)",
            "def doTest(self, m, demand):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    import matplotlib.pyplot as plt\n    if self.config.ifSaveFigure:\n        plt.figure(self.curGame, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n        (Rsltdnn, plt) = self.tester(self.config.agentTypes, plt, 'b', 'OurPolicy', m)\n        baseStockdata = self.players[0].srdqnBaseStock\n        (RsltRnd, plt) = self.tester(['rnd', 'rnd', 'rnd', 'rnd'], plt, 'y', 'RAND', m)\n        (RsltStrm, plt) = self.tester(['Strm', 'Strm', 'Strm', 'Strm'], plt, 'g', 'Strm', m)\n        if self.ifOptimalSolExist:\n            if self.config.agentTypes == ['srdqn', 'Strm', 'Strm', 'Strm']:\n                (Rsltbs, plt) = self.tester(['bs', 'Strm', 'Strm', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'srdqn', 'Strm', 'Strm']:\n                (Rsltbs, plt) = self.tester(['Strm', 'bs', 'Strm', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'Strm', 'srdqn', 'Strm']:\n                (Rsltbs, plt) = self.tester(['Strm', 'Strm', 'bs', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'Strm', 'Strm', 'srdqn']:\n                (Rsltbs, plt) = self.tester(['Strm', 'Strm', 'Strm', 'bs'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['srdqn', 'rnd', 'rnd', 'rnd']:\n                (Rsltbs, plt) = self.tester(['bs', 'rnd', 'rnd', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'srdqn', 'rnd', 'rnd']:\n                (Rsltbs, plt) = self.tester(['rnd', 'bs', 'rnd', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'rnd', 'srdqn', 'rnd']:\n                (Rsltbs, plt) = self.tester(['rnd', 'rnd', 'bs', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'rnd', 'rnd', 'srdqn']:\n                (Rsltbs, plt) = self.tester(['rnd', 'rnd', 'rnd', 'bs'], plt, 'r', 'RND-BS', m)\n            else:\n                (Rsltbs, plt) = self.tester(['bs', 'bs', 'bs', 'bs'], plt, 'r', 'BS', m)\n            self.middleTestResult += [[RsltRnd, RsltStrm, Rsltbs]]\n        else:\n            self.middleTestResult += [[RsltRnd, RsltStrm]]\n    else:\n        RsltRnd = self.middleTestResult[m][0]\n        RsltStrm = self.middleTestResult[m][1]\n        if self.ifOptimalSolExist:\n            Rsltbs = self.middleTestResult[m][2]\n    if self.config.ifSaveFigure:\n        savePlot(self.players, self.curGame, Rsltdnn, RsltStrm, Rsltbs, RsltRnd, self.config, m)\n        plt.close()\n    result_srdqn = ', '.join(map('{:.2f}'.format, Rsltdnn))\n    result_rand = ', '.join(map('{:.2f}'.format, RsltRnd))\n    result_strm = ', '.join(map('{:.2f}'.format, RsltStrm))\n    if self.ifOptimalSolExist:\n        result_bs = ', '.join(map('{:.2f}'.format, Rsltbs))\n        print('output; {0:s}; Iter= {1:s}; SRDQN= [{2:s}]; sum = {3:2.4f}; Rand= [{4:s}]; sum = {5:2.4f}; Strm= [{6:s}]; sum = {7:2.4f}; BS= [{8:s}]; sum = {9:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), str(str(self.curGame) + '-' + str(m)), result_srdqn, sum(Rsltdnn), result_rand, sum(RsltRnd), result_strm, sum(RsltStrm), result_bs, sum(Rsltbs)))\n        self.resultTest += [[Rsltdnn, RsltRnd, RsltStrm, Rsltbs]]\n    else:\n        print('output; {0:s}; Iter= {1:s}; SRDQN= [{2:s}]; sum = {3:2.4f}; Rand= [{4:s}]; sum = {5:2.4f}; Strm= [{6:s}]; sum = {7:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), str(str(self.curGame) + '-' + str(m)), result_srdqn, sum(Rsltdnn), result_rand, sum(RsltRnd), result_strm, sum(RsltStrm)))\n        self.resultTest += [[Rsltdnn, RsltRnd, RsltStrm]]\n    return sum(Rsltdnn)",
            "def doTest(self, m, demand):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    import matplotlib.pyplot as plt\n    if self.config.ifSaveFigure:\n        plt.figure(self.curGame, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n        (Rsltdnn, plt) = self.tester(self.config.agentTypes, plt, 'b', 'OurPolicy', m)\n        baseStockdata = self.players[0].srdqnBaseStock\n        (RsltRnd, plt) = self.tester(['rnd', 'rnd', 'rnd', 'rnd'], plt, 'y', 'RAND', m)\n        (RsltStrm, plt) = self.tester(['Strm', 'Strm', 'Strm', 'Strm'], plt, 'g', 'Strm', m)\n        if self.ifOptimalSolExist:\n            if self.config.agentTypes == ['srdqn', 'Strm', 'Strm', 'Strm']:\n                (Rsltbs, plt) = self.tester(['bs', 'Strm', 'Strm', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'srdqn', 'Strm', 'Strm']:\n                (Rsltbs, plt) = self.tester(['Strm', 'bs', 'Strm', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'Strm', 'srdqn', 'Strm']:\n                (Rsltbs, plt) = self.tester(['Strm', 'Strm', 'bs', 'Strm'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['Strm', 'Strm', 'Strm', 'srdqn']:\n                (Rsltbs, plt) = self.tester(['Strm', 'Strm', 'Strm', 'bs'], plt, 'r', 'Strm-BS', m)\n            elif self.config.agentTypes == ['srdqn', 'rnd', 'rnd', 'rnd']:\n                (Rsltbs, plt) = self.tester(['bs', 'rnd', 'rnd', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'srdqn', 'rnd', 'rnd']:\n                (Rsltbs, plt) = self.tester(['rnd', 'bs', 'rnd', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'rnd', 'srdqn', 'rnd']:\n                (Rsltbs, plt) = self.tester(['rnd', 'rnd', 'bs', 'rnd'], plt, 'r', 'RND-BS', m)\n            elif self.config.agentTypes == ['rnd', 'rnd', 'rnd', 'srdqn']:\n                (Rsltbs, plt) = self.tester(['rnd', 'rnd', 'rnd', 'bs'], plt, 'r', 'RND-BS', m)\n            else:\n                (Rsltbs, plt) = self.tester(['bs', 'bs', 'bs', 'bs'], plt, 'r', 'BS', m)\n            self.middleTestResult += [[RsltRnd, RsltStrm, Rsltbs]]\n        else:\n            self.middleTestResult += [[RsltRnd, RsltStrm]]\n    else:\n        RsltRnd = self.middleTestResult[m][0]\n        RsltStrm = self.middleTestResult[m][1]\n        if self.ifOptimalSolExist:\n            Rsltbs = self.middleTestResult[m][2]\n    if self.config.ifSaveFigure:\n        savePlot(self.players, self.curGame, Rsltdnn, RsltStrm, Rsltbs, RsltRnd, self.config, m)\n        plt.close()\n    result_srdqn = ', '.join(map('{:.2f}'.format, Rsltdnn))\n    result_rand = ', '.join(map('{:.2f}'.format, RsltRnd))\n    result_strm = ', '.join(map('{:.2f}'.format, RsltStrm))\n    if self.ifOptimalSolExist:\n        result_bs = ', '.join(map('{:.2f}'.format, Rsltbs))\n        print('output; {0:s}; Iter= {1:s}; SRDQN= [{2:s}]; sum = {3:2.4f}; Rand= [{4:s}]; sum = {5:2.4f}; Strm= [{6:s}]; sum = {7:2.4f}; BS= [{8:s}]; sum = {9:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), str(str(self.curGame) + '-' + str(m)), result_srdqn, sum(Rsltdnn), result_rand, sum(RsltRnd), result_strm, sum(RsltStrm), result_bs, sum(Rsltbs)))\n        self.resultTest += [[Rsltdnn, RsltRnd, RsltStrm, Rsltbs]]\n    else:\n        print('output; {0:s}; Iter= {1:s}; SRDQN= [{2:s}]; sum = {3:2.4f}; Rand= [{4:s}]; sum = {5:2.4f}; Strm= [{6:s}]; sum = {7:2.4f}'.format(strftime('%Y-%m-%d %H:%M:%S', gmtime()), str(str(self.curGame) + '-' + str(m)), result_srdqn, sum(Rsltdnn), result_rand, sum(RsltRnd), result_strm, sum(RsltStrm)))\n        self.resultTest += [[Rsltdnn, RsltRnd, RsltStrm]]\n    return sum(Rsltdnn)"
        ]
    },
    {
        "func_name": "tester",
        "original": "def tester(self, testType, plt, colori, labeli, m):\n    for k in range(0, self.config.NoAgent):\n        self.players[k].compType = testType[k]\n    if labeli != 'OurPolicy':\n        result = self.playGame(self.demand)\n    else:\n        result = [-1 * self.players[i].cumReward for i in range(0, self.config.NoAgent)]\n    if self.config.ifSaveFigure:\n        plt = plotting(plt, [np.array(self.players[i].hist) for i in range(0, self.config.NoAgent)], colori, labeli)\n    if self.config.ifsaveHistInterval and (self.curGame == 0 or self.curGame == 1 or self.curGame == 2 or (self.curGame == 3) or ((self.curGame - 1) % self.config.saveHistInterval == 0) or (self.curGame % self.config.saveHistInterval == 0) or (self.curGame % self.config.saveHistInterval == 1) or (self.curGame % self.config.saveHistInterval == 2)):\n        for k in range(0, self.config.NoAgent):\n            name = labeli + '-' + str(self.curGame) + '-' + 'player' + '-' + str(k) + '-' + str(m)\n            np.save(os.path.join(self.config.model_dir, name), np.array(self.players[k].hist2))\n    return (result, plt)",
        "mutated": [
            "def tester(self, testType, plt, colori, labeli, m):\n    if False:\n        i = 10\n    for k in range(0, self.config.NoAgent):\n        self.players[k].compType = testType[k]\n    if labeli != 'OurPolicy':\n        result = self.playGame(self.demand)\n    else:\n        result = [-1 * self.players[i].cumReward for i in range(0, self.config.NoAgent)]\n    if self.config.ifSaveFigure:\n        plt = plotting(plt, [np.array(self.players[i].hist) for i in range(0, self.config.NoAgent)], colori, labeli)\n    if self.config.ifsaveHistInterval and (self.curGame == 0 or self.curGame == 1 or self.curGame == 2 or (self.curGame == 3) or ((self.curGame - 1) % self.config.saveHistInterval == 0) or (self.curGame % self.config.saveHistInterval == 0) or (self.curGame % self.config.saveHistInterval == 1) or (self.curGame % self.config.saveHistInterval == 2)):\n        for k in range(0, self.config.NoAgent):\n            name = labeli + '-' + str(self.curGame) + '-' + 'player' + '-' + str(k) + '-' + str(m)\n            np.save(os.path.join(self.config.model_dir, name), np.array(self.players[k].hist2))\n    return (result, plt)",
            "def tester(self, testType, plt, colori, labeli, m):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    for k in range(0, self.config.NoAgent):\n        self.players[k].compType = testType[k]\n    if labeli != 'OurPolicy':\n        result = self.playGame(self.demand)\n    else:\n        result = [-1 * self.players[i].cumReward for i in range(0, self.config.NoAgent)]\n    if self.config.ifSaveFigure:\n        plt = plotting(plt, [np.array(self.players[i].hist) for i in range(0, self.config.NoAgent)], colori, labeli)\n    if self.config.ifsaveHistInterval and (self.curGame == 0 or self.curGame == 1 or self.curGame == 2 or (self.curGame == 3) or ((self.curGame - 1) % self.config.saveHistInterval == 0) or (self.curGame % self.config.saveHistInterval == 0) or (self.curGame % self.config.saveHistInterval == 1) or (self.curGame % self.config.saveHistInterval == 2)):\n        for k in range(0, self.config.NoAgent):\n            name = labeli + '-' + str(self.curGame) + '-' + 'player' + '-' + str(k) + '-' + str(m)\n            np.save(os.path.join(self.config.model_dir, name), np.array(self.players[k].hist2))\n    return (result, plt)",
            "def tester(self, testType, plt, colori, labeli, m):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    for k in range(0, self.config.NoAgent):\n        self.players[k].compType = testType[k]\n    if labeli != 'OurPolicy':\n        result = self.playGame(self.demand)\n    else:\n        result = [-1 * self.players[i].cumReward for i in range(0, self.config.NoAgent)]\n    if self.config.ifSaveFigure:\n        plt = plotting(plt, [np.array(self.players[i].hist) for i in range(0, self.config.NoAgent)], colori, labeli)\n    if self.config.ifsaveHistInterval and (self.curGame == 0 or self.curGame == 1 or self.curGame == 2 or (self.curGame == 3) or ((self.curGame - 1) % self.config.saveHistInterval == 0) or (self.curGame % self.config.saveHistInterval == 0) or (self.curGame % self.config.saveHistInterval == 1) or (self.curGame % self.config.saveHistInterval == 2)):\n        for k in range(0, self.config.NoAgent):\n            name = labeli + '-' + str(self.curGame) + '-' + 'player' + '-' + str(k) + '-' + str(m)\n            np.save(os.path.join(self.config.model_dir, name), np.array(self.players[k].hist2))\n    return (result, plt)",
            "def tester(self, testType, plt, colori, labeli, m):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    for k in range(0, self.config.NoAgent):\n        self.players[k].compType = testType[k]\n    if labeli != 'OurPolicy':\n        result = self.playGame(self.demand)\n    else:\n        result = [-1 * self.players[i].cumReward for i in range(0, self.config.NoAgent)]\n    if self.config.ifSaveFigure:\n        plt = plotting(plt, [np.array(self.players[i].hist) for i in range(0, self.config.NoAgent)], colori, labeli)\n    if self.config.ifsaveHistInterval and (self.curGame == 0 or self.curGame == 1 or self.curGame == 2 or (self.curGame == 3) or ((self.curGame - 1) % self.config.saveHistInterval == 0) or (self.curGame % self.config.saveHistInterval == 0) or (self.curGame % self.config.saveHistInterval == 1) or (self.curGame % self.config.saveHistInterval == 2)):\n        for k in range(0, self.config.NoAgent):\n            name = labeli + '-' + str(self.curGame) + '-' + 'player' + '-' + str(k) + '-' + str(m)\n            np.save(os.path.join(self.config.model_dir, name), np.array(self.players[k].hist2))\n    return (result, plt)",
            "def tester(self, testType, plt, colori, labeli, m):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    for k in range(0, self.config.NoAgent):\n        self.players[k].compType = testType[k]\n    if labeli != 'OurPolicy':\n        result = self.playGame(self.demand)\n    else:\n        result = [-1 * self.players[i].cumReward for i in range(0, self.config.NoAgent)]\n    if self.config.ifSaveFigure:\n        plt = plotting(plt, [np.array(self.players[i].hist) for i in range(0, self.config.NoAgent)], colori, labeli)\n    if self.config.ifsaveHistInterval and (self.curGame == 0 or self.curGame == 1 or self.curGame == 2 or (self.curGame == 3) or ((self.curGame - 1) % self.config.saveHistInterval == 0) or (self.curGame % self.config.saveHistInterval == 0) or (self.curGame % self.config.saveHistInterval == 1) or (self.curGame % self.config.saveHistInterval == 2)):\n        for k in range(0, self.config.NoAgent):\n            name = labeli + '-' + str(self.curGame) + '-' + 'player' + '-' + str(k) + '-' + str(m)\n            np.save(os.path.join(self.config.model_dir, name), np.array(self.players[k].hist2))\n    return (result, plt)"
        ]
    },
    {
        "func_name": "playGame",
        "original": "def playGame(self, demand):\n    self.resetGame(demand)\n    while self.curTime < self.T:\n        self.handelAction(np.array(0))\n        self.next()\n    return [-1 * self.players[i].cumReward for i in range(0, self.config.NoAgent)]",
        "mutated": [
            "def playGame(self, demand):\n    if False:\n        i = 10\n    self.resetGame(demand)\n    while self.curTime < self.T:\n        self.handelAction(np.array(0))\n        self.next()\n    return [-1 * self.players[i].cumReward for i in range(0, self.config.NoAgent)]",
            "def playGame(self, demand):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.resetGame(demand)\n    while self.curTime < self.T:\n        self.handelAction(np.array(0))\n        self.next()\n    return [-1 * self.players[i].cumReward for i in range(0, self.config.NoAgent)]",
            "def playGame(self, demand):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.resetGame(demand)\n    while self.curTime < self.T:\n        self.handelAction(np.array(0))\n        self.next()\n    return [-1 * self.players[i].cumReward for i in range(0, self.config.NoAgent)]",
            "def playGame(self, demand):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.resetGame(demand)\n    while self.curTime < self.T:\n        self.handelAction(np.array(0))\n        self.next()\n    return [-1 * self.players[i].cumReward for i in range(0, self.config.NoAgent)]",
            "def playGame(self, demand):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.resetGame(demand)\n    while self.curTime < self.T:\n        self.handelAction(np.array(0))\n        self.next()\n    return [-1 * self.players[i].cumReward for i in range(0, self.config.NoAgent)]"
        ]
    }
]