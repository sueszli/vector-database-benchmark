[
    {
        "func_name": "query",
        "original": "def query(dataset, query_string: str):\n    \"\"\"Returns a sliced :class:`~deeplake.core.dataset.Dataset` with given query results.\n\n    It allows to run SQL like queries on dataset and extract results. See supported keywords and the Tensor Query Language documentation\n    :ref:`here <tql>`.\n\n\n    Args:\n        dataset: deeplake.Dataset object on which the query needs to be run\n        query_string (str): An SQL string adjusted with new functionalities to run on the given :class:`deeplake.Dataset` object\n\n\n    Returns:\n        Dataset: A deeplake.Dataset object.\n\n    Examples:\n\n        Query from dataset all the samples with lables other than ``5``\n\n        >>> import deeplake\n        >>> from deeplake.enterprise import query\n        >>> ds = deeplake.load('hub://activeloop/fashion-mnist-train')\n        >>> query_ds_train = query(ds_train, \"select * where labels != 5\")\n\n        Query from dataset first appeard ``1000`` samples where the ``categories`` is ``car`` and ``1000`` samples where the ``categories`` is ``motorcycle``\n\n        >>> ds_train = deeplake.load('hub://activeloop/coco-train')\n        >>> query_ds_train = query(ds_train, \"(select * where contains(categories, 'car') limit 1000) union (select * where contains(categories, 'motorcycle') limit 1000)\")\n    \"\"\"\n    if isinstance(dataset, DeepLakeQueryDataset):\n        ds = dataset.indra_ds\n    elif dataset.libdeeplake_dataset is not None:\n        ds = dataset.libdeeplake_dataset\n        slice_ = dataset.index.values[0].value\n        if slice_ != slice(None):\n            if isinstance(slice_, tuple):\n                slice_ = list(slice_)\n            ds = ds[slice_]\n    else:\n        ds = dataset_to_libdeeplake(dataset)\n    dsv = ds.query(query_string)\n    from deeplake.enterprise.convert_to_libdeeplake import INDRA_API\n    if not isinstance(dataset, DeepLakeQueryDataset) and INDRA_API.tql.parse(query_string).is_filter and (len(dsv.indexes) < INDRA_DATASET_SAMPLES_THRESHOLD):\n        indexes = list(dsv.indexes)\n        return dataset.no_view_dataset[indexes]\n    else:\n        view = DeepLakeQueryDataset(deeplake_ds=dataset, indra_ds=dsv)\n        view._tql_query = query_string\n        if hasattr(dataset, 'is_actually_cloud'):\n            view.is_actually_cloud = dataset.is_actually_cloud\n        return view",
        "mutated": [
            "def query(dataset, query_string: str):\n    if False:\n        i = 10\n    'Returns a sliced :class:`~deeplake.core.dataset.Dataset` with given query results.\\n\\n    It allows to run SQL like queries on dataset and extract results. See supported keywords and the Tensor Query Language documentation\\n    :ref:`here <tql>`.\\n\\n\\n    Args:\\n        dataset: deeplake.Dataset object on which the query needs to be run\\n        query_string (str): An SQL string adjusted with new functionalities to run on the given :class:`deeplake.Dataset` object\\n\\n\\n    Returns:\\n        Dataset: A deeplake.Dataset object.\\n\\n    Examples:\\n\\n        Query from dataset all the samples with lables other than ``5``\\n\\n        >>> import deeplake\\n        >>> from deeplake.enterprise import query\\n        >>> ds = deeplake.load(\\'hub://activeloop/fashion-mnist-train\\')\\n        >>> query_ds_train = query(ds_train, \"select * where labels != 5\")\\n\\n        Query from dataset first appeard ``1000`` samples where the ``categories`` is ``car`` and ``1000`` samples where the ``categories`` is ``motorcycle``\\n\\n        >>> ds_train = deeplake.load(\\'hub://activeloop/coco-train\\')\\n        >>> query_ds_train = query(ds_train, \"(select * where contains(categories, \\'car\\') limit 1000) union (select * where contains(categories, \\'motorcycle\\') limit 1000)\")\\n    '\n    if isinstance(dataset, DeepLakeQueryDataset):\n        ds = dataset.indra_ds\n    elif dataset.libdeeplake_dataset is not None:\n        ds = dataset.libdeeplake_dataset\n        slice_ = dataset.index.values[0].value\n        if slice_ != slice(None):\n            if isinstance(slice_, tuple):\n                slice_ = list(slice_)\n            ds = ds[slice_]\n    else:\n        ds = dataset_to_libdeeplake(dataset)\n    dsv = ds.query(query_string)\n    from deeplake.enterprise.convert_to_libdeeplake import INDRA_API\n    if not isinstance(dataset, DeepLakeQueryDataset) and INDRA_API.tql.parse(query_string).is_filter and (len(dsv.indexes) < INDRA_DATASET_SAMPLES_THRESHOLD):\n        indexes = list(dsv.indexes)\n        return dataset.no_view_dataset[indexes]\n    else:\n        view = DeepLakeQueryDataset(deeplake_ds=dataset, indra_ds=dsv)\n        view._tql_query = query_string\n        if hasattr(dataset, 'is_actually_cloud'):\n            view.is_actually_cloud = dataset.is_actually_cloud\n        return view",
            "def query(dataset, query_string: str):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Returns a sliced :class:`~deeplake.core.dataset.Dataset` with given query results.\\n\\n    It allows to run SQL like queries on dataset and extract results. See supported keywords and the Tensor Query Language documentation\\n    :ref:`here <tql>`.\\n\\n\\n    Args:\\n        dataset: deeplake.Dataset object on which the query needs to be run\\n        query_string (str): An SQL string adjusted with new functionalities to run on the given :class:`deeplake.Dataset` object\\n\\n\\n    Returns:\\n        Dataset: A deeplake.Dataset object.\\n\\n    Examples:\\n\\n        Query from dataset all the samples with lables other than ``5``\\n\\n        >>> import deeplake\\n        >>> from deeplake.enterprise import query\\n        >>> ds = deeplake.load(\\'hub://activeloop/fashion-mnist-train\\')\\n        >>> query_ds_train = query(ds_train, \"select * where labels != 5\")\\n\\n        Query from dataset first appeard ``1000`` samples where the ``categories`` is ``car`` and ``1000`` samples where the ``categories`` is ``motorcycle``\\n\\n        >>> ds_train = deeplake.load(\\'hub://activeloop/coco-train\\')\\n        >>> query_ds_train = query(ds_train, \"(select * where contains(categories, \\'car\\') limit 1000) union (select * where contains(categories, \\'motorcycle\\') limit 1000)\")\\n    '\n    if isinstance(dataset, DeepLakeQueryDataset):\n        ds = dataset.indra_ds\n    elif dataset.libdeeplake_dataset is not None:\n        ds = dataset.libdeeplake_dataset\n        slice_ = dataset.index.values[0].value\n        if slice_ != slice(None):\n            if isinstance(slice_, tuple):\n                slice_ = list(slice_)\n            ds = ds[slice_]\n    else:\n        ds = dataset_to_libdeeplake(dataset)\n    dsv = ds.query(query_string)\n    from deeplake.enterprise.convert_to_libdeeplake import INDRA_API\n    if not isinstance(dataset, DeepLakeQueryDataset) and INDRA_API.tql.parse(query_string).is_filter and (len(dsv.indexes) < INDRA_DATASET_SAMPLES_THRESHOLD):\n        indexes = list(dsv.indexes)\n        return dataset.no_view_dataset[indexes]\n    else:\n        view = DeepLakeQueryDataset(deeplake_ds=dataset, indra_ds=dsv)\n        view._tql_query = query_string\n        if hasattr(dataset, 'is_actually_cloud'):\n            view.is_actually_cloud = dataset.is_actually_cloud\n        return view",
            "def query(dataset, query_string: str):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Returns a sliced :class:`~deeplake.core.dataset.Dataset` with given query results.\\n\\n    It allows to run SQL like queries on dataset and extract results. See supported keywords and the Tensor Query Language documentation\\n    :ref:`here <tql>`.\\n\\n\\n    Args:\\n        dataset: deeplake.Dataset object on which the query needs to be run\\n        query_string (str): An SQL string adjusted with new functionalities to run on the given :class:`deeplake.Dataset` object\\n\\n\\n    Returns:\\n        Dataset: A deeplake.Dataset object.\\n\\n    Examples:\\n\\n        Query from dataset all the samples with lables other than ``5``\\n\\n        >>> import deeplake\\n        >>> from deeplake.enterprise import query\\n        >>> ds = deeplake.load(\\'hub://activeloop/fashion-mnist-train\\')\\n        >>> query_ds_train = query(ds_train, \"select * where labels != 5\")\\n\\n        Query from dataset first appeard ``1000`` samples where the ``categories`` is ``car`` and ``1000`` samples where the ``categories`` is ``motorcycle``\\n\\n        >>> ds_train = deeplake.load(\\'hub://activeloop/coco-train\\')\\n        >>> query_ds_train = query(ds_train, \"(select * where contains(categories, \\'car\\') limit 1000) union (select * where contains(categories, \\'motorcycle\\') limit 1000)\")\\n    '\n    if isinstance(dataset, DeepLakeQueryDataset):\n        ds = dataset.indra_ds\n    elif dataset.libdeeplake_dataset is not None:\n        ds = dataset.libdeeplake_dataset\n        slice_ = dataset.index.values[0].value\n        if slice_ != slice(None):\n            if isinstance(slice_, tuple):\n                slice_ = list(slice_)\n            ds = ds[slice_]\n    else:\n        ds = dataset_to_libdeeplake(dataset)\n    dsv = ds.query(query_string)\n    from deeplake.enterprise.convert_to_libdeeplake import INDRA_API\n    if not isinstance(dataset, DeepLakeQueryDataset) and INDRA_API.tql.parse(query_string).is_filter and (len(dsv.indexes) < INDRA_DATASET_SAMPLES_THRESHOLD):\n        indexes = list(dsv.indexes)\n        return dataset.no_view_dataset[indexes]\n    else:\n        view = DeepLakeQueryDataset(deeplake_ds=dataset, indra_ds=dsv)\n        view._tql_query = query_string\n        if hasattr(dataset, 'is_actually_cloud'):\n            view.is_actually_cloud = dataset.is_actually_cloud\n        return view",
            "def query(dataset, query_string: str):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Returns a sliced :class:`~deeplake.core.dataset.Dataset` with given query results.\\n\\n    It allows to run SQL like queries on dataset and extract results. See supported keywords and the Tensor Query Language documentation\\n    :ref:`here <tql>`.\\n\\n\\n    Args:\\n        dataset: deeplake.Dataset object on which the query needs to be run\\n        query_string (str): An SQL string adjusted with new functionalities to run on the given :class:`deeplake.Dataset` object\\n\\n\\n    Returns:\\n        Dataset: A deeplake.Dataset object.\\n\\n    Examples:\\n\\n        Query from dataset all the samples with lables other than ``5``\\n\\n        >>> import deeplake\\n        >>> from deeplake.enterprise import query\\n        >>> ds = deeplake.load(\\'hub://activeloop/fashion-mnist-train\\')\\n        >>> query_ds_train = query(ds_train, \"select * where labels != 5\")\\n\\n        Query from dataset first appeard ``1000`` samples where the ``categories`` is ``car`` and ``1000`` samples where the ``categories`` is ``motorcycle``\\n\\n        >>> ds_train = deeplake.load(\\'hub://activeloop/coco-train\\')\\n        >>> query_ds_train = query(ds_train, \"(select * where contains(categories, \\'car\\') limit 1000) union (select * where contains(categories, \\'motorcycle\\') limit 1000)\")\\n    '\n    if isinstance(dataset, DeepLakeQueryDataset):\n        ds = dataset.indra_ds\n    elif dataset.libdeeplake_dataset is not None:\n        ds = dataset.libdeeplake_dataset\n        slice_ = dataset.index.values[0].value\n        if slice_ != slice(None):\n            if isinstance(slice_, tuple):\n                slice_ = list(slice_)\n            ds = ds[slice_]\n    else:\n        ds = dataset_to_libdeeplake(dataset)\n    dsv = ds.query(query_string)\n    from deeplake.enterprise.convert_to_libdeeplake import INDRA_API\n    if not isinstance(dataset, DeepLakeQueryDataset) and INDRA_API.tql.parse(query_string).is_filter and (len(dsv.indexes) < INDRA_DATASET_SAMPLES_THRESHOLD):\n        indexes = list(dsv.indexes)\n        return dataset.no_view_dataset[indexes]\n    else:\n        view = DeepLakeQueryDataset(deeplake_ds=dataset, indra_ds=dsv)\n        view._tql_query = query_string\n        if hasattr(dataset, 'is_actually_cloud'):\n            view.is_actually_cloud = dataset.is_actually_cloud\n        return view",
            "def query(dataset, query_string: str):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Returns a sliced :class:`~deeplake.core.dataset.Dataset` with given query results.\\n\\n    It allows to run SQL like queries on dataset and extract results. See supported keywords and the Tensor Query Language documentation\\n    :ref:`here <tql>`.\\n\\n\\n    Args:\\n        dataset: deeplake.Dataset object on which the query needs to be run\\n        query_string (str): An SQL string adjusted with new functionalities to run on the given :class:`deeplake.Dataset` object\\n\\n\\n    Returns:\\n        Dataset: A deeplake.Dataset object.\\n\\n    Examples:\\n\\n        Query from dataset all the samples with lables other than ``5``\\n\\n        >>> import deeplake\\n        >>> from deeplake.enterprise import query\\n        >>> ds = deeplake.load(\\'hub://activeloop/fashion-mnist-train\\')\\n        >>> query_ds_train = query(ds_train, \"select * where labels != 5\")\\n\\n        Query from dataset first appeard ``1000`` samples where the ``categories`` is ``car`` and ``1000`` samples where the ``categories`` is ``motorcycle``\\n\\n        >>> ds_train = deeplake.load(\\'hub://activeloop/coco-train\\')\\n        >>> query_ds_train = query(ds_train, \"(select * where contains(categories, \\'car\\') limit 1000) union (select * where contains(categories, \\'motorcycle\\') limit 1000)\")\\n    '\n    if isinstance(dataset, DeepLakeQueryDataset):\n        ds = dataset.indra_ds\n    elif dataset.libdeeplake_dataset is not None:\n        ds = dataset.libdeeplake_dataset\n        slice_ = dataset.index.values[0].value\n        if slice_ != slice(None):\n            if isinstance(slice_, tuple):\n                slice_ = list(slice_)\n            ds = ds[slice_]\n    else:\n        ds = dataset_to_libdeeplake(dataset)\n    dsv = ds.query(query_string)\n    from deeplake.enterprise.convert_to_libdeeplake import INDRA_API\n    if not isinstance(dataset, DeepLakeQueryDataset) and INDRA_API.tql.parse(query_string).is_filter and (len(dsv.indexes) < INDRA_DATASET_SAMPLES_THRESHOLD):\n        indexes = list(dsv.indexes)\n        return dataset.no_view_dataset[indexes]\n    else:\n        view = DeepLakeQueryDataset(deeplake_ds=dataset, indra_ds=dsv)\n        view._tql_query = query_string\n        if hasattr(dataset, 'is_actually_cloud'):\n            view.is_actually_cloud = dataset.is_actually_cloud\n        return view"
        ]
    },
    {
        "func_name": "sample_by",
        "original": "def sample_by(dataset, weights: Union[str, list, tuple, np.ndarray], replace: Optional[bool]=True, size: Optional[int]=None):\n    \"\"\"Returns a sliced :class:`~deeplake.core.dataset.Dataset` with given sampler applied.\n\n\n    Args:\n        dataset: deeplake.Dataset object on which the query needs to be run\n        weights: (Union[str, list, tuple, np.ndarray]): If it's string then tql will be run to calculate the weights based on the expression. list, tuple and ndarray will be treated as the list of the weights per sample\n        replace: Optional[bool] If true the samples can be repeated in the result view.\n            (default: ``True``).\n        size: Optional[int] The length of the result view.\n            (default: ``len(dataset)``)\n\n\n    Returns:\n        Dataset: A deeplake.Dataset object.\n\n    Raises:\n        ValueError: When the given np.ndarray is multidimensional\n\n    Examples:\n\n        Sample the dataset with ``labels == 5`` twice more than ``labels == 6``\n\n        >>> import deeplake\n        >>> from deeplake.experimental import query\n        >>> ds = deeplake.load('hub://activeloop/fashion-mnist-train')\n        >>> sampled_ds = sample_by(ds, \"max_weight(labels == 5: 10, labels == 6: 5)\")\n\n        Sample the dataset treating `labels` tensor as weights.\n\n        >>> import deeplake\n        >>> from deeplake.experimental import query\n        >>> ds = deeplake.load('hub://activeloop/fashion-mnist-train')\n        >>> sampled_ds = sample_by(ds, \"labels\")\n\n        Sample the dataset with the given weights;\n\n        >>> ds = deeplake.load('hub://activeloop/coco-train')\n        >>> weights = list()\n        >>> for i in range(0, len(ds)):\n        >>>     weights.append(i % 5)\n        >>> sampled_ds = sample_by(ds, weights, replace=False)\n    \"\"\"\n    if isinstance(weights, np.ndarray):\n        if len(weights.shape) != 1:\n            raise ValueError('weights should be 1 dimensional array.')\n        weights = tuple(weights)\n    ds = dataset_to_libdeeplake(dataset)\n    if size is None:\n        dsv = ds.sample(weights, replace=replace)\n    else:\n        dsv = ds.sample(weights, replace=replace, size=size)\n    indexes = list(dsv.indexes)\n    return dataset.no_view_dataset[indexes]",
        "mutated": [
            "def sample_by(dataset, weights: Union[str, list, tuple, np.ndarray], replace: Optional[bool]=True, size: Optional[int]=None):\n    if False:\n        i = 10\n    'Returns a sliced :class:`~deeplake.core.dataset.Dataset` with given sampler applied.\\n\\n\\n    Args:\\n        dataset: deeplake.Dataset object on which the query needs to be run\\n        weights: (Union[str, list, tuple, np.ndarray]): If it\\'s string then tql will be run to calculate the weights based on the expression. list, tuple and ndarray will be treated as the list of the weights per sample\\n        replace: Optional[bool] If true the samples can be repeated in the result view.\\n            (default: ``True``).\\n        size: Optional[int] The length of the result view.\\n            (default: ``len(dataset)``)\\n\\n\\n    Returns:\\n        Dataset: A deeplake.Dataset object.\\n\\n    Raises:\\n        ValueError: When the given np.ndarray is multidimensional\\n\\n    Examples:\\n\\n        Sample the dataset with ``labels == 5`` twice more than ``labels == 6``\\n\\n        >>> import deeplake\\n        >>> from deeplake.experimental import query\\n        >>> ds = deeplake.load(\\'hub://activeloop/fashion-mnist-train\\')\\n        >>> sampled_ds = sample_by(ds, \"max_weight(labels == 5: 10, labels == 6: 5)\")\\n\\n        Sample the dataset treating `labels` tensor as weights.\\n\\n        >>> import deeplake\\n        >>> from deeplake.experimental import query\\n        >>> ds = deeplake.load(\\'hub://activeloop/fashion-mnist-train\\')\\n        >>> sampled_ds = sample_by(ds, \"labels\")\\n\\n        Sample the dataset with the given weights;\\n\\n        >>> ds = deeplake.load(\\'hub://activeloop/coco-train\\')\\n        >>> weights = list()\\n        >>> for i in range(0, len(ds)):\\n        >>>     weights.append(i % 5)\\n        >>> sampled_ds = sample_by(ds, weights, replace=False)\\n    '\n    if isinstance(weights, np.ndarray):\n        if len(weights.shape) != 1:\n            raise ValueError('weights should be 1 dimensional array.')\n        weights = tuple(weights)\n    ds = dataset_to_libdeeplake(dataset)\n    if size is None:\n        dsv = ds.sample(weights, replace=replace)\n    else:\n        dsv = ds.sample(weights, replace=replace, size=size)\n    indexes = list(dsv.indexes)\n    return dataset.no_view_dataset[indexes]",
            "def sample_by(dataset, weights: Union[str, list, tuple, np.ndarray], replace: Optional[bool]=True, size: Optional[int]=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Returns a sliced :class:`~deeplake.core.dataset.Dataset` with given sampler applied.\\n\\n\\n    Args:\\n        dataset: deeplake.Dataset object on which the query needs to be run\\n        weights: (Union[str, list, tuple, np.ndarray]): If it\\'s string then tql will be run to calculate the weights based on the expression. list, tuple and ndarray will be treated as the list of the weights per sample\\n        replace: Optional[bool] If true the samples can be repeated in the result view.\\n            (default: ``True``).\\n        size: Optional[int] The length of the result view.\\n            (default: ``len(dataset)``)\\n\\n\\n    Returns:\\n        Dataset: A deeplake.Dataset object.\\n\\n    Raises:\\n        ValueError: When the given np.ndarray is multidimensional\\n\\n    Examples:\\n\\n        Sample the dataset with ``labels == 5`` twice more than ``labels == 6``\\n\\n        >>> import deeplake\\n        >>> from deeplake.experimental import query\\n        >>> ds = deeplake.load(\\'hub://activeloop/fashion-mnist-train\\')\\n        >>> sampled_ds = sample_by(ds, \"max_weight(labels == 5: 10, labels == 6: 5)\")\\n\\n        Sample the dataset treating `labels` tensor as weights.\\n\\n        >>> import deeplake\\n        >>> from deeplake.experimental import query\\n        >>> ds = deeplake.load(\\'hub://activeloop/fashion-mnist-train\\')\\n        >>> sampled_ds = sample_by(ds, \"labels\")\\n\\n        Sample the dataset with the given weights;\\n\\n        >>> ds = deeplake.load(\\'hub://activeloop/coco-train\\')\\n        >>> weights = list()\\n        >>> for i in range(0, len(ds)):\\n        >>>     weights.append(i % 5)\\n        >>> sampled_ds = sample_by(ds, weights, replace=False)\\n    '\n    if isinstance(weights, np.ndarray):\n        if len(weights.shape) != 1:\n            raise ValueError('weights should be 1 dimensional array.')\n        weights = tuple(weights)\n    ds = dataset_to_libdeeplake(dataset)\n    if size is None:\n        dsv = ds.sample(weights, replace=replace)\n    else:\n        dsv = ds.sample(weights, replace=replace, size=size)\n    indexes = list(dsv.indexes)\n    return dataset.no_view_dataset[indexes]",
            "def sample_by(dataset, weights: Union[str, list, tuple, np.ndarray], replace: Optional[bool]=True, size: Optional[int]=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Returns a sliced :class:`~deeplake.core.dataset.Dataset` with given sampler applied.\\n\\n\\n    Args:\\n        dataset: deeplake.Dataset object on which the query needs to be run\\n        weights: (Union[str, list, tuple, np.ndarray]): If it\\'s string then tql will be run to calculate the weights based on the expression. list, tuple and ndarray will be treated as the list of the weights per sample\\n        replace: Optional[bool] If true the samples can be repeated in the result view.\\n            (default: ``True``).\\n        size: Optional[int] The length of the result view.\\n            (default: ``len(dataset)``)\\n\\n\\n    Returns:\\n        Dataset: A deeplake.Dataset object.\\n\\n    Raises:\\n        ValueError: When the given np.ndarray is multidimensional\\n\\n    Examples:\\n\\n        Sample the dataset with ``labels == 5`` twice more than ``labels == 6``\\n\\n        >>> import deeplake\\n        >>> from deeplake.experimental import query\\n        >>> ds = deeplake.load(\\'hub://activeloop/fashion-mnist-train\\')\\n        >>> sampled_ds = sample_by(ds, \"max_weight(labels == 5: 10, labels == 6: 5)\")\\n\\n        Sample the dataset treating `labels` tensor as weights.\\n\\n        >>> import deeplake\\n        >>> from deeplake.experimental import query\\n        >>> ds = deeplake.load(\\'hub://activeloop/fashion-mnist-train\\')\\n        >>> sampled_ds = sample_by(ds, \"labels\")\\n\\n        Sample the dataset with the given weights;\\n\\n        >>> ds = deeplake.load(\\'hub://activeloop/coco-train\\')\\n        >>> weights = list()\\n        >>> for i in range(0, len(ds)):\\n        >>>     weights.append(i % 5)\\n        >>> sampled_ds = sample_by(ds, weights, replace=False)\\n    '\n    if isinstance(weights, np.ndarray):\n        if len(weights.shape) != 1:\n            raise ValueError('weights should be 1 dimensional array.')\n        weights = tuple(weights)\n    ds = dataset_to_libdeeplake(dataset)\n    if size is None:\n        dsv = ds.sample(weights, replace=replace)\n    else:\n        dsv = ds.sample(weights, replace=replace, size=size)\n    indexes = list(dsv.indexes)\n    return dataset.no_view_dataset[indexes]",
            "def sample_by(dataset, weights: Union[str, list, tuple, np.ndarray], replace: Optional[bool]=True, size: Optional[int]=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Returns a sliced :class:`~deeplake.core.dataset.Dataset` with given sampler applied.\\n\\n\\n    Args:\\n        dataset: deeplake.Dataset object on which the query needs to be run\\n        weights: (Union[str, list, tuple, np.ndarray]): If it\\'s string then tql will be run to calculate the weights based on the expression. list, tuple and ndarray will be treated as the list of the weights per sample\\n        replace: Optional[bool] If true the samples can be repeated in the result view.\\n            (default: ``True``).\\n        size: Optional[int] The length of the result view.\\n            (default: ``len(dataset)``)\\n\\n\\n    Returns:\\n        Dataset: A deeplake.Dataset object.\\n\\n    Raises:\\n        ValueError: When the given np.ndarray is multidimensional\\n\\n    Examples:\\n\\n        Sample the dataset with ``labels == 5`` twice more than ``labels == 6``\\n\\n        >>> import deeplake\\n        >>> from deeplake.experimental import query\\n        >>> ds = deeplake.load(\\'hub://activeloop/fashion-mnist-train\\')\\n        >>> sampled_ds = sample_by(ds, \"max_weight(labels == 5: 10, labels == 6: 5)\")\\n\\n        Sample the dataset treating `labels` tensor as weights.\\n\\n        >>> import deeplake\\n        >>> from deeplake.experimental import query\\n        >>> ds = deeplake.load(\\'hub://activeloop/fashion-mnist-train\\')\\n        >>> sampled_ds = sample_by(ds, \"labels\")\\n\\n        Sample the dataset with the given weights;\\n\\n        >>> ds = deeplake.load(\\'hub://activeloop/coco-train\\')\\n        >>> weights = list()\\n        >>> for i in range(0, len(ds)):\\n        >>>     weights.append(i % 5)\\n        >>> sampled_ds = sample_by(ds, weights, replace=False)\\n    '\n    if isinstance(weights, np.ndarray):\n        if len(weights.shape) != 1:\n            raise ValueError('weights should be 1 dimensional array.')\n        weights = tuple(weights)\n    ds = dataset_to_libdeeplake(dataset)\n    if size is None:\n        dsv = ds.sample(weights, replace=replace)\n    else:\n        dsv = ds.sample(weights, replace=replace, size=size)\n    indexes = list(dsv.indexes)\n    return dataset.no_view_dataset[indexes]",
            "def sample_by(dataset, weights: Union[str, list, tuple, np.ndarray], replace: Optional[bool]=True, size: Optional[int]=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Returns a sliced :class:`~deeplake.core.dataset.Dataset` with given sampler applied.\\n\\n\\n    Args:\\n        dataset: deeplake.Dataset object on which the query needs to be run\\n        weights: (Union[str, list, tuple, np.ndarray]): If it\\'s string then tql will be run to calculate the weights based on the expression. list, tuple and ndarray will be treated as the list of the weights per sample\\n        replace: Optional[bool] If true the samples can be repeated in the result view.\\n            (default: ``True``).\\n        size: Optional[int] The length of the result view.\\n            (default: ``len(dataset)``)\\n\\n\\n    Returns:\\n        Dataset: A deeplake.Dataset object.\\n\\n    Raises:\\n        ValueError: When the given np.ndarray is multidimensional\\n\\n    Examples:\\n\\n        Sample the dataset with ``labels == 5`` twice more than ``labels == 6``\\n\\n        >>> import deeplake\\n        >>> from deeplake.experimental import query\\n        >>> ds = deeplake.load(\\'hub://activeloop/fashion-mnist-train\\')\\n        >>> sampled_ds = sample_by(ds, \"max_weight(labels == 5: 10, labels == 6: 5)\")\\n\\n        Sample the dataset treating `labels` tensor as weights.\\n\\n        >>> import deeplake\\n        >>> from deeplake.experimental import query\\n        >>> ds = deeplake.load(\\'hub://activeloop/fashion-mnist-train\\')\\n        >>> sampled_ds = sample_by(ds, \"labels\")\\n\\n        Sample the dataset with the given weights;\\n\\n        >>> ds = deeplake.load(\\'hub://activeloop/coco-train\\')\\n        >>> weights = list()\\n        >>> for i in range(0, len(ds)):\\n        >>>     weights.append(i % 5)\\n        >>> sampled_ds = sample_by(ds, weights, replace=False)\\n    '\n    if isinstance(weights, np.ndarray):\n        if len(weights.shape) != 1:\n            raise ValueError('weights should be 1 dimensional array.')\n        weights = tuple(weights)\n    ds = dataset_to_libdeeplake(dataset)\n    if size is None:\n        dsv = ds.sample(weights, replace=replace)\n    else:\n        dsv = ds.sample(weights, replace=replace, size=size)\n    indexes = list(dsv.indexes)\n    return dataset.no_view_dataset[indexes]"
        ]
    }
]