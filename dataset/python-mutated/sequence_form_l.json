[
    {
        "func_name": "_construct_lps",
        "original": "def _construct_lps(state, infosets, infoset_actions, infoset_action_maps, chance_reach, lps, parent_is_keys, parent_isa_keys):\n    \"\"\"Build the linear programs recursively from this state.\n\n  Args:\n    state: an open spiel state (root of the game tree)\n    infosets: a list of dicts, one per player, that maps infostate to an id. The\n      dicts are filled by this function and should initially only contain root\n      values.\n    infoset_actions: a list of dicts, one per player, that maps a string of\n      (infostate, action) pair to an id. The dicts are filled by this function\n      and should inirially only contain the root values\n    infoset_action_maps: a list of dicts, one per player, that maps each\n      info_state to a list of (infostate, action) string\n    chance_reach: the contribution of chance's reach probability (should start\n      at 1).\n    lps: a list of linear programs, one per player. The first one will be\n      constructred as in Eq (8) of Koller, Megiddo and von Stengel. The second\n      lp is Eq (9). Initially these should contain only the root-level\n      constraints and variables.\n    parent_is_keys: a list of parent information state keys for this state\n    parent_isa_keys: a list of parent (infostate, action) keys\n  \"\"\"\n    if state.is_terminal():\n        returns = state.returns()\n        lps[0].add_or_reuse_constraint(parent_isa_keys[0], lp_solver.CONS_TYPE_GEQ)\n        lps[0].add_to_cons_coeff(parent_isa_keys[0], parent_isa_keys[1], -1.0 * returns[0] * chance_reach)\n        lps[0].set_cons_coeff(parent_isa_keys[0], parent_is_keys[0], 1.0)\n        lps[1].add_or_reuse_constraint(parent_isa_keys[1], lp_solver.CONS_TYPE_LEQ)\n        lps[1].add_to_cons_coeff(parent_isa_keys[1], parent_isa_keys[0], -1.0 * returns[0] * chance_reach)\n        lps[1].set_cons_coeff(parent_isa_keys[1], parent_is_keys[1], -1.0)\n        return\n    if state.is_chance_node():\n        for (action, prob) in state.chance_outcomes():\n            new_state = state.child(action)\n            _construct_lps(new_state, infosets, infoset_actions, infoset_action_maps, prob * chance_reach, lps, parent_is_keys, parent_isa_keys)\n        return\n    player = state.current_player()\n    info_state = state.information_state_string(player)\n    legal_actions = state.legal_actions(player)\n    if player == 0:\n        lps[0].add_or_reuse_variable(info_state)\n        lps[0].add_or_reuse_constraint(parent_isa_keys[0], lp_solver.CONS_TYPE_GEQ)\n        lps[0].set_cons_coeff(parent_isa_keys[0], parent_is_keys[0], 1.0)\n        lps[0].set_cons_coeff(parent_isa_keys[0], info_state, -1.0)\n        lps[1].add_or_reuse_constraint(info_state, lp_solver.CONS_TYPE_EQ)\n        lps[1].set_cons_coeff(info_state, parent_isa_keys[0], -1.0)\n    else:\n        lps[1].add_or_reuse_variable(info_state)\n        lps[1].add_or_reuse_constraint(parent_isa_keys[1], lp_solver.CONS_TYPE_LEQ)\n        lps[1].set_cons_coeff(parent_isa_keys[1], parent_is_keys[1], -1.0)\n        lps[1].set_cons_coeff(parent_isa_keys[1], info_state, 1.0)\n        lps[0].add_or_reuse_constraint(info_state, lp_solver.CONS_TYPE_EQ)\n        lps[0].set_cons_coeff(info_state, parent_isa_keys[1], -1.0)\n    if info_state not in infosets[player]:\n        infosets[player][info_state] = len(infosets[player])\n    if info_state not in infoset_action_maps[player]:\n        infoset_action_maps[player][info_state] = []\n    new_parent_is_keys = parent_is_keys[:]\n    new_parent_is_keys[player] = info_state\n    for action in legal_actions:\n        isa_key = info_state + _DELIMITER + str(action)\n        if isa_key not in infoset_actions[player]:\n            infoset_actions[player][isa_key] = len(infoset_actions[player])\n        if isa_key not in infoset_action_maps[player][info_state]:\n            infoset_action_maps[player][info_state].append(isa_key)\n        if player == 0:\n            lps[1].add_or_reuse_variable(isa_key, lb=0)\n            lps[1].set_cons_coeff(info_state, isa_key, 1.0)\n        else:\n            lps[0].add_or_reuse_variable(isa_key, lb=0)\n            lps[0].set_cons_coeff(info_state, isa_key, 1.0)\n        new_parent_isa_keys = parent_isa_keys[:]\n        new_parent_isa_keys[player] = isa_key\n        new_state = state.child(action)\n        _construct_lps(new_state, infosets, infoset_actions, infoset_action_maps, chance_reach, lps, new_parent_is_keys, new_parent_isa_keys)",
        "mutated": [
            "def _construct_lps(state, infosets, infoset_actions, infoset_action_maps, chance_reach, lps, parent_is_keys, parent_isa_keys):\n    if False:\n        i = 10\n    \"Build the linear programs recursively from this state.\\n\\n  Args:\\n    state: an open spiel state (root of the game tree)\\n    infosets: a list of dicts, one per player, that maps infostate to an id. The\\n      dicts are filled by this function and should initially only contain root\\n      values.\\n    infoset_actions: a list of dicts, one per player, that maps a string of\\n      (infostate, action) pair to an id. The dicts are filled by this function\\n      and should inirially only contain the root values\\n    infoset_action_maps: a list of dicts, one per player, that maps each\\n      info_state to a list of (infostate, action) string\\n    chance_reach: the contribution of chance's reach probability (should start\\n      at 1).\\n    lps: a list of linear programs, one per player. The first one will be\\n      constructred as in Eq (8) of Koller, Megiddo and von Stengel. The second\\n      lp is Eq (9). Initially these should contain only the root-level\\n      constraints and variables.\\n    parent_is_keys: a list of parent information state keys for this state\\n    parent_isa_keys: a list of parent (infostate, action) keys\\n  \"\n    if state.is_terminal():\n        returns = state.returns()\n        lps[0].add_or_reuse_constraint(parent_isa_keys[0], lp_solver.CONS_TYPE_GEQ)\n        lps[0].add_to_cons_coeff(parent_isa_keys[0], parent_isa_keys[1], -1.0 * returns[0] * chance_reach)\n        lps[0].set_cons_coeff(parent_isa_keys[0], parent_is_keys[0], 1.0)\n        lps[1].add_or_reuse_constraint(parent_isa_keys[1], lp_solver.CONS_TYPE_LEQ)\n        lps[1].add_to_cons_coeff(parent_isa_keys[1], parent_isa_keys[0], -1.0 * returns[0] * chance_reach)\n        lps[1].set_cons_coeff(parent_isa_keys[1], parent_is_keys[1], -1.0)\n        return\n    if state.is_chance_node():\n        for (action, prob) in state.chance_outcomes():\n            new_state = state.child(action)\n            _construct_lps(new_state, infosets, infoset_actions, infoset_action_maps, prob * chance_reach, lps, parent_is_keys, parent_isa_keys)\n        return\n    player = state.current_player()\n    info_state = state.information_state_string(player)\n    legal_actions = state.legal_actions(player)\n    if player == 0:\n        lps[0].add_or_reuse_variable(info_state)\n        lps[0].add_or_reuse_constraint(parent_isa_keys[0], lp_solver.CONS_TYPE_GEQ)\n        lps[0].set_cons_coeff(parent_isa_keys[0], parent_is_keys[0], 1.0)\n        lps[0].set_cons_coeff(parent_isa_keys[0], info_state, -1.0)\n        lps[1].add_or_reuse_constraint(info_state, lp_solver.CONS_TYPE_EQ)\n        lps[1].set_cons_coeff(info_state, parent_isa_keys[0], -1.0)\n    else:\n        lps[1].add_or_reuse_variable(info_state)\n        lps[1].add_or_reuse_constraint(parent_isa_keys[1], lp_solver.CONS_TYPE_LEQ)\n        lps[1].set_cons_coeff(parent_isa_keys[1], parent_is_keys[1], -1.0)\n        lps[1].set_cons_coeff(parent_isa_keys[1], info_state, 1.0)\n        lps[0].add_or_reuse_constraint(info_state, lp_solver.CONS_TYPE_EQ)\n        lps[0].set_cons_coeff(info_state, parent_isa_keys[1], -1.0)\n    if info_state not in infosets[player]:\n        infosets[player][info_state] = len(infosets[player])\n    if info_state not in infoset_action_maps[player]:\n        infoset_action_maps[player][info_state] = []\n    new_parent_is_keys = parent_is_keys[:]\n    new_parent_is_keys[player] = info_state\n    for action in legal_actions:\n        isa_key = info_state + _DELIMITER + str(action)\n        if isa_key not in infoset_actions[player]:\n            infoset_actions[player][isa_key] = len(infoset_actions[player])\n        if isa_key not in infoset_action_maps[player][info_state]:\n            infoset_action_maps[player][info_state].append(isa_key)\n        if player == 0:\n            lps[1].add_or_reuse_variable(isa_key, lb=0)\n            lps[1].set_cons_coeff(info_state, isa_key, 1.0)\n        else:\n            lps[0].add_or_reuse_variable(isa_key, lb=0)\n            lps[0].set_cons_coeff(info_state, isa_key, 1.0)\n        new_parent_isa_keys = parent_isa_keys[:]\n        new_parent_isa_keys[player] = isa_key\n        new_state = state.child(action)\n        _construct_lps(new_state, infosets, infoset_actions, infoset_action_maps, chance_reach, lps, new_parent_is_keys, new_parent_isa_keys)",
            "def _construct_lps(state, infosets, infoset_actions, infoset_action_maps, chance_reach, lps, parent_is_keys, parent_isa_keys):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Build the linear programs recursively from this state.\\n\\n  Args:\\n    state: an open spiel state (root of the game tree)\\n    infosets: a list of dicts, one per player, that maps infostate to an id. The\\n      dicts are filled by this function and should initially only contain root\\n      values.\\n    infoset_actions: a list of dicts, one per player, that maps a string of\\n      (infostate, action) pair to an id. The dicts are filled by this function\\n      and should inirially only contain the root values\\n    infoset_action_maps: a list of dicts, one per player, that maps each\\n      info_state to a list of (infostate, action) string\\n    chance_reach: the contribution of chance's reach probability (should start\\n      at 1).\\n    lps: a list of linear programs, one per player. The first one will be\\n      constructred as in Eq (8) of Koller, Megiddo and von Stengel. The second\\n      lp is Eq (9). Initially these should contain only the root-level\\n      constraints and variables.\\n    parent_is_keys: a list of parent information state keys for this state\\n    parent_isa_keys: a list of parent (infostate, action) keys\\n  \"\n    if state.is_terminal():\n        returns = state.returns()\n        lps[0].add_or_reuse_constraint(parent_isa_keys[0], lp_solver.CONS_TYPE_GEQ)\n        lps[0].add_to_cons_coeff(parent_isa_keys[0], parent_isa_keys[1], -1.0 * returns[0] * chance_reach)\n        lps[0].set_cons_coeff(parent_isa_keys[0], parent_is_keys[0], 1.0)\n        lps[1].add_or_reuse_constraint(parent_isa_keys[1], lp_solver.CONS_TYPE_LEQ)\n        lps[1].add_to_cons_coeff(parent_isa_keys[1], parent_isa_keys[0], -1.0 * returns[0] * chance_reach)\n        lps[1].set_cons_coeff(parent_isa_keys[1], parent_is_keys[1], -1.0)\n        return\n    if state.is_chance_node():\n        for (action, prob) in state.chance_outcomes():\n            new_state = state.child(action)\n            _construct_lps(new_state, infosets, infoset_actions, infoset_action_maps, prob * chance_reach, lps, parent_is_keys, parent_isa_keys)\n        return\n    player = state.current_player()\n    info_state = state.information_state_string(player)\n    legal_actions = state.legal_actions(player)\n    if player == 0:\n        lps[0].add_or_reuse_variable(info_state)\n        lps[0].add_or_reuse_constraint(parent_isa_keys[0], lp_solver.CONS_TYPE_GEQ)\n        lps[0].set_cons_coeff(parent_isa_keys[0], parent_is_keys[0], 1.0)\n        lps[0].set_cons_coeff(parent_isa_keys[0], info_state, -1.0)\n        lps[1].add_or_reuse_constraint(info_state, lp_solver.CONS_TYPE_EQ)\n        lps[1].set_cons_coeff(info_state, parent_isa_keys[0], -1.0)\n    else:\n        lps[1].add_or_reuse_variable(info_state)\n        lps[1].add_or_reuse_constraint(parent_isa_keys[1], lp_solver.CONS_TYPE_LEQ)\n        lps[1].set_cons_coeff(parent_isa_keys[1], parent_is_keys[1], -1.0)\n        lps[1].set_cons_coeff(parent_isa_keys[1], info_state, 1.0)\n        lps[0].add_or_reuse_constraint(info_state, lp_solver.CONS_TYPE_EQ)\n        lps[0].set_cons_coeff(info_state, parent_isa_keys[1], -1.0)\n    if info_state not in infosets[player]:\n        infosets[player][info_state] = len(infosets[player])\n    if info_state not in infoset_action_maps[player]:\n        infoset_action_maps[player][info_state] = []\n    new_parent_is_keys = parent_is_keys[:]\n    new_parent_is_keys[player] = info_state\n    for action in legal_actions:\n        isa_key = info_state + _DELIMITER + str(action)\n        if isa_key not in infoset_actions[player]:\n            infoset_actions[player][isa_key] = len(infoset_actions[player])\n        if isa_key not in infoset_action_maps[player][info_state]:\n            infoset_action_maps[player][info_state].append(isa_key)\n        if player == 0:\n            lps[1].add_or_reuse_variable(isa_key, lb=0)\n            lps[1].set_cons_coeff(info_state, isa_key, 1.0)\n        else:\n            lps[0].add_or_reuse_variable(isa_key, lb=0)\n            lps[0].set_cons_coeff(info_state, isa_key, 1.0)\n        new_parent_isa_keys = parent_isa_keys[:]\n        new_parent_isa_keys[player] = isa_key\n        new_state = state.child(action)\n        _construct_lps(new_state, infosets, infoset_actions, infoset_action_maps, chance_reach, lps, new_parent_is_keys, new_parent_isa_keys)",
            "def _construct_lps(state, infosets, infoset_actions, infoset_action_maps, chance_reach, lps, parent_is_keys, parent_isa_keys):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Build the linear programs recursively from this state.\\n\\n  Args:\\n    state: an open spiel state (root of the game tree)\\n    infosets: a list of dicts, one per player, that maps infostate to an id. The\\n      dicts are filled by this function and should initially only contain root\\n      values.\\n    infoset_actions: a list of dicts, one per player, that maps a string of\\n      (infostate, action) pair to an id. The dicts are filled by this function\\n      and should inirially only contain the root values\\n    infoset_action_maps: a list of dicts, one per player, that maps each\\n      info_state to a list of (infostate, action) string\\n    chance_reach: the contribution of chance's reach probability (should start\\n      at 1).\\n    lps: a list of linear programs, one per player. The first one will be\\n      constructred as in Eq (8) of Koller, Megiddo and von Stengel. The second\\n      lp is Eq (9). Initially these should contain only the root-level\\n      constraints and variables.\\n    parent_is_keys: a list of parent information state keys for this state\\n    parent_isa_keys: a list of parent (infostate, action) keys\\n  \"\n    if state.is_terminal():\n        returns = state.returns()\n        lps[0].add_or_reuse_constraint(parent_isa_keys[0], lp_solver.CONS_TYPE_GEQ)\n        lps[0].add_to_cons_coeff(parent_isa_keys[0], parent_isa_keys[1], -1.0 * returns[0] * chance_reach)\n        lps[0].set_cons_coeff(parent_isa_keys[0], parent_is_keys[0], 1.0)\n        lps[1].add_or_reuse_constraint(parent_isa_keys[1], lp_solver.CONS_TYPE_LEQ)\n        lps[1].add_to_cons_coeff(parent_isa_keys[1], parent_isa_keys[0], -1.0 * returns[0] * chance_reach)\n        lps[1].set_cons_coeff(parent_isa_keys[1], parent_is_keys[1], -1.0)\n        return\n    if state.is_chance_node():\n        for (action, prob) in state.chance_outcomes():\n            new_state = state.child(action)\n            _construct_lps(new_state, infosets, infoset_actions, infoset_action_maps, prob * chance_reach, lps, parent_is_keys, parent_isa_keys)\n        return\n    player = state.current_player()\n    info_state = state.information_state_string(player)\n    legal_actions = state.legal_actions(player)\n    if player == 0:\n        lps[0].add_or_reuse_variable(info_state)\n        lps[0].add_or_reuse_constraint(parent_isa_keys[0], lp_solver.CONS_TYPE_GEQ)\n        lps[0].set_cons_coeff(parent_isa_keys[0], parent_is_keys[0], 1.0)\n        lps[0].set_cons_coeff(parent_isa_keys[0], info_state, -1.0)\n        lps[1].add_or_reuse_constraint(info_state, lp_solver.CONS_TYPE_EQ)\n        lps[1].set_cons_coeff(info_state, parent_isa_keys[0], -1.0)\n    else:\n        lps[1].add_or_reuse_variable(info_state)\n        lps[1].add_or_reuse_constraint(parent_isa_keys[1], lp_solver.CONS_TYPE_LEQ)\n        lps[1].set_cons_coeff(parent_isa_keys[1], parent_is_keys[1], -1.0)\n        lps[1].set_cons_coeff(parent_isa_keys[1], info_state, 1.0)\n        lps[0].add_or_reuse_constraint(info_state, lp_solver.CONS_TYPE_EQ)\n        lps[0].set_cons_coeff(info_state, parent_isa_keys[1], -1.0)\n    if info_state not in infosets[player]:\n        infosets[player][info_state] = len(infosets[player])\n    if info_state not in infoset_action_maps[player]:\n        infoset_action_maps[player][info_state] = []\n    new_parent_is_keys = parent_is_keys[:]\n    new_parent_is_keys[player] = info_state\n    for action in legal_actions:\n        isa_key = info_state + _DELIMITER + str(action)\n        if isa_key not in infoset_actions[player]:\n            infoset_actions[player][isa_key] = len(infoset_actions[player])\n        if isa_key not in infoset_action_maps[player][info_state]:\n            infoset_action_maps[player][info_state].append(isa_key)\n        if player == 0:\n            lps[1].add_or_reuse_variable(isa_key, lb=0)\n            lps[1].set_cons_coeff(info_state, isa_key, 1.0)\n        else:\n            lps[0].add_or_reuse_variable(isa_key, lb=0)\n            lps[0].set_cons_coeff(info_state, isa_key, 1.0)\n        new_parent_isa_keys = parent_isa_keys[:]\n        new_parent_isa_keys[player] = isa_key\n        new_state = state.child(action)\n        _construct_lps(new_state, infosets, infoset_actions, infoset_action_maps, chance_reach, lps, new_parent_is_keys, new_parent_isa_keys)",
            "def _construct_lps(state, infosets, infoset_actions, infoset_action_maps, chance_reach, lps, parent_is_keys, parent_isa_keys):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Build the linear programs recursively from this state.\\n\\n  Args:\\n    state: an open spiel state (root of the game tree)\\n    infosets: a list of dicts, one per player, that maps infostate to an id. The\\n      dicts are filled by this function and should initially only contain root\\n      values.\\n    infoset_actions: a list of dicts, one per player, that maps a string of\\n      (infostate, action) pair to an id. The dicts are filled by this function\\n      and should inirially only contain the root values\\n    infoset_action_maps: a list of dicts, one per player, that maps each\\n      info_state to a list of (infostate, action) string\\n    chance_reach: the contribution of chance's reach probability (should start\\n      at 1).\\n    lps: a list of linear programs, one per player. The first one will be\\n      constructred as in Eq (8) of Koller, Megiddo and von Stengel. The second\\n      lp is Eq (9). Initially these should contain only the root-level\\n      constraints and variables.\\n    parent_is_keys: a list of parent information state keys for this state\\n    parent_isa_keys: a list of parent (infostate, action) keys\\n  \"\n    if state.is_terminal():\n        returns = state.returns()\n        lps[0].add_or_reuse_constraint(parent_isa_keys[0], lp_solver.CONS_TYPE_GEQ)\n        lps[0].add_to_cons_coeff(parent_isa_keys[0], parent_isa_keys[1], -1.0 * returns[0] * chance_reach)\n        lps[0].set_cons_coeff(parent_isa_keys[0], parent_is_keys[0], 1.0)\n        lps[1].add_or_reuse_constraint(parent_isa_keys[1], lp_solver.CONS_TYPE_LEQ)\n        lps[1].add_to_cons_coeff(parent_isa_keys[1], parent_isa_keys[0], -1.0 * returns[0] * chance_reach)\n        lps[1].set_cons_coeff(parent_isa_keys[1], parent_is_keys[1], -1.0)\n        return\n    if state.is_chance_node():\n        for (action, prob) in state.chance_outcomes():\n            new_state = state.child(action)\n            _construct_lps(new_state, infosets, infoset_actions, infoset_action_maps, prob * chance_reach, lps, parent_is_keys, parent_isa_keys)\n        return\n    player = state.current_player()\n    info_state = state.information_state_string(player)\n    legal_actions = state.legal_actions(player)\n    if player == 0:\n        lps[0].add_or_reuse_variable(info_state)\n        lps[0].add_or_reuse_constraint(parent_isa_keys[0], lp_solver.CONS_TYPE_GEQ)\n        lps[0].set_cons_coeff(parent_isa_keys[0], parent_is_keys[0], 1.0)\n        lps[0].set_cons_coeff(parent_isa_keys[0], info_state, -1.0)\n        lps[1].add_or_reuse_constraint(info_state, lp_solver.CONS_TYPE_EQ)\n        lps[1].set_cons_coeff(info_state, parent_isa_keys[0], -1.0)\n    else:\n        lps[1].add_or_reuse_variable(info_state)\n        lps[1].add_or_reuse_constraint(parent_isa_keys[1], lp_solver.CONS_TYPE_LEQ)\n        lps[1].set_cons_coeff(parent_isa_keys[1], parent_is_keys[1], -1.0)\n        lps[1].set_cons_coeff(parent_isa_keys[1], info_state, 1.0)\n        lps[0].add_or_reuse_constraint(info_state, lp_solver.CONS_TYPE_EQ)\n        lps[0].set_cons_coeff(info_state, parent_isa_keys[1], -1.0)\n    if info_state not in infosets[player]:\n        infosets[player][info_state] = len(infosets[player])\n    if info_state not in infoset_action_maps[player]:\n        infoset_action_maps[player][info_state] = []\n    new_parent_is_keys = parent_is_keys[:]\n    new_parent_is_keys[player] = info_state\n    for action in legal_actions:\n        isa_key = info_state + _DELIMITER + str(action)\n        if isa_key not in infoset_actions[player]:\n            infoset_actions[player][isa_key] = len(infoset_actions[player])\n        if isa_key not in infoset_action_maps[player][info_state]:\n            infoset_action_maps[player][info_state].append(isa_key)\n        if player == 0:\n            lps[1].add_or_reuse_variable(isa_key, lb=0)\n            lps[1].set_cons_coeff(info_state, isa_key, 1.0)\n        else:\n            lps[0].add_or_reuse_variable(isa_key, lb=0)\n            lps[0].set_cons_coeff(info_state, isa_key, 1.0)\n        new_parent_isa_keys = parent_isa_keys[:]\n        new_parent_isa_keys[player] = isa_key\n        new_state = state.child(action)\n        _construct_lps(new_state, infosets, infoset_actions, infoset_action_maps, chance_reach, lps, new_parent_is_keys, new_parent_isa_keys)",
            "def _construct_lps(state, infosets, infoset_actions, infoset_action_maps, chance_reach, lps, parent_is_keys, parent_isa_keys):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Build the linear programs recursively from this state.\\n\\n  Args:\\n    state: an open spiel state (root of the game tree)\\n    infosets: a list of dicts, one per player, that maps infostate to an id. The\\n      dicts are filled by this function and should initially only contain root\\n      values.\\n    infoset_actions: a list of dicts, one per player, that maps a string of\\n      (infostate, action) pair to an id. The dicts are filled by this function\\n      and should inirially only contain the root values\\n    infoset_action_maps: a list of dicts, one per player, that maps each\\n      info_state to a list of (infostate, action) string\\n    chance_reach: the contribution of chance's reach probability (should start\\n      at 1).\\n    lps: a list of linear programs, one per player. The first one will be\\n      constructred as in Eq (8) of Koller, Megiddo and von Stengel. The second\\n      lp is Eq (9). Initially these should contain only the root-level\\n      constraints and variables.\\n    parent_is_keys: a list of parent information state keys for this state\\n    parent_isa_keys: a list of parent (infostate, action) keys\\n  \"\n    if state.is_terminal():\n        returns = state.returns()\n        lps[0].add_or_reuse_constraint(parent_isa_keys[0], lp_solver.CONS_TYPE_GEQ)\n        lps[0].add_to_cons_coeff(parent_isa_keys[0], parent_isa_keys[1], -1.0 * returns[0] * chance_reach)\n        lps[0].set_cons_coeff(parent_isa_keys[0], parent_is_keys[0], 1.0)\n        lps[1].add_or_reuse_constraint(parent_isa_keys[1], lp_solver.CONS_TYPE_LEQ)\n        lps[1].add_to_cons_coeff(parent_isa_keys[1], parent_isa_keys[0], -1.0 * returns[0] * chance_reach)\n        lps[1].set_cons_coeff(parent_isa_keys[1], parent_is_keys[1], -1.0)\n        return\n    if state.is_chance_node():\n        for (action, prob) in state.chance_outcomes():\n            new_state = state.child(action)\n            _construct_lps(new_state, infosets, infoset_actions, infoset_action_maps, prob * chance_reach, lps, parent_is_keys, parent_isa_keys)\n        return\n    player = state.current_player()\n    info_state = state.information_state_string(player)\n    legal_actions = state.legal_actions(player)\n    if player == 0:\n        lps[0].add_or_reuse_variable(info_state)\n        lps[0].add_or_reuse_constraint(parent_isa_keys[0], lp_solver.CONS_TYPE_GEQ)\n        lps[0].set_cons_coeff(parent_isa_keys[0], parent_is_keys[0], 1.0)\n        lps[0].set_cons_coeff(parent_isa_keys[0], info_state, -1.0)\n        lps[1].add_or_reuse_constraint(info_state, lp_solver.CONS_TYPE_EQ)\n        lps[1].set_cons_coeff(info_state, parent_isa_keys[0], -1.0)\n    else:\n        lps[1].add_or_reuse_variable(info_state)\n        lps[1].add_or_reuse_constraint(parent_isa_keys[1], lp_solver.CONS_TYPE_LEQ)\n        lps[1].set_cons_coeff(parent_isa_keys[1], parent_is_keys[1], -1.0)\n        lps[1].set_cons_coeff(parent_isa_keys[1], info_state, 1.0)\n        lps[0].add_or_reuse_constraint(info_state, lp_solver.CONS_TYPE_EQ)\n        lps[0].set_cons_coeff(info_state, parent_isa_keys[1], -1.0)\n    if info_state not in infosets[player]:\n        infosets[player][info_state] = len(infosets[player])\n    if info_state not in infoset_action_maps[player]:\n        infoset_action_maps[player][info_state] = []\n    new_parent_is_keys = parent_is_keys[:]\n    new_parent_is_keys[player] = info_state\n    for action in legal_actions:\n        isa_key = info_state + _DELIMITER + str(action)\n        if isa_key not in infoset_actions[player]:\n            infoset_actions[player][isa_key] = len(infoset_actions[player])\n        if isa_key not in infoset_action_maps[player][info_state]:\n            infoset_action_maps[player][info_state].append(isa_key)\n        if player == 0:\n            lps[1].add_or_reuse_variable(isa_key, lb=0)\n            lps[1].set_cons_coeff(info_state, isa_key, 1.0)\n        else:\n            lps[0].add_or_reuse_variable(isa_key, lb=0)\n            lps[0].set_cons_coeff(info_state, isa_key, 1.0)\n        new_parent_isa_keys = parent_isa_keys[:]\n        new_parent_isa_keys[player] = isa_key\n        new_state = state.child(action)\n        _construct_lps(new_state, infosets, infoset_actions, infoset_action_maps, chance_reach, lps, new_parent_is_keys, new_parent_isa_keys)"
        ]
    },
    {
        "func_name": "solve_zero_sum_game",
        "original": "def solve_zero_sum_game(game, solver=None):\n    \"\"\"Solve the two-player zero-sum game using sequence-form LPs.\n\n  Args:\n    game: the spiel game tp solve (must be zero-sum, sequential, and have chance\n      mode of deterministic or explicit stochastic).\n    solver: a specific solver to use, sent to cvxopt (i.e. 'lapack', 'blas',\n      'glpk'). A value of None uses cvxopt's default solver.\n\n  Returns:\n    A 4-tuple containing:\n      - player 0 value\n      - player 1 value\n      - player 0 policy: a policy.TabularPolicy for player 0\n      - player 1 policy: a policy.TabularPolicy for player 1\n  \"\"\"\n    assert game.num_players() == 2\n    assert game.get_type().utility == pyspiel.GameType.Utility.ZERO_SUM\n    assert game.get_type().dynamics == pyspiel.GameType.Dynamics.SEQUENTIAL\n    assert game.get_type().chance_mode == pyspiel.GameType.ChanceMode.DETERMINISTIC or game.get_type().chance_mode == pyspiel.GameType.ChanceMode.EXPLICIT_STOCHASTIC\n    infosets = [{_EMPTY_INFOSET_KEYS[0]: 0}, {_EMPTY_INFOSET_KEYS[1]: 0}]\n    infoset_actions = [{_EMPTY_INFOSET_ACTION_KEYS[0]: 0}, {_EMPTY_INFOSET_ACTION_KEYS[1]: 0}]\n    infoset_action_maps = [{}, {}]\n    lps = [lp_solver.LinearProgram(lp_solver.OBJ_MIN), lp_solver.LinearProgram(lp_solver.OBJ_MAX)]\n    lps[0].add_or_reuse_variable(_EMPTY_INFOSET_ACTION_KEYS[1], lb=0)\n    lps[0].add_or_reuse_variable(_EMPTY_INFOSET_KEYS[0])\n    lps[1].add_or_reuse_variable(_EMPTY_INFOSET_ACTION_KEYS[0], lb=0)\n    lps[1].add_or_reuse_variable(_EMPTY_INFOSET_KEYS[1])\n    lps[0].set_obj_coeff(_EMPTY_INFOSET_KEYS[0], 1.0)\n    lps[1].set_obj_coeff(_EMPTY_INFOSET_KEYS[1], -1.0)\n    lps[0].add_or_reuse_constraint(_EMPTY_INFOSET_KEYS[1], lp_solver.CONS_TYPE_EQ)\n    lps[0].set_cons_coeff(_EMPTY_INFOSET_KEYS[1], _EMPTY_INFOSET_ACTION_KEYS[1], -1.0)\n    lps[0].set_cons_rhs(_EMPTY_INFOSET_KEYS[1], -1.0)\n    lps[1].add_or_reuse_constraint(_EMPTY_INFOSET_KEYS[0], lp_solver.CONS_TYPE_EQ)\n    lps[1].set_cons_coeff(_EMPTY_INFOSET_KEYS[0], _EMPTY_INFOSET_ACTION_KEYS[0], 1.0)\n    lps[1].set_cons_rhs(_EMPTY_INFOSET_KEYS[0], 1.0)\n    _construct_lps(game.new_initial_state(), infosets, infoset_actions, infoset_action_maps, 1.0, lps, _EMPTY_INFOSET_KEYS[:], _EMPTY_INFOSET_ACTION_KEYS[:])\n    solutions = [lps[0].solve(solver=solver), lps[1].solve(solver=solver)]\n    policies = [policy.TabularPolicy(game), policy.TabularPolicy(game)]\n    for i in range(2):\n        for info_state in infoset_action_maps[i]:\n            total_weight = 0\n            num_actions = 0\n            for isa_key in infoset_action_maps[i][info_state]:\n                total_weight += solutions[1 - i][lps[1 - i].get_var_id(isa_key)]\n                num_actions += 1\n            unif_pr = 1.0 / num_actions\n            state_policy = policies[i].policy_for_key(info_state)\n            for isa_key in infoset_action_maps[i][info_state]:\n                rel_weight = solutions[1 - i][lps[1 - i].get_var_id(isa_key)]\n                (_, action_str) = isa_key.split(_DELIMITER)\n                action = int(action_str)\n                pr_action = rel_weight / total_weight if total_weight > 0 else unif_pr\n                state_policy[action] = pr_action\n    return (solutions[0][lps[0].get_var_id(_EMPTY_INFOSET_KEYS[0])], solutions[1][lps[1].get_var_id(_EMPTY_INFOSET_KEYS[1])], policies[0], policies[1])",
        "mutated": [
            "def solve_zero_sum_game(game, solver=None):\n    if False:\n        i = 10\n    \"Solve the two-player zero-sum game using sequence-form LPs.\\n\\n  Args:\\n    game: the spiel game tp solve (must be zero-sum, sequential, and have chance\\n      mode of deterministic or explicit stochastic).\\n    solver: a specific solver to use, sent to cvxopt (i.e. 'lapack', 'blas',\\n      'glpk'). A value of None uses cvxopt's default solver.\\n\\n  Returns:\\n    A 4-tuple containing:\\n      - player 0 value\\n      - player 1 value\\n      - player 0 policy: a policy.TabularPolicy for player 0\\n      - player 1 policy: a policy.TabularPolicy for player 1\\n  \"\n    assert game.num_players() == 2\n    assert game.get_type().utility == pyspiel.GameType.Utility.ZERO_SUM\n    assert game.get_type().dynamics == pyspiel.GameType.Dynamics.SEQUENTIAL\n    assert game.get_type().chance_mode == pyspiel.GameType.ChanceMode.DETERMINISTIC or game.get_type().chance_mode == pyspiel.GameType.ChanceMode.EXPLICIT_STOCHASTIC\n    infosets = [{_EMPTY_INFOSET_KEYS[0]: 0}, {_EMPTY_INFOSET_KEYS[1]: 0}]\n    infoset_actions = [{_EMPTY_INFOSET_ACTION_KEYS[0]: 0}, {_EMPTY_INFOSET_ACTION_KEYS[1]: 0}]\n    infoset_action_maps = [{}, {}]\n    lps = [lp_solver.LinearProgram(lp_solver.OBJ_MIN), lp_solver.LinearProgram(lp_solver.OBJ_MAX)]\n    lps[0].add_or_reuse_variable(_EMPTY_INFOSET_ACTION_KEYS[1], lb=0)\n    lps[0].add_or_reuse_variable(_EMPTY_INFOSET_KEYS[0])\n    lps[1].add_or_reuse_variable(_EMPTY_INFOSET_ACTION_KEYS[0], lb=0)\n    lps[1].add_or_reuse_variable(_EMPTY_INFOSET_KEYS[1])\n    lps[0].set_obj_coeff(_EMPTY_INFOSET_KEYS[0], 1.0)\n    lps[1].set_obj_coeff(_EMPTY_INFOSET_KEYS[1], -1.0)\n    lps[0].add_or_reuse_constraint(_EMPTY_INFOSET_KEYS[1], lp_solver.CONS_TYPE_EQ)\n    lps[0].set_cons_coeff(_EMPTY_INFOSET_KEYS[1], _EMPTY_INFOSET_ACTION_KEYS[1], -1.0)\n    lps[0].set_cons_rhs(_EMPTY_INFOSET_KEYS[1], -1.0)\n    lps[1].add_or_reuse_constraint(_EMPTY_INFOSET_KEYS[0], lp_solver.CONS_TYPE_EQ)\n    lps[1].set_cons_coeff(_EMPTY_INFOSET_KEYS[0], _EMPTY_INFOSET_ACTION_KEYS[0], 1.0)\n    lps[1].set_cons_rhs(_EMPTY_INFOSET_KEYS[0], 1.0)\n    _construct_lps(game.new_initial_state(), infosets, infoset_actions, infoset_action_maps, 1.0, lps, _EMPTY_INFOSET_KEYS[:], _EMPTY_INFOSET_ACTION_KEYS[:])\n    solutions = [lps[0].solve(solver=solver), lps[1].solve(solver=solver)]\n    policies = [policy.TabularPolicy(game), policy.TabularPolicy(game)]\n    for i in range(2):\n        for info_state in infoset_action_maps[i]:\n            total_weight = 0\n            num_actions = 0\n            for isa_key in infoset_action_maps[i][info_state]:\n                total_weight += solutions[1 - i][lps[1 - i].get_var_id(isa_key)]\n                num_actions += 1\n            unif_pr = 1.0 / num_actions\n            state_policy = policies[i].policy_for_key(info_state)\n            for isa_key in infoset_action_maps[i][info_state]:\n                rel_weight = solutions[1 - i][lps[1 - i].get_var_id(isa_key)]\n                (_, action_str) = isa_key.split(_DELIMITER)\n                action = int(action_str)\n                pr_action = rel_weight / total_weight if total_weight > 0 else unif_pr\n                state_policy[action] = pr_action\n    return (solutions[0][lps[0].get_var_id(_EMPTY_INFOSET_KEYS[0])], solutions[1][lps[1].get_var_id(_EMPTY_INFOSET_KEYS[1])], policies[0], policies[1])",
            "def solve_zero_sum_game(game, solver=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Solve the two-player zero-sum game using sequence-form LPs.\\n\\n  Args:\\n    game: the spiel game tp solve (must be zero-sum, sequential, and have chance\\n      mode of deterministic or explicit stochastic).\\n    solver: a specific solver to use, sent to cvxopt (i.e. 'lapack', 'blas',\\n      'glpk'). A value of None uses cvxopt's default solver.\\n\\n  Returns:\\n    A 4-tuple containing:\\n      - player 0 value\\n      - player 1 value\\n      - player 0 policy: a policy.TabularPolicy for player 0\\n      - player 1 policy: a policy.TabularPolicy for player 1\\n  \"\n    assert game.num_players() == 2\n    assert game.get_type().utility == pyspiel.GameType.Utility.ZERO_SUM\n    assert game.get_type().dynamics == pyspiel.GameType.Dynamics.SEQUENTIAL\n    assert game.get_type().chance_mode == pyspiel.GameType.ChanceMode.DETERMINISTIC or game.get_type().chance_mode == pyspiel.GameType.ChanceMode.EXPLICIT_STOCHASTIC\n    infosets = [{_EMPTY_INFOSET_KEYS[0]: 0}, {_EMPTY_INFOSET_KEYS[1]: 0}]\n    infoset_actions = [{_EMPTY_INFOSET_ACTION_KEYS[0]: 0}, {_EMPTY_INFOSET_ACTION_KEYS[1]: 0}]\n    infoset_action_maps = [{}, {}]\n    lps = [lp_solver.LinearProgram(lp_solver.OBJ_MIN), lp_solver.LinearProgram(lp_solver.OBJ_MAX)]\n    lps[0].add_or_reuse_variable(_EMPTY_INFOSET_ACTION_KEYS[1], lb=0)\n    lps[0].add_or_reuse_variable(_EMPTY_INFOSET_KEYS[0])\n    lps[1].add_or_reuse_variable(_EMPTY_INFOSET_ACTION_KEYS[0], lb=0)\n    lps[1].add_or_reuse_variable(_EMPTY_INFOSET_KEYS[1])\n    lps[0].set_obj_coeff(_EMPTY_INFOSET_KEYS[0], 1.0)\n    lps[1].set_obj_coeff(_EMPTY_INFOSET_KEYS[1], -1.0)\n    lps[0].add_or_reuse_constraint(_EMPTY_INFOSET_KEYS[1], lp_solver.CONS_TYPE_EQ)\n    lps[0].set_cons_coeff(_EMPTY_INFOSET_KEYS[1], _EMPTY_INFOSET_ACTION_KEYS[1], -1.0)\n    lps[0].set_cons_rhs(_EMPTY_INFOSET_KEYS[1], -1.0)\n    lps[1].add_or_reuse_constraint(_EMPTY_INFOSET_KEYS[0], lp_solver.CONS_TYPE_EQ)\n    lps[1].set_cons_coeff(_EMPTY_INFOSET_KEYS[0], _EMPTY_INFOSET_ACTION_KEYS[0], 1.0)\n    lps[1].set_cons_rhs(_EMPTY_INFOSET_KEYS[0], 1.0)\n    _construct_lps(game.new_initial_state(), infosets, infoset_actions, infoset_action_maps, 1.0, lps, _EMPTY_INFOSET_KEYS[:], _EMPTY_INFOSET_ACTION_KEYS[:])\n    solutions = [lps[0].solve(solver=solver), lps[1].solve(solver=solver)]\n    policies = [policy.TabularPolicy(game), policy.TabularPolicy(game)]\n    for i in range(2):\n        for info_state in infoset_action_maps[i]:\n            total_weight = 0\n            num_actions = 0\n            for isa_key in infoset_action_maps[i][info_state]:\n                total_weight += solutions[1 - i][lps[1 - i].get_var_id(isa_key)]\n                num_actions += 1\n            unif_pr = 1.0 / num_actions\n            state_policy = policies[i].policy_for_key(info_state)\n            for isa_key in infoset_action_maps[i][info_state]:\n                rel_weight = solutions[1 - i][lps[1 - i].get_var_id(isa_key)]\n                (_, action_str) = isa_key.split(_DELIMITER)\n                action = int(action_str)\n                pr_action = rel_weight / total_weight if total_weight > 0 else unif_pr\n                state_policy[action] = pr_action\n    return (solutions[0][lps[0].get_var_id(_EMPTY_INFOSET_KEYS[0])], solutions[1][lps[1].get_var_id(_EMPTY_INFOSET_KEYS[1])], policies[0], policies[1])",
            "def solve_zero_sum_game(game, solver=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Solve the two-player zero-sum game using sequence-form LPs.\\n\\n  Args:\\n    game: the spiel game tp solve (must be zero-sum, sequential, and have chance\\n      mode of deterministic or explicit stochastic).\\n    solver: a specific solver to use, sent to cvxopt (i.e. 'lapack', 'blas',\\n      'glpk'). A value of None uses cvxopt's default solver.\\n\\n  Returns:\\n    A 4-tuple containing:\\n      - player 0 value\\n      - player 1 value\\n      - player 0 policy: a policy.TabularPolicy for player 0\\n      - player 1 policy: a policy.TabularPolicy for player 1\\n  \"\n    assert game.num_players() == 2\n    assert game.get_type().utility == pyspiel.GameType.Utility.ZERO_SUM\n    assert game.get_type().dynamics == pyspiel.GameType.Dynamics.SEQUENTIAL\n    assert game.get_type().chance_mode == pyspiel.GameType.ChanceMode.DETERMINISTIC or game.get_type().chance_mode == pyspiel.GameType.ChanceMode.EXPLICIT_STOCHASTIC\n    infosets = [{_EMPTY_INFOSET_KEYS[0]: 0}, {_EMPTY_INFOSET_KEYS[1]: 0}]\n    infoset_actions = [{_EMPTY_INFOSET_ACTION_KEYS[0]: 0}, {_EMPTY_INFOSET_ACTION_KEYS[1]: 0}]\n    infoset_action_maps = [{}, {}]\n    lps = [lp_solver.LinearProgram(lp_solver.OBJ_MIN), lp_solver.LinearProgram(lp_solver.OBJ_MAX)]\n    lps[0].add_or_reuse_variable(_EMPTY_INFOSET_ACTION_KEYS[1], lb=0)\n    lps[0].add_or_reuse_variable(_EMPTY_INFOSET_KEYS[0])\n    lps[1].add_or_reuse_variable(_EMPTY_INFOSET_ACTION_KEYS[0], lb=0)\n    lps[1].add_or_reuse_variable(_EMPTY_INFOSET_KEYS[1])\n    lps[0].set_obj_coeff(_EMPTY_INFOSET_KEYS[0], 1.0)\n    lps[1].set_obj_coeff(_EMPTY_INFOSET_KEYS[1], -1.0)\n    lps[0].add_or_reuse_constraint(_EMPTY_INFOSET_KEYS[1], lp_solver.CONS_TYPE_EQ)\n    lps[0].set_cons_coeff(_EMPTY_INFOSET_KEYS[1], _EMPTY_INFOSET_ACTION_KEYS[1], -1.0)\n    lps[0].set_cons_rhs(_EMPTY_INFOSET_KEYS[1], -1.0)\n    lps[1].add_or_reuse_constraint(_EMPTY_INFOSET_KEYS[0], lp_solver.CONS_TYPE_EQ)\n    lps[1].set_cons_coeff(_EMPTY_INFOSET_KEYS[0], _EMPTY_INFOSET_ACTION_KEYS[0], 1.0)\n    lps[1].set_cons_rhs(_EMPTY_INFOSET_KEYS[0], 1.0)\n    _construct_lps(game.new_initial_state(), infosets, infoset_actions, infoset_action_maps, 1.0, lps, _EMPTY_INFOSET_KEYS[:], _EMPTY_INFOSET_ACTION_KEYS[:])\n    solutions = [lps[0].solve(solver=solver), lps[1].solve(solver=solver)]\n    policies = [policy.TabularPolicy(game), policy.TabularPolicy(game)]\n    for i in range(2):\n        for info_state in infoset_action_maps[i]:\n            total_weight = 0\n            num_actions = 0\n            for isa_key in infoset_action_maps[i][info_state]:\n                total_weight += solutions[1 - i][lps[1 - i].get_var_id(isa_key)]\n                num_actions += 1\n            unif_pr = 1.0 / num_actions\n            state_policy = policies[i].policy_for_key(info_state)\n            for isa_key in infoset_action_maps[i][info_state]:\n                rel_weight = solutions[1 - i][lps[1 - i].get_var_id(isa_key)]\n                (_, action_str) = isa_key.split(_DELIMITER)\n                action = int(action_str)\n                pr_action = rel_weight / total_weight if total_weight > 0 else unif_pr\n                state_policy[action] = pr_action\n    return (solutions[0][lps[0].get_var_id(_EMPTY_INFOSET_KEYS[0])], solutions[1][lps[1].get_var_id(_EMPTY_INFOSET_KEYS[1])], policies[0], policies[1])",
            "def solve_zero_sum_game(game, solver=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Solve the two-player zero-sum game using sequence-form LPs.\\n\\n  Args:\\n    game: the spiel game tp solve (must be zero-sum, sequential, and have chance\\n      mode of deterministic or explicit stochastic).\\n    solver: a specific solver to use, sent to cvxopt (i.e. 'lapack', 'blas',\\n      'glpk'). A value of None uses cvxopt's default solver.\\n\\n  Returns:\\n    A 4-tuple containing:\\n      - player 0 value\\n      - player 1 value\\n      - player 0 policy: a policy.TabularPolicy for player 0\\n      - player 1 policy: a policy.TabularPolicy for player 1\\n  \"\n    assert game.num_players() == 2\n    assert game.get_type().utility == pyspiel.GameType.Utility.ZERO_SUM\n    assert game.get_type().dynamics == pyspiel.GameType.Dynamics.SEQUENTIAL\n    assert game.get_type().chance_mode == pyspiel.GameType.ChanceMode.DETERMINISTIC or game.get_type().chance_mode == pyspiel.GameType.ChanceMode.EXPLICIT_STOCHASTIC\n    infosets = [{_EMPTY_INFOSET_KEYS[0]: 0}, {_EMPTY_INFOSET_KEYS[1]: 0}]\n    infoset_actions = [{_EMPTY_INFOSET_ACTION_KEYS[0]: 0}, {_EMPTY_INFOSET_ACTION_KEYS[1]: 0}]\n    infoset_action_maps = [{}, {}]\n    lps = [lp_solver.LinearProgram(lp_solver.OBJ_MIN), lp_solver.LinearProgram(lp_solver.OBJ_MAX)]\n    lps[0].add_or_reuse_variable(_EMPTY_INFOSET_ACTION_KEYS[1], lb=0)\n    lps[0].add_or_reuse_variable(_EMPTY_INFOSET_KEYS[0])\n    lps[1].add_or_reuse_variable(_EMPTY_INFOSET_ACTION_KEYS[0], lb=0)\n    lps[1].add_or_reuse_variable(_EMPTY_INFOSET_KEYS[1])\n    lps[0].set_obj_coeff(_EMPTY_INFOSET_KEYS[0], 1.0)\n    lps[1].set_obj_coeff(_EMPTY_INFOSET_KEYS[1], -1.0)\n    lps[0].add_or_reuse_constraint(_EMPTY_INFOSET_KEYS[1], lp_solver.CONS_TYPE_EQ)\n    lps[0].set_cons_coeff(_EMPTY_INFOSET_KEYS[1], _EMPTY_INFOSET_ACTION_KEYS[1], -1.0)\n    lps[0].set_cons_rhs(_EMPTY_INFOSET_KEYS[1], -1.0)\n    lps[1].add_or_reuse_constraint(_EMPTY_INFOSET_KEYS[0], lp_solver.CONS_TYPE_EQ)\n    lps[1].set_cons_coeff(_EMPTY_INFOSET_KEYS[0], _EMPTY_INFOSET_ACTION_KEYS[0], 1.0)\n    lps[1].set_cons_rhs(_EMPTY_INFOSET_KEYS[0], 1.0)\n    _construct_lps(game.new_initial_state(), infosets, infoset_actions, infoset_action_maps, 1.0, lps, _EMPTY_INFOSET_KEYS[:], _EMPTY_INFOSET_ACTION_KEYS[:])\n    solutions = [lps[0].solve(solver=solver), lps[1].solve(solver=solver)]\n    policies = [policy.TabularPolicy(game), policy.TabularPolicy(game)]\n    for i in range(2):\n        for info_state in infoset_action_maps[i]:\n            total_weight = 0\n            num_actions = 0\n            for isa_key in infoset_action_maps[i][info_state]:\n                total_weight += solutions[1 - i][lps[1 - i].get_var_id(isa_key)]\n                num_actions += 1\n            unif_pr = 1.0 / num_actions\n            state_policy = policies[i].policy_for_key(info_state)\n            for isa_key in infoset_action_maps[i][info_state]:\n                rel_weight = solutions[1 - i][lps[1 - i].get_var_id(isa_key)]\n                (_, action_str) = isa_key.split(_DELIMITER)\n                action = int(action_str)\n                pr_action = rel_weight / total_weight if total_weight > 0 else unif_pr\n                state_policy[action] = pr_action\n    return (solutions[0][lps[0].get_var_id(_EMPTY_INFOSET_KEYS[0])], solutions[1][lps[1].get_var_id(_EMPTY_INFOSET_KEYS[1])], policies[0], policies[1])",
            "def solve_zero_sum_game(game, solver=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Solve the two-player zero-sum game using sequence-form LPs.\\n\\n  Args:\\n    game: the spiel game tp solve (must be zero-sum, sequential, and have chance\\n      mode of deterministic or explicit stochastic).\\n    solver: a specific solver to use, sent to cvxopt (i.e. 'lapack', 'blas',\\n      'glpk'). A value of None uses cvxopt's default solver.\\n\\n  Returns:\\n    A 4-tuple containing:\\n      - player 0 value\\n      - player 1 value\\n      - player 0 policy: a policy.TabularPolicy for player 0\\n      - player 1 policy: a policy.TabularPolicy for player 1\\n  \"\n    assert game.num_players() == 2\n    assert game.get_type().utility == pyspiel.GameType.Utility.ZERO_SUM\n    assert game.get_type().dynamics == pyspiel.GameType.Dynamics.SEQUENTIAL\n    assert game.get_type().chance_mode == pyspiel.GameType.ChanceMode.DETERMINISTIC or game.get_type().chance_mode == pyspiel.GameType.ChanceMode.EXPLICIT_STOCHASTIC\n    infosets = [{_EMPTY_INFOSET_KEYS[0]: 0}, {_EMPTY_INFOSET_KEYS[1]: 0}]\n    infoset_actions = [{_EMPTY_INFOSET_ACTION_KEYS[0]: 0}, {_EMPTY_INFOSET_ACTION_KEYS[1]: 0}]\n    infoset_action_maps = [{}, {}]\n    lps = [lp_solver.LinearProgram(lp_solver.OBJ_MIN), lp_solver.LinearProgram(lp_solver.OBJ_MAX)]\n    lps[0].add_or_reuse_variable(_EMPTY_INFOSET_ACTION_KEYS[1], lb=0)\n    lps[0].add_or_reuse_variable(_EMPTY_INFOSET_KEYS[0])\n    lps[1].add_or_reuse_variable(_EMPTY_INFOSET_ACTION_KEYS[0], lb=0)\n    lps[1].add_or_reuse_variable(_EMPTY_INFOSET_KEYS[1])\n    lps[0].set_obj_coeff(_EMPTY_INFOSET_KEYS[0], 1.0)\n    lps[1].set_obj_coeff(_EMPTY_INFOSET_KEYS[1], -1.0)\n    lps[0].add_or_reuse_constraint(_EMPTY_INFOSET_KEYS[1], lp_solver.CONS_TYPE_EQ)\n    lps[0].set_cons_coeff(_EMPTY_INFOSET_KEYS[1], _EMPTY_INFOSET_ACTION_KEYS[1], -1.0)\n    lps[0].set_cons_rhs(_EMPTY_INFOSET_KEYS[1], -1.0)\n    lps[1].add_or_reuse_constraint(_EMPTY_INFOSET_KEYS[0], lp_solver.CONS_TYPE_EQ)\n    lps[1].set_cons_coeff(_EMPTY_INFOSET_KEYS[0], _EMPTY_INFOSET_ACTION_KEYS[0], 1.0)\n    lps[1].set_cons_rhs(_EMPTY_INFOSET_KEYS[0], 1.0)\n    _construct_lps(game.new_initial_state(), infosets, infoset_actions, infoset_action_maps, 1.0, lps, _EMPTY_INFOSET_KEYS[:], _EMPTY_INFOSET_ACTION_KEYS[:])\n    solutions = [lps[0].solve(solver=solver), lps[1].solve(solver=solver)]\n    policies = [policy.TabularPolicy(game), policy.TabularPolicy(game)]\n    for i in range(2):\n        for info_state in infoset_action_maps[i]:\n            total_weight = 0\n            num_actions = 0\n            for isa_key in infoset_action_maps[i][info_state]:\n                total_weight += solutions[1 - i][lps[1 - i].get_var_id(isa_key)]\n                num_actions += 1\n            unif_pr = 1.0 / num_actions\n            state_policy = policies[i].policy_for_key(info_state)\n            for isa_key in infoset_action_maps[i][info_state]:\n                rel_weight = solutions[1 - i][lps[1 - i].get_var_id(isa_key)]\n                (_, action_str) = isa_key.split(_DELIMITER)\n                action = int(action_str)\n                pr_action = rel_weight / total_weight if total_weight > 0 else unif_pr\n                state_policy[action] = pr_action\n    return (solutions[0][lps[0].get_var_id(_EMPTY_INFOSET_KEYS[0])], solutions[1][lps[1].get_var_id(_EMPTY_INFOSET_KEYS[1])], policies[0], policies[1])"
        ]
    }
]