[
    {
        "func_name": "analysis",
        "original": "def analysis(db_path, model_name='VGG-Face', detector_backend='opencv', distance_metric='cosine', enable_face_analysis=True, source=0, time_threshold=5, frame_threshold=5):\n    text_color = (255, 255, 255)\n    pivot_img_size = 112\n    enable_emotion = True\n    enable_age_gender = True\n    target_size = functions.find_target_size(model_name=model_name)\n    DeepFace.build_model(model_name=model_name)\n    print(f'facial recognition model {model_name} is just built')\n    if enable_face_analysis:\n        DeepFace.build_model(model_name='Age')\n        print('Age model is just built')\n        DeepFace.build_model(model_name='Gender')\n        print('Gender model is just built')\n        DeepFace.build_model(model_name='Emotion')\n        print('Emotion model is just built')\n    DeepFace.find(img_path=np.zeros([224, 224, 3]), db_path=db_path, model_name=model_name, detector_backend=detector_backend, distance_metric=distance_metric, enforce_detection=False)\n    freeze = False\n    face_detected = False\n    face_included_frames = 0\n    freezed_frame = 0\n    tic = time.time()\n    cap = cv2.VideoCapture(source)\n    while True:\n        (_, img) = cap.read()\n        if img is None:\n            break\n        raw_img = img.copy()\n        resolution_x = img.shape[1]\n        resolution_y = img.shape[0]\n        if freeze == False:\n            try:\n                face_objs = DeepFace.extract_faces(img_path=img, target_size=target_size, detector_backend=detector_backend, enforce_detection=False)\n                faces = []\n                for face_obj in face_objs:\n                    facial_area = face_obj['facial_area']\n                    faces.append((facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']))\n            except:\n                faces = []\n            if len(faces) == 0:\n                face_included_frames = 0\n        else:\n            faces = []\n        detected_faces = []\n        face_index = 0\n        for (x, y, w, h) in faces:\n            if w > 130:\n                face_detected = True\n                if face_index == 0:\n                    face_included_frames = face_included_frames + 1\n                cv2.rectangle(img, (x, y), (x + w, y + h), (67, 67, 67), 1)\n                cv2.putText(img, str(frame_threshold - face_included_frames), (int(x + w / 4), int(y + h / 1.5)), cv2.FONT_HERSHEY_SIMPLEX, 4, (255, 255, 255), 2)\n                detected_face = img[int(y):int(y + h), int(x):int(x + w)]\n                detected_faces.append((x, y, w, h))\n                face_index = face_index + 1\n        if face_detected == True and face_included_frames == frame_threshold and (freeze == False):\n            freeze = True\n            base_img = raw_img.copy()\n            detected_faces_final = detected_faces.copy()\n            tic = time.time()\n        if freeze == True:\n            toc = time.time()\n            if toc - tic < time_threshold:\n                if freezed_frame == 0:\n                    freeze_img = base_img.copy()\n                    for detected_face in detected_faces_final:\n                        x = detected_face[0]\n                        y = detected_face[1]\n                        w = detected_face[2]\n                        h = detected_face[3]\n                        cv2.rectangle(freeze_img, (x, y), (x + w, y + h), (67, 67, 67), 1)\n                        custom_face = base_img[y:y + h, x:x + w]\n                        if enable_face_analysis == True:\n                            demographies = DeepFace.analyze(img_path=custom_face, detector_backend=detector_backend, enforce_detection=False, silent=True)\n                            if len(demographies) > 0:\n                                demography = demographies[0]\n                                if enable_emotion:\n                                    emotion = demography['emotion']\n                                    emotion_df = pd.DataFrame(emotion.items(), columns=['emotion', 'score'])\n                                    emotion_df = emotion_df.sort_values(by=['score'], ascending=False).reset_index(drop=True)\n                                    overlay = freeze_img.copy()\n                                    opacity = 0.4\n                                    if x + w + pivot_img_size < resolution_x:\n                                        cv2.rectangle(freeze_img, (x + w, y), (x + w + pivot_img_size, y + h), (64, 64, 64), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                    elif x - pivot_img_size > 0:\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y), (x, y + h), (64, 64, 64), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                    for (index, instance) in emotion_df.iterrows():\n                                        current_emotion = instance['emotion']\n                                        emotion_label = f'{current_emotion} '\n                                        emotion_score = instance['score'] / 100\n                                        bar_x = 35\n                                        bar_x = int(bar_x * emotion_score)\n                                        if x + w + pivot_img_size < resolution_x:\n                                            text_location_y = y + 20 + (index + 1) * 20\n                                            text_location_x = x + w\n                                            if text_location_y < y + h:\n                                                cv2.putText(freeze_img, emotion_label, (text_location_x, text_location_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n                                                cv2.rectangle(freeze_img, (x + w + 70, y + 13 + (index + 1) * 20), (x + w + 70 + bar_x, y + 13 + (index + 1) * 20 + 5), (255, 255, 255), cv2.FILLED)\n                                        elif x - pivot_img_size > 0:\n                                            text_location_y = y + 20 + (index + 1) * 20\n                                            text_location_x = x - pivot_img_size\n                                            if text_location_y <= y + h:\n                                                cv2.putText(freeze_img, emotion_label, (text_location_x, text_location_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n                                                cv2.rectangle(freeze_img, (x - pivot_img_size + 70, y + 13 + (index + 1) * 20), (x - pivot_img_size + 70 + bar_x, y + 13 + (index + 1) * 20 + 5), (255, 255, 255), cv2.FILLED)\n                                if enable_age_gender:\n                                    apparent_age = demography['age']\n                                    dominant_gender = demography['dominant_gender']\n                                    gender = 'M' if dominant_gender == 'Man' else 'W'\n                                    analysis_report = str(int(apparent_age)) + ' ' + gender\n                                    info_box_color = (46, 200, 255)\n                                    if y - pivot_img_size + int(pivot_img_size / 5) > 0:\n                                        triangle_coordinates = np.array([(x + int(w / 2), y), (x + int(w / 2) - int(w / 10), y - int(pivot_img_size / 3)), (x + int(w / 2) + int(w / 10), y - int(pivot_img_size / 3))])\n                                        cv2.drawContours(freeze_img, [triangle_coordinates], 0, info_box_color, -1)\n                                        cv2.rectangle(freeze_img, (x + int(w / 5), y - pivot_img_size + int(pivot_img_size / 5)), (x + w - int(w / 5), y - int(pivot_img_size / 3)), info_box_color, cv2.FILLED)\n                                        cv2.putText(freeze_img, analysis_report, (x + int(w / 3.5), y - int(pivot_img_size / 2.1)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n                                    elif y + h + pivot_img_size - int(pivot_img_size / 5) < resolution_y:\n                                        triangle_coordinates = np.array([(x + int(w / 2), y + h), (x + int(w / 2) - int(w / 10), y + h + int(pivot_img_size / 3)), (x + int(w / 2) + int(w / 10), y + h + int(pivot_img_size / 3))])\n                                        cv2.drawContours(freeze_img, [triangle_coordinates], 0, info_box_color, -1)\n                                        cv2.rectangle(freeze_img, (x + int(w / 5), y + h + int(pivot_img_size / 3)), (x + w - int(w / 5), y + h + pivot_img_size - int(pivot_img_size / 5)), info_box_color, cv2.FILLED)\n                                        cv2.putText(freeze_img, analysis_report, (x + int(w / 3.5), y + h + int(pivot_img_size / 1.5)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n                        dfs = DeepFace.find(img_path=custom_face, db_path=db_path, model_name=model_name, detector_backend=detector_backend, distance_metric=distance_metric, enforce_detection=False, silent=True)\n                        if len(dfs) > 0:\n                            df = dfs[0]\n                            if df.shape[0] > 0:\n                                candidate = df.iloc[0]\n                                label = candidate['identity']\n                                display_img = cv2.imread(label)\n                                source_objs = DeepFace.extract_faces(img_path=label, target_size=(pivot_img_size, pivot_img_size), detector_backend=detector_backend, enforce_detection=False, align=False)\n                                if len(source_objs) > 0:\n                                    source_obj = source_objs[0]\n                                    display_img = source_obj['face']\n                                    display_img *= 255\n                                    display_img = display_img[:, :, ::-1]\n                                label = label.split('/')[-1]\n                                try:\n                                    if y - pivot_img_size > 0 and x + w + pivot_img_size < resolution_x:\n                                        freeze_img[y - pivot_img_size:y, x + w:x + w + pivot_img_size] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x + w, y), (x + w + pivot_img_size, y + 20), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x + w, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y), (x + 3 * int(w / 4), y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + 3 * int(w / 4), y - int(pivot_img_size / 2)), (x + w, y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif y + h + pivot_img_size < resolution_y and x - pivot_img_size > 0:\n                                        freeze_img[y + h:y + h + pivot_img_size, x - pivot_img_size:x] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y + h - 20), (x, y + h), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x - pivot_img_size, y + h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y + h), (x + int(w / 2) - int(w / 4), y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) - int(w / 4), y + h + int(pivot_img_size / 2)), (x, y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif y - pivot_img_size > 0 and x - pivot_img_size > 0:\n                                        freeze_img[y - pivot_img_size:y, x - pivot_img_size:x] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y), (x, y + 20), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x - pivot_img_size, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y), (x + int(w / 2) - int(w / 4), y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) - int(w / 4), y - int(pivot_img_size / 2)), (x, y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif x + w + pivot_img_size < resolution_x and y + h + pivot_img_size < resolution_y:\n                                        freeze_img[y + h:y + h + pivot_img_size, x + w:x + w + pivot_img_size] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x + w, y + h - 20), (x + w + pivot_img_size, y + h), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x + w, y + h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y + h), (x + int(w / 2) + int(w / 4), y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) + int(w / 4), y + h + int(pivot_img_size / 2)), (x + w, y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                except Exception as err:\n                                    print(str(err))\n                        tic = time.time()\n                time_left = int(time_threshold - (toc - tic) + 1)\n                cv2.rectangle(freeze_img, (10, 10), (90, 50), (67, 67, 67), -10)\n                cv2.putText(freeze_img, str(time_left), (40, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1)\n                cv2.imshow('img', freeze_img)\n                freezed_frame = freezed_frame + 1\n            else:\n                face_detected = False\n                face_included_frames = 0\n                freeze = False\n                freezed_frame = 0\n        else:\n            cv2.imshow('img', img)\n        if cv2.waitKey(1) & 255 == ord('q'):\n            break\n    cap.release()\n    cv2.destroyAllWindows()",
        "mutated": [
            "def analysis(db_path, model_name='VGG-Face', detector_backend='opencv', distance_metric='cosine', enable_face_analysis=True, source=0, time_threshold=5, frame_threshold=5):\n    if False:\n        i = 10\n    text_color = (255, 255, 255)\n    pivot_img_size = 112\n    enable_emotion = True\n    enable_age_gender = True\n    target_size = functions.find_target_size(model_name=model_name)\n    DeepFace.build_model(model_name=model_name)\n    print(f'facial recognition model {model_name} is just built')\n    if enable_face_analysis:\n        DeepFace.build_model(model_name='Age')\n        print('Age model is just built')\n        DeepFace.build_model(model_name='Gender')\n        print('Gender model is just built')\n        DeepFace.build_model(model_name='Emotion')\n        print('Emotion model is just built')\n    DeepFace.find(img_path=np.zeros([224, 224, 3]), db_path=db_path, model_name=model_name, detector_backend=detector_backend, distance_metric=distance_metric, enforce_detection=False)\n    freeze = False\n    face_detected = False\n    face_included_frames = 0\n    freezed_frame = 0\n    tic = time.time()\n    cap = cv2.VideoCapture(source)\n    while True:\n        (_, img) = cap.read()\n        if img is None:\n            break\n        raw_img = img.copy()\n        resolution_x = img.shape[1]\n        resolution_y = img.shape[0]\n        if freeze == False:\n            try:\n                face_objs = DeepFace.extract_faces(img_path=img, target_size=target_size, detector_backend=detector_backend, enforce_detection=False)\n                faces = []\n                for face_obj in face_objs:\n                    facial_area = face_obj['facial_area']\n                    faces.append((facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']))\n            except:\n                faces = []\n            if len(faces) == 0:\n                face_included_frames = 0\n        else:\n            faces = []\n        detected_faces = []\n        face_index = 0\n        for (x, y, w, h) in faces:\n            if w > 130:\n                face_detected = True\n                if face_index == 0:\n                    face_included_frames = face_included_frames + 1\n                cv2.rectangle(img, (x, y), (x + w, y + h), (67, 67, 67), 1)\n                cv2.putText(img, str(frame_threshold - face_included_frames), (int(x + w / 4), int(y + h / 1.5)), cv2.FONT_HERSHEY_SIMPLEX, 4, (255, 255, 255), 2)\n                detected_face = img[int(y):int(y + h), int(x):int(x + w)]\n                detected_faces.append((x, y, w, h))\n                face_index = face_index + 1\n        if face_detected == True and face_included_frames == frame_threshold and (freeze == False):\n            freeze = True\n            base_img = raw_img.copy()\n            detected_faces_final = detected_faces.copy()\n            tic = time.time()\n        if freeze == True:\n            toc = time.time()\n            if toc - tic < time_threshold:\n                if freezed_frame == 0:\n                    freeze_img = base_img.copy()\n                    for detected_face in detected_faces_final:\n                        x = detected_face[0]\n                        y = detected_face[1]\n                        w = detected_face[2]\n                        h = detected_face[3]\n                        cv2.rectangle(freeze_img, (x, y), (x + w, y + h), (67, 67, 67), 1)\n                        custom_face = base_img[y:y + h, x:x + w]\n                        if enable_face_analysis == True:\n                            demographies = DeepFace.analyze(img_path=custom_face, detector_backend=detector_backend, enforce_detection=False, silent=True)\n                            if len(demographies) > 0:\n                                demography = demographies[0]\n                                if enable_emotion:\n                                    emotion = demography['emotion']\n                                    emotion_df = pd.DataFrame(emotion.items(), columns=['emotion', 'score'])\n                                    emotion_df = emotion_df.sort_values(by=['score'], ascending=False).reset_index(drop=True)\n                                    overlay = freeze_img.copy()\n                                    opacity = 0.4\n                                    if x + w + pivot_img_size < resolution_x:\n                                        cv2.rectangle(freeze_img, (x + w, y), (x + w + pivot_img_size, y + h), (64, 64, 64), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                    elif x - pivot_img_size > 0:\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y), (x, y + h), (64, 64, 64), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                    for (index, instance) in emotion_df.iterrows():\n                                        current_emotion = instance['emotion']\n                                        emotion_label = f'{current_emotion} '\n                                        emotion_score = instance['score'] / 100\n                                        bar_x = 35\n                                        bar_x = int(bar_x * emotion_score)\n                                        if x + w + pivot_img_size < resolution_x:\n                                            text_location_y = y + 20 + (index + 1) * 20\n                                            text_location_x = x + w\n                                            if text_location_y < y + h:\n                                                cv2.putText(freeze_img, emotion_label, (text_location_x, text_location_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n                                                cv2.rectangle(freeze_img, (x + w + 70, y + 13 + (index + 1) * 20), (x + w + 70 + bar_x, y + 13 + (index + 1) * 20 + 5), (255, 255, 255), cv2.FILLED)\n                                        elif x - pivot_img_size > 0:\n                                            text_location_y = y + 20 + (index + 1) * 20\n                                            text_location_x = x - pivot_img_size\n                                            if text_location_y <= y + h:\n                                                cv2.putText(freeze_img, emotion_label, (text_location_x, text_location_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n                                                cv2.rectangle(freeze_img, (x - pivot_img_size + 70, y + 13 + (index + 1) * 20), (x - pivot_img_size + 70 + bar_x, y + 13 + (index + 1) * 20 + 5), (255, 255, 255), cv2.FILLED)\n                                if enable_age_gender:\n                                    apparent_age = demography['age']\n                                    dominant_gender = demography['dominant_gender']\n                                    gender = 'M' if dominant_gender == 'Man' else 'W'\n                                    analysis_report = str(int(apparent_age)) + ' ' + gender\n                                    info_box_color = (46, 200, 255)\n                                    if y - pivot_img_size + int(pivot_img_size / 5) > 0:\n                                        triangle_coordinates = np.array([(x + int(w / 2), y), (x + int(w / 2) - int(w / 10), y - int(pivot_img_size / 3)), (x + int(w / 2) + int(w / 10), y - int(pivot_img_size / 3))])\n                                        cv2.drawContours(freeze_img, [triangle_coordinates], 0, info_box_color, -1)\n                                        cv2.rectangle(freeze_img, (x + int(w / 5), y - pivot_img_size + int(pivot_img_size / 5)), (x + w - int(w / 5), y - int(pivot_img_size / 3)), info_box_color, cv2.FILLED)\n                                        cv2.putText(freeze_img, analysis_report, (x + int(w / 3.5), y - int(pivot_img_size / 2.1)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n                                    elif y + h + pivot_img_size - int(pivot_img_size / 5) < resolution_y:\n                                        triangle_coordinates = np.array([(x + int(w / 2), y + h), (x + int(w / 2) - int(w / 10), y + h + int(pivot_img_size / 3)), (x + int(w / 2) + int(w / 10), y + h + int(pivot_img_size / 3))])\n                                        cv2.drawContours(freeze_img, [triangle_coordinates], 0, info_box_color, -1)\n                                        cv2.rectangle(freeze_img, (x + int(w / 5), y + h + int(pivot_img_size / 3)), (x + w - int(w / 5), y + h + pivot_img_size - int(pivot_img_size / 5)), info_box_color, cv2.FILLED)\n                                        cv2.putText(freeze_img, analysis_report, (x + int(w / 3.5), y + h + int(pivot_img_size / 1.5)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n                        dfs = DeepFace.find(img_path=custom_face, db_path=db_path, model_name=model_name, detector_backend=detector_backend, distance_metric=distance_metric, enforce_detection=False, silent=True)\n                        if len(dfs) > 0:\n                            df = dfs[0]\n                            if df.shape[0] > 0:\n                                candidate = df.iloc[0]\n                                label = candidate['identity']\n                                display_img = cv2.imread(label)\n                                source_objs = DeepFace.extract_faces(img_path=label, target_size=(pivot_img_size, pivot_img_size), detector_backend=detector_backend, enforce_detection=False, align=False)\n                                if len(source_objs) > 0:\n                                    source_obj = source_objs[0]\n                                    display_img = source_obj['face']\n                                    display_img *= 255\n                                    display_img = display_img[:, :, ::-1]\n                                label = label.split('/')[-1]\n                                try:\n                                    if y - pivot_img_size > 0 and x + w + pivot_img_size < resolution_x:\n                                        freeze_img[y - pivot_img_size:y, x + w:x + w + pivot_img_size] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x + w, y), (x + w + pivot_img_size, y + 20), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x + w, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y), (x + 3 * int(w / 4), y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + 3 * int(w / 4), y - int(pivot_img_size / 2)), (x + w, y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif y + h + pivot_img_size < resolution_y and x - pivot_img_size > 0:\n                                        freeze_img[y + h:y + h + pivot_img_size, x - pivot_img_size:x] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y + h - 20), (x, y + h), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x - pivot_img_size, y + h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y + h), (x + int(w / 2) - int(w / 4), y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) - int(w / 4), y + h + int(pivot_img_size / 2)), (x, y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif y - pivot_img_size > 0 and x - pivot_img_size > 0:\n                                        freeze_img[y - pivot_img_size:y, x - pivot_img_size:x] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y), (x, y + 20), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x - pivot_img_size, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y), (x + int(w / 2) - int(w / 4), y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) - int(w / 4), y - int(pivot_img_size / 2)), (x, y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif x + w + pivot_img_size < resolution_x and y + h + pivot_img_size < resolution_y:\n                                        freeze_img[y + h:y + h + pivot_img_size, x + w:x + w + pivot_img_size] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x + w, y + h - 20), (x + w + pivot_img_size, y + h), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x + w, y + h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y + h), (x + int(w / 2) + int(w / 4), y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) + int(w / 4), y + h + int(pivot_img_size / 2)), (x + w, y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                except Exception as err:\n                                    print(str(err))\n                        tic = time.time()\n                time_left = int(time_threshold - (toc - tic) + 1)\n                cv2.rectangle(freeze_img, (10, 10), (90, 50), (67, 67, 67), -10)\n                cv2.putText(freeze_img, str(time_left), (40, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1)\n                cv2.imshow('img', freeze_img)\n                freezed_frame = freezed_frame + 1\n            else:\n                face_detected = False\n                face_included_frames = 0\n                freeze = False\n                freezed_frame = 0\n        else:\n            cv2.imshow('img', img)\n        if cv2.waitKey(1) & 255 == ord('q'):\n            break\n    cap.release()\n    cv2.destroyAllWindows()",
            "def analysis(db_path, model_name='VGG-Face', detector_backend='opencv', distance_metric='cosine', enable_face_analysis=True, source=0, time_threshold=5, frame_threshold=5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    text_color = (255, 255, 255)\n    pivot_img_size = 112\n    enable_emotion = True\n    enable_age_gender = True\n    target_size = functions.find_target_size(model_name=model_name)\n    DeepFace.build_model(model_name=model_name)\n    print(f'facial recognition model {model_name} is just built')\n    if enable_face_analysis:\n        DeepFace.build_model(model_name='Age')\n        print('Age model is just built')\n        DeepFace.build_model(model_name='Gender')\n        print('Gender model is just built')\n        DeepFace.build_model(model_name='Emotion')\n        print('Emotion model is just built')\n    DeepFace.find(img_path=np.zeros([224, 224, 3]), db_path=db_path, model_name=model_name, detector_backend=detector_backend, distance_metric=distance_metric, enforce_detection=False)\n    freeze = False\n    face_detected = False\n    face_included_frames = 0\n    freezed_frame = 0\n    tic = time.time()\n    cap = cv2.VideoCapture(source)\n    while True:\n        (_, img) = cap.read()\n        if img is None:\n            break\n        raw_img = img.copy()\n        resolution_x = img.shape[1]\n        resolution_y = img.shape[0]\n        if freeze == False:\n            try:\n                face_objs = DeepFace.extract_faces(img_path=img, target_size=target_size, detector_backend=detector_backend, enforce_detection=False)\n                faces = []\n                for face_obj in face_objs:\n                    facial_area = face_obj['facial_area']\n                    faces.append((facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']))\n            except:\n                faces = []\n            if len(faces) == 0:\n                face_included_frames = 0\n        else:\n            faces = []\n        detected_faces = []\n        face_index = 0\n        for (x, y, w, h) in faces:\n            if w > 130:\n                face_detected = True\n                if face_index == 0:\n                    face_included_frames = face_included_frames + 1\n                cv2.rectangle(img, (x, y), (x + w, y + h), (67, 67, 67), 1)\n                cv2.putText(img, str(frame_threshold - face_included_frames), (int(x + w / 4), int(y + h / 1.5)), cv2.FONT_HERSHEY_SIMPLEX, 4, (255, 255, 255), 2)\n                detected_face = img[int(y):int(y + h), int(x):int(x + w)]\n                detected_faces.append((x, y, w, h))\n                face_index = face_index + 1\n        if face_detected == True and face_included_frames == frame_threshold and (freeze == False):\n            freeze = True\n            base_img = raw_img.copy()\n            detected_faces_final = detected_faces.copy()\n            tic = time.time()\n        if freeze == True:\n            toc = time.time()\n            if toc - tic < time_threshold:\n                if freezed_frame == 0:\n                    freeze_img = base_img.copy()\n                    for detected_face in detected_faces_final:\n                        x = detected_face[0]\n                        y = detected_face[1]\n                        w = detected_face[2]\n                        h = detected_face[3]\n                        cv2.rectangle(freeze_img, (x, y), (x + w, y + h), (67, 67, 67), 1)\n                        custom_face = base_img[y:y + h, x:x + w]\n                        if enable_face_analysis == True:\n                            demographies = DeepFace.analyze(img_path=custom_face, detector_backend=detector_backend, enforce_detection=False, silent=True)\n                            if len(demographies) > 0:\n                                demography = demographies[0]\n                                if enable_emotion:\n                                    emotion = demography['emotion']\n                                    emotion_df = pd.DataFrame(emotion.items(), columns=['emotion', 'score'])\n                                    emotion_df = emotion_df.sort_values(by=['score'], ascending=False).reset_index(drop=True)\n                                    overlay = freeze_img.copy()\n                                    opacity = 0.4\n                                    if x + w + pivot_img_size < resolution_x:\n                                        cv2.rectangle(freeze_img, (x + w, y), (x + w + pivot_img_size, y + h), (64, 64, 64), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                    elif x - pivot_img_size > 0:\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y), (x, y + h), (64, 64, 64), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                    for (index, instance) in emotion_df.iterrows():\n                                        current_emotion = instance['emotion']\n                                        emotion_label = f'{current_emotion} '\n                                        emotion_score = instance['score'] / 100\n                                        bar_x = 35\n                                        bar_x = int(bar_x * emotion_score)\n                                        if x + w + pivot_img_size < resolution_x:\n                                            text_location_y = y + 20 + (index + 1) * 20\n                                            text_location_x = x + w\n                                            if text_location_y < y + h:\n                                                cv2.putText(freeze_img, emotion_label, (text_location_x, text_location_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n                                                cv2.rectangle(freeze_img, (x + w + 70, y + 13 + (index + 1) * 20), (x + w + 70 + bar_x, y + 13 + (index + 1) * 20 + 5), (255, 255, 255), cv2.FILLED)\n                                        elif x - pivot_img_size > 0:\n                                            text_location_y = y + 20 + (index + 1) * 20\n                                            text_location_x = x - pivot_img_size\n                                            if text_location_y <= y + h:\n                                                cv2.putText(freeze_img, emotion_label, (text_location_x, text_location_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n                                                cv2.rectangle(freeze_img, (x - pivot_img_size + 70, y + 13 + (index + 1) * 20), (x - pivot_img_size + 70 + bar_x, y + 13 + (index + 1) * 20 + 5), (255, 255, 255), cv2.FILLED)\n                                if enable_age_gender:\n                                    apparent_age = demography['age']\n                                    dominant_gender = demography['dominant_gender']\n                                    gender = 'M' if dominant_gender == 'Man' else 'W'\n                                    analysis_report = str(int(apparent_age)) + ' ' + gender\n                                    info_box_color = (46, 200, 255)\n                                    if y - pivot_img_size + int(pivot_img_size / 5) > 0:\n                                        triangle_coordinates = np.array([(x + int(w / 2), y), (x + int(w / 2) - int(w / 10), y - int(pivot_img_size / 3)), (x + int(w / 2) + int(w / 10), y - int(pivot_img_size / 3))])\n                                        cv2.drawContours(freeze_img, [triangle_coordinates], 0, info_box_color, -1)\n                                        cv2.rectangle(freeze_img, (x + int(w / 5), y - pivot_img_size + int(pivot_img_size / 5)), (x + w - int(w / 5), y - int(pivot_img_size / 3)), info_box_color, cv2.FILLED)\n                                        cv2.putText(freeze_img, analysis_report, (x + int(w / 3.5), y - int(pivot_img_size / 2.1)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n                                    elif y + h + pivot_img_size - int(pivot_img_size / 5) < resolution_y:\n                                        triangle_coordinates = np.array([(x + int(w / 2), y + h), (x + int(w / 2) - int(w / 10), y + h + int(pivot_img_size / 3)), (x + int(w / 2) + int(w / 10), y + h + int(pivot_img_size / 3))])\n                                        cv2.drawContours(freeze_img, [triangle_coordinates], 0, info_box_color, -1)\n                                        cv2.rectangle(freeze_img, (x + int(w / 5), y + h + int(pivot_img_size / 3)), (x + w - int(w / 5), y + h + pivot_img_size - int(pivot_img_size / 5)), info_box_color, cv2.FILLED)\n                                        cv2.putText(freeze_img, analysis_report, (x + int(w / 3.5), y + h + int(pivot_img_size / 1.5)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n                        dfs = DeepFace.find(img_path=custom_face, db_path=db_path, model_name=model_name, detector_backend=detector_backend, distance_metric=distance_metric, enforce_detection=False, silent=True)\n                        if len(dfs) > 0:\n                            df = dfs[0]\n                            if df.shape[0] > 0:\n                                candidate = df.iloc[0]\n                                label = candidate['identity']\n                                display_img = cv2.imread(label)\n                                source_objs = DeepFace.extract_faces(img_path=label, target_size=(pivot_img_size, pivot_img_size), detector_backend=detector_backend, enforce_detection=False, align=False)\n                                if len(source_objs) > 0:\n                                    source_obj = source_objs[0]\n                                    display_img = source_obj['face']\n                                    display_img *= 255\n                                    display_img = display_img[:, :, ::-1]\n                                label = label.split('/')[-1]\n                                try:\n                                    if y - pivot_img_size > 0 and x + w + pivot_img_size < resolution_x:\n                                        freeze_img[y - pivot_img_size:y, x + w:x + w + pivot_img_size] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x + w, y), (x + w + pivot_img_size, y + 20), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x + w, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y), (x + 3 * int(w / 4), y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + 3 * int(w / 4), y - int(pivot_img_size / 2)), (x + w, y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif y + h + pivot_img_size < resolution_y and x - pivot_img_size > 0:\n                                        freeze_img[y + h:y + h + pivot_img_size, x - pivot_img_size:x] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y + h - 20), (x, y + h), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x - pivot_img_size, y + h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y + h), (x + int(w / 2) - int(w / 4), y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) - int(w / 4), y + h + int(pivot_img_size / 2)), (x, y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif y - pivot_img_size > 0 and x - pivot_img_size > 0:\n                                        freeze_img[y - pivot_img_size:y, x - pivot_img_size:x] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y), (x, y + 20), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x - pivot_img_size, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y), (x + int(w / 2) - int(w / 4), y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) - int(w / 4), y - int(pivot_img_size / 2)), (x, y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif x + w + pivot_img_size < resolution_x and y + h + pivot_img_size < resolution_y:\n                                        freeze_img[y + h:y + h + pivot_img_size, x + w:x + w + pivot_img_size] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x + w, y + h - 20), (x + w + pivot_img_size, y + h), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x + w, y + h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y + h), (x + int(w / 2) + int(w / 4), y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) + int(w / 4), y + h + int(pivot_img_size / 2)), (x + w, y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                except Exception as err:\n                                    print(str(err))\n                        tic = time.time()\n                time_left = int(time_threshold - (toc - tic) + 1)\n                cv2.rectangle(freeze_img, (10, 10), (90, 50), (67, 67, 67), -10)\n                cv2.putText(freeze_img, str(time_left), (40, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1)\n                cv2.imshow('img', freeze_img)\n                freezed_frame = freezed_frame + 1\n            else:\n                face_detected = False\n                face_included_frames = 0\n                freeze = False\n                freezed_frame = 0\n        else:\n            cv2.imshow('img', img)\n        if cv2.waitKey(1) & 255 == ord('q'):\n            break\n    cap.release()\n    cv2.destroyAllWindows()",
            "def analysis(db_path, model_name='VGG-Face', detector_backend='opencv', distance_metric='cosine', enable_face_analysis=True, source=0, time_threshold=5, frame_threshold=5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    text_color = (255, 255, 255)\n    pivot_img_size = 112\n    enable_emotion = True\n    enable_age_gender = True\n    target_size = functions.find_target_size(model_name=model_name)\n    DeepFace.build_model(model_name=model_name)\n    print(f'facial recognition model {model_name} is just built')\n    if enable_face_analysis:\n        DeepFace.build_model(model_name='Age')\n        print('Age model is just built')\n        DeepFace.build_model(model_name='Gender')\n        print('Gender model is just built')\n        DeepFace.build_model(model_name='Emotion')\n        print('Emotion model is just built')\n    DeepFace.find(img_path=np.zeros([224, 224, 3]), db_path=db_path, model_name=model_name, detector_backend=detector_backend, distance_metric=distance_metric, enforce_detection=False)\n    freeze = False\n    face_detected = False\n    face_included_frames = 0\n    freezed_frame = 0\n    tic = time.time()\n    cap = cv2.VideoCapture(source)\n    while True:\n        (_, img) = cap.read()\n        if img is None:\n            break\n        raw_img = img.copy()\n        resolution_x = img.shape[1]\n        resolution_y = img.shape[0]\n        if freeze == False:\n            try:\n                face_objs = DeepFace.extract_faces(img_path=img, target_size=target_size, detector_backend=detector_backend, enforce_detection=False)\n                faces = []\n                for face_obj in face_objs:\n                    facial_area = face_obj['facial_area']\n                    faces.append((facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']))\n            except:\n                faces = []\n            if len(faces) == 0:\n                face_included_frames = 0\n        else:\n            faces = []\n        detected_faces = []\n        face_index = 0\n        for (x, y, w, h) in faces:\n            if w > 130:\n                face_detected = True\n                if face_index == 0:\n                    face_included_frames = face_included_frames + 1\n                cv2.rectangle(img, (x, y), (x + w, y + h), (67, 67, 67), 1)\n                cv2.putText(img, str(frame_threshold - face_included_frames), (int(x + w / 4), int(y + h / 1.5)), cv2.FONT_HERSHEY_SIMPLEX, 4, (255, 255, 255), 2)\n                detected_face = img[int(y):int(y + h), int(x):int(x + w)]\n                detected_faces.append((x, y, w, h))\n                face_index = face_index + 1\n        if face_detected == True and face_included_frames == frame_threshold and (freeze == False):\n            freeze = True\n            base_img = raw_img.copy()\n            detected_faces_final = detected_faces.copy()\n            tic = time.time()\n        if freeze == True:\n            toc = time.time()\n            if toc - tic < time_threshold:\n                if freezed_frame == 0:\n                    freeze_img = base_img.copy()\n                    for detected_face in detected_faces_final:\n                        x = detected_face[0]\n                        y = detected_face[1]\n                        w = detected_face[2]\n                        h = detected_face[3]\n                        cv2.rectangle(freeze_img, (x, y), (x + w, y + h), (67, 67, 67), 1)\n                        custom_face = base_img[y:y + h, x:x + w]\n                        if enable_face_analysis == True:\n                            demographies = DeepFace.analyze(img_path=custom_face, detector_backend=detector_backend, enforce_detection=False, silent=True)\n                            if len(demographies) > 0:\n                                demography = demographies[0]\n                                if enable_emotion:\n                                    emotion = demography['emotion']\n                                    emotion_df = pd.DataFrame(emotion.items(), columns=['emotion', 'score'])\n                                    emotion_df = emotion_df.sort_values(by=['score'], ascending=False).reset_index(drop=True)\n                                    overlay = freeze_img.copy()\n                                    opacity = 0.4\n                                    if x + w + pivot_img_size < resolution_x:\n                                        cv2.rectangle(freeze_img, (x + w, y), (x + w + pivot_img_size, y + h), (64, 64, 64), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                    elif x - pivot_img_size > 0:\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y), (x, y + h), (64, 64, 64), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                    for (index, instance) in emotion_df.iterrows():\n                                        current_emotion = instance['emotion']\n                                        emotion_label = f'{current_emotion} '\n                                        emotion_score = instance['score'] / 100\n                                        bar_x = 35\n                                        bar_x = int(bar_x * emotion_score)\n                                        if x + w + pivot_img_size < resolution_x:\n                                            text_location_y = y + 20 + (index + 1) * 20\n                                            text_location_x = x + w\n                                            if text_location_y < y + h:\n                                                cv2.putText(freeze_img, emotion_label, (text_location_x, text_location_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n                                                cv2.rectangle(freeze_img, (x + w + 70, y + 13 + (index + 1) * 20), (x + w + 70 + bar_x, y + 13 + (index + 1) * 20 + 5), (255, 255, 255), cv2.FILLED)\n                                        elif x - pivot_img_size > 0:\n                                            text_location_y = y + 20 + (index + 1) * 20\n                                            text_location_x = x - pivot_img_size\n                                            if text_location_y <= y + h:\n                                                cv2.putText(freeze_img, emotion_label, (text_location_x, text_location_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n                                                cv2.rectangle(freeze_img, (x - pivot_img_size + 70, y + 13 + (index + 1) * 20), (x - pivot_img_size + 70 + bar_x, y + 13 + (index + 1) * 20 + 5), (255, 255, 255), cv2.FILLED)\n                                if enable_age_gender:\n                                    apparent_age = demography['age']\n                                    dominant_gender = demography['dominant_gender']\n                                    gender = 'M' if dominant_gender == 'Man' else 'W'\n                                    analysis_report = str(int(apparent_age)) + ' ' + gender\n                                    info_box_color = (46, 200, 255)\n                                    if y - pivot_img_size + int(pivot_img_size / 5) > 0:\n                                        triangle_coordinates = np.array([(x + int(w / 2), y), (x + int(w / 2) - int(w / 10), y - int(pivot_img_size / 3)), (x + int(w / 2) + int(w / 10), y - int(pivot_img_size / 3))])\n                                        cv2.drawContours(freeze_img, [triangle_coordinates], 0, info_box_color, -1)\n                                        cv2.rectangle(freeze_img, (x + int(w / 5), y - pivot_img_size + int(pivot_img_size / 5)), (x + w - int(w / 5), y - int(pivot_img_size / 3)), info_box_color, cv2.FILLED)\n                                        cv2.putText(freeze_img, analysis_report, (x + int(w / 3.5), y - int(pivot_img_size / 2.1)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n                                    elif y + h + pivot_img_size - int(pivot_img_size / 5) < resolution_y:\n                                        triangle_coordinates = np.array([(x + int(w / 2), y + h), (x + int(w / 2) - int(w / 10), y + h + int(pivot_img_size / 3)), (x + int(w / 2) + int(w / 10), y + h + int(pivot_img_size / 3))])\n                                        cv2.drawContours(freeze_img, [triangle_coordinates], 0, info_box_color, -1)\n                                        cv2.rectangle(freeze_img, (x + int(w / 5), y + h + int(pivot_img_size / 3)), (x + w - int(w / 5), y + h + pivot_img_size - int(pivot_img_size / 5)), info_box_color, cv2.FILLED)\n                                        cv2.putText(freeze_img, analysis_report, (x + int(w / 3.5), y + h + int(pivot_img_size / 1.5)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n                        dfs = DeepFace.find(img_path=custom_face, db_path=db_path, model_name=model_name, detector_backend=detector_backend, distance_metric=distance_metric, enforce_detection=False, silent=True)\n                        if len(dfs) > 0:\n                            df = dfs[0]\n                            if df.shape[0] > 0:\n                                candidate = df.iloc[0]\n                                label = candidate['identity']\n                                display_img = cv2.imread(label)\n                                source_objs = DeepFace.extract_faces(img_path=label, target_size=(pivot_img_size, pivot_img_size), detector_backend=detector_backend, enforce_detection=False, align=False)\n                                if len(source_objs) > 0:\n                                    source_obj = source_objs[0]\n                                    display_img = source_obj['face']\n                                    display_img *= 255\n                                    display_img = display_img[:, :, ::-1]\n                                label = label.split('/')[-1]\n                                try:\n                                    if y - pivot_img_size > 0 and x + w + pivot_img_size < resolution_x:\n                                        freeze_img[y - pivot_img_size:y, x + w:x + w + pivot_img_size] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x + w, y), (x + w + pivot_img_size, y + 20), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x + w, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y), (x + 3 * int(w / 4), y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + 3 * int(w / 4), y - int(pivot_img_size / 2)), (x + w, y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif y + h + pivot_img_size < resolution_y and x - pivot_img_size > 0:\n                                        freeze_img[y + h:y + h + pivot_img_size, x - pivot_img_size:x] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y + h - 20), (x, y + h), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x - pivot_img_size, y + h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y + h), (x + int(w / 2) - int(w / 4), y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) - int(w / 4), y + h + int(pivot_img_size / 2)), (x, y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif y - pivot_img_size > 0 and x - pivot_img_size > 0:\n                                        freeze_img[y - pivot_img_size:y, x - pivot_img_size:x] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y), (x, y + 20), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x - pivot_img_size, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y), (x + int(w / 2) - int(w / 4), y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) - int(w / 4), y - int(pivot_img_size / 2)), (x, y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif x + w + pivot_img_size < resolution_x and y + h + pivot_img_size < resolution_y:\n                                        freeze_img[y + h:y + h + pivot_img_size, x + w:x + w + pivot_img_size] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x + w, y + h - 20), (x + w + pivot_img_size, y + h), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x + w, y + h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y + h), (x + int(w / 2) + int(w / 4), y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) + int(w / 4), y + h + int(pivot_img_size / 2)), (x + w, y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                except Exception as err:\n                                    print(str(err))\n                        tic = time.time()\n                time_left = int(time_threshold - (toc - tic) + 1)\n                cv2.rectangle(freeze_img, (10, 10), (90, 50), (67, 67, 67), -10)\n                cv2.putText(freeze_img, str(time_left), (40, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1)\n                cv2.imshow('img', freeze_img)\n                freezed_frame = freezed_frame + 1\n            else:\n                face_detected = False\n                face_included_frames = 0\n                freeze = False\n                freezed_frame = 0\n        else:\n            cv2.imshow('img', img)\n        if cv2.waitKey(1) & 255 == ord('q'):\n            break\n    cap.release()\n    cv2.destroyAllWindows()",
            "def analysis(db_path, model_name='VGG-Face', detector_backend='opencv', distance_metric='cosine', enable_face_analysis=True, source=0, time_threshold=5, frame_threshold=5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    text_color = (255, 255, 255)\n    pivot_img_size = 112\n    enable_emotion = True\n    enable_age_gender = True\n    target_size = functions.find_target_size(model_name=model_name)\n    DeepFace.build_model(model_name=model_name)\n    print(f'facial recognition model {model_name} is just built')\n    if enable_face_analysis:\n        DeepFace.build_model(model_name='Age')\n        print('Age model is just built')\n        DeepFace.build_model(model_name='Gender')\n        print('Gender model is just built')\n        DeepFace.build_model(model_name='Emotion')\n        print('Emotion model is just built')\n    DeepFace.find(img_path=np.zeros([224, 224, 3]), db_path=db_path, model_name=model_name, detector_backend=detector_backend, distance_metric=distance_metric, enforce_detection=False)\n    freeze = False\n    face_detected = False\n    face_included_frames = 0\n    freezed_frame = 0\n    tic = time.time()\n    cap = cv2.VideoCapture(source)\n    while True:\n        (_, img) = cap.read()\n        if img is None:\n            break\n        raw_img = img.copy()\n        resolution_x = img.shape[1]\n        resolution_y = img.shape[0]\n        if freeze == False:\n            try:\n                face_objs = DeepFace.extract_faces(img_path=img, target_size=target_size, detector_backend=detector_backend, enforce_detection=False)\n                faces = []\n                for face_obj in face_objs:\n                    facial_area = face_obj['facial_area']\n                    faces.append((facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']))\n            except:\n                faces = []\n            if len(faces) == 0:\n                face_included_frames = 0\n        else:\n            faces = []\n        detected_faces = []\n        face_index = 0\n        for (x, y, w, h) in faces:\n            if w > 130:\n                face_detected = True\n                if face_index == 0:\n                    face_included_frames = face_included_frames + 1\n                cv2.rectangle(img, (x, y), (x + w, y + h), (67, 67, 67), 1)\n                cv2.putText(img, str(frame_threshold - face_included_frames), (int(x + w / 4), int(y + h / 1.5)), cv2.FONT_HERSHEY_SIMPLEX, 4, (255, 255, 255), 2)\n                detected_face = img[int(y):int(y + h), int(x):int(x + w)]\n                detected_faces.append((x, y, w, h))\n                face_index = face_index + 1\n        if face_detected == True and face_included_frames == frame_threshold and (freeze == False):\n            freeze = True\n            base_img = raw_img.copy()\n            detected_faces_final = detected_faces.copy()\n            tic = time.time()\n        if freeze == True:\n            toc = time.time()\n            if toc - tic < time_threshold:\n                if freezed_frame == 0:\n                    freeze_img = base_img.copy()\n                    for detected_face in detected_faces_final:\n                        x = detected_face[0]\n                        y = detected_face[1]\n                        w = detected_face[2]\n                        h = detected_face[3]\n                        cv2.rectangle(freeze_img, (x, y), (x + w, y + h), (67, 67, 67), 1)\n                        custom_face = base_img[y:y + h, x:x + w]\n                        if enable_face_analysis == True:\n                            demographies = DeepFace.analyze(img_path=custom_face, detector_backend=detector_backend, enforce_detection=False, silent=True)\n                            if len(demographies) > 0:\n                                demography = demographies[0]\n                                if enable_emotion:\n                                    emotion = demography['emotion']\n                                    emotion_df = pd.DataFrame(emotion.items(), columns=['emotion', 'score'])\n                                    emotion_df = emotion_df.sort_values(by=['score'], ascending=False).reset_index(drop=True)\n                                    overlay = freeze_img.copy()\n                                    opacity = 0.4\n                                    if x + w + pivot_img_size < resolution_x:\n                                        cv2.rectangle(freeze_img, (x + w, y), (x + w + pivot_img_size, y + h), (64, 64, 64), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                    elif x - pivot_img_size > 0:\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y), (x, y + h), (64, 64, 64), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                    for (index, instance) in emotion_df.iterrows():\n                                        current_emotion = instance['emotion']\n                                        emotion_label = f'{current_emotion} '\n                                        emotion_score = instance['score'] / 100\n                                        bar_x = 35\n                                        bar_x = int(bar_x * emotion_score)\n                                        if x + w + pivot_img_size < resolution_x:\n                                            text_location_y = y + 20 + (index + 1) * 20\n                                            text_location_x = x + w\n                                            if text_location_y < y + h:\n                                                cv2.putText(freeze_img, emotion_label, (text_location_x, text_location_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n                                                cv2.rectangle(freeze_img, (x + w + 70, y + 13 + (index + 1) * 20), (x + w + 70 + bar_x, y + 13 + (index + 1) * 20 + 5), (255, 255, 255), cv2.FILLED)\n                                        elif x - pivot_img_size > 0:\n                                            text_location_y = y + 20 + (index + 1) * 20\n                                            text_location_x = x - pivot_img_size\n                                            if text_location_y <= y + h:\n                                                cv2.putText(freeze_img, emotion_label, (text_location_x, text_location_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n                                                cv2.rectangle(freeze_img, (x - pivot_img_size + 70, y + 13 + (index + 1) * 20), (x - pivot_img_size + 70 + bar_x, y + 13 + (index + 1) * 20 + 5), (255, 255, 255), cv2.FILLED)\n                                if enable_age_gender:\n                                    apparent_age = demography['age']\n                                    dominant_gender = demography['dominant_gender']\n                                    gender = 'M' if dominant_gender == 'Man' else 'W'\n                                    analysis_report = str(int(apparent_age)) + ' ' + gender\n                                    info_box_color = (46, 200, 255)\n                                    if y - pivot_img_size + int(pivot_img_size / 5) > 0:\n                                        triangle_coordinates = np.array([(x + int(w / 2), y), (x + int(w / 2) - int(w / 10), y - int(pivot_img_size / 3)), (x + int(w / 2) + int(w / 10), y - int(pivot_img_size / 3))])\n                                        cv2.drawContours(freeze_img, [triangle_coordinates], 0, info_box_color, -1)\n                                        cv2.rectangle(freeze_img, (x + int(w / 5), y - pivot_img_size + int(pivot_img_size / 5)), (x + w - int(w / 5), y - int(pivot_img_size / 3)), info_box_color, cv2.FILLED)\n                                        cv2.putText(freeze_img, analysis_report, (x + int(w / 3.5), y - int(pivot_img_size / 2.1)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n                                    elif y + h + pivot_img_size - int(pivot_img_size / 5) < resolution_y:\n                                        triangle_coordinates = np.array([(x + int(w / 2), y + h), (x + int(w / 2) - int(w / 10), y + h + int(pivot_img_size / 3)), (x + int(w / 2) + int(w / 10), y + h + int(pivot_img_size / 3))])\n                                        cv2.drawContours(freeze_img, [triangle_coordinates], 0, info_box_color, -1)\n                                        cv2.rectangle(freeze_img, (x + int(w / 5), y + h + int(pivot_img_size / 3)), (x + w - int(w / 5), y + h + pivot_img_size - int(pivot_img_size / 5)), info_box_color, cv2.FILLED)\n                                        cv2.putText(freeze_img, analysis_report, (x + int(w / 3.5), y + h + int(pivot_img_size / 1.5)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n                        dfs = DeepFace.find(img_path=custom_face, db_path=db_path, model_name=model_name, detector_backend=detector_backend, distance_metric=distance_metric, enforce_detection=False, silent=True)\n                        if len(dfs) > 0:\n                            df = dfs[0]\n                            if df.shape[0] > 0:\n                                candidate = df.iloc[0]\n                                label = candidate['identity']\n                                display_img = cv2.imread(label)\n                                source_objs = DeepFace.extract_faces(img_path=label, target_size=(pivot_img_size, pivot_img_size), detector_backend=detector_backend, enforce_detection=False, align=False)\n                                if len(source_objs) > 0:\n                                    source_obj = source_objs[0]\n                                    display_img = source_obj['face']\n                                    display_img *= 255\n                                    display_img = display_img[:, :, ::-1]\n                                label = label.split('/')[-1]\n                                try:\n                                    if y - pivot_img_size > 0 and x + w + pivot_img_size < resolution_x:\n                                        freeze_img[y - pivot_img_size:y, x + w:x + w + pivot_img_size] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x + w, y), (x + w + pivot_img_size, y + 20), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x + w, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y), (x + 3 * int(w / 4), y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + 3 * int(w / 4), y - int(pivot_img_size / 2)), (x + w, y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif y + h + pivot_img_size < resolution_y and x - pivot_img_size > 0:\n                                        freeze_img[y + h:y + h + pivot_img_size, x - pivot_img_size:x] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y + h - 20), (x, y + h), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x - pivot_img_size, y + h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y + h), (x + int(w / 2) - int(w / 4), y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) - int(w / 4), y + h + int(pivot_img_size / 2)), (x, y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif y - pivot_img_size > 0 and x - pivot_img_size > 0:\n                                        freeze_img[y - pivot_img_size:y, x - pivot_img_size:x] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y), (x, y + 20), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x - pivot_img_size, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y), (x + int(w / 2) - int(w / 4), y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) - int(w / 4), y - int(pivot_img_size / 2)), (x, y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif x + w + pivot_img_size < resolution_x and y + h + pivot_img_size < resolution_y:\n                                        freeze_img[y + h:y + h + pivot_img_size, x + w:x + w + pivot_img_size] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x + w, y + h - 20), (x + w + pivot_img_size, y + h), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x + w, y + h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y + h), (x + int(w / 2) + int(w / 4), y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) + int(w / 4), y + h + int(pivot_img_size / 2)), (x + w, y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                except Exception as err:\n                                    print(str(err))\n                        tic = time.time()\n                time_left = int(time_threshold - (toc - tic) + 1)\n                cv2.rectangle(freeze_img, (10, 10), (90, 50), (67, 67, 67), -10)\n                cv2.putText(freeze_img, str(time_left), (40, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1)\n                cv2.imshow('img', freeze_img)\n                freezed_frame = freezed_frame + 1\n            else:\n                face_detected = False\n                face_included_frames = 0\n                freeze = False\n                freezed_frame = 0\n        else:\n            cv2.imshow('img', img)\n        if cv2.waitKey(1) & 255 == ord('q'):\n            break\n    cap.release()\n    cv2.destroyAllWindows()",
            "def analysis(db_path, model_name='VGG-Face', detector_backend='opencv', distance_metric='cosine', enable_face_analysis=True, source=0, time_threshold=5, frame_threshold=5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    text_color = (255, 255, 255)\n    pivot_img_size = 112\n    enable_emotion = True\n    enable_age_gender = True\n    target_size = functions.find_target_size(model_name=model_name)\n    DeepFace.build_model(model_name=model_name)\n    print(f'facial recognition model {model_name} is just built')\n    if enable_face_analysis:\n        DeepFace.build_model(model_name='Age')\n        print('Age model is just built')\n        DeepFace.build_model(model_name='Gender')\n        print('Gender model is just built')\n        DeepFace.build_model(model_name='Emotion')\n        print('Emotion model is just built')\n    DeepFace.find(img_path=np.zeros([224, 224, 3]), db_path=db_path, model_name=model_name, detector_backend=detector_backend, distance_metric=distance_metric, enforce_detection=False)\n    freeze = False\n    face_detected = False\n    face_included_frames = 0\n    freezed_frame = 0\n    tic = time.time()\n    cap = cv2.VideoCapture(source)\n    while True:\n        (_, img) = cap.read()\n        if img is None:\n            break\n        raw_img = img.copy()\n        resolution_x = img.shape[1]\n        resolution_y = img.shape[0]\n        if freeze == False:\n            try:\n                face_objs = DeepFace.extract_faces(img_path=img, target_size=target_size, detector_backend=detector_backend, enforce_detection=False)\n                faces = []\n                for face_obj in face_objs:\n                    facial_area = face_obj['facial_area']\n                    faces.append((facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']))\n            except:\n                faces = []\n            if len(faces) == 0:\n                face_included_frames = 0\n        else:\n            faces = []\n        detected_faces = []\n        face_index = 0\n        for (x, y, w, h) in faces:\n            if w > 130:\n                face_detected = True\n                if face_index == 0:\n                    face_included_frames = face_included_frames + 1\n                cv2.rectangle(img, (x, y), (x + w, y + h), (67, 67, 67), 1)\n                cv2.putText(img, str(frame_threshold - face_included_frames), (int(x + w / 4), int(y + h / 1.5)), cv2.FONT_HERSHEY_SIMPLEX, 4, (255, 255, 255), 2)\n                detected_face = img[int(y):int(y + h), int(x):int(x + w)]\n                detected_faces.append((x, y, w, h))\n                face_index = face_index + 1\n        if face_detected == True and face_included_frames == frame_threshold and (freeze == False):\n            freeze = True\n            base_img = raw_img.copy()\n            detected_faces_final = detected_faces.copy()\n            tic = time.time()\n        if freeze == True:\n            toc = time.time()\n            if toc - tic < time_threshold:\n                if freezed_frame == 0:\n                    freeze_img = base_img.copy()\n                    for detected_face in detected_faces_final:\n                        x = detected_face[0]\n                        y = detected_face[1]\n                        w = detected_face[2]\n                        h = detected_face[3]\n                        cv2.rectangle(freeze_img, (x, y), (x + w, y + h), (67, 67, 67), 1)\n                        custom_face = base_img[y:y + h, x:x + w]\n                        if enable_face_analysis == True:\n                            demographies = DeepFace.analyze(img_path=custom_face, detector_backend=detector_backend, enforce_detection=False, silent=True)\n                            if len(demographies) > 0:\n                                demography = demographies[0]\n                                if enable_emotion:\n                                    emotion = demography['emotion']\n                                    emotion_df = pd.DataFrame(emotion.items(), columns=['emotion', 'score'])\n                                    emotion_df = emotion_df.sort_values(by=['score'], ascending=False).reset_index(drop=True)\n                                    overlay = freeze_img.copy()\n                                    opacity = 0.4\n                                    if x + w + pivot_img_size < resolution_x:\n                                        cv2.rectangle(freeze_img, (x + w, y), (x + w + pivot_img_size, y + h), (64, 64, 64), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                    elif x - pivot_img_size > 0:\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y), (x, y + h), (64, 64, 64), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                    for (index, instance) in emotion_df.iterrows():\n                                        current_emotion = instance['emotion']\n                                        emotion_label = f'{current_emotion} '\n                                        emotion_score = instance['score'] / 100\n                                        bar_x = 35\n                                        bar_x = int(bar_x * emotion_score)\n                                        if x + w + pivot_img_size < resolution_x:\n                                            text_location_y = y + 20 + (index + 1) * 20\n                                            text_location_x = x + w\n                                            if text_location_y < y + h:\n                                                cv2.putText(freeze_img, emotion_label, (text_location_x, text_location_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n                                                cv2.rectangle(freeze_img, (x + w + 70, y + 13 + (index + 1) * 20), (x + w + 70 + bar_x, y + 13 + (index + 1) * 20 + 5), (255, 255, 255), cv2.FILLED)\n                                        elif x - pivot_img_size > 0:\n                                            text_location_y = y + 20 + (index + 1) * 20\n                                            text_location_x = x - pivot_img_size\n                                            if text_location_y <= y + h:\n                                                cv2.putText(freeze_img, emotion_label, (text_location_x, text_location_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n                                                cv2.rectangle(freeze_img, (x - pivot_img_size + 70, y + 13 + (index + 1) * 20), (x - pivot_img_size + 70 + bar_x, y + 13 + (index + 1) * 20 + 5), (255, 255, 255), cv2.FILLED)\n                                if enable_age_gender:\n                                    apparent_age = demography['age']\n                                    dominant_gender = demography['dominant_gender']\n                                    gender = 'M' if dominant_gender == 'Man' else 'W'\n                                    analysis_report = str(int(apparent_age)) + ' ' + gender\n                                    info_box_color = (46, 200, 255)\n                                    if y - pivot_img_size + int(pivot_img_size / 5) > 0:\n                                        triangle_coordinates = np.array([(x + int(w / 2), y), (x + int(w / 2) - int(w / 10), y - int(pivot_img_size / 3)), (x + int(w / 2) + int(w / 10), y - int(pivot_img_size / 3))])\n                                        cv2.drawContours(freeze_img, [triangle_coordinates], 0, info_box_color, -1)\n                                        cv2.rectangle(freeze_img, (x + int(w / 5), y - pivot_img_size + int(pivot_img_size / 5)), (x + w - int(w / 5), y - int(pivot_img_size / 3)), info_box_color, cv2.FILLED)\n                                        cv2.putText(freeze_img, analysis_report, (x + int(w / 3.5), y - int(pivot_img_size / 2.1)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n                                    elif y + h + pivot_img_size - int(pivot_img_size / 5) < resolution_y:\n                                        triangle_coordinates = np.array([(x + int(w / 2), y + h), (x + int(w / 2) - int(w / 10), y + h + int(pivot_img_size / 3)), (x + int(w / 2) + int(w / 10), y + h + int(pivot_img_size / 3))])\n                                        cv2.drawContours(freeze_img, [triangle_coordinates], 0, info_box_color, -1)\n                                        cv2.rectangle(freeze_img, (x + int(w / 5), y + h + int(pivot_img_size / 3)), (x + w - int(w / 5), y + h + pivot_img_size - int(pivot_img_size / 5)), info_box_color, cv2.FILLED)\n                                        cv2.putText(freeze_img, analysis_report, (x + int(w / 3.5), y + h + int(pivot_img_size / 1.5)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n                        dfs = DeepFace.find(img_path=custom_face, db_path=db_path, model_name=model_name, detector_backend=detector_backend, distance_metric=distance_metric, enforce_detection=False, silent=True)\n                        if len(dfs) > 0:\n                            df = dfs[0]\n                            if df.shape[0] > 0:\n                                candidate = df.iloc[0]\n                                label = candidate['identity']\n                                display_img = cv2.imread(label)\n                                source_objs = DeepFace.extract_faces(img_path=label, target_size=(pivot_img_size, pivot_img_size), detector_backend=detector_backend, enforce_detection=False, align=False)\n                                if len(source_objs) > 0:\n                                    source_obj = source_objs[0]\n                                    display_img = source_obj['face']\n                                    display_img *= 255\n                                    display_img = display_img[:, :, ::-1]\n                                label = label.split('/')[-1]\n                                try:\n                                    if y - pivot_img_size > 0 and x + w + pivot_img_size < resolution_x:\n                                        freeze_img[y - pivot_img_size:y, x + w:x + w + pivot_img_size] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x + w, y), (x + w + pivot_img_size, y + 20), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x + w, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y), (x + 3 * int(w / 4), y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + 3 * int(w / 4), y - int(pivot_img_size / 2)), (x + w, y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif y + h + pivot_img_size < resolution_y and x - pivot_img_size > 0:\n                                        freeze_img[y + h:y + h + pivot_img_size, x - pivot_img_size:x] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y + h - 20), (x, y + h), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x - pivot_img_size, y + h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y + h), (x + int(w / 2) - int(w / 4), y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) - int(w / 4), y + h + int(pivot_img_size / 2)), (x, y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif y - pivot_img_size > 0 and x - pivot_img_size > 0:\n                                        freeze_img[y - pivot_img_size:y, x - pivot_img_size:x] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x - pivot_img_size, y), (x, y + 20), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x - pivot_img_size, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y), (x + int(w / 2) - int(w / 4), y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) - int(w / 4), y - int(pivot_img_size / 2)), (x, y - int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                    elif x + w + pivot_img_size < resolution_x and y + h + pivot_img_size < resolution_y:\n                                        freeze_img[y + h:y + h + pivot_img_size, x + w:x + w + pivot_img_size] = display_img\n                                        overlay = freeze_img.copy()\n                                        opacity = 0.4\n                                        cv2.rectangle(freeze_img, (x + w, y + h - 20), (x + w + pivot_img_size, y + h), (46, 200, 255), cv2.FILLED)\n                                        cv2.addWeighted(overlay, opacity, freeze_img, 1 - opacity, 0, freeze_img)\n                                        cv2.putText(freeze_img, label, (x + w, y + h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n                                        cv2.line(freeze_img, (x + int(w / 2), y + h), (x + int(w / 2) + int(w / 4), y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                        cv2.line(freeze_img, (x + int(w / 2) + int(w / 4), y + h + int(pivot_img_size / 2)), (x + w, y + h + int(pivot_img_size / 2)), (67, 67, 67), 1)\n                                except Exception as err:\n                                    print(str(err))\n                        tic = time.time()\n                time_left = int(time_threshold - (toc - tic) + 1)\n                cv2.rectangle(freeze_img, (10, 10), (90, 50), (67, 67, 67), -10)\n                cv2.putText(freeze_img, str(time_left), (40, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1)\n                cv2.imshow('img', freeze_img)\n                freezed_frame = freezed_frame + 1\n            else:\n                face_detected = False\n                face_included_frames = 0\n                freeze = False\n                freezed_frame = 0\n        else:\n            cv2.imshow('img', img)\n        if cv2.waitKey(1) & 255 == ord('q'):\n            break\n    cap.release()\n    cv2.destroyAllWindows()"
        ]
    }
]