[
    {
        "func_name": "load_pair_history",
        "original": "def load_pair_history(pair: str, timeframe: str, datadir: Path, *, timerange: Optional[TimeRange]=None, fill_up_missing: bool=True, drop_incomplete: bool=False, startup_candles: int=0, data_format: Optional[str]=None, data_handler: Optional[IDataHandler]=None, candle_type: CandleType=CandleType.SPOT) -> DataFrame:\n    \"\"\"\n    Load cached ohlcv history for the given pair.\n\n    :param pair: Pair to load data for\n    :param timeframe: Timeframe (e.g. \"5m\")\n    :param datadir: Path to the data storage location.\n    :param data_format: Format of the data. Ignored if data_handler is set.\n    :param timerange: Limit data to be loaded to this timerange\n    :param fill_up_missing: Fill missing values with \"No action\"-candles\n    :param drop_incomplete: Drop last candle assuming it may be incomplete.\n    :param startup_candles: Additional candles to load at the start of the period\n    :param data_handler: Initialized data-handler to use.\n                         Will be initialized from data_format if not set\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\n    :return: DataFrame with ohlcv data, or empty DataFrame\n    \"\"\"\n    data_handler = get_datahandler(datadir, data_format, data_handler)\n    return data_handler.ohlcv_load(pair=pair, timeframe=timeframe, timerange=timerange, fill_missing=fill_up_missing, drop_incomplete=drop_incomplete, startup_candles=startup_candles, candle_type=candle_type)",
        "mutated": [
            "def load_pair_history(pair: str, timeframe: str, datadir: Path, *, timerange: Optional[TimeRange]=None, fill_up_missing: bool=True, drop_incomplete: bool=False, startup_candles: int=0, data_format: Optional[str]=None, data_handler: Optional[IDataHandler]=None, candle_type: CandleType=CandleType.SPOT) -> DataFrame:\n    if False:\n        i = 10\n    '\\n    Load cached ohlcv history for the given pair.\\n\\n    :param pair: Pair to load data for\\n    :param timeframe: Timeframe (e.g. \"5m\")\\n    :param datadir: Path to the data storage location.\\n    :param data_format: Format of the data. Ignored if data_handler is set.\\n    :param timerange: Limit data to be loaded to this timerange\\n    :param fill_up_missing: Fill missing values with \"No action\"-candles\\n    :param drop_incomplete: Drop last candle assuming it may be incomplete.\\n    :param startup_candles: Additional candles to load at the start of the period\\n    :param data_handler: Initialized data-handler to use.\\n                         Will be initialized from data_format if not set\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    :return: DataFrame with ohlcv data, or empty DataFrame\\n    '\n    data_handler = get_datahandler(datadir, data_format, data_handler)\n    return data_handler.ohlcv_load(pair=pair, timeframe=timeframe, timerange=timerange, fill_missing=fill_up_missing, drop_incomplete=drop_incomplete, startup_candles=startup_candles, candle_type=candle_type)",
            "def load_pair_history(pair: str, timeframe: str, datadir: Path, *, timerange: Optional[TimeRange]=None, fill_up_missing: bool=True, drop_incomplete: bool=False, startup_candles: int=0, data_format: Optional[str]=None, data_handler: Optional[IDataHandler]=None, candle_type: CandleType=CandleType.SPOT) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Load cached ohlcv history for the given pair.\\n\\n    :param pair: Pair to load data for\\n    :param timeframe: Timeframe (e.g. \"5m\")\\n    :param datadir: Path to the data storage location.\\n    :param data_format: Format of the data. Ignored if data_handler is set.\\n    :param timerange: Limit data to be loaded to this timerange\\n    :param fill_up_missing: Fill missing values with \"No action\"-candles\\n    :param drop_incomplete: Drop last candle assuming it may be incomplete.\\n    :param startup_candles: Additional candles to load at the start of the period\\n    :param data_handler: Initialized data-handler to use.\\n                         Will be initialized from data_format if not set\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    :return: DataFrame with ohlcv data, or empty DataFrame\\n    '\n    data_handler = get_datahandler(datadir, data_format, data_handler)\n    return data_handler.ohlcv_load(pair=pair, timeframe=timeframe, timerange=timerange, fill_missing=fill_up_missing, drop_incomplete=drop_incomplete, startup_candles=startup_candles, candle_type=candle_type)",
            "def load_pair_history(pair: str, timeframe: str, datadir: Path, *, timerange: Optional[TimeRange]=None, fill_up_missing: bool=True, drop_incomplete: bool=False, startup_candles: int=0, data_format: Optional[str]=None, data_handler: Optional[IDataHandler]=None, candle_type: CandleType=CandleType.SPOT) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Load cached ohlcv history for the given pair.\\n\\n    :param pair: Pair to load data for\\n    :param timeframe: Timeframe (e.g. \"5m\")\\n    :param datadir: Path to the data storage location.\\n    :param data_format: Format of the data. Ignored if data_handler is set.\\n    :param timerange: Limit data to be loaded to this timerange\\n    :param fill_up_missing: Fill missing values with \"No action\"-candles\\n    :param drop_incomplete: Drop last candle assuming it may be incomplete.\\n    :param startup_candles: Additional candles to load at the start of the period\\n    :param data_handler: Initialized data-handler to use.\\n                         Will be initialized from data_format if not set\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    :return: DataFrame with ohlcv data, or empty DataFrame\\n    '\n    data_handler = get_datahandler(datadir, data_format, data_handler)\n    return data_handler.ohlcv_load(pair=pair, timeframe=timeframe, timerange=timerange, fill_missing=fill_up_missing, drop_incomplete=drop_incomplete, startup_candles=startup_candles, candle_type=candle_type)",
            "def load_pair_history(pair: str, timeframe: str, datadir: Path, *, timerange: Optional[TimeRange]=None, fill_up_missing: bool=True, drop_incomplete: bool=False, startup_candles: int=0, data_format: Optional[str]=None, data_handler: Optional[IDataHandler]=None, candle_type: CandleType=CandleType.SPOT) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Load cached ohlcv history for the given pair.\\n\\n    :param pair: Pair to load data for\\n    :param timeframe: Timeframe (e.g. \"5m\")\\n    :param datadir: Path to the data storage location.\\n    :param data_format: Format of the data. Ignored if data_handler is set.\\n    :param timerange: Limit data to be loaded to this timerange\\n    :param fill_up_missing: Fill missing values with \"No action\"-candles\\n    :param drop_incomplete: Drop last candle assuming it may be incomplete.\\n    :param startup_candles: Additional candles to load at the start of the period\\n    :param data_handler: Initialized data-handler to use.\\n                         Will be initialized from data_format if not set\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    :return: DataFrame with ohlcv data, or empty DataFrame\\n    '\n    data_handler = get_datahandler(datadir, data_format, data_handler)\n    return data_handler.ohlcv_load(pair=pair, timeframe=timeframe, timerange=timerange, fill_missing=fill_up_missing, drop_incomplete=drop_incomplete, startup_candles=startup_candles, candle_type=candle_type)",
            "def load_pair_history(pair: str, timeframe: str, datadir: Path, *, timerange: Optional[TimeRange]=None, fill_up_missing: bool=True, drop_incomplete: bool=False, startup_candles: int=0, data_format: Optional[str]=None, data_handler: Optional[IDataHandler]=None, candle_type: CandleType=CandleType.SPOT) -> DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Load cached ohlcv history for the given pair.\\n\\n    :param pair: Pair to load data for\\n    :param timeframe: Timeframe (e.g. \"5m\")\\n    :param datadir: Path to the data storage location.\\n    :param data_format: Format of the data. Ignored if data_handler is set.\\n    :param timerange: Limit data to be loaded to this timerange\\n    :param fill_up_missing: Fill missing values with \"No action\"-candles\\n    :param drop_incomplete: Drop last candle assuming it may be incomplete.\\n    :param startup_candles: Additional candles to load at the start of the period\\n    :param data_handler: Initialized data-handler to use.\\n                         Will be initialized from data_format if not set\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    :return: DataFrame with ohlcv data, or empty DataFrame\\n    '\n    data_handler = get_datahandler(datadir, data_format, data_handler)\n    return data_handler.ohlcv_load(pair=pair, timeframe=timeframe, timerange=timerange, fill_missing=fill_up_missing, drop_incomplete=drop_incomplete, startup_candles=startup_candles, candle_type=candle_type)"
        ]
    },
    {
        "func_name": "load_data",
        "original": "def load_data(datadir: Path, timeframe: str, pairs: List[str], *, timerange: Optional[TimeRange]=None, fill_up_missing: bool=True, startup_candles: int=0, fail_without_data: bool=False, data_format: str='feather', candle_type: CandleType=CandleType.SPOT, user_futures_funding_rate: Optional[int]=None) -> Dict[str, DataFrame]:\n    \"\"\"\n    Load ohlcv history data for a list of pairs.\n\n    :param datadir: Path to the data storage location.\n    :param timeframe: Timeframe (e.g. \"5m\")\n    :param pairs: List of pairs to load\n    :param timerange: Limit data to be loaded to this timerange\n    :param fill_up_missing: Fill missing values with \"No action\"-candles\n    :param startup_candles: Additional candles to load at the start of the period\n    :param fail_without_data: Raise OperationalException if no data is found.\n    :param data_format: Data format which should be used. Defaults to json\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\n    :return: dict(<pair>:<Dataframe>)\n    \"\"\"\n    result: Dict[str, DataFrame] = {}\n    if startup_candles > 0 and timerange:\n        logger.info(f'Using indicator startup period: {startup_candles} ...')\n    data_handler = get_datahandler(datadir, data_format)\n    for pair in pairs:\n        hist = load_pair_history(pair=pair, timeframe=timeframe, datadir=datadir, timerange=timerange, fill_up_missing=fill_up_missing, startup_candles=startup_candles, data_handler=data_handler, candle_type=candle_type)\n        if not hist.empty:\n            result[pair] = hist\n        elif candle_type is CandleType.FUNDING_RATE and user_futures_funding_rate is not None:\n            logger.warn(f'{pair} using user specified [{user_futures_funding_rate}]')\n        elif candle_type not in (CandleType.SPOT, CandleType.FUTURES):\n            result[pair] = DataFrame(columns=['date', 'open', 'close', 'high', 'low', 'volume'])\n    if fail_without_data and (not result):\n        raise OperationalException('No data found. Terminating.')\n    return result",
        "mutated": [
            "def load_data(datadir: Path, timeframe: str, pairs: List[str], *, timerange: Optional[TimeRange]=None, fill_up_missing: bool=True, startup_candles: int=0, fail_without_data: bool=False, data_format: str='feather', candle_type: CandleType=CandleType.SPOT, user_futures_funding_rate: Optional[int]=None) -> Dict[str, DataFrame]:\n    if False:\n        i = 10\n    '\\n    Load ohlcv history data for a list of pairs.\\n\\n    :param datadir: Path to the data storage location.\\n    :param timeframe: Timeframe (e.g. \"5m\")\\n    :param pairs: List of pairs to load\\n    :param timerange: Limit data to be loaded to this timerange\\n    :param fill_up_missing: Fill missing values with \"No action\"-candles\\n    :param startup_candles: Additional candles to load at the start of the period\\n    :param fail_without_data: Raise OperationalException if no data is found.\\n    :param data_format: Data format which should be used. Defaults to json\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    :return: dict(<pair>:<Dataframe>)\\n    '\n    result: Dict[str, DataFrame] = {}\n    if startup_candles > 0 and timerange:\n        logger.info(f'Using indicator startup period: {startup_candles} ...')\n    data_handler = get_datahandler(datadir, data_format)\n    for pair in pairs:\n        hist = load_pair_history(pair=pair, timeframe=timeframe, datadir=datadir, timerange=timerange, fill_up_missing=fill_up_missing, startup_candles=startup_candles, data_handler=data_handler, candle_type=candle_type)\n        if not hist.empty:\n            result[pair] = hist\n        elif candle_type is CandleType.FUNDING_RATE and user_futures_funding_rate is not None:\n            logger.warn(f'{pair} using user specified [{user_futures_funding_rate}]')\n        elif candle_type not in (CandleType.SPOT, CandleType.FUTURES):\n            result[pair] = DataFrame(columns=['date', 'open', 'close', 'high', 'low', 'volume'])\n    if fail_without_data and (not result):\n        raise OperationalException('No data found. Terminating.')\n    return result",
            "def load_data(datadir: Path, timeframe: str, pairs: List[str], *, timerange: Optional[TimeRange]=None, fill_up_missing: bool=True, startup_candles: int=0, fail_without_data: bool=False, data_format: str='feather', candle_type: CandleType=CandleType.SPOT, user_futures_funding_rate: Optional[int]=None) -> Dict[str, DataFrame]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Load ohlcv history data for a list of pairs.\\n\\n    :param datadir: Path to the data storage location.\\n    :param timeframe: Timeframe (e.g. \"5m\")\\n    :param pairs: List of pairs to load\\n    :param timerange: Limit data to be loaded to this timerange\\n    :param fill_up_missing: Fill missing values with \"No action\"-candles\\n    :param startup_candles: Additional candles to load at the start of the period\\n    :param fail_without_data: Raise OperationalException if no data is found.\\n    :param data_format: Data format which should be used. Defaults to json\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    :return: dict(<pair>:<Dataframe>)\\n    '\n    result: Dict[str, DataFrame] = {}\n    if startup_candles > 0 and timerange:\n        logger.info(f'Using indicator startup period: {startup_candles} ...')\n    data_handler = get_datahandler(datadir, data_format)\n    for pair in pairs:\n        hist = load_pair_history(pair=pair, timeframe=timeframe, datadir=datadir, timerange=timerange, fill_up_missing=fill_up_missing, startup_candles=startup_candles, data_handler=data_handler, candle_type=candle_type)\n        if not hist.empty:\n            result[pair] = hist\n        elif candle_type is CandleType.FUNDING_RATE and user_futures_funding_rate is not None:\n            logger.warn(f'{pair} using user specified [{user_futures_funding_rate}]')\n        elif candle_type not in (CandleType.SPOT, CandleType.FUTURES):\n            result[pair] = DataFrame(columns=['date', 'open', 'close', 'high', 'low', 'volume'])\n    if fail_without_data and (not result):\n        raise OperationalException('No data found. Terminating.')\n    return result",
            "def load_data(datadir: Path, timeframe: str, pairs: List[str], *, timerange: Optional[TimeRange]=None, fill_up_missing: bool=True, startup_candles: int=0, fail_without_data: bool=False, data_format: str='feather', candle_type: CandleType=CandleType.SPOT, user_futures_funding_rate: Optional[int]=None) -> Dict[str, DataFrame]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Load ohlcv history data for a list of pairs.\\n\\n    :param datadir: Path to the data storage location.\\n    :param timeframe: Timeframe (e.g. \"5m\")\\n    :param pairs: List of pairs to load\\n    :param timerange: Limit data to be loaded to this timerange\\n    :param fill_up_missing: Fill missing values with \"No action\"-candles\\n    :param startup_candles: Additional candles to load at the start of the period\\n    :param fail_without_data: Raise OperationalException if no data is found.\\n    :param data_format: Data format which should be used. Defaults to json\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    :return: dict(<pair>:<Dataframe>)\\n    '\n    result: Dict[str, DataFrame] = {}\n    if startup_candles > 0 and timerange:\n        logger.info(f'Using indicator startup period: {startup_candles} ...')\n    data_handler = get_datahandler(datadir, data_format)\n    for pair in pairs:\n        hist = load_pair_history(pair=pair, timeframe=timeframe, datadir=datadir, timerange=timerange, fill_up_missing=fill_up_missing, startup_candles=startup_candles, data_handler=data_handler, candle_type=candle_type)\n        if not hist.empty:\n            result[pair] = hist\n        elif candle_type is CandleType.FUNDING_RATE and user_futures_funding_rate is not None:\n            logger.warn(f'{pair} using user specified [{user_futures_funding_rate}]')\n        elif candle_type not in (CandleType.SPOT, CandleType.FUTURES):\n            result[pair] = DataFrame(columns=['date', 'open', 'close', 'high', 'low', 'volume'])\n    if fail_without_data and (not result):\n        raise OperationalException('No data found. Terminating.')\n    return result",
            "def load_data(datadir: Path, timeframe: str, pairs: List[str], *, timerange: Optional[TimeRange]=None, fill_up_missing: bool=True, startup_candles: int=0, fail_without_data: bool=False, data_format: str='feather', candle_type: CandleType=CandleType.SPOT, user_futures_funding_rate: Optional[int]=None) -> Dict[str, DataFrame]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Load ohlcv history data for a list of pairs.\\n\\n    :param datadir: Path to the data storage location.\\n    :param timeframe: Timeframe (e.g. \"5m\")\\n    :param pairs: List of pairs to load\\n    :param timerange: Limit data to be loaded to this timerange\\n    :param fill_up_missing: Fill missing values with \"No action\"-candles\\n    :param startup_candles: Additional candles to load at the start of the period\\n    :param fail_without_data: Raise OperationalException if no data is found.\\n    :param data_format: Data format which should be used. Defaults to json\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    :return: dict(<pair>:<Dataframe>)\\n    '\n    result: Dict[str, DataFrame] = {}\n    if startup_candles > 0 and timerange:\n        logger.info(f'Using indicator startup period: {startup_candles} ...')\n    data_handler = get_datahandler(datadir, data_format)\n    for pair in pairs:\n        hist = load_pair_history(pair=pair, timeframe=timeframe, datadir=datadir, timerange=timerange, fill_up_missing=fill_up_missing, startup_candles=startup_candles, data_handler=data_handler, candle_type=candle_type)\n        if not hist.empty:\n            result[pair] = hist\n        elif candle_type is CandleType.FUNDING_RATE and user_futures_funding_rate is not None:\n            logger.warn(f'{pair} using user specified [{user_futures_funding_rate}]')\n        elif candle_type not in (CandleType.SPOT, CandleType.FUTURES):\n            result[pair] = DataFrame(columns=['date', 'open', 'close', 'high', 'low', 'volume'])\n    if fail_without_data and (not result):\n        raise OperationalException('No data found. Terminating.')\n    return result",
            "def load_data(datadir: Path, timeframe: str, pairs: List[str], *, timerange: Optional[TimeRange]=None, fill_up_missing: bool=True, startup_candles: int=0, fail_without_data: bool=False, data_format: str='feather', candle_type: CandleType=CandleType.SPOT, user_futures_funding_rate: Optional[int]=None) -> Dict[str, DataFrame]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Load ohlcv history data for a list of pairs.\\n\\n    :param datadir: Path to the data storage location.\\n    :param timeframe: Timeframe (e.g. \"5m\")\\n    :param pairs: List of pairs to load\\n    :param timerange: Limit data to be loaded to this timerange\\n    :param fill_up_missing: Fill missing values with \"No action\"-candles\\n    :param startup_candles: Additional candles to load at the start of the period\\n    :param fail_without_data: Raise OperationalException if no data is found.\\n    :param data_format: Data format which should be used. Defaults to json\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    :return: dict(<pair>:<Dataframe>)\\n    '\n    result: Dict[str, DataFrame] = {}\n    if startup_candles > 0 and timerange:\n        logger.info(f'Using indicator startup period: {startup_candles} ...')\n    data_handler = get_datahandler(datadir, data_format)\n    for pair in pairs:\n        hist = load_pair_history(pair=pair, timeframe=timeframe, datadir=datadir, timerange=timerange, fill_up_missing=fill_up_missing, startup_candles=startup_candles, data_handler=data_handler, candle_type=candle_type)\n        if not hist.empty:\n            result[pair] = hist\n        elif candle_type is CandleType.FUNDING_RATE and user_futures_funding_rate is not None:\n            logger.warn(f'{pair} using user specified [{user_futures_funding_rate}]')\n        elif candle_type not in (CandleType.SPOT, CandleType.FUTURES):\n            result[pair] = DataFrame(columns=['date', 'open', 'close', 'high', 'low', 'volume'])\n    if fail_without_data and (not result):\n        raise OperationalException('No data found. Terminating.')\n    return result"
        ]
    },
    {
        "func_name": "refresh_data",
        "original": "def refresh_data(*, datadir: Path, timeframe: str, pairs: List[str], exchange: Exchange, data_format: Optional[str]=None, timerange: Optional[TimeRange]=None, candle_type: CandleType) -> None:\n    \"\"\"\n    Refresh ohlcv history data for a list of pairs.\n\n    :param datadir: Path to the data storage location.\n    :param timeframe: Timeframe (e.g. \"5m\")\n    :param pairs: List of pairs to load\n    :param exchange: Exchange object\n    :param data_format: dataformat to use\n    :param timerange: Limit data to be loaded to this timerange\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\n    \"\"\"\n    data_handler = get_datahandler(datadir, data_format)\n    for (idx, pair) in enumerate(pairs):\n        process = f'{idx}/{len(pairs)}'\n        _download_pair_history(pair=pair, process=process, timeframe=timeframe, datadir=datadir, timerange=timerange, exchange=exchange, data_handler=data_handler, candle_type=candle_type)",
        "mutated": [
            "def refresh_data(*, datadir: Path, timeframe: str, pairs: List[str], exchange: Exchange, data_format: Optional[str]=None, timerange: Optional[TimeRange]=None, candle_type: CandleType) -> None:\n    if False:\n        i = 10\n    '\\n    Refresh ohlcv history data for a list of pairs.\\n\\n    :param datadir: Path to the data storage location.\\n    :param timeframe: Timeframe (e.g. \"5m\")\\n    :param pairs: List of pairs to load\\n    :param exchange: Exchange object\\n    :param data_format: dataformat to use\\n    :param timerange: Limit data to be loaded to this timerange\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    '\n    data_handler = get_datahandler(datadir, data_format)\n    for (idx, pair) in enumerate(pairs):\n        process = f'{idx}/{len(pairs)}'\n        _download_pair_history(pair=pair, process=process, timeframe=timeframe, datadir=datadir, timerange=timerange, exchange=exchange, data_handler=data_handler, candle_type=candle_type)",
            "def refresh_data(*, datadir: Path, timeframe: str, pairs: List[str], exchange: Exchange, data_format: Optional[str]=None, timerange: Optional[TimeRange]=None, candle_type: CandleType) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Refresh ohlcv history data for a list of pairs.\\n\\n    :param datadir: Path to the data storage location.\\n    :param timeframe: Timeframe (e.g. \"5m\")\\n    :param pairs: List of pairs to load\\n    :param exchange: Exchange object\\n    :param data_format: dataformat to use\\n    :param timerange: Limit data to be loaded to this timerange\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    '\n    data_handler = get_datahandler(datadir, data_format)\n    for (idx, pair) in enumerate(pairs):\n        process = f'{idx}/{len(pairs)}'\n        _download_pair_history(pair=pair, process=process, timeframe=timeframe, datadir=datadir, timerange=timerange, exchange=exchange, data_handler=data_handler, candle_type=candle_type)",
            "def refresh_data(*, datadir: Path, timeframe: str, pairs: List[str], exchange: Exchange, data_format: Optional[str]=None, timerange: Optional[TimeRange]=None, candle_type: CandleType) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Refresh ohlcv history data for a list of pairs.\\n\\n    :param datadir: Path to the data storage location.\\n    :param timeframe: Timeframe (e.g. \"5m\")\\n    :param pairs: List of pairs to load\\n    :param exchange: Exchange object\\n    :param data_format: dataformat to use\\n    :param timerange: Limit data to be loaded to this timerange\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    '\n    data_handler = get_datahandler(datadir, data_format)\n    for (idx, pair) in enumerate(pairs):\n        process = f'{idx}/{len(pairs)}'\n        _download_pair_history(pair=pair, process=process, timeframe=timeframe, datadir=datadir, timerange=timerange, exchange=exchange, data_handler=data_handler, candle_type=candle_type)",
            "def refresh_data(*, datadir: Path, timeframe: str, pairs: List[str], exchange: Exchange, data_format: Optional[str]=None, timerange: Optional[TimeRange]=None, candle_type: CandleType) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Refresh ohlcv history data for a list of pairs.\\n\\n    :param datadir: Path to the data storage location.\\n    :param timeframe: Timeframe (e.g. \"5m\")\\n    :param pairs: List of pairs to load\\n    :param exchange: Exchange object\\n    :param data_format: dataformat to use\\n    :param timerange: Limit data to be loaded to this timerange\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    '\n    data_handler = get_datahandler(datadir, data_format)\n    for (idx, pair) in enumerate(pairs):\n        process = f'{idx}/{len(pairs)}'\n        _download_pair_history(pair=pair, process=process, timeframe=timeframe, datadir=datadir, timerange=timerange, exchange=exchange, data_handler=data_handler, candle_type=candle_type)",
            "def refresh_data(*, datadir: Path, timeframe: str, pairs: List[str], exchange: Exchange, data_format: Optional[str]=None, timerange: Optional[TimeRange]=None, candle_type: CandleType) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Refresh ohlcv history data for a list of pairs.\\n\\n    :param datadir: Path to the data storage location.\\n    :param timeframe: Timeframe (e.g. \"5m\")\\n    :param pairs: List of pairs to load\\n    :param exchange: Exchange object\\n    :param data_format: dataformat to use\\n    :param timerange: Limit data to be loaded to this timerange\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    '\n    data_handler = get_datahandler(datadir, data_format)\n    for (idx, pair) in enumerate(pairs):\n        process = f'{idx}/{len(pairs)}'\n        _download_pair_history(pair=pair, process=process, timeframe=timeframe, datadir=datadir, timerange=timerange, exchange=exchange, data_handler=data_handler, candle_type=candle_type)"
        ]
    },
    {
        "func_name": "_load_cached_data_for_updating",
        "original": "def _load_cached_data_for_updating(pair: str, timeframe: str, timerange: Optional[TimeRange], data_handler: IDataHandler, candle_type: CandleType, prepend: bool=False) -> Tuple[DataFrame, Optional[int], Optional[int]]:\n    \"\"\"\n    Load cached data to download more data.\n    If timerange is passed in, checks whether data from an before the stored data will be\n    downloaded.\n    If that's the case then what's available should be completely overwritten.\n    Otherwise downloads always start at the end of the available data to avoid data gaps.\n    Note: Only used by download_pair_history().\n    \"\"\"\n    start = None\n    end = None\n    if timerange:\n        if timerange.starttype == 'date':\n            start = timerange.startdt\n        if timerange.stoptype == 'date':\n            end = timerange.stopdt\n    data = data_handler.ohlcv_load(pair, timeframe=timeframe, timerange=None, fill_missing=False, drop_incomplete=True, warn_no_data=False, candle_type=candle_type)\n    if not data.empty:\n        if not prepend and start and (start < data.iloc[0]['date']):\n            data = DataFrame(columns=DEFAULT_DATAFRAME_COLUMNS)\n        elif prepend:\n            end = data.iloc[0]['date']\n        else:\n            start = data.iloc[-1]['date']\n    start_ms = int(start.timestamp() * 1000) if start else None\n    end_ms = int(end.timestamp() * 1000) if end else None\n    return (data, start_ms, end_ms)",
        "mutated": [
            "def _load_cached_data_for_updating(pair: str, timeframe: str, timerange: Optional[TimeRange], data_handler: IDataHandler, candle_type: CandleType, prepend: bool=False) -> Tuple[DataFrame, Optional[int], Optional[int]]:\n    if False:\n        i = 10\n    \"\\n    Load cached data to download more data.\\n    If timerange is passed in, checks whether data from an before the stored data will be\\n    downloaded.\\n    If that's the case then what's available should be completely overwritten.\\n    Otherwise downloads always start at the end of the available data to avoid data gaps.\\n    Note: Only used by download_pair_history().\\n    \"\n    start = None\n    end = None\n    if timerange:\n        if timerange.starttype == 'date':\n            start = timerange.startdt\n        if timerange.stoptype == 'date':\n            end = timerange.stopdt\n    data = data_handler.ohlcv_load(pair, timeframe=timeframe, timerange=None, fill_missing=False, drop_incomplete=True, warn_no_data=False, candle_type=candle_type)\n    if not data.empty:\n        if not prepend and start and (start < data.iloc[0]['date']):\n            data = DataFrame(columns=DEFAULT_DATAFRAME_COLUMNS)\n        elif prepend:\n            end = data.iloc[0]['date']\n        else:\n            start = data.iloc[-1]['date']\n    start_ms = int(start.timestamp() * 1000) if start else None\n    end_ms = int(end.timestamp() * 1000) if end else None\n    return (data, start_ms, end_ms)",
            "def _load_cached_data_for_updating(pair: str, timeframe: str, timerange: Optional[TimeRange], data_handler: IDataHandler, candle_type: CandleType, prepend: bool=False) -> Tuple[DataFrame, Optional[int], Optional[int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Load cached data to download more data.\\n    If timerange is passed in, checks whether data from an before the stored data will be\\n    downloaded.\\n    If that's the case then what's available should be completely overwritten.\\n    Otherwise downloads always start at the end of the available data to avoid data gaps.\\n    Note: Only used by download_pair_history().\\n    \"\n    start = None\n    end = None\n    if timerange:\n        if timerange.starttype == 'date':\n            start = timerange.startdt\n        if timerange.stoptype == 'date':\n            end = timerange.stopdt\n    data = data_handler.ohlcv_load(pair, timeframe=timeframe, timerange=None, fill_missing=False, drop_incomplete=True, warn_no_data=False, candle_type=candle_type)\n    if not data.empty:\n        if not prepend and start and (start < data.iloc[0]['date']):\n            data = DataFrame(columns=DEFAULT_DATAFRAME_COLUMNS)\n        elif prepend:\n            end = data.iloc[0]['date']\n        else:\n            start = data.iloc[-1]['date']\n    start_ms = int(start.timestamp() * 1000) if start else None\n    end_ms = int(end.timestamp() * 1000) if end else None\n    return (data, start_ms, end_ms)",
            "def _load_cached_data_for_updating(pair: str, timeframe: str, timerange: Optional[TimeRange], data_handler: IDataHandler, candle_type: CandleType, prepend: bool=False) -> Tuple[DataFrame, Optional[int], Optional[int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Load cached data to download more data.\\n    If timerange is passed in, checks whether data from an before the stored data will be\\n    downloaded.\\n    If that's the case then what's available should be completely overwritten.\\n    Otherwise downloads always start at the end of the available data to avoid data gaps.\\n    Note: Only used by download_pair_history().\\n    \"\n    start = None\n    end = None\n    if timerange:\n        if timerange.starttype == 'date':\n            start = timerange.startdt\n        if timerange.stoptype == 'date':\n            end = timerange.stopdt\n    data = data_handler.ohlcv_load(pair, timeframe=timeframe, timerange=None, fill_missing=False, drop_incomplete=True, warn_no_data=False, candle_type=candle_type)\n    if not data.empty:\n        if not prepend and start and (start < data.iloc[0]['date']):\n            data = DataFrame(columns=DEFAULT_DATAFRAME_COLUMNS)\n        elif prepend:\n            end = data.iloc[0]['date']\n        else:\n            start = data.iloc[-1]['date']\n    start_ms = int(start.timestamp() * 1000) if start else None\n    end_ms = int(end.timestamp() * 1000) if end else None\n    return (data, start_ms, end_ms)",
            "def _load_cached_data_for_updating(pair: str, timeframe: str, timerange: Optional[TimeRange], data_handler: IDataHandler, candle_type: CandleType, prepend: bool=False) -> Tuple[DataFrame, Optional[int], Optional[int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Load cached data to download more data.\\n    If timerange is passed in, checks whether data from an before the stored data will be\\n    downloaded.\\n    If that's the case then what's available should be completely overwritten.\\n    Otherwise downloads always start at the end of the available data to avoid data gaps.\\n    Note: Only used by download_pair_history().\\n    \"\n    start = None\n    end = None\n    if timerange:\n        if timerange.starttype == 'date':\n            start = timerange.startdt\n        if timerange.stoptype == 'date':\n            end = timerange.stopdt\n    data = data_handler.ohlcv_load(pair, timeframe=timeframe, timerange=None, fill_missing=False, drop_incomplete=True, warn_no_data=False, candle_type=candle_type)\n    if not data.empty:\n        if not prepend and start and (start < data.iloc[0]['date']):\n            data = DataFrame(columns=DEFAULT_DATAFRAME_COLUMNS)\n        elif prepend:\n            end = data.iloc[0]['date']\n        else:\n            start = data.iloc[-1]['date']\n    start_ms = int(start.timestamp() * 1000) if start else None\n    end_ms = int(end.timestamp() * 1000) if end else None\n    return (data, start_ms, end_ms)",
            "def _load_cached_data_for_updating(pair: str, timeframe: str, timerange: Optional[TimeRange], data_handler: IDataHandler, candle_type: CandleType, prepend: bool=False) -> Tuple[DataFrame, Optional[int], Optional[int]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Load cached data to download more data.\\n    If timerange is passed in, checks whether data from an before the stored data will be\\n    downloaded.\\n    If that's the case then what's available should be completely overwritten.\\n    Otherwise downloads always start at the end of the available data to avoid data gaps.\\n    Note: Only used by download_pair_history().\\n    \"\n    start = None\n    end = None\n    if timerange:\n        if timerange.starttype == 'date':\n            start = timerange.startdt\n        if timerange.stoptype == 'date':\n            end = timerange.stopdt\n    data = data_handler.ohlcv_load(pair, timeframe=timeframe, timerange=None, fill_missing=False, drop_incomplete=True, warn_no_data=False, candle_type=candle_type)\n    if not data.empty:\n        if not prepend and start and (start < data.iloc[0]['date']):\n            data = DataFrame(columns=DEFAULT_DATAFRAME_COLUMNS)\n        elif prepend:\n            end = data.iloc[0]['date']\n        else:\n            start = data.iloc[-1]['date']\n    start_ms = int(start.timestamp() * 1000) if start else None\n    end_ms = int(end.timestamp() * 1000) if end else None\n    return (data, start_ms, end_ms)"
        ]
    },
    {
        "func_name": "_download_pair_history",
        "original": "def _download_pair_history(pair: str, *, datadir: Path, exchange: Exchange, timeframe: str='5m', process: str='', new_pairs_days: int=30, data_handler: Optional[IDataHandler]=None, timerange: Optional[TimeRange]=None, candle_type: CandleType, erase: bool=False, prepend: bool=False) -> bool:\n    \"\"\"\n    Download latest candles from the exchange for the pair and timeframe passed in parameters\n    The data is downloaded starting from the last correct data that\n    exists in a cache. If timerange starts earlier than the data in the cache,\n    the full data will be redownloaded\n\n    :param pair: pair to download\n    :param timeframe: Timeframe (e.g \"5m\")\n    :param timerange: range of time to download\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\n    :param erase: Erase existing data\n    :return: bool with success state\n    \"\"\"\n    data_handler = get_datahandler(datadir, data_handler=data_handler)\n    try:\n        if erase:\n            if data_handler.ohlcv_purge(pair, timeframe, candle_type=candle_type):\n                logger.info(f'Deleting existing data for pair {pair}, {timeframe}, {candle_type}.')\n        (data, since_ms, until_ms) = _load_cached_data_for_updating(pair, timeframe, timerange, data_handler=data_handler, candle_type=candle_type, prepend=prepend)\n        logger.info(f'''({process}) - Download history data for \"{pair}\", {timeframe}, {candle_type} and store in {datadir}. From {(format_ms_time(since_ms) if since_ms else 'start')} to {(format_ms_time(until_ms) if until_ms else 'now')}''')\n        logger.debug('Current Start: %s', f\"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        logger.debug('Current End: %s', f\"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        new_data = exchange.get_historic_ohlcv(pair=pair, timeframe=timeframe, since_ms=since_ms if since_ms else int((datetime.now() - timedelta(days=new_pairs_days)).timestamp()) * 1000, is_new_pair=data.empty, candle_type=candle_type, until_ms=until_ms if until_ms else None)\n        new_dataframe = ohlcv_to_dataframe(new_data, timeframe, pair, fill_missing=False, drop_incomplete=True)\n        if data.empty:\n            data = new_dataframe\n        else:\n            data = clean_ohlcv_dataframe(concat([data, new_dataframe], axis=0), timeframe, pair, fill_missing=False, drop_incomplete=False)\n        logger.debug('New Start: %s', f\"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        logger.debug('New End: %s', f\"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        data_handler.ohlcv_store(pair, timeframe, data=data, candle_type=candle_type)\n        return True\n    except Exception:\n        logger.exception(f'Failed to download history data for pair: \"{pair}\", timeframe: {timeframe}.')\n        return False",
        "mutated": [
            "def _download_pair_history(pair: str, *, datadir: Path, exchange: Exchange, timeframe: str='5m', process: str='', new_pairs_days: int=30, data_handler: Optional[IDataHandler]=None, timerange: Optional[TimeRange]=None, candle_type: CandleType, erase: bool=False, prepend: bool=False) -> bool:\n    if False:\n        i = 10\n    '\\n    Download latest candles from the exchange for the pair and timeframe passed in parameters\\n    The data is downloaded starting from the last correct data that\\n    exists in a cache. If timerange starts earlier than the data in the cache,\\n    the full data will be redownloaded\\n\\n    :param pair: pair to download\\n    :param timeframe: Timeframe (e.g \"5m\")\\n    :param timerange: range of time to download\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    :param erase: Erase existing data\\n    :return: bool with success state\\n    '\n    data_handler = get_datahandler(datadir, data_handler=data_handler)\n    try:\n        if erase:\n            if data_handler.ohlcv_purge(pair, timeframe, candle_type=candle_type):\n                logger.info(f'Deleting existing data for pair {pair}, {timeframe}, {candle_type}.')\n        (data, since_ms, until_ms) = _load_cached_data_for_updating(pair, timeframe, timerange, data_handler=data_handler, candle_type=candle_type, prepend=prepend)\n        logger.info(f'''({process}) - Download history data for \"{pair}\", {timeframe}, {candle_type} and store in {datadir}. From {(format_ms_time(since_ms) if since_ms else 'start')} to {(format_ms_time(until_ms) if until_ms else 'now')}''')\n        logger.debug('Current Start: %s', f\"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        logger.debug('Current End: %s', f\"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        new_data = exchange.get_historic_ohlcv(pair=pair, timeframe=timeframe, since_ms=since_ms if since_ms else int((datetime.now() - timedelta(days=new_pairs_days)).timestamp()) * 1000, is_new_pair=data.empty, candle_type=candle_type, until_ms=until_ms if until_ms else None)\n        new_dataframe = ohlcv_to_dataframe(new_data, timeframe, pair, fill_missing=False, drop_incomplete=True)\n        if data.empty:\n            data = new_dataframe\n        else:\n            data = clean_ohlcv_dataframe(concat([data, new_dataframe], axis=0), timeframe, pair, fill_missing=False, drop_incomplete=False)\n        logger.debug('New Start: %s', f\"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        logger.debug('New End: %s', f\"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        data_handler.ohlcv_store(pair, timeframe, data=data, candle_type=candle_type)\n        return True\n    except Exception:\n        logger.exception(f'Failed to download history data for pair: \"{pair}\", timeframe: {timeframe}.')\n        return False",
            "def _download_pair_history(pair: str, *, datadir: Path, exchange: Exchange, timeframe: str='5m', process: str='', new_pairs_days: int=30, data_handler: Optional[IDataHandler]=None, timerange: Optional[TimeRange]=None, candle_type: CandleType, erase: bool=False, prepend: bool=False) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Download latest candles from the exchange for the pair and timeframe passed in parameters\\n    The data is downloaded starting from the last correct data that\\n    exists in a cache. If timerange starts earlier than the data in the cache,\\n    the full data will be redownloaded\\n\\n    :param pair: pair to download\\n    :param timeframe: Timeframe (e.g \"5m\")\\n    :param timerange: range of time to download\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    :param erase: Erase existing data\\n    :return: bool with success state\\n    '\n    data_handler = get_datahandler(datadir, data_handler=data_handler)\n    try:\n        if erase:\n            if data_handler.ohlcv_purge(pair, timeframe, candle_type=candle_type):\n                logger.info(f'Deleting existing data for pair {pair}, {timeframe}, {candle_type}.')\n        (data, since_ms, until_ms) = _load_cached_data_for_updating(pair, timeframe, timerange, data_handler=data_handler, candle_type=candle_type, prepend=prepend)\n        logger.info(f'''({process}) - Download history data for \"{pair}\", {timeframe}, {candle_type} and store in {datadir}. From {(format_ms_time(since_ms) if since_ms else 'start')} to {(format_ms_time(until_ms) if until_ms else 'now')}''')\n        logger.debug('Current Start: %s', f\"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        logger.debug('Current End: %s', f\"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        new_data = exchange.get_historic_ohlcv(pair=pair, timeframe=timeframe, since_ms=since_ms if since_ms else int((datetime.now() - timedelta(days=new_pairs_days)).timestamp()) * 1000, is_new_pair=data.empty, candle_type=candle_type, until_ms=until_ms if until_ms else None)\n        new_dataframe = ohlcv_to_dataframe(new_data, timeframe, pair, fill_missing=False, drop_incomplete=True)\n        if data.empty:\n            data = new_dataframe\n        else:\n            data = clean_ohlcv_dataframe(concat([data, new_dataframe], axis=0), timeframe, pair, fill_missing=False, drop_incomplete=False)\n        logger.debug('New Start: %s', f\"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        logger.debug('New End: %s', f\"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        data_handler.ohlcv_store(pair, timeframe, data=data, candle_type=candle_type)\n        return True\n    except Exception:\n        logger.exception(f'Failed to download history data for pair: \"{pair}\", timeframe: {timeframe}.')\n        return False",
            "def _download_pair_history(pair: str, *, datadir: Path, exchange: Exchange, timeframe: str='5m', process: str='', new_pairs_days: int=30, data_handler: Optional[IDataHandler]=None, timerange: Optional[TimeRange]=None, candle_type: CandleType, erase: bool=False, prepend: bool=False) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Download latest candles from the exchange for the pair and timeframe passed in parameters\\n    The data is downloaded starting from the last correct data that\\n    exists in a cache. If timerange starts earlier than the data in the cache,\\n    the full data will be redownloaded\\n\\n    :param pair: pair to download\\n    :param timeframe: Timeframe (e.g \"5m\")\\n    :param timerange: range of time to download\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    :param erase: Erase existing data\\n    :return: bool with success state\\n    '\n    data_handler = get_datahandler(datadir, data_handler=data_handler)\n    try:\n        if erase:\n            if data_handler.ohlcv_purge(pair, timeframe, candle_type=candle_type):\n                logger.info(f'Deleting existing data for pair {pair}, {timeframe}, {candle_type}.')\n        (data, since_ms, until_ms) = _load_cached_data_for_updating(pair, timeframe, timerange, data_handler=data_handler, candle_type=candle_type, prepend=prepend)\n        logger.info(f'''({process}) - Download history data for \"{pair}\", {timeframe}, {candle_type} and store in {datadir}. From {(format_ms_time(since_ms) if since_ms else 'start')} to {(format_ms_time(until_ms) if until_ms else 'now')}''')\n        logger.debug('Current Start: %s', f\"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        logger.debug('Current End: %s', f\"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        new_data = exchange.get_historic_ohlcv(pair=pair, timeframe=timeframe, since_ms=since_ms if since_ms else int((datetime.now() - timedelta(days=new_pairs_days)).timestamp()) * 1000, is_new_pair=data.empty, candle_type=candle_type, until_ms=until_ms if until_ms else None)\n        new_dataframe = ohlcv_to_dataframe(new_data, timeframe, pair, fill_missing=False, drop_incomplete=True)\n        if data.empty:\n            data = new_dataframe\n        else:\n            data = clean_ohlcv_dataframe(concat([data, new_dataframe], axis=0), timeframe, pair, fill_missing=False, drop_incomplete=False)\n        logger.debug('New Start: %s', f\"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        logger.debug('New End: %s', f\"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        data_handler.ohlcv_store(pair, timeframe, data=data, candle_type=candle_type)\n        return True\n    except Exception:\n        logger.exception(f'Failed to download history data for pair: \"{pair}\", timeframe: {timeframe}.')\n        return False",
            "def _download_pair_history(pair: str, *, datadir: Path, exchange: Exchange, timeframe: str='5m', process: str='', new_pairs_days: int=30, data_handler: Optional[IDataHandler]=None, timerange: Optional[TimeRange]=None, candle_type: CandleType, erase: bool=False, prepend: bool=False) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Download latest candles from the exchange for the pair and timeframe passed in parameters\\n    The data is downloaded starting from the last correct data that\\n    exists in a cache. If timerange starts earlier than the data in the cache,\\n    the full data will be redownloaded\\n\\n    :param pair: pair to download\\n    :param timeframe: Timeframe (e.g \"5m\")\\n    :param timerange: range of time to download\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    :param erase: Erase existing data\\n    :return: bool with success state\\n    '\n    data_handler = get_datahandler(datadir, data_handler=data_handler)\n    try:\n        if erase:\n            if data_handler.ohlcv_purge(pair, timeframe, candle_type=candle_type):\n                logger.info(f'Deleting existing data for pair {pair}, {timeframe}, {candle_type}.')\n        (data, since_ms, until_ms) = _load_cached_data_for_updating(pair, timeframe, timerange, data_handler=data_handler, candle_type=candle_type, prepend=prepend)\n        logger.info(f'''({process}) - Download history data for \"{pair}\", {timeframe}, {candle_type} and store in {datadir}. From {(format_ms_time(since_ms) if since_ms else 'start')} to {(format_ms_time(until_ms) if until_ms else 'now')}''')\n        logger.debug('Current Start: %s', f\"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        logger.debug('Current End: %s', f\"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        new_data = exchange.get_historic_ohlcv(pair=pair, timeframe=timeframe, since_ms=since_ms if since_ms else int((datetime.now() - timedelta(days=new_pairs_days)).timestamp()) * 1000, is_new_pair=data.empty, candle_type=candle_type, until_ms=until_ms if until_ms else None)\n        new_dataframe = ohlcv_to_dataframe(new_data, timeframe, pair, fill_missing=False, drop_incomplete=True)\n        if data.empty:\n            data = new_dataframe\n        else:\n            data = clean_ohlcv_dataframe(concat([data, new_dataframe], axis=0), timeframe, pair, fill_missing=False, drop_incomplete=False)\n        logger.debug('New Start: %s', f\"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        logger.debug('New End: %s', f\"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        data_handler.ohlcv_store(pair, timeframe, data=data, candle_type=candle_type)\n        return True\n    except Exception:\n        logger.exception(f'Failed to download history data for pair: \"{pair}\", timeframe: {timeframe}.')\n        return False",
            "def _download_pair_history(pair: str, *, datadir: Path, exchange: Exchange, timeframe: str='5m', process: str='', new_pairs_days: int=30, data_handler: Optional[IDataHandler]=None, timerange: Optional[TimeRange]=None, candle_type: CandleType, erase: bool=False, prepend: bool=False) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Download latest candles from the exchange for the pair and timeframe passed in parameters\\n    The data is downloaded starting from the last correct data that\\n    exists in a cache. If timerange starts earlier than the data in the cache,\\n    the full data will be redownloaded\\n\\n    :param pair: pair to download\\n    :param timeframe: Timeframe (e.g \"5m\")\\n    :param timerange: range of time to download\\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\\n    :param erase: Erase existing data\\n    :return: bool with success state\\n    '\n    data_handler = get_datahandler(datadir, data_handler=data_handler)\n    try:\n        if erase:\n            if data_handler.ohlcv_purge(pair, timeframe, candle_type=candle_type):\n                logger.info(f'Deleting existing data for pair {pair}, {timeframe}, {candle_type}.')\n        (data, since_ms, until_ms) = _load_cached_data_for_updating(pair, timeframe, timerange, data_handler=data_handler, candle_type=candle_type, prepend=prepend)\n        logger.info(f'''({process}) - Download history data for \"{pair}\", {timeframe}, {candle_type} and store in {datadir}. From {(format_ms_time(since_ms) if since_ms else 'start')} to {(format_ms_time(until_ms) if until_ms else 'now')}''')\n        logger.debug('Current Start: %s', f\"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        logger.debug('Current End: %s', f\"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        new_data = exchange.get_historic_ohlcv(pair=pair, timeframe=timeframe, since_ms=since_ms if since_ms else int((datetime.now() - timedelta(days=new_pairs_days)).timestamp()) * 1000, is_new_pair=data.empty, candle_type=candle_type, until_ms=until_ms if until_ms else None)\n        new_dataframe = ohlcv_to_dataframe(new_data, timeframe, pair, fill_missing=False, drop_incomplete=True)\n        if data.empty:\n            data = new_dataframe\n        else:\n            data = clean_ohlcv_dataframe(concat([data, new_dataframe], axis=0), timeframe, pair, fill_missing=False, drop_incomplete=False)\n        logger.debug('New Start: %s', f\"{data.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        logger.debug('New End: %s', f\"{data.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\" if not data.empty else 'None')\n        data_handler.ohlcv_store(pair, timeframe, data=data, candle_type=candle_type)\n        return True\n    except Exception:\n        logger.exception(f'Failed to download history data for pair: \"{pair}\", timeframe: {timeframe}.')\n        return False"
        ]
    },
    {
        "func_name": "refresh_backtest_ohlcv_data",
        "original": "def refresh_backtest_ohlcv_data(exchange: Exchange, pairs: List[str], timeframes: List[str], datadir: Path, trading_mode: str, timerange: Optional[TimeRange]=None, new_pairs_days: int=30, erase: bool=False, data_format: Optional[str]=None, prepend: bool=False) -> List[str]:\n    \"\"\"\n    Refresh stored ohlcv data for backtesting and hyperopt operations.\n    Used by freqtrade download-data subcommand.\n    :return: List of pairs that are not available.\n    \"\"\"\n    pairs_not_available = []\n    data_handler = get_datahandler(datadir, data_format)\n    candle_type = CandleType.get_default(trading_mode)\n    process = ''\n    for (idx, pair) in enumerate(pairs, start=1):\n        if pair not in exchange.markets:\n            pairs_not_available.append(pair)\n            logger.info(f'Skipping pair {pair}...')\n            continue\n        for timeframe in timeframes:\n            logger.debug(f'Downloading pair {pair}, {candle_type}, interval {timeframe}.')\n            process = f'{idx}/{len(pairs)}'\n            _download_pair_history(pair=pair, process=process, datadir=datadir, exchange=exchange, timerange=timerange, data_handler=data_handler, timeframe=str(timeframe), new_pairs_days=new_pairs_days, candle_type=candle_type, erase=erase, prepend=prepend)\n        if trading_mode == 'futures':\n            tf_mark = exchange.get_option('mark_ohlcv_timeframe')\n            fr_candle_type = CandleType.from_string(exchange.get_option('mark_ohlcv_price'))\n            for funding_candle_type in (CandleType.FUNDING_RATE, fr_candle_type):\n                _download_pair_history(pair=pair, process=process, datadir=datadir, exchange=exchange, timerange=timerange, data_handler=data_handler, timeframe=str(tf_mark), new_pairs_days=new_pairs_days, candle_type=funding_candle_type, erase=erase, prepend=prepend)\n    return pairs_not_available",
        "mutated": [
            "def refresh_backtest_ohlcv_data(exchange: Exchange, pairs: List[str], timeframes: List[str], datadir: Path, trading_mode: str, timerange: Optional[TimeRange]=None, new_pairs_days: int=30, erase: bool=False, data_format: Optional[str]=None, prepend: bool=False) -> List[str]:\n    if False:\n        i = 10\n    '\\n    Refresh stored ohlcv data for backtesting and hyperopt operations.\\n    Used by freqtrade download-data subcommand.\\n    :return: List of pairs that are not available.\\n    '\n    pairs_not_available = []\n    data_handler = get_datahandler(datadir, data_format)\n    candle_type = CandleType.get_default(trading_mode)\n    process = ''\n    for (idx, pair) in enumerate(pairs, start=1):\n        if pair not in exchange.markets:\n            pairs_not_available.append(pair)\n            logger.info(f'Skipping pair {pair}...')\n            continue\n        for timeframe in timeframes:\n            logger.debug(f'Downloading pair {pair}, {candle_type}, interval {timeframe}.')\n            process = f'{idx}/{len(pairs)}'\n            _download_pair_history(pair=pair, process=process, datadir=datadir, exchange=exchange, timerange=timerange, data_handler=data_handler, timeframe=str(timeframe), new_pairs_days=new_pairs_days, candle_type=candle_type, erase=erase, prepend=prepend)\n        if trading_mode == 'futures':\n            tf_mark = exchange.get_option('mark_ohlcv_timeframe')\n            fr_candle_type = CandleType.from_string(exchange.get_option('mark_ohlcv_price'))\n            for funding_candle_type in (CandleType.FUNDING_RATE, fr_candle_type):\n                _download_pair_history(pair=pair, process=process, datadir=datadir, exchange=exchange, timerange=timerange, data_handler=data_handler, timeframe=str(tf_mark), new_pairs_days=new_pairs_days, candle_type=funding_candle_type, erase=erase, prepend=prepend)\n    return pairs_not_available",
            "def refresh_backtest_ohlcv_data(exchange: Exchange, pairs: List[str], timeframes: List[str], datadir: Path, trading_mode: str, timerange: Optional[TimeRange]=None, new_pairs_days: int=30, erase: bool=False, data_format: Optional[str]=None, prepend: bool=False) -> List[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Refresh stored ohlcv data for backtesting and hyperopt operations.\\n    Used by freqtrade download-data subcommand.\\n    :return: List of pairs that are not available.\\n    '\n    pairs_not_available = []\n    data_handler = get_datahandler(datadir, data_format)\n    candle_type = CandleType.get_default(trading_mode)\n    process = ''\n    for (idx, pair) in enumerate(pairs, start=1):\n        if pair not in exchange.markets:\n            pairs_not_available.append(pair)\n            logger.info(f'Skipping pair {pair}...')\n            continue\n        for timeframe in timeframes:\n            logger.debug(f'Downloading pair {pair}, {candle_type}, interval {timeframe}.')\n            process = f'{idx}/{len(pairs)}'\n            _download_pair_history(pair=pair, process=process, datadir=datadir, exchange=exchange, timerange=timerange, data_handler=data_handler, timeframe=str(timeframe), new_pairs_days=new_pairs_days, candle_type=candle_type, erase=erase, prepend=prepend)\n        if trading_mode == 'futures':\n            tf_mark = exchange.get_option('mark_ohlcv_timeframe')\n            fr_candle_type = CandleType.from_string(exchange.get_option('mark_ohlcv_price'))\n            for funding_candle_type in (CandleType.FUNDING_RATE, fr_candle_type):\n                _download_pair_history(pair=pair, process=process, datadir=datadir, exchange=exchange, timerange=timerange, data_handler=data_handler, timeframe=str(tf_mark), new_pairs_days=new_pairs_days, candle_type=funding_candle_type, erase=erase, prepend=prepend)\n    return pairs_not_available",
            "def refresh_backtest_ohlcv_data(exchange: Exchange, pairs: List[str], timeframes: List[str], datadir: Path, trading_mode: str, timerange: Optional[TimeRange]=None, new_pairs_days: int=30, erase: bool=False, data_format: Optional[str]=None, prepend: bool=False) -> List[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Refresh stored ohlcv data for backtesting and hyperopt operations.\\n    Used by freqtrade download-data subcommand.\\n    :return: List of pairs that are not available.\\n    '\n    pairs_not_available = []\n    data_handler = get_datahandler(datadir, data_format)\n    candle_type = CandleType.get_default(trading_mode)\n    process = ''\n    for (idx, pair) in enumerate(pairs, start=1):\n        if pair not in exchange.markets:\n            pairs_not_available.append(pair)\n            logger.info(f'Skipping pair {pair}...')\n            continue\n        for timeframe in timeframes:\n            logger.debug(f'Downloading pair {pair}, {candle_type}, interval {timeframe}.')\n            process = f'{idx}/{len(pairs)}'\n            _download_pair_history(pair=pair, process=process, datadir=datadir, exchange=exchange, timerange=timerange, data_handler=data_handler, timeframe=str(timeframe), new_pairs_days=new_pairs_days, candle_type=candle_type, erase=erase, prepend=prepend)\n        if trading_mode == 'futures':\n            tf_mark = exchange.get_option('mark_ohlcv_timeframe')\n            fr_candle_type = CandleType.from_string(exchange.get_option('mark_ohlcv_price'))\n            for funding_candle_type in (CandleType.FUNDING_RATE, fr_candle_type):\n                _download_pair_history(pair=pair, process=process, datadir=datadir, exchange=exchange, timerange=timerange, data_handler=data_handler, timeframe=str(tf_mark), new_pairs_days=new_pairs_days, candle_type=funding_candle_type, erase=erase, prepend=prepend)\n    return pairs_not_available",
            "def refresh_backtest_ohlcv_data(exchange: Exchange, pairs: List[str], timeframes: List[str], datadir: Path, trading_mode: str, timerange: Optional[TimeRange]=None, new_pairs_days: int=30, erase: bool=False, data_format: Optional[str]=None, prepend: bool=False) -> List[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Refresh stored ohlcv data for backtesting and hyperopt operations.\\n    Used by freqtrade download-data subcommand.\\n    :return: List of pairs that are not available.\\n    '\n    pairs_not_available = []\n    data_handler = get_datahandler(datadir, data_format)\n    candle_type = CandleType.get_default(trading_mode)\n    process = ''\n    for (idx, pair) in enumerate(pairs, start=1):\n        if pair not in exchange.markets:\n            pairs_not_available.append(pair)\n            logger.info(f'Skipping pair {pair}...')\n            continue\n        for timeframe in timeframes:\n            logger.debug(f'Downloading pair {pair}, {candle_type}, interval {timeframe}.')\n            process = f'{idx}/{len(pairs)}'\n            _download_pair_history(pair=pair, process=process, datadir=datadir, exchange=exchange, timerange=timerange, data_handler=data_handler, timeframe=str(timeframe), new_pairs_days=new_pairs_days, candle_type=candle_type, erase=erase, prepend=prepend)\n        if trading_mode == 'futures':\n            tf_mark = exchange.get_option('mark_ohlcv_timeframe')\n            fr_candle_type = CandleType.from_string(exchange.get_option('mark_ohlcv_price'))\n            for funding_candle_type in (CandleType.FUNDING_RATE, fr_candle_type):\n                _download_pair_history(pair=pair, process=process, datadir=datadir, exchange=exchange, timerange=timerange, data_handler=data_handler, timeframe=str(tf_mark), new_pairs_days=new_pairs_days, candle_type=funding_candle_type, erase=erase, prepend=prepend)\n    return pairs_not_available",
            "def refresh_backtest_ohlcv_data(exchange: Exchange, pairs: List[str], timeframes: List[str], datadir: Path, trading_mode: str, timerange: Optional[TimeRange]=None, new_pairs_days: int=30, erase: bool=False, data_format: Optional[str]=None, prepend: bool=False) -> List[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Refresh stored ohlcv data for backtesting and hyperopt operations.\\n    Used by freqtrade download-data subcommand.\\n    :return: List of pairs that are not available.\\n    '\n    pairs_not_available = []\n    data_handler = get_datahandler(datadir, data_format)\n    candle_type = CandleType.get_default(trading_mode)\n    process = ''\n    for (idx, pair) in enumerate(pairs, start=1):\n        if pair not in exchange.markets:\n            pairs_not_available.append(pair)\n            logger.info(f'Skipping pair {pair}...')\n            continue\n        for timeframe in timeframes:\n            logger.debug(f'Downloading pair {pair}, {candle_type}, interval {timeframe}.')\n            process = f'{idx}/{len(pairs)}'\n            _download_pair_history(pair=pair, process=process, datadir=datadir, exchange=exchange, timerange=timerange, data_handler=data_handler, timeframe=str(timeframe), new_pairs_days=new_pairs_days, candle_type=candle_type, erase=erase, prepend=prepend)\n        if trading_mode == 'futures':\n            tf_mark = exchange.get_option('mark_ohlcv_timeframe')\n            fr_candle_type = CandleType.from_string(exchange.get_option('mark_ohlcv_price'))\n            for funding_candle_type in (CandleType.FUNDING_RATE, fr_candle_type):\n                _download_pair_history(pair=pair, process=process, datadir=datadir, exchange=exchange, timerange=timerange, data_handler=data_handler, timeframe=str(tf_mark), new_pairs_days=new_pairs_days, candle_type=funding_candle_type, erase=erase, prepend=prepend)\n    return pairs_not_available"
        ]
    },
    {
        "func_name": "_download_trades_history",
        "original": "def _download_trades_history(exchange: Exchange, pair: str, *, new_pairs_days: int=30, timerange: Optional[TimeRange]=None, data_handler: IDataHandler) -> bool:\n    \"\"\"\n    Download trade history from the exchange.\n    Appends to previously downloaded trades data.\n    \"\"\"\n    try:\n        until = None\n        since = 0\n        if timerange:\n            if timerange.starttype == 'date':\n                since = timerange.startts * 1000\n            if timerange.stoptype == 'date':\n                until = timerange.stopts * 1000\n        trades = data_handler.trades_load(pair)\n        if not trades.empty and since > 0 and (since < trades.iloc[0]['timestamp']):\n            logger.info(f\"Start ({trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}) earlier than available data. Redownloading trades for {pair}...\")\n            trades = trades_list_to_df([])\n        from_id = trades.iloc[-1]['id'] if not trades.empty else None\n        if not trades.empty and since < trades.iloc[-1]['timestamp']:\n            since = trades.iloc[-1]['timestamp'] - 5 * 1000\n            logger.info(f'Using last trade date -5s - Downloading trades for {pair} since: {format_ms_time(since)}.')\n        if not since:\n            since = dt_ts(dt_now() - timedelta(days=new_pairs_days))\n        logger.debug('Current Start: %s', 'None' if trades.empty else f\"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.debug('Current End: %s', 'None' if trades.empty else f\"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.info(f'Current Amount of trades: {len(trades)}')\n        new_trades = exchange.get_historic_trades(pair=pair, since=since, until=until, from_id=from_id)\n        new_trades_df = trades_list_to_df(new_trades[1])\n        trades = concat([trades, new_trades_df], axis=0)\n        trades = trades_df_remove_duplicates(trades)\n        data_handler.trades_store(pair, data=trades)\n        logger.debug('New Start: %s', 'None' if trades.empty else f\"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.debug('New End: %s', 'None' if trades.empty else f\"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.info(f'New Amount of trades: {len(trades)}')\n        return True\n    except Exception:\n        logger.exception(f'Failed to download historic trades for pair: \"{pair}\". ')\n        return False",
        "mutated": [
            "def _download_trades_history(exchange: Exchange, pair: str, *, new_pairs_days: int=30, timerange: Optional[TimeRange]=None, data_handler: IDataHandler) -> bool:\n    if False:\n        i = 10\n    '\\n    Download trade history from the exchange.\\n    Appends to previously downloaded trades data.\\n    '\n    try:\n        until = None\n        since = 0\n        if timerange:\n            if timerange.starttype == 'date':\n                since = timerange.startts * 1000\n            if timerange.stoptype == 'date':\n                until = timerange.stopts * 1000\n        trades = data_handler.trades_load(pair)\n        if not trades.empty and since > 0 and (since < trades.iloc[0]['timestamp']):\n            logger.info(f\"Start ({trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}) earlier than available data. Redownloading trades for {pair}...\")\n            trades = trades_list_to_df([])\n        from_id = trades.iloc[-1]['id'] if not trades.empty else None\n        if not trades.empty and since < trades.iloc[-1]['timestamp']:\n            since = trades.iloc[-1]['timestamp'] - 5 * 1000\n            logger.info(f'Using last trade date -5s - Downloading trades for {pair} since: {format_ms_time(since)}.')\n        if not since:\n            since = dt_ts(dt_now() - timedelta(days=new_pairs_days))\n        logger.debug('Current Start: %s', 'None' if trades.empty else f\"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.debug('Current End: %s', 'None' if trades.empty else f\"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.info(f'Current Amount of trades: {len(trades)}')\n        new_trades = exchange.get_historic_trades(pair=pair, since=since, until=until, from_id=from_id)\n        new_trades_df = trades_list_to_df(new_trades[1])\n        trades = concat([trades, new_trades_df], axis=0)\n        trades = trades_df_remove_duplicates(trades)\n        data_handler.trades_store(pair, data=trades)\n        logger.debug('New Start: %s', 'None' if trades.empty else f\"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.debug('New End: %s', 'None' if trades.empty else f\"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.info(f'New Amount of trades: {len(trades)}')\n        return True\n    except Exception:\n        logger.exception(f'Failed to download historic trades for pair: \"{pair}\". ')\n        return False",
            "def _download_trades_history(exchange: Exchange, pair: str, *, new_pairs_days: int=30, timerange: Optional[TimeRange]=None, data_handler: IDataHandler) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Download trade history from the exchange.\\n    Appends to previously downloaded trades data.\\n    '\n    try:\n        until = None\n        since = 0\n        if timerange:\n            if timerange.starttype == 'date':\n                since = timerange.startts * 1000\n            if timerange.stoptype == 'date':\n                until = timerange.stopts * 1000\n        trades = data_handler.trades_load(pair)\n        if not trades.empty and since > 0 and (since < trades.iloc[0]['timestamp']):\n            logger.info(f\"Start ({trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}) earlier than available data. Redownloading trades for {pair}...\")\n            trades = trades_list_to_df([])\n        from_id = trades.iloc[-1]['id'] if not trades.empty else None\n        if not trades.empty and since < trades.iloc[-1]['timestamp']:\n            since = trades.iloc[-1]['timestamp'] - 5 * 1000\n            logger.info(f'Using last trade date -5s - Downloading trades for {pair} since: {format_ms_time(since)}.')\n        if not since:\n            since = dt_ts(dt_now() - timedelta(days=new_pairs_days))\n        logger.debug('Current Start: %s', 'None' if trades.empty else f\"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.debug('Current End: %s', 'None' if trades.empty else f\"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.info(f'Current Amount of trades: {len(trades)}')\n        new_trades = exchange.get_historic_trades(pair=pair, since=since, until=until, from_id=from_id)\n        new_trades_df = trades_list_to_df(new_trades[1])\n        trades = concat([trades, new_trades_df], axis=0)\n        trades = trades_df_remove_duplicates(trades)\n        data_handler.trades_store(pair, data=trades)\n        logger.debug('New Start: %s', 'None' if trades.empty else f\"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.debug('New End: %s', 'None' if trades.empty else f\"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.info(f'New Amount of trades: {len(trades)}')\n        return True\n    except Exception:\n        logger.exception(f'Failed to download historic trades for pair: \"{pair}\". ')\n        return False",
            "def _download_trades_history(exchange: Exchange, pair: str, *, new_pairs_days: int=30, timerange: Optional[TimeRange]=None, data_handler: IDataHandler) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Download trade history from the exchange.\\n    Appends to previously downloaded trades data.\\n    '\n    try:\n        until = None\n        since = 0\n        if timerange:\n            if timerange.starttype == 'date':\n                since = timerange.startts * 1000\n            if timerange.stoptype == 'date':\n                until = timerange.stopts * 1000\n        trades = data_handler.trades_load(pair)\n        if not trades.empty and since > 0 and (since < trades.iloc[0]['timestamp']):\n            logger.info(f\"Start ({trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}) earlier than available data. Redownloading trades for {pair}...\")\n            trades = trades_list_to_df([])\n        from_id = trades.iloc[-1]['id'] if not trades.empty else None\n        if not trades.empty and since < trades.iloc[-1]['timestamp']:\n            since = trades.iloc[-1]['timestamp'] - 5 * 1000\n            logger.info(f'Using last trade date -5s - Downloading trades for {pair} since: {format_ms_time(since)}.')\n        if not since:\n            since = dt_ts(dt_now() - timedelta(days=new_pairs_days))\n        logger.debug('Current Start: %s', 'None' if trades.empty else f\"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.debug('Current End: %s', 'None' if trades.empty else f\"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.info(f'Current Amount of trades: {len(trades)}')\n        new_trades = exchange.get_historic_trades(pair=pair, since=since, until=until, from_id=from_id)\n        new_trades_df = trades_list_to_df(new_trades[1])\n        trades = concat([trades, new_trades_df], axis=0)\n        trades = trades_df_remove_duplicates(trades)\n        data_handler.trades_store(pair, data=trades)\n        logger.debug('New Start: %s', 'None' if trades.empty else f\"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.debug('New End: %s', 'None' if trades.empty else f\"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.info(f'New Amount of trades: {len(trades)}')\n        return True\n    except Exception:\n        logger.exception(f'Failed to download historic trades for pair: \"{pair}\". ')\n        return False",
            "def _download_trades_history(exchange: Exchange, pair: str, *, new_pairs_days: int=30, timerange: Optional[TimeRange]=None, data_handler: IDataHandler) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Download trade history from the exchange.\\n    Appends to previously downloaded trades data.\\n    '\n    try:\n        until = None\n        since = 0\n        if timerange:\n            if timerange.starttype == 'date':\n                since = timerange.startts * 1000\n            if timerange.stoptype == 'date':\n                until = timerange.stopts * 1000\n        trades = data_handler.trades_load(pair)\n        if not trades.empty and since > 0 and (since < trades.iloc[0]['timestamp']):\n            logger.info(f\"Start ({trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}) earlier than available data. Redownloading trades for {pair}...\")\n            trades = trades_list_to_df([])\n        from_id = trades.iloc[-1]['id'] if not trades.empty else None\n        if not trades.empty and since < trades.iloc[-1]['timestamp']:\n            since = trades.iloc[-1]['timestamp'] - 5 * 1000\n            logger.info(f'Using last trade date -5s - Downloading trades for {pair} since: {format_ms_time(since)}.')\n        if not since:\n            since = dt_ts(dt_now() - timedelta(days=new_pairs_days))\n        logger.debug('Current Start: %s', 'None' if trades.empty else f\"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.debug('Current End: %s', 'None' if trades.empty else f\"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.info(f'Current Amount of trades: {len(trades)}')\n        new_trades = exchange.get_historic_trades(pair=pair, since=since, until=until, from_id=from_id)\n        new_trades_df = trades_list_to_df(new_trades[1])\n        trades = concat([trades, new_trades_df], axis=0)\n        trades = trades_df_remove_duplicates(trades)\n        data_handler.trades_store(pair, data=trades)\n        logger.debug('New Start: %s', 'None' if trades.empty else f\"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.debug('New End: %s', 'None' if trades.empty else f\"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.info(f'New Amount of trades: {len(trades)}')\n        return True\n    except Exception:\n        logger.exception(f'Failed to download historic trades for pair: \"{pair}\". ')\n        return False",
            "def _download_trades_history(exchange: Exchange, pair: str, *, new_pairs_days: int=30, timerange: Optional[TimeRange]=None, data_handler: IDataHandler) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Download trade history from the exchange.\\n    Appends to previously downloaded trades data.\\n    '\n    try:\n        until = None\n        since = 0\n        if timerange:\n            if timerange.starttype == 'date':\n                since = timerange.startts * 1000\n            if timerange.stoptype == 'date':\n                until = timerange.stopts * 1000\n        trades = data_handler.trades_load(pair)\n        if not trades.empty and since > 0 and (since < trades.iloc[0]['timestamp']):\n            logger.info(f\"Start ({trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}) earlier than available data. Redownloading trades for {pair}...\")\n            trades = trades_list_to_df([])\n        from_id = trades.iloc[-1]['id'] if not trades.empty else None\n        if not trades.empty and since < trades.iloc[-1]['timestamp']:\n            since = trades.iloc[-1]['timestamp'] - 5 * 1000\n            logger.info(f'Using last trade date -5s - Downloading trades for {pair} since: {format_ms_time(since)}.')\n        if not since:\n            since = dt_ts(dt_now() - timedelta(days=new_pairs_days))\n        logger.debug('Current Start: %s', 'None' if trades.empty else f\"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.debug('Current End: %s', 'None' if trades.empty else f\"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.info(f'Current Amount of trades: {len(trades)}')\n        new_trades = exchange.get_historic_trades(pair=pair, since=since, until=until, from_id=from_id)\n        new_trades_df = trades_list_to_df(new_trades[1])\n        trades = concat([trades, new_trades_df], axis=0)\n        trades = trades_df_remove_duplicates(trades)\n        data_handler.trades_store(pair, data=trades)\n        logger.debug('New Start: %s', 'None' if trades.empty else f\"{trades.iloc[0]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.debug('New End: %s', 'None' if trades.empty else f\"{trades.iloc[-1]['date']:{DATETIME_PRINT_FORMAT}}\")\n        logger.info(f'New Amount of trades: {len(trades)}')\n        return True\n    except Exception:\n        logger.exception(f'Failed to download historic trades for pair: \"{pair}\". ')\n        return False"
        ]
    },
    {
        "func_name": "refresh_backtest_trades_data",
        "original": "def refresh_backtest_trades_data(exchange: Exchange, pairs: List[str], datadir: Path, timerange: TimeRange, new_pairs_days: int=30, erase: bool=False, data_format: str='feather') -> List[str]:\n    \"\"\"\n    Refresh stored trades data for backtesting and hyperopt operations.\n    Used by freqtrade download-data subcommand.\n    :return: List of pairs that are not available.\n    \"\"\"\n    pairs_not_available = []\n    data_handler = get_datahandler(datadir, data_format=data_format)\n    for pair in pairs:\n        if pair not in exchange.markets:\n            pairs_not_available.append(pair)\n            logger.info(f'Skipping pair {pair}...')\n            continue\n        if erase:\n            if data_handler.trades_purge(pair):\n                logger.info(f'Deleting existing data for pair {pair}.')\n        logger.info(f'Downloading trades for pair {pair}.')\n        _download_trades_history(exchange=exchange, pair=pair, new_pairs_days=new_pairs_days, timerange=timerange, data_handler=data_handler)\n    return pairs_not_available",
        "mutated": [
            "def refresh_backtest_trades_data(exchange: Exchange, pairs: List[str], datadir: Path, timerange: TimeRange, new_pairs_days: int=30, erase: bool=False, data_format: str='feather') -> List[str]:\n    if False:\n        i = 10\n    '\\n    Refresh stored trades data for backtesting and hyperopt operations.\\n    Used by freqtrade download-data subcommand.\\n    :return: List of pairs that are not available.\\n    '\n    pairs_not_available = []\n    data_handler = get_datahandler(datadir, data_format=data_format)\n    for pair in pairs:\n        if pair not in exchange.markets:\n            pairs_not_available.append(pair)\n            logger.info(f'Skipping pair {pair}...')\n            continue\n        if erase:\n            if data_handler.trades_purge(pair):\n                logger.info(f'Deleting existing data for pair {pair}.')\n        logger.info(f'Downloading trades for pair {pair}.')\n        _download_trades_history(exchange=exchange, pair=pair, new_pairs_days=new_pairs_days, timerange=timerange, data_handler=data_handler)\n    return pairs_not_available",
            "def refresh_backtest_trades_data(exchange: Exchange, pairs: List[str], datadir: Path, timerange: TimeRange, new_pairs_days: int=30, erase: bool=False, data_format: str='feather') -> List[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Refresh stored trades data for backtesting and hyperopt operations.\\n    Used by freqtrade download-data subcommand.\\n    :return: List of pairs that are not available.\\n    '\n    pairs_not_available = []\n    data_handler = get_datahandler(datadir, data_format=data_format)\n    for pair in pairs:\n        if pair not in exchange.markets:\n            pairs_not_available.append(pair)\n            logger.info(f'Skipping pair {pair}...')\n            continue\n        if erase:\n            if data_handler.trades_purge(pair):\n                logger.info(f'Deleting existing data for pair {pair}.')\n        logger.info(f'Downloading trades for pair {pair}.')\n        _download_trades_history(exchange=exchange, pair=pair, new_pairs_days=new_pairs_days, timerange=timerange, data_handler=data_handler)\n    return pairs_not_available",
            "def refresh_backtest_trades_data(exchange: Exchange, pairs: List[str], datadir: Path, timerange: TimeRange, new_pairs_days: int=30, erase: bool=False, data_format: str='feather') -> List[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Refresh stored trades data for backtesting and hyperopt operations.\\n    Used by freqtrade download-data subcommand.\\n    :return: List of pairs that are not available.\\n    '\n    pairs_not_available = []\n    data_handler = get_datahandler(datadir, data_format=data_format)\n    for pair in pairs:\n        if pair not in exchange.markets:\n            pairs_not_available.append(pair)\n            logger.info(f'Skipping pair {pair}...')\n            continue\n        if erase:\n            if data_handler.trades_purge(pair):\n                logger.info(f'Deleting existing data for pair {pair}.')\n        logger.info(f'Downloading trades for pair {pair}.')\n        _download_trades_history(exchange=exchange, pair=pair, new_pairs_days=new_pairs_days, timerange=timerange, data_handler=data_handler)\n    return pairs_not_available",
            "def refresh_backtest_trades_data(exchange: Exchange, pairs: List[str], datadir: Path, timerange: TimeRange, new_pairs_days: int=30, erase: bool=False, data_format: str='feather') -> List[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Refresh stored trades data for backtesting and hyperopt operations.\\n    Used by freqtrade download-data subcommand.\\n    :return: List of pairs that are not available.\\n    '\n    pairs_not_available = []\n    data_handler = get_datahandler(datadir, data_format=data_format)\n    for pair in pairs:\n        if pair not in exchange.markets:\n            pairs_not_available.append(pair)\n            logger.info(f'Skipping pair {pair}...')\n            continue\n        if erase:\n            if data_handler.trades_purge(pair):\n                logger.info(f'Deleting existing data for pair {pair}.')\n        logger.info(f'Downloading trades for pair {pair}.')\n        _download_trades_history(exchange=exchange, pair=pair, new_pairs_days=new_pairs_days, timerange=timerange, data_handler=data_handler)\n    return pairs_not_available",
            "def refresh_backtest_trades_data(exchange: Exchange, pairs: List[str], datadir: Path, timerange: TimeRange, new_pairs_days: int=30, erase: bool=False, data_format: str='feather') -> List[str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Refresh stored trades data for backtesting and hyperopt operations.\\n    Used by freqtrade download-data subcommand.\\n    :return: List of pairs that are not available.\\n    '\n    pairs_not_available = []\n    data_handler = get_datahandler(datadir, data_format=data_format)\n    for pair in pairs:\n        if pair not in exchange.markets:\n            pairs_not_available.append(pair)\n            logger.info(f'Skipping pair {pair}...')\n            continue\n        if erase:\n            if data_handler.trades_purge(pair):\n                logger.info(f'Deleting existing data for pair {pair}.')\n        logger.info(f'Downloading trades for pair {pair}.')\n        _download_trades_history(exchange=exchange, pair=pair, new_pairs_days=new_pairs_days, timerange=timerange, data_handler=data_handler)\n    return pairs_not_available"
        ]
    },
    {
        "func_name": "get_timerange",
        "original": "def get_timerange(data: Dict[str, DataFrame]) -> Tuple[datetime, datetime]:\n    \"\"\"\n    Get the maximum common timerange for the given backtest data.\n\n    :param data: dictionary with preprocessed backtesting data\n    :return: tuple containing min_date, max_date\n    \"\"\"\n    timeranges = [(frame['date'].min().to_pydatetime(), frame['date'].max().to_pydatetime()) for frame in data.values()]\n    return (min(timeranges, key=operator.itemgetter(0))[0], max(timeranges, key=operator.itemgetter(1))[1])",
        "mutated": [
            "def get_timerange(data: Dict[str, DataFrame]) -> Tuple[datetime, datetime]:\n    if False:\n        i = 10\n    '\\n    Get the maximum common timerange for the given backtest data.\\n\\n    :param data: dictionary with preprocessed backtesting data\\n    :return: tuple containing min_date, max_date\\n    '\n    timeranges = [(frame['date'].min().to_pydatetime(), frame['date'].max().to_pydatetime()) for frame in data.values()]\n    return (min(timeranges, key=operator.itemgetter(0))[0], max(timeranges, key=operator.itemgetter(1))[1])",
            "def get_timerange(data: Dict[str, DataFrame]) -> Tuple[datetime, datetime]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Get the maximum common timerange for the given backtest data.\\n\\n    :param data: dictionary with preprocessed backtesting data\\n    :return: tuple containing min_date, max_date\\n    '\n    timeranges = [(frame['date'].min().to_pydatetime(), frame['date'].max().to_pydatetime()) for frame in data.values()]\n    return (min(timeranges, key=operator.itemgetter(0))[0], max(timeranges, key=operator.itemgetter(1))[1])",
            "def get_timerange(data: Dict[str, DataFrame]) -> Tuple[datetime, datetime]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Get the maximum common timerange for the given backtest data.\\n\\n    :param data: dictionary with preprocessed backtesting data\\n    :return: tuple containing min_date, max_date\\n    '\n    timeranges = [(frame['date'].min().to_pydatetime(), frame['date'].max().to_pydatetime()) for frame in data.values()]\n    return (min(timeranges, key=operator.itemgetter(0))[0], max(timeranges, key=operator.itemgetter(1))[1])",
            "def get_timerange(data: Dict[str, DataFrame]) -> Tuple[datetime, datetime]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Get the maximum common timerange for the given backtest data.\\n\\n    :param data: dictionary with preprocessed backtesting data\\n    :return: tuple containing min_date, max_date\\n    '\n    timeranges = [(frame['date'].min().to_pydatetime(), frame['date'].max().to_pydatetime()) for frame in data.values()]\n    return (min(timeranges, key=operator.itemgetter(0))[0], max(timeranges, key=operator.itemgetter(1))[1])",
            "def get_timerange(data: Dict[str, DataFrame]) -> Tuple[datetime, datetime]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Get the maximum common timerange for the given backtest data.\\n\\n    :param data: dictionary with preprocessed backtesting data\\n    :return: tuple containing min_date, max_date\\n    '\n    timeranges = [(frame['date'].min().to_pydatetime(), frame['date'].max().to_pydatetime()) for frame in data.values()]\n    return (min(timeranges, key=operator.itemgetter(0))[0], max(timeranges, key=operator.itemgetter(1))[1])"
        ]
    },
    {
        "func_name": "validate_backtest_data",
        "original": "def validate_backtest_data(data: DataFrame, pair: str, min_date: datetime, max_date: datetime, timeframe_min: int) -> bool:\n    \"\"\"\n    Validates preprocessed backtesting data for missing values and shows warnings about it that.\n\n    :param data: preprocessed backtesting data (as DataFrame)\n    :param pair: pair used for log output.\n    :param min_date: start-date of the data\n    :param max_date: end-date of the data\n    :param timeframe_min: Timeframe in minutes\n    \"\"\"\n    expected_frames = int((max_date - min_date).total_seconds() // 60 // timeframe_min)\n    found_missing = False\n    dflen = len(data)\n    if dflen < expected_frames:\n        found_missing = True\n        logger.warning(\"%s has missing frames: expected %s, got %s, that's %s missing values\", pair, expected_frames, dflen, expected_frames - dflen)\n    return found_missing",
        "mutated": [
            "def validate_backtest_data(data: DataFrame, pair: str, min_date: datetime, max_date: datetime, timeframe_min: int) -> bool:\n    if False:\n        i = 10\n    '\\n    Validates preprocessed backtesting data for missing values and shows warnings about it that.\\n\\n    :param data: preprocessed backtesting data (as DataFrame)\\n    :param pair: pair used for log output.\\n    :param min_date: start-date of the data\\n    :param max_date: end-date of the data\\n    :param timeframe_min: Timeframe in minutes\\n    '\n    expected_frames = int((max_date - min_date).total_seconds() // 60 // timeframe_min)\n    found_missing = False\n    dflen = len(data)\n    if dflen < expected_frames:\n        found_missing = True\n        logger.warning(\"%s has missing frames: expected %s, got %s, that's %s missing values\", pair, expected_frames, dflen, expected_frames - dflen)\n    return found_missing",
            "def validate_backtest_data(data: DataFrame, pair: str, min_date: datetime, max_date: datetime, timeframe_min: int) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Validates preprocessed backtesting data for missing values and shows warnings about it that.\\n\\n    :param data: preprocessed backtesting data (as DataFrame)\\n    :param pair: pair used for log output.\\n    :param min_date: start-date of the data\\n    :param max_date: end-date of the data\\n    :param timeframe_min: Timeframe in minutes\\n    '\n    expected_frames = int((max_date - min_date).total_seconds() // 60 // timeframe_min)\n    found_missing = False\n    dflen = len(data)\n    if dflen < expected_frames:\n        found_missing = True\n        logger.warning(\"%s has missing frames: expected %s, got %s, that's %s missing values\", pair, expected_frames, dflen, expected_frames - dflen)\n    return found_missing",
            "def validate_backtest_data(data: DataFrame, pair: str, min_date: datetime, max_date: datetime, timeframe_min: int) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Validates preprocessed backtesting data for missing values and shows warnings about it that.\\n\\n    :param data: preprocessed backtesting data (as DataFrame)\\n    :param pair: pair used for log output.\\n    :param min_date: start-date of the data\\n    :param max_date: end-date of the data\\n    :param timeframe_min: Timeframe in minutes\\n    '\n    expected_frames = int((max_date - min_date).total_seconds() // 60 // timeframe_min)\n    found_missing = False\n    dflen = len(data)\n    if dflen < expected_frames:\n        found_missing = True\n        logger.warning(\"%s has missing frames: expected %s, got %s, that's %s missing values\", pair, expected_frames, dflen, expected_frames - dflen)\n    return found_missing",
            "def validate_backtest_data(data: DataFrame, pair: str, min_date: datetime, max_date: datetime, timeframe_min: int) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Validates preprocessed backtesting data for missing values and shows warnings about it that.\\n\\n    :param data: preprocessed backtesting data (as DataFrame)\\n    :param pair: pair used for log output.\\n    :param min_date: start-date of the data\\n    :param max_date: end-date of the data\\n    :param timeframe_min: Timeframe in minutes\\n    '\n    expected_frames = int((max_date - min_date).total_seconds() // 60 // timeframe_min)\n    found_missing = False\n    dflen = len(data)\n    if dflen < expected_frames:\n        found_missing = True\n        logger.warning(\"%s has missing frames: expected %s, got %s, that's %s missing values\", pair, expected_frames, dflen, expected_frames - dflen)\n    return found_missing",
            "def validate_backtest_data(data: DataFrame, pair: str, min_date: datetime, max_date: datetime, timeframe_min: int) -> bool:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Validates preprocessed backtesting data for missing values and shows warnings about it that.\\n\\n    :param data: preprocessed backtesting data (as DataFrame)\\n    :param pair: pair used for log output.\\n    :param min_date: start-date of the data\\n    :param max_date: end-date of the data\\n    :param timeframe_min: Timeframe in minutes\\n    '\n    expected_frames = int((max_date - min_date).total_seconds() // 60 // timeframe_min)\n    found_missing = False\n    dflen = len(data)\n    if dflen < expected_frames:\n        found_missing = True\n        logger.warning(\"%s has missing frames: expected %s, got %s, that's %s missing values\", pair, expected_frames, dflen, expected_frames - dflen)\n    return found_missing"
        ]
    },
    {
        "func_name": "download_data_main",
        "original": "def download_data_main(config: Config) -> None:\n    timerange = TimeRange()\n    if 'days' in config:\n        time_since = (datetime.now() - timedelta(days=config['days'])).strftime('%Y%m%d')\n        timerange = TimeRange.parse_timerange(f'{time_since}-')\n    if 'timerange' in config:\n        timerange = timerange.parse_timerange(config['timerange'])\n    config['stake_currency'] = ''\n    pairs_not_available: List[str] = []\n    from freqtrade.resolvers.exchange_resolver import ExchangeResolver\n    exchange = ExchangeResolver.load_exchange(config, validate=False)\n    available_pairs = [p for p in exchange.get_markets(tradable_only=True, active_only=not config.get('include_inactive')).keys()]\n    expanded_pairs = dynamic_expand_pairlist(config, available_pairs)\n    if 'timeframes' not in config:\n        config['timeframes'] = DL_DATA_TIMEFRAMES\n    if not config['exchange'].get('skip_pair_validation', False):\n        exchange.validate_pairs(expanded_pairs)\n    logger.info(f\"About to download pairs: {expanded_pairs}, intervals: {config['timeframes']} to {config['datadir']}\")\n    for timeframe in config['timeframes']:\n        exchange.validate_timeframes(timeframe)\n    try:\n        if config.get('download_trades'):\n            if config.get('trading_mode') == 'futures':\n                raise OperationalException('Trade download not supported for futures.')\n            pairs_not_available = refresh_backtest_trades_data(exchange, pairs=expanded_pairs, datadir=config['datadir'], timerange=timerange, new_pairs_days=config['new_pairs_days'], erase=bool(config.get('erase')), data_format=config['dataformat_trades'])\n            convert_trades_to_ohlcv(pairs=expanded_pairs, timeframes=config['timeframes'], datadir=config['datadir'], timerange=timerange, erase=bool(config.get('erase')), data_format_ohlcv=config['dataformat_ohlcv'], data_format_trades=config['dataformat_trades'])\n        else:\n            if not exchange.get_option('ohlcv_has_history', True):\n                raise OperationalException(f'Historic klines not available for {exchange.name}. Please use `--dl-trades` instead for this exchange (will unfortunately take a long time).')\n            migrate_binance_futures_data(config)\n            pairs_not_available = refresh_backtest_ohlcv_data(exchange, pairs=expanded_pairs, timeframes=config['timeframes'], datadir=config['datadir'], timerange=timerange, new_pairs_days=config['new_pairs_days'], erase=bool(config.get('erase')), data_format=config['dataformat_ohlcv'], trading_mode=config.get('trading_mode', 'spot'), prepend=config.get('prepend_data', False))\n    finally:\n        if pairs_not_available:\n            logger.info(f\"Pairs [{','.join(pairs_not_available)}] not available on exchange {exchange.name}.\")",
        "mutated": [
            "def download_data_main(config: Config) -> None:\n    if False:\n        i = 10\n    timerange = TimeRange()\n    if 'days' in config:\n        time_since = (datetime.now() - timedelta(days=config['days'])).strftime('%Y%m%d')\n        timerange = TimeRange.parse_timerange(f'{time_since}-')\n    if 'timerange' in config:\n        timerange = timerange.parse_timerange(config['timerange'])\n    config['stake_currency'] = ''\n    pairs_not_available: List[str] = []\n    from freqtrade.resolvers.exchange_resolver import ExchangeResolver\n    exchange = ExchangeResolver.load_exchange(config, validate=False)\n    available_pairs = [p for p in exchange.get_markets(tradable_only=True, active_only=not config.get('include_inactive')).keys()]\n    expanded_pairs = dynamic_expand_pairlist(config, available_pairs)\n    if 'timeframes' not in config:\n        config['timeframes'] = DL_DATA_TIMEFRAMES\n    if not config['exchange'].get('skip_pair_validation', False):\n        exchange.validate_pairs(expanded_pairs)\n    logger.info(f\"About to download pairs: {expanded_pairs}, intervals: {config['timeframes']} to {config['datadir']}\")\n    for timeframe in config['timeframes']:\n        exchange.validate_timeframes(timeframe)\n    try:\n        if config.get('download_trades'):\n            if config.get('trading_mode') == 'futures':\n                raise OperationalException('Trade download not supported for futures.')\n            pairs_not_available = refresh_backtest_trades_data(exchange, pairs=expanded_pairs, datadir=config['datadir'], timerange=timerange, new_pairs_days=config['new_pairs_days'], erase=bool(config.get('erase')), data_format=config['dataformat_trades'])\n            convert_trades_to_ohlcv(pairs=expanded_pairs, timeframes=config['timeframes'], datadir=config['datadir'], timerange=timerange, erase=bool(config.get('erase')), data_format_ohlcv=config['dataformat_ohlcv'], data_format_trades=config['dataformat_trades'])\n        else:\n            if not exchange.get_option('ohlcv_has_history', True):\n                raise OperationalException(f'Historic klines not available for {exchange.name}. Please use `--dl-trades` instead for this exchange (will unfortunately take a long time).')\n            migrate_binance_futures_data(config)\n            pairs_not_available = refresh_backtest_ohlcv_data(exchange, pairs=expanded_pairs, timeframes=config['timeframes'], datadir=config['datadir'], timerange=timerange, new_pairs_days=config['new_pairs_days'], erase=bool(config.get('erase')), data_format=config['dataformat_ohlcv'], trading_mode=config.get('trading_mode', 'spot'), prepend=config.get('prepend_data', False))\n    finally:\n        if pairs_not_available:\n            logger.info(f\"Pairs [{','.join(pairs_not_available)}] not available on exchange {exchange.name}.\")",
            "def download_data_main(config: Config) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    timerange = TimeRange()\n    if 'days' in config:\n        time_since = (datetime.now() - timedelta(days=config['days'])).strftime('%Y%m%d')\n        timerange = TimeRange.parse_timerange(f'{time_since}-')\n    if 'timerange' in config:\n        timerange = timerange.parse_timerange(config['timerange'])\n    config['stake_currency'] = ''\n    pairs_not_available: List[str] = []\n    from freqtrade.resolvers.exchange_resolver import ExchangeResolver\n    exchange = ExchangeResolver.load_exchange(config, validate=False)\n    available_pairs = [p for p in exchange.get_markets(tradable_only=True, active_only=not config.get('include_inactive')).keys()]\n    expanded_pairs = dynamic_expand_pairlist(config, available_pairs)\n    if 'timeframes' not in config:\n        config['timeframes'] = DL_DATA_TIMEFRAMES\n    if not config['exchange'].get('skip_pair_validation', False):\n        exchange.validate_pairs(expanded_pairs)\n    logger.info(f\"About to download pairs: {expanded_pairs}, intervals: {config['timeframes']} to {config['datadir']}\")\n    for timeframe in config['timeframes']:\n        exchange.validate_timeframes(timeframe)\n    try:\n        if config.get('download_trades'):\n            if config.get('trading_mode') == 'futures':\n                raise OperationalException('Trade download not supported for futures.')\n            pairs_not_available = refresh_backtest_trades_data(exchange, pairs=expanded_pairs, datadir=config['datadir'], timerange=timerange, new_pairs_days=config['new_pairs_days'], erase=bool(config.get('erase')), data_format=config['dataformat_trades'])\n            convert_trades_to_ohlcv(pairs=expanded_pairs, timeframes=config['timeframes'], datadir=config['datadir'], timerange=timerange, erase=bool(config.get('erase')), data_format_ohlcv=config['dataformat_ohlcv'], data_format_trades=config['dataformat_trades'])\n        else:\n            if not exchange.get_option('ohlcv_has_history', True):\n                raise OperationalException(f'Historic klines not available for {exchange.name}. Please use `--dl-trades` instead for this exchange (will unfortunately take a long time).')\n            migrate_binance_futures_data(config)\n            pairs_not_available = refresh_backtest_ohlcv_data(exchange, pairs=expanded_pairs, timeframes=config['timeframes'], datadir=config['datadir'], timerange=timerange, new_pairs_days=config['new_pairs_days'], erase=bool(config.get('erase')), data_format=config['dataformat_ohlcv'], trading_mode=config.get('trading_mode', 'spot'), prepend=config.get('prepend_data', False))\n    finally:\n        if pairs_not_available:\n            logger.info(f\"Pairs [{','.join(pairs_not_available)}] not available on exchange {exchange.name}.\")",
            "def download_data_main(config: Config) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    timerange = TimeRange()\n    if 'days' in config:\n        time_since = (datetime.now() - timedelta(days=config['days'])).strftime('%Y%m%d')\n        timerange = TimeRange.parse_timerange(f'{time_since}-')\n    if 'timerange' in config:\n        timerange = timerange.parse_timerange(config['timerange'])\n    config['stake_currency'] = ''\n    pairs_not_available: List[str] = []\n    from freqtrade.resolvers.exchange_resolver import ExchangeResolver\n    exchange = ExchangeResolver.load_exchange(config, validate=False)\n    available_pairs = [p for p in exchange.get_markets(tradable_only=True, active_only=not config.get('include_inactive')).keys()]\n    expanded_pairs = dynamic_expand_pairlist(config, available_pairs)\n    if 'timeframes' not in config:\n        config['timeframes'] = DL_DATA_TIMEFRAMES\n    if not config['exchange'].get('skip_pair_validation', False):\n        exchange.validate_pairs(expanded_pairs)\n    logger.info(f\"About to download pairs: {expanded_pairs}, intervals: {config['timeframes']} to {config['datadir']}\")\n    for timeframe in config['timeframes']:\n        exchange.validate_timeframes(timeframe)\n    try:\n        if config.get('download_trades'):\n            if config.get('trading_mode') == 'futures':\n                raise OperationalException('Trade download not supported for futures.')\n            pairs_not_available = refresh_backtest_trades_data(exchange, pairs=expanded_pairs, datadir=config['datadir'], timerange=timerange, new_pairs_days=config['new_pairs_days'], erase=bool(config.get('erase')), data_format=config['dataformat_trades'])\n            convert_trades_to_ohlcv(pairs=expanded_pairs, timeframes=config['timeframes'], datadir=config['datadir'], timerange=timerange, erase=bool(config.get('erase')), data_format_ohlcv=config['dataformat_ohlcv'], data_format_trades=config['dataformat_trades'])\n        else:\n            if not exchange.get_option('ohlcv_has_history', True):\n                raise OperationalException(f'Historic klines not available for {exchange.name}. Please use `--dl-trades` instead for this exchange (will unfortunately take a long time).')\n            migrate_binance_futures_data(config)\n            pairs_not_available = refresh_backtest_ohlcv_data(exchange, pairs=expanded_pairs, timeframes=config['timeframes'], datadir=config['datadir'], timerange=timerange, new_pairs_days=config['new_pairs_days'], erase=bool(config.get('erase')), data_format=config['dataformat_ohlcv'], trading_mode=config.get('trading_mode', 'spot'), prepend=config.get('prepend_data', False))\n    finally:\n        if pairs_not_available:\n            logger.info(f\"Pairs [{','.join(pairs_not_available)}] not available on exchange {exchange.name}.\")",
            "def download_data_main(config: Config) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    timerange = TimeRange()\n    if 'days' in config:\n        time_since = (datetime.now() - timedelta(days=config['days'])).strftime('%Y%m%d')\n        timerange = TimeRange.parse_timerange(f'{time_since}-')\n    if 'timerange' in config:\n        timerange = timerange.parse_timerange(config['timerange'])\n    config['stake_currency'] = ''\n    pairs_not_available: List[str] = []\n    from freqtrade.resolvers.exchange_resolver import ExchangeResolver\n    exchange = ExchangeResolver.load_exchange(config, validate=False)\n    available_pairs = [p for p in exchange.get_markets(tradable_only=True, active_only=not config.get('include_inactive')).keys()]\n    expanded_pairs = dynamic_expand_pairlist(config, available_pairs)\n    if 'timeframes' not in config:\n        config['timeframes'] = DL_DATA_TIMEFRAMES\n    if not config['exchange'].get('skip_pair_validation', False):\n        exchange.validate_pairs(expanded_pairs)\n    logger.info(f\"About to download pairs: {expanded_pairs}, intervals: {config['timeframes']} to {config['datadir']}\")\n    for timeframe in config['timeframes']:\n        exchange.validate_timeframes(timeframe)\n    try:\n        if config.get('download_trades'):\n            if config.get('trading_mode') == 'futures':\n                raise OperationalException('Trade download not supported for futures.')\n            pairs_not_available = refresh_backtest_trades_data(exchange, pairs=expanded_pairs, datadir=config['datadir'], timerange=timerange, new_pairs_days=config['new_pairs_days'], erase=bool(config.get('erase')), data_format=config['dataformat_trades'])\n            convert_trades_to_ohlcv(pairs=expanded_pairs, timeframes=config['timeframes'], datadir=config['datadir'], timerange=timerange, erase=bool(config.get('erase')), data_format_ohlcv=config['dataformat_ohlcv'], data_format_trades=config['dataformat_trades'])\n        else:\n            if not exchange.get_option('ohlcv_has_history', True):\n                raise OperationalException(f'Historic klines not available for {exchange.name}. Please use `--dl-trades` instead for this exchange (will unfortunately take a long time).')\n            migrate_binance_futures_data(config)\n            pairs_not_available = refresh_backtest_ohlcv_data(exchange, pairs=expanded_pairs, timeframes=config['timeframes'], datadir=config['datadir'], timerange=timerange, new_pairs_days=config['new_pairs_days'], erase=bool(config.get('erase')), data_format=config['dataformat_ohlcv'], trading_mode=config.get('trading_mode', 'spot'), prepend=config.get('prepend_data', False))\n    finally:\n        if pairs_not_available:\n            logger.info(f\"Pairs [{','.join(pairs_not_available)}] not available on exchange {exchange.name}.\")",
            "def download_data_main(config: Config) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    timerange = TimeRange()\n    if 'days' in config:\n        time_since = (datetime.now() - timedelta(days=config['days'])).strftime('%Y%m%d')\n        timerange = TimeRange.parse_timerange(f'{time_since}-')\n    if 'timerange' in config:\n        timerange = timerange.parse_timerange(config['timerange'])\n    config['stake_currency'] = ''\n    pairs_not_available: List[str] = []\n    from freqtrade.resolvers.exchange_resolver import ExchangeResolver\n    exchange = ExchangeResolver.load_exchange(config, validate=False)\n    available_pairs = [p for p in exchange.get_markets(tradable_only=True, active_only=not config.get('include_inactive')).keys()]\n    expanded_pairs = dynamic_expand_pairlist(config, available_pairs)\n    if 'timeframes' not in config:\n        config['timeframes'] = DL_DATA_TIMEFRAMES\n    if not config['exchange'].get('skip_pair_validation', False):\n        exchange.validate_pairs(expanded_pairs)\n    logger.info(f\"About to download pairs: {expanded_pairs}, intervals: {config['timeframes']} to {config['datadir']}\")\n    for timeframe in config['timeframes']:\n        exchange.validate_timeframes(timeframe)\n    try:\n        if config.get('download_trades'):\n            if config.get('trading_mode') == 'futures':\n                raise OperationalException('Trade download not supported for futures.')\n            pairs_not_available = refresh_backtest_trades_data(exchange, pairs=expanded_pairs, datadir=config['datadir'], timerange=timerange, new_pairs_days=config['new_pairs_days'], erase=bool(config.get('erase')), data_format=config['dataformat_trades'])\n            convert_trades_to_ohlcv(pairs=expanded_pairs, timeframes=config['timeframes'], datadir=config['datadir'], timerange=timerange, erase=bool(config.get('erase')), data_format_ohlcv=config['dataformat_ohlcv'], data_format_trades=config['dataformat_trades'])\n        else:\n            if not exchange.get_option('ohlcv_has_history', True):\n                raise OperationalException(f'Historic klines not available for {exchange.name}. Please use `--dl-trades` instead for this exchange (will unfortunately take a long time).')\n            migrate_binance_futures_data(config)\n            pairs_not_available = refresh_backtest_ohlcv_data(exchange, pairs=expanded_pairs, timeframes=config['timeframes'], datadir=config['datadir'], timerange=timerange, new_pairs_days=config['new_pairs_days'], erase=bool(config.get('erase')), data_format=config['dataformat_ohlcv'], trading_mode=config.get('trading_mode', 'spot'), prepend=config.get('prepend_data', False))\n    finally:\n        if pairs_not_available:\n            logger.info(f\"Pairs [{','.join(pairs_not_available)}] not available on exchange {exchange.name}.\")"
        ]
    }
]