from future.utils import native_str
from pycuda.tools import context_dependent_memoize
from neon.backends.cuda_templates import _ew_types
from neon.backends.util.source_module import SourceModule
'\nCUDA kernels for lookup table layers. Kernels are only given for bprop, since\nfprop is just a take operation. There is a deterministic kernel and\nnon-deterministic kernel (using atomics) provided. Sorting kernels are also\nprovided to help with the deterministic version.\n'

@context_dependent_memoize
def _get_lut_bprop_kernel(dtype, deterministic=False):
    if False:
        for i in range(10):
            print('nop')
    '\n    Builds the bprop kernel for lookup table layers based on templated code.\n    If the deterministic version is requested, an index buffer must be passed\n    as an argument. This index buffer re-orders items in the input tensor\n    so that word_ids are sorted. This is required since we need to be sure that\n    each thread only updates weights for one word id.\n\n    Arguments:\n        dtype (np.dtype): The data which the kernel will operate on.\n        deterministic (boolean): Builds the deterministic kernel when this is\n            set to True.\n    '
    if not deterministic:
        code = '\n__global__ void lut_bprop(\n    int* inputs, %(type)s* dW, %(type)s* errors, const int nin,\n    const int embedding_dim, const int vocab_size, const int pad_idx)\n{\n    const int tid  = threadIdx.x;\n    const int bid  = blockIdx.x;\n\n    int word_id = inputs[bid];\n    int error_row = bid * embedding_dim;\n    int output_row = word_id * embedding_dim;\n\n    if(word_id != pad_idx)\n    {\n        for(int i = tid; i < embedding_dim; i += blockDim.x)\n        {\n            atomicAdd(&dW[output_row + i], errors[error_row + i]);\n        }\n    }\n}\n'
        code = code % {'type': _ew_types[dtype]['type']}
        module = SourceModule(code, options=['--use_fast_math'])
        kernel = module.get_function('lut_bprop')
        kernel.prepare('PPPIIIi')
    else:
        code = '\n__global__ void lut_bprop(\n    int* inputs, int* index_buffer, %(type)s* dW, %(type)s* errors,\n    const int nin, const int embedding_dim, const int vocab_size,\n    const int pad_idx)\n{\n    const int tid  = threadIdx.x;\n    const int bid  = blockIdx.x;\n\n    int index_position = bid;\n    int index = index_buffer[index_position];\n    int word_id = inputs[index];\n\n    if((bid == 0 || word_id != inputs[index_buffer[bid - 1]]) && word_id != pad_idx)\n    {\n        int output_row = word_id * embedding_dim;\n\n        do {\n            int error_row = index * embedding_dim;\n\n            for(int i = tid; i < embedding_dim; i += blockDim.x)\n            {\n                dW[output_row + i] += errors[error_row + i];\n            }\n\n            index_position++;\n            if(index_position == gridDim.x)\n            {\n                break;\n            }\n            index = index_buffer[index_position];\n        } while(inputs[index] == word_id);\n    }\n}\n'
        code = code % {'type': _ew_types[dtype]['type']}
        module = SourceModule(code, options=['--use_fast_math'])
        kernel = module.get_function('lut_bprop')
        kernel.prepare('PPPPIIIi')
    kernel.name = 'lut_bprop'
    return kernel

def _get_sorting_kernel(kernel_id, block_size):
    if False:
        print('Hello World!')
    "\n    Builds kernels used for sorting inputs. There are several kernels here\n    corresponding to the steps in the algorithm. The algorithm works by\n    determining the sorted position for each input item. This is done with\n    a bucket sort algorithm, where each word_id is a bucket. The first step\n    determines the size of each bucket (number of occurences of each word_id).\n    Next, a prefix some is computed over the list of bucket sizes to find\n    where each bucket will be placed in the output buffer. Finally, each thread\n    places it's index into the correct sorted position based on the bucket\n    start index (computed from the prefix sum) and that thread's offset into\n    the bucket (which is taken from the output of the atomic add done in the\n    first step.)\n\n    Arguments:\n        kernel_id (Integer): Which step to build the kernel for [0, 4]\n        block_size (Integer): Number of threads per block for the prefix sum\n            kernels.\n    "
    code = '\n#define THREADS %(threads)s\n#define STORE_BLOCKSUM %(store_blocksum)s\n__global__ void sort_inputs0(\n        int* inputs, int* index_buffer, int* offset_buffer, int* word_counts, const int vocab_size,\n        const int input_length)\n{\n    const int tid = threadIdx.x + (blockDim.x * blockIdx.x);\n    int word_id;\n\n    if(tid < input_length)\n    {\n        word_id = inputs[tid];\n        offset_buffer[tid] = atomicAdd(&word_counts[word_id], 1);\n    }\n}\n\n__device__ void scan(int* buffer, int* blocksum, int global_length)\n{\n    const int tid = (threadIdx.x << 1) + 1;\n    const int gid = ((threadIdx.x + (blockIdx.x * blockDim.x)) << 1) + 1;\n\n    __shared__ int local_counts[THREADS * 2];\n    local_counts[tid] = buffer[gid];\n    local_counts[tid - 1] = buffer[gid - 1];\n\n    #pragma unroll\n    for(int skip = 1; skip <= THREADS; skip <<= 1)\n    {\n        int mask = (skip << 1) - 1;\n        if((tid & mask) == mask)\n        {\n            local_counts[tid] += local_counts[tid - skip];\n        }\n\n        __syncthreads();\n    }\n\n    if(tid == (THREADS * 2 - 1))\n    {\n#if STORE_BLOCKSUM\n        blocksum[blockIdx.x] = local_counts[tid];\n#endif\n        local_counts[tid] = 0;\n    }\n\n    #pragma unroll\n    for(int skip = THREADS; skip > 0; skip >>= 1)\n    {\n        int mask = (skip << 1) - 1;\n        if((tid & mask) == mask)\n        {\n            int temp = local_counts[tid - skip];\n            local_counts[tid - skip] = local_counts[tid];\n            local_counts[tid] += temp;\n        }\n\n        __syncthreads();\n    }\n\n    if(gid < global_length)\n    {\n        buffer[gid] = local_counts[tid];\n        buffer[gid - 1] = local_counts[tid - 1];\n    }\n}\n\n__global__ void sort_inputs1(\n        int* inputs, int* index_buffer, int* offset_buffer, int* word_counts, const int vocab_size,\n        const int input_length)\n{\n    scan(word_counts, word_counts + vocab_size, vocab_size);\n}\n\n__global__ void sort_inputs2(\n        int* inputs, int* index_buffer, int* offset_buffer, int* word_counts, const int vocab_size,\n        const int input_length)\n{\n    scan(word_counts + vocab_size, 0, blockDim.x);\n}\n\n__global__ void sort_inputs3(\n        int* inputs, int* index_buffer, int* offset_buffer, int* word_counts, const int vocab_size,\n        const int input_length)\n{\n    const int gid = (threadIdx.x + (blockIdx.x * blockDim.x)) << 1;\n\n    if(gid < vocab_size)\n    {\n        word_counts[gid] += word_counts[vocab_size + blockIdx.x];\n        word_counts[gid + 1] += word_counts[vocab_size + blockIdx.x];\n    }\n}\n\n__global__ void sort_inputs4(\n        int* inputs, int* index_buffer, int* offset_buffer, int* word_counts, const int vocab_size,\n        const int input_length)\n{\n    const int tid = threadIdx.x + (blockDim.x * blockIdx.x);\n    int word_id;\n\n    if(tid < input_length)\n    {\n        word_id = inputs[tid];\n        int sorted_position = word_counts[word_id] + offset_buffer[tid];\n        index_buffer[sorted_position] = tid;\n    }\n}\n'
    code = code % {'threads': block_size, 'store_blocksum': 1 if kernel_id == 1 else 0}
    module = SourceModule(code, options=['--use_fast_math'])
    function_name = 'sort_inputs' + native_str(kernel_id)
    kernel = module.get_function(function_name)
    kernel.prepare('PPPPII')
    kernel.name = 'sort_inputs'
    return kernel