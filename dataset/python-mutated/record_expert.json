[
    {
        "func_name": "generate_expert_traj",
        "original": "def generate_expert_traj(model, save_path=None, env=None, n_timesteps=0, n_episodes=100, image_folder='recorded_images'):\n    \"\"\"\n    Train expert controller (if needed) and record expert trajectories.\n\n    .. note::\n\n        only Box and Discrete spaces are supported for now.\n\n    :param model: (RL model or callable) The expert model, if it needs to be trained,\n        then you need to pass ``n_timesteps > 0``.\n    :param save_path: (str) Path without the extension where the expert dataset will be saved\n        (ex: 'expert_cartpole' -> creates 'expert_cartpole.npz').\n        If not specified, it will not save, and just return the generated expert trajectories.\n        This parameter must be specified for image-based environments.\n    :param env: (gym.Env) The environment, if not defined then it tries to use the model\n        environment.\n    :param n_timesteps: (int) Number of training timesteps\n    :param n_episodes: (int) Number of trajectories (episodes) to record\n    :param image_folder: (str) When using images, folder that will be used to record images.\n    :return: (dict) the generated expert trajectories.\n    \"\"\"\n    if env is None and isinstance(model, BaseRLModel):\n        env = model.get_env()\n    assert env is not None, 'You must set the env in the model or pass it to the function.'\n    is_vec_env = False\n    if isinstance(env, VecEnv) and (not isinstance(env, _UnvecWrapper)):\n        is_vec_env = True\n        if env.num_envs > 1:\n            warnings.warn('You are using multiple envs, only the data from the first one will be recorded.')\n    assert isinstance(env.observation_space, spaces.Box) or isinstance(env.observation_space, spaces.Discrete), 'Observation space type not supported'\n    assert isinstance(env.action_space, spaces.Box) or isinstance(env.action_space, spaces.Discrete), 'Action space type not supported'\n    obs_space = env.observation_space\n    record_images = len(obs_space.shape) == 3 and obs_space.shape[-1] in [1, 3, 4] and (obs_space.dtype == np.uint8)\n    if record_images and save_path is None:\n        warnings.warn('Observations are images but no save path was specified, so will save in numpy archive; this can lead to higher memory usage.')\n        record_images = False\n    if not record_images and len(obs_space.shape) == 3 and (obs_space.dtype == np.uint8):\n        warnings.warn('The observations looks like images (shape = {}) but the number of channel > 4, so it will be saved in the numpy archive which can lead to high memory usage'.format(obs_space.shape))\n    image_ext = 'jpg'\n    if record_images:\n        if isinstance(env, VecFrameStack) and env.n_stack == 4:\n            image_ext = 'png'\n        folder_path = os.path.dirname(save_path)\n        image_folder = os.path.join(folder_path, image_folder)\n        os.makedirs(image_folder, exist_ok=True)\n        print('=' * 10)\n        print('Images will be recorded to {}/'.format(image_folder))\n        print('Image shape: {}'.format(obs_space.shape))\n        print('=' * 10)\n    if n_timesteps > 0 and isinstance(model, BaseRLModel):\n        model.learn(n_timesteps)\n    actions = []\n    observations = []\n    rewards = []\n    episode_returns = np.zeros((n_episodes,))\n    episode_starts = []\n    ep_idx = 0\n    obs = env.reset()\n    episode_starts.append(True)\n    reward_sum = 0.0\n    idx = 0\n    (state, mask) = (None, None)\n    if is_vec_env:\n        mask = [True for _ in range(env.num_envs)]\n    while ep_idx < n_episodes:\n        obs_ = obs[0] if is_vec_env else obs\n        if record_images:\n            image_path = os.path.join(image_folder, '{}.{}'.format(idx, image_ext))\n            if obs_.shape[-1] == 3:\n                obs_ = cv2.cvtColor(obs_, cv2.COLOR_RGB2BGR)\n            cv2.imwrite(image_path, obs_)\n            observations.append(image_path)\n        else:\n            observations.append(obs_)\n        if isinstance(model, BaseRLModel):\n            (action, state) = model.predict(obs, state=state, mask=mask)\n        else:\n            action = model(obs)\n        (obs, reward, done, _) = env.step(action)\n        if is_vec_env:\n            mask = [done[0] for _ in range(env.num_envs)]\n            action = np.array([action[0]])\n            reward = np.array([reward[0]])\n            done = np.array([done[0]])\n        actions.append(action)\n        rewards.append(reward)\n        episode_starts.append(done)\n        reward_sum += reward\n        idx += 1\n        if done:\n            if not is_vec_env:\n                obs = env.reset()\n                state = None\n            episode_returns[ep_idx] = reward_sum\n            reward_sum = 0.0\n            ep_idx += 1\n    if isinstance(env.observation_space, spaces.Box) and (not record_images):\n        observations = np.concatenate(observations).reshape((-1,) + env.observation_space.shape)\n    elif isinstance(env.observation_space, spaces.Discrete):\n        observations = np.array(observations).reshape((-1, 1))\n    elif record_images:\n        observations = np.array(observations)\n    if isinstance(env.action_space, spaces.Box):\n        actions = np.concatenate(actions).reshape((-1,) + env.action_space.shape)\n    elif isinstance(env.action_space, spaces.Discrete):\n        actions = np.array(actions).reshape((-1, 1))\n    rewards = np.array(rewards)\n    episode_starts = np.array(episode_starts[:-1])\n    assert len(observations) == len(actions)\n    numpy_dict = {'actions': actions, 'obs': observations, 'rewards': rewards, 'episode_returns': episode_returns, 'episode_starts': episode_starts}\n    for (key, val) in numpy_dict.items():\n        print(key, val.shape)\n    if save_path is not None:\n        np.savez(save_path, **numpy_dict)\n    env.close()\n    return numpy_dict",
        "mutated": [
            "def generate_expert_traj(model, save_path=None, env=None, n_timesteps=0, n_episodes=100, image_folder='recorded_images'):\n    if False:\n        i = 10\n    \"\\n    Train expert controller (if needed) and record expert trajectories.\\n\\n    .. note::\\n\\n        only Box and Discrete spaces are supported for now.\\n\\n    :param model: (RL model or callable) The expert model, if it needs to be trained,\\n        then you need to pass ``n_timesteps > 0``.\\n    :param save_path: (str) Path without the extension where the expert dataset will be saved\\n        (ex: 'expert_cartpole' -> creates 'expert_cartpole.npz').\\n        If not specified, it will not save, and just return the generated expert trajectories.\\n        This parameter must be specified for image-based environments.\\n    :param env: (gym.Env) The environment, if not defined then it tries to use the model\\n        environment.\\n    :param n_timesteps: (int) Number of training timesteps\\n    :param n_episodes: (int) Number of trajectories (episodes) to record\\n    :param image_folder: (str) When using images, folder that will be used to record images.\\n    :return: (dict) the generated expert trajectories.\\n    \"\n    if env is None and isinstance(model, BaseRLModel):\n        env = model.get_env()\n    assert env is not None, 'You must set the env in the model or pass it to the function.'\n    is_vec_env = False\n    if isinstance(env, VecEnv) and (not isinstance(env, _UnvecWrapper)):\n        is_vec_env = True\n        if env.num_envs > 1:\n            warnings.warn('You are using multiple envs, only the data from the first one will be recorded.')\n    assert isinstance(env.observation_space, spaces.Box) or isinstance(env.observation_space, spaces.Discrete), 'Observation space type not supported'\n    assert isinstance(env.action_space, spaces.Box) or isinstance(env.action_space, spaces.Discrete), 'Action space type not supported'\n    obs_space = env.observation_space\n    record_images = len(obs_space.shape) == 3 and obs_space.shape[-1] in [1, 3, 4] and (obs_space.dtype == np.uint8)\n    if record_images and save_path is None:\n        warnings.warn('Observations are images but no save path was specified, so will save in numpy archive; this can lead to higher memory usage.')\n        record_images = False\n    if not record_images and len(obs_space.shape) == 3 and (obs_space.dtype == np.uint8):\n        warnings.warn('The observations looks like images (shape = {}) but the number of channel > 4, so it will be saved in the numpy archive which can lead to high memory usage'.format(obs_space.shape))\n    image_ext = 'jpg'\n    if record_images:\n        if isinstance(env, VecFrameStack) and env.n_stack == 4:\n            image_ext = 'png'\n        folder_path = os.path.dirname(save_path)\n        image_folder = os.path.join(folder_path, image_folder)\n        os.makedirs(image_folder, exist_ok=True)\n        print('=' * 10)\n        print('Images will be recorded to {}/'.format(image_folder))\n        print('Image shape: {}'.format(obs_space.shape))\n        print('=' * 10)\n    if n_timesteps > 0 and isinstance(model, BaseRLModel):\n        model.learn(n_timesteps)\n    actions = []\n    observations = []\n    rewards = []\n    episode_returns = np.zeros((n_episodes,))\n    episode_starts = []\n    ep_idx = 0\n    obs = env.reset()\n    episode_starts.append(True)\n    reward_sum = 0.0\n    idx = 0\n    (state, mask) = (None, None)\n    if is_vec_env:\n        mask = [True for _ in range(env.num_envs)]\n    while ep_idx < n_episodes:\n        obs_ = obs[0] if is_vec_env else obs\n        if record_images:\n            image_path = os.path.join(image_folder, '{}.{}'.format(idx, image_ext))\n            if obs_.shape[-1] == 3:\n                obs_ = cv2.cvtColor(obs_, cv2.COLOR_RGB2BGR)\n            cv2.imwrite(image_path, obs_)\n            observations.append(image_path)\n        else:\n            observations.append(obs_)\n        if isinstance(model, BaseRLModel):\n            (action, state) = model.predict(obs, state=state, mask=mask)\n        else:\n            action = model(obs)\n        (obs, reward, done, _) = env.step(action)\n        if is_vec_env:\n            mask = [done[0] for _ in range(env.num_envs)]\n            action = np.array([action[0]])\n            reward = np.array([reward[0]])\n            done = np.array([done[0]])\n        actions.append(action)\n        rewards.append(reward)\n        episode_starts.append(done)\n        reward_sum += reward\n        idx += 1\n        if done:\n            if not is_vec_env:\n                obs = env.reset()\n                state = None\n            episode_returns[ep_idx] = reward_sum\n            reward_sum = 0.0\n            ep_idx += 1\n    if isinstance(env.observation_space, spaces.Box) and (not record_images):\n        observations = np.concatenate(observations).reshape((-1,) + env.observation_space.shape)\n    elif isinstance(env.observation_space, spaces.Discrete):\n        observations = np.array(observations).reshape((-1, 1))\n    elif record_images:\n        observations = np.array(observations)\n    if isinstance(env.action_space, spaces.Box):\n        actions = np.concatenate(actions).reshape((-1,) + env.action_space.shape)\n    elif isinstance(env.action_space, spaces.Discrete):\n        actions = np.array(actions).reshape((-1, 1))\n    rewards = np.array(rewards)\n    episode_starts = np.array(episode_starts[:-1])\n    assert len(observations) == len(actions)\n    numpy_dict = {'actions': actions, 'obs': observations, 'rewards': rewards, 'episode_returns': episode_returns, 'episode_starts': episode_starts}\n    for (key, val) in numpy_dict.items():\n        print(key, val.shape)\n    if save_path is not None:\n        np.savez(save_path, **numpy_dict)\n    env.close()\n    return numpy_dict",
            "def generate_expert_traj(model, save_path=None, env=None, n_timesteps=0, n_episodes=100, image_folder='recorded_images'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Train expert controller (if needed) and record expert trajectories.\\n\\n    .. note::\\n\\n        only Box and Discrete spaces are supported for now.\\n\\n    :param model: (RL model or callable) The expert model, if it needs to be trained,\\n        then you need to pass ``n_timesteps > 0``.\\n    :param save_path: (str) Path without the extension where the expert dataset will be saved\\n        (ex: 'expert_cartpole' -> creates 'expert_cartpole.npz').\\n        If not specified, it will not save, and just return the generated expert trajectories.\\n        This parameter must be specified for image-based environments.\\n    :param env: (gym.Env) The environment, if not defined then it tries to use the model\\n        environment.\\n    :param n_timesteps: (int) Number of training timesteps\\n    :param n_episodes: (int) Number of trajectories (episodes) to record\\n    :param image_folder: (str) When using images, folder that will be used to record images.\\n    :return: (dict) the generated expert trajectories.\\n    \"\n    if env is None and isinstance(model, BaseRLModel):\n        env = model.get_env()\n    assert env is not None, 'You must set the env in the model or pass it to the function.'\n    is_vec_env = False\n    if isinstance(env, VecEnv) and (not isinstance(env, _UnvecWrapper)):\n        is_vec_env = True\n        if env.num_envs > 1:\n            warnings.warn('You are using multiple envs, only the data from the first one will be recorded.')\n    assert isinstance(env.observation_space, spaces.Box) or isinstance(env.observation_space, spaces.Discrete), 'Observation space type not supported'\n    assert isinstance(env.action_space, spaces.Box) or isinstance(env.action_space, spaces.Discrete), 'Action space type not supported'\n    obs_space = env.observation_space\n    record_images = len(obs_space.shape) == 3 and obs_space.shape[-1] in [1, 3, 4] and (obs_space.dtype == np.uint8)\n    if record_images and save_path is None:\n        warnings.warn('Observations are images but no save path was specified, so will save in numpy archive; this can lead to higher memory usage.')\n        record_images = False\n    if not record_images and len(obs_space.shape) == 3 and (obs_space.dtype == np.uint8):\n        warnings.warn('The observations looks like images (shape = {}) but the number of channel > 4, so it will be saved in the numpy archive which can lead to high memory usage'.format(obs_space.shape))\n    image_ext = 'jpg'\n    if record_images:\n        if isinstance(env, VecFrameStack) and env.n_stack == 4:\n            image_ext = 'png'\n        folder_path = os.path.dirname(save_path)\n        image_folder = os.path.join(folder_path, image_folder)\n        os.makedirs(image_folder, exist_ok=True)\n        print('=' * 10)\n        print('Images will be recorded to {}/'.format(image_folder))\n        print('Image shape: {}'.format(obs_space.shape))\n        print('=' * 10)\n    if n_timesteps > 0 and isinstance(model, BaseRLModel):\n        model.learn(n_timesteps)\n    actions = []\n    observations = []\n    rewards = []\n    episode_returns = np.zeros((n_episodes,))\n    episode_starts = []\n    ep_idx = 0\n    obs = env.reset()\n    episode_starts.append(True)\n    reward_sum = 0.0\n    idx = 0\n    (state, mask) = (None, None)\n    if is_vec_env:\n        mask = [True for _ in range(env.num_envs)]\n    while ep_idx < n_episodes:\n        obs_ = obs[0] if is_vec_env else obs\n        if record_images:\n            image_path = os.path.join(image_folder, '{}.{}'.format(idx, image_ext))\n            if obs_.shape[-1] == 3:\n                obs_ = cv2.cvtColor(obs_, cv2.COLOR_RGB2BGR)\n            cv2.imwrite(image_path, obs_)\n            observations.append(image_path)\n        else:\n            observations.append(obs_)\n        if isinstance(model, BaseRLModel):\n            (action, state) = model.predict(obs, state=state, mask=mask)\n        else:\n            action = model(obs)\n        (obs, reward, done, _) = env.step(action)\n        if is_vec_env:\n            mask = [done[0] for _ in range(env.num_envs)]\n            action = np.array([action[0]])\n            reward = np.array([reward[0]])\n            done = np.array([done[0]])\n        actions.append(action)\n        rewards.append(reward)\n        episode_starts.append(done)\n        reward_sum += reward\n        idx += 1\n        if done:\n            if not is_vec_env:\n                obs = env.reset()\n                state = None\n            episode_returns[ep_idx] = reward_sum\n            reward_sum = 0.0\n            ep_idx += 1\n    if isinstance(env.observation_space, spaces.Box) and (not record_images):\n        observations = np.concatenate(observations).reshape((-1,) + env.observation_space.shape)\n    elif isinstance(env.observation_space, spaces.Discrete):\n        observations = np.array(observations).reshape((-1, 1))\n    elif record_images:\n        observations = np.array(observations)\n    if isinstance(env.action_space, spaces.Box):\n        actions = np.concatenate(actions).reshape((-1,) + env.action_space.shape)\n    elif isinstance(env.action_space, spaces.Discrete):\n        actions = np.array(actions).reshape((-1, 1))\n    rewards = np.array(rewards)\n    episode_starts = np.array(episode_starts[:-1])\n    assert len(observations) == len(actions)\n    numpy_dict = {'actions': actions, 'obs': observations, 'rewards': rewards, 'episode_returns': episode_returns, 'episode_starts': episode_starts}\n    for (key, val) in numpy_dict.items():\n        print(key, val.shape)\n    if save_path is not None:\n        np.savez(save_path, **numpy_dict)\n    env.close()\n    return numpy_dict",
            "def generate_expert_traj(model, save_path=None, env=None, n_timesteps=0, n_episodes=100, image_folder='recorded_images'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Train expert controller (if needed) and record expert trajectories.\\n\\n    .. note::\\n\\n        only Box and Discrete spaces are supported for now.\\n\\n    :param model: (RL model or callable) The expert model, if it needs to be trained,\\n        then you need to pass ``n_timesteps > 0``.\\n    :param save_path: (str) Path without the extension where the expert dataset will be saved\\n        (ex: 'expert_cartpole' -> creates 'expert_cartpole.npz').\\n        If not specified, it will not save, and just return the generated expert trajectories.\\n        This parameter must be specified for image-based environments.\\n    :param env: (gym.Env) The environment, if not defined then it tries to use the model\\n        environment.\\n    :param n_timesteps: (int) Number of training timesteps\\n    :param n_episodes: (int) Number of trajectories (episodes) to record\\n    :param image_folder: (str) When using images, folder that will be used to record images.\\n    :return: (dict) the generated expert trajectories.\\n    \"\n    if env is None and isinstance(model, BaseRLModel):\n        env = model.get_env()\n    assert env is not None, 'You must set the env in the model or pass it to the function.'\n    is_vec_env = False\n    if isinstance(env, VecEnv) and (not isinstance(env, _UnvecWrapper)):\n        is_vec_env = True\n        if env.num_envs > 1:\n            warnings.warn('You are using multiple envs, only the data from the first one will be recorded.')\n    assert isinstance(env.observation_space, spaces.Box) or isinstance(env.observation_space, spaces.Discrete), 'Observation space type not supported'\n    assert isinstance(env.action_space, spaces.Box) or isinstance(env.action_space, spaces.Discrete), 'Action space type not supported'\n    obs_space = env.observation_space\n    record_images = len(obs_space.shape) == 3 and obs_space.shape[-1] in [1, 3, 4] and (obs_space.dtype == np.uint8)\n    if record_images and save_path is None:\n        warnings.warn('Observations are images but no save path was specified, so will save in numpy archive; this can lead to higher memory usage.')\n        record_images = False\n    if not record_images and len(obs_space.shape) == 3 and (obs_space.dtype == np.uint8):\n        warnings.warn('The observations looks like images (shape = {}) but the number of channel > 4, so it will be saved in the numpy archive which can lead to high memory usage'.format(obs_space.shape))\n    image_ext = 'jpg'\n    if record_images:\n        if isinstance(env, VecFrameStack) and env.n_stack == 4:\n            image_ext = 'png'\n        folder_path = os.path.dirname(save_path)\n        image_folder = os.path.join(folder_path, image_folder)\n        os.makedirs(image_folder, exist_ok=True)\n        print('=' * 10)\n        print('Images will be recorded to {}/'.format(image_folder))\n        print('Image shape: {}'.format(obs_space.shape))\n        print('=' * 10)\n    if n_timesteps > 0 and isinstance(model, BaseRLModel):\n        model.learn(n_timesteps)\n    actions = []\n    observations = []\n    rewards = []\n    episode_returns = np.zeros((n_episodes,))\n    episode_starts = []\n    ep_idx = 0\n    obs = env.reset()\n    episode_starts.append(True)\n    reward_sum = 0.0\n    idx = 0\n    (state, mask) = (None, None)\n    if is_vec_env:\n        mask = [True for _ in range(env.num_envs)]\n    while ep_idx < n_episodes:\n        obs_ = obs[0] if is_vec_env else obs\n        if record_images:\n            image_path = os.path.join(image_folder, '{}.{}'.format(idx, image_ext))\n            if obs_.shape[-1] == 3:\n                obs_ = cv2.cvtColor(obs_, cv2.COLOR_RGB2BGR)\n            cv2.imwrite(image_path, obs_)\n            observations.append(image_path)\n        else:\n            observations.append(obs_)\n        if isinstance(model, BaseRLModel):\n            (action, state) = model.predict(obs, state=state, mask=mask)\n        else:\n            action = model(obs)\n        (obs, reward, done, _) = env.step(action)\n        if is_vec_env:\n            mask = [done[0] for _ in range(env.num_envs)]\n            action = np.array([action[0]])\n            reward = np.array([reward[0]])\n            done = np.array([done[0]])\n        actions.append(action)\n        rewards.append(reward)\n        episode_starts.append(done)\n        reward_sum += reward\n        idx += 1\n        if done:\n            if not is_vec_env:\n                obs = env.reset()\n                state = None\n            episode_returns[ep_idx] = reward_sum\n            reward_sum = 0.0\n            ep_idx += 1\n    if isinstance(env.observation_space, spaces.Box) and (not record_images):\n        observations = np.concatenate(observations).reshape((-1,) + env.observation_space.shape)\n    elif isinstance(env.observation_space, spaces.Discrete):\n        observations = np.array(observations).reshape((-1, 1))\n    elif record_images:\n        observations = np.array(observations)\n    if isinstance(env.action_space, spaces.Box):\n        actions = np.concatenate(actions).reshape((-1,) + env.action_space.shape)\n    elif isinstance(env.action_space, spaces.Discrete):\n        actions = np.array(actions).reshape((-1, 1))\n    rewards = np.array(rewards)\n    episode_starts = np.array(episode_starts[:-1])\n    assert len(observations) == len(actions)\n    numpy_dict = {'actions': actions, 'obs': observations, 'rewards': rewards, 'episode_returns': episode_returns, 'episode_starts': episode_starts}\n    for (key, val) in numpy_dict.items():\n        print(key, val.shape)\n    if save_path is not None:\n        np.savez(save_path, **numpy_dict)\n    env.close()\n    return numpy_dict",
            "def generate_expert_traj(model, save_path=None, env=None, n_timesteps=0, n_episodes=100, image_folder='recorded_images'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Train expert controller (if needed) and record expert trajectories.\\n\\n    .. note::\\n\\n        only Box and Discrete spaces are supported for now.\\n\\n    :param model: (RL model or callable) The expert model, if it needs to be trained,\\n        then you need to pass ``n_timesteps > 0``.\\n    :param save_path: (str) Path without the extension where the expert dataset will be saved\\n        (ex: 'expert_cartpole' -> creates 'expert_cartpole.npz').\\n        If not specified, it will not save, and just return the generated expert trajectories.\\n        This parameter must be specified for image-based environments.\\n    :param env: (gym.Env) The environment, if not defined then it tries to use the model\\n        environment.\\n    :param n_timesteps: (int) Number of training timesteps\\n    :param n_episodes: (int) Number of trajectories (episodes) to record\\n    :param image_folder: (str) When using images, folder that will be used to record images.\\n    :return: (dict) the generated expert trajectories.\\n    \"\n    if env is None and isinstance(model, BaseRLModel):\n        env = model.get_env()\n    assert env is not None, 'You must set the env in the model or pass it to the function.'\n    is_vec_env = False\n    if isinstance(env, VecEnv) and (not isinstance(env, _UnvecWrapper)):\n        is_vec_env = True\n        if env.num_envs > 1:\n            warnings.warn('You are using multiple envs, only the data from the first one will be recorded.')\n    assert isinstance(env.observation_space, spaces.Box) or isinstance(env.observation_space, spaces.Discrete), 'Observation space type not supported'\n    assert isinstance(env.action_space, spaces.Box) or isinstance(env.action_space, spaces.Discrete), 'Action space type not supported'\n    obs_space = env.observation_space\n    record_images = len(obs_space.shape) == 3 and obs_space.shape[-1] in [1, 3, 4] and (obs_space.dtype == np.uint8)\n    if record_images and save_path is None:\n        warnings.warn('Observations are images but no save path was specified, so will save in numpy archive; this can lead to higher memory usage.')\n        record_images = False\n    if not record_images and len(obs_space.shape) == 3 and (obs_space.dtype == np.uint8):\n        warnings.warn('The observations looks like images (shape = {}) but the number of channel > 4, so it will be saved in the numpy archive which can lead to high memory usage'.format(obs_space.shape))\n    image_ext = 'jpg'\n    if record_images:\n        if isinstance(env, VecFrameStack) and env.n_stack == 4:\n            image_ext = 'png'\n        folder_path = os.path.dirname(save_path)\n        image_folder = os.path.join(folder_path, image_folder)\n        os.makedirs(image_folder, exist_ok=True)\n        print('=' * 10)\n        print('Images will be recorded to {}/'.format(image_folder))\n        print('Image shape: {}'.format(obs_space.shape))\n        print('=' * 10)\n    if n_timesteps > 0 and isinstance(model, BaseRLModel):\n        model.learn(n_timesteps)\n    actions = []\n    observations = []\n    rewards = []\n    episode_returns = np.zeros((n_episodes,))\n    episode_starts = []\n    ep_idx = 0\n    obs = env.reset()\n    episode_starts.append(True)\n    reward_sum = 0.0\n    idx = 0\n    (state, mask) = (None, None)\n    if is_vec_env:\n        mask = [True for _ in range(env.num_envs)]\n    while ep_idx < n_episodes:\n        obs_ = obs[0] if is_vec_env else obs\n        if record_images:\n            image_path = os.path.join(image_folder, '{}.{}'.format(idx, image_ext))\n            if obs_.shape[-1] == 3:\n                obs_ = cv2.cvtColor(obs_, cv2.COLOR_RGB2BGR)\n            cv2.imwrite(image_path, obs_)\n            observations.append(image_path)\n        else:\n            observations.append(obs_)\n        if isinstance(model, BaseRLModel):\n            (action, state) = model.predict(obs, state=state, mask=mask)\n        else:\n            action = model(obs)\n        (obs, reward, done, _) = env.step(action)\n        if is_vec_env:\n            mask = [done[0] for _ in range(env.num_envs)]\n            action = np.array([action[0]])\n            reward = np.array([reward[0]])\n            done = np.array([done[0]])\n        actions.append(action)\n        rewards.append(reward)\n        episode_starts.append(done)\n        reward_sum += reward\n        idx += 1\n        if done:\n            if not is_vec_env:\n                obs = env.reset()\n                state = None\n            episode_returns[ep_idx] = reward_sum\n            reward_sum = 0.0\n            ep_idx += 1\n    if isinstance(env.observation_space, spaces.Box) and (not record_images):\n        observations = np.concatenate(observations).reshape((-1,) + env.observation_space.shape)\n    elif isinstance(env.observation_space, spaces.Discrete):\n        observations = np.array(observations).reshape((-1, 1))\n    elif record_images:\n        observations = np.array(observations)\n    if isinstance(env.action_space, spaces.Box):\n        actions = np.concatenate(actions).reshape((-1,) + env.action_space.shape)\n    elif isinstance(env.action_space, spaces.Discrete):\n        actions = np.array(actions).reshape((-1, 1))\n    rewards = np.array(rewards)\n    episode_starts = np.array(episode_starts[:-1])\n    assert len(observations) == len(actions)\n    numpy_dict = {'actions': actions, 'obs': observations, 'rewards': rewards, 'episode_returns': episode_returns, 'episode_starts': episode_starts}\n    for (key, val) in numpy_dict.items():\n        print(key, val.shape)\n    if save_path is not None:\n        np.savez(save_path, **numpy_dict)\n    env.close()\n    return numpy_dict",
            "def generate_expert_traj(model, save_path=None, env=None, n_timesteps=0, n_episodes=100, image_folder='recorded_images'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Train expert controller (if needed) and record expert trajectories.\\n\\n    .. note::\\n\\n        only Box and Discrete spaces are supported for now.\\n\\n    :param model: (RL model or callable) The expert model, if it needs to be trained,\\n        then you need to pass ``n_timesteps > 0``.\\n    :param save_path: (str) Path without the extension where the expert dataset will be saved\\n        (ex: 'expert_cartpole' -> creates 'expert_cartpole.npz').\\n        If not specified, it will not save, and just return the generated expert trajectories.\\n        This parameter must be specified for image-based environments.\\n    :param env: (gym.Env) The environment, if not defined then it tries to use the model\\n        environment.\\n    :param n_timesteps: (int) Number of training timesteps\\n    :param n_episodes: (int) Number of trajectories (episodes) to record\\n    :param image_folder: (str) When using images, folder that will be used to record images.\\n    :return: (dict) the generated expert trajectories.\\n    \"\n    if env is None and isinstance(model, BaseRLModel):\n        env = model.get_env()\n    assert env is not None, 'You must set the env in the model or pass it to the function.'\n    is_vec_env = False\n    if isinstance(env, VecEnv) and (not isinstance(env, _UnvecWrapper)):\n        is_vec_env = True\n        if env.num_envs > 1:\n            warnings.warn('You are using multiple envs, only the data from the first one will be recorded.')\n    assert isinstance(env.observation_space, spaces.Box) or isinstance(env.observation_space, spaces.Discrete), 'Observation space type not supported'\n    assert isinstance(env.action_space, spaces.Box) or isinstance(env.action_space, spaces.Discrete), 'Action space type not supported'\n    obs_space = env.observation_space\n    record_images = len(obs_space.shape) == 3 and obs_space.shape[-1] in [1, 3, 4] and (obs_space.dtype == np.uint8)\n    if record_images and save_path is None:\n        warnings.warn('Observations are images but no save path was specified, so will save in numpy archive; this can lead to higher memory usage.')\n        record_images = False\n    if not record_images and len(obs_space.shape) == 3 and (obs_space.dtype == np.uint8):\n        warnings.warn('The observations looks like images (shape = {}) but the number of channel > 4, so it will be saved in the numpy archive which can lead to high memory usage'.format(obs_space.shape))\n    image_ext = 'jpg'\n    if record_images:\n        if isinstance(env, VecFrameStack) and env.n_stack == 4:\n            image_ext = 'png'\n        folder_path = os.path.dirname(save_path)\n        image_folder = os.path.join(folder_path, image_folder)\n        os.makedirs(image_folder, exist_ok=True)\n        print('=' * 10)\n        print('Images will be recorded to {}/'.format(image_folder))\n        print('Image shape: {}'.format(obs_space.shape))\n        print('=' * 10)\n    if n_timesteps > 0 and isinstance(model, BaseRLModel):\n        model.learn(n_timesteps)\n    actions = []\n    observations = []\n    rewards = []\n    episode_returns = np.zeros((n_episodes,))\n    episode_starts = []\n    ep_idx = 0\n    obs = env.reset()\n    episode_starts.append(True)\n    reward_sum = 0.0\n    idx = 0\n    (state, mask) = (None, None)\n    if is_vec_env:\n        mask = [True for _ in range(env.num_envs)]\n    while ep_idx < n_episodes:\n        obs_ = obs[0] if is_vec_env else obs\n        if record_images:\n            image_path = os.path.join(image_folder, '{}.{}'.format(idx, image_ext))\n            if obs_.shape[-1] == 3:\n                obs_ = cv2.cvtColor(obs_, cv2.COLOR_RGB2BGR)\n            cv2.imwrite(image_path, obs_)\n            observations.append(image_path)\n        else:\n            observations.append(obs_)\n        if isinstance(model, BaseRLModel):\n            (action, state) = model.predict(obs, state=state, mask=mask)\n        else:\n            action = model(obs)\n        (obs, reward, done, _) = env.step(action)\n        if is_vec_env:\n            mask = [done[0] for _ in range(env.num_envs)]\n            action = np.array([action[0]])\n            reward = np.array([reward[0]])\n            done = np.array([done[0]])\n        actions.append(action)\n        rewards.append(reward)\n        episode_starts.append(done)\n        reward_sum += reward\n        idx += 1\n        if done:\n            if not is_vec_env:\n                obs = env.reset()\n                state = None\n            episode_returns[ep_idx] = reward_sum\n            reward_sum = 0.0\n            ep_idx += 1\n    if isinstance(env.observation_space, spaces.Box) and (not record_images):\n        observations = np.concatenate(observations).reshape((-1,) + env.observation_space.shape)\n    elif isinstance(env.observation_space, spaces.Discrete):\n        observations = np.array(observations).reshape((-1, 1))\n    elif record_images:\n        observations = np.array(observations)\n    if isinstance(env.action_space, spaces.Box):\n        actions = np.concatenate(actions).reshape((-1,) + env.action_space.shape)\n    elif isinstance(env.action_space, spaces.Discrete):\n        actions = np.array(actions).reshape((-1, 1))\n    rewards = np.array(rewards)\n    episode_starts = np.array(episode_starts[:-1])\n    assert len(observations) == len(actions)\n    numpy_dict = {'actions': actions, 'obs': observations, 'rewards': rewards, 'episode_returns': episode_returns, 'episode_starts': episode_starts}\n    for (key, val) in numpy_dict.items():\n        print(key, val.shape)\n    if save_path is not None:\n        np.savez(save_path, **numpy_dict)\n    env.close()\n    return numpy_dict"
        ]
    }
]