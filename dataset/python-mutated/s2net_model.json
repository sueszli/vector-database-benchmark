[
    {
        "func_name": "__init__",
        "original": "def __init__(self, model_dir: str, **kwargs):\n    \"\"\"\n         An end-to-end deep network for monocular panorama depth estimation on a unit spherical surface.\n         This is the  official implementation of paper S2Net: Accurate Panorama Depth Estimation on Spherical Surface,\n        https://arxiv.org/abs/2301.05845.\n        Args:\n            model_dir: the path of the pretrained model file\n        \"\"\"\n    super().__init__(model_dir, **kwargs)\n    if 'device' in kwargs:\n        self.device = create_device(kwargs['device'])\n    else:\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    cfg_path = osp.join(model_dir, 'model.yaml')\n    cfg = get_config(cfg_path)\n    encoder_model_dict = {'swin': SwinSphDecoderNet, 'resNet': ResnetSphDecoderNet, 'effnet': EffnetSphDecoderNet}\n    model_path = osp.join(model_dir, ModelFile.TORCH_MODEL_FILE)\n    logger.info(f'loading model {model_path}')\n    model_dict = torch.load(model_path, map_location=torch.device('cpu'))\n    self.w = cfg.DATA.IMG_HEIGHT\n    self.h = cfg.DATA.IMG_WIDTH\n    self.max_depth_meters = 10.0\n    self.to_tensor = transforms.ToTensor()\n    self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    model_type = encoder_model_dict[cfg.BACKBONE.TYPE]\n    self.model = model_type(cfg, pretrained=False)\n    self.model.to(self.device)\n    self.model.load_state_dict(model_dict['model'], strict=True)\n    self.model.eval()\n    nside = 128\n    self.hp_info = compute_hp_info(nside, (cfg.DATA.IMG_HEIGHT, cfg.DATA.IMG_WIDTH))\n    logger.info(f'model init done! Device:{self.device}')",
        "mutated": [
            "def __init__(self, model_dir: str, **kwargs):\n    if False:\n        i = 10\n    '\\n         An end-to-end deep network for monocular panorama depth estimation on a unit spherical surface.\\n         This is the  official implementation of paper S2Net: Accurate Panorama Depth Estimation on Spherical Surface,\\n        https://arxiv.org/abs/2301.05845.\\n        Args:\\n            model_dir: the path of the pretrained model file\\n        '\n    super().__init__(model_dir, **kwargs)\n    if 'device' in kwargs:\n        self.device = create_device(kwargs['device'])\n    else:\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    cfg_path = osp.join(model_dir, 'model.yaml')\n    cfg = get_config(cfg_path)\n    encoder_model_dict = {'swin': SwinSphDecoderNet, 'resNet': ResnetSphDecoderNet, 'effnet': EffnetSphDecoderNet}\n    model_path = osp.join(model_dir, ModelFile.TORCH_MODEL_FILE)\n    logger.info(f'loading model {model_path}')\n    model_dict = torch.load(model_path, map_location=torch.device('cpu'))\n    self.w = cfg.DATA.IMG_HEIGHT\n    self.h = cfg.DATA.IMG_WIDTH\n    self.max_depth_meters = 10.0\n    self.to_tensor = transforms.ToTensor()\n    self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    model_type = encoder_model_dict[cfg.BACKBONE.TYPE]\n    self.model = model_type(cfg, pretrained=False)\n    self.model.to(self.device)\n    self.model.load_state_dict(model_dict['model'], strict=True)\n    self.model.eval()\n    nside = 128\n    self.hp_info = compute_hp_info(nside, (cfg.DATA.IMG_HEIGHT, cfg.DATA.IMG_WIDTH))\n    logger.info(f'model init done! Device:{self.device}')",
            "def __init__(self, model_dir: str, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n         An end-to-end deep network for monocular panorama depth estimation on a unit spherical surface.\\n         This is the  official implementation of paper S2Net: Accurate Panorama Depth Estimation on Spherical Surface,\\n        https://arxiv.org/abs/2301.05845.\\n        Args:\\n            model_dir: the path of the pretrained model file\\n        '\n    super().__init__(model_dir, **kwargs)\n    if 'device' in kwargs:\n        self.device = create_device(kwargs['device'])\n    else:\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    cfg_path = osp.join(model_dir, 'model.yaml')\n    cfg = get_config(cfg_path)\n    encoder_model_dict = {'swin': SwinSphDecoderNet, 'resNet': ResnetSphDecoderNet, 'effnet': EffnetSphDecoderNet}\n    model_path = osp.join(model_dir, ModelFile.TORCH_MODEL_FILE)\n    logger.info(f'loading model {model_path}')\n    model_dict = torch.load(model_path, map_location=torch.device('cpu'))\n    self.w = cfg.DATA.IMG_HEIGHT\n    self.h = cfg.DATA.IMG_WIDTH\n    self.max_depth_meters = 10.0\n    self.to_tensor = transforms.ToTensor()\n    self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    model_type = encoder_model_dict[cfg.BACKBONE.TYPE]\n    self.model = model_type(cfg, pretrained=False)\n    self.model.to(self.device)\n    self.model.load_state_dict(model_dict['model'], strict=True)\n    self.model.eval()\n    nside = 128\n    self.hp_info = compute_hp_info(nside, (cfg.DATA.IMG_HEIGHT, cfg.DATA.IMG_WIDTH))\n    logger.info(f'model init done! Device:{self.device}')",
            "def __init__(self, model_dir: str, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n         An end-to-end deep network for monocular panorama depth estimation on a unit spherical surface.\\n         This is the  official implementation of paper S2Net: Accurate Panorama Depth Estimation on Spherical Surface,\\n        https://arxiv.org/abs/2301.05845.\\n        Args:\\n            model_dir: the path of the pretrained model file\\n        '\n    super().__init__(model_dir, **kwargs)\n    if 'device' in kwargs:\n        self.device = create_device(kwargs['device'])\n    else:\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    cfg_path = osp.join(model_dir, 'model.yaml')\n    cfg = get_config(cfg_path)\n    encoder_model_dict = {'swin': SwinSphDecoderNet, 'resNet': ResnetSphDecoderNet, 'effnet': EffnetSphDecoderNet}\n    model_path = osp.join(model_dir, ModelFile.TORCH_MODEL_FILE)\n    logger.info(f'loading model {model_path}')\n    model_dict = torch.load(model_path, map_location=torch.device('cpu'))\n    self.w = cfg.DATA.IMG_HEIGHT\n    self.h = cfg.DATA.IMG_WIDTH\n    self.max_depth_meters = 10.0\n    self.to_tensor = transforms.ToTensor()\n    self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    model_type = encoder_model_dict[cfg.BACKBONE.TYPE]\n    self.model = model_type(cfg, pretrained=False)\n    self.model.to(self.device)\n    self.model.load_state_dict(model_dict['model'], strict=True)\n    self.model.eval()\n    nside = 128\n    self.hp_info = compute_hp_info(nside, (cfg.DATA.IMG_HEIGHT, cfg.DATA.IMG_WIDTH))\n    logger.info(f'model init done! Device:{self.device}')",
            "def __init__(self, model_dir: str, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n         An end-to-end deep network for monocular panorama depth estimation on a unit spherical surface.\\n         This is the  official implementation of paper S2Net: Accurate Panorama Depth Estimation on Spherical Surface,\\n        https://arxiv.org/abs/2301.05845.\\n        Args:\\n            model_dir: the path of the pretrained model file\\n        '\n    super().__init__(model_dir, **kwargs)\n    if 'device' in kwargs:\n        self.device = create_device(kwargs['device'])\n    else:\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    cfg_path = osp.join(model_dir, 'model.yaml')\n    cfg = get_config(cfg_path)\n    encoder_model_dict = {'swin': SwinSphDecoderNet, 'resNet': ResnetSphDecoderNet, 'effnet': EffnetSphDecoderNet}\n    model_path = osp.join(model_dir, ModelFile.TORCH_MODEL_FILE)\n    logger.info(f'loading model {model_path}')\n    model_dict = torch.load(model_path, map_location=torch.device('cpu'))\n    self.w = cfg.DATA.IMG_HEIGHT\n    self.h = cfg.DATA.IMG_WIDTH\n    self.max_depth_meters = 10.0\n    self.to_tensor = transforms.ToTensor()\n    self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    model_type = encoder_model_dict[cfg.BACKBONE.TYPE]\n    self.model = model_type(cfg, pretrained=False)\n    self.model.to(self.device)\n    self.model.load_state_dict(model_dict['model'], strict=True)\n    self.model.eval()\n    nside = 128\n    self.hp_info = compute_hp_info(nside, (cfg.DATA.IMG_HEIGHT, cfg.DATA.IMG_WIDTH))\n    logger.info(f'model init done! Device:{self.device}')",
            "def __init__(self, model_dir: str, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n         An end-to-end deep network for monocular panorama depth estimation on a unit spherical surface.\\n         This is the  official implementation of paper S2Net: Accurate Panorama Depth Estimation on Spherical Surface,\\n        https://arxiv.org/abs/2301.05845.\\n        Args:\\n            model_dir: the path of the pretrained model file\\n        '\n    super().__init__(model_dir, **kwargs)\n    if 'device' in kwargs:\n        self.device = create_device(kwargs['device'])\n    else:\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    cfg_path = osp.join(model_dir, 'model.yaml')\n    cfg = get_config(cfg_path)\n    encoder_model_dict = {'swin': SwinSphDecoderNet, 'resNet': ResnetSphDecoderNet, 'effnet': EffnetSphDecoderNet}\n    model_path = osp.join(model_dir, ModelFile.TORCH_MODEL_FILE)\n    logger.info(f'loading model {model_path}')\n    model_dict = torch.load(model_path, map_location=torch.device('cpu'))\n    self.w = cfg.DATA.IMG_HEIGHT\n    self.h = cfg.DATA.IMG_WIDTH\n    self.max_depth_meters = 10.0\n    self.to_tensor = transforms.ToTensor()\n    self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    model_type = encoder_model_dict[cfg.BACKBONE.TYPE]\n    self.model = model_type(cfg, pretrained=False)\n    self.model.to(self.device)\n    self.model.load_state_dict(model_dict['model'], strict=True)\n    self.model.eval()\n    nside = 128\n    self.hp_info = compute_hp_info(nside, (cfg.DATA.IMG_HEIGHT, cfg.DATA.IMG_WIDTH))\n    logger.info(f'model init done! Device:{self.device}')"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, rgb):\n    \"\"\"\n        Args:\n            rgb:  equirectangular panorama images\n            The torch size of rgb should be [n, 3, 512, 1024]\n        Returns:\n            S2net model outputs containing the predicted equirectangular depth images in metric\n        \"\"\"\n    equi_inputs = rgb.to(self.device)\n    return self.model(equi_inputs)",
        "mutated": [
            "def forward(self, rgb):\n    if False:\n        i = 10\n    '\\n        Args:\\n            rgb:  equirectangular panorama images\\n            The torch size of rgb should be [n, 3, 512, 1024]\\n        Returns:\\n            S2net model outputs containing the predicted equirectangular depth images in metric\\n        '\n    equi_inputs = rgb.to(self.device)\n    return self.model(equi_inputs)",
            "def forward(self, rgb):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Args:\\n            rgb:  equirectangular panorama images\\n            The torch size of rgb should be [n, 3, 512, 1024]\\n        Returns:\\n            S2net model outputs containing the predicted equirectangular depth images in metric\\n        '\n    equi_inputs = rgb.to(self.device)\n    return self.model(equi_inputs)",
            "def forward(self, rgb):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Args:\\n            rgb:  equirectangular panorama images\\n            The torch size of rgb should be [n, 3, 512, 1024]\\n        Returns:\\n            S2net model outputs containing the predicted equirectangular depth images in metric\\n        '\n    equi_inputs = rgb.to(self.device)\n    return self.model(equi_inputs)",
            "def forward(self, rgb):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Args:\\n            rgb:  equirectangular panorama images\\n            The torch size of rgb should be [n, 3, 512, 1024]\\n        Returns:\\n            S2net model outputs containing the predicted equirectangular depth images in metric\\n        '\n    equi_inputs = rgb.to(self.device)\n    return self.model(equi_inputs)",
            "def forward(self, rgb):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Args:\\n            rgb:  equirectangular panorama images\\n            The torch size of rgb should be [n, 3, 512, 1024]\\n        Returns:\\n            S2net model outputs containing the predicted equirectangular depth images in metric\\n        '\n    equi_inputs = rgb.to(self.device)\n    return self.model(equi_inputs)"
        ]
    },
    {
        "func_name": "postprocess",
        "original": "def postprocess(self, pred_depths_hp):\n    depth_maps = render_depth_map(pred_depths_hp, self.hp_info['image_to_sp_map'])[0]\n    results = {OutputKeys.DEPTHS: depth_maps}\n    return results",
        "mutated": [
            "def postprocess(self, pred_depths_hp):\n    if False:\n        i = 10\n    depth_maps = render_depth_map(pred_depths_hp, self.hp_info['image_to_sp_map'])[0]\n    results = {OutputKeys.DEPTHS: depth_maps}\n    return results",
            "def postprocess(self, pred_depths_hp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    depth_maps = render_depth_map(pred_depths_hp, self.hp_info['image_to_sp_map'])[0]\n    results = {OutputKeys.DEPTHS: depth_maps}\n    return results",
            "def postprocess(self, pred_depths_hp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    depth_maps = render_depth_map(pred_depths_hp, self.hp_info['image_to_sp_map'])[0]\n    results = {OutputKeys.DEPTHS: depth_maps}\n    return results",
            "def postprocess(self, pred_depths_hp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    depth_maps = render_depth_map(pred_depths_hp, self.hp_info['image_to_sp_map'])[0]\n    results = {OutputKeys.DEPTHS: depth_maps}\n    return results",
            "def postprocess(self, pred_depths_hp):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    depth_maps = render_depth_map(pred_depths_hp, self.hp_info['image_to_sp_map'])[0]\n    results = {OutputKeys.DEPTHS: depth_maps}\n    return results"
        ]
    }
]