[
    {
        "func_name": "_ternary_layout",
        "original": "def _ternary_layout(title='Ternary contour plot', width=550, height=525, pole_labels=['a', 'b', 'c']):\n    \"\"\"\n    Layout of ternary contour plot, to be passed to ``go.FigureWidget``\n    object.\n\n    Parameters\n    ==========\n    title : str or None\n        Title of ternary plot\n    width : int\n        Figure width.\n    height : int\n        Figure height.\n    pole_labels : str, default ['a', 'b', 'c']\n        Names of the three poles of the triangle.\n    \"\"\"\n    return dict(title=title, width=width, height=height, ternary=dict(sum=1, aaxis=dict(title=dict(text=pole_labels[0]), min=0.01, linewidth=2, ticks='outside'), baxis=dict(title=dict(text=pole_labels[1]), min=0.01, linewidth=2, ticks='outside'), caxis=dict(title=dict(text=pole_labels[2]), min=0.01, linewidth=2, ticks='outside')), showlegend=False)",
        "mutated": [
            "def _ternary_layout(title='Ternary contour plot', width=550, height=525, pole_labels=['a', 'b', 'c']):\n    if False:\n        i = 10\n    \"\\n    Layout of ternary contour plot, to be passed to ``go.FigureWidget``\\n    object.\\n\\n    Parameters\\n    ==========\\n    title : str or None\\n        Title of ternary plot\\n    width : int\\n        Figure width.\\n    height : int\\n        Figure height.\\n    pole_labels : str, default ['a', 'b', 'c']\\n        Names of the three poles of the triangle.\\n    \"\n    return dict(title=title, width=width, height=height, ternary=dict(sum=1, aaxis=dict(title=dict(text=pole_labels[0]), min=0.01, linewidth=2, ticks='outside'), baxis=dict(title=dict(text=pole_labels[1]), min=0.01, linewidth=2, ticks='outside'), caxis=dict(title=dict(text=pole_labels[2]), min=0.01, linewidth=2, ticks='outside')), showlegend=False)",
            "def _ternary_layout(title='Ternary contour plot', width=550, height=525, pole_labels=['a', 'b', 'c']):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Layout of ternary contour plot, to be passed to ``go.FigureWidget``\\n    object.\\n\\n    Parameters\\n    ==========\\n    title : str or None\\n        Title of ternary plot\\n    width : int\\n        Figure width.\\n    height : int\\n        Figure height.\\n    pole_labels : str, default ['a', 'b', 'c']\\n        Names of the three poles of the triangle.\\n    \"\n    return dict(title=title, width=width, height=height, ternary=dict(sum=1, aaxis=dict(title=dict(text=pole_labels[0]), min=0.01, linewidth=2, ticks='outside'), baxis=dict(title=dict(text=pole_labels[1]), min=0.01, linewidth=2, ticks='outside'), caxis=dict(title=dict(text=pole_labels[2]), min=0.01, linewidth=2, ticks='outside')), showlegend=False)",
            "def _ternary_layout(title='Ternary contour plot', width=550, height=525, pole_labels=['a', 'b', 'c']):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Layout of ternary contour plot, to be passed to ``go.FigureWidget``\\n    object.\\n\\n    Parameters\\n    ==========\\n    title : str or None\\n        Title of ternary plot\\n    width : int\\n        Figure width.\\n    height : int\\n        Figure height.\\n    pole_labels : str, default ['a', 'b', 'c']\\n        Names of the three poles of the triangle.\\n    \"\n    return dict(title=title, width=width, height=height, ternary=dict(sum=1, aaxis=dict(title=dict(text=pole_labels[0]), min=0.01, linewidth=2, ticks='outside'), baxis=dict(title=dict(text=pole_labels[1]), min=0.01, linewidth=2, ticks='outside'), caxis=dict(title=dict(text=pole_labels[2]), min=0.01, linewidth=2, ticks='outside')), showlegend=False)",
            "def _ternary_layout(title='Ternary contour plot', width=550, height=525, pole_labels=['a', 'b', 'c']):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Layout of ternary contour plot, to be passed to ``go.FigureWidget``\\n    object.\\n\\n    Parameters\\n    ==========\\n    title : str or None\\n        Title of ternary plot\\n    width : int\\n        Figure width.\\n    height : int\\n        Figure height.\\n    pole_labels : str, default ['a', 'b', 'c']\\n        Names of the three poles of the triangle.\\n    \"\n    return dict(title=title, width=width, height=height, ternary=dict(sum=1, aaxis=dict(title=dict(text=pole_labels[0]), min=0.01, linewidth=2, ticks='outside'), baxis=dict(title=dict(text=pole_labels[1]), min=0.01, linewidth=2, ticks='outside'), caxis=dict(title=dict(text=pole_labels[2]), min=0.01, linewidth=2, ticks='outside')), showlegend=False)",
            "def _ternary_layout(title='Ternary contour plot', width=550, height=525, pole_labels=['a', 'b', 'c']):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Layout of ternary contour plot, to be passed to ``go.FigureWidget``\\n    object.\\n\\n    Parameters\\n    ==========\\n    title : str or None\\n        Title of ternary plot\\n    width : int\\n        Figure width.\\n    height : int\\n        Figure height.\\n    pole_labels : str, default ['a', 'b', 'c']\\n        Names of the three poles of the triangle.\\n    \"\n    return dict(title=title, width=width, height=height, ternary=dict(sum=1, aaxis=dict(title=dict(text=pole_labels[0]), min=0.01, linewidth=2, ticks='outside'), baxis=dict(title=dict(text=pole_labels[1]), min=0.01, linewidth=2, ticks='outside'), caxis=dict(title=dict(text=pole_labels[2]), min=0.01, linewidth=2, ticks='outside')), showlegend=False)"
        ]
    },
    {
        "func_name": "_replace_zero_coords",
        "original": "def _replace_zero_coords(ternary_data, delta=0.0005):\n    \"\"\"\n    Replaces zero ternary coordinates with delta and normalize the new\n    triplets (a, b, c).\n\n    Parameters\n    ----------\n\n    ternary_data : ndarray of shape (N, 3)\n\n    delta : float\n        Small float to regularize logarithm.\n\n    Notes\n    -----\n    Implements a method\n    by J. A. Martin-Fernandez,  C. Barcelo-Vidal, V. Pawlowsky-Glahn,\n    Dealing with zeros and missing values in compositional data sets\n    using nonparametric imputation, Mathematical Geology 35 (2003),\n    pp 253-278.\n    \"\"\"\n    zero_mask = ternary_data == 0\n    is_any_coord_zero = np.any(zero_mask, axis=0)\n    unity_complement = 1 - delta * is_any_coord_zero\n    if np.any(unity_complement) < 0:\n        raise ValueError('The provided value of delta led to negativeternary coords.Set a smaller delta')\n    ternary_data = np.where(zero_mask, delta, unity_complement * ternary_data)\n    return ternary_data",
        "mutated": [
            "def _replace_zero_coords(ternary_data, delta=0.0005):\n    if False:\n        i = 10\n    '\\n    Replaces zero ternary coordinates with delta and normalize the new\\n    triplets (a, b, c).\\n\\n    Parameters\\n    ----------\\n\\n    ternary_data : ndarray of shape (N, 3)\\n\\n    delta : float\\n        Small float to regularize logarithm.\\n\\n    Notes\\n    -----\\n    Implements a method\\n    by J. A. Martin-Fernandez,  C. Barcelo-Vidal, V. Pawlowsky-Glahn,\\n    Dealing with zeros and missing values in compositional data sets\\n    using nonparametric imputation, Mathematical Geology 35 (2003),\\n    pp 253-278.\\n    '\n    zero_mask = ternary_data == 0\n    is_any_coord_zero = np.any(zero_mask, axis=0)\n    unity_complement = 1 - delta * is_any_coord_zero\n    if np.any(unity_complement) < 0:\n        raise ValueError('The provided value of delta led to negativeternary coords.Set a smaller delta')\n    ternary_data = np.where(zero_mask, delta, unity_complement * ternary_data)\n    return ternary_data",
            "def _replace_zero_coords(ternary_data, delta=0.0005):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Replaces zero ternary coordinates with delta and normalize the new\\n    triplets (a, b, c).\\n\\n    Parameters\\n    ----------\\n\\n    ternary_data : ndarray of shape (N, 3)\\n\\n    delta : float\\n        Small float to regularize logarithm.\\n\\n    Notes\\n    -----\\n    Implements a method\\n    by J. A. Martin-Fernandez,  C. Barcelo-Vidal, V. Pawlowsky-Glahn,\\n    Dealing with zeros and missing values in compositional data sets\\n    using nonparametric imputation, Mathematical Geology 35 (2003),\\n    pp 253-278.\\n    '\n    zero_mask = ternary_data == 0\n    is_any_coord_zero = np.any(zero_mask, axis=0)\n    unity_complement = 1 - delta * is_any_coord_zero\n    if np.any(unity_complement) < 0:\n        raise ValueError('The provided value of delta led to negativeternary coords.Set a smaller delta')\n    ternary_data = np.where(zero_mask, delta, unity_complement * ternary_data)\n    return ternary_data",
            "def _replace_zero_coords(ternary_data, delta=0.0005):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Replaces zero ternary coordinates with delta and normalize the new\\n    triplets (a, b, c).\\n\\n    Parameters\\n    ----------\\n\\n    ternary_data : ndarray of shape (N, 3)\\n\\n    delta : float\\n        Small float to regularize logarithm.\\n\\n    Notes\\n    -----\\n    Implements a method\\n    by J. A. Martin-Fernandez,  C. Barcelo-Vidal, V. Pawlowsky-Glahn,\\n    Dealing with zeros and missing values in compositional data sets\\n    using nonparametric imputation, Mathematical Geology 35 (2003),\\n    pp 253-278.\\n    '\n    zero_mask = ternary_data == 0\n    is_any_coord_zero = np.any(zero_mask, axis=0)\n    unity_complement = 1 - delta * is_any_coord_zero\n    if np.any(unity_complement) < 0:\n        raise ValueError('The provided value of delta led to negativeternary coords.Set a smaller delta')\n    ternary_data = np.where(zero_mask, delta, unity_complement * ternary_data)\n    return ternary_data",
            "def _replace_zero_coords(ternary_data, delta=0.0005):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Replaces zero ternary coordinates with delta and normalize the new\\n    triplets (a, b, c).\\n\\n    Parameters\\n    ----------\\n\\n    ternary_data : ndarray of shape (N, 3)\\n\\n    delta : float\\n        Small float to regularize logarithm.\\n\\n    Notes\\n    -----\\n    Implements a method\\n    by J. A. Martin-Fernandez,  C. Barcelo-Vidal, V. Pawlowsky-Glahn,\\n    Dealing with zeros and missing values in compositional data sets\\n    using nonparametric imputation, Mathematical Geology 35 (2003),\\n    pp 253-278.\\n    '\n    zero_mask = ternary_data == 0\n    is_any_coord_zero = np.any(zero_mask, axis=0)\n    unity_complement = 1 - delta * is_any_coord_zero\n    if np.any(unity_complement) < 0:\n        raise ValueError('The provided value of delta led to negativeternary coords.Set a smaller delta')\n    ternary_data = np.where(zero_mask, delta, unity_complement * ternary_data)\n    return ternary_data",
            "def _replace_zero_coords(ternary_data, delta=0.0005):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Replaces zero ternary coordinates with delta and normalize the new\\n    triplets (a, b, c).\\n\\n    Parameters\\n    ----------\\n\\n    ternary_data : ndarray of shape (N, 3)\\n\\n    delta : float\\n        Small float to regularize logarithm.\\n\\n    Notes\\n    -----\\n    Implements a method\\n    by J. A. Martin-Fernandez,  C. Barcelo-Vidal, V. Pawlowsky-Glahn,\\n    Dealing with zeros and missing values in compositional data sets\\n    using nonparametric imputation, Mathematical Geology 35 (2003),\\n    pp 253-278.\\n    '\n    zero_mask = ternary_data == 0\n    is_any_coord_zero = np.any(zero_mask, axis=0)\n    unity_complement = 1 - delta * is_any_coord_zero\n    if np.any(unity_complement) < 0:\n        raise ValueError('The provided value of delta led to negativeternary coords.Set a smaller delta')\n    ternary_data = np.where(zero_mask, delta, unity_complement * ternary_data)\n    return ternary_data"
        ]
    },
    {
        "func_name": "_ilr_transform",
        "original": "def _ilr_transform(barycentric):\n    \"\"\"\n    Perform Isometric Log-Ratio on barycentric (compositional) data.\n\n    Parameters\n    ----------\n    barycentric: ndarray of shape (3, N)\n        Barycentric coordinates.\n\n    References\n    ----------\n    \"An algebraic method to compute isometric logratio transformation and\n    back transformation of compositional data\", Jarauta-Bragulat, E.,\n    Buenestado, P.; Hervada-Sala, C., in Proc. of the Annual Conf. of the\n    Intl Assoc for Math Geology, 2003, pp 31-30.\n    \"\"\"\n    barycentric = np.asarray(barycentric)\n    x_0 = np.log(barycentric[0] / barycentric[1]) / np.sqrt(2)\n    x_1 = 1.0 / np.sqrt(6) * np.log(barycentric[0] * barycentric[1] / barycentric[2] ** 2)\n    ilr_tdata = np.stack((x_0, x_1))\n    return ilr_tdata",
        "mutated": [
            "def _ilr_transform(barycentric):\n    if False:\n        i = 10\n    '\\n    Perform Isometric Log-Ratio on barycentric (compositional) data.\\n\\n    Parameters\\n    ----------\\n    barycentric: ndarray of shape (3, N)\\n        Barycentric coordinates.\\n\\n    References\\n    ----------\\n    \"An algebraic method to compute isometric logratio transformation and\\n    back transformation of compositional data\", Jarauta-Bragulat, E.,\\n    Buenestado, P.; Hervada-Sala, C., in Proc. of the Annual Conf. of the\\n    Intl Assoc for Math Geology, 2003, pp 31-30.\\n    '\n    barycentric = np.asarray(barycentric)\n    x_0 = np.log(barycentric[0] / barycentric[1]) / np.sqrt(2)\n    x_1 = 1.0 / np.sqrt(6) * np.log(barycentric[0] * barycentric[1] / barycentric[2] ** 2)\n    ilr_tdata = np.stack((x_0, x_1))\n    return ilr_tdata",
            "def _ilr_transform(barycentric):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Perform Isometric Log-Ratio on barycentric (compositional) data.\\n\\n    Parameters\\n    ----------\\n    barycentric: ndarray of shape (3, N)\\n        Barycentric coordinates.\\n\\n    References\\n    ----------\\n    \"An algebraic method to compute isometric logratio transformation and\\n    back transformation of compositional data\", Jarauta-Bragulat, E.,\\n    Buenestado, P.; Hervada-Sala, C., in Proc. of the Annual Conf. of the\\n    Intl Assoc for Math Geology, 2003, pp 31-30.\\n    '\n    barycentric = np.asarray(barycentric)\n    x_0 = np.log(barycentric[0] / barycentric[1]) / np.sqrt(2)\n    x_1 = 1.0 / np.sqrt(6) * np.log(barycentric[0] * barycentric[1] / barycentric[2] ** 2)\n    ilr_tdata = np.stack((x_0, x_1))\n    return ilr_tdata",
            "def _ilr_transform(barycentric):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Perform Isometric Log-Ratio on barycentric (compositional) data.\\n\\n    Parameters\\n    ----------\\n    barycentric: ndarray of shape (3, N)\\n        Barycentric coordinates.\\n\\n    References\\n    ----------\\n    \"An algebraic method to compute isometric logratio transformation and\\n    back transformation of compositional data\", Jarauta-Bragulat, E.,\\n    Buenestado, P.; Hervada-Sala, C., in Proc. of the Annual Conf. of the\\n    Intl Assoc for Math Geology, 2003, pp 31-30.\\n    '\n    barycentric = np.asarray(barycentric)\n    x_0 = np.log(barycentric[0] / barycentric[1]) / np.sqrt(2)\n    x_1 = 1.0 / np.sqrt(6) * np.log(barycentric[0] * barycentric[1] / barycentric[2] ** 2)\n    ilr_tdata = np.stack((x_0, x_1))\n    return ilr_tdata",
            "def _ilr_transform(barycentric):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Perform Isometric Log-Ratio on barycentric (compositional) data.\\n\\n    Parameters\\n    ----------\\n    barycentric: ndarray of shape (3, N)\\n        Barycentric coordinates.\\n\\n    References\\n    ----------\\n    \"An algebraic method to compute isometric logratio transformation and\\n    back transformation of compositional data\", Jarauta-Bragulat, E.,\\n    Buenestado, P.; Hervada-Sala, C., in Proc. of the Annual Conf. of the\\n    Intl Assoc for Math Geology, 2003, pp 31-30.\\n    '\n    barycentric = np.asarray(barycentric)\n    x_0 = np.log(barycentric[0] / barycentric[1]) / np.sqrt(2)\n    x_1 = 1.0 / np.sqrt(6) * np.log(barycentric[0] * barycentric[1] / barycentric[2] ** 2)\n    ilr_tdata = np.stack((x_0, x_1))\n    return ilr_tdata",
            "def _ilr_transform(barycentric):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Perform Isometric Log-Ratio on barycentric (compositional) data.\\n\\n    Parameters\\n    ----------\\n    barycentric: ndarray of shape (3, N)\\n        Barycentric coordinates.\\n\\n    References\\n    ----------\\n    \"An algebraic method to compute isometric logratio transformation and\\n    back transformation of compositional data\", Jarauta-Bragulat, E.,\\n    Buenestado, P.; Hervada-Sala, C., in Proc. of the Annual Conf. of the\\n    Intl Assoc for Math Geology, 2003, pp 31-30.\\n    '\n    barycentric = np.asarray(barycentric)\n    x_0 = np.log(barycentric[0] / barycentric[1]) / np.sqrt(2)\n    x_1 = 1.0 / np.sqrt(6) * np.log(barycentric[0] * barycentric[1] / barycentric[2] ** 2)\n    ilr_tdata = np.stack((x_0, x_1))\n    return ilr_tdata"
        ]
    },
    {
        "func_name": "_ilr_inverse",
        "original": "def _ilr_inverse(x):\n    \"\"\"\n    Perform inverse Isometric Log-Ratio (ILR) transform to retrieve\n    barycentric (compositional) data.\n\n    Parameters\n    ----------\n    x : array of shape (2, N)\n        Coordinates in ILR space.\n\n    References\n    ----------\n    \"An algebraic method to compute isometric logratio transformation and\n    back transformation of compositional data\", Jarauta-Bragulat, E.,\n    Buenestado, P.; Hervada-Sala, C., in Proc. of the Annual Conf. of the\n    Intl Assoc for Math Geology, 2003, pp 31-30.\n    \"\"\"\n    x = np.array(x)\n    matrix = np.array([[0.5, 1, 1.0], [-0.5, 1, 1.0], [0.0, 0.0, 1.0]])\n    s = np.sqrt(2) / 2\n    t = np.sqrt(3 / 2)\n    Sk = np.einsum('ik, kj -> ij', np.array([[s, t], [-s, t]]), x)\n    Z = -np.log(1 + np.exp(Sk).sum(axis=0))\n    log_barycentric = np.einsum('ik, kj -> ij', matrix, np.stack((2 * s * x[0], t * x[1], Z)))\n    iilr_tdata = np.exp(log_barycentric)\n    return iilr_tdata",
        "mutated": [
            "def _ilr_inverse(x):\n    if False:\n        i = 10\n    '\\n    Perform inverse Isometric Log-Ratio (ILR) transform to retrieve\\n    barycentric (compositional) data.\\n\\n    Parameters\\n    ----------\\n    x : array of shape (2, N)\\n        Coordinates in ILR space.\\n\\n    References\\n    ----------\\n    \"An algebraic method to compute isometric logratio transformation and\\n    back transformation of compositional data\", Jarauta-Bragulat, E.,\\n    Buenestado, P.; Hervada-Sala, C., in Proc. of the Annual Conf. of the\\n    Intl Assoc for Math Geology, 2003, pp 31-30.\\n    '\n    x = np.array(x)\n    matrix = np.array([[0.5, 1, 1.0], [-0.5, 1, 1.0], [0.0, 0.0, 1.0]])\n    s = np.sqrt(2) / 2\n    t = np.sqrt(3 / 2)\n    Sk = np.einsum('ik, kj -> ij', np.array([[s, t], [-s, t]]), x)\n    Z = -np.log(1 + np.exp(Sk).sum(axis=0))\n    log_barycentric = np.einsum('ik, kj -> ij', matrix, np.stack((2 * s * x[0], t * x[1], Z)))\n    iilr_tdata = np.exp(log_barycentric)\n    return iilr_tdata",
            "def _ilr_inverse(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Perform inverse Isometric Log-Ratio (ILR) transform to retrieve\\n    barycentric (compositional) data.\\n\\n    Parameters\\n    ----------\\n    x : array of shape (2, N)\\n        Coordinates in ILR space.\\n\\n    References\\n    ----------\\n    \"An algebraic method to compute isometric logratio transformation and\\n    back transformation of compositional data\", Jarauta-Bragulat, E.,\\n    Buenestado, P.; Hervada-Sala, C., in Proc. of the Annual Conf. of the\\n    Intl Assoc for Math Geology, 2003, pp 31-30.\\n    '\n    x = np.array(x)\n    matrix = np.array([[0.5, 1, 1.0], [-0.5, 1, 1.0], [0.0, 0.0, 1.0]])\n    s = np.sqrt(2) / 2\n    t = np.sqrt(3 / 2)\n    Sk = np.einsum('ik, kj -> ij', np.array([[s, t], [-s, t]]), x)\n    Z = -np.log(1 + np.exp(Sk).sum(axis=0))\n    log_barycentric = np.einsum('ik, kj -> ij', matrix, np.stack((2 * s * x[0], t * x[1], Z)))\n    iilr_tdata = np.exp(log_barycentric)\n    return iilr_tdata",
            "def _ilr_inverse(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Perform inverse Isometric Log-Ratio (ILR) transform to retrieve\\n    barycentric (compositional) data.\\n\\n    Parameters\\n    ----------\\n    x : array of shape (2, N)\\n        Coordinates in ILR space.\\n\\n    References\\n    ----------\\n    \"An algebraic method to compute isometric logratio transformation and\\n    back transformation of compositional data\", Jarauta-Bragulat, E.,\\n    Buenestado, P.; Hervada-Sala, C., in Proc. of the Annual Conf. of the\\n    Intl Assoc for Math Geology, 2003, pp 31-30.\\n    '\n    x = np.array(x)\n    matrix = np.array([[0.5, 1, 1.0], [-0.5, 1, 1.0], [0.0, 0.0, 1.0]])\n    s = np.sqrt(2) / 2\n    t = np.sqrt(3 / 2)\n    Sk = np.einsum('ik, kj -> ij', np.array([[s, t], [-s, t]]), x)\n    Z = -np.log(1 + np.exp(Sk).sum(axis=0))\n    log_barycentric = np.einsum('ik, kj -> ij', matrix, np.stack((2 * s * x[0], t * x[1], Z)))\n    iilr_tdata = np.exp(log_barycentric)\n    return iilr_tdata",
            "def _ilr_inverse(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Perform inverse Isometric Log-Ratio (ILR) transform to retrieve\\n    barycentric (compositional) data.\\n\\n    Parameters\\n    ----------\\n    x : array of shape (2, N)\\n        Coordinates in ILR space.\\n\\n    References\\n    ----------\\n    \"An algebraic method to compute isometric logratio transformation and\\n    back transformation of compositional data\", Jarauta-Bragulat, E.,\\n    Buenestado, P.; Hervada-Sala, C., in Proc. of the Annual Conf. of the\\n    Intl Assoc for Math Geology, 2003, pp 31-30.\\n    '\n    x = np.array(x)\n    matrix = np.array([[0.5, 1, 1.0], [-0.5, 1, 1.0], [0.0, 0.0, 1.0]])\n    s = np.sqrt(2) / 2\n    t = np.sqrt(3 / 2)\n    Sk = np.einsum('ik, kj -> ij', np.array([[s, t], [-s, t]]), x)\n    Z = -np.log(1 + np.exp(Sk).sum(axis=0))\n    log_barycentric = np.einsum('ik, kj -> ij', matrix, np.stack((2 * s * x[0], t * x[1], Z)))\n    iilr_tdata = np.exp(log_barycentric)\n    return iilr_tdata",
            "def _ilr_inverse(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Perform inverse Isometric Log-Ratio (ILR) transform to retrieve\\n    barycentric (compositional) data.\\n\\n    Parameters\\n    ----------\\n    x : array of shape (2, N)\\n        Coordinates in ILR space.\\n\\n    References\\n    ----------\\n    \"An algebraic method to compute isometric logratio transformation and\\n    back transformation of compositional data\", Jarauta-Bragulat, E.,\\n    Buenestado, P.; Hervada-Sala, C., in Proc. of the Annual Conf. of the\\n    Intl Assoc for Math Geology, 2003, pp 31-30.\\n    '\n    x = np.array(x)\n    matrix = np.array([[0.5, 1, 1.0], [-0.5, 1, 1.0], [0.0, 0.0, 1.0]])\n    s = np.sqrt(2) / 2\n    t = np.sqrt(3 / 2)\n    Sk = np.einsum('ik, kj -> ij', np.array([[s, t], [-s, t]]), x)\n    Z = -np.log(1 + np.exp(Sk).sum(axis=0))\n    log_barycentric = np.einsum('ik, kj -> ij', matrix, np.stack((2 * s * x[0], t * x[1], Z)))\n    iilr_tdata = np.exp(log_barycentric)\n    return iilr_tdata"
        ]
    },
    {
        "func_name": "_transform_barycentric_cartesian",
        "original": "def _transform_barycentric_cartesian():\n    \"\"\"\n    Returns the transformation matrix from barycentric to Cartesian\n    coordinates and conversely.\n    \"\"\"\n    tri_verts = np.array([[0.5, np.sqrt(3) / 2], [0, 0], [1, 0]])\n    M = np.array([tri_verts[:, 0], tri_verts[:, 1], np.ones(3)])\n    return (M, np.linalg.inv(M))",
        "mutated": [
            "def _transform_barycentric_cartesian():\n    if False:\n        i = 10\n    '\\n    Returns the transformation matrix from barycentric to Cartesian\\n    coordinates and conversely.\\n    '\n    tri_verts = np.array([[0.5, np.sqrt(3) / 2], [0, 0], [1, 0]])\n    M = np.array([tri_verts[:, 0], tri_verts[:, 1], np.ones(3)])\n    return (M, np.linalg.inv(M))",
            "def _transform_barycentric_cartesian():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Returns the transformation matrix from barycentric to Cartesian\\n    coordinates and conversely.\\n    '\n    tri_verts = np.array([[0.5, np.sqrt(3) / 2], [0, 0], [1, 0]])\n    M = np.array([tri_verts[:, 0], tri_verts[:, 1], np.ones(3)])\n    return (M, np.linalg.inv(M))",
            "def _transform_barycentric_cartesian():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Returns the transformation matrix from barycentric to Cartesian\\n    coordinates and conversely.\\n    '\n    tri_verts = np.array([[0.5, np.sqrt(3) / 2], [0, 0], [1, 0]])\n    M = np.array([tri_verts[:, 0], tri_verts[:, 1], np.ones(3)])\n    return (M, np.linalg.inv(M))",
            "def _transform_barycentric_cartesian():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Returns the transformation matrix from barycentric to Cartesian\\n    coordinates and conversely.\\n    '\n    tri_verts = np.array([[0.5, np.sqrt(3) / 2], [0, 0], [1, 0]])\n    M = np.array([tri_verts[:, 0], tri_verts[:, 1], np.ones(3)])\n    return (M, np.linalg.inv(M))",
            "def _transform_barycentric_cartesian():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Returns the transformation matrix from barycentric to Cartesian\\n    coordinates and conversely.\\n    '\n    tri_verts = np.array([[0.5, np.sqrt(3) / 2], [0, 0], [1, 0]])\n    M = np.array([tri_verts[:, 0], tri_verts[:, 1], np.ones(3)])\n    return (M, np.linalg.inv(M))"
        ]
    },
    {
        "func_name": "_prepare_barycentric_coord",
        "original": "def _prepare_barycentric_coord(b_coords):\n    \"\"\"\n    Check ternary coordinates and return the right barycentric coordinates.\n    \"\"\"\n    if not isinstance(b_coords, (list, np.ndarray)):\n        raise ValueError('Data  should be either an array of shape (n,m),or a list of n m-lists, m=2 or 3')\n    b_coords = np.asarray(b_coords)\n    if b_coords.shape[0] not in (2, 3):\n        raise ValueError('A point should have  2 (a, b) or 3 (a, b, c)barycentric coordinates')\n    if len(b_coords) == 3 and (not np.allclose(b_coords.sum(axis=0), 1, rtol=0.01)) and (not np.allclose(b_coords.sum(axis=0), 100, rtol=0.01)):\n        msg = 'The sum of coordinates should be 1 or 100 for all data points'\n        raise ValueError(msg)\n    if len(b_coords) == 2:\n        (A, B) = b_coords\n        C = 1 - (A + B)\n    else:\n        (A, B, C) = b_coords / b_coords.sum(axis=0)\n    if np.any(np.stack((A, B, C)) < 0):\n        raise ValueError('Barycentric coordinates should be positive.')\n    return np.stack((A, B, C))",
        "mutated": [
            "def _prepare_barycentric_coord(b_coords):\n    if False:\n        i = 10\n    '\\n    Check ternary coordinates and return the right barycentric coordinates.\\n    '\n    if not isinstance(b_coords, (list, np.ndarray)):\n        raise ValueError('Data  should be either an array of shape (n,m),or a list of n m-lists, m=2 or 3')\n    b_coords = np.asarray(b_coords)\n    if b_coords.shape[0] not in (2, 3):\n        raise ValueError('A point should have  2 (a, b) or 3 (a, b, c)barycentric coordinates')\n    if len(b_coords) == 3 and (not np.allclose(b_coords.sum(axis=0), 1, rtol=0.01)) and (not np.allclose(b_coords.sum(axis=0), 100, rtol=0.01)):\n        msg = 'The sum of coordinates should be 1 or 100 for all data points'\n        raise ValueError(msg)\n    if len(b_coords) == 2:\n        (A, B) = b_coords\n        C = 1 - (A + B)\n    else:\n        (A, B, C) = b_coords / b_coords.sum(axis=0)\n    if np.any(np.stack((A, B, C)) < 0):\n        raise ValueError('Barycentric coordinates should be positive.')\n    return np.stack((A, B, C))",
            "def _prepare_barycentric_coord(b_coords):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Check ternary coordinates and return the right barycentric coordinates.\\n    '\n    if not isinstance(b_coords, (list, np.ndarray)):\n        raise ValueError('Data  should be either an array of shape (n,m),or a list of n m-lists, m=2 or 3')\n    b_coords = np.asarray(b_coords)\n    if b_coords.shape[0] not in (2, 3):\n        raise ValueError('A point should have  2 (a, b) or 3 (a, b, c)barycentric coordinates')\n    if len(b_coords) == 3 and (not np.allclose(b_coords.sum(axis=0), 1, rtol=0.01)) and (not np.allclose(b_coords.sum(axis=0), 100, rtol=0.01)):\n        msg = 'The sum of coordinates should be 1 or 100 for all data points'\n        raise ValueError(msg)\n    if len(b_coords) == 2:\n        (A, B) = b_coords\n        C = 1 - (A + B)\n    else:\n        (A, B, C) = b_coords / b_coords.sum(axis=0)\n    if np.any(np.stack((A, B, C)) < 0):\n        raise ValueError('Barycentric coordinates should be positive.')\n    return np.stack((A, B, C))",
            "def _prepare_barycentric_coord(b_coords):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Check ternary coordinates and return the right barycentric coordinates.\\n    '\n    if not isinstance(b_coords, (list, np.ndarray)):\n        raise ValueError('Data  should be either an array of shape (n,m),or a list of n m-lists, m=2 or 3')\n    b_coords = np.asarray(b_coords)\n    if b_coords.shape[0] not in (2, 3):\n        raise ValueError('A point should have  2 (a, b) or 3 (a, b, c)barycentric coordinates')\n    if len(b_coords) == 3 and (not np.allclose(b_coords.sum(axis=0), 1, rtol=0.01)) and (not np.allclose(b_coords.sum(axis=0), 100, rtol=0.01)):\n        msg = 'The sum of coordinates should be 1 or 100 for all data points'\n        raise ValueError(msg)\n    if len(b_coords) == 2:\n        (A, B) = b_coords\n        C = 1 - (A + B)\n    else:\n        (A, B, C) = b_coords / b_coords.sum(axis=0)\n    if np.any(np.stack((A, B, C)) < 0):\n        raise ValueError('Barycentric coordinates should be positive.')\n    return np.stack((A, B, C))",
            "def _prepare_barycentric_coord(b_coords):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Check ternary coordinates and return the right barycentric coordinates.\\n    '\n    if not isinstance(b_coords, (list, np.ndarray)):\n        raise ValueError('Data  should be either an array of shape (n,m),or a list of n m-lists, m=2 or 3')\n    b_coords = np.asarray(b_coords)\n    if b_coords.shape[0] not in (2, 3):\n        raise ValueError('A point should have  2 (a, b) or 3 (a, b, c)barycentric coordinates')\n    if len(b_coords) == 3 and (not np.allclose(b_coords.sum(axis=0), 1, rtol=0.01)) and (not np.allclose(b_coords.sum(axis=0), 100, rtol=0.01)):\n        msg = 'The sum of coordinates should be 1 or 100 for all data points'\n        raise ValueError(msg)\n    if len(b_coords) == 2:\n        (A, B) = b_coords\n        C = 1 - (A + B)\n    else:\n        (A, B, C) = b_coords / b_coords.sum(axis=0)\n    if np.any(np.stack((A, B, C)) < 0):\n        raise ValueError('Barycentric coordinates should be positive.')\n    return np.stack((A, B, C))",
            "def _prepare_barycentric_coord(b_coords):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Check ternary coordinates and return the right barycentric coordinates.\\n    '\n    if not isinstance(b_coords, (list, np.ndarray)):\n        raise ValueError('Data  should be either an array of shape (n,m),or a list of n m-lists, m=2 or 3')\n    b_coords = np.asarray(b_coords)\n    if b_coords.shape[0] not in (2, 3):\n        raise ValueError('A point should have  2 (a, b) or 3 (a, b, c)barycentric coordinates')\n    if len(b_coords) == 3 and (not np.allclose(b_coords.sum(axis=0), 1, rtol=0.01)) and (not np.allclose(b_coords.sum(axis=0), 100, rtol=0.01)):\n        msg = 'The sum of coordinates should be 1 or 100 for all data points'\n        raise ValueError(msg)\n    if len(b_coords) == 2:\n        (A, B) = b_coords\n        C = 1 - (A + B)\n    else:\n        (A, B, C) = b_coords / b_coords.sum(axis=0)\n    if np.any(np.stack((A, B, C)) < 0):\n        raise ValueError('Barycentric coordinates should be positive.')\n    return np.stack((A, B, C))"
        ]
    },
    {
        "func_name": "_compute_grid",
        "original": "def _compute_grid(coordinates, values, interp_mode='ilr'):\n    \"\"\"\n    Transform data points with Cartesian or ILR mapping, then Compute\n    interpolation on a regular grid.\n\n    Parameters\n    ==========\n\n    coordinates : array-like\n        Barycentric coordinates of data points.\n    values : 1-d array-like\n        Data points, field to be represented as contours.\n    interp_mode : 'ilr' (default) or 'cartesian'\n        Defines how data are interpolated to compute contours.\n    \"\"\"\n    if interp_mode == 'cartesian':\n        (M, invM) = _transform_barycentric_cartesian()\n        coord_points = np.einsum('ik, kj -> ij', M, coordinates)\n    elif interp_mode == 'ilr':\n        coordinates = _replace_zero_coords(coordinates)\n        coord_points = _ilr_transform(coordinates)\n    else:\n        raise ValueError('interp_mode should be cartesian or ilr')\n    (xx, yy) = coord_points[:2]\n    (x_min, x_max) = (xx.min(), xx.max())\n    (y_min, y_max) = (yy.min(), yy.max())\n    n_interp = max(200, int(np.sqrt(len(values))))\n    gr_x = np.linspace(x_min, x_max, n_interp)\n    gr_y = np.linspace(y_min, y_max, n_interp)\n    (grid_x, grid_y) = np.meshgrid(gr_x, gr_y)\n    grid_z = scipy_interp.griddata(coord_points[:2].T, values, (grid_x, grid_y), method='cubic')\n    grid_z_other = scipy_interp.griddata(coord_points[:2].T, values, (grid_x, grid_y), method='nearest')\n    return (grid_z, gr_x, gr_y)",
        "mutated": [
            "def _compute_grid(coordinates, values, interp_mode='ilr'):\n    if False:\n        i = 10\n    \"\\n    Transform data points with Cartesian or ILR mapping, then Compute\\n    interpolation on a regular grid.\\n\\n    Parameters\\n    ==========\\n\\n    coordinates : array-like\\n        Barycentric coordinates of data points.\\n    values : 1-d array-like\\n        Data points, field to be represented as contours.\\n    interp_mode : 'ilr' (default) or 'cartesian'\\n        Defines how data are interpolated to compute contours.\\n    \"\n    if interp_mode == 'cartesian':\n        (M, invM) = _transform_barycentric_cartesian()\n        coord_points = np.einsum('ik, kj -> ij', M, coordinates)\n    elif interp_mode == 'ilr':\n        coordinates = _replace_zero_coords(coordinates)\n        coord_points = _ilr_transform(coordinates)\n    else:\n        raise ValueError('interp_mode should be cartesian or ilr')\n    (xx, yy) = coord_points[:2]\n    (x_min, x_max) = (xx.min(), xx.max())\n    (y_min, y_max) = (yy.min(), yy.max())\n    n_interp = max(200, int(np.sqrt(len(values))))\n    gr_x = np.linspace(x_min, x_max, n_interp)\n    gr_y = np.linspace(y_min, y_max, n_interp)\n    (grid_x, grid_y) = np.meshgrid(gr_x, gr_y)\n    grid_z = scipy_interp.griddata(coord_points[:2].T, values, (grid_x, grid_y), method='cubic')\n    grid_z_other = scipy_interp.griddata(coord_points[:2].T, values, (grid_x, grid_y), method='nearest')\n    return (grid_z, gr_x, gr_y)",
            "def _compute_grid(coordinates, values, interp_mode='ilr'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Transform data points with Cartesian or ILR mapping, then Compute\\n    interpolation on a regular grid.\\n\\n    Parameters\\n    ==========\\n\\n    coordinates : array-like\\n        Barycentric coordinates of data points.\\n    values : 1-d array-like\\n        Data points, field to be represented as contours.\\n    interp_mode : 'ilr' (default) or 'cartesian'\\n        Defines how data are interpolated to compute contours.\\n    \"\n    if interp_mode == 'cartesian':\n        (M, invM) = _transform_barycentric_cartesian()\n        coord_points = np.einsum('ik, kj -> ij', M, coordinates)\n    elif interp_mode == 'ilr':\n        coordinates = _replace_zero_coords(coordinates)\n        coord_points = _ilr_transform(coordinates)\n    else:\n        raise ValueError('interp_mode should be cartesian or ilr')\n    (xx, yy) = coord_points[:2]\n    (x_min, x_max) = (xx.min(), xx.max())\n    (y_min, y_max) = (yy.min(), yy.max())\n    n_interp = max(200, int(np.sqrt(len(values))))\n    gr_x = np.linspace(x_min, x_max, n_interp)\n    gr_y = np.linspace(y_min, y_max, n_interp)\n    (grid_x, grid_y) = np.meshgrid(gr_x, gr_y)\n    grid_z = scipy_interp.griddata(coord_points[:2].T, values, (grid_x, grid_y), method='cubic')\n    grid_z_other = scipy_interp.griddata(coord_points[:2].T, values, (grid_x, grid_y), method='nearest')\n    return (grid_z, gr_x, gr_y)",
            "def _compute_grid(coordinates, values, interp_mode='ilr'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Transform data points with Cartesian or ILR mapping, then Compute\\n    interpolation on a regular grid.\\n\\n    Parameters\\n    ==========\\n\\n    coordinates : array-like\\n        Barycentric coordinates of data points.\\n    values : 1-d array-like\\n        Data points, field to be represented as contours.\\n    interp_mode : 'ilr' (default) or 'cartesian'\\n        Defines how data are interpolated to compute contours.\\n    \"\n    if interp_mode == 'cartesian':\n        (M, invM) = _transform_barycentric_cartesian()\n        coord_points = np.einsum('ik, kj -> ij', M, coordinates)\n    elif interp_mode == 'ilr':\n        coordinates = _replace_zero_coords(coordinates)\n        coord_points = _ilr_transform(coordinates)\n    else:\n        raise ValueError('interp_mode should be cartesian or ilr')\n    (xx, yy) = coord_points[:2]\n    (x_min, x_max) = (xx.min(), xx.max())\n    (y_min, y_max) = (yy.min(), yy.max())\n    n_interp = max(200, int(np.sqrt(len(values))))\n    gr_x = np.linspace(x_min, x_max, n_interp)\n    gr_y = np.linspace(y_min, y_max, n_interp)\n    (grid_x, grid_y) = np.meshgrid(gr_x, gr_y)\n    grid_z = scipy_interp.griddata(coord_points[:2].T, values, (grid_x, grid_y), method='cubic')\n    grid_z_other = scipy_interp.griddata(coord_points[:2].T, values, (grid_x, grid_y), method='nearest')\n    return (grid_z, gr_x, gr_y)",
            "def _compute_grid(coordinates, values, interp_mode='ilr'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Transform data points with Cartesian or ILR mapping, then Compute\\n    interpolation on a regular grid.\\n\\n    Parameters\\n    ==========\\n\\n    coordinates : array-like\\n        Barycentric coordinates of data points.\\n    values : 1-d array-like\\n        Data points, field to be represented as contours.\\n    interp_mode : 'ilr' (default) or 'cartesian'\\n        Defines how data are interpolated to compute contours.\\n    \"\n    if interp_mode == 'cartesian':\n        (M, invM) = _transform_barycentric_cartesian()\n        coord_points = np.einsum('ik, kj -> ij', M, coordinates)\n    elif interp_mode == 'ilr':\n        coordinates = _replace_zero_coords(coordinates)\n        coord_points = _ilr_transform(coordinates)\n    else:\n        raise ValueError('interp_mode should be cartesian or ilr')\n    (xx, yy) = coord_points[:2]\n    (x_min, x_max) = (xx.min(), xx.max())\n    (y_min, y_max) = (yy.min(), yy.max())\n    n_interp = max(200, int(np.sqrt(len(values))))\n    gr_x = np.linspace(x_min, x_max, n_interp)\n    gr_y = np.linspace(y_min, y_max, n_interp)\n    (grid_x, grid_y) = np.meshgrid(gr_x, gr_y)\n    grid_z = scipy_interp.griddata(coord_points[:2].T, values, (grid_x, grid_y), method='cubic')\n    grid_z_other = scipy_interp.griddata(coord_points[:2].T, values, (grid_x, grid_y), method='nearest')\n    return (grid_z, gr_x, gr_y)",
            "def _compute_grid(coordinates, values, interp_mode='ilr'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Transform data points with Cartesian or ILR mapping, then Compute\\n    interpolation on a regular grid.\\n\\n    Parameters\\n    ==========\\n\\n    coordinates : array-like\\n        Barycentric coordinates of data points.\\n    values : 1-d array-like\\n        Data points, field to be represented as contours.\\n    interp_mode : 'ilr' (default) or 'cartesian'\\n        Defines how data are interpolated to compute contours.\\n    \"\n    if interp_mode == 'cartesian':\n        (M, invM) = _transform_barycentric_cartesian()\n        coord_points = np.einsum('ik, kj -> ij', M, coordinates)\n    elif interp_mode == 'ilr':\n        coordinates = _replace_zero_coords(coordinates)\n        coord_points = _ilr_transform(coordinates)\n    else:\n        raise ValueError('interp_mode should be cartesian or ilr')\n    (xx, yy) = coord_points[:2]\n    (x_min, x_max) = (xx.min(), xx.max())\n    (y_min, y_max) = (yy.min(), yy.max())\n    n_interp = max(200, int(np.sqrt(len(values))))\n    gr_x = np.linspace(x_min, x_max, n_interp)\n    gr_y = np.linspace(y_min, y_max, n_interp)\n    (grid_x, grid_y) = np.meshgrid(gr_x, gr_y)\n    grid_z = scipy_interp.griddata(coord_points[:2].T, values, (grid_x, grid_y), method='cubic')\n    grid_z_other = scipy_interp.griddata(coord_points[:2].T, values, (grid_x, grid_y), method='nearest')\n    return (grid_z, gr_x, gr_y)"
        ]
    },
    {
        "func_name": "_polygon_area",
        "original": "def _polygon_area(x, y):\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))",
        "mutated": [
            "def _polygon_area(x, y):\n    if False:\n        i = 10\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))",
            "def _polygon_area(x, y):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))",
            "def _polygon_area(x, y):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))",
            "def _polygon_area(x, y):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))",
            "def _polygon_area(x, y):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"
        ]
    },
    {
        "func_name": "_colors",
        "original": "def _colors(ncontours, colormap=None):\n    \"\"\"\n    Return a list of ``ncontours`` colors from the ``colormap`` colorscale.\n    \"\"\"\n    if colormap in clrs.PLOTLY_SCALES.keys():\n        cmap = clrs.PLOTLY_SCALES[colormap]\n    else:\n        raise exceptions.PlotlyError('Colorscale must be a valid Plotly Colorscale.The available colorscale names are {}'.format(clrs.PLOTLY_SCALES.keys()))\n    values = np.linspace(0, 1, ncontours)\n    vals_cmap = np.array([pair[0] for pair in cmap])\n    cols = np.array([pair[1] for pair in cmap])\n    inds = np.searchsorted(vals_cmap, values)\n    if '#' in cols[0]:\n        cols = [clrs.label_rgb(clrs.hex_to_rgb(col)) for col in cols]\n    colors = [cols[0]]\n    for (ind, val) in zip(inds[1:], values[1:]):\n        (val1, val2) = (vals_cmap[ind - 1], vals_cmap[ind])\n        interm = (val - val1) / (val2 - val1)\n        col = clrs.find_intermediate_color(cols[ind - 1], cols[ind], interm, colortype='rgb')\n        colors.append(col)\n    return colors",
        "mutated": [
            "def _colors(ncontours, colormap=None):\n    if False:\n        i = 10\n    '\\n    Return a list of ``ncontours`` colors from the ``colormap`` colorscale.\\n    '\n    if colormap in clrs.PLOTLY_SCALES.keys():\n        cmap = clrs.PLOTLY_SCALES[colormap]\n    else:\n        raise exceptions.PlotlyError('Colorscale must be a valid Plotly Colorscale.The available colorscale names are {}'.format(clrs.PLOTLY_SCALES.keys()))\n    values = np.linspace(0, 1, ncontours)\n    vals_cmap = np.array([pair[0] for pair in cmap])\n    cols = np.array([pair[1] for pair in cmap])\n    inds = np.searchsorted(vals_cmap, values)\n    if '#' in cols[0]:\n        cols = [clrs.label_rgb(clrs.hex_to_rgb(col)) for col in cols]\n    colors = [cols[0]]\n    for (ind, val) in zip(inds[1:], values[1:]):\n        (val1, val2) = (vals_cmap[ind - 1], vals_cmap[ind])\n        interm = (val - val1) / (val2 - val1)\n        col = clrs.find_intermediate_color(cols[ind - 1], cols[ind], interm, colortype='rgb')\n        colors.append(col)\n    return colors",
            "def _colors(ncontours, colormap=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Return a list of ``ncontours`` colors from the ``colormap`` colorscale.\\n    '\n    if colormap in clrs.PLOTLY_SCALES.keys():\n        cmap = clrs.PLOTLY_SCALES[colormap]\n    else:\n        raise exceptions.PlotlyError('Colorscale must be a valid Plotly Colorscale.The available colorscale names are {}'.format(clrs.PLOTLY_SCALES.keys()))\n    values = np.linspace(0, 1, ncontours)\n    vals_cmap = np.array([pair[0] for pair in cmap])\n    cols = np.array([pair[1] for pair in cmap])\n    inds = np.searchsorted(vals_cmap, values)\n    if '#' in cols[0]:\n        cols = [clrs.label_rgb(clrs.hex_to_rgb(col)) for col in cols]\n    colors = [cols[0]]\n    for (ind, val) in zip(inds[1:], values[1:]):\n        (val1, val2) = (vals_cmap[ind - 1], vals_cmap[ind])\n        interm = (val - val1) / (val2 - val1)\n        col = clrs.find_intermediate_color(cols[ind - 1], cols[ind], interm, colortype='rgb')\n        colors.append(col)\n    return colors",
            "def _colors(ncontours, colormap=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Return a list of ``ncontours`` colors from the ``colormap`` colorscale.\\n    '\n    if colormap in clrs.PLOTLY_SCALES.keys():\n        cmap = clrs.PLOTLY_SCALES[colormap]\n    else:\n        raise exceptions.PlotlyError('Colorscale must be a valid Plotly Colorscale.The available colorscale names are {}'.format(clrs.PLOTLY_SCALES.keys()))\n    values = np.linspace(0, 1, ncontours)\n    vals_cmap = np.array([pair[0] for pair in cmap])\n    cols = np.array([pair[1] for pair in cmap])\n    inds = np.searchsorted(vals_cmap, values)\n    if '#' in cols[0]:\n        cols = [clrs.label_rgb(clrs.hex_to_rgb(col)) for col in cols]\n    colors = [cols[0]]\n    for (ind, val) in zip(inds[1:], values[1:]):\n        (val1, val2) = (vals_cmap[ind - 1], vals_cmap[ind])\n        interm = (val - val1) / (val2 - val1)\n        col = clrs.find_intermediate_color(cols[ind - 1], cols[ind], interm, colortype='rgb')\n        colors.append(col)\n    return colors",
            "def _colors(ncontours, colormap=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Return a list of ``ncontours`` colors from the ``colormap`` colorscale.\\n    '\n    if colormap in clrs.PLOTLY_SCALES.keys():\n        cmap = clrs.PLOTLY_SCALES[colormap]\n    else:\n        raise exceptions.PlotlyError('Colorscale must be a valid Plotly Colorscale.The available colorscale names are {}'.format(clrs.PLOTLY_SCALES.keys()))\n    values = np.linspace(0, 1, ncontours)\n    vals_cmap = np.array([pair[0] for pair in cmap])\n    cols = np.array([pair[1] for pair in cmap])\n    inds = np.searchsorted(vals_cmap, values)\n    if '#' in cols[0]:\n        cols = [clrs.label_rgb(clrs.hex_to_rgb(col)) for col in cols]\n    colors = [cols[0]]\n    for (ind, val) in zip(inds[1:], values[1:]):\n        (val1, val2) = (vals_cmap[ind - 1], vals_cmap[ind])\n        interm = (val - val1) / (val2 - val1)\n        col = clrs.find_intermediate_color(cols[ind - 1], cols[ind], interm, colortype='rgb')\n        colors.append(col)\n    return colors",
            "def _colors(ncontours, colormap=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Return a list of ``ncontours`` colors from the ``colormap`` colorscale.\\n    '\n    if colormap in clrs.PLOTLY_SCALES.keys():\n        cmap = clrs.PLOTLY_SCALES[colormap]\n    else:\n        raise exceptions.PlotlyError('Colorscale must be a valid Plotly Colorscale.The available colorscale names are {}'.format(clrs.PLOTLY_SCALES.keys()))\n    values = np.linspace(0, 1, ncontours)\n    vals_cmap = np.array([pair[0] for pair in cmap])\n    cols = np.array([pair[1] for pair in cmap])\n    inds = np.searchsorted(vals_cmap, values)\n    if '#' in cols[0]:\n        cols = [clrs.label_rgb(clrs.hex_to_rgb(col)) for col in cols]\n    colors = [cols[0]]\n    for (ind, val) in zip(inds[1:], values[1:]):\n        (val1, val2) = (vals_cmap[ind - 1], vals_cmap[ind])\n        interm = (val - val1) / (val2 - val1)\n        col = clrs.find_intermediate_color(cols[ind - 1], cols[ind], interm, colortype='rgb')\n        colors.append(col)\n    return colors"
        ]
    },
    {
        "func_name": "_is_invalid_contour",
        "original": "def _is_invalid_contour(x, y):\n    \"\"\"\n    Utility function for _contour_trace\n\n    Contours with an area of the order as 1 pixel are considered spurious.\n    \"\"\"\n    too_small = np.all(np.abs(x - x[0]) < 2) and np.all(np.abs(y - y[0]) < 2)\n    return too_small",
        "mutated": [
            "def _is_invalid_contour(x, y):\n    if False:\n        i = 10\n    '\\n    Utility function for _contour_trace\\n\\n    Contours with an area of the order as 1 pixel are considered spurious.\\n    '\n    too_small = np.all(np.abs(x - x[0]) < 2) and np.all(np.abs(y - y[0]) < 2)\n    return too_small",
            "def _is_invalid_contour(x, y):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Utility function for _contour_trace\\n\\n    Contours with an area of the order as 1 pixel are considered spurious.\\n    '\n    too_small = np.all(np.abs(x - x[0]) < 2) and np.all(np.abs(y - y[0]) < 2)\n    return too_small",
            "def _is_invalid_contour(x, y):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Utility function for _contour_trace\\n\\n    Contours with an area of the order as 1 pixel are considered spurious.\\n    '\n    too_small = np.all(np.abs(x - x[0]) < 2) and np.all(np.abs(y - y[0]) < 2)\n    return too_small",
            "def _is_invalid_contour(x, y):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Utility function for _contour_trace\\n\\n    Contours with an area of the order as 1 pixel are considered spurious.\\n    '\n    too_small = np.all(np.abs(x - x[0]) < 2) and np.all(np.abs(y - y[0]) < 2)\n    return too_small",
            "def _is_invalid_contour(x, y):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Utility function for _contour_trace\\n\\n    Contours with an area of the order as 1 pixel are considered spurious.\\n    '\n    too_small = np.all(np.abs(x - x[0]) < 2) and np.all(np.abs(y - y[0]) < 2)\n    return too_small"
        ]
    },
    {
        "func_name": "_extract_contours",
        "original": "def _extract_contours(im, values, colors):\n    \"\"\"\n    Utility function for _contour_trace.\n\n    In ``im`` only one part of the domain has valid values (corresponding\n    to a subdomain where barycentric coordinates are well defined). When\n    computing contours, we need to assign values outside of this domain.\n    We can choose a value either smaller than all the values inside the\n    valid domain, or larger. This value must be chose with caution so that\n    no spurious contours are added. For example, if the boundary of the valid\n    domain has large values and the outer value is set to a small one, all\n    intermediate contours will be added at the boundary.\n\n    Therefore, we compute the two sets of contours (with an outer value\n    smaller of larger than all values in the valid domain), and choose\n    the value resulting in a smaller total number of contours. There might\n    be a faster way to do this, but it works...\n    \"\"\"\n    mask_nan = np.isnan(im)\n    (im_min, im_max) = (im[np.logical_not(mask_nan)].min(), im[np.logical_not(mask_nan)].max())\n    zz_min = np.copy(im)\n    zz_min[mask_nan] = 2 * im_min\n    zz_max = np.copy(im)\n    zz_max[mask_nan] = 2 * im_max\n    (all_contours1, all_values1, all_areas1, all_colors1) = ([], [], [], [])\n    (all_contours2, all_values2, all_areas2, all_colors2) = ([], [], [], [])\n    for (i, val) in enumerate(values):\n        contour_level1 = measure.find_contours(zz_min, val)\n        contour_level2 = measure.find_contours(zz_max, val)\n        all_contours1.extend(contour_level1)\n        all_contours2.extend(contour_level2)\n        all_values1.extend([val] * len(contour_level1))\n        all_values2.extend([val] * len(contour_level2))\n        all_areas1.extend([_polygon_area(contour.T[1], contour.T[0]) for contour in contour_level1])\n        all_areas2.extend([_polygon_area(contour.T[1], contour.T[0]) for contour in contour_level2])\n        all_colors1.extend([colors[i]] * len(contour_level1))\n        all_colors2.extend([colors[i]] * len(contour_level2))\n    if len(all_contours1) <= len(all_contours2):\n        return (all_contours1, all_values1, all_areas1, all_colors1)\n    else:\n        return (all_contours2, all_values2, all_areas2, all_colors2)",
        "mutated": [
            "def _extract_contours(im, values, colors):\n    if False:\n        i = 10\n    '\\n    Utility function for _contour_trace.\\n\\n    In ``im`` only one part of the domain has valid values (corresponding\\n    to a subdomain where barycentric coordinates are well defined). When\\n    computing contours, we need to assign values outside of this domain.\\n    We can choose a value either smaller than all the values inside the\\n    valid domain, or larger. This value must be chose with caution so that\\n    no spurious contours are added. For example, if the boundary of the valid\\n    domain has large values and the outer value is set to a small one, all\\n    intermediate contours will be added at the boundary.\\n\\n    Therefore, we compute the two sets of contours (with an outer value\\n    smaller of larger than all values in the valid domain), and choose\\n    the value resulting in a smaller total number of contours. There might\\n    be a faster way to do this, but it works...\\n    '\n    mask_nan = np.isnan(im)\n    (im_min, im_max) = (im[np.logical_not(mask_nan)].min(), im[np.logical_not(mask_nan)].max())\n    zz_min = np.copy(im)\n    zz_min[mask_nan] = 2 * im_min\n    zz_max = np.copy(im)\n    zz_max[mask_nan] = 2 * im_max\n    (all_contours1, all_values1, all_areas1, all_colors1) = ([], [], [], [])\n    (all_contours2, all_values2, all_areas2, all_colors2) = ([], [], [], [])\n    for (i, val) in enumerate(values):\n        contour_level1 = measure.find_contours(zz_min, val)\n        contour_level2 = measure.find_contours(zz_max, val)\n        all_contours1.extend(contour_level1)\n        all_contours2.extend(contour_level2)\n        all_values1.extend([val] * len(contour_level1))\n        all_values2.extend([val] * len(contour_level2))\n        all_areas1.extend([_polygon_area(contour.T[1], contour.T[0]) for contour in contour_level1])\n        all_areas2.extend([_polygon_area(contour.T[1], contour.T[0]) for contour in contour_level2])\n        all_colors1.extend([colors[i]] * len(contour_level1))\n        all_colors2.extend([colors[i]] * len(contour_level2))\n    if len(all_contours1) <= len(all_contours2):\n        return (all_contours1, all_values1, all_areas1, all_colors1)\n    else:\n        return (all_contours2, all_values2, all_areas2, all_colors2)",
            "def _extract_contours(im, values, colors):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Utility function for _contour_trace.\\n\\n    In ``im`` only one part of the domain has valid values (corresponding\\n    to a subdomain where barycentric coordinates are well defined). When\\n    computing contours, we need to assign values outside of this domain.\\n    We can choose a value either smaller than all the values inside the\\n    valid domain, or larger. This value must be chose with caution so that\\n    no spurious contours are added. For example, if the boundary of the valid\\n    domain has large values and the outer value is set to a small one, all\\n    intermediate contours will be added at the boundary.\\n\\n    Therefore, we compute the two sets of contours (with an outer value\\n    smaller of larger than all values in the valid domain), and choose\\n    the value resulting in a smaller total number of contours. There might\\n    be a faster way to do this, but it works...\\n    '\n    mask_nan = np.isnan(im)\n    (im_min, im_max) = (im[np.logical_not(mask_nan)].min(), im[np.logical_not(mask_nan)].max())\n    zz_min = np.copy(im)\n    zz_min[mask_nan] = 2 * im_min\n    zz_max = np.copy(im)\n    zz_max[mask_nan] = 2 * im_max\n    (all_contours1, all_values1, all_areas1, all_colors1) = ([], [], [], [])\n    (all_contours2, all_values2, all_areas2, all_colors2) = ([], [], [], [])\n    for (i, val) in enumerate(values):\n        contour_level1 = measure.find_contours(zz_min, val)\n        contour_level2 = measure.find_contours(zz_max, val)\n        all_contours1.extend(contour_level1)\n        all_contours2.extend(contour_level2)\n        all_values1.extend([val] * len(contour_level1))\n        all_values2.extend([val] * len(contour_level2))\n        all_areas1.extend([_polygon_area(contour.T[1], contour.T[0]) for contour in contour_level1])\n        all_areas2.extend([_polygon_area(contour.T[1], contour.T[0]) for contour in contour_level2])\n        all_colors1.extend([colors[i]] * len(contour_level1))\n        all_colors2.extend([colors[i]] * len(contour_level2))\n    if len(all_contours1) <= len(all_contours2):\n        return (all_contours1, all_values1, all_areas1, all_colors1)\n    else:\n        return (all_contours2, all_values2, all_areas2, all_colors2)",
            "def _extract_contours(im, values, colors):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Utility function for _contour_trace.\\n\\n    In ``im`` only one part of the domain has valid values (corresponding\\n    to a subdomain where barycentric coordinates are well defined). When\\n    computing contours, we need to assign values outside of this domain.\\n    We can choose a value either smaller than all the values inside the\\n    valid domain, or larger. This value must be chose with caution so that\\n    no spurious contours are added. For example, if the boundary of the valid\\n    domain has large values and the outer value is set to a small one, all\\n    intermediate contours will be added at the boundary.\\n\\n    Therefore, we compute the two sets of contours (with an outer value\\n    smaller of larger than all values in the valid domain), and choose\\n    the value resulting in a smaller total number of contours. There might\\n    be a faster way to do this, but it works...\\n    '\n    mask_nan = np.isnan(im)\n    (im_min, im_max) = (im[np.logical_not(mask_nan)].min(), im[np.logical_not(mask_nan)].max())\n    zz_min = np.copy(im)\n    zz_min[mask_nan] = 2 * im_min\n    zz_max = np.copy(im)\n    zz_max[mask_nan] = 2 * im_max\n    (all_contours1, all_values1, all_areas1, all_colors1) = ([], [], [], [])\n    (all_contours2, all_values2, all_areas2, all_colors2) = ([], [], [], [])\n    for (i, val) in enumerate(values):\n        contour_level1 = measure.find_contours(zz_min, val)\n        contour_level2 = measure.find_contours(zz_max, val)\n        all_contours1.extend(contour_level1)\n        all_contours2.extend(contour_level2)\n        all_values1.extend([val] * len(contour_level1))\n        all_values2.extend([val] * len(contour_level2))\n        all_areas1.extend([_polygon_area(contour.T[1], contour.T[0]) for contour in contour_level1])\n        all_areas2.extend([_polygon_area(contour.T[1], contour.T[0]) for contour in contour_level2])\n        all_colors1.extend([colors[i]] * len(contour_level1))\n        all_colors2.extend([colors[i]] * len(contour_level2))\n    if len(all_contours1) <= len(all_contours2):\n        return (all_contours1, all_values1, all_areas1, all_colors1)\n    else:\n        return (all_contours2, all_values2, all_areas2, all_colors2)",
            "def _extract_contours(im, values, colors):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Utility function for _contour_trace.\\n\\n    In ``im`` only one part of the domain has valid values (corresponding\\n    to a subdomain where barycentric coordinates are well defined). When\\n    computing contours, we need to assign values outside of this domain.\\n    We can choose a value either smaller than all the values inside the\\n    valid domain, or larger. This value must be chose with caution so that\\n    no spurious contours are added. For example, if the boundary of the valid\\n    domain has large values and the outer value is set to a small one, all\\n    intermediate contours will be added at the boundary.\\n\\n    Therefore, we compute the two sets of contours (with an outer value\\n    smaller of larger than all values in the valid domain), and choose\\n    the value resulting in a smaller total number of contours. There might\\n    be a faster way to do this, but it works...\\n    '\n    mask_nan = np.isnan(im)\n    (im_min, im_max) = (im[np.logical_not(mask_nan)].min(), im[np.logical_not(mask_nan)].max())\n    zz_min = np.copy(im)\n    zz_min[mask_nan] = 2 * im_min\n    zz_max = np.copy(im)\n    zz_max[mask_nan] = 2 * im_max\n    (all_contours1, all_values1, all_areas1, all_colors1) = ([], [], [], [])\n    (all_contours2, all_values2, all_areas2, all_colors2) = ([], [], [], [])\n    for (i, val) in enumerate(values):\n        contour_level1 = measure.find_contours(zz_min, val)\n        contour_level2 = measure.find_contours(zz_max, val)\n        all_contours1.extend(contour_level1)\n        all_contours2.extend(contour_level2)\n        all_values1.extend([val] * len(contour_level1))\n        all_values2.extend([val] * len(contour_level2))\n        all_areas1.extend([_polygon_area(contour.T[1], contour.T[0]) for contour in contour_level1])\n        all_areas2.extend([_polygon_area(contour.T[1], contour.T[0]) for contour in contour_level2])\n        all_colors1.extend([colors[i]] * len(contour_level1))\n        all_colors2.extend([colors[i]] * len(contour_level2))\n    if len(all_contours1) <= len(all_contours2):\n        return (all_contours1, all_values1, all_areas1, all_colors1)\n    else:\n        return (all_contours2, all_values2, all_areas2, all_colors2)",
            "def _extract_contours(im, values, colors):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Utility function for _contour_trace.\\n\\n    In ``im`` only one part of the domain has valid values (corresponding\\n    to a subdomain where barycentric coordinates are well defined). When\\n    computing contours, we need to assign values outside of this domain.\\n    We can choose a value either smaller than all the values inside the\\n    valid domain, or larger. This value must be chose with caution so that\\n    no spurious contours are added. For example, if the boundary of the valid\\n    domain has large values and the outer value is set to a small one, all\\n    intermediate contours will be added at the boundary.\\n\\n    Therefore, we compute the two sets of contours (with an outer value\\n    smaller of larger than all values in the valid domain), and choose\\n    the value resulting in a smaller total number of contours. There might\\n    be a faster way to do this, but it works...\\n    '\n    mask_nan = np.isnan(im)\n    (im_min, im_max) = (im[np.logical_not(mask_nan)].min(), im[np.logical_not(mask_nan)].max())\n    zz_min = np.copy(im)\n    zz_min[mask_nan] = 2 * im_min\n    zz_max = np.copy(im)\n    zz_max[mask_nan] = 2 * im_max\n    (all_contours1, all_values1, all_areas1, all_colors1) = ([], [], [], [])\n    (all_contours2, all_values2, all_areas2, all_colors2) = ([], [], [], [])\n    for (i, val) in enumerate(values):\n        contour_level1 = measure.find_contours(zz_min, val)\n        contour_level2 = measure.find_contours(zz_max, val)\n        all_contours1.extend(contour_level1)\n        all_contours2.extend(contour_level2)\n        all_values1.extend([val] * len(contour_level1))\n        all_values2.extend([val] * len(contour_level2))\n        all_areas1.extend([_polygon_area(contour.T[1], contour.T[0]) for contour in contour_level1])\n        all_areas2.extend([_polygon_area(contour.T[1], contour.T[0]) for contour in contour_level2])\n        all_colors1.extend([colors[i]] * len(contour_level1))\n        all_colors2.extend([colors[i]] * len(contour_level2))\n    if len(all_contours1) <= len(all_contours2):\n        return (all_contours1, all_values1, all_areas1, all_colors1)\n    else:\n        return (all_contours2, all_values2, all_areas2, all_colors2)"
        ]
    },
    {
        "func_name": "_add_outer_contour",
        "original": "def _add_outer_contour(all_contours, all_values, all_areas, all_colors, values, val_outer, v_min, v_max, colors, color_min, color_max):\n    \"\"\"\n    Utility function for _contour_trace\n\n    Adds the background color to fill gaps outside of computed contours.\n\n    To compute the background color, the color of the contour with largest\n    area (``val_outer``) is used. As background color, we choose the next\n    color value in the direction of the extrema of the colormap.\n\n    Then we add information for the outer contour for the different lists\n    provided as arguments.\n\n    A discrete colormap with all used colors is also returned (to be used\n    by colorscale trace).\n    \"\"\"\n    outer_contour = 20 * np.array([[0, 0, 1], [0, 1, 0.5]]).T\n    all_contours = [outer_contour] + all_contours\n    delta_values = np.diff(values)[0]\n    values = np.concatenate(([values[0] - delta_values], values, [values[-1] + delta_values]))\n    colors = np.concatenate(([color_min], colors, [color_max]))\n    index = np.nonzero(values == val_outer)[0][0]\n    if index < len(values) / 2:\n        index -= 1\n    else:\n        index += 1\n    all_colors = [colors[index]] + all_colors\n    all_values = [values[index]] + all_values\n    all_areas = [0] + all_areas\n    used_colors = [color for color in colors if color in all_colors]\n    color_number = len(used_colors)\n    scale = np.linspace(0, 1, color_number + 1)\n    discrete_cm = []\n    for (i, color) in enumerate(used_colors):\n        discrete_cm.append([scale[i], used_colors[i]])\n        discrete_cm.append([scale[i + 1], used_colors[i]])\n    discrete_cm.append([scale[color_number], used_colors[color_number - 1]])\n    return (all_contours, all_values, all_areas, all_colors, discrete_cm)",
        "mutated": [
            "def _add_outer_contour(all_contours, all_values, all_areas, all_colors, values, val_outer, v_min, v_max, colors, color_min, color_max):\n    if False:\n        i = 10\n    '\\n    Utility function for _contour_trace\\n\\n    Adds the background color to fill gaps outside of computed contours.\\n\\n    To compute the background color, the color of the contour with largest\\n    area (``val_outer``) is used. As background color, we choose the next\\n    color value in the direction of the extrema of the colormap.\\n\\n    Then we add information for the outer contour for the different lists\\n    provided as arguments.\\n\\n    A discrete colormap with all used colors is also returned (to be used\\n    by colorscale trace).\\n    '\n    outer_contour = 20 * np.array([[0, 0, 1], [0, 1, 0.5]]).T\n    all_contours = [outer_contour] + all_contours\n    delta_values = np.diff(values)[0]\n    values = np.concatenate(([values[0] - delta_values], values, [values[-1] + delta_values]))\n    colors = np.concatenate(([color_min], colors, [color_max]))\n    index = np.nonzero(values == val_outer)[0][0]\n    if index < len(values) / 2:\n        index -= 1\n    else:\n        index += 1\n    all_colors = [colors[index]] + all_colors\n    all_values = [values[index]] + all_values\n    all_areas = [0] + all_areas\n    used_colors = [color for color in colors if color in all_colors]\n    color_number = len(used_colors)\n    scale = np.linspace(0, 1, color_number + 1)\n    discrete_cm = []\n    for (i, color) in enumerate(used_colors):\n        discrete_cm.append([scale[i], used_colors[i]])\n        discrete_cm.append([scale[i + 1], used_colors[i]])\n    discrete_cm.append([scale[color_number], used_colors[color_number - 1]])\n    return (all_contours, all_values, all_areas, all_colors, discrete_cm)",
            "def _add_outer_contour(all_contours, all_values, all_areas, all_colors, values, val_outer, v_min, v_max, colors, color_min, color_max):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Utility function for _contour_trace\\n\\n    Adds the background color to fill gaps outside of computed contours.\\n\\n    To compute the background color, the color of the contour with largest\\n    area (``val_outer``) is used. As background color, we choose the next\\n    color value in the direction of the extrema of the colormap.\\n\\n    Then we add information for the outer contour for the different lists\\n    provided as arguments.\\n\\n    A discrete colormap with all used colors is also returned (to be used\\n    by colorscale trace).\\n    '\n    outer_contour = 20 * np.array([[0, 0, 1], [0, 1, 0.5]]).T\n    all_contours = [outer_contour] + all_contours\n    delta_values = np.diff(values)[0]\n    values = np.concatenate(([values[0] - delta_values], values, [values[-1] + delta_values]))\n    colors = np.concatenate(([color_min], colors, [color_max]))\n    index = np.nonzero(values == val_outer)[0][0]\n    if index < len(values) / 2:\n        index -= 1\n    else:\n        index += 1\n    all_colors = [colors[index]] + all_colors\n    all_values = [values[index]] + all_values\n    all_areas = [0] + all_areas\n    used_colors = [color for color in colors if color in all_colors]\n    color_number = len(used_colors)\n    scale = np.linspace(0, 1, color_number + 1)\n    discrete_cm = []\n    for (i, color) in enumerate(used_colors):\n        discrete_cm.append([scale[i], used_colors[i]])\n        discrete_cm.append([scale[i + 1], used_colors[i]])\n    discrete_cm.append([scale[color_number], used_colors[color_number - 1]])\n    return (all_contours, all_values, all_areas, all_colors, discrete_cm)",
            "def _add_outer_contour(all_contours, all_values, all_areas, all_colors, values, val_outer, v_min, v_max, colors, color_min, color_max):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Utility function for _contour_trace\\n\\n    Adds the background color to fill gaps outside of computed contours.\\n\\n    To compute the background color, the color of the contour with largest\\n    area (``val_outer``) is used. As background color, we choose the next\\n    color value in the direction of the extrema of the colormap.\\n\\n    Then we add information for the outer contour for the different lists\\n    provided as arguments.\\n\\n    A discrete colormap with all used colors is also returned (to be used\\n    by colorscale trace).\\n    '\n    outer_contour = 20 * np.array([[0, 0, 1], [0, 1, 0.5]]).T\n    all_contours = [outer_contour] + all_contours\n    delta_values = np.diff(values)[0]\n    values = np.concatenate(([values[0] - delta_values], values, [values[-1] + delta_values]))\n    colors = np.concatenate(([color_min], colors, [color_max]))\n    index = np.nonzero(values == val_outer)[0][0]\n    if index < len(values) / 2:\n        index -= 1\n    else:\n        index += 1\n    all_colors = [colors[index]] + all_colors\n    all_values = [values[index]] + all_values\n    all_areas = [0] + all_areas\n    used_colors = [color for color in colors if color in all_colors]\n    color_number = len(used_colors)\n    scale = np.linspace(0, 1, color_number + 1)\n    discrete_cm = []\n    for (i, color) in enumerate(used_colors):\n        discrete_cm.append([scale[i], used_colors[i]])\n        discrete_cm.append([scale[i + 1], used_colors[i]])\n    discrete_cm.append([scale[color_number], used_colors[color_number - 1]])\n    return (all_contours, all_values, all_areas, all_colors, discrete_cm)",
            "def _add_outer_contour(all_contours, all_values, all_areas, all_colors, values, val_outer, v_min, v_max, colors, color_min, color_max):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Utility function for _contour_trace\\n\\n    Adds the background color to fill gaps outside of computed contours.\\n\\n    To compute the background color, the color of the contour with largest\\n    area (``val_outer``) is used. As background color, we choose the next\\n    color value in the direction of the extrema of the colormap.\\n\\n    Then we add information for the outer contour for the different lists\\n    provided as arguments.\\n\\n    A discrete colormap with all used colors is also returned (to be used\\n    by colorscale trace).\\n    '\n    outer_contour = 20 * np.array([[0, 0, 1], [0, 1, 0.5]]).T\n    all_contours = [outer_contour] + all_contours\n    delta_values = np.diff(values)[0]\n    values = np.concatenate(([values[0] - delta_values], values, [values[-1] + delta_values]))\n    colors = np.concatenate(([color_min], colors, [color_max]))\n    index = np.nonzero(values == val_outer)[0][0]\n    if index < len(values) / 2:\n        index -= 1\n    else:\n        index += 1\n    all_colors = [colors[index]] + all_colors\n    all_values = [values[index]] + all_values\n    all_areas = [0] + all_areas\n    used_colors = [color for color in colors if color in all_colors]\n    color_number = len(used_colors)\n    scale = np.linspace(0, 1, color_number + 1)\n    discrete_cm = []\n    for (i, color) in enumerate(used_colors):\n        discrete_cm.append([scale[i], used_colors[i]])\n        discrete_cm.append([scale[i + 1], used_colors[i]])\n    discrete_cm.append([scale[color_number], used_colors[color_number - 1]])\n    return (all_contours, all_values, all_areas, all_colors, discrete_cm)",
            "def _add_outer_contour(all_contours, all_values, all_areas, all_colors, values, val_outer, v_min, v_max, colors, color_min, color_max):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Utility function for _contour_trace\\n\\n    Adds the background color to fill gaps outside of computed contours.\\n\\n    To compute the background color, the color of the contour with largest\\n    area (``val_outer``) is used. As background color, we choose the next\\n    color value in the direction of the extrema of the colormap.\\n\\n    Then we add information for the outer contour for the different lists\\n    provided as arguments.\\n\\n    A discrete colormap with all used colors is also returned (to be used\\n    by colorscale trace).\\n    '\n    outer_contour = 20 * np.array([[0, 0, 1], [0, 1, 0.5]]).T\n    all_contours = [outer_contour] + all_contours\n    delta_values = np.diff(values)[0]\n    values = np.concatenate(([values[0] - delta_values], values, [values[-1] + delta_values]))\n    colors = np.concatenate(([color_min], colors, [color_max]))\n    index = np.nonzero(values == val_outer)[0][0]\n    if index < len(values) / 2:\n        index -= 1\n    else:\n        index += 1\n    all_colors = [colors[index]] + all_colors\n    all_values = [values[index]] + all_values\n    all_areas = [0] + all_areas\n    used_colors = [color for color in colors if color in all_colors]\n    color_number = len(used_colors)\n    scale = np.linspace(0, 1, color_number + 1)\n    discrete_cm = []\n    for (i, color) in enumerate(used_colors):\n        discrete_cm.append([scale[i], used_colors[i]])\n        discrete_cm.append([scale[i + 1], used_colors[i]])\n    discrete_cm.append([scale[color_number], used_colors[color_number - 1]])\n    return (all_contours, all_values, all_areas, all_colors, discrete_cm)"
        ]
    },
    {
        "func_name": "_contour_trace",
        "original": "def _contour_trace(x, y, z, ncontours=None, colorscale='Electric', linecolor='rgb(150,150,150)', interp_mode='llr', coloring=None, v_min=0, v_max=1):\n    \"\"\"\n    Contour trace in Cartesian coordinates.\n\n    Parameters\n    ==========\n\n    x, y : array-like\n        Cartesian coordinates\n    z : array-like\n        Field to be represented as contours.\n    ncontours : int or None\n        Number of contours to display (determined automatically if None).\n    colorscale : None or str (Plotly colormap)\n        colorscale of the contours.\n    linecolor : rgb color\n        Color used for lines. If ``colorscale`` is not None, line colors are\n        determined from ``colorscale`` instead.\n    interp_mode : 'ilr' (default) or 'cartesian'\n        Defines how data are interpolated to compute contours. If 'irl',\n        ILR (Isometric Log-Ratio) of compositional data is performed. If\n        'cartesian', contours are determined in Cartesian space.\n    coloring : None or 'lines'\n        How to display contour. Filled contours if None, lines if ``lines``.\n    vmin, vmax : float\n        Bounds of interval of values used for the colorspace\n\n    Notes\n    =====\n    \"\"\"\n    colors = _colors(ncontours + 2, colorscale)\n    values = np.linspace(v_min, v_max, ncontours + 2)\n    (color_min, color_max) = (colors[0], colors[-1])\n    colors = colors[1:-1]\n    values = values[1:-1]\n    if linecolor is None:\n        linecolor = 'rgb(150, 150, 150)'\n    else:\n        colors = [linecolor] * ncontours\n    (all_contours, all_values, all_areas, all_colors) = _extract_contours(z, values, colors)\n    order = np.argsort(all_areas)[::-1]\n    (all_contours, all_values, all_areas, all_colors, discrete_cm) = _add_outer_contour(all_contours, all_values, all_areas, all_colors, values, all_values[order[0]], v_min, v_max, colors, color_min, color_max)\n    order = np.concatenate(([0], order + 1))\n    traces = []\n    (M, invM) = _transform_barycentric_cartesian()\n    dx = (x.max() - x.min()) / x.size\n    dy = (y.max() - y.min()) / y.size\n    for index in order:\n        (y_contour, x_contour) = all_contours[index].T\n        val = all_values[index]\n        if interp_mode == 'cartesian':\n            bar_coords = np.dot(invM, np.stack((dx * x_contour, dy * y_contour, np.ones(x_contour.shape))))\n        elif interp_mode == 'ilr':\n            bar_coords = _ilr_inverse(np.stack((dx * x_contour + x.min(), dy * y_contour + y.min())))\n        if index == 0:\n            a = np.array([1, 0, 0])\n            b = np.array([0, 1, 0])\n            c = np.array([0, 0, 1])\n        else:\n            (a, b, c) = bar_coords\n        if _is_invalid_contour(x_contour, y_contour):\n            continue\n        _col = all_colors[index] if coloring == 'lines' else linecolor\n        trace = dict(type='scatterternary', a=a, b=b, c=c, mode='lines', line=dict(color=_col, shape='spline', width=1), fill='toself', fillcolor=all_colors[index], showlegend=True, hoverinfo='skip', name='%.3f' % val)\n        if coloring == 'lines':\n            trace['fill'] = None\n        traces.append(trace)\n    return (traces, discrete_cm)",
        "mutated": [
            "def _contour_trace(x, y, z, ncontours=None, colorscale='Electric', linecolor='rgb(150,150,150)', interp_mode='llr', coloring=None, v_min=0, v_max=1):\n    if False:\n        i = 10\n    \"\\n    Contour trace in Cartesian coordinates.\\n\\n    Parameters\\n    ==========\\n\\n    x, y : array-like\\n        Cartesian coordinates\\n    z : array-like\\n        Field to be represented as contours.\\n    ncontours : int or None\\n        Number of contours to display (determined automatically if None).\\n    colorscale : None or str (Plotly colormap)\\n        colorscale of the contours.\\n    linecolor : rgb color\\n        Color used for lines. If ``colorscale`` is not None, line colors are\\n        determined from ``colorscale`` instead.\\n    interp_mode : 'ilr' (default) or 'cartesian'\\n        Defines how data are interpolated to compute contours. If 'irl',\\n        ILR (Isometric Log-Ratio) of compositional data is performed. If\\n        'cartesian', contours are determined in Cartesian space.\\n    coloring : None or 'lines'\\n        How to display contour. Filled contours if None, lines if ``lines``.\\n    vmin, vmax : float\\n        Bounds of interval of values used for the colorspace\\n\\n    Notes\\n    =====\\n    \"\n    colors = _colors(ncontours + 2, colorscale)\n    values = np.linspace(v_min, v_max, ncontours + 2)\n    (color_min, color_max) = (colors[0], colors[-1])\n    colors = colors[1:-1]\n    values = values[1:-1]\n    if linecolor is None:\n        linecolor = 'rgb(150, 150, 150)'\n    else:\n        colors = [linecolor] * ncontours\n    (all_contours, all_values, all_areas, all_colors) = _extract_contours(z, values, colors)\n    order = np.argsort(all_areas)[::-1]\n    (all_contours, all_values, all_areas, all_colors, discrete_cm) = _add_outer_contour(all_contours, all_values, all_areas, all_colors, values, all_values[order[0]], v_min, v_max, colors, color_min, color_max)\n    order = np.concatenate(([0], order + 1))\n    traces = []\n    (M, invM) = _transform_barycentric_cartesian()\n    dx = (x.max() - x.min()) / x.size\n    dy = (y.max() - y.min()) / y.size\n    for index in order:\n        (y_contour, x_contour) = all_contours[index].T\n        val = all_values[index]\n        if interp_mode == 'cartesian':\n            bar_coords = np.dot(invM, np.stack((dx * x_contour, dy * y_contour, np.ones(x_contour.shape))))\n        elif interp_mode == 'ilr':\n            bar_coords = _ilr_inverse(np.stack((dx * x_contour + x.min(), dy * y_contour + y.min())))\n        if index == 0:\n            a = np.array([1, 0, 0])\n            b = np.array([0, 1, 0])\n            c = np.array([0, 0, 1])\n        else:\n            (a, b, c) = bar_coords\n        if _is_invalid_contour(x_contour, y_contour):\n            continue\n        _col = all_colors[index] if coloring == 'lines' else linecolor\n        trace = dict(type='scatterternary', a=a, b=b, c=c, mode='lines', line=dict(color=_col, shape='spline', width=1), fill='toself', fillcolor=all_colors[index], showlegend=True, hoverinfo='skip', name='%.3f' % val)\n        if coloring == 'lines':\n            trace['fill'] = None\n        traces.append(trace)\n    return (traces, discrete_cm)",
            "def _contour_trace(x, y, z, ncontours=None, colorscale='Electric', linecolor='rgb(150,150,150)', interp_mode='llr', coloring=None, v_min=0, v_max=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Contour trace in Cartesian coordinates.\\n\\n    Parameters\\n    ==========\\n\\n    x, y : array-like\\n        Cartesian coordinates\\n    z : array-like\\n        Field to be represented as contours.\\n    ncontours : int or None\\n        Number of contours to display (determined automatically if None).\\n    colorscale : None or str (Plotly colormap)\\n        colorscale of the contours.\\n    linecolor : rgb color\\n        Color used for lines. If ``colorscale`` is not None, line colors are\\n        determined from ``colorscale`` instead.\\n    interp_mode : 'ilr' (default) or 'cartesian'\\n        Defines how data are interpolated to compute contours. If 'irl',\\n        ILR (Isometric Log-Ratio) of compositional data is performed. If\\n        'cartesian', contours are determined in Cartesian space.\\n    coloring : None or 'lines'\\n        How to display contour. Filled contours if None, lines if ``lines``.\\n    vmin, vmax : float\\n        Bounds of interval of values used for the colorspace\\n\\n    Notes\\n    =====\\n    \"\n    colors = _colors(ncontours + 2, colorscale)\n    values = np.linspace(v_min, v_max, ncontours + 2)\n    (color_min, color_max) = (colors[0], colors[-1])\n    colors = colors[1:-1]\n    values = values[1:-1]\n    if linecolor is None:\n        linecolor = 'rgb(150, 150, 150)'\n    else:\n        colors = [linecolor] * ncontours\n    (all_contours, all_values, all_areas, all_colors) = _extract_contours(z, values, colors)\n    order = np.argsort(all_areas)[::-1]\n    (all_contours, all_values, all_areas, all_colors, discrete_cm) = _add_outer_contour(all_contours, all_values, all_areas, all_colors, values, all_values[order[0]], v_min, v_max, colors, color_min, color_max)\n    order = np.concatenate(([0], order + 1))\n    traces = []\n    (M, invM) = _transform_barycentric_cartesian()\n    dx = (x.max() - x.min()) / x.size\n    dy = (y.max() - y.min()) / y.size\n    for index in order:\n        (y_contour, x_contour) = all_contours[index].T\n        val = all_values[index]\n        if interp_mode == 'cartesian':\n            bar_coords = np.dot(invM, np.stack((dx * x_contour, dy * y_contour, np.ones(x_contour.shape))))\n        elif interp_mode == 'ilr':\n            bar_coords = _ilr_inverse(np.stack((dx * x_contour + x.min(), dy * y_contour + y.min())))\n        if index == 0:\n            a = np.array([1, 0, 0])\n            b = np.array([0, 1, 0])\n            c = np.array([0, 0, 1])\n        else:\n            (a, b, c) = bar_coords\n        if _is_invalid_contour(x_contour, y_contour):\n            continue\n        _col = all_colors[index] if coloring == 'lines' else linecolor\n        trace = dict(type='scatterternary', a=a, b=b, c=c, mode='lines', line=dict(color=_col, shape='spline', width=1), fill='toself', fillcolor=all_colors[index], showlegend=True, hoverinfo='skip', name='%.3f' % val)\n        if coloring == 'lines':\n            trace['fill'] = None\n        traces.append(trace)\n    return (traces, discrete_cm)",
            "def _contour_trace(x, y, z, ncontours=None, colorscale='Electric', linecolor='rgb(150,150,150)', interp_mode='llr', coloring=None, v_min=0, v_max=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Contour trace in Cartesian coordinates.\\n\\n    Parameters\\n    ==========\\n\\n    x, y : array-like\\n        Cartesian coordinates\\n    z : array-like\\n        Field to be represented as contours.\\n    ncontours : int or None\\n        Number of contours to display (determined automatically if None).\\n    colorscale : None or str (Plotly colormap)\\n        colorscale of the contours.\\n    linecolor : rgb color\\n        Color used for lines. If ``colorscale`` is not None, line colors are\\n        determined from ``colorscale`` instead.\\n    interp_mode : 'ilr' (default) or 'cartesian'\\n        Defines how data are interpolated to compute contours. If 'irl',\\n        ILR (Isometric Log-Ratio) of compositional data is performed. If\\n        'cartesian', contours are determined in Cartesian space.\\n    coloring : None or 'lines'\\n        How to display contour. Filled contours if None, lines if ``lines``.\\n    vmin, vmax : float\\n        Bounds of interval of values used for the colorspace\\n\\n    Notes\\n    =====\\n    \"\n    colors = _colors(ncontours + 2, colorscale)\n    values = np.linspace(v_min, v_max, ncontours + 2)\n    (color_min, color_max) = (colors[0], colors[-1])\n    colors = colors[1:-1]\n    values = values[1:-1]\n    if linecolor is None:\n        linecolor = 'rgb(150, 150, 150)'\n    else:\n        colors = [linecolor] * ncontours\n    (all_contours, all_values, all_areas, all_colors) = _extract_contours(z, values, colors)\n    order = np.argsort(all_areas)[::-1]\n    (all_contours, all_values, all_areas, all_colors, discrete_cm) = _add_outer_contour(all_contours, all_values, all_areas, all_colors, values, all_values[order[0]], v_min, v_max, colors, color_min, color_max)\n    order = np.concatenate(([0], order + 1))\n    traces = []\n    (M, invM) = _transform_barycentric_cartesian()\n    dx = (x.max() - x.min()) / x.size\n    dy = (y.max() - y.min()) / y.size\n    for index in order:\n        (y_contour, x_contour) = all_contours[index].T\n        val = all_values[index]\n        if interp_mode == 'cartesian':\n            bar_coords = np.dot(invM, np.stack((dx * x_contour, dy * y_contour, np.ones(x_contour.shape))))\n        elif interp_mode == 'ilr':\n            bar_coords = _ilr_inverse(np.stack((dx * x_contour + x.min(), dy * y_contour + y.min())))\n        if index == 0:\n            a = np.array([1, 0, 0])\n            b = np.array([0, 1, 0])\n            c = np.array([0, 0, 1])\n        else:\n            (a, b, c) = bar_coords\n        if _is_invalid_contour(x_contour, y_contour):\n            continue\n        _col = all_colors[index] if coloring == 'lines' else linecolor\n        trace = dict(type='scatterternary', a=a, b=b, c=c, mode='lines', line=dict(color=_col, shape='spline', width=1), fill='toself', fillcolor=all_colors[index], showlegend=True, hoverinfo='skip', name='%.3f' % val)\n        if coloring == 'lines':\n            trace['fill'] = None\n        traces.append(trace)\n    return (traces, discrete_cm)",
            "def _contour_trace(x, y, z, ncontours=None, colorscale='Electric', linecolor='rgb(150,150,150)', interp_mode='llr', coloring=None, v_min=0, v_max=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Contour trace in Cartesian coordinates.\\n\\n    Parameters\\n    ==========\\n\\n    x, y : array-like\\n        Cartesian coordinates\\n    z : array-like\\n        Field to be represented as contours.\\n    ncontours : int or None\\n        Number of contours to display (determined automatically if None).\\n    colorscale : None or str (Plotly colormap)\\n        colorscale of the contours.\\n    linecolor : rgb color\\n        Color used for lines. If ``colorscale`` is not None, line colors are\\n        determined from ``colorscale`` instead.\\n    interp_mode : 'ilr' (default) or 'cartesian'\\n        Defines how data are interpolated to compute contours. If 'irl',\\n        ILR (Isometric Log-Ratio) of compositional data is performed. If\\n        'cartesian', contours are determined in Cartesian space.\\n    coloring : None or 'lines'\\n        How to display contour. Filled contours if None, lines if ``lines``.\\n    vmin, vmax : float\\n        Bounds of interval of values used for the colorspace\\n\\n    Notes\\n    =====\\n    \"\n    colors = _colors(ncontours + 2, colorscale)\n    values = np.linspace(v_min, v_max, ncontours + 2)\n    (color_min, color_max) = (colors[0], colors[-1])\n    colors = colors[1:-1]\n    values = values[1:-1]\n    if linecolor is None:\n        linecolor = 'rgb(150, 150, 150)'\n    else:\n        colors = [linecolor] * ncontours\n    (all_contours, all_values, all_areas, all_colors) = _extract_contours(z, values, colors)\n    order = np.argsort(all_areas)[::-1]\n    (all_contours, all_values, all_areas, all_colors, discrete_cm) = _add_outer_contour(all_contours, all_values, all_areas, all_colors, values, all_values[order[0]], v_min, v_max, colors, color_min, color_max)\n    order = np.concatenate(([0], order + 1))\n    traces = []\n    (M, invM) = _transform_barycentric_cartesian()\n    dx = (x.max() - x.min()) / x.size\n    dy = (y.max() - y.min()) / y.size\n    for index in order:\n        (y_contour, x_contour) = all_contours[index].T\n        val = all_values[index]\n        if interp_mode == 'cartesian':\n            bar_coords = np.dot(invM, np.stack((dx * x_contour, dy * y_contour, np.ones(x_contour.shape))))\n        elif interp_mode == 'ilr':\n            bar_coords = _ilr_inverse(np.stack((dx * x_contour + x.min(), dy * y_contour + y.min())))\n        if index == 0:\n            a = np.array([1, 0, 0])\n            b = np.array([0, 1, 0])\n            c = np.array([0, 0, 1])\n        else:\n            (a, b, c) = bar_coords\n        if _is_invalid_contour(x_contour, y_contour):\n            continue\n        _col = all_colors[index] if coloring == 'lines' else linecolor\n        trace = dict(type='scatterternary', a=a, b=b, c=c, mode='lines', line=dict(color=_col, shape='spline', width=1), fill='toself', fillcolor=all_colors[index], showlegend=True, hoverinfo='skip', name='%.3f' % val)\n        if coloring == 'lines':\n            trace['fill'] = None\n        traces.append(trace)\n    return (traces, discrete_cm)",
            "def _contour_trace(x, y, z, ncontours=None, colorscale='Electric', linecolor='rgb(150,150,150)', interp_mode='llr', coloring=None, v_min=0, v_max=1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Contour trace in Cartesian coordinates.\\n\\n    Parameters\\n    ==========\\n\\n    x, y : array-like\\n        Cartesian coordinates\\n    z : array-like\\n        Field to be represented as contours.\\n    ncontours : int or None\\n        Number of contours to display (determined automatically if None).\\n    colorscale : None or str (Plotly colormap)\\n        colorscale of the contours.\\n    linecolor : rgb color\\n        Color used for lines. If ``colorscale`` is not None, line colors are\\n        determined from ``colorscale`` instead.\\n    interp_mode : 'ilr' (default) or 'cartesian'\\n        Defines how data are interpolated to compute contours. If 'irl',\\n        ILR (Isometric Log-Ratio) of compositional data is performed. If\\n        'cartesian', contours are determined in Cartesian space.\\n    coloring : None or 'lines'\\n        How to display contour. Filled contours if None, lines if ``lines``.\\n    vmin, vmax : float\\n        Bounds of interval of values used for the colorspace\\n\\n    Notes\\n    =====\\n    \"\n    colors = _colors(ncontours + 2, colorscale)\n    values = np.linspace(v_min, v_max, ncontours + 2)\n    (color_min, color_max) = (colors[0], colors[-1])\n    colors = colors[1:-1]\n    values = values[1:-1]\n    if linecolor is None:\n        linecolor = 'rgb(150, 150, 150)'\n    else:\n        colors = [linecolor] * ncontours\n    (all_contours, all_values, all_areas, all_colors) = _extract_contours(z, values, colors)\n    order = np.argsort(all_areas)[::-1]\n    (all_contours, all_values, all_areas, all_colors, discrete_cm) = _add_outer_contour(all_contours, all_values, all_areas, all_colors, values, all_values[order[0]], v_min, v_max, colors, color_min, color_max)\n    order = np.concatenate(([0], order + 1))\n    traces = []\n    (M, invM) = _transform_barycentric_cartesian()\n    dx = (x.max() - x.min()) / x.size\n    dy = (y.max() - y.min()) / y.size\n    for index in order:\n        (y_contour, x_contour) = all_contours[index].T\n        val = all_values[index]\n        if interp_mode == 'cartesian':\n            bar_coords = np.dot(invM, np.stack((dx * x_contour, dy * y_contour, np.ones(x_contour.shape))))\n        elif interp_mode == 'ilr':\n            bar_coords = _ilr_inverse(np.stack((dx * x_contour + x.min(), dy * y_contour + y.min())))\n        if index == 0:\n            a = np.array([1, 0, 0])\n            b = np.array([0, 1, 0])\n            c = np.array([0, 0, 1])\n        else:\n            (a, b, c) = bar_coords\n        if _is_invalid_contour(x_contour, y_contour):\n            continue\n        _col = all_colors[index] if coloring == 'lines' else linecolor\n        trace = dict(type='scatterternary', a=a, b=b, c=c, mode='lines', line=dict(color=_col, shape='spline', width=1), fill='toself', fillcolor=all_colors[index], showlegend=True, hoverinfo='skip', name='%.3f' % val)\n        if coloring == 'lines':\n            trace['fill'] = None\n        traces.append(trace)\n    return (traces, discrete_cm)"
        ]
    },
    {
        "func_name": "create_ternary_contour",
        "original": "def create_ternary_contour(coordinates, values, pole_labels=['a', 'b', 'c'], width=500, height=500, ncontours=None, showscale=False, coloring=None, colorscale='Bluered', linecolor=None, title=None, interp_mode='ilr', showmarkers=False):\n    \"\"\"\n    Ternary contour plot.\n\n    Parameters\n    ----------\n\n    coordinates : list or ndarray\n        Barycentric coordinates of shape (2, N) or (3, N) where N is the\n        number of data points. The sum of the 3 coordinates is expected\n        to be 1 for all data points.\n    values : array-like\n        Data points of field to be represented as contours.\n    pole_labels : str, default ['a', 'b', 'c']\n        Names of the three poles of the triangle.\n    width : int\n        Figure width.\n    height : int\n        Figure height.\n    ncontours : int or None\n        Number of contours to display (determined automatically if None).\n    showscale : bool, default False\n        If True, a colorbar showing the color scale is displayed.\n    coloring : None or 'lines'\n        How to display contour. Filled contours if None, lines if ``lines``.\n    colorscale : None or str (Plotly colormap)\n        colorscale of the contours.\n    linecolor : None or rgb color\n        Color used for lines. ``colorscale`` has to be set to None, otherwise\n        line colors are determined from ``colorscale``.\n    title : str or None\n        Title of ternary plot\n    interp_mode : 'ilr' (default) or 'cartesian'\n        Defines how data are interpolated to compute contours. If 'irl',\n        ILR (Isometric Log-Ratio) of compositional data is performed. If\n        'cartesian', contours are determined in Cartesian space.\n    showmarkers : bool, default False\n        If True, markers corresponding to input compositional points are\n        superimposed on contours, using the same colorscale.\n\n    Examples\n    ========\n\n    Example 1: ternary contour plot with filled contours\n\n    >>> import plotly.figure_factory as ff\n    >>> import numpy as np\n    >>> # Define coordinates\n    >>> a, b = np.mgrid[0:1:20j, 0:1:20j]\n    >>> mask = a + b <= 1\n    >>> a = a[mask].ravel()\n    >>> b = b[mask].ravel()\n    >>> c = 1 - a - b\n    >>> # Values to be displayed as contours\n    >>> z = a * b * c\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z)\n    >>> fig.show()\n\n    It is also possible to give only two barycentric coordinates for each\n    point, since the sum of the three coordinates is one:\n\n    >>> fig = ff.create_ternary_contour(np.stack((a, b)), z)\n\n\n    Example 2: ternary contour plot with line contours\n\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, coloring='lines')\n\n    Example 3: customize number of contours\n\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, ncontours=8)\n\n    Example 4: superimpose contour plot and original data as markers\n\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, coloring='lines',\n    ...                                 showmarkers=True)\n\n    Example 5: customize title and pole labels\n\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z,\n    ...                                 title='Ternary plot',\n    ...                                 pole_labels=['clay', 'quartz', 'fledspar'])\n    \"\"\"\n    if scipy_interp is None:\n        raise ImportError('    The create_ternary_contour figure factory requires the scipy package')\n    sk_measure = optional_imports.get_module('skimage')\n    if sk_measure is None:\n        raise ImportError('    The create_ternary_contour figure factory requires the scikit-image\\n    package')\n    if colorscale is None:\n        showscale = False\n    if ncontours is None:\n        ncontours = 5\n    coordinates = _prepare_barycentric_coord(coordinates)\n    (v_min, v_max) = (values.min(), values.max())\n    (grid_z, gr_x, gr_y) = _compute_grid(coordinates, values, interp_mode=interp_mode)\n    layout = _ternary_layout(pole_labels=pole_labels, width=width, height=height, title=title)\n    (contour_trace, discrete_cm) = _contour_trace(gr_x, gr_y, grid_z, ncontours=ncontours, colorscale=colorscale, linecolor=linecolor, interp_mode=interp_mode, coloring=coloring, v_min=v_min, v_max=v_max)\n    fig = go.Figure(data=contour_trace, layout=layout)\n    opacity = 1 if showmarkers else 0\n    (a, b, c) = coordinates\n    hovertemplate = pole_labels[0] + ': %{a:.3f}<br>' + pole_labels[1] + ': %{b:.3f}<br>' + pole_labels[2] + ': %{c:.3f}<br>z: %{marker.color:.3f}<extra></extra>'\n    fig.add_scatterternary(a=a, b=b, c=c, mode='markers', marker={'color': values, 'colorscale': colorscale, 'line': {'color': 'rgb(120, 120, 120)', 'width': int(coloring != 'lines')}}, opacity=opacity, hovertemplate=hovertemplate)\n    if showscale:\n        if not showmarkers:\n            colorscale = discrete_cm\n        colorbar = dict({'type': 'scatterternary', 'a': [None], 'b': [None], 'c': [None], 'marker': {'cmin': values.min(), 'cmax': values.max(), 'colorscale': colorscale, 'showscale': True}, 'mode': 'markers'})\n        fig.add_trace(colorbar)\n    return fig",
        "mutated": [
            "def create_ternary_contour(coordinates, values, pole_labels=['a', 'b', 'c'], width=500, height=500, ncontours=None, showscale=False, coloring=None, colorscale='Bluered', linecolor=None, title=None, interp_mode='ilr', showmarkers=False):\n    if False:\n        i = 10\n    \"\\n    Ternary contour plot.\\n\\n    Parameters\\n    ----------\\n\\n    coordinates : list or ndarray\\n        Barycentric coordinates of shape (2, N) or (3, N) where N is the\\n        number of data points. The sum of the 3 coordinates is expected\\n        to be 1 for all data points.\\n    values : array-like\\n        Data points of field to be represented as contours.\\n    pole_labels : str, default ['a', 'b', 'c']\\n        Names of the three poles of the triangle.\\n    width : int\\n        Figure width.\\n    height : int\\n        Figure height.\\n    ncontours : int or None\\n        Number of contours to display (determined automatically if None).\\n    showscale : bool, default False\\n        If True, a colorbar showing the color scale is displayed.\\n    coloring : None or 'lines'\\n        How to display contour. Filled contours if None, lines if ``lines``.\\n    colorscale : None or str (Plotly colormap)\\n        colorscale of the contours.\\n    linecolor : None or rgb color\\n        Color used for lines. ``colorscale`` has to be set to None, otherwise\\n        line colors are determined from ``colorscale``.\\n    title : str or None\\n        Title of ternary plot\\n    interp_mode : 'ilr' (default) or 'cartesian'\\n        Defines how data are interpolated to compute contours. If 'irl',\\n        ILR (Isometric Log-Ratio) of compositional data is performed. If\\n        'cartesian', contours are determined in Cartesian space.\\n    showmarkers : bool, default False\\n        If True, markers corresponding to input compositional points are\\n        superimposed on contours, using the same colorscale.\\n\\n    Examples\\n    ========\\n\\n    Example 1: ternary contour plot with filled contours\\n\\n    >>> import plotly.figure_factory as ff\\n    >>> import numpy as np\\n    >>> # Define coordinates\\n    >>> a, b = np.mgrid[0:1:20j, 0:1:20j]\\n    >>> mask = a + b <= 1\\n    >>> a = a[mask].ravel()\\n    >>> b = b[mask].ravel()\\n    >>> c = 1 - a - b\\n    >>> # Values to be displayed as contours\\n    >>> z = a * b * c\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z)\\n    >>> fig.show()\\n\\n    It is also possible to give only two barycentric coordinates for each\\n    point, since the sum of the three coordinates is one:\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b)), z)\\n\\n\\n    Example 2: ternary contour plot with line contours\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, coloring='lines')\\n\\n    Example 3: customize number of contours\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, ncontours=8)\\n\\n    Example 4: superimpose contour plot and original data as markers\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, coloring='lines',\\n    ...                                 showmarkers=True)\\n\\n    Example 5: customize title and pole labels\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z,\\n    ...                                 title='Ternary plot',\\n    ...                                 pole_labels=['clay', 'quartz', 'fledspar'])\\n    \"\n    if scipy_interp is None:\n        raise ImportError('    The create_ternary_contour figure factory requires the scipy package')\n    sk_measure = optional_imports.get_module('skimage')\n    if sk_measure is None:\n        raise ImportError('    The create_ternary_contour figure factory requires the scikit-image\\n    package')\n    if colorscale is None:\n        showscale = False\n    if ncontours is None:\n        ncontours = 5\n    coordinates = _prepare_barycentric_coord(coordinates)\n    (v_min, v_max) = (values.min(), values.max())\n    (grid_z, gr_x, gr_y) = _compute_grid(coordinates, values, interp_mode=interp_mode)\n    layout = _ternary_layout(pole_labels=pole_labels, width=width, height=height, title=title)\n    (contour_trace, discrete_cm) = _contour_trace(gr_x, gr_y, grid_z, ncontours=ncontours, colorscale=colorscale, linecolor=linecolor, interp_mode=interp_mode, coloring=coloring, v_min=v_min, v_max=v_max)\n    fig = go.Figure(data=contour_trace, layout=layout)\n    opacity = 1 if showmarkers else 0\n    (a, b, c) = coordinates\n    hovertemplate = pole_labels[0] + ': %{a:.3f}<br>' + pole_labels[1] + ': %{b:.3f}<br>' + pole_labels[2] + ': %{c:.3f}<br>z: %{marker.color:.3f}<extra></extra>'\n    fig.add_scatterternary(a=a, b=b, c=c, mode='markers', marker={'color': values, 'colorscale': colorscale, 'line': {'color': 'rgb(120, 120, 120)', 'width': int(coloring != 'lines')}}, opacity=opacity, hovertemplate=hovertemplate)\n    if showscale:\n        if not showmarkers:\n            colorscale = discrete_cm\n        colorbar = dict({'type': 'scatterternary', 'a': [None], 'b': [None], 'c': [None], 'marker': {'cmin': values.min(), 'cmax': values.max(), 'colorscale': colorscale, 'showscale': True}, 'mode': 'markers'})\n        fig.add_trace(colorbar)\n    return fig",
            "def create_ternary_contour(coordinates, values, pole_labels=['a', 'b', 'c'], width=500, height=500, ncontours=None, showscale=False, coloring=None, colorscale='Bluered', linecolor=None, title=None, interp_mode='ilr', showmarkers=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Ternary contour plot.\\n\\n    Parameters\\n    ----------\\n\\n    coordinates : list or ndarray\\n        Barycentric coordinates of shape (2, N) or (3, N) where N is the\\n        number of data points. The sum of the 3 coordinates is expected\\n        to be 1 for all data points.\\n    values : array-like\\n        Data points of field to be represented as contours.\\n    pole_labels : str, default ['a', 'b', 'c']\\n        Names of the three poles of the triangle.\\n    width : int\\n        Figure width.\\n    height : int\\n        Figure height.\\n    ncontours : int or None\\n        Number of contours to display (determined automatically if None).\\n    showscale : bool, default False\\n        If True, a colorbar showing the color scale is displayed.\\n    coloring : None or 'lines'\\n        How to display contour. Filled contours if None, lines if ``lines``.\\n    colorscale : None or str (Plotly colormap)\\n        colorscale of the contours.\\n    linecolor : None or rgb color\\n        Color used for lines. ``colorscale`` has to be set to None, otherwise\\n        line colors are determined from ``colorscale``.\\n    title : str or None\\n        Title of ternary plot\\n    interp_mode : 'ilr' (default) or 'cartesian'\\n        Defines how data are interpolated to compute contours. If 'irl',\\n        ILR (Isometric Log-Ratio) of compositional data is performed. If\\n        'cartesian', contours are determined in Cartesian space.\\n    showmarkers : bool, default False\\n        If True, markers corresponding to input compositional points are\\n        superimposed on contours, using the same colorscale.\\n\\n    Examples\\n    ========\\n\\n    Example 1: ternary contour plot with filled contours\\n\\n    >>> import plotly.figure_factory as ff\\n    >>> import numpy as np\\n    >>> # Define coordinates\\n    >>> a, b = np.mgrid[0:1:20j, 0:1:20j]\\n    >>> mask = a + b <= 1\\n    >>> a = a[mask].ravel()\\n    >>> b = b[mask].ravel()\\n    >>> c = 1 - a - b\\n    >>> # Values to be displayed as contours\\n    >>> z = a * b * c\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z)\\n    >>> fig.show()\\n\\n    It is also possible to give only two barycentric coordinates for each\\n    point, since the sum of the three coordinates is one:\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b)), z)\\n\\n\\n    Example 2: ternary contour plot with line contours\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, coloring='lines')\\n\\n    Example 3: customize number of contours\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, ncontours=8)\\n\\n    Example 4: superimpose contour plot and original data as markers\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, coloring='lines',\\n    ...                                 showmarkers=True)\\n\\n    Example 5: customize title and pole labels\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z,\\n    ...                                 title='Ternary plot',\\n    ...                                 pole_labels=['clay', 'quartz', 'fledspar'])\\n    \"\n    if scipy_interp is None:\n        raise ImportError('    The create_ternary_contour figure factory requires the scipy package')\n    sk_measure = optional_imports.get_module('skimage')\n    if sk_measure is None:\n        raise ImportError('    The create_ternary_contour figure factory requires the scikit-image\\n    package')\n    if colorscale is None:\n        showscale = False\n    if ncontours is None:\n        ncontours = 5\n    coordinates = _prepare_barycentric_coord(coordinates)\n    (v_min, v_max) = (values.min(), values.max())\n    (grid_z, gr_x, gr_y) = _compute_grid(coordinates, values, interp_mode=interp_mode)\n    layout = _ternary_layout(pole_labels=pole_labels, width=width, height=height, title=title)\n    (contour_trace, discrete_cm) = _contour_trace(gr_x, gr_y, grid_z, ncontours=ncontours, colorscale=colorscale, linecolor=linecolor, interp_mode=interp_mode, coloring=coloring, v_min=v_min, v_max=v_max)\n    fig = go.Figure(data=contour_trace, layout=layout)\n    opacity = 1 if showmarkers else 0\n    (a, b, c) = coordinates\n    hovertemplate = pole_labels[0] + ': %{a:.3f}<br>' + pole_labels[1] + ': %{b:.3f}<br>' + pole_labels[2] + ': %{c:.3f}<br>z: %{marker.color:.3f}<extra></extra>'\n    fig.add_scatterternary(a=a, b=b, c=c, mode='markers', marker={'color': values, 'colorscale': colorscale, 'line': {'color': 'rgb(120, 120, 120)', 'width': int(coloring != 'lines')}}, opacity=opacity, hovertemplate=hovertemplate)\n    if showscale:\n        if not showmarkers:\n            colorscale = discrete_cm\n        colorbar = dict({'type': 'scatterternary', 'a': [None], 'b': [None], 'c': [None], 'marker': {'cmin': values.min(), 'cmax': values.max(), 'colorscale': colorscale, 'showscale': True}, 'mode': 'markers'})\n        fig.add_trace(colorbar)\n    return fig",
            "def create_ternary_contour(coordinates, values, pole_labels=['a', 'b', 'c'], width=500, height=500, ncontours=None, showscale=False, coloring=None, colorscale='Bluered', linecolor=None, title=None, interp_mode='ilr', showmarkers=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Ternary contour plot.\\n\\n    Parameters\\n    ----------\\n\\n    coordinates : list or ndarray\\n        Barycentric coordinates of shape (2, N) or (3, N) where N is the\\n        number of data points. The sum of the 3 coordinates is expected\\n        to be 1 for all data points.\\n    values : array-like\\n        Data points of field to be represented as contours.\\n    pole_labels : str, default ['a', 'b', 'c']\\n        Names of the three poles of the triangle.\\n    width : int\\n        Figure width.\\n    height : int\\n        Figure height.\\n    ncontours : int or None\\n        Number of contours to display (determined automatically if None).\\n    showscale : bool, default False\\n        If True, a colorbar showing the color scale is displayed.\\n    coloring : None or 'lines'\\n        How to display contour. Filled contours if None, lines if ``lines``.\\n    colorscale : None or str (Plotly colormap)\\n        colorscale of the contours.\\n    linecolor : None or rgb color\\n        Color used for lines. ``colorscale`` has to be set to None, otherwise\\n        line colors are determined from ``colorscale``.\\n    title : str or None\\n        Title of ternary plot\\n    interp_mode : 'ilr' (default) or 'cartesian'\\n        Defines how data are interpolated to compute contours. If 'irl',\\n        ILR (Isometric Log-Ratio) of compositional data is performed. If\\n        'cartesian', contours are determined in Cartesian space.\\n    showmarkers : bool, default False\\n        If True, markers corresponding to input compositional points are\\n        superimposed on contours, using the same colorscale.\\n\\n    Examples\\n    ========\\n\\n    Example 1: ternary contour plot with filled contours\\n\\n    >>> import plotly.figure_factory as ff\\n    >>> import numpy as np\\n    >>> # Define coordinates\\n    >>> a, b = np.mgrid[0:1:20j, 0:1:20j]\\n    >>> mask = a + b <= 1\\n    >>> a = a[mask].ravel()\\n    >>> b = b[mask].ravel()\\n    >>> c = 1 - a - b\\n    >>> # Values to be displayed as contours\\n    >>> z = a * b * c\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z)\\n    >>> fig.show()\\n\\n    It is also possible to give only two barycentric coordinates for each\\n    point, since the sum of the three coordinates is one:\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b)), z)\\n\\n\\n    Example 2: ternary contour plot with line contours\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, coloring='lines')\\n\\n    Example 3: customize number of contours\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, ncontours=8)\\n\\n    Example 4: superimpose contour plot and original data as markers\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, coloring='lines',\\n    ...                                 showmarkers=True)\\n\\n    Example 5: customize title and pole labels\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z,\\n    ...                                 title='Ternary plot',\\n    ...                                 pole_labels=['clay', 'quartz', 'fledspar'])\\n    \"\n    if scipy_interp is None:\n        raise ImportError('    The create_ternary_contour figure factory requires the scipy package')\n    sk_measure = optional_imports.get_module('skimage')\n    if sk_measure is None:\n        raise ImportError('    The create_ternary_contour figure factory requires the scikit-image\\n    package')\n    if colorscale is None:\n        showscale = False\n    if ncontours is None:\n        ncontours = 5\n    coordinates = _prepare_barycentric_coord(coordinates)\n    (v_min, v_max) = (values.min(), values.max())\n    (grid_z, gr_x, gr_y) = _compute_grid(coordinates, values, interp_mode=interp_mode)\n    layout = _ternary_layout(pole_labels=pole_labels, width=width, height=height, title=title)\n    (contour_trace, discrete_cm) = _contour_trace(gr_x, gr_y, grid_z, ncontours=ncontours, colorscale=colorscale, linecolor=linecolor, interp_mode=interp_mode, coloring=coloring, v_min=v_min, v_max=v_max)\n    fig = go.Figure(data=contour_trace, layout=layout)\n    opacity = 1 if showmarkers else 0\n    (a, b, c) = coordinates\n    hovertemplate = pole_labels[0] + ': %{a:.3f}<br>' + pole_labels[1] + ': %{b:.3f}<br>' + pole_labels[2] + ': %{c:.3f}<br>z: %{marker.color:.3f}<extra></extra>'\n    fig.add_scatterternary(a=a, b=b, c=c, mode='markers', marker={'color': values, 'colorscale': colorscale, 'line': {'color': 'rgb(120, 120, 120)', 'width': int(coloring != 'lines')}}, opacity=opacity, hovertemplate=hovertemplate)\n    if showscale:\n        if not showmarkers:\n            colorscale = discrete_cm\n        colorbar = dict({'type': 'scatterternary', 'a': [None], 'b': [None], 'c': [None], 'marker': {'cmin': values.min(), 'cmax': values.max(), 'colorscale': colorscale, 'showscale': True}, 'mode': 'markers'})\n        fig.add_trace(colorbar)\n    return fig",
            "def create_ternary_contour(coordinates, values, pole_labels=['a', 'b', 'c'], width=500, height=500, ncontours=None, showscale=False, coloring=None, colorscale='Bluered', linecolor=None, title=None, interp_mode='ilr', showmarkers=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Ternary contour plot.\\n\\n    Parameters\\n    ----------\\n\\n    coordinates : list or ndarray\\n        Barycentric coordinates of shape (2, N) or (3, N) where N is the\\n        number of data points. The sum of the 3 coordinates is expected\\n        to be 1 for all data points.\\n    values : array-like\\n        Data points of field to be represented as contours.\\n    pole_labels : str, default ['a', 'b', 'c']\\n        Names of the three poles of the triangle.\\n    width : int\\n        Figure width.\\n    height : int\\n        Figure height.\\n    ncontours : int or None\\n        Number of contours to display (determined automatically if None).\\n    showscale : bool, default False\\n        If True, a colorbar showing the color scale is displayed.\\n    coloring : None or 'lines'\\n        How to display contour. Filled contours if None, lines if ``lines``.\\n    colorscale : None or str (Plotly colormap)\\n        colorscale of the contours.\\n    linecolor : None or rgb color\\n        Color used for lines. ``colorscale`` has to be set to None, otherwise\\n        line colors are determined from ``colorscale``.\\n    title : str or None\\n        Title of ternary plot\\n    interp_mode : 'ilr' (default) or 'cartesian'\\n        Defines how data are interpolated to compute contours. If 'irl',\\n        ILR (Isometric Log-Ratio) of compositional data is performed. If\\n        'cartesian', contours are determined in Cartesian space.\\n    showmarkers : bool, default False\\n        If True, markers corresponding to input compositional points are\\n        superimposed on contours, using the same colorscale.\\n\\n    Examples\\n    ========\\n\\n    Example 1: ternary contour plot with filled contours\\n\\n    >>> import plotly.figure_factory as ff\\n    >>> import numpy as np\\n    >>> # Define coordinates\\n    >>> a, b = np.mgrid[0:1:20j, 0:1:20j]\\n    >>> mask = a + b <= 1\\n    >>> a = a[mask].ravel()\\n    >>> b = b[mask].ravel()\\n    >>> c = 1 - a - b\\n    >>> # Values to be displayed as contours\\n    >>> z = a * b * c\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z)\\n    >>> fig.show()\\n\\n    It is also possible to give only two barycentric coordinates for each\\n    point, since the sum of the three coordinates is one:\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b)), z)\\n\\n\\n    Example 2: ternary contour plot with line contours\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, coloring='lines')\\n\\n    Example 3: customize number of contours\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, ncontours=8)\\n\\n    Example 4: superimpose contour plot and original data as markers\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, coloring='lines',\\n    ...                                 showmarkers=True)\\n\\n    Example 5: customize title and pole labels\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z,\\n    ...                                 title='Ternary plot',\\n    ...                                 pole_labels=['clay', 'quartz', 'fledspar'])\\n    \"\n    if scipy_interp is None:\n        raise ImportError('    The create_ternary_contour figure factory requires the scipy package')\n    sk_measure = optional_imports.get_module('skimage')\n    if sk_measure is None:\n        raise ImportError('    The create_ternary_contour figure factory requires the scikit-image\\n    package')\n    if colorscale is None:\n        showscale = False\n    if ncontours is None:\n        ncontours = 5\n    coordinates = _prepare_barycentric_coord(coordinates)\n    (v_min, v_max) = (values.min(), values.max())\n    (grid_z, gr_x, gr_y) = _compute_grid(coordinates, values, interp_mode=interp_mode)\n    layout = _ternary_layout(pole_labels=pole_labels, width=width, height=height, title=title)\n    (contour_trace, discrete_cm) = _contour_trace(gr_x, gr_y, grid_z, ncontours=ncontours, colorscale=colorscale, linecolor=linecolor, interp_mode=interp_mode, coloring=coloring, v_min=v_min, v_max=v_max)\n    fig = go.Figure(data=contour_trace, layout=layout)\n    opacity = 1 if showmarkers else 0\n    (a, b, c) = coordinates\n    hovertemplate = pole_labels[0] + ': %{a:.3f}<br>' + pole_labels[1] + ': %{b:.3f}<br>' + pole_labels[2] + ': %{c:.3f}<br>z: %{marker.color:.3f}<extra></extra>'\n    fig.add_scatterternary(a=a, b=b, c=c, mode='markers', marker={'color': values, 'colorscale': colorscale, 'line': {'color': 'rgb(120, 120, 120)', 'width': int(coloring != 'lines')}}, opacity=opacity, hovertemplate=hovertemplate)\n    if showscale:\n        if not showmarkers:\n            colorscale = discrete_cm\n        colorbar = dict({'type': 'scatterternary', 'a': [None], 'b': [None], 'c': [None], 'marker': {'cmin': values.min(), 'cmax': values.max(), 'colorscale': colorscale, 'showscale': True}, 'mode': 'markers'})\n        fig.add_trace(colorbar)\n    return fig",
            "def create_ternary_contour(coordinates, values, pole_labels=['a', 'b', 'c'], width=500, height=500, ncontours=None, showscale=False, coloring=None, colorscale='Bluered', linecolor=None, title=None, interp_mode='ilr', showmarkers=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Ternary contour plot.\\n\\n    Parameters\\n    ----------\\n\\n    coordinates : list or ndarray\\n        Barycentric coordinates of shape (2, N) or (3, N) where N is the\\n        number of data points. The sum of the 3 coordinates is expected\\n        to be 1 for all data points.\\n    values : array-like\\n        Data points of field to be represented as contours.\\n    pole_labels : str, default ['a', 'b', 'c']\\n        Names of the three poles of the triangle.\\n    width : int\\n        Figure width.\\n    height : int\\n        Figure height.\\n    ncontours : int or None\\n        Number of contours to display (determined automatically if None).\\n    showscale : bool, default False\\n        If True, a colorbar showing the color scale is displayed.\\n    coloring : None or 'lines'\\n        How to display contour. Filled contours if None, lines if ``lines``.\\n    colorscale : None or str (Plotly colormap)\\n        colorscale of the contours.\\n    linecolor : None or rgb color\\n        Color used for lines. ``colorscale`` has to be set to None, otherwise\\n        line colors are determined from ``colorscale``.\\n    title : str or None\\n        Title of ternary plot\\n    interp_mode : 'ilr' (default) or 'cartesian'\\n        Defines how data are interpolated to compute contours. If 'irl',\\n        ILR (Isometric Log-Ratio) of compositional data is performed. If\\n        'cartesian', contours are determined in Cartesian space.\\n    showmarkers : bool, default False\\n        If True, markers corresponding to input compositional points are\\n        superimposed on contours, using the same colorscale.\\n\\n    Examples\\n    ========\\n\\n    Example 1: ternary contour plot with filled contours\\n\\n    >>> import plotly.figure_factory as ff\\n    >>> import numpy as np\\n    >>> # Define coordinates\\n    >>> a, b = np.mgrid[0:1:20j, 0:1:20j]\\n    >>> mask = a + b <= 1\\n    >>> a = a[mask].ravel()\\n    >>> b = b[mask].ravel()\\n    >>> c = 1 - a - b\\n    >>> # Values to be displayed as contours\\n    >>> z = a * b * c\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z)\\n    >>> fig.show()\\n\\n    It is also possible to give only two barycentric coordinates for each\\n    point, since the sum of the three coordinates is one:\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b)), z)\\n\\n\\n    Example 2: ternary contour plot with line contours\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, coloring='lines')\\n\\n    Example 3: customize number of contours\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, ncontours=8)\\n\\n    Example 4: superimpose contour plot and original data as markers\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z, coloring='lines',\\n    ...                                 showmarkers=True)\\n\\n    Example 5: customize title and pole labels\\n\\n    >>> fig = ff.create_ternary_contour(np.stack((a, b, c)), z,\\n    ...                                 title='Ternary plot',\\n    ...                                 pole_labels=['clay', 'quartz', 'fledspar'])\\n    \"\n    if scipy_interp is None:\n        raise ImportError('    The create_ternary_contour figure factory requires the scipy package')\n    sk_measure = optional_imports.get_module('skimage')\n    if sk_measure is None:\n        raise ImportError('    The create_ternary_contour figure factory requires the scikit-image\\n    package')\n    if colorscale is None:\n        showscale = False\n    if ncontours is None:\n        ncontours = 5\n    coordinates = _prepare_barycentric_coord(coordinates)\n    (v_min, v_max) = (values.min(), values.max())\n    (grid_z, gr_x, gr_y) = _compute_grid(coordinates, values, interp_mode=interp_mode)\n    layout = _ternary_layout(pole_labels=pole_labels, width=width, height=height, title=title)\n    (contour_trace, discrete_cm) = _contour_trace(gr_x, gr_y, grid_z, ncontours=ncontours, colorscale=colorscale, linecolor=linecolor, interp_mode=interp_mode, coloring=coloring, v_min=v_min, v_max=v_max)\n    fig = go.Figure(data=contour_trace, layout=layout)\n    opacity = 1 if showmarkers else 0\n    (a, b, c) = coordinates\n    hovertemplate = pole_labels[0] + ': %{a:.3f}<br>' + pole_labels[1] + ': %{b:.3f}<br>' + pole_labels[2] + ': %{c:.3f}<br>z: %{marker.color:.3f}<extra></extra>'\n    fig.add_scatterternary(a=a, b=b, c=c, mode='markers', marker={'color': values, 'colorscale': colorscale, 'line': {'color': 'rgb(120, 120, 120)', 'width': int(coloring != 'lines')}}, opacity=opacity, hovertemplate=hovertemplate)\n    if showscale:\n        if not showmarkers:\n            colorscale = discrete_cm\n        colorbar = dict({'type': 'scatterternary', 'a': [None], 'b': [None], 'c': [None], 'marker': {'cmin': values.min(), 'cmax': values.max(), 'colorscale': colorscale, 'showscale': True}, 'mode': 'markers'})\n        fig.add_trace(colorbar)\n    return fig"
        ]
    }
]