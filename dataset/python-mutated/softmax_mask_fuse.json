[
    {
        "func_name": "softmax_mask_fuse",
        "original": "def softmax_mask_fuse(x, mask, name=None):\n    \"\"\"\n    Do a masked softmax on x.\n\n    This is designed for speeding up Transformer structure.\n    Used for reducing operation such as: tmp = x + mask, out = softmax(tmp).\n    The equation is:\n\n    .. math::\n        out = softmax(x + mask)\n\n    Note:\n        This API only supports GPU.\n\n    Args:\n        x (4-D Tensor): The input tensor, should be in 4D shape, it's data type should be float16, float32.\n                        The fourth dimension of x must be larger or equal to 32 and less then 8192.\n        mask (4-D Tensor): The input tensor, should be in 4D shape, it's data type should be float16, float32.\n                           The second dimension of mask must be 1, and other dimensions must be same with x.\n        name (str, optional): Name for the operation (optional, default is None).\n                              For more information, please refer to :ref:`api_guide_Name`.\n\n    Returns:\n        4-D Tensor. A location into which the result is stored. It's dimension is 4D. Has same shape with x.\n\n    Examples:\n        .. code-block:: python\n\n            >>> # doctest: +REQUIRES(env:GPU)\n            >>> import paddle\n            >>> import paddle.incubate as incubate\n\n            >>> x = paddle.rand([2, 8, 8, 32])\n            >>> mask = paddle.rand([2, 1, 8, 32])\n\n            >>> rst = incubate.softmax_mask_fuse(x, mask)\n            >>> rst.shape\n            [2, 8, 8, 32]\n    \"\"\"\n    if in_dynamic_mode():\n        out = _legacy_C_ops.fused_softmax_mask(x, mask)\n        return out\n    helper = LayerHelper('fused_softmax_mask', **locals())\n    out = helper.create_variable_for_type_inference(dtype=x.dtype)\n    helper.append_op(type='fused_softmax_mask', inputs={'X': [x], 'Mask': [mask]}, outputs={'Out': [out]})\n    return out",
        "mutated": [
            "def softmax_mask_fuse(x, mask, name=None):\n    if False:\n        i = 10\n    \"\\n    Do a masked softmax on x.\\n\\n    This is designed for speeding up Transformer structure.\\n    Used for reducing operation such as: tmp = x + mask, out = softmax(tmp).\\n    The equation is:\\n\\n    .. math::\\n        out = softmax(x + mask)\\n\\n    Note:\\n        This API only supports GPU.\\n\\n    Args:\\n        x (4-D Tensor): The input tensor, should be in 4D shape, it's data type should be float16, float32.\\n                        The fourth dimension of x must be larger or equal to 32 and less then 8192.\\n        mask (4-D Tensor): The input tensor, should be in 4D shape, it's data type should be float16, float32.\\n                           The second dimension of mask must be 1, and other dimensions must be same with x.\\n        name (str, optional): Name for the operation (optional, default is None).\\n                              For more information, please refer to :ref:`api_guide_Name`.\\n\\n    Returns:\\n        4-D Tensor. A location into which the result is stored. It's dimension is 4D. Has same shape with x.\\n\\n    Examples:\\n        .. code-block:: python\\n\\n            >>> # doctest: +REQUIRES(env:GPU)\\n            >>> import paddle\\n            >>> import paddle.incubate as incubate\\n\\n            >>> x = paddle.rand([2, 8, 8, 32])\\n            >>> mask = paddle.rand([2, 1, 8, 32])\\n\\n            >>> rst = incubate.softmax_mask_fuse(x, mask)\\n            >>> rst.shape\\n            [2, 8, 8, 32]\\n    \"\n    if in_dynamic_mode():\n        out = _legacy_C_ops.fused_softmax_mask(x, mask)\n        return out\n    helper = LayerHelper('fused_softmax_mask', **locals())\n    out = helper.create_variable_for_type_inference(dtype=x.dtype)\n    helper.append_op(type='fused_softmax_mask', inputs={'X': [x], 'Mask': [mask]}, outputs={'Out': [out]})\n    return out",
            "def softmax_mask_fuse(x, mask, name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Do a masked softmax on x.\\n\\n    This is designed for speeding up Transformer structure.\\n    Used for reducing operation such as: tmp = x + mask, out = softmax(tmp).\\n    The equation is:\\n\\n    .. math::\\n        out = softmax(x + mask)\\n\\n    Note:\\n        This API only supports GPU.\\n\\n    Args:\\n        x (4-D Tensor): The input tensor, should be in 4D shape, it's data type should be float16, float32.\\n                        The fourth dimension of x must be larger or equal to 32 and less then 8192.\\n        mask (4-D Tensor): The input tensor, should be in 4D shape, it's data type should be float16, float32.\\n                           The second dimension of mask must be 1, and other dimensions must be same with x.\\n        name (str, optional): Name for the operation (optional, default is None).\\n                              For more information, please refer to :ref:`api_guide_Name`.\\n\\n    Returns:\\n        4-D Tensor. A location into which the result is stored. It's dimension is 4D. Has same shape with x.\\n\\n    Examples:\\n        .. code-block:: python\\n\\n            >>> # doctest: +REQUIRES(env:GPU)\\n            >>> import paddle\\n            >>> import paddle.incubate as incubate\\n\\n            >>> x = paddle.rand([2, 8, 8, 32])\\n            >>> mask = paddle.rand([2, 1, 8, 32])\\n\\n            >>> rst = incubate.softmax_mask_fuse(x, mask)\\n            >>> rst.shape\\n            [2, 8, 8, 32]\\n    \"\n    if in_dynamic_mode():\n        out = _legacy_C_ops.fused_softmax_mask(x, mask)\n        return out\n    helper = LayerHelper('fused_softmax_mask', **locals())\n    out = helper.create_variable_for_type_inference(dtype=x.dtype)\n    helper.append_op(type='fused_softmax_mask', inputs={'X': [x], 'Mask': [mask]}, outputs={'Out': [out]})\n    return out",
            "def softmax_mask_fuse(x, mask, name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Do a masked softmax on x.\\n\\n    This is designed for speeding up Transformer structure.\\n    Used for reducing operation such as: tmp = x + mask, out = softmax(tmp).\\n    The equation is:\\n\\n    .. math::\\n        out = softmax(x + mask)\\n\\n    Note:\\n        This API only supports GPU.\\n\\n    Args:\\n        x (4-D Tensor): The input tensor, should be in 4D shape, it's data type should be float16, float32.\\n                        The fourth dimension of x must be larger or equal to 32 and less then 8192.\\n        mask (4-D Tensor): The input tensor, should be in 4D shape, it's data type should be float16, float32.\\n                           The second dimension of mask must be 1, and other dimensions must be same with x.\\n        name (str, optional): Name for the operation (optional, default is None).\\n                              For more information, please refer to :ref:`api_guide_Name`.\\n\\n    Returns:\\n        4-D Tensor. A location into which the result is stored. It's dimension is 4D. Has same shape with x.\\n\\n    Examples:\\n        .. code-block:: python\\n\\n            >>> # doctest: +REQUIRES(env:GPU)\\n            >>> import paddle\\n            >>> import paddle.incubate as incubate\\n\\n            >>> x = paddle.rand([2, 8, 8, 32])\\n            >>> mask = paddle.rand([2, 1, 8, 32])\\n\\n            >>> rst = incubate.softmax_mask_fuse(x, mask)\\n            >>> rst.shape\\n            [2, 8, 8, 32]\\n    \"\n    if in_dynamic_mode():\n        out = _legacy_C_ops.fused_softmax_mask(x, mask)\n        return out\n    helper = LayerHelper('fused_softmax_mask', **locals())\n    out = helper.create_variable_for_type_inference(dtype=x.dtype)\n    helper.append_op(type='fused_softmax_mask', inputs={'X': [x], 'Mask': [mask]}, outputs={'Out': [out]})\n    return out",
            "def softmax_mask_fuse(x, mask, name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Do a masked softmax on x.\\n\\n    This is designed for speeding up Transformer structure.\\n    Used for reducing operation such as: tmp = x + mask, out = softmax(tmp).\\n    The equation is:\\n\\n    .. math::\\n        out = softmax(x + mask)\\n\\n    Note:\\n        This API only supports GPU.\\n\\n    Args:\\n        x (4-D Tensor): The input tensor, should be in 4D shape, it's data type should be float16, float32.\\n                        The fourth dimension of x must be larger or equal to 32 and less then 8192.\\n        mask (4-D Tensor): The input tensor, should be in 4D shape, it's data type should be float16, float32.\\n                           The second dimension of mask must be 1, and other dimensions must be same with x.\\n        name (str, optional): Name for the operation (optional, default is None).\\n                              For more information, please refer to :ref:`api_guide_Name`.\\n\\n    Returns:\\n        4-D Tensor. A location into which the result is stored. It's dimension is 4D. Has same shape with x.\\n\\n    Examples:\\n        .. code-block:: python\\n\\n            >>> # doctest: +REQUIRES(env:GPU)\\n            >>> import paddle\\n            >>> import paddle.incubate as incubate\\n\\n            >>> x = paddle.rand([2, 8, 8, 32])\\n            >>> mask = paddle.rand([2, 1, 8, 32])\\n\\n            >>> rst = incubate.softmax_mask_fuse(x, mask)\\n            >>> rst.shape\\n            [2, 8, 8, 32]\\n    \"\n    if in_dynamic_mode():\n        out = _legacy_C_ops.fused_softmax_mask(x, mask)\n        return out\n    helper = LayerHelper('fused_softmax_mask', **locals())\n    out = helper.create_variable_for_type_inference(dtype=x.dtype)\n    helper.append_op(type='fused_softmax_mask', inputs={'X': [x], 'Mask': [mask]}, outputs={'Out': [out]})\n    return out",
            "def softmax_mask_fuse(x, mask, name=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Do a masked softmax on x.\\n\\n    This is designed for speeding up Transformer structure.\\n    Used for reducing operation such as: tmp = x + mask, out = softmax(tmp).\\n    The equation is:\\n\\n    .. math::\\n        out = softmax(x + mask)\\n\\n    Note:\\n        This API only supports GPU.\\n\\n    Args:\\n        x (4-D Tensor): The input tensor, should be in 4D shape, it's data type should be float16, float32.\\n                        The fourth dimension of x must be larger or equal to 32 and less then 8192.\\n        mask (4-D Tensor): The input tensor, should be in 4D shape, it's data type should be float16, float32.\\n                           The second dimension of mask must be 1, and other dimensions must be same with x.\\n        name (str, optional): Name for the operation (optional, default is None).\\n                              For more information, please refer to :ref:`api_guide_Name`.\\n\\n    Returns:\\n        4-D Tensor. A location into which the result is stored. It's dimension is 4D. Has same shape with x.\\n\\n    Examples:\\n        .. code-block:: python\\n\\n            >>> # doctest: +REQUIRES(env:GPU)\\n            >>> import paddle\\n            >>> import paddle.incubate as incubate\\n\\n            >>> x = paddle.rand([2, 8, 8, 32])\\n            >>> mask = paddle.rand([2, 1, 8, 32])\\n\\n            >>> rst = incubate.softmax_mask_fuse(x, mask)\\n            >>> rst.shape\\n            [2, 8, 8, 32]\\n    \"\n    if in_dynamic_mode():\n        out = _legacy_C_ops.fused_softmax_mask(x, mask)\n        return out\n    helper = LayerHelper('fused_softmax_mask', **locals())\n    out = helper.create_variable_for_type_inference(dtype=x.dtype)\n    helper.append_op(type='fused_softmax_mask', inputs={'X': [x], 'Mask': [mask]}, outputs={'Out': [out]})\n    return out"
        ]
    }
]