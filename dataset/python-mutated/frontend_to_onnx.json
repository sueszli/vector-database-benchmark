[
    {
        "func_name": "__init__",
        "original": "def __init__(self, module, module_bits) -> None:\n    \"\"\"\n        Parameters\n        ----------\n        module : torch.nn.Module\n            Layer module of pytorch model\n        module_bits : int\n            Bits width setting for module\n        \"\"\"\n    super().__init__()\n    self.module = module\n    self.module_bits = module_bits",
        "mutated": [
            "def __init__(self, module, module_bits) -> None:\n    if False:\n        i = 10\n    '\\n        Parameters\\n        ----------\\n        module : torch.nn.Module\\n            Layer module of pytorch model\\n        module_bits : int\\n            Bits width setting for module\\n        '\n    super().__init__()\n    self.module = module\n    self.module_bits = module_bits",
            "def __init__(self, module, module_bits) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Parameters\\n        ----------\\n        module : torch.nn.Module\\n            Layer module of pytorch model\\n        module_bits : int\\n            Bits width setting for module\\n        '\n    super().__init__()\n    self.module = module\n    self.module_bits = module_bits",
            "def __init__(self, module, module_bits) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Parameters\\n        ----------\\n        module : torch.nn.Module\\n            Layer module of pytorch model\\n        module_bits : int\\n            Bits width setting for module\\n        '\n    super().__init__()\n    self.module = module\n    self.module_bits = module_bits",
            "def __init__(self, module, module_bits) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Parameters\\n        ----------\\n        module : torch.nn.Module\\n            Layer module of pytorch model\\n        module_bits : int\\n            Bits width setting for module\\n        '\n    super().__init__()\n    self.module = module\n    self.module_bits = module_bits",
            "def __init__(self, module, module_bits) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Parameters\\n        ----------\\n        module : torch.nn.Module\\n            Layer module of pytorch model\\n        module_bits : int\\n            Bits width setting for module\\n        '\n    super().__init__()\n    self.module = module\n    self.module_bits = module_bits"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, inputs):\n    inputs = inputs * self.module_bits\n    inputs = self.module(inputs)\n    return inputs",
        "mutated": [
            "def forward(self, inputs):\n    if False:\n        i = 10\n    inputs = inputs * self.module_bits\n    inputs = self.module(inputs)\n    return inputs",
            "def forward(self, inputs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    inputs = inputs * self.module_bits\n    inputs = self.module(inputs)\n    return inputs",
            "def forward(self, inputs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    inputs = inputs * self.module_bits\n    inputs = self.module(inputs)\n    return inputs",
            "def forward(self, inputs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    inputs = inputs * self.module_bits\n    inputs = self.module(inputs)\n    return inputs",
            "def forward(self, inputs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    inputs = inputs * self.module_bits\n    inputs = self.module(inputs)\n    return inputs"
        ]
    },
    {
        "func_name": "unwrapper",
        "original": "def unwrapper(model_onnx, index2name, config):\n    \"\"\"\n    Fill onnx config and remove wrapper node in onnx\n\n    Parameters\n    ----------\n    model_onnx : onnx model\n        Onnx model which is converted from pytorch model\n    index2name : dict\n        Dictionary of layer index and name\n    config : dict\n        Config recording name of layers and calibration parameters\n\n    Returns\n    -------\n    onnx model\n        Onnx model which is converted from pytorch model\n    dict\n        The configuration of onnx model layers and calibration parameters\n    \"\"\"\n    support_op = ['Gemm', 'Conv', 'Relu', 'Clip', 'MaxP']\n    idx = 0\n    onnx_config = {}\n    while idx < len(model_onnx.graph.node):\n        nd = model_onnx.graph.node[idx]\n        if nd.name[0:4] in support_op and idx > 1:\n            const_nd = model_onnx.graph.node[idx - 2]\n            mul_nd = model_onnx.graph.node[idx - 1]\n            index = int(onnx.numpy_helper.to_array(const_nd.attribute[0].t))\n            if index != -1:\n                name = index2name[index]\n                onnx_config[nd.name] = config[name]\n            nd.input[0] = mul_nd.input[0]\n            model_onnx.graph.node.remove(const_nd)\n            model_onnx.graph.node.remove(mul_nd)\n            idx = idx - 2\n        idx = idx + 1\n    return (model_onnx, onnx_config)",
        "mutated": [
            "def unwrapper(model_onnx, index2name, config):\n    if False:\n        i = 10\n    '\\n    Fill onnx config and remove wrapper node in onnx\\n\\n    Parameters\\n    ----------\\n    model_onnx : onnx model\\n        Onnx model which is converted from pytorch model\\n    index2name : dict\\n        Dictionary of layer index and name\\n    config : dict\\n        Config recording name of layers and calibration parameters\\n\\n    Returns\\n    -------\\n    onnx model\\n        Onnx model which is converted from pytorch model\\n    dict\\n        The configuration of onnx model layers and calibration parameters\\n    '\n    support_op = ['Gemm', 'Conv', 'Relu', 'Clip', 'MaxP']\n    idx = 0\n    onnx_config = {}\n    while idx < len(model_onnx.graph.node):\n        nd = model_onnx.graph.node[idx]\n        if nd.name[0:4] in support_op and idx > 1:\n            const_nd = model_onnx.graph.node[idx - 2]\n            mul_nd = model_onnx.graph.node[idx - 1]\n            index = int(onnx.numpy_helper.to_array(const_nd.attribute[0].t))\n            if index != -1:\n                name = index2name[index]\n                onnx_config[nd.name] = config[name]\n            nd.input[0] = mul_nd.input[0]\n            model_onnx.graph.node.remove(const_nd)\n            model_onnx.graph.node.remove(mul_nd)\n            idx = idx - 2\n        idx = idx + 1\n    return (model_onnx, onnx_config)",
            "def unwrapper(model_onnx, index2name, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Fill onnx config and remove wrapper node in onnx\\n\\n    Parameters\\n    ----------\\n    model_onnx : onnx model\\n        Onnx model which is converted from pytorch model\\n    index2name : dict\\n        Dictionary of layer index and name\\n    config : dict\\n        Config recording name of layers and calibration parameters\\n\\n    Returns\\n    -------\\n    onnx model\\n        Onnx model which is converted from pytorch model\\n    dict\\n        The configuration of onnx model layers and calibration parameters\\n    '\n    support_op = ['Gemm', 'Conv', 'Relu', 'Clip', 'MaxP']\n    idx = 0\n    onnx_config = {}\n    while idx < len(model_onnx.graph.node):\n        nd = model_onnx.graph.node[idx]\n        if nd.name[0:4] in support_op and idx > 1:\n            const_nd = model_onnx.graph.node[idx - 2]\n            mul_nd = model_onnx.graph.node[idx - 1]\n            index = int(onnx.numpy_helper.to_array(const_nd.attribute[0].t))\n            if index != -1:\n                name = index2name[index]\n                onnx_config[nd.name] = config[name]\n            nd.input[0] = mul_nd.input[0]\n            model_onnx.graph.node.remove(const_nd)\n            model_onnx.graph.node.remove(mul_nd)\n            idx = idx - 2\n        idx = idx + 1\n    return (model_onnx, onnx_config)",
            "def unwrapper(model_onnx, index2name, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Fill onnx config and remove wrapper node in onnx\\n\\n    Parameters\\n    ----------\\n    model_onnx : onnx model\\n        Onnx model which is converted from pytorch model\\n    index2name : dict\\n        Dictionary of layer index and name\\n    config : dict\\n        Config recording name of layers and calibration parameters\\n\\n    Returns\\n    -------\\n    onnx model\\n        Onnx model which is converted from pytorch model\\n    dict\\n        The configuration of onnx model layers and calibration parameters\\n    '\n    support_op = ['Gemm', 'Conv', 'Relu', 'Clip', 'MaxP']\n    idx = 0\n    onnx_config = {}\n    while idx < len(model_onnx.graph.node):\n        nd = model_onnx.graph.node[idx]\n        if nd.name[0:4] in support_op and idx > 1:\n            const_nd = model_onnx.graph.node[idx - 2]\n            mul_nd = model_onnx.graph.node[idx - 1]\n            index = int(onnx.numpy_helper.to_array(const_nd.attribute[0].t))\n            if index != -1:\n                name = index2name[index]\n                onnx_config[nd.name] = config[name]\n            nd.input[0] = mul_nd.input[0]\n            model_onnx.graph.node.remove(const_nd)\n            model_onnx.graph.node.remove(mul_nd)\n            idx = idx - 2\n        idx = idx + 1\n    return (model_onnx, onnx_config)",
            "def unwrapper(model_onnx, index2name, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Fill onnx config and remove wrapper node in onnx\\n\\n    Parameters\\n    ----------\\n    model_onnx : onnx model\\n        Onnx model which is converted from pytorch model\\n    index2name : dict\\n        Dictionary of layer index and name\\n    config : dict\\n        Config recording name of layers and calibration parameters\\n\\n    Returns\\n    -------\\n    onnx model\\n        Onnx model which is converted from pytorch model\\n    dict\\n        The configuration of onnx model layers and calibration parameters\\n    '\n    support_op = ['Gemm', 'Conv', 'Relu', 'Clip', 'MaxP']\n    idx = 0\n    onnx_config = {}\n    while idx < len(model_onnx.graph.node):\n        nd = model_onnx.graph.node[idx]\n        if nd.name[0:4] in support_op and idx > 1:\n            const_nd = model_onnx.graph.node[idx - 2]\n            mul_nd = model_onnx.graph.node[idx - 1]\n            index = int(onnx.numpy_helper.to_array(const_nd.attribute[0].t))\n            if index != -1:\n                name = index2name[index]\n                onnx_config[nd.name] = config[name]\n            nd.input[0] = mul_nd.input[0]\n            model_onnx.graph.node.remove(const_nd)\n            model_onnx.graph.node.remove(mul_nd)\n            idx = idx - 2\n        idx = idx + 1\n    return (model_onnx, onnx_config)",
            "def unwrapper(model_onnx, index2name, config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Fill onnx config and remove wrapper node in onnx\\n\\n    Parameters\\n    ----------\\n    model_onnx : onnx model\\n        Onnx model which is converted from pytorch model\\n    index2name : dict\\n        Dictionary of layer index and name\\n    config : dict\\n        Config recording name of layers and calibration parameters\\n\\n    Returns\\n    -------\\n    onnx model\\n        Onnx model which is converted from pytorch model\\n    dict\\n        The configuration of onnx model layers and calibration parameters\\n    '\n    support_op = ['Gemm', 'Conv', 'Relu', 'Clip', 'MaxP']\n    idx = 0\n    onnx_config = {}\n    while idx < len(model_onnx.graph.node):\n        nd = model_onnx.graph.node[idx]\n        if nd.name[0:4] in support_op and idx > 1:\n            const_nd = model_onnx.graph.node[idx - 2]\n            mul_nd = model_onnx.graph.node[idx - 1]\n            index = int(onnx.numpy_helper.to_array(const_nd.attribute[0].t))\n            if index != -1:\n                name = index2name[index]\n                onnx_config[nd.name] = config[name]\n            nd.input[0] = mul_nd.input[0]\n            model_onnx.graph.node.remove(const_nd)\n            model_onnx.graph.node.remove(mul_nd)\n            idx = idx - 2\n        idx = idx + 1\n    return (model_onnx, onnx_config)"
        ]
    },
    {
        "func_name": "torch_to_onnx",
        "original": "def torch_to_onnx(model, config, input_shape, model_path, input_names, output_names):\n    \"\"\"\n    Convert torch model to onnx model and get layer bits config of onnx model.\n\n    Parameters\n    ----------\n    model : pytorch model\n        The model to speedup by quantization\n    config : dict\n        Config recording bits number and name of layers\n    input_shape : tuple\n        The input shape of model, shall pass it to torch.onnx.export\n    model_path : str\n        The path user want to store onnx model which is converted from pytorch model\n    input_names : list\n        Input name of onnx model providing for torch.onnx.export to generate onnx model\n    output_name : list\n        Output name of onnx model providing for torch.onnx.export to generate onnx model\n\n    Returns\n    -------\n    onnx model\n        Onnx model which is converted from pytorch model\n    dict\n        The configuration of onnx model layers and calibration parameters\n    \"\"\"\n    support_op = [torch.nn.Conv2d, torch.nn.Linear, torch.nn.ReLU, torch.nn.ReLU6, torch.nn.MaxPool2d]\n    index2name = {}\n    name2index = {}\n    if config is not None:\n        for (i, name) in enumerate(config.keys()):\n            index2name[i * 2] = name\n            name2index[name] = i * 2\n    for (name, module) in model.named_modules():\n        if config is not None and name in config:\n            assert type(module) in support_op\n            wrapper_module = LayernameModuleWrapper(module, name2index[name])\n            set_nested_attr(model, name, wrapper_module)\n        elif type(module) in support_op:\n            wrapper_module = LayernameModuleWrapper(module, -1)\n            set_nested_attr(model, name, wrapper_module)\n    device = torch.device('cpu')\n    dummy_input = torch.randn(input_shape)\n    dummy_input = dummy_input.to(device)\n    model.to(device)\n    torch.onnx.export(model, dummy_input, model_path, verbose=False, input_names=input_names, output_names=output_names, export_params=True)\n    model_onnx = onnx.load(model_path)\n    (model_onnx, onnx_config) = unwrapper(model_onnx, index2name, config)\n    onnx.save(model_onnx, model_path)\n    onnx.checker.check_model(model_onnx)\n    return (model_onnx, onnx_config)",
        "mutated": [
            "def torch_to_onnx(model, config, input_shape, model_path, input_names, output_names):\n    if False:\n        i = 10\n    '\\n    Convert torch model to onnx model and get layer bits config of onnx model.\\n\\n    Parameters\\n    ----------\\n    model : pytorch model\\n        The model to speedup by quantization\\n    config : dict\\n        Config recording bits number and name of layers\\n    input_shape : tuple\\n        The input shape of model, shall pass it to torch.onnx.export\\n    model_path : str\\n        The path user want to store onnx model which is converted from pytorch model\\n    input_names : list\\n        Input name of onnx model providing for torch.onnx.export to generate onnx model\\n    output_name : list\\n        Output name of onnx model providing for torch.onnx.export to generate onnx model\\n\\n    Returns\\n    -------\\n    onnx model\\n        Onnx model which is converted from pytorch model\\n    dict\\n        The configuration of onnx model layers and calibration parameters\\n    '\n    support_op = [torch.nn.Conv2d, torch.nn.Linear, torch.nn.ReLU, torch.nn.ReLU6, torch.nn.MaxPool2d]\n    index2name = {}\n    name2index = {}\n    if config is not None:\n        for (i, name) in enumerate(config.keys()):\n            index2name[i * 2] = name\n            name2index[name] = i * 2\n    for (name, module) in model.named_modules():\n        if config is not None and name in config:\n            assert type(module) in support_op\n            wrapper_module = LayernameModuleWrapper(module, name2index[name])\n            set_nested_attr(model, name, wrapper_module)\n        elif type(module) in support_op:\n            wrapper_module = LayernameModuleWrapper(module, -1)\n            set_nested_attr(model, name, wrapper_module)\n    device = torch.device('cpu')\n    dummy_input = torch.randn(input_shape)\n    dummy_input = dummy_input.to(device)\n    model.to(device)\n    torch.onnx.export(model, dummy_input, model_path, verbose=False, input_names=input_names, output_names=output_names, export_params=True)\n    model_onnx = onnx.load(model_path)\n    (model_onnx, onnx_config) = unwrapper(model_onnx, index2name, config)\n    onnx.save(model_onnx, model_path)\n    onnx.checker.check_model(model_onnx)\n    return (model_onnx, onnx_config)",
            "def torch_to_onnx(model, config, input_shape, model_path, input_names, output_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Convert torch model to onnx model and get layer bits config of onnx model.\\n\\n    Parameters\\n    ----------\\n    model : pytorch model\\n        The model to speedup by quantization\\n    config : dict\\n        Config recording bits number and name of layers\\n    input_shape : tuple\\n        The input shape of model, shall pass it to torch.onnx.export\\n    model_path : str\\n        The path user want to store onnx model which is converted from pytorch model\\n    input_names : list\\n        Input name of onnx model providing for torch.onnx.export to generate onnx model\\n    output_name : list\\n        Output name of onnx model providing for torch.onnx.export to generate onnx model\\n\\n    Returns\\n    -------\\n    onnx model\\n        Onnx model which is converted from pytorch model\\n    dict\\n        The configuration of onnx model layers and calibration parameters\\n    '\n    support_op = [torch.nn.Conv2d, torch.nn.Linear, torch.nn.ReLU, torch.nn.ReLU6, torch.nn.MaxPool2d]\n    index2name = {}\n    name2index = {}\n    if config is not None:\n        for (i, name) in enumerate(config.keys()):\n            index2name[i * 2] = name\n            name2index[name] = i * 2\n    for (name, module) in model.named_modules():\n        if config is not None and name in config:\n            assert type(module) in support_op\n            wrapper_module = LayernameModuleWrapper(module, name2index[name])\n            set_nested_attr(model, name, wrapper_module)\n        elif type(module) in support_op:\n            wrapper_module = LayernameModuleWrapper(module, -1)\n            set_nested_attr(model, name, wrapper_module)\n    device = torch.device('cpu')\n    dummy_input = torch.randn(input_shape)\n    dummy_input = dummy_input.to(device)\n    model.to(device)\n    torch.onnx.export(model, dummy_input, model_path, verbose=False, input_names=input_names, output_names=output_names, export_params=True)\n    model_onnx = onnx.load(model_path)\n    (model_onnx, onnx_config) = unwrapper(model_onnx, index2name, config)\n    onnx.save(model_onnx, model_path)\n    onnx.checker.check_model(model_onnx)\n    return (model_onnx, onnx_config)",
            "def torch_to_onnx(model, config, input_shape, model_path, input_names, output_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Convert torch model to onnx model and get layer bits config of onnx model.\\n\\n    Parameters\\n    ----------\\n    model : pytorch model\\n        The model to speedup by quantization\\n    config : dict\\n        Config recording bits number and name of layers\\n    input_shape : tuple\\n        The input shape of model, shall pass it to torch.onnx.export\\n    model_path : str\\n        The path user want to store onnx model which is converted from pytorch model\\n    input_names : list\\n        Input name of onnx model providing for torch.onnx.export to generate onnx model\\n    output_name : list\\n        Output name of onnx model providing for torch.onnx.export to generate onnx model\\n\\n    Returns\\n    -------\\n    onnx model\\n        Onnx model which is converted from pytorch model\\n    dict\\n        The configuration of onnx model layers and calibration parameters\\n    '\n    support_op = [torch.nn.Conv2d, torch.nn.Linear, torch.nn.ReLU, torch.nn.ReLU6, torch.nn.MaxPool2d]\n    index2name = {}\n    name2index = {}\n    if config is not None:\n        for (i, name) in enumerate(config.keys()):\n            index2name[i * 2] = name\n            name2index[name] = i * 2\n    for (name, module) in model.named_modules():\n        if config is not None and name in config:\n            assert type(module) in support_op\n            wrapper_module = LayernameModuleWrapper(module, name2index[name])\n            set_nested_attr(model, name, wrapper_module)\n        elif type(module) in support_op:\n            wrapper_module = LayernameModuleWrapper(module, -1)\n            set_nested_attr(model, name, wrapper_module)\n    device = torch.device('cpu')\n    dummy_input = torch.randn(input_shape)\n    dummy_input = dummy_input.to(device)\n    model.to(device)\n    torch.onnx.export(model, dummy_input, model_path, verbose=False, input_names=input_names, output_names=output_names, export_params=True)\n    model_onnx = onnx.load(model_path)\n    (model_onnx, onnx_config) = unwrapper(model_onnx, index2name, config)\n    onnx.save(model_onnx, model_path)\n    onnx.checker.check_model(model_onnx)\n    return (model_onnx, onnx_config)",
            "def torch_to_onnx(model, config, input_shape, model_path, input_names, output_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Convert torch model to onnx model and get layer bits config of onnx model.\\n\\n    Parameters\\n    ----------\\n    model : pytorch model\\n        The model to speedup by quantization\\n    config : dict\\n        Config recording bits number and name of layers\\n    input_shape : tuple\\n        The input shape of model, shall pass it to torch.onnx.export\\n    model_path : str\\n        The path user want to store onnx model which is converted from pytorch model\\n    input_names : list\\n        Input name of onnx model providing for torch.onnx.export to generate onnx model\\n    output_name : list\\n        Output name of onnx model providing for torch.onnx.export to generate onnx model\\n\\n    Returns\\n    -------\\n    onnx model\\n        Onnx model which is converted from pytorch model\\n    dict\\n        The configuration of onnx model layers and calibration parameters\\n    '\n    support_op = [torch.nn.Conv2d, torch.nn.Linear, torch.nn.ReLU, torch.nn.ReLU6, torch.nn.MaxPool2d]\n    index2name = {}\n    name2index = {}\n    if config is not None:\n        for (i, name) in enumerate(config.keys()):\n            index2name[i * 2] = name\n            name2index[name] = i * 2\n    for (name, module) in model.named_modules():\n        if config is not None and name in config:\n            assert type(module) in support_op\n            wrapper_module = LayernameModuleWrapper(module, name2index[name])\n            set_nested_attr(model, name, wrapper_module)\n        elif type(module) in support_op:\n            wrapper_module = LayernameModuleWrapper(module, -1)\n            set_nested_attr(model, name, wrapper_module)\n    device = torch.device('cpu')\n    dummy_input = torch.randn(input_shape)\n    dummy_input = dummy_input.to(device)\n    model.to(device)\n    torch.onnx.export(model, dummy_input, model_path, verbose=False, input_names=input_names, output_names=output_names, export_params=True)\n    model_onnx = onnx.load(model_path)\n    (model_onnx, onnx_config) = unwrapper(model_onnx, index2name, config)\n    onnx.save(model_onnx, model_path)\n    onnx.checker.check_model(model_onnx)\n    return (model_onnx, onnx_config)",
            "def torch_to_onnx(model, config, input_shape, model_path, input_names, output_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Convert torch model to onnx model and get layer bits config of onnx model.\\n\\n    Parameters\\n    ----------\\n    model : pytorch model\\n        The model to speedup by quantization\\n    config : dict\\n        Config recording bits number and name of layers\\n    input_shape : tuple\\n        The input shape of model, shall pass it to torch.onnx.export\\n    model_path : str\\n        The path user want to store onnx model which is converted from pytorch model\\n    input_names : list\\n        Input name of onnx model providing for torch.onnx.export to generate onnx model\\n    output_name : list\\n        Output name of onnx model providing for torch.onnx.export to generate onnx model\\n\\n    Returns\\n    -------\\n    onnx model\\n        Onnx model which is converted from pytorch model\\n    dict\\n        The configuration of onnx model layers and calibration parameters\\n    '\n    support_op = [torch.nn.Conv2d, torch.nn.Linear, torch.nn.ReLU, torch.nn.ReLU6, torch.nn.MaxPool2d]\n    index2name = {}\n    name2index = {}\n    if config is not None:\n        for (i, name) in enumerate(config.keys()):\n            index2name[i * 2] = name\n            name2index[name] = i * 2\n    for (name, module) in model.named_modules():\n        if config is not None and name in config:\n            assert type(module) in support_op\n            wrapper_module = LayernameModuleWrapper(module, name2index[name])\n            set_nested_attr(model, name, wrapper_module)\n        elif type(module) in support_op:\n            wrapper_module = LayernameModuleWrapper(module, -1)\n            set_nested_attr(model, name, wrapper_module)\n    device = torch.device('cpu')\n    dummy_input = torch.randn(input_shape)\n    dummy_input = dummy_input.to(device)\n    model.to(device)\n    torch.onnx.export(model, dummy_input, model_path, verbose=False, input_names=input_names, output_names=output_names, export_params=True)\n    model_onnx = onnx.load(model_path)\n    (model_onnx, onnx_config) = unwrapper(model_onnx, index2name, config)\n    onnx.save(model_onnx, model_path)\n    onnx.checker.check_model(model_onnx)\n    return (model_onnx, onnx_config)"
        ]
    }
]