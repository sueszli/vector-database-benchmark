"""
This is only meant to add docs to objects defined in C-extension modules.
The purpose is to allow easier editing of the docstrings without
requiring a re-compile.

NOTE: Many of the methods of ndarray have corresponding functions.
      If you update these docstrings, please keep also the ones in
      _core/fromnumeric.py, matrixlib/defmatrix.py up-to-date.

"""
from numpy._core.function_base import add_newdoc
from numpy._core.overrides import array_function_like_doc
add_newdoc('numpy._core', 'flatiter', "\n    Flat iterator object to iterate over arrays.\n\n    A `flatiter` iterator is returned by ``x.flat`` for any array `x`.\n    It allows iterating over the array as if it were a 1-D array,\n    either in a for-loop or by calling its `next` method.\n\n    Iteration is done in row-major, C-style order (the last\n    index varying the fastest). The iterator can also be indexed using\n    basic slicing or advanced indexing.\n\n    See Also\n    --------\n    ndarray.flat : Return a flat iterator over an array.\n    ndarray.flatten : Returns a flattened copy of an array.\n\n    Notes\n    -----\n    A `flatiter` iterator can not be constructed directly from Python code\n    by calling the `flatiter` constructor.\n\n    Examples\n    --------\n    >>> x = np.arange(6).reshape(2, 3)\n    >>> fl = x.flat\n    >>> type(fl)\n    <class 'numpy.flatiter'>\n    >>> for item in fl:\n    ...     print(item)\n    ...\n    0\n    1\n    2\n    3\n    4\n    5\n\n    >>> fl[2:4]\n    array([2, 3])\n\n    ")
add_newdoc('numpy._core', 'flatiter', ('base', '\n    A reference to the array that is iterated over.\n\n    Examples\n    --------\n    >>> x = np.arange(5)\n    >>> fl = x.flat\n    >>> fl.base is x\n    True\n\n    '))
add_newdoc('numpy._core', 'flatiter', ('coords', '\n    An N-dimensional tuple of current coordinates.\n\n    Examples\n    --------\n    >>> x = np.arange(6).reshape(2, 3)\n    >>> fl = x.flat\n    >>> fl.coords\n    (0, 0)\n    >>> next(fl)\n    0\n    >>> fl.coords\n    (0, 1)\n\n    '))
add_newdoc('numpy._core', 'flatiter', ('index', '\n    Current flat index into the array.\n\n    Examples\n    --------\n    >>> x = np.arange(6).reshape(2, 3)\n    >>> fl = x.flat\n    >>> fl.index\n    0\n    >>> next(fl)\n    0\n    >>> fl.index\n    1\n\n    '))
add_newdoc('numpy._core', 'flatiter', ('__array__', '__array__(type=None) Get array from iterator\n\n    '))
add_newdoc('numpy._core', 'flatiter', ('copy', '\n    copy()\n\n    Get a copy of the iterator as a 1-D array.\n\n    Examples\n    --------\n    >>> x = np.arange(6).reshape(2, 3)\n    >>> x\n    array([[0, 1, 2],\n           [3, 4, 5]])\n    >>> fl = x.flat\n    >>> fl.copy()\n    array([0, 1, 2, 3, 4, 5])\n\n    '))
add_newdoc('numpy._core', 'nditer', '\n    nditer(op, flags=None, op_flags=None, op_dtypes=None, order=\'K\',\n        casting=\'safe\', op_axes=None, itershape=None, buffersize=0)\n\n    Efficient multi-dimensional iterator object to iterate over arrays.\n    To get started using this object, see the\n    :ref:`introductory guide to array iteration <arrays.nditer>`.\n\n    Parameters\n    ----------\n    op : ndarray or sequence of array_like\n        The array(s) to iterate over.\n\n    flags : sequence of str, optional\n          Flags to control the behavior of the iterator.\n\n          * ``buffered`` enables buffering when required.\n          * ``c_index`` causes a C-order index to be tracked.\n          * ``f_index`` causes a Fortran-order index to be tracked.\n          * ``multi_index`` causes a multi-index, or a tuple of indices\n            with one per iteration dimension, to be tracked.\n          * ``common_dtype`` causes all the operands to be converted to\n            a common data type, with copying or buffering as necessary.\n          * ``copy_if_overlap`` causes the iterator to determine if read\n            operands have overlap with write operands, and make temporary\n            copies as necessary to avoid overlap. False positives (needless\n            copying) are possible in some cases.\n          * ``delay_bufalloc`` delays allocation of the buffers until\n            a reset() call is made. Allows ``allocate`` operands to\n            be initialized before their values are copied into the buffers.\n          * ``external_loop`` causes the ``values`` given to be\n            one-dimensional arrays with multiple values instead of\n            zero-dimensional arrays.\n          * ``grow_inner`` allows the ``value`` array sizes to be made\n            larger than the buffer size when both ``buffered`` and\n            ``external_loop`` is used.\n          * ``ranged`` allows the iterator to be restricted to a sub-range\n            of the iterindex values.\n          * ``refs_ok`` enables iteration of reference types, such as\n            object arrays.\n          * ``reduce_ok`` enables iteration of ``readwrite`` operands\n            which are broadcasted, also known as reduction operands.\n          * ``zerosize_ok`` allows `itersize` to be zero.\n    op_flags : list of list of str, optional\n          This is a list of flags for each operand. At minimum, one of\n          ``readonly``, ``readwrite``, or ``writeonly`` must be specified.\n\n          * ``readonly`` indicates the operand will only be read from.\n          * ``readwrite`` indicates the operand will be read from and written to.\n          * ``writeonly`` indicates the operand will only be written to.\n          * ``no_broadcast`` prevents the operand from being broadcasted.\n          * ``contig`` forces the operand data to be contiguous.\n          * ``aligned`` forces the operand data to be aligned.\n          * ``nbo`` forces the operand data to be in native byte order.\n          * ``copy`` allows a temporary read-only copy if required.\n          * ``updateifcopy`` allows a temporary read-write copy if required.\n          * ``allocate`` causes the array to be allocated if it is None\n            in the ``op`` parameter.\n          * ``no_subtype`` prevents an ``allocate`` operand from using a subtype.\n          * ``arraymask`` indicates that this operand is the mask to use\n            for selecting elements when writing to operands with the\n            \'writemasked\' flag set. The iterator does not enforce this,\n            but when writing from a buffer back to the array, it only\n            copies those elements indicated by this mask.\n          * ``writemasked`` indicates that only elements where the chosen\n            ``arraymask`` operand is True will be written to.\n          * ``overlap_assume_elementwise`` can be used to mark operands that are\n            accessed only in the iterator order, to allow less conservative\n            copying when ``copy_if_overlap`` is present.\n    op_dtypes : dtype or tuple of dtype(s), optional\n        The required data type(s) of the operands. If copying or buffering\n        is enabled, the data will be converted to/from their original types.\n    order : {\'C\', \'F\', \'A\', \'K\'}, optional\n        Controls the iteration order. \'C\' means C order, \'F\' means\n        Fortran order, \'A\' means \'F\' order if all the arrays are Fortran\n        contiguous, \'C\' order otherwise, and \'K\' means as close to the\n        order the array elements appear in memory as possible. This also\n        affects the element memory order of ``allocate`` operands, as they\n        are allocated to be compatible with iteration order.\n        Default is \'K\'.\n    casting : {\'no\', \'equiv\', \'safe\', \'same_kind\', \'unsafe\'}, optional\n        Controls what kind of data casting may occur when making a copy\n        or buffering.  Setting this to \'unsafe\' is not recommended,\n        as it can adversely affect accumulations.\n\n        * \'no\' means the data types should not be cast at all.\n        * \'equiv\' means only byte-order changes are allowed.\n        * \'safe\' means only casts which can preserve values are allowed.\n        * \'same_kind\' means only safe casts or casts within a kind,\n          like float64 to float32, are allowed.\n        * \'unsafe\' means any data conversions may be done.\n    op_axes : list of list of ints, optional\n        If provided, is a list of ints or None for each operands.\n        The list of axes for an operand is a mapping from the dimensions\n        of the iterator to the dimensions of the operand. A value of\n        -1 can be placed for entries, causing that dimension to be\n        treated as `newaxis`.\n    itershape : tuple of ints, optional\n        The desired shape of the iterator. This allows ``allocate`` operands\n        with a dimension mapped by op_axes not corresponding to a dimension\n        of a different operand to get a value not equal to 1 for that\n        dimension.\n    buffersize : int, optional\n        When buffering is enabled, controls the size of the temporary\n        buffers. Set to 0 for the default value.\n\n    Attributes\n    ----------\n    dtypes : tuple of dtype(s)\n        The data types of the values provided in `value`. This may be\n        different from the operand data types if buffering is enabled.\n        Valid only before the iterator is closed.\n    finished : bool\n        Whether the iteration over the operands is finished or not.\n    has_delayed_bufalloc : bool\n        If True, the iterator was created with the ``delay_bufalloc`` flag,\n        and no reset() function was called on it yet.\n    has_index : bool\n        If True, the iterator was created with either the ``c_index`` or\n        the ``f_index`` flag, and the property `index` can be used to\n        retrieve it.\n    has_multi_index : bool\n        If True, the iterator was created with the ``multi_index`` flag,\n        and the property `multi_index` can be used to retrieve it.\n    index\n        When the ``c_index`` or ``f_index`` flag was used, this property\n        provides access to the index. Raises a ValueError if accessed\n        and ``has_index`` is False.\n    iterationneedsapi : bool\n        Whether iteration requires access to the Python API, for example\n        if one of the operands is an object array.\n    iterindex : int\n        An index which matches the order of iteration.\n    itersize : int\n        Size of the iterator.\n    itviews\n        Structured view(s) of `operands` in memory, matching the reordered\n        and optimized iterator access pattern. Valid only before the iterator\n        is closed.\n    multi_index\n        When the ``multi_index`` flag was used, this property\n        provides access to the index. Raises a ValueError if accessed\n        accessed and ``has_multi_index`` is False.\n    ndim : int\n        The dimensions of the iterator.\n    nop : int\n        The number of iterator operands.\n    operands : tuple of operand(s)\n        The array(s) to be iterated over. Valid only before the iterator is\n        closed.\n    shape : tuple of ints\n        Shape tuple, the shape of the iterator.\n    value\n        Value of ``operands`` at current iteration. Normally, this is a\n        tuple of array scalars, but if the flag ``external_loop`` is used,\n        it is a tuple of one dimensional arrays.\n\n    Notes\n    -----\n    `nditer` supersedes `flatiter`.  The iterator implementation behind\n    `nditer` is also exposed by the NumPy C API.\n\n    The Python exposure supplies two iteration interfaces, one which follows\n    the Python iterator protocol, and another which mirrors the C-style\n    do-while pattern.  The native Python approach is better in most cases, but\n    if you need the coordinates or index of an iterator, use the C-style pattern.\n\n    Examples\n    --------\n    Here is how we might write an ``iter_add`` function, using the\n    Python iterator protocol:\n\n    >>> def iter_add_py(x, y, out=None):\n    ...     addop = np.add\n    ...     it = np.nditer([x, y, out], [],\n    ...                 [[\'readonly\'], [\'readonly\'], [\'writeonly\',\'allocate\']])\n    ...     with it:\n    ...         for (a, b, c) in it:\n    ...             addop(a, b, out=c)\n    ...         return it.operands[2]\n\n    Here is the same function, but following the C-style pattern:\n\n    >>> def iter_add(x, y, out=None):\n    ...    addop = np.add\n    ...    it = np.nditer([x, y, out], [],\n    ...                [[\'readonly\'], [\'readonly\'], [\'writeonly\',\'allocate\']])\n    ...    with it:\n    ...        while not it.finished:\n    ...            addop(it[0], it[1], out=it[2])\n    ...            it.iternext()\n    ...        return it.operands[2]\n\n    Here is an example outer product function:\n\n    >>> def outer_it(x, y, out=None):\n    ...     mulop = np.multiply\n    ...     it = np.nditer([x, y, out], [\'external_loop\'],\n    ...             [[\'readonly\'], [\'readonly\'], [\'writeonly\', \'allocate\']],\n    ...             op_axes=[list(range(x.ndim)) + [-1] * y.ndim,\n    ...                      [-1] * x.ndim + list(range(y.ndim)),\n    ...                      None])\n    ...     with it:\n    ...         for (a, b, c) in it:\n    ...             mulop(a, b, out=c)\n    ...         return it.operands[2]\n\n    >>> a = np.arange(2)+1\n    >>> b = np.arange(3)+1\n    >>> outer_it(a,b)\n    array([[1, 2, 3],\n           [2, 4, 6]])\n\n    Here is an example function which operates like a "lambda" ufunc:\n\n    >>> def luf(lamdaexpr, *args, **kwargs):\n    ...    \'\'\'luf(lambdaexpr, op1, ..., opn, out=None, order=\'K\', casting=\'safe\', buffersize=0)\'\'\'\n    ...    nargs = len(args)\n    ...    op = (kwargs.get(\'out\',None),) + args\n    ...    it = np.nditer(op, [\'buffered\',\'external_loop\'],\n    ...            [[\'writeonly\',\'allocate\',\'no_broadcast\']] +\n    ...                            [[\'readonly\',\'nbo\',\'aligned\']]*nargs,\n    ...            order=kwargs.get(\'order\',\'K\'),\n    ...            casting=kwargs.get(\'casting\',\'safe\'),\n    ...            buffersize=kwargs.get(\'buffersize\',0))\n    ...    while not it.finished:\n    ...        it[0] = lamdaexpr(*it[1:])\n    ...        it.iternext()\n    ...    return it.operands[0]\n\n    >>> a = np.arange(5)\n    >>> b = np.ones(5)\n    >>> luf(lambda i,j:i*i + j/2, a, b)\n    array([  0.5,   1.5,   4.5,   9.5,  16.5])\n\n    If operand flags ``"writeonly"`` or ``"readwrite"`` are used the\n    operands may be views into the original data with the\n    `WRITEBACKIFCOPY` flag. In this case `nditer` must be used as a\n    context manager or the `nditer.close` method must be called before\n    using the result. The temporary data will be written back to the\n    original data when the :meth:`~object.__exit__` function is called\n    but not before:\n\n    >>> a = np.arange(6, dtype=\'i4\')[::-2]\n    >>> with np.nditer(a, [],\n    ...        [[\'writeonly\', \'updateifcopy\']],\n    ...        casting=\'unsafe\',\n    ...        op_dtypes=[np.dtype(\'f4\')]) as i:\n    ...    x = i.operands[0]\n    ...    x[:] = [-1, -2, -3]\n    ...    # a still unchanged here\n    >>> a, x\n    (array([-1, -2, -3], dtype=int32), array([-1., -2., -3.], dtype=float32))\n\n    It is important to note that once the iterator is exited, dangling\n    references (like `x` in the example) may or may not share data with\n    the original data `a`. If writeback semantics were active, i.e. if\n    `x.base.flags.writebackifcopy` is `True`, then exiting the iterator\n    will sever the connection between `x` and `a`, writing to `x` will\n    no longer write to `a`. If writeback semantics are not active, then\n    `x.data` will still point at some part of `a.data`, and writing to\n    one will affect the other.\n\n    Context management and the `close` method appeared in version 1.15.0.\n\n    ')
add_newdoc('numpy._core', 'nditer', ('copy', '\n    copy()\n\n    Get a copy of the iterator in its current state.\n\n    Examples\n    --------\n    >>> x = np.arange(10)\n    >>> y = x + 1\n    >>> it = np.nditer([x, y])\n    >>> next(it)\n    (array(0), array(1))\n    >>> it2 = it.copy()\n    >>> next(it2)\n    (array(1), array(2))\n\n    '))
add_newdoc('numpy._core', 'nditer', ('operands', '\n    operands[`Slice`]\n\n    The array(s) to be iterated over. Valid only before the iterator is closed.\n    '))
add_newdoc('numpy._core', 'nditer', ('debug_print', '\n    debug_print()\n\n    Print the current state of the `nditer` instance and debug info to stdout.\n\n    '))
add_newdoc('numpy._core', 'nditer', ('enable_external_loop', '\n    enable_external_loop()\n\n    When the "external_loop" was not used during construction, but\n    is desired, this modifies the iterator to behave as if the flag\n    was specified.\n\n    '))
add_newdoc('numpy._core', 'nditer', ('iternext', '\n    iternext()\n\n    Check whether iterations are left, and perform a single internal iteration\n    without returning the result.  Used in the C-style pattern do-while\n    pattern.  For an example, see `nditer`.\n\n    Returns\n    -------\n    iternext : bool\n        Whether or not there are iterations left.\n\n    '))
add_newdoc('numpy._core', 'nditer', ('remove_axis', '\n    remove_axis(i, /)\n\n    Removes axis `i` from the iterator. Requires that the flag "multi_index"\n    be enabled.\n\n    '))
add_newdoc('numpy._core', 'nditer', ('remove_multi_index', '\n    remove_multi_index()\n\n    When the "multi_index" flag was specified, this removes it, allowing\n    the internal iteration structure to be optimized further.\n\n    '))
add_newdoc('numpy._core', 'nditer', ('reset', '\n    reset()\n\n    Reset the iterator to its initial state.\n\n    '))
add_newdoc('numpy._core', 'nested_iters', '\n    nested_iters(op, axes, flags=None, op_flags=None, op_dtypes=None,     order="K", casting="safe", buffersize=0)\n\n    Create nditers for use in nested loops\n\n    Create a tuple of `nditer` objects which iterate in nested loops over\n    different axes of the op argument. The first iterator is used in the\n    outermost loop, the last in the innermost loop. Advancing one will change\n    the subsequent iterators to point at its new element.\n\n    Parameters\n    ----------\n    op : ndarray or sequence of array_like\n        The array(s) to iterate over.\n\n    axes : list of list of int\n        Each item is used as an "op_axes" argument to an nditer\n\n    flags, op_flags, op_dtypes, order, casting, buffersize (optional)\n        See `nditer` parameters of the same name\n\n    Returns\n    -------\n    iters : tuple of nditer\n        An nditer for each item in `axes`, outermost first\n\n    See Also\n    --------\n    nditer\n\n    Examples\n    --------\n\n    Basic usage. Note how y is the "flattened" version of\n    [a[:, 0, :], a[:, 1, 0], a[:, 2, :]] since we specified\n    the first iter\'s axes as [1]\n\n    >>> a = np.arange(12).reshape(2, 3, 2)\n    >>> i, j = np.nested_iters(a, [[1], [0, 2]], flags=["multi_index"])\n    >>> for x in i:\n    ...      print(i.multi_index)\n    ...      for y in j:\n    ...          print(\'\', j.multi_index, y)\n    (0,)\n     (0, 0) 0\n     (0, 1) 1\n     (1, 0) 6\n     (1, 1) 7\n    (1,)\n     (0, 0) 2\n     (0, 1) 3\n     (1, 0) 8\n     (1, 1) 9\n    (2,)\n     (0, 0) 4\n     (0, 1) 5\n     (1, 0) 10\n     (1, 1) 11\n\n    ')
add_newdoc('numpy._core', 'nditer', ('close', '\n    close()\n\n    Resolve all writeback semantics in writeable operands.\n\n    .. versionadded:: 1.15.0\n\n    See Also\n    --------\n\n    :ref:`nditer-context-manager`\n\n    '))
add_newdoc('numpy._core', 'broadcast', '\n    Produce an object that mimics broadcasting.\n\n    Parameters\n    ----------\n    in1, in2, ... : array_like\n        Input parameters.\n\n    Returns\n    -------\n    b : broadcast object\n        Broadcast the input parameters against one another, and\n        return an object that encapsulates the result.\n        Amongst others, it has ``shape`` and ``nd`` properties, and\n        may be used as an iterator.\n\n    See Also\n    --------\n    broadcast_arrays\n    broadcast_to\n    broadcast_shapes\n\n    Examples\n    --------\n\n    Manually adding two vectors, using broadcasting:\n\n    >>> x = np.array([[1], [2], [3]])\n    >>> y = np.array([4, 5, 6])\n    >>> b = np.broadcast(x, y)\n\n    >>> out = np.empty(b.shape)\n    >>> out.flat = [u+v for (u,v) in b]\n    >>> out\n    array([[5.,  6.,  7.],\n           [6.,  7.,  8.],\n           [7.,  8.,  9.]])\n\n    Compare against built-in broadcasting:\n\n    >>> x + y\n    array([[5, 6, 7],\n           [6, 7, 8],\n           [7, 8, 9]])\n\n    ')
add_newdoc('numpy._core', 'broadcast', ('index', '\n    current index in broadcasted result\n\n    Examples\n    --------\n    >>> x = np.array([[1], [2], [3]])\n    >>> y = np.array([4, 5, 6])\n    >>> b = np.broadcast(x, y)\n    >>> b.index\n    0\n    >>> next(b), next(b), next(b)\n    ((1, 4), (1, 5), (1, 6))\n    >>> b.index\n    3\n\n    '))
add_newdoc('numpy._core', 'broadcast', ('iters', '\n    tuple of iterators along ``self``\'s "components."\n\n    Returns a tuple of `numpy.flatiter` objects, one for each "component"\n    of ``self``.\n\n    See Also\n    --------\n    numpy.flatiter\n\n    Examples\n    --------\n    >>> x = np.array([1, 2, 3])\n    >>> y = np.array([[4], [5], [6]])\n    >>> b = np.broadcast(x, y)\n    >>> row, col = b.iters\n    >>> next(row), next(col)\n    (1, 4)\n\n    '))
add_newdoc('numpy._core', 'broadcast', ('ndim', '\n    Number of dimensions of broadcasted result. Alias for `nd`.\n\n    .. versionadded:: 1.12.0\n\n    Examples\n    --------\n    >>> x = np.array([1, 2, 3])\n    >>> y = np.array([[4], [5], [6]])\n    >>> b = np.broadcast(x, y)\n    >>> b.ndim\n    2\n\n    '))
add_newdoc('numpy._core', 'broadcast', ('nd', '\n    Number of dimensions of broadcasted result. For code intended for NumPy\n    1.12.0 and later the more consistent `ndim` is preferred.\n\n    Examples\n    --------\n    >>> x = np.array([1, 2, 3])\n    >>> y = np.array([[4], [5], [6]])\n    >>> b = np.broadcast(x, y)\n    >>> b.nd\n    2\n\n    '))
add_newdoc('numpy._core', 'broadcast', ('numiter', '\n    Number of iterators possessed by the broadcasted result.\n\n    Examples\n    --------\n    >>> x = np.array([1, 2, 3])\n    >>> y = np.array([[4], [5], [6]])\n    >>> b = np.broadcast(x, y)\n    >>> b.numiter\n    2\n\n    '))
add_newdoc('numpy._core', 'broadcast', ('shape', '\n    Shape of broadcasted result.\n\n    Examples\n    --------\n    >>> x = np.array([1, 2, 3])\n    >>> y = np.array([[4], [5], [6]])\n    >>> b = np.broadcast(x, y)\n    >>> b.shape\n    (3, 3)\n\n    '))
add_newdoc('numpy._core', 'broadcast', ('size', '\n    Total size of broadcasted result.\n\n    Examples\n    --------\n    >>> x = np.array([1, 2, 3])\n    >>> y = np.array([[4], [5], [6]])\n    >>> b = np.broadcast(x, y)\n    >>> b.size\n    9\n\n    '))
add_newdoc('numpy._core', 'broadcast', ('reset', "\n    reset()\n\n    Reset the broadcasted result's iterator(s).\n\n    Parameters\n    ----------\n    None\n\n    Returns\n    -------\n    None\n\n    Examples\n    --------\n    >>> x = np.array([1, 2, 3])\n    >>> y = np.array([[4], [5], [6]])\n    >>> b = np.broadcast(x, y)\n    >>> b.index\n    0\n    >>> next(b), next(b), next(b)\n    ((1, 4), (2, 4), (3, 4))\n    >>> b.index\n    3\n    >>> b.reset()\n    >>> b.index\n    0\n\n    "))
add_newdoc('numpy._core.multiarray', 'array', "\n    array(object, dtype=None, *, copy=True, order='K', subok=False, ndmin=0,\n          like=None)\n\n    Create an array.\n\n    Parameters\n    ----------\n    object : array_like\n        An array, any object exposing the array interface, an object whose\n        ``__array__`` method returns an array, or any (nested) sequence.\n        If object is a scalar, a 0-dimensional array containing object is\n        returned.\n    dtype : data-type, optional\n        The desired data-type for the array. If not given, NumPy will try to use\n        a default ``dtype`` that can represent the values (by applying promotion\n        rules when necessary.)\n    copy : bool, optional\n        If true (default), then the object is copied.  Otherwise, a copy will\n        only be made if ``__array__`` returns a copy, if obj is a nested\n        sequence, or if a copy is needed to satisfy any of the other\n        requirements (``dtype``, ``order``, etc.).\n    order : {'K', 'A', 'C', 'F'}, optional\n        Specify the memory layout of the array. If object is not an array, the\n        newly created array will be in C order (row major) unless 'F' is\n        specified, in which case it will be in Fortran order (column major).\n        If object is an array the following holds.\n\n        ===== ========= ===================================================\n        order  no copy                     copy=True\n        ===== ========= ===================================================\n        'K'   unchanged F & C order preserved, otherwise most similar order\n        'A'   unchanged F order if input is F and not C, otherwise C order\n        'C'   C order   C order\n        'F'   F order   F order\n        ===== ========= ===================================================\n\n        When ``copy=False`` and a copy is made for other reasons, the result is\n        the same as if ``copy=True``, with some exceptions for 'A', see the\n        Notes section. The default order is 'K'.\n    subok : bool, optional\n        If True, then sub-classes will be passed-through, otherwise\n        the returned array will be forced to be a base-class array (default).\n    ndmin : int, optional\n        Specifies the minimum number of dimensions that the resulting\n        array should have.  Ones will be prepended to the shape as\n        needed to meet this requirement.\n    ${ARRAY_FUNCTION_LIKE}\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    out : ndarray\n        An array object satisfying the specified requirements.\n\n    See Also\n    --------\n    empty_like : Return an empty array with shape and type of input.\n    ones_like : Return an array of ones with shape and type of input.\n    zeros_like : Return an array of zeros with shape and type of input.\n    full_like : Return a new array with shape of input filled with value.\n    empty : Return a new uninitialized array.\n    ones : Return a new array setting values to one.\n    zeros : Return a new array setting values to zero.\n    full : Return a new array of given shape filled with value.\n\n\n    Notes\n    -----\n    When order is 'A' and ``object`` is an array in neither 'C' nor 'F' order,\n    and a copy is forced by a change in dtype, then the order of the result is\n    not necessarily 'C' as expected. This is likely a bug.\n\n    Examples\n    --------\n    >>> np.array([1, 2, 3])\n    array([1, 2, 3])\n\n    Upcasting:\n\n    >>> np.array([1, 2, 3.0])\n    array([ 1.,  2.,  3.])\n\n    More than one dimension:\n\n    >>> np.array([[1, 2], [3, 4]])\n    array([[1, 2],\n           [3, 4]])\n\n    Minimum dimensions 2:\n\n    >>> np.array([1, 2, 3], ndmin=2)\n    array([[1, 2, 3]])\n\n    Type provided:\n\n    >>> np.array([1, 2, 3], dtype=complex)\n    array([ 1.+0.j,  2.+0.j,  3.+0.j])\n\n    Data-type consisting of more than one element:\n\n    >>> x = np.array([(1,2),(3,4)],dtype=[('a','<i4'),('b','<i4')])\n    >>> x['a']\n    array([1, 3])\n\n    Creating an array from sub-classes:\n\n    >>> np.array(np.asmatrix('1 2; 3 4'))\n    array([[1, 2],\n           [3, 4]])\n\n    >>> np.array(np.asmatrix('1 2; 3 4'), subok=True)\n    matrix([[1, 2],\n            [3, 4]])\n\n    ".replace('${ARRAY_FUNCTION_LIKE}', array_function_like_doc))
add_newdoc('numpy._core.multiarray', 'asarray', "\n    asarray(a, dtype=None, order=None, *, like=None)\n\n    Convert the input to an array.\n\n    Parameters\n    ----------\n    a : array_like\n        Input data, in any form that can be converted to an array.  This\n        includes lists, lists of tuples, tuples, tuples of tuples, tuples\n        of lists and ndarrays.\n    dtype : data-type, optional\n        By default, the data-type is inferred from the input data.\n    order : {'C', 'F', 'A', 'K'}, optional\n        Memory layout.  'A' and 'K' depend on the order of input array a.\n        'C' row-major (C-style),\n        'F' column-major (Fortran-style) memory representation.\n        'A' (any) means 'F' if `a` is Fortran contiguous, 'C' otherwise\n        'K' (keep) preserve input order\n        Defaults to 'K'.\n    ${ARRAY_FUNCTION_LIKE}\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    out : ndarray\n        Array interpretation of `a`.  No copy is performed if the input\n        is already an ndarray with matching dtype and order.  If `a` is a\n        subclass of ndarray, a base class ndarray is returned.\n\n    See Also\n    --------\n    asanyarray : Similar function which passes through subclasses.\n    ascontiguousarray : Convert input to a contiguous array.\n    asfortranarray : Convert input to an ndarray with column-major\n                     memory order.\n    asarray_chkfinite : Similar function which checks input for NaNs and Infs.\n    fromiter : Create an array from an iterator.\n    fromfunction : Construct an array by executing a function on grid\n                   positions.\n\n    Examples\n    --------\n    Convert a list into an array:\n\n    >>> a = [1, 2]\n    >>> np.asarray(a)\n    array([1, 2])\n\n    Existing arrays are not copied:\n\n    >>> a = np.array([1, 2])\n    >>> np.asarray(a) is a\n    True\n\n    If `dtype` is set, array is copied only if dtype does not match:\n\n    >>> a = np.array([1, 2], dtype=np.float32)\n    >>> np.shares_memory(np.asarray(a, dtype=np.float32), a)\n    True\n    >>> np.shares_memory(np.asarray(a, dtype=np.float64), a)\n    False\n\n    Contrary to `asanyarray`, ndarray subclasses are not passed through:\n\n    >>> issubclass(np.recarray, np.ndarray)\n    True\n    >>> a = np.array([(1., 2), (3., 4)], dtype='f4,i4').view(np.recarray)\n    >>> np.asarray(a) is a\n    False\n    >>> np.asanyarray(a) is a\n    True\n\n    ".replace('${ARRAY_FUNCTION_LIKE}', array_function_like_doc))
add_newdoc('numpy._core.multiarray', 'asanyarray', "\n    asanyarray(a, dtype=None, order=None, *, like=None)\n\n    Convert the input to an ndarray, but pass ndarray subclasses through.\n\n    Parameters\n    ----------\n    a : array_like\n        Input data, in any form that can be converted to an array.  This\n        includes scalars, lists, lists of tuples, tuples, tuples of tuples,\n        tuples of lists, and ndarrays.\n    dtype : data-type, optional\n        By default, the data-type is inferred from the input data.\n    order : {'C', 'F', 'A', 'K'}, optional\n        Memory layout.  'A' and 'K' depend on the order of input array a.\n        'C' row-major (C-style),\n        'F' column-major (Fortran-style) memory representation.\n        'A' (any) means 'F' if `a` is Fortran contiguous, 'C' otherwise\n        'K' (keep) preserve input order\n        Defaults to 'C'.\n    ${ARRAY_FUNCTION_LIKE}\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    out : ndarray or an ndarray subclass\n        Array interpretation of `a`.  If `a` is an ndarray or a subclass\n        of ndarray, it is returned as-is and no copy is performed.\n\n    See Also\n    --------\n    asarray : Similar function which always returns ndarrays.\n    ascontiguousarray : Convert input to a contiguous array.\n    asfortranarray : Convert input to an ndarray with column-major\n                     memory order.\n    asarray_chkfinite : Similar function which checks input for NaNs and\n                        Infs.\n    fromiter : Create an array from an iterator.\n    fromfunction : Construct an array by executing a function on grid\n                   positions.\n\n    Examples\n    --------\n    Convert a list into an array:\n\n    >>> a = [1, 2]\n    >>> np.asanyarray(a)\n    array([1, 2])\n\n    Instances of `ndarray` subclasses are passed through as-is:\n\n    >>> a = np.array([(1., 2), (3., 4)], dtype='f4,i4').view(np.recarray)\n    >>> np.asanyarray(a) is a\n    True\n\n    ".replace('${ARRAY_FUNCTION_LIKE}', array_function_like_doc))
add_newdoc('numpy._core.multiarray', 'ascontiguousarray', "\n    ascontiguousarray(a, dtype=None, *, like=None)\n\n    Return a contiguous array (ndim >= 1) in memory (C order).\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    dtype : str or dtype object, optional\n        Data-type of returned array.\n    ${ARRAY_FUNCTION_LIKE}\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    out : ndarray\n        Contiguous array of same shape and content as `a`, with type `dtype`\n        if specified.\n\n    See Also\n    --------\n    asfortranarray : Convert input to an ndarray with column-major\n                     memory order.\n    require : Return an ndarray that satisfies requirements.\n    ndarray.flags : Information about the memory layout of the array.\n\n    Examples\n    --------\n    Starting with a Fortran-contiguous array:\n\n    >>> x = np.ones((2, 3), order='F')\n    >>> x.flags['F_CONTIGUOUS']\n    True\n\n    Calling ``ascontiguousarray`` makes a C-contiguous copy:\n\n    >>> y = np.ascontiguousarray(x)\n    >>> y.flags['C_CONTIGUOUS']\n    True\n    >>> np.may_share_memory(x, y)\n    False\n\n    Now, starting with a C-contiguous array:\n\n    >>> x = np.ones((2, 3), order='C')\n    >>> x.flags['C_CONTIGUOUS']\n    True\n\n    Then, calling ``ascontiguousarray`` returns the same object:\n\n    >>> y = np.ascontiguousarray(x)\n    >>> x is y\n    True\n\n    Note: This function returns an array with at least one-dimension (1-d)\n    so it will not preserve 0-d arrays.\n\n    ".replace('${ARRAY_FUNCTION_LIKE}', array_function_like_doc))
add_newdoc('numpy._core.multiarray', 'asfortranarray', "\n    asfortranarray(a, dtype=None, *, like=None)\n\n    Return an array (ndim >= 1) laid out in Fortran order in memory.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    dtype : str or dtype object, optional\n        By default, the data-type is inferred from the input data.\n    ${ARRAY_FUNCTION_LIKE}\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    out : ndarray\n        The input `a` in Fortran, or column-major, order.\n\n    See Also\n    --------\n    ascontiguousarray : Convert input to a contiguous (C order) array.\n    asanyarray : Convert input to an ndarray with either row or\n        column-major memory order.\n    require : Return an ndarray that satisfies requirements.\n    ndarray.flags : Information about the memory layout of the array.\n\n    Examples\n    --------\n    Starting with a C-contiguous array:\n\n    >>> x = np.ones((2, 3), order='C')\n    >>> x.flags['C_CONTIGUOUS']\n    True\n\n    Calling ``asfortranarray`` makes a Fortran-contiguous copy:\n\n    >>> y = np.asfortranarray(x)\n    >>> y.flags['F_CONTIGUOUS']\n    True\n    >>> np.may_share_memory(x, y)\n    False\n\n    Now, starting with a Fortran-contiguous array:\n\n    >>> x = np.ones((2, 3), order='F')\n    >>> x.flags['F_CONTIGUOUS']\n    True\n\n    Then, calling ``asfortranarray`` returns the same object:\n\n    >>> y = np.asfortranarray(x)\n    >>> x is y\n    True\n\n    Note: This function returns an array with at least one-dimension (1-d)\n    so it will not preserve 0-d arrays.\n\n    ".replace('${ARRAY_FUNCTION_LIKE}', array_function_like_doc))
add_newdoc('numpy._core.multiarray', 'empty', "\n    empty(shape, dtype=float, order='C', *, like=None)\n\n    Return a new array of given shape and type, without initializing entries.\n\n    Parameters\n    ----------\n    shape : int or tuple of int\n        Shape of the empty array, e.g., ``(2, 3)`` or ``2``.\n    dtype : data-type, optional\n        Desired output data-type for the array, e.g, `numpy.int8`. Default is\n        `numpy.float64`.\n    order : {'C', 'F'}, optional, default: 'C'\n        Whether to store multi-dimensional data in row-major\n        (C-style) or column-major (Fortran-style) order in\n        memory.\n    ${ARRAY_FUNCTION_LIKE}\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    out : ndarray\n        Array of uninitialized (arbitrary) data of the given shape, dtype, and\n        order.  Object arrays will be initialized to None.\n\n    See Also\n    --------\n    empty_like : Return an empty array with shape and type of input.\n    ones : Return a new array setting values to one.\n    zeros : Return a new array setting values to zero.\n    full : Return a new array of given shape filled with value.\n\n\n    Notes\n    -----\n    `empty`, unlike `zeros`, does not set the array values to zero,\n    and may therefore be marginally faster.  On the other hand, it requires\n    the user to manually set all the values in the array, and should be\n    used with caution.\n\n    Examples\n    --------\n    >>> np.empty([2, 2])\n    array([[ -9.74499359e+001,   6.69583040e-309],\n           [  2.13182611e-314,   3.06959433e-309]])         #uninitialized\n\n    >>> np.empty([2, 2], dtype=int)\n    array([[-1073741821, -1067949133],\n           [  496041986,    19249760]])                     #uninitialized\n\n    ".replace('${ARRAY_FUNCTION_LIKE}', array_function_like_doc))
add_newdoc('numpy._core.multiarray', 'scalar', '\n    scalar(dtype, obj)\n\n    Return a new scalar array of the given type initialized with obj.\n\n    This function is meant mainly for pickle support. `dtype` must be a\n    valid data-type descriptor. If `dtype` corresponds to an object\n    descriptor, then `obj` can be any object, otherwise `obj` must be a\n    string. If `obj` is not given, it will be interpreted as None for object\n    type and as zeros for all other types.\n\n    ')
add_newdoc('numpy._core.multiarray', 'zeros', "\n    zeros(shape, dtype=float, order='C', *, like=None)\n\n    Return a new array of given shape and type, filled with zeros.\n\n    Parameters\n    ----------\n    shape : int or tuple of ints\n        Shape of the new array, e.g., ``(2, 3)`` or ``2``.\n    dtype : data-type, optional\n        The desired data-type for the array, e.g., `numpy.int8`.  Default is\n        `numpy.float64`.\n    order : {'C', 'F'}, optional, default: 'C'\n        Whether to store multi-dimensional data in row-major\n        (C-style) or column-major (Fortran-style) order in\n        memory.\n    ${ARRAY_FUNCTION_LIKE}\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    out : ndarray\n        Array of zeros with the given shape, dtype, and order.\n\n    See Also\n    --------\n    zeros_like : Return an array of zeros with shape and type of input.\n    empty : Return a new uninitialized array.\n    ones : Return a new array setting values to one.\n    full : Return a new array of given shape filled with value.\n\n    Examples\n    --------\n    >>> np.zeros(5)\n    array([ 0.,  0.,  0.,  0.,  0.])\n\n    >>> np.zeros((5,), dtype=int)\n    array([0, 0, 0, 0, 0])\n\n    >>> np.zeros((2, 1))\n    array([[ 0.],\n           [ 0.]])\n\n    >>> s = (2,2)\n    >>> np.zeros(s)\n    array([[ 0.,  0.],\n           [ 0.,  0.]])\n\n    >>> np.zeros((2,), dtype=[('x', 'i4'), ('y', 'i4')]) # custom dtype\n    array([(0, 0), (0, 0)],\n          dtype=[('x', '<i4'), ('y', '<i4')])\n\n    ".replace('${ARRAY_FUNCTION_LIKE}', array_function_like_doc))
add_newdoc('numpy._core.multiarray', 'set_typeDict', 'set_typeDict(dict)\n\n    Set the internal dictionary that can look up an array type using a\n    registered code.\n\n    ')
add_newdoc('numpy._core.multiarray', 'fromstring', "\n    fromstring(string, dtype=float, count=-1, *, sep, like=None)\n\n    A new 1-D array initialized from text data in a string.\n\n    Parameters\n    ----------\n    string : str\n        A string containing the data.\n    dtype : data-type, optional\n        The data type of the array; default: float.  For binary input data,\n        the data must be in exactly this format. Most builtin numeric types are\n        supported and extension types may be supported.\n\n        .. versionadded:: 1.18.0\n            Complex dtypes.\n\n    count : int, optional\n        Read this number of `dtype` elements from the data.  If this is\n        negative (the default), the count will be determined from the\n        length of the data.\n    sep : str, optional\n        The string separating numbers in the data; extra whitespace between\n        elements is also ignored.\n\n        .. deprecated:: 1.14\n            Passing ``sep=''``, the default, is deprecated since it will\n            trigger the deprecated binary mode of this function. This mode\n            interprets `string` as binary bytes, rather than ASCII text with\n            decimal numbers, an operation which is better spelt\n            ``frombuffer(string, dtype, count)``. If `string` contains unicode\n            text, the binary mode of `fromstring` will first encode it into\n            bytes using utf-8, which will not produce sane results.\n\n    ${ARRAY_FUNCTION_LIKE}\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    arr : ndarray\n        The constructed array.\n\n    Raises\n    ------\n    ValueError\n        If the string is not the correct size to satisfy the requested\n        `dtype` and `count`.\n\n    See Also\n    --------\n    frombuffer, fromfile, fromiter\n\n    Examples\n    --------\n    >>> np.fromstring('1 2', dtype=int, sep=' ')\n    array([1, 2])\n    >>> np.fromstring('1, 2', dtype=int, sep=',')\n    array([1, 2])\n\n    ".replace('${ARRAY_FUNCTION_LIKE}', array_function_like_doc))
add_newdoc('numpy._core.multiarray', 'compare_chararrays', '\n    compare_chararrays(a1, a2, cmp, rstrip)\n\n    Performs element-wise comparison of two string arrays using the\n    comparison operator specified by `cmp`.\n\n    Parameters\n    ----------\n    a1, a2 : array_like\n        Arrays to be compared.\n    cmp : {"<", "<=", "==", ">=", ">", "!="}\n        Type of comparison.\n    rstrip : Boolean\n        If True, the spaces at the end of Strings are removed before the comparison.\n\n    Returns\n    -------\n    out : ndarray\n        The output array of type Boolean with the same shape as a and b.\n\n    Raises\n    ------\n    ValueError\n        If `cmp` is not valid.\n    TypeError\n        If at least one of `a` or `b` is a non-string array\n\n    Examples\n    --------\n    >>> a = np.array(["a", "b", "cde"])\n    >>> b = np.array(["a", "a", "dec"])\n    >>> np.char.compare_chararrays(a, b, ">", True)\n    array([False,  True, False])\n\n    ')
add_newdoc('numpy._core.multiarray', 'fromiter', '\n    fromiter(iter, dtype, count=-1, *, like=None)\n\n    Create a new 1-dimensional array from an iterable object.\n\n    Parameters\n    ----------\n    iter : iterable object\n        An iterable object providing data for the array.\n    dtype : data-type\n        The data-type of the returned array.\n\n        .. versionchanged:: 1.23\n            Object and subarray dtypes are now supported (note that the final\n            result is not 1-D for a subarray dtype).\n\n    count : int, optional\n        The number of items to read from *iterable*.  The default is -1,\n        which means all data is read.\n    ${ARRAY_FUNCTION_LIKE}\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    out : ndarray\n        The output array.\n\n    Notes\n    -----\n    Specify `count` to improve performance.  It allows ``fromiter`` to\n    pre-allocate the output array, instead of resizing it on demand.\n\n    Examples\n    --------\n    >>> iterable = (x*x for x in range(5))\n    >>> np.fromiter(iterable, float)\n    array([  0.,   1.,   4.,   9.,  16.])\n\n    A carefully constructed subarray dtype will lead to higher dimensional\n    results:\n\n    >>> iterable = ((x+1, x+2) for x in range(5))\n    >>> np.fromiter(iterable, dtype=np.dtype((int, 2)))\n    array([[1, 2],\n           [2, 3],\n           [3, 4],\n           [4, 5],\n           [5, 6]])\n\n\n    '.replace('${ARRAY_FUNCTION_LIKE}', array_function_like_doc))
add_newdoc('numpy._core.multiarray', 'fromfile', '\n    fromfile(file, dtype=float, count=-1, sep=\'\', offset=0, *, like=None)\n\n    Construct an array from data in a text or binary file.\n\n    A highly efficient way of reading binary data with a known data-type,\n    as well as parsing simply formatted text files.  Data written using the\n    `tofile` method can be read using this function.\n\n    Parameters\n    ----------\n    file : file or str or Path\n        Open file object or filename.\n\n        .. versionchanged:: 1.17.0\n            `pathlib.Path` objects are now accepted.\n\n    dtype : data-type\n        Data type of the returned array.\n        For binary files, it is used to determine the size and byte-order\n        of the items in the file.\n        Most builtin numeric types are supported and extension types may be supported.\n\n        .. versionadded:: 1.18.0\n            Complex dtypes.\n\n    count : int\n        Number of items to read. ``-1`` means all items (i.e., the complete\n        file).\n    sep : str\n        Separator between items if file is a text file.\n        Empty ("") separator means the file should be treated as binary.\n        Spaces (" ") in the separator match zero or more whitespace characters.\n        A separator consisting only of spaces must match at least one\n        whitespace.\n    offset : int\n        The offset (in bytes) from the file\'s current position. Defaults to 0.\n        Only permitted for binary files.\n\n        .. versionadded:: 1.17.0\n    ${ARRAY_FUNCTION_LIKE}\n\n        .. versionadded:: 1.20.0\n\n    See also\n    --------\n    load, save\n    ndarray.tofile\n    loadtxt : More flexible way of loading data from a text file.\n\n    Notes\n    -----\n    Do not rely on the combination of `tofile` and `fromfile` for\n    data storage, as the binary files generated are not platform\n    independent.  In particular, no byte-order or data-type information is\n    saved.  Data can be stored in the platform independent ``.npy`` format\n    using `save` and `load` instead.\n\n    Examples\n    --------\n    Construct an ndarray:\n\n    >>> dt = np.dtype([(\'time\', [(\'min\', np.int64), (\'sec\', np.int64)]),\n    ...                (\'temp\', float)])\n    >>> x = np.zeros((1,), dtype=dt)\n    >>> x[\'time\'][\'min\'] = 10; x[\'temp\'] = 98.25\n    >>> x\n    array([((10, 0), 98.25)],\n          dtype=[(\'time\', [(\'min\', \'<i8\'), (\'sec\', \'<i8\')]), (\'temp\', \'<f8\')])\n\n    Save the raw data to disk:\n\n    >>> import tempfile\n    >>> fname = tempfile.mkstemp()[1]\n    >>> x.tofile(fname)\n\n    Read the raw data from disk:\n\n    >>> np.fromfile(fname, dtype=dt)\n    array([((10, 0), 98.25)],\n          dtype=[(\'time\', [(\'min\', \'<i8\'), (\'sec\', \'<i8\')]), (\'temp\', \'<f8\')])\n\n    The recommended way to store and load data:\n\n    >>> np.save(fname, x)\n    >>> np.load(fname + \'.npy\')\n    array([((10, 0), 98.25)],\n          dtype=[(\'time\', [(\'min\', \'<i8\'), (\'sec\', \'<i8\')]), (\'temp\', \'<f8\')])\n\n    '.replace('${ARRAY_FUNCTION_LIKE}', array_function_like_doc))
add_newdoc('numpy._core.multiarray', 'frombuffer', "\n    frombuffer(buffer, dtype=float, count=-1, offset=0, *, like=None)\n\n    Interpret a buffer as a 1-dimensional array.\n\n    Parameters\n    ----------\n    buffer : buffer_like\n        An object that exposes the buffer interface.\n    dtype : data-type, optional\n        Data-type of the returned array; default: float.\n    count : int, optional\n        Number of items to read. ``-1`` means all data in the buffer.\n    offset : int, optional\n        Start reading the buffer from this offset (in bytes); default: 0.\n    ${ARRAY_FUNCTION_LIKE}\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    out : ndarray\n\n    See also\n    --------\n    ndarray.tobytes\n        Inverse of this operation, construct Python bytes from the raw data\n        bytes in the array.\n\n    Notes\n    -----\n    If the buffer has data that is not in machine byte-order, this should\n    be specified as part of the data-type, e.g.::\n\n      >>> dt = np.dtype(int)\n      >>> dt = dt.newbyteorder('>')\n      >>> np.frombuffer(buf, dtype=dt) # doctest: +SKIP\n\n    The data of the resulting array will not be byteswapped, but will be\n    interpreted correctly.\n\n    This function creates a view into the original object.  This should be safe\n    in general, but it may make sense to copy the result when the original\n    object is mutable or untrusted.\n\n    Examples\n    --------\n    >>> s = b'hello world'\n    >>> np.frombuffer(s, dtype='S1', count=5, offset=6)\n    array([b'w', b'o', b'r', b'l', b'd'], dtype='|S1')\n\n    >>> np.frombuffer(b'\\x01\\x02', dtype=np.uint8)\n    array([1, 2], dtype=uint8)\n    >>> np.frombuffer(b'\\x01\\x02\\x03\\x04\\x05', dtype=np.uint8, count=3)\n    array([1, 2, 3], dtype=uint8)\n\n    ".replace('${ARRAY_FUNCTION_LIKE}', array_function_like_doc))
add_newdoc('numpy._core.multiarray', 'from_dlpack', '\n    from_dlpack(x, /)\n\n    Create a NumPy array from an object implementing the ``__dlpack__``\n    protocol. Generally, the returned NumPy array is a read-only view\n    of the input object. See [1]_ and [2]_ for more details.\n\n    Parameters\n    ----------\n    x : object\n        A Python object that implements the ``__dlpack__`` and\n        ``__dlpack_device__`` methods.\n\n    Returns\n    -------\n    out : ndarray\n\n    References\n    ----------\n    .. [1] Array API documentation,\n       https://data-apis.org/array-api/latest/design_topics/data_interchange.html#syntax-for-data-interchange-with-dlpack\n\n    .. [2] Python specification for DLPack,\n       https://dmlc.github.io/dlpack/latest/python_spec.html\n\n    Examples\n    --------\n    >>> import torch\n    >>> x = torch.arange(10)\n    >>> # create a view of the torch tensor "x" in NumPy\n    >>> y = np.from_dlpack(x)\n    ')
add_newdoc('numpy._core.multiarray', 'correlate', 'cross_correlate(a,v, mode=0)')
add_newdoc('numpy._core.multiarray', 'arange', '\n    arange([start,] stop[, step,], dtype=None, *, like=None)\n\n    Return evenly spaced values within a given interval.\n\n    ``arange`` can be called with a varying number of positional arguments:\n\n    * ``arange(stop)``: Values are generated within the half-open interval\n      ``[0, stop)`` (in other words, the interval including `start` but\n      excluding `stop`).\n    * ``arange(start, stop)``: Values are generated within the half-open\n      interval ``[start, stop)``.\n    * ``arange(start, stop, step)`` Values are generated within the half-open\n      interval ``[start, stop)``, with spacing between values given by\n      ``step``.\n\n    For integer arguments the function is roughly equivalent to the Python\n    built-in :py:class:`range`, but returns an ndarray rather than a ``range``\n    instance.\n\n    When using a non-integer step, such as 0.1, it is often better to use\n    `numpy.linspace`.\n\n    See the Warning sections below for more information.\n\n    Parameters\n    ----------\n    start : integer or real, optional\n        Start of interval.  The interval includes this value.  The default\n        start value is 0.\n    stop : integer or real\n        End of interval.  The interval does not include this value, except\n        in some cases where `step` is not an integer and floating point\n        round-off affects the length of `out`.\n    step : integer or real, optional\n        Spacing between values.  For any output `out`, this is the distance\n        between two adjacent values, ``out[i+1] - out[i]``.  The default\n        step size is 1.  If `step` is specified as a position argument,\n        `start` must also be given.\n    dtype : dtype, optional\n        The type of the output array.  If `dtype` is not given, infer the data\n        type from the other input arguments.\n    ${ARRAY_FUNCTION_LIKE}\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    arange : ndarray\n        Array of evenly spaced values.\n\n        For floating point arguments, the length of the result is\n        ``ceil((stop - start)/step)``.  Because of floating point overflow,\n        this rule may result in the last element of `out` being greater\n        than `stop`.\n\n    Warnings\n    --------\n    The length of the output might not be numerically stable.\n\n    Another stability issue is due to the internal implementation of\n    `numpy.arange`.\n    The actual step value used to populate the array is\n    ``dtype(start + step) - dtype(start)`` and not `step`. Precision loss\n    can occur here, due to casting or due to using floating points when\n    `start` is much larger than `step`. This can lead to unexpected\n    behaviour. For example::\n\n      >>> np.arange(0, 5, 0.5, dtype=int)\n      array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n      >>> np.arange(-3, 3, 0.5, dtype=int)\n      array([-3, -2, -1,  0,  1,  2,  3,  4,  5,  6,  7,  8])\n\n    In such cases, the use of `numpy.linspace` should be preferred.\n\n    The built-in :py:class:`range` generates :std:doc:`Python built-in integers\n    that have arbitrary size <python:c-api/long>`, while `numpy.arange`\n    produces `numpy.int32` or `numpy.int64` numbers. This may result in\n    incorrect results for large integer values::\n\n      >>> power = 40\n      >>> modulo = 10000\n      >>> x1 = [(n ** power) % modulo for n in range(8)]\n      >>> x2 = [(n ** power) % modulo for n in np.arange(8)]\n      >>> print(x1)\n      [0, 1, 7776, 8801, 6176, 625, 6576, 4001]  # correct\n      >>> print(x2)\n      [0, 1, 7776, 7185, 0, 5969, 4816, 3361]  # incorrect\n\n    See Also\n    --------\n    numpy.linspace : Evenly spaced numbers with careful handling of endpoints.\n    numpy.ogrid: Arrays of evenly spaced numbers in N-dimensions.\n    numpy.mgrid: Grid-shaped arrays of evenly spaced numbers in N-dimensions.\n    :ref:`how-to-partition`\n\n    Examples\n    --------\n    >>> np.arange(3)\n    array([0, 1, 2])\n    >>> np.arange(3.0)\n    array([ 0.,  1.,  2.])\n    >>> np.arange(3,7)\n    array([3, 4, 5, 6])\n    >>> np.arange(3,7,2)\n    array([3, 5])\n\n    '.replace('${ARRAY_FUNCTION_LIKE}', array_function_like_doc))
add_newdoc('numpy._core.multiarray', '_get_ndarray_c_version', '_get_ndarray_c_version()\n\n    Return the compile time NPY_VERSION (formerly called NDARRAY_VERSION) number.\n\n    ')
add_newdoc('numpy._core.multiarray', '_reconstruct', '_reconstruct(subtype, shape, dtype)\n\n    Construct an empty array. Used by Pickles.\n\n    ')
add_newdoc('numpy._core.multiarray', 'set_string_function', '\n    set_string_function(f, repr=1)\n\n    Internal method to set a function to be used when pretty printing arrays.\n\n    ')
add_newdoc('numpy._core.multiarray', 'promote_types', '\n    promote_types(type1, type2)\n\n    Returns the data type with the smallest size and smallest scalar\n    kind to which both ``type1`` and ``type2`` may be safely cast.\n    The returned data type is always considered "canonical", this mainly\n    means that the promoted dtype will always be in native byte order.\n\n    This function is symmetric, but rarely associative.\n\n    Parameters\n    ----------\n    type1 : dtype or dtype specifier\n        First data type.\n    type2 : dtype or dtype specifier\n        Second data type.\n\n    Returns\n    -------\n    out : dtype\n        The promoted data type.\n\n    Notes\n    -----\n    Please see `numpy.result_type` for additional information about promotion.\n\n    .. versionadded:: 1.6.0\n\n    Starting in NumPy 1.9, promote_types function now returns a valid string\n    length when given an integer or float dtype as one argument and a string\n    dtype as another argument. Previously it always returned the input string\n    dtype, even if it wasn\'t long enough to store the max integer/float value\n    converted to a string.\n\n    .. versionchanged:: 1.23.0\n\n    NumPy now supports promotion for more structured dtypes.  It will now\n    remove unnecessary padding from a structure dtype and promote included\n    fields individually.\n\n    See Also\n    --------\n    result_type, dtype, can_cast\n\n    Examples\n    --------\n    >>> np.promote_types(\'f4\', \'f8\')\n    dtype(\'float64\')\n\n    >>> np.promote_types(\'i8\', \'f4\')\n    dtype(\'float64\')\n\n    >>> np.promote_types(\'>i8\', \'<c8\')\n    dtype(\'complex128\')\n\n    >>> np.promote_types(\'i4\', \'S8\')\n    dtype(\'S11\')\n\n    An example of a non-associative case:\n\n    >>> p = np.promote_types\n    >>> p(\'S\', p(\'i1\', \'u1\'))\n    dtype(\'S6\')\n    >>> p(p(\'S\', \'i1\'), \'u1\')\n    dtype(\'S4\')\n\n    ')
add_newdoc('numpy._core.multiarray', 'c_einsum', "\n    c_einsum(subscripts, *operands, out=None, dtype=None, order='K',\n           casting='safe')\n\n    *This documentation shadows that of the native python implementation of the `einsum` function,\n    except all references and examples related to the `optimize` argument (v 0.12.0) have been removed.*\n\n    Evaluates the Einstein summation convention on the operands.\n\n    Using the Einstein summation convention, many common multi-dimensional,\n    linear algebraic array operations can be represented in a simple fashion.\n    In *implicit* mode `einsum` computes these values.\n\n    In *explicit* mode, `einsum` provides further flexibility to compute\n    other array operations that might not be considered classical Einstein\n    summation operations, by disabling, or forcing summation over specified\n    subscript labels.\n\n    See the notes and examples for clarification.\n\n    Parameters\n    ----------\n    subscripts : str\n        Specifies the subscripts for summation as comma separated list of\n        subscript labels. An implicit (classical Einstein summation)\n        calculation is performed unless the explicit indicator '->' is\n        included as well as subscript labels of the precise output form.\n    operands : list of array_like\n        These are the arrays for the operation.\n    out : ndarray, optional\n        If provided, the calculation is done into this array.\n    dtype : {data-type, None}, optional\n        If provided, forces the calculation to use the data type specified.\n        Note that you may have to also give a more liberal `casting`\n        parameter to allow the conversions. Default is None.\n    order : {'C', 'F', 'A', 'K'}, optional\n        Controls the memory layout of the output. 'C' means it should\n        be C contiguous. 'F' means it should be Fortran contiguous,\n        'A' means it should be 'F' if the inputs are all 'F', 'C' otherwise.\n        'K' means it should be as close to the layout of the inputs as\n        is possible, including arbitrarily permuted axes.\n        Default is 'K'.\n    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n        Controls what kind of data casting may occur.  Setting this to\n        'unsafe' is not recommended, as it can adversely affect accumulations.\n\n          * 'no' means the data types should not be cast at all.\n          * 'equiv' means only byte-order changes are allowed.\n          * 'safe' means only casts which can preserve values are allowed.\n          * 'same_kind' means only safe casts or casts within a kind,\n            like float64 to float32, are allowed.\n          * 'unsafe' means any data conversions may be done.\n\n        Default is 'safe'.\n    optimize : {False, True, 'greedy', 'optimal'}, optional\n        Controls if intermediate optimization should occur. No optimization\n        will occur if False and True will default to the 'greedy' algorithm.\n        Also accepts an explicit contraction list from the ``np.einsum_path``\n        function. See ``np.einsum_path`` for more details. Defaults to False.\n\n    Returns\n    -------\n    output : ndarray\n        The calculation based on the Einstein summation convention.\n\n    See Also\n    --------\n    einsum_path, dot, inner, outer, tensordot, linalg.multi_dot\n\n    Notes\n    -----\n    .. versionadded:: 1.6.0\n\n    The Einstein summation convention can be used to compute\n    many multi-dimensional, linear algebraic array operations. `einsum`\n    provides a succinct way of representing these.\n\n    A non-exhaustive list of these operations,\n    which can be computed by `einsum`, is shown below along with examples:\n\n    * Trace of an array, :py:func:`numpy.trace`.\n    * Return a diagonal, :py:func:`numpy.diag`.\n    * Array axis summations, :py:func:`numpy.sum`.\n    * Transpositions and permutations, :py:func:`numpy.transpose`.\n    * Matrix multiplication and dot product, :py:func:`numpy.matmul` :py:func:`numpy.dot`.\n    * Vector inner and outer products, :py:func:`numpy.inner` :py:func:`numpy.outer`.\n    * Broadcasting, element-wise and scalar multiplication, :py:func:`numpy.multiply`.\n    * Tensor contractions, :py:func:`numpy.tensordot`.\n    * Chained array operations, in efficient calculation order, :py:func:`numpy.einsum_path`.\n\n    The subscripts string is a comma-separated list of subscript labels,\n    where each label refers to a dimension of the corresponding operand.\n    Whenever a label is repeated it is summed, so ``np.einsum('i,i', a, b)``\n    is equivalent to :py:func:`np.inner(a,b) <numpy.inner>`. If a label\n    appears only once, it is not summed, so ``np.einsum('i', a)`` produces a\n    view of ``a`` with no changes. A further example ``np.einsum('ij,jk', a, b)``\n    describes traditional matrix multiplication and is equivalent to\n    :py:func:`np.matmul(a,b) <numpy.matmul>`. Repeated subscript labels in one\n    operand take the diagonal. For example, ``np.einsum('ii', a)`` is equivalent\n    to :py:func:`np.trace(a) <numpy.trace>`.\n\n    In *implicit mode*, the chosen subscripts are important\n    since the axes of the output are reordered alphabetically.  This\n    means that ``np.einsum('ij', a)`` doesn't affect a 2D array, while\n    ``np.einsum('ji', a)`` takes its transpose. Additionally,\n    ``np.einsum('ij,jk', a, b)`` returns a matrix multiplication, while,\n    ``np.einsum('ij,jh', a, b)`` returns the transpose of the\n    multiplication since subscript 'h' precedes subscript 'i'.\n\n    In *explicit mode* the output can be directly controlled by\n    specifying output subscript labels.  This requires the\n    identifier '->' as well as the list of output subscript labels.\n    This feature increases the flexibility of the function since\n    summing can be disabled or forced when required. The call\n    ``np.einsum('i->', a)`` is like :py:func:`np.sum(a, axis=-1) <numpy.sum>`,\n    and ``np.einsum('ii->i', a)`` is like :py:func:`np.diag(a) <numpy.diag>`.\n    The difference is that `einsum` does not allow broadcasting by default.\n    Additionally ``np.einsum('ij,jh->ih', a, b)`` directly specifies the\n    order of the output subscript labels and therefore returns matrix\n    multiplication, unlike the example above in implicit mode.\n\n    To enable and control broadcasting, use an ellipsis.  Default\n    NumPy-style broadcasting is done by adding an ellipsis\n    to the left of each term, like ``np.einsum('...ii->...i', a)``.\n    To take the trace along the first and last axes,\n    you can do ``np.einsum('i...i', a)``, or to do a matrix-matrix\n    product with the left-most indices instead of rightmost, one can do\n    ``np.einsum('ij...,jk...->ik...', a, b)``.\n\n    When there is only one operand, no axes are summed, and no output\n    parameter is provided, a view into the operand is returned instead\n    of a new array.  Thus, taking the diagonal as ``np.einsum('ii->i', a)``\n    produces a view (changed in version 1.10.0).\n\n    `einsum` also provides an alternative way to provide the subscripts\n    and operands as ``einsum(op0, sublist0, op1, sublist1, ..., [sublistout])``.\n    If the output shape is not provided in this format `einsum` will be\n    calculated in implicit mode, otherwise it will be performed explicitly.\n    The examples below have corresponding `einsum` calls with the two\n    parameter methods.\n\n    .. versionadded:: 1.10.0\n\n    Views returned from einsum are now writeable whenever the input array\n    is writeable. For example, ``np.einsum('ijk...->kji...', a)`` will now\n    have the same effect as :py:func:`np.swapaxes(a, 0, 2) <numpy.swapaxes>`\n    and ``np.einsum('ii->i', a)`` will return a writeable view of the diagonal\n    of a 2D array.\n\n    Examples\n    --------\n    >>> a = np.arange(25).reshape(5,5)\n    >>> b = np.arange(5)\n    >>> c = np.arange(6).reshape(2,3)\n\n    Trace of a matrix:\n\n    >>> np.einsum('ii', a)\n    60\n    >>> np.einsum(a, [0,0])\n    60\n    >>> np.trace(a)\n    60\n\n    Extract the diagonal (requires explicit form):\n\n    >>> np.einsum('ii->i', a)\n    array([ 0,  6, 12, 18, 24])\n    >>> np.einsum(a, [0,0], [0])\n    array([ 0,  6, 12, 18, 24])\n    >>> np.diag(a)\n    array([ 0,  6, 12, 18, 24])\n\n    Sum over an axis (requires explicit form):\n\n    >>> np.einsum('ij->i', a)\n    array([ 10,  35,  60,  85, 110])\n    >>> np.einsum(a, [0,1], [0])\n    array([ 10,  35,  60,  85, 110])\n    >>> np.sum(a, axis=1)\n    array([ 10,  35,  60,  85, 110])\n\n    For higher dimensional arrays summing a single axis can be done with ellipsis:\n\n    >>> np.einsum('...j->...', a)\n    array([ 10,  35,  60,  85, 110])\n    >>> np.einsum(a, [Ellipsis,1], [Ellipsis])\n    array([ 10,  35,  60,  85, 110])\n\n    Compute a matrix transpose, or reorder any number of axes:\n\n    >>> np.einsum('ji', c)\n    array([[0, 3],\n           [1, 4],\n           [2, 5]])\n    >>> np.einsum('ij->ji', c)\n    array([[0, 3],\n           [1, 4],\n           [2, 5]])\n    >>> np.einsum(c, [1,0])\n    array([[0, 3],\n           [1, 4],\n           [2, 5]])\n    >>> np.transpose(c)\n    array([[0, 3],\n           [1, 4],\n           [2, 5]])\n\n    Vector inner products:\n\n    >>> np.einsum('i,i', b, b)\n    30\n    >>> np.einsum(b, [0], b, [0])\n    30\n    >>> np.inner(b,b)\n    30\n\n    Matrix vector multiplication:\n\n    >>> np.einsum('ij,j', a, b)\n    array([ 30,  80, 130, 180, 230])\n    >>> np.einsum(a, [0,1], b, [1])\n    array([ 30,  80, 130, 180, 230])\n    >>> np.dot(a, b)\n    array([ 30,  80, 130, 180, 230])\n    >>> np.einsum('...j,j', a, b)\n    array([ 30,  80, 130, 180, 230])\n\n    Broadcasting and scalar multiplication:\n\n    >>> np.einsum('..., ...', 3, c)\n    array([[ 0,  3,  6],\n           [ 9, 12, 15]])\n    >>> np.einsum(',ij', 3, c)\n    array([[ 0,  3,  6],\n           [ 9, 12, 15]])\n    >>> np.einsum(3, [Ellipsis], c, [Ellipsis])\n    array([[ 0,  3,  6],\n           [ 9, 12, 15]])\n    >>> np.multiply(3, c)\n    array([[ 0,  3,  6],\n           [ 9, 12, 15]])\n\n    Vector outer product:\n\n    >>> np.einsum('i,j', np.arange(2)+1, b)\n    array([[0, 1, 2, 3, 4],\n           [0, 2, 4, 6, 8]])\n    >>> np.einsum(np.arange(2)+1, [0], b, [1])\n    array([[0, 1, 2, 3, 4],\n           [0, 2, 4, 6, 8]])\n    >>> np.outer(np.arange(2)+1, b)\n    array([[0, 1, 2, 3, 4],\n           [0, 2, 4, 6, 8]])\n\n    Tensor contraction:\n\n    >>> a = np.arange(60.).reshape(3,4,5)\n    >>> b = np.arange(24.).reshape(4,3,2)\n    >>> np.einsum('ijk,jil->kl', a, b)\n    array([[ 4400.,  4730.],\n           [ 4532.,  4874.],\n           [ 4664.,  5018.],\n           [ 4796.,  5162.],\n           [ 4928.,  5306.]])\n    >>> np.einsum(a, [0,1,2], b, [1,0,3], [2,3])\n    array([[ 4400.,  4730.],\n           [ 4532.,  4874.],\n           [ 4664.,  5018.],\n           [ 4796.,  5162.],\n           [ 4928.,  5306.]])\n    >>> np.tensordot(a,b, axes=([1,0],[0,1]))\n    array([[ 4400.,  4730.],\n           [ 4532.,  4874.],\n           [ 4664.,  5018.],\n           [ 4796.,  5162.],\n           [ 4928.,  5306.]])\n\n    Writeable returned arrays (since version 1.10.0):\n\n    >>> a = np.zeros((3, 3))\n    >>> np.einsum('ii->i', a)[:] = 1\n    >>> a\n    array([[ 1.,  0.,  0.],\n           [ 0.,  1.,  0.],\n           [ 0.,  0.,  1.]])\n\n    Example of ellipsis use:\n\n    >>> a = np.arange(6).reshape((3,2))\n    >>> b = np.arange(12).reshape((4,3))\n    >>> np.einsum('ki,jk->ij', a, b)\n    array([[10, 28, 46, 64],\n           [13, 40, 67, 94]])\n    >>> np.einsum('ki,...k->i...', a, b)\n    array([[10, 28, 46, 64],\n           [13, 40, 67, 94]])\n    >>> np.einsum('k...,jk', a, b)\n    array([[10, 28, 46, 64],\n           [13, 40, 67, 94]])\n\n    ")
add_newdoc('numpy._core.multiarray', 'ndarray', '\n    ndarray(shape, dtype=float, buffer=None, offset=0,\n            strides=None, order=None)\n\n    An array object represents a multidimensional, homogeneous array\n    of fixed-size items.  An associated data-type object describes the\n    format of each element in the array (its byte-order, how many bytes it\n    occupies in memory, whether it is an integer, a floating point number,\n    or something else, etc.)\n\n    Arrays should be constructed using `array`, `zeros` or `empty` (refer\n    to the See Also section below).  The parameters given here refer to\n    a low-level method (`ndarray(...)`) for instantiating an array.\n\n    For more information, refer to the `numpy` module and examine the\n    methods and attributes of an array.\n\n    Parameters\n    ----------\n    (for the __new__ method; see Notes below)\n\n    shape : tuple of ints\n        Shape of created array.\n    dtype : data-type, optional\n        Any object that can be interpreted as a numpy data type.\n    buffer : object exposing buffer interface, optional\n        Used to fill the array with data.\n    offset : int, optional\n        Offset of array data in buffer.\n    strides : tuple of ints, optional\n        Strides of data in memory.\n    order : {\'C\', \'F\'}, optional\n        Row-major (C-style) or column-major (Fortran-style) order.\n\n    Attributes\n    ----------\n    T : ndarray\n        Transpose of the array.\n    data : buffer\n        The array\'s elements, in memory.\n    dtype : dtype object\n        Describes the format of the elements in the array.\n    flags : dict\n        Dictionary containing information related to memory use, e.g.,\n        \'C_CONTIGUOUS\', \'OWNDATA\', \'WRITEABLE\', etc.\n    flat : numpy.flatiter object\n        Flattened version of the array as an iterator.  The iterator\n        allows assignments, e.g., ``x.flat = 3`` (See `ndarray.flat` for\n        assignment examples; TODO).\n    imag : ndarray\n        Imaginary part of the array.\n    real : ndarray\n        Real part of the array.\n    size : int\n        Number of elements in the array.\n    itemsize : int\n        The memory use of each array element in bytes.\n    nbytes : int\n        The total number of bytes required to store the array data,\n        i.e., ``itemsize * size``.\n    ndim : int\n        The array\'s number of dimensions.\n    shape : tuple of ints\n        Shape of the array.\n    strides : tuple of ints\n        The step-size required to move from one element to the next in\n        memory. For example, a contiguous ``(3, 4)`` array of type\n        ``int16`` in C-order has strides ``(8, 2)``.  This implies that\n        to move from element to element in memory requires jumps of 2 bytes.\n        To move from row-to-row, one needs to jump 8 bytes at a time\n        (``2 * 4``).\n    ctypes : ctypes object\n        Class containing properties of the array needed for interaction\n        with ctypes.\n    base : ndarray\n        If the array is a view into another array, that array is its `base`\n        (unless that array is also a view).  The `base` array is where the\n        array data is actually stored.\n\n    See Also\n    --------\n    array : Construct an array.\n    zeros : Create an array, each element of which is zero.\n    empty : Create an array, but leave its allocated memory unchanged (i.e.,\n            it contains "garbage").\n    dtype : Create a data-type.\n    numpy.typing.NDArray : An ndarray alias :term:`generic <generic type>`\n                           w.r.t. its `dtype.type <numpy.dtype.type>`.\n\n    Notes\n    -----\n    There are two modes of creating an array using ``__new__``:\n\n    1. If `buffer` is None, then only `shape`, `dtype`, and `order`\n       are used.\n    2. If `buffer` is an object exposing the buffer interface, then\n       all keywords are interpreted.\n\n    No ``__init__`` method is needed because the array is fully initialized\n    after the ``__new__`` method.\n\n    Examples\n    --------\n    These examples illustrate the low-level `ndarray` constructor.  Refer\n    to the `See Also` section above for easier ways of constructing an\n    ndarray.\n\n    First mode, `buffer` is None:\n\n    >>> np.ndarray(shape=(2,2), dtype=float, order=\'F\')\n    array([[0.0e+000, 0.0e+000], # random\n           [     nan, 2.5e-323]])\n\n    Second mode:\n\n    >>> np.ndarray((2,), buffer=np.array([1,2,3]),\n    ...            offset=np.int_().itemsize,\n    ...            dtype=int) # offset = 1*itemsize, i.e. skip first element\n    array([2, 3])\n\n    ')
add_newdoc('numpy._core.multiarray', 'ndarray', ('__array_interface__', 'Array protocol: Python side.'))
add_newdoc('numpy._core.multiarray', 'ndarray', ('__array_priority__', 'Array priority.'))
add_newdoc('numpy._core.multiarray', 'ndarray', ('__array_struct__', 'Array protocol: C-struct side.'))
add_newdoc('numpy._core.multiarray', 'ndarray', ('__dlpack__', 'a.__dlpack__(*, stream=None)\n\n    DLPack Protocol: Part of the Array API.'))
add_newdoc('numpy._core.multiarray', 'ndarray', ('__dlpack_device__', 'a.__dlpack_device__()\n\n    DLPack Protocol: Part of the Array API.'))
add_newdoc('numpy._core.multiarray', 'ndarray', ('base', '\n    Base object if memory is from some other object.\n\n    Examples\n    --------\n    The base of an array that owns its memory is None:\n\n    >>> x = np.array([1,2,3,4])\n    >>> x.base is None\n    True\n\n    Slicing creates a view, whose memory is shared with x:\n\n    >>> y = x[2:]\n    >>> y.base is x\n    True\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('ctypes', '\n    An object to simplify the interaction of the array with the ctypes\n    module.\n\n    This attribute creates an object that makes it easier to use arrays\n    when calling shared libraries with the ctypes module. The returned\n    object has, among others, data, shape, and strides attributes (see\n    Notes below) which themselves return ctypes objects that can be used\n    as arguments to a shared library.\n\n    Parameters\n    ----------\n    None\n\n    Returns\n    -------\n    c : Python object\n        Possessing attributes data, shape, strides, etc.\n\n    See Also\n    --------\n    numpy.ctypeslib\n\n    Notes\n    -----\n    Below are the public attributes of this object which were documented\n    in "Guide to NumPy" (we have omitted undocumented public attributes,\n    as well as documented private attributes):\n\n    .. autoattribute:: numpy._core._internal._ctypes.data\n        :noindex:\n\n    .. autoattribute:: numpy._core._internal._ctypes.shape\n        :noindex:\n\n    .. autoattribute:: numpy._core._internal._ctypes.strides\n        :noindex:\n\n    .. automethod:: numpy._core._internal._ctypes.data_as\n        :noindex:\n\n    .. automethod:: numpy._core._internal._ctypes.shape_as\n        :noindex:\n\n    .. automethod:: numpy._core._internal._ctypes.strides_as\n        :noindex:\n\n    If the ctypes module is not available, then the ctypes attribute\n    of array objects still returns something useful, but ctypes objects\n    are not returned and errors may be raised instead. In particular,\n    the object will still have the ``as_parameter`` attribute which will\n    return an integer equal to the data attribute.\n\n    Examples\n    --------\n    >>> import ctypes\n    >>> x = np.array([[0, 1], [2, 3]], dtype=np.int32)\n    >>> x\n    array([[0, 1],\n           [2, 3]], dtype=int32)\n    >>> x.ctypes.data\n    31962608 # may vary\n    >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32))\n    <__main__.LP_c_uint object at 0x7ff2fc1fc200> # may vary\n    >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint32)).contents\n    c_uint(0)\n    >>> x.ctypes.data_as(ctypes.POINTER(ctypes.c_uint64)).contents\n    c_ulong(4294967296)\n    >>> x.ctypes.shape\n    <numpy._core._internal.c_long_Array_2 object at 0x7ff2fc1fce60> # may vary\n    >>> x.ctypes.strides\n    <numpy._core._internal.c_long_Array_2 object at 0x7ff2fc1ff320> # may vary\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('data', "Python buffer object pointing to the start of the array's data."))
add_newdoc('numpy._core.multiarray', 'ndarray', ('dtype', "\n    Data-type of the array's elements.\n\n    .. warning::\n\n        Setting ``arr.dtype`` is discouraged and may be deprecated in the\n        future.  Setting will replace the ``dtype`` without modifying the\n        memory (see also `ndarray.view` and `ndarray.astype`).\n\n    Parameters\n    ----------\n    None\n\n    Returns\n    -------\n    d : numpy dtype object\n\n    See Also\n    --------\n    ndarray.astype : Cast the values contained in the array to a new data-type.\n    ndarray.view : Create a view of the same data but a different data-type.\n    numpy.dtype\n\n    Examples\n    --------\n    >>> x\n    array([[0, 1],\n           [2, 3]])\n    >>> x.dtype\n    dtype('int32')\n    >>> type(x.dtype)\n    <type 'numpy.dtype'>\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('imag', "\n    The imaginary part of the array.\n\n    Examples\n    --------\n    >>> x = np.sqrt([1+0j, 0+1j])\n    >>> x.imag\n    array([ 0.        ,  0.70710678])\n    >>> x.imag.dtype\n    dtype('float64')\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('itemsize', '\n    Length of one array element in bytes.\n\n    Examples\n    --------\n    >>> x = np.array([1,2,3], dtype=np.float64)\n    >>> x.itemsize\n    8\n    >>> x = np.array([1,2,3], dtype=np.complex128)\n    >>> x.itemsize\n    16\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('flags', "\n    Information about the memory layout of the array.\n\n    Attributes\n    ----------\n    C_CONTIGUOUS (C)\n        The data is in a single, C-style contiguous segment.\n    F_CONTIGUOUS (F)\n        The data is in a single, Fortran-style contiguous segment.\n    OWNDATA (O)\n        The array owns the memory it uses or borrows it from another object.\n    WRITEABLE (W)\n        The data area can be written to.  Setting this to False locks\n        the data, making it read-only.  A view (slice, etc.) inherits WRITEABLE\n        from its base array at creation time, but a view of a writeable\n        array may be subsequently locked while the base array remains writeable.\n        (The opposite is not true, in that a view of a locked array may not\n        be made writeable.  However, currently, locking a base object does not\n        lock any views that already reference it, so under that circumstance it\n        is possible to alter the contents of a locked array via a previously\n        created writeable view onto it.)  Attempting to change a non-writeable\n        array raises a RuntimeError exception.\n    ALIGNED (A)\n        The data and all elements are aligned appropriately for the hardware.\n    WRITEBACKIFCOPY (X)\n        This array is a copy of some other array. The C-API function\n        PyArray_ResolveWritebackIfCopy must be called before deallocating\n        to the base array will be updated with the contents of this array.\n    FNC\n        F_CONTIGUOUS and not C_CONTIGUOUS.\n    FORC\n        F_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n    BEHAVED (B)\n        ALIGNED and WRITEABLE.\n    CARRAY (CA)\n        BEHAVED and C_CONTIGUOUS.\n    FARRAY (FA)\n        BEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n\n    Notes\n    -----\n    The `flags` object can be accessed dictionary-like (as in ``a.flags['WRITEABLE']``),\n    or by using lowercased attribute names (as in ``a.flags.writeable``). Short flag\n    names are only supported in dictionary access.\n\n    Only the WRITEBACKIFCOPY, WRITEABLE, and ALIGNED flags can be\n    changed by the user, via direct assignment to the attribute or dictionary\n    entry, or by calling `ndarray.setflags`.\n\n    The array flags cannot be set arbitrarily:\n\n    - WRITEBACKIFCOPY can only be set ``False``.\n    - ALIGNED can only be set ``True`` if the data is truly aligned.\n    - WRITEABLE can only be set ``True`` if the array owns its own memory\n      or the ultimate owner of the memory exposes a writeable buffer\n      interface or is a string.\n\n    Arrays can be both C-style and Fortran-style contiguous simultaneously.\n    This is clear for 1-dimensional arrays, but can also be true for higher\n    dimensional arrays.\n\n    Even for contiguous arrays a stride for a given dimension\n    ``arr.strides[dim]`` may be *arbitrary* if ``arr.shape[dim] == 1``\n    or the array has no elements.\n    It does *not* generally hold that ``self.strides[-1] == self.itemsize``\n    for C-style contiguous arrays or ``self.strides[0] == self.itemsize`` for\n    Fortran-style contiguous arrays is true.\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('flat', "\n    A 1-D iterator over the array.\n\n    This is a `numpy.flatiter` instance, which acts similarly to, but is not\n    a subclass of, Python's built-in iterator object.\n\n    See Also\n    --------\n    flatten : Return a copy of the array collapsed into one dimension.\n\n    flatiter\n\n    Examples\n    --------\n    >>> x = np.arange(1, 7).reshape(2, 3)\n    >>> x\n    array([[1, 2, 3],\n           [4, 5, 6]])\n    >>> x.flat[3]\n    4\n    >>> x.T\n    array([[1, 4],\n           [2, 5],\n           [3, 6]])\n    >>> x.T.flat[3]\n    5\n    >>> type(x.flat)\n    <class 'numpy.flatiter'>\n\n    An assignment example:\n\n    >>> x.flat = 3; x\n    array([[3, 3, 3],\n           [3, 3, 3]])\n    >>> x.flat[[1,4]] = 1; x\n    array([[3, 1, 3],\n           [3, 1, 3]])\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('nbytes', '\n    Total bytes consumed by the elements of the array.\n\n    Notes\n    -----\n    Does not include memory consumed by non-element attributes of the\n    array object.\n\n    See Also\n    --------\n    sys.getsizeof\n        Memory consumed by the object itself without parents in case view.\n        This does include memory consumed by non-element attributes.\n\n    Examples\n    --------\n    >>> x = np.zeros((3,5,2), dtype=np.complex128)\n    >>> x.nbytes\n    480\n    >>> np.prod(x.shape) * x.itemsize\n    480\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('ndim', '\n    Number of array dimensions.\n\n    Examples\n    --------\n    >>> x = np.array([1, 2, 3])\n    >>> x.ndim\n    1\n    >>> y = np.zeros((2, 3, 4))\n    >>> y.ndim\n    3\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('real', "\n    The real part of the array.\n\n    Examples\n    --------\n    >>> x = np.sqrt([1+0j, 0+1j])\n    >>> x.real\n    array([ 1.        ,  0.70710678])\n    >>> x.real.dtype\n    dtype('float64')\n\n    See Also\n    --------\n    numpy.real : equivalent function\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('shape', '\n    Tuple of array dimensions.\n\n    The shape property is usually used to get the current shape of an array,\n    but may also be used to reshape the array in-place by assigning a tuple of\n    array dimensions to it.  As with `numpy.reshape`, one of the new shape\n    dimensions can be -1, in which case its value is inferred from the size of\n    the array and the remaining dimensions. Reshaping an array in-place will\n    fail if a copy is required.\n\n    .. warning::\n\n        Setting ``arr.shape`` is discouraged and may be deprecated in the\n        future.  Using `ndarray.reshape` is the preferred approach.\n\n    Examples\n    --------\n    >>> x = np.array([1, 2, 3, 4])\n    >>> x.shape\n    (4,)\n    >>> y = np.zeros((2, 3, 4))\n    >>> y.shape\n    (2, 3, 4)\n    >>> y.shape = (3, 8)\n    >>> y\n    array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n    >>> y.shape = (3, 6)\n    Traceback (most recent call last):\n      File "<stdin>", line 1, in <module>\n    ValueError: total size of new array must be unchanged\n    >>> np.zeros((4,2))[::2].shape = (-1,)\n    Traceback (most recent call last):\n      File "<stdin>", line 1, in <module>\n    AttributeError: Incompatible shape for in-place modification. Use\n    `.reshape()` to make a copy with the desired shape.\n\n    See Also\n    --------\n    numpy.shape : Equivalent getter function.\n    numpy.reshape : Function similar to setting ``shape``.\n    ndarray.reshape : Method similar to setting ``shape``.\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('size', "\n    Number of elements in the array.\n\n    Equal to ``np.prod(a.shape)``, i.e., the product of the array's\n    dimensions.\n\n    Notes\n    -----\n    `a.size` returns a standard arbitrary precision Python integer. This\n    may not be the case with other methods of obtaining the same value\n    (like the suggested ``np.prod(a.shape)``, which returns an instance\n    of ``np.int_``), and may be relevant if the value is used further in\n    calculations that may overflow a fixed size integer type.\n\n    Examples\n    --------\n    >>> x = np.zeros((3, 5, 2), dtype=np.complex128)\n    >>> x.size\n    30\n    >>> np.prod(x.shape)\n    30\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('strides', '\n    Tuple of bytes to step in each dimension when traversing an array.\n\n    The byte offset of element ``(i[0], i[1], ..., i[n])`` in an array `a`\n    is::\n\n        offset = sum(np.array(i) * a.strides)\n\n    A more detailed explanation of strides can be found in\n    :ref:`arrays.ndarray`.\n\n    .. warning::\n\n        Setting ``arr.strides`` is discouraged and may be deprecated in the\n        future.  `numpy.lib.stride_tricks.as_strided` should be preferred\n        to create a new view of the same data in a safer way.\n\n    Notes\n    -----\n    Imagine an array of 32-bit integers (each 4 bytes)::\n\n      x = np.array([[0, 1, 2, 3, 4],\n                    [5, 6, 7, 8, 9]], dtype=np.int32)\n\n    This array is stored in memory as 40 bytes, one after the other\n    (known as a contiguous block of memory).  The strides of an array tell\n    us how many bytes we have to skip in memory to move to the next position\n    along a certain axis.  For example, we have to skip 4 bytes (1 value) to\n    move to the next column, but 20 bytes (5 values) to get to the same\n    position in the next row.  As such, the strides for the array `x` will be\n    ``(20, 4)``.\n\n    See Also\n    --------\n    numpy.lib.stride_tricks.as_strided\n\n    Examples\n    --------\n    >>> y = np.reshape(np.arange(2*3*4), (2,3,4))\n    >>> y\n    array([[[ 0,  1,  2,  3],\n            [ 4,  5,  6,  7],\n            [ 8,  9, 10, 11]],\n           [[12, 13, 14, 15],\n            [16, 17, 18, 19],\n            [20, 21, 22, 23]]])\n    >>> y.strides\n    (48, 16, 4)\n    >>> y[1,1,1]\n    17\n    >>> offset=sum(y.strides * np.array((1,1,1)))\n    >>> offset/y.itemsize\n    17\n\n    >>> x = np.reshape(np.arange(5*6*7*8), (5,6,7,8)).transpose(2,3,1,0)\n    >>> x.strides\n    (32, 4, 224, 1344)\n    >>> i = np.array([3,5,2,2])\n    >>> offset = sum(i * x.strides)\n    >>> x[3,5,2,2]\n    813\n    >>> offset / x.itemsize\n    813\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('T', '\n    View of the transposed array.\n\n    Same as ``self.transpose()``.\n\n    Examples\n    --------\n    >>> a = np.array([[1, 2], [3, 4]])\n    >>> a\n    array([[1, 2],\n           [3, 4]])\n    >>> a.T\n    array([[1, 3],\n           [2, 4]])\n\n    >>> a = np.array([1, 2, 3, 4])\n    >>> a\n    array([1, 2, 3, 4])\n    >>> a.T\n    array([1, 2, 3, 4])\n\n    See Also\n    --------\n    transpose\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('mT', '\n    View of the matrix transposed array.\n    \n    The matrix transpose is the transpose of the last two dimensions, even\n    if the array is of higher dimension.\n\n    .. versionadded:: 2.0\n\n    Raises\n    ------\n    ValueError\n        If the array is of dimension less than 2.\n        \n    Examples\n    --------\n    >>> a = np.array([[1, 2], [3, 4]])\n    >>> a\n    array([[1, 2],\n           [3, 4]])\n    >>> a.mT\n    array([[1, 3],\n           [2, 4]])\n           \n    >>> a = np.arange(8).reshape((2, 2, 2))\n    >>> a\n    array([[[0, 1],\n            [2, 3]],\n    <BLANKLINE>\n           [[4, 5],\n            [6, 7]]])\n    >>> a.mT\n    array([[[0, 2],\n            [1, 3]],\n    <BLANKLINE>\n           [[4, 6],\n            [5, 7]]])\n    \n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('__array__', '\n    a.__array__([dtype], /)\n\n    Returns either a new reference to self if dtype is not given or a new array\n    of provided data type if dtype is different from the current dtype of the\n    array.\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('__array_finalize__', '\n    a.__array_finalize__(obj, /)\n\n    Present so subclasses can call super. Does nothing.\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('__array_wrap__', '\n    a.__array_wrap__(array[, context], /)\n\n    Returns a view of `array` with the same type as self.\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('__copy__', "\n    a.__copy__()\n\n    Used if :func:`copy.copy` is called on an array. Returns a copy of the array.\n\n    Equivalent to ``a.copy(order='K')``.\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('__class_getitem__', '\n    a.__class_getitem__(item, /)\n\n    Return a parametrized wrapper around the `~numpy.ndarray` type.\n\n    .. versionadded:: 1.22\n\n    Returns\n    -------\n    alias : types.GenericAlias\n        A parametrized `~numpy.ndarray` type.\n\n    Examples\n    --------\n    >>> from typing import Any\n    >>> import numpy as np\n\n    >>> np.ndarray[Any, np.dtype[Any]]\n    numpy.ndarray[typing.Any, numpy.dtype[typing.Any]]\n\n    See Also\n    --------\n    :pep:`585` : Type hinting generics in standard collections.\n    numpy.typing.NDArray : An ndarray alias :term:`generic <generic type>`\n                        w.r.t. its `dtype.type <numpy.dtype.type>`.\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('__deepcopy__', '\n    a.__deepcopy__(memo, /)\n\n    Used if :func:`copy.deepcopy` is called on an array.\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('__reduce__', '\n    a.__reduce__()\n\n    For pickling.\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('__setstate__', "\n    a.__setstate__(state, /)\n\n    For unpickling.\n\n    The `state` argument must be a sequence that contains the following\n    elements:\n\n    Parameters\n    ----------\n    version : int\n        optional pickle version. If omitted defaults to 0.\n    shape : tuple\n    dtype : data-type\n    isFortran : bool\n    rawdata : string or list\n        a binary string with the data (or a list if 'a' is an object array)\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('all', '\n    a.all(axis=None, out=None, keepdims=False, *, where=True)\n\n    Returns True if all elements evaluate to True.\n\n    Refer to `numpy.all` for full documentation.\n\n    See Also\n    --------\n    numpy.all : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('any', '\n    a.any(axis=None, out=None, keepdims=False, *, where=True)\n\n    Returns True if any of the elements of `a` evaluate to True.\n\n    Refer to `numpy.any` for full documentation.\n\n    See Also\n    --------\n    numpy.any : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('argmax', '\n    a.argmax(axis=None, out=None, *, keepdims=False)\n\n    Return indices of the maximum values along the given axis.\n\n    Refer to `numpy.argmax` for full documentation.\n\n    See Also\n    --------\n    numpy.argmax : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('argmin', '\n    a.argmin(axis=None, out=None, *, keepdims=False)\n\n    Return indices of the minimum values along the given axis.\n\n    Refer to `numpy.argmin` for detailed documentation.\n\n    See Also\n    --------\n    numpy.argmin : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('argsort', '\n    a.argsort(axis=-1, kind=None, order=None)\n\n    Returns the indices that would sort this array.\n\n    Refer to `numpy.argsort` for full documentation.\n\n    See Also\n    --------\n    numpy.argsort : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('argpartition', "\n    a.argpartition(kth, axis=-1, kind='introselect', order=None)\n\n    Returns the indices that would partition this array.\n\n    Refer to `numpy.argpartition` for full documentation.\n\n    .. versionadded:: 1.8.0\n\n    See Also\n    --------\n    numpy.argpartition : equivalent function\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('astype', '\n    a.astype(dtype, order=\'K\', casting=\'unsafe\', subok=True, copy=True)\n\n    Copy of the array, cast to a specified type.\n\n    Parameters\n    ----------\n    dtype : str or dtype\n        Typecode or data-type to which the array is cast.\n    order : {\'C\', \'F\', \'A\', \'K\'}, optional\n        Controls the memory layout order of the result.\n        \'C\' means C order, \'F\' means Fortran order, \'A\'\n        means \'F\' order if all the arrays are Fortran contiguous,\n        \'C\' order otherwise, and \'K\' means as close to the\n        order the array elements appear in memory as possible.\n        Default is \'K\'.\n    casting : {\'no\', \'equiv\', \'safe\', \'same_kind\', \'unsafe\'}, optional\n        Controls what kind of data casting may occur. Defaults to \'unsafe\'\n        for backwards compatibility.\n\n        * \'no\' means the data types should not be cast at all.\n        * \'equiv\' means only byte-order changes are allowed.\n        * \'safe\' means only casts which can preserve values are allowed.\n        * \'same_kind\' means only safe casts or casts within a kind,\n          like float64 to float32, are allowed.\n        * \'unsafe\' means any data conversions may be done.\n    subok : bool, optional\n        If True, then sub-classes will be passed-through (default), otherwise\n        the returned array will be forced to be a base-class array.\n    copy : bool, optional\n        By default, astype always returns a newly allocated array. If this\n        is set to false, and the `dtype`, `order`, and `subok`\n        requirements are satisfied, the input array is returned instead\n        of a copy.\n\n    Returns\n    -------\n    arr_t : ndarray\n        Unless `copy` is False and the other conditions for returning the input\n        array are satisfied (see description for `copy` input parameter), `arr_t`\n        is a new array of the same shape as the input array, with dtype, order\n        given by `dtype`, `order`.\n\n    Notes\n    -----\n    .. versionchanged:: 1.17.0\n       Casting between a simple data type and a structured one is possible only\n       for "unsafe" casting.  Casting to multiple fields is allowed, but\n       casting from multiple fields is not.\n\n    .. versionchanged:: 1.9.0\n       Casting from numeric to string types in \'safe\' casting mode requires\n       that the string dtype length is long enough to store the max\n       integer/float value converted.\n\n    Raises\n    ------\n    ComplexWarning\n        When casting from complex to float or int. To avoid this,\n        one should use ``a.real.astype(t)``.\n\n    Examples\n    --------\n    >>> x = np.array([1, 2, 2.5])\n    >>> x\n    array([1. ,  2. ,  2.5])\n\n    >>> x.astype(int)\n    array([1, 2, 2])\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('byteswap', "\n    a.byteswap(inplace=False)\n\n    Swap the bytes of the array elements\n\n    Toggle between low-endian and big-endian data representation by\n    returning a byteswapped array, optionally swapped in-place.\n    Arrays of byte-strings are not swapped. The real and imaginary\n    parts of a complex number are swapped individually.\n\n    Parameters\n    ----------\n    inplace : bool, optional\n        If ``True``, swap bytes in-place, default is ``False``.\n\n    Returns\n    -------\n    out : ndarray\n        The byteswapped array. If `inplace` is ``True``, this is\n        a view to self.\n\n    Examples\n    --------\n    >>> A = np.array([1, 256, 8755], dtype=np.int16)\n    >>> list(map(hex, A))\n    ['0x1', '0x100', '0x2233']\n    >>> A.byteswap(inplace=True)\n    array([  256,     1, 13090], dtype=int16)\n    >>> list(map(hex, A))\n    ['0x100', '0x1', '0x3322']\n\n    Arrays of byte-strings are not swapped\n\n    >>> A = np.array([b'ceg', b'fac'])\n    >>> A.byteswap()\n    array([b'ceg', b'fac'], dtype='|S3')\n\n    ``A.view(A.dtype.newbyteorder()).byteswap()`` produces an array with\n    the same values but different representation in memory\n\n    >>> A = np.array([1, 2, 3])\n    >>> A.view(np.uint8)\n    array([1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0,\n           0, 0], dtype=uint8)\n    >>> A.view(A.dtype.newbyteorder()).byteswap(inplace=True)\n    array([1, 2, 3])\n    >>> A.view(np.uint8)\n    array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n           0, 3], dtype=uint8)\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('choose', "\n    a.choose(choices, out=None, mode='raise')\n\n    Use an index array to construct a new array from a set of choices.\n\n    Refer to `numpy.choose` for full documentation.\n\n    See Also\n    --------\n    numpy.choose : equivalent function\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('clip', '\n    a.clip(min=None, max=None, out=None, **kwargs)\n\n    Return an array whose values are limited to ``[min, max]``.\n    One of max or min must be given.\n\n    Refer to `numpy.clip` for full documentation.\n\n    See Also\n    --------\n    numpy.clip : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('compress', '\n    a.compress(condition, axis=None, out=None)\n\n    Return selected slices of this array along given axis.\n\n    Refer to `numpy.compress` for full documentation.\n\n    See Also\n    --------\n    numpy.compress : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('conj', '\n    a.conj()\n\n    Complex-conjugate all elements.\n\n    Refer to `numpy.conjugate` for full documentation.\n\n    See Also\n    --------\n    numpy.conjugate : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('conjugate', '\n    a.conjugate()\n\n    Return the complex conjugate, element-wise.\n\n    Refer to `numpy.conjugate` for full documentation.\n\n    See Also\n    --------\n    numpy.conjugate : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('copy', "\n    a.copy(order='C')\n\n    Return a copy of the array.\n\n    Parameters\n    ----------\n    order : {'C', 'F', 'A', 'K'}, optional\n        Controls the memory layout of the copy. 'C' means C-order,\n        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,\n        'C' otherwise. 'K' means match the layout of `a` as closely\n        as possible. (Note that this function and :func:`numpy.copy` are very\n        similar but have different default values for their order=\n        arguments, and this function always passes sub-classes through.)\n\n    See also\n    --------\n    numpy.copy : Similar function with different default behavior\n    numpy.copyto\n\n    Notes\n    -----\n    This function is the preferred method for creating an array copy.  The\n    function :func:`numpy.copy` is similar, but it defaults to using order 'K',\n    and will not pass sub-classes through by default.\n\n    Examples\n    --------\n    >>> x = np.array([[1,2,3],[4,5,6]], order='F')\n\n    >>> y = x.copy()\n\n    >>> x.fill(0)\n\n    >>> x\n    array([[0, 0, 0],\n           [0, 0, 0]])\n\n    >>> y\n    array([[1, 2, 3],\n           [4, 5, 6]])\n\n    >>> y.flags['C_CONTIGUOUS']\n    True\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('cumprod', '\n    a.cumprod(axis=None, dtype=None, out=None)\n\n    Return the cumulative product of the elements along the given axis.\n\n    Refer to `numpy.cumprod` for full documentation.\n\n    See Also\n    --------\n    numpy.cumprod : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('cumsum', '\n    a.cumsum(axis=None, dtype=None, out=None)\n\n    Return the cumulative sum of the elements along the given axis.\n\n    Refer to `numpy.cumsum` for full documentation.\n\n    See Also\n    --------\n    numpy.cumsum : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('diagonal', '\n    a.diagonal(offset=0, axis1=0, axis2=1)\n\n    Return specified diagonals. In NumPy 1.9 the returned array is a\n    read-only view instead of a copy as in previous NumPy versions.  In\n    a future version the read-only restriction will be removed.\n\n    Refer to :func:`numpy.diagonal` for full documentation.\n\n    See Also\n    --------\n    numpy.diagonal : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', 'dot')
add_newdoc('numpy._core.multiarray', 'ndarray', ('dump', '\n    a.dump(file)\n\n    Dump a pickle of the array to the specified file.\n    The array can be read back with pickle.load or numpy.load.\n\n    Parameters\n    ----------\n    file : str or Path\n        A string naming the dump file.\n\n        .. versionchanged:: 1.17.0\n            `pathlib.Path` objects are now accepted.\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('dumps', '\n    a.dumps()\n\n    Returns the pickle of the array as a string.\n    pickle.loads will convert the string back to an array.\n\n    Parameters\n    ----------\n    None\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('fill', '\n    a.fill(value)\n\n    Fill the array with a scalar value.\n\n    Parameters\n    ----------\n    value : scalar\n        All elements of `a` will be assigned this value.\n\n    Examples\n    --------\n    >>> a = np.array([1, 2])\n    >>> a.fill(0)\n    >>> a\n    array([0, 0])\n    >>> a = np.empty(2)\n    >>> a.fill(1)\n    >>> a\n    array([1.,  1.])\n\n    Fill expects a scalar value and always behaves the same as assigning\n    to a single array element.  The following is a rare example where this\n    distinction is important:\n\n    >>> a = np.array([None, None], dtype=object)\n    >>> a[0] = np.array(3)\n    >>> a\n    array([array(3), None], dtype=object)\n    >>> a.fill(np.array(3))\n    >>> a\n    array([array(3), array(3)], dtype=object)\n\n    Where other forms of assignments will unpack the array being assigned:\n\n    >>> a[...] = np.array(3)\n    >>> a\n    array([3, 3], dtype=object)\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('flatten', "\n    a.flatten(order='C')\n\n    Return a copy of the array collapsed into one dimension.\n\n    Parameters\n    ----------\n    order : {'C', 'F', 'A', 'K'}, optional\n        'C' means to flatten in row-major (C-style) order.\n        'F' means to flatten in column-major (Fortran-\n        style) order. 'A' means to flatten in column-major\n        order if `a` is Fortran *contiguous* in memory,\n        row-major order otherwise. 'K' means to flatten\n        `a` in the order the elements occur in memory.\n        The default is 'C'.\n\n    Returns\n    -------\n    y : ndarray\n        A copy of the input array, flattened to one dimension.\n\n    See Also\n    --------\n    ravel : Return a flattened array.\n    flat : A 1-D flat iterator over the array.\n\n    Examples\n    --------\n    >>> a = np.array([[1,2], [3,4]])\n    >>> a.flatten()\n    array([1, 2, 3, 4])\n    >>> a.flatten('F')\n    array([1, 3, 2, 4])\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('getfield', '\n    a.getfield(dtype, offset=0)\n\n    Returns a field of the given array as a certain type.\n\n    A field is a view of the array data with a given data-type. The values in\n    the view are determined by the given type and the offset into the current\n    array in bytes. The offset needs to be such that the view dtype fits in the\n    array dtype; for example an array of dtype complex128 has 16-byte elements.\n    If taking a view with a 32-bit integer (4 bytes), the offset needs to be\n    between 0 and 12 bytes.\n\n    Parameters\n    ----------\n    dtype : str or dtype\n        The data type of the view. The dtype size of the view can not be larger\n        than that of the array itself.\n    offset : int\n        Number of bytes to skip before beginning the element view.\n\n    Examples\n    --------\n    >>> x = np.diag([1.+1.j]*2)\n    >>> x[1, 1] = 2 + 4.j\n    >>> x\n    array([[1.+1.j,  0.+0.j],\n           [0.+0.j,  2.+4.j]])\n    >>> x.getfield(np.float64)\n    array([[1.,  0.],\n           [0.,  2.]])\n\n    By choosing an offset of 8 bytes we can select the complex part of the\n    array for our view:\n\n    >>> x.getfield(np.float64, offset=8)\n    array([[1.,  0.],\n           [0.,  4.]])\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('item', "\n    a.item(*args)\n\n    Copy an element of an array to a standard Python scalar and return it.\n\n    Parameters\n    ----------\n    \\*args : Arguments (variable number and type)\n\n        * none: in this case, the method only works for arrays\n          with one element (`a.size == 1`), which element is\n          copied into a standard Python scalar object and returned.\n\n        * int_type: this argument is interpreted as a flat index into\n          the array, specifying which element to copy and return.\n\n        * tuple of int_types: functions as does a single int_type argument,\n          except that the argument is interpreted as an nd-index into the\n          array.\n\n    Returns\n    -------\n    z : Standard Python scalar object\n        A copy of the specified element of the array as a suitable\n        Python scalar\n\n    Notes\n    -----\n    When the data type of `a` is longdouble or clongdouble, item() returns\n    a scalar array object because there is no available Python scalar that\n    would not lose information. Void arrays return a buffer object for item(),\n    unless fields are defined, in which case a tuple is returned.\n\n    `item` is very similar to a[args], except, instead of an array scalar,\n    a standard Python scalar is returned. This can be useful for speeding up\n    access to elements of the array and doing arithmetic on elements of the\n    array using Python's optimized math.\n\n    Examples\n    --------\n    >>> np.random.seed(123)\n    >>> x = np.random.randint(9, size=(3, 3))\n    >>> x\n    array([[2, 2, 6],\n           [1, 3, 6],\n           [1, 0, 1]])\n    >>> x.item(3)\n    1\n    >>> x.item(7)\n    0\n    >>> x.item((0, 1))\n    2\n    >>> x.item((2, 2))\n    1\n\n    For an array with object dtype, elements are returned as-is.\n\n    >>> a = np.array([np.int64(1)], dtype=object)\n    >>> a.item() #return np.int64\n    np.int64(1)\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('max', '\n    a.max(axis=None, out=None, keepdims=False, initial=<no value>, where=True)\n\n    Return the maximum along a given axis.\n\n    Refer to `numpy.amax` for full documentation.\n\n    See Also\n    --------\n    numpy.amax : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('mean', '\n    a.mean(axis=None, dtype=None, out=None, keepdims=False, *, where=True)\n\n    Returns the average of the array elements along given axis.\n\n    Refer to `numpy.mean` for full documentation.\n\n    See Also\n    --------\n    numpy.mean : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('min', '\n    a.min(axis=None, out=None, keepdims=False, initial=<no value>, where=True)\n\n    Return the minimum along a given axis.\n\n    Refer to `numpy.amin` for full documentation.\n\n    See Also\n    --------\n    numpy.amin : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('nonzero', '\n    a.nonzero()\n\n    Return the indices of the elements that are non-zero.\n\n    Refer to `numpy.nonzero` for full documentation.\n\n    See Also\n    --------\n    numpy.nonzero : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('prod', '\n    a.prod(axis=None, dtype=None, out=None, keepdims=False,\n        initial=1, where=True)\n\n    Return the product of the array elements over the given axis\n\n    Refer to `numpy.prod` for full documentation.\n\n    See Also\n    --------\n    numpy.prod : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('put', "\n    a.put(indices, values, mode='raise')\n\n    Set ``a.flat[n] = values[n]`` for all `n` in indices.\n\n    Refer to `numpy.put` for full documentation.\n\n    See Also\n    --------\n    numpy.put : equivalent function\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('ravel', '\n    a.ravel([order])\n\n    Return a flattened array.\n\n    Refer to `numpy.ravel` for full documentation.\n\n    See Also\n    --------\n    numpy.ravel : equivalent function\n\n    ndarray.flat : a flat iterator on the array.\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('repeat', '\n    a.repeat(repeats, axis=None)\n\n    Repeat elements of an array.\n\n    Refer to `numpy.repeat` for full documentation.\n\n    See Also\n    --------\n    numpy.repeat : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('reshape', "\n    a.reshape(shape, /, order='C')\n\n    Returns an array containing the same data with a new shape.\n\n    Refer to `numpy.reshape` for full documentation.\n\n    See Also\n    --------\n    numpy.reshape : equivalent function\n\n    Notes\n    -----\n    Unlike the free function `numpy.reshape`, this method on `ndarray` allows\n    the elements of the shape parameter to be passed in as separate arguments.\n    For example, ``a.reshape(10, 11)`` is equivalent to\n    ``a.reshape((10, 11))``.\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('resize', "\n    a.resize(new_shape, refcheck=True)\n\n    Change shape and size of array in-place.\n\n    Parameters\n    ----------\n    new_shape : tuple of ints, or `n` ints\n        Shape of resized array.\n    refcheck : bool, optional\n        If False, reference count will not be checked. Default is True.\n\n    Returns\n    -------\n    None\n\n    Raises\n    ------\n    ValueError\n        If `a` does not own its own data or references or views to it exist,\n        and the data memory must be changed.\n        PyPy only: will always raise if the data memory must be changed, since\n        there is no reliable way to determine if references or views to it\n        exist.\n\n    SystemError\n        If the `order` keyword argument is specified. This behaviour is a\n        bug in NumPy.\n\n    See Also\n    --------\n    resize : Return a new array with the specified shape.\n\n    Notes\n    -----\n    This reallocates space for the data area if necessary.\n\n    Only contiguous arrays (data elements consecutive in memory) can be\n    resized.\n\n    The purpose of the reference count check is to make sure you\n    do not use this array as a buffer for another Python object and then\n    reallocate the memory. However, reference counts can increase in\n    other ways so if you are sure that you have not shared the memory\n    for this array with another Python object, then you may safely set\n    `refcheck` to False.\n\n    Examples\n    --------\n    Shrinking an array: array is flattened (in the order that the data are\n    stored in memory), resized, and reshaped:\n\n    >>> a = np.array([[0, 1], [2, 3]], order='C')\n    >>> a.resize((2, 1))\n    >>> a\n    array([[0],\n           [1]])\n\n    >>> a = np.array([[0, 1], [2, 3]], order='F')\n    >>> a.resize((2, 1))\n    >>> a\n    array([[0],\n           [2]])\n\n    Enlarging an array: as above, but missing entries are filled with zeros:\n\n    >>> b = np.array([[0, 1], [2, 3]])\n    >>> b.resize(2, 3) # new_shape parameter doesn't have to be a tuple\n    >>> b\n    array([[0, 1, 2],\n           [3, 0, 0]])\n\n    Referencing an array prevents resizing...\n\n    >>> c = a\n    >>> a.resize((1, 1))\n    Traceback (most recent call last):\n    ...\n    ValueError: cannot resize an array that references or is referenced ...\n\n    Unless `refcheck` is False:\n\n    >>> a.resize((1, 1), refcheck=False)\n    >>> a\n    array([[0]])\n    >>> c\n    array([[0]])\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('round', '\n    a.round(decimals=0, out=None)\n\n    Return `a` with each element rounded to the given number of decimals.\n\n    Refer to `numpy.around` for full documentation.\n\n    See Also\n    --------\n    numpy.around : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('searchsorted', "\n    a.searchsorted(v, side='left', sorter=None)\n\n    Find indices where elements of v should be inserted in a to maintain order.\n\n    For full documentation, see `numpy.searchsorted`\n\n    See Also\n    --------\n    numpy.searchsorted : equivalent function\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('setfield', "\n    a.setfield(val, dtype, offset=0)\n\n    Put a value into a specified place in a field defined by a data-type.\n\n    Place `val` into `a`'s field defined by `dtype` and beginning `offset`\n    bytes into the field.\n\n    Parameters\n    ----------\n    val : object\n        Value to be placed in field.\n    dtype : dtype object\n        Data-type of the field in which to place `val`.\n    offset : int, optional\n        The number of bytes into the field at which to place `val`.\n\n    Returns\n    -------\n    None\n\n    See Also\n    --------\n    getfield\n\n    Examples\n    --------\n    >>> x = np.eye(3)\n    >>> x.getfield(np.float64)\n    array([[1.,  0.,  0.],\n           [0.,  1.,  0.],\n           [0.,  0.,  1.]])\n    >>> x.setfield(3, np.int32)\n    >>> x.getfield(np.int32)\n    array([[3, 3, 3],\n           [3, 3, 3],\n           [3, 3, 3]], dtype=int32)\n    >>> x\n    array([[1.0e+000, 1.5e-323, 1.5e-323],\n           [1.5e-323, 1.0e+000, 1.5e-323],\n           [1.5e-323, 1.5e-323, 1.0e+000]])\n    >>> x.setfield(np.eye(3), np.int32)\n    >>> x\n    array([[1.,  0.,  0.],\n           [0.,  1.,  0.],\n           [0.,  0.,  1.]])\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('setflags', '\n    a.setflags(write=None, align=None, uic=None)\n\n    Set array flags WRITEABLE, ALIGNED, WRITEBACKIFCOPY,\n    respectively.\n\n    These Boolean-valued flags affect how numpy interprets the memory\n    area used by `a` (see Notes below). The ALIGNED flag can only\n    be set to True if the data is actually aligned according to the type.\n    The WRITEBACKIFCOPY flag can never be set\n    to True. The flag WRITEABLE can only be set to True if the array owns its\n    own memory, or the ultimate owner of the memory exposes a writeable buffer\n    interface, or is a string. (The exception for string is made so that\n    unpickling can be done without copying memory.)\n\n    Parameters\n    ----------\n    write : bool, optional\n        Describes whether or not `a` can be written to.\n    align : bool, optional\n        Describes whether or not `a` is aligned properly for its type.\n    uic : bool, optional\n        Describes whether or not `a` is a copy of another "base" array.\n\n    Notes\n    -----\n    Array flags provide information about how the memory area used\n    for the array is to be interpreted. There are 7 Boolean flags\n    in use, only three of which can be changed by the user:\n    WRITEBACKIFCOPY, WRITEABLE, and ALIGNED.\n\n    WRITEABLE (W) the data area can be written to;\n\n    ALIGNED (A) the data and strides are aligned appropriately for the hardware\n    (as determined by the compiler);\n\n    WRITEBACKIFCOPY (X) this array is a copy of some other array (referenced\n    by .base). When the C-API function PyArray_ResolveWritebackIfCopy is\n    called, the base array will be updated with the contents of this array.\n\n    All flags can be accessed using the single (upper case) letter as well\n    as the full name.\n\n    Examples\n    --------\n    >>> y = np.array([[3, 1, 7],\n    ...               [2, 0, 0],\n    ...               [8, 5, 9]])\n    >>> y\n    array([[3, 1, 7],\n           [2, 0, 0],\n           [8, 5, 9]])\n    >>> y.flags\n      C_CONTIGUOUS : True\n      F_CONTIGUOUS : False\n      OWNDATA : True\n      WRITEABLE : True\n      ALIGNED : True\n      WRITEBACKIFCOPY : False\n    >>> y.setflags(write=0, align=0)\n    >>> y.flags\n      C_CONTIGUOUS : True\n      F_CONTIGUOUS : False\n      OWNDATA : True\n      WRITEABLE : False\n      ALIGNED : False\n      WRITEBACKIFCOPY : False\n    >>> y.setflags(uic=1)\n    Traceback (most recent call last):\n      File "<stdin>", line 1, in <module>\n    ValueError: cannot set WRITEBACKIFCOPY flag to True\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('sort', "\n    a.sort(axis=-1, kind=None, order=None)\n\n    Sort an array in-place. Refer to `numpy.sort` for full documentation.\n\n    Parameters\n    ----------\n    axis : int, optional\n        Axis along which to sort. Default is -1, which means sort along the\n        last axis.\n    kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional\n        Sorting algorithm. The default is 'quicksort'. Note that both 'stable'\n        and 'mergesort' use timsort under the covers and, in general, the\n        actual implementation will vary with datatype. The 'mergesort' option\n        is retained for backwards compatibility.\n\n        .. versionchanged:: 1.15.0\n           The 'stable' option was added.\n\n    order : str or list of str, optional\n        When `a` is an array with fields defined, this argument specifies\n        which fields to compare first, second, etc.  A single field can\n        be specified as a string, and not all fields need be specified,\n        but unspecified fields will still be used, in the order in which\n        they come up in the dtype, to break ties.\n\n    See Also\n    --------\n    numpy.sort : Return a sorted copy of an array.\n    numpy.argsort : Indirect sort.\n    numpy.lexsort : Indirect stable sort on multiple keys.\n    numpy.searchsorted : Find elements in sorted array.\n    numpy.partition: Partial sort.\n\n    Notes\n    -----\n    See `numpy.sort` for notes on the different sorting algorithms.\n\n    Examples\n    --------\n    >>> a = np.array([[1,4], [3,1]])\n    >>> a.sort(axis=1)\n    >>> a\n    array([[1, 4],\n           [1, 3]])\n    >>> a.sort(axis=0)\n    >>> a\n    array([[1, 3],\n           [1, 4]])\n\n    Use the `order` keyword to specify a field to use when sorting a\n    structured array:\n\n    >>> a = np.array([('a', 2), ('c', 1)], dtype=[('x', 'S1'), ('y', int)])\n    >>> a.sort(order='y')\n    >>> a\n    array([(b'c', 1), (b'a', 2)],\n          dtype=[('x', 'S1'), ('y', '<i8')])\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('partition', "\n    a.partition(kth, axis=-1, kind='introselect', order=None)\n\n    Rearranges the elements in the array in such a way that the value of the\n    element in kth position is in the position it would be in a sorted array.\n    All elements smaller than the kth element are moved before this element and\n    all equal or greater are moved behind it. The ordering of the elements in\n    the two partitions is undefined.\n\n    .. versionadded:: 1.8.0\n\n    Parameters\n    ----------\n    kth : int or sequence of ints\n        Element index to partition by. The kth element value will be in its\n        final sorted position and all smaller elements will be moved before it\n        and all equal or greater elements behind it.\n        The order of all elements in the partitions is undefined.\n        If provided with a sequence of kth it will partition all elements\n        indexed by kth of them into their sorted position at once.\n\n        .. deprecated:: 1.22.0\n            Passing booleans as index is deprecated.\n    axis : int, optional\n        Axis along which to sort. Default is -1, which means sort along the\n        last axis.\n    kind : {'introselect'}, optional\n        Selection algorithm. Default is 'introselect'.\n    order : str or list of str, optional\n        When `a` is an array with fields defined, this argument specifies\n        which fields to compare first, second, etc. A single field can\n        be specified as a string, and not all fields need to be specified,\n        but unspecified fields will still be used, in the order in which\n        they come up in the dtype, to break ties.\n\n    See Also\n    --------\n    numpy.partition : Return a partitioned copy of an array.\n    argpartition : Indirect partition.\n    sort : Full sort.\n\n    Notes\n    -----\n    See ``np.partition`` for notes on the different algorithms.\n\n    Examples\n    --------\n    >>> a = np.array([3, 4, 2, 1])\n    >>> a.partition(3)\n    >>> a\n    array([2, 1, 3, 4]) # may vary\n\n    >>> a.partition((1, 3))\n    >>> a\n    array([1, 2, 3, 4])\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('squeeze', '\n    a.squeeze(axis=None)\n\n    Remove axes of length one from `a`.\n\n    Refer to `numpy.squeeze` for full documentation.\n\n    See Also\n    --------\n    numpy.squeeze : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('std', '\n    a.std(axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)\n\n    Returns the standard deviation of the array elements along given axis.\n\n    Refer to `numpy.std` for full documentation.\n\n    See Also\n    --------\n    numpy.std : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('sum', '\n    a.sum(axis=None, dtype=None, out=None, keepdims=False, initial=0, where=True)\n\n    Return the sum of the array elements over the given axis.\n\n    Refer to `numpy.sum` for full documentation.\n\n    See Also\n    --------\n    numpy.sum : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('swapaxes', '\n    a.swapaxes(axis1, axis2)\n\n    Return a view of the array with `axis1` and `axis2` interchanged.\n\n    Refer to `numpy.swapaxes` for full documentation.\n\n    See Also\n    --------\n    numpy.swapaxes : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('take', "\n    a.take(indices, axis=None, out=None, mode='raise')\n\n    Return an array formed from the elements of `a` at the given indices.\n\n    Refer to `numpy.take` for full documentation.\n\n    See Also\n    --------\n    numpy.take : equivalent function\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('tofile', '\n    a.tofile(fid, sep="", format="%s")\n\n    Write array to a file as text or binary (default).\n\n    Data is always written in \'C\' order, independent of the order of `a`.\n    The data produced by this method can be recovered using the function\n    fromfile().\n\n    Parameters\n    ----------\n    fid : file or str or Path\n        An open file object, or a string containing a filename.\n\n        .. versionchanged:: 1.17.0\n            `pathlib.Path` objects are now accepted.\n\n    sep : str\n        Separator between array items for text output.\n        If "" (empty), a binary file is written, equivalent to\n        ``file.write(a.tobytes())``.\n    format : str\n        Format string for text file output.\n        Each entry in the array is formatted to text by first converting\n        it to the closest Python type, and then using "format" % item.\n\n    Notes\n    -----\n    This is a convenience function for quick storage of array data.\n    Information on endianness and precision is lost, so this method is not a\n    good choice for files intended to archive data or transport data between\n    machines with different endianness. Some of these problems can be overcome\n    by outputting the data as text files, at the expense of speed and file\n    size.\n\n    When fid is a file object, array contents are directly written to the\n    file, bypassing the file object\'s ``write`` method. As a result, tofile\n    cannot be used with files objects supporting compression (e.g., GzipFile)\n    or file-like objects that do not support ``fileno()`` (e.g., BytesIO).\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('tolist', "\n    a.tolist()\n\n    Return the array as an ``a.ndim``-levels deep nested list of Python scalars.\n\n    Return a copy of the array data as a (nested) Python list.\n    Data items are converted to the nearest compatible builtin Python type, via\n    the `~numpy.ndarray.item` function.\n\n    If ``a.ndim`` is 0, then since the depth of the nested list is 0, it will\n    not be a list at all, but a simple Python scalar.\n\n    Parameters\n    ----------\n    none\n\n    Returns\n    -------\n    y : object, or list of object, or list of list of object, or ...\n        The possibly nested list of array elements.\n\n    Notes\n    -----\n    The array may be recreated via ``a = np.array(a.tolist())``, although this\n    may sometimes lose precision.\n\n    Examples\n    --------\n    For a 1D array, ``a.tolist()`` is almost the same as ``list(a)``,\n    except that ``tolist`` changes numpy scalars to Python scalars:\n\n    >>> a = np.uint32([1, 2])\n    >>> a_list = list(a)\n    >>> a_list\n    [1, 2]\n    >>> type(a_list[0])\n    <class 'numpy.uint32'>\n    >>> a_tolist = a.tolist()\n    >>> a_tolist\n    [1, 2]\n    >>> type(a_tolist[0])\n    <class 'int'>\n\n    Additionally, for a 2D array, ``tolist`` applies recursively:\n\n    >>> a = np.array([[1, 2], [3, 4]])\n    >>> list(a)\n    [array([1, 2]), array([3, 4])]\n    >>> a.tolist()\n    [[1, 2], [3, 4]]\n\n    The base case for this recursion is a 0D array:\n\n    >>> a = np.array(1)\n    >>> list(a)\n    Traceback (most recent call last):\n      ...\n    TypeError: iteration over a 0-d array\n    >>> a.tolist()\n    1\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('tobytes', "\n    a.tobytes(order='C')\n\n    Construct Python bytes containing the raw data bytes in the array.\n\n    Constructs Python bytes showing a copy of the raw contents of\n    data memory. The bytes object is produced in C-order by default.\n    This behavior is controlled by the ``order`` parameter.\n\n    .. versionadded:: 1.9.0\n\n    Parameters\n    ----------\n    order : {'C', 'F', 'A'}, optional\n        Controls the memory layout of the bytes object. 'C' means C-order,\n        'F' means F-order, 'A' (short for *Any*) means 'F' if `a` is\n        Fortran contiguous, 'C' otherwise. Default is 'C'.\n\n    Returns\n    -------\n    s : bytes\n        Python bytes exhibiting a copy of `a`'s raw data.\n\n    See also\n    --------\n    frombuffer\n        Inverse of this operation, construct a 1-dimensional array from Python\n        bytes.\n\n    Examples\n    --------\n    >>> x = np.array([[0, 1], [2, 3]], dtype='<u2')\n    >>> x.tobytes()\n    b'\\x00\\x00\\x01\\x00\\x02\\x00\\x03\\x00'\n    >>> x.tobytes('C') == x.tobytes()\n    True\n    >>> x.tobytes('F')\n    b'\\x00\\x00\\x02\\x00\\x01\\x00\\x03\\x00'\n\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('tostring', "\n    a.tostring(order='C')\n\n    A compatibility alias for `~ndarray.tobytes`, with exactly the same\n    behavior.\n\n    Despite its name, it returns :class:`bytes` not :class:`str`\\ s.\n\n    .. deprecated:: 1.19.0\n    "))
add_newdoc('numpy._core.multiarray', 'ndarray', ('trace', '\n    a.trace(offset=0, axis1=0, axis2=1, dtype=None, out=None)\n\n    Return the sum along diagonals of the array.\n\n    Refer to `numpy.trace` for full documentation.\n\n    See Also\n    --------\n    numpy.trace : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('transpose', '\n    a.transpose(*axes)\n\n    Returns a view of the array with axes transposed.\n\n    Refer to `numpy.transpose` for full documentation.\n\n    Parameters\n    ----------\n    axes : None, tuple of ints, or `n` ints\n\n     * None or no argument: reverses the order of the axes.\n\n     * tuple of ints: `i` in the `j`-th place in the tuple means that the\n       array\'s `i`-th axis becomes the transposed array\'s `j`-th axis.\n\n     * `n` ints: same as an n-tuple of the same ints (this form is\n       intended simply as a "convenience" alternative to the tuple form).\n\n    Returns\n    -------\n    p : ndarray\n        View of the array with its axes suitably permuted.\n\n    See Also\n    --------\n    transpose : Equivalent function.\n    ndarray.T : Array property returning the array transposed.\n    ndarray.reshape : Give a new shape to an array without changing its data.\n\n    Examples\n    --------\n    >>> a = np.array([[1, 2], [3, 4]])\n    >>> a\n    array([[1, 2],\n           [3, 4]])\n    >>> a.transpose()\n    array([[1, 3],\n           [2, 4]])\n    >>> a.transpose((1, 0))\n    array([[1, 3],\n           [2, 4]])\n    >>> a.transpose(1, 0)\n    array([[1, 3],\n           [2, 4]])\n\n    >>> a = np.array([1, 2, 3, 4])\n    >>> a\n    array([1, 2, 3, 4])\n    >>> a.transpose()\n    array([1, 2, 3, 4])\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('var', '\n    a.var(axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True)\n\n    Returns the variance of the array elements, along given axis.\n\n    Refer to `numpy.var` for full documentation.\n\n    See Also\n    --------\n    numpy.var : equivalent function\n\n    '))
add_newdoc('numpy._core.multiarray', 'ndarray', ('view', "\n    a.view([dtype][, type])\n\n    New view of array with the same data.\n\n    .. note::\n        Passing None for ``dtype`` is different from omitting the parameter,\n        since the former invokes ``dtype(None)`` which is an alias for\n        ``dtype('float64')``.\n\n    Parameters\n    ----------\n    dtype : data-type or ndarray sub-class, optional\n        Data-type descriptor of the returned view, e.g., float32 or int16.\n        Omitting it results in the view having the same data-type as `a`.\n        This argument can also be specified as an ndarray sub-class, which\n        then specifies the type of the returned object (this is equivalent to\n        setting the ``type`` parameter).\n    type : Python type, optional\n        Type of the returned view, e.g., ndarray or matrix.  Again, omission\n        of the parameter results in type preservation.\n\n    Notes\n    -----\n    ``a.view()`` is used two different ways:\n\n    ``a.view(some_dtype)`` or ``a.view(dtype=some_dtype)`` constructs a view\n    of the array's memory with a different data-type.  This can cause a\n    reinterpretation of the bytes of memory.\n\n    ``a.view(ndarray_subclass)`` or ``a.view(type=ndarray_subclass)`` just\n    returns an instance of `ndarray_subclass` that looks at the same array\n    (same shape, dtype, etc.)  This does not cause a reinterpretation of the\n    memory.\n\n    For ``a.view(some_dtype)``, if ``some_dtype`` has a different number of\n    bytes per entry than the previous dtype (for example, converting a regular\n    array to a structured array), then the last axis of ``a`` must be\n    contiguous. This axis will be resized in the result.\n\n    .. versionchanged:: 1.23.0\n       Only the last axis needs to be contiguous. Previously, the entire array\n       had to be C-contiguous.\n\n    Examples\n    --------\n    >>> x = np.array([(1, 2)], dtype=[('a', np.int8), ('b', np.int8)])\n\n    Viewing array data using a different type and dtype:\n\n    >>> y = x.view(dtype=np.int16, type=np.matrix)\n    >>> y\n    matrix([[513]], dtype=int16)\n    >>> print(type(y))\n    <class 'numpy.matrix'>\n\n    Creating a view on a structured array so it can be used in calculations\n\n    >>> x = np.array([(1, 2),(3,4)], dtype=[('a', np.int8), ('b', np.int8)])\n    >>> xv = x.view(dtype=np.int8).reshape(-1,2)\n    >>> xv\n    array([[1, 2],\n           [3, 4]], dtype=int8)\n    >>> xv.mean(0)\n    array([2.,  3.])\n\n    Making changes to the view changes the underlying array\n\n    >>> xv[0,1] = 20\n    >>> x\n    array([(1, 20), (3,  4)], dtype=[('a', 'i1'), ('b', 'i1')])\n\n    Using a view to convert an array to a recarray:\n\n    >>> z = x.view(np.recarray)\n    >>> z.a\n    array([1, 3], dtype=int8)\n\n    Views share data:\n\n    >>> x[0] = (9, 10)\n    >>> z[0]\n    np.record((9, 10), dtype=[('a', 'i1'), ('b', 'i1')])\n\n    Views that change the dtype size (bytes per entry) should normally be\n    avoided on arrays defined by slices, transposes, fortran-ordering, etc.:\n\n    >>> x = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.int16)\n    >>> y = x[:, ::2]\n    >>> y\n    array([[1, 3],\n           [4, 6]], dtype=int16)\n    >>> y.view(dtype=[('width', np.int16), ('length', np.int16)])\n    Traceback (most recent call last):\n        ...\n    ValueError: To change to a dtype of a different size, the last axis must be contiguous\n    >>> z = y.copy()\n    >>> z.view(dtype=[('width', np.int16), ('length', np.int16)])\n    array([[(1, 3)],\n           [(4, 6)]], dtype=[('width', '<i2'), ('length', '<i2')])\n\n    However, views that change dtype are totally fine for arrays with a\n    contiguous last axis, even if the rest of the axes are not C-contiguous:\n\n    >>> x = np.arange(2 * 3 * 4, dtype=np.int8).reshape(2, 3, 4)\n    >>> x.transpose(1, 0, 2).view(np.int16)\n    array([[[ 256,  770],\n            [3340, 3854]],\n    <BLANKLINE>\n           [[1284, 1798],\n            [4368, 4882]],\n    <BLANKLINE>\n           [[2312, 2826],\n            [5396, 5910]]], dtype=int16)\n\n    "))
add_newdoc('numpy._core.umath', 'frompyfunc', "\n    frompyfunc(func, /, nin, nout, *[, identity])\n\n    Takes an arbitrary Python function and returns a NumPy ufunc.\n\n    Can be used, for example, to add broadcasting to a built-in Python\n    function (see Examples section).\n\n    Parameters\n    ----------\n    func : Python function object\n        An arbitrary Python function.\n    nin : int\n        The number of input arguments.\n    nout : int\n        The number of objects returned by `func`.\n    identity : object, optional\n        The value to use for the `~numpy.ufunc.identity` attribute of the resulting\n        object. If specified, this is equivalent to setting the underlying\n        C ``identity`` field to ``PyUFunc_IdentityValue``.\n        If omitted, the identity is set to ``PyUFunc_None``. Note that this is\n        _not_ equivalent to setting the identity to ``None``, which implies the\n        operation is reorderable.\n\n    Returns\n    -------\n    out : ufunc\n        Returns a NumPy universal function (``ufunc``) object.\n\n    See Also\n    --------\n    vectorize : Evaluates pyfunc over input arrays using broadcasting rules of numpy.\n\n    Notes\n    -----\n    The returned ufunc always returns PyObject arrays.\n\n    Examples\n    --------\n    Use frompyfunc to add broadcasting to the Python function ``oct``:\n\n    >>> oct_array = np.frompyfunc(oct, 1, 1)\n    >>> oct_array(np.array((10, 30, 100)))\n    array(['0o12', '0o36', '0o144'], dtype=object)\n    >>> np.array((oct(10), oct(30), oct(100))) # for comparison\n    array(['0o12', '0o36', '0o144'], dtype='<U5')\n\n    ")
add_newdoc('numpy._core.multiarray', 'add_docstring', '\n    add_docstring(obj, docstring)\n\n    Add a docstring to a built-in obj if possible.\n    If the obj already has a docstring raise a RuntimeError\n    If this routine does not know how to add a docstring to the object\n    raise a TypeError\n    ')
add_newdoc('numpy._core.umath', '_add_newdoc_ufunc', '\n    add_ufunc_docstring(ufunc, new_docstring)\n\n    Replace the docstring for a ufunc with new_docstring.\n    This method will only work if the current docstring for\n    the ufunc is NULL. (At the C level, i.e. when ufunc->doc is NULL.)\n\n    Parameters\n    ----------\n    ufunc : numpy.ufunc\n        A ufunc whose current doc is NULL.\n    new_docstring : string\n        The new docstring for the ufunc.\n\n    Notes\n    -----\n    This method allocates memory for new_docstring on\n    the heap. Technically this creates a mempory leak, since this\n    memory will not be reclaimed until the end of the program\n    even if the ufunc itself is removed. However this will only\n    be a problem if the user is repeatedly creating ufuncs with\n    no documentation, adding documentation via add_newdoc_ufunc,\n    and then throwing away the ufunc.\n    ')
add_newdoc('numpy._core.multiarray', 'get_handler_name', '\n    get_handler_name(a: ndarray) -> str,None\n\n    Return the name of the memory handler used by `a`. If not provided, return\n    the name of the memory handler that will be used to allocate data for the\n    next `ndarray` in this context. May return None if `a` does not own its\n    memory, in which case you can traverse ``a.base`` for a memory handler.\n    ')
add_newdoc('numpy._core.multiarray', 'get_handler_version', '\n    get_handler_version(a: ndarray) -> int,None\n\n    Return the version of the memory handler used by `a`. If not provided,\n    return the version of the memory handler that will be used to allocate data\n    for the next `ndarray` in this context. May return None if `a` does not own\n    its memory, in which case you can traverse ``a.base`` for a memory handler.\n    ')
add_newdoc('numpy._core.multiarray', '_get_madvise_hugepage', '\n    _get_madvise_hugepage() -> bool\n\n    Get use of ``madvise (2)`` MADV_HUGEPAGE support when\n    allocating the array data. Returns the currently set value.\n    See `global_state` for more information.\n    ')
add_newdoc('numpy._core.multiarray', '_set_madvise_hugepage', '\n    _set_madvise_hugepage(enabled: bool) -> bool\n\n    Set  or unset use of ``madvise (2)`` MADV_HUGEPAGE support when\n    allocating the array data. Returns the previously set value.\n    See `global_state` for more information.\n    ')
add_newdoc('numpy._core._multiarray_tests', 'format_float_OSprintf_g', '\n    format_float_OSprintf_g(val, precision)\n\n    Print a floating point scalar using the system\'s printf function,\n    equivalent to:\n\n        printf("%.*g", precision, val);\n\n    for half/float/double, or replacing \'g\' by \'Lg\' for longdouble. This\n    method is designed to help cross-validate the format_float_* methods.\n\n    Parameters\n    ----------\n    val : python float or numpy floating scalar\n        Value to format.\n\n    precision : non-negative integer, optional\n        Precision given to printf.\n\n    Returns\n    -------\n    rep : string\n        The string representation of the floating point value\n\n    See Also\n    --------\n    format_float_scientific\n    format_float_positional\n    ')
add_newdoc('numpy._core', 'ufunc', "\n    Functions that operate element by element on whole arrays.\n\n    To see the documentation for a specific ufunc, use `info`.  For\n    example, ``np.info(np.sin)``.  Because ufuncs are written in C\n    (for speed) and linked into Python with NumPy's ufunc facility,\n    Python's help() function finds this page whenever help() is called\n    on a ufunc.\n\n    A detailed explanation of ufuncs can be found in the docs for :ref:`ufuncs`.\n\n    **Calling ufuncs:** ``op(*x[, out], where=True, **kwargs)``\n\n    Apply `op` to the arguments `*x` elementwise, broadcasting the arguments.\n\n    The broadcasting rules are:\n\n    * Dimensions of length 1 may be prepended to either array.\n    * Arrays may be repeated along dimensions of length 1.\n\n    Parameters\n    ----------\n    *x : array_like\n        Input arrays.\n    out : ndarray, None, or tuple of ndarray and None, optional\n        Alternate array object(s) in which to put the result; if provided, it\n        must have a shape that the inputs broadcast to. A tuple of arrays\n        (possible only as a keyword argument) must have length equal to the\n        number of outputs; use None for uninitialized outputs to be\n        allocated by the ufunc.\n    where : array_like, optional\n        This condition is broadcast over the input. At locations where the\n        condition is True, the `out` array will be set to the ufunc result.\n        Elsewhere, the `out` array will retain its original value.\n        Note that if an uninitialized `out` array is created via the default\n        ``out=None``, locations within it where the condition is False will\n        remain uninitialized.\n    **kwargs\n        For other keyword-only arguments, see the :ref:`ufunc docs <ufuncs.kwargs>`.\n\n    Returns\n    -------\n    r : ndarray or tuple of ndarray\n        `r` will have the shape that the arrays in `x` broadcast to; if `out` is\n        provided, it will be returned. If not, `r` will be allocated and\n        may contain uninitialized values. If the function has more than one\n        output, then the result will be a tuple of arrays.\n\n    ")
add_newdoc('numpy._core', 'ufunc', ('identity', '\n    The identity value.\n\n    Data attribute containing the identity element for the ufunc, \n    if it has one. If it does not, the attribute value is None.\n\n    Examples\n    --------\n    >>> np.add.identity\n    0\n    >>> np.multiply.identity\n    1\n    >>> np.power.identity\n    1\n    >>> print(np.exp.identity)\n    None\n    '))
add_newdoc('numpy._core', 'ufunc', ('nargs', '\n    The number of arguments.\n\n    Data attribute containing the number of arguments the ufunc takes, including\n    optional ones.\n\n    Notes\n    -----\n    Typically this value will be one more than what you might expect \n    because all ufuncs take  the optional "out" argument.\n\n    Examples\n    --------\n    >>> np.add.nargs\n    3\n    >>> np.multiply.nargs\n    3\n    >>> np.power.nargs\n    3\n    >>> np.exp.nargs\n    2\n    '))
add_newdoc('numpy._core', 'ufunc', ('nin', '\n    The number of inputs.\n\n    Data attribute containing the number of arguments the ufunc treats as input.\n\n    Examples\n    --------\n    >>> np.add.nin\n    2\n    >>> np.multiply.nin\n    2\n    >>> np.power.nin\n    2\n    >>> np.exp.nin\n    1\n    '))
add_newdoc('numpy._core', 'ufunc', ('nout', '\n    The number of outputs.\n\n    Data attribute containing the number of arguments the ufunc treats as output.\n\n    Notes\n    -----\n    Since all ufuncs can take output arguments, this will always be at least 1.\n\n    Examples\n    --------\n    >>> np.add.nout\n    1\n    >>> np.multiply.nout\n    1\n    >>> np.power.nout\n    1\n    >>> np.exp.nout\n    1\n\n    '))
add_newdoc('numpy._core', 'ufunc', ('ntypes', '\n    The number of types.\n\n    The number of numerical NumPy types - of which there are 18 total - on which\n    the ufunc can operate.\n\n    See Also\n    --------\n    numpy.ufunc.types\n\n    Examples\n    --------\n    >>> np.add.ntypes\n    18\n    >>> np.multiply.ntypes\n    18\n    >>> np.power.ntypes\n    17\n    >>> np.exp.ntypes\n    7\n    >>> np.remainder.ntypes\n    14\n\n    '))
add_newdoc('numpy._core', 'ufunc', ('types', '\n    Returns a list with types grouped input->output.\n\n    Data attribute listing the data-type "Domain-Range" groupings the ufunc can\n    deliver. The data-types are given using the character codes.\n\n    See Also\n    --------\n    numpy.ufunc.ntypes\n\n    Examples\n    --------\n    >>> np.add.types\n    [\'??->?\', \'bb->b\', \'BB->B\', \'hh->h\', \'HH->H\', \'ii->i\', \'II->I\', \'ll->l\',\n    \'LL->L\', \'qq->q\', \'QQ->Q\', \'ff->f\', \'dd->d\', \'gg->g\', \'FF->F\', \'DD->D\',\n    \'GG->G\', \'OO->O\']\n\n    >>> np.multiply.types\n    [\'??->?\', \'bb->b\', \'BB->B\', \'hh->h\', \'HH->H\', \'ii->i\', \'II->I\', \'ll->l\',\n    \'LL->L\', \'qq->q\', \'QQ->Q\', \'ff->f\', \'dd->d\', \'gg->g\', \'FF->F\', \'DD->D\',\n    \'GG->G\', \'OO->O\']\n\n    >>> np.power.types\n    [\'bb->b\', \'BB->B\', \'hh->h\', \'HH->H\', \'ii->i\', \'II->I\', \'ll->l\', \'LL->L\',\n    \'qq->q\', \'QQ->Q\', \'ff->f\', \'dd->d\', \'gg->g\', \'FF->F\', \'DD->D\', \'GG->G\',\n    \'OO->O\']\n\n    >>> np.exp.types\n    [\'f->f\', \'d->d\', \'g->g\', \'F->F\', \'D->D\', \'G->G\', \'O->O\']\n\n    >>> np.remainder.types\n    [\'bb->b\', \'BB->B\', \'hh->h\', \'HH->H\', \'ii->i\', \'II->I\', \'ll->l\', \'LL->L\',\n    \'qq->q\', \'QQ->Q\', \'ff->f\', \'dd->d\', \'gg->g\', \'OO->O\']\n\n    '))
add_newdoc('numpy._core', 'ufunc', ('signature', "\n    Definition of the core elements a generalized ufunc operates on.\n\n    The signature determines how the dimensions of each input/output array\n    are split into core and loop dimensions:\n\n    1. Each dimension in the signature is matched to a dimension of the\n       corresponding passed-in array, starting from the end of the shape tuple.\n    2. Core dimensions assigned to the same label in the signature must have\n       exactly matching sizes, no broadcasting is performed.\n    3. The core dimensions are removed from all inputs and the remaining\n       dimensions are broadcast together, defining the loop dimensions.\n\n    Notes\n    -----\n    Generalized ufuncs are used internally in many linalg functions, and in\n    the testing suite; the examples below are taken from these.\n    For ufuncs that operate on scalars, the signature is None, which is\n    equivalent to '()' for every argument.\n\n    Examples\n    --------\n    >>> np.linalg._umath_linalg.det.signature\n    '(m,m)->()'\n    >>> np.matmul.signature\n    '(n?,k),(k,m?)->(n?,m?)'\n    >>> np.add.signature is None\n    True  # equivalent to '(),()->()'\n    "))
add_newdoc('numpy._core', 'ufunc', ('reduce', "\n    reduce(array, axis=0, dtype=None, out=None, keepdims=False, initial=<no value>, where=True)\n\n    Reduces `array`'s dimension by one, by applying ufunc along one axis.\n\n    Let :math:`array.shape = (N_0, ..., N_i, ..., N_{M-1})`.  Then\n    :math:`ufunc.reduce(array, axis=i)[k_0, ..,k_{i-1}, k_{i+1}, .., k_{M-1}]` =\n    the result of iterating `j` over :math:`range(N_i)`, cumulatively applying\n    ufunc to each :math:`array[k_0, ..,k_{i-1}, j, k_{i+1}, .., k_{M-1}]`.\n    For a one-dimensional array, reduce produces results equivalent to:\n    ::\n\n     r = op.identity # op = ufunc\n     for i in range(len(A)):\n       r = op(r, A[i])\n     return r\n\n    For example, add.reduce() is equivalent to sum().\n\n    Parameters\n    ----------\n    array : array_like\n        The array to act on.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which a reduction is performed.\n        The default (`axis` = 0) is perform a reduction over the first\n        dimension of the input array. `axis` may be negative, in\n        which case it counts from the last to the first axis.\n\n        .. versionadded:: 1.7.0\n\n        If this is None, a reduction is performed over all the axes.\n        If this is a tuple of ints, a reduction is performed on multiple\n        axes, instead of a single axis or all the axes as before.\n\n        For operations which are either not commutative or not associative,\n        doing a reduction over multiple axes is not well-defined. The\n        ufuncs do not currently raise an exception in this case, but will\n        likely do so in the future.\n    dtype : data-type code, optional\n        The type used to represent the intermediate results. Defaults\n        to the data-type of the output array if this is provided, or\n        the data-type of the input array if no output array is provided.\n    out : ndarray, None, or tuple of ndarray and None, optional\n        A location into which the result is stored. If not provided or None,\n        a freshly-allocated array is returned. For consistency with\n        ``ufunc.__call__``, if given as a keyword, this may be wrapped in a\n        1-element tuple.\n\n        .. versionchanged:: 1.13.0\n           Tuples are allowed for keyword argument.\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the original `array`.\n\n        .. versionadded:: 1.7.0\n    initial : scalar, optional\n        The value with which to start the reduction.\n        If the ufunc has no identity or the dtype is object, this defaults\n        to None - otherwise it defaults to ufunc.identity.\n        If ``None`` is given, the first element of the reduction is used,\n        and an error is thrown if the reduction is empty.\n\n        .. versionadded:: 1.15.0\n\n    where : array_like of bool, optional\n        A boolean array which is broadcasted to match the dimensions\n        of `array`, and selects elements to include in the reduction. Note\n        that for ufuncs like ``minimum`` that do not have an identity\n        defined, one has to pass in also ``initial``.\n\n        .. versionadded:: 1.17.0\n\n    Returns\n    -------\n    r : ndarray\n        The reduced array. If `out` was supplied, `r` is a reference to it.\n\n    Examples\n    --------\n    >>> np.multiply.reduce([2,3,5])\n    30\n\n    A multi-dimensional array example:\n\n    >>> X = np.arange(8).reshape((2,2,2))\n    >>> X\n    array([[[0, 1],\n            [2, 3]],\n           [[4, 5],\n            [6, 7]]])\n    >>> np.add.reduce(X, 0)\n    array([[ 4,  6],\n           [ 8, 10]])\n    >>> np.add.reduce(X) # confirm: default axis value is 0\n    array([[ 4,  6],\n           [ 8, 10]])\n    >>> np.add.reduce(X, 1)\n    array([[ 2,  4],\n           [10, 12]])\n    >>> np.add.reduce(X, 2)\n    array([[ 1,  5],\n           [ 9, 13]])\n\n    You can use the ``initial`` keyword argument to initialize the reduction\n    with a different value, and ``where`` to select specific elements to include:\n\n    >>> np.add.reduce([10], initial=5)\n    15\n    >>> np.add.reduce(np.ones((2, 2, 2)), axis=(0, 2), initial=10)\n    array([14., 14.])\n    >>> a = np.array([10., np.nan, 10])\n    >>> np.add.reduce(a, where=~np.isnan(a))\n    20.0\n\n    Allows reductions of empty arrays where they would normally fail, i.e.\n    for ufuncs without an identity.\n\n    >>> np.minimum.reduce([], initial=np.inf)\n    inf\n    >>> np.minimum.reduce([[1., 2.], [3., 4.]], initial=10., where=[True, False])\n    array([ 1., 10.])\n    >>> np.minimum.reduce([])\n    Traceback (most recent call last):\n        ...\n    ValueError: zero-size array to reduction operation minimum which has no identity\n    "))
add_newdoc('numpy._core', 'ufunc', ('accumulate', "\n    accumulate(array, axis=0, dtype=None, out=None)\n\n    Accumulate the result of applying the operator to all elements.\n\n    For a one-dimensional array, accumulate produces results equivalent to::\n\n      r = np.empty(len(A))\n      t = op.identity        # op = the ufunc being applied to A's  elements\n      for i in range(len(A)):\n          t = op(t, A[i])\n          r[i] = t\n      return r\n\n    For example, add.accumulate() is equivalent to np.cumsum().\n\n    For a multi-dimensional array, accumulate is applied along only one\n    axis (axis zero by default; see Examples below) so repeated use is\n    necessary if one wants to accumulate over multiple axes.\n\n    Parameters\n    ----------\n    array : array_like\n        The array to act on.\n    axis : int, optional\n        The axis along which to apply the accumulation; default is zero.\n    dtype : data-type code, optional\n        The data-type used to represent the intermediate results. Defaults\n        to the data-type of the output array if such is provided, or the\n        data-type of the input array if no output array is provided.\n    out : ndarray, None, or tuple of ndarray and None, optional\n        A location into which the result is stored. If not provided or None,\n        a freshly-allocated array is returned. For consistency with\n        ``ufunc.__call__``, if given as a keyword, this may be wrapped in a\n        1-element tuple.\n\n        .. versionchanged:: 1.13.0\n           Tuples are allowed for keyword argument.\n\n    Returns\n    -------\n    r : ndarray\n        The accumulated values. If `out` was supplied, `r` is a reference to\n        `out`.\n\n    Examples\n    --------\n    1-D array examples:\n\n    >>> np.add.accumulate([2, 3, 5])\n    array([ 2,  5, 10])\n    >>> np.multiply.accumulate([2, 3, 5])\n    array([ 2,  6, 30])\n\n    2-D array examples:\n\n    >>> I = np.eye(2)\n    >>> I\n    array([[1.,  0.],\n           [0.,  1.]])\n\n    Accumulate along axis 0 (rows), down columns:\n\n    >>> np.add.accumulate(I, 0)\n    array([[1.,  0.],\n           [1.,  1.]])\n    >>> np.add.accumulate(I) # no axis specified = axis zero\n    array([[1.,  0.],\n           [1.,  1.]])\n\n    Accumulate along axis 1 (columns), through rows:\n\n    >>> np.add.accumulate(I, 1)\n    array([[1.,  1.],\n           [0.,  1.]])\n\n    "))
add_newdoc('numpy._core', 'ufunc', ('reduceat', '\n    reduceat(array, indices, axis=0, dtype=None, out=None)\n\n    Performs a (local) reduce with specified slices over a single axis.\n\n    For i in ``range(len(indices))``, `reduceat` computes\n    ``ufunc.reduce(array[indices[i]:indices[i+1]])``, which becomes the i-th\n    generalized "row" parallel to `axis` in the final result (i.e., in a\n    2-D array, for example, if `axis = 0`, it becomes the i-th row, but if\n    `axis = 1`, it becomes the i-th column).  There are three exceptions to this:\n\n    * when ``i = len(indices) - 1`` (so for the last index),\n      ``indices[i+1] = array.shape[axis]``.\n    * if ``indices[i] >= indices[i + 1]``, the i-th generalized "row" is\n      simply ``array[indices[i]]``.\n    * if ``indices[i] >= len(array)`` or ``indices[i] < 0``, an error is raised.\n\n    The shape of the output depends on the size of `indices`, and may be\n    larger than `array` (this happens if ``len(indices) > array.shape[axis]``).\n\n    Parameters\n    ----------\n    array : array_like\n        The array to act on.\n    indices : array_like\n        Paired indices, comma separated (not colon), specifying slices to\n        reduce.\n    axis : int, optional\n        The axis along which to apply the reduceat.\n    dtype : data-type code, optional\n        The type used to represent the intermediate results. Defaults\n        to the data type of the output array if this is provided, or\n        the data type of the input array if no output array is provided.\n    out : ndarray, None, or tuple of ndarray and None, optional\n        A location into which the result is stored. If not provided or None,\n        a freshly-allocated array is returned. For consistency with\n        ``ufunc.__call__``, if given as a keyword, this may be wrapped in a\n        1-element tuple.\n\n        .. versionchanged:: 1.13.0\n           Tuples are allowed for keyword argument.\n\n    Returns\n    -------\n    r : ndarray\n        The reduced values. If `out` was supplied, `r` is a reference to\n        `out`.\n\n    Notes\n    -----\n    A descriptive example:\n\n    If `array` is 1-D, the function `ufunc.accumulate(array)` is the same as\n    ``ufunc.reduceat(array, indices)[::2]`` where `indices` is\n    ``range(len(array) - 1)`` with a zero placed\n    in every other element:\n    ``indices = zeros(2 * len(array) - 1)``,\n    ``indices[1::2] = range(1, len(array))``.\n\n    Don\'t be fooled by this attribute\'s name: `reduceat(array)` is not\n    necessarily smaller than `array`.\n\n    Examples\n    --------\n    To take the running sum of four successive values:\n\n    >>> np.add.reduceat(np.arange(8),[0,4, 1,5, 2,6, 3,7])[::2]\n    array([ 6, 10, 14, 18])\n\n    A 2-D example:\n\n    >>> x = np.linspace(0, 15, 16).reshape(4,4)\n    >>> x\n    array([[ 0.,   1.,   2.,   3.],\n           [ 4.,   5.,   6.,   7.],\n           [ 8.,   9.,  10.,  11.],\n           [12.,  13.,  14.,  15.]])\n\n    ::\n\n     # reduce such that the result has the following five rows:\n     # [row1 + row2 + row3]\n     # [row4]\n     # [row2]\n     # [row3]\n     # [row1 + row2 + row3 + row4]\n\n    >>> np.add.reduceat(x, [0, 3, 1, 2, 0])\n    array([[12.,  15.,  18.,  21.],\n           [12.,  13.,  14.,  15.],\n           [ 4.,   5.,   6.,   7.],\n           [ 8.,   9.,  10.,  11.],\n           [24.,  28.,  32.,  36.]])\n\n    ::\n\n     # reduce such that result has the following two columns:\n     # [col1 * col2 * col3, col4]\n\n    >>> np.multiply.reduceat(x, [0, 3], 1)\n    array([[   0.,     3.],\n           [ 120.,     7.],\n           [ 720.,    11.],\n           [2184.,    15.]])\n\n    '))
add_newdoc('numpy._core', 'ufunc', ('outer', '\n    outer(A, B, /, **kwargs)\n\n    Apply the ufunc `op` to all pairs (a, b) with a in `A` and b in `B`.\n\n    Let ``M = A.ndim``, ``N = B.ndim``. Then the result, `C`, of\n    ``op.outer(A, B)`` is an array of dimension M + N such that:\n\n    .. math:: C[i_0, ..., i_{M-1}, j_0, ..., j_{N-1}] =\n       op(A[i_0, ..., i_{M-1}], B[j_0, ..., j_{N-1}])\n\n    For `A` and `B` one-dimensional, this is equivalent to::\n\n      r = empty(len(A),len(B))\n      for i in range(len(A)):\n          for j in range(len(B)):\n              r[i,j] = op(A[i], B[j])  # op = ufunc in question\n\n    Parameters\n    ----------\n    A : array_like\n        First array\n    B : array_like\n        Second array\n    kwargs : any\n        Arguments to pass on to the ufunc. Typically `dtype` or `out`.\n        See `ufunc` for a comprehensive overview of all available arguments.\n\n    Returns\n    -------\n    r : ndarray\n        Output array\n\n    See Also\n    --------\n    numpy.outer : A less powerful version of ``np.multiply.outer``\n                  that `ravel`\\ s all inputs to 1D. This exists\n                  primarily for compatibility with old code.\n\n    tensordot : ``np.tensordot(a, b, axes=((), ()))`` and\n                ``np.multiply.outer(a, b)`` behave same for all\n                dimensions of a and b.\n\n    Examples\n    --------\n    >>> np.multiply.outer([1, 2, 3], [4, 5, 6])\n    array([[ 4,  5,  6],\n           [ 8, 10, 12],\n           [12, 15, 18]])\n\n    A multi-dimensional example:\n\n    >>> A = np.array([[1, 2, 3], [4, 5, 6]])\n    >>> A.shape\n    (2, 3)\n    >>> B = np.array([[1, 2, 3, 4]])\n    >>> B.shape\n    (1, 4)\n    >>> C = np.multiply.outer(A, B)\n    >>> C.shape; C\n    (2, 3, 1, 4)\n    array([[[[ 1,  2,  3,  4]],\n            [[ 2,  4,  6,  8]],\n            [[ 3,  6,  9, 12]]],\n           [[[ 4,  8, 12, 16]],\n            [[ 5, 10, 15, 20]],\n            [[ 6, 12, 18, 24]]]])\n\n    '))
add_newdoc('numpy._core', 'ufunc', ('at', "\n    at(a, indices, b=None, /)\n\n    Performs unbuffered in place operation on operand 'a' for elements\n    specified by 'indices'. For addition ufunc, this method is equivalent to\n    ``a[indices] += b``, except that results are accumulated for elements that\n    are indexed more than once. For example, ``a[[0,0]] += 1`` will only\n    increment the first element once because of buffering, whereas\n    ``add.at(a, [0,0], 1)`` will increment the first element twice.\n\n    .. versionadded:: 1.8.0\n\n    Parameters\n    ----------\n    a : array_like\n        The array to perform in place operation on.\n    indices : array_like or tuple\n        Array like index object or slice object for indexing into first\n        operand. If first operand has multiple dimensions, indices can be a\n        tuple of array like index objects or slice objects.\n    b : array_like\n        Second operand for ufuncs requiring two operands. Operand must be\n        broadcastable over first operand after indexing or slicing.\n\n    Examples\n    --------\n    Set items 0 and 1 to their negative values:\n\n    >>> a = np.array([1, 2, 3, 4])\n    >>> np.negative.at(a, [0, 1])\n    >>> a\n    array([-1, -2,  3,  4])\n\n    Increment items 0 and 1, and increment item 2 twice:\n\n    >>> a = np.array([1, 2, 3, 4])\n    >>> np.add.at(a, [0, 1, 2, 2], 1)\n    >>> a\n    array([2, 3, 5, 4])\n\n    Add items 0 and 1 in first array to second array,\n    and store results in first array:\n\n    >>> a = np.array([1, 2, 3, 4])\n    >>> b = np.array([1, 2])\n    >>> np.add.at(a, [0, 1], b)\n    >>> a\n    array([2, 4, 3, 4])\n\n    "))
add_newdoc('numpy._core', 'ufunc', ('resolve_dtypes', '\n    resolve_dtypes(dtypes, *, signature=None, casting=None, reduction=False)\n\n    Find the dtypes NumPy will use for the operation.  Both input and\n    output dtypes are returned and may differ from those provided.\n\n    .. note::\n\n        This function always applies NEP 50 rules since it is not provided\n        any actual values.  The Python types ``int``, ``float``, and\n        ``complex`` thus behave weak and should be passed for "untyped"\n        Python input.\n\n    Parameters\n    ----------\n    dtypes : tuple of dtypes, None, or literal int, float, complex\n        The input dtypes for each operand.  Output operands can be\n        None, indicating that the dtype must be found.\n    signature : tuple of DTypes or None, optional\n        If given, enforces exact DType (classes) of the specific operand.\n        The ufunc ``dtype`` argument is equivalent to passing a tuple with\n        only output dtypes set.\n    casting : {\'no\', \'equiv\', \'safe\', \'same_kind\', \'unsafe\'}, optional\n        The casting mode when casting is necessary.  This is identical to\n        the ufunc call casting modes.\n    reduction : boolean\n        If given, the resolution assumes a reduce operation is happening\n        which slightly changes the promotion and type resolution rules.\n        `dtypes` is usually something like ``(None, np.dtype("i2"), None)``\n        for reductions (first input is also the output).\n\n        .. note::\n\n            The default casting mode is "same_kind", however, as of\n            NumPy 1.24, NumPy uses "unsafe" for reductions.\n\n    Returns\n    -------\n    dtypes : tuple of dtypes\n        The dtypes which NumPy would use for the calculation.  Note that\n        dtypes may not match the passed in ones (casting is necessary).\n\n\n    Examples\n    --------\n    This API requires passing dtypes, define them for convenience:\n\n    >>> int32 = np.dtype("int32")\n    >>> float32 = np.dtype("float32")\n\n    The typical ufunc call does not pass an output dtype.  `numpy.add` has two\n    inputs and one output, so leave the output as ``None`` (not provided):\n\n    >>> np.add.resolve_dtypes((int32, float32, None))\n    (dtype(\'float64\'), dtype(\'float64\'), dtype(\'float64\'))\n\n    The loop found uses "float64" for all operands (including the output), the\n    first input would be cast.\n\n    ``resolve_dtypes`` supports "weak" handling for Python scalars by passing\n    ``int``, ``float``, or ``complex``:\n\n    >>> np.add.resolve_dtypes((float32, float, None))\n    (dtype(\'float32\'), dtype(\'float32\'), dtype(\'float32\'))\n\n    Where the Python ``float`` behaves samilar to a Python value ``0.0``\n    in a ufunc call.  (See :ref:`NEP 50 <NEP50>` for details.)\n\n    '))
add_newdoc('numpy._core', 'ufunc', ('_resolve_dtypes_and_context', '\n    _resolve_dtypes_and_context(dtypes, *, signature=None, casting=None, reduction=False)\n\n    See `numpy.ufunc.resolve_dtypes` for parameter information.  This\n    function is considered *unstable*.  You may use it, but the returned\n    information is NumPy version specific and expected to change.\n    Large API/ABI changes are not expected, but a new NumPy version is\n    expected to require updating code using this functionality.\n\n    This function is designed to be used in conjunction with\n    `numpy.ufunc._get_strided_loop`.  The calls are split to mirror the C API\n    and allow future improvements.\n\n    Returns\n    -------\n    dtypes : tuple of dtypes\n    call_info :\n        PyCapsule with all necessary information to get access to low level\n        C calls.  See `numpy.ufunc._get_strided_loop` for more information.\n\n    '))
add_newdoc('numpy._core', 'ufunc', ('_get_strided_loop', "\n    _get_strided_loop(call_info, /, *, fixed_strides=None)\n\n    This function fills in the ``call_info`` capsule to include all\n    information necessary to call the low-level strided loop from NumPy.\n\n    See notes for more information.\n\n    Parameters\n    ----------\n    call_info : PyCapsule\n        The PyCapsule returned by `numpy.ufunc._resolve_dtypes_and_context`.\n    fixed_strides : tuple of int or None, optional\n        A tuple with fixed byte strides of all input arrays.  NumPy may use\n        this information to find specialized loops, so any call must follow\n        the given stride.  Use ``None`` to indicate that the stride is not\n        known (or not fixed) for all calls.\n\n    Notes\n    -----\n    Together with `numpy.ufunc._resolve_dtypes_and_context` this function\n    gives low-level access to the NumPy ufunc loops.\n    The first function does general preparation and returns the required\n    information. It returns this as a C capsule with the version specific\n    name ``numpy_1.24_ufunc_call_info``.\n    The NumPy 1.24 ufunc call info capsule has the following layout::\n\n        typedef struct {\n            PyArrayMethod_StridedLoop *strided_loop;\n            PyArrayMethod_Context *context;\n            NpyAuxData *auxdata;\n\n            /* Flag information (expected to change) */\n            npy_bool requires_pyapi;  /* GIL is required by loop */\n\n            /* Loop doesn't set FPE flags; if not set check FPE flags */\n            npy_bool no_floatingpoint_errors;\n        } ufunc_call_info;\n\n    Note that the first call only fills in the ``context``.  The call to\n    ``_get_strided_loop`` fills in all other data.\n    Please see the ``numpy/experimental_dtype_api.h`` header for exact\n    call information; the main thing to note is that the new-style loops\n    return 0 on success, -1 on failure.  They are passed context as new\n    first input and ``auxdata`` as (replaced) last.\n\n    Only the ``strided_loop``signature is considered guaranteed stable\n    for NumPy bug-fix releases.  All other API is tied to the experimental\n    API versioning.\n\n    The reason for the split call is that cast information is required to\n    decide what the fixed-strides will be.\n\n    NumPy ties the lifetime of the ``auxdata`` information to the capsule.\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', '\n    dtype(dtype, align=False, copy=False, [metadata])\n\n    Create a data type object.\n\n    A numpy array is homogeneous, and contains elements described by a\n    dtype object. A dtype object can be constructed from different\n    combinations of fundamental numeric types.\n\n    Parameters\n    ----------\n    dtype\n        Object to be converted to a data type object.\n    align : bool, optional\n        Add padding to the fields to match what a C compiler would output\n        for a similar C-struct. Can be ``True`` only if `obj` is a dictionary\n        or a comma-separated string. If a struct dtype is being created,\n        this also sets a sticky alignment flag ``isalignedstruct``.\n    copy : bool, optional\n        Make a new copy of the data-type object. If ``False``, the result\n        may just be a reference to a built-in data-type object.\n    metadata : dict, optional\n        An optional dictionary with dtype metadata.\n\n    See also\n    --------\n    result_type\n\n    Examples\n    --------\n    Using array-scalar type:\n\n    >>> np.dtype(np.int16)\n    dtype(\'int16\')\n\n    Structured type, one field name \'f1\', containing int16:\n\n    >>> np.dtype([(\'f1\', np.int16)])\n    dtype([(\'f1\', \'<i2\')])\n\n    Structured type, one field named \'f1\', in itself containing a structured\n    type with one field:\n\n    >>> np.dtype([(\'f1\', [(\'f1\', np.int16)])])\n    dtype([(\'f1\', [(\'f1\', \'<i2\')])])\n\n    Structured type, two fields: the first field contains an unsigned int, the\n    second an int32:\n\n    >>> np.dtype([(\'f1\', np.uint64), (\'f2\', np.int32)])\n    dtype([(\'f1\', \'<u8\'), (\'f2\', \'<i4\')])\n\n    Using array-protocol type strings:\n\n    >>> np.dtype([(\'a\',\'f8\'),(\'b\',\'S10\')])\n    dtype([(\'a\', \'<f8\'), (\'b\', \'S10\')])\n\n    Using comma-separated field formats.  The shape is (2,3):\n\n    >>> np.dtype("i4, (2,3)f8")\n    dtype([(\'f0\', \'<i4\'), (\'f1\', \'<f8\', (2, 3))])\n\n    Using tuples.  ``int`` is a fixed type, 3 the field\'s shape.  ``void``\n    is a flexible type, here of size 10:\n\n    >>> np.dtype([(\'hello\',(np.int64,3)),(\'world\',np.void,10)])\n    dtype([(\'hello\', \'<i8\', (3,)), (\'world\', \'V10\')])\n\n    Subdivide ``int16`` into 2 ``int8``\'s, called x and y.  0 and 1 are\n    the offsets in bytes:\n\n    >>> np.dtype((np.int16, {\'x\':(np.int8,0), \'y\':(np.int8,1)}))\n    dtype((numpy.int16, [(\'x\', \'i1\'), (\'y\', \'i1\')]))\n\n    Using dictionaries.  Two fields named \'gender\' and \'age\':\n\n    >>> np.dtype({\'names\':[\'gender\',\'age\'], \'formats\':[\'S1\',np.uint8]})\n    dtype([(\'gender\', \'S1\'), (\'age\', \'u1\')])\n\n    Offsets in bytes, here 0 and 25:\n\n    >>> np.dtype({\'surname\':(\'S25\',0),\'age\':(np.uint8,25)})\n    dtype([(\'surname\', \'S25\'), (\'age\', \'u1\')])\n\n    ')
add_newdoc('numpy._core.multiarray', 'dtype', ('alignment', "\n    The required alignment (bytes) of this data-type according to the compiler.\n\n    More information is available in the C-API section of the manual.\n\n    Examples\n    --------\n\n    >>> x = np.dtype('i4')\n    >>> x.alignment\n    4\n\n    >>> x = np.dtype(float)\n    >>> x.alignment\n    8\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('byteorder', "\n    A character indicating the byte-order of this data-type object.\n\n    One of:\n\n    ===  ==============\n    '='  native\n    '<'  little-endian\n    '>'  big-endian\n    '|'  not applicable\n    ===  ==============\n\n    All built-in data-type objects have byteorder either '=' or '|'.\n\n    Examples\n    --------\n\n    >>> dt = np.dtype('i2')\n    >>> dt.byteorder\n    '='\n    >>> # endian is not relevant for 8 bit numbers\n    >>> np.dtype('i1').byteorder\n    '|'\n    >>> # or ASCII strings\n    >>> np.dtype('S2').byteorder\n    '|'\n    >>> # Even if specific code is given, and it is native\n    >>> # '=' is the byteorder\n    >>> import sys\n    >>> sys_is_le = sys.byteorder == 'little'\n    >>> native_code = '<' if sys_is_le else '>'\n    >>> swapped_code = '>' if sys_is_le else '<'\n    >>> dt = np.dtype(native_code + 'i2')\n    >>> dt.byteorder\n    '='\n    >>> # Swapped code shows up as itself\n    >>> dt = np.dtype(swapped_code + 'i2')\n    >>> dt.byteorder == swapped_code\n    True\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('char', "A unique character code for each of the 21 different built-in types.\n\n    Examples\n    --------\n\n    >>> x = np.dtype(float)\n    >>> x.char\n    'd'\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('descr', "\n    `__array_interface__` description of the data-type.\n\n    The format is that required by the 'descr' key in the\n    `__array_interface__` attribute.\n\n    Warning: This attribute exists specifically for `__array_interface__`,\n    and passing it directly to `numpy.dtype` will not accurately reconstruct\n    some dtypes (e.g., scalar and subarray dtypes).\n\n    Examples\n    --------\n\n    >>> x = np.dtype(float)\n    >>> x.descr\n    [('', '<f8')]\n\n    >>> dt = np.dtype([('name', np.str_, 16), ('grades', np.float64, (2,))])\n    >>> dt.descr\n    [('name', '<U16'), ('grades', '<f8', (2,))]\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('fields', "\n    Dictionary of named fields defined for this data type, or ``None``.\n\n    The dictionary is indexed by keys that are the names of the fields.\n    Each entry in the dictionary is a tuple fully describing the field::\n\n      (dtype, offset[, title])\n\n    Offset is limited to C int, which is signed and usually 32 bits.\n    If present, the optional title can be any object (if it is a string\n    or unicode then it will also be a key in the fields dictionary,\n    otherwise it's meta-data). Notice also that the first two elements\n    of the tuple can be passed directly as arguments to the \n    ``ndarray.getfield`` and ``ndarray.setfield`` methods.\n\n    See Also\n    --------\n    ndarray.getfield, ndarray.setfield\n\n    Examples\n    --------\n    >>> dt = np.dtype([('name', np.str_, 16), ('grades', np.float64, (2,))])\n    >>> print(dt.fields)\n    {'grades': (dtype(('float64',(2,))), 16), 'name': (dtype('|S16'), 0)}\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('flags', "\n    Bit-flags describing how this data type is to be interpreted.\n\n    Bit-masks are in ``numpy._core.multiarray`` as the constants\n    `ITEM_HASOBJECT`, `LIST_PICKLE`, `ITEM_IS_POINTER`, `NEEDS_INIT`,\n    `NEEDS_PYAPI`, `USE_GETITEM`, `USE_SETITEM`. A full explanation\n    of these flags is in C-API documentation; they are largely useful\n    for user-defined data-types.\n\n    The following example demonstrates that operations on this particular\n    dtype requires Python C-API.\n\n    Examples\n    --------\n\n    >>> x = np.dtype([('a', np.int32, 8), ('b', np.float64, 6)])\n    >>> x.flags\n    16\n    >>> np._core.multiarray.NEEDS_PYAPI\n    16\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('hasobject', "\n    Boolean indicating whether this dtype contains any reference-counted\n    objects in any fields or sub-dtypes.\n\n    Recall that what is actually in the ndarray memory representing\n    the Python object is the memory address of that object (a pointer).\n    Special handling may be required, and this attribute is useful for\n    distinguishing data types that may contain arbitrary Python objects\n    and data-types that won't.\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('isbuiltin', "\n    Integer indicating how this dtype relates to the built-in dtypes.\n\n    Read-only.\n\n    =  ========================================================================\n    0  if this is a structured array type, with fields\n    1  if this is a dtype compiled into numpy (such as ints, floats etc)\n    2  if the dtype is for a user-defined numpy type\n       A user-defined type uses the numpy C-API machinery to extend\n       numpy to handle a new array type. See\n       :ref:`user.user-defined-data-types` in the NumPy manual.\n    =  ========================================================================\n\n    Examples\n    --------\n    >>> dt = np.dtype('i2')\n    >>> dt.isbuiltin\n    1\n    >>> dt = np.dtype('f8')\n    >>> dt.isbuiltin\n    1\n    >>> dt = np.dtype([('field1', 'f8')])\n    >>> dt.isbuiltin\n    0\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('isnative', '\n    Boolean indicating whether the byte order of this dtype is native\n    to the platform.\n\n    '))
add_newdoc('numpy._core.multiarray', 'dtype', ('isalignedstruct', '\n    Boolean indicating whether the dtype is a struct which maintains\n    field alignment. This flag is sticky, so when combining multiple\n    structs together, it is preserved and produces new dtypes which\n    are also aligned.\n\n    '))
add_newdoc('numpy._core.multiarray', 'dtype', ('itemsize', "\n    The element size of this data-type object.\n\n    For 18 of the 21 types this number is fixed by the data-type.\n    For the flexible data-types, this number can be anything.\n\n    Examples\n    --------\n\n    >>> arr = np.array([[1, 2], [3, 4]])\n    >>> arr.dtype\n    dtype('int64')\n    >>> arr.itemsize\n    8\n\n    >>> dt = np.dtype([('name', np.str_, 16), ('grades', np.float64, (2,))])\n    >>> dt.itemsize\n    80\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('kind', "\n    A character code (one of 'biufcmMOSUV') identifying the general kind of data.\n\n    =  ======================\n    b  boolean\n    i  signed integer\n    u  unsigned integer\n    f  floating-point\n    c  complex floating-point\n    m  timedelta\n    M  datetime\n    O  object\n    S  (byte-)string\n    U  Unicode\n    V  void\n    =  ======================\n\n    Examples\n    --------\n\n    >>> dt = np.dtype('i4')\n    >>> dt.kind\n    'i'\n    >>> dt = np.dtype('f8')\n    >>> dt.kind\n    'f'\n    >>> dt = np.dtype([('field1', 'f8')])\n    >>> dt.kind\n    'V'\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('metadata', '\n    Either ``None`` or a readonly dictionary of metadata (mappingproxy).\n\n    The metadata field can be set using any dictionary at data-type\n    creation. NumPy currently has no uniform approach to propagating\n    metadata; although some array operations preserve it, there is no\n    guarantee that others will.\n\n    .. warning::\n\n        Although used in certain projects, this feature was long undocumented\n        and is not well supported. Some aspects of metadata propagation\n        are expected to change in the future.\n\n    Examples\n    --------\n\n    >>> dt = np.dtype(float, metadata={"key": "value"})\n    >>> dt.metadata["key"]\n    \'value\'\n    >>> arr = np.array([1, 2, 3], dtype=dt)\n    >>> arr.dtype.metadata\n    mappingproxy({\'key\': \'value\'})\n\n    Adding arrays with identical datatypes currently preserves the metadata:\n\n    >>> (arr + arr).dtype.metadata\n    mappingproxy({\'key\': \'value\'})\n\n    But if the arrays have different dtype metadata, the metadata may be\n    dropped:\n\n    >>> dt2 = np.dtype(float, metadata={"key2": "value2"})\n    >>> arr2 = np.array([3, 2, 1], dtype=dt2)\n    >>> (arr + arr2).dtype.metadata is None\n    True  # The metadata field is cleared so None is returned\n    '))
add_newdoc('numpy._core.multiarray', 'dtype', ('name', "\n    A bit-width name for this data-type.\n\n    Un-sized flexible data-type objects do not have this attribute.\n\n    Examples\n    --------\n\n    >>> x = np.dtype(float)\n    >>> x.name\n    'float64'\n    >>> x = np.dtype([('a', np.int32, 8), ('b', np.float64, 6)])\n    >>> x.name\n    'void640'\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('names', "\n    Ordered list of field names, or ``None`` if there are no fields.\n\n    The names are ordered according to increasing byte offset. This can be\n    used, for example, to walk through all of the named fields in offset order.\n\n    Examples\n    --------\n    >>> dt = np.dtype([('name', np.str_, 16), ('grades', np.float64, (2,))])\n    >>> dt.names\n    ('name', 'grades')\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('num', '\n    A unique number for each of the 21 different built-in types.\n\n    These are roughly ordered from least-to-most precision.\n\n    Examples\n    --------\n\n    >>> dt = np.dtype(str)\n    >>> dt.num\n    19\n\n    >>> dt = np.dtype(float)\n    >>> dt.num\n    12\n\n    '))
add_newdoc('numpy._core.multiarray', 'dtype', ('shape', "\n    Shape tuple of the sub-array if this data type describes a sub-array,\n    and ``()`` otherwise.\n\n    Examples\n    --------\n\n    >>> dt = np.dtype(('i4', 4))\n    >>> dt.shape\n    (4,)\n\n    >>> dt = np.dtype(('i4', (2, 3)))\n    >>> dt.shape\n    (2, 3)\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('ndim', "\n    Number of dimensions of the sub-array if this data type describes a\n    sub-array, and ``0`` otherwise.\n\n    .. versionadded:: 1.13.0\n\n    Examples\n    --------\n    >>> x = np.dtype(float)\n    >>> x.ndim\n    0\n\n    >>> x = np.dtype((float, 8))\n    >>> x.ndim\n    1\n\n    >>> x = np.dtype(('i4', (3, 4)))\n    >>> x.ndim\n    2\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('str', 'The array-protocol typestring of this data-type object.'))
add_newdoc('numpy._core.multiarray', 'dtype', ('subdtype', "\n    Tuple ``(item_dtype, shape)`` if this `dtype` describes a sub-array, and\n    None otherwise.\n\n    The *shape* is the fixed shape of the sub-array described by this\n    data type, and *item_dtype* the data type of the array.\n\n    If a field whose dtype object has this attribute is retrieved,\n    then the extra dimensions implied by *shape* are tacked on to\n    the end of the retrieved array.\n\n    See Also\n    --------\n    dtype.base\n\n    Examples\n    --------\n    >>> x = numpy.dtype('8f')\n    >>> x.subdtype\n    (dtype('float32'), (8,))\n\n    >>> x =  numpy.dtype('i2')\n    >>> x.subdtype\n    >>>\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('base', "\n    Returns dtype for the base element of the subarrays,\n    regardless of their dimension or shape.\n\n    See Also\n    --------\n    dtype.subdtype\n\n    Examples\n    --------\n    >>> x = numpy.dtype('8f')\n    >>> x.base\n    dtype('float32')\n\n    >>> x =  numpy.dtype('i2')\n    >>> x.base\n    dtype('int16')\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('type', 'The type object used to instantiate a scalar of this data-type.'))
add_newdoc('numpy._core.multiarray', 'dtype', ('newbyteorder', "\n    newbyteorder(new_order='S', /)\n\n    Return a new dtype with a different byte order.\n\n    Changes are also made in all fields and sub-arrays of the data type.\n\n    Parameters\n    ----------\n    new_order : string, optional\n        Byte order to force; a value from the byte order specifications\n        below.  The default value ('S') results in swapping the current\n        byte order.  `new_order` codes can be any of:\n\n        * 'S' - swap dtype from current to opposite endian\n        * {'<', 'little'} - little endian\n        * {'>', 'big'} - big endian\n        * {'=', 'native'} - native order\n        * {'|', 'I'} - ignore (no change to byte order)\n\n    Returns\n    -------\n    new_dtype : dtype\n        New dtype object with the given change to the byte order.\n\n    Notes\n    -----\n    Changes are also made in all fields and sub-arrays of the data type.\n\n    Examples\n    --------\n    >>> import sys\n    >>> sys_is_le = sys.byteorder == 'little'\n    >>> native_code = '<' if sys_is_le else '>'\n    >>> swapped_code = '>' if sys_is_le else '<'\n    >>> native_dt = np.dtype(native_code+'i2')\n    >>> swapped_dt = np.dtype(swapped_code+'i2')\n    >>> native_dt.newbyteorder('S') == swapped_dt\n    True\n    >>> native_dt.newbyteorder() == swapped_dt\n    True\n    >>> native_dt == swapped_dt.newbyteorder('S')\n    True\n    >>> native_dt == swapped_dt.newbyteorder('=')\n    True\n    >>> native_dt == swapped_dt.newbyteorder('N')\n    True\n    >>> native_dt == native_dt.newbyteorder('|')\n    True\n    >>> np.dtype('<i2') == native_dt.newbyteorder('<')\n    True\n    >>> np.dtype('<i2') == native_dt.newbyteorder('L')\n    True\n    >>> np.dtype('>i2') == native_dt.newbyteorder('>')\n    True\n    >>> np.dtype('>i2') == native_dt.newbyteorder('B')\n    True\n\n    "))
add_newdoc('numpy._core.multiarray', 'dtype', ('__class_getitem__', '\n    __class_getitem__(item, /)\n\n    Return a parametrized wrapper around the `~numpy.dtype` type.\n\n    .. versionadded:: 1.22\n\n    Returns\n    -------\n    alias : types.GenericAlias\n        A parametrized `~numpy.dtype` type.\n\n    Examples\n    --------\n    >>> import numpy as np\n\n    >>> np.dtype[np.int64]\n    numpy.dtype[numpy.int64]\n\n    See Also\n    --------\n    :pep:`585` : Type hinting generics in standard collections.\n\n    '))
add_newdoc('numpy._core.multiarray', 'dtype', ('__ge__', '\n    __ge__(value, /)\n\n    Return ``self >= value``.\n\n    Equivalent to ``np.can_cast(value, self, casting="safe")``.\n\n    See Also\n    --------\n    can_cast : Returns True if cast between data types can occur according to\n               the casting rule.\n\n    '))
add_newdoc('numpy._core.multiarray', 'dtype', ('__le__', '\n    __le__(value, /)\n\n    Return ``self <= value``.\n\n    Equivalent to ``np.can_cast(self, value, casting="safe")``.\n\n    See Also\n    --------\n    can_cast : Returns True if cast between data types can occur according to\n               the casting rule.\n\n    '))
add_newdoc('numpy._core.multiarray', 'dtype', ('__gt__', '\n    __ge__(value, /)\n\n    Return ``self > value``.\n\n    Equivalent to\n    ``self != value and np.can_cast(value, self, casting="safe")``.\n\n    See Also\n    --------\n    can_cast : Returns True if cast between data types can occur according to\n               the casting rule.\n\n    '))
add_newdoc('numpy._core.multiarray', 'dtype', ('__lt__', '\n    __lt__(value, /)\n\n    Return ``self < value``.\n\n    Equivalent to\n    ``self != value and np.can_cast(self, value, casting="safe")``.\n\n    See Also\n    --------\n    can_cast : Returns True if cast between data types can occur according to\n               the casting rule.\n\n    '))
add_newdoc('numpy._core.multiarray', 'busdaycalendar', '\n    busdaycalendar(weekmask=\'1111100\', holidays=None)\n\n    A business day calendar object that efficiently stores information\n    defining valid days for the busday family of functions.\n\n    The default valid days are Monday through Friday ("business days").\n    A busdaycalendar object can be specified with any set of weekly\n    valid days, plus an optional "holiday" dates that always will be invalid.\n\n    Once a busdaycalendar object is created, the weekmask and holidays\n    cannot be modified.\n\n    .. versionadded:: 1.7.0\n\n    Parameters\n    ----------\n    weekmask : str or array_like of bool, optional\n        A seven-element array indicating which of Monday through Sunday are\n        valid days. May be specified as a length-seven list or array, like\n        [1,1,1,1,1,0,0]; a length-seven string, like \'1111100\'; or a string\n        like "Mon Tue Wed Thu Fri", made up of 3-character abbreviations for\n        weekdays, optionally separated by white space. Valid abbreviations\n        are: Mon Tue Wed Thu Fri Sat Sun\n    holidays : array_like of datetime64[D], optional\n        An array of dates to consider as invalid dates, no matter which\n        weekday they fall upon.  Holiday dates may be specified in any\n        order, and NaT (not-a-time) dates are ignored.  This list is\n        saved in a normalized form that is suited for fast calculations\n        of valid days.\n\n    Returns\n    -------\n    out : busdaycalendar\n        A business day calendar object containing the specified\n        weekmask and holidays values.\n\n    See Also\n    --------\n    is_busday : Returns a boolean array indicating valid days.\n    busday_offset : Applies an offset counted in valid days.\n    busday_count : Counts how many valid days are in a half-open date range.\n\n    Attributes\n    ----------\n    weekmask : (copy) seven-element array of bool\n    holidays : (copy) sorted array of datetime64[D]\n\n    Notes\n    -----\n    Once a busdaycalendar object is created, you cannot modify the\n    weekmask or holidays.  The attributes return copies of internal data.\n\n    Examples\n    --------\n    >>> # Some important days in July\n    ... bdd = np.busdaycalendar(\n    ...             holidays=[\'2011-07-01\', \'2011-07-04\', \'2011-07-17\'])\n    >>> # Default is Monday to Friday weekdays\n    ... bdd.weekmask\n    array([ True,  True,  True,  True,  True, False, False])\n    >>> # Any holidays already on the weekend are removed\n    ... bdd.holidays\n    array([\'2011-07-01\', \'2011-07-04\'], dtype=\'datetime64[D]\')\n    ')
add_newdoc('numpy._core.multiarray', 'busdaycalendar', ('weekmask', 'A copy of the seven-element boolean mask indicating valid days.'))
add_newdoc('numpy._core.multiarray', 'busdaycalendar', ('holidays', 'A copy of the holiday array indicating additional invalid days.'))
add_newdoc('numpy._core.multiarray', 'normalize_axis_index', "\n    normalize_axis_index(axis, ndim, msg_prefix=None)\n\n    Normalizes an axis index, `axis`, such that is a valid positive index into\n    the shape of array with `ndim` dimensions. Raises an AxisError with an\n    appropriate message if this is not possible.\n\n    Used internally by all axis-checking logic.\n\n    .. versionadded:: 1.13.0\n\n    Parameters\n    ----------\n    axis : int\n        The un-normalized index of the axis. Can be negative\n    ndim : int\n        The number of dimensions of the array that `axis` should be normalized\n        against\n    msg_prefix : str\n        A prefix to put before the message, typically the name of the argument\n\n    Returns\n    -------\n    normalized_axis : int\n        The normalized axis index, such that `0 <= normalized_axis < ndim`\n\n    Raises\n    ------\n    AxisError\n        If the axis index is invalid, when `-ndim <= axis < ndim` is false.\n\n    Examples\n    --------\n    >>> normalize_axis_index(0, ndim=3)\n    0\n    >>> normalize_axis_index(1, ndim=3)\n    1\n    >>> normalize_axis_index(-1, ndim=3)\n    2\n\n    >>> normalize_axis_index(3, ndim=3)\n    Traceback (most recent call last):\n    ...\n    AxisError: axis 3 is out of bounds for array of dimension 3\n    >>> normalize_axis_index(-4, ndim=3, msg_prefix='axes_arg')\n    Traceback (most recent call last):\n    ...\n    AxisError: axes_arg: axis -4 is out of bounds for array of dimension 3\n    ")
add_newdoc('numpy._core.multiarray', 'datetime_data', "\n    datetime_data(dtype, /)\n\n    Get information about the step size of a date or time type.\n\n    The returned tuple can be passed as the second argument of `numpy.datetime64` and\n    `numpy.timedelta64`.\n\n    Parameters\n    ----------\n    dtype : dtype\n        The dtype object, which must be a `datetime64` or `timedelta64` type.\n\n    Returns\n    -------\n    unit : str\n        The :ref:`datetime unit <arrays.dtypes.dateunits>` on which this dtype\n        is based.\n    count : int\n        The number of base units in a step.\n\n    Examples\n    --------\n    >>> dt_25s = np.dtype('timedelta64[25s]')\n    >>> np.datetime_data(dt_25s)\n    ('s', 25)\n    >>> np.array(10, dt_25s).astype('timedelta64[s]')\n    array(250, dtype='timedelta64[s]')\n\n    The result can be used to construct a datetime that uses the same units\n    as a timedelta\n\n    >>> np.datetime64('2010', np.datetime_data(dt_25s))\n    numpy.datetime64('2010-01-01T00:00:00','25s')\n    ")
add_newdoc('numpy._core.numerictypes', 'generic', '\n    Base class for numpy scalar types.\n\n    Class from which most (all?) numpy scalar types are derived.  For\n    consistency, exposes the same API as `ndarray`, despite many\n    consequent attributes being either "get-only," or completely irrelevant.\n    This is the class from which it is strongly suggested users should derive\n    custom scalar types.\n\n    ')

def refer_to_array_attribute(attr, method=True):
    if False:
        return 10
    docstring = '\n    Scalar {} identical to the corresponding array attribute.\n\n    Please see `ndarray.{}`.\n    '
    return (attr, docstring.format('method' if method else 'attribute', attr))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('T', method=False))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('base', method=False))
add_newdoc('numpy._core.numerictypes', 'generic', ('data', 'Pointer to start of data.'))
add_newdoc('numpy._core.numerictypes', 'generic', ('dtype', 'Get array data-descriptor.'))
add_newdoc('numpy._core.numerictypes', 'generic', ('flags', 'The integer value of flags.'))
add_newdoc('numpy._core.numerictypes', 'generic', ('flat', 'A 1-D view of the scalar.'))
add_newdoc('numpy._core.numerictypes', 'generic', ('imag', 'The imaginary part of the scalar.'))
add_newdoc('numpy._core.numerictypes', 'generic', ('itemsize', 'The length of one element in bytes.'))
add_newdoc('numpy._core.numerictypes', 'generic', ('ndim', 'The number of array dimensions.'))
add_newdoc('numpy._core.numerictypes', 'generic', ('real', 'The real part of the scalar.'))
add_newdoc('numpy._core.numerictypes', 'generic', ('shape', 'Tuple of array dimensions.'))
add_newdoc('numpy._core.numerictypes', 'generic', ('size', 'The number of elements in the gentype.'))
add_newdoc('numpy._core.numerictypes', 'generic', ('strides', 'Tuple of bytes steps in each dimension.'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('all'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('any'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('argmax'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('argmin'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('argsort'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('astype'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('byteswap'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('choose'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('clip'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('compress'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('conjugate'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('copy'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('cumprod'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('cumsum'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('diagonal'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('dump'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('dumps'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('fill'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('flatten'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('getfield'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('item'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('max'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('mean'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('min'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('nonzero'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('prod'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('put'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('ravel'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('repeat'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('reshape'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('resize'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('round'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('searchsorted'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('setfield'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('setflags'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('sort'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('squeeze'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('std'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('sum'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('swapaxes'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('take'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('tofile'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('tolist'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('tostring'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('trace'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('transpose'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('var'))
add_newdoc('numpy._core.numerictypes', 'generic', refer_to_array_attribute('view'))
add_newdoc('numpy._core.numerictypes', 'number', ('__class_getitem__', '\n    __class_getitem__(item, /)\n\n    Return a parametrized wrapper around the `~numpy.number` type.\n\n    .. versionadded:: 1.22\n\n    Returns\n    -------\n    alias : types.GenericAlias\n        A parametrized `~numpy.number` type.\n\n    Examples\n    --------\n    >>> from typing import Any\n    >>> import numpy as np\n\n    >>> np.signedinteger[Any]\n    numpy.signedinteger[typing.Any]\n\n    See Also\n    --------\n    :pep:`585` : Type hinting generics in standard collections.\n\n    '))
add_newdoc('numpy._core.numerictypes', 'number', '\n    Abstract base class of all numeric scalar types.\n\n    ')
add_newdoc('numpy._core.numerictypes', 'integer', '\n    Abstract base class of all integer scalar types.\n\n    ')
add_newdoc('numpy._core.numerictypes', 'signedinteger', '\n    Abstract base class of all signed integer scalar types.\n\n    ')
add_newdoc('numpy._core.numerictypes', 'unsignedinteger', '\n    Abstract base class of all unsigned integer scalar types.\n\n    ')
add_newdoc('numpy._core.numerictypes', 'inexact', '\n    Abstract base class of all numeric scalar types with a (potentially)\n    inexact representation of the values in its range, such as\n    floating-point numbers.\n\n    ')
add_newdoc('numpy._core.numerictypes', 'floating', '\n    Abstract base class of all floating-point scalar types.\n\n    ')
add_newdoc('numpy._core.numerictypes', 'complexfloating', '\n    Abstract base class of all complex number scalar types that are made up of\n    floating-point numbers.\n\n    ')
add_newdoc('numpy._core.numerictypes', 'flexible', '\n    Abstract base class of all scalar types without predefined length.\n    The actual size of these types depends on the specific `numpy.dtype`\n    instantiation.\n\n    ')
add_newdoc('numpy._core.numerictypes', 'character', '\n    Abstract base class of all character string scalar types.\n\n    ')