[
    {
        "func_name": "decompose",
        "original": "def decompose(S: np.ndarray, *, n_components: Optional[int]=None, transformer: Optional[object]=None, sort: bool=False, fit: bool=True, **kwargs: Any) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Decompose a feature matrix.\n\n    Given a spectrogram ``S``, produce a decomposition into ``components``\n    and ``activations`` such that ``S ~= components.dot(activations)``.\n\n    By default, this is done with with non-negative matrix factorization (NMF),\n    but any `sklearn.decomposition`-type object will work.\n\n    Parameters\n    ----------\n    S : np.ndarray [shape=(..., n_features, n_samples), dtype=float]\n        The input feature matrix (e.g., magnitude spectrogram)\n\n        If the input has multiple channels (leading dimensions), they will be automatically\n        flattened prior to decomposition.\n\n        If the input is multi-channel, channels and features are automatically flattened into\n        a single axis before the decomposition.\n        For example, a stereo input `S` with shape `(2, n_features, n_samples)` is\n        automatically reshaped to `(2 * n_features, n_samples)`.\n\n    n_components : int > 0 [scalar] or None\n        number of desired components\n\n        if None, then ``n_features`` components are used\n\n    transformer : None or object\n        If None, use `sklearn.decomposition.NMF`\n\n        Otherwise, any object with a similar interface to NMF should work.\n        ``transformer`` must follow the scikit-learn convention, where\n        input data is ``(n_samples, n_features)``.\n\n        `transformer.fit_transform()` will be run on ``S.T`` (not ``S``),\n        the return value of which is stored (transposed) as ``activations``\n\n        The components will be retrieved as ``transformer.components_.T``::\n\n            S ~= np.dot(activations, transformer.components_).T\n\n        or equivalently::\n\n            S ~= np.dot(transformer.components_.T, activations.T)\n\n    sort : bool\n        If ``True``, components are sorted by ascending peak frequency.\n\n        .. note:: If used with ``transformer``, sorting is applied to copies\n            of the decomposition parameters, and not to ``transformer``\n            internal parameters.\n\n        .. warning:: If the input array has more than two dimensions\n            (e.g., if it's a multi-channel spectrogram), then axis sorting\n            is not supported and a `ParameterError` exception is raised.\n\n    fit : bool\n        If `True`, components are estimated from the input ``S``.\n\n        If `False`, components are assumed to be pre-computed and stored\n        in ``transformer``, and are not changed.\n\n    **kwargs : Additional keyword arguments to the default transformer\n        `sklearn.decomposition.NMF`\n\n    Returns\n    -------\n    components: np.ndarray [shape=(..., n_features, n_components)]\n        matrix of components (basis elements).\n    activations: np.ndarray [shape=(n_components, n_samples)]\n        transformed matrix/activation matrix\n\n    Raises\n    ------\n    ParameterError\n        if ``fit`` is False and no ``transformer`` object is provided.\n\n        if the input array is multi-channel and ``sort=True`` is specified.\n\n    See Also\n    --------\n    sklearn.decomposition : SciKit-Learn matrix decomposition modules\n\n    Examples\n    --------\n    Decompose a magnitude spectrogram into 16 components with NMF\n\n    >>> y, sr = librosa.load(librosa.ex('pistachio'), duration=5)\n    >>> S = np.abs(librosa.stft(y))\n    >>> comps, acts = librosa.decompose.decompose(S, n_components=16)\n\n    Sort components by ascending peak frequency\n\n    >>> comps, acts = librosa.decompose.decompose(S, n_components=16,\n    ...                                           sort=True)\n\n    Or with sparse dictionary learning\n\n    >>> import sklearn.decomposition\n    >>> T = sklearn.decomposition.MiniBatchDictionaryLearning(n_components=16)\n    >>> scomps, sacts = librosa.decompose.decompose(S, transformer=T, sort=True)\n\n    >>> import matplotlib.pyplot as plt\n    >>> layout = [list(\".AAAA\"), list(\"BCCCC\"), list(\".DDDD\")]\n    >>> fig, ax = plt.subplot_mosaic(layout, constrained_layout=True)\n    >>> librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),\n    ...                          y_axis='log', x_axis='time', ax=ax['A'])\n    >>> ax['A'].set(title='Input spectrogram')\n    >>> ax['A'].label_outer()\n    >>> librosa.display.specshow(librosa.amplitude_to_db(comps,\n    >>>                                                  ref=np.max),\n    >>>                          y_axis='log', ax=ax['B'])\n    >>> ax['B'].set(title='Components')\n    >>> ax['B'].label_outer()\n    >>> ax['B'].sharey(ax['A'])\n    >>> librosa.display.specshow(acts, x_axis='time', ax=ax['C'], cmap='gray_r')\n    >>> ax['C'].set(ylabel='Components', title='Activations')\n    >>> ax['C'].sharex(ax['A'])\n    >>> ax['C'].label_outer()\n    >>> S_approx = comps.dot(acts)\n    >>> img = librosa.display.specshow(librosa.amplitude_to_db(S_approx,\n    >>>                                                        ref=np.max),\n    >>>                                y_axis='log', x_axis='time', ax=ax['D'])\n    >>> ax['D'].set(title='Reconstructed spectrogram')\n    >>> ax['D'].sharex(ax['A'])\n    >>> ax['D'].sharey(ax['A'])\n    >>> ax['D'].label_outer()\n    >>> fig.colorbar(img, ax=list(ax.values()), format=\"%+2.f dB\")\n    \"\"\"\n    orig_shape = list(S.shape)\n    if S.ndim > 2 and sort:\n        raise ParameterError('Parameter sort=True is unsupported for input with more than two dimensions')\n    S = S.T.reshape((S.shape[-1], -1), order='F')\n    if n_components is None:\n        n_components = S.shape[-1]\n    if transformer is None:\n        if fit is False:\n            raise ParameterError('fit must be True if transformer is None')\n        transformer = sklearn.decomposition.NMF(n_components=n_components, **kwargs)\n    activations: np.ndarray\n    if fit:\n        activations = transformer.fit_transform(S).T\n    else:\n        activations = transformer.transform(S).T\n    components: np.ndarray = transformer.components_\n    component_shape = orig_shape[:-1] + [-1]\n    components = components.reshape(component_shape[::-1], order='F').T\n    if sort:\n        (components, idx) = util.axis_sort(components, index=True)\n        activations = activations[idx]\n    return (components, activations)",
        "mutated": [
            "def decompose(S: np.ndarray, *, n_components: Optional[int]=None, transformer: Optional[object]=None, sort: bool=False, fit: bool=True, **kwargs: Any) -> Tuple[np.ndarray, np.ndarray]:\n    if False:\n        i = 10\n    'Decompose a feature matrix.\\n\\n    Given a spectrogram ``S``, produce a decomposition into ``components``\\n    and ``activations`` such that ``S ~= components.dot(activations)``.\\n\\n    By default, this is done with with non-negative matrix factorization (NMF),\\n    but any `sklearn.decomposition`-type object will work.\\n\\n    Parameters\\n    ----------\\n    S : np.ndarray [shape=(..., n_features, n_samples), dtype=float]\\n        The input feature matrix (e.g., magnitude spectrogram)\\n\\n        If the input has multiple channels (leading dimensions), they will be automatically\\n        flattened prior to decomposition.\\n\\n        If the input is multi-channel, channels and features are automatically flattened into\\n        a single axis before the decomposition.\\n        For example, a stereo input `S` with shape `(2, n_features, n_samples)` is\\n        automatically reshaped to `(2 * n_features, n_samples)`.\\n\\n    n_components : int > 0 [scalar] or None\\n        number of desired components\\n\\n        if None, then ``n_features`` components are used\\n\\n    transformer : None or object\\n        If None, use `sklearn.decomposition.NMF`\\n\\n        Otherwise, any object with a similar interface to NMF should work.\\n        ``transformer`` must follow the scikit-learn convention, where\\n        input data is ``(n_samples, n_features)``.\\n\\n        `transformer.fit_transform()` will be run on ``S.T`` (not ``S``),\\n        the return value of which is stored (transposed) as ``activations``\\n\\n        The components will be retrieved as ``transformer.components_.T``::\\n\\n            S ~= np.dot(activations, transformer.components_).T\\n\\n        or equivalently::\\n\\n            S ~= np.dot(transformer.components_.T, activations.T)\\n\\n    sort : bool\\n        If ``True``, components are sorted by ascending peak frequency.\\n\\n        .. note:: If used with ``transformer``, sorting is applied to copies\\n            of the decomposition parameters, and not to ``transformer``\\n            internal parameters.\\n\\n        .. warning:: If the input array has more than two dimensions\\n            (e.g., if it\\'s a multi-channel spectrogram), then axis sorting\\n            is not supported and a `ParameterError` exception is raised.\\n\\n    fit : bool\\n        If `True`, components are estimated from the input ``S``.\\n\\n        If `False`, components are assumed to be pre-computed and stored\\n        in ``transformer``, and are not changed.\\n\\n    **kwargs : Additional keyword arguments to the default transformer\\n        `sklearn.decomposition.NMF`\\n\\n    Returns\\n    -------\\n    components: np.ndarray [shape=(..., n_features, n_components)]\\n        matrix of components (basis elements).\\n    activations: np.ndarray [shape=(n_components, n_samples)]\\n        transformed matrix/activation matrix\\n\\n    Raises\\n    ------\\n    ParameterError\\n        if ``fit`` is False and no ``transformer`` object is provided.\\n\\n        if the input array is multi-channel and ``sort=True`` is specified.\\n\\n    See Also\\n    --------\\n    sklearn.decomposition : SciKit-Learn matrix decomposition modules\\n\\n    Examples\\n    --------\\n    Decompose a magnitude spectrogram into 16 components with NMF\\n\\n    >>> y, sr = librosa.load(librosa.ex(\\'pistachio\\'), duration=5)\\n    >>> S = np.abs(librosa.stft(y))\\n    >>> comps, acts = librosa.decompose.decompose(S, n_components=16)\\n\\n    Sort components by ascending peak frequency\\n\\n    >>> comps, acts = librosa.decompose.decompose(S, n_components=16,\\n    ...                                           sort=True)\\n\\n    Or with sparse dictionary learning\\n\\n    >>> import sklearn.decomposition\\n    >>> T = sklearn.decomposition.MiniBatchDictionaryLearning(n_components=16)\\n    >>> scomps, sacts = librosa.decompose.decompose(S, transformer=T, sort=True)\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> layout = [list(\".AAAA\"), list(\"BCCCC\"), list(\".DDDD\")]\\n    >>> fig, ax = plt.subplot_mosaic(layout, constrained_layout=True)\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[\\'A\\'])\\n    >>> ax[\\'A\\'].set(title=\\'Input spectrogram\\')\\n    >>> ax[\\'A\\'].label_outer()\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(comps,\\n    >>>                                                  ref=np.max),\\n    >>>                          y_axis=\\'log\\', ax=ax[\\'B\\'])\\n    >>> ax[\\'B\\'].set(title=\\'Components\\')\\n    >>> ax[\\'B\\'].label_outer()\\n    >>> ax[\\'B\\'].sharey(ax[\\'A\\'])\\n    >>> librosa.display.specshow(acts, x_axis=\\'time\\', ax=ax[\\'C\\'], cmap=\\'gray_r\\')\\n    >>> ax[\\'C\\'].set(ylabel=\\'Components\\', title=\\'Activations\\')\\n    >>> ax[\\'C\\'].sharex(ax[\\'A\\'])\\n    >>> ax[\\'C\\'].label_outer()\\n    >>> S_approx = comps.dot(acts)\\n    >>> img = librosa.display.specshow(librosa.amplitude_to_db(S_approx,\\n    >>>                                                        ref=np.max),\\n    >>>                                y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[\\'D\\'])\\n    >>> ax[\\'D\\'].set(title=\\'Reconstructed spectrogram\\')\\n    >>> ax[\\'D\\'].sharex(ax[\\'A\\'])\\n    >>> ax[\\'D\\'].sharey(ax[\\'A\\'])\\n    >>> ax[\\'D\\'].label_outer()\\n    >>> fig.colorbar(img, ax=list(ax.values()), format=\"%+2.f dB\")\\n    '\n    orig_shape = list(S.shape)\n    if S.ndim > 2 and sort:\n        raise ParameterError('Parameter sort=True is unsupported for input with more than two dimensions')\n    S = S.T.reshape((S.shape[-1], -1), order='F')\n    if n_components is None:\n        n_components = S.shape[-1]\n    if transformer is None:\n        if fit is False:\n            raise ParameterError('fit must be True if transformer is None')\n        transformer = sklearn.decomposition.NMF(n_components=n_components, **kwargs)\n    activations: np.ndarray\n    if fit:\n        activations = transformer.fit_transform(S).T\n    else:\n        activations = transformer.transform(S).T\n    components: np.ndarray = transformer.components_\n    component_shape = orig_shape[:-1] + [-1]\n    components = components.reshape(component_shape[::-1], order='F').T\n    if sort:\n        (components, idx) = util.axis_sort(components, index=True)\n        activations = activations[idx]\n    return (components, activations)",
            "def decompose(S: np.ndarray, *, n_components: Optional[int]=None, transformer: Optional[object]=None, sort: bool=False, fit: bool=True, **kwargs: Any) -> Tuple[np.ndarray, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Decompose a feature matrix.\\n\\n    Given a spectrogram ``S``, produce a decomposition into ``components``\\n    and ``activations`` such that ``S ~= components.dot(activations)``.\\n\\n    By default, this is done with with non-negative matrix factorization (NMF),\\n    but any `sklearn.decomposition`-type object will work.\\n\\n    Parameters\\n    ----------\\n    S : np.ndarray [shape=(..., n_features, n_samples), dtype=float]\\n        The input feature matrix (e.g., magnitude spectrogram)\\n\\n        If the input has multiple channels (leading dimensions), they will be automatically\\n        flattened prior to decomposition.\\n\\n        If the input is multi-channel, channels and features are automatically flattened into\\n        a single axis before the decomposition.\\n        For example, a stereo input `S` with shape `(2, n_features, n_samples)` is\\n        automatically reshaped to `(2 * n_features, n_samples)`.\\n\\n    n_components : int > 0 [scalar] or None\\n        number of desired components\\n\\n        if None, then ``n_features`` components are used\\n\\n    transformer : None or object\\n        If None, use `sklearn.decomposition.NMF`\\n\\n        Otherwise, any object with a similar interface to NMF should work.\\n        ``transformer`` must follow the scikit-learn convention, where\\n        input data is ``(n_samples, n_features)``.\\n\\n        `transformer.fit_transform()` will be run on ``S.T`` (not ``S``),\\n        the return value of which is stored (transposed) as ``activations``\\n\\n        The components will be retrieved as ``transformer.components_.T``::\\n\\n            S ~= np.dot(activations, transformer.components_).T\\n\\n        or equivalently::\\n\\n            S ~= np.dot(transformer.components_.T, activations.T)\\n\\n    sort : bool\\n        If ``True``, components are sorted by ascending peak frequency.\\n\\n        .. note:: If used with ``transformer``, sorting is applied to copies\\n            of the decomposition parameters, and not to ``transformer``\\n            internal parameters.\\n\\n        .. warning:: If the input array has more than two dimensions\\n            (e.g., if it\\'s a multi-channel spectrogram), then axis sorting\\n            is not supported and a `ParameterError` exception is raised.\\n\\n    fit : bool\\n        If `True`, components are estimated from the input ``S``.\\n\\n        If `False`, components are assumed to be pre-computed and stored\\n        in ``transformer``, and are not changed.\\n\\n    **kwargs : Additional keyword arguments to the default transformer\\n        `sklearn.decomposition.NMF`\\n\\n    Returns\\n    -------\\n    components: np.ndarray [shape=(..., n_features, n_components)]\\n        matrix of components (basis elements).\\n    activations: np.ndarray [shape=(n_components, n_samples)]\\n        transformed matrix/activation matrix\\n\\n    Raises\\n    ------\\n    ParameterError\\n        if ``fit`` is False and no ``transformer`` object is provided.\\n\\n        if the input array is multi-channel and ``sort=True`` is specified.\\n\\n    See Also\\n    --------\\n    sklearn.decomposition : SciKit-Learn matrix decomposition modules\\n\\n    Examples\\n    --------\\n    Decompose a magnitude spectrogram into 16 components with NMF\\n\\n    >>> y, sr = librosa.load(librosa.ex(\\'pistachio\\'), duration=5)\\n    >>> S = np.abs(librosa.stft(y))\\n    >>> comps, acts = librosa.decompose.decompose(S, n_components=16)\\n\\n    Sort components by ascending peak frequency\\n\\n    >>> comps, acts = librosa.decompose.decompose(S, n_components=16,\\n    ...                                           sort=True)\\n\\n    Or with sparse dictionary learning\\n\\n    >>> import sklearn.decomposition\\n    >>> T = sklearn.decomposition.MiniBatchDictionaryLearning(n_components=16)\\n    >>> scomps, sacts = librosa.decompose.decompose(S, transformer=T, sort=True)\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> layout = [list(\".AAAA\"), list(\"BCCCC\"), list(\".DDDD\")]\\n    >>> fig, ax = plt.subplot_mosaic(layout, constrained_layout=True)\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[\\'A\\'])\\n    >>> ax[\\'A\\'].set(title=\\'Input spectrogram\\')\\n    >>> ax[\\'A\\'].label_outer()\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(comps,\\n    >>>                                                  ref=np.max),\\n    >>>                          y_axis=\\'log\\', ax=ax[\\'B\\'])\\n    >>> ax[\\'B\\'].set(title=\\'Components\\')\\n    >>> ax[\\'B\\'].label_outer()\\n    >>> ax[\\'B\\'].sharey(ax[\\'A\\'])\\n    >>> librosa.display.specshow(acts, x_axis=\\'time\\', ax=ax[\\'C\\'], cmap=\\'gray_r\\')\\n    >>> ax[\\'C\\'].set(ylabel=\\'Components\\', title=\\'Activations\\')\\n    >>> ax[\\'C\\'].sharex(ax[\\'A\\'])\\n    >>> ax[\\'C\\'].label_outer()\\n    >>> S_approx = comps.dot(acts)\\n    >>> img = librosa.display.specshow(librosa.amplitude_to_db(S_approx,\\n    >>>                                                        ref=np.max),\\n    >>>                                y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[\\'D\\'])\\n    >>> ax[\\'D\\'].set(title=\\'Reconstructed spectrogram\\')\\n    >>> ax[\\'D\\'].sharex(ax[\\'A\\'])\\n    >>> ax[\\'D\\'].sharey(ax[\\'A\\'])\\n    >>> ax[\\'D\\'].label_outer()\\n    >>> fig.colorbar(img, ax=list(ax.values()), format=\"%+2.f dB\")\\n    '\n    orig_shape = list(S.shape)\n    if S.ndim > 2 and sort:\n        raise ParameterError('Parameter sort=True is unsupported for input with more than two dimensions')\n    S = S.T.reshape((S.shape[-1], -1), order='F')\n    if n_components is None:\n        n_components = S.shape[-1]\n    if transformer is None:\n        if fit is False:\n            raise ParameterError('fit must be True if transformer is None')\n        transformer = sklearn.decomposition.NMF(n_components=n_components, **kwargs)\n    activations: np.ndarray\n    if fit:\n        activations = transformer.fit_transform(S).T\n    else:\n        activations = transformer.transform(S).T\n    components: np.ndarray = transformer.components_\n    component_shape = orig_shape[:-1] + [-1]\n    components = components.reshape(component_shape[::-1], order='F').T\n    if sort:\n        (components, idx) = util.axis_sort(components, index=True)\n        activations = activations[idx]\n    return (components, activations)",
            "def decompose(S: np.ndarray, *, n_components: Optional[int]=None, transformer: Optional[object]=None, sort: bool=False, fit: bool=True, **kwargs: Any) -> Tuple[np.ndarray, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Decompose a feature matrix.\\n\\n    Given a spectrogram ``S``, produce a decomposition into ``components``\\n    and ``activations`` such that ``S ~= components.dot(activations)``.\\n\\n    By default, this is done with with non-negative matrix factorization (NMF),\\n    but any `sklearn.decomposition`-type object will work.\\n\\n    Parameters\\n    ----------\\n    S : np.ndarray [shape=(..., n_features, n_samples), dtype=float]\\n        The input feature matrix (e.g., magnitude spectrogram)\\n\\n        If the input has multiple channels (leading dimensions), they will be automatically\\n        flattened prior to decomposition.\\n\\n        If the input is multi-channel, channels and features are automatically flattened into\\n        a single axis before the decomposition.\\n        For example, a stereo input `S` with shape `(2, n_features, n_samples)` is\\n        automatically reshaped to `(2 * n_features, n_samples)`.\\n\\n    n_components : int > 0 [scalar] or None\\n        number of desired components\\n\\n        if None, then ``n_features`` components are used\\n\\n    transformer : None or object\\n        If None, use `sklearn.decomposition.NMF`\\n\\n        Otherwise, any object with a similar interface to NMF should work.\\n        ``transformer`` must follow the scikit-learn convention, where\\n        input data is ``(n_samples, n_features)``.\\n\\n        `transformer.fit_transform()` will be run on ``S.T`` (not ``S``),\\n        the return value of which is stored (transposed) as ``activations``\\n\\n        The components will be retrieved as ``transformer.components_.T``::\\n\\n            S ~= np.dot(activations, transformer.components_).T\\n\\n        or equivalently::\\n\\n            S ~= np.dot(transformer.components_.T, activations.T)\\n\\n    sort : bool\\n        If ``True``, components are sorted by ascending peak frequency.\\n\\n        .. note:: If used with ``transformer``, sorting is applied to copies\\n            of the decomposition parameters, and not to ``transformer``\\n            internal parameters.\\n\\n        .. warning:: If the input array has more than two dimensions\\n            (e.g., if it\\'s a multi-channel spectrogram), then axis sorting\\n            is not supported and a `ParameterError` exception is raised.\\n\\n    fit : bool\\n        If `True`, components are estimated from the input ``S``.\\n\\n        If `False`, components are assumed to be pre-computed and stored\\n        in ``transformer``, and are not changed.\\n\\n    **kwargs : Additional keyword arguments to the default transformer\\n        `sklearn.decomposition.NMF`\\n\\n    Returns\\n    -------\\n    components: np.ndarray [shape=(..., n_features, n_components)]\\n        matrix of components (basis elements).\\n    activations: np.ndarray [shape=(n_components, n_samples)]\\n        transformed matrix/activation matrix\\n\\n    Raises\\n    ------\\n    ParameterError\\n        if ``fit`` is False and no ``transformer`` object is provided.\\n\\n        if the input array is multi-channel and ``sort=True`` is specified.\\n\\n    See Also\\n    --------\\n    sklearn.decomposition : SciKit-Learn matrix decomposition modules\\n\\n    Examples\\n    --------\\n    Decompose a magnitude spectrogram into 16 components with NMF\\n\\n    >>> y, sr = librosa.load(librosa.ex(\\'pistachio\\'), duration=5)\\n    >>> S = np.abs(librosa.stft(y))\\n    >>> comps, acts = librosa.decompose.decompose(S, n_components=16)\\n\\n    Sort components by ascending peak frequency\\n\\n    >>> comps, acts = librosa.decompose.decompose(S, n_components=16,\\n    ...                                           sort=True)\\n\\n    Or with sparse dictionary learning\\n\\n    >>> import sklearn.decomposition\\n    >>> T = sklearn.decomposition.MiniBatchDictionaryLearning(n_components=16)\\n    >>> scomps, sacts = librosa.decompose.decompose(S, transformer=T, sort=True)\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> layout = [list(\".AAAA\"), list(\"BCCCC\"), list(\".DDDD\")]\\n    >>> fig, ax = plt.subplot_mosaic(layout, constrained_layout=True)\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[\\'A\\'])\\n    >>> ax[\\'A\\'].set(title=\\'Input spectrogram\\')\\n    >>> ax[\\'A\\'].label_outer()\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(comps,\\n    >>>                                                  ref=np.max),\\n    >>>                          y_axis=\\'log\\', ax=ax[\\'B\\'])\\n    >>> ax[\\'B\\'].set(title=\\'Components\\')\\n    >>> ax[\\'B\\'].label_outer()\\n    >>> ax[\\'B\\'].sharey(ax[\\'A\\'])\\n    >>> librosa.display.specshow(acts, x_axis=\\'time\\', ax=ax[\\'C\\'], cmap=\\'gray_r\\')\\n    >>> ax[\\'C\\'].set(ylabel=\\'Components\\', title=\\'Activations\\')\\n    >>> ax[\\'C\\'].sharex(ax[\\'A\\'])\\n    >>> ax[\\'C\\'].label_outer()\\n    >>> S_approx = comps.dot(acts)\\n    >>> img = librosa.display.specshow(librosa.amplitude_to_db(S_approx,\\n    >>>                                                        ref=np.max),\\n    >>>                                y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[\\'D\\'])\\n    >>> ax[\\'D\\'].set(title=\\'Reconstructed spectrogram\\')\\n    >>> ax[\\'D\\'].sharex(ax[\\'A\\'])\\n    >>> ax[\\'D\\'].sharey(ax[\\'A\\'])\\n    >>> ax[\\'D\\'].label_outer()\\n    >>> fig.colorbar(img, ax=list(ax.values()), format=\"%+2.f dB\")\\n    '\n    orig_shape = list(S.shape)\n    if S.ndim > 2 and sort:\n        raise ParameterError('Parameter sort=True is unsupported for input with more than two dimensions')\n    S = S.T.reshape((S.shape[-1], -1), order='F')\n    if n_components is None:\n        n_components = S.shape[-1]\n    if transformer is None:\n        if fit is False:\n            raise ParameterError('fit must be True if transformer is None')\n        transformer = sklearn.decomposition.NMF(n_components=n_components, **kwargs)\n    activations: np.ndarray\n    if fit:\n        activations = transformer.fit_transform(S).T\n    else:\n        activations = transformer.transform(S).T\n    components: np.ndarray = transformer.components_\n    component_shape = orig_shape[:-1] + [-1]\n    components = components.reshape(component_shape[::-1], order='F').T\n    if sort:\n        (components, idx) = util.axis_sort(components, index=True)\n        activations = activations[idx]\n    return (components, activations)",
            "def decompose(S: np.ndarray, *, n_components: Optional[int]=None, transformer: Optional[object]=None, sort: bool=False, fit: bool=True, **kwargs: Any) -> Tuple[np.ndarray, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Decompose a feature matrix.\\n\\n    Given a spectrogram ``S``, produce a decomposition into ``components``\\n    and ``activations`` such that ``S ~= components.dot(activations)``.\\n\\n    By default, this is done with with non-negative matrix factorization (NMF),\\n    but any `sklearn.decomposition`-type object will work.\\n\\n    Parameters\\n    ----------\\n    S : np.ndarray [shape=(..., n_features, n_samples), dtype=float]\\n        The input feature matrix (e.g., magnitude spectrogram)\\n\\n        If the input has multiple channels (leading dimensions), they will be automatically\\n        flattened prior to decomposition.\\n\\n        If the input is multi-channel, channels and features are automatically flattened into\\n        a single axis before the decomposition.\\n        For example, a stereo input `S` with shape `(2, n_features, n_samples)` is\\n        automatically reshaped to `(2 * n_features, n_samples)`.\\n\\n    n_components : int > 0 [scalar] or None\\n        number of desired components\\n\\n        if None, then ``n_features`` components are used\\n\\n    transformer : None or object\\n        If None, use `sklearn.decomposition.NMF`\\n\\n        Otherwise, any object with a similar interface to NMF should work.\\n        ``transformer`` must follow the scikit-learn convention, where\\n        input data is ``(n_samples, n_features)``.\\n\\n        `transformer.fit_transform()` will be run on ``S.T`` (not ``S``),\\n        the return value of which is stored (transposed) as ``activations``\\n\\n        The components will be retrieved as ``transformer.components_.T``::\\n\\n            S ~= np.dot(activations, transformer.components_).T\\n\\n        or equivalently::\\n\\n            S ~= np.dot(transformer.components_.T, activations.T)\\n\\n    sort : bool\\n        If ``True``, components are sorted by ascending peak frequency.\\n\\n        .. note:: If used with ``transformer``, sorting is applied to copies\\n            of the decomposition parameters, and not to ``transformer``\\n            internal parameters.\\n\\n        .. warning:: If the input array has more than two dimensions\\n            (e.g., if it\\'s a multi-channel spectrogram), then axis sorting\\n            is not supported and a `ParameterError` exception is raised.\\n\\n    fit : bool\\n        If `True`, components are estimated from the input ``S``.\\n\\n        If `False`, components are assumed to be pre-computed and stored\\n        in ``transformer``, and are not changed.\\n\\n    **kwargs : Additional keyword arguments to the default transformer\\n        `sklearn.decomposition.NMF`\\n\\n    Returns\\n    -------\\n    components: np.ndarray [shape=(..., n_features, n_components)]\\n        matrix of components (basis elements).\\n    activations: np.ndarray [shape=(n_components, n_samples)]\\n        transformed matrix/activation matrix\\n\\n    Raises\\n    ------\\n    ParameterError\\n        if ``fit`` is False and no ``transformer`` object is provided.\\n\\n        if the input array is multi-channel and ``sort=True`` is specified.\\n\\n    See Also\\n    --------\\n    sklearn.decomposition : SciKit-Learn matrix decomposition modules\\n\\n    Examples\\n    --------\\n    Decompose a magnitude spectrogram into 16 components with NMF\\n\\n    >>> y, sr = librosa.load(librosa.ex(\\'pistachio\\'), duration=5)\\n    >>> S = np.abs(librosa.stft(y))\\n    >>> comps, acts = librosa.decompose.decompose(S, n_components=16)\\n\\n    Sort components by ascending peak frequency\\n\\n    >>> comps, acts = librosa.decompose.decompose(S, n_components=16,\\n    ...                                           sort=True)\\n\\n    Or with sparse dictionary learning\\n\\n    >>> import sklearn.decomposition\\n    >>> T = sklearn.decomposition.MiniBatchDictionaryLearning(n_components=16)\\n    >>> scomps, sacts = librosa.decompose.decompose(S, transformer=T, sort=True)\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> layout = [list(\".AAAA\"), list(\"BCCCC\"), list(\".DDDD\")]\\n    >>> fig, ax = plt.subplot_mosaic(layout, constrained_layout=True)\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[\\'A\\'])\\n    >>> ax[\\'A\\'].set(title=\\'Input spectrogram\\')\\n    >>> ax[\\'A\\'].label_outer()\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(comps,\\n    >>>                                                  ref=np.max),\\n    >>>                          y_axis=\\'log\\', ax=ax[\\'B\\'])\\n    >>> ax[\\'B\\'].set(title=\\'Components\\')\\n    >>> ax[\\'B\\'].label_outer()\\n    >>> ax[\\'B\\'].sharey(ax[\\'A\\'])\\n    >>> librosa.display.specshow(acts, x_axis=\\'time\\', ax=ax[\\'C\\'], cmap=\\'gray_r\\')\\n    >>> ax[\\'C\\'].set(ylabel=\\'Components\\', title=\\'Activations\\')\\n    >>> ax[\\'C\\'].sharex(ax[\\'A\\'])\\n    >>> ax[\\'C\\'].label_outer()\\n    >>> S_approx = comps.dot(acts)\\n    >>> img = librosa.display.specshow(librosa.amplitude_to_db(S_approx,\\n    >>>                                                        ref=np.max),\\n    >>>                                y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[\\'D\\'])\\n    >>> ax[\\'D\\'].set(title=\\'Reconstructed spectrogram\\')\\n    >>> ax[\\'D\\'].sharex(ax[\\'A\\'])\\n    >>> ax[\\'D\\'].sharey(ax[\\'A\\'])\\n    >>> ax[\\'D\\'].label_outer()\\n    >>> fig.colorbar(img, ax=list(ax.values()), format=\"%+2.f dB\")\\n    '\n    orig_shape = list(S.shape)\n    if S.ndim > 2 and sort:\n        raise ParameterError('Parameter sort=True is unsupported for input with more than two dimensions')\n    S = S.T.reshape((S.shape[-1], -1), order='F')\n    if n_components is None:\n        n_components = S.shape[-1]\n    if transformer is None:\n        if fit is False:\n            raise ParameterError('fit must be True if transformer is None')\n        transformer = sklearn.decomposition.NMF(n_components=n_components, **kwargs)\n    activations: np.ndarray\n    if fit:\n        activations = transformer.fit_transform(S).T\n    else:\n        activations = transformer.transform(S).T\n    components: np.ndarray = transformer.components_\n    component_shape = orig_shape[:-1] + [-1]\n    components = components.reshape(component_shape[::-1], order='F').T\n    if sort:\n        (components, idx) = util.axis_sort(components, index=True)\n        activations = activations[idx]\n    return (components, activations)",
            "def decompose(S: np.ndarray, *, n_components: Optional[int]=None, transformer: Optional[object]=None, sort: bool=False, fit: bool=True, **kwargs: Any) -> Tuple[np.ndarray, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Decompose a feature matrix.\\n\\n    Given a spectrogram ``S``, produce a decomposition into ``components``\\n    and ``activations`` such that ``S ~= components.dot(activations)``.\\n\\n    By default, this is done with with non-negative matrix factorization (NMF),\\n    but any `sklearn.decomposition`-type object will work.\\n\\n    Parameters\\n    ----------\\n    S : np.ndarray [shape=(..., n_features, n_samples), dtype=float]\\n        The input feature matrix (e.g., magnitude spectrogram)\\n\\n        If the input has multiple channels (leading dimensions), they will be automatically\\n        flattened prior to decomposition.\\n\\n        If the input is multi-channel, channels and features are automatically flattened into\\n        a single axis before the decomposition.\\n        For example, a stereo input `S` with shape `(2, n_features, n_samples)` is\\n        automatically reshaped to `(2 * n_features, n_samples)`.\\n\\n    n_components : int > 0 [scalar] or None\\n        number of desired components\\n\\n        if None, then ``n_features`` components are used\\n\\n    transformer : None or object\\n        If None, use `sklearn.decomposition.NMF`\\n\\n        Otherwise, any object with a similar interface to NMF should work.\\n        ``transformer`` must follow the scikit-learn convention, where\\n        input data is ``(n_samples, n_features)``.\\n\\n        `transformer.fit_transform()` will be run on ``S.T`` (not ``S``),\\n        the return value of which is stored (transposed) as ``activations``\\n\\n        The components will be retrieved as ``transformer.components_.T``::\\n\\n            S ~= np.dot(activations, transformer.components_).T\\n\\n        or equivalently::\\n\\n            S ~= np.dot(transformer.components_.T, activations.T)\\n\\n    sort : bool\\n        If ``True``, components are sorted by ascending peak frequency.\\n\\n        .. note:: If used with ``transformer``, sorting is applied to copies\\n            of the decomposition parameters, and not to ``transformer``\\n            internal parameters.\\n\\n        .. warning:: If the input array has more than two dimensions\\n            (e.g., if it\\'s a multi-channel spectrogram), then axis sorting\\n            is not supported and a `ParameterError` exception is raised.\\n\\n    fit : bool\\n        If `True`, components are estimated from the input ``S``.\\n\\n        If `False`, components are assumed to be pre-computed and stored\\n        in ``transformer``, and are not changed.\\n\\n    **kwargs : Additional keyword arguments to the default transformer\\n        `sklearn.decomposition.NMF`\\n\\n    Returns\\n    -------\\n    components: np.ndarray [shape=(..., n_features, n_components)]\\n        matrix of components (basis elements).\\n    activations: np.ndarray [shape=(n_components, n_samples)]\\n        transformed matrix/activation matrix\\n\\n    Raises\\n    ------\\n    ParameterError\\n        if ``fit`` is False and no ``transformer`` object is provided.\\n\\n        if the input array is multi-channel and ``sort=True`` is specified.\\n\\n    See Also\\n    --------\\n    sklearn.decomposition : SciKit-Learn matrix decomposition modules\\n\\n    Examples\\n    --------\\n    Decompose a magnitude spectrogram into 16 components with NMF\\n\\n    >>> y, sr = librosa.load(librosa.ex(\\'pistachio\\'), duration=5)\\n    >>> S = np.abs(librosa.stft(y))\\n    >>> comps, acts = librosa.decompose.decompose(S, n_components=16)\\n\\n    Sort components by ascending peak frequency\\n\\n    >>> comps, acts = librosa.decompose.decompose(S, n_components=16,\\n    ...                                           sort=True)\\n\\n    Or with sparse dictionary learning\\n\\n    >>> import sklearn.decomposition\\n    >>> T = sklearn.decomposition.MiniBatchDictionaryLearning(n_components=16)\\n    >>> scomps, sacts = librosa.decompose.decompose(S, transformer=T, sort=True)\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> layout = [list(\".AAAA\"), list(\"BCCCC\"), list(\".DDDD\")]\\n    >>> fig, ax = plt.subplot_mosaic(layout, constrained_layout=True)\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[\\'A\\'])\\n    >>> ax[\\'A\\'].set(title=\\'Input spectrogram\\')\\n    >>> ax[\\'A\\'].label_outer()\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(comps,\\n    >>>                                                  ref=np.max),\\n    >>>                          y_axis=\\'log\\', ax=ax[\\'B\\'])\\n    >>> ax[\\'B\\'].set(title=\\'Components\\')\\n    >>> ax[\\'B\\'].label_outer()\\n    >>> ax[\\'B\\'].sharey(ax[\\'A\\'])\\n    >>> librosa.display.specshow(acts, x_axis=\\'time\\', ax=ax[\\'C\\'], cmap=\\'gray_r\\')\\n    >>> ax[\\'C\\'].set(ylabel=\\'Components\\', title=\\'Activations\\')\\n    >>> ax[\\'C\\'].sharex(ax[\\'A\\'])\\n    >>> ax[\\'C\\'].label_outer()\\n    >>> S_approx = comps.dot(acts)\\n    >>> img = librosa.display.specshow(librosa.amplitude_to_db(S_approx,\\n    >>>                                                        ref=np.max),\\n    >>>                                y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[\\'D\\'])\\n    >>> ax[\\'D\\'].set(title=\\'Reconstructed spectrogram\\')\\n    >>> ax[\\'D\\'].sharex(ax[\\'A\\'])\\n    >>> ax[\\'D\\'].sharey(ax[\\'A\\'])\\n    >>> ax[\\'D\\'].label_outer()\\n    >>> fig.colorbar(img, ax=list(ax.values()), format=\"%+2.f dB\")\\n    '\n    orig_shape = list(S.shape)\n    if S.ndim > 2 and sort:\n        raise ParameterError('Parameter sort=True is unsupported for input with more than two dimensions')\n    S = S.T.reshape((S.shape[-1], -1), order='F')\n    if n_components is None:\n        n_components = S.shape[-1]\n    if transformer is None:\n        if fit is False:\n            raise ParameterError('fit must be True if transformer is None')\n        transformer = sklearn.decomposition.NMF(n_components=n_components, **kwargs)\n    activations: np.ndarray\n    if fit:\n        activations = transformer.fit_transform(S).T\n    else:\n        activations = transformer.transform(S).T\n    components: np.ndarray = transformer.components_\n    component_shape = orig_shape[:-1] + [-1]\n    components = components.reshape(component_shape[::-1], order='F').T\n    if sort:\n        (components, idx) = util.axis_sort(components, index=True)\n        activations = activations[idx]\n    return (components, activations)"
        ]
    },
    {
        "func_name": "hpss",
        "original": "@cache(level=30)\ndef hpss(S: np.ndarray, *, kernel_size: Union[_IntLike_co, Tuple[_IntLike_co, _IntLike_co], List[_IntLike_co]]=31, power: float=2.0, mask: bool=False, margin: Union[_FloatLike_co, Tuple[_FloatLike_co, _FloatLike_co], List[_FloatLike_co]]=1.0) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Median-filtering harmonic percussive source separation (HPSS).\n\n    If ``margin = 1.0``, decomposes an input spectrogram ``S = H + P``\n    where ``H`` contains the harmonic components,\n    and ``P`` contains the percussive components.\n\n    If ``margin > 1.0``, decomposes an input spectrogram ``S = H + P + R``\n    where ``R`` contains residual components not included in ``H`` or ``P``.\n\n    This implementation is based upon the algorithm described by [#]_ and [#]_.\n\n    .. [#] Fitzgerald, Derry.\n        \"Harmonic/percussive separation using median filtering.\"\n        13th International Conference on Digital Audio Effects (DAFX10),\n        Graz, Austria, 2010.\n\n    .. [#] Driedger, M\u00fcller, Disch.\n        \"Extending harmonic-percussive separation of audio.\"\n        15th International Society for Music Information Retrieval Conference (ISMIR 2014),\n        Taipei, Taiwan, 2014.\n\n    Parameters\n    ----------\n    S : np.ndarray [shape=(..., d, n)]\n        input spectrogram. May be real (magnitude) or complex.\n        Multi-channel is supported.\n\n    kernel_size : int or tuple (kernel_harmonic, kernel_percussive)\n        kernel size(s) for the median filters.\n\n        - If scalar, the same size is used for both harmonic and percussive.\n        - If tuple, the first value specifies the width of the\n          harmonic filter, and the second value specifies the width\n          of the percussive filter.\n\n    power : float > 0 [scalar]\n        Exponent for the Wiener filter when constructing soft mask matrices.\n\n    mask : bool\n        Return the masking matrices instead of components.\n\n        Masking matrices contain non-negative real values that\n        can be used to measure the assignment of energy from ``S``\n        into harmonic or percussive components.\n\n        Components can be recovered by multiplying ``S * mask_H``\n        or ``S * mask_P``.\n\n    margin : float or tuple (margin_harmonic, margin_percussive)\n        margin size(s) for the masks (as described in [2]_)\n\n        - If scalar, the same size is used for both harmonic and percussive.\n        - If tuple, the first value specifies the margin of the\n          harmonic mask, and the second value specifies the margin\n          of the percussive mask.\n\n    Returns\n    -------\n    harmonic : np.ndarray [shape=(..., d, n)]\n        harmonic component (or mask)\n    percussive : np.ndarray [shape=(..., d, n)]\n        percussive component (or mask)\n\n    See Also\n    --------\n    librosa.util.softmask\n\n    Notes\n    -----\n    This function caches at level 30.\n\n    Examples\n    --------\n    Separate into harmonic and percussive\n\n    >>> y, sr = librosa.load(librosa.ex('choice'), duration=5)\n    >>> D = librosa.stft(y)\n    >>> H, P = librosa.decompose.hpss(D)\n\n    >>> import matplotlib.pyplot as plt\n    >>> fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\n    >>> img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D),\n    ...                                                        ref=np.max),\n    ...                          y_axis='log', x_axis='time', ax=ax[0])\n    >>> ax[0].set(title='Full power spectrogram')\n    >>> ax[0].label_outer()\n    >>> librosa.display.specshow(librosa.amplitude_to_db(np.abs(H),\n    ...                                                  ref=np.max(np.abs(D))),\n    ...                          y_axis='log', x_axis='time', ax=ax[1])\n    >>> ax[1].set(title='Harmonic power spectrogram')\n    >>> ax[1].label_outer()\n    >>> librosa.display.specshow(librosa.amplitude_to_db(np.abs(P),\n    ...                                                  ref=np.max(np.abs(D))),\n    ...                          y_axis='log', x_axis='time', ax=ax[2])\n    >>> ax[2].set(title='Percussive power spectrogram')\n    >>> fig.colorbar(img, ax=ax, format='%+2.0f dB')\n\n    Or with a narrower horizontal filter\n\n    >>> H, P = librosa.decompose.hpss(D, kernel_size=(13, 31))\n\n    Just get harmonic/percussive masks, not the spectra\n\n    >>> mask_H, mask_P = librosa.decompose.hpss(D, mask=True)\n    >>> mask_H\n    array([[1.853e-03, 1.701e-04, ..., 9.922e-01, 1.000e+00],\n           [2.316e-03, 2.127e-04, ..., 9.989e-01, 1.000e+00],\n           ...,\n           [8.195e-05, 6.939e-05, ..., 3.105e-04, 4.231e-04],\n           [3.159e-05, 4.156e-05, ..., 6.216e-04, 6.188e-04]],\n          dtype=float32)\n    >>> mask_P\n    array([[9.981e-01, 9.998e-01, ..., 7.759e-03, 3.201e-05],\n           [9.977e-01, 9.998e-01, ..., 1.122e-03, 4.451e-06],\n           ...,\n           [9.999e-01, 9.999e-01, ..., 9.997e-01, 9.996e-01],\n           [1.000e+00, 1.000e+00, ..., 9.994e-01, 9.994e-01]],\n          dtype=float32)\n\n    Separate into harmonic/percussive/residual components by using a margin > 1.0\n\n    >>> H, P = librosa.decompose.hpss(D, margin=3.0)\n    >>> R = D - (H+P)\n    >>> y_harm = librosa.istft(H)\n    >>> y_perc = librosa.istft(P)\n    >>> y_resi = librosa.istft(R)\n\n    Get a more isolated percussive component by widening its margin\n\n    >>> H, P = librosa.decompose.hpss(D, margin=(1.0,5.0))\n    \"\"\"\n    phase: Union[float, np.ndarray]\n    if np.iscomplexobj(S):\n        (S, phase) = core.magphase(S)\n    else:\n        phase = 1\n    if isinstance(kernel_size, tuple) or isinstance(kernel_size, list):\n        win_harm = kernel_size[0]\n        win_perc = kernel_size[1]\n    else:\n        win_harm = kernel_size\n        win_perc = kernel_size\n    if isinstance(margin, tuple) or isinstance(margin, list):\n        margin_harm = margin[0]\n        margin_perc = margin[1]\n    else:\n        margin_harm = margin\n        margin_perc = margin\n    if margin_harm < 1 or margin_perc < 1:\n        raise ParameterError('Margins must be >= 1.0. A typical range is between 1 and 10.')\n    harm_shape: List[_IntLike_co] = [1] * S.ndim\n    harm_shape[-1] = win_harm\n    perc_shape: List[_IntLike_co] = [1] * S.ndim\n    perc_shape[-2] = win_perc\n    harm = np.empty_like(S)\n    harm[:] = median_filter(S, size=harm_shape, mode='reflect')\n    perc = np.empty_like(S)\n    perc[:] = median_filter(S, size=perc_shape, mode='reflect')\n    split_zeros = margin_harm == 1 and margin_perc == 1\n    mask_harm = util.softmask(harm, perc * margin_harm, power=power, split_zeros=split_zeros)\n    mask_perc = util.softmask(perc, harm * margin_perc, power=power, split_zeros=split_zeros)\n    if mask:\n        return (mask_harm, mask_perc)\n    return (S * mask_harm * phase, S * mask_perc * phase)",
        "mutated": [
            "@cache(level=30)\ndef hpss(S: np.ndarray, *, kernel_size: Union[_IntLike_co, Tuple[_IntLike_co, _IntLike_co], List[_IntLike_co]]=31, power: float=2.0, mask: bool=False, margin: Union[_FloatLike_co, Tuple[_FloatLike_co, _FloatLike_co], List[_FloatLike_co]]=1.0) -> Tuple[np.ndarray, np.ndarray]:\n    if False:\n        i = 10\n    'Median-filtering harmonic percussive source separation (HPSS).\\n\\n    If ``margin = 1.0``, decomposes an input spectrogram ``S = H + P``\\n    where ``H`` contains the harmonic components,\\n    and ``P`` contains the percussive components.\\n\\n    If ``margin > 1.0``, decomposes an input spectrogram ``S = H + P + R``\\n    where ``R`` contains residual components not included in ``H`` or ``P``.\\n\\n    This implementation is based upon the algorithm described by [#]_ and [#]_.\\n\\n    .. [#] Fitzgerald, Derry.\\n        \"Harmonic/percussive separation using median filtering.\"\\n        13th International Conference on Digital Audio Effects (DAFX10),\\n        Graz, Austria, 2010.\\n\\n    .. [#] Driedger, M\u00fcller, Disch.\\n        \"Extending harmonic-percussive separation of audio.\"\\n        15th International Society for Music Information Retrieval Conference (ISMIR 2014),\\n        Taipei, Taiwan, 2014.\\n\\n    Parameters\\n    ----------\\n    S : np.ndarray [shape=(..., d, n)]\\n        input spectrogram. May be real (magnitude) or complex.\\n        Multi-channel is supported.\\n\\n    kernel_size : int or tuple (kernel_harmonic, kernel_percussive)\\n        kernel size(s) for the median filters.\\n\\n        - If scalar, the same size is used for both harmonic and percussive.\\n        - If tuple, the first value specifies the width of the\\n          harmonic filter, and the second value specifies the width\\n          of the percussive filter.\\n\\n    power : float > 0 [scalar]\\n        Exponent for the Wiener filter when constructing soft mask matrices.\\n\\n    mask : bool\\n        Return the masking matrices instead of components.\\n\\n        Masking matrices contain non-negative real values that\\n        can be used to measure the assignment of energy from ``S``\\n        into harmonic or percussive components.\\n\\n        Components can be recovered by multiplying ``S * mask_H``\\n        or ``S * mask_P``.\\n\\n    margin : float or tuple (margin_harmonic, margin_percussive)\\n        margin size(s) for the masks (as described in [2]_)\\n\\n        - If scalar, the same size is used for both harmonic and percussive.\\n        - If tuple, the first value specifies the margin of the\\n          harmonic mask, and the second value specifies the margin\\n          of the percussive mask.\\n\\n    Returns\\n    -------\\n    harmonic : np.ndarray [shape=(..., d, n)]\\n        harmonic component (or mask)\\n    percussive : np.ndarray [shape=(..., d, n)]\\n        percussive component (or mask)\\n\\n    See Also\\n    --------\\n    librosa.util.softmask\\n\\n    Notes\\n    -----\\n    This function caches at level 30.\\n\\n    Examples\\n    --------\\n    Separate into harmonic and percussive\\n\\n    >>> y, sr = librosa.load(librosa.ex(\\'choice\\'), duration=5)\\n    >>> D = librosa.stft(y)\\n    >>> H, P = librosa.decompose.hpss(D)\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\\n    >>> img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D),\\n    ...                                                        ref=np.max),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[0])\\n    >>> ax[0].set(title=\\'Full power spectrogram\\')\\n    >>> ax[0].label_outer()\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(np.abs(H),\\n    ...                                                  ref=np.max(np.abs(D))),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[1])\\n    >>> ax[1].set(title=\\'Harmonic power spectrogram\\')\\n    >>> ax[1].label_outer()\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(np.abs(P),\\n    ...                                                  ref=np.max(np.abs(D))),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[2])\\n    >>> ax[2].set(title=\\'Percussive power spectrogram\\')\\n    >>> fig.colorbar(img, ax=ax, format=\\'%+2.0f dB\\')\\n\\n    Or with a narrower horizontal filter\\n\\n    >>> H, P = librosa.decompose.hpss(D, kernel_size=(13, 31))\\n\\n    Just get harmonic/percussive masks, not the spectra\\n\\n    >>> mask_H, mask_P = librosa.decompose.hpss(D, mask=True)\\n    >>> mask_H\\n    array([[1.853e-03, 1.701e-04, ..., 9.922e-01, 1.000e+00],\\n           [2.316e-03, 2.127e-04, ..., 9.989e-01, 1.000e+00],\\n           ...,\\n           [8.195e-05, 6.939e-05, ..., 3.105e-04, 4.231e-04],\\n           [3.159e-05, 4.156e-05, ..., 6.216e-04, 6.188e-04]],\\n          dtype=float32)\\n    >>> mask_P\\n    array([[9.981e-01, 9.998e-01, ..., 7.759e-03, 3.201e-05],\\n           [9.977e-01, 9.998e-01, ..., 1.122e-03, 4.451e-06],\\n           ...,\\n           [9.999e-01, 9.999e-01, ..., 9.997e-01, 9.996e-01],\\n           [1.000e+00, 1.000e+00, ..., 9.994e-01, 9.994e-01]],\\n          dtype=float32)\\n\\n    Separate into harmonic/percussive/residual components by using a margin > 1.0\\n\\n    >>> H, P = librosa.decompose.hpss(D, margin=3.0)\\n    >>> R = D - (H+P)\\n    >>> y_harm = librosa.istft(H)\\n    >>> y_perc = librosa.istft(P)\\n    >>> y_resi = librosa.istft(R)\\n\\n    Get a more isolated percussive component by widening its margin\\n\\n    >>> H, P = librosa.decompose.hpss(D, margin=(1.0,5.0))\\n    '\n    phase: Union[float, np.ndarray]\n    if np.iscomplexobj(S):\n        (S, phase) = core.magphase(S)\n    else:\n        phase = 1\n    if isinstance(kernel_size, tuple) or isinstance(kernel_size, list):\n        win_harm = kernel_size[0]\n        win_perc = kernel_size[1]\n    else:\n        win_harm = kernel_size\n        win_perc = kernel_size\n    if isinstance(margin, tuple) or isinstance(margin, list):\n        margin_harm = margin[0]\n        margin_perc = margin[1]\n    else:\n        margin_harm = margin\n        margin_perc = margin\n    if margin_harm < 1 or margin_perc < 1:\n        raise ParameterError('Margins must be >= 1.0. A typical range is between 1 and 10.')\n    harm_shape: List[_IntLike_co] = [1] * S.ndim\n    harm_shape[-1] = win_harm\n    perc_shape: List[_IntLike_co] = [1] * S.ndim\n    perc_shape[-2] = win_perc\n    harm = np.empty_like(S)\n    harm[:] = median_filter(S, size=harm_shape, mode='reflect')\n    perc = np.empty_like(S)\n    perc[:] = median_filter(S, size=perc_shape, mode='reflect')\n    split_zeros = margin_harm == 1 and margin_perc == 1\n    mask_harm = util.softmask(harm, perc * margin_harm, power=power, split_zeros=split_zeros)\n    mask_perc = util.softmask(perc, harm * margin_perc, power=power, split_zeros=split_zeros)\n    if mask:\n        return (mask_harm, mask_perc)\n    return (S * mask_harm * phase, S * mask_perc * phase)",
            "@cache(level=30)\ndef hpss(S: np.ndarray, *, kernel_size: Union[_IntLike_co, Tuple[_IntLike_co, _IntLike_co], List[_IntLike_co]]=31, power: float=2.0, mask: bool=False, margin: Union[_FloatLike_co, Tuple[_FloatLike_co, _FloatLike_co], List[_FloatLike_co]]=1.0) -> Tuple[np.ndarray, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Median-filtering harmonic percussive source separation (HPSS).\\n\\n    If ``margin = 1.0``, decomposes an input spectrogram ``S = H + P``\\n    where ``H`` contains the harmonic components,\\n    and ``P`` contains the percussive components.\\n\\n    If ``margin > 1.0``, decomposes an input spectrogram ``S = H + P + R``\\n    where ``R`` contains residual components not included in ``H`` or ``P``.\\n\\n    This implementation is based upon the algorithm described by [#]_ and [#]_.\\n\\n    .. [#] Fitzgerald, Derry.\\n        \"Harmonic/percussive separation using median filtering.\"\\n        13th International Conference on Digital Audio Effects (DAFX10),\\n        Graz, Austria, 2010.\\n\\n    .. [#] Driedger, M\u00fcller, Disch.\\n        \"Extending harmonic-percussive separation of audio.\"\\n        15th International Society for Music Information Retrieval Conference (ISMIR 2014),\\n        Taipei, Taiwan, 2014.\\n\\n    Parameters\\n    ----------\\n    S : np.ndarray [shape=(..., d, n)]\\n        input spectrogram. May be real (magnitude) or complex.\\n        Multi-channel is supported.\\n\\n    kernel_size : int or tuple (kernel_harmonic, kernel_percussive)\\n        kernel size(s) for the median filters.\\n\\n        - If scalar, the same size is used for both harmonic and percussive.\\n        - If tuple, the first value specifies the width of the\\n          harmonic filter, and the second value specifies the width\\n          of the percussive filter.\\n\\n    power : float > 0 [scalar]\\n        Exponent for the Wiener filter when constructing soft mask matrices.\\n\\n    mask : bool\\n        Return the masking matrices instead of components.\\n\\n        Masking matrices contain non-negative real values that\\n        can be used to measure the assignment of energy from ``S``\\n        into harmonic or percussive components.\\n\\n        Components can be recovered by multiplying ``S * mask_H``\\n        or ``S * mask_P``.\\n\\n    margin : float or tuple (margin_harmonic, margin_percussive)\\n        margin size(s) for the masks (as described in [2]_)\\n\\n        - If scalar, the same size is used for both harmonic and percussive.\\n        - If tuple, the first value specifies the margin of the\\n          harmonic mask, and the second value specifies the margin\\n          of the percussive mask.\\n\\n    Returns\\n    -------\\n    harmonic : np.ndarray [shape=(..., d, n)]\\n        harmonic component (or mask)\\n    percussive : np.ndarray [shape=(..., d, n)]\\n        percussive component (or mask)\\n\\n    See Also\\n    --------\\n    librosa.util.softmask\\n\\n    Notes\\n    -----\\n    This function caches at level 30.\\n\\n    Examples\\n    --------\\n    Separate into harmonic and percussive\\n\\n    >>> y, sr = librosa.load(librosa.ex(\\'choice\\'), duration=5)\\n    >>> D = librosa.stft(y)\\n    >>> H, P = librosa.decompose.hpss(D)\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\\n    >>> img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D),\\n    ...                                                        ref=np.max),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[0])\\n    >>> ax[0].set(title=\\'Full power spectrogram\\')\\n    >>> ax[0].label_outer()\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(np.abs(H),\\n    ...                                                  ref=np.max(np.abs(D))),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[1])\\n    >>> ax[1].set(title=\\'Harmonic power spectrogram\\')\\n    >>> ax[1].label_outer()\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(np.abs(P),\\n    ...                                                  ref=np.max(np.abs(D))),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[2])\\n    >>> ax[2].set(title=\\'Percussive power spectrogram\\')\\n    >>> fig.colorbar(img, ax=ax, format=\\'%+2.0f dB\\')\\n\\n    Or with a narrower horizontal filter\\n\\n    >>> H, P = librosa.decompose.hpss(D, kernel_size=(13, 31))\\n\\n    Just get harmonic/percussive masks, not the spectra\\n\\n    >>> mask_H, mask_P = librosa.decompose.hpss(D, mask=True)\\n    >>> mask_H\\n    array([[1.853e-03, 1.701e-04, ..., 9.922e-01, 1.000e+00],\\n           [2.316e-03, 2.127e-04, ..., 9.989e-01, 1.000e+00],\\n           ...,\\n           [8.195e-05, 6.939e-05, ..., 3.105e-04, 4.231e-04],\\n           [3.159e-05, 4.156e-05, ..., 6.216e-04, 6.188e-04]],\\n          dtype=float32)\\n    >>> mask_P\\n    array([[9.981e-01, 9.998e-01, ..., 7.759e-03, 3.201e-05],\\n           [9.977e-01, 9.998e-01, ..., 1.122e-03, 4.451e-06],\\n           ...,\\n           [9.999e-01, 9.999e-01, ..., 9.997e-01, 9.996e-01],\\n           [1.000e+00, 1.000e+00, ..., 9.994e-01, 9.994e-01]],\\n          dtype=float32)\\n\\n    Separate into harmonic/percussive/residual components by using a margin > 1.0\\n\\n    >>> H, P = librosa.decompose.hpss(D, margin=3.0)\\n    >>> R = D - (H+P)\\n    >>> y_harm = librosa.istft(H)\\n    >>> y_perc = librosa.istft(P)\\n    >>> y_resi = librosa.istft(R)\\n\\n    Get a more isolated percussive component by widening its margin\\n\\n    >>> H, P = librosa.decompose.hpss(D, margin=(1.0,5.0))\\n    '\n    phase: Union[float, np.ndarray]\n    if np.iscomplexobj(S):\n        (S, phase) = core.magphase(S)\n    else:\n        phase = 1\n    if isinstance(kernel_size, tuple) or isinstance(kernel_size, list):\n        win_harm = kernel_size[0]\n        win_perc = kernel_size[1]\n    else:\n        win_harm = kernel_size\n        win_perc = kernel_size\n    if isinstance(margin, tuple) or isinstance(margin, list):\n        margin_harm = margin[0]\n        margin_perc = margin[1]\n    else:\n        margin_harm = margin\n        margin_perc = margin\n    if margin_harm < 1 or margin_perc < 1:\n        raise ParameterError('Margins must be >= 1.0. A typical range is between 1 and 10.')\n    harm_shape: List[_IntLike_co] = [1] * S.ndim\n    harm_shape[-1] = win_harm\n    perc_shape: List[_IntLike_co] = [1] * S.ndim\n    perc_shape[-2] = win_perc\n    harm = np.empty_like(S)\n    harm[:] = median_filter(S, size=harm_shape, mode='reflect')\n    perc = np.empty_like(S)\n    perc[:] = median_filter(S, size=perc_shape, mode='reflect')\n    split_zeros = margin_harm == 1 and margin_perc == 1\n    mask_harm = util.softmask(harm, perc * margin_harm, power=power, split_zeros=split_zeros)\n    mask_perc = util.softmask(perc, harm * margin_perc, power=power, split_zeros=split_zeros)\n    if mask:\n        return (mask_harm, mask_perc)\n    return (S * mask_harm * phase, S * mask_perc * phase)",
            "@cache(level=30)\ndef hpss(S: np.ndarray, *, kernel_size: Union[_IntLike_co, Tuple[_IntLike_co, _IntLike_co], List[_IntLike_co]]=31, power: float=2.0, mask: bool=False, margin: Union[_FloatLike_co, Tuple[_FloatLike_co, _FloatLike_co], List[_FloatLike_co]]=1.0) -> Tuple[np.ndarray, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Median-filtering harmonic percussive source separation (HPSS).\\n\\n    If ``margin = 1.0``, decomposes an input spectrogram ``S = H + P``\\n    where ``H`` contains the harmonic components,\\n    and ``P`` contains the percussive components.\\n\\n    If ``margin > 1.0``, decomposes an input spectrogram ``S = H + P + R``\\n    where ``R`` contains residual components not included in ``H`` or ``P``.\\n\\n    This implementation is based upon the algorithm described by [#]_ and [#]_.\\n\\n    .. [#] Fitzgerald, Derry.\\n        \"Harmonic/percussive separation using median filtering.\"\\n        13th International Conference on Digital Audio Effects (DAFX10),\\n        Graz, Austria, 2010.\\n\\n    .. [#] Driedger, M\u00fcller, Disch.\\n        \"Extending harmonic-percussive separation of audio.\"\\n        15th International Society for Music Information Retrieval Conference (ISMIR 2014),\\n        Taipei, Taiwan, 2014.\\n\\n    Parameters\\n    ----------\\n    S : np.ndarray [shape=(..., d, n)]\\n        input spectrogram. May be real (magnitude) or complex.\\n        Multi-channel is supported.\\n\\n    kernel_size : int or tuple (kernel_harmonic, kernel_percussive)\\n        kernel size(s) for the median filters.\\n\\n        - If scalar, the same size is used for both harmonic and percussive.\\n        - If tuple, the first value specifies the width of the\\n          harmonic filter, and the second value specifies the width\\n          of the percussive filter.\\n\\n    power : float > 0 [scalar]\\n        Exponent for the Wiener filter when constructing soft mask matrices.\\n\\n    mask : bool\\n        Return the masking matrices instead of components.\\n\\n        Masking matrices contain non-negative real values that\\n        can be used to measure the assignment of energy from ``S``\\n        into harmonic or percussive components.\\n\\n        Components can be recovered by multiplying ``S * mask_H``\\n        or ``S * mask_P``.\\n\\n    margin : float or tuple (margin_harmonic, margin_percussive)\\n        margin size(s) for the masks (as described in [2]_)\\n\\n        - If scalar, the same size is used for both harmonic and percussive.\\n        - If tuple, the first value specifies the margin of the\\n          harmonic mask, and the second value specifies the margin\\n          of the percussive mask.\\n\\n    Returns\\n    -------\\n    harmonic : np.ndarray [shape=(..., d, n)]\\n        harmonic component (or mask)\\n    percussive : np.ndarray [shape=(..., d, n)]\\n        percussive component (or mask)\\n\\n    See Also\\n    --------\\n    librosa.util.softmask\\n\\n    Notes\\n    -----\\n    This function caches at level 30.\\n\\n    Examples\\n    --------\\n    Separate into harmonic and percussive\\n\\n    >>> y, sr = librosa.load(librosa.ex(\\'choice\\'), duration=5)\\n    >>> D = librosa.stft(y)\\n    >>> H, P = librosa.decompose.hpss(D)\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\\n    >>> img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D),\\n    ...                                                        ref=np.max),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[0])\\n    >>> ax[0].set(title=\\'Full power spectrogram\\')\\n    >>> ax[0].label_outer()\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(np.abs(H),\\n    ...                                                  ref=np.max(np.abs(D))),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[1])\\n    >>> ax[1].set(title=\\'Harmonic power spectrogram\\')\\n    >>> ax[1].label_outer()\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(np.abs(P),\\n    ...                                                  ref=np.max(np.abs(D))),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[2])\\n    >>> ax[2].set(title=\\'Percussive power spectrogram\\')\\n    >>> fig.colorbar(img, ax=ax, format=\\'%+2.0f dB\\')\\n\\n    Or with a narrower horizontal filter\\n\\n    >>> H, P = librosa.decompose.hpss(D, kernel_size=(13, 31))\\n\\n    Just get harmonic/percussive masks, not the spectra\\n\\n    >>> mask_H, mask_P = librosa.decompose.hpss(D, mask=True)\\n    >>> mask_H\\n    array([[1.853e-03, 1.701e-04, ..., 9.922e-01, 1.000e+00],\\n           [2.316e-03, 2.127e-04, ..., 9.989e-01, 1.000e+00],\\n           ...,\\n           [8.195e-05, 6.939e-05, ..., 3.105e-04, 4.231e-04],\\n           [3.159e-05, 4.156e-05, ..., 6.216e-04, 6.188e-04]],\\n          dtype=float32)\\n    >>> mask_P\\n    array([[9.981e-01, 9.998e-01, ..., 7.759e-03, 3.201e-05],\\n           [9.977e-01, 9.998e-01, ..., 1.122e-03, 4.451e-06],\\n           ...,\\n           [9.999e-01, 9.999e-01, ..., 9.997e-01, 9.996e-01],\\n           [1.000e+00, 1.000e+00, ..., 9.994e-01, 9.994e-01]],\\n          dtype=float32)\\n\\n    Separate into harmonic/percussive/residual components by using a margin > 1.0\\n\\n    >>> H, P = librosa.decompose.hpss(D, margin=3.0)\\n    >>> R = D - (H+P)\\n    >>> y_harm = librosa.istft(H)\\n    >>> y_perc = librosa.istft(P)\\n    >>> y_resi = librosa.istft(R)\\n\\n    Get a more isolated percussive component by widening its margin\\n\\n    >>> H, P = librosa.decompose.hpss(D, margin=(1.0,5.0))\\n    '\n    phase: Union[float, np.ndarray]\n    if np.iscomplexobj(S):\n        (S, phase) = core.magphase(S)\n    else:\n        phase = 1\n    if isinstance(kernel_size, tuple) or isinstance(kernel_size, list):\n        win_harm = kernel_size[0]\n        win_perc = kernel_size[1]\n    else:\n        win_harm = kernel_size\n        win_perc = kernel_size\n    if isinstance(margin, tuple) or isinstance(margin, list):\n        margin_harm = margin[0]\n        margin_perc = margin[1]\n    else:\n        margin_harm = margin\n        margin_perc = margin\n    if margin_harm < 1 or margin_perc < 1:\n        raise ParameterError('Margins must be >= 1.0. A typical range is between 1 and 10.')\n    harm_shape: List[_IntLike_co] = [1] * S.ndim\n    harm_shape[-1] = win_harm\n    perc_shape: List[_IntLike_co] = [1] * S.ndim\n    perc_shape[-2] = win_perc\n    harm = np.empty_like(S)\n    harm[:] = median_filter(S, size=harm_shape, mode='reflect')\n    perc = np.empty_like(S)\n    perc[:] = median_filter(S, size=perc_shape, mode='reflect')\n    split_zeros = margin_harm == 1 and margin_perc == 1\n    mask_harm = util.softmask(harm, perc * margin_harm, power=power, split_zeros=split_zeros)\n    mask_perc = util.softmask(perc, harm * margin_perc, power=power, split_zeros=split_zeros)\n    if mask:\n        return (mask_harm, mask_perc)\n    return (S * mask_harm * phase, S * mask_perc * phase)",
            "@cache(level=30)\ndef hpss(S: np.ndarray, *, kernel_size: Union[_IntLike_co, Tuple[_IntLike_co, _IntLike_co], List[_IntLike_co]]=31, power: float=2.0, mask: bool=False, margin: Union[_FloatLike_co, Tuple[_FloatLike_co, _FloatLike_co], List[_FloatLike_co]]=1.0) -> Tuple[np.ndarray, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Median-filtering harmonic percussive source separation (HPSS).\\n\\n    If ``margin = 1.0``, decomposes an input spectrogram ``S = H + P``\\n    where ``H`` contains the harmonic components,\\n    and ``P`` contains the percussive components.\\n\\n    If ``margin > 1.0``, decomposes an input spectrogram ``S = H + P + R``\\n    where ``R`` contains residual components not included in ``H`` or ``P``.\\n\\n    This implementation is based upon the algorithm described by [#]_ and [#]_.\\n\\n    .. [#] Fitzgerald, Derry.\\n        \"Harmonic/percussive separation using median filtering.\"\\n        13th International Conference on Digital Audio Effects (DAFX10),\\n        Graz, Austria, 2010.\\n\\n    .. [#] Driedger, M\u00fcller, Disch.\\n        \"Extending harmonic-percussive separation of audio.\"\\n        15th International Society for Music Information Retrieval Conference (ISMIR 2014),\\n        Taipei, Taiwan, 2014.\\n\\n    Parameters\\n    ----------\\n    S : np.ndarray [shape=(..., d, n)]\\n        input spectrogram. May be real (magnitude) or complex.\\n        Multi-channel is supported.\\n\\n    kernel_size : int or tuple (kernel_harmonic, kernel_percussive)\\n        kernel size(s) for the median filters.\\n\\n        - If scalar, the same size is used for both harmonic and percussive.\\n        - If tuple, the first value specifies the width of the\\n          harmonic filter, and the second value specifies the width\\n          of the percussive filter.\\n\\n    power : float > 0 [scalar]\\n        Exponent for the Wiener filter when constructing soft mask matrices.\\n\\n    mask : bool\\n        Return the masking matrices instead of components.\\n\\n        Masking matrices contain non-negative real values that\\n        can be used to measure the assignment of energy from ``S``\\n        into harmonic or percussive components.\\n\\n        Components can be recovered by multiplying ``S * mask_H``\\n        or ``S * mask_P``.\\n\\n    margin : float or tuple (margin_harmonic, margin_percussive)\\n        margin size(s) for the masks (as described in [2]_)\\n\\n        - If scalar, the same size is used for both harmonic and percussive.\\n        - If tuple, the first value specifies the margin of the\\n          harmonic mask, and the second value specifies the margin\\n          of the percussive mask.\\n\\n    Returns\\n    -------\\n    harmonic : np.ndarray [shape=(..., d, n)]\\n        harmonic component (or mask)\\n    percussive : np.ndarray [shape=(..., d, n)]\\n        percussive component (or mask)\\n\\n    See Also\\n    --------\\n    librosa.util.softmask\\n\\n    Notes\\n    -----\\n    This function caches at level 30.\\n\\n    Examples\\n    --------\\n    Separate into harmonic and percussive\\n\\n    >>> y, sr = librosa.load(librosa.ex(\\'choice\\'), duration=5)\\n    >>> D = librosa.stft(y)\\n    >>> H, P = librosa.decompose.hpss(D)\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\\n    >>> img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D),\\n    ...                                                        ref=np.max),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[0])\\n    >>> ax[0].set(title=\\'Full power spectrogram\\')\\n    >>> ax[0].label_outer()\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(np.abs(H),\\n    ...                                                  ref=np.max(np.abs(D))),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[1])\\n    >>> ax[1].set(title=\\'Harmonic power spectrogram\\')\\n    >>> ax[1].label_outer()\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(np.abs(P),\\n    ...                                                  ref=np.max(np.abs(D))),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[2])\\n    >>> ax[2].set(title=\\'Percussive power spectrogram\\')\\n    >>> fig.colorbar(img, ax=ax, format=\\'%+2.0f dB\\')\\n\\n    Or with a narrower horizontal filter\\n\\n    >>> H, P = librosa.decompose.hpss(D, kernel_size=(13, 31))\\n\\n    Just get harmonic/percussive masks, not the spectra\\n\\n    >>> mask_H, mask_P = librosa.decompose.hpss(D, mask=True)\\n    >>> mask_H\\n    array([[1.853e-03, 1.701e-04, ..., 9.922e-01, 1.000e+00],\\n           [2.316e-03, 2.127e-04, ..., 9.989e-01, 1.000e+00],\\n           ...,\\n           [8.195e-05, 6.939e-05, ..., 3.105e-04, 4.231e-04],\\n           [3.159e-05, 4.156e-05, ..., 6.216e-04, 6.188e-04]],\\n          dtype=float32)\\n    >>> mask_P\\n    array([[9.981e-01, 9.998e-01, ..., 7.759e-03, 3.201e-05],\\n           [9.977e-01, 9.998e-01, ..., 1.122e-03, 4.451e-06],\\n           ...,\\n           [9.999e-01, 9.999e-01, ..., 9.997e-01, 9.996e-01],\\n           [1.000e+00, 1.000e+00, ..., 9.994e-01, 9.994e-01]],\\n          dtype=float32)\\n\\n    Separate into harmonic/percussive/residual components by using a margin > 1.0\\n\\n    >>> H, P = librosa.decompose.hpss(D, margin=3.0)\\n    >>> R = D - (H+P)\\n    >>> y_harm = librosa.istft(H)\\n    >>> y_perc = librosa.istft(P)\\n    >>> y_resi = librosa.istft(R)\\n\\n    Get a more isolated percussive component by widening its margin\\n\\n    >>> H, P = librosa.decompose.hpss(D, margin=(1.0,5.0))\\n    '\n    phase: Union[float, np.ndarray]\n    if np.iscomplexobj(S):\n        (S, phase) = core.magphase(S)\n    else:\n        phase = 1\n    if isinstance(kernel_size, tuple) or isinstance(kernel_size, list):\n        win_harm = kernel_size[0]\n        win_perc = kernel_size[1]\n    else:\n        win_harm = kernel_size\n        win_perc = kernel_size\n    if isinstance(margin, tuple) or isinstance(margin, list):\n        margin_harm = margin[0]\n        margin_perc = margin[1]\n    else:\n        margin_harm = margin\n        margin_perc = margin\n    if margin_harm < 1 or margin_perc < 1:\n        raise ParameterError('Margins must be >= 1.0. A typical range is between 1 and 10.')\n    harm_shape: List[_IntLike_co] = [1] * S.ndim\n    harm_shape[-1] = win_harm\n    perc_shape: List[_IntLike_co] = [1] * S.ndim\n    perc_shape[-2] = win_perc\n    harm = np.empty_like(S)\n    harm[:] = median_filter(S, size=harm_shape, mode='reflect')\n    perc = np.empty_like(S)\n    perc[:] = median_filter(S, size=perc_shape, mode='reflect')\n    split_zeros = margin_harm == 1 and margin_perc == 1\n    mask_harm = util.softmask(harm, perc * margin_harm, power=power, split_zeros=split_zeros)\n    mask_perc = util.softmask(perc, harm * margin_perc, power=power, split_zeros=split_zeros)\n    if mask:\n        return (mask_harm, mask_perc)\n    return (S * mask_harm * phase, S * mask_perc * phase)",
            "@cache(level=30)\ndef hpss(S: np.ndarray, *, kernel_size: Union[_IntLike_co, Tuple[_IntLike_co, _IntLike_co], List[_IntLike_co]]=31, power: float=2.0, mask: bool=False, margin: Union[_FloatLike_co, Tuple[_FloatLike_co, _FloatLike_co], List[_FloatLike_co]]=1.0) -> Tuple[np.ndarray, np.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Median-filtering harmonic percussive source separation (HPSS).\\n\\n    If ``margin = 1.0``, decomposes an input spectrogram ``S = H + P``\\n    where ``H`` contains the harmonic components,\\n    and ``P`` contains the percussive components.\\n\\n    If ``margin > 1.0``, decomposes an input spectrogram ``S = H + P + R``\\n    where ``R`` contains residual components not included in ``H`` or ``P``.\\n\\n    This implementation is based upon the algorithm described by [#]_ and [#]_.\\n\\n    .. [#] Fitzgerald, Derry.\\n        \"Harmonic/percussive separation using median filtering.\"\\n        13th International Conference on Digital Audio Effects (DAFX10),\\n        Graz, Austria, 2010.\\n\\n    .. [#] Driedger, M\u00fcller, Disch.\\n        \"Extending harmonic-percussive separation of audio.\"\\n        15th International Society for Music Information Retrieval Conference (ISMIR 2014),\\n        Taipei, Taiwan, 2014.\\n\\n    Parameters\\n    ----------\\n    S : np.ndarray [shape=(..., d, n)]\\n        input spectrogram. May be real (magnitude) or complex.\\n        Multi-channel is supported.\\n\\n    kernel_size : int or tuple (kernel_harmonic, kernel_percussive)\\n        kernel size(s) for the median filters.\\n\\n        - If scalar, the same size is used for both harmonic and percussive.\\n        - If tuple, the first value specifies the width of the\\n          harmonic filter, and the second value specifies the width\\n          of the percussive filter.\\n\\n    power : float > 0 [scalar]\\n        Exponent for the Wiener filter when constructing soft mask matrices.\\n\\n    mask : bool\\n        Return the masking matrices instead of components.\\n\\n        Masking matrices contain non-negative real values that\\n        can be used to measure the assignment of energy from ``S``\\n        into harmonic or percussive components.\\n\\n        Components can be recovered by multiplying ``S * mask_H``\\n        or ``S * mask_P``.\\n\\n    margin : float or tuple (margin_harmonic, margin_percussive)\\n        margin size(s) for the masks (as described in [2]_)\\n\\n        - If scalar, the same size is used for both harmonic and percussive.\\n        - If tuple, the first value specifies the margin of the\\n          harmonic mask, and the second value specifies the margin\\n          of the percussive mask.\\n\\n    Returns\\n    -------\\n    harmonic : np.ndarray [shape=(..., d, n)]\\n        harmonic component (or mask)\\n    percussive : np.ndarray [shape=(..., d, n)]\\n        percussive component (or mask)\\n\\n    See Also\\n    --------\\n    librosa.util.softmask\\n\\n    Notes\\n    -----\\n    This function caches at level 30.\\n\\n    Examples\\n    --------\\n    Separate into harmonic and percussive\\n\\n    >>> y, sr = librosa.load(librosa.ex(\\'choice\\'), duration=5)\\n    >>> D = librosa.stft(y)\\n    >>> H, P = librosa.decompose.hpss(D)\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\\n    >>> img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D),\\n    ...                                                        ref=np.max),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[0])\\n    >>> ax[0].set(title=\\'Full power spectrogram\\')\\n    >>> ax[0].label_outer()\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(np.abs(H),\\n    ...                                                  ref=np.max(np.abs(D))),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[1])\\n    >>> ax[1].set(title=\\'Harmonic power spectrogram\\')\\n    >>> ax[1].label_outer()\\n    >>> librosa.display.specshow(librosa.amplitude_to_db(np.abs(P),\\n    ...                                                  ref=np.max(np.abs(D))),\\n    ...                          y_axis=\\'log\\', x_axis=\\'time\\', ax=ax[2])\\n    >>> ax[2].set(title=\\'Percussive power spectrogram\\')\\n    >>> fig.colorbar(img, ax=ax, format=\\'%+2.0f dB\\')\\n\\n    Or with a narrower horizontal filter\\n\\n    >>> H, P = librosa.decompose.hpss(D, kernel_size=(13, 31))\\n\\n    Just get harmonic/percussive masks, not the spectra\\n\\n    >>> mask_H, mask_P = librosa.decompose.hpss(D, mask=True)\\n    >>> mask_H\\n    array([[1.853e-03, 1.701e-04, ..., 9.922e-01, 1.000e+00],\\n           [2.316e-03, 2.127e-04, ..., 9.989e-01, 1.000e+00],\\n           ...,\\n           [8.195e-05, 6.939e-05, ..., 3.105e-04, 4.231e-04],\\n           [3.159e-05, 4.156e-05, ..., 6.216e-04, 6.188e-04]],\\n          dtype=float32)\\n    >>> mask_P\\n    array([[9.981e-01, 9.998e-01, ..., 7.759e-03, 3.201e-05],\\n           [9.977e-01, 9.998e-01, ..., 1.122e-03, 4.451e-06],\\n           ...,\\n           [9.999e-01, 9.999e-01, ..., 9.997e-01, 9.996e-01],\\n           [1.000e+00, 1.000e+00, ..., 9.994e-01, 9.994e-01]],\\n          dtype=float32)\\n\\n    Separate into harmonic/percussive/residual components by using a margin > 1.0\\n\\n    >>> H, P = librosa.decompose.hpss(D, margin=3.0)\\n    >>> R = D - (H+P)\\n    >>> y_harm = librosa.istft(H)\\n    >>> y_perc = librosa.istft(P)\\n    >>> y_resi = librosa.istft(R)\\n\\n    Get a more isolated percussive component by widening its margin\\n\\n    >>> H, P = librosa.decompose.hpss(D, margin=(1.0,5.0))\\n    '\n    phase: Union[float, np.ndarray]\n    if np.iscomplexobj(S):\n        (S, phase) = core.magphase(S)\n    else:\n        phase = 1\n    if isinstance(kernel_size, tuple) or isinstance(kernel_size, list):\n        win_harm = kernel_size[0]\n        win_perc = kernel_size[1]\n    else:\n        win_harm = kernel_size\n        win_perc = kernel_size\n    if isinstance(margin, tuple) or isinstance(margin, list):\n        margin_harm = margin[0]\n        margin_perc = margin[1]\n    else:\n        margin_harm = margin\n        margin_perc = margin\n    if margin_harm < 1 or margin_perc < 1:\n        raise ParameterError('Margins must be >= 1.0. A typical range is between 1 and 10.')\n    harm_shape: List[_IntLike_co] = [1] * S.ndim\n    harm_shape[-1] = win_harm\n    perc_shape: List[_IntLike_co] = [1] * S.ndim\n    perc_shape[-2] = win_perc\n    harm = np.empty_like(S)\n    harm[:] = median_filter(S, size=harm_shape, mode='reflect')\n    perc = np.empty_like(S)\n    perc[:] = median_filter(S, size=perc_shape, mode='reflect')\n    split_zeros = margin_harm == 1 and margin_perc == 1\n    mask_harm = util.softmask(harm, perc * margin_harm, power=power, split_zeros=split_zeros)\n    mask_perc = util.softmask(perc, harm * margin_perc, power=power, split_zeros=split_zeros)\n    if mask:\n        return (mask_harm, mask_perc)\n    return (S * mask_harm * phase, S * mask_perc * phase)"
        ]
    },
    {
        "func_name": "nn_filter",
        "original": "@cache(level=30)\ndef nn_filter(S: np.ndarray, *, rec: Optional[Union[scipy.sparse.spmatrix, np.ndarray]]=None, aggregate: Optional[Callable]=None, axis: int=-1, **kwargs: Any) -> np.ndarray:\n    \"\"\"Filter by nearest-neighbor aggregation.\n\n    Each data point (e.g, spectrogram column) is replaced\n    by aggregating its nearest neighbors in feature space.\n\n    This can be useful for de-noising a spectrogram or feature matrix.\n\n    The non-local means method [#]_ can be recovered by providing a\n    weighted recurrence matrix as input and specifying ``aggregate=np.average``.\n\n    Similarly, setting ``aggregate=np.median`` produces sparse de-noising\n    as in REPET-SIM [#]_.\n\n    .. [#] Buades, A., Coll, B., & Morel, J. M.\n        (2005, June). A non-local algorithm for image denoising.\n        In Computer Vision and Pattern Recognition, 2005.\n        CVPR 2005. IEEE Computer Society Conference on (Vol. 2, pp. 60-65). IEEE.\n\n    .. [#] Rafii, Z., & Pardo, B.\n        (2012, October).  \"Music/Voice Separation Using the Similarity Matrix.\"\n        International Society for Music Information Retrieval Conference, 2012.\n\n    Parameters\n    ----------\n    S : np.ndarray\n        The input data (spectrogram) to filter. Multi-channel is supported.\n\n    rec : (optional) scipy.sparse.spmatrix or np.ndarray\n        Optionally, a pre-computed nearest-neighbor matrix\n        as provided by `librosa.segment.recurrence_matrix`\n\n    aggregate : function\n        aggregation function (default: `np.mean`)\n\n        If ``aggregate=np.average``, then a weighted average is\n        computed according to the (per-row) weights in ``rec``.\n\n        For all other aggregation functions, all neighbors\n        are treated equally.\n\n    axis : int\n        The axis along which to filter (by default, columns)\n\n    **kwargs\n        Additional keyword arguments provided to\n        `librosa.segment.recurrence_matrix` if ``rec`` is not provided\n\n    Returns\n    -------\n    S_filtered : np.ndarray\n        The filtered data, with shape equivalent to the input ``S``.\n\n    Raises\n    ------\n    ParameterError\n        if ``rec`` is provided and its shape is incompatible with ``S``.\n\n    See Also\n    --------\n    decompose\n    hpss\n    librosa.segment.recurrence_matrix\n\n    Notes\n    -----\n    This function caches at level 30.\n\n    Examples\n    --------\n    De-noise a chromagram by non-local median filtering.\n    By default this would use euclidean distance to select neighbors,\n    but this can be overridden directly by setting the ``metric`` parameter.\n\n    >>> y, sr = librosa.load(librosa.ex('brahms'),\n    ...                      offset=30, duration=10)\n    >>> chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n    >>> chroma_med = librosa.decompose.nn_filter(chroma,\n    ...                                          aggregate=np.median,\n    ...                                          metric='cosine')\n\n    To use non-local means, provide an affinity matrix and ``aggregate=np.average``.\n\n    >>> rec = librosa.segment.recurrence_matrix(chroma, mode='affinity',\n    ...                                         metric='cosine', sparse=True)\n    >>> chroma_nlm = librosa.decompose.nn_filter(chroma, rec=rec,\n    ...                                          aggregate=np.average)\n\n    >>> import matplotlib.pyplot as plt\n    >>> fig, ax = plt.subplots(nrows=5, sharex=True, sharey=True, figsize=(10, 10))\n    >>> librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', ax=ax[0])\n    >>> ax[0].set(title='Unfiltered')\n    >>> ax[0].label_outer()\n    >>> librosa.display.specshow(chroma_med, y_axis='chroma', x_axis='time', ax=ax[1])\n    >>> ax[1].set(title='Median-filtered')\n    >>> ax[1].label_outer()\n    >>> imgc = librosa.display.specshow(chroma_nlm, y_axis='chroma', x_axis='time', ax=ax[2])\n    >>> ax[2].set(title='Non-local means')\n    >>> ax[2].label_outer()\n    >>> imgr1 = librosa.display.specshow(chroma - chroma_med,\n    ...                          y_axis='chroma', x_axis='time', ax=ax[3])\n    >>> ax[3].set(title='Original - median')\n    >>> ax[3].label_outer()\n    >>> imgr2 = librosa.display.specshow(chroma - chroma_nlm,\n    ...                          y_axis='chroma', x_axis='time', ax=ax[4])\n    >>> ax[4].label_outer()\n    >>> ax[4].set(title='Original - NLM')\n    >>> fig.colorbar(imgc, ax=ax[:3])\n    >>> fig.colorbar(imgr1, ax=[ax[3]])\n    >>> fig.colorbar(imgr2, ax=[ax[4]])\n    \"\"\"\n    if aggregate is None:\n        aggregate = np.mean\n    rec_s: scipy.sparse.spmatrix\n    if rec is None:\n        kwargs = dict(kwargs)\n        kwargs['sparse'] = True\n        rec_s = segment.recurrence_matrix(S, axis=axis, **kwargs)\n    elif not scipy.sparse.issparse(rec):\n        rec_s = scipy.sparse.csc_matrix(rec)\n    else:\n        rec_s = rec\n    if rec_s.shape[0] != S.shape[axis] or rec_s.shape[0] != rec_s.shape[1]:\n        raise ParameterError(f'Invalid self-similarity matrix shape rec.shape={rec_s.shape} for S.shape={S.shape}')\n    return __nn_filter_helper(rec_s.data, rec_s.indices, rec_s.indptr, S.swapaxes(0, axis), aggregate).swapaxes(0, axis)",
        "mutated": [
            "@cache(level=30)\ndef nn_filter(S: np.ndarray, *, rec: Optional[Union[scipy.sparse.spmatrix, np.ndarray]]=None, aggregate: Optional[Callable]=None, axis: int=-1, **kwargs: Any) -> np.ndarray:\n    if False:\n        i = 10\n    'Filter by nearest-neighbor aggregation.\\n\\n    Each data point (e.g, spectrogram column) is replaced\\n    by aggregating its nearest neighbors in feature space.\\n\\n    This can be useful for de-noising a spectrogram or feature matrix.\\n\\n    The non-local means method [#]_ can be recovered by providing a\\n    weighted recurrence matrix as input and specifying ``aggregate=np.average``.\\n\\n    Similarly, setting ``aggregate=np.median`` produces sparse de-noising\\n    as in REPET-SIM [#]_.\\n\\n    .. [#] Buades, A., Coll, B., & Morel, J. M.\\n        (2005, June). A non-local algorithm for image denoising.\\n        In Computer Vision and Pattern Recognition, 2005.\\n        CVPR 2005. IEEE Computer Society Conference on (Vol. 2, pp. 60-65). IEEE.\\n\\n    .. [#] Rafii, Z., & Pardo, B.\\n        (2012, October).  \"Music/Voice Separation Using the Similarity Matrix.\"\\n        International Society for Music Information Retrieval Conference, 2012.\\n\\n    Parameters\\n    ----------\\n    S : np.ndarray\\n        The input data (spectrogram) to filter. Multi-channel is supported.\\n\\n    rec : (optional) scipy.sparse.spmatrix or np.ndarray\\n        Optionally, a pre-computed nearest-neighbor matrix\\n        as provided by `librosa.segment.recurrence_matrix`\\n\\n    aggregate : function\\n        aggregation function (default: `np.mean`)\\n\\n        If ``aggregate=np.average``, then a weighted average is\\n        computed according to the (per-row) weights in ``rec``.\\n\\n        For all other aggregation functions, all neighbors\\n        are treated equally.\\n\\n    axis : int\\n        The axis along which to filter (by default, columns)\\n\\n    **kwargs\\n        Additional keyword arguments provided to\\n        `librosa.segment.recurrence_matrix` if ``rec`` is not provided\\n\\n    Returns\\n    -------\\n    S_filtered : np.ndarray\\n        The filtered data, with shape equivalent to the input ``S``.\\n\\n    Raises\\n    ------\\n    ParameterError\\n        if ``rec`` is provided and its shape is incompatible with ``S``.\\n\\n    See Also\\n    --------\\n    decompose\\n    hpss\\n    librosa.segment.recurrence_matrix\\n\\n    Notes\\n    -----\\n    This function caches at level 30.\\n\\n    Examples\\n    --------\\n    De-noise a chromagram by non-local median filtering.\\n    By default this would use euclidean distance to select neighbors,\\n    but this can be overridden directly by setting the ``metric`` parameter.\\n\\n    >>> y, sr = librosa.load(librosa.ex(\\'brahms\\'),\\n    ...                      offset=30, duration=10)\\n    >>> chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\\n    >>> chroma_med = librosa.decompose.nn_filter(chroma,\\n    ...                                          aggregate=np.median,\\n    ...                                          metric=\\'cosine\\')\\n\\n    To use non-local means, provide an affinity matrix and ``aggregate=np.average``.\\n\\n    >>> rec = librosa.segment.recurrence_matrix(chroma, mode=\\'affinity\\',\\n    ...                                         metric=\\'cosine\\', sparse=True)\\n    >>> chroma_nlm = librosa.decompose.nn_filter(chroma, rec=rec,\\n    ...                                          aggregate=np.average)\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> fig, ax = plt.subplots(nrows=5, sharex=True, sharey=True, figsize=(10, 10))\\n    >>> librosa.display.specshow(chroma, y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[0])\\n    >>> ax[0].set(title=\\'Unfiltered\\')\\n    >>> ax[0].label_outer()\\n    >>> librosa.display.specshow(chroma_med, y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[1])\\n    >>> ax[1].set(title=\\'Median-filtered\\')\\n    >>> ax[1].label_outer()\\n    >>> imgc = librosa.display.specshow(chroma_nlm, y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[2])\\n    >>> ax[2].set(title=\\'Non-local means\\')\\n    >>> ax[2].label_outer()\\n    >>> imgr1 = librosa.display.specshow(chroma - chroma_med,\\n    ...                          y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[3])\\n    >>> ax[3].set(title=\\'Original - median\\')\\n    >>> ax[3].label_outer()\\n    >>> imgr2 = librosa.display.specshow(chroma - chroma_nlm,\\n    ...                          y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[4])\\n    >>> ax[4].label_outer()\\n    >>> ax[4].set(title=\\'Original - NLM\\')\\n    >>> fig.colorbar(imgc, ax=ax[:3])\\n    >>> fig.colorbar(imgr1, ax=[ax[3]])\\n    >>> fig.colorbar(imgr2, ax=[ax[4]])\\n    '\n    if aggregate is None:\n        aggregate = np.mean\n    rec_s: scipy.sparse.spmatrix\n    if rec is None:\n        kwargs = dict(kwargs)\n        kwargs['sparse'] = True\n        rec_s = segment.recurrence_matrix(S, axis=axis, **kwargs)\n    elif not scipy.sparse.issparse(rec):\n        rec_s = scipy.sparse.csc_matrix(rec)\n    else:\n        rec_s = rec\n    if rec_s.shape[0] != S.shape[axis] or rec_s.shape[0] != rec_s.shape[1]:\n        raise ParameterError(f'Invalid self-similarity matrix shape rec.shape={rec_s.shape} for S.shape={S.shape}')\n    return __nn_filter_helper(rec_s.data, rec_s.indices, rec_s.indptr, S.swapaxes(0, axis), aggregate).swapaxes(0, axis)",
            "@cache(level=30)\ndef nn_filter(S: np.ndarray, *, rec: Optional[Union[scipy.sparse.spmatrix, np.ndarray]]=None, aggregate: Optional[Callable]=None, axis: int=-1, **kwargs: Any) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Filter by nearest-neighbor aggregation.\\n\\n    Each data point (e.g, spectrogram column) is replaced\\n    by aggregating its nearest neighbors in feature space.\\n\\n    This can be useful for de-noising a spectrogram or feature matrix.\\n\\n    The non-local means method [#]_ can be recovered by providing a\\n    weighted recurrence matrix as input and specifying ``aggregate=np.average``.\\n\\n    Similarly, setting ``aggregate=np.median`` produces sparse de-noising\\n    as in REPET-SIM [#]_.\\n\\n    .. [#] Buades, A., Coll, B., & Morel, J. M.\\n        (2005, June). A non-local algorithm for image denoising.\\n        In Computer Vision and Pattern Recognition, 2005.\\n        CVPR 2005. IEEE Computer Society Conference on (Vol. 2, pp. 60-65). IEEE.\\n\\n    .. [#] Rafii, Z., & Pardo, B.\\n        (2012, October).  \"Music/Voice Separation Using the Similarity Matrix.\"\\n        International Society for Music Information Retrieval Conference, 2012.\\n\\n    Parameters\\n    ----------\\n    S : np.ndarray\\n        The input data (spectrogram) to filter. Multi-channel is supported.\\n\\n    rec : (optional) scipy.sparse.spmatrix or np.ndarray\\n        Optionally, a pre-computed nearest-neighbor matrix\\n        as provided by `librosa.segment.recurrence_matrix`\\n\\n    aggregate : function\\n        aggregation function (default: `np.mean`)\\n\\n        If ``aggregate=np.average``, then a weighted average is\\n        computed according to the (per-row) weights in ``rec``.\\n\\n        For all other aggregation functions, all neighbors\\n        are treated equally.\\n\\n    axis : int\\n        The axis along which to filter (by default, columns)\\n\\n    **kwargs\\n        Additional keyword arguments provided to\\n        `librosa.segment.recurrence_matrix` if ``rec`` is not provided\\n\\n    Returns\\n    -------\\n    S_filtered : np.ndarray\\n        The filtered data, with shape equivalent to the input ``S``.\\n\\n    Raises\\n    ------\\n    ParameterError\\n        if ``rec`` is provided and its shape is incompatible with ``S``.\\n\\n    See Also\\n    --------\\n    decompose\\n    hpss\\n    librosa.segment.recurrence_matrix\\n\\n    Notes\\n    -----\\n    This function caches at level 30.\\n\\n    Examples\\n    --------\\n    De-noise a chromagram by non-local median filtering.\\n    By default this would use euclidean distance to select neighbors,\\n    but this can be overridden directly by setting the ``metric`` parameter.\\n\\n    >>> y, sr = librosa.load(librosa.ex(\\'brahms\\'),\\n    ...                      offset=30, duration=10)\\n    >>> chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\\n    >>> chroma_med = librosa.decompose.nn_filter(chroma,\\n    ...                                          aggregate=np.median,\\n    ...                                          metric=\\'cosine\\')\\n\\n    To use non-local means, provide an affinity matrix and ``aggregate=np.average``.\\n\\n    >>> rec = librosa.segment.recurrence_matrix(chroma, mode=\\'affinity\\',\\n    ...                                         metric=\\'cosine\\', sparse=True)\\n    >>> chroma_nlm = librosa.decompose.nn_filter(chroma, rec=rec,\\n    ...                                          aggregate=np.average)\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> fig, ax = plt.subplots(nrows=5, sharex=True, sharey=True, figsize=(10, 10))\\n    >>> librosa.display.specshow(chroma, y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[0])\\n    >>> ax[0].set(title=\\'Unfiltered\\')\\n    >>> ax[0].label_outer()\\n    >>> librosa.display.specshow(chroma_med, y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[1])\\n    >>> ax[1].set(title=\\'Median-filtered\\')\\n    >>> ax[1].label_outer()\\n    >>> imgc = librosa.display.specshow(chroma_nlm, y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[2])\\n    >>> ax[2].set(title=\\'Non-local means\\')\\n    >>> ax[2].label_outer()\\n    >>> imgr1 = librosa.display.specshow(chroma - chroma_med,\\n    ...                          y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[3])\\n    >>> ax[3].set(title=\\'Original - median\\')\\n    >>> ax[3].label_outer()\\n    >>> imgr2 = librosa.display.specshow(chroma - chroma_nlm,\\n    ...                          y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[4])\\n    >>> ax[4].label_outer()\\n    >>> ax[4].set(title=\\'Original - NLM\\')\\n    >>> fig.colorbar(imgc, ax=ax[:3])\\n    >>> fig.colorbar(imgr1, ax=[ax[3]])\\n    >>> fig.colorbar(imgr2, ax=[ax[4]])\\n    '\n    if aggregate is None:\n        aggregate = np.mean\n    rec_s: scipy.sparse.spmatrix\n    if rec is None:\n        kwargs = dict(kwargs)\n        kwargs['sparse'] = True\n        rec_s = segment.recurrence_matrix(S, axis=axis, **kwargs)\n    elif not scipy.sparse.issparse(rec):\n        rec_s = scipy.sparse.csc_matrix(rec)\n    else:\n        rec_s = rec\n    if rec_s.shape[0] != S.shape[axis] or rec_s.shape[0] != rec_s.shape[1]:\n        raise ParameterError(f'Invalid self-similarity matrix shape rec.shape={rec_s.shape} for S.shape={S.shape}')\n    return __nn_filter_helper(rec_s.data, rec_s.indices, rec_s.indptr, S.swapaxes(0, axis), aggregate).swapaxes(0, axis)",
            "@cache(level=30)\ndef nn_filter(S: np.ndarray, *, rec: Optional[Union[scipy.sparse.spmatrix, np.ndarray]]=None, aggregate: Optional[Callable]=None, axis: int=-1, **kwargs: Any) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Filter by nearest-neighbor aggregation.\\n\\n    Each data point (e.g, spectrogram column) is replaced\\n    by aggregating its nearest neighbors in feature space.\\n\\n    This can be useful for de-noising a spectrogram or feature matrix.\\n\\n    The non-local means method [#]_ can be recovered by providing a\\n    weighted recurrence matrix as input and specifying ``aggregate=np.average``.\\n\\n    Similarly, setting ``aggregate=np.median`` produces sparse de-noising\\n    as in REPET-SIM [#]_.\\n\\n    .. [#] Buades, A., Coll, B., & Morel, J. M.\\n        (2005, June). A non-local algorithm for image denoising.\\n        In Computer Vision and Pattern Recognition, 2005.\\n        CVPR 2005. IEEE Computer Society Conference on (Vol. 2, pp. 60-65). IEEE.\\n\\n    .. [#] Rafii, Z., & Pardo, B.\\n        (2012, October).  \"Music/Voice Separation Using the Similarity Matrix.\"\\n        International Society for Music Information Retrieval Conference, 2012.\\n\\n    Parameters\\n    ----------\\n    S : np.ndarray\\n        The input data (spectrogram) to filter. Multi-channel is supported.\\n\\n    rec : (optional) scipy.sparse.spmatrix or np.ndarray\\n        Optionally, a pre-computed nearest-neighbor matrix\\n        as provided by `librosa.segment.recurrence_matrix`\\n\\n    aggregate : function\\n        aggregation function (default: `np.mean`)\\n\\n        If ``aggregate=np.average``, then a weighted average is\\n        computed according to the (per-row) weights in ``rec``.\\n\\n        For all other aggregation functions, all neighbors\\n        are treated equally.\\n\\n    axis : int\\n        The axis along which to filter (by default, columns)\\n\\n    **kwargs\\n        Additional keyword arguments provided to\\n        `librosa.segment.recurrence_matrix` if ``rec`` is not provided\\n\\n    Returns\\n    -------\\n    S_filtered : np.ndarray\\n        The filtered data, with shape equivalent to the input ``S``.\\n\\n    Raises\\n    ------\\n    ParameterError\\n        if ``rec`` is provided and its shape is incompatible with ``S``.\\n\\n    See Also\\n    --------\\n    decompose\\n    hpss\\n    librosa.segment.recurrence_matrix\\n\\n    Notes\\n    -----\\n    This function caches at level 30.\\n\\n    Examples\\n    --------\\n    De-noise a chromagram by non-local median filtering.\\n    By default this would use euclidean distance to select neighbors,\\n    but this can be overridden directly by setting the ``metric`` parameter.\\n\\n    >>> y, sr = librosa.load(librosa.ex(\\'brahms\\'),\\n    ...                      offset=30, duration=10)\\n    >>> chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\\n    >>> chroma_med = librosa.decompose.nn_filter(chroma,\\n    ...                                          aggregate=np.median,\\n    ...                                          metric=\\'cosine\\')\\n\\n    To use non-local means, provide an affinity matrix and ``aggregate=np.average``.\\n\\n    >>> rec = librosa.segment.recurrence_matrix(chroma, mode=\\'affinity\\',\\n    ...                                         metric=\\'cosine\\', sparse=True)\\n    >>> chroma_nlm = librosa.decompose.nn_filter(chroma, rec=rec,\\n    ...                                          aggregate=np.average)\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> fig, ax = plt.subplots(nrows=5, sharex=True, sharey=True, figsize=(10, 10))\\n    >>> librosa.display.specshow(chroma, y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[0])\\n    >>> ax[0].set(title=\\'Unfiltered\\')\\n    >>> ax[0].label_outer()\\n    >>> librosa.display.specshow(chroma_med, y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[1])\\n    >>> ax[1].set(title=\\'Median-filtered\\')\\n    >>> ax[1].label_outer()\\n    >>> imgc = librosa.display.specshow(chroma_nlm, y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[2])\\n    >>> ax[2].set(title=\\'Non-local means\\')\\n    >>> ax[2].label_outer()\\n    >>> imgr1 = librosa.display.specshow(chroma - chroma_med,\\n    ...                          y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[3])\\n    >>> ax[3].set(title=\\'Original - median\\')\\n    >>> ax[3].label_outer()\\n    >>> imgr2 = librosa.display.specshow(chroma - chroma_nlm,\\n    ...                          y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[4])\\n    >>> ax[4].label_outer()\\n    >>> ax[4].set(title=\\'Original - NLM\\')\\n    >>> fig.colorbar(imgc, ax=ax[:3])\\n    >>> fig.colorbar(imgr1, ax=[ax[3]])\\n    >>> fig.colorbar(imgr2, ax=[ax[4]])\\n    '\n    if aggregate is None:\n        aggregate = np.mean\n    rec_s: scipy.sparse.spmatrix\n    if rec is None:\n        kwargs = dict(kwargs)\n        kwargs['sparse'] = True\n        rec_s = segment.recurrence_matrix(S, axis=axis, **kwargs)\n    elif not scipy.sparse.issparse(rec):\n        rec_s = scipy.sparse.csc_matrix(rec)\n    else:\n        rec_s = rec\n    if rec_s.shape[0] != S.shape[axis] or rec_s.shape[0] != rec_s.shape[1]:\n        raise ParameterError(f'Invalid self-similarity matrix shape rec.shape={rec_s.shape} for S.shape={S.shape}')\n    return __nn_filter_helper(rec_s.data, rec_s.indices, rec_s.indptr, S.swapaxes(0, axis), aggregate).swapaxes(0, axis)",
            "@cache(level=30)\ndef nn_filter(S: np.ndarray, *, rec: Optional[Union[scipy.sparse.spmatrix, np.ndarray]]=None, aggregate: Optional[Callable]=None, axis: int=-1, **kwargs: Any) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Filter by nearest-neighbor aggregation.\\n\\n    Each data point (e.g, spectrogram column) is replaced\\n    by aggregating its nearest neighbors in feature space.\\n\\n    This can be useful for de-noising a spectrogram or feature matrix.\\n\\n    The non-local means method [#]_ can be recovered by providing a\\n    weighted recurrence matrix as input and specifying ``aggregate=np.average``.\\n\\n    Similarly, setting ``aggregate=np.median`` produces sparse de-noising\\n    as in REPET-SIM [#]_.\\n\\n    .. [#] Buades, A., Coll, B., & Morel, J. M.\\n        (2005, June). A non-local algorithm for image denoising.\\n        In Computer Vision and Pattern Recognition, 2005.\\n        CVPR 2005. IEEE Computer Society Conference on (Vol. 2, pp. 60-65). IEEE.\\n\\n    .. [#] Rafii, Z., & Pardo, B.\\n        (2012, October).  \"Music/Voice Separation Using the Similarity Matrix.\"\\n        International Society for Music Information Retrieval Conference, 2012.\\n\\n    Parameters\\n    ----------\\n    S : np.ndarray\\n        The input data (spectrogram) to filter. Multi-channel is supported.\\n\\n    rec : (optional) scipy.sparse.spmatrix or np.ndarray\\n        Optionally, a pre-computed nearest-neighbor matrix\\n        as provided by `librosa.segment.recurrence_matrix`\\n\\n    aggregate : function\\n        aggregation function (default: `np.mean`)\\n\\n        If ``aggregate=np.average``, then a weighted average is\\n        computed according to the (per-row) weights in ``rec``.\\n\\n        For all other aggregation functions, all neighbors\\n        are treated equally.\\n\\n    axis : int\\n        The axis along which to filter (by default, columns)\\n\\n    **kwargs\\n        Additional keyword arguments provided to\\n        `librosa.segment.recurrence_matrix` if ``rec`` is not provided\\n\\n    Returns\\n    -------\\n    S_filtered : np.ndarray\\n        The filtered data, with shape equivalent to the input ``S``.\\n\\n    Raises\\n    ------\\n    ParameterError\\n        if ``rec`` is provided and its shape is incompatible with ``S``.\\n\\n    See Also\\n    --------\\n    decompose\\n    hpss\\n    librosa.segment.recurrence_matrix\\n\\n    Notes\\n    -----\\n    This function caches at level 30.\\n\\n    Examples\\n    --------\\n    De-noise a chromagram by non-local median filtering.\\n    By default this would use euclidean distance to select neighbors,\\n    but this can be overridden directly by setting the ``metric`` parameter.\\n\\n    >>> y, sr = librosa.load(librosa.ex(\\'brahms\\'),\\n    ...                      offset=30, duration=10)\\n    >>> chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\\n    >>> chroma_med = librosa.decompose.nn_filter(chroma,\\n    ...                                          aggregate=np.median,\\n    ...                                          metric=\\'cosine\\')\\n\\n    To use non-local means, provide an affinity matrix and ``aggregate=np.average``.\\n\\n    >>> rec = librosa.segment.recurrence_matrix(chroma, mode=\\'affinity\\',\\n    ...                                         metric=\\'cosine\\', sparse=True)\\n    >>> chroma_nlm = librosa.decompose.nn_filter(chroma, rec=rec,\\n    ...                                          aggregate=np.average)\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> fig, ax = plt.subplots(nrows=5, sharex=True, sharey=True, figsize=(10, 10))\\n    >>> librosa.display.specshow(chroma, y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[0])\\n    >>> ax[0].set(title=\\'Unfiltered\\')\\n    >>> ax[0].label_outer()\\n    >>> librosa.display.specshow(chroma_med, y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[1])\\n    >>> ax[1].set(title=\\'Median-filtered\\')\\n    >>> ax[1].label_outer()\\n    >>> imgc = librosa.display.specshow(chroma_nlm, y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[2])\\n    >>> ax[2].set(title=\\'Non-local means\\')\\n    >>> ax[2].label_outer()\\n    >>> imgr1 = librosa.display.specshow(chroma - chroma_med,\\n    ...                          y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[3])\\n    >>> ax[3].set(title=\\'Original - median\\')\\n    >>> ax[3].label_outer()\\n    >>> imgr2 = librosa.display.specshow(chroma - chroma_nlm,\\n    ...                          y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[4])\\n    >>> ax[4].label_outer()\\n    >>> ax[4].set(title=\\'Original - NLM\\')\\n    >>> fig.colorbar(imgc, ax=ax[:3])\\n    >>> fig.colorbar(imgr1, ax=[ax[3]])\\n    >>> fig.colorbar(imgr2, ax=[ax[4]])\\n    '\n    if aggregate is None:\n        aggregate = np.mean\n    rec_s: scipy.sparse.spmatrix\n    if rec is None:\n        kwargs = dict(kwargs)\n        kwargs['sparse'] = True\n        rec_s = segment.recurrence_matrix(S, axis=axis, **kwargs)\n    elif not scipy.sparse.issparse(rec):\n        rec_s = scipy.sparse.csc_matrix(rec)\n    else:\n        rec_s = rec\n    if rec_s.shape[0] != S.shape[axis] or rec_s.shape[0] != rec_s.shape[1]:\n        raise ParameterError(f'Invalid self-similarity matrix shape rec.shape={rec_s.shape} for S.shape={S.shape}')\n    return __nn_filter_helper(rec_s.data, rec_s.indices, rec_s.indptr, S.swapaxes(0, axis), aggregate).swapaxes(0, axis)",
            "@cache(level=30)\ndef nn_filter(S: np.ndarray, *, rec: Optional[Union[scipy.sparse.spmatrix, np.ndarray]]=None, aggregate: Optional[Callable]=None, axis: int=-1, **kwargs: Any) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Filter by nearest-neighbor aggregation.\\n\\n    Each data point (e.g, spectrogram column) is replaced\\n    by aggregating its nearest neighbors in feature space.\\n\\n    This can be useful for de-noising a spectrogram or feature matrix.\\n\\n    The non-local means method [#]_ can be recovered by providing a\\n    weighted recurrence matrix as input and specifying ``aggregate=np.average``.\\n\\n    Similarly, setting ``aggregate=np.median`` produces sparse de-noising\\n    as in REPET-SIM [#]_.\\n\\n    .. [#] Buades, A., Coll, B., & Morel, J. M.\\n        (2005, June). A non-local algorithm for image denoising.\\n        In Computer Vision and Pattern Recognition, 2005.\\n        CVPR 2005. IEEE Computer Society Conference on (Vol. 2, pp. 60-65). IEEE.\\n\\n    .. [#] Rafii, Z., & Pardo, B.\\n        (2012, October).  \"Music/Voice Separation Using the Similarity Matrix.\"\\n        International Society for Music Information Retrieval Conference, 2012.\\n\\n    Parameters\\n    ----------\\n    S : np.ndarray\\n        The input data (spectrogram) to filter. Multi-channel is supported.\\n\\n    rec : (optional) scipy.sparse.spmatrix or np.ndarray\\n        Optionally, a pre-computed nearest-neighbor matrix\\n        as provided by `librosa.segment.recurrence_matrix`\\n\\n    aggregate : function\\n        aggregation function (default: `np.mean`)\\n\\n        If ``aggregate=np.average``, then a weighted average is\\n        computed according to the (per-row) weights in ``rec``.\\n\\n        For all other aggregation functions, all neighbors\\n        are treated equally.\\n\\n    axis : int\\n        The axis along which to filter (by default, columns)\\n\\n    **kwargs\\n        Additional keyword arguments provided to\\n        `librosa.segment.recurrence_matrix` if ``rec`` is not provided\\n\\n    Returns\\n    -------\\n    S_filtered : np.ndarray\\n        The filtered data, with shape equivalent to the input ``S``.\\n\\n    Raises\\n    ------\\n    ParameterError\\n        if ``rec`` is provided and its shape is incompatible with ``S``.\\n\\n    See Also\\n    --------\\n    decompose\\n    hpss\\n    librosa.segment.recurrence_matrix\\n\\n    Notes\\n    -----\\n    This function caches at level 30.\\n\\n    Examples\\n    --------\\n    De-noise a chromagram by non-local median filtering.\\n    By default this would use euclidean distance to select neighbors,\\n    but this can be overridden directly by setting the ``metric`` parameter.\\n\\n    >>> y, sr = librosa.load(librosa.ex(\\'brahms\\'),\\n    ...                      offset=30, duration=10)\\n    >>> chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\\n    >>> chroma_med = librosa.decompose.nn_filter(chroma,\\n    ...                                          aggregate=np.median,\\n    ...                                          metric=\\'cosine\\')\\n\\n    To use non-local means, provide an affinity matrix and ``aggregate=np.average``.\\n\\n    >>> rec = librosa.segment.recurrence_matrix(chroma, mode=\\'affinity\\',\\n    ...                                         metric=\\'cosine\\', sparse=True)\\n    >>> chroma_nlm = librosa.decompose.nn_filter(chroma, rec=rec,\\n    ...                                          aggregate=np.average)\\n\\n    >>> import matplotlib.pyplot as plt\\n    >>> fig, ax = plt.subplots(nrows=5, sharex=True, sharey=True, figsize=(10, 10))\\n    >>> librosa.display.specshow(chroma, y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[0])\\n    >>> ax[0].set(title=\\'Unfiltered\\')\\n    >>> ax[0].label_outer()\\n    >>> librosa.display.specshow(chroma_med, y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[1])\\n    >>> ax[1].set(title=\\'Median-filtered\\')\\n    >>> ax[1].label_outer()\\n    >>> imgc = librosa.display.specshow(chroma_nlm, y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[2])\\n    >>> ax[2].set(title=\\'Non-local means\\')\\n    >>> ax[2].label_outer()\\n    >>> imgr1 = librosa.display.specshow(chroma - chroma_med,\\n    ...                          y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[3])\\n    >>> ax[3].set(title=\\'Original - median\\')\\n    >>> ax[3].label_outer()\\n    >>> imgr2 = librosa.display.specshow(chroma - chroma_nlm,\\n    ...                          y_axis=\\'chroma\\', x_axis=\\'time\\', ax=ax[4])\\n    >>> ax[4].label_outer()\\n    >>> ax[4].set(title=\\'Original - NLM\\')\\n    >>> fig.colorbar(imgc, ax=ax[:3])\\n    >>> fig.colorbar(imgr1, ax=[ax[3]])\\n    >>> fig.colorbar(imgr2, ax=[ax[4]])\\n    '\n    if aggregate is None:\n        aggregate = np.mean\n    rec_s: scipy.sparse.spmatrix\n    if rec is None:\n        kwargs = dict(kwargs)\n        kwargs['sparse'] = True\n        rec_s = segment.recurrence_matrix(S, axis=axis, **kwargs)\n    elif not scipy.sparse.issparse(rec):\n        rec_s = scipy.sparse.csc_matrix(rec)\n    else:\n        rec_s = rec\n    if rec_s.shape[0] != S.shape[axis] or rec_s.shape[0] != rec_s.shape[1]:\n        raise ParameterError(f'Invalid self-similarity matrix shape rec.shape={rec_s.shape} for S.shape={S.shape}')\n    return __nn_filter_helper(rec_s.data, rec_s.indices, rec_s.indptr, S.swapaxes(0, axis), aggregate).swapaxes(0, axis)"
        ]
    },
    {
        "func_name": "__nn_filter_helper",
        "original": "def __nn_filter_helper(R_data, R_indices, R_ptr, S: np.ndarray, aggregate: Callable) -> np.ndarray:\n    \"\"\"Nearest-neighbor filter helper function.\n\n    This is an internal function, not for use outside of the decompose module.\n\n    It applies the nearest-neighbor filter to S, assuming that the first index\n    corresponds to observations.\n\n    Parameters\n    ----------\n    R_data, R_indices, R_ptr : np.ndarrays\n        The ``data``, ``indices``, and ``indptr`` of a scipy.sparse matrix\n    S : np.ndarray\n        The observation data to filter\n    aggregate : callable\n        The aggregation operator\n\n    Returns\n    -------\n    S_out : np.ndarray like S\n        The filtered data array\n    \"\"\"\n    s_out = np.empty_like(S)\n    for i in range(len(R_ptr) - 1):\n        targets = R_indices[R_ptr[i]:R_ptr[i + 1]]\n        if not len(targets):\n            s_out[i] = S[i]\n            continue\n        neighbors = np.take(S, targets, axis=0)\n        if aggregate is np.average:\n            weights = R_data[R_ptr[i]:R_ptr[i + 1]]\n            s_out[i] = aggregate(neighbors, axis=0, weights=weights)\n        else:\n            s_out[i] = aggregate(neighbors, axis=0)\n    return s_out",
        "mutated": [
            "def __nn_filter_helper(R_data, R_indices, R_ptr, S: np.ndarray, aggregate: Callable) -> np.ndarray:\n    if False:\n        i = 10\n    'Nearest-neighbor filter helper function.\\n\\n    This is an internal function, not for use outside of the decompose module.\\n\\n    It applies the nearest-neighbor filter to S, assuming that the first index\\n    corresponds to observations.\\n\\n    Parameters\\n    ----------\\n    R_data, R_indices, R_ptr : np.ndarrays\\n        The ``data``, ``indices``, and ``indptr`` of a scipy.sparse matrix\\n    S : np.ndarray\\n        The observation data to filter\\n    aggregate : callable\\n        The aggregation operator\\n\\n    Returns\\n    -------\\n    S_out : np.ndarray like S\\n        The filtered data array\\n    '\n    s_out = np.empty_like(S)\n    for i in range(len(R_ptr) - 1):\n        targets = R_indices[R_ptr[i]:R_ptr[i + 1]]\n        if not len(targets):\n            s_out[i] = S[i]\n            continue\n        neighbors = np.take(S, targets, axis=0)\n        if aggregate is np.average:\n            weights = R_data[R_ptr[i]:R_ptr[i + 1]]\n            s_out[i] = aggregate(neighbors, axis=0, weights=weights)\n        else:\n            s_out[i] = aggregate(neighbors, axis=0)\n    return s_out",
            "def __nn_filter_helper(R_data, R_indices, R_ptr, S: np.ndarray, aggregate: Callable) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Nearest-neighbor filter helper function.\\n\\n    This is an internal function, not for use outside of the decompose module.\\n\\n    It applies the nearest-neighbor filter to S, assuming that the first index\\n    corresponds to observations.\\n\\n    Parameters\\n    ----------\\n    R_data, R_indices, R_ptr : np.ndarrays\\n        The ``data``, ``indices``, and ``indptr`` of a scipy.sparse matrix\\n    S : np.ndarray\\n        The observation data to filter\\n    aggregate : callable\\n        The aggregation operator\\n\\n    Returns\\n    -------\\n    S_out : np.ndarray like S\\n        The filtered data array\\n    '\n    s_out = np.empty_like(S)\n    for i in range(len(R_ptr) - 1):\n        targets = R_indices[R_ptr[i]:R_ptr[i + 1]]\n        if not len(targets):\n            s_out[i] = S[i]\n            continue\n        neighbors = np.take(S, targets, axis=0)\n        if aggregate is np.average:\n            weights = R_data[R_ptr[i]:R_ptr[i + 1]]\n            s_out[i] = aggregate(neighbors, axis=0, weights=weights)\n        else:\n            s_out[i] = aggregate(neighbors, axis=0)\n    return s_out",
            "def __nn_filter_helper(R_data, R_indices, R_ptr, S: np.ndarray, aggregate: Callable) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Nearest-neighbor filter helper function.\\n\\n    This is an internal function, not for use outside of the decompose module.\\n\\n    It applies the nearest-neighbor filter to S, assuming that the first index\\n    corresponds to observations.\\n\\n    Parameters\\n    ----------\\n    R_data, R_indices, R_ptr : np.ndarrays\\n        The ``data``, ``indices``, and ``indptr`` of a scipy.sparse matrix\\n    S : np.ndarray\\n        The observation data to filter\\n    aggregate : callable\\n        The aggregation operator\\n\\n    Returns\\n    -------\\n    S_out : np.ndarray like S\\n        The filtered data array\\n    '\n    s_out = np.empty_like(S)\n    for i in range(len(R_ptr) - 1):\n        targets = R_indices[R_ptr[i]:R_ptr[i + 1]]\n        if not len(targets):\n            s_out[i] = S[i]\n            continue\n        neighbors = np.take(S, targets, axis=0)\n        if aggregate is np.average:\n            weights = R_data[R_ptr[i]:R_ptr[i + 1]]\n            s_out[i] = aggregate(neighbors, axis=0, weights=weights)\n        else:\n            s_out[i] = aggregate(neighbors, axis=0)\n    return s_out",
            "def __nn_filter_helper(R_data, R_indices, R_ptr, S: np.ndarray, aggregate: Callable) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Nearest-neighbor filter helper function.\\n\\n    This is an internal function, not for use outside of the decompose module.\\n\\n    It applies the nearest-neighbor filter to S, assuming that the first index\\n    corresponds to observations.\\n\\n    Parameters\\n    ----------\\n    R_data, R_indices, R_ptr : np.ndarrays\\n        The ``data``, ``indices``, and ``indptr`` of a scipy.sparse matrix\\n    S : np.ndarray\\n        The observation data to filter\\n    aggregate : callable\\n        The aggregation operator\\n\\n    Returns\\n    -------\\n    S_out : np.ndarray like S\\n        The filtered data array\\n    '\n    s_out = np.empty_like(S)\n    for i in range(len(R_ptr) - 1):\n        targets = R_indices[R_ptr[i]:R_ptr[i + 1]]\n        if not len(targets):\n            s_out[i] = S[i]\n            continue\n        neighbors = np.take(S, targets, axis=0)\n        if aggregate is np.average:\n            weights = R_data[R_ptr[i]:R_ptr[i + 1]]\n            s_out[i] = aggregate(neighbors, axis=0, weights=weights)\n        else:\n            s_out[i] = aggregate(neighbors, axis=0)\n    return s_out",
            "def __nn_filter_helper(R_data, R_indices, R_ptr, S: np.ndarray, aggregate: Callable) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Nearest-neighbor filter helper function.\\n\\n    This is an internal function, not for use outside of the decompose module.\\n\\n    It applies the nearest-neighbor filter to S, assuming that the first index\\n    corresponds to observations.\\n\\n    Parameters\\n    ----------\\n    R_data, R_indices, R_ptr : np.ndarrays\\n        The ``data``, ``indices``, and ``indptr`` of a scipy.sparse matrix\\n    S : np.ndarray\\n        The observation data to filter\\n    aggregate : callable\\n        The aggregation operator\\n\\n    Returns\\n    -------\\n    S_out : np.ndarray like S\\n        The filtered data array\\n    '\n    s_out = np.empty_like(S)\n    for i in range(len(R_ptr) - 1):\n        targets = R_indices[R_ptr[i]:R_ptr[i + 1]]\n        if not len(targets):\n            s_out[i] = S[i]\n            continue\n        neighbors = np.take(S, targets, axis=0)\n        if aggregate is np.average:\n            weights = R_data[R_ptr[i]:R_ptr[i + 1]]\n            s_out[i] = aggregate(neighbors, axis=0, weights=weights)\n        else:\n            s_out[i] = aggregate(neighbors, axis=0)\n    return s_out"
        ]
    }
]