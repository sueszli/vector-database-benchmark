[
    {
        "func_name": "_train_dataset_process",
        "original": "def _train_dataset_process(dataset_name, results_queue):\n    \"\"\"Runs each train job in a new process.\"\"\"\n    load_start_time = time.time()\n    dataset = datasets.get_dataset(dataset_name)\n    config = dataset.default_model_config\n    df = dataset.load()\n    load_end_time = time.time()\n    if 'split' not in df:\n        df['split'] = 0\n    available_splits = sorted(df.split.unique())\n    results = TrainingResults(LUDWIG_VERSION, get_commit_hash(), dataset.version, dataset.name, config is not None, splits=' '.join([str(s) for s in available_splits]), load_time=load_end_time - load_start_time)\n    if config:\n        dataset.export('.')\n        print(f'Training {dataset_name}')\n        train_start_time = time.time()\n        model = LudwigModel(config)\n        (train_stats, _, output_directory) = model.train(dataset=df, model_name=dataset_name)\n        evaluate_start_time = time.time()\n        (eval_stats, _, _) = model.evaluate(df, split=2 if 2 in available_splits else 0, collect_predictions=False, collect_overall_stats=True)\n        evaluate_end_time = time.time()\n        visualize.learning_curves([train_stats], model_names=[dataset_name], output_directory=output_directory)\n        results.output_directory = output_directory\n        first_of_name = config['output_features'][0]['name']\n        stats = eval_stats[first_of_name]\n        if 'accuracy' in stats:\n            results.metric = 'accuracy'\n            results.performance = stats['accuracy']\n        elif 'root_mean_squared_error' in stats:\n            results.metric = 'root_mean_squared_error'\n            results.performance = stats['root_mean_squared_error']\n        elif 'mean_squared_error' in stats:\n            results.metric = 'mean_squared_error'\n            results.performance = stats['mean_squared_error']\n        elif 'mean_absolute_error' in stats:\n            results.metric = 'mean_absolute_error'\n            results.performance = stats['mean_absolute_error']\n        elif 'loss' in stats:\n            results.metric = 'loss'\n            results.performance = stats['loss']\n        results.train_time = evaluate_start_time - train_start_time\n        results.eval_time = evaluate_end_time - evaluate_start_time\n        print(f'Trained {dataset_name} in {evaluate_end_time - load_start_time:.2f} seconds')\n    results_queue.put(results)",
        "mutated": [
            "def _train_dataset_process(dataset_name, results_queue):\n    if False:\n        i = 10\n    'Runs each train job in a new process.'\n    load_start_time = time.time()\n    dataset = datasets.get_dataset(dataset_name)\n    config = dataset.default_model_config\n    df = dataset.load()\n    load_end_time = time.time()\n    if 'split' not in df:\n        df['split'] = 0\n    available_splits = sorted(df.split.unique())\n    results = TrainingResults(LUDWIG_VERSION, get_commit_hash(), dataset.version, dataset.name, config is not None, splits=' '.join([str(s) for s in available_splits]), load_time=load_end_time - load_start_time)\n    if config:\n        dataset.export('.')\n        print(f'Training {dataset_name}')\n        train_start_time = time.time()\n        model = LudwigModel(config)\n        (train_stats, _, output_directory) = model.train(dataset=df, model_name=dataset_name)\n        evaluate_start_time = time.time()\n        (eval_stats, _, _) = model.evaluate(df, split=2 if 2 in available_splits else 0, collect_predictions=False, collect_overall_stats=True)\n        evaluate_end_time = time.time()\n        visualize.learning_curves([train_stats], model_names=[dataset_name], output_directory=output_directory)\n        results.output_directory = output_directory\n        first_of_name = config['output_features'][0]['name']\n        stats = eval_stats[first_of_name]\n        if 'accuracy' in stats:\n            results.metric = 'accuracy'\n            results.performance = stats['accuracy']\n        elif 'root_mean_squared_error' in stats:\n            results.metric = 'root_mean_squared_error'\n            results.performance = stats['root_mean_squared_error']\n        elif 'mean_squared_error' in stats:\n            results.metric = 'mean_squared_error'\n            results.performance = stats['mean_squared_error']\n        elif 'mean_absolute_error' in stats:\n            results.metric = 'mean_absolute_error'\n            results.performance = stats['mean_absolute_error']\n        elif 'loss' in stats:\n            results.metric = 'loss'\n            results.performance = stats['loss']\n        results.train_time = evaluate_start_time - train_start_time\n        results.eval_time = evaluate_end_time - evaluate_start_time\n        print(f'Trained {dataset_name} in {evaluate_end_time - load_start_time:.2f} seconds')\n    results_queue.put(results)",
            "def _train_dataset_process(dataset_name, results_queue):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Runs each train job in a new process.'\n    load_start_time = time.time()\n    dataset = datasets.get_dataset(dataset_name)\n    config = dataset.default_model_config\n    df = dataset.load()\n    load_end_time = time.time()\n    if 'split' not in df:\n        df['split'] = 0\n    available_splits = sorted(df.split.unique())\n    results = TrainingResults(LUDWIG_VERSION, get_commit_hash(), dataset.version, dataset.name, config is not None, splits=' '.join([str(s) for s in available_splits]), load_time=load_end_time - load_start_time)\n    if config:\n        dataset.export('.')\n        print(f'Training {dataset_name}')\n        train_start_time = time.time()\n        model = LudwigModel(config)\n        (train_stats, _, output_directory) = model.train(dataset=df, model_name=dataset_name)\n        evaluate_start_time = time.time()\n        (eval_stats, _, _) = model.evaluate(df, split=2 if 2 in available_splits else 0, collect_predictions=False, collect_overall_stats=True)\n        evaluate_end_time = time.time()\n        visualize.learning_curves([train_stats], model_names=[dataset_name], output_directory=output_directory)\n        results.output_directory = output_directory\n        first_of_name = config['output_features'][0]['name']\n        stats = eval_stats[first_of_name]\n        if 'accuracy' in stats:\n            results.metric = 'accuracy'\n            results.performance = stats['accuracy']\n        elif 'root_mean_squared_error' in stats:\n            results.metric = 'root_mean_squared_error'\n            results.performance = stats['root_mean_squared_error']\n        elif 'mean_squared_error' in stats:\n            results.metric = 'mean_squared_error'\n            results.performance = stats['mean_squared_error']\n        elif 'mean_absolute_error' in stats:\n            results.metric = 'mean_absolute_error'\n            results.performance = stats['mean_absolute_error']\n        elif 'loss' in stats:\n            results.metric = 'loss'\n            results.performance = stats['loss']\n        results.train_time = evaluate_start_time - train_start_time\n        results.eval_time = evaluate_end_time - evaluate_start_time\n        print(f'Trained {dataset_name} in {evaluate_end_time - load_start_time:.2f} seconds')\n    results_queue.put(results)",
            "def _train_dataset_process(dataset_name, results_queue):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Runs each train job in a new process.'\n    load_start_time = time.time()\n    dataset = datasets.get_dataset(dataset_name)\n    config = dataset.default_model_config\n    df = dataset.load()\n    load_end_time = time.time()\n    if 'split' not in df:\n        df['split'] = 0\n    available_splits = sorted(df.split.unique())\n    results = TrainingResults(LUDWIG_VERSION, get_commit_hash(), dataset.version, dataset.name, config is not None, splits=' '.join([str(s) for s in available_splits]), load_time=load_end_time - load_start_time)\n    if config:\n        dataset.export('.')\n        print(f'Training {dataset_name}')\n        train_start_time = time.time()\n        model = LudwigModel(config)\n        (train_stats, _, output_directory) = model.train(dataset=df, model_name=dataset_name)\n        evaluate_start_time = time.time()\n        (eval_stats, _, _) = model.evaluate(df, split=2 if 2 in available_splits else 0, collect_predictions=False, collect_overall_stats=True)\n        evaluate_end_time = time.time()\n        visualize.learning_curves([train_stats], model_names=[dataset_name], output_directory=output_directory)\n        results.output_directory = output_directory\n        first_of_name = config['output_features'][0]['name']\n        stats = eval_stats[first_of_name]\n        if 'accuracy' in stats:\n            results.metric = 'accuracy'\n            results.performance = stats['accuracy']\n        elif 'root_mean_squared_error' in stats:\n            results.metric = 'root_mean_squared_error'\n            results.performance = stats['root_mean_squared_error']\n        elif 'mean_squared_error' in stats:\n            results.metric = 'mean_squared_error'\n            results.performance = stats['mean_squared_error']\n        elif 'mean_absolute_error' in stats:\n            results.metric = 'mean_absolute_error'\n            results.performance = stats['mean_absolute_error']\n        elif 'loss' in stats:\n            results.metric = 'loss'\n            results.performance = stats['loss']\n        results.train_time = evaluate_start_time - train_start_time\n        results.eval_time = evaluate_end_time - evaluate_start_time\n        print(f'Trained {dataset_name} in {evaluate_end_time - load_start_time:.2f} seconds')\n    results_queue.put(results)",
            "def _train_dataset_process(dataset_name, results_queue):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Runs each train job in a new process.'\n    load_start_time = time.time()\n    dataset = datasets.get_dataset(dataset_name)\n    config = dataset.default_model_config\n    df = dataset.load()\n    load_end_time = time.time()\n    if 'split' not in df:\n        df['split'] = 0\n    available_splits = sorted(df.split.unique())\n    results = TrainingResults(LUDWIG_VERSION, get_commit_hash(), dataset.version, dataset.name, config is not None, splits=' '.join([str(s) for s in available_splits]), load_time=load_end_time - load_start_time)\n    if config:\n        dataset.export('.')\n        print(f'Training {dataset_name}')\n        train_start_time = time.time()\n        model = LudwigModel(config)\n        (train_stats, _, output_directory) = model.train(dataset=df, model_name=dataset_name)\n        evaluate_start_time = time.time()\n        (eval_stats, _, _) = model.evaluate(df, split=2 if 2 in available_splits else 0, collect_predictions=False, collect_overall_stats=True)\n        evaluate_end_time = time.time()\n        visualize.learning_curves([train_stats], model_names=[dataset_name], output_directory=output_directory)\n        results.output_directory = output_directory\n        first_of_name = config['output_features'][0]['name']\n        stats = eval_stats[first_of_name]\n        if 'accuracy' in stats:\n            results.metric = 'accuracy'\n            results.performance = stats['accuracy']\n        elif 'root_mean_squared_error' in stats:\n            results.metric = 'root_mean_squared_error'\n            results.performance = stats['root_mean_squared_error']\n        elif 'mean_squared_error' in stats:\n            results.metric = 'mean_squared_error'\n            results.performance = stats['mean_squared_error']\n        elif 'mean_absolute_error' in stats:\n            results.metric = 'mean_absolute_error'\n            results.performance = stats['mean_absolute_error']\n        elif 'loss' in stats:\n            results.metric = 'loss'\n            results.performance = stats['loss']\n        results.train_time = evaluate_start_time - train_start_time\n        results.eval_time = evaluate_end_time - evaluate_start_time\n        print(f'Trained {dataset_name} in {evaluate_end_time - load_start_time:.2f} seconds')\n    results_queue.put(results)",
            "def _train_dataset_process(dataset_name, results_queue):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Runs each train job in a new process.'\n    load_start_time = time.time()\n    dataset = datasets.get_dataset(dataset_name)\n    config = dataset.default_model_config\n    df = dataset.load()\n    load_end_time = time.time()\n    if 'split' not in df:\n        df['split'] = 0\n    available_splits = sorted(df.split.unique())\n    results = TrainingResults(LUDWIG_VERSION, get_commit_hash(), dataset.version, dataset.name, config is not None, splits=' '.join([str(s) for s in available_splits]), load_time=load_end_time - load_start_time)\n    if config:\n        dataset.export('.')\n        print(f'Training {dataset_name}')\n        train_start_time = time.time()\n        model = LudwigModel(config)\n        (train_stats, _, output_directory) = model.train(dataset=df, model_name=dataset_name)\n        evaluate_start_time = time.time()\n        (eval_stats, _, _) = model.evaluate(df, split=2 if 2 in available_splits else 0, collect_predictions=False, collect_overall_stats=True)\n        evaluate_end_time = time.time()\n        visualize.learning_curves([train_stats], model_names=[dataset_name], output_directory=output_directory)\n        results.output_directory = output_directory\n        first_of_name = config['output_features'][0]['name']\n        stats = eval_stats[first_of_name]\n        if 'accuracy' in stats:\n            results.metric = 'accuracy'\n            results.performance = stats['accuracy']\n        elif 'root_mean_squared_error' in stats:\n            results.metric = 'root_mean_squared_error'\n            results.performance = stats['root_mean_squared_error']\n        elif 'mean_squared_error' in stats:\n            results.metric = 'mean_squared_error'\n            results.performance = stats['mean_squared_error']\n        elif 'mean_absolute_error' in stats:\n            results.metric = 'mean_absolute_error'\n            results.performance = stats['mean_absolute_error']\n        elif 'loss' in stats:\n            results.metric = 'loss'\n            results.performance = stats['loss']\n        results.train_time = evaluate_start_time - train_start_time\n        results.eval_time = evaluate_end_time - evaluate_start_time\n        print(f'Trained {dataset_name} in {evaluate_end_time - load_start_time:.2f} seconds')\n    results_queue.put(results)"
        ]
    },
    {
        "func_name": "train_all_datasets",
        "original": "def train_all_datasets():\n    max_processes = 4\n    running_processes = {}\n    accumulated_results = []\n    results_queue = multiprocessing.Queue()\n    for dataset_name in datasets.list_datasets():\n        if len(running_processes) >= max_processes:\n            next_results = results_queue.get()\n            accumulated_results.append(next_results)\n            process = running_processes[next_results.dataset_name]\n            process.join()\n            del running_processes[next_results.dataset_name]\n        process = multiprocessing.Process(target=_train_dataset_process, args=[dataset_name, results_queue])\n        running_processes[dataset_name] = process\n        process.start()\n    while len(running_processes) > 0:\n        if len(running_processes) < 4:\n            remaining_datasets = ', '.join(sorted(running_processes.keys()))\n            print(f'Finishing up, waiting for {len(running_processes)} to complete ({remaining_datasets})')\n        else:\n            print(f'Finishing up, waiting for {len(running_processes)} to complete')\n        next_results = results_queue.get()\n        accumulated_results.append(next_results)\n        process = running_processes[next_results.dataset_name]\n        process.join()\n        del running_processes[next_results.dataset_name]\n    results_df = pd.DataFrame(accumulated_results)\n    with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.precision', 3, 'display.width', 120):\n        results_to_display = results_df[results_df['has_config']].copy()\n        results_to_display = results_to_display.drop(columns=['dataset_version', 'output_directory', 'ludwig_version', 'ludwig_commit', 'has_config'])\n        print(results_to_display)\n    results_df.to_csv('train_all_model_configs_results.csv', index=False)",
        "mutated": [
            "def train_all_datasets():\n    if False:\n        i = 10\n    max_processes = 4\n    running_processes = {}\n    accumulated_results = []\n    results_queue = multiprocessing.Queue()\n    for dataset_name in datasets.list_datasets():\n        if len(running_processes) >= max_processes:\n            next_results = results_queue.get()\n            accumulated_results.append(next_results)\n            process = running_processes[next_results.dataset_name]\n            process.join()\n            del running_processes[next_results.dataset_name]\n        process = multiprocessing.Process(target=_train_dataset_process, args=[dataset_name, results_queue])\n        running_processes[dataset_name] = process\n        process.start()\n    while len(running_processes) > 0:\n        if len(running_processes) < 4:\n            remaining_datasets = ', '.join(sorted(running_processes.keys()))\n            print(f'Finishing up, waiting for {len(running_processes)} to complete ({remaining_datasets})')\n        else:\n            print(f'Finishing up, waiting for {len(running_processes)} to complete')\n        next_results = results_queue.get()\n        accumulated_results.append(next_results)\n        process = running_processes[next_results.dataset_name]\n        process.join()\n        del running_processes[next_results.dataset_name]\n    results_df = pd.DataFrame(accumulated_results)\n    with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.precision', 3, 'display.width', 120):\n        results_to_display = results_df[results_df['has_config']].copy()\n        results_to_display = results_to_display.drop(columns=['dataset_version', 'output_directory', 'ludwig_version', 'ludwig_commit', 'has_config'])\n        print(results_to_display)\n    results_df.to_csv('train_all_model_configs_results.csv', index=False)",
            "def train_all_datasets():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    max_processes = 4\n    running_processes = {}\n    accumulated_results = []\n    results_queue = multiprocessing.Queue()\n    for dataset_name in datasets.list_datasets():\n        if len(running_processes) >= max_processes:\n            next_results = results_queue.get()\n            accumulated_results.append(next_results)\n            process = running_processes[next_results.dataset_name]\n            process.join()\n            del running_processes[next_results.dataset_name]\n        process = multiprocessing.Process(target=_train_dataset_process, args=[dataset_name, results_queue])\n        running_processes[dataset_name] = process\n        process.start()\n    while len(running_processes) > 0:\n        if len(running_processes) < 4:\n            remaining_datasets = ', '.join(sorted(running_processes.keys()))\n            print(f'Finishing up, waiting for {len(running_processes)} to complete ({remaining_datasets})')\n        else:\n            print(f'Finishing up, waiting for {len(running_processes)} to complete')\n        next_results = results_queue.get()\n        accumulated_results.append(next_results)\n        process = running_processes[next_results.dataset_name]\n        process.join()\n        del running_processes[next_results.dataset_name]\n    results_df = pd.DataFrame(accumulated_results)\n    with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.precision', 3, 'display.width', 120):\n        results_to_display = results_df[results_df['has_config']].copy()\n        results_to_display = results_to_display.drop(columns=['dataset_version', 'output_directory', 'ludwig_version', 'ludwig_commit', 'has_config'])\n        print(results_to_display)\n    results_df.to_csv('train_all_model_configs_results.csv', index=False)",
            "def train_all_datasets():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    max_processes = 4\n    running_processes = {}\n    accumulated_results = []\n    results_queue = multiprocessing.Queue()\n    for dataset_name in datasets.list_datasets():\n        if len(running_processes) >= max_processes:\n            next_results = results_queue.get()\n            accumulated_results.append(next_results)\n            process = running_processes[next_results.dataset_name]\n            process.join()\n            del running_processes[next_results.dataset_name]\n        process = multiprocessing.Process(target=_train_dataset_process, args=[dataset_name, results_queue])\n        running_processes[dataset_name] = process\n        process.start()\n    while len(running_processes) > 0:\n        if len(running_processes) < 4:\n            remaining_datasets = ', '.join(sorted(running_processes.keys()))\n            print(f'Finishing up, waiting for {len(running_processes)} to complete ({remaining_datasets})')\n        else:\n            print(f'Finishing up, waiting for {len(running_processes)} to complete')\n        next_results = results_queue.get()\n        accumulated_results.append(next_results)\n        process = running_processes[next_results.dataset_name]\n        process.join()\n        del running_processes[next_results.dataset_name]\n    results_df = pd.DataFrame(accumulated_results)\n    with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.precision', 3, 'display.width', 120):\n        results_to_display = results_df[results_df['has_config']].copy()\n        results_to_display = results_to_display.drop(columns=['dataset_version', 'output_directory', 'ludwig_version', 'ludwig_commit', 'has_config'])\n        print(results_to_display)\n    results_df.to_csv('train_all_model_configs_results.csv', index=False)",
            "def train_all_datasets():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    max_processes = 4\n    running_processes = {}\n    accumulated_results = []\n    results_queue = multiprocessing.Queue()\n    for dataset_name in datasets.list_datasets():\n        if len(running_processes) >= max_processes:\n            next_results = results_queue.get()\n            accumulated_results.append(next_results)\n            process = running_processes[next_results.dataset_name]\n            process.join()\n            del running_processes[next_results.dataset_name]\n        process = multiprocessing.Process(target=_train_dataset_process, args=[dataset_name, results_queue])\n        running_processes[dataset_name] = process\n        process.start()\n    while len(running_processes) > 0:\n        if len(running_processes) < 4:\n            remaining_datasets = ', '.join(sorted(running_processes.keys()))\n            print(f'Finishing up, waiting for {len(running_processes)} to complete ({remaining_datasets})')\n        else:\n            print(f'Finishing up, waiting for {len(running_processes)} to complete')\n        next_results = results_queue.get()\n        accumulated_results.append(next_results)\n        process = running_processes[next_results.dataset_name]\n        process.join()\n        del running_processes[next_results.dataset_name]\n    results_df = pd.DataFrame(accumulated_results)\n    with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.precision', 3, 'display.width', 120):\n        results_to_display = results_df[results_df['has_config']].copy()\n        results_to_display = results_to_display.drop(columns=['dataset_version', 'output_directory', 'ludwig_version', 'ludwig_commit', 'has_config'])\n        print(results_to_display)\n    results_df.to_csv('train_all_model_configs_results.csv', index=False)",
            "def train_all_datasets():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    max_processes = 4\n    running_processes = {}\n    accumulated_results = []\n    results_queue = multiprocessing.Queue()\n    for dataset_name in datasets.list_datasets():\n        if len(running_processes) >= max_processes:\n            next_results = results_queue.get()\n            accumulated_results.append(next_results)\n            process = running_processes[next_results.dataset_name]\n            process.join()\n            del running_processes[next_results.dataset_name]\n        process = multiprocessing.Process(target=_train_dataset_process, args=[dataset_name, results_queue])\n        running_processes[dataset_name] = process\n        process.start()\n    while len(running_processes) > 0:\n        if len(running_processes) < 4:\n            remaining_datasets = ', '.join(sorted(running_processes.keys()))\n            print(f'Finishing up, waiting for {len(running_processes)} to complete ({remaining_datasets})')\n        else:\n            print(f'Finishing up, waiting for {len(running_processes)} to complete')\n        next_results = results_queue.get()\n        accumulated_results.append(next_results)\n        process = running_processes[next_results.dataset_name]\n        process.join()\n        del running_processes[next_results.dataset_name]\n    results_df = pd.DataFrame(accumulated_results)\n    with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.precision', 3, 'display.width', 120):\n        results_to_display = results_df[results_df['has_config']].copy()\n        results_to_display = results_to_display.drop(columns=['dataset_version', 'output_directory', 'ludwig_version', 'ludwig_commit', 'has_config'])\n        print(results_to_display)\n    results_df.to_csv('train_all_model_configs_results.csv', index=False)"
        ]
    }
]