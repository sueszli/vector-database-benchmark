[
    {
        "func_name": "__init__",
        "original": "def __init__(self, path, pathlog, param, Model_name, rupture_set, sample, Domain_in_model, selected_ScL, dimention_used, use_all_ScL_data, mfd_param, mfd_hyp, bg_ratio, calculation_log_file, faults_names, scenarios_names, faults_data, faults_lon, faults_lat, list_fbg, fbgpath, branch):\n    self.Run_Name = param['Run_Name']\n    self.param = param\n    self.Domain_in_the_model = Domain_in_model\n    self.rupture_set = rupture_set\n    self.Model_name = Model_name\n    self.mfd_param = mfd_param\n    self.mfd_hyp = mfd_hyp\n    self.sample = sample\n    self.path = path\n    self.pathlog = pathlog\n    np.random.seed = param['main']['parameters']['Random_seed']\n    self.Mmin = param['main']['parameters']['Mmin']\n    self.selected_ScL = selected_ScL\n    self.dimention_used = dimention_used\n    self.use_all_ScL_data = use_all_ScL_data\n    self.bg_ratio = bg_ratio\n    self.sr_correl = param['main']['parameters']['SR_correl']\n    self.size_of_increment = param['main']['parameters']['dsr']\n    self.fit_quality = param['main']['parameters']['fit_quality'] / 100.0\n    self.Mmax_range = param['main']['parameters']['Mmax_range']\n    self.calculation_log_file = calculation_log_file\n    if not param['main']['background']['option_bg'] in ['None', 'none']:\n        self.File_bg = param['dirpath'] + param['main']['background']['File_bg']\n    if param['main']['background']['option_bg'] == 'zone':\n        if param['main']['background']['use_host_model'] in ['true', 'True']:\n            self.use_host_model = True\n            self.host_model_file = param['dirpath'] + param['main']['background']['host_model_file']\n        self.file_prop_bg = param['dirpath'] + param['main']['background']['file_prop_bg']\n    self.faults_names = faults_names\n    self.scenarios_names = scenarios_names\n    self.faults_data = faults_data\n    (self.faults_lon, self.faults_lat) = (faults_lon, faults_lat)\n    self.list_fbg = list_fbg\n    self.fbgpath = fbgpath\n    self.branch = branch\n    self.initialize()",
        "mutated": [
            "def __init__(self, path, pathlog, param, Model_name, rupture_set, sample, Domain_in_model, selected_ScL, dimention_used, use_all_ScL_data, mfd_param, mfd_hyp, bg_ratio, calculation_log_file, faults_names, scenarios_names, faults_data, faults_lon, faults_lat, list_fbg, fbgpath, branch):\n    if False:\n        i = 10\n    self.Run_Name = param['Run_Name']\n    self.param = param\n    self.Domain_in_the_model = Domain_in_model\n    self.rupture_set = rupture_set\n    self.Model_name = Model_name\n    self.mfd_param = mfd_param\n    self.mfd_hyp = mfd_hyp\n    self.sample = sample\n    self.path = path\n    self.pathlog = pathlog\n    np.random.seed = param['main']['parameters']['Random_seed']\n    self.Mmin = param['main']['parameters']['Mmin']\n    self.selected_ScL = selected_ScL\n    self.dimention_used = dimention_used\n    self.use_all_ScL_data = use_all_ScL_data\n    self.bg_ratio = bg_ratio\n    self.sr_correl = param['main']['parameters']['SR_correl']\n    self.size_of_increment = param['main']['parameters']['dsr']\n    self.fit_quality = param['main']['parameters']['fit_quality'] / 100.0\n    self.Mmax_range = param['main']['parameters']['Mmax_range']\n    self.calculation_log_file = calculation_log_file\n    if not param['main']['background']['option_bg'] in ['None', 'none']:\n        self.File_bg = param['dirpath'] + param['main']['background']['File_bg']\n    if param['main']['background']['option_bg'] == 'zone':\n        if param['main']['background']['use_host_model'] in ['true', 'True']:\n            self.use_host_model = True\n            self.host_model_file = param['dirpath'] + param['main']['background']['host_model_file']\n        self.file_prop_bg = param['dirpath'] + param['main']['background']['file_prop_bg']\n    self.faults_names = faults_names\n    self.scenarios_names = scenarios_names\n    self.faults_data = faults_data\n    (self.faults_lon, self.faults_lat) = (faults_lon, faults_lat)\n    self.list_fbg = list_fbg\n    self.fbgpath = fbgpath\n    self.branch = branch\n    self.initialize()",
            "def __init__(self, path, pathlog, param, Model_name, rupture_set, sample, Domain_in_model, selected_ScL, dimention_used, use_all_ScL_data, mfd_param, mfd_hyp, bg_ratio, calculation_log_file, faults_names, scenarios_names, faults_data, faults_lon, faults_lat, list_fbg, fbgpath, branch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.Run_Name = param['Run_Name']\n    self.param = param\n    self.Domain_in_the_model = Domain_in_model\n    self.rupture_set = rupture_set\n    self.Model_name = Model_name\n    self.mfd_param = mfd_param\n    self.mfd_hyp = mfd_hyp\n    self.sample = sample\n    self.path = path\n    self.pathlog = pathlog\n    np.random.seed = param['main']['parameters']['Random_seed']\n    self.Mmin = param['main']['parameters']['Mmin']\n    self.selected_ScL = selected_ScL\n    self.dimention_used = dimention_used\n    self.use_all_ScL_data = use_all_ScL_data\n    self.bg_ratio = bg_ratio\n    self.sr_correl = param['main']['parameters']['SR_correl']\n    self.size_of_increment = param['main']['parameters']['dsr']\n    self.fit_quality = param['main']['parameters']['fit_quality'] / 100.0\n    self.Mmax_range = param['main']['parameters']['Mmax_range']\n    self.calculation_log_file = calculation_log_file\n    if not param['main']['background']['option_bg'] in ['None', 'none']:\n        self.File_bg = param['dirpath'] + param['main']['background']['File_bg']\n    if param['main']['background']['option_bg'] == 'zone':\n        if param['main']['background']['use_host_model'] in ['true', 'True']:\n            self.use_host_model = True\n            self.host_model_file = param['dirpath'] + param['main']['background']['host_model_file']\n        self.file_prop_bg = param['dirpath'] + param['main']['background']['file_prop_bg']\n    self.faults_names = faults_names\n    self.scenarios_names = scenarios_names\n    self.faults_data = faults_data\n    (self.faults_lon, self.faults_lat) = (faults_lon, faults_lat)\n    self.list_fbg = list_fbg\n    self.fbgpath = fbgpath\n    self.branch = branch\n    self.initialize()",
            "def __init__(self, path, pathlog, param, Model_name, rupture_set, sample, Domain_in_model, selected_ScL, dimention_used, use_all_ScL_data, mfd_param, mfd_hyp, bg_ratio, calculation_log_file, faults_names, scenarios_names, faults_data, faults_lon, faults_lat, list_fbg, fbgpath, branch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.Run_Name = param['Run_Name']\n    self.param = param\n    self.Domain_in_the_model = Domain_in_model\n    self.rupture_set = rupture_set\n    self.Model_name = Model_name\n    self.mfd_param = mfd_param\n    self.mfd_hyp = mfd_hyp\n    self.sample = sample\n    self.path = path\n    self.pathlog = pathlog\n    np.random.seed = param['main']['parameters']['Random_seed']\n    self.Mmin = param['main']['parameters']['Mmin']\n    self.selected_ScL = selected_ScL\n    self.dimention_used = dimention_used\n    self.use_all_ScL_data = use_all_ScL_data\n    self.bg_ratio = bg_ratio\n    self.sr_correl = param['main']['parameters']['SR_correl']\n    self.size_of_increment = param['main']['parameters']['dsr']\n    self.fit_quality = param['main']['parameters']['fit_quality'] / 100.0\n    self.Mmax_range = param['main']['parameters']['Mmax_range']\n    self.calculation_log_file = calculation_log_file\n    if not param['main']['background']['option_bg'] in ['None', 'none']:\n        self.File_bg = param['dirpath'] + param['main']['background']['File_bg']\n    if param['main']['background']['option_bg'] == 'zone':\n        if param['main']['background']['use_host_model'] in ['true', 'True']:\n            self.use_host_model = True\n            self.host_model_file = param['dirpath'] + param['main']['background']['host_model_file']\n        self.file_prop_bg = param['dirpath'] + param['main']['background']['file_prop_bg']\n    self.faults_names = faults_names\n    self.scenarios_names = scenarios_names\n    self.faults_data = faults_data\n    (self.faults_lon, self.faults_lat) = (faults_lon, faults_lat)\n    self.list_fbg = list_fbg\n    self.fbgpath = fbgpath\n    self.branch = branch\n    self.initialize()",
            "def __init__(self, path, pathlog, param, Model_name, rupture_set, sample, Domain_in_model, selected_ScL, dimention_used, use_all_ScL_data, mfd_param, mfd_hyp, bg_ratio, calculation_log_file, faults_names, scenarios_names, faults_data, faults_lon, faults_lat, list_fbg, fbgpath, branch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.Run_Name = param['Run_Name']\n    self.param = param\n    self.Domain_in_the_model = Domain_in_model\n    self.rupture_set = rupture_set\n    self.Model_name = Model_name\n    self.mfd_param = mfd_param\n    self.mfd_hyp = mfd_hyp\n    self.sample = sample\n    self.path = path\n    self.pathlog = pathlog\n    np.random.seed = param['main']['parameters']['Random_seed']\n    self.Mmin = param['main']['parameters']['Mmin']\n    self.selected_ScL = selected_ScL\n    self.dimention_used = dimention_used\n    self.use_all_ScL_data = use_all_ScL_data\n    self.bg_ratio = bg_ratio\n    self.sr_correl = param['main']['parameters']['SR_correl']\n    self.size_of_increment = param['main']['parameters']['dsr']\n    self.fit_quality = param['main']['parameters']['fit_quality'] / 100.0\n    self.Mmax_range = param['main']['parameters']['Mmax_range']\n    self.calculation_log_file = calculation_log_file\n    if not param['main']['background']['option_bg'] in ['None', 'none']:\n        self.File_bg = param['dirpath'] + param['main']['background']['File_bg']\n    if param['main']['background']['option_bg'] == 'zone':\n        if param['main']['background']['use_host_model'] in ['true', 'True']:\n            self.use_host_model = True\n            self.host_model_file = param['dirpath'] + param['main']['background']['host_model_file']\n        self.file_prop_bg = param['dirpath'] + param['main']['background']['file_prop_bg']\n    self.faults_names = faults_names\n    self.scenarios_names = scenarios_names\n    self.faults_data = faults_data\n    (self.faults_lon, self.faults_lat) = (faults_lon, faults_lat)\n    self.list_fbg = list_fbg\n    self.fbgpath = fbgpath\n    self.branch = branch\n    self.initialize()",
            "def __init__(self, path, pathlog, param, Model_name, rupture_set, sample, Domain_in_model, selected_ScL, dimention_used, use_all_ScL_data, mfd_param, mfd_hyp, bg_ratio, calculation_log_file, faults_names, scenarios_names, faults_data, faults_lon, faults_lat, list_fbg, fbgpath, branch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.Run_Name = param['Run_Name']\n    self.param = param\n    self.Domain_in_the_model = Domain_in_model\n    self.rupture_set = rupture_set\n    self.Model_name = Model_name\n    self.mfd_param = mfd_param\n    self.mfd_hyp = mfd_hyp\n    self.sample = sample\n    self.path = path\n    self.pathlog = pathlog\n    np.random.seed = param['main']['parameters']['Random_seed']\n    self.Mmin = param['main']['parameters']['Mmin']\n    self.selected_ScL = selected_ScL\n    self.dimention_used = dimention_used\n    self.use_all_ScL_data = use_all_ScL_data\n    self.bg_ratio = bg_ratio\n    self.sr_correl = param['main']['parameters']['SR_correl']\n    self.size_of_increment = param['main']['parameters']['dsr']\n    self.fit_quality = param['main']['parameters']['fit_quality'] / 100.0\n    self.Mmax_range = param['main']['parameters']['Mmax_range']\n    self.calculation_log_file = calculation_log_file\n    if not param['main']['background']['option_bg'] in ['None', 'none']:\n        self.File_bg = param['dirpath'] + param['main']['background']['File_bg']\n    if param['main']['background']['option_bg'] == 'zone':\n        if param['main']['background']['use_host_model'] in ['true', 'True']:\n            self.use_host_model = True\n            self.host_model_file = param['dirpath'] + param['main']['background']['host_model_file']\n        self.file_prop_bg = param['dirpath'] + param['main']['background']['file_prop_bg']\n    self.faults_names = faults_names\n    self.scenarios_names = scenarios_names\n    self.faults_data = faults_data\n    (self.faults_lon, self.faults_lat) = (faults_lon, faults_lat)\n    self.list_fbg = list_fbg\n    self.fbgpath = fbgpath\n    self.branch = branch\n    self.initialize()"
        ]
    },
    {
        "func_name": "initialize",
        "original": "def initialize(self):\n    path = self.param['dirpath']\n    explo_time = self.param['main']['parameters']['explo_time']\n    if self.param['main']['parameters']['use_multiF'] in ['True', 'true']:\n        use_multiF = True\n    else:\n        use_multiF == False\n    max_rup_per_file = 2000\n    faults_names = self.faults_names\n    scenarios_names = self.scenarios_names\n    faults_data = self.faults_data\n    (faults_lon, faults_lat) = (self.faults_lon, self.faults_lat)\n    list_src_files = []\n    log_sr_file = open(self.pathlog + '/slip_rate_sample_' + str(self.sample) + '.txt', 'w')\n    log_mdf_file = open(self.pathlog + '/mdf_sample_' + str(self.sample) + '.txt', 'w')\n    cut_sm_file = False\n    if len(faults_names) + len(scenarios_names) > max_rup_per_file:\n        cut_sm_file = True\n    if cut_sm_file == False:\n        XMLfile = open(self.path + '/Source_model_' + str(self.sample) + '.xml', 'w')\n    else:\n        n_cut_sf = 1\n        while len(faults_names) / n_cut_sf > max_rup_per_file:\n            n_cut_sf += 1\n        n_cut_mf = 1\n        while len(scenarios_names) / n_cut_mf > max_rup_per_file:\n            n_cut_mf += 1\n        if use_multiF == False:\n            ' create the file list'\n            (sf_files, sf_counter) = ([], [])\n            for i in range(n_cut_sf):\n                f = self.path + '/sm_' + str(self.sample) + '_sf_' + str(i + 1) + '.xml'\n                sf_files.append(open(f, 'w'))\n                sf_counter.append(0)\n                list_src_files.append(f)\n            (mf_files, mf_counter) = ([], [])\n            for i in range(n_cut_mf):\n                f = self.path + '/sm_' + str(self.sample) + '_mf_' + str(i + 1) + '.xml'\n                mf_files.append(open(f, 'w'))\n                mf_counter.append(0)\n                list_src_files.append(f)\n        if use_multiF == True:\n            n_cut_f = n_cut_sf + n_cut_mf\n            s_files = []\n            for i in range(n_cut_mf):\n                f = self.path + '/sm_' + str(i) + '.xml'\n                s_files.append(f)\n                list_src_files.append(f)\n            (dict_txt, dict_n_rup) = ({}, {})\n            for f in s_files:\n                dict_txt.update({f: ''})\n                dict_n_rup.update({f: 0})\n    include_all_faults = False\n    if 'include_all_faults' in self.param['main']['background'].keys():\n        if self.param['main']['background']['include_all_faults'] in ['True', 'true']:\n            include_all_faults = True\n    if use_multiF == True:\n        '\\n            #######################################\\n            #######################################\\n            USING MULTIFAULT TYPOLOGY IN OQ\\n            #######################################\\n            #######################################\\n            '\n        simplify_faults = self.param['main']['parameters']['simplify_faults']\n        if simplify_faults in ['True', 'true']:\n            resample = [False]\n        elif not 'resample' in self.param['main']['parameters'].keys():\n            resample = [False]\n        else:\n            rsp = self.param['main']['parameters']['resample']\n            if rsp[0] in ['True', 'true']:\n                resample = [True]\n                resample.append(float(rsp[1]))\n                resample.append(float(rsp[2]))\n                resample.append(float(rsp[3]))\n            else:\n                resample = [False]\n        if 'vertical_faults' in self.param['main']['parameters'].keys():\n            vertical_faults = self.param['main']['parameters']['vertical_faults']\n            if vertical_faults in ['True', 'true']:\n                vertical_faults = True\n            else:\n                vertical_faults = False\n        else:\n            vertical_faults = False\n        sections_xml = path + self.Run_Name + '/ssm/' + self.Model_name + '_sections.xml'\n        if not os.path.exists(sections_xml):\n            txt = wsf.start(self.Model_name)\n            for section_id in range(len(faults_names)):\n                geotype = 'kite'\n                txt = wsf.wrt_section(txt, section_id, faults_names, faults_data, geotype, resample, vertical_faults)\n            txt = wsf.end(txt)\n            wsf.build(sections_xml, txt)\n        log_general_parameters_file = open(self.pathlog + '/general_parameters_sample_' + str(self.sample) + '.txt', 'w')\n        M_min = float(self.Mmin)\n        log_general_parameters_file.write('M_tronc\\t' + str(M_min) + '\\n')\n        mfd_param = self.mfd_param\n        log_general_parameters_file.write('b_value\\t' + str(mfd_param['b_value']) + '\\n')\n        log_general_parameters_file.close()\n        faults_area = []\n        faults_length = []\n        faults_width = []\n        faults_slip_rates = []\n        faults_mecanism = []\n        faults_shear_mod = []\n        '########################################################\\n            # Random sampling of the fault slip-rate\\n            ########################################################'\n        print('Picking slip-rates...')\n        if self.sample == 1:\n            self.sr_correl = False\n        if self.sr_correl == True:\n            M_faults_correl = []\n            for Fault_name in faults_names:\n                M_faults_correl_i = []\n                sc_with_fault = []\n                for index_scenario in range(len(scenarios_names)):\n                    scenario_i = self.rupture_set[index_scenario]\n                    if Fault_name in scenario_i:\n                        sc_with_fault += scenario_i\n                for Fault_name_i in faults_names:\n                    nb_join_ruptures = 0\n                    if Fault_name == Fault_name_i:\n                        nb_join_ruptures = 0\n                    elif Fault_name_i in sc_with_fault:\n                        nb_join_ruptures = sc_with_fault.count(Fault_name_i)\n                    else:\n                        nb_join_ruptures = 0\n                    M_faults_correl_i.append(nb_join_ruptures)\n                M_faults_correl.append(M_faults_correl_i)\n            M_linked_lvl = np.zeros_like(M_faults_correl)\n            for lvl in [1, 2, 3, 4]:\n                for i in range(len(faults_names)):\n                    for j in range(len(faults_names)):\n                        if M_linked_lvl[i][j] == 0:\n                            if M_faults_correl[i][j] != 0:\n                                M_linked_lvl[i][j] = lvl\n                            else:\n                                for jj in range(len(M_faults_correl[j])):\n                                    if M_faults_correl[j][jj] != 0:\n                                        if M_linked_lvl[i][j] == 0:\n                                            M_linked_lvl[i][j] = lvl + 1\n            max_correl = np.max(M_faults_correl)\n            list_quater_picked = list(np.zeros(len(faults_names)))\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                sr_values = [faults_data[index_fault]['slip_rate_min'], faults_data[index_fault]['slip_rate_moy'], faults_data[index_fault]['slip_rate_max']]\n                slip_rate = select_sr.select(sr_values, self.sample, index_fault, M_linked_lvl[index_fault], list_quater_picked)\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        else:\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                slip_rate_min = faults_data[index_fault]['slip_rate_min']\n                slip_rate_moy = faults_data[index_fault]['slip_rate_moy']\n                slip_rate_max = faults_data[index_fault]['slip_rate_max']\n                if self.sample == 1:\n                    slip_rate = slip_rate_moy\n                else:\n                    slip_rate_inf = np.random.uniform(slip_rate_min, slip_rate_moy)\n                    slip_rate_sup = np.random.uniform(slip_rate_moy, slip_rate_max)\n                    slip_rate = np.random.choice([slip_rate_inf, slip_rate_sup])\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        print('\\t\\tslip-rates picked.')\n        ratio_test = 0.5\n        count_reruns = 1\n        count_mfd90 = 1\n        f_pkl_mdf = self.pathlog + '/mfd_' + str(self.sample) + '.pkl'\n        re_use_mfd_pkl = True\n        if not os.path.isfile(f_pkl_mdf):\n            re_use_mfd_pkl = False\n        if self.param['main']['parameters']['force_rerun'] == True:\n            re_use_mfd_pkl = False\n        if re_use_mfd_pkl == False:\n            while abs(ratio_test - 1) > self.fit_quality or math.isnan(ratio_test) == True:\n                MFDs = EQ_on_faults.EQ_on_faults_from_sr(self.Run_Name, M_min, mfd_param, faults_names, faults_area, faults_length, faults_width, faults_slip_rates, scenarios_names, faults_shear_mod, self.path, self.pathlog, self.sample, self.selected_ScL, self.dimention_used, self.use_all_ScL_data, faults_mecanism, self.bg_ratio, self.size_of_increment, self.mfd_hyp, count_reruns, faults_lon, faults_lat, self.Mmax_range, self.calculation_log_file, self.branch, self.param)\n                ratio_test = MFDs.ratio_test\n                if abs(ratio_test - 1) > self.fit_quality:\n                    print('bad sampling => re-run')\n                    count_reruns += 1\n                    if MFDs.ratio_NMS > 90.0:\n                        count_reruns -= 1\n                        count_mfd90 += 1\n                    else:\n                        count_mfd90 = 1\n                elif MFDs.ratio_NMS > 90.0:\n                    ratio_test = 0.5\n                    print('bad sampling => re-run')\n                    count_mfd90 += 1\n                else:\n                    count_mfd90 = 1\n                if math.isnan(ratio_test) == True:\n                    print('bad sampling => re-run')\n                    count_reruns = 1\n                if count_reruns > 3 or count_mfd90 > 3:\n                    print('\\n\\n\\n!!!!!! maybe there is a problem!!!')\n                    ratio_test = 1.0\n            with open(f_pkl_mdf, 'wb') as f:\n                MFDs_to_pkl = [MFDs.EQ_rate_BG, MFDs.faults_names, MFDs.OQ_entry_faults, MFDs.scenarios_names, MFDs.OQ_entry_scenarios, MFDs.index_faults_in_scenario, MFDs.M_slip_repartition]\n                pickle.dump(MFDs_to_pkl, f)\n        else:\n            print('Reloading MFDs from previous run')\n            with open(f_pkl_mdf, 'rb') as f:\n                MFDs_to_pkl = pickle.load(f)\n        EQ_rate_BG = MFDs_to_pkl[0]\n        faults_names = MFDs_to_pkl[1]\n        OQ_entry_faults = MFDs_to_pkl[2]\n        scenarios_names = MFDs_to_pkl[3]\n        OQ_entry_scenarios = MFDs_to_pkl[4]\n        index_faults_in_scenario = MFDs_to_pkl[5]\n        M_slip_repartition = MFDs_to_pkl[6]\n        if self.selected_ScL == 'Le2010':\n            ScL_oq = 'Leonard2014_SCR'\n        if self.selected_ScL == 'WC1994':\n            ScL_oq = 'WC1994'\n        else:\n            ScL_oq = 'WC1994'\n        (Lon_bg, Lat_bg) = bg.geom(self.Model_name, self.File_bg)\n        Poly_bg = []\n        for (x1, y1) in zip(Lon_bg, Lat_bg):\n            Poly_bg.append((x1, y1))\n        try:\n            bbPath_BG = mplPath.Path(Poly_bg)\n        except:\n            print('ERROR, please make sure the model name matches in the bg file')\n        f_in_bg = []\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            for (lon, lat) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                if bbPath_BG.contains_point((lon, lat)):\n                    f_in_bg.append(index_fault)\n        outside_faults = []\n        if include_all_faults == True:\n            for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n                if not index_fault in f_in_bg:\n                    f_in_bg.append(index_fault)\n                    outside_faults.append(index_fault)\n        source_id = 0\n        if cut_sm_file == False:\n            source_xml = self.path + '/Source_model_' + str(self.sample) + '.xml'\n            list_src_files.append(source_xml)\n            trt = faults_data[0]['domain']\n            txt = wmfs.start(explo_time, trt)\n            name = 'multifaultsource'\n            txt = wmfs.start_multifault_source(txt, name, trt, sections_xml, source_id)\n        else:\n            for f in s_files:\n                trt = faults_data[0]['domain']\n                dict_txt[f] = wmfs.start(explo_time, trt)\n                name = 'multifaultsource_' + str(source_id)\n                dict_txt[f] = wmfs.start_multifault_source(dict_txt[f], name, trt, sections_xml, source_id)\n                source_id += 1\n            f = list(dict_txt.keys())[0]\n        single_f_xml = self.path + '/single_sec_rup.xml'\n        trt = faults_data[0]['domain']\n        single_txt = wss.start(self.Model_name, trt)\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            if index_fault in f_in_bg:\n                i_MFD = np.where(np.array(faults_names) == fault_name)[0][0]\n                MFD = OQ_entry_faults[i_MFD]\n                if sum(MFD) != 0:\n                    source_id = source_id + 1\n                    Fault_Name = self.Model_name + '_' + str(fault_name)\n                    fault_trt = faults_data[index_fault]['domain']\n                    if not fault_trt in str(self.Domain_in_the_model):\n                        self.Domain_in_the_model.append(fault_trt)\n                    trt = str(fault_trt)\n                    rake = faults_data[index_fault]['rake']\n                    geotype = 'kite'\n                    name = 'single_fault_' + fault_name\n                    single_txt = wss.wrt_source(single_txt, index_fault, faults_names, faults_data, geotype, resample, vertical_faults, fault_trt, M_min, MFD, ScL_oq)\n        single_txt = wss.end(single_txt)\n        wss.build(single_f_xml, single_txt)\n        if len(self.rupture_set) != 0:\n            for scenario in enumerate(scenarios_names):\n                sc_in = False\n                index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                index_faults_in_sc = index_faults_in_scenario[index_scenario][0]\n                for i in index_faults_in_sc:\n                    if i in f_in_bg:\n                        sc_in = True\n                if sc_in == True:\n                    index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                    MFD = OQ_entry_scenarios[index_scenario]\n                    if sum(MFD) != 0:\n                        faults_in_scenario = np.take(faults_names, index_faults_in_sc)\n                        source_id = source_id + 1\n                        scenar_name = '_'.join(('{!s}={!r}'.format(key, val) for (key, val) in scenario[1].items()))\n                        source_name = self.Model_name + '_scenario_'\n                        source_name += str(scenar_name)\n                        list_trt = []\n                        scenario_mechanism = []\n                        for fname in faults_in_scenario:\n                            i = faults_names.index(fname)\n                            scenario_mechanism.append(faults_data[i]['rake'])\n                            fault_trt = faults_data[i]['domain']\n                            list_trt.append(fault_trt)\n                            if not fault_trt in str(self.Domain_in_the_model):\n                                self.Domain_in_the_model.append(fault_trt)\n                        fault_trt = max(list_trt, key=list_trt.count)\n                        trt = str(fault_trt)\n                        rake = np.mean(scenario_mechanism)\n                        if cut_sm_file == False:\n                            txt = wmfs.wrt_multifault_source(txt, MFD, self.Mmin, explo_time, rake, index_faults_in_sc)\n                        else:\n                            if not dict_n_rup[f] < max_rup_per_file:\n                                i = 0\n                                while dict_n_rup[f] > max_rup_per_file:\n                                    i += 1\n                                    f = list(dict_txt.keys())[i]\n                            txt = dict_txt[f]\n                            dict_txt[f] = wmfs.wrt_multifault_source(txt, MFD, self.Mmin, explo_time, rake, index_faults_in_sc)\n                            dict_n_rup[f] += 1\n        if cut_sm_file == False:\n            txt = wmfs.end_multifault_source(txt)\n            txt = wmfs.end(txt)\n            wmfs.build(source_xml, txt)\n        else:\n            for f in s_files:\n                if dict_n_rup[f] > 0:\n                    dict_txt[f] = wmfs.end_multifault_source(dict_txt[f])\n                    txt = wmfs.end(dict_txt[f])\n                    wmfs.build(f, txt)\n    else:\n        '\\n            ###########\\n            ############\\n            NOT USING MULTIFAULTSOURCE TYPOLOGY in OQ\\n\\n            '\n        line = \"<?xml version='1.0' encoding='utf-8'?>\\n\"\n        line += '<nrml xmlns:gml=\"http://www.opengis.net/gml\"\\n'\n        line += '\\txmlns=\"http://openquake.org/xmlns/nrml/0.5\">\\n'\n        line += '\\t<sourceModel name=\"Hazard Model\"'\n        line += ' investigation_time=\"' + str(round(explo_time, 1)) + '\">\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n        line = '\\t\\t<sourceGroup\\nname=\"group 1\"\\nrup_interdep=\"indep\"\\nsrc_interdep=\"indep\"\\ntectonicRegion=\"Active Shallow Crust\"\\n>\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n        log_general_parameters_file = open(self.pathlog + '/Log/general_parameters_sample_' + str(self.sample) + '.txt', 'w')\n        M_min = float(self.Mmin)\n        log_general_parameters_file.write('M_tronc\\t' + str(M_min) + '\\n')\n        log_general_parameters_file.write('b_value\\t' + str(self.b_value) + '\\n')\n        log_general_parameters_file.close()\n        faults_area = []\n        faults_length = []\n        faults_width = []\n        faults_slip_rates = []\n        faults_mecanism = []\n        faults_shear_mod = []\n        '########################################################\\n            # Random sampling of the fault slip-rate\\n            ########################################################'\n        print('Picking slip-rates...')\n        if self.sample == 1:\n            self.sr_correl = False\n        if self.sr_correl == True:\n            M_faults_correl = []\n            for Fault_name in faults_names:\n                M_faults_correl_i = []\n                sc_with_fault = []\n                for index_scenario in range(len(scenarios_names)):\n                    scenario_i = self.rupture_set[index_scenario]\n                    if Fault_name in scenario_i:\n                        sc_with_fault += scenario_i\n                for Fault_name_i in faults_names:\n                    nb_join_ruptures = 0\n                    if Fault_name == Fault_name_i:\n                        nb_join_ruptures = 0\n                    elif Fault_name_i in sc_with_fault:\n                        nb_join_ruptures = sc_with_fault.count(Fault_name_i)\n                    else:\n                        nb_join_ruptures = 0\n                    M_faults_correl_i.append(nb_join_ruptures)\n                M_faults_correl.append(M_faults_correl_i)\n            M_linked_lvl = np.zeros_like(M_faults_correl)\n            for lvl in [1, 2, 3, 4]:\n                for i in range(len(faults_names)):\n                    for j in range(len(faults_names)):\n                        if M_linked_lvl[i][j] == 0:\n                            if M_faults_correl[i][j] != 0:\n                                M_linked_lvl[i][j] = lvl\n                            else:\n                                for jj in range(len(M_faults_correl[j])):\n                                    if M_faults_correl[j][jj] != 0:\n                                        if M_linked_lvl[i][j] == 0:\n                                            M_linked_lvl[i][j] = lvl + 1\n            max_correl = np.max(M_faults_correl)\n            list_quater_picked = list(np.zeros(len(faults_names)))\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                sr_values = [faults_data[index_fault]['slip_rate_min'], faults_data[index_fault]['slip_rate_moy'], faults_data[index_fault]['slip_rate_max']]\n                slip_rate = select_sr.select(sr_values, self.sample, index_fault, M_linked_lvl[index_fault], list_quater_picked)\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        else:\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                slip_rate_min = faults_data[index_fault]['slip_rate_min']\n                slip_rate_moy = faults_data[index_fault]['slip_rate_moy']\n                slip_rate_max = faults_data[index_fault]['slip_rate_max']\n                if self.sample == 1:\n                    slip_rate = slip_rate_moy\n                else:\n                    slip_rate_inf = np.random.uniform(slip_rate_min, slip_rate_moy)\n                    slip_rate_sup = np.random.uniform(slip_rate_moy, slip_rate_max)\n                    slip_rate = np.random.choice([slip_rate_inf, slip_rate_sup])\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        print('\\t\\tslip-rates picked.')\n        ratio_test = 0.5\n        count_reruns = 1\n        count_mfd90 = 1\n        f_pkl_mdf = self.pathlog + '/mfd_' + str(self.sample) + '.pkl'\n        re_use_mfd_pkl = True\n        if not os.path.isfile(f_pkl_mdf):\n            re_use_mfd_pkl = False\n        if re_use_mfd_pkl == False:\n            while abs(ratio_test - 1) > self.fit_quality or math.isnan(ratio_test) == True:\n                MFDs = EQ_on_faults.EQ_on_faults_from_sr(M_min, mfd_param, faults_names, faults_area, faults_length, faults_width, faults_slip_rates, scenarios_names, faults_shear_mod, self.path, self.sample, self.selected_ScL, self.dimention_used, self.use_all_ScL_data, faults_mecanism, self.bg_ratio, self.size_of_increment, self.mfd_hyp, count_reruns, faults_lon, faults_lat, self.Mmax_range, self.calculation_log_file, self.branch, self.param)\n                ratio_test = MFDs.ratio_test\n                if abs(ratio_test - 1) > self.fit_quality:\n                    print('bad sampling => re-run')\n                    count_reruns += 1\n                    if MFDs.ratio_NMS > 90.0:\n                        count_reruns -= 1\n                        count_mfd90 += 1\n                    else:\n                        count_mfd90 = 1\n                elif MFDs.ratio_NMS > 90.0:\n                    ratio_test = 0.5\n                    print('bad sampling => re-run')\n                    count_mfd90 += 1\n                else:\n                    count_mfd90 = 1\n                if math.isnan(ratio_test) == True:\n                    print('bad sampling => re-run')\n                    count_reruns = 1\n                if count_reruns > 3 or count_mfd90 > 3:\n                    print('\\n\\n\\n!!!!!! maybe there is a problem!!!')\n                    ratio_test = 1.0\n            with open(f_pkl_mdf, 'wb') as f:\n                MFDs_to_pkl = [MFDs.EQ_rate_BG, MFDs.faults_names, MFDs.OQ_entry_faults, MFDs.scenarios_names, MFDs.OQ_entry_scenarios, MFDs.index_faults_in_scenario, MFDs.M_slip_repartition]\n                pickle.dump(MFDs_to_pkl, f)\n        else:\n            print('Reloading MFDs from previous run')\n            with open(f_pkl_mdf, 'rb') as f:\n                MFDs_to_pkl = pickle.load(f)\n        EQ_rate_BG = MFDs_to_pkl[0]\n        faults_names = MFDs_to_pkl[1]\n        OQ_entry_faults = MFDs_to_pkl[2]\n        scenarios_names = MFDs_to_pkl[3]\n        OQ_entry_scenarios = MFDs_to_pkl[4]\n        index_faults_in_scenario = MFDs_to_pkl[5]\n        M_slip_repartition = MFDs_to_pkl[6]\n        if self.selected_ScL == 'Le2010':\n            ScL_oq = 'Leonard2014_SCR'\n        elif self.selected_ScL == 'WC1994':\n            ScL_oq = 'WC1994'\n        else:\n            ScL_oq = 'WC1994'\n        (Lon_bg, Lat_bg) = bg.geom(self.Model_name, self.File_bg)\n        Poly_bg = []\n        for (x1, y1) in zip(Lon_bg, Lat_bg):\n            Poly_bg.append((x1, y1))\n        bbPath_BG = mplPath.Path(Poly_bg)\n        f_in_bg = []\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            for (lon, lat) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                if bbPath_BG.contains_point((lon, lat)):\n                    f_in_bg.append(index_fault)\n        outside_faults = []\n        if include_all_faults == True:\n            for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n                if not index_fault in f_in_bg:\n                    f_in_bg.append(index_fault)\n                    outside_faults.append(index_fault)\n        ID_number = 0\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            if index_fault in f_in_bg:\n                use_simple_faults = False\n                if use_simple_faults == True:\n                    (line, self.Domain_in_the_model, ID_number) = fault_source.write_simple_fault(index_fault, fault_name, OQ_entry_faults, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, M_min, ID_number)\n                else:\n                    (line, self.Domain_in_the_model, ID_number) = fault_source.write_non_parametric_one_fault(index_fault, fault_name, OQ_entry_faults, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, M_min, ID_number, explo_time)\n                if cut_sm_file == False:\n                    XMLfile.write(line)\n                else:\n                    i_w = 0\n                    while sf_counter[i_w] > 500:\n                        i_w += 1\n                    sf_files[i_w].write(line)\n                    sf_counter[i_w] += 1\n        if len(self.rupture_set) != 0:\n            for scenario in enumerate(scenarios_names):\n                sc_in = False\n                index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                for i in index_faults_in_scenario[index_scenario][0]:\n                    if i in f_in_bg:\n                        sc_in = True\n                if sc_in == True:\n                    use_non_param = True\n                    if use_non_param == False:\n                        (line, ID_number) = fault_source.write_characteristic_scenario(scenarios_names, OQ_entry_scenarios, index_faults_in_scenario, scenario, faults_names, self.Model_name, faults_data, log_mdf_file, M_min, ID_number)\n                    else:\n                        (line, ID_number) = fault_source.write_non_parametric_source(scenario, scenarios_names, OQ_entry_scenarios, index_faults_in_scenario, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, explo_time, M_min, ID_number)\n                    if cut_sm_file == False:\n                        XMLfile.write(line)\n                    else:\n                        i_w = 0\n                        while mf_counter[i_w] > 500:\n                            i_w += 1\n                        mf_files[i_w].write(line)\n                        mf_counter[i_w] += 1\n    '#########################\\n        # Defining the background seismicity\\n        #########################'\n    MFD = EQ_rate_BG\n    pts_list = {}\n    if sum(MFD) != 0.0 and self.param['main']['background']['option_bg'] == 'zone':\n        bg_file = self.path + '/bg_' + str(self.sample) + '.xml'\n        list_src_files.append(bg_file)\n        bg_file = open(bg_file, 'w')\n        line = \"<?xml version='1.0' encoding='utf-8'?>\\n\"\n        line += '<nrml xmlns:gml=\"http://www.opengis.net/gml\"\\n'\n        line += '\\txmlns=\"http://openquake.org/xmlns/nrml/0.5\">\\n'\n        line += '\\t<sourceModel name=\"Hazard Model\">\\n'\n        (upperSeismoDepth, lowerSeismoDepth, ruptAspectRatio, nodalPlanes, hypoDepths) = bg.prop(self.Model_name, self.file_prop_bg)\n        line += '\\t\\t<sourceGroup\\nname=\"group 2\"\\nrup_interdep=\"indep\"\\nsrc_interdep=\"indep\"\\ntectonicRegion=\"' + str(self.Domain_in_the_model[0]) + '\"\\n>\\n'\n        line += '\\t\\t<areaSource id=\"' + str(source_id + 1) + '\" name=\"Background\" tectonicRegion=\"' + str(self.Domain_in_the_model[0]) + '\">\\n'\n        line += '\\t\\t\\t<areaGeometry>\\n'\n        line += '\\t\\t\\t\\t<gml:Polygon>\\n'\n        line += '\\t\\t\\t\\t\\t<gml:exterior>\\n'\n        line += '\\t\\t\\t\\t\\t\\t<gml:LinearRing>\\n'\n        line += '\\t\\t\\t\\t\\t\\t\\t<gml:posList>\\n'\n        for (x, y) in zip(Lon_bg, Lat_bg):\n            line += '\\t\\t\\t\\t\\t\\t\\t\\t' + str(x) + ' ' + str(y) + '\\n'\n        line += '\\t\\t\\t\\t\\t\\t\\t</gml:posList>\\n'\n        line += '\\t\\t\\t\\t\\t\\t</gml:LinearRing>\\n'\n        line += '\\t\\t\\t\\t\\t</gml:exterior>\\n'\n        line += '\\t\\t\\t\\t</gml:Polygon>\\n'\n        line += '\\t\\t\\t\\t<upperSeismoDepth>' + str(upperSeismoDepth) + '</upperSeismoDepth>\\n'\n        line += '\\t\\t\\t\\t<lowerSeismoDepth>' + str(lowerSeismoDepth) + '</lowerSeismoDepth>\\n'\n        line += '\\t\\t\\t</areaGeometry>\\n'\n        line += '\\t\\t\\t<magScaleRel>' + ScL_oq + '</magScaleRel>\\n'\n        line += '\\t\\t\\t<ruptAspectRatio>' + str(ruptAspectRatio) + '</ruptAspectRatio>\\n'\n        log_mdf_file.write('Background' + '\\t' + str(M_min) + '\\t' + ' '.join(list(map(str, MFD))) + '\\n')\n        line += '\\t\\t\\t<incrementalMFD binWidth=\"0.10\" minMag=\"' + str(M_min) + '\">\\n'\n        line += '\\t\\t\\t<occurRates> ' + ' '.join(list(map(str, MFD))) + '</occurRates>\\n'\n        line += '\\t\\t\\t</incrementalMFD>\\n'\n        line += '\\t\\t\\t<nodalPlaneDist>\\n'\n        for i in range(len(nodalPlanes)):\n            line += '\\t\\t\\t\\t<nodalPlane probability=\"' + str(nodalPlanes[i][0]) + '\" strike=\"' + str(nodalPlanes[i][1]) + '\" dip=\"' + str(nodalPlanes[i][2]) + '\" rake=\"' + str(nodalPlanes[i][3]) + '\" />\\n'\n        line += '\\t\\t\\t</nodalPlaneDist>\\n'\n        line += '\\t\\t\\t<hypoDepthDist>\\n'\n        for i in range(len(hypoDepths)):\n            line += '\\t\\t\\t\\t<hypoDepth probability=\"' + str(hypoDepths[i][0]) + '\" depth=\"' + str(hypoDepths[i][1]) + '\" />\\n'\n        line += '\\t\\t\\t</hypoDepthDist>\\n'\n        line += '\\t\\t</areaSource>\\n'\n        line += '\\t</sourceGroup>\\n'\n        line += '\\t</sourceModel>\\n'\n        line += '</nrml>\\n'\n        bg_file.write(line)\n        bg_file.close()\n    elif sum(MFD) != 0.0 and self.param['main']['background']['option_bg'] == 'smooth':\n        Mmin_checked = False\n        Mmax = M_min + len(EQ_rate_BG) * 0.1 - 1\n        mags = np.linspace(M_min, Mmax, len(EQ_rate_BG))\n        list_bg_xml = self.list_fbg\n        if os.path.isdir(self.fbgpath):\n            list_bg_xml = [self.fbgpath + '/' + i for i in list_bg_xml if '.xml' in i]\n        with open(list_bg_xml[0]) as myfile:\n            if 'multiPointSource' in myfile.read():\n                multiPointSource_type = True\n            else:\n                multiPointSource_type = False\n        if multiPointSource_type == True:\n            bg.get_multipoints(EQ_rate_BG, M_min, bbPath_BG, list_bg_xml, include_all_faults, outside_faults, faults_data, OQ_entry_faults, self.path, self.pathlog, list_src_files)\n        else:\n            pts_list = {}\n            pts_out_list = {}\n            sum_rates = [0.0 for _ in mags]\n            for fbg in list_bg_xml:\n                tree = ET.parse(fbg)\n                ET.register_namespace('', 'http://openquake.org/xmlns/nrml/0.5')\n                nrml = tree.getroot()\n                i_point = 0\n                for pointSource in nrml[0][0]:\n                    pt_in_BG = False\n                    i_child = 0\n                    for child in pointSource.getchildren():\n                        if 'pointGeometry' in str(child):\n                            s_tmp = pointSource[i_child][0][0].text\n                            s_tmp = s_tmp.replace('\\n', '')\n                            s_tmp = [float(i) for i in s_tmp.split(' ') if i != '']\n                            if bbPath_BG.contains_point((s_tmp[0], s_tmp[1])) == 1:\n                                pt_in_BG = True\n                            str_loc = str(s_tmp[0]) + '_' + str(s_tmp[1])\n                        if 'truncGutenbergRichterMFD' in str(child):\n                            aValue = nrml[0][0][i_point][i_child].get('aValue')\n                            minMag = nrml[0][0][i_point][i_child].get('minMag')\n                            i_trGR = i_child\n                        i_child += 1\n                    aValue = nrml[0][0][i_point][i_trGR].get('aValue')\n                    minMag = nrml[0][0][i_point][i_trGR].get('minMag')\n                    bValue = nrml[0][0][i_point][i_trGR].get('bValue')\n                    maxMag = nrml[0][0][i_point][i_trGR].get('maxMag')\n                    mfd_smooth = []\n                    i_mag = 0\n                    for mag in mags:\n                        mag_lo = mag - 0.05\n                        mag_hi = mag + 0.05\n                        r = 10 ** (float(aValue) - float(bValue) * mag_lo) - 10 ** (float(aValue) - float(bValue) * mag_hi)\n                        sum_rates[i_mag] += r\n                        i_mag += 1\n                        mfd_smooth.append(r)\n                    if pt_in_BG == True:\n                        pts_list.update({str_loc: {'aValue': aValue, 'bValue': bValue, 'maxMag': maxMag, 'minMag': minMag, 'mfd_smooth': mfd_smooth}})\n                        if Mmin_checked == False:\n                            if float(minMag) < M_min:\n                                print('!!!!')\n                                print('WARNING : BG has a smaller Mmin than the SHERIFS input')\n                                print('!!!!')\n                                Mmin_checked = True\n                    elif include_all_faults == True:\n                        pt_very_far = True\n                        lon_lat_distance_criteria = 1.0\n                        i = 0\n                        while pt_very_far == False and i < len(outside_faults):\n                            i_fault = outside_faults[i]\n                            mean_lon = np.mean(faults_data[index_fault]['lon'])\n                            mean_lat = np.mean(faults_data[index_fault]['lat'])\n                            if abs(float(s_tmp[0]) - mean_lon) < lon_lat_distance_criteria:\n                                pt_very_far = False\n                            if abs(float(s_tmp[1]) - mean_lat) < lon_lat_distance_criteria:\n                                pt_very_far = False\n                            i += 1\n                        if pt_very_far == False:\n                            dist_critera = 50.0\n                            dist = 1000000.0\n                            closest_fault = 'nope'\n                            for i_fault in outside_faults:\n                                mean_lon = np.mean(faults_data[index_fault]['lon'])\n                                mean_lat = np.mean(faults_data[index_fault]['lat'])\n                                dist_i = distance(mean_lon, mean_lat, float(s_tmp[0]), float(s_tmp[1]))\n                                if dist_i < dist_critera:\n                                    for (lon_f, lat_f) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                                        dist_i = distance(mean_lon, mean_lat, float(s_tmp[0]), float(s_tmp[1]))\n                                        if dist_i < dist:\n                                            dist = dist_i\n                                            closest_fault = i_fault\n                                if dist_i < dist:\n                                    dist = dist_i\n                                    closest_fault = i_fault\n                            closest_dist = dist\n                            pts_out_list.update({str_loc: {'aValue': aValue, 'bValue': bValue, 'maxMag': maxMag, 'minMag': minMag, 'mfd_smooth': mfd_smooth, 'distance': closest_dist, 'closest_fault': i_fault}})\n                    i_point += 1\n            nb_pt_in_buff = {}\n            if include_all_faults == True:\n                for i_fault in outside_faults:\n                    buffer_1 = 10.0\n                    buffer_2 = 20.0\n                    nb_buf1 = 0\n                    nb_buf2 = 0\n                    for str_loc in pts_out_list.keys():\n                        if pts_out_list[str_loc]['closest_fault'] == i_fault:\n                            if pts_out_list[str_loc]['closest_dist'] < buffer_1:\n                                nb_buf1 += 1\n                            elif pts_out_list[str_loc]['closest_dist'] < buffer_2:\n                                nb_buf2 += 1\n                    nb_pt_in_buff.update({i_fault: {'nb_buf1': nb_buf1, 'nb_buf2': nb_buf2}})\n            sum_bg_min = 0.0\n            i_bg = 0\n            for fbg in list_bg_xml:\n                tree = ET.parse(fbg)\n                ET.register_namespace('', 'http://openquake.org/xmlns/nrml/0.5')\n                nrml = tree.getroot()\n                i_point = 0\n                for pointSource in nrml[0][0]:\n                    pt_in_BG = False\n                    i_child = 0\n                    for child in pointSource.getchildren():\n                        if 'magScaleRel' in str(child):\n                            nrml[0][0][i_point][i_child].text = ScL_oq\n                        if 'pointGeometry' in str(child):\n                            s_tmp = pointSource[i_child][0][0].text\n                            s_tmp = s_tmp.replace('\\n', '')\n                            s_tmp = [float(i) for i in s_tmp.split(' ') if i != '']\n                            str_loc = str(s_tmp[0]) + '_' + str(s_tmp[1])\n                        if 'truncGutenbergRichterMFD' in str(child):\n                            i_trGR = i_child\n                        i_child += 1\n                    if str_loc in pts_list.keys():\n                        b_value = float(pts_list[str_loc]['bValue'])\n                        a_value = float(pts_list[str_loc]['aValue'])\n                        attrib = {'minMag': str(M_min), 'binWidth': '0.10'}\n                        element = nrml[0][0][i_point].makeelement('incrementalMFD', attrib)\n                        nrml[0][0][i_point].append(element)\n                        element = nrml[0][0][i_point][-1].makeelement('occurRates', {})\n                        nrml[0][0][i_point][-1].append(element)\n                        str_tmp = ' '\n                        pt_scl_mfd = []\n                        i_mag = 0\n                        for mag in mags:\n                            mag_lo = mag - 0.05\n                            mag_hi = mag + 0.05\n                            r = 10 ** (a_value - b_value * mag_lo) - 10 ** (a_value - b_value * mag_hi)\n                            norm_r = r / sum_rates[i_mag]\n                            str_tmp += str(EQ_rate_BG[i_mag] * norm_r)\n                            str_tmp += ' '\n                            sum_bg_min += EQ_rate_BG[i_mag] * norm_r\n                            pt_scl_mfd.append(EQ_rate_BG[i_mag] * norm_r)\n                            i_mag += 1\n                        pts_list[str_loc].update({'scaled_mfd': pt_scl_mfd})\n                        nrml[0][0][i_point][-1][0].text = str_tmp\n                        nrml[0][0][i_point].remove(nrml[0][0][i_point][i_trGR])\n                    if include_all_faults == True:\n                        if str_loc in pts_out_list.keys():\n                            b_value = float(pts_list[str_loc]['bValue'])\n                            a_value = float(pts_list[str_loc]['aValue'])\n                            attrib = {'minMag': str(M_min), 'binWidth': '0.10'}\n                            element = nrml[0][0][i_point].makeelement('incrementalMFD', attrib)\n                            nrml[0][0][i_point].append(element)\n                            element = nrml[0][0][i_point][-1].makeelement('occurRates', {})\n                            nrml[0][0][i_point][-1].append(element)\n                            str_tmp = ' '\n                            pt_scl_mfd = []\n                            i_fault = pts_out_list[str_loc]['closest_fault']\n                            mfd_single_clst_f = OQ_entry_faults[i_fault]\n                            id_ruptures = []\n                            mfd_mlt_clst_f = []\n                            for (scenario_i, mfd_i) in zip(index_faults_in_scenario, OQ_entry_scenarios):\n                                if i_fault in scenario_i:\n                                    id_ruptures.append(scenario_i)\n                                    mfd_mlt_clst_f.append(mfd_i)\n                            i_mag = 0\n                            for mag in mags:\n                                mag_lo = mag - 0.05\n                                mag_hi = mag + 0.05\n                                r = 10 ** (a_value - b_value * mag_lo) - 10 ** (a_value - b_value * mag_hi)\n                                if mag >= 6.5:\n                                    buffer_to_use = 'nb_buf2'\n                                else:\n                                    buffer_to_use = 'nb_buf1'\n                                reduction = 0.0\n                                for (f_in_rup, mfd_i) in zip(id_ruptures, mfd_mlt_clst_f):\n                                    reduction += mfd_i[i_mag] / float(len(f_in_rup) * nb_pt_in_buff[i_fault][buffer_to_use])\n                                if reduction > r:\n                                    r = 0.0\n                                else:\n                                    r -= reduction\n                                str_tmp += str(r)\n                                str_tmp += ' '\n                                pt_scl_mfd.append(r)\n                                i_mag += 1\n                            pts_out_list[str_loc].update({'scaled_mfd': pt_scl_mfd})\n                            nrml[0][0][i_point][-1][0].text = str_tmp\n                            nrml[0][0][i_point].remove(nrml[0][0][i_point][i_trGR])\n                    i_point += 1\n                i_bg += 1\n                fbg_out = self.path + '/bg_' + str(self.sample) + '_' + str(i_bg) + '.xml'\n                tree.write(fbg_out)\n                list_src_files.append(fbg_out)\n    '#############################\\n        ### defining the other sources based on the host model\\n        ##############################'\n    if self.param['main']['background']['use_host_model'] == True and cut_sm_file == False:\n        host_model.build(XMLfile, self.host_model_file, Lon_bg, Lat_bg)\n    if self.param['main']['background']['use_host_model'] == True and cut_sm_file == True:\n        print(\"WARNING : can't use host model and cut files yet !\")\n    if use_multiF == False:\n        line = '\\t\\t\\t</sourceGroup>\\n'\n        line += '\\t</sourceModel>\\n'\n        line += '</nrml>\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n            XMLfile.close()\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n                f.close()\n    log_sr_file.close()\n    log_mdf_file.close()\n    self.list_src_files = list_src_files\n    '#############################\\n        ### Get the particiaption rates of sections\\n        ##############################'\n    import participation_rates as p_rates\n    from section_info import get_nonzero_Mmax\n    (dict_p_rates, mfd_total, all_non_zero_rups) = p_rates.get_all_participation_rates(MFDs_to_pkl, self.param, faults_names)\n    bin_mag = p_rates.get_bin_mag(mfd_total, self.Mmin)\n    all_participation_rates = []\n    sections_Mmax = []\n    if not os.path.isdir(self.pathlog + '/participation_rates'):\n        os.makedirs(self.pathlog + '/participation_rates')\n    for fault_name in faults_names:\n        (incremental_rate, cumulative_rate) = p_rates.extract_rates(fault_name, dict_p_rates)\n        all_participation_rates.append(cumulative_rate)\n        ptf = self.pathlog + '/participation_rates/' + str(fault_name) + '.png'\n        p_rates.plot_participation_rates(bin_mag, incremental_rate, cumulative_rate, fault_name, ptf)\n        Mmax = get_nonzero_Mmax(bin_mag, cumulative_rate)\n        sections_Mmax.append(Mmax)\n    '#############################\\n        ### Exporting the results in a Geojson\\n        ##############################'\n    features = []\n    for si in f_in_bg:\n        sections = []\n        geom = []\n        for (lon_i, lat_i) in zip(faults_data[si]['lon'], faults_data[si]['lat']):\n            geom.append((lon_i, lat_i))\n        geom = LineString(list(geom))\n        properties = {}\n        for key in faults_data[si].keys():\n            if not key in ['lat', 'lon']:\n                properties.update({key: faults_data[si][key]})\n        NMS = float(M_slip_repartition[faults_data[si]['name']]['NMS'])\n        sumdsr = 0.0\n        for key in M_slip_repartition[faults_data[si]['name']].keys():\n            sumdsr += M_slip_repartition[faults_data[si]['name']][key]\n        properties.update({'NMS': NMS / float(sumdsr)})\n        properties.update({'nb_rup': float(all_non_zero_rups[si])})\n        properties.update({'Mmax': float(sections_Mmax[si])})\n        properties.update({'participation_rates': [bin_mag, all_participation_rates[si]]})\n        nms_i = NMS / float(sumdsr)\n        mmax_i = sections_Mmax[si]\n        if mmax_i >= max(sections_Mmax) - 0.3:\n            if nms_i < 0.1:\n                indicator = 1.0 - nms_i\n            else:\n                indicator = 0.0\n        elif mmax_i >= max(sections_Mmax) - 0.5:\n            if nms_i < 0.05:\n                indicator = 1.0 - nms_i\n            else:\n                indicator = 0.0\n        else:\n            indicator = 0.0\n        properties.update({'might_to_be_limiting': round(indicator, 2)})\n        features.append(Feature(geometry=geom, properties=properties))\n    feature_collection = FeatureCollection(features)\n    with open(self.pathlog + '/out_sections.geojson', 'w') as f:\n        dump(feature_collection, f)\n    '#######################\\n        ### some figures\\n        ######################'\n    if 'figures' in self.param.keys():\n        if self.param['figures']['print'] in ['true', 'True']:\n            make_figures = True\n        else:\n            make_figures = False\n    else:\n        make_figures = False\n    plt_model_mfd = False\n    if make_figures == True:\n        if self.param['figures']['model_mfd'] in ['true', 'True']:\n            plt_model_mfd = True\n    if 'mfd_cat' in self.param['figures'].keys():\n        data = self.param['figures']['mfd_cat']\n    else:\n        data = False\n    if plt_model_mfd == True:\n        x = MFDs.bin_mag\n        y = rates.get_rate_model(MFDs.rup_rates, MFDs.fault_prop, x)\n        lim = [[x[0] - 0.05, x[-1] + 0.05], [min(y) / 2.0, max(y) * 2.0]]\n        axis = ['magnitude', 'annual earthquake rates']\n        path = self.pathlog + '/modelMFD.png'\n        title = 'MFD of the whole system'\n        plt_mfd.plot(x, y, lim, axis, data, path, title)\n    if plt_model_mfd == True:\n        x = MFDs.bin_mag\n        (ft, bgmfd) = rates.get_rate_faults_n_bg(MFDs.rup_rates, MFDs.fault_prop, x)\n        ys = [rates.get_rate_model(MFDs.rup_rates, MFDs.fault_prop, x), ft, bgmfd]\n        lim = [[x[0] - 0.05, x[-1] + 0.05], [min(ys[0]) / 2.0, max(ys[0]) * 2.0]]\n        axis = ['magnitude', 'annual earthquake rates']\n        path = self.pathlog + '/modelMFD_bg_ft.png'\n        title = 'MFD of the whole system, faults, background'\n        plt_mfd.plot_bg_ft(x, ys, lim, axis, path, title)\n    ' mfd in a more local scale '\n    part_mfd = False\n    if make_figures == True:\n        if 'part_mfd' in self.param['figures'].keys():\n            if self.param['figures']['part_mfd'] in ['true', 'True']:\n                part_mfd = True\n    if part_mfd == True:\n        loc_cat = local_cat.read_geojson(self.param['figures']['parts_gjson'])\n        for zone in loc_cat.keys():\n            polypt = loc_cat[zone]['poly']\n            lons = []\n            lats = []\n            for pt in polypt[0][0]:\n                lons.append(pt[0])\n                lats.append(pt[1])\n            poly = []\n            for (x1, y1) in zip(lons, lats):\n                poly.append((x1, y1))\n            area_zone = geometry_tools.PolyArea(lons, lats)\n            area_bg = geometry_tools.PolyArea(Lon_bg, Lat_bg)\n            ratio_area = float(area_zone) / float(area_bg)\n            local_zone_mfd = [i * ratio_area for i in EQ_rate_BG]\n            poly = mplPath.Path(poly)\n            (txt_no_bg, rate_faults, rate_bg, smooth) = local_cat.get_model_rate(poly, OQ_entry_faults, OQ_entry_scenarios, pts_list, MFDs.bin_mag, self.param, faults_data, faults_names, index_faults_in_scenario, local_zone_mfd)\n            x = MFDs.bin_mag\n            rate_model = [i + j for (i, j) in zip(rate_faults, rate_bg)]\n            lim = [[x[0] - 0.05, x[-1] + 0.05], [min(rate_model) / 2.0, max(rate_model) * 2.0]]\n            axis = ['magnitude', 'annual earthquake rates']\n            title = 'MFD in zone ' + str(zone) + txt_no_bg\n            path = self.pathlog + '/MFD_zone' + str(zone) + '.png'\n            if 'cat_rates' in loc_cat[zone].keys():\n                data = loc_cat[zone]['cat_rates']\n            else:\n                data = False\n            if data == None:\n                data = False\n            if data == True:\n                if len(data[0]) == 0:\n                    data = False\n                if len(data[0]) != len(data[1]):\n                    data = False\n                    print('For zone', zone, ' : wrong bining')\n                    print('please check the geojson file')\n            plt_mfd.local(x, [rate_model, rate_faults, rate_bg, smooth], data, lim, axis, path, title)",
        "mutated": [
            "def initialize(self):\n    if False:\n        i = 10\n    path = self.param['dirpath']\n    explo_time = self.param['main']['parameters']['explo_time']\n    if self.param['main']['parameters']['use_multiF'] in ['True', 'true']:\n        use_multiF = True\n    else:\n        use_multiF == False\n    max_rup_per_file = 2000\n    faults_names = self.faults_names\n    scenarios_names = self.scenarios_names\n    faults_data = self.faults_data\n    (faults_lon, faults_lat) = (self.faults_lon, self.faults_lat)\n    list_src_files = []\n    log_sr_file = open(self.pathlog + '/slip_rate_sample_' + str(self.sample) + '.txt', 'w')\n    log_mdf_file = open(self.pathlog + '/mdf_sample_' + str(self.sample) + '.txt', 'w')\n    cut_sm_file = False\n    if len(faults_names) + len(scenarios_names) > max_rup_per_file:\n        cut_sm_file = True\n    if cut_sm_file == False:\n        XMLfile = open(self.path + '/Source_model_' + str(self.sample) + '.xml', 'w')\n    else:\n        n_cut_sf = 1\n        while len(faults_names) / n_cut_sf > max_rup_per_file:\n            n_cut_sf += 1\n        n_cut_mf = 1\n        while len(scenarios_names) / n_cut_mf > max_rup_per_file:\n            n_cut_mf += 1\n        if use_multiF == False:\n            ' create the file list'\n            (sf_files, sf_counter) = ([], [])\n            for i in range(n_cut_sf):\n                f = self.path + '/sm_' + str(self.sample) + '_sf_' + str(i + 1) + '.xml'\n                sf_files.append(open(f, 'w'))\n                sf_counter.append(0)\n                list_src_files.append(f)\n            (mf_files, mf_counter) = ([], [])\n            for i in range(n_cut_mf):\n                f = self.path + '/sm_' + str(self.sample) + '_mf_' + str(i + 1) + '.xml'\n                mf_files.append(open(f, 'w'))\n                mf_counter.append(0)\n                list_src_files.append(f)\n        if use_multiF == True:\n            n_cut_f = n_cut_sf + n_cut_mf\n            s_files = []\n            for i in range(n_cut_mf):\n                f = self.path + '/sm_' + str(i) + '.xml'\n                s_files.append(f)\n                list_src_files.append(f)\n            (dict_txt, dict_n_rup) = ({}, {})\n            for f in s_files:\n                dict_txt.update({f: ''})\n                dict_n_rup.update({f: 0})\n    include_all_faults = False\n    if 'include_all_faults' in self.param['main']['background'].keys():\n        if self.param['main']['background']['include_all_faults'] in ['True', 'true']:\n            include_all_faults = True\n    if use_multiF == True:\n        '\\n            #######################################\\n            #######################################\\n            USING MULTIFAULT TYPOLOGY IN OQ\\n            #######################################\\n            #######################################\\n            '\n        simplify_faults = self.param['main']['parameters']['simplify_faults']\n        if simplify_faults in ['True', 'true']:\n            resample = [False]\n        elif not 'resample' in self.param['main']['parameters'].keys():\n            resample = [False]\n        else:\n            rsp = self.param['main']['parameters']['resample']\n            if rsp[0] in ['True', 'true']:\n                resample = [True]\n                resample.append(float(rsp[1]))\n                resample.append(float(rsp[2]))\n                resample.append(float(rsp[3]))\n            else:\n                resample = [False]\n        if 'vertical_faults' in self.param['main']['parameters'].keys():\n            vertical_faults = self.param['main']['parameters']['vertical_faults']\n            if vertical_faults in ['True', 'true']:\n                vertical_faults = True\n            else:\n                vertical_faults = False\n        else:\n            vertical_faults = False\n        sections_xml = path + self.Run_Name + '/ssm/' + self.Model_name + '_sections.xml'\n        if not os.path.exists(sections_xml):\n            txt = wsf.start(self.Model_name)\n            for section_id in range(len(faults_names)):\n                geotype = 'kite'\n                txt = wsf.wrt_section(txt, section_id, faults_names, faults_data, geotype, resample, vertical_faults)\n            txt = wsf.end(txt)\n            wsf.build(sections_xml, txt)\n        log_general_parameters_file = open(self.pathlog + '/general_parameters_sample_' + str(self.sample) + '.txt', 'w')\n        M_min = float(self.Mmin)\n        log_general_parameters_file.write('M_tronc\\t' + str(M_min) + '\\n')\n        mfd_param = self.mfd_param\n        log_general_parameters_file.write('b_value\\t' + str(mfd_param['b_value']) + '\\n')\n        log_general_parameters_file.close()\n        faults_area = []\n        faults_length = []\n        faults_width = []\n        faults_slip_rates = []\n        faults_mecanism = []\n        faults_shear_mod = []\n        '########################################################\\n            # Random sampling of the fault slip-rate\\n            ########################################################'\n        print('Picking slip-rates...')\n        if self.sample == 1:\n            self.sr_correl = False\n        if self.sr_correl == True:\n            M_faults_correl = []\n            for Fault_name in faults_names:\n                M_faults_correl_i = []\n                sc_with_fault = []\n                for index_scenario in range(len(scenarios_names)):\n                    scenario_i = self.rupture_set[index_scenario]\n                    if Fault_name in scenario_i:\n                        sc_with_fault += scenario_i\n                for Fault_name_i in faults_names:\n                    nb_join_ruptures = 0\n                    if Fault_name == Fault_name_i:\n                        nb_join_ruptures = 0\n                    elif Fault_name_i in sc_with_fault:\n                        nb_join_ruptures = sc_with_fault.count(Fault_name_i)\n                    else:\n                        nb_join_ruptures = 0\n                    M_faults_correl_i.append(nb_join_ruptures)\n                M_faults_correl.append(M_faults_correl_i)\n            M_linked_lvl = np.zeros_like(M_faults_correl)\n            for lvl in [1, 2, 3, 4]:\n                for i in range(len(faults_names)):\n                    for j in range(len(faults_names)):\n                        if M_linked_lvl[i][j] == 0:\n                            if M_faults_correl[i][j] != 0:\n                                M_linked_lvl[i][j] = lvl\n                            else:\n                                for jj in range(len(M_faults_correl[j])):\n                                    if M_faults_correl[j][jj] != 0:\n                                        if M_linked_lvl[i][j] == 0:\n                                            M_linked_lvl[i][j] = lvl + 1\n            max_correl = np.max(M_faults_correl)\n            list_quater_picked = list(np.zeros(len(faults_names)))\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                sr_values = [faults_data[index_fault]['slip_rate_min'], faults_data[index_fault]['slip_rate_moy'], faults_data[index_fault]['slip_rate_max']]\n                slip_rate = select_sr.select(sr_values, self.sample, index_fault, M_linked_lvl[index_fault], list_quater_picked)\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        else:\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                slip_rate_min = faults_data[index_fault]['slip_rate_min']\n                slip_rate_moy = faults_data[index_fault]['slip_rate_moy']\n                slip_rate_max = faults_data[index_fault]['slip_rate_max']\n                if self.sample == 1:\n                    slip_rate = slip_rate_moy\n                else:\n                    slip_rate_inf = np.random.uniform(slip_rate_min, slip_rate_moy)\n                    slip_rate_sup = np.random.uniform(slip_rate_moy, slip_rate_max)\n                    slip_rate = np.random.choice([slip_rate_inf, slip_rate_sup])\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        print('\\t\\tslip-rates picked.')\n        ratio_test = 0.5\n        count_reruns = 1\n        count_mfd90 = 1\n        f_pkl_mdf = self.pathlog + '/mfd_' + str(self.sample) + '.pkl'\n        re_use_mfd_pkl = True\n        if not os.path.isfile(f_pkl_mdf):\n            re_use_mfd_pkl = False\n        if self.param['main']['parameters']['force_rerun'] == True:\n            re_use_mfd_pkl = False\n        if re_use_mfd_pkl == False:\n            while abs(ratio_test - 1) > self.fit_quality or math.isnan(ratio_test) == True:\n                MFDs = EQ_on_faults.EQ_on_faults_from_sr(self.Run_Name, M_min, mfd_param, faults_names, faults_area, faults_length, faults_width, faults_slip_rates, scenarios_names, faults_shear_mod, self.path, self.pathlog, self.sample, self.selected_ScL, self.dimention_used, self.use_all_ScL_data, faults_mecanism, self.bg_ratio, self.size_of_increment, self.mfd_hyp, count_reruns, faults_lon, faults_lat, self.Mmax_range, self.calculation_log_file, self.branch, self.param)\n                ratio_test = MFDs.ratio_test\n                if abs(ratio_test - 1) > self.fit_quality:\n                    print('bad sampling => re-run')\n                    count_reruns += 1\n                    if MFDs.ratio_NMS > 90.0:\n                        count_reruns -= 1\n                        count_mfd90 += 1\n                    else:\n                        count_mfd90 = 1\n                elif MFDs.ratio_NMS > 90.0:\n                    ratio_test = 0.5\n                    print('bad sampling => re-run')\n                    count_mfd90 += 1\n                else:\n                    count_mfd90 = 1\n                if math.isnan(ratio_test) == True:\n                    print('bad sampling => re-run')\n                    count_reruns = 1\n                if count_reruns > 3 or count_mfd90 > 3:\n                    print('\\n\\n\\n!!!!!! maybe there is a problem!!!')\n                    ratio_test = 1.0\n            with open(f_pkl_mdf, 'wb') as f:\n                MFDs_to_pkl = [MFDs.EQ_rate_BG, MFDs.faults_names, MFDs.OQ_entry_faults, MFDs.scenarios_names, MFDs.OQ_entry_scenarios, MFDs.index_faults_in_scenario, MFDs.M_slip_repartition]\n                pickle.dump(MFDs_to_pkl, f)\n        else:\n            print('Reloading MFDs from previous run')\n            with open(f_pkl_mdf, 'rb') as f:\n                MFDs_to_pkl = pickle.load(f)\n        EQ_rate_BG = MFDs_to_pkl[0]\n        faults_names = MFDs_to_pkl[1]\n        OQ_entry_faults = MFDs_to_pkl[2]\n        scenarios_names = MFDs_to_pkl[3]\n        OQ_entry_scenarios = MFDs_to_pkl[4]\n        index_faults_in_scenario = MFDs_to_pkl[5]\n        M_slip_repartition = MFDs_to_pkl[6]\n        if self.selected_ScL == 'Le2010':\n            ScL_oq = 'Leonard2014_SCR'\n        if self.selected_ScL == 'WC1994':\n            ScL_oq = 'WC1994'\n        else:\n            ScL_oq = 'WC1994'\n        (Lon_bg, Lat_bg) = bg.geom(self.Model_name, self.File_bg)\n        Poly_bg = []\n        for (x1, y1) in zip(Lon_bg, Lat_bg):\n            Poly_bg.append((x1, y1))\n        try:\n            bbPath_BG = mplPath.Path(Poly_bg)\n        except:\n            print('ERROR, please make sure the model name matches in the bg file')\n        f_in_bg = []\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            for (lon, lat) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                if bbPath_BG.contains_point((lon, lat)):\n                    f_in_bg.append(index_fault)\n        outside_faults = []\n        if include_all_faults == True:\n            for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n                if not index_fault in f_in_bg:\n                    f_in_bg.append(index_fault)\n                    outside_faults.append(index_fault)\n        source_id = 0\n        if cut_sm_file == False:\n            source_xml = self.path + '/Source_model_' + str(self.sample) + '.xml'\n            list_src_files.append(source_xml)\n            trt = faults_data[0]['domain']\n            txt = wmfs.start(explo_time, trt)\n            name = 'multifaultsource'\n            txt = wmfs.start_multifault_source(txt, name, trt, sections_xml, source_id)\n        else:\n            for f in s_files:\n                trt = faults_data[0]['domain']\n                dict_txt[f] = wmfs.start(explo_time, trt)\n                name = 'multifaultsource_' + str(source_id)\n                dict_txt[f] = wmfs.start_multifault_source(dict_txt[f], name, trt, sections_xml, source_id)\n                source_id += 1\n            f = list(dict_txt.keys())[0]\n        single_f_xml = self.path + '/single_sec_rup.xml'\n        trt = faults_data[0]['domain']\n        single_txt = wss.start(self.Model_name, trt)\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            if index_fault in f_in_bg:\n                i_MFD = np.where(np.array(faults_names) == fault_name)[0][0]\n                MFD = OQ_entry_faults[i_MFD]\n                if sum(MFD) != 0:\n                    source_id = source_id + 1\n                    Fault_Name = self.Model_name + '_' + str(fault_name)\n                    fault_trt = faults_data[index_fault]['domain']\n                    if not fault_trt in str(self.Domain_in_the_model):\n                        self.Domain_in_the_model.append(fault_trt)\n                    trt = str(fault_trt)\n                    rake = faults_data[index_fault]['rake']\n                    geotype = 'kite'\n                    name = 'single_fault_' + fault_name\n                    single_txt = wss.wrt_source(single_txt, index_fault, faults_names, faults_data, geotype, resample, vertical_faults, fault_trt, M_min, MFD, ScL_oq)\n        single_txt = wss.end(single_txt)\n        wss.build(single_f_xml, single_txt)\n        if len(self.rupture_set) != 0:\n            for scenario in enumerate(scenarios_names):\n                sc_in = False\n                index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                index_faults_in_sc = index_faults_in_scenario[index_scenario][0]\n                for i in index_faults_in_sc:\n                    if i in f_in_bg:\n                        sc_in = True\n                if sc_in == True:\n                    index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                    MFD = OQ_entry_scenarios[index_scenario]\n                    if sum(MFD) != 0:\n                        faults_in_scenario = np.take(faults_names, index_faults_in_sc)\n                        source_id = source_id + 1\n                        scenar_name = '_'.join(('{!s}={!r}'.format(key, val) for (key, val) in scenario[1].items()))\n                        source_name = self.Model_name + '_scenario_'\n                        source_name += str(scenar_name)\n                        list_trt = []\n                        scenario_mechanism = []\n                        for fname in faults_in_scenario:\n                            i = faults_names.index(fname)\n                            scenario_mechanism.append(faults_data[i]['rake'])\n                            fault_trt = faults_data[i]['domain']\n                            list_trt.append(fault_trt)\n                            if not fault_trt in str(self.Domain_in_the_model):\n                                self.Domain_in_the_model.append(fault_trt)\n                        fault_trt = max(list_trt, key=list_trt.count)\n                        trt = str(fault_trt)\n                        rake = np.mean(scenario_mechanism)\n                        if cut_sm_file == False:\n                            txt = wmfs.wrt_multifault_source(txt, MFD, self.Mmin, explo_time, rake, index_faults_in_sc)\n                        else:\n                            if not dict_n_rup[f] < max_rup_per_file:\n                                i = 0\n                                while dict_n_rup[f] > max_rup_per_file:\n                                    i += 1\n                                    f = list(dict_txt.keys())[i]\n                            txt = dict_txt[f]\n                            dict_txt[f] = wmfs.wrt_multifault_source(txt, MFD, self.Mmin, explo_time, rake, index_faults_in_sc)\n                            dict_n_rup[f] += 1\n        if cut_sm_file == False:\n            txt = wmfs.end_multifault_source(txt)\n            txt = wmfs.end(txt)\n            wmfs.build(source_xml, txt)\n        else:\n            for f in s_files:\n                if dict_n_rup[f] > 0:\n                    dict_txt[f] = wmfs.end_multifault_source(dict_txt[f])\n                    txt = wmfs.end(dict_txt[f])\n                    wmfs.build(f, txt)\n    else:\n        '\\n            ###########\\n            ############\\n            NOT USING MULTIFAULTSOURCE TYPOLOGY in OQ\\n\\n            '\n        line = \"<?xml version='1.0' encoding='utf-8'?>\\n\"\n        line += '<nrml xmlns:gml=\"http://www.opengis.net/gml\"\\n'\n        line += '\\txmlns=\"http://openquake.org/xmlns/nrml/0.5\">\\n'\n        line += '\\t<sourceModel name=\"Hazard Model\"'\n        line += ' investigation_time=\"' + str(round(explo_time, 1)) + '\">\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n        line = '\\t\\t<sourceGroup\\nname=\"group 1\"\\nrup_interdep=\"indep\"\\nsrc_interdep=\"indep\"\\ntectonicRegion=\"Active Shallow Crust\"\\n>\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n        log_general_parameters_file = open(self.pathlog + '/Log/general_parameters_sample_' + str(self.sample) + '.txt', 'w')\n        M_min = float(self.Mmin)\n        log_general_parameters_file.write('M_tronc\\t' + str(M_min) + '\\n')\n        log_general_parameters_file.write('b_value\\t' + str(self.b_value) + '\\n')\n        log_general_parameters_file.close()\n        faults_area = []\n        faults_length = []\n        faults_width = []\n        faults_slip_rates = []\n        faults_mecanism = []\n        faults_shear_mod = []\n        '########################################################\\n            # Random sampling of the fault slip-rate\\n            ########################################################'\n        print('Picking slip-rates...')\n        if self.sample == 1:\n            self.sr_correl = False\n        if self.sr_correl == True:\n            M_faults_correl = []\n            for Fault_name in faults_names:\n                M_faults_correl_i = []\n                sc_with_fault = []\n                for index_scenario in range(len(scenarios_names)):\n                    scenario_i = self.rupture_set[index_scenario]\n                    if Fault_name in scenario_i:\n                        sc_with_fault += scenario_i\n                for Fault_name_i in faults_names:\n                    nb_join_ruptures = 0\n                    if Fault_name == Fault_name_i:\n                        nb_join_ruptures = 0\n                    elif Fault_name_i in sc_with_fault:\n                        nb_join_ruptures = sc_with_fault.count(Fault_name_i)\n                    else:\n                        nb_join_ruptures = 0\n                    M_faults_correl_i.append(nb_join_ruptures)\n                M_faults_correl.append(M_faults_correl_i)\n            M_linked_lvl = np.zeros_like(M_faults_correl)\n            for lvl in [1, 2, 3, 4]:\n                for i in range(len(faults_names)):\n                    for j in range(len(faults_names)):\n                        if M_linked_lvl[i][j] == 0:\n                            if M_faults_correl[i][j] != 0:\n                                M_linked_lvl[i][j] = lvl\n                            else:\n                                for jj in range(len(M_faults_correl[j])):\n                                    if M_faults_correl[j][jj] != 0:\n                                        if M_linked_lvl[i][j] == 0:\n                                            M_linked_lvl[i][j] = lvl + 1\n            max_correl = np.max(M_faults_correl)\n            list_quater_picked = list(np.zeros(len(faults_names)))\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                sr_values = [faults_data[index_fault]['slip_rate_min'], faults_data[index_fault]['slip_rate_moy'], faults_data[index_fault]['slip_rate_max']]\n                slip_rate = select_sr.select(sr_values, self.sample, index_fault, M_linked_lvl[index_fault], list_quater_picked)\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        else:\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                slip_rate_min = faults_data[index_fault]['slip_rate_min']\n                slip_rate_moy = faults_data[index_fault]['slip_rate_moy']\n                slip_rate_max = faults_data[index_fault]['slip_rate_max']\n                if self.sample == 1:\n                    slip_rate = slip_rate_moy\n                else:\n                    slip_rate_inf = np.random.uniform(slip_rate_min, slip_rate_moy)\n                    slip_rate_sup = np.random.uniform(slip_rate_moy, slip_rate_max)\n                    slip_rate = np.random.choice([slip_rate_inf, slip_rate_sup])\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        print('\\t\\tslip-rates picked.')\n        ratio_test = 0.5\n        count_reruns = 1\n        count_mfd90 = 1\n        f_pkl_mdf = self.pathlog + '/mfd_' + str(self.sample) + '.pkl'\n        re_use_mfd_pkl = True\n        if not os.path.isfile(f_pkl_mdf):\n            re_use_mfd_pkl = False\n        if re_use_mfd_pkl == False:\n            while abs(ratio_test - 1) > self.fit_quality or math.isnan(ratio_test) == True:\n                MFDs = EQ_on_faults.EQ_on_faults_from_sr(M_min, mfd_param, faults_names, faults_area, faults_length, faults_width, faults_slip_rates, scenarios_names, faults_shear_mod, self.path, self.sample, self.selected_ScL, self.dimention_used, self.use_all_ScL_data, faults_mecanism, self.bg_ratio, self.size_of_increment, self.mfd_hyp, count_reruns, faults_lon, faults_lat, self.Mmax_range, self.calculation_log_file, self.branch, self.param)\n                ratio_test = MFDs.ratio_test\n                if abs(ratio_test - 1) > self.fit_quality:\n                    print('bad sampling => re-run')\n                    count_reruns += 1\n                    if MFDs.ratio_NMS > 90.0:\n                        count_reruns -= 1\n                        count_mfd90 += 1\n                    else:\n                        count_mfd90 = 1\n                elif MFDs.ratio_NMS > 90.0:\n                    ratio_test = 0.5\n                    print('bad sampling => re-run')\n                    count_mfd90 += 1\n                else:\n                    count_mfd90 = 1\n                if math.isnan(ratio_test) == True:\n                    print('bad sampling => re-run')\n                    count_reruns = 1\n                if count_reruns > 3 or count_mfd90 > 3:\n                    print('\\n\\n\\n!!!!!! maybe there is a problem!!!')\n                    ratio_test = 1.0\n            with open(f_pkl_mdf, 'wb') as f:\n                MFDs_to_pkl = [MFDs.EQ_rate_BG, MFDs.faults_names, MFDs.OQ_entry_faults, MFDs.scenarios_names, MFDs.OQ_entry_scenarios, MFDs.index_faults_in_scenario, MFDs.M_slip_repartition]\n                pickle.dump(MFDs_to_pkl, f)\n        else:\n            print('Reloading MFDs from previous run')\n            with open(f_pkl_mdf, 'rb') as f:\n                MFDs_to_pkl = pickle.load(f)\n        EQ_rate_BG = MFDs_to_pkl[0]\n        faults_names = MFDs_to_pkl[1]\n        OQ_entry_faults = MFDs_to_pkl[2]\n        scenarios_names = MFDs_to_pkl[3]\n        OQ_entry_scenarios = MFDs_to_pkl[4]\n        index_faults_in_scenario = MFDs_to_pkl[5]\n        M_slip_repartition = MFDs_to_pkl[6]\n        if self.selected_ScL == 'Le2010':\n            ScL_oq = 'Leonard2014_SCR'\n        elif self.selected_ScL == 'WC1994':\n            ScL_oq = 'WC1994'\n        else:\n            ScL_oq = 'WC1994'\n        (Lon_bg, Lat_bg) = bg.geom(self.Model_name, self.File_bg)\n        Poly_bg = []\n        for (x1, y1) in zip(Lon_bg, Lat_bg):\n            Poly_bg.append((x1, y1))\n        bbPath_BG = mplPath.Path(Poly_bg)\n        f_in_bg = []\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            for (lon, lat) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                if bbPath_BG.contains_point((lon, lat)):\n                    f_in_bg.append(index_fault)\n        outside_faults = []\n        if include_all_faults == True:\n            for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n                if not index_fault in f_in_bg:\n                    f_in_bg.append(index_fault)\n                    outside_faults.append(index_fault)\n        ID_number = 0\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            if index_fault in f_in_bg:\n                use_simple_faults = False\n                if use_simple_faults == True:\n                    (line, self.Domain_in_the_model, ID_number) = fault_source.write_simple_fault(index_fault, fault_name, OQ_entry_faults, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, M_min, ID_number)\n                else:\n                    (line, self.Domain_in_the_model, ID_number) = fault_source.write_non_parametric_one_fault(index_fault, fault_name, OQ_entry_faults, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, M_min, ID_number, explo_time)\n                if cut_sm_file == False:\n                    XMLfile.write(line)\n                else:\n                    i_w = 0\n                    while sf_counter[i_w] > 500:\n                        i_w += 1\n                    sf_files[i_w].write(line)\n                    sf_counter[i_w] += 1\n        if len(self.rupture_set) != 0:\n            for scenario in enumerate(scenarios_names):\n                sc_in = False\n                index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                for i in index_faults_in_scenario[index_scenario][0]:\n                    if i in f_in_bg:\n                        sc_in = True\n                if sc_in == True:\n                    use_non_param = True\n                    if use_non_param == False:\n                        (line, ID_number) = fault_source.write_characteristic_scenario(scenarios_names, OQ_entry_scenarios, index_faults_in_scenario, scenario, faults_names, self.Model_name, faults_data, log_mdf_file, M_min, ID_number)\n                    else:\n                        (line, ID_number) = fault_source.write_non_parametric_source(scenario, scenarios_names, OQ_entry_scenarios, index_faults_in_scenario, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, explo_time, M_min, ID_number)\n                    if cut_sm_file == False:\n                        XMLfile.write(line)\n                    else:\n                        i_w = 0\n                        while mf_counter[i_w] > 500:\n                            i_w += 1\n                        mf_files[i_w].write(line)\n                        mf_counter[i_w] += 1\n    '#########################\\n        # Defining the background seismicity\\n        #########################'\n    MFD = EQ_rate_BG\n    pts_list = {}\n    if sum(MFD) != 0.0 and self.param['main']['background']['option_bg'] == 'zone':\n        bg_file = self.path + '/bg_' + str(self.sample) + '.xml'\n        list_src_files.append(bg_file)\n        bg_file = open(bg_file, 'w')\n        line = \"<?xml version='1.0' encoding='utf-8'?>\\n\"\n        line += '<nrml xmlns:gml=\"http://www.opengis.net/gml\"\\n'\n        line += '\\txmlns=\"http://openquake.org/xmlns/nrml/0.5\">\\n'\n        line += '\\t<sourceModel name=\"Hazard Model\">\\n'\n        (upperSeismoDepth, lowerSeismoDepth, ruptAspectRatio, nodalPlanes, hypoDepths) = bg.prop(self.Model_name, self.file_prop_bg)\n        line += '\\t\\t<sourceGroup\\nname=\"group 2\"\\nrup_interdep=\"indep\"\\nsrc_interdep=\"indep\"\\ntectonicRegion=\"' + str(self.Domain_in_the_model[0]) + '\"\\n>\\n'\n        line += '\\t\\t<areaSource id=\"' + str(source_id + 1) + '\" name=\"Background\" tectonicRegion=\"' + str(self.Domain_in_the_model[0]) + '\">\\n'\n        line += '\\t\\t\\t<areaGeometry>\\n'\n        line += '\\t\\t\\t\\t<gml:Polygon>\\n'\n        line += '\\t\\t\\t\\t\\t<gml:exterior>\\n'\n        line += '\\t\\t\\t\\t\\t\\t<gml:LinearRing>\\n'\n        line += '\\t\\t\\t\\t\\t\\t\\t<gml:posList>\\n'\n        for (x, y) in zip(Lon_bg, Lat_bg):\n            line += '\\t\\t\\t\\t\\t\\t\\t\\t' + str(x) + ' ' + str(y) + '\\n'\n        line += '\\t\\t\\t\\t\\t\\t\\t</gml:posList>\\n'\n        line += '\\t\\t\\t\\t\\t\\t</gml:LinearRing>\\n'\n        line += '\\t\\t\\t\\t\\t</gml:exterior>\\n'\n        line += '\\t\\t\\t\\t</gml:Polygon>\\n'\n        line += '\\t\\t\\t\\t<upperSeismoDepth>' + str(upperSeismoDepth) + '</upperSeismoDepth>\\n'\n        line += '\\t\\t\\t\\t<lowerSeismoDepth>' + str(lowerSeismoDepth) + '</lowerSeismoDepth>\\n'\n        line += '\\t\\t\\t</areaGeometry>\\n'\n        line += '\\t\\t\\t<magScaleRel>' + ScL_oq + '</magScaleRel>\\n'\n        line += '\\t\\t\\t<ruptAspectRatio>' + str(ruptAspectRatio) + '</ruptAspectRatio>\\n'\n        log_mdf_file.write('Background' + '\\t' + str(M_min) + '\\t' + ' '.join(list(map(str, MFD))) + '\\n')\n        line += '\\t\\t\\t<incrementalMFD binWidth=\"0.10\" minMag=\"' + str(M_min) + '\">\\n'\n        line += '\\t\\t\\t<occurRates> ' + ' '.join(list(map(str, MFD))) + '</occurRates>\\n'\n        line += '\\t\\t\\t</incrementalMFD>\\n'\n        line += '\\t\\t\\t<nodalPlaneDist>\\n'\n        for i in range(len(nodalPlanes)):\n            line += '\\t\\t\\t\\t<nodalPlane probability=\"' + str(nodalPlanes[i][0]) + '\" strike=\"' + str(nodalPlanes[i][1]) + '\" dip=\"' + str(nodalPlanes[i][2]) + '\" rake=\"' + str(nodalPlanes[i][3]) + '\" />\\n'\n        line += '\\t\\t\\t</nodalPlaneDist>\\n'\n        line += '\\t\\t\\t<hypoDepthDist>\\n'\n        for i in range(len(hypoDepths)):\n            line += '\\t\\t\\t\\t<hypoDepth probability=\"' + str(hypoDepths[i][0]) + '\" depth=\"' + str(hypoDepths[i][1]) + '\" />\\n'\n        line += '\\t\\t\\t</hypoDepthDist>\\n'\n        line += '\\t\\t</areaSource>\\n'\n        line += '\\t</sourceGroup>\\n'\n        line += '\\t</sourceModel>\\n'\n        line += '</nrml>\\n'\n        bg_file.write(line)\n        bg_file.close()\n    elif sum(MFD) != 0.0 and self.param['main']['background']['option_bg'] == 'smooth':\n        Mmin_checked = False\n        Mmax = M_min + len(EQ_rate_BG) * 0.1 - 1\n        mags = np.linspace(M_min, Mmax, len(EQ_rate_BG))\n        list_bg_xml = self.list_fbg\n        if os.path.isdir(self.fbgpath):\n            list_bg_xml = [self.fbgpath + '/' + i for i in list_bg_xml if '.xml' in i]\n        with open(list_bg_xml[0]) as myfile:\n            if 'multiPointSource' in myfile.read():\n                multiPointSource_type = True\n            else:\n                multiPointSource_type = False\n        if multiPointSource_type == True:\n            bg.get_multipoints(EQ_rate_BG, M_min, bbPath_BG, list_bg_xml, include_all_faults, outside_faults, faults_data, OQ_entry_faults, self.path, self.pathlog, list_src_files)\n        else:\n            pts_list = {}\n            pts_out_list = {}\n            sum_rates = [0.0 for _ in mags]\n            for fbg in list_bg_xml:\n                tree = ET.parse(fbg)\n                ET.register_namespace('', 'http://openquake.org/xmlns/nrml/0.5')\n                nrml = tree.getroot()\n                i_point = 0\n                for pointSource in nrml[0][0]:\n                    pt_in_BG = False\n                    i_child = 0\n                    for child in pointSource.getchildren():\n                        if 'pointGeometry' in str(child):\n                            s_tmp = pointSource[i_child][0][0].text\n                            s_tmp = s_tmp.replace('\\n', '')\n                            s_tmp = [float(i) for i in s_tmp.split(' ') if i != '']\n                            if bbPath_BG.contains_point((s_tmp[0], s_tmp[1])) == 1:\n                                pt_in_BG = True\n                            str_loc = str(s_tmp[0]) + '_' + str(s_tmp[1])\n                        if 'truncGutenbergRichterMFD' in str(child):\n                            aValue = nrml[0][0][i_point][i_child].get('aValue')\n                            minMag = nrml[0][0][i_point][i_child].get('minMag')\n                            i_trGR = i_child\n                        i_child += 1\n                    aValue = nrml[0][0][i_point][i_trGR].get('aValue')\n                    minMag = nrml[0][0][i_point][i_trGR].get('minMag')\n                    bValue = nrml[0][0][i_point][i_trGR].get('bValue')\n                    maxMag = nrml[0][0][i_point][i_trGR].get('maxMag')\n                    mfd_smooth = []\n                    i_mag = 0\n                    for mag in mags:\n                        mag_lo = mag - 0.05\n                        mag_hi = mag + 0.05\n                        r = 10 ** (float(aValue) - float(bValue) * mag_lo) - 10 ** (float(aValue) - float(bValue) * mag_hi)\n                        sum_rates[i_mag] += r\n                        i_mag += 1\n                        mfd_smooth.append(r)\n                    if pt_in_BG == True:\n                        pts_list.update({str_loc: {'aValue': aValue, 'bValue': bValue, 'maxMag': maxMag, 'minMag': minMag, 'mfd_smooth': mfd_smooth}})\n                        if Mmin_checked == False:\n                            if float(minMag) < M_min:\n                                print('!!!!')\n                                print('WARNING : BG has a smaller Mmin than the SHERIFS input')\n                                print('!!!!')\n                                Mmin_checked = True\n                    elif include_all_faults == True:\n                        pt_very_far = True\n                        lon_lat_distance_criteria = 1.0\n                        i = 0\n                        while pt_very_far == False and i < len(outside_faults):\n                            i_fault = outside_faults[i]\n                            mean_lon = np.mean(faults_data[index_fault]['lon'])\n                            mean_lat = np.mean(faults_data[index_fault]['lat'])\n                            if abs(float(s_tmp[0]) - mean_lon) < lon_lat_distance_criteria:\n                                pt_very_far = False\n                            if abs(float(s_tmp[1]) - mean_lat) < lon_lat_distance_criteria:\n                                pt_very_far = False\n                            i += 1\n                        if pt_very_far == False:\n                            dist_critera = 50.0\n                            dist = 1000000.0\n                            closest_fault = 'nope'\n                            for i_fault in outside_faults:\n                                mean_lon = np.mean(faults_data[index_fault]['lon'])\n                                mean_lat = np.mean(faults_data[index_fault]['lat'])\n                                dist_i = distance(mean_lon, mean_lat, float(s_tmp[0]), float(s_tmp[1]))\n                                if dist_i < dist_critera:\n                                    for (lon_f, lat_f) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                                        dist_i = distance(mean_lon, mean_lat, float(s_tmp[0]), float(s_tmp[1]))\n                                        if dist_i < dist:\n                                            dist = dist_i\n                                            closest_fault = i_fault\n                                if dist_i < dist:\n                                    dist = dist_i\n                                    closest_fault = i_fault\n                            closest_dist = dist\n                            pts_out_list.update({str_loc: {'aValue': aValue, 'bValue': bValue, 'maxMag': maxMag, 'minMag': minMag, 'mfd_smooth': mfd_smooth, 'distance': closest_dist, 'closest_fault': i_fault}})\n                    i_point += 1\n            nb_pt_in_buff = {}\n            if include_all_faults == True:\n                for i_fault in outside_faults:\n                    buffer_1 = 10.0\n                    buffer_2 = 20.0\n                    nb_buf1 = 0\n                    nb_buf2 = 0\n                    for str_loc in pts_out_list.keys():\n                        if pts_out_list[str_loc]['closest_fault'] == i_fault:\n                            if pts_out_list[str_loc]['closest_dist'] < buffer_1:\n                                nb_buf1 += 1\n                            elif pts_out_list[str_loc]['closest_dist'] < buffer_2:\n                                nb_buf2 += 1\n                    nb_pt_in_buff.update({i_fault: {'nb_buf1': nb_buf1, 'nb_buf2': nb_buf2}})\n            sum_bg_min = 0.0\n            i_bg = 0\n            for fbg in list_bg_xml:\n                tree = ET.parse(fbg)\n                ET.register_namespace('', 'http://openquake.org/xmlns/nrml/0.5')\n                nrml = tree.getroot()\n                i_point = 0\n                for pointSource in nrml[0][0]:\n                    pt_in_BG = False\n                    i_child = 0\n                    for child in pointSource.getchildren():\n                        if 'magScaleRel' in str(child):\n                            nrml[0][0][i_point][i_child].text = ScL_oq\n                        if 'pointGeometry' in str(child):\n                            s_tmp = pointSource[i_child][0][0].text\n                            s_tmp = s_tmp.replace('\\n', '')\n                            s_tmp = [float(i) for i in s_tmp.split(' ') if i != '']\n                            str_loc = str(s_tmp[0]) + '_' + str(s_tmp[1])\n                        if 'truncGutenbergRichterMFD' in str(child):\n                            i_trGR = i_child\n                        i_child += 1\n                    if str_loc in pts_list.keys():\n                        b_value = float(pts_list[str_loc]['bValue'])\n                        a_value = float(pts_list[str_loc]['aValue'])\n                        attrib = {'minMag': str(M_min), 'binWidth': '0.10'}\n                        element = nrml[0][0][i_point].makeelement('incrementalMFD', attrib)\n                        nrml[0][0][i_point].append(element)\n                        element = nrml[0][0][i_point][-1].makeelement('occurRates', {})\n                        nrml[0][0][i_point][-1].append(element)\n                        str_tmp = ' '\n                        pt_scl_mfd = []\n                        i_mag = 0\n                        for mag in mags:\n                            mag_lo = mag - 0.05\n                            mag_hi = mag + 0.05\n                            r = 10 ** (a_value - b_value * mag_lo) - 10 ** (a_value - b_value * mag_hi)\n                            norm_r = r / sum_rates[i_mag]\n                            str_tmp += str(EQ_rate_BG[i_mag] * norm_r)\n                            str_tmp += ' '\n                            sum_bg_min += EQ_rate_BG[i_mag] * norm_r\n                            pt_scl_mfd.append(EQ_rate_BG[i_mag] * norm_r)\n                            i_mag += 1\n                        pts_list[str_loc].update({'scaled_mfd': pt_scl_mfd})\n                        nrml[0][0][i_point][-1][0].text = str_tmp\n                        nrml[0][0][i_point].remove(nrml[0][0][i_point][i_trGR])\n                    if include_all_faults == True:\n                        if str_loc in pts_out_list.keys():\n                            b_value = float(pts_list[str_loc]['bValue'])\n                            a_value = float(pts_list[str_loc]['aValue'])\n                            attrib = {'minMag': str(M_min), 'binWidth': '0.10'}\n                            element = nrml[0][0][i_point].makeelement('incrementalMFD', attrib)\n                            nrml[0][0][i_point].append(element)\n                            element = nrml[0][0][i_point][-1].makeelement('occurRates', {})\n                            nrml[0][0][i_point][-1].append(element)\n                            str_tmp = ' '\n                            pt_scl_mfd = []\n                            i_fault = pts_out_list[str_loc]['closest_fault']\n                            mfd_single_clst_f = OQ_entry_faults[i_fault]\n                            id_ruptures = []\n                            mfd_mlt_clst_f = []\n                            for (scenario_i, mfd_i) in zip(index_faults_in_scenario, OQ_entry_scenarios):\n                                if i_fault in scenario_i:\n                                    id_ruptures.append(scenario_i)\n                                    mfd_mlt_clst_f.append(mfd_i)\n                            i_mag = 0\n                            for mag in mags:\n                                mag_lo = mag - 0.05\n                                mag_hi = mag + 0.05\n                                r = 10 ** (a_value - b_value * mag_lo) - 10 ** (a_value - b_value * mag_hi)\n                                if mag >= 6.5:\n                                    buffer_to_use = 'nb_buf2'\n                                else:\n                                    buffer_to_use = 'nb_buf1'\n                                reduction = 0.0\n                                for (f_in_rup, mfd_i) in zip(id_ruptures, mfd_mlt_clst_f):\n                                    reduction += mfd_i[i_mag] / float(len(f_in_rup) * nb_pt_in_buff[i_fault][buffer_to_use])\n                                if reduction > r:\n                                    r = 0.0\n                                else:\n                                    r -= reduction\n                                str_tmp += str(r)\n                                str_tmp += ' '\n                                pt_scl_mfd.append(r)\n                                i_mag += 1\n                            pts_out_list[str_loc].update({'scaled_mfd': pt_scl_mfd})\n                            nrml[0][0][i_point][-1][0].text = str_tmp\n                            nrml[0][0][i_point].remove(nrml[0][0][i_point][i_trGR])\n                    i_point += 1\n                i_bg += 1\n                fbg_out = self.path + '/bg_' + str(self.sample) + '_' + str(i_bg) + '.xml'\n                tree.write(fbg_out)\n                list_src_files.append(fbg_out)\n    '#############################\\n        ### defining the other sources based on the host model\\n        ##############################'\n    if self.param['main']['background']['use_host_model'] == True and cut_sm_file == False:\n        host_model.build(XMLfile, self.host_model_file, Lon_bg, Lat_bg)\n    if self.param['main']['background']['use_host_model'] == True and cut_sm_file == True:\n        print(\"WARNING : can't use host model and cut files yet !\")\n    if use_multiF == False:\n        line = '\\t\\t\\t</sourceGroup>\\n'\n        line += '\\t</sourceModel>\\n'\n        line += '</nrml>\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n            XMLfile.close()\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n                f.close()\n    log_sr_file.close()\n    log_mdf_file.close()\n    self.list_src_files = list_src_files\n    '#############################\\n        ### Get the particiaption rates of sections\\n        ##############################'\n    import participation_rates as p_rates\n    from section_info import get_nonzero_Mmax\n    (dict_p_rates, mfd_total, all_non_zero_rups) = p_rates.get_all_participation_rates(MFDs_to_pkl, self.param, faults_names)\n    bin_mag = p_rates.get_bin_mag(mfd_total, self.Mmin)\n    all_participation_rates = []\n    sections_Mmax = []\n    if not os.path.isdir(self.pathlog + '/participation_rates'):\n        os.makedirs(self.pathlog + '/participation_rates')\n    for fault_name in faults_names:\n        (incremental_rate, cumulative_rate) = p_rates.extract_rates(fault_name, dict_p_rates)\n        all_participation_rates.append(cumulative_rate)\n        ptf = self.pathlog + '/participation_rates/' + str(fault_name) + '.png'\n        p_rates.plot_participation_rates(bin_mag, incremental_rate, cumulative_rate, fault_name, ptf)\n        Mmax = get_nonzero_Mmax(bin_mag, cumulative_rate)\n        sections_Mmax.append(Mmax)\n    '#############################\\n        ### Exporting the results in a Geojson\\n        ##############################'\n    features = []\n    for si in f_in_bg:\n        sections = []\n        geom = []\n        for (lon_i, lat_i) in zip(faults_data[si]['lon'], faults_data[si]['lat']):\n            geom.append((lon_i, lat_i))\n        geom = LineString(list(geom))\n        properties = {}\n        for key in faults_data[si].keys():\n            if not key in ['lat', 'lon']:\n                properties.update({key: faults_data[si][key]})\n        NMS = float(M_slip_repartition[faults_data[si]['name']]['NMS'])\n        sumdsr = 0.0\n        for key in M_slip_repartition[faults_data[si]['name']].keys():\n            sumdsr += M_slip_repartition[faults_data[si]['name']][key]\n        properties.update({'NMS': NMS / float(sumdsr)})\n        properties.update({'nb_rup': float(all_non_zero_rups[si])})\n        properties.update({'Mmax': float(sections_Mmax[si])})\n        properties.update({'participation_rates': [bin_mag, all_participation_rates[si]]})\n        nms_i = NMS / float(sumdsr)\n        mmax_i = sections_Mmax[si]\n        if mmax_i >= max(sections_Mmax) - 0.3:\n            if nms_i < 0.1:\n                indicator = 1.0 - nms_i\n            else:\n                indicator = 0.0\n        elif mmax_i >= max(sections_Mmax) - 0.5:\n            if nms_i < 0.05:\n                indicator = 1.0 - nms_i\n            else:\n                indicator = 0.0\n        else:\n            indicator = 0.0\n        properties.update({'might_to_be_limiting': round(indicator, 2)})\n        features.append(Feature(geometry=geom, properties=properties))\n    feature_collection = FeatureCollection(features)\n    with open(self.pathlog + '/out_sections.geojson', 'w') as f:\n        dump(feature_collection, f)\n    '#######################\\n        ### some figures\\n        ######################'\n    if 'figures' in self.param.keys():\n        if self.param['figures']['print'] in ['true', 'True']:\n            make_figures = True\n        else:\n            make_figures = False\n    else:\n        make_figures = False\n    plt_model_mfd = False\n    if make_figures == True:\n        if self.param['figures']['model_mfd'] in ['true', 'True']:\n            plt_model_mfd = True\n    if 'mfd_cat' in self.param['figures'].keys():\n        data = self.param['figures']['mfd_cat']\n    else:\n        data = False\n    if plt_model_mfd == True:\n        x = MFDs.bin_mag\n        y = rates.get_rate_model(MFDs.rup_rates, MFDs.fault_prop, x)\n        lim = [[x[0] - 0.05, x[-1] + 0.05], [min(y) / 2.0, max(y) * 2.0]]\n        axis = ['magnitude', 'annual earthquake rates']\n        path = self.pathlog + '/modelMFD.png'\n        title = 'MFD of the whole system'\n        plt_mfd.plot(x, y, lim, axis, data, path, title)\n    if plt_model_mfd == True:\n        x = MFDs.bin_mag\n        (ft, bgmfd) = rates.get_rate_faults_n_bg(MFDs.rup_rates, MFDs.fault_prop, x)\n        ys = [rates.get_rate_model(MFDs.rup_rates, MFDs.fault_prop, x), ft, bgmfd]\n        lim = [[x[0] - 0.05, x[-1] + 0.05], [min(ys[0]) / 2.0, max(ys[0]) * 2.0]]\n        axis = ['magnitude', 'annual earthquake rates']\n        path = self.pathlog + '/modelMFD_bg_ft.png'\n        title = 'MFD of the whole system, faults, background'\n        plt_mfd.plot_bg_ft(x, ys, lim, axis, path, title)\n    ' mfd in a more local scale '\n    part_mfd = False\n    if make_figures == True:\n        if 'part_mfd' in self.param['figures'].keys():\n            if self.param['figures']['part_mfd'] in ['true', 'True']:\n                part_mfd = True\n    if part_mfd == True:\n        loc_cat = local_cat.read_geojson(self.param['figures']['parts_gjson'])\n        for zone in loc_cat.keys():\n            polypt = loc_cat[zone]['poly']\n            lons = []\n            lats = []\n            for pt in polypt[0][0]:\n                lons.append(pt[0])\n                lats.append(pt[1])\n            poly = []\n            for (x1, y1) in zip(lons, lats):\n                poly.append((x1, y1))\n            area_zone = geometry_tools.PolyArea(lons, lats)\n            area_bg = geometry_tools.PolyArea(Lon_bg, Lat_bg)\n            ratio_area = float(area_zone) / float(area_bg)\n            local_zone_mfd = [i * ratio_area for i in EQ_rate_BG]\n            poly = mplPath.Path(poly)\n            (txt_no_bg, rate_faults, rate_bg, smooth) = local_cat.get_model_rate(poly, OQ_entry_faults, OQ_entry_scenarios, pts_list, MFDs.bin_mag, self.param, faults_data, faults_names, index_faults_in_scenario, local_zone_mfd)\n            x = MFDs.bin_mag\n            rate_model = [i + j for (i, j) in zip(rate_faults, rate_bg)]\n            lim = [[x[0] - 0.05, x[-1] + 0.05], [min(rate_model) / 2.0, max(rate_model) * 2.0]]\n            axis = ['magnitude', 'annual earthquake rates']\n            title = 'MFD in zone ' + str(zone) + txt_no_bg\n            path = self.pathlog + '/MFD_zone' + str(zone) + '.png'\n            if 'cat_rates' in loc_cat[zone].keys():\n                data = loc_cat[zone]['cat_rates']\n            else:\n                data = False\n            if data == None:\n                data = False\n            if data == True:\n                if len(data[0]) == 0:\n                    data = False\n                if len(data[0]) != len(data[1]):\n                    data = False\n                    print('For zone', zone, ' : wrong bining')\n                    print('please check the geojson file')\n            plt_mfd.local(x, [rate_model, rate_faults, rate_bg, smooth], data, lim, axis, path, title)",
            "def initialize(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    path = self.param['dirpath']\n    explo_time = self.param['main']['parameters']['explo_time']\n    if self.param['main']['parameters']['use_multiF'] in ['True', 'true']:\n        use_multiF = True\n    else:\n        use_multiF == False\n    max_rup_per_file = 2000\n    faults_names = self.faults_names\n    scenarios_names = self.scenarios_names\n    faults_data = self.faults_data\n    (faults_lon, faults_lat) = (self.faults_lon, self.faults_lat)\n    list_src_files = []\n    log_sr_file = open(self.pathlog + '/slip_rate_sample_' + str(self.sample) + '.txt', 'w')\n    log_mdf_file = open(self.pathlog + '/mdf_sample_' + str(self.sample) + '.txt', 'w')\n    cut_sm_file = False\n    if len(faults_names) + len(scenarios_names) > max_rup_per_file:\n        cut_sm_file = True\n    if cut_sm_file == False:\n        XMLfile = open(self.path + '/Source_model_' + str(self.sample) + '.xml', 'w')\n    else:\n        n_cut_sf = 1\n        while len(faults_names) / n_cut_sf > max_rup_per_file:\n            n_cut_sf += 1\n        n_cut_mf = 1\n        while len(scenarios_names) / n_cut_mf > max_rup_per_file:\n            n_cut_mf += 1\n        if use_multiF == False:\n            ' create the file list'\n            (sf_files, sf_counter) = ([], [])\n            for i in range(n_cut_sf):\n                f = self.path + '/sm_' + str(self.sample) + '_sf_' + str(i + 1) + '.xml'\n                sf_files.append(open(f, 'w'))\n                sf_counter.append(0)\n                list_src_files.append(f)\n            (mf_files, mf_counter) = ([], [])\n            for i in range(n_cut_mf):\n                f = self.path + '/sm_' + str(self.sample) + '_mf_' + str(i + 1) + '.xml'\n                mf_files.append(open(f, 'w'))\n                mf_counter.append(0)\n                list_src_files.append(f)\n        if use_multiF == True:\n            n_cut_f = n_cut_sf + n_cut_mf\n            s_files = []\n            for i in range(n_cut_mf):\n                f = self.path + '/sm_' + str(i) + '.xml'\n                s_files.append(f)\n                list_src_files.append(f)\n            (dict_txt, dict_n_rup) = ({}, {})\n            for f in s_files:\n                dict_txt.update({f: ''})\n                dict_n_rup.update({f: 0})\n    include_all_faults = False\n    if 'include_all_faults' in self.param['main']['background'].keys():\n        if self.param['main']['background']['include_all_faults'] in ['True', 'true']:\n            include_all_faults = True\n    if use_multiF == True:\n        '\\n            #######################################\\n            #######################################\\n            USING MULTIFAULT TYPOLOGY IN OQ\\n            #######################################\\n            #######################################\\n            '\n        simplify_faults = self.param['main']['parameters']['simplify_faults']\n        if simplify_faults in ['True', 'true']:\n            resample = [False]\n        elif not 'resample' in self.param['main']['parameters'].keys():\n            resample = [False]\n        else:\n            rsp = self.param['main']['parameters']['resample']\n            if rsp[0] in ['True', 'true']:\n                resample = [True]\n                resample.append(float(rsp[1]))\n                resample.append(float(rsp[2]))\n                resample.append(float(rsp[3]))\n            else:\n                resample = [False]\n        if 'vertical_faults' in self.param['main']['parameters'].keys():\n            vertical_faults = self.param['main']['parameters']['vertical_faults']\n            if vertical_faults in ['True', 'true']:\n                vertical_faults = True\n            else:\n                vertical_faults = False\n        else:\n            vertical_faults = False\n        sections_xml = path + self.Run_Name + '/ssm/' + self.Model_name + '_sections.xml'\n        if not os.path.exists(sections_xml):\n            txt = wsf.start(self.Model_name)\n            for section_id in range(len(faults_names)):\n                geotype = 'kite'\n                txt = wsf.wrt_section(txt, section_id, faults_names, faults_data, geotype, resample, vertical_faults)\n            txt = wsf.end(txt)\n            wsf.build(sections_xml, txt)\n        log_general_parameters_file = open(self.pathlog + '/general_parameters_sample_' + str(self.sample) + '.txt', 'w')\n        M_min = float(self.Mmin)\n        log_general_parameters_file.write('M_tronc\\t' + str(M_min) + '\\n')\n        mfd_param = self.mfd_param\n        log_general_parameters_file.write('b_value\\t' + str(mfd_param['b_value']) + '\\n')\n        log_general_parameters_file.close()\n        faults_area = []\n        faults_length = []\n        faults_width = []\n        faults_slip_rates = []\n        faults_mecanism = []\n        faults_shear_mod = []\n        '########################################################\\n            # Random sampling of the fault slip-rate\\n            ########################################################'\n        print('Picking slip-rates...')\n        if self.sample == 1:\n            self.sr_correl = False\n        if self.sr_correl == True:\n            M_faults_correl = []\n            for Fault_name in faults_names:\n                M_faults_correl_i = []\n                sc_with_fault = []\n                for index_scenario in range(len(scenarios_names)):\n                    scenario_i = self.rupture_set[index_scenario]\n                    if Fault_name in scenario_i:\n                        sc_with_fault += scenario_i\n                for Fault_name_i in faults_names:\n                    nb_join_ruptures = 0\n                    if Fault_name == Fault_name_i:\n                        nb_join_ruptures = 0\n                    elif Fault_name_i in sc_with_fault:\n                        nb_join_ruptures = sc_with_fault.count(Fault_name_i)\n                    else:\n                        nb_join_ruptures = 0\n                    M_faults_correl_i.append(nb_join_ruptures)\n                M_faults_correl.append(M_faults_correl_i)\n            M_linked_lvl = np.zeros_like(M_faults_correl)\n            for lvl in [1, 2, 3, 4]:\n                for i in range(len(faults_names)):\n                    for j in range(len(faults_names)):\n                        if M_linked_lvl[i][j] == 0:\n                            if M_faults_correl[i][j] != 0:\n                                M_linked_lvl[i][j] = lvl\n                            else:\n                                for jj in range(len(M_faults_correl[j])):\n                                    if M_faults_correl[j][jj] != 0:\n                                        if M_linked_lvl[i][j] == 0:\n                                            M_linked_lvl[i][j] = lvl + 1\n            max_correl = np.max(M_faults_correl)\n            list_quater_picked = list(np.zeros(len(faults_names)))\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                sr_values = [faults_data[index_fault]['slip_rate_min'], faults_data[index_fault]['slip_rate_moy'], faults_data[index_fault]['slip_rate_max']]\n                slip_rate = select_sr.select(sr_values, self.sample, index_fault, M_linked_lvl[index_fault], list_quater_picked)\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        else:\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                slip_rate_min = faults_data[index_fault]['slip_rate_min']\n                slip_rate_moy = faults_data[index_fault]['slip_rate_moy']\n                slip_rate_max = faults_data[index_fault]['slip_rate_max']\n                if self.sample == 1:\n                    slip_rate = slip_rate_moy\n                else:\n                    slip_rate_inf = np.random.uniform(slip_rate_min, slip_rate_moy)\n                    slip_rate_sup = np.random.uniform(slip_rate_moy, slip_rate_max)\n                    slip_rate = np.random.choice([slip_rate_inf, slip_rate_sup])\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        print('\\t\\tslip-rates picked.')\n        ratio_test = 0.5\n        count_reruns = 1\n        count_mfd90 = 1\n        f_pkl_mdf = self.pathlog + '/mfd_' + str(self.sample) + '.pkl'\n        re_use_mfd_pkl = True\n        if not os.path.isfile(f_pkl_mdf):\n            re_use_mfd_pkl = False\n        if self.param['main']['parameters']['force_rerun'] == True:\n            re_use_mfd_pkl = False\n        if re_use_mfd_pkl == False:\n            while abs(ratio_test - 1) > self.fit_quality or math.isnan(ratio_test) == True:\n                MFDs = EQ_on_faults.EQ_on_faults_from_sr(self.Run_Name, M_min, mfd_param, faults_names, faults_area, faults_length, faults_width, faults_slip_rates, scenarios_names, faults_shear_mod, self.path, self.pathlog, self.sample, self.selected_ScL, self.dimention_used, self.use_all_ScL_data, faults_mecanism, self.bg_ratio, self.size_of_increment, self.mfd_hyp, count_reruns, faults_lon, faults_lat, self.Mmax_range, self.calculation_log_file, self.branch, self.param)\n                ratio_test = MFDs.ratio_test\n                if abs(ratio_test - 1) > self.fit_quality:\n                    print('bad sampling => re-run')\n                    count_reruns += 1\n                    if MFDs.ratio_NMS > 90.0:\n                        count_reruns -= 1\n                        count_mfd90 += 1\n                    else:\n                        count_mfd90 = 1\n                elif MFDs.ratio_NMS > 90.0:\n                    ratio_test = 0.5\n                    print('bad sampling => re-run')\n                    count_mfd90 += 1\n                else:\n                    count_mfd90 = 1\n                if math.isnan(ratio_test) == True:\n                    print('bad sampling => re-run')\n                    count_reruns = 1\n                if count_reruns > 3 or count_mfd90 > 3:\n                    print('\\n\\n\\n!!!!!! maybe there is a problem!!!')\n                    ratio_test = 1.0\n            with open(f_pkl_mdf, 'wb') as f:\n                MFDs_to_pkl = [MFDs.EQ_rate_BG, MFDs.faults_names, MFDs.OQ_entry_faults, MFDs.scenarios_names, MFDs.OQ_entry_scenarios, MFDs.index_faults_in_scenario, MFDs.M_slip_repartition]\n                pickle.dump(MFDs_to_pkl, f)\n        else:\n            print('Reloading MFDs from previous run')\n            with open(f_pkl_mdf, 'rb') as f:\n                MFDs_to_pkl = pickle.load(f)\n        EQ_rate_BG = MFDs_to_pkl[0]\n        faults_names = MFDs_to_pkl[1]\n        OQ_entry_faults = MFDs_to_pkl[2]\n        scenarios_names = MFDs_to_pkl[3]\n        OQ_entry_scenarios = MFDs_to_pkl[4]\n        index_faults_in_scenario = MFDs_to_pkl[5]\n        M_slip_repartition = MFDs_to_pkl[6]\n        if self.selected_ScL == 'Le2010':\n            ScL_oq = 'Leonard2014_SCR'\n        if self.selected_ScL == 'WC1994':\n            ScL_oq = 'WC1994'\n        else:\n            ScL_oq = 'WC1994'\n        (Lon_bg, Lat_bg) = bg.geom(self.Model_name, self.File_bg)\n        Poly_bg = []\n        for (x1, y1) in zip(Lon_bg, Lat_bg):\n            Poly_bg.append((x1, y1))\n        try:\n            bbPath_BG = mplPath.Path(Poly_bg)\n        except:\n            print('ERROR, please make sure the model name matches in the bg file')\n        f_in_bg = []\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            for (lon, lat) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                if bbPath_BG.contains_point((lon, lat)):\n                    f_in_bg.append(index_fault)\n        outside_faults = []\n        if include_all_faults == True:\n            for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n                if not index_fault in f_in_bg:\n                    f_in_bg.append(index_fault)\n                    outside_faults.append(index_fault)\n        source_id = 0\n        if cut_sm_file == False:\n            source_xml = self.path + '/Source_model_' + str(self.sample) + '.xml'\n            list_src_files.append(source_xml)\n            trt = faults_data[0]['domain']\n            txt = wmfs.start(explo_time, trt)\n            name = 'multifaultsource'\n            txt = wmfs.start_multifault_source(txt, name, trt, sections_xml, source_id)\n        else:\n            for f in s_files:\n                trt = faults_data[0]['domain']\n                dict_txt[f] = wmfs.start(explo_time, trt)\n                name = 'multifaultsource_' + str(source_id)\n                dict_txt[f] = wmfs.start_multifault_source(dict_txt[f], name, trt, sections_xml, source_id)\n                source_id += 1\n            f = list(dict_txt.keys())[0]\n        single_f_xml = self.path + '/single_sec_rup.xml'\n        trt = faults_data[0]['domain']\n        single_txt = wss.start(self.Model_name, trt)\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            if index_fault in f_in_bg:\n                i_MFD = np.where(np.array(faults_names) == fault_name)[0][0]\n                MFD = OQ_entry_faults[i_MFD]\n                if sum(MFD) != 0:\n                    source_id = source_id + 1\n                    Fault_Name = self.Model_name + '_' + str(fault_name)\n                    fault_trt = faults_data[index_fault]['domain']\n                    if not fault_trt in str(self.Domain_in_the_model):\n                        self.Domain_in_the_model.append(fault_trt)\n                    trt = str(fault_trt)\n                    rake = faults_data[index_fault]['rake']\n                    geotype = 'kite'\n                    name = 'single_fault_' + fault_name\n                    single_txt = wss.wrt_source(single_txt, index_fault, faults_names, faults_data, geotype, resample, vertical_faults, fault_trt, M_min, MFD, ScL_oq)\n        single_txt = wss.end(single_txt)\n        wss.build(single_f_xml, single_txt)\n        if len(self.rupture_set) != 0:\n            for scenario in enumerate(scenarios_names):\n                sc_in = False\n                index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                index_faults_in_sc = index_faults_in_scenario[index_scenario][0]\n                for i in index_faults_in_sc:\n                    if i in f_in_bg:\n                        sc_in = True\n                if sc_in == True:\n                    index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                    MFD = OQ_entry_scenarios[index_scenario]\n                    if sum(MFD) != 0:\n                        faults_in_scenario = np.take(faults_names, index_faults_in_sc)\n                        source_id = source_id + 1\n                        scenar_name = '_'.join(('{!s}={!r}'.format(key, val) for (key, val) in scenario[1].items()))\n                        source_name = self.Model_name + '_scenario_'\n                        source_name += str(scenar_name)\n                        list_trt = []\n                        scenario_mechanism = []\n                        for fname in faults_in_scenario:\n                            i = faults_names.index(fname)\n                            scenario_mechanism.append(faults_data[i]['rake'])\n                            fault_trt = faults_data[i]['domain']\n                            list_trt.append(fault_trt)\n                            if not fault_trt in str(self.Domain_in_the_model):\n                                self.Domain_in_the_model.append(fault_trt)\n                        fault_trt = max(list_trt, key=list_trt.count)\n                        trt = str(fault_trt)\n                        rake = np.mean(scenario_mechanism)\n                        if cut_sm_file == False:\n                            txt = wmfs.wrt_multifault_source(txt, MFD, self.Mmin, explo_time, rake, index_faults_in_sc)\n                        else:\n                            if not dict_n_rup[f] < max_rup_per_file:\n                                i = 0\n                                while dict_n_rup[f] > max_rup_per_file:\n                                    i += 1\n                                    f = list(dict_txt.keys())[i]\n                            txt = dict_txt[f]\n                            dict_txt[f] = wmfs.wrt_multifault_source(txt, MFD, self.Mmin, explo_time, rake, index_faults_in_sc)\n                            dict_n_rup[f] += 1\n        if cut_sm_file == False:\n            txt = wmfs.end_multifault_source(txt)\n            txt = wmfs.end(txt)\n            wmfs.build(source_xml, txt)\n        else:\n            for f in s_files:\n                if dict_n_rup[f] > 0:\n                    dict_txt[f] = wmfs.end_multifault_source(dict_txt[f])\n                    txt = wmfs.end(dict_txt[f])\n                    wmfs.build(f, txt)\n    else:\n        '\\n            ###########\\n            ############\\n            NOT USING MULTIFAULTSOURCE TYPOLOGY in OQ\\n\\n            '\n        line = \"<?xml version='1.0' encoding='utf-8'?>\\n\"\n        line += '<nrml xmlns:gml=\"http://www.opengis.net/gml\"\\n'\n        line += '\\txmlns=\"http://openquake.org/xmlns/nrml/0.5\">\\n'\n        line += '\\t<sourceModel name=\"Hazard Model\"'\n        line += ' investigation_time=\"' + str(round(explo_time, 1)) + '\">\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n        line = '\\t\\t<sourceGroup\\nname=\"group 1\"\\nrup_interdep=\"indep\"\\nsrc_interdep=\"indep\"\\ntectonicRegion=\"Active Shallow Crust\"\\n>\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n        log_general_parameters_file = open(self.pathlog + '/Log/general_parameters_sample_' + str(self.sample) + '.txt', 'w')\n        M_min = float(self.Mmin)\n        log_general_parameters_file.write('M_tronc\\t' + str(M_min) + '\\n')\n        log_general_parameters_file.write('b_value\\t' + str(self.b_value) + '\\n')\n        log_general_parameters_file.close()\n        faults_area = []\n        faults_length = []\n        faults_width = []\n        faults_slip_rates = []\n        faults_mecanism = []\n        faults_shear_mod = []\n        '########################################################\\n            # Random sampling of the fault slip-rate\\n            ########################################################'\n        print('Picking slip-rates...')\n        if self.sample == 1:\n            self.sr_correl = False\n        if self.sr_correl == True:\n            M_faults_correl = []\n            for Fault_name in faults_names:\n                M_faults_correl_i = []\n                sc_with_fault = []\n                for index_scenario in range(len(scenarios_names)):\n                    scenario_i = self.rupture_set[index_scenario]\n                    if Fault_name in scenario_i:\n                        sc_with_fault += scenario_i\n                for Fault_name_i in faults_names:\n                    nb_join_ruptures = 0\n                    if Fault_name == Fault_name_i:\n                        nb_join_ruptures = 0\n                    elif Fault_name_i in sc_with_fault:\n                        nb_join_ruptures = sc_with_fault.count(Fault_name_i)\n                    else:\n                        nb_join_ruptures = 0\n                    M_faults_correl_i.append(nb_join_ruptures)\n                M_faults_correl.append(M_faults_correl_i)\n            M_linked_lvl = np.zeros_like(M_faults_correl)\n            for lvl in [1, 2, 3, 4]:\n                for i in range(len(faults_names)):\n                    for j in range(len(faults_names)):\n                        if M_linked_lvl[i][j] == 0:\n                            if M_faults_correl[i][j] != 0:\n                                M_linked_lvl[i][j] = lvl\n                            else:\n                                for jj in range(len(M_faults_correl[j])):\n                                    if M_faults_correl[j][jj] != 0:\n                                        if M_linked_lvl[i][j] == 0:\n                                            M_linked_lvl[i][j] = lvl + 1\n            max_correl = np.max(M_faults_correl)\n            list_quater_picked = list(np.zeros(len(faults_names)))\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                sr_values = [faults_data[index_fault]['slip_rate_min'], faults_data[index_fault]['slip_rate_moy'], faults_data[index_fault]['slip_rate_max']]\n                slip_rate = select_sr.select(sr_values, self.sample, index_fault, M_linked_lvl[index_fault], list_quater_picked)\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        else:\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                slip_rate_min = faults_data[index_fault]['slip_rate_min']\n                slip_rate_moy = faults_data[index_fault]['slip_rate_moy']\n                slip_rate_max = faults_data[index_fault]['slip_rate_max']\n                if self.sample == 1:\n                    slip_rate = slip_rate_moy\n                else:\n                    slip_rate_inf = np.random.uniform(slip_rate_min, slip_rate_moy)\n                    slip_rate_sup = np.random.uniform(slip_rate_moy, slip_rate_max)\n                    slip_rate = np.random.choice([slip_rate_inf, slip_rate_sup])\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        print('\\t\\tslip-rates picked.')\n        ratio_test = 0.5\n        count_reruns = 1\n        count_mfd90 = 1\n        f_pkl_mdf = self.pathlog + '/mfd_' + str(self.sample) + '.pkl'\n        re_use_mfd_pkl = True\n        if not os.path.isfile(f_pkl_mdf):\n            re_use_mfd_pkl = False\n        if re_use_mfd_pkl == False:\n            while abs(ratio_test - 1) > self.fit_quality or math.isnan(ratio_test) == True:\n                MFDs = EQ_on_faults.EQ_on_faults_from_sr(M_min, mfd_param, faults_names, faults_area, faults_length, faults_width, faults_slip_rates, scenarios_names, faults_shear_mod, self.path, self.sample, self.selected_ScL, self.dimention_used, self.use_all_ScL_data, faults_mecanism, self.bg_ratio, self.size_of_increment, self.mfd_hyp, count_reruns, faults_lon, faults_lat, self.Mmax_range, self.calculation_log_file, self.branch, self.param)\n                ratio_test = MFDs.ratio_test\n                if abs(ratio_test - 1) > self.fit_quality:\n                    print('bad sampling => re-run')\n                    count_reruns += 1\n                    if MFDs.ratio_NMS > 90.0:\n                        count_reruns -= 1\n                        count_mfd90 += 1\n                    else:\n                        count_mfd90 = 1\n                elif MFDs.ratio_NMS > 90.0:\n                    ratio_test = 0.5\n                    print('bad sampling => re-run')\n                    count_mfd90 += 1\n                else:\n                    count_mfd90 = 1\n                if math.isnan(ratio_test) == True:\n                    print('bad sampling => re-run')\n                    count_reruns = 1\n                if count_reruns > 3 or count_mfd90 > 3:\n                    print('\\n\\n\\n!!!!!! maybe there is a problem!!!')\n                    ratio_test = 1.0\n            with open(f_pkl_mdf, 'wb') as f:\n                MFDs_to_pkl = [MFDs.EQ_rate_BG, MFDs.faults_names, MFDs.OQ_entry_faults, MFDs.scenarios_names, MFDs.OQ_entry_scenarios, MFDs.index_faults_in_scenario, MFDs.M_slip_repartition]\n                pickle.dump(MFDs_to_pkl, f)\n        else:\n            print('Reloading MFDs from previous run')\n            with open(f_pkl_mdf, 'rb') as f:\n                MFDs_to_pkl = pickle.load(f)\n        EQ_rate_BG = MFDs_to_pkl[0]\n        faults_names = MFDs_to_pkl[1]\n        OQ_entry_faults = MFDs_to_pkl[2]\n        scenarios_names = MFDs_to_pkl[3]\n        OQ_entry_scenarios = MFDs_to_pkl[4]\n        index_faults_in_scenario = MFDs_to_pkl[5]\n        M_slip_repartition = MFDs_to_pkl[6]\n        if self.selected_ScL == 'Le2010':\n            ScL_oq = 'Leonard2014_SCR'\n        elif self.selected_ScL == 'WC1994':\n            ScL_oq = 'WC1994'\n        else:\n            ScL_oq = 'WC1994'\n        (Lon_bg, Lat_bg) = bg.geom(self.Model_name, self.File_bg)\n        Poly_bg = []\n        for (x1, y1) in zip(Lon_bg, Lat_bg):\n            Poly_bg.append((x1, y1))\n        bbPath_BG = mplPath.Path(Poly_bg)\n        f_in_bg = []\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            for (lon, lat) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                if bbPath_BG.contains_point((lon, lat)):\n                    f_in_bg.append(index_fault)\n        outside_faults = []\n        if include_all_faults == True:\n            for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n                if not index_fault in f_in_bg:\n                    f_in_bg.append(index_fault)\n                    outside_faults.append(index_fault)\n        ID_number = 0\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            if index_fault in f_in_bg:\n                use_simple_faults = False\n                if use_simple_faults == True:\n                    (line, self.Domain_in_the_model, ID_number) = fault_source.write_simple_fault(index_fault, fault_name, OQ_entry_faults, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, M_min, ID_number)\n                else:\n                    (line, self.Domain_in_the_model, ID_number) = fault_source.write_non_parametric_one_fault(index_fault, fault_name, OQ_entry_faults, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, M_min, ID_number, explo_time)\n                if cut_sm_file == False:\n                    XMLfile.write(line)\n                else:\n                    i_w = 0\n                    while sf_counter[i_w] > 500:\n                        i_w += 1\n                    sf_files[i_w].write(line)\n                    sf_counter[i_w] += 1\n        if len(self.rupture_set) != 0:\n            for scenario in enumerate(scenarios_names):\n                sc_in = False\n                index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                for i in index_faults_in_scenario[index_scenario][0]:\n                    if i in f_in_bg:\n                        sc_in = True\n                if sc_in == True:\n                    use_non_param = True\n                    if use_non_param == False:\n                        (line, ID_number) = fault_source.write_characteristic_scenario(scenarios_names, OQ_entry_scenarios, index_faults_in_scenario, scenario, faults_names, self.Model_name, faults_data, log_mdf_file, M_min, ID_number)\n                    else:\n                        (line, ID_number) = fault_source.write_non_parametric_source(scenario, scenarios_names, OQ_entry_scenarios, index_faults_in_scenario, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, explo_time, M_min, ID_number)\n                    if cut_sm_file == False:\n                        XMLfile.write(line)\n                    else:\n                        i_w = 0\n                        while mf_counter[i_w] > 500:\n                            i_w += 1\n                        mf_files[i_w].write(line)\n                        mf_counter[i_w] += 1\n    '#########################\\n        # Defining the background seismicity\\n        #########################'\n    MFD = EQ_rate_BG\n    pts_list = {}\n    if sum(MFD) != 0.0 and self.param['main']['background']['option_bg'] == 'zone':\n        bg_file = self.path + '/bg_' + str(self.sample) + '.xml'\n        list_src_files.append(bg_file)\n        bg_file = open(bg_file, 'w')\n        line = \"<?xml version='1.0' encoding='utf-8'?>\\n\"\n        line += '<nrml xmlns:gml=\"http://www.opengis.net/gml\"\\n'\n        line += '\\txmlns=\"http://openquake.org/xmlns/nrml/0.5\">\\n'\n        line += '\\t<sourceModel name=\"Hazard Model\">\\n'\n        (upperSeismoDepth, lowerSeismoDepth, ruptAspectRatio, nodalPlanes, hypoDepths) = bg.prop(self.Model_name, self.file_prop_bg)\n        line += '\\t\\t<sourceGroup\\nname=\"group 2\"\\nrup_interdep=\"indep\"\\nsrc_interdep=\"indep\"\\ntectonicRegion=\"' + str(self.Domain_in_the_model[0]) + '\"\\n>\\n'\n        line += '\\t\\t<areaSource id=\"' + str(source_id + 1) + '\" name=\"Background\" tectonicRegion=\"' + str(self.Domain_in_the_model[0]) + '\">\\n'\n        line += '\\t\\t\\t<areaGeometry>\\n'\n        line += '\\t\\t\\t\\t<gml:Polygon>\\n'\n        line += '\\t\\t\\t\\t\\t<gml:exterior>\\n'\n        line += '\\t\\t\\t\\t\\t\\t<gml:LinearRing>\\n'\n        line += '\\t\\t\\t\\t\\t\\t\\t<gml:posList>\\n'\n        for (x, y) in zip(Lon_bg, Lat_bg):\n            line += '\\t\\t\\t\\t\\t\\t\\t\\t' + str(x) + ' ' + str(y) + '\\n'\n        line += '\\t\\t\\t\\t\\t\\t\\t</gml:posList>\\n'\n        line += '\\t\\t\\t\\t\\t\\t</gml:LinearRing>\\n'\n        line += '\\t\\t\\t\\t\\t</gml:exterior>\\n'\n        line += '\\t\\t\\t\\t</gml:Polygon>\\n'\n        line += '\\t\\t\\t\\t<upperSeismoDepth>' + str(upperSeismoDepth) + '</upperSeismoDepth>\\n'\n        line += '\\t\\t\\t\\t<lowerSeismoDepth>' + str(lowerSeismoDepth) + '</lowerSeismoDepth>\\n'\n        line += '\\t\\t\\t</areaGeometry>\\n'\n        line += '\\t\\t\\t<magScaleRel>' + ScL_oq + '</magScaleRel>\\n'\n        line += '\\t\\t\\t<ruptAspectRatio>' + str(ruptAspectRatio) + '</ruptAspectRatio>\\n'\n        log_mdf_file.write('Background' + '\\t' + str(M_min) + '\\t' + ' '.join(list(map(str, MFD))) + '\\n')\n        line += '\\t\\t\\t<incrementalMFD binWidth=\"0.10\" minMag=\"' + str(M_min) + '\">\\n'\n        line += '\\t\\t\\t<occurRates> ' + ' '.join(list(map(str, MFD))) + '</occurRates>\\n'\n        line += '\\t\\t\\t</incrementalMFD>\\n'\n        line += '\\t\\t\\t<nodalPlaneDist>\\n'\n        for i in range(len(nodalPlanes)):\n            line += '\\t\\t\\t\\t<nodalPlane probability=\"' + str(nodalPlanes[i][0]) + '\" strike=\"' + str(nodalPlanes[i][1]) + '\" dip=\"' + str(nodalPlanes[i][2]) + '\" rake=\"' + str(nodalPlanes[i][3]) + '\" />\\n'\n        line += '\\t\\t\\t</nodalPlaneDist>\\n'\n        line += '\\t\\t\\t<hypoDepthDist>\\n'\n        for i in range(len(hypoDepths)):\n            line += '\\t\\t\\t\\t<hypoDepth probability=\"' + str(hypoDepths[i][0]) + '\" depth=\"' + str(hypoDepths[i][1]) + '\" />\\n'\n        line += '\\t\\t\\t</hypoDepthDist>\\n'\n        line += '\\t\\t</areaSource>\\n'\n        line += '\\t</sourceGroup>\\n'\n        line += '\\t</sourceModel>\\n'\n        line += '</nrml>\\n'\n        bg_file.write(line)\n        bg_file.close()\n    elif sum(MFD) != 0.0 and self.param['main']['background']['option_bg'] == 'smooth':\n        Mmin_checked = False\n        Mmax = M_min + len(EQ_rate_BG) * 0.1 - 1\n        mags = np.linspace(M_min, Mmax, len(EQ_rate_BG))\n        list_bg_xml = self.list_fbg\n        if os.path.isdir(self.fbgpath):\n            list_bg_xml = [self.fbgpath + '/' + i for i in list_bg_xml if '.xml' in i]\n        with open(list_bg_xml[0]) as myfile:\n            if 'multiPointSource' in myfile.read():\n                multiPointSource_type = True\n            else:\n                multiPointSource_type = False\n        if multiPointSource_type == True:\n            bg.get_multipoints(EQ_rate_BG, M_min, bbPath_BG, list_bg_xml, include_all_faults, outside_faults, faults_data, OQ_entry_faults, self.path, self.pathlog, list_src_files)\n        else:\n            pts_list = {}\n            pts_out_list = {}\n            sum_rates = [0.0 for _ in mags]\n            for fbg in list_bg_xml:\n                tree = ET.parse(fbg)\n                ET.register_namespace('', 'http://openquake.org/xmlns/nrml/0.5')\n                nrml = tree.getroot()\n                i_point = 0\n                for pointSource in nrml[0][0]:\n                    pt_in_BG = False\n                    i_child = 0\n                    for child in pointSource.getchildren():\n                        if 'pointGeometry' in str(child):\n                            s_tmp = pointSource[i_child][0][0].text\n                            s_tmp = s_tmp.replace('\\n', '')\n                            s_tmp = [float(i) for i in s_tmp.split(' ') if i != '']\n                            if bbPath_BG.contains_point((s_tmp[0], s_tmp[1])) == 1:\n                                pt_in_BG = True\n                            str_loc = str(s_tmp[0]) + '_' + str(s_tmp[1])\n                        if 'truncGutenbergRichterMFD' in str(child):\n                            aValue = nrml[0][0][i_point][i_child].get('aValue')\n                            minMag = nrml[0][0][i_point][i_child].get('minMag')\n                            i_trGR = i_child\n                        i_child += 1\n                    aValue = nrml[0][0][i_point][i_trGR].get('aValue')\n                    minMag = nrml[0][0][i_point][i_trGR].get('minMag')\n                    bValue = nrml[0][0][i_point][i_trGR].get('bValue')\n                    maxMag = nrml[0][0][i_point][i_trGR].get('maxMag')\n                    mfd_smooth = []\n                    i_mag = 0\n                    for mag in mags:\n                        mag_lo = mag - 0.05\n                        mag_hi = mag + 0.05\n                        r = 10 ** (float(aValue) - float(bValue) * mag_lo) - 10 ** (float(aValue) - float(bValue) * mag_hi)\n                        sum_rates[i_mag] += r\n                        i_mag += 1\n                        mfd_smooth.append(r)\n                    if pt_in_BG == True:\n                        pts_list.update({str_loc: {'aValue': aValue, 'bValue': bValue, 'maxMag': maxMag, 'minMag': minMag, 'mfd_smooth': mfd_smooth}})\n                        if Mmin_checked == False:\n                            if float(minMag) < M_min:\n                                print('!!!!')\n                                print('WARNING : BG has a smaller Mmin than the SHERIFS input')\n                                print('!!!!')\n                                Mmin_checked = True\n                    elif include_all_faults == True:\n                        pt_very_far = True\n                        lon_lat_distance_criteria = 1.0\n                        i = 0\n                        while pt_very_far == False and i < len(outside_faults):\n                            i_fault = outside_faults[i]\n                            mean_lon = np.mean(faults_data[index_fault]['lon'])\n                            mean_lat = np.mean(faults_data[index_fault]['lat'])\n                            if abs(float(s_tmp[0]) - mean_lon) < lon_lat_distance_criteria:\n                                pt_very_far = False\n                            if abs(float(s_tmp[1]) - mean_lat) < lon_lat_distance_criteria:\n                                pt_very_far = False\n                            i += 1\n                        if pt_very_far == False:\n                            dist_critera = 50.0\n                            dist = 1000000.0\n                            closest_fault = 'nope'\n                            for i_fault in outside_faults:\n                                mean_lon = np.mean(faults_data[index_fault]['lon'])\n                                mean_lat = np.mean(faults_data[index_fault]['lat'])\n                                dist_i = distance(mean_lon, mean_lat, float(s_tmp[0]), float(s_tmp[1]))\n                                if dist_i < dist_critera:\n                                    for (lon_f, lat_f) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                                        dist_i = distance(mean_lon, mean_lat, float(s_tmp[0]), float(s_tmp[1]))\n                                        if dist_i < dist:\n                                            dist = dist_i\n                                            closest_fault = i_fault\n                                if dist_i < dist:\n                                    dist = dist_i\n                                    closest_fault = i_fault\n                            closest_dist = dist\n                            pts_out_list.update({str_loc: {'aValue': aValue, 'bValue': bValue, 'maxMag': maxMag, 'minMag': minMag, 'mfd_smooth': mfd_smooth, 'distance': closest_dist, 'closest_fault': i_fault}})\n                    i_point += 1\n            nb_pt_in_buff = {}\n            if include_all_faults == True:\n                for i_fault in outside_faults:\n                    buffer_1 = 10.0\n                    buffer_2 = 20.0\n                    nb_buf1 = 0\n                    nb_buf2 = 0\n                    for str_loc in pts_out_list.keys():\n                        if pts_out_list[str_loc]['closest_fault'] == i_fault:\n                            if pts_out_list[str_loc]['closest_dist'] < buffer_1:\n                                nb_buf1 += 1\n                            elif pts_out_list[str_loc]['closest_dist'] < buffer_2:\n                                nb_buf2 += 1\n                    nb_pt_in_buff.update({i_fault: {'nb_buf1': nb_buf1, 'nb_buf2': nb_buf2}})\n            sum_bg_min = 0.0\n            i_bg = 0\n            for fbg in list_bg_xml:\n                tree = ET.parse(fbg)\n                ET.register_namespace('', 'http://openquake.org/xmlns/nrml/0.5')\n                nrml = tree.getroot()\n                i_point = 0\n                for pointSource in nrml[0][0]:\n                    pt_in_BG = False\n                    i_child = 0\n                    for child in pointSource.getchildren():\n                        if 'magScaleRel' in str(child):\n                            nrml[0][0][i_point][i_child].text = ScL_oq\n                        if 'pointGeometry' in str(child):\n                            s_tmp = pointSource[i_child][0][0].text\n                            s_tmp = s_tmp.replace('\\n', '')\n                            s_tmp = [float(i) for i in s_tmp.split(' ') if i != '']\n                            str_loc = str(s_tmp[0]) + '_' + str(s_tmp[1])\n                        if 'truncGutenbergRichterMFD' in str(child):\n                            i_trGR = i_child\n                        i_child += 1\n                    if str_loc in pts_list.keys():\n                        b_value = float(pts_list[str_loc]['bValue'])\n                        a_value = float(pts_list[str_loc]['aValue'])\n                        attrib = {'minMag': str(M_min), 'binWidth': '0.10'}\n                        element = nrml[0][0][i_point].makeelement('incrementalMFD', attrib)\n                        nrml[0][0][i_point].append(element)\n                        element = nrml[0][0][i_point][-1].makeelement('occurRates', {})\n                        nrml[0][0][i_point][-1].append(element)\n                        str_tmp = ' '\n                        pt_scl_mfd = []\n                        i_mag = 0\n                        for mag in mags:\n                            mag_lo = mag - 0.05\n                            mag_hi = mag + 0.05\n                            r = 10 ** (a_value - b_value * mag_lo) - 10 ** (a_value - b_value * mag_hi)\n                            norm_r = r / sum_rates[i_mag]\n                            str_tmp += str(EQ_rate_BG[i_mag] * norm_r)\n                            str_tmp += ' '\n                            sum_bg_min += EQ_rate_BG[i_mag] * norm_r\n                            pt_scl_mfd.append(EQ_rate_BG[i_mag] * norm_r)\n                            i_mag += 1\n                        pts_list[str_loc].update({'scaled_mfd': pt_scl_mfd})\n                        nrml[0][0][i_point][-1][0].text = str_tmp\n                        nrml[0][0][i_point].remove(nrml[0][0][i_point][i_trGR])\n                    if include_all_faults == True:\n                        if str_loc in pts_out_list.keys():\n                            b_value = float(pts_list[str_loc]['bValue'])\n                            a_value = float(pts_list[str_loc]['aValue'])\n                            attrib = {'minMag': str(M_min), 'binWidth': '0.10'}\n                            element = nrml[0][0][i_point].makeelement('incrementalMFD', attrib)\n                            nrml[0][0][i_point].append(element)\n                            element = nrml[0][0][i_point][-1].makeelement('occurRates', {})\n                            nrml[0][0][i_point][-1].append(element)\n                            str_tmp = ' '\n                            pt_scl_mfd = []\n                            i_fault = pts_out_list[str_loc]['closest_fault']\n                            mfd_single_clst_f = OQ_entry_faults[i_fault]\n                            id_ruptures = []\n                            mfd_mlt_clst_f = []\n                            for (scenario_i, mfd_i) in zip(index_faults_in_scenario, OQ_entry_scenarios):\n                                if i_fault in scenario_i:\n                                    id_ruptures.append(scenario_i)\n                                    mfd_mlt_clst_f.append(mfd_i)\n                            i_mag = 0\n                            for mag in mags:\n                                mag_lo = mag - 0.05\n                                mag_hi = mag + 0.05\n                                r = 10 ** (a_value - b_value * mag_lo) - 10 ** (a_value - b_value * mag_hi)\n                                if mag >= 6.5:\n                                    buffer_to_use = 'nb_buf2'\n                                else:\n                                    buffer_to_use = 'nb_buf1'\n                                reduction = 0.0\n                                for (f_in_rup, mfd_i) in zip(id_ruptures, mfd_mlt_clst_f):\n                                    reduction += mfd_i[i_mag] / float(len(f_in_rup) * nb_pt_in_buff[i_fault][buffer_to_use])\n                                if reduction > r:\n                                    r = 0.0\n                                else:\n                                    r -= reduction\n                                str_tmp += str(r)\n                                str_tmp += ' '\n                                pt_scl_mfd.append(r)\n                                i_mag += 1\n                            pts_out_list[str_loc].update({'scaled_mfd': pt_scl_mfd})\n                            nrml[0][0][i_point][-1][0].text = str_tmp\n                            nrml[0][0][i_point].remove(nrml[0][0][i_point][i_trGR])\n                    i_point += 1\n                i_bg += 1\n                fbg_out = self.path + '/bg_' + str(self.sample) + '_' + str(i_bg) + '.xml'\n                tree.write(fbg_out)\n                list_src_files.append(fbg_out)\n    '#############################\\n        ### defining the other sources based on the host model\\n        ##############################'\n    if self.param['main']['background']['use_host_model'] == True and cut_sm_file == False:\n        host_model.build(XMLfile, self.host_model_file, Lon_bg, Lat_bg)\n    if self.param['main']['background']['use_host_model'] == True and cut_sm_file == True:\n        print(\"WARNING : can't use host model and cut files yet !\")\n    if use_multiF == False:\n        line = '\\t\\t\\t</sourceGroup>\\n'\n        line += '\\t</sourceModel>\\n'\n        line += '</nrml>\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n            XMLfile.close()\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n                f.close()\n    log_sr_file.close()\n    log_mdf_file.close()\n    self.list_src_files = list_src_files\n    '#############################\\n        ### Get the particiaption rates of sections\\n        ##############################'\n    import participation_rates as p_rates\n    from section_info import get_nonzero_Mmax\n    (dict_p_rates, mfd_total, all_non_zero_rups) = p_rates.get_all_participation_rates(MFDs_to_pkl, self.param, faults_names)\n    bin_mag = p_rates.get_bin_mag(mfd_total, self.Mmin)\n    all_participation_rates = []\n    sections_Mmax = []\n    if not os.path.isdir(self.pathlog + '/participation_rates'):\n        os.makedirs(self.pathlog + '/participation_rates')\n    for fault_name in faults_names:\n        (incremental_rate, cumulative_rate) = p_rates.extract_rates(fault_name, dict_p_rates)\n        all_participation_rates.append(cumulative_rate)\n        ptf = self.pathlog + '/participation_rates/' + str(fault_name) + '.png'\n        p_rates.plot_participation_rates(bin_mag, incremental_rate, cumulative_rate, fault_name, ptf)\n        Mmax = get_nonzero_Mmax(bin_mag, cumulative_rate)\n        sections_Mmax.append(Mmax)\n    '#############################\\n        ### Exporting the results in a Geojson\\n        ##############################'\n    features = []\n    for si in f_in_bg:\n        sections = []\n        geom = []\n        for (lon_i, lat_i) in zip(faults_data[si]['lon'], faults_data[si]['lat']):\n            geom.append((lon_i, lat_i))\n        geom = LineString(list(geom))\n        properties = {}\n        for key in faults_data[si].keys():\n            if not key in ['lat', 'lon']:\n                properties.update({key: faults_data[si][key]})\n        NMS = float(M_slip_repartition[faults_data[si]['name']]['NMS'])\n        sumdsr = 0.0\n        for key in M_slip_repartition[faults_data[si]['name']].keys():\n            sumdsr += M_slip_repartition[faults_data[si]['name']][key]\n        properties.update({'NMS': NMS / float(sumdsr)})\n        properties.update({'nb_rup': float(all_non_zero_rups[si])})\n        properties.update({'Mmax': float(sections_Mmax[si])})\n        properties.update({'participation_rates': [bin_mag, all_participation_rates[si]]})\n        nms_i = NMS / float(sumdsr)\n        mmax_i = sections_Mmax[si]\n        if mmax_i >= max(sections_Mmax) - 0.3:\n            if nms_i < 0.1:\n                indicator = 1.0 - nms_i\n            else:\n                indicator = 0.0\n        elif mmax_i >= max(sections_Mmax) - 0.5:\n            if nms_i < 0.05:\n                indicator = 1.0 - nms_i\n            else:\n                indicator = 0.0\n        else:\n            indicator = 0.0\n        properties.update({'might_to_be_limiting': round(indicator, 2)})\n        features.append(Feature(geometry=geom, properties=properties))\n    feature_collection = FeatureCollection(features)\n    with open(self.pathlog + '/out_sections.geojson', 'w') as f:\n        dump(feature_collection, f)\n    '#######################\\n        ### some figures\\n        ######################'\n    if 'figures' in self.param.keys():\n        if self.param['figures']['print'] in ['true', 'True']:\n            make_figures = True\n        else:\n            make_figures = False\n    else:\n        make_figures = False\n    plt_model_mfd = False\n    if make_figures == True:\n        if self.param['figures']['model_mfd'] in ['true', 'True']:\n            plt_model_mfd = True\n    if 'mfd_cat' in self.param['figures'].keys():\n        data = self.param['figures']['mfd_cat']\n    else:\n        data = False\n    if plt_model_mfd == True:\n        x = MFDs.bin_mag\n        y = rates.get_rate_model(MFDs.rup_rates, MFDs.fault_prop, x)\n        lim = [[x[0] - 0.05, x[-1] + 0.05], [min(y) / 2.0, max(y) * 2.0]]\n        axis = ['magnitude', 'annual earthquake rates']\n        path = self.pathlog + '/modelMFD.png'\n        title = 'MFD of the whole system'\n        plt_mfd.plot(x, y, lim, axis, data, path, title)\n    if plt_model_mfd == True:\n        x = MFDs.bin_mag\n        (ft, bgmfd) = rates.get_rate_faults_n_bg(MFDs.rup_rates, MFDs.fault_prop, x)\n        ys = [rates.get_rate_model(MFDs.rup_rates, MFDs.fault_prop, x), ft, bgmfd]\n        lim = [[x[0] - 0.05, x[-1] + 0.05], [min(ys[0]) / 2.0, max(ys[0]) * 2.0]]\n        axis = ['magnitude', 'annual earthquake rates']\n        path = self.pathlog + '/modelMFD_bg_ft.png'\n        title = 'MFD of the whole system, faults, background'\n        plt_mfd.plot_bg_ft(x, ys, lim, axis, path, title)\n    ' mfd in a more local scale '\n    part_mfd = False\n    if make_figures == True:\n        if 'part_mfd' in self.param['figures'].keys():\n            if self.param['figures']['part_mfd'] in ['true', 'True']:\n                part_mfd = True\n    if part_mfd == True:\n        loc_cat = local_cat.read_geojson(self.param['figures']['parts_gjson'])\n        for zone in loc_cat.keys():\n            polypt = loc_cat[zone]['poly']\n            lons = []\n            lats = []\n            for pt in polypt[0][0]:\n                lons.append(pt[0])\n                lats.append(pt[1])\n            poly = []\n            for (x1, y1) in zip(lons, lats):\n                poly.append((x1, y1))\n            area_zone = geometry_tools.PolyArea(lons, lats)\n            area_bg = geometry_tools.PolyArea(Lon_bg, Lat_bg)\n            ratio_area = float(area_zone) / float(area_bg)\n            local_zone_mfd = [i * ratio_area for i in EQ_rate_BG]\n            poly = mplPath.Path(poly)\n            (txt_no_bg, rate_faults, rate_bg, smooth) = local_cat.get_model_rate(poly, OQ_entry_faults, OQ_entry_scenarios, pts_list, MFDs.bin_mag, self.param, faults_data, faults_names, index_faults_in_scenario, local_zone_mfd)\n            x = MFDs.bin_mag\n            rate_model = [i + j for (i, j) in zip(rate_faults, rate_bg)]\n            lim = [[x[0] - 0.05, x[-1] + 0.05], [min(rate_model) / 2.0, max(rate_model) * 2.0]]\n            axis = ['magnitude', 'annual earthquake rates']\n            title = 'MFD in zone ' + str(zone) + txt_no_bg\n            path = self.pathlog + '/MFD_zone' + str(zone) + '.png'\n            if 'cat_rates' in loc_cat[zone].keys():\n                data = loc_cat[zone]['cat_rates']\n            else:\n                data = False\n            if data == None:\n                data = False\n            if data == True:\n                if len(data[0]) == 0:\n                    data = False\n                if len(data[0]) != len(data[1]):\n                    data = False\n                    print('For zone', zone, ' : wrong bining')\n                    print('please check the geojson file')\n            plt_mfd.local(x, [rate_model, rate_faults, rate_bg, smooth], data, lim, axis, path, title)",
            "def initialize(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    path = self.param['dirpath']\n    explo_time = self.param['main']['parameters']['explo_time']\n    if self.param['main']['parameters']['use_multiF'] in ['True', 'true']:\n        use_multiF = True\n    else:\n        use_multiF == False\n    max_rup_per_file = 2000\n    faults_names = self.faults_names\n    scenarios_names = self.scenarios_names\n    faults_data = self.faults_data\n    (faults_lon, faults_lat) = (self.faults_lon, self.faults_lat)\n    list_src_files = []\n    log_sr_file = open(self.pathlog + '/slip_rate_sample_' + str(self.sample) + '.txt', 'w')\n    log_mdf_file = open(self.pathlog + '/mdf_sample_' + str(self.sample) + '.txt', 'w')\n    cut_sm_file = False\n    if len(faults_names) + len(scenarios_names) > max_rup_per_file:\n        cut_sm_file = True\n    if cut_sm_file == False:\n        XMLfile = open(self.path + '/Source_model_' + str(self.sample) + '.xml', 'w')\n    else:\n        n_cut_sf = 1\n        while len(faults_names) / n_cut_sf > max_rup_per_file:\n            n_cut_sf += 1\n        n_cut_mf = 1\n        while len(scenarios_names) / n_cut_mf > max_rup_per_file:\n            n_cut_mf += 1\n        if use_multiF == False:\n            ' create the file list'\n            (sf_files, sf_counter) = ([], [])\n            for i in range(n_cut_sf):\n                f = self.path + '/sm_' + str(self.sample) + '_sf_' + str(i + 1) + '.xml'\n                sf_files.append(open(f, 'w'))\n                sf_counter.append(0)\n                list_src_files.append(f)\n            (mf_files, mf_counter) = ([], [])\n            for i in range(n_cut_mf):\n                f = self.path + '/sm_' + str(self.sample) + '_mf_' + str(i + 1) + '.xml'\n                mf_files.append(open(f, 'w'))\n                mf_counter.append(0)\n                list_src_files.append(f)\n        if use_multiF == True:\n            n_cut_f = n_cut_sf + n_cut_mf\n            s_files = []\n            for i in range(n_cut_mf):\n                f = self.path + '/sm_' + str(i) + '.xml'\n                s_files.append(f)\n                list_src_files.append(f)\n            (dict_txt, dict_n_rup) = ({}, {})\n            for f in s_files:\n                dict_txt.update({f: ''})\n                dict_n_rup.update({f: 0})\n    include_all_faults = False\n    if 'include_all_faults' in self.param['main']['background'].keys():\n        if self.param['main']['background']['include_all_faults'] in ['True', 'true']:\n            include_all_faults = True\n    if use_multiF == True:\n        '\\n            #######################################\\n            #######################################\\n            USING MULTIFAULT TYPOLOGY IN OQ\\n            #######################################\\n            #######################################\\n            '\n        simplify_faults = self.param['main']['parameters']['simplify_faults']\n        if simplify_faults in ['True', 'true']:\n            resample = [False]\n        elif not 'resample' in self.param['main']['parameters'].keys():\n            resample = [False]\n        else:\n            rsp = self.param['main']['parameters']['resample']\n            if rsp[0] in ['True', 'true']:\n                resample = [True]\n                resample.append(float(rsp[1]))\n                resample.append(float(rsp[2]))\n                resample.append(float(rsp[3]))\n            else:\n                resample = [False]\n        if 'vertical_faults' in self.param['main']['parameters'].keys():\n            vertical_faults = self.param['main']['parameters']['vertical_faults']\n            if vertical_faults in ['True', 'true']:\n                vertical_faults = True\n            else:\n                vertical_faults = False\n        else:\n            vertical_faults = False\n        sections_xml = path + self.Run_Name + '/ssm/' + self.Model_name + '_sections.xml'\n        if not os.path.exists(sections_xml):\n            txt = wsf.start(self.Model_name)\n            for section_id in range(len(faults_names)):\n                geotype = 'kite'\n                txt = wsf.wrt_section(txt, section_id, faults_names, faults_data, geotype, resample, vertical_faults)\n            txt = wsf.end(txt)\n            wsf.build(sections_xml, txt)\n        log_general_parameters_file = open(self.pathlog + '/general_parameters_sample_' + str(self.sample) + '.txt', 'w')\n        M_min = float(self.Mmin)\n        log_general_parameters_file.write('M_tronc\\t' + str(M_min) + '\\n')\n        mfd_param = self.mfd_param\n        log_general_parameters_file.write('b_value\\t' + str(mfd_param['b_value']) + '\\n')\n        log_general_parameters_file.close()\n        faults_area = []\n        faults_length = []\n        faults_width = []\n        faults_slip_rates = []\n        faults_mecanism = []\n        faults_shear_mod = []\n        '########################################################\\n            # Random sampling of the fault slip-rate\\n            ########################################################'\n        print('Picking slip-rates...')\n        if self.sample == 1:\n            self.sr_correl = False\n        if self.sr_correl == True:\n            M_faults_correl = []\n            for Fault_name in faults_names:\n                M_faults_correl_i = []\n                sc_with_fault = []\n                for index_scenario in range(len(scenarios_names)):\n                    scenario_i = self.rupture_set[index_scenario]\n                    if Fault_name in scenario_i:\n                        sc_with_fault += scenario_i\n                for Fault_name_i in faults_names:\n                    nb_join_ruptures = 0\n                    if Fault_name == Fault_name_i:\n                        nb_join_ruptures = 0\n                    elif Fault_name_i in sc_with_fault:\n                        nb_join_ruptures = sc_with_fault.count(Fault_name_i)\n                    else:\n                        nb_join_ruptures = 0\n                    M_faults_correl_i.append(nb_join_ruptures)\n                M_faults_correl.append(M_faults_correl_i)\n            M_linked_lvl = np.zeros_like(M_faults_correl)\n            for lvl in [1, 2, 3, 4]:\n                for i in range(len(faults_names)):\n                    for j in range(len(faults_names)):\n                        if M_linked_lvl[i][j] == 0:\n                            if M_faults_correl[i][j] != 0:\n                                M_linked_lvl[i][j] = lvl\n                            else:\n                                for jj in range(len(M_faults_correl[j])):\n                                    if M_faults_correl[j][jj] != 0:\n                                        if M_linked_lvl[i][j] == 0:\n                                            M_linked_lvl[i][j] = lvl + 1\n            max_correl = np.max(M_faults_correl)\n            list_quater_picked = list(np.zeros(len(faults_names)))\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                sr_values = [faults_data[index_fault]['slip_rate_min'], faults_data[index_fault]['slip_rate_moy'], faults_data[index_fault]['slip_rate_max']]\n                slip_rate = select_sr.select(sr_values, self.sample, index_fault, M_linked_lvl[index_fault], list_quater_picked)\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        else:\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                slip_rate_min = faults_data[index_fault]['slip_rate_min']\n                slip_rate_moy = faults_data[index_fault]['slip_rate_moy']\n                slip_rate_max = faults_data[index_fault]['slip_rate_max']\n                if self.sample == 1:\n                    slip_rate = slip_rate_moy\n                else:\n                    slip_rate_inf = np.random.uniform(slip_rate_min, slip_rate_moy)\n                    slip_rate_sup = np.random.uniform(slip_rate_moy, slip_rate_max)\n                    slip_rate = np.random.choice([slip_rate_inf, slip_rate_sup])\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        print('\\t\\tslip-rates picked.')\n        ratio_test = 0.5\n        count_reruns = 1\n        count_mfd90 = 1\n        f_pkl_mdf = self.pathlog + '/mfd_' + str(self.sample) + '.pkl'\n        re_use_mfd_pkl = True\n        if not os.path.isfile(f_pkl_mdf):\n            re_use_mfd_pkl = False\n        if self.param['main']['parameters']['force_rerun'] == True:\n            re_use_mfd_pkl = False\n        if re_use_mfd_pkl == False:\n            while abs(ratio_test - 1) > self.fit_quality or math.isnan(ratio_test) == True:\n                MFDs = EQ_on_faults.EQ_on_faults_from_sr(self.Run_Name, M_min, mfd_param, faults_names, faults_area, faults_length, faults_width, faults_slip_rates, scenarios_names, faults_shear_mod, self.path, self.pathlog, self.sample, self.selected_ScL, self.dimention_used, self.use_all_ScL_data, faults_mecanism, self.bg_ratio, self.size_of_increment, self.mfd_hyp, count_reruns, faults_lon, faults_lat, self.Mmax_range, self.calculation_log_file, self.branch, self.param)\n                ratio_test = MFDs.ratio_test\n                if abs(ratio_test - 1) > self.fit_quality:\n                    print('bad sampling => re-run')\n                    count_reruns += 1\n                    if MFDs.ratio_NMS > 90.0:\n                        count_reruns -= 1\n                        count_mfd90 += 1\n                    else:\n                        count_mfd90 = 1\n                elif MFDs.ratio_NMS > 90.0:\n                    ratio_test = 0.5\n                    print('bad sampling => re-run')\n                    count_mfd90 += 1\n                else:\n                    count_mfd90 = 1\n                if math.isnan(ratio_test) == True:\n                    print('bad sampling => re-run')\n                    count_reruns = 1\n                if count_reruns > 3 or count_mfd90 > 3:\n                    print('\\n\\n\\n!!!!!! maybe there is a problem!!!')\n                    ratio_test = 1.0\n            with open(f_pkl_mdf, 'wb') as f:\n                MFDs_to_pkl = [MFDs.EQ_rate_BG, MFDs.faults_names, MFDs.OQ_entry_faults, MFDs.scenarios_names, MFDs.OQ_entry_scenarios, MFDs.index_faults_in_scenario, MFDs.M_slip_repartition]\n                pickle.dump(MFDs_to_pkl, f)\n        else:\n            print('Reloading MFDs from previous run')\n            with open(f_pkl_mdf, 'rb') as f:\n                MFDs_to_pkl = pickle.load(f)\n        EQ_rate_BG = MFDs_to_pkl[0]\n        faults_names = MFDs_to_pkl[1]\n        OQ_entry_faults = MFDs_to_pkl[2]\n        scenarios_names = MFDs_to_pkl[3]\n        OQ_entry_scenarios = MFDs_to_pkl[4]\n        index_faults_in_scenario = MFDs_to_pkl[5]\n        M_slip_repartition = MFDs_to_pkl[6]\n        if self.selected_ScL == 'Le2010':\n            ScL_oq = 'Leonard2014_SCR'\n        if self.selected_ScL == 'WC1994':\n            ScL_oq = 'WC1994'\n        else:\n            ScL_oq = 'WC1994'\n        (Lon_bg, Lat_bg) = bg.geom(self.Model_name, self.File_bg)\n        Poly_bg = []\n        for (x1, y1) in zip(Lon_bg, Lat_bg):\n            Poly_bg.append((x1, y1))\n        try:\n            bbPath_BG = mplPath.Path(Poly_bg)\n        except:\n            print('ERROR, please make sure the model name matches in the bg file')\n        f_in_bg = []\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            for (lon, lat) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                if bbPath_BG.contains_point((lon, lat)):\n                    f_in_bg.append(index_fault)\n        outside_faults = []\n        if include_all_faults == True:\n            for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n                if not index_fault in f_in_bg:\n                    f_in_bg.append(index_fault)\n                    outside_faults.append(index_fault)\n        source_id = 0\n        if cut_sm_file == False:\n            source_xml = self.path + '/Source_model_' + str(self.sample) + '.xml'\n            list_src_files.append(source_xml)\n            trt = faults_data[0]['domain']\n            txt = wmfs.start(explo_time, trt)\n            name = 'multifaultsource'\n            txt = wmfs.start_multifault_source(txt, name, trt, sections_xml, source_id)\n        else:\n            for f in s_files:\n                trt = faults_data[0]['domain']\n                dict_txt[f] = wmfs.start(explo_time, trt)\n                name = 'multifaultsource_' + str(source_id)\n                dict_txt[f] = wmfs.start_multifault_source(dict_txt[f], name, trt, sections_xml, source_id)\n                source_id += 1\n            f = list(dict_txt.keys())[0]\n        single_f_xml = self.path + '/single_sec_rup.xml'\n        trt = faults_data[0]['domain']\n        single_txt = wss.start(self.Model_name, trt)\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            if index_fault in f_in_bg:\n                i_MFD = np.where(np.array(faults_names) == fault_name)[0][0]\n                MFD = OQ_entry_faults[i_MFD]\n                if sum(MFD) != 0:\n                    source_id = source_id + 1\n                    Fault_Name = self.Model_name + '_' + str(fault_name)\n                    fault_trt = faults_data[index_fault]['domain']\n                    if not fault_trt in str(self.Domain_in_the_model):\n                        self.Domain_in_the_model.append(fault_trt)\n                    trt = str(fault_trt)\n                    rake = faults_data[index_fault]['rake']\n                    geotype = 'kite'\n                    name = 'single_fault_' + fault_name\n                    single_txt = wss.wrt_source(single_txt, index_fault, faults_names, faults_data, geotype, resample, vertical_faults, fault_trt, M_min, MFD, ScL_oq)\n        single_txt = wss.end(single_txt)\n        wss.build(single_f_xml, single_txt)\n        if len(self.rupture_set) != 0:\n            for scenario in enumerate(scenarios_names):\n                sc_in = False\n                index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                index_faults_in_sc = index_faults_in_scenario[index_scenario][0]\n                for i in index_faults_in_sc:\n                    if i in f_in_bg:\n                        sc_in = True\n                if sc_in == True:\n                    index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                    MFD = OQ_entry_scenarios[index_scenario]\n                    if sum(MFD) != 0:\n                        faults_in_scenario = np.take(faults_names, index_faults_in_sc)\n                        source_id = source_id + 1\n                        scenar_name = '_'.join(('{!s}={!r}'.format(key, val) for (key, val) in scenario[1].items()))\n                        source_name = self.Model_name + '_scenario_'\n                        source_name += str(scenar_name)\n                        list_trt = []\n                        scenario_mechanism = []\n                        for fname in faults_in_scenario:\n                            i = faults_names.index(fname)\n                            scenario_mechanism.append(faults_data[i]['rake'])\n                            fault_trt = faults_data[i]['domain']\n                            list_trt.append(fault_trt)\n                            if not fault_trt in str(self.Domain_in_the_model):\n                                self.Domain_in_the_model.append(fault_trt)\n                        fault_trt = max(list_trt, key=list_trt.count)\n                        trt = str(fault_trt)\n                        rake = np.mean(scenario_mechanism)\n                        if cut_sm_file == False:\n                            txt = wmfs.wrt_multifault_source(txt, MFD, self.Mmin, explo_time, rake, index_faults_in_sc)\n                        else:\n                            if not dict_n_rup[f] < max_rup_per_file:\n                                i = 0\n                                while dict_n_rup[f] > max_rup_per_file:\n                                    i += 1\n                                    f = list(dict_txt.keys())[i]\n                            txt = dict_txt[f]\n                            dict_txt[f] = wmfs.wrt_multifault_source(txt, MFD, self.Mmin, explo_time, rake, index_faults_in_sc)\n                            dict_n_rup[f] += 1\n        if cut_sm_file == False:\n            txt = wmfs.end_multifault_source(txt)\n            txt = wmfs.end(txt)\n            wmfs.build(source_xml, txt)\n        else:\n            for f in s_files:\n                if dict_n_rup[f] > 0:\n                    dict_txt[f] = wmfs.end_multifault_source(dict_txt[f])\n                    txt = wmfs.end(dict_txt[f])\n                    wmfs.build(f, txt)\n    else:\n        '\\n            ###########\\n            ############\\n            NOT USING MULTIFAULTSOURCE TYPOLOGY in OQ\\n\\n            '\n        line = \"<?xml version='1.0' encoding='utf-8'?>\\n\"\n        line += '<nrml xmlns:gml=\"http://www.opengis.net/gml\"\\n'\n        line += '\\txmlns=\"http://openquake.org/xmlns/nrml/0.5\">\\n'\n        line += '\\t<sourceModel name=\"Hazard Model\"'\n        line += ' investigation_time=\"' + str(round(explo_time, 1)) + '\">\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n        line = '\\t\\t<sourceGroup\\nname=\"group 1\"\\nrup_interdep=\"indep\"\\nsrc_interdep=\"indep\"\\ntectonicRegion=\"Active Shallow Crust\"\\n>\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n        log_general_parameters_file = open(self.pathlog + '/Log/general_parameters_sample_' + str(self.sample) + '.txt', 'w')\n        M_min = float(self.Mmin)\n        log_general_parameters_file.write('M_tronc\\t' + str(M_min) + '\\n')\n        log_general_parameters_file.write('b_value\\t' + str(self.b_value) + '\\n')\n        log_general_parameters_file.close()\n        faults_area = []\n        faults_length = []\n        faults_width = []\n        faults_slip_rates = []\n        faults_mecanism = []\n        faults_shear_mod = []\n        '########################################################\\n            # Random sampling of the fault slip-rate\\n            ########################################################'\n        print('Picking slip-rates...')\n        if self.sample == 1:\n            self.sr_correl = False\n        if self.sr_correl == True:\n            M_faults_correl = []\n            for Fault_name in faults_names:\n                M_faults_correl_i = []\n                sc_with_fault = []\n                for index_scenario in range(len(scenarios_names)):\n                    scenario_i = self.rupture_set[index_scenario]\n                    if Fault_name in scenario_i:\n                        sc_with_fault += scenario_i\n                for Fault_name_i in faults_names:\n                    nb_join_ruptures = 0\n                    if Fault_name == Fault_name_i:\n                        nb_join_ruptures = 0\n                    elif Fault_name_i in sc_with_fault:\n                        nb_join_ruptures = sc_with_fault.count(Fault_name_i)\n                    else:\n                        nb_join_ruptures = 0\n                    M_faults_correl_i.append(nb_join_ruptures)\n                M_faults_correl.append(M_faults_correl_i)\n            M_linked_lvl = np.zeros_like(M_faults_correl)\n            for lvl in [1, 2, 3, 4]:\n                for i in range(len(faults_names)):\n                    for j in range(len(faults_names)):\n                        if M_linked_lvl[i][j] == 0:\n                            if M_faults_correl[i][j] != 0:\n                                M_linked_lvl[i][j] = lvl\n                            else:\n                                for jj in range(len(M_faults_correl[j])):\n                                    if M_faults_correl[j][jj] != 0:\n                                        if M_linked_lvl[i][j] == 0:\n                                            M_linked_lvl[i][j] = lvl + 1\n            max_correl = np.max(M_faults_correl)\n            list_quater_picked = list(np.zeros(len(faults_names)))\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                sr_values = [faults_data[index_fault]['slip_rate_min'], faults_data[index_fault]['slip_rate_moy'], faults_data[index_fault]['slip_rate_max']]\n                slip_rate = select_sr.select(sr_values, self.sample, index_fault, M_linked_lvl[index_fault], list_quater_picked)\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        else:\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                slip_rate_min = faults_data[index_fault]['slip_rate_min']\n                slip_rate_moy = faults_data[index_fault]['slip_rate_moy']\n                slip_rate_max = faults_data[index_fault]['slip_rate_max']\n                if self.sample == 1:\n                    slip_rate = slip_rate_moy\n                else:\n                    slip_rate_inf = np.random.uniform(slip_rate_min, slip_rate_moy)\n                    slip_rate_sup = np.random.uniform(slip_rate_moy, slip_rate_max)\n                    slip_rate = np.random.choice([slip_rate_inf, slip_rate_sup])\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        print('\\t\\tslip-rates picked.')\n        ratio_test = 0.5\n        count_reruns = 1\n        count_mfd90 = 1\n        f_pkl_mdf = self.pathlog + '/mfd_' + str(self.sample) + '.pkl'\n        re_use_mfd_pkl = True\n        if not os.path.isfile(f_pkl_mdf):\n            re_use_mfd_pkl = False\n        if re_use_mfd_pkl == False:\n            while abs(ratio_test - 1) > self.fit_quality or math.isnan(ratio_test) == True:\n                MFDs = EQ_on_faults.EQ_on_faults_from_sr(M_min, mfd_param, faults_names, faults_area, faults_length, faults_width, faults_slip_rates, scenarios_names, faults_shear_mod, self.path, self.sample, self.selected_ScL, self.dimention_used, self.use_all_ScL_data, faults_mecanism, self.bg_ratio, self.size_of_increment, self.mfd_hyp, count_reruns, faults_lon, faults_lat, self.Mmax_range, self.calculation_log_file, self.branch, self.param)\n                ratio_test = MFDs.ratio_test\n                if abs(ratio_test - 1) > self.fit_quality:\n                    print('bad sampling => re-run')\n                    count_reruns += 1\n                    if MFDs.ratio_NMS > 90.0:\n                        count_reruns -= 1\n                        count_mfd90 += 1\n                    else:\n                        count_mfd90 = 1\n                elif MFDs.ratio_NMS > 90.0:\n                    ratio_test = 0.5\n                    print('bad sampling => re-run')\n                    count_mfd90 += 1\n                else:\n                    count_mfd90 = 1\n                if math.isnan(ratio_test) == True:\n                    print('bad sampling => re-run')\n                    count_reruns = 1\n                if count_reruns > 3 or count_mfd90 > 3:\n                    print('\\n\\n\\n!!!!!! maybe there is a problem!!!')\n                    ratio_test = 1.0\n            with open(f_pkl_mdf, 'wb') as f:\n                MFDs_to_pkl = [MFDs.EQ_rate_BG, MFDs.faults_names, MFDs.OQ_entry_faults, MFDs.scenarios_names, MFDs.OQ_entry_scenarios, MFDs.index_faults_in_scenario, MFDs.M_slip_repartition]\n                pickle.dump(MFDs_to_pkl, f)\n        else:\n            print('Reloading MFDs from previous run')\n            with open(f_pkl_mdf, 'rb') as f:\n                MFDs_to_pkl = pickle.load(f)\n        EQ_rate_BG = MFDs_to_pkl[0]\n        faults_names = MFDs_to_pkl[1]\n        OQ_entry_faults = MFDs_to_pkl[2]\n        scenarios_names = MFDs_to_pkl[3]\n        OQ_entry_scenarios = MFDs_to_pkl[4]\n        index_faults_in_scenario = MFDs_to_pkl[5]\n        M_slip_repartition = MFDs_to_pkl[6]\n        if self.selected_ScL == 'Le2010':\n            ScL_oq = 'Leonard2014_SCR'\n        elif self.selected_ScL == 'WC1994':\n            ScL_oq = 'WC1994'\n        else:\n            ScL_oq = 'WC1994'\n        (Lon_bg, Lat_bg) = bg.geom(self.Model_name, self.File_bg)\n        Poly_bg = []\n        for (x1, y1) in zip(Lon_bg, Lat_bg):\n            Poly_bg.append((x1, y1))\n        bbPath_BG = mplPath.Path(Poly_bg)\n        f_in_bg = []\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            for (lon, lat) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                if bbPath_BG.contains_point((lon, lat)):\n                    f_in_bg.append(index_fault)\n        outside_faults = []\n        if include_all_faults == True:\n            for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n                if not index_fault in f_in_bg:\n                    f_in_bg.append(index_fault)\n                    outside_faults.append(index_fault)\n        ID_number = 0\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            if index_fault in f_in_bg:\n                use_simple_faults = False\n                if use_simple_faults == True:\n                    (line, self.Domain_in_the_model, ID_number) = fault_source.write_simple_fault(index_fault, fault_name, OQ_entry_faults, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, M_min, ID_number)\n                else:\n                    (line, self.Domain_in_the_model, ID_number) = fault_source.write_non_parametric_one_fault(index_fault, fault_name, OQ_entry_faults, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, M_min, ID_number, explo_time)\n                if cut_sm_file == False:\n                    XMLfile.write(line)\n                else:\n                    i_w = 0\n                    while sf_counter[i_w] > 500:\n                        i_w += 1\n                    sf_files[i_w].write(line)\n                    sf_counter[i_w] += 1\n        if len(self.rupture_set) != 0:\n            for scenario in enumerate(scenarios_names):\n                sc_in = False\n                index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                for i in index_faults_in_scenario[index_scenario][0]:\n                    if i in f_in_bg:\n                        sc_in = True\n                if sc_in == True:\n                    use_non_param = True\n                    if use_non_param == False:\n                        (line, ID_number) = fault_source.write_characteristic_scenario(scenarios_names, OQ_entry_scenarios, index_faults_in_scenario, scenario, faults_names, self.Model_name, faults_data, log_mdf_file, M_min, ID_number)\n                    else:\n                        (line, ID_number) = fault_source.write_non_parametric_source(scenario, scenarios_names, OQ_entry_scenarios, index_faults_in_scenario, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, explo_time, M_min, ID_number)\n                    if cut_sm_file == False:\n                        XMLfile.write(line)\n                    else:\n                        i_w = 0\n                        while mf_counter[i_w] > 500:\n                            i_w += 1\n                        mf_files[i_w].write(line)\n                        mf_counter[i_w] += 1\n    '#########################\\n        # Defining the background seismicity\\n        #########################'\n    MFD = EQ_rate_BG\n    pts_list = {}\n    if sum(MFD) != 0.0 and self.param['main']['background']['option_bg'] == 'zone':\n        bg_file = self.path + '/bg_' + str(self.sample) + '.xml'\n        list_src_files.append(bg_file)\n        bg_file = open(bg_file, 'w')\n        line = \"<?xml version='1.0' encoding='utf-8'?>\\n\"\n        line += '<nrml xmlns:gml=\"http://www.opengis.net/gml\"\\n'\n        line += '\\txmlns=\"http://openquake.org/xmlns/nrml/0.5\">\\n'\n        line += '\\t<sourceModel name=\"Hazard Model\">\\n'\n        (upperSeismoDepth, lowerSeismoDepth, ruptAspectRatio, nodalPlanes, hypoDepths) = bg.prop(self.Model_name, self.file_prop_bg)\n        line += '\\t\\t<sourceGroup\\nname=\"group 2\"\\nrup_interdep=\"indep\"\\nsrc_interdep=\"indep\"\\ntectonicRegion=\"' + str(self.Domain_in_the_model[0]) + '\"\\n>\\n'\n        line += '\\t\\t<areaSource id=\"' + str(source_id + 1) + '\" name=\"Background\" tectonicRegion=\"' + str(self.Domain_in_the_model[0]) + '\">\\n'\n        line += '\\t\\t\\t<areaGeometry>\\n'\n        line += '\\t\\t\\t\\t<gml:Polygon>\\n'\n        line += '\\t\\t\\t\\t\\t<gml:exterior>\\n'\n        line += '\\t\\t\\t\\t\\t\\t<gml:LinearRing>\\n'\n        line += '\\t\\t\\t\\t\\t\\t\\t<gml:posList>\\n'\n        for (x, y) in zip(Lon_bg, Lat_bg):\n            line += '\\t\\t\\t\\t\\t\\t\\t\\t' + str(x) + ' ' + str(y) + '\\n'\n        line += '\\t\\t\\t\\t\\t\\t\\t</gml:posList>\\n'\n        line += '\\t\\t\\t\\t\\t\\t</gml:LinearRing>\\n'\n        line += '\\t\\t\\t\\t\\t</gml:exterior>\\n'\n        line += '\\t\\t\\t\\t</gml:Polygon>\\n'\n        line += '\\t\\t\\t\\t<upperSeismoDepth>' + str(upperSeismoDepth) + '</upperSeismoDepth>\\n'\n        line += '\\t\\t\\t\\t<lowerSeismoDepth>' + str(lowerSeismoDepth) + '</lowerSeismoDepth>\\n'\n        line += '\\t\\t\\t</areaGeometry>\\n'\n        line += '\\t\\t\\t<magScaleRel>' + ScL_oq + '</magScaleRel>\\n'\n        line += '\\t\\t\\t<ruptAspectRatio>' + str(ruptAspectRatio) + '</ruptAspectRatio>\\n'\n        log_mdf_file.write('Background' + '\\t' + str(M_min) + '\\t' + ' '.join(list(map(str, MFD))) + '\\n')\n        line += '\\t\\t\\t<incrementalMFD binWidth=\"0.10\" minMag=\"' + str(M_min) + '\">\\n'\n        line += '\\t\\t\\t<occurRates> ' + ' '.join(list(map(str, MFD))) + '</occurRates>\\n'\n        line += '\\t\\t\\t</incrementalMFD>\\n'\n        line += '\\t\\t\\t<nodalPlaneDist>\\n'\n        for i in range(len(nodalPlanes)):\n            line += '\\t\\t\\t\\t<nodalPlane probability=\"' + str(nodalPlanes[i][0]) + '\" strike=\"' + str(nodalPlanes[i][1]) + '\" dip=\"' + str(nodalPlanes[i][2]) + '\" rake=\"' + str(nodalPlanes[i][3]) + '\" />\\n'\n        line += '\\t\\t\\t</nodalPlaneDist>\\n'\n        line += '\\t\\t\\t<hypoDepthDist>\\n'\n        for i in range(len(hypoDepths)):\n            line += '\\t\\t\\t\\t<hypoDepth probability=\"' + str(hypoDepths[i][0]) + '\" depth=\"' + str(hypoDepths[i][1]) + '\" />\\n'\n        line += '\\t\\t\\t</hypoDepthDist>\\n'\n        line += '\\t\\t</areaSource>\\n'\n        line += '\\t</sourceGroup>\\n'\n        line += '\\t</sourceModel>\\n'\n        line += '</nrml>\\n'\n        bg_file.write(line)\n        bg_file.close()\n    elif sum(MFD) != 0.0 and self.param['main']['background']['option_bg'] == 'smooth':\n        Mmin_checked = False\n        Mmax = M_min + len(EQ_rate_BG) * 0.1 - 1\n        mags = np.linspace(M_min, Mmax, len(EQ_rate_BG))\n        list_bg_xml = self.list_fbg\n        if os.path.isdir(self.fbgpath):\n            list_bg_xml = [self.fbgpath + '/' + i for i in list_bg_xml if '.xml' in i]\n        with open(list_bg_xml[0]) as myfile:\n            if 'multiPointSource' in myfile.read():\n                multiPointSource_type = True\n            else:\n                multiPointSource_type = False\n        if multiPointSource_type == True:\n            bg.get_multipoints(EQ_rate_BG, M_min, bbPath_BG, list_bg_xml, include_all_faults, outside_faults, faults_data, OQ_entry_faults, self.path, self.pathlog, list_src_files)\n        else:\n            pts_list = {}\n            pts_out_list = {}\n            sum_rates = [0.0 for _ in mags]\n            for fbg in list_bg_xml:\n                tree = ET.parse(fbg)\n                ET.register_namespace('', 'http://openquake.org/xmlns/nrml/0.5')\n                nrml = tree.getroot()\n                i_point = 0\n                for pointSource in nrml[0][0]:\n                    pt_in_BG = False\n                    i_child = 0\n                    for child in pointSource.getchildren():\n                        if 'pointGeometry' in str(child):\n                            s_tmp = pointSource[i_child][0][0].text\n                            s_tmp = s_tmp.replace('\\n', '')\n                            s_tmp = [float(i) for i in s_tmp.split(' ') if i != '']\n                            if bbPath_BG.contains_point((s_tmp[0], s_tmp[1])) == 1:\n                                pt_in_BG = True\n                            str_loc = str(s_tmp[0]) + '_' + str(s_tmp[1])\n                        if 'truncGutenbergRichterMFD' in str(child):\n                            aValue = nrml[0][0][i_point][i_child].get('aValue')\n                            minMag = nrml[0][0][i_point][i_child].get('minMag')\n                            i_trGR = i_child\n                        i_child += 1\n                    aValue = nrml[0][0][i_point][i_trGR].get('aValue')\n                    minMag = nrml[0][0][i_point][i_trGR].get('minMag')\n                    bValue = nrml[0][0][i_point][i_trGR].get('bValue')\n                    maxMag = nrml[0][0][i_point][i_trGR].get('maxMag')\n                    mfd_smooth = []\n                    i_mag = 0\n                    for mag in mags:\n                        mag_lo = mag - 0.05\n                        mag_hi = mag + 0.05\n                        r = 10 ** (float(aValue) - float(bValue) * mag_lo) - 10 ** (float(aValue) - float(bValue) * mag_hi)\n                        sum_rates[i_mag] += r\n                        i_mag += 1\n                        mfd_smooth.append(r)\n                    if pt_in_BG == True:\n                        pts_list.update({str_loc: {'aValue': aValue, 'bValue': bValue, 'maxMag': maxMag, 'minMag': minMag, 'mfd_smooth': mfd_smooth}})\n                        if Mmin_checked == False:\n                            if float(minMag) < M_min:\n                                print('!!!!')\n                                print('WARNING : BG has a smaller Mmin than the SHERIFS input')\n                                print('!!!!')\n                                Mmin_checked = True\n                    elif include_all_faults == True:\n                        pt_very_far = True\n                        lon_lat_distance_criteria = 1.0\n                        i = 0\n                        while pt_very_far == False and i < len(outside_faults):\n                            i_fault = outside_faults[i]\n                            mean_lon = np.mean(faults_data[index_fault]['lon'])\n                            mean_lat = np.mean(faults_data[index_fault]['lat'])\n                            if abs(float(s_tmp[0]) - mean_lon) < lon_lat_distance_criteria:\n                                pt_very_far = False\n                            if abs(float(s_tmp[1]) - mean_lat) < lon_lat_distance_criteria:\n                                pt_very_far = False\n                            i += 1\n                        if pt_very_far == False:\n                            dist_critera = 50.0\n                            dist = 1000000.0\n                            closest_fault = 'nope'\n                            for i_fault in outside_faults:\n                                mean_lon = np.mean(faults_data[index_fault]['lon'])\n                                mean_lat = np.mean(faults_data[index_fault]['lat'])\n                                dist_i = distance(mean_lon, mean_lat, float(s_tmp[0]), float(s_tmp[1]))\n                                if dist_i < dist_critera:\n                                    for (lon_f, lat_f) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                                        dist_i = distance(mean_lon, mean_lat, float(s_tmp[0]), float(s_tmp[1]))\n                                        if dist_i < dist:\n                                            dist = dist_i\n                                            closest_fault = i_fault\n                                if dist_i < dist:\n                                    dist = dist_i\n                                    closest_fault = i_fault\n                            closest_dist = dist\n                            pts_out_list.update({str_loc: {'aValue': aValue, 'bValue': bValue, 'maxMag': maxMag, 'minMag': minMag, 'mfd_smooth': mfd_smooth, 'distance': closest_dist, 'closest_fault': i_fault}})\n                    i_point += 1\n            nb_pt_in_buff = {}\n            if include_all_faults == True:\n                for i_fault in outside_faults:\n                    buffer_1 = 10.0\n                    buffer_2 = 20.0\n                    nb_buf1 = 0\n                    nb_buf2 = 0\n                    for str_loc in pts_out_list.keys():\n                        if pts_out_list[str_loc]['closest_fault'] == i_fault:\n                            if pts_out_list[str_loc]['closest_dist'] < buffer_1:\n                                nb_buf1 += 1\n                            elif pts_out_list[str_loc]['closest_dist'] < buffer_2:\n                                nb_buf2 += 1\n                    nb_pt_in_buff.update({i_fault: {'nb_buf1': nb_buf1, 'nb_buf2': nb_buf2}})\n            sum_bg_min = 0.0\n            i_bg = 0\n            for fbg in list_bg_xml:\n                tree = ET.parse(fbg)\n                ET.register_namespace('', 'http://openquake.org/xmlns/nrml/0.5')\n                nrml = tree.getroot()\n                i_point = 0\n                for pointSource in nrml[0][0]:\n                    pt_in_BG = False\n                    i_child = 0\n                    for child in pointSource.getchildren():\n                        if 'magScaleRel' in str(child):\n                            nrml[0][0][i_point][i_child].text = ScL_oq\n                        if 'pointGeometry' in str(child):\n                            s_tmp = pointSource[i_child][0][0].text\n                            s_tmp = s_tmp.replace('\\n', '')\n                            s_tmp = [float(i) for i in s_tmp.split(' ') if i != '']\n                            str_loc = str(s_tmp[0]) + '_' + str(s_tmp[1])\n                        if 'truncGutenbergRichterMFD' in str(child):\n                            i_trGR = i_child\n                        i_child += 1\n                    if str_loc in pts_list.keys():\n                        b_value = float(pts_list[str_loc]['bValue'])\n                        a_value = float(pts_list[str_loc]['aValue'])\n                        attrib = {'minMag': str(M_min), 'binWidth': '0.10'}\n                        element = nrml[0][0][i_point].makeelement('incrementalMFD', attrib)\n                        nrml[0][0][i_point].append(element)\n                        element = nrml[0][0][i_point][-1].makeelement('occurRates', {})\n                        nrml[0][0][i_point][-1].append(element)\n                        str_tmp = ' '\n                        pt_scl_mfd = []\n                        i_mag = 0\n                        for mag in mags:\n                            mag_lo = mag - 0.05\n                            mag_hi = mag + 0.05\n                            r = 10 ** (a_value - b_value * mag_lo) - 10 ** (a_value - b_value * mag_hi)\n                            norm_r = r / sum_rates[i_mag]\n                            str_tmp += str(EQ_rate_BG[i_mag] * norm_r)\n                            str_tmp += ' '\n                            sum_bg_min += EQ_rate_BG[i_mag] * norm_r\n                            pt_scl_mfd.append(EQ_rate_BG[i_mag] * norm_r)\n                            i_mag += 1\n                        pts_list[str_loc].update({'scaled_mfd': pt_scl_mfd})\n                        nrml[0][0][i_point][-1][0].text = str_tmp\n                        nrml[0][0][i_point].remove(nrml[0][0][i_point][i_trGR])\n                    if include_all_faults == True:\n                        if str_loc in pts_out_list.keys():\n                            b_value = float(pts_list[str_loc]['bValue'])\n                            a_value = float(pts_list[str_loc]['aValue'])\n                            attrib = {'minMag': str(M_min), 'binWidth': '0.10'}\n                            element = nrml[0][0][i_point].makeelement('incrementalMFD', attrib)\n                            nrml[0][0][i_point].append(element)\n                            element = nrml[0][0][i_point][-1].makeelement('occurRates', {})\n                            nrml[0][0][i_point][-1].append(element)\n                            str_tmp = ' '\n                            pt_scl_mfd = []\n                            i_fault = pts_out_list[str_loc]['closest_fault']\n                            mfd_single_clst_f = OQ_entry_faults[i_fault]\n                            id_ruptures = []\n                            mfd_mlt_clst_f = []\n                            for (scenario_i, mfd_i) in zip(index_faults_in_scenario, OQ_entry_scenarios):\n                                if i_fault in scenario_i:\n                                    id_ruptures.append(scenario_i)\n                                    mfd_mlt_clst_f.append(mfd_i)\n                            i_mag = 0\n                            for mag in mags:\n                                mag_lo = mag - 0.05\n                                mag_hi = mag + 0.05\n                                r = 10 ** (a_value - b_value * mag_lo) - 10 ** (a_value - b_value * mag_hi)\n                                if mag >= 6.5:\n                                    buffer_to_use = 'nb_buf2'\n                                else:\n                                    buffer_to_use = 'nb_buf1'\n                                reduction = 0.0\n                                for (f_in_rup, mfd_i) in zip(id_ruptures, mfd_mlt_clst_f):\n                                    reduction += mfd_i[i_mag] / float(len(f_in_rup) * nb_pt_in_buff[i_fault][buffer_to_use])\n                                if reduction > r:\n                                    r = 0.0\n                                else:\n                                    r -= reduction\n                                str_tmp += str(r)\n                                str_tmp += ' '\n                                pt_scl_mfd.append(r)\n                                i_mag += 1\n                            pts_out_list[str_loc].update({'scaled_mfd': pt_scl_mfd})\n                            nrml[0][0][i_point][-1][0].text = str_tmp\n                            nrml[0][0][i_point].remove(nrml[0][0][i_point][i_trGR])\n                    i_point += 1\n                i_bg += 1\n                fbg_out = self.path + '/bg_' + str(self.sample) + '_' + str(i_bg) + '.xml'\n                tree.write(fbg_out)\n                list_src_files.append(fbg_out)\n    '#############################\\n        ### defining the other sources based on the host model\\n        ##############################'\n    if self.param['main']['background']['use_host_model'] == True and cut_sm_file == False:\n        host_model.build(XMLfile, self.host_model_file, Lon_bg, Lat_bg)\n    if self.param['main']['background']['use_host_model'] == True and cut_sm_file == True:\n        print(\"WARNING : can't use host model and cut files yet !\")\n    if use_multiF == False:\n        line = '\\t\\t\\t</sourceGroup>\\n'\n        line += '\\t</sourceModel>\\n'\n        line += '</nrml>\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n            XMLfile.close()\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n                f.close()\n    log_sr_file.close()\n    log_mdf_file.close()\n    self.list_src_files = list_src_files\n    '#############################\\n        ### Get the particiaption rates of sections\\n        ##############################'\n    import participation_rates as p_rates\n    from section_info import get_nonzero_Mmax\n    (dict_p_rates, mfd_total, all_non_zero_rups) = p_rates.get_all_participation_rates(MFDs_to_pkl, self.param, faults_names)\n    bin_mag = p_rates.get_bin_mag(mfd_total, self.Mmin)\n    all_participation_rates = []\n    sections_Mmax = []\n    if not os.path.isdir(self.pathlog + '/participation_rates'):\n        os.makedirs(self.pathlog + '/participation_rates')\n    for fault_name in faults_names:\n        (incremental_rate, cumulative_rate) = p_rates.extract_rates(fault_name, dict_p_rates)\n        all_participation_rates.append(cumulative_rate)\n        ptf = self.pathlog + '/participation_rates/' + str(fault_name) + '.png'\n        p_rates.plot_participation_rates(bin_mag, incremental_rate, cumulative_rate, fault_name, ptf)\n        Mmax = get_nonzero_Mmax(bin_mag, cumulative_rate)\n        sections_Mmax.append(Mmax)\n    '#############################\\n        ### Exporting the results in a Geojson\\n        ##############################'\n    features = []\n    for si in f_in_bg:\n        sections = []\n        geom = []\n        for (lon_i, lat_i) in zip(faults_data[si]['lon'], faults_data[si]['lat']):\n            geom.append((lon_i, lat_i))\n        geom = LineString(list(geom))\n        properties = {}\n        for key in faults_data[si].keys():\n            if not key in ['lat', 'lon']:\n                properties.update({key: faults_data[si][key]})\n        NMS = float(M_slip_repartition[faults_data[si]['name']]['NMS'])\n        sumdsr = 0.0\n        for key in M_slip_repartition[faults_data[si]['name']].keys():\n            sumdsr += M_slip_repartition[faults_data[si]['name']][key]\n        properties.update({'NMS': NMS / float(sumdsr)})\n        properties.update({'nb_rup': float(all_non_zero_rups[si])})\n        properties.update({'Mmax': float(sections_Mmax[si])})\n        properties.update({'participation_rates': [bin_mag, all_participation_rates[si]]})\n        nms_i = NMS / float(sumdsr)\n        mmax_i = sections_Mmax[si]\n        if mmax_i >= max(sections_Mmax) - 0.3:\n            if nms_i < 0.1:\n                indicator = 1.0 - nms_i\n            else:\n                indicator = 0.0\n        elif mmax_i >= max(sections_Mmax) - 0.5:\n            if nms_i < 0.05:\n                indicator = 1.0 - nms_i\n            else:\n                indicator = 0.0\n        else:\n            indicator = 0.0\n        properties.update({'might_to_be_limiting': round(indicator, 2)})\n        features.append(Feature(geometry=geom, properties=properties))\n    feature_collection = FeatureCollection(features)\n    with open(self.pathlog + '/out_sections.geojson', 'w') as f:\n        dump(feature_collection, f)\n    '#######################\\n        ### some figures\\n        ######################'\n    if 'figures' in self.param.keys():\n        if self.param['figures']['print'] in ['true', 'True']:\n            make_figures = True\n        else:\n            make_figures = False\n    else:\n        make_figures = False\n    plt_model_mfd = False\n    if make_figures == True:\n        if self.param['figures']['model_mfd'] in ['true', 'True']:\n            plt_model_mfd = True\n    if 'mfd_cat' in self.param['figures'].keys():\n        data = self.param['figures']['mfd_cat']\n    else:\n        data = False\n    if plt_model_mfd == True:\n        x = MFDs.bin_mag\n        y = rates.get_rate_model(MFDs.rup_rates, MFDs.fault_prop, x)\n        lim = [[x[0] - 0.05, x[-1] + 0.05], [min(y) / 2.0, max(y) * 2.0]]\n        axis = ['magnitude', 'annual earthquake rates']\n        path = self.pathlog + '/modelMFD.png'\n        title = 'MFD of the whole system'\n        plt_mfd.plot(x, y, lim, axis, data, path, title)\n    if plt_model_mfd == True:\n        x = MFDs.bin_mag\n        (ft, bgmfd) = rates.get_rate_faults_n_bg(MFDs.rup_rates, MFDs.fault_prop, x)\n        ys = [rates.get_rate_model(MFDs.rup_rates, MFDs.fault_prop, x), ft, bgmfd]\n        lim = [[x[0] - 0.05, x[-1] + 0.05], [min(ys[0]) / 2.0, max(ys[0]) * 2.0]]\n        axis = ['magnitude', 'annual earthquake rates']\n        path = self.pathlog + '/modelMFD_bg_ft.png'\n        title = 'MFD of the whole system, faults, background'\n        plt_mfd.plot_bg_ft(x, ys, lim, axis, path, title)\n    ' mfd in a more local scale '\n    part_mfd = False\n    if make_figures == True:\n        if 'part_mfd' in self.param['figures'].keys():\n            if self.param['figures']['part_mfd'] in ['true', 'True']:\n                part_mfd = True\n    if part_mfd == True:\n        loc_cat = local_cat.read_geojson(self.param['figures']['parts_gjson'])\n        for zone in loc_cat.keys():\n            polypt = loc_cat[zone]['poly']\n            lons = []\n            lats = []\n            for pt in polypt[0][0]:\n                lons.append(pt[0])\n                lats.append(pt[1])\n            poly = []\n            for (x1, y1) in zip(lons, lats):\n                poly.append((x1, y1))\n            area_zone = geometry_tools.PolyArea(lons, lats)\n            area_bg = geometry_tools.PolyArea(Lon_bg, Lat_bg)\n            ratio_area = float(area_zone) / float(area_bg)\n            local_zone_mfd = [i * ratio_area for i in EQ_rate_BG]\n            poly = mplPath.Path(poly)\n            (txt_no_bg, rate_faults, rate_bg, smooth) = local_cat.get_model_rate(poly, OQ_entry_faults, OQ_entry_scenarios, pts_list, MFDs.bin_mag, self.param, faults_data, faults_names, index_faults_in_scenario, local_zone_mfd)\n            x = MFDs.bin_mag\n            rate_model = [i + j for (i, j) in zip(rate_faults, rate_bg)]\n            lim = [[x[0] - 0.05, x[-1] + 0.05], [min(rate_model) / 2.0, max(rate_model) * 2.0]]\n            axis = ['magnitude', 'annual earthquake rates']\n            title = 'MFD in zone ' + str(zone) + txt_no_bg\n            path = self.pathlog + '/MFD_zone' + str(zone) + '.png'\n            if 'cat_rates' in loc_cat[zone].keys():\n                data = loc_cat[zone]['cat_rates']\n            else:\n                data = False\n            if data == None:\n                data = False\n            if data == True:\n                if len(data[0]) == 0:\n                    data = False\n                if len(data[0]) != len(data[1]):\n                    data = False\n                    print('For zone', zone, ' : wrong bining')\n                    print('please check the geojson file')\n            plt_mfd.local(x, [rate_model, rate_faults, rate_bg, smooth], data, lim, axis, path, title)",
            "def initialize(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    path = self.param['dirpath']\n    explo_time = self.param['main']['parameters']['explo_time']\n    if self.param['main']['parameters']['use_multiF'] in ['True', 'true']:\n        use_multiF = True\n    else:\n        use_multiF == False\n    max_rup_per_file = 2000\n    faults_names = self.faults_names\n    scenarios_names = self.scenarios_names\n    faults_data = self.faults_data\n    (faults_lon, faults_lat) = (self.faults_lon, self.faults_lat)\n    list_src_files = []\n    log_sr_file = open(self.pathlog + '/slip_rate_sample_' + str(self.sample) + '.txt', 'w')\n    log_mdf_file = open(self.pathlog + '/mdf_sample_' + str(self.sample) + '.txt', 'w')\n    cut_sm_file = False\n    if len(faults_names) + len(scenarios_names) > max_rup_per_file:\n        cut_sm_file = True\n    if cut_sm_file == False:\n        XMLfile = open(self.path + '/Source_model_' + str(self.sample) + '.xml', 'w')\n    else:\n        n_cut_sf = 1\n        while len(faults_names) / n_cut_sf > max_rup_per_file:\n            n_cut_sf += 1\n        n_cut_mf = 1\n        while len(scenarios_names) / n_cut_mf > max_rup_per_file:\n            n_cut_mf += 1\n        if use_multiF == False:\n            ' create the file list'\n            (sf_files, sf_counter) = ([], [])\n            for i in range(n_cut_sf):\n                f = self.path + '/sm_' + str(self.sample) + '_sf_' + str(i + 1) + '.xml'\n                sf_files.append(open(f, 'w'))\n                sf_counter.append(0)\n                list_src_files.append(f)\n            (mf_files, mf_counter) = ([], [])\n            for i in range(n_cut_mf):\n                f = self.path + '/sm_' + str(self.sample) + '_mf_' + str(i + 1) + '.xml'\n                mf_files.append(open(f, 'w'))\n                mf_counter.append(0)\n                list_src_files.append(f)\n        if use_multiF == True:\n            n_cut_f = n_cut_sf + n_cut_mf\n            s_files = []\n            for i in range(n_cut_mf):\n                f = self.path + '/sm_' + str(i) + '.xml'\n                s_files.append(f)\n                list_src_files.append(f)\n            (dict_txt, dict_n_rup) = ({}, {})\n            for f in s_files:\n                dict_txt.update({f: ''})\n                dict_n_rup.update({f: 0})\n    include_all_faults = False\n    if 'include_all_faults' in self.param['main']['background'].keys():\n        if self.param['main']['background']['include_all_faults'] in ['True', 'true']:\n            include_all_faults = True\n    if use_multiF == True:\n        '\\n            #######################################\\n            #######################################\\n            USING MULTIFAULT TYPOLOGY IN OQ\\n            #######################################\\n            #######################################\\n            '\n        simplify_faults = self.param['main']['parameters']['simplify_faults']\n        if simplify_faults in ['True', 'true']:\n            resample = [False]\n        elif not 'resample' in self.param['main']['parameters'].keys():\n            resample = [False]\n        else:\n            rsp = self.param['main']['parameters']['resample']\n            if rsp[0] in ['True', 'true']:\n                resample = [True]\n                resample.append(float(rsp[1]))\n                resample.append(float(rsp[2]))\n                resample.append(float(rsp[3]))\n            else:\n                resample = [False]\n        if 'vertical_faults' in self.param['main']['parameters'].keys():\n            vertical_faults = self.param['main']['parameters']['vertical_faults']\n            if vertical_faults in ['True', 'true']:\n                vertical_faults = True\n            else:\n                vertical_faults = False\n        else:\n            vertical_faults = False\n        sections_xml = path + self.Run_Name + '/ssm/' + self.Model_name + '_sections.xml'\n        if not os.path.exists(sections_xml):\n            txt = wsf.start(self.Model_name)\n            for section_id in range(len(faults_names)):\n                geotype = 'kite'\n                txt = wsf.wrt_section(txt, section_id, faults_names, faults_data, geotype, resample, vertical_faults)\n            txt = wsf.end(txt)\n            wsf.build(sections_xml, txt)\n        log_general_parameters_file = open(self.pathlog + '/general_parameters_sample_' + str(self.sample) + '.txt', 'w')\n        M_min = float(self.Mmin)\n        log_general_parameters_file.write('M_tronc\\t' + str(M_min) + '\\n')\n        mfd_param = self.mfd_param\n        log_general_parameters_file.write('b_value\\t' + str(mfd_param['b_value']) + '\\n')\n        log_general_parameters_file.close()\n        faults_area = []\n        faults_length = []\n        faults_width = []\n        faults_slip_rates = []\n        faults_mecanism = []\n        faults_shear_mod = []\n        '########################################################\\n            # Random sampling of the fault slip-rate\\n            ########################################################'\n        print('Picking slip-rates...')\n        if self.sample == 1:\n            self.sr_correl = False\n        if self.sr_correl == True:\n            M_faults_correl = []\n            for Fault_name in faults_names:\n                M_faults_correl_i = []\n                sc_with_fault = []\n                for index_scenario in range(len(scenarios_names)):\n                    scenario_i = self.rupture_set[index_scenario]\n                    if Fault_name in scenario_i:\n                        sc_with_fault += scenario_i\n                for Fault_name_i in faults_names:\n                    nb_join_ruptures = 0\n                    if Fault_name == Fault_name_i:\n                        nb_join_ruptures = 0\n                    elif Fault_name_i in sc_with_fault:\n                        nb_join_ruptures = sc_with_fault.count(Fault_name_i)\n                    else:\n                        nb_join_ruptures = 0\n                    M_faults_correl_i.append(nb_join_ruptures)\n                M_faults_correl.append(M_faults_correl_i)\n            M_linked_lvl = np.zeros_like(M_faults_correl)\n            for lvl in [1, 2, 3, 4]:\n                for i in range(len(faults_names)):\n                    for j in range(len(faults_names)):\n                        if M_linked_lvl[i][j] == 0:\n                            if M_faults_correl[i][j] != 0:\n                                M_linked_lvl[i][j] = lvl\n                            else:\n                                for jj in range(len(M_faults_correl[j])):\n                                    if M_faults_correl[j][jj] != 0:\n                                        if M_linked_lvl[i][j] == 0:\n                                            M_linked_lvl[i][j] = lvl + 1\n            max_correl = np.max(M_faults_correl)\n            list_quater_picked = list(np.zeros(len(faults_names)))\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                sr_values = [faults_data[index_fault]['slip_rate_min'], faults_data[index_fault]['slip_rate_moy'], faults_data[index_fault]['slip_rate_max']]\n                slip_rate = select_sr.select(sr_values, self.sample, index_fault, M_linked_lvl[index_fault], list_quater_picked)\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        else:\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                slip_rate_min = faults_data[index_fault]['slip_rate_min']\n                slip_rate_moy = faults_data[index_fault]['slip_rate_moy']\n                slip_rate_max = faults_data[index_fault]['slip_rate_max']\n                if self.sample == 1:\n                    slip_rate = slip_rate_moy\n                else:\n                    slip_rate_inf = np.random.uniform(slip_rate_min, slip_rate_moy)\n                    slip_rate_sup = np.random.uniform(slip_rate_moy, slip_rate_max)\n                    slip_rate = np.random.choice([slip_rate_inf, slip_rate_sup])\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        print('\\t\\tslip-rates picked.')\n        ratio_test = 0.5\n        count_reruns = 1\n        count_mfd90 = 1\n        f_pkl_mdf = self.pathlog + '/mfd_' + str(self.sample) + '.pkl'\n        re_use_mfd_pkl = True\n        if not os.path.isfile(f_pkl_mdf):\n            re_use_mfd_pkl = False\n        if self.param['main']['parameters']['force_rerun'] == True:\n            re_use_mfd_pkl = False\n        if re_use_mfd_pkl == False:\n            while abs(ratio_test - 1) > self.fit_quality or math.isnan(ratio_test) == True:\n                MFDs = EQ_on_faults.EQ_on_faults_from_sr(self.Run_Name, M_min, mfd_param, faults_names, faults_area, faults_length, faults_width, faults_slip_rates, scenarios_names, faults_shear_mod, self.path, self.pathlog, self.sample, self.selected_ScL, self.dimention_used, self.use_all_ScL_data, faults_mecanism, self.bg_ratio, self.size_of_increment, self.mfd_hyp, count_reruns, faults_lon, faults_lat, self.Mmax_range, self.calculation_log_file, self.branch, self.param)\n                ratio_test = MFDs.ratio_test\n                if abs(ratio_test - 1) > self.fit_quality:\n                    print('bad sampling => re-run')\n                    count_reruns += 1\n                    if MFDs.ratio_NMS > 90.0:\n                        count_reruns -= 1\n                        count_mfd90 += 1\n                    else:\n                        count_mfd90 = 1\n                elif MFDs.ratio_NMS > 90.0:\n                    ratio_test = 0.5\n                    print('bad sampling => re-run')\n                    count_mfd90 += 1\n                else:\n                    count_mfd90 = 1\n                if math.isnan(ratio_test) == True:\n                    print('bad sampling => re-run')\n                    count_reruns = 1\n                if count_reruns > 3 or count_mfd90 > 3:\n                    print('\\n\\n\\n!!!!!! maybe there is a problem!!!')\n                    ratio_test = 1.0\n            with open(f_pkl_mdf, 'wb') as f:\n                MFDs_to_pkl = [MFDs.EQ_rate_BG, MFDs.faults_names, MFDs.OQ_entry_faults, MFDs.scenarios_names, MFDs.OQ_entry_scenarios, MFDs.index_faults_in_scenario, MFDs.M_slip_repartition]\n                pickle.dump(MFDs_to_pkl, f)\n        else:\n            print('Reloading MFDs from previous run')\n            with open(f_pkl_mdf, 'rb') as f:\n                MFDs_to_pkl = pickle.load(f)\n        EQ_rate_BG = MFDs_to_pkl[0]\n        faults_names = MFDs_to_pkl[1]\n        OQ_entry_faults = MFDs_to_pkl[2]\n        scenarios_names = MFDs_to_pkl[3]\n        OQ_entry_scenarios = MFDs_to_pkl[4]\n        index_faults_in_scenario = MFDs_to_pkl[5]\n        M_slip_repartition = MFDs_to_pkl[6]\n        if self.selected_ScL == 'Le2010':\n            ScL_oq = 'Leonard2014_SCR'\n        if self.selected_ScL == 'WC1994':\n            ScL_oq = 'WC1994'\n        else:\n            ScL_oq = 'WC1994'\n        (Lon_bg, Lat_bg) = bg.geom(self.Model_name, self.File_bg)\n        Poly_bg = []\n        for (x1, y1) in zip(Lon_bg, Lat_bg):\n            Poly_bg.append((x1, y1))\n        try:\n            bbPath_BG = mplPath.Path(Poly_bg)\n        except:\n            print('ERROR, please make sure the model name matches in the bg file')\n        f_in_bg = []\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            for (lon, lat) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                if bbPath_BG.contains_point((lon, lat)):\n                    f_in_bg.append(index_fault)\n        outside_faults = []\n        if include_all_faults == True:\n            for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n                if not index_fault in f_in_bg:\n                    f_in_bg.append(index_fault)\n                    outside_faults.append(index_fault)\n        source_id = 0\n        if cut_sm_file == False:\n            source_xml = self.path + '/Source_model_' + str(self.sample) + '.xml'\n            list_src_files.append(source_xml)\n            trt = faults_data[0]['domain']\n            txt = wmfs.start(explo_time, trt)\n            name = 'multifaultsource'\n            txt = wmfs.start_multifault_source(txt, name, trt, sections_xml, source_id)\n        else:\n            for f in s_files:\n                trt = faults_data[0]['domain']\n                dict_txt[f] = wmfs.start(explo_time, trt)\n                name = 'multifaultsource_' + str(source_id)\n                dict_txt[f] = wmfs.start_multifault_source(dict_txt[f], name, trt, sections_xml, source_id)\n                source_id += 1\n            f = list(dict_txt.keys())[0]\n        single_f_xml = self.path + '/single_sec_rup.xml'\n        trt = faults_data[0]['domain']\n        single_txt = wss.start(self.Model_name, trt)\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            if index_fault in f_in_bg:\n                i_MFD = np.where(np.array(faults_names) == fault_name)[0][0]\n                MFD = OQ_entry_faults[i_MFD]\n                if sum(MFD) != 0:\n                    source_id = source_id + 1\n                    Fault_Name = self.Model_name + '_' + str(fault_name)\n                    fault_trt = faults_data[index_fault]['domain']\n                    if not fault_trt in str(self.Domain_in_the_model):\n                        self.Domain_in_the_model.append(fault_trt)\n                    trt = str(fault_trt)\n                    rake = faults_data[index_fault]['rake']\n                    geotype = 'kite'\n                    name = 'single_fault_' + fault_name\n                    single_txt = wss.wrt_source(single_txt, index_fault, faults_names, faults_data, geotype, resample, vertical_faults, fault_trt, M_min, MFD, ScL_oq)\n        single_txt = wss.end(single_txt)\n        wss.build(single_f_xml, single_txt)\n        if len(self.rupture_set) != 0:\n            for scenario in enumerate(scenarios_names):\n                sc_in = False\n                index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                index_faults_in_sc = index_faults_in_scenario[index_scenario][0]\n                for i in index_faults_in_sc:\n                    if i in f_in_bg:\n                        sc_in = True\n                if sc_in == True:\n                    index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                    MFD = OQ_entry_scenarios[index_scenario]\n                    if sum(MFD) != 0:\n                        faults_in_scenario = np.take(faults_names, index_faults_in_sc)\n                        source_id = source_id + 1\n                        scenar_name = '_'.join(('{!s}={!r}'.format(key, val) for (key, val) in scenario[1].items()))\n                        source_name = self.Model_name + '_scenario_'\n                        source_name += str(scenar_name)\n                        list_trt = []\n                        scenario_mechanism = []\n                        for fname in faults_in_scenario:\n                            i = faults_names.index(fname)\n                            scenario_mechanism.append(faults_data[i]['rake'])\n                            fault_trt = faults_data[i]['domain']\n                            list_trt.append(fault_trt)\n                            if not fault_trt in str(self.Domain_in_the_model):\n                                self.Domain_in_the_model.append(fault_trt)\n                        fault_trt = max(list_trt, key=list_trt.count)\n                        trt = str(fault_trt)\n                        rake = np.mean(scenario_mechanism)\n                        if cut_sm_file == False:\n                            txt = wmfs.wrt_multifault_source(txt, MFD, self.Mmin, explo_time, rake, index_faults_in_sc)\n                        else:\n                            if not dict_n_rup[f] < max_rup_per_file:\n                                i = 0\n                                while dict_n_rup[f] > max_rup_per_file:\n                                    i += 1\n                                    f = list(dict_txt.keys())[i]\n                            txt = dict_txt[f]\n                            dict_txt[f] = wmfs.wrt_multifault_source(txt, MFD, self.Mmin, explo_time, rake, index_faults_in_sc)\n                            dict_n_rup[f] += 1\n        if cut_sm_file == False:\n            txt = wmfs.end_multifault_source(txt)\n            txt = wmfs.end(txt)\n            wmfs.build(source_xml, txt)\n        else:\n            for f in s_files:\n                if dict_n_rup[f] > 0:\n                    dict_txt[f] = wmfs.end_multifault_source(dict_txt[f])\n                    txt = wmfs.end(dict_txt[f])\n                    wmfs.build(f, txt)\n    else:\n        '\\n            ###########\\n            ############\\n            NOT USING MULTIFAULTSOURCE TYPOLOGY in OQ\\n\\n            '\n        line = \"<?xml version='1.0' encoding='utf-8'?>\\n\"\n        line += '<nrml xmlns:gml=\"http://www.opengis.net/gml\"\\n'\n        line += '\\txmlns=\"http://openquake.org/xmlns/nrml/0.5\">\\n'\n        line += '\\t<sourceModel name=\"Hazard Model\"'\n        line += ' investigation_time=\"' + str(round(explo_time, 1)) + '\">\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n        line = '\\t\\t<sourceGroup\\nname=\"group 1\"\\nrup_interdep=\"indep\"\\nsrc_interdep=\"indep\"\\ntectonicRegion=\"Active Shallow Crust\"\\n>\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n        log_general_parameters_file = open(self.pathlog + '/Log/general_parameters_sample_' + str(self.sample) + '.txt', 'w')\n        M_min = float(self.Mmin)\n        log_general_parameters_file.write('M_tronc\\t' + str(M_min) + '\\n')\n        log_general_parameters_file.write('b_value\\t' + str(self.b_value) + '\\n')\n        log_general_parameters_file.close()\n        faults_area = []\n        faults_length = []\n        faults_width = []\n        faults_slip_rates = []\n        faults_mecanism = []\n        faults_shear_mod = []\n        '########################################################\\n            # Random sampling of the fault slip-rate\\n            ########################################################'\n        print('Picking slip-rates...')\n        if self.sample == 1:\n            self.sr_correl = False\n        if self.sr_correl == True:\n            M_faults_correl = []\n            for Fault_name in faults_names:\n                M_faults_correl_i = []\n                sc_with_fault = []\n                for index_scenario in range(len(scenarios_names)):\n                    scenario_i = self.rupture_set[index_scenario]\n                    if Fault_name in scenario_i:\n                        sc_with_fault += scenario_i\n                for Fault_name_i in faults_names:\n                    nb_join_ruptures = 0\n                    if Fault_name == Fault_name_i:\n                        nb_join_ruptures = 0\n                    elif Fault_name_i in sc_with_fault:\n                        nb_join_ruptures = sc_with_fault.count(Fault_name_i)\n                    else:\n                        nb_join_ruptures = 0\n                    M_faults_correl_i.append(nb_join_ruptures)\n                M_faults_correl.append(M_faults_correl_i)\n            M_linked_lvl = np.zeros_like(M_faults_correl)\n            for lvl in [1, 2, 3, 4]:\n                for i in range(len(faults_names)):\n                    for j in range(len(faults_names)):\n                        if M_linked_lvl[i][j] == 0:\n                            if M_faults_correl[i][j] != 0:\n                                M_linked_lvl[i][j] = lvl\n                            else:\n                                for jj in range(len(M_faults_correl[j])):\n                                    if M_faults_correl[j][jj] != 0:\n                                        if M_linked_lvl[i][j] == 0:\n                                            M_linked_lvl[i][j] = lvl + 1\n            max_correl = np.max(M_faults_correl)\n            list_quater_picked = list(np.zeros(len(faults_names)))\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                sr_values = [faults_data[index_fault]['slip_rate_min'], faults_data[index_fault]['slip_rate_moy'], faults_data[index_fault]['slip_rate_max']]\n                slip_rate = select_sr.select(sr_values, self.sample, index_fault, M_linked_lvl[index_fault], list_quater_picked)\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        else:\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                slip_rate_min = faults_data[index_fault]['slip_rate_min']\n                slip_rate_moy = faults_data[index_fault]['slip_rate_moy']\n                slip_rate_max = faults_data[index_fault]['slip_rate_max']\n                if self.sample == 1:\n                    slip_rate = slip_rate_moy\n                else:\n                    slip_rate_inf = np.random.uniform(slip_rate_min, slip_rate_moy)\n                    slip_rate_sup = np.random.uniform(slip_rate_moy, slip_rate_max)\n                    slip_rate = np.random.choice([slip_rate_inf, slip_rate_sup])\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        print('\\t\\tslip-rates picked.')\n        ratio_test = 0.5\n        count_reruns = 1\n        count_mfd90 = 1\n        f_pkl_mdf = self.pathlog + '/mfd_' + str(self.sample) + '.pkl'\n        re_use_mfd_pkl = True\n        if not os.path.isfile(f_pkl_mdf):\n            re_use_mfd_pkl = False\n        if re_use_mfd_pkl == False:\n            while abs(ratio_test - 1) > self.fit_quality or math.isnan(ratio_test) == True:\n                MFDs = EQ_on_faults.EQ_on_faults_from_sr(M_min, mfd_param, faults_names, faults_area, faults_length, faults_width, faults_slip_rates, scenarios_names, faults_shear_mod, self.path, self.sample, self.selected_ScL, self.dimention_used, self.use_all_ScL_data, faults_mecanism, self.bg_ratio, self.size_of_increment, self.mfd_hyp, count_reruns, faults_lon, faults_lat, self.Mmax_range, self.calculation_log_file, self.branch, self.param)\n                ratio_test = MFDs.ratio_test\n                if abs(ratio_test - 1) > self.fit_quality:\n                    print('bad sampling => re-run')\n                    count_reruns += 1\n                    if MFDs.ratio_NMS > 90.0:\n                        count_reruns -= 1\n                        count_mfd90 += 1\n                    else:\n                        count_mfd90 = 1\n                elif MFDs.ratio_NMS > 90.0:\n                    ratio_test = 0.5\n                    print('bad sampling => re-run')\n                    count_mfd90 += 1\n                else:\n                    count_mfd90 = 1\n                if math.isnan(ratio_test) == True:\n                    print('bad sampling => re-run')\n                    count_reruns = 1\n                if count_reruns > 3 or count_mfd90 > 3:\n                    print('\\n\\n\\n!!!!!! maybe there is a problem!!!')\n                    ratio_test = 1.0\n            with open(f_pkl_mdf, 'wb') as f:\n                MFDs_to_pkl = [MFDs.EQ_rate_BG, MFDs.faults_names, MFDs.OQ_entry_faults, MFDs.scenarios_names, MFDs.OQ_entry_scenarios, MFDs.index_faults_in_scenario, MFDs.M_slip_repartition]\n                pickle.dump(MFDs_to_pkl, f)\n        else:\n            print('Reloading MFDs from previous run')\n            with open(f_pkl_mdf, 'rb') as f:\n                MFDs_to_pkl = pickle.load(f)\n        EQ_rate_BG = MFDs_to_pkl[0]\n        faults_names = MFDs_to_pkl[1]\n        OQ_entry_faults = MFDs_to_pkl[2]\n        scenarios_names = MFDs_to_pkl[3]\n        OQ_entry_scenarios = MFDs_to_pkl[4]\n        index_faults_in_scenario = MFDs_to_pkl[5]\n        M_slip_repartition = MFDs_to_pkl[6]\n        if self.selected_ScL == 'Le2010':\n            ScL_oq = 'Leonard2014_SCR'\n        elif self.selected_ScL == 'WC1994':\n            ScL_oq = 'WC1994'\n        else:\n            ScL_oq = 'WC1994'\n        (Lon_bg, Lat_bg) = bg.geom(self.Model_name, self.File_bg)\n        Poly_bg = []\n        for (x1, y1) in zip(Lon_bg, Lat_bg):\n            Poly_bg.append((x1, y1))\n        bbPath_BG = mplPath.Path(Poly_bg)\n        f_in_bg = []\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            for (lon, lat) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                if bbPath_BG.contains_point((lon, lat)):\n                    f_in_bg.append(index_fault)\n        outside_faults = []\n        if include_all_faults == True:\n            for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n                if not index_fault in f_in_bg:\n                    f_in_bg.append(index_fault)\n                    outside_faults.append(index_fault)\n        ID_number = 0\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            if index_fault in f_in_bg:\n                use_simple_faults = False\n                if use_simple_faults == True:\n                    (line, self.Domain_in_the_model, ID_number) = fault_source.write_simple_fault(index_fault, fault_name, OQ_entry_faults, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, M_min, ID_number)\n                else:\n                    (line, self.Domain_in_the_model, ID_number) = fault_source.write_non_parametric_one_fault(index_fault, fault_name, OQ_entry_faults, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, M_min, ID_number, explo_time)\n                if cut_sm_file == False:\n                    XMLfile.write(line)\n                else:\n                    i_w = 0\n                    while sf_counter[i_w] > 500:\n                        i_w += 1\n                    sf_files[i_w].write(line)\n                    sf_counter[i_w] += 1\n        if len(self.rupture_set) != 0:\n            for scenario in enumerate(scenarios_names):\n                sc_in = False\n                index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                for i in index_faults_in_scenario[index_scenario][0]:\n                    if i in f_in_bg:\n                        sc_in = True\n                if sc_in == True:\n                    use_non_param = True\n                    if use_non_param == False:\n                        (line, ID_number) = fault_source.write_characteristic_scenario(scenarios_names, OQ_entry_scenarios, index_faults_in_scenario, scenario, faults_names, self.Model_name, faults_data, log_mdf_file, M_min, ID_number)\n                    else:\n                        (line, ID_number) = fault_source.write_non_parametric_source(scenario, scenarios_names, OQ_entry_scenarios, index_faults_in_scenario, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, explo_time, M_min, ID_number)\n                    if cut_sm_file == False:\n                        XMLfile.write(line)\n                    else:\n                        i_w = 0\n                        while mf_counter[i_w] > 500:\n                            i_w += 1\n                        mf_files[i_w].write(line)\n                        mf_counter[i_w] += 1\n    '#########################\\n        # Defining the background seismicity\\n        #########################'\n    MFD = EQ_rate_BG\n    pts_list = {}\n    if sum(MFD) != 0.0 and self.param['main']['background']['option_bg'] == 'zone':\n        bg_file = self.path + '/bg_' + str(self.sample) + '.xml'\n        list_src_files.append(bg_file)\n        bg_file = open(bg_file, 'w')\n        line = \"<?xml version='1.0' encoding='utf-8'?>\\n\"\n        line += '<nrml xmlns:gml=\"http://www.opengis.net/gml\"\\n'\n        line += '\\txmlns=\"http://openquake.org/xmlns/nrml/0.5\">\\n'\n        line += '\\t<sourceModel name=\"Hazard Model\">\\n'\n        (upperSeismoDepth, lowerSeismoDepth, ruptAspectRatio, nodalPlanes, hypoDepths) = bg.prop(self.Model_name, self.file_prop_bg)\n        line += '\\t\\t<sourceGroup\\nname=\"group 2\"\\nrup_interdep=\"indep\"\\nsrc_interdep=\"indep\"\\ntectonicRegion=\"' + str(self.Domain_in_the_model[0]) + '\"\\n>\\n'\n        line += '\\t\\t<areaSource id=\"' + str(source_id + 1) + '\" name=\"Background\" tectonicRegion=\"' + str(self.Domain_in_the_model[0]) + '\">\\n'\n        line += '\\t\\t\\t<areaGeometry>\\n'\n        line += '\\t\\t\\t\\t<gml:Polygon>\\n'\n        line += '\\t\\t\\t\\t\\t<gml:exterior>\\n'\n        line += '\\t\\t\\t\\t\\t\\t<gml:LinearRing>\\n'\n        line += '\\t\\t\\t\\t\\t\\t\\t<gml:posList>\\n'\n        for (x, y) in zip(Lon_bg, Lat_bg):\n            line += '\\t\\t\\t\\t\\t\\t\\t\\t' + str(x) + ' ' + str(y) + '\\n'\n        line += '\\t\\t\\t\\t\\t\\t\\t</gml:posList>\\n'\n        line += '\\t\\t\\t\\t\\t\\t</gml:LinearRing>\\n'\n        line += '\\t\\t\\t\\t\\t</gml:exterior>\\n'\n        line += '\\t\\t\\t\\t</gml:Polygon>\\n'\n        line += '\\t\\t\\t\\t<upperSeismoDepth>' + str(upperSeismoDepth) + '</upperSeismoDepth>\\n'\n        line += '\\t\\t\\t\\t<lowerSeismoDepth>' + str(lowerSeismoDepth) + '</lowerSeismoDepth>\\n'\n        line += '\\t\\t\\t</areaGeometry>\\n'\n        line += '\\t\\t\\t<magScaleRel>' + ScL_oq + '</magScaleRel>\\n'\n        line += '\\t\\t\\t<ruptAspectRatio>' + str(ruptAspectRatio) + '</ruptAspectRatio>\\n'\n        log_mdf_file.write('Background' + '\\t' + str(M_min) + '\\t' + ' '.join(list(map(str, MFD))) + '\\n')\n        line += '\\t\\t\\t<incrementalMFD binWidth=\"0.10\" minMag=\"' + str(M_min) + '\">\\n'\n        line += '\\t\\t\\t<occurRates> ' + ' '.join(list(map(str, MFD))) + '</occurRates>\\n'\n        line += '\\t\\t\\t</incrementalMFD>\\n'\n        line += '\\t\\t\\t<nodalPlaneDist>\\n'\n        for i in range(len(nodalPlanes)):\n            line += '\\t\\t\\t\\t<nodalPlane probability=\"' + str(nodalPlanes[i][0]) + '\" strike=\"' + str(nodalPlanes[i][1]) + '\" dip=\"' + str(nodalPlanes[i][2]) + '\" rake=\"' + str(nodalPlanes[i][3]) + '\" />\\n'\n        line += '\\t\\t\\t</nodalPlaneDist>\\n'\n        line += '\\t\\t\\t<hypoDepthDist>\\n'\n        for i in range(len(hypoDepths)):\n            line += '\\t\\t\\t\\t<hypoDepth probability=\"' + str(hypoDepths[i][0]) + '\" depth=\"' + str(hypoDepths[i][1]) + '\" />\\n'\n        line += '\\t\\t\\t</hypoDepthDist>\\n'\n        line += '\\t\\t</areaSource>\\n'\n        line += '\\t</sourceGroup>\\n'\n        line += '\\t</sourceModel>\\n'\n        line += '</nrml>\\n'\n        bg_file.write(line)\n        bg_file.close()\n    elif sum(MFD) != 0.0 and self.param['main']['background']['option_bg'] == 'smooth':\n        Mmin_checked = False\n        Mmax = M_min + len(EQ_rate_BG) * 0.1 - 1\n        mags = np.linspace(M_min, Mmax, len(EQ_rate_BG))\n        list_bg_xml = self.list_fbg\n        if os.path.isdir(self.fbgpath):\n            list_bg_xml = [self.fbgpath + '/' + i for i in list_bg_xml if '.xml' in i]\n        with open(list_bg_xml[0]) as myfile:\n            if 'multiPointSource' in myfile.read():\n                multiPointSource_type = True\n            else:\n                multiPointSource_type = False\n        if multiPointSource_type == True:\n            bg.get_multipoints(EQ_rate_BG, M_min, bbPath_BG, list_bg_xml, include_all_faults, outside_faults, faults_data, OQ_entry_faults, self.path, self.pathlog, list_src_files)\n        else:\n            pts_list = {}\n            pts_out_list = {}\n            sum_rates = [0.0 for _ in mags]\n            for fbg in list_bg_xml:\n                tree = ET.parse(fbg)\n                ET.register_namespace('', 'http://openquake.org/xmlns/nrml/0.5')\n                nrml = tree.getroot()\n                i_point = 0\n                for pointSource in nrml[0][0]:\n                    pt_in_BG = False\n                    i_child = 0\n                    for child in pointSource.getchildren():\n                        if 'pointGeometry' in str(child):\n                            s_tmp = pointSource[i_child][0][0].text\n                            s_tmp = s_tmp.replace('\\n', '')\n                            s_tmp = [float(i) for i in s_tmp.split(' ') if i != '']\n                            if bbPath_BG.contains_point((s_tmp[0], s_tmp[1])) == 1:\n                                pt_in_BG = True\n                            str_loc = str(s_tmp[0]) + '_' + str(s_tmp[1])\n                        if 'truncGutenbergRichterMFD' in str(child):\n                            aValue = nrml[0][0][i_point][i_child].get('aValue')\n                            minMag = nrml[0][0][i_point][i_child].get('minMag')\n                            i_trGR = i_child\n                        i_child += 1\n                    aValue = nrml[0][0][i_point][i_trGR].get('aValue')\n                    minMag = nrml[0][0][i_point][i_trGR].get('minMag')\n                    bValue = nrml[0][0][i_point][i_trGR].get('bValue')\n                    maxMag = nrml[0][0][i_point][i_trGR].get('maxMag')\n                    mfd_smooth = []\n                    i_mag = 0\n                    for mag in mags:\n                        mag_lo = mag - 0.05\n                        mag_hi = mag + 0.05\n                        r = 10 ** (float(aValue) - float(bValue) * mag_lo) - 10 ** (float(aValue) - float(bValue) * mag_hi)\n                        sum_rates[i_mag] += r\n                        i_mag += 1\n                        mfd_smooth.append(r)\n                    if pt_in_BG == True:\n                        pts_list.update({str_loc: {'aValue': aValue, 'bValue': bValue, 'maxMag': maxMag, 'minMag': minMag, 'mfd_smooth': mfd_smooth}})\n                        if Mmin_checked == False:\n                            if float(minMag) < M_min:\n                                print('!!!!')\n                                print('WARNING : BG has a smaller Mmin than the SHERIFS input')\n                                print('!!!!')\n                                Mmin_checked = True\n                    elif include_all_faults == True:\n                        pt_very_far = True\n                        lon_lat_distance_criteria = 1.0\n                        i = 0\n                        while pt_very_far == False and i < len(outside_faults):\n                            i_fault = outside_faults[i]\n                            mean_lon = np.mean(faults_data[index_fault]['lon'])\n                            mean_lat = np.mean(faults_data[index_fault]['lat'])\n                            if abs(float(s_tmp[0]) - mean_lon) < lon_lat_distance_criteria:\n                                pt_very_far = False\n                            if abs(float(s_tmp[1]) - mean_lat) < lon_lat_distance_criteria:\n                                pt_very_far = False\n                            i += 1\n                        if pt_very_far == False:\n                            dist_critera = 50.0\n                            dist = 1000000.0\n                            closest_fault = 'nope'\n                            for i_fault in outside_faults:\n                                mean_lon = np.mean(faults_data[index_fault]['lon'])\n                                mean_lat = np.mean(faults_data[index_fault]['lat'])\n                                dist_i = distance(mean_lon, mean_lat, float(s_tmp[0]), float(s_tmp[1]))\n                                if dist_i < dist_critera:\n                                    for (lon_f, lat_f) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                                        dist_i = distance(mean_lon, mean_lat, float(s_tmp[0]), float(s_tmp[1]))\n                                        if dist_i < dist:\n                                            dist = dist_i\n                                            closest_fault = i_fault\n                                if dist_i < dist:\n                                    dist = dist_i\n                                    closest_fault = i_fault\n                            closest_dist = dist\n                            pts_out_list.update({str_loc: {'aValue': aValue, 'bValue': bValue, 'maxMag': maxMag, 'minMag': minMag, 'mfd_smooth': mfd_smooth, 'distance': closest_dist, 'closest_fault': i_fault}})\n                    i_point += 1\n            nb_pt_in_buff = {}\n            if include_all_faults == True:\n                for i_fault in outside_faults:\n                    buffer_1 = 10.0\n                    buffer_2 = 20.0\n                    nb_buf1 = 0\n                    nb_buf2 = 0\n                    for str_loc in pts_out_list.keys():\n                        if pts_out_list[str_loc]['closest_fault'] == i_fault:\n                            if pts_out_list[str_loc]['closest_dist'] < buffer_1:\n                                nb_buf1 += 1\n                            elif pts_out_list[str_loc]['closest_dist'] < buffer_2:\n                                nb_buf2 += 1\n                    nb_pt_in_buff.update({i_fault: {'nb_buf1': nb_buf1, 'nb_buf2': nb_buf2}})\n            sum_bg_min = 0.0\n            i_bg = 0\n            for fbg in list_bg_xml:\n                tree = ET.parse(fbg)\n                ET.register_namespace('', 'http://openquake.org/xmlns/nrml/0.5')\n                nrml = tree.getroot()\n                i_point = 0\n                for pointSource in nrml[0][0]:\n                    pt_in_BG = False\n                    i_child = 0\n                    for child in pointSource.getchildren():\n                        if 'magScaleRel' in str(child):\n                            nrml[0][0][i_point][i_child].text = ScL_oq\n                        if 'pointGeometry' in str(child):\n                            s_tmp = pointSource[i_child][0][0].text\n                            s_tmp = s_tmp.replace('\\n', '')\n                            s_tmp = [float(i) for i in s_tmp.split(' ') if i != '']\n                            str_loc = str(s_tmp[0]) + '_' + str(s_tmp[1])\n                        if 'truncGutenbergRichterMFD' in str(child):\n                            i_trGR = i_child\n                        i_child += 1\n                    if str_loc in pts_list.keys():\n                        b_value = float(pts_list[str_loc]['bValue'])\n                        a_value = float(pts_list[str_loc]['aValue'])\n                        attrib = {'minMag': str(M_min), 'binWidth': '0.10'}\n                        element = nrml[0][0][i_point].makeelement('incrementalMFD', attrib)\n                        nrml[0][0][i_point].append(element)\n                        element = nrml[0][0][i_point][-1].makeelement('occurRates', {})\n                        nrml[0][0][i_point][-1].append(element)\n                        str_tmp = ' '\n                        pt_scl_mfd = []\n                        i_mag = 0\n                        for mag in mags:\n                            mag_lo = mag - 0.05\n                            mag_hi = mag + 0.05\n                            r = 10 ** (a_value - b_value * mag_lo) - 10 ** (a_value - b_value * mag_hi)\n                            norm_r = r / sum_rates[i_mag]\n                            str_tmp += str(EQ_rate_BG[i_mag] * norm_r)\n                            str_tmp += ' '\n                            sum_bg_min += EQ_rate_BG[i_mag] * norm_r\n                            pt_scl_mfd.append(EQ_rate_BG[i_mag] * norm_r)\n                            i_mag += 1\n                        pts_list[str_loc].update({'scaled_mfd': pt_scl_mfd})\n                        nrml[0][0][i_point][-1][0].text = str_tmp\n                        nrml[0][0][i_point].remove(nrml[0][0][i_point][i_trGR])\n                    if include_all_faults == True:\n                        if str_loc in pts_out_list.keys():\n                            b_value = float(pts_list[str_loc]['bValue'])\n                            a_value = float(pts_list[str_loc]['aValue'])\n                            attrib = {'minMag': str(M_min), 'binWidth': '0.10'}\n                            element = nrml[0][0][i_point].makeelement('incrementalMFD', attrib)\n                            nrml[0][0][i_point].append(element)\n                            element = nrml[0][0][i_point][-1].makeelement('occurRates', {})\n                            nrml[0][0][i_point][-1].append(element)\n                            str_tmp = ' '\n                            pt_scl_mfd = []\n                            i_fault = pts_out_list[str_loc]['closest_fault']\n                            mfd_single_clst_f = OQ_entry_faults[i_fault]\n                            id_ruptures = []\n                            mfd_mlt_clst_f = []\n                            for (scenario_i, mfd_i) in zip(index_faults_in_scenario, OQ_entry_scenarios):\n                                if i_fault in scenario_i:\n                                    id_ruptures.append(scenario_i)\n                                    mfd_mlt_clst_f.append(mfd_i)\n                            i_mag = 0\n                            for mag in mags:\n                                mag_lo = mag - 0.05\n                                mag_hi = mag + 0.05\n                                r = 10 ** (a_value - b_value * mag_lo) - 10 ** (a_value - b_value * mag_hi)\n                                if mag >= 6.5:\n                                    buffer_to_use = 'nb_buf2'\n                                else:\n                                    buffer_to_use = 'nb_buf1'\n                                reduction = 0.0\n                                for (f_in_rup, mfd_i) in zip(id_ruptures, mfd_mlt_clst_f):\n                                    reduction += mfd_i[i_mag] / float(len(f_in_rup) * nb_pt_in_buff[i_fault][buffer_to_use])\n                                if reduction > r:\n                                    r = 0.0\n                                else:\n                                    r -= reduction\n                                str_tmp += str(r)\n                                str_tmp += ' '\n                                pt_scl_mfd.append(r)\n                                i_mag += 1\n                            pts_out_list[str_loc].update({'scaled_mfd': pt_scl_mfd})\n                            nrml[0][0][i_point][-1][0].text = str_tmp\n                            nrml[0][0][i_point].remove(nrml[0][0][i_point][i_trGR])\n                    i_point += 1\n                i_bg += 1\n                fbg_out = self.path + '/bg_' + str(self.sample) + '_' + str(i_bg) + '.xml'\n                tree.write(fbg_out)\n                list_src_files.append(fbg_out)\n    '#############################\\n        ### defining the other sources based on the host model\\n        ##############################'\n    if self.param['main']['background']['use_host_model'] == True and cut_sm_file == False:\n        host_model.build(XMLfile, self.host_model_file, Lon_bg, Lat_bg)\n    if self.param['main']['background']['use_host_model'] == True and cut_sm_file == True:\n        print(\"WARNING : can't use host model and cut files yet !\")\n    if use_multiF == False:\n        line = '\\t\\t\\t</sourceGroup>\\n'\n        line += '\\t</sourceModel>\\n'\n        line += '</nrml>\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n            XMLfile.close()\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n                f.close()\n    log_sr_file.close()\n    log_mdf_file.close()\n    self.list_src_files = list_src_files\n    '#############################\\n        ### Get the particiaption rates of sections\\n        ##############################'\n    import participation_rates as p_rates\n    from section_info import get_nonzero_Mmax\n    (dict_p_rates, mfd_total, all_non_zero_rups) = p_rates.get_all_participation_rates(MFDs_to_pkl, self.param, faults_names)\n    bin_mag = p_rates.get_bin_mag(mfd_total, self.Mmin)\n    all_participation_rates = []\n    sections_Mmax = []\n    if not os.path.isdir(self.pathlog + '/participation_rates'):\n        os.makedirs(self.pathlog + '/participation_rates')\n    for fault_name in faults_names:\n        (incremental_rate, cumulative_rate) = p_rates.extract_rates(fault_name, dict_p_rates)\n        all_participation_rates.append(cumulative_rate)\n        ptf = self.pathlog + '/participation_rates/' + str(fault_name) + '.png'\n        p_rates.plot_participation_rates(bin_mag, incremental_rate, cumulative_rate, fault_name, ptf)\n        Mmax = get_nonzero_Mmax(bin_mag, cumulative_rate)\n        sections_Mmax.append(Mmax)\n    '#############################\\n        ### Exporting the results in a Geojson\\n        ##############################'\n    features = []\n    for si in f_in_bg:\n        sections = []\n        geom = []\n        for (lon_i, lat_i) in zip(faults_data[si]['lon'], faults_data[si]['lat']):\n            geom.append((lon_i, lat_i))\n        geom = LineString(list(geom))\n        properties = {}\n        for key in faults_data[si].keys():\n            if not key in ['lat', 'lon']:\n                properties.update({key: faults_data[si][key]})\n        NMS = float(M_slip_repartition[faults_data[si]['name']]['NMS'])\n        sumdsr = 0.0\n        for key in M_slip_repartition[faults_data[si]['name']].keys():\n            sumdsr += M_slip_repartition[faults_data[si]['name']][key]\n        properties.update({'NMS': NMS / float(sumdsr)})\n        properties.update({'nb_rup': float(all_non_zero_rups[si])})\n        properties.update({'Mmax': float(sections_Mmax[si])})\n        properties.update({'participation_rates': [bin_mag, all_participation_rates[si]]})\n        nms_i = NMS / float(sumdsr)\n        mmax_i = sections_Mmax[si]\n        if mmax_i >= max(sections_Mmax) - 0.3:\n            if nms_i < 0.1:\n                indicator = 1.0 - nms_i\n            else:\n                indicator = 0.0\n        elif mmax_i >= max(sections_Mmax) - 0.5:\n            if nms_i < 0.05:\n                indicator = 1.0 - nms_i\n            else:\n                indicator = 0.0\n        else:\n            indicator = 0.0\n        properties.update({'might_to_be_limiting': round(indicator, 2)})\n        features.append(Feature(geometry=geom, properties=properties))\n    feature_collection = FeatureCollection(features)\n    with open(self.pathlog + '/out_sections.geojson', 'w') as f:\n        dump(feature_collection, f)\n    '#######################\\n        ### some figures\\n        ######################'\n    if 'figures' in self.param.keys():\n        if self.param['figures']['print'] in ['true', 'True']:\n            make_figures = True\n        else:\n            make_figures = False\n    else:\n        make_figures = False\n    plt_model_mfd = False\n    if make_figures == True:\n        if self.param['figures']['model_mfd'] in ['true', 'True']:\n            plt_model_mfd = True\n    if 'mfd_cat' in self.param['figures'].keys():\n        data = self.param['figures']['mfd_cat']\n    else:\n        data = False\n    if plt_model_mfd == True:\n        x = MFDs.bin_mag\n        y = rates.get_rate_model(MFDs.rup_rates, MFDs.fault_prop, x)\n        lim = [[x[0] - 0.05, x[-1] + 0.05], [min(y) / 2.0, max(y) * 2.0]]\n        axis = ['magnitude', 'annual earthquake rates']\n        path = self.pathlog + '/modelMFD.png'\n        title = 'MFD of the whole system'\n        plt_mfd.plot(x, y, lim, axis, data, path, title)\n    if plt_model_mfd == True:\n        x = MFDs.bin_mag\n        (ft, bgmfd) = rates.get_rate_faults_n_bg(MFDs.rup_rates, MFDs.fault_prop, x)\n        ys = [rates.get_rate_model(MFDs.rup_rates, MFDs.fault_prop, x), ft, bgmfd]\n        lim = [[x[0] - 0.05, x[-1] + 0.05], [min(ys[0]) / 2.0, max(ys[0]) * 2.0]]\n        axis = ['magnitude', 'annual earthquake rates']\n        path = self.pathlog + '/modelMFD_bg_ft.png'\n        title = 'MFD of the whole system, faults, background'\n        plt_mfd.plot_bg_ft(x, ys, lim, axis, path, title)\n    ' mfd in a more local scale '\n    part_mfd = False\n    if make_figures == True:\n        if 'part_mfd' in self.param['figures'].keys():\n            if self.param['figures']['part_mfd'] in ['true', 'True']:\n                part_mfd = True\n    if part_mfd == True:\n        loc_cat = local_cat.read_geojson(self.param['figures']['parts_gjson'])\n        for zone in loc_cat.keys():\n            polypt = loc_cat[zone]['poly']\n            lons = []\n            lats = []\n            for pt in polypt[0][0]:\n                lons.append(pt[0])\n                lats.append(pt[1])\n            poly = []\n            for (x1, y1) in zip(lons, lats):\n                poly.append((x1, y1))\n            area_zone = geometry_tools.PolyArea(lons, lats)\n            area_bg = geometry_tools.PolyArea(Lon_bg, Lat_bg)\n            ratio_area = float(area_zone) / float(area_bg)\n            local_zone_mfd = [i * ratio_area for i in EQ_rate_BG]\n            poly = mplPath.Path(poly)\n            (txt_no_bg, rate_faults, rate_bg, smooth) = local_cat.get_model_rate(poly, OQ_entry_faults, OQ_entry_scenarios, pts_list, MFDs.bin_mag, self.param, faults_data, faults_names, index_faults_in_scenario, local_zone_mfd)\n            x = MFDs.bin_mag\n            rate_model = [i + j for (i, j) in zip(rate_faults, rate_bg)]\n            lim = [[x[0] - 0.05, x[-1] + 0.05], [min(rate_model) / 2.0, max(rate_model) * 2.0]]\n            axis = ['magnitude', 'annual earthquake rates']\n            title = 'MFD in zone ' + str(zone) + txt_no_bg\n            path = self.pathlog + '/MFD_zone' + str(zone) + '.png'\n            if 'cat_rates' in loc_cat[zone].keys():\n                data = loc_cat[zone]['cat_rates']\n            else:\n                data = False\n            if data == None:\n                data = False\n            if data == True:\n                if len(data[0]) == 0:\n                    data = False\n                if len(data[0]) != len(data[1]):\n                    data = False\n                    print('For zone', zone, ' : wrong bining')\n                    print('please check the geojson file')\n            plt_mfd.local(x, [rate_model, rate_faults, rate_bg, smooth], data, lim, axis, path, title)",
            "def initialize(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    path = self.param['dirpath']\n    explo_time = self.param['main']['parameters']['explo_time']\n    if self.param['main']['parameters']['use_multiF'] in ['True', 'true']:\n        use_multiF = True\n    else:\n        use_multiF == False\n    max_rup_per_file = 2000\n    faults_names = self.faults_names\n    scenarios_names = self.scenarios_names\n    faults_data = self.faults_data\n    (faults_lon, faults_lat) = (self.faults_lon, self.faults_lat)\n    list_src_files = []\n    log_sr_file = open(self.pathlog + '/slip_rate_sample_' + str(self.sample) + '.txt', 'w')\n    log_mdf_file = open(self.pathlog + '/mdf_sample_' + str(self.sample) + '.txt', 'w')\n    cut_sm_file = False\n    if len(faults_names) + len(scenarios_names) > max_rup_per_file:\n        cut_sm_file = True\n    if cut_sm_file == False:\n        XMLfile = open(self.path + '/Source_model_' + str(self.sample) + '.xml', 'w')\n    else:\n        n_cut_sf = 1\n        while len(faults_names) / n_cut_sf > max_rup_per_file:\n            n_cut_sf += 1\n        n_cut_mf = 1\n        while len(scenarios_names) / n_cut_mf > max_rup_per_file:\n            n_cut_mf += 1\n        if use_multiF == False:\n            ' create the file list'\n            (sf_files, sf_counter) = ([], [])\n            for i in range(n_cut_sf):\n                f = self.path + '/sm_' + str(self.sample) + '_sf_' + str(i + 1) + '.xml'\n                sf_files.append(open(f, 'w'))\n                sf_counter.append(0)\n                list_src_files.append(f)\n            (mf_files, mf_counter) = ([], [])\n            for i in range(n_cut_mf):\n                f = self.path + '/sm_' + str(self.sample) + '_mf_' + str(i + 1) + '.xml'\n                mf_files.append(open(f, 'w'))\n                mf_counter.append(0)\n                list_src_files.append(f)\n        if use_multiF == True:\n            n_cut_f = n_cut_sf + n_cut_mf\n            s_files = []\n            for i in range(n_cut_mf):\n                f = self.path + '/sm_' + str(i) + '.xml'\n                s_files.append(f)\n                list_src_files.append(f)\n            (dict_txt, dict_n_rup) = ({}, {})\n            for f in s_files:\n                dict_txt.update({f: ''})\n                dict_n_rup.update({f: 0})\n    include_all_faults = False\n    if 'include_all_faults' in self.param['main']['background'].keys():\n        if self.param['main']['background']['include_all_faults'] in ['True', 'true']:\n            include_all_faults = True\n    if use_multiF == True:\n        '\\n            #######################################\\n            #######################################\\n            USING MULTIFAULT TYPOLOGY IN OQ\\n            #######################################\\n            #######################################\\n            '\n        simplify_faults = self.param['main']['parameters']['simplify_faults']\n        if simplify_faults in ['True', 'true']:\n            resample = [False]\n        elif not 'resample' in self.param['main']['parameters'].keys():\n            resample = [False]\n        else:\n            rsp = self.param['main']['parameters']['resample']\n            if rsp[0] in ['True', 'true']:\n                resample = [True]\n                resample.append(float(rsp[1]))\n                resample.append(float(rsp[2]))\n                resample.append(float(rsp[3]))\n            else:\n                resample = [False]\n        if 'vertical_faults' in self.param['main']['parameters'].keys():\n            vertical_faults = self.param['main']['parameters']['vertical_faults']\n            if vertical_faults in ['True', 'true']:\n                vertical_faults = True\n            else:\n                vertical_faults = False\n        else:\n            vertical_faults = False\n        sections_xml = path + self.Run_Name + '/ssm/' + self.Model_name + '_sections.xml'\n        if not os.path.exists(sections_xml):\n            txt = wsf.start(self.Model_name)\n            for section_id in range(len(faults_names)):\n                geotype = 'kite'\n                txt = wsf.wrt_section(txt, section_id, faults_names, faults_data, geotype, resample, vertical_faults)\n            txt = wsf.end(txt)\n            wsf.build(sections_xml, txt)\n        log_general_parameters_file = open(self.pathlog + '/general_parameters_sample_' + str(self.sample) + '.txt', 'w')\n        M_min = float(self.Mmin)\n        log_general_parameters_file.write('M_tronc\\t' + str(M_min) + '\\n')\n        mfd_param = self.mfd_param\n        log_general_parameters_file.write('b_value\\t' + str(mfd_param['b_value']) + '\\n')\n        log_general_parameters_file.close()\n        faults_area = []\n        faults_length = []\n        faults_width = []\n        faults_slip_rates = []\n        faults_mecanism = []\n        faults_shear_mod = []\n        '########################################################\\n            # Random sampling of the fault slip-rate\\n            ########################################################'\n        print('Picking slip-rates...')\n        if self.sample == 1:\n            self.sr_correl = False\n        if self.sr_correl == True:\n            M_faults_correl = []\n            for Fault_name in faults_names:\n                M_faults_correl_i = []\n                sc_with_fault = []\n                for index_scenario in range(len(scenarios_names)):\n                    scenario_i = self.rupture_set[index_scenario]\n                    if Fault_name in scenario_i:\n                        sc_with_fault += scenario_i\n                for Fault_name_i in faults_names:\n                    nb_join_ruptures = 0\n                    if Fault_name == Fault_name_i:\n                        nb_join_ruptures = 0\n                    elif Fault_name_i in sc_with_fault:\n                        nb_join_ruptures = sc_with_fault.count(Fault_name_i)\n                    else:\n                        nb_join_ruptures = 0\n                    M_faults_correl_i.append(nb_join_ruptures)\n                M_faults_correl.append(M_faults_correl_i)\n            M_linked_lvl = np.zeros_like(M_faults_correl)\n            for lvl in [1, 2, 3, 4]:\n                for i in range(len(faults_names)):\n                    for j in range(len(faults_names)):\n                        if M_linked_lvl[i][j] == 0:\n                            if M_faults_correl[i][j] != 0:\n                                M_linked_lvl[i][j] = lvl\n                            else:\n                                for jj in range(len(M_faults_correl[j])):\n                                    if M_faults_correl[j][jj] != 0:\n                                        if M_linked_lvl[i][j] == 0:\n                                            M_linked_lvl[i][j] = lvl + 1\n            max_correl = np.max(M_faults_correl)\n            list_quater_picked = list(np.zeros(len(faults_names)))\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                sr_values = [faults_data[index_fault]['slip_rate_min'], faults_data[index_fault]['slip_rate_moy'], faults_data[index_fault]['slip_rate_max']]\n                slip_rate = select_sr.select(sr_values, self.sample, index_fault, M_linked_lvl[index_fault], list_quater_picked)\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        else:\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                slip_rate_min = faults_data[index_fault]['slip_rate_min']\n                slip_rate_moy = faults_data[index_fault]['slip_rate_moy']\n                slip_rate_max = faults_data[index_fault]['slip_rate_max']\n                if self.sample == 1:\n                    slip_rate = slip_rate_moy\n                else:\n                    slip_rate_inf = np.random.uniform(slip_rate_min, slip_rate_moy)\n                    slip_rate_sup = np.random.uniform(slip_rate_moy, slip_rate_max)\n                    slip_rate = np.random.choice([slip_rate_inf, slip_rate_sup])\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        print('\\t\\tslip-rates picked.')\n        ratio_test = 0.5\n        count_reruns = 1\n        count_mfd90 = 1\n        f_pkl_mdf = self.pathlog + '/mfd_' + str(self.sample) + '.pkl'\n        re_use_mfd_pkl = True\n        if not os.path.isfile(f_pkl_mdf):\n            re_use_mfd_pkl = False\n        if self.param['main']['parameters']['force_rerun'] == True:\n            re_use_mfd_pkl = False\n        if re_use_mfd_pkl == False:\n            while abs(ratio_test - 1) > self.fit_quality or math.isnan(ratio_test) == True:\n                MFDs = EQ_on_faults.EQ_on_faults_from_sr(self.Run_Name, M_min, mfd_param, faults_names, faults_area, faults_length, faults_width, faults_slip_rates, scenarios_names, faults_shear_mod, self.path, self.pathlog, self.sample, self.selected_ScL, self.dimention_used, self.use_all_ScL_data, faults_mecanism, self.bg_ratio, self.size_of_increment, self.mfd_hyp, count_reruns, faults_lon, faults_lat, self.Mmax_range, self.calculation_log_file, self.branch, self.param)\n                ratio_test = MFDs.ratio_test\n                if abs(ratio_test - 1) > self.fit_quality:\n                    print('bad sampling => re-run')\n                    count_reruns += 1\n                    if MFDs.ratio_NMS > 90.0:\n                        count_reruns -= 1\n                        count_mfd90 += 1\n                    else:\n                        count_mfd90 = 1\n                elif MFDs.ratio_NMS > 90.0:\n                    ratio_test = 0.5\n                    print('bad sampling => re-run')\n                    count_mfd90 += 1\n                else:\n                    count_mfd90 = 1\n                if math.isnan(ratio_test) == True:\n                    print('bad sampling => re-run')\n                    count_reruns = 1\n                if count_reruns > 3 or count_mfd90 > 3:\n                    print('\\n\\n\\n!!!!!! maybe there is a problem!!!')\n                    ratio_test = 1.0\n            with open(f_pkl_mdf, 'wb') as f:\n                MFDs_to_pkl = [MFDs.EQ_rate_BG, MFDs.faults_names, MFDs.OQ_entry_faults, MFDs.scenarios_names, MFDs.OQ_entry_scenarios, MFDs.index_faults_in_scenario, MFDs.M_slip_repartition]\n                pickle.dump(MFDs_to_pkl, f)\n        else:\n            print('Reloading MFDs from previous run')\n            with open(f_pkl_mdf, 'rb') as f:\n                MFDs_to_pkl = pickle.load(f)\n        EQ_rate_BG = MFDs_to_pkl[0]\n        faults_names = MFDs_to_pkl[1]\n        OQ_entry_faults = MFDs_to_pkl[2]\n        scenarios_names = MFDs_to_pkl[3]\n        OQ_entry_scenarios = MFDs_to_pkl[4]\n        index_faults_in_scenario = MFDs_to_pkl[5]\n        M_slip_repartition = MFDs_to_pkl[6]\n        if self.selected_ScL == 'Le2010':\n            ScL_oq = 'Leonard2014_SCR'\n        if self.selected_ScL == 'WC1994':\n            ScL_oq = 'WC1994'\n        else:\n            ScL_oq = 'WC1994'\n        (Lon_bg, Lat_bg) = bg.geom(self.Model_name, self.File_bg)\n        Poly_bg = []\n        for (x1, y1) in zip(Lon_bg, Lat_bg):\n            Poly_bg.append((x1, y1))\n        try:\n            bbPath_BG = mplPath.Path(Poly_bg)\n        except:\n            print('ERROR, please make sure the model name matches in the bg file')\n        f_in_bg = []\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            for (lon, lat) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                if bbPath_BG.contains_point((lon, lat)):\n                    f_in_bg.append(index_fault)\n        outside_faults = []\n        if include_all_faults == True:\n            for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n                if not index_fault in f_in_bg:\n                    f_in_bg.append(index_fault)\n                    outside_faults.append(index_fault)\n        source_id = 0\n        if cut_sm_file == False:\n            source_xml = self.path + '/Source_model_' + str(self.sample) + '.xml'\n            list_src_files.append(source_xml)\n            trt = faults_data[0]['domain']\n            txt = wmfs.start(explo_time, trt)\n            name = 'multifaultsource'\n            txt = wmfs.start_multifault_source(txt, name, trt, sections_xml, source_id)\n        else:\n            for f in s_files:\n                trt = faults_data[0]['domain']\n                dict_txt[f] = wmfs.start(explo_time, trt)\n                name = 'multifaultsource_' + str(source_id)\n                dict_txt[f] = wmfs.start_multifault_source(dict_txt[f], name, trt, sections_xml, source_id)\n                source_id += 1\n            f = list(dict_txt.keys())[0]\n        single_f_xml = self.path + '/single_sec_rup.xml'\n        trt = faults_data[0]['domain']\n        single_txt = wss.start(self.Model_name, trt)\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            if index_fault in f_in_bg:\n                i_MFD = np.where(np.array(faults_names) == fault_name)[0][0]\n                MFD = OQ_entry_faults[i_MFD]\n                if sum(MFD) != 0:\n                    source_id = source_id + 1\n                    Fault_Name = self.Model_name + '_' + str(fault_name)\n                    fault_trt = faults_data[index_fault]['domain']\n                    if not fault_trt in str(self.Domain_in_the_model):\n                        self.Domain_in_the_model.append(fault_trt)\n                    trt = str(fault_trt)\n                    rake = faults_data[index_fault]['rake']\n                    geotype = 'kite'\n                    name = 'single_fault_' + fault_name\n                    single_txt = wss.wrt_source(single_txt, index_fault, faults_names, faults_data, geotype, resample, vertical_faults, fault_trt, M_min, MFD, ScL_oq)\n        single_txt = wss.end(single_txt)\n        wss.build(single_f_xml, single_txt)\n        if len(self.rupture_set) != 0:\n            for scenario in enumerate(scenarios_names):\n                sc_in = False\n                index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                index_faults_in_sc = index_faults_in_scenario[index_scenario][0]\n                for i in index_faults_in_sc:\n                    if i in f_in_bg:\n                        sc_in = True\n                if sc_in == True:\n                    index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                    MFD = OQ_entry_scenarios[index_scenario]\n                    if sum(MFD) != 0:\n                        faults_in_scenario = np.take(faults_names, index_faults_in_sc)\n                        source_id = source_id + 1\n                        scenar_name = '_'.join(('{!s}={!r}'.format(key, val) for (key, val) in scenario[1].items()))\n                        source_name = self.Model_name + '_scenario_'\n                        source_name += str(scenar_name)\n                        list_trt = []\n                        scenario_mechanism = []\n                        for fname in faults_in_scenario:\n                            i = faults_names.index(fname)\n                            scenario_mechanism.append(faults_data[i]['rake'])\n                            fault_trt = faults_data[i]['domain']\n                            list_trt.append(fault_trt)\n                            if not fault_trt in str(self.Domain_in_the_model):\n                                self.Domain_in_the_model.append(fault_trt)\n                        fault_trt = max(list_trt, key=list_trt.count)\n                        trt = str(fault_trt)\n                        rake = np.mean(scenario_mechanism)\n                        if cut_sm_file == False:\n                            txt = wmfs.wrt_multifault_source(txt, MFD, self.Mmin, explo_time, rake, index_faults_in_sc)\n                        else:\n                            if not dict_n_rup[f] < max_rup_per_file:\n                                i = 0\n                                while dict_n_rup[f] > max_rup_per_file:\n                                    i += 1\n                                    f = list(dict_txt.keys())[i]\n                            txt = dict_txt[f]\n                            dict_txt[f] = wmfs.wrt_multifault_source(txt, MFD, self.Mmin, explo_time, rake, index_faults_in_sc)\n                            dict_n_rup[f] += 1\n        if cut_sm_file == False:\n            txt = wmfs.end_multifault_source(txt)\n            txt = wmfs.end(txt)\n            wmfs.build(source_xml, txt)\n        else:\n            for f in s_files:\n                if dict_n_rup[f] > 0:\n                    dict_txt[f] = wmfs.end_multifault_source(dict_txt[f])\n                    txt = wmfs.end(dict_txt[f])\n                    wmfs.build(f, txt)\n    else:\n        '\\n            ###########\\n            ############\\n            NOT USING MULTIFAULTSOURCE TYPOLOGY in OQ\\n\\n            '\n        line = \"<?xml version='1.0' encoding='utf-8'?>\\n\"\n        line += '<nrml xmlns:gml=\"http://www.opengis.net/gml\"\\n'\n        line += '\\txmlns=\"http://openquake.org/xmlns/nrml/0.5\">\\n'\n        line += '\\t<sourceModel name=\"Hazard Model\"'\n        line += ' investigation_time=\"' + str(round(explo_time, 1)) + '\">\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n        line = '\\t\\t<sourceGroup\\nname=\"group 1\"\\nrup_interdep=\"indep\"\\nsrc_interdep=\"indep\"\\ntectonicRegion=\"Active Shallow Crust\"\\n>\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n        log_general_parameters_file = open(self.pathlog + '/Log/general_parameters_sample_' + str(self.sample) + '.txt', 'w')\n        M_min = float(self.Mmin)\n        log_general_parameters_file.write('M_tronc\\t' + str(M_min) + '\\n')\n        log_general_parameters_file.write('b_value\\t' + str(self.b_value) + '\\n')\n        log_general_parameters_file.close()\n        faults_area = []\n        faults_length = []\n        faults_width = []\n        faults_slip_rates = []\n        faults_mecanism = []\n        faults_shear_mod = []\n        '########################################################\\n            # Random sampling of the fault slip-rate\\n            ########################################################'\n        print('Picking slip-rates...')\n        if self.sample == 1:\n            self.sr_correl = False\n        if self.sr_correl == True:\n            M_faults_correl = []\n            for Fault_name in faults_names:\n                M_faults_correl_i = []\n                sc_with_fault = []\n                for index_scenario in range(len(scenarios_names)):\n                    scenario_i = self.rupture_set[index_scenario]\n                    if Fault_name in scenario_i:\n                        sc_with_fault += scenario_i\n                for Fault_name_i in faults_names:\n                    nb_join_ruptures = 0\n                    if Fault_name == Fault_name_i:\n                        nb_join_ruptures = 0\n                    elif Fault_name_i in sc_with_fault:\n                        nb_join_ruptures = sc_with_fault.count(Fault_name_i)\n                    else:\n                        nb_join_ruptures = 0\n                    M_faults_correl_i.append(nb_join_ruptures)\n                M_faults_correl.append(M_faults_correl_i)\n            M_linked_lvl = np.zeros_like(M_faults_correl)\n            for lvl in [1, 2, 3, 4]:\n                for i in range(len(faults_names)):\n                    for j in range(len(faults_names)):\n                        if M_linked_lvl[i][j] == 0:\n                            if M_faults_correl[i][j] != 0:\n                                M_linked_lvl[i][j] = lvl\n                            else:\n                                for jj in range(len(M_faults_correl[j])):\n                                    if M_faults_correl[j][jj] != 0:\n                                        if M_linked_lvl[i][j] == 0:\n                                            M_linked_lvl[i][j] = lvl + 1\n            max_correl = np.max(M_faults_correl)\n            list_quater_picked = list(np.zeros(len(faults_names)))\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                sr_values = [faults_data[index_fault]['slip_rate_min'], faults_data[index_fault]['slip_rate_moy'], faults_data[index_fault]['slip_rate_max']]\n                slip_rate = select_sr.select(sr_values, self.sample, index_fault, M_linked_lvl[index_fault], list_quater_picked)\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        else:\n            index_fault = 0\n            for Fault_name in faults_names:\n                faults_length.append(faults_data[index_fault]['length'])\n                faults_area.append(faults_data[index_fault]['area'])\n                faults_width.append(faults_data[index_fault]['width'])\n                faults_mecanism.append(faults_data[index_fault]['mecanism'])\n                slip_rate_min = faults_data[index_fault]['slip_rate_min']\n                slip_rate_moy = faults_data[index_fault]['slip_rate_moy']\n                slip_rate_max = faults_data[index_fault]['slip_rate_max']\n                if self.sample == 1:\n                    slip_rate = slip_rate_moy\n                else:\n                    slip_rate_inf = np.random.uniform(slip_rate_min, slip_rate_moy)\n                    slip_rate_sup = np.random.uniform(slip_rate_moy, slip_rate_max)\n                    slip_rate = np.random.choice([slip_rate_inf, slip_rate_sup])\n                log_line = str(Fault_name) + '\\t' + str(slip_rate) + '\\n'\n                log_sr_file.write(log_line)\n                faults_slip_rates.append(slip_rate * 0.001)\n                faults_shear_mod.append(faults_data[index_fault]['shear_mod'])\n                index_fault += 1\n        print('\\t\\tslip-rates picked.')\n        ratio_test = 0.5\n        count_reruns = 1\n        count_mfd90 = 1\n        f_pkl_mdf = self.pathlog + '/mfd_' + str(self.sample) + '.pkl'\n        re_use_mfd_pkl = True\n        if not os.path.isfile(f_pkl_mdf):\n            re_use_mfd_pkl = False\n        if re_use_mfd_pkl == False:\n            while abs(ratio_test - 1) > self.fit_quality or math.isnan(ratio_test) == True:\n                MFDs = EQ_on_faults.EQ_on_faults_from_sr(M_min, mfd_param, faults_names, faults_area, faults_length, faults_width, faults_slip_rates, scenarios_names, faults_shear_mod, self.path, self.sample, self.selected_ScL, self.dimention_used, self.use_all_ScL_data, faults_mecanism, self.bg_ratio, self.size_of_increment, self.mfd_hyp, count_reruns, faults_lon, faults_lat, self.Mmax_range, self.calculation_log_file, self.branch, self.param)\n                ratio_test = MFDs.ratio_test\n                if abs(ratio_test - 1) > self.fit_quality:\n                    print('bad sampling => re-run')\n                    count_reruns += 1\n                    if MFDs.ratio_NMS > 90.0:\n                        count_reruns -= 1\n                        count_mfd90 += 1\n                    else:\n                        count_mfd90 = 1\n                elif MFDs.ratio_NMS > 90.0:\n                    ratio_test = 0.5\n                    print('bad sampling => re-run')\n                    count_mfd90 += 1\n                else:\n                    count_mfd90 = 1\n                if math.isnan(ratio_test) == True:\n                    print('bad sampling => re-run')\n                    count_reruns = 1\n                if count_reruns > 3 or count_mfd90 > 3:\n                    print('\\n\\n\\n!!!!!! maybe there is a problem!!!')\n                    ratio_test = 1.0\n            with open(f_pkl_mdf, 'wb') as f:\n                MFDs_to_pkl = [MFDs.EQ_rate_BG, MFDs.faults_names, MFDs.OQ_entry_faults, MFDs.scenarios_names, MFDs.OQ_entry_scenarios, MFDs.index_faults_in_scenario, MFDs.M_slip_repartition]\n                pickle.dump(MFDs_to_pkl, f)\n        else:\n            print('Reloading MFDs from previous run')\n            with open(f_pkl_mdf, 'rb') as f:\n                MFDs_to_pkl = pickle.load(f)\n        EQ_rate_BG = MFDs_to_pkl[0]\n        faults_names = MFDs_to_pkl[1]\n        OQ_entry_faults = MFDs_to_pkl[2]\n        scenarios_names = MFDs_to_pkl[3]\n        OQ_entry_scenarios = MFDs_to_pkl[4]\n        index_faults_in_scenario = MFDs_to_pkl[5]\n        M_slip_repartition = MFDs_to_pkl[6]\n        if self.selected_ScL == 'Le2010':\n            ScL_oq = 'Leonard2014_SCR'\n        elif self.selected_ScL == 'WC1994':\n            ScL_oq = 'WC1994'\n        else:\n            ScL_oq = 'WC1994'\n        (Lon_bg, Lat_bg) = bg.geom(self.Model_name, self.File_bg)\n        Poly_bg = []\n        for (x1, y1) in zip(Lon_bg, Lat_bg):\n            Poly_bg.append((x1, y1))\n        bbPath_BG = mplPath.Path(Poly_bg)\n        f_in_bg = []\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            for (lon, lat) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                if bbPath_BG.contains_point((lon, lat)):\n                    f_in_bg.append(index_fault)\n        outside_faults = []\n        if include_all_faults == True:\n            for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n                if not index_fault in f_in_bg:\n                    f_in_bg.append(index_fault)\n                    outside_faults.append(index_fault)\n        ID_number = 0\n        for (index_fault, fault_name) in zip(range(len(faults_names)), faults_names):\n            if index_fault in f_in_bg:\n                use_simple_faults = False\n                if use_simple_faults == True:\n                    (line, self.Domain_in_the_model, ID_number) = fault_source.write_simple_fault(index_fault, fault_name, OQ_entry_faults, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, M_min, ID_number)\n                else:\n                    (line, self.Domain_in_the_model, ID_number) = fault_source.write_non_parametric_one_fault(index_fault, fault_name, OQ_entry_faults, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, M_min, ID_number, explo_time)\n                if cut_sm_file == False:\n                    XMLfile.write(line)\n                else:\n                    i_w = 0\n                    while sf_counter[i_w] > 500:\n                        i_w += 1\n                    sf_files[i_w].write(line)\n                    sf_counter[i_w] += 1\n        if len(self.rupture_set) != 0:\n            for scenario in enumerate(scenarios_names):\n                sc_in = False\n                index_scenario = np.where(np.array(scenarios_names) == scenario[1])[0][0]\n                for i in index_faults_in_scenario[index_scenario][0]:\n                    if i in f_in_bg:\n                        sc_in = True\n                if sc_in == True:\n                    use_non_param = True\n                    if use_non_param == False:\n                        (line, ID_number) = fault_source.write_characteristic_scenario(scenarios_names, OQ_entry_scenarios, index_faults_in_scenario, scenario, faults_names, self.Model_name, faults_data, log_mdf_file, M_min, ID_number)\n                    else:\n                        (line, ID_number) = fault_source.write_non_parametric_source(scenario, scenarios_names, OQ_entry_scenarios, index_faults_in_scenario, faults_names, faults_data, self.Model_name, self.Domain_in_the_model, ScL_oq, log_mdf_file, explo_time, M_min, ID_number)\n                    if cut_sm_file == False:\n                        XMLfile.write(line)\n                    else:\n                        i_w = 0\n                        while mf_counter[i_w] > 500:\n                            i_w += 1\n                        mf_files[i_w].write(line)\n                        mf_counter[i_w] += 1\n    '#########################\\n        # Defining the background seismicity\\n        #########################'\n    MFD = EQ_rate_BG\n    pts_list = {}\n    if sum(MFD) != 0.0 and self.param['main']['background']['option_bg'] == 'zone':\n        bg_file = self.path + '/bg_' + str(self.sample) + '.xml'\n        list_src_files.append(bg_file)\n        bg_file = open(bg_file, 'w')\n        line = \"<?xml version='1.0' encoding='utf-8'?>\\n\"\n        line += '<nrml xmlns:gml=\"http://www.opengis.net/gml\"\\n'\n        line += '\\txmlns=\"http://openquake.org/xmlns/nrml/0.5\">\\n'\n        line += '\\t<sourceModel name=\"Hazard Model\">\\n'\n        (upperSeismoDepth, lowerSeismoDepth, ruptAspectRatio, nodalPlanes, hypoDepths) = bg.prop(self.Model_name, self.file_prop_bg)\n        line += '\\t\\t<sourceGroup\\nname=\"group 2\"\\nrup_interdep=\"indep\"\\nsrc_interdep=\"indep\"\\ntectonicRegion=\"' + str(self.Domain_in_the_model[0]) + '\"\\n>\\n'\n        line += '\\t\\t<areaSource id=\"' + str(source_id + 1) + '\" name=\"Background\" tectonicRegion=\"' + str(self.Domain_in_the_model[0]) + '\">\\n'\n        line += '\\t\\t\\t<areaGeometry>\\n'\n        line += '\\t\\t\\t\\t<gml:Polygon>\\n'\n        line += '\\t\\t\\t\\t\\t<gml:exterior>\\n'\n        line += '\\t\\t\\t\\t\\t\\t<gml:LinearRing>\\n'\n        line += '\\t\\t\\t\\t\\t\\t\\t<gml:posList>\\n'\n        for (x, y) in zip(Lon_bg, Lat_bg):\n            line += '\\t\\t\\t\\t\\t\\t\\t\\t' + str(x) + ' ' + str(y) + '\\n'\n        line += '\\t\\t\\t\\t\\t\\t\\t</gml:posList>\\n'\n        line += '\\t\\t\\t\\t\\t\\t</gml:LinearRing>\\n'\n        line += '\\t\\t\\t\\t\\t</gml:exterior>\\n'\n        line += '\\t\\t\\t\\t</gml:Polygon>\\n'\n        line += '\\t\\t\\t\\t<upperSeismoDepth>' + str(upperSeismoDepth) + '</upperSeismoDepth>\\n'\n        line += '\\t\\t\\t\\t<lowerSeismoDepth>' + str(lowerSeismoDepth) + '</lowerSeismoDepth>\\n'\n        line += '\\t\\t\\t</areaGeometry>\\n'\n        line += '\\t\\t\\t<magScaleRel>' + ScL_oq + '</magScaleRel>\\n'\n        line += '\\t\\t\\t<ruptAspectRatio>' + str(ruptAspectRatio) + '</ruptAspectRatio>\\n'\n        log_mdf_file.write('Background' + '\\t' + str(M_min) + '\\t' + ' '.join(list(map(str, MFD))) + '\\n')\n        line += '\\t\\t\\t<incrementalMFD binWidth=\"0.10\" minMag=\"' + str(M_min) + '\">\\n'\n        line += '\\t\\t\\t<occurRates> ' + ' '.join(list(map(str, MFD))) + '</occurRates>\\n'\n        line += '\\t\\t\\t</incrementalMFD>\\n'\n        line += '\\t\\t\\t<nodalPlaneDist>\\n'\n        for i in range(len(nodalPlanes)):\n            line += '\\t\\t\\t\\t<nodalPlane probability=\"' + str(nodalPlanes[i][0]) + '\" strike=\"' + str(nodalPlanes[i][1]) + '\" dip=\"' + str(nodalPlanes[i][2]) + '\" rake=\"' + str(nodalPlanes[i][3]) + '\" />\\n'\n        line += '\\t\\t\\t</nodalPlaneDist>\\n'\n        line += '\\t\\t\\t<hypoDepthDist>\\n'\n        for i in range(len(hypoDepths)):\n            line += '\\t\\t\\t\\t<hypoDepth probability=\"' + str(hypoDepths[i][0]) + '\" depth=\"' + str(hypoDepths[i][1]) + '\" />\\n'\n        line += '\\t\\t\\t</hypoDepthDist>\\n'\n        line += '\\t\\t</areaSource>\\n'\n        line += '\\t</sourceGroup>\\n'\n        line += '\\t</sourceModel>\\n'\n        line += '</nrml>\\n'\n        bg_file.write(line)\n        bg_file.close()\n    elif sum(MFD) != 0.0 and self.param['main']['background']['option_bg'] == 'smooth':\n        Mmin_checked = False\n        Mmax = M_min + len(EQ_rate_BG) * 0.1 - 1\n        mags = np.linspace(M_min, Mmax, len(EQ_rate_BG))\n        list_bg_xml = self.list_fbg\n        if os.path.isdir(self.fbgpath):\n            list_bg_xml = [self.fbgpath + '/' + i for i in list_bg_xml if '.xml' in i]\n        with open(list_bg_xml[0]) as myfile:\n            if 'multiPointSource' in myfile.read():\n                multiPointSource_type = True\n            else:\n                multiPointSource_type = False\n        if multiPointSource_type == True:\n            bg.get_multipoints(EQ_rate_BG, M_min, bbPath_BG, list_bg_xml, include_all_faults, outside_faults, faults_data, OQ_entry_faults, self.path, self.pathlog, list_src_files)\n        else:\n            pts_list = {}\n            pts_out_list = {}\n            sum_rates = [0.0 for _ in mags]\n            for fbg in list_bg_xml:\n                tree = ET.parse(fbg)\n                ET.register_namespace('', 'http://openquake.org/xmlns/nrml/0.5')\n                nrml = tree.getroot()\n                i_point = 0\n                for pointSource in nrml[0][0]:\n                    pt_in_BG = False\n                    i_child = 0\n                    for child in pointSource.getchildren():\n                        if 'pointGeometry' in str(child):\n                            s_tmp = pointSource[i_child][0][0].text\n                            s_tmp = s_tmp.replace('\\n', '')\n                            s_tmp = [float(i) for i in s_tmp.split(' ') if i != '']\n                            if bbPath_BG.contains_point((s_tmp[0], s_tmp[1])) == 1:\n                                pt_in_BG = True\n                            str_loc = str(s_tmp[0]) + '_' + str(s_tmp[1])\n                        if 'truncGutenbergRichterMFD' in str(child):\n                            aValue = nrml[0][0][i_point][i_child].get('aValue')\n                            minMag = nrml[0][0][i_point][i_child].get('minMag')\n                            i_trGR = i_child\n                        i_child += 1\n                    aValue = nrml[0][0][i_point][i_trGR].get('aValue')\n                    minMag = nrml[0][0][i_point][i_trGR].get('minMag')\n                    bValue = nrml[0][0][i_point][i_trGR].get('bValue')\n                    maxMag = nrml[0][0][i_point][i_trGR].get('maxMag')\n                    mfd_smooth = []\n                    i_mag = 0\n                    for mag in mags:\n                        mag_lo = mag - 0.05\n                        mag_hi = mag + 0.05\n                        r = 10 ** (float(aValue) - float(bValue) * mag_lo) - 10 ** (float(aValue) - float(bValue) * mag_hi)\n                        sum_rates[i_mag] += r\n                        i_mag += 1\n                        mfd_smooth.append(r)\n                    if pt_in_BG == True:\n                        pts_list.update({str_loc: {'aValue': aValue, 'bValue': bValue, 'maxMag': maxMag, 'minMag': minMag, 'mfd_smooth': mfd_smooth}})\n                        if Mmin_checked == False:\n                            if float(minMag) < M_min:\n                                print('!!!!')\n                                print('WARNING : BG has a smaller Mmin than the SHERIFS input')\n                                print('!!!!')\n                                Mmin_checked = True\n                    elif include_all_faults == True:\n                        pt_very_far = True\n                        lon_lat_distance_criteria = 1.0\n                        i = 0\n                        while pt_very_far == False and i < len(outside_faults):\n                            i_fault = outside_faults[i]\n                            mean_lon = np.mean(faults_data[index_fault]['lon'])\n                            mean_lat = np.mean(faults_data[index_fault]['lat'])\n                            if abs(float(s_tmp[0]) - mean_lon) < lon_lat_distance_criteria:\n                                pt_very_far = False\n                            if abs(float(s_tmp[1]) - mean_lat) < lon_lat_distance_criteria:\n                                pt_very_far = False\n                            i += 1\n                        if pt_very_far == False:\n                            dist_critera = 50.0\n                            dist = 1000000.0\n                            closest_fault = 'nope'\n                            for i_fault in outside_faults:\n                                mean_lon = np.mean(faults_data[index_fault]['lon'])\n                                mean_lat = np.mean(faults_data[index_fault]['lat'])\n                                dist_i = distance(mean_lon, mean_lat, float(s_tmp[0]), float(s_tmp[1]))\n                                if dist_i < dist_critera:\n                                    for (lon_f, lat_f) in zip(faults_data[index_fault]['lon'], faults_data[index_fault]['lat']):\n                                        dist_i = distance(mean_lon, mean_lat, float(s_tmp[0]), float(s_tmp[1]))\n                                        if dist_i < dist:\n                                            dist = dist_i\n                                            closest_fault = i_fault\n                                if dist_i < dist:\n                                    dist = dist_i\n                                    closest_fault = i_fault\n                            closest_dist = dist\n                            pts_out_list.update({str_loc: {'aValue': aValue, 'bValue': bValue, 'maxMag': maxMag, 'minMag': minMag, 'mfd_smooth': mfd_smooth, 'distance': closest_dist, 'closest_fault': i_fault}})\n                    i_point += 1\n            nb_pt_in_buff = {}\n            if include_all_faults == True:\n                for i_fault in outside_faults:\n                    buffer_1 = 10.0\n                    buffer_2 = 20.0\n                    nb_buf1 = 0\n                    nb_buf2 = 0\n                    for str_loc in pts_out_list.keys():\n                        if pts_out_list[str_loc]['closest_fault'] == i_fault:\n                            if pts_out_list[str_loc]['closest_dist'] < buffer_1:\n                                nb_buf1 += 1\n                            elif pts_out_list[str_loc]['closest_dist'] < buffer_2:\n                                nb_buf2 += 1\n                    nb_pt_in_buff.update({i_fault: {'nb_buf1': nb_buf1, 'nb_buf2': nb_buf2}})\n            sum_bg_min = 0.0\n            i_bg = 0\n            for fbg in list_bg_xml:\n                tree = ET.parse(fbg)\n                ET.register_namespace('', 'http://openquake.org/xmlns/nrml/0.5')\n                nrml = tree.getroot()\n                i_point = 0\n                for pointSource in nrml[0][0]:\n                    pt_in_BG = False\n                    i_child = 0\n                    for child in pointSource.getchildren():\n                        if 'magScaleRel' in str(child):\n                            nrml[0][0][i_point][i_child].text = ScL_oq\n                        if 'pointGeometry' in str(child):\n                            s_tmp = pointSource[i_child][0][0].text\n                            s_tmp = s_tmp.replace('\\n', '')\n                            s_tmp = [float(i) for i in s_tmp.split(' ') if i != '']\n                            str_loc = str(s_tmp[0]) + '_' + str(s_tmp[1])\n                        if 'truncGutenbergRichterMFD' in str(child):\n                            i_trGR = i_child\n                        i_child += 1\n                    if str_loc in pts_list.keys():\n                        b_value = float(pts_list[str_loc]['bValue'])\n                        a_value = float(pts_list[str_loc]['aValue'])\n                        attrib = {'minMag': str(M_min), 'binWidth': '0.10'}\n                        element = nrml[0][0][i_point].makeelement('incrementalMFD', attrib)\n                        nrml[0][0][i_point].append(element)\n                        element = nrml[0][0][i_point][-1].makeelement('occurRates', {})\n                        nrml[0][0][i_point][-1].append(element)\n                        str_tmp = ' '\n                        pt_scl_mfd = []\n                        i_mag = 0\n                        for mag in mags:\n                            mag_lo = mag - 0.05\n                            mag_hi = mag + 0.05\n                            r = 10 ** (a_value - b_value * mag_lo) - 10 ** (a_value - b_value * mag_hi)\n                            norm_r = r / sum_rates[i_mag]\n                            str_tmp += str(EQ_rate_BG[i_mag] * norm_r)\n                            str_tmp += ' '\n                            sum_bg_min += EQ_rate_BG[i_mag] * norm_r\n                            pt_scl_mfd.append(EQ_rate_BG[i_mag] * norm_r)\n                            i_mag += 1\n                        pts_list[str_loc].update({'scaled_mfd': pt_scl_mfd})\n                        nrml[0][0][i_point][-1][0].text = str_tmp\n                        nrml[0][0][i_point].remove(nrml[0][0][i_point][i_trGR])\n                    if include_all_faults == True:\n                        if str_loc in pts_out_list.keys():\n                            b_value = float(pts_list[str_loc]['bValue'])\n                            a_value = float(pts_list[str_loc]['aValue'])\n                            attrib = {'minMag': str(M_min), 'binWidth': '0.10'}\n                            element = nrml[0][0][i_point].makeelement('incrementalMFD', attrib)\n                            nrml[0][0][i_point].append(element)\n                            element = nrml[0][0][i_point][-1].makeelement('occurRates', {})\n                            nrml[0][0][i_point][-1].append(element)\n                            str_tmp = ' '\n                            pt_scl_mfd = []\n                            i_fault = pts_out_list[str_loc]['closest_fault']\n                            mfd_single_clst_f = OQ_entry_faults[i_fault]\n                            id_ruptures = []\n                            mfd_mlt_clst_f = []\n                            for (scenario_i, mfd_i) in zip(index_faults_in_scenario, OQ_entry_scenarios):\n                                if i_fault in scenario_i:\n                                    id_ruptures.append(scenario_i)\n                                    mfd_mlt_clst_f.append(mfd_i)\n                            i_mag = 0\n                            for mag in mags:\n                                mag_lo = mag - 0.05\n                                mag_hi = mag + 0.05\n                                r = 10 ** (a_value - b_value * mag_lo) - 10 ** (a_value - b_value * mag_hi)\n                                if mag >= 6.5:\n                                    buffer_to_use = 'nb_buf2'\n                                else:\n                                    buffer_to_use = 'nb_buf1'\n                                reduction = 0.0\n                                for (f_in_rup, mfd_i) in zip(id_ruptures, mfd_mlt_clst_f):\n                                    reduction += mfd_i[i_mag] / float(len(f_in_rup) * nb_pt_in_buff[i_fault][buffer_to_use])\n                                if reduction > r:\n                                    r = 0.0\n                                else:\n                                    r -= reduction\n                                str_tmp += str(r)\n                                str_tmp += ' '\n                                pt_scl_mfd.append(r)\n                                i_mag += 1\n                            pts_out_list[str_loc].update({'scaled_mfd': pt_scl_mfd})\n                            nrml[0][0][i_point][-1][0].text = str_tmp\n                            nrml[0][0][i_point].remove(nrml[0][0][i_point][i_trGR])\n                    i_point += 1\n                i_bg += 1\n                fbg_out = self.path + '/bg_' + str(self.sample) + '_' + str(i_bg) + '.xml'\n                tree.write(fbg_out)\n                list_src_files.append(fbg_out)\n    '#############################\\n        ### defining the other sources based on the host model\\n        ##############################'\n    if self.param['main']['background']['use_host_model'] == True and cut_sm_file == False:\n        host_model.build(XMLfile, self.host_model_file, Lon_bg, Lat_bg)\n    if self.param['main']['background']['use_host_model'] == True and cut_sm_file == True:\n        print(\"WARNING : can't use host model and cut files yet !\")\n    if use_multiF == False:\n        line = '\\t\\t\\t</sourceGroup>\\n'\n        line += '\\t</sourceModel>\\n'\n        line += '</nrml>\\n'\n        if cut_sm_file == False:\n            XMLfile.write(line)\n            XMLfile.close()\n        else:\n            for f in sf_files + mf_files:\n                f.write(line)\n                f.close()\n    log_sr_file.close()\n    log_mdf_file.close()\n    self.list_src_files = list_src_files\n    '#############################\\n        ### Get the particiaption rates of sections\\n        ##############################'\n    import participation_rates as p_rates\n    from section_info import get_nonzero_Mmax\n    (dict_p_rates, mfd_total, all_non_zero_rups) = p_rates.get_all_participation_rates(MFDs_to_pkl, self.param, faults_names)\n    bin_mag = p_rates.get_bin_mag(mfd_total, self.Mmin)\n    all_participation_rates = []\n    sections_Mmax = []\n    if not os.path.isdir(self.pathlog + '/participation_rates'):\n        os.makedirs(self.pathlog + '/participation_rates')\n    for fault_name in faults_names:\n        (incremental_rate, cumulative_rate) = p_rates.extract_rates(fault_name, dict_p_rates)\n        all_participation_rates.append(cumulative_rate)\n        ptf = self.pathlog + '/participation_rates/' + str(fault_name) + '.png'\n        p_rates.plot_participation_rates(bin_mag, incremental_rate, cumulative_rate, fault_name, ptf)\n        Mmax = get_nonzero_Mmax(bin_mag, cumulative_rate)\n        sections_Mmax.append(Mmax)\n    '#############################\\n        ### Exporting the results in a Geojson\\n        ##############################'\n    features = []\n    for si in f_in_bg:\n        sections = []\n        geom = []\n        for (lon_i, lat_i) in zip(faults_data[si]['lon'], faults_data[si]['lat']):\n            geom.append((lon_i, lat_i))\n        geom = LineString(list(geom))\n        properties = {}\n        for key in faults_data[si].keys():\n            if not key in ['lat', 'lon']:\n                properties.update({key: faults_data[si][key]})\n        NMS = float(M_slip_repartition[faults_data[si]['name']]['NMS'])\n        sumdsr = 0.0\n        for key in M_slip_repartition[faults_data[si]['name']].keys():\n            sumdsr += M_slip_repartition[faults_data[si]['name']][key]\n        properties.update({'NMS': NMS / float(sumdsr)})\n        properties.update({'nb_rup': float(all_non_zero_rups[si])})\n        properties.update({'Mmax': float(sections_Mmax[si])})\n        properties.update({'participation_rates': [bin_mag, all_participation_rates[si]]})\n        nms_i = NMS / float(sumdsr)\n        mmax_i = sections_Mmax[si]\n        if mmax_i >= max(sections_Mmax) - 0.3:\n            if nms_i < 0.1:\n                indicator = 1.0 - nms_i\n            else:\n                indicator = 0.0\n        elif mmax_i >= max(sections_Mmax) - 0.5:\n            if nms_i < 0.05:\n                indicator = 1.0 - nms_i\n            else:\n                indicator = 0.0\n        else:\n            indicator = 0.0\n        properties.update({'might_to_be_limiting': round(indicator, 2)})\n        features.append(Feature(geometry=geom, properties=properties))\n    feature_collection = FeatureCollection(features)\n    with open(self.pathlog + '/out_sections.geojson', 'w') as f:\n        dump(feature_collection, f)\n    '#######################\\n        ### some figures\\n        ######################'\n    if 'figures' in self.param.keys():\n        if self.param['figures']['print'] in ['true', 'True']:\n            make_figures = True\n        else:\n            make_figures = False\n    else:\n        make_figures = False\n    plt_model_mfd = False\n    if make_figures == True:\n        if self.param['figures']['model_mfd'] in ['true', 'True']:\n            plt_model_mfd = True\n    if 'mfd_cat' in self.param['figures'].keys():\n        data = self.param['figures']['mfd_cat']\n    else:\n        data = False\n    if plt_model_mfd == True:\n        x = MFDs.bin_mag\n        y = rates.get_rate_model(MFDs.rup_rates, MFDs.fault_prop, x)\n        lim = [[x[0] - 0.05, x[-1] + 0.05], [min(y) / 2.0, max(y) * 2.0]]\n        axis = ['magnitude', 'annual earthquake rates']\n        path = self.pathlog + '/modelMFD.png'\n        title = 'MFD of the whole system'\n        plt_mfd.plot(x, y, lim, axis, data, path, title)\n    if plt_model_mfd == True:\n        x = MFDs.bin_mag\n        (ft, bgmfd) = rates.get_rate_faults_n_bg(MFDs.rup_rates, MFDs.fault_prop, x)\n        ys = [rates.get_rate_model(MFDs.rup_rates, MFDs.fault_prop, x), ft, bgmfd]\n        lim = [[x[0] - 0.05, x[-1] + 0.05], [min(ys[0]) / 2.0, max(ys[0]) * 2.0]]\n        axis = ['magnitude', 'annual earthquake rates']\n        path = self.pathlog + '/modelMFD_bg_ft.png'\n        title = 'MFD of the whole system, faults, background'\n        plt_mfd.plot_bg_ft(x, ys, lim, axis, path, title)\n    ' mfd in a more local scale '\n    part_mfd = False\n    if make_figures == True:\n        if 'part_mfd' in self.param['figures'].keys():\n            if self.param['figures']['part_mfd'] in ['true', 'True']:\n                part_mfd = True\n    if part_mfd == True:\n        loc_cat = local_cat.read_geojson(self.param['figures']['parts_gjson'])\n        for zone in loc_cat.keys():\n            polypt = loc_cat[zone]['poly']\n            lons = []\n            lats = []\n            for pt in polypt[0][0]:\n                lons.append(pt[0])\n                lats.append(pt[1])\n            poly = []\n            for (x1, y1) in zip(lons, lats):\n                poly.append((x1, y1))\n            area_zone = geometry_tools.PolyArea(lons, lats)\n            area_bg = geometry_tools.PolyArea(Lon_bg, Lat_bg)\n            ratio_area = float(area_zone) / float(area_bg)\n            local_zone_mfd = [i * ratio_area for i in EQ_rate_BG]\n            poly = mplPath.Path(poly)\n            (txt_no_bg, rate_faults, rate_bg, smooth) = local_cat.get_model_rate(poly, OQ_entry_faults, OQ_entry_scenarios, pts_list, MFDs.bin_mag, self.param, faults_data, faults_names, index_faults_in_scenario, local_zone_mfd)\n            x = MFDs.bin_mag\n            rate_model = [i + j for (i, j) in zip(rate_faults, rate_bg)]\n            lim = [[x[0] - 0.05, x[-1] + 0.05], [min(rate_model) / 2.0, max(rate_model) * 2.0]]\n            axis = ['magnitude', 'annual earthquake rates']\n            title = 'MFD in zone ' + str(zone) + txt_no_bg\n            path = self.pathlog + '/MFD_zone' + str(zone) + '.png'\n            if 'cat_rates' in loc_cat[zone].keys():\n                data = loc_cat[zone]['cat_rates']\n            else:\n                data = False\n            if data == None:\n                data = False\n            if data == True:\n                if len(data[0]) == 0:\n                    data = False\n                if len(data[0]) != len(data[1]):\n                    data = False\n                    print('For zone', zone, ' : wrong bining')\n                    print('please check the geojson file')\n            plt_mfd.local(x, [rate_model, rate_faults, rate_bg, smooth], data, lim, axis, path, title)"
        ]
    }
]