[
    {
        "func_name": "__init__",
        "original": "def __init__(self):\n    super(Policy, self).__init__()\n    self.data = []\n    self.fc1 = layers.Dense(128, kernel_initializer='he_normal')\n    self.fc2 = layers.Dense(2, kernel_initializer='he_normal')\n    self.optimizer = optimizers.Adam(lr=learning_rate)",
        "mutated": [
            "def __init__(self):\n    if False:\n        i = 10\n    super(Policy, self).__init__()\n    self.data = []\n    self.fc1 = layers.Dense(128, kernel_initializer='he_normal')\n    self.fc2 = layers.Dense(2, kernel_initializer='he_normal')\n    self.optimizer = optimizers.Adam(lr=learning_rate)",
            "def __init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super(Policy, self).__init__()\n    self.data = []\n    self.fc1 = layers.Dense(128, kernel_initializer='he_normal')\n    self.fc2 = layers.Dense(2, kernel_initializer='he_normal')\n    self.optimizer = optimizers.Adam(lr=learning_rate)",
            "def __init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super(Policy, self).__init__()\n    self.data = []\n    self.fc1 = layers.Dense(128, kernel_initializer='he_normal')\n    self.fc2 = layers.Dense(2, kernel_initializer='he_normal')\n    self.optimizer = optimizers.Adam(lr=learning_rate)",
            "def __init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super(Policy, self).__init__()\n    self.data = []\n    self.fc1 = layers.Dense(128, kernel_initializer='he_normal')\n    self.fc2 = layers.Dense(2, kernel_initializer='he_normal')\n    self.optimizer = optimizers.Adam(lr=learning_rate)",
            "def __init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super(Policy, self).__init__()\n    self.data = []\n    self.fc1 = layers.Dense(128, kernel_initializer='he_normal')\n    self.fc2 = layers.Dense(2, kernel_initializer='he_normal')\n    self.optimizer = optimizers.Adam(lr=learning_rate)"
        ]
    },
    {
        "func_name": "call",
        "original": "def call(self, inputs, training=None):\n    x = tf.nn.relu(self.fc1(inputs))\n    x = tf.nn.softmax(self.fc2(x), axis=1)\n    return x",
        "mutated": [
            "def call(self, inputs, training=None):\n    if False:\n        i = 10\n    x = tf.nn.relu(self.fc1(inputs))\n    x = tf.nn.softmax(self.fc2(x), axis=1)\n    return x",
            "def call(self, inputs, training=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    x = tf.nn.relu(self.fc1(inputs))\n    x = tf.nn.softmax(self.fc2(x), axis=1)\n    return x",
            "def call(self, inputs, training=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    x = tf.nn.relu(self.fc1(inputs))\n    x = tf.nn.softmax(self.fc2(x), axis=1)\n    return x",
            "def call(self, inputs, training=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    x = tf.nn.relu(self.fc1(inputs))\n    x = tf.nn.softmax(self.fc2(x), axis=1)\n    return x",
            "def call(self, inputs, training=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    x = tf.nn.relu(self.fc1(inputs))\n    x = tf.nn.softmax(self.fc2(x), axis=1)\n    return x"
        ]
    },
    {
        "func_name": "put_data",
        "original": "def put_data(self, item):\n    self.data.append(item)",
        "mutated": [
            "def put_data(self, item):\n    if False:\n        i = 10\n    self.data.append(item)",
            "def put_data(self, item):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.data.append(item)",
            "def put_data(self, item):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.data.append(item)",
            "def put_data(self, item):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.data.append(item)",
            "def put_data(self, item):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.data.append(item)"
        ]
    },
    {
        "func_name": "train_net",
        "original": "def train_net(self, tape):\n    R = 0\n    for (r, log_prob) in self.data[::-1]:\n        R = r + gamma * R\n        loss = -log_prob * R\n        with tape.stop_recording():\n            grads = tape.gradient(loss, self.trainable_variables)\n            self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n    self.data = []",
        "mutated": [
            "def train_net(self, tape):\n    if False:\n        i = 10\n    R = 0\n    for (r, log_prob) in self.data[::-1]:\n        R = r + gamma * R\n        loss = -log_prob * R\n        with tape.stop_recording():\n            grads = tape.gradient(loss, self.trainable_variables)\n            self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n    self.data = []",
            "def train_net(self, tape):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    R = 0\n    for (r, log_prob) in self.data[::-1]:\n        R = r + gamma * R\n        loss = -log_prob * R\n        with tape.stop_recording():\n            grads = tape.gradient(loss, self.trainable_variables)\n            self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n    self.data = []",
            "def train_net(self, tape):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    R = 0\n    for (r, log_prob) in self.data[::-1]:\n        R = r + gamma * R\n        loss = -log_prob * R\n        with tape.stop_recording():\n            grads = tape.gradient(loss, self.trainable_variables)\n            self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n    self.data = []",
            "def train_net(self, tape):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    R = 0\n    for (r, log_prob) in self.data[::-1]:\n        R = r + gamma * R\n        loss = -log_prob * R\n        with tape.stop_recording():\n            grads = tape.gradient(loss, self.trainable_variables)\n            self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n    self.data = []",
            "def train_net(self, tape):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    R = 0\n    for (r, log_prob) in self.data[::-1]:\n        R = r + gamma * R\n        loss = -log_prob * R\n        with tape.stop_recording():\n            grads = tape.gradient(loss, self.trainable_variables)\n            self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n    self.data = []"
        ]
    },
    {
        "func_name": "main",
        "original": "def main():\n    pi = Policy()\n    pi(tf.random.normal((4, 4)))\n    pi.summary()\n    score = 0.0\n    print_interval = 20\n    returns = []\n    for n_epi in range(400):\n        s = env.reset()\n        with tf.GradientTape(persistent=True) as tape:\n            for t in range(501):\n                s = tf.constant(s, dtype=tf.float32)\n                s = tf.expand_dims(s, axis=0)\n                prob = pi(s)\n                a = tf.random.categorical(tf.math.log(prob), 1)[0]\n                a = int(a)\n                (s_prime, r, done, info) = env.step(a)\n                pi.put_data((r, tf.math.log(prob[0][a])))\n                s = s_prime\n                score += r\n                if n_epi > 1000:\n                    env.render()\n                if done:\n                    break\n            pi.train_net(tape)\n        del tape\n        if n_epi % print_interval == 0 and n_epi != 0:\n            returns.append(score / print_interval)\n            print(f'# of episode :{n_epi}, avg score : {score / print_interval}')\n            score = 0.0\n    env.close()\n    plt.plot(np.arange(len(returns)) * print_interval, returns)\n    plt.plot(np.arange(len(returns)) * print_interval, returns, 's')\n    plt.xlabel('\u56de\u5408\u6570')\n    plt.ylabel('\u603b\u56de\u62a5')\n    plt.savefig('reinforce-tf-cartpole.svg')",
        "mutated": [
            "def main():\n    if False:\n        i = 10\n    pi = Policy()\n    pi(tf.random.normal((4, 4)))\n    pi.summary()\n    score = 0.0\n    print_interval = 20\n    returns = []\n    for n_epi in range(400):\n        s = env.reset()\n        with tf.GradientTape(persistent=True) as tape:\n            for t in range(501):\n                s = tf.constant(s, dtype=tf.float32)\n                s = tf.expand_dims(s, axis=0)\n                prob = pi(s)\n                a = tf.random.categorical(tf.math.log(prob), 1)[0]\n                a = int(a)\n                (s_prime, r, done, info) = env.step(a)\n                pi.put_data((r, tf.math.log(prob[0][a])))\n                s = s_prime\n                score += r\n                if n_epi > 1000:\n                    env.render()\n                if done:\n                    break\n            pi.train_net(tape)\n        del tape\n        if n_epi % print_interval == 0 and n_epi != 0:\n            returns.append(score / print_interval)\n            print(f'# of episode :{n_epi}, avg score : {score / print_interval}')\n            score = 0.0\n    env.close()\n    plt.plot(np.arange(len(returns)) * print_interval, returns)\n    plt.plot(np.arange(len(returns)) * print_interval, returns, 's')\n    plt.xlabel('\u56de\u5408\u6570')\n    plt.ylabel('\u603b\u56de\u62a5')\n    plt.savefig('reinforce-tf-cartpole.svg')",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    pi = Policy()\n    pi(tf.random.normal((4, 4)))\n    pi.summary()\n    score = 0.0\n    print_interval = 20\n    returns = []\n    for n_epi in range(400):\n        s = env.reset()\n        with tf.GradientTape(persistent=True) as tape:\n            for t in range(501):\n                s = tf.constant(s, dtype=tf.float32)\n                s = tf.expand_dims(s, axis=0)\n                prob = pi(s)\n                a = tf.random.categorical(tf.math.log(prob), 1)[0]\n                a = int(a)\n                (s_prime, r, done, info) = env.step(a)\n                pi.put_data((r, tf.math.log(prob[0][a])))\n                s = s_prime\n                score += r\n                if n_epi > 1000:\n                    env.render()\n                if done:\n                    break\n            pi.train_net(tape)\n        del tape\n        if n_epi % print_interval == 0 and n_epi != 0:\n            returns.append(score / print_interval)\n            print(f'# of episode :{n_epi}, avg score : {score / print_interval}')\n            score = 0.0\n    env.close()\n    plt.plot(np.arange(len(returns)) * print_interval, returns)\n    plt.plot(np.arange(len(returns)) * print_interval, returns, 's')\n    plt.xlabel('\u56de\u5408\u6570')\n    plt.ylabel('\u603b\u56de\u62a5')\n    plt.savefig('reinforce-tf-cartpole.svg')",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    pi = Policy()\n    pi(tf.random.normal((4, 4)))\n    pi.summary()\n    score = 0.0\n    print_interval = 20\n    returns = []\n    for n_epi in range(400):\n        s = env.reset()\n        with tf.GradientTape(persistent=True) as tape:\n            for t in range(501):\n                s = tf.constant(s, dtype=tf.float32)\n                s = tf.expand_dims(s, axis=0)\n                prob = pi(s)\n                a = tf.random.categorical(tf.math.log(prob), 1)[0]\n                a = int(a)\n                (s_prime, r, done, info) = env.step(a)\n                pi.put_data((r, tf.math.log(prob[0][a])))\n                s = s_prime\n                score += r\n                if n_epi > 1000:\n                    env.render()\n                if done:\n                    break\n            pi.train_net(tape)\n        del tape\n        if n_epi % print_interval == 0 and n_epi != 0:\n            returns.append(score / print_interval)\n            print(f'# of episode :{n_epi}, avg score : {score / print_interval}')\n            score = 0.0\n    env.close()\n    plt.plot(np.arange(len(returns)) * print_interval, returns)\n    plt.plot(np.arange(len(returns)) * print_interval, returns, 's')\n    plt.xlabel('\u56de\u5408\u6570')\n    plt.ylabel('\u603b\u56de\u62a5')\n    plt.savefig('reinforce-tf-cartpole.svg')",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    pi = Policy()\n    pi(tf.random.normal((4, 4)))\n    pi.summary()\n    score = 0.0\n    print_interval = 20\n    returns = []\n    for n_epi in range(400):\n        s = env.reset()\n        with tf.GradientTape(persistent=True) as tape:\n            for t in range(501):\n                s = tf.constant(s, dtype=tf.float32)\n                s = tf.expand_dims(s, axis=0)\n                prob = pi(s)\n                a = tf.random.categorical(tf.math.log(prob), 1)[0]\n                a = int(a)\n                (s_prime, r, done, info) = env.step(a)\n                pi.put_data((r, tf.math.log(prob[0][a])))\n                s = s_prime\n                score += r\n                if n_epi > 1000:\n                    env.render()\n                if done:\n                    break\n            pi.train_net(tape)\n        del tape\n        if n_epi % print_interval == 0 and n_epi != 0:\n            returns.append(score / print_interval)\n            print(f'# of episode :{n_epi}, avg score : {score / print_interval}')\n            score = 0.0\n    env.close()\n    plt.plot(np.arange(len(returns)) * print_interval, returns)\n    plt.plot(np.arange(len(returns)) * print_interval, returns, 's')\n    plt.xlabel('\u56de\u5408\u6570')\n    plt.ylabel('\u603b\u56de\u62a5')\n    plt.savefig('reinforce-tf-cartpole.svg')",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    pi = Policy()\n    pi(tf.random.normal((4, 4)))\n    pi.summary()\n    score = 0.0\n    print_interval = 20\n    returns = []\n    for n_epi in range(400):\n        s = env.reset()\n        with tf.GradientTape(persistent=True) as tape:\n            for t in range(501):\n                s = tf.constant(s, dtype=tf.float32)\n                s = tf.expand_dims(s, axis=0)\n                prob = pi(s)\n                a = tf.random.categorical(tf.math.log(prob), 1)[0]\n                a = int(a)\n                (s_prime, r, done, info) = env.step(a)\n                pi.put_data((r, tf.math.log(prob[0][a])))\n                s = s_prime\n                score += r\n                if n_epi > 1000:\n                    env.render()\n                if done:\n                    break\n            pi.train_net(tape)\n        del tape\n        if n_epi % print_interval == 0 and n_epi != 0:\n            returns.append(score / print_interval)\n            print(f'# of episode :{n_epi}, avg score : {score / print_interval}')\n            score = 0.0\n    env.close()\n    plt.plot(np.arange(len(returns)) * print_interval, returns)\n    plt.plot(np.arange(len(returns)) * print_interval, returns, 's')\n    plt.xlabel('\u56de\u5408\u6570')\n    plt.ylabel('\u603b\u56de\u62a5')\n    plt.savefig('reinforce-tf-cartpole.svg')"
        ]
    }
]