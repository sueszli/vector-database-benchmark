[
    {
        "func_name": "__init__",
        "original": "def __init__(self, in_channels, num_classes=3, extra_width=0.2, seg_score_thr=0.3, init_cfg=None, loss_seg=dict(type='FocalLoss', use_sigmoid=True, reduction='sum', gamma=2.0, alpha=0.25, loss_weight=1.0), loss_part=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)):\n    super(PointwiseSemanticHead, self).__init__(init_cfg=init_cfg)\n    self.extra_width = extra_width\n    self.num_classes = num_classes\n    self.seg_score_thr = seg_score_thr\n    self.seg_cls_layer = nn.Linear(in_channels, 1, bias=True)\n    self.seg_reg_layer = nn.Linear(in_channels, 3, bias=True)\n    self.loss_seg = build_loss(loss_seg)\n    self.loss_part = build_loss(loss_part)",
        "mutated": [
            "def __init__(self, in_channels, num_classes=3, extra_width=0.2, seg_score_thr=0.3, init_cfg=None, loss_seg=dict(type='FocalLoss', use_sigmoid=True, reduction='sum', gamma=2.0, alpha=0.25, loss_weight=1.0), loss_part=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)):\n    if False:\n        i = 10\n    super(PointwiseSemanticHead, self).__init__(init_cfg=init_cfg)\n    self.extra_width = extra_width\n    self.num_classes = num_classes\n    self.seg_score_thr = seg_score_thr\n    self.seg_cls_layer = nn.Linear(in_channels, 1, bias=True)\n    self.seg_reg_layer = nn.Linear(in_channels, 3, bias=True)\n    self.loss_seg = build_loss(loss_seg)\n    self.loss_part = build_loss(loss_part)",
            "def __init__(self, in_channels, num_classes=3, extra_width=0.2, seg_score_thr=0.3, init_cfg=None, loss_seg=dict(type='FocalLoss', use_sigmoid=True, reduction='sum', gamma=2.0, alpha=0.25, loss_weight=1.0), loss_part=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super(PointwiseSemanticHead, self).__init__(init_cfg=init_cfg)\n    self.extra_width = extra_width\n    self.num_classes = num_classes\n    self.seg_score_thr = seg_score_thr\n    self.seg_cls_layer = nn.Linear(in_channels, 1, bias=True)\n    self.seg_reg_layer = nn.Linear(in_channels, 3, bias=True)\n    self.loss_seg = build_loss(loss_seg)\n    self.loss_part = build_loss(loss_part)",
            "def __init__(self, in_channels, num_classes=3, extra_width=0.2, seg_score_thr=0.3, init_cfg=None, loss_seg=dict(type='FocalLoss', use_sigmoid=True, reduction='sum', gamma=2.0, alpha=0.25, loss_weight=1.0), loss_part=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super(PointwiseSemanticHead, self).__init__(init_cfg=init_cfg)\n    self.extra_width = extra_width\n    self.num_classes = num_classes\n    self.seg_score_thr = seg_score_thr\n    self.seg_cls_layer = nn.Linear(in_channels, 1, bias=True)\n    self.seg_reg_layer = nn.Linear(in_channels, 3, bias=True)\n    self.loss_seg = build_loss(loss_seg)\n    self.loss_part = build_loss(loss_part)",
            "def __init__(self, in_channels, num_classes=3, extra_width=0.2, seg_score_thr=0.3, init_cfg=None, loss_seg=dict(type='FocalLoss', use_sigmoid=True, reduction='sum', gamma=2.0, alpha=0.25, loss_weight=1.0), loss_part=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super(PointwiseSemanticHead, self).__init__(init_cfg=init_cfg)\n    self.extra_width = extra_width\n    self.num_classes = num_classes\n    self.seg_score_thr = seg_score_thr\n    self.seg_cls_layer = nn.Linear(in_channels, 1, bias=True)\n    self.seg_reg_layer = nn.Linear(in_channels, 3, bias=True)\n    self.loss_seg = build_loss(loss_seg)\n    self.loss_part = build_loss(loss_part)",
            "def __init__(self, in_channels, num_classes=3, extra_width=0.2, seg_score_thr=0.3, init_cfg=None, loss_seg=dict(type='FocalLoss', use_sigmoid=True, reduction='sum', gamma=2.0, alpha=0.25, loss_weight=1.0), loss_part=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super(PointwiseSemanticHead, self).__init__(init_cfg=init_cfg)\n    self.extra_width = extra_width\n    self.num_classes = num_classes\n    self.seg_score_thr = seg_score_thr\n    self.seg_cls_layer = nn.Linear(in_channels, 1, bias=True)\n    self.seg_reg_layer = nn.Linear(in_channels, 3, bias=True)\n    self.loss_seg = build_loss(loss_seg)\n    self.loss_part = build_loss(loss_part)"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, x):\n    \"\"\"Forward pass.\n\n        Args:\n            x (torch.Tensor): Features from the first stage.\n\n        Returns:\n            dict: Part features, segmentation and part predictions.\n\n                - seg_preds (torch.Tensor): Segment predictions.\n                - part_preds (torch.Tensor): Part predictions.\n                - part_feats (torch.Tensor): Feature predictions.\n        \"\"\"\n    seg_preds = self.seg_cls_layer(x)\n    part_preds = self.seg_reg_layer(x)\n    seg_scores = torch.sigmoid(seg_preds).detach()\n    seg_mask = seg_scores > self.seg_score_thr\n    part_offsets = torch.sigmoid(part_preds).clone().detach()\n    part_offsets[seg_mask.view(-1) == 0] = 0\n    part_feats = torch.cat((part_offsets, seg_scores), dim=-1)\n    return dict(seg_preds=seg_preds, part_preds=part_preds, part_feats=part_feats)",
        "mutated": [
            "def forward(self, x):\n    if False:\n        i = 10\n    'Forward pass.\\n\\n        Args:\\n            x (torch.Tensor): Features from the first stage.\\n\\n        Returns:\\n            dict: Part features, segmentation and part predictions.\\n\\n                - seg_preds (torch.Tensor): Segment predictions.\\n                - part_preds (torch.Tensor): Part predictions.\\n                - part_feats (torch.Tensor): Feature predictions.\\n        '\n    seg_preds = self.seg_cls_layer(x)\n    part_preds = self.seg_reg_layer(x)\n    seg_scores = torch.sigmoid(seg_preds).detach()\n    seg_mask = seg_scores > self.seg_score_thr\n    part_offsets = torch.sigmoid(part_preds).clone().detach()\n    part_offsets[seg_mask.view(-1) == 0] = 0\n    part_feats = torch.cat((part_offsets, seg_scores), dim=-1)\n    return dict(seg_preds=seg_preds, part_preds=part_preds, part_feats=part_feats)",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Forward pass.\\n\\n        Args:\\n            x (torch.Tensor): Features from the first stage.\\n\\n        Returns:\\n            dict: Part features, segmentation and part predictions.\\n\\n                - seg_preds (torch.Tensor): Segment predictions.\\n                - part_preds (torch.Tensor): Part predictions.\\n                - part_feats (torch.Tensor): Feature predictions.\\n        '\n    seg_preds = self.seg_cls_layer(x)\n    part_preds = self.seg_reg_layer(x)\n    seg_scores = torch.sigmoid(seg_preds).detach()\n    seg_mask = seg_scores > self.seg_score_thr\n    part_offsets = torch.sigmoid(part_preds).clone().detach()\n    part_offsets[seg_mask.view(-1) == 0] = 0\n    part_feats = torch.cat((part_offsets, seg_scores), dim=-1)\n    return dict(seg_preds=seg_preds, part_preds=part_preds, part_feats=part_feats)",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Forward pass.\\n\\n        Args:\\n            x (torch.Tensor): Features from the first stage.\\n\\n        Returns:\\n            dict: Part features, segmentation and part predictions.\\n\\n                - seg_preds (torch.Tensor): Segment predictions.\\n                - part_preds (torch.Tensor): Part predictions.\\n                - part_feats (torch.Tensor): Feature predictions.\\n        '\n    seg_preds = self.seg_cls_layer(x)\n    part_preds = self.seg_reg_layer(x)\n    seg_scores = torch.sigmoid(seg_preds).detach()\n    seg_mask = seg_scores > self.seg_score_thr\n    part_offsets = torch.sigmoid(part_preds).clone().detach()\n    part_offsets[seg_mask.view(-1) == 0] = 0\n    part_feats = torch.cat((part_offsets, seg_scores), dim=-1)\n    return dict(seg_preds=seg_preds, part_preds=part_preds, part_feats=part_feats)",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Forward pass.\\n\\n        Args:\\n            x (torch.Tensor): Features from the first stage.\\n\\n        Returns:\\n            dict: Part features, segmentation and part predictions.\\n\\n                - seg_preds (torch.Tensor): Segment predictions.\\n                - part_preds (torch.Tensor): Part predictions.\\n                - part_feats (torch.Tensor): Feature predictions.\\n        '\n    seg_preds = self.seg_cls_layer(x)\n    part_preds = self.seg_reg_layer(x)\n    seg_scores = torch.sigmoid(seg_preds).detach()\n    seg_mask = seg_scores > self.seg_score_thr\n    part_offsets = torch.sigmoid(part_preds).clone().detach()\n    part_offsets[seg_mask.view(-1) == 0] = 0\n    part_feats = torch.cat((part_offsets, seg_scores), dim=-1)\n    return dict(seg_preds=seg_preds, part_preds=part_preds, part_feats=part_feats)",
            "def forward(self, x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Forward pass.\\n\\n        Args:\\n            x (torch.Tensor): Features from the first stage.\\n\\n        Returns:\\n            dict: Part features, segmentation and part predictions.\\n\\n                - seg_preds (torch.Tensor): Segment predictions.\\n                - part_preds (torch.Tensor): Part predictions.\\n                - part_feats (torch.Tensor): Feature predictions.\\n        '\n    seg_preds = self.seg_cls_layer(x)\n    part_preds = self.seg_reg_layer(x)\n    seg_scores = torch.sigmoid(seg_preds).detach()\n    seg_mask = seg_scores > self.seg_score_thr\n    part_offsets = torch.sigmoid(part_preds).clone().detach()\n    part_offsets[seg_mask.view(-1) == 0] = 0\n    part_feats = torch.cat((part_offsets, seg_scores), dim=-1)\n    return dict(seg_preds=seg_preds, part_preds=part_preds, part_feats=part_feats)"
        ]
    },
    {
        "func_name": "get_targets_single",
        "original": "def get_targets_single(self, voxel_centers, gt_bboxes_3d, gt_labels_3d):\n    \"\"\"generate segmentation and part prediction targets for a single\n        sample.\n\n        Args:\n            voxel_centers (torch.Tensor): The center of voxels in shape\n                (voxel_num, 3).\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth boxes in\n                shape (box_num, 7).\n            gt_labels_3d (torch.Tensor): Class labels of ground truths in\n                shape (box_num).\n\n        Returns:\n            tuple[torch.Tensor]: Segmentation targets with shape [voxel_num]\n                part prediction targets with shape [voxel_num, 3]\n        \"\"\"\n    gt_bboxes_3d = gt_bboxes_3d.to(voxel_centers.device)\n    enlarged_gt_boxes = gt_bboxes_3d.enlarged_box(self.extra_width)\n    part_targets = voxel_centers.new_zeros((voxel_centers.shape[0], 3), dtype=torch.float32)\n    box_idx = gt_bboxes_3d.points_in_boxes_part(voxel_centers)\n    enlarge_box_idx = enlarged_gt_boxes.points_in_boxes_part(voxel_centers).long()\n    gt_labels_pad = F.pad(gt_labels_3d, (1, 0), mode='constant', value=self.num_classes)\n    seg_targets = gt_labels_pad[box_idx.long() + 1]\n    fg_pt_flag = box_idx > -1\n    ignore_flag = fg_pt_flag ^ (enlarge_box_idx > -1)\n    seg_targets[ignore_flag] = -1\n    for k in range(len(gt_bboxes_3d)):\n        k_box_flag = box_idx == k\n        if not k_box_flag.any():\n            continue\n        fg_voxels = voxel_centers[k_box_flag]\n        transformed_voxels = fg_voxels - gt_bboxes_3d.bottom_center[k]\n        transformed_voxels = rotation_3d_in_axis(transformed_voxels.unsqueeze(0), -gt_bboxes_3d.yaw[k].view(1), axis=2)\n        part_targets[k_box_flag] = transformed_voxels / gt_bboxes_3d.dims[k] + voxel_centers.new_tensor([0.5, 0.5, 0])\n    part_targets = torch.clamp(part_targets, min=0)\n    return (seg_targets, part_targets)",
        "mutated": [
            "def get_targets_single(self, voxel_centers, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n    'generate segmentation and part prediction targets for a single\\n        sample.\\n\\n        Args:\\n            voxel_centers (torch.Tensor): The center of voxels in shape\\n                (voxel_num, 3).\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth boxes in\\n                shape (box_num, 7).\\n            gt_labels_3d (torch.Tensor): Class labels of ground truths in\\n                shape (box_num).\\n\\n        Returns:\\n            tuple[torch.Tensor]: Segmentation targets with shape [voxel_num]\\n                part prediction targets with shape [voxel_num, 3]\\n        '\n    gt_bboxes_3d = gt_bboxes_3d.to(voxel_centers.device)\n    enlarged_gt_boxes = gt_bboxes_3d.enlarged_box(self.extra_width)\n    part_targets = voxel_centers.new_zeros((voxel_centers.shape[0], 3), dtype=torch.float32)\n    box_idx = gt_bboxes_3d.points_in_boxes_part(voxel_centers)\n    enlarge_box_idx = enlarged_gt_boxes.points_in_boxes_part(voxel_centers).long()\n    gt_labels_pad = F.pad(gt_labels_3d, (1, 0), mode='constant', value=self.num_classes)\n    seg_targets = gt_labels_pad[box_idx.long() + 1]\n    fg_pt_flag = box_idx > -1\n    ignore_flag = fg_pt_flag ^ (enlarge_box_idx > -1)\n    seg_targets[ignore_flag] = -1\n    for k in range(len(gt_bboxes_3d)):\n        k_box_flag = box_idx == k\n        if not k_box_flag.any():\n            continue\n        fg_voxels = voxel_centers[k_box_flag]\n        transformed_voxels = fg_voxels - gt_bboxes_3d.bottom_center[k]\n        transformed_voxels = rotation_3d_in_axis(transformed_voxels.unsqueeze(0), -gt_bboxes_3d.yaw[k].view(1), axis=2)\n        part_targets[k_box_flag] = transformed_voxels / gt_bboxes_3d.dims[k] + voxel_centers.new_tensor([0.5, 0.5, 0])\n    part_targets = torch.clamp(part_targets, min=0)\n    return (seg_targets, part_targets)",
            "def get_targets_single(self, voxel_centers, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'generate segmentation and part prediction targets for a single\\n        sample.\\n\\n        Args:\\n            voxel_centers (torch.Tensor): The center of voxels in shape\\n                (voxel_num, 3).\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth boxes in\\n                shape (box_num, 7).\\n            gt_labels_3d (torch.Tensor): Class labels of ground truths in\\n                shape (box_num).\\n\\n        Returns:\\n            tuple[torch.Tensor]: Segmentation targets with shape [voxel_num]\\n                part prediction targets with shape [voxel_num, 3]\\n        '\n    gt_bboxes_3d = gt_bboxes_3d.to(voxel_centers.device)\n    enlarged_gt_boxes = gt_bboxes_3d.enlarged_box(self.extra_width)\n    part_targets = voxel_centers.new_zeros((voxel_centers.shape[0], 3), dtype=torch.float32)\n    box_idx = gt_bboxes_3d.points_in_boxes_part(voxel_centers)\n    enlarge_box_idx = enlarged_gt_boxes.points_in_boxes_part(voxel_centers).long()\n    gt_labels_pad = F.pad(gt_labels_3d, (1, 0), mode='constant', value=self.num_classes)\n    seg_targets = gt_labels_pad[box_idx.long() + 1]\n    fg_pt_flag = box_idx > -1\n    ignore_flag = fg_pt_flag ^ (enlarge_box_idx > -1)\n    seg_targets[ignore_flag] = -1\n    for k in range(len(gt_bboxes_3d)):\n        k_box_flag = box_idx == k\n        if not k_box_flag.any():\n            continue\n        fg_voxels = voxel_centers[k_box_flag]\n        transformed_voxels = fg_voxels - gt_bboxes_3d.bottom_center[k]\n        transformed_voxels = rotation_3d_in_axis(transformed_voxels.unsqueeze(0), -gt_bboxes_3d.yaw[k].view(1), axis=2)\n        part_targets[k_box_flag] = transformed_voxels / gt_bboxes_3d.dims[k] + voxel_centers.new_tensor([0.5, 0.5, 0])\n    part_targets = torch.clamp(part_targets, min=0)\n    return (seg_targets, part_targets)",
            "def get_targets_single(self, voxel_centers, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'generate segmentation and part prediction targets for a single\\n        sample.\\n\\n        Args:\\n            voxel_centers (torch.Tensor): The center of voxels in shape\\n                (voxel_num, 3).\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth boxes in\\n                shape (box_num, 7).\\n            gt_labels_3d (torch.Tensor): Class labels of ground truths in\\n                shape (box_num).\\n\\n        Returns:\\n            tuple[torch.Tensor]: Segmentation targets with shape [voxel_num]\\n                part prediction targets with shape [voxel_num, 3]\\n        '\n    gt_bboxes_3d = gt_bboxes_3d.to(voxel_centers.device)\n    enlarged_gt_boxes = gt_bboxes_3d.enlarged_box(self.extra_width)\n    part_targets = voxel_centers.new_zeros((voxel_centers.shape[0], 3), dtype=torch.float32)\n    box_idx = gt_bboxes_3d.points_in_boxes_part(voxel_centers)\n    enlarge_box_idx = enlarged_gt_boxes.points_in_boxes_part(voxel_centers).long()\n    gt_labels_pad = F.pad(gt_labels_3d, (1, 0), mode='constant', value=self.num_classes)\n    seg_targets = gt_labels_pad[box_idx.long() + 1]\n    fg_pt_flag = box_idx > -1\n    ignore_flag = fg_pt_flag ^ (enlarge_box_idx > -1)\n    seg_targets[ignore_flag] = -1\n    for k in range(len(gt_bboxes_3d)):\n        k_box_flag = box_idx == k\n        if not k_box_flag.any():\n            continue\n        fg_voxels = voxel_centers[k_box_flag]\n        transformed_voxels = fg_voxels - gt_bboxes_3d.bottom_center[k]\n        transformed_voxels = rotation_3d_in_axis(transformed_voxels.unsqueeze(0), -gt_bboxes_3d.yaw[k].view(1), axis=2)\n        part_targets[k_box_flag] = transformed_voxels / gt_bboxes_3d.dims[k] + voxel_centers.new_tensor([0.5, 0.5, 0])\n    part_targets = torch.clamp(part_targets, min=0)\n    return (seg_targets, part_targets)",
            "def get_targets_single(self, voxel_centers, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'generate segmentation and part prediction targets for a single\\n        sample.\\n\\n        Args:\\n            voxel_centers (torch.Tensor): The center of voxels in shape\\n                (voxel_num, 3).\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth boxes in\\n                shape (box_num, 7).\\n            gt_labels_3d (torch.Tensor): Class labels of ground truths in\\n                shape (box_num).\\n\\n        Returns:\\n            tuple[torch.Tensor]: Segmentation targets with shape [voxel_num]\\n                part prediction targets with shape [voxel_num, 3]\\n        '\n    gt_bboxes_3d = gt_bboxes_3d.to(voxel_centers.device)\n    enlarged_gt_boxes = gt_bboxes_3d.enlarged_box(self.extra_width)\n    part_targets = voxel_centers.new_zeros((voxel_centers.shape[0], 3), dtype=torch.float32)\n    box_idx = gt_bboxes_3d.points_in_boxes_part(voxel_centers)\n    enlarge_box_idx = enlarged_gt_boxes.points_in_boxes_part(voxel_centers).long()\n    gt_labels_pad = F.pad(gt_labels_3d, (1, 0), mode='constant', value=self.num_classes)\n    seg_targets = gt_labels_pad[box_idx.long() + 1]\n    fg_pt_flag = box_idx > -1\n    ignore_flag = fg_pt_flag ^ (enlarge_box_idx > -1)\n    seg_targets[ignore_flag] = -1\n    for k in range(len(gt_bboxes_3d)):\n        k_box_flag = box_idx == k\n        if not k_box_flag.any():\n            continue\n        fg_voxels = voxel_centers[k_box_flag]\n        transformed_voxels = fg_voxels - gt_bboxes_3d.bottom_center[k]\n        transformed_voxels = rotation_3d_in_axis(transformed_voxels.unsqueeze(0), -gt_bboxes_3d.yaw[k].view(1), axis=2)\n        part_targets[k_box_flag] = transformed_voxels / gt_bboxes_3d.dims[k] + voxel_centers.new_tensor([0.5, 0.5, 0])\n    part_targets = torch.clamp(part_targets, min=0)\n    return (seg_targets, part_targets)",
            "def get_targets_single(self, voxel_centers, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'generate segmentation and part prediction targets for a single\\n        sample.\\n\\n        Args:\\n            voxel_centers (torch.Tensor): The center of voxels in shape\\n                (voxel_num, 3).\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth boxes in\\n                shape (box_num, 7).\\n            gt_labels_3d (torch.Tensor): Class labels of ground truths in\\n                shape (box_num).\\n\\n        Returns:\\n            tuple[torch.Tensor]: Segmentation targets with shape [voxel_num]\\n                part prediction targets with shape [voxel_num, 3]\\n        '\n    gt_bboxes_3d = gt_bboxes_3d.to(voxel_centers.device)\n    enlarged_gt_boxes = gt_bboxes_3d.enlarged_box(self.extra_width)\n    part_targets = voxel_centers.new_zeros((voxel_centers.shape[0], 3), dtype=torch.float32)\n    box_idx = gt_bboxes_3d.points_in_boxes_part(voxel_centers)\n    enlarge_box_idx = enlarged_gt_boxes.points_in_boxes_part(voxel_centers).long()\n    gt_labels_pad = F.pad(gt_labels_3d, (1, 0), mode='constant', value=self.num_classes)\n    seg_targets = gt_labels_pad[box_idx.long() + 1]\n    fg_pt_flag = box_idx > -1\n    ignore_flag = fg_pt_flag ^ (enlarge_box_idx > -1)\n    seg_targets[ignore_flag] = -1\n    for k in range(len(gt_bboxes_3d)):\n        k_box_flag = box_idx == k\n        if not k_box_flag.any():\n            continue\n        fg_voxels = voxel_centers[k_box_flag]\n        transformed_voxels = fg_voxels - gt_bboxes_3d.bottom_center[k]\n        transformed_voxels = rotation_3d_in_axis(transformed_voxels.unsqueeze(0), -gt_bboxes_3d.yaw[k].view(1), axis=2)\n        part_targets[k_box_flag] = transformed_voxels / gt_bboxes_3d.dims[k] + voxel_centers.new_tensor([0.5, 0.5, 0])\n    part_targets = torch.clamp(part_targets, min=0)\n    return (seg_targets, part_targets)"
        ]
    },
    {
        "func_name": "get_targets",
        "original": "def get_targets(self, voxels_dict, gt_bboxes_3d, gt_labels_3d):\n    \"\"\"generate segmentation and part prediction targets.\n\n        Args:\n            voxel_centers (torch.Tensor): The center of voxels in shape\n                (voxel_num, 3).\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth boxes in\n                shape (box_num, 7).\n            gt_labels_3d (torch.Tensor): Class labels of ground truths in\n                shape (box_num).\n\n        Returns:\n            dict: Prediction targets\n\n                - seg_targets (torch.Tensor): Segmentation targets\n                    with shape [voxel_num].\n                - part_targets (torch.Tensor): Part prediction targets\n                    with shape [voxel_num, 3].\n        \"\"\"\n    batch_size = len(gt_labels_3d)\n    voxel_center_list = []\n    for idx in range(batch_size):\n        coords_idx = voxels_dict['coors'][:, 0] == idx\n        voxel_center_list.append(voxels_dict['voxel_centers'][coords_idx])\n    (seg_targets, part_targets) = multi_apply(self.get_targets_single, voxel_center_list, gt_bboxes_3d, gt_labels_3d)\n    seg_targets = torch.cat(seg_targets, dim=0)\n    part_targets = torch.cat(part_targets, dim=0)\n    return dict(seg_targets=seg_targets, part_targets=part_targets)",
        "mutated": [
            "def get_targets(self, voxels_dict, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n    'generate segmentation and part prediction targets.\\n\\n        Args:\\n            voxel_centers (torch.Tensor): The center of voxels in shape\\n                (voxel_num, 3).\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth boxes in\\n                shape (box_num, 7).\\n            gt_labels_3d (torch.Tensor): Class labels of ground truths in\\n                shape (box_num).\\n\\n        Returns:\\n            dict: Prediction targets\\n\\n                - seg_targets (torch.Tensor): Segmentation targets\\n                    with shape [voxel_num].\\n                - part_targets (torch.Tensor): Part prediction targets\\n                    with shape [voxel_num, 3].\\n        '\n    batch_size = len(gt_labels_3d)\n    voxel_center_list = []\n    for idx in range(batch_size):\n        coords_idx = voxels_dict['coors'][:, 0] == idx\n        voxel_center_list.append(voxels_dict['voxel_centers'][coords_idx])\n    (seg_targets, part_targets) = multi_apply(self.get_targets_single, voxel_center_list, gt_bboxes_3d, gt_labels_3d)\n    seg_targets = torch.cat(seg_targets, dim=0)\n    part_targets = torch.cat(part_targets, dim=0)\n    return dict(seg_targets=seg_targets, part_targets=part_targets)",
            "def get_targets(self, voxels_dict, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'generate segmentation and part prediction targets.\\n\\n        Args:\\n            voxel_centers (torch.Tensor): The center of voxels in shape\\n                (voxel_num, 3).\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth boxes in\\n                shape (box_num, 7).\\n            gt_labels_3d (torch.Tensor): Class labels of ground truths in\\n                shape (box_num).\\n\\n        Returns:\\n            dict: Prediction targets\\n\\n                - seg_targets (torch.Tensor): Segmentation targets\\n                    with shape [voxel_num].\\n                - part_targets (torch.Tensor): Part prediction targets\\n                    with shape [voxel_num, 3].\\n        '\n    batch_size = len(gt_labels_3d)\n    voxel_center_list = []\n    for idx in range(batch_size):\n        coords_idx = voxels_dict['coors'][:, 0] == idx\n        voxel_center_list.append(voxels_dict['voxel_centers'][coords_idx])\n    (seg_targets, part_targets) = multi_apply(self.get_targets_single, voxel_center_list, gt_bboxes_3d, gt_labels_3d)\n    seg_targets = torch.cat(seg_targets, dim=0)\n    part_targets = torch.cat(part_targets, dim=0)\n    return dict(seg_targets=seg_targets, part_targets=part_targets)",
            "def get_targets(self, voxels_dict, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'generate segmentation and part prediction targets.\\n\\n        Args:\\n            voxel_centers (torch.Tensor): The center of voxels in shape\\n                (voxel_num, 3).\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth boxes in\\n                shape (box_num, 7).\\n            gt_labels_3d (torch.Tensor): Class labels of ground truths in\\n                shape (box_num).\\n\\n        Returns:\\n            dict: Prediction targets\\n\\n                - seg_targets (torch.Tensor): Segmentation targets\\n                    with shape [voxel_num].\\n                - part_targets (torch.Tensor): Part prediction targets\\n                    with shape [voxel_num, 3].\\n        '\n    batch_size = len(gt_labels_3d)\n    voxel_center_list = []\n    for idx in range(batch_size):\n        coords_idx = voxels_dict['coors'][:, 0] == idx\n        voxel_center_list.append(voxels_dict['voxel_centers'][coords_idx])\n    (seg_targets, part_targets) = multi_apply(self.get_targets_single, voxel_center_list, gt_bboxes_3d, gt_labels_3d)\n    seg_targets = torch.cat(seg_targets, dim=0)\n    part_targets = torch.cat(part_targets, dim=0)\n    return dict(seg_targets=seg_targets, part_targets=part_targets)",
            "def get_targets(self, voxels_dict, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'generate segmentation and part prediction targets.\\n\\n        Args:\\n            voxel_centers (torch.Tensor): The center of voxels in shape\\n                (voxel_num, 3).\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth boxes in\\n                shape (box_num, 7).\\n            gt_labels_3d (torch.Tensor): Class labels of ground truths in\\n                shape (box_num).\\n\\n        Returns:\\n            dict: Prediction targets\\n\\n                - seg_targets (torch.Tensor): Segmentation targets\\n                    with shape [voxel_num].\\n                - part_targets (torch.Tensor): Part prediction targets\\n                    with shape [voxel_num, 3].\\n        '\n    batch_size = len(gt_labels_3d)\n    voxel_center_list = []\n    for idx in range(batch_size):\n        coords_idx = voxels_dict['coors'][:, 0] == idx\n        voxel_center_list.append(voxels_dict['voxel_centers'][coords_idx])\n    (seg_targets, part_targets) = multi_apply(self.get_targets_single, voxel_center_list, gt_bboxes_3d, gt_labels_3d)\n    seg_targets = torch.cat(seg_targets, dim=0)\n    part_targets = torch.cat(part_targets, dim=0)\n    return dict(seg_targets=seg_targets, part_targets=part_targets)",
            "def get_targets(self, voxels_dict, gt_bboxes_3d, gt_labels_3d):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'generate segmentation and part prediction targets.\\n\\n        Args:\\n            voxel_centers (torch.Tensor): The center of voxels in shape\\n                (voxel_num, 3).\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth boxes in\\n                shape (box_num, 7).\\n            gt_labels_3d (torch.Tensor): Class labels of ground truths in\\n                shape (box_num).\\n\\n        Returns:\\n            dict: Prediction targets\\n\\n                - seg_targets (torch.Tensor): Segmentation targets\\n                    with shape [voxel_num].\\n                - part_targets (torch.Tensor): Part prediction targets\\n                    with shape [voxel_num, 3].\\n        '\n    batch_size = len(gt_labels_3d)\n    voxel_center_list = []\n    for idx in range(batch_size):\n        coords_idx = voxels_dict['coors'][:, 0] == idx\n        voxel_center_list.append(voxels_dict['voxel_centers'][coords_idx])\n    (seg_targets, part_targets) = multi_apply(self.get_targets_single, voxel_center_list, gt_bboxes_3d, gt_labels_3d)\n    seg_targets = torch.cat(seg_targets, dim=0)\n    part_targets = torch.cat(part_targets, dim=0)\n    return dict(seg_targets=seg_targets, part_targets=part_targets)"
        ]
    },
    {
        "func_name": "loss",
        "original": "def loss(self, semantic_results, semantic_targets):\n    \"\"\"Calculate point-wise segmentation and part prediction losses.\n\n        Args:\n            semantic_results (dict): Results from semantic head.\n\n                - seg_preds: Segmentation predictions.\n                - part_preds: Part predictions.\n\n            semantic_targets (dict): Targets of semantic results.\n\n                - seg_preds: Segmentation targets.\n                - part_preds: Part targets.\n\n        Returns:\n            dict: Loss of segmentation and part prediction.\n\n                - loss_seg (torch.Tensor): Segmentation prediction loss.\n                - loss_part (torch.Tensor): Part prediction loss.\n        \"\"\"\n    seg_preds = semantic_results['seg_preds']\n    part_preds = semantic_results['part_preds']\n    seg_targets = semantic_targets['seg_targets']\n    part_targets = semantic_targets['part_targets']\n    pos_mask = (seg_targets > -1) & (seg_targets < self.num_classes)\n    binary_seg_target = pos_mask.long()\n    pos = pos_mask.float()\n    neg = (seg_targets == self.num_classes).float()\n    seg_weights = pos + neg\n    pos_normalizer = pos.sum()\n    seg_weights = seg_weights / torch.clamp(pos_normalizer, min=1.0)\n    loss_seg = self.loss_seg(seg_preds, binary_seg_target, seg_weights)\n    if pos_normalizer > 0:\n        loss_part = self.loss_part(part_preds[pos_mask], part_targets[pos_mask])\n    else:\n        loss_part = loss_seg.new_tensor(0)\n    return dict(loss_seg=loss_seg, loss_part=loss_part)",
        "mutated": [
            "def loss(self, semantic_results, semantic_targets):\n    if False:\n        i = 10\n    'Calculate point-wise segmentation and part prediction losses.\\n\\n        Args:\\n            semantic_results (dict): Results from semantic head.\\n\\n                - seg_preds: Segmentation predictions.\\n                - part_preds: Part predictions.\\n\\n            semantic_targets (dict): Targets of semantic results.\\n\\n                - seg_preds: Segmentation targets.\\n                - part_preds: Part targets.\\n\\n        Returns:\\n            dict: Loss of segmentation and part prediction.\\n\\n                - loss_seg (torch.Tensor): Segmentation prediction loss.\\n                - loss_part (torch.Tensor): Part prediction loss.\\n        '\n    seg_preds = semantic_results['seg_preds']\n    part_preds = semantic_results['part_preds']\n    seg_targets = semantic_targets['seg_targets']\n    part_targets = semantic_targets['part_targets']\n    pos_mask = (seg_targets > -1) & (seg_targets < self.num_classes)\n    binary_seg_target = pos_mask.long()\n    pos = pos_mask.float()\n    neg = (seg_targets == self.num_classes).float()\n    seg_weights = pos + neg\n    pos_normalizer = pos.sum()\n    seg_weights = seg_weights / torch.clamp(pos_normalizer, min=1.0)\n    loss_seg = self.loss_seg(seg_preds, binary_seg_target, seg_weights)\n    if pos_normalizer > 0:\n        loss_part = self.loss_part(part_preds[pos_mask], part_targets[pos_mask])\n    else:\n        loss_part = loss_seg.new_tensor(0)\n    return dict(loss_seg=loss_seg, loss_part=loss_part)",
            "def loss(self, semantic_results, semantic_targets):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Calculate point-wise segmentation and part prediction losses.\\n\\n        Args:\\n            semantic_results (dict): Results from semantic head.\\n\\n                - seg_preds: Segmentation predictions.\\n                - part_preds: Part predictions.\\n\\n            semantic_targets (dict): Targets of semantic results.\\n\\n                - seg_preds: Segmentation targets.\\n                - part_preds: Part targets.\\n\\n        Returns:\\n            dict: Loss of segmentation and part prediction.\\n\\n                - loss_seg (torch.Tensor): Segmentation prediction loss.\\n                - loss_part (torch.Tensor): Part prediction loss.\\n        '\n    seg_preds = semantic_results['seg_preds']\n    part_preds = semantic_results['part_preds']\n    seg_targets = semantic_targets['seg_targets']\n    part_targets = semantic_targets['part_targets']\n    pos_mask = (seg_targets > -1) & (seg_targets < self.num_classes)\n    binary_seg_target = pos_mask.long()\n    pos = pos_mask.float()\n    neg = (seg_targets == self.num_classes).float()\n    seg_weights = pos + neg\n    pos_normalizer = pos.sum()\n    seg_weights = seg_weights / torch.clamp(pos_normalizer, min=1.0)\n    loss_seg = self.loss_seg(seg_preds, binary_seg_target, seg_weights)\n    if pos_normalizer > 0:\n        loss_part = self.loss_part(part_preds[pos_mask], part_targets[pos_mask])\n    else:\n        loss_part = loss_seg.new_tensor(0)\n    return dict(loss_seg=loss_seg, loss_part=loss_part)",
            "def loss(self, semantic_results, semantic_targets):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Calculate point-wise segmentation and part prediction losses.\\n\\n        Args:\\n            semantic_results (dict): Results from semantic head.\\n\\n                - seg_preds: Segmentation predictions.\\n                - part_preds: Part predictions.\\n\\n            semantic_targets (dict): Targets of semantic results.\\n\\n                - seg_preds: Segmentation targets.\\n                - part_preds: Part targets.\\n\\n        Returns:\\n            dict: Loss of segmentation and part prediction.\\n\\n                - loss_seg (torch.Tensor): Segmentation prediction loss.\\n                - loss_part (torch.Tensor): Part prediction loss.\\n        '\n    seg_preds = semantic_results['seg_preds']\n    part_preds = semantic_results['part_preds']\n    seg_targets = semantic_targets['seg_targets']\n    part_targets = semantic_targets['part_targets']\n    pos_mask = (seg_targets > -1) & (seg_targets < self.num_classes)\n    binary_seg_target = pos_mask.long()\n    pos = pos_mask.float()\n    neg = (seg_targets == self.num_classes).float()\n    seg_weights = pos + neg\n    pos_normalizer = pos.sum()\n    seg_weights = seg_weights / torch.clamp(pos_normalizer, min=1.0)\n    loss_seg = self.loss_seg(seg_preds, binary_seg_target, seg_weights)\n    if pos_normalizer > 0:\n        loss_part = self.loss_part(part_preds[pos_mask], part_targets[pos_mask])\n    else:\n        loss_part = loss_seg.new_tensor(0)\n    return dict(loss_seg=loss_seg, loss_part=loss_part)",
            "def loss(self, semantic_results, semantic_targets):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Calculate point-wise segmentation and part prediction losses.\\n\\n        Args:\\n            semantic_results (dict): Results from semantic head.\\n\\n                - seg_preds: Segmentation predictions.\\n                - part_preds: Part predictions.\\n\\n            semantic_targets (dict): Targets of semantic results.\\n\\n                - seg_preds: Segmentation targets.\\n                - part_preds: Part targets.\\n\\n        Returns:\\n            dict: Loss of segmentation and part prediction.\\n\\n                - loss_seg (torch.Tensor): Segmentation prediction loss.\\n                - loss_part (torch.Tensor): Part prediction loss.\\n        '\n    seg_preds = semantic_results['seg_preds']\n    part_preds = semantic_results['part_preds']\n    seg_targets = semantic_targets['seg_targets']\n    part_targets = semantic_targets['part_targets']\n    pos_mask = (seg_targets > -1) & (seg_targets < self.num_classes)\n    binary_seg_target = pos_mask.long()\n    pos = pos_mask.float()\n    neg = (seg_targets == self.num_classes).float()\n    seg_weights = pos + neg\n    pos_normalizer = pos.sum()\n    seg_weights = seg_weights / torch.clamp(pos_normalizer, min=1.0)\n    loss_seg = self.loss_seg(seg_preds, binary_seg_target, seg_weights)\n    if pos_normalizer > 0:\n        loss_part = self.loss_part(part_preds[pos_mask], part_targets[pos_mask])\n    else:\n        loss_part = loss_seg.new_tensor(0)\n    return dict(loss_seg=loss_seg, loss_part=loss_part)",
            "def loss(self, semantic_results, semantic_targets):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Calculate point-wise segmentation and part prediction losses.\\n\\n        Args:\\n            semantic_results (dict): Results from semantic head.\\n\\n                - seg_preds: Segmentation predictions.\\n                - part_preds: Part predictions.\\n\\n            semantic_targets (dict): Targets of semantic results.\\n\\n                - seg_preds: Segmentation targets.\\n                - part_preds: Part targets.\\n\\n        Returns:\\n            dict: Loss of segmentation and part prediction.\\n\\n                - loss_seg (torch.Tensor): Segmentation prediction loss.\\n                - loss_part (torch.Tensor): Part prediction loss.\\n        '\n    seg_preds = semantic_results['seg_preds']\n    part_preds = semantic_results['part_preds']\n    seg_targets = semantic_targets['seg_targets']\n    part_targets = semantic_targets['part_targets']\n    pos_mask = (seg_targets > -1) & (seg_targets < self.num_classes)\n    binary_seg_target = pos_mask.long()\n    pos = pos_mask.float()\n    neg = (seg_targets == self.num_classes).float()\n    seg_weights = pos + neg\n    pos_normalizer = pos.sum()\n    seg_weights = seg_weights / torch.clamp(pos_normalizer, min=1.0)\n    loss_seg = self.loss_seg(seg_preds, binary_seg_target, seg_weights)\n    if pos_normalizer > 0:\n        loss_part = self.loss_part(part_preds[pos_mask], part_targets[pos_mask])\n    else:\n        loss_part = loss_seg.new_tensor(0)\n    return dict(loss_seg=loss_seg, loss_part=loss_part)"
        ]
    }
]