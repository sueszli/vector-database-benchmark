[
    {
        "func_name": "load_data",
        "original": "def load_data(data_format: str='Dataset', as_train_test: bool=True) -> t.Union[t.Tuple, t.Union[Dataset, pd.DataFrame]]:\n    \"\"\"Load and returns part of the Lending club dataset (classification).\n\n    Parameters\n    ----------\n    data_format : str, default: 'Dataset'\n        Represent the format of the returned value. Can be 'Dataset'|'Dataframe'\n        'Dataset' will return the data as a Dataset object\n        'Dataframe' will return the data as a pandas Dataframe object\n\n    as_train_test : bool, default: True\n        If True, the returned data is splitted into train and test exactly like the toy model\n        was trained. The first return value is the train data and the second is the test data.\n        In order to get this model, call the load_fitted_model() function.\n        Otherwise, returns a single object.\n\n    Returns\n    -------\n    dataset : Union[deepchecks.Dataset, pd.DataFrame]\n        the data object, corresponding to the data_format attribute.\n    train, test : Tuple[Union[deepchecks.Dataset, pd.DataFrame],Union[deepchecks.Dataset, pd.DataFrame]\n        tuple if as_train_test = True. Tuple of two objects represents the dataset splitted to train and test sets.\n    \"\"\"\n    if not as_train_test:\n        dataset = pd.read_csv(_FULL_DATA_URL, index_col=False)\n        if data_format == 'Dataset':\n            dataset = Dataset(dataset, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            return dataset\n        elif data_format == 'Dataframe':\n            return dataset\n        else:\n            raise ValueError('data_format must be either \"Dataset\" or \"Dataframe\"')\n    else:\n        train = pd.read_csv(_TRAIN_DATA_URL, index_col=False)\n        test = pd.read_csv(_TEST_DATA_URL, index_col=False)\n        if data_format == 'Dataset':\n            train = Dataset(train, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            test = Dataset(test, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            return (train, test)\n        elif data_format == 'Dataframe':\n            return (train, test)\n        else:\n            raise ValueError('data_format must be either \"Dataset\" or \"Dataframe\"')",
        "mutated": [
            "def load_data(data_format: str='Dataset', as_train_test: bool=True) -> t.Union[t.Tuple, t.Union[Dataset, pd.DataFrame]]:\n    if False:\n        i = 10\n    \"Load and returns part of the Lending club dataset (classification).\\n\\n    Parameters\\n    ----------\\n    data_format : str, default: 'Dataset'\\n        Represent the format of the returned value. Can be 'Dataset'|'Dataframe'\\n        'Dataset' will return the data as a Dataset object\\n        'Dataframe' will return the data as a pandas Dataframe object\\n\\n    as_train_test : bool, default: True\\n        If True, the returned data is splitted into train and test exactly like the toy model\\n        was trained. The first return value is the train data and the second is the test data.\\n        In order to get this model, call the load_fitted_model() function.\\n        Otherwise, returns a single object.\\n\\n    Returns\\n    -------\\n    dataset : Union[deepchecks.Dataset, pd.DataFrame]\\n        the data object, corresponding to the data_format attribute.\\n    train, test : Tuple[Union[deepchecks.Dataset, pd.DataFrame],Union[deepchecks.Dataset, pd.DataFrame]\\n        tuple if as_train_test = True. Tuple of two objects represents the dataset splitted to train and test sets.\\n    \"\n    if not as_train_test:\n        dataset = pd.read_csv(_FULL_DATA_URL, index_col=False)\n        if data_format == 'Dataset':\n            dataset = Dataset(dataset, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            return dataset\n        elif data_format == 'Dataframe':\n            return dataset\n        else:\n            raise ValueError('data_format must be either \"Dataset\" or \"Dataframe\"')\n    else:\n        train = pd.read_csv(_TRAIN_DATA_URL, index_col=False)\n        test = pd.read_csv(_TEST_DATA_URL, index_col=False)\n        if data_format == 'Dataset':\n            train = Dataset(train, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            test = Dataset(test, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            return (train, test)\n        elif data_format == 'Dataframe':\n            return (train, test)\n        else:\n            raise ValueError('data_format must be either \"Dataset\" or \"Dataframe\"')",
            "def load_data(data_format: str='Dataset', as_train_test: bool=True) -> t.Union[t.Tuple, t.Union[Dataset, pd.DataFrame]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Load and returns part of the Lending club dataset (classification).\\n\\n    Parameters\\n    ----------\\n    data_format : str, default: 'Dataset'\\n        Represent the format of the returned value. Can be 'Dataset'|'Dataframe'\\n        'Dataset' will return the data as a Dataset object\\n        'Dataframe' will return the data as a pandas Dataframe object\\n\\n    as_train_test : bool, default: True\\n        If True, the returned data is splitted into train and test exactly like the toy model\\n        was trained. The first return value is the train data and the second is the test data.\\n        In order to get this model, call the load_fitted_model() function.\\n        Otherwise, returns a single object.\\n\\n    Returns\\n    -------\\n    dataset : Union[deepchecks.Dataset, pd.DataFrame]\\n        the data object, corresponding to the data_format attribute.\\n    train, test : Tuple[Union[deepchecks.Dataset, pd.DataFrame],Union[deepchecks.Dataset, pd.DataFrame]\\n        tuple if as_train_test = True. Tuple of two objects represents the dataset splitted to train and test sets.\\n    \"\n    if not as_train_test:\n        dataset = pd.read_csv(_FULL_DATA_URL, index_col=False)\n        if data_format == 'Dataset':\n            dataset = Dataset(dataset, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            return dataset\n        elif data_format == 'Dataframe':\n            return dataset\n        else:\n            raise ValueError('data_format must be either \"Dataset\" or \"Dataframe\"')\n    else:\n        train = pd.read_csv(_TRAIN_DATA_URL, index_col=False)\n        test = pd.read_csv(_TEST_DATA_URL, index_col=False)\n        if data_format == 'Dataset':\n            train = Dataset(train, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            test = Dataset(test, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            return (train, test)\n        elif data_format == 'Dataframe':\n            return (train, test)\n        else:\n            raise ValueError('data_format must be either \"Dataset\" or \"Dataframe\"')",
            "def load_data(data_format: str='Dataset', as_train_test: bool=True) -> t.Union[t.Tuple, t.Union[Dataset, pd.DataFrame]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Load and returns part of the Lending club dataset (classification).\\n\\n    Parameters\\n    ----------\\n    data_format : str, default: 'Dataset'\\n        Represent the format of the returned value. Can be 'Dataset'|'Dataframe'\\n        'Dataset' will return the data as a Dataset object\\n        'Dataframe' will return the data as a pandas Dataframe object\\n\\n    as_train_test : bool, default: True\\n        If True, the returned data is splitted into train and test exactly like the toy model\\n        was trained. The first return value is the train data and the second is the test data.\\n        In order to get this model, call the load_fitted_model() function.\\n        Otherwise, returns a single object.\\n\\n    Returns\\n    -------\\n    dataset : Union[deepchecks.Dataset, pd.DataFrame]\\n        the data object, corresponding to the data_format attribute.\\n    train, test : Tuple[Union[deepchecks.Dataset, pd.DataFrame],Union[deepchecks.Dataset, pd.DataFrame]\\n        tuple if as_train_test = True. Tuple of two objects represents the dataset splitted to train and test sets.\\n    \"\n    if not as_train_test:\n        dataset = pd.read_csv(_FULL_DATA_URL, index_col=False)\n        if data_format == 'Dataset':\n            dataset = Dataset(dataset, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            return dataset\n        elif data_format == 'Dataframe':\n            return dataset\n        else:\n            raise ValueError('data_format must be either \"Dataset\" or \"Dataframe\"')\n    else:\n        train = pd.read_csv(_TRAIN_DATA_URL, index_col=False)\n        test = pd.read_csv(_TEST_DATA_URL, index_col=False)\n        if data_format == 'Dataset':\n            train = Dataset(train, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            test = Dataset(test, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            return (train, test)\n        elif data_format == 'Dataframe':\n            return (train, test)\n        else:\n            raise ValueError('data_format must be either \"Dataset\" or \"Dataframe\"')",
            "def load_data(data_format: str='Dataset', as_train_test: bool=True) -> t.Union[t.Tuple, t.Union[Dataset, pd.DataFrame]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Load and returns part of the Lending club dataset (classification).\\n\\n    Parameters\\n    ----------\\n    data_format : str, default: 'Dataset'\\n        Represent the format of the returned value. Can be 'Dataset'|'Dataframe'\\n        'Dataset' will return the data as a Dataset object\\n        'Dataframe' will return the data as a pandas Dataframe object\\n\\n    as_train_test : bool, default: True\\n        If True, the returned data is splitted into train and test exactly like the toy model\\n        was trained. The first return value is the train data and the second is the test data.\\n        In order to get this model, call the load_fitted_model() function.\\n        Otherwise, returns a single object.\\n\\n    Returns\\n    -------\\n    dataset : Union[deepchecks.Dataset, pd.DataFrame]\\n        the data object, corresponding to the data_format attribute.\\n    train, test : Tuple[Union[deepchecks.Dataset, pd.DataFrame],Union[deepchecks.Dataset, pd.DataFrame]\\n        tuple if as_train_test = True. Tuple of two objects represents the dataset splitted to train and test sets.\\n    \"\n    if not as_train_test:\n        dataset = pd.read_csv(_FULL_DATA_URL, index_col=False)\n        if data_format == 'Dataset':\n            dataset = Dataset(dataset, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            return dataset\n        elif data_format == 'Dataframe':\n            return dataset\n        else:\n            raise ValueError('data_format must be either \"Dataset\" or \"Dataframe\"')\n    else:\n        train = pd.read_csv(_TRAIN_DATA_URL, index_col=False)\n        test = pd.read_csv(_TEST_DATA_URL, index_col=False)\n        if data_format == 'Dataset':\n            train = Dataset(train, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            test = Dataset(test, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            return (train, test)\n        elif data_format == 'Dataframe':\n            return (train, test)\n        else:\n            raise ValueError('data_format must be either \"Dataset\" or \"Dataframe\"')",
            "def load_data(data_format: str='Dataset', as_train_test: bool=True) -> t.Union[t.Tuple, t.Union[Dataset, pd.DataFrame]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Load and returns part of the Lending club dataset (classification).\\n\\n    Parameters\\n    ----------\\n    data_format : str, default: 'Dataset'\\n        Represent the format of the returned value. Can be 'Dataset'|'Dataframe'\\n        'Dataset' will return the data as a Dataset object\\n        'Dataframe' will return the data as a pandas Dataframe object\\n\\n    as_train_test : bool, default: True\\n        If True, the returned data is splitted into train and test exactly like the toy model\\n        was trained. The first return value is the train data and the second is the test data.\\n        In order to get this model, call the load_fitted_model() function.\\n        Otherwise, returns a single object.\\n\\n    Returns\\n    -------\\n    dataset : Union[deepchecks.Dataset, pd.DataFrame]\\n        the data object, corresponding to the data_format attribute.\\n    train, test : Tuple[Union[deepchecks.Dataset, pd.DataFrame],Union[deepchecks.Dataset, pd.DataFrame]\\n        tuple if as_train_test = True. Tuple of two objects represents the dataset splitted to train and test sets.\\n    \"\n    if not as_train_test:\n        dataset = pd.read_csv(_FULL_DATA_URL, index_col=False)\n        if data_format == 'Dataset':\n            dataset = Dataset(dataset, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            return dataset\n        elif data_format == 'Dataframe':\n            return dataset\n        else:\n            raise ValueError('data_format must be either \"Dataset\" or \"Dataframe\"')\n    else:\n        train = pd.read_csv(_TRAIN_DATA_URL, index_col=False)\n        test = pd.read_csv(_TEST_DATA_URL, index_col=False)\n        if data_format == 'Dataset':\n            train = Dataset(train, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            test = Dataset(test, label=_target, cat_features=_CAT_FEATURES, index_name=_index_name, datetime_name=_datetime_name)\n            return (train, test)\n        elif data_format == 'Dataframe':\n            return (train, test)\n        else:\n            raise ValueError('data_format must be either \"Dataset\" or \"Dataframe\"')"
        ]
    },
    {
        "func_name": "load_fitted_model",
        "original": "def load_fitted_model(pretrained=True):\n    \"\"\"Load and return a fitted classification model.\n\n    Returns\n    -------\n    model : Joblib\n        The model/pipeline that was trained on the adult dataset.\n\n    \"\"\"\n    if sklearn.__version__ == _MODEL_VERSION and pretrained:\n        with urlopen(_MODEL_URL) as f:\n            model = joblib.load(f)\n    else:\n        model = _build_model()\n        (train, _) = load_data()\n        model.fit(train.features_columns, train.data[_target])\n    return model",
        "mutated": [
            "def load_fitted_model(pretrained=True):\n    if False:\n        i = 10\n    'Load and return a fitted classification model.\\n\\n    Returns\\n    -------\\n    model : Joblib\\n        The model/pipeline that was trained on the adult dataset.\\n\\n    '\n    if sklearn.__version__ == _MODEL_VERSION and pretrained:\n        with urlopen(_MODEL_URL) as f:\n            model = joblib.load(f)\n    else:\n        model = _build_model()\n        (train, _) = load_data()\n        model.fit(train.features_columns, train.data[_target])\n    return model",
            "def load_fitted_model(pretrained=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Load and return a fitted classification model.\\n\\n    Returns\\n    -------\\n    model : Joblib\\n        The model/pipeline that was trained on the adult dataset.\\n\\n    '\n    if sklearn.__version__ == _MODEL_VERSION and pretrained:\n        with urlopen(_MODEL_URL) as f:\n            model = joblib.load(f)\n    else:\n        model = _build_model()\n        (train, _) = load_data()\n        model.fit(train.features_columns, train.data[_target])\n    return model",
            "def load_fitted_model(pretrained=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Load and return a fitted classification model.\\n\\n    Returns\\n    -------\\n    model : Joblib\\n        The model/pipeline that was trained on the adult dataset.\\n\\n    '\n    if sklearn.__version__ == _MODEL_VERSION and pretrained:\n        with urlopen(_MODEL_URL) as f:\n            model = joblib.load(f)\n    else:\n        model = _build_model()\n        (train, _) = load_data()\n        model.fit(train.features_columns, train.data[_target])\n    return model",
            "def load_fitted_model(pretrained=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Load and return a fitted classification model.\\n\\n    Returns\\n    -------\\n    model : Joblib\\n        The model/pipeline that was trained on the adult dataset.\\n\\n    '\n    if sklearn.__version__ == _MODEL_VERSION and pretrained:\n        with urlopen(_MODEL_URL) as f:\n            model = joblib.load(f)\n    else:\n        model = _build_model()\n        (train, _) = load_data()\n        model.fit(train.features_columns, train.data[_target])\n    return model",
            "def load_fitted_model(pretrained=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Load and return a fitted classification model.\\n\\n    Returns\\n    -------\\n    model : Joblib\\n        The model/pipeline that was trained on the adult dataset.\\n\\n    '\n    if sklearn.__version__ == _MODEL_VERSION and pretrained:\n        with urlopen(_MODEL_URL) as f:\n            model = joblib.load(f)\n    else:\n        model = _build_model()\n        (train, _) = load_data()\n        model.fit(train.features_columns, train.data[_target])\n    return model"
        ]
    },
    {
        "func_name": "_build_model",
        "original": "def _build_model():\n    \"\"\"Build the model to fit.\"\"\"\n    categorical_transformer = Pipeline(steps=[('encoder', run_available_kwargs(OrdinalEncoder, handle_unknown='use_encoded_value', unknown_value=np.nan, dtype=np.float64))])\n    preprocessor = ColumnTransformer(transformers=[('num', 'passthrough', _NUM_FEATURES), ('cat', categorical_transformer, _CAT_FEATURES)])\n    model = Pipeline(steps=[('preprocessing', preprocessor), ('model', run_available_kwargs(HistGradientBoostingClassifier, max_depth=5, max_iter=200, random_state=42, categorical_features=[False] * len(_NUM_FEATURES) + [True] * len(_CAT_FEATURES)))])\n    return model",
        "mutated": [
            "def _build_model():\n    if False:\n        i = 10\n    'Build the model to fit.'\n    categorical_transformer = Pipeline(steps=[('encoder', run_available_kwargs(OrdinalEncoder, handle_unknown='use_encoded_value', unknown_value=np.nan, dtype=np.float64))])\n    preprocessor = ColumnTransformer(transformers=[('num', 'passthrough', _NUM_FEATURES), ('cat', categorical_transformer, _CAT_FEATURES)])\n    model = Pipeline(steps=[('preprocessing', preprocessor), ('model', run_available_kwargs(HistGradientBoostingClassifier, max_depth=5, max_iter=200, random_state=42, categorical_features=[False] * len(_NUM_FEATURES) + [True] * len(_CAT_FEATURES)))])\n    return model",
            "def _build_model():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Build the model to fit.'\n    categorical_transformer = Pipeline(steps=[('encoder', run_available_kwargs(OrdinalEncoder, handle_unknown='use_encoded_value', unknown_value=np.nan, dtype=np.float64))])\n    preprocessor = ColumnTransformer(transformers=[('num', 'passthrough', _NUM_FEATURES), ('cat', categorical_transformer, _CAT_FEATURES)])\n    model = Pipeline(steps=[('preprocessing', preprocessor), ('model', run_available_kwargs(HistGradientBoostingClassifier, max_depth=5, max_iter=200, random_state=42, categorical_features=[False] * len(_NUM_FEATURES) + [True] * len(_CAT_FEATURES)))])\n    return model",
            "def _build_model():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Build the model to fit.'\n    categorical_transformer = Pipeline(steps=[('encoder', run_available_kwargs(OrdinalEncoder, handle_unknown='use_encoded_value', unknown_value=np.nan, dtype=np.float64))])\n    preprocessor = ColumnTransformer(transformers=[('num', 'passthrough', _NUM_FEATURES), ('cat', categorical_transformer, _CAT_FEATURES)])\n    model = Pipeline(steps=[('preprocessing', preprocessor), ('model', run_available_kwargs(HistGradientBoostingClassifier, max_depth=5, max_iter=200, random_state=42, categorical_features=[False] * len(_NUM_FEATURES) + [True] * len(_CAT_FEATURES)))])\n    return model",
            "def _build_model():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Build the model to fit.'\n    categorical_transformer = Pipeline(steps=[('encoder', run_available_kwargs(OrdinalEncoder, handle_unknown='use_encoded_value', unknown_value=np.nan, dtype=np.float64))])\n    preprocessor = ColumnTransformer(transformers=[('num', 'passthrough', _NUM_FEATURES), ('cat', categorical_transformer, _CAT_FEATURES)])\n    model = Pipeline(steps=[('preprocessing', preprocessor), ('model', run_available_kwargs(HistGradientBoostingClassifier, max_depth=5, max_iter=200, random_state=42, categorical_features=[False] * len(_NUM_FEATURES) + [True] * len(_CAT_FEATURES)))])\n    return model",
            "def _build_model():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Build the model to fit.'\n    categorical_transformer = Pipeline(steps=[('encoder', run_available_kwargs(OrdinalEncoder, handle_unknown='use_encoded_value', unknown_value=np.nan, dtype=np.float64))])\n    preprocessor = ColumnTransformer(transformers=[('num', 'passthrough', _NUM_FEATURES), ('cat', categorical_transformer, _CAT_FEATURES)])\n    model = Pipeline(steps=[('preprocessing', preprocessor), ('model', run_available_kwargs(HistGradientBoostingClassifier, max_depth=5, max_iter=200, random_state=42, categorical_features=[False] * len(_NUM_FEATURES) + [True] * len(_CAT_FEATURES)))])\n    return model"
        ]
    }
]