[
    {
        "func_name": "compute_group",
        "original": "@classmethod\ndef compute_group(cls, data, scales, **params):\n    import scipy.stats as stats\n    from scipy import linalg\n    level = params['level']\n    segments = params['segments']\n    type_ = params['type']\n    dfn = 2\n    dfd = len(data) - 1\n    if dfd < 3:\n        warn('Too few points to calculate an ellipse', PlotnineWarning)\n        return pd.DataFrame({'x': [], 'y': []})\n    m: FloatArray = np.asarray(data[['x', 'y']])\n    if type_ == 't':\n        res = cov_trob(m)\n        cov = res['cov']\n        center = res['center']\n    elif type_ == 'norm':\n        cov = np.cov(m, rowvar=False)\n        center = np.mean(m, axis=0)\n    elif type_ == 'euclid':\n        cov = np.cov(m, rowvar=False)\n        cov = np.diag(np.repeat(np.diag(cov).min(), 2))\n        center = np.mean(m, axis=0)\n    else:\n        raise ValueError(f'Unknown value for type={type_}')\n    chol_decomp = linalg.cholesky(cov, lower=False)\n    if type_ == 'euclid':\n        radius = level / chol_decomp.max()\n    else:\n        radius = np.sqrt(dfn * stats.f.ppf(level, dfn, dfd))\n    space = np.linspace(0, 2 * np.pi, segments)\n    unit_circle = np.column_stack([np.cos(space), np.sin(space)])\n    res = center + radius * np.dot(unit_circle, chol_decomp)\n    return pd.DataFrame({'x': res[:, 0], 'y': res[:, 1]})",
        "mutated": [
            "@classmethod\ndef compute_group(cls, data, scales, **params):\n    if False:\n        i = 10\n    import scipy.stats as stats\n    from scipy import linalg\n    level = params['level']\n    segments = params['segments']\n    type_ = params['type']\n    dfn = 2\n    dfd = len(data) - 1\n    if dfd < 3:\n        warn('Too few points to calculate an ellipse', PlotnineWarning)\n        return pd.DataFrame({'x': [], 'y': []})\n    m: FloatArray = np.asarray(data[['x', 'y']])\n    if type_ == 't':\n        res = cov_trob(m)\n        cov = res['cov']\n        center = res['center']\n    elif type_ == 'norm':\n        cov = np.cov(m, rowvar=False)\n        center = np.mean(m, axis=0)\n    elif type_ == 'euclid':\n        cov = np.cov(m, rowvar=False)\n        cov = np.diag(np.repeat(np.diag(cov).min(), 2))\n        center = np.mean(m, axis=0)\n    else:\n        raise ValueError(f'Unknown value for type={type_}')\n    chol_decomp = linalg.cholesky(cov, lower=False)\n    if type_ == 'euclid':\n        radius = level / chol_decomp.max()\n    else:\n        radius = np.sqrt(dfn * stats.f.ppf(level, dfn, dfd))\n    space = np.linspace(0, 2 * np.pi, segments)\n    unit_circle = np.column_stack([np.cos(space), np.sin(space)])\n    res = center + radius * np.dot(unit_circle, chol_decomp)\n    return pd.DataFrame({'x': res[:, 0], 'y': res[:, 1]})",
            "@classmethod\ndef compute_group(cls, data, scales, **params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    import scipy.stats as stats\n    from scipy import linalg\n    level = params['level']\n    segments = params['segments']\n    type_ = params['type']\n    dfn = 2\n    dfd = len(data) - 1\n    if dfd < 3:\n        warn('Too few points to calculate an ellipse', PlotnineWarning)\n        return pd.DataFrame({'x': [], 'y': []})\n    m: FloatArray = np.asarray(data[['x', 'y']])\n    if type_ == 't':\n        res = cov_trob(m)\n        cov = res['cov']\n        center = res['center']\n    elif type_ == 'norm':\n        cov = np.cov(m, rowvar=False)\n        center = np.mean(m, axis=0)\n    elif type_ == 'euclid':\n        cov = np.cov(m, rowvar=False)\n        cov = np.diag(np.repeat(np.diag(cov).min(), 2))\n        center = np.mean(m, axis=0)\n    else:\n        raise ValueError(f'Unknown value for type={type_}')\n    chol_decomp = linalg.cholesky(cov, lower=False)\n    if type_ == 'euclid':\n        radius = level / chol_decomp.max()\n    else:\n        radius = np.sqrt(dfn * stats.f.ppf(level, dfn, dfd))\n    space = np.linspace(0, 2 * np.pi, segments)\n    unit_circle = np.column_stack([np.cos(space), np.sin(space)])\n    res = center + radius * np.dot(unit_circle, chol_decomp)\n    return pd.DataFrame({'x': res[:, 0], 'y': res[:, 1]})",
            "@classmethod\ndef compute_group(cls, data, scales, **params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    import scipy.stats as stats\n    from scipy import linalg\n    level = params['level']\n    segments = params['segments']\n    type_ = params['type']\n    dfn = 2\n    dfd = len(data) - 1\n    if dfd < 3:\n        warn('Too few points to calculate an ellipse', PlotnineWarning)\n        return pd.DataFrame({'x': [], 'y': []})\n    m: FloatArray = np.asarray(data[['x', 'y']])\n    if type_ == 't':\n        res = cov_trob(m)\n        cov = res['cov']\n        center = res['center']\n    elif type_ == 'norm':\n        cov = np.cov(m, rowvar=False)\n        center = np.mean(m, axis=0)\n    elif type_ == 'euclid':\n        cov = np.cov(m, rowvar=False)\n        cov = np.diag(np.repeat(np.diag(cov).min(), 2))\n        center = np.mean(m, axis=0)\n    else:\n        raise ValueError(f'Unknown value for type={type_}')\n    chol_decomp = linalg.cholesky(cov, lower=False)\n    if type_ == 'euclid':\n        radius = level / chol_decomp.max()\n    else:\n        radius = np.sqrt(dfn * stats.f.ppf(level, dfn, dfd))\n    space = np.linspace(0, 2 * np.pi, segments)\n    unit_circle = np.column_stack([np.cos(space), np.sin(space)])\n    res = center + radius * np.dot(unit_circle, chol_decomp)\n    return pd.DataFrame({'x': res[:, 0], 'y': res[:, 1]})",
            "@classmethod\ndef compute_group(cls, data, scales, **params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    import scipy.stats as stats\n    from scipy import linalg\n    level = params['level']\n    segments = params['segments']\n    type_ = params['type']\n    dfn = 2\n    dfd = len(data) - 1\n    if dfd < 3:\n        warn('Too few points to calculate an ellipse', PlotnineWarning)\n        return pd.DataFrame({'x': [], 'y': []})\n    m: FloatArray = np.asarray(data[['x', 'y']])\n    if type_ == 't':\n        res = cov_trob(m)\n        cov = res['cov']\n        center = res['center']\n    elif type_ == 'norm':\n        cov = np.cov(m, rowvar=False)\n        center = np.mean(m, axis=0)\n    elif type_ == 'euclid':\n        cov = np.cov(m, rowvar=False)\n        cov = np.diag(np.repeat(np.diag(cov).min(), 2))\n        center = np.mean(m, axis=0)\n    else:\n        raise ValueError(f'Unknown value for type={type_}')\n    chol_decomp = linalg.cholesky(cov, lower=False)\n    if type_ == 'euclid':\n        radius = level / chol_decomp.max()\n    else:\n        radius = np.sqrt(dfn * stats.f.ppf(level, dfn, dfd))\n    space = np.linspace(0, 2 * np.pi, segments)\n    unit_circle = np.column_stack([np.cos(space), np.sin(space)])\n    res = center + radius * np.dot(unit_circle, chol_decomp)\n    return pd.DataFrame({'x': res[:, 0], 'y': res[:, 1]})",
            "@classmethod\ndef compute_group(cls, data, scales, **params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    import scipy.stats as stats\n    from scipy import linalg\n    level = params['level']\n    segments = params['segments']\n    type_ = params['type']\n    dfn = 2\n    dfd = len(data) - 1\n    if dfd < 3:\n        warn('Too few points to calculate an ellipse', PlotnineWarning)\n        return pd.DataFrame({'x': [], 'y': []})\n    m: FloatArray = np.asarray(data[['x', 'y']])\n    if type_ == 't':\n        res = cov_trob(m)\n        cov = res['cov']\n        center = res['center']\n    elif type_ == 'norm':\n        cov = np.cov(m, rowvar=False)\n        center = np.mean(m, axis=0)\n    elif type_ == 'euclid':\n        cov = np.cov(m, rowvar=False)\n        cov = np.diag(np.repeat(np.diag(cov).min(), 2))\n        center = np.mean(m, axis=0)\n    else:\n        raise ValueError(f'Unknown value for type={type_}')\n    chol_decomp = linalg.cholesky(cov, lower=False)\n    if type_ == 'euclid':\n        radius = level / chol_decomp.max()\n    else:\n        radius = np.sqrt(dfn * stats.f.ppf(level, dfn, dfd))\n    space = np.linspace(0, 2 * np.pi, segments)\n    unit_circle = np.column_stack([np.cos(space), np.sin(space)])\n    res = center + radius * np.dot(unit_circle, chol_decomp)\n    return pd.DataFrame({'x': res[:, 0], 'y': res[:, 1]})"
        ]
    },
    {
        "func_name": "test_values",
        "original": "def test_values(x):\n    if pd.isna(x).any() or np.isinf(x).any():\n        raise ValueError(\"Missing or infinite values in 'x'\")",
        "mutated": [
            "def test_values(x):\n    if False:\n        i = 10\n    if pd.isna(x).any() or np.isinf(x).any():\n        raise ValueError(\"Missing or infinite values in 'x'\")",
            "def test_values(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if pd.isna(x).any() or np.isinf(x).any():\n        raise ValueError(\"Missing or infinite values in 'x'\")",
            "def test_values(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if pd.isna(x).any() or np.isinf(x).any():\n        raise ValueError(\"Missing or infinite values in 'x'\")",
            "def test_values(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if pd.isna(x).any() or np.isinf(x).any():\n        raise ValueError(\"Missing or infinite values in 'x'\")",
            "def test_values(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if pd.isna(x).any() or np.isinf(x).any():\n        raise ValueError(\"Missing or infinite values in 'x'\")"
        ]
    },
    {
        "func_name": "scale_simp",
        "original": "def scale_simp(x, center, n, p):\n    return x - np.repeat([center], n, axis=0)",
        "mutated": [
            "def scale_simp(x, center, n, p):\n    if False:\n        i = 10\n    return x - np.repeat([center], n, axis=0)",
            "def scale_simp(x, center, n, p):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return x - np.repeat([center], n, axis=0)",
            "def scale_simp(x, center, n, p):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return x - np.repeat([center], n, axis=0)",
            "def scale_simp(x, center, n, p):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return x - np.repeat([center], n, axis=0)",
            "def scale_simp(x, center, n, p):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return x - np.repeat([center], n, axis=0)"
        ]
    },
    {
        "func_name": "cov_trob",
        "original": "def cov_trob(x, wt: Optional[FloatArrayLike]=None, cor=False, center: FloatArrayLike | bool=True, nu=5, maxit=25, tol=0.01):\n    \"\"\"\n    Covariance Estimation for Multivariate t Distribution\n\n    Estimates a covariance or correlation matrix assuming the\n    data came from a multivariate t distribution: this provides\n    some degree of robustness to outlier without giving a high\n    breakdown point.\n\n    **credit**: This function a port of the R function\n    ``MASS::cov.trob``.\n\n    Parameters\n    ----------\n    x : array\n        data matrix. Missing values (NaNs) are not allowed.\n    wt : array\n        A vector of weights for each case: these are treated as\n        if the case i actually occurred ``wt[i]`` times.\n    cor : bool\n        Flag to choose between returning the correlation\n        (``cor=True``) or covariance (``cor=False``) matrix.\n    center : array or bool\n        A logical value or a numeric vector providing the location\n        about which the covariance is to be taken.\n        If ``center=False``, no centering is done; if\n        ``center=True`` the MLE of the location vector is used.\n    nu : int\n        'degrees of freedom' for the multivariate t distribution.\n        Must exceed 2 (so that the covariance matrix is finite).\n    maxit : int\n        Maximum number of iterations in fitting.\n    tol : float\n        Convergence tolerance for fitting.\n\n    Returns\n    -------\n    out : dict\n        A dictionary with with the following key-value\n\n        - ``cov`` : the fitted covariance matrix.\n        - ``center`` : the estimated or specified location vector.\n        - ``wt`` : the specified weights: only returned if the\n           wt argument was given.\n        - ``n_obs`` : the number of cases used in the fitting.\n        - ``cor`` : the fitted correlation matrix: only returned\n          if ``cor=True``.\n        - ``call`` : The matched call.\n        - ``iter`` : The number of iterations used.\n\n    References\n    ----------\n    - J. T. Kent, D. E. Tyler and Y. Vardi (1994) A curious likelihood\n      identity for the multivariate t-distribution. *Communications in\n      Statistics-Simulation and Computation* **23**, 441-453.\n\n    - Venables, W. N. and Ripley, B. D. (1999) *Modern Applied\n      Statistics with S-PLUS*. Third Edition. Springer.\n\n    \"\"\"\n    from scipy import linalg\n\n    def test_values(x):\n        if pd.isna(x).any() or np.isinf(x).any():\n            raise ValueError(\"Missing or infinite values in 'x'\")\n\n    def scale_simp(x, center, n, p):\n        return x - np.repeat([center], n, axis=0)\n    x = np.asarray(x)\n    (n, p) = x.shape\n    test_values(x)\n    ans: dict[str, Any] = {}\n    if wt is None:\n        wt = np.ones(n)\n    else:\n        wt = np.asarray(wt)\n        ans['wt0'] = wt\n        if len(wt) != n:\n            raise ValueError(\"length of 'wt' must equal number of observations.\")\n        if any(wt < 0):\n            raise ValueError('Negative weights not allowed.')\n        if not np.sum(wt):\n            raise ValueError('No positive weights.')\n        x = x[wt > 0, :]\n        wt = wt[wt > 0]\n        (n, _) = x.shape\n    wt = wt[:, np.newaxis]\n    use_loc = False\n    if isinstance(center, bool):\n        if center:\n            loc = np.sum(wt * x, axis=0) / wt.sum()\n            use_loc = True\n        else:\n            loc = np.zeros(p)\n    else:\n        if len(center) != p:\n            raise ValueError(\"'center' is not the right length\")\n        loc = p\n    w = wt * (1 + p / nu)\n    for iteration in range(maxit):\n        w0 = w\n        X = scale_simp(x, loc, n, p)\n        (_, s, v) = linalg.svd(np.sqrt(w / np.sum(w)) * X)\n        wX = np.dot(np.dot(X, v.T), np.diag(np.full(p, 1 / s)))\n        Q = np.squeeze(np.dot(wX ** 2, np.ones(p)))\n        w = wt * (nu + p) / (nu + Q)[:, np.newaxis]\n        if use_loc:\n            loc = np.sum(w * x, axis=0) / w.sum()\n        if all(np.abs(w - w0) < tol):\n            break\n    else:\n        _c1 = np.mean(w) - np.mean(wt) > tol\n        _c2 = np.abs(np.mean(w * Q) / p - 1) > tol\n        if _c1 and _c2:\n            warn('Convergence probably failed.', PlotnineWarning)\n    _a = np.sqrt(w) * X\n    cov = np.dot(_a.T, _a) / np.sum(wt)\n    if cor:\n        sd = np.sqrt(np.diag(cov))\n        ans['cor'] = cov / sd / np.repeat([sd], p, axis=0).T\n    ans.update(cov=cov, center=loc, n_obs=n, iter=iteration)\n    return ans",
        "mutated": [
            "def cov_trob(x, wt: Optional[FloatArrayLike]=None, cor=False, center: FloatArrayLike | bool=True, nu=5, maxit=25, tol=0.01):\n    if False:\n        i = 10\n    \"\\n    Covariance Estimation for Multivariate t Distribution\\n\\n    Estimates a covariance or correlation matrix assuming the\\n    data came from a multivariate t distribution: this provides\\n    some degree of robustness to outlier without giving a high\\n    breakdown point.\\n\\n    **credit**: This function a port of the R function\\n    ``MASS::cov.trob``.\\n\\n    Parameters\\n    ----------\\n    x : array\\n        data matrix. Missing values (NaNs) are not allowed.\\n    wt : array\\n        A vector of weights for each case: these are treated as\\n        if the case i actually occurred ``wt[i]`` times.\\n    cor : bool\\n        Flag to choose between returning the correlation\\n        (``cor=True``) or covariance (``cor=False``) matrix.\\n    center : array or bool\\n        A logical value or a numeric vector providing the location\\n        about which the covariance is to be taken.\\n        If ``center=False``, no centering is done; if\\n        ``center=True`` the MLE of the location vector is used.\\n    nu : int\\n        'degrees of freedom' for the multivariate t distribution.\\n        Must exceed 2 (so that the covariance matrix is finite).\\n    maxit : int\\n        Maximum number of iterations in fitting.\\n    tol : float\\n        Convergence tolerance for fitting.\\n\\n    Returns\\n    -------\\n    out : dict\\n        A dictionary with with the following key-value\\n\\n        - ``cov`` : the fitted covariance matrix.\\n        - ``center`` : the estimated or specified location vector.\\n        - ``wt`` : the specified weights: only returned if the\\n           wt argument was given.\\n        - ``n_obs`` : the number of cases used in the fitting.\\n        - ``cor`` : the fitted correlation matrix: only returned\\n          if ``cor=True``.\\n        - ``call`` : The matched call.\\n        - ``iter`` : The number of iterations used.\\n\\n    References\\n    ----------\\n    - J. T. Kent, D. E. Tyler and Y. Vardi (1994) A curious likelihood\\n      identity for the multivariate t-distribution. *Communications in\\n      Statistics-Simulation and Computation* **23**, 441-453.\\n\\n    - Venables, W. N. and Ripley, B. D. (1999) *Modern Applied\\n      Statistics with S-PLUS*. Third Edition. Springer.\\n\\n    \"\n    from scipy import linalg\n\n    def test_values(x):\n        if pd.isna(x).any() or np.isinf(x).any():\n            raise ValueError(\"Missing or infinite values in 'x'\")\n\n    def scale_simp(x, center, n, p):\n        return x - np.repeat([center], n, axis=0)\n    x = np.asarray(x)\n    (n, p) = x.shape\n    test_values(x)\n    ans: dict[str, Any] = {}\n    if wt is None:\n        wt = np.ones(n)\n    else:\n        wt = np.asarray(wt)\n        ans['wt0'] = wt\n        if len(wt) != n:\n            raise ValueError(\"length of 'wt' must equal number of observations.\")\n        if any(wt < 0):\n            raise ValueError('Negative weights not allowed.')\n        if not np.sum(wt):\n            raise ValueError('No positive weights.')\n        x = x[wt > 0, :]\n        wt = wt[wt > 0]\n        (n, _) = x.shape\n    wt = wt[:, np.newaxis]\n    use_loc = False\n    if isinstance(center, bool):\n        if center:\n            loc = np.sum(wt * x, axis=0) / wt.sum()\n            use_loc = True\n        else:\n            loc = np.zeros(p)\n    else:\n        if len(center) != p:\n            raise ValueError(\"'center' is not the right length\")\n        loc = p\n    w = wt * (1 + p / nu)\n    for iteration in range(maxit):\n        w0 = w\n        X = scale_simp(x, loc, n, p)\n        (_, s, v) = linalg.svd(np.sqrt(w / np.sum(w)) * X)\n        wX = np.dot(np.dot(X, v.T), np.diag(np.full(p, 1 / s)))\n        Q = np.squeeze(np.dot(wX ** 2, np.ones(p)))\n        w = wt * (nu + p) / (nu + Q)[:, np.newaxis]\n        if use_loc:\n            loc = np.sum(w * x, axis=0) / w.sum()\n        if all(np.abs(w - w0) < tol):\n            break\n    else:\n        _c1 = np.mean(w) - np.mean(wt) > tol\n        _c2 = np.abs(np.mean(w * Q) / p - 1) > tol\n        if _c1 and _c2:\n            warn('Convergence probably failed.', PlotnineWarning)\n    _a = np.sqrt(w) * X\n    cov = np.dot(_a.T, _a) / np.sum(wt)\n    if cor:\n        sd = np.sqrt(np.diag(cov))\n        ans['cor'] = cov / sd / np.repeat([sd], p, axis=0).T\n    ans.update(cov=cov, center=loc, n_obs=n, iter=iteration)\n    return ans",
            "def cov_trob(x, wt: Optional[FloatArrayLike]=None, cor=False, center: FloatArrayLike | bool=True, nu=5, maxit=25, tol=0.01):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Covariance Estimation for Multivariate t Distribution\\n\\n    Estimates a covariance or correlation matrix assuming the\\n    data came from a multivariate t distribution: this provides\\n    some degree of robustness to outlier without giving a high\\n    breakdown point.\\n\\n    **credit**: This function a port of the R function\\n    ``MASS::cov.trob``.\\n\\n    Parameters\\n    ----------\\n    x : array\\n        data matrix. Missing values (NaNs) are not allowed.\\n    wt : array\\n        A vector of weights for each case: these are treated as\\n        if the case i actually occurred ``wt[i]`` times.\\n    cor : bool\\n        Flag to choose between returning the correlation\\n        (``cor=True``) or covariance (``cor=False``) matrix.\\n    center : array or bool\\n        A logical value or a numeric vector providing the location\\n        about which the covariance is to be taken.\\n        If ``center=False``, no centering is done; if\\n        ``center=True`` the MLE of the location vector is used.\\n    nu : int\\n        'degrees of freedom' for the multivariate t distribution.\\n        Must exceed 2 (so that the covariance matrix is finite).\\n    maxit : int\\n        Maximum number of iterations in fitting.\\n    tol : float\\n        Convergence tolerance for fitting.\\n\\n    Returns\\n    -------\\n    out : dict\\n        A dictionary with with the following key-value\\n\\n        - ``cov`` : the fitted covariance matrix.\\n        - ``center`` : the estimated or specified location vector.\\n        - ``wt`` : the specified weights: only returned if the\\n           wt argument was given.\\n        - ``n_obs`` : the number of cases used in the fitting.\\n        - ``cor`` : the fitted correlation matrix: only returned\\n          if ``cor=True``.\\n        - ``call`` : The matched call.\\n        - ``iter`` : The number of iterations used.\\n\\n    References\\n    ----------\\n    - J. T. Kent, D. E. Tyler and Y. Vardi (1994) A curious likelihood\\n      identity for the multivariate t-distribution. *Communications in\\n      Statistics-Simulation and Computation* **23**, 441-453.\\n\\n    - Venables, W. N. and Ripley, B. D. (1999) *Modern Applied\\n      Statistics with S-PLUS*. Third Edition. Springer.\\n\\n    \"\n    from scipy import linalg\n\n    def test_values(x):\n        if pd.isna(x).any() or np.isinf(x).any():\n            raise ValueError(\"Missing or infinite values in 'x'\")\n\n    def scale_simp(x, center, n, p):\n        return x - np.repeat([center], n, axis=0)\n    x = np.asarray(x)\n    (n, p) = x.shape\n    test_values(x)\n    ans: dict[str, Any] = {}\n    if wt is None:\n        wt = np.ones(n)\n    else:\n        wt = np.asarray(wt)\n        ans['wt0'] = wt\n        if len(wt) != n:\n            raise ValueError(\"length of 'wt' must equal number of observations.\")\n        if any(wt < 0):\n            raise ValueError('Negative weights not allowed.')\n        if not np.sum(wt):\n            raise ValueError('No positive weights.')\n        x = x[wt > 0, :]\n        wt = wt[wt > 0]\n        (n, _) = x.shape\n    wt = wt[:, np.newaxis]\n    use_loc = False\n    if isinstance(center, bool):\n        if center:\n            loc = np.sum(wt * x, axis=0) / wt.sum()\n            use_loc = True\n        else:\n            loc = np.zeros(p)\n    else:\n        if len(center) != p:\n            raise ValueError(\"'center' is not the right length\")\n        loc = p\n    w = wt * (1 + p / nu)\n    for iteration in range(maxit):\n        w0 = w\n        X = scale_simp(x, loc, n, p)\n        (_, s, v) = linalg.svd(np.sqrt(w / np.sum(w)) * X)\n        wX = np.dot(np.dot(X, v.T), np.diag(np.full(p, 1 / s)))\n        Q = np.squeeze(np.dot(wX ** 2, np.ones(p)))\n        w = wt * (nu + p) / (nu + Q)[:, np.newaxis]\n        if use_loc:\n            loc = np.sum(w * x, axis=0) / w.sum()\n        if all(np.abs(w - w0) < tol):\n            break\n    else:\n        _c1 = np.mean(w) - np.mean(wt) > tol\n        _c2 = np.abs(np.mean(w * Q) / p - 1) > tol\n        if _c1 and _c2:\n            warn('Convergence probably failed.', PlotnineWarning)\n    _a = np.sqrt(w) * X\n    cov = np.dot(_a.T, _a) / np.sum(wt)\n    if cor:\n        sd = np.sqrt(np.diag(cov))\n        ans['cor'] = cov / sd / np.repeat([sd], p, axis=0).T\n    ans.update(cov=cov, center=loc, n_obs=n, iter=iteration)\n    return ans",
            "def cov_trob(x, wt: Optional[FloatArrayLike]=None, cor=False, center: FloatArrayLike | bool=True, nu=5, maxit=25, tol=0.01):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Covariance Estimation for Multivariate t Distribution\\n\\n    Estimates a covariance or correlation matrix assuming the\\n    data came from a multivariate t distribution: this provides\\n    some degree of robustness to outlier without giving a high\\n    breakdown point.\\n\\n    **credit**: This function a port of the R function\\n    ``MASS::cov.trob``.\\n\\n    Parameters\\n    ----------\\n    x : array\\n        data matrix. Missing values (NaNs) are not allowed.\\n    wt : array\\n        A vector of weights for each case: these are treated as\\n        if the case i actually occurred ``wt[i]`` times.\\n    cor : bool\\n        Flag to choose between returning the correlation\\n        (``cor=True``) or covariance (``cor=False``) matrix.\\n    center : array or bool\\n        A logical value or a numeric vector providing the location\\n        about which the covariance is to be taken.\\n        If ``center=False``, no centering is done; if\\n        ``center=True`` the MLE of the location vector is used.\\n    nu : int\\n        'degrees of freedom' for the multivariate t distribution.\\n        Must exceed 2 (so that the covariance matrix is finite).\\n    maxit : int\\n        Maximum number of iterations in fitting.\\n    tol : float\\n        Convergence tolerance for fitting.\\n\\n    Returns\\n    -------\\n    out : dict\\n        A dictionary with with the following key-value\\n\\n        - ``cov`` : the fitted covariance matrix.\\n        - ``center`` : the estimated or specified location vector.\\n        - ``wt`` : the specified weights: only returned if the\\n           wt argument was given.\\n        - ``n_obs`` : the number of cases used in the fitting.\\n        - ``cor`` : the fitted correlation matrix: only returned\\n          if ``cor=True``.\\n        - ``call`` : The matched call.\\n        - ``iter`` : The number of iterations used.\\n\\n    References\\n    ----------\\n    - J. T. Kent, D. E. Tyler and Y. Vardi (1994) A curious likelihood\\n      identity for the multivariate t-distribution. *Communications in\\n      Statistics-Simulation and Computation* **23**, 441-453.\\n\\n    - Venables, W. N. and Ripley, B. D. (1999) *Modern Applied\\n      Statistics with S-PLUS*. Third Edition. Springer.\\n\\n    \"\n    from scipy import linalg\n\n    def test_values(x):\n        if pd.isna(x).any() or np.isinf(x).any():\n            raise ValueError(\"Missing or infinite values in 'x'\")\n\n    def scale_simp(x, center, n, p):\n        return x - np.repeat([center], n, axis=0)\n    x = np.asarray(x)\n    (n, p) = x.shape\n    test_values(x)\n    ans: dict[str, Any] = {}\n    if wt is None:\n        wt = np.ones(n)\n    else:\n        wt = np.asarray(wt)\n        ans['wt0'] = wt\n        if len(wt) != n:\n            raise ValueError(\"length of 'wt' must equal number of observations.\")\n        if any(wt < 0):\n            raise ValueError('Negative weights not allowed.')\n        if not np.sum(wt):\n            raise ValueError('No positive weights.')\n        x = x[wt > 0, :]\n        wt = wt[wt > 0]\n        (n, _) = x.shape\n    wt = wt[:, np.newaxis]\n    use_loc = False\n    if isinstance(center, bool):\n        if center:\n            loc = np.sum(wt * x, axis=0) / wt.sum()\n            use_loc = True\n        else:\n            loc = np.zeros(p)\n    else:\n        if len(center) != p:\n            raise ValueError(\"'center' is not the right length\")\n        loc = p\n    w = wt * (1 + p / nu)\n    for iteration in range(maxit):\n        w0 = w\n        X = scale_simp(x, loc, n, p)\n        (_, s, v) = linalg.svd(np.sqrt(w / np.sum(w)) * X)\n        wX = np.dot(np.dot(X, v.T), np.diag(np.full(p, 1 / s)))\n        Q = np.squeeze(np.dot(wX ** 2, np.ones(p)))\n        w = wt * (nu + p) / (nu + Q)[:, np.newaxis]\n        if use_loc:\n            loc = np.sum(w * x, axis=0) / w.sum()\n        if all(np.abs(w - w0) < tol):\n            break\n    else:\n        _c1 = np.mean(w) - np.mean(wt) > tol\n        _c2 = np.abs(np.mean(w * Q) / p - 1) > tol\n        if _c1 and _c2:\n            warn('Convergence probably failed.', PlotnineWarning)\n    _a = np.sqrt(w) * X\n    cov = np.dot(_a.T, _a) / np.sum(wt)\n    if cor:\n        sd = np.sqrt(np.diag(cov))\n        ans['cor'] = cov / sd / np.repeat([sd], p, axis=0).T\n    ans.update(cov=cov, center=loc, n_obs=n, iter=iteration)\n    return ans",
            "def cov_trob(x, wt: Optional[FloatArrayLike]=None, cor=False, center: FloatArrayLike | bool=True, nu=5, maxit=25, tol=0.01):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Covariance Estimation for Multivariate t Distribution\\n\\n    Estimates a covariance or correlation matrix assuming the\\n    data came from a multivariate t distribution: this provides\\n    some degree of robustness to outlier without giving a high\\n    breakdown point.\\n\\n    **credit**: This function a port of the R function\\n    ``MASS::cov.trob``.\\n\\n    Parameters\\n    ----------\\n    x : array\\n        data matrix. Missing values (NaNs) are not allowed.\\n    wt : array\\n        A vector of weights for each case: these are treated as\\n        if the case i actually occurred ``wt[i]`` times.\\n    cor : bool\\n        Flag to choose between returning the correlation\\n        (``cor=True``) or covariance (``cor=False``) matrix.\\n    center : array or bool\\n        A logical value or a numeric vector providing the location\\n        about which the covariance is to be taken.\\n        If ``center=False``, no centering is done; if\\n        ``center=True`` the MLE of the location vector is used.\\n    nu : int\\n        'degrees of freedom' for the multivariate t distribution.\\n        Must exceed 2 (so that the covariance matrix is finite).\\n    maxit : int\\n        Maximum number of iterations in fitting.\\n    tol : float\\n        Convergence tolerance for fitting.\\n\\n    Returns\\n    -------\\n    out : dict\\n        A dictionary with with the following key-value\\n\\n        - ``cov`` : the fitted covariance matrix.\\n        - ``center`` : the estimated or specified location vector.\\n        - ``wt`` : the specified weights: only returned if the\\n           wt argument was given.\\n        - ``n_obs`` : the number of cases used in the fitting.\\n        - ``cor`` : the fitted correlation matrix: only returned\\n          if ``cor=True``.\\n        - ``call`` : The matched call.\\n        - ``iter`` : The number of iterations used.\\n\\n    References\\n    ----------\\n    - J. T. Kent, D. E. Tyler and Y. Vardi (1994) A curious likelihood\\n      identity for the multivariate t-distribution. *Communications in\\n      Statistics-Simulation and Computation* **23**, 441-453.\\n\\n    - Venables, W. N. and Ripley, B. D. (1999) *Modern Applied\\n      Statistics with S-PLUS*. Third Edition. Springer.\\n\\n    \"\n    from scipy import linalg\n\n    def test_values(x):\n        if pd.isna(x).any() or np.isinf(x).any():\n            raise ValueError(\"Missing or infinite values in 'x'\")\n\n    def scale_simp(x, center, n, p):\n        return x - np.repeat([center], n, axis=0)\n    x = np.asarray(x)\n    (n, p) = x.shape\n    test_values(x)\n    ans: dict[str, Any] = {}\n    if wt is None:\n        wt = np.ones(n)\n    else:\n        wt = np.asarray(wt)\n        ans['wt0'] = wt\n        if len(wt) != n:\n            raise ValueError(\"length of 'wt' must equal number of observations.\")\n        if any(wt < 0):\n            raise ValueError('Negative weights not allowed.')\n        if not np.sum(wt):\n            raise ValueError('No positive weights.')\n        x = x[wt > 0, :]\n        wt = wt[wt > 0]\n        (n, _) = x.shape\n    wt = wt[:, np.newaxis]\n    use_loc = False\n    if isinstance(center, bool):\n        if center:\n            loc = np.sum(wt * x, axis=0) / wt.sum()\n            use_loc = True\n        else:\n            loc = np.zeros(p)\n    else:\n        if len(center) != p:\n            raise ValueError(\"'center' is not the right length\")\n        loc = p\n    w = wt * (1 + p / nu)\n    for iteration in range(maxit):\n        w0 = w\n        X = scale_simp(x, loc, n, p)\n        (_, s, v) = linalg.svd(np.sqrt(w / np.sum(w)) * X)\n        wX = np.dot(np.dot(X, v.T), np.diag(np.full(p, 1 / s)))\n        Q = np.squeeze(np.dot(wX ** 2, np.ones(p)))\n        w = wt * (nu + p) / (nu + Q)[:, np.newaxis]\n        if use_loc:\n            loc = np.sum(w * x, axis=0) / w.sum()\n        if all(np.abs(w - w0) < tol):\n            break\n    else:\n        _c1 = np.mean(w) - np.mean(wt) > tol\n        _c2 = np.abs(np.mean(w * Q) / p - 1) > tol\n        if _c1 and _c2:\n            warn('Convergence probably failed.', PlotnineWarning)\n    _a = np.sqrt(w) * X\n    cov = np.dot(_a.T, _a) / np.sum(wt)\n    if cor:\n        sd = np.sqrt(np.diag(cov))\n        ans['cor'] = cov / sd / np.repeat([sd], p, axis=0).T\n    ans.update(cov=cov, center=loc, n_obs=n, iter=iteration)\n    return ans",
            "def cov_trob(x, wt: Optional[FloatArrayLike]=None, cor=False, center: FloatArrayLike | bool=True, nu=5, maxit=25, tol=0.01):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Covariance Estimation for Multivariate t Distribution\\n\\n    Estimates a covariance or correlation matrix assuming the\\n    data came from a multivariate t distribution: this provides\\n    some degree of robustness to outlier without giving a high\\n    breakdown point.\\n\\n    **credit**: This function a port of the R function\\n    ``MASS::cov.trob``.\\n\\n    Parameters\\n    ----------\\n    x : array\\n        data matrix. Missing values (NaNs) are not allowed.\\n    wt : array\\n        A vector of weights for each case: these are treated as\\n        if the case i actually occurred ``wt[i]`` times.\\n    cor : bool\\n        Flag to choose between returning the correlation\\n        (``cor=True``) or covariance (``cor=False``) matrix.\\n    center : array or bool\\n        A logical value or a numeric vector providing the location\\n        about which the covariance is to be taken.\\n        If ``center=False``, no centering is done; if\\n        ``center=True`` the MLE of the location vector is used.\\n    nu : int\\n        'degrees of freedom' for the multivariate t distribution.\\n        Must exceed 2 (so that the covariance matrix is finite).\\n    maxit : int\\n        Maximum number of iterations in fitting.\\n    tol : float\\n        Convergence tolerance for fitting.\\n\\n    Returns\\n    -------\\n    out : dict\\n        A dictionary with with the following key-value\\n\\n        - ``cov`` : the fitted covariance matrix.\\n        - ``center`` : the estimated or specified location vector.\\n        - ``wt`` : the specified weights: only returned if the\\n           wt argument was given.\\n        - ``n_obs`` : the number of cases used in the fitting.\\n        - ``cor`` : the fitted correlation matrix: only returned\\n          if ``cor=True``.\\n        - ``call`` : The matched call.\\n        - ``iter`` : The number of iterations used.\\n\\n    References\\n    ----------\\n    - J. T. Kent, D. E. Tyler and Y. Vardi (1994) A curious likelihood\\n      identity for the multivariate t-distribution. *Communications in\\n      Statistics-Simulation and Computation* **23**, 441-453.\\n\\n    - Venables, W. N. and Ripley, B. D. (1999) *Modern Applied\\n      Statistics with S-PLUS*. Third Edition. Springer.\\n\\n    \"\n    from scipy import linalg\n\n    def test_values(x):\n        if pd.isna(x).any() or np.isinf(x).any():\n            raise ValueError(\"Missing or infinite values in 'x'\")\n\n    def scale_simp(x, center, n, p):\n        return x - np.repeat([center], n, axis=0)\n    x = np.asarray(x)\n    (n, p) = x.shape\n    test_values(x)\n    ans: dict[str, Any] = {}\n    if wt is None:\n        wt = np.ones(n)\n    else:\n        wt = np.asarray(wt)\n        ans['wt0'] = wt\n        if len(wt) != n:\n            raise ValueError(\"length of 'wt' must equal number of observations.\")\n        if any(wt < 0):\n            raise ValueError('Negative weights not allowed.')\n        if not np.sum(wt):\n            raise ValueError('No positive weights.')\n        x = x[wt > 0, :]\n        wt = wt[wt > 0]\n        (n, _) = x.shape\n    wt = wt[:, np.newaxis]\n    use_loc = False\n    if isinstance(center, bool):\n        if center:\n            loc = np.sum(wt * x, axis=0) / wt.sum()\n            use_loc = True\n        else:\n            loc = np.zeros(p)\n    else:\n        if len(center) != p:\n            raise ValueError(\"'center' is not the right length\")\n        loc = p\n    w = wt * (1 + p / nu)\n    for iteration in range(maxit):\n        w0 = w\n        X = scale_simp(x, loc, n, p)\n        (_, s, v) = linalg.svd(np.sqrt(w / np.sum(w)) * X)\n        wX = np.dot(np.dot(X, v.T), np.diag(np.full(p, 1 / s)))\n        Q = np.squeeze(np.dot(wX ** 2, np.ones(p)))\n        w = wt * (nu + p) / (nu + Q)[:, np.newaxis]\n        if use_loc:\n            loc = np.sum(w * x, axis=0) / w.sum()\n        if all(np.abs(w - w0) < tol):\n            break\n    else:\n        _c1 = np.mean(w) - np.mean(wt) > tol\n        _c2 = np.abs(np.mean(w * Q) / p - 1) > tol\n        if _c1 and _c2:\n            warn('Convergence probably failed.', PlotnineWarning)\n    _a = np.sqrt(w) * X\n    cov = np.dot(_a.T, _a) / np.sum(wt)\n    if cor:\n        sd = np.sqrt(np.diag(cov))\n        ans['cor'] = cov / sd / np.repeat([sd], p, axis=0).T\n    ans.update(cov=cov, center=loc, n_obs=n, iter=iteration)\n    return ans"
        ]
    }
]