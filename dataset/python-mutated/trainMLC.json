[
    {
        "func_name": "print_runningloss",
        "original": "def print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, phase):\n    epoch_loss = running_loss / dataset_sizes[phase]\n    print('{} Loss: {:.4f} '.format(phase, epoch_loss))\n    epoch_precision = running_precision / batch_num\n    print('{} Precision: {:.4f} '.format(phase, epoch_precision))\n    epoch_recall = running_recall / batch_num\n    print('{} Recall: {:.4f} '.format(phase, epoch_recall))\n    with open(os.path.join(args.checkpoint_path, 'losslog.txt'), 'a+', encoding='utf8') as f:\n        f.write(f'epoch: {epoch}\\tloss: {epoch_loss}\\tprecision: {epoch_precision}\\trecall: {epoch_recall}\\tphase: {phase}\\n')",
        "mutated": [
            "def print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, phase):\n    if False:\n        i = 10\n    epoch_loss = running_loss / dataset_sizes[phase]\n    print('{} Loss: {:.4f} '.format(phase, epoch_loss))\n    epoch_precision = running_precision / batch_num\n    print('{} Precision: {:.4f} '.format(phase, epoch_precision))\n    epoch_recall = running_recall / batch_num\n    print('{} Recall: {:.4f} '.format(phase, epoch_recall))\n    with open(os.path.join(args.checkpoint_path, 'losslog.txt'), 'a+', encoding='utf8') as f:\n        f.write(f'epoch: {epoch}\\tloss: {epoch_loss}\\tprecision: {epoch_precision}\\trecall: {epoch_recall}\\tphase: {phase}\\n')",
            "def print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, phase):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    epoch_loss = running_loss / dataset_sizes[phase]\n    print('{} Loss: {:.4f} '.format(phase, epoch_loss))\n    epoch_precision = running_precision / batch_num\n    print('{} Precision: {:.4f} '.format(phase, epoch_precision))\n    epoch_recall = running_recall / batch_num\n    print('{} Recall: {:.4f} '.format(phase, epoch_recall))\n    with open(os.path.join(args.checkpoint_path, 'losslog.txt'), 'a+', encoding='utf8') as f:\n        f.write(f'epoch: {epoch}\\tloss: {epoch_loss}\\tprecision: {epoch_precision}\\trecall: {epoch_recall}\\tphase: {phase}\\n')",
            "def print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, phase):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    epoch_loss = running_loss / dataset_sizes[phase]\n    print('{} Loss: {:.4f} '.format(phase, epoch_loss))\n    epoch_precision = running_precision / batch_num\n    print('{} Precision: {:.4f} '.format(phase, epoch_precision))\n    epoch_recall = running_recall / batch_num\n    print('{} Recall: {:.4f} '.format(phase, epoch_recall))\n    with open(os.path.join(args.checkpoint_path, 'losslog.txt'), 'a+', encoding='utf8') as f:\n        f.write(f'epoch: {epoch}\\tloss: {epoch_loss}\\tprecision: {epoch_precision}\\trecall: {epoch_recall}\\tphase: {phase}\\n')",
            "def print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, phase):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    epoch_loss = running_loss / dataset_sizes[phase]\n    print('{} Loss: {:.4f} '.format(phase, epoch_loss))\n    epoch_precision = running_precision / batch_num\n    print('{} Precision: {:.4f} '.format(phase, epoch_precision))\n    epoch_recall = running_recall / batch_num\n    print('{} Recall: {:.4f} '.format(phase, epoch_recall))\n    with open(os.path.join(args.checkpoint_path, 'losslog.txt'), 'a+', encoding='utf8') as f:\n        f.write(f'epoch: {epoch}\\tloss: {epoch_loss}\\tprecision: {epoch_precision}\\trecall: {epoch_recall}\\tphase: {phase}\\n')",
            "def print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, phase):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    epoch_loss = running_loss / dataset_sizes[phase]\n    print('{} Loss: {:.4f} '.format(phase, epoch_loss))\n    epoch_precision = running_precision / batch_num\n    print('{} Precision: {:.4f} '.format(phase, epoch_precision))\n    epoch_recall = running_recall / batch_num\n    print('{} Recall: {:.4f} '.format(phase, epoch_recall))\n    with open(os.path.join(args.checkpoint_path, 'losslog.txt'), 'a+', encoding='utf8') as f:\n        f.write(f'epoch: {epoch}\\tloss: {epoch_loss}\\tprecision: {epoch_precision}\\trecall: {epoch_recall}\\tphase: {phase}\\n')"
        ]
    },
    {
        "func_name": "train_model",
        "original": "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, starting_epoch=0):\n    sigmoid = nn.Sigmoid()\n    since = time.time()\n    for epoch in range(starting_epoch, num_epochs):\n        phase = 'trn'\n        if epoch % 5 == 0:\n            phase = 'val'\n        if phase:\n            running_loss = 0.0\n            running_precision = 0.0\n            running_recall = 0.0\n            batch_num = 0\n            print(f'\\n---- starting Epoch {epoch + 1}/{num_epochs} ----')\n            model.train()\n            for data in dataloaders['trn']:\n                (inputs, labels) = data\n                if use_gpu:\n                    inputs = inputs.cuda()\n                    labels = labels.cuda()\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(sigmoid(outputs), labels)\n                (precision, recall) = calculate_acc(sigmoid(outputs), labels)\n                running_precision += precision\n                running_recall += recall\n                batch_num += 1\n                loss.backward()\n                optimizer.step()\n                scheduler.step()\n                running_loss += loss.item() * inputs.size(0)\n            print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, 'trn')\n        if phase == 'val':\n            running_loss = 0.0\n            running_precision = 0.0\n            running_recall = 0.0\n            batch_num = 0\n            with torch.no_grad():\n                model.eval()\n                for data in dataloaders['val']:\n                    (inputs, labels) = data\n                    if use_gpu:\n                        inputs = inputs.cuda()\n                        labels = labels.cuda()\n                    outputs = model(inputs)\n                    loss = criterion(sigmoid(outputs), labels)\n                    running_loss += loss.item() * inputs.size(0)\n                    (precision, recall) = calculate_acc(sigmoid(outputs), labels)\n                    running_precision += precision\n                    running_recall += recall\n                    batch_num += 1\n            print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, 'val')\n            utils.save_checkpoint(model, optimizer, epoch, args.checkpoint_path)\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))",
        "mutated": [
            "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, starting_epoch=0):\n    if False:\n        i = 10\n    sigmoid = nn.Sigmoid()\n    since = time.time()\n    for epoch in range(starting_epoch, num_epochs):\n        phase = 'trn'\n        if epoch % 5 == 0:\n            phase = 'val'\n        if phase:\n            running_loss = 0.0\n            running_precision = 0.0\n            running_recall = 0.0\n            batch_num = 0\n            print(f'\\n---- starting Epoch {epoch + 1}/{num_epochs} ----')\n            model.train()\n            for data in dataloaders['trn']:\n                (inputs, labels) = data\n                if use_gpu:\n                    inputs = inputs.cuda()\n                    labels = labels.cuda()\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(sigmoid(outputs), labels)\n                (precision, recall) = calculate_acc(sigmoid(outputs), labels)\n                running_precision += precision\n                running_recall += recall\n                batch_num += 1\n                loss.backward()\n                optimizer.step()\n                scheduler.step()\n                running_loss += loss.item() * inputs.size(0)\n            print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, 'trn')\n        if phase == 'val':\n            running_loss = 0.0\n            running_precision = 0.0\n            running_recall = 0.0\n            batch_num = 0\n            with torch.no_grad():\n                model.eval()\n                for data in dataloaders['val']:\n                    (inputs, labels) = data\n                    if use_gpu:\n                        inputs = inputs.cuda()\n                        labels = labels.cuda()\n                    outputs = model(inputs)\n                    loss = criterion(sigmoid(outputs), labels)\n                    running_loss += loss.item() * inputs.size(0)\n                    (precision, recall) = calculate_acc(sigmoid(outputs), labels)\n                    running_precision += precision\n                    running_recall += recall\n                    batch_num += 1\n            print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, 'val')\n            utils.save_checkpoint(model, optimizer, epoch, args.checkpoint_path)\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))",
            "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, starting_epoch=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    sigmoid = nn.Sigmoid()\n    since = time.time()\n    for epoch in range(starting_epoch, num_epochs):\n        phase = 'trn'\n        if epoch % 5 == 0:\n            phase = 'val'\n        if phase:\n            running_loss = 0.0\n            running_precision = 0.0\n            running_recall = 0.0\n            batch_num = 0\n            print(f'\\n---- starting Epoch {epoch + 1}/{num_epochs} ----')\n            model.train()\n            for data in dataloaders['trn']:\n                (inputs, labels) = data\n                if use_gpu:\n                    inputs = inputs.cuda()\n                    labels = labels.cuda()\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(sigmoid(outputs), labels)\n                (precision, recall) = calculate_acc(sigmoid(outputs), labels)\n                running_precision += precision\n                running_recall += recall\n                batch_num += 1\n                loss.backward()\n                optimizer.step()\n                scheduler.step()\n                running_loss += loss.item() * inputs.size(0)\n            print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, 'trn')\n        if phase == 'val':\n            running_loss = 0.0\n            running_precision = 0.0\n            running_recall = 0.0\n            batch_num = 0\n            with torch.no_grad():\n                model.eval()\n                for data in dataloaders['val']:\n                    (inputs, labels) = data\n                    if use_gpu:\n                        inputs = inputs.cuda()\n                        labels = labels.cuda()\n                    outputs = model(inputs)\n                    loss = criterion(sigmoid(outputs), labels)\n                    running_loss += loss.item() * inputs.size(0)\n                    (precision, recall) = calculate_acc(sigmoid(outputs), labels)\n                    running_precision += precision\n                    running_recall += recall\n                    batch_num += 1\n            print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, 'val')\n            utils.save_checkpoint(model, optimizer, epoch, args.checkpoint_path)\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))",
            "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, starting_epoch=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    sigmoid = nn.Sigmoid()\n    since = time.time()\n    for epoch in range(starting_epoch, num_epochs):\n        phase = 'trn'\n        if epoch % 5 == 0:\n            phase = 'val'\n        if phase:\n            running_loss = 0.0\n            running_precision = 0.0\n            running_recall = 0.0\n            batch_num = 0\n            print(f'\\n---- starting Epoch {epoch + 1}/{num_epochs} ----')\n            model.train()\n            for data in dataloaders['trn']:\n                (inputs, labels) = data\n                if use_gpu:\n                    inputs = inputs.cuda()\n                    labels = labels.cuda()\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(sigmoid(outputs), labels)\n                (precision, recall) = calculate_acc(sigmoid(outputs), labels)\n                running_precision += precision\n                running_recall += recall\n                batch_num += 1\n                loss.backward()\n                optimizer.step()\n                scheduler.step()\n                running_loss += loss.item() * inputs.size(0)\n            print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, 'trn')\n        if phase == 'val':\n            running_loss = 0.0\n            running_precision = 0.0\n            running_recall = 0.0\n            batch_num = 0\n            with torch.no_grad():\n                model.eval()\n                for data in dataloaders['val']:\n                    (inputs, labels) = data\n                    if use_gpu:\n                        inputs = inputs.cuda()\n                        labels = labels.cuda()\n                    outputs = model(inputs)\n                    loss = criterion(sigmoid(outputs), labels)\n                    running_loss += loss.item() * inputs.size(0)\n                    (precision, recall) = calculate_acc(sigmoid(outputs), labels)\n                    running_precision += precision\n                    running_recall += recall\n                    batch_num += 1\n            print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, 'val')\n            utils.save_checkpoint(model, optimizer, epoch, args.checkpoint_path)\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))",
            "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, starting_epoch=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    sigmoid = nn.Sigmoid()\n    since = time.time()\n    for epoch in range(starting_epoch, num_epochs):\n        phase = 'trn'\n        if epoch % 5 == 0:\n            phase = 'val'\n        if phase:\n            running_loss = 0.0\n            running_precision = 0.0\n            running_recall = 0.0\n            batch_num = 0\n            print(f'\\n---- starting Epoch {epoch + 1}/{num_epochs} ----')\n            model.train()\n            for data in dataloaders['trn']:\n                (inputs, labels) = data\n                if use_gpu:\n                    inputs = inputs.cuda()\n                    labels = labels.cuda()\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(sigmoid(outputs), labels)\n                (precision, recall) = calculate_acc(sigmoid(outputs), labels)\n                running_precision += precision\n                running_recall += recall\n                batch_num += 1\n                loss.backward()\n                optimizer.step()\n                scheduler.step()\n                running_loss += loss.item() * inputs.size(0)\n            print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, 'trn')\n        if phase == 'val':\n            running_loss = 0.0\n            running_precision = 0.0\n            running_recall = 0.0\n            batch_num = 0\n            with torch.no_grad():\n                model.eval()\n                for data in dataloaders['val']:\n                    (inputs, labels) = data\n                    if use_gpu:\n                        inputs = inputs.cuda()\n                        labels = labels.cuda()\n                    outputs = model(inputs)\n                    loss = criterion(sigmoid(outputs), labels)\n                    running_loss += loss.item() * inputs.size(0)\n                    (precision, recall) = calculate_acc(sigmoid(outputs), labels)\n                    running_precision += precision\n                    running_recall += recall\n                    batch_num += 1\n            print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, 'val')\n            utils.save_checkpoint(model, optimizer, epoch, args.checkpoint_path)\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))",
            "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, starting_epoch=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    sigmoid = nn.Sigmoid()\n    since = time.time()\n    for epoch in range(starting_epoch, num_epochs):\n        phase = 'trn'\n        if epoch % 5 == 0:\n            phase = 'val'\n        if phase:\n            running_loss = 0.0\n            running_precision = 0.0\n            running_recall = 0.0\n            batch_num = 0\n            print(f'\\n---- starting Epoch {epoch + 1}/{num_epochs} ----')\n            model.train()\n            for data in dataloaders['trn']:\n                (inputs, labels) = data\n                if use_gpu:\n                    inputs = inputs.cuda()\n                    labels = labels.cuda()\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(sigmoid(outputs), labels)\n                (precision, recall) = calculate_acc(sigmoid(outputs), labels)\n                running_precision += precision\n                running_recall += recall\n                batch_num += 1\n                loss.backward()\n                optimizer.step()\n                scheduler.step()\n                running_loss += loss.item() * inputs.size(0)\n            print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, 'trn')\n        if phase == 'val':\n            running_loss = 0.0\n            running_precision = 0.0\n            running_recall = 0.0\n            batch_num = 0\n            with torch.no_grad():\n                model.eval()\n                for data in dataloaders['val']:\n                    (inputs, labels) = data\n                    if use_gpu:\n                        inputs = inputs.cuda()\n                        labels = labels.cuda()\n                    outputs = model(inputs)\n                    loss = criterion(sigmoid(outputs), labels)\n                    running_loss += loss.item() * inputs.size(0)\n                    (precision, recall) = calculate_acc(sigmoid(outputs), labels)\n                    running_precision += precision\n                    running_recall += recall\n                    batch_num += 1\n            print_runningloss(epoch, running_loss, running_precision, running_recall, batch_num, 'val')\n            utils.save_checkpoint(model, optimizer, epoch, args.checkpoint_path)\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
        ]
    },
    {
        "func_name": "calculate_acc",
        "original": "def calculate_acc(model_pred, labels):\n    precision = 0\n    recall = 0\n    tops = torch.sum(labels, dim=1)\n    batch_size = model_pred.shape[0]\n    for bat in range(batch_size):\n        top = tops[bat]\n        pred_label_locate = torch.argsort(model_pred, descending=True)[:, :int(top)]\n        tmp_label = torch.zeros(1, model_pred.shape[1]).cuda()\n        tmp_label[0, pred_label_locate[bat]] = 1\n        target_num = torch.sum(labels[bat])\n        pred_num_true = torch.sum(tmp_label * labels[bat])\n        precision += pred_num_true / top\n        recall += pred_num_true / target_num\n    return (precision / batch_size, recall / batch_size)",
        "mutated": [
            "def calculate_acc(model_pred, labels):\n    if False:\n        i = 10\n    precision = 0\n    recall = 0\n    tops = torch.sum(labels, dim=1)\n    batch_size = model_pred.shape[0]\n    for bat in range(batch_size):\n        top = tops[bat]\n        pred_label_locate = torch.argsort(model_pred, descending=True)[:, :int(top)]\n        tmp_label = torch.zeros(1, model_pred.shape[1]).cuda()\n        tmp_label[0, pred_label_locate[bat]] = 1\n        target_num = torch.sum(labels[bat])\n        pred_num_true = torch.sum(tmp_label * labels[bat])\n        precision += pred_num_true / top\n        recall += pred_num_true / target_num\n    return (precision / batch_size, recall / batch_size)",
            "def calculate_acc(model_pred, labels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    precision = 0\n    recall = 0\n    tops = torch.sum(labels, dim=1)\n    batch_size = model_pred.shape[0]\n    for bat in range(batch_size):\n        top = tops[bat]\n        pred_label_locate = torch.argsort(model_pred, descending=True)[:, :int(top)]\n        tmp_label = torch.zeros(1, model_pred.shape[1]).cuda()\n        tmp_label[0, pred_label_locate[bat]] = 1\n        target_num = torch.sum(labels[bat])\n        pred_num_true = torch.sum(tmp_label * labels[bat])\n        precision += pred_num_true / top\n        recall += pred_num_true / target_num\n    return (precision / batch_size, recall / batch_size)",
            "def calculate_acc(model_pred, labels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    precision = 0\n    recall = 0\n    tops = torch.sum(labels, dim=1)\n    batch_size = model_pred.shape[0]\n    for bat in range(batch_size):\n        top = tops[bat]\n        pred_label_locate = torch.argsort(model_pred, descending=True)[:, :int(top)]\n        tmp_label = torch.zeros(1, model_pred.shape[1]).cuda()\n        tmp_label[0, pred_label_locate[bat]] = 1\n        target_num = torch.sum(labels[bat])\n        pred_num_true = torch.sum(tmp_label * labels[bat])\n        precision += pred_num_true / top\n        recall += pred_num_true / target_num\n    return (precision / batch_size, recall / batch_size)",
            "def calculate_acc(model_pred, labels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    precision = 0\n    recall = 0\n    tops = torch.sum(labels, dim=1)\n    batch_size = model_pred.shape[0]\n    for bat in range(batch_size):\n        top = tops[bat]\n        pred_label_locate = torch.argsort(model_pred, descending=True)[:, :int(top)]\n        tmp_label = torch.zeros(1, model_pred.shape[1]).cuda()\n        tmp_label[0, pred_label_locate[bat]] = 1\n        target_num = torch.sum(labels[bat])\n        pred_num_true = torch.sum(tmp_label * labels[bat])\n        precision += pred_num_true / top\n        recall += pred_num_true / target_num\n    return (precision / batch_size, recall / batch_size)",
            "def calculate_acc(model_pred, labels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    precision = 0\n    recall = 0\n    tops = torch.sum(labels, dim=1)\n    batch_size = model_pred.shape[0]\n    for bat in range(batch_size):\n        top = tops[bat]\n        pred_label_locate = torch.argsort(model_pred, descending=True)[:, :int(top)]\n        tmp_label = torch.zeros(1, model_pred.shape[1]).cuda()\n        tmp_label[0, pred_label_locate[bat]] = 1\n        target_num = torch.sum(labels[bat])\n        pred_num_true = torch.sum(tmp_label * labels[bat])\n        precision += pred_num_true / top\n        recall += pred_num_true / target_num\n    return (precision / batch_size, recall / batch_size)"
        ]
    },
    {
        "func_name": "main",
        "original": "def main():\n    num_labels = trn_data.dataset.getNumLabels()\n    model = None\n    starting_epoch = 0\n    try:\n        (saved_model, iteration, _, _) = utils.load_checkpoint(utils.get_latest_checkpoint(args.checkpoint, 'cv_*.pth'))\n        model = saved_model\n        starting_epoch = iteration\n        print(f'successfully loading checkpoint cv_{iteration}.pth')\n    except:\n        model = models.resnet50(weights='DEFAULT')\n    in_features = model.fc.in_features\n    model.fc = nn.Sequential(nn.Linear(in_features, 1024), nn.ReLU(), nn.Dropout(0.5), nn.Linear(1024, num_labels), nn.LogSoftmax(dim=1))\n    if use_gpu:\n        model = model.cuda()\n    criterion = nn.BCELoss()\n    optimizer_ft = torch.optim.AdamW(model.parameters(), args.learning_rate, eps=1e-09, betas=[0.8, 0.99])\n    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)\n    train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=args.num_epochs, starting_epoch=starting_epoch)",
        "mutated": [
            "def main():\n    if False:\n        i = 10\n    num_labels = trn_data.dataset.getNumLabels()\n    model = None\n    starting_epoch = 0\n    try:\n        (saved_model, iteration, _, _) = utils.load_checkpoint(utils.get_latest_checkpoint(args.checkpoint, 'cv_*.pth'))\n        model = saved_model\n        starting_epoch = iteration\n        print(f'successfully loading checkpoint cv_{iteration}.pth')\n    except:\n        model = models.resnet50(weights='DEFAULT')\n    in_features = model.fc.in_features\n    model.fc = nn.Sequential(nn.Linear(in_features, 1024), nn.ReLU(), nn.Dropout(0.5), nn.Linear(1024, num_labels), nn.LogSoftmax(dim=1))\n    if use_gpu:\n        model = model.cuda()\n    criterion = nn.BCELoss()\n    optimizer_ft = torch.optim.AdamW(model.parameters(), args.learning_rate, eps=1e-09, betas=[0.8, 0.99])\n    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)\n    train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=args.num_epochs, starting_epoch=starting_epoch)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    num_labels = trn_data.dataset.getNumLabels()\n    model = None\n    starting_epoch = 0\n    try:\n        (saved_model, iteration, _, _) = utils.load_checkpoint(utils.get_latest_checkpoint(args.checkpoint, 'cv_*.pth'))\n        model = saved_model\n        starting_epoch = iteration\n        print(f'successfully loading checkpoint cv_{iteration}.pth')\n    except:\n        model = models.resnet50(weights='DEFAULT')\n    in_features = model.fc.in_features\n    model.fc = nn.Sequential(nn.Linear(in_features, 1024), nn.ReLU(), nn.Dropout(0.5), nn.Linear(1024, num_labels), nn.LogSoftmax(dim=1))\n    if use_gpu:\n        model = model.cuda()\n    criterion = nn.BCELoss()\n    optimizer_ft = torch.optim.AdamW(model.parameters(), args.learning_rate, eps=1e-09, betas=[0.8, 0.99])\n    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)\n    train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=args.num_epochs, starting_epoch=starting_epoch)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    num_labels = trn_data.dataset.getNumLabels()\n    model = None\n    starting_epoch = 0\n    try:\n        (saved_model, iteration, _, _) = utils.load_checkpoint(utils.get_latest_checkpoint(args.checkpoint, 'cv_*.pth'))\n        model = saved_model\n        starting_epoch = iteration\n        print(f'successfully loading checkpoint cv_{iteration}.pth')\n    except:\n        model = models.resnet50(weights='DEFAULT')\n    in_features = model.fc.in_features\n    model.fc = nn.Sequential(nn.Linear(in_features, 1024), nn.ReLU(), nn.Dropout(0.5), nn.Linear(1024, num_labels), nn.LogSoftmax(dim=1))\n    if use_gpu:\n        model = model.cuda()\n    criterion = nn.BCELoss()\n    optimizer_ft = torch.optim.AdamW(model.parameters(), args.learning_rate, eps=1e-09, betas=[0.8, 0.99])\n    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)\n    train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=args.num_epochs, starting_epoch=starting_epoch)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    num_labels = trn_data.dataset.getNumLabels()\n    model = None\n    starting_epoch = 0\n    try:\n        (saved_model, iteration, _, _) = utils.load_checkpoint(utils.get_latest_checkpoint(args.checkpoint, 'cv_*.pth'))\n        model = saved_model\n        starting_epoch = iteration\n        print(f'successfully loading checkpoint cv_{iteration}.pth')\n    except:\n        model = models.resnet50(weights='DEFAULT')\n    in_features = model.fc.in_features\n    model.fc = nn.Sequential(nn.Linear(in_features, 1024), nn.ReLU(), nn.Dropout(0.5), nn.Linear(1024, num_labels), nn.LogSoftmax(dim=1))\n    if use_gpu:\n        model = model.cuda()\n    criterion = nn.BCELoss()\n    optimizer_ft = torch.optim.AdamW(model.parameters(), args.learning_rate, eps=1e-09, betas=[0.8, 0.99])\n    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)\n    train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=args.num_epochs, starting_epoch=starting_epoch)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    num_labels = trn_data.dataset.getNumLabels()\n    model = None\n    starting_epoch = 0\n    try:\n        (saved_model, iteration, _, _) = utils.load_checkpoint(utils.get_latest_checkpoint(args.checkpoint, 'cv_*.pth'))\n        model = saved_model\n        starting_epoch = iteration\n        print(f'successfully loading checkpoint cv_{iteration}.pth')\n    except:\n        model = models.resnet50(weights='DEFAULT')\n    in_features = model.fc.in_features\n    model.fc = nn.Sequential(nn.Linear(in_features, 1024), nn.ReLU(), nn.Dropout(0.5), nn.Linear(1024, num_labels), nn.LogSoftmax(dim=1))\n    if use_gpu:\n        model = model.cuda()\n    criterion = nn.BCELoss()\n    optimizer_ft = torch.optim.AdamW(model.parameters(), args.learning_rate, eps=1e-09, betas=[0.8, 0.99])\n    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)\n    train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=args.num_epochs, starting_epoch=starting_epoch)"
        ]
    }
]