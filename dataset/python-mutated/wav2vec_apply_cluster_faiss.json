[
    {
        "func_name": "get_parser",
        "original": "def get_parser():\n    parser = argparse.ArgumentParser(description='apply clusters')\n    parser.add_argument('data', help='location of tsv files')\n    parser.add_argument('--split', help='split to process', required=True)\n    parser.add_argument('--labels', help='split to process', default='phn')\n    parser.add_argument('--path', help='path to pca and centroids', required=True)\n    parser.add_argument('--checkpoint', type=str, help='checkpoint for wav2vec model (if using wav2vec features)', required=True)\n    parser.add_argument('--layer', '-l', type=int, help='which layer to read', default=14)\n    parser.add_argument('--max-tsz', type=int, help='batch kmeans up to this much', default=14)\n    return parser",
        "mutated": [
            "def get_parser():\n    if False:\n        i = 10\n    parser = argparse.ArgumentParser(description='apply clusters')\n    parser.add_argument('data', help='location of tsv files')\n    parser.add_argument('--split', help='split to process', required=True)\n    parser.add_argument('--labels', help='split to process', default='phn')\n    parser.add_argument('--path', help='path to pca and centroids', required=True)\n    parser.add_argument('--checkpoint', type=str, help='checkpoint for wav2vec model (if using wav2vec features)', required=True)\n    parser.add_argument('--layer', '-l', type=int, help='which layer to read', default=14)\n    parser.add_argument('--max-tsz', type=int, help='batch kmeans up to this much', default=14)\n    return parser",
            "def get_parser():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    parser = argparse.ArgumentParser(description='apply clusters')\n    parser.add_argument('data', help='location of tsv files')\n    parser.add_argument('--split', help='split to process', required=True)\n    parser.add_argument('--labels', help='split to process', default='phn')\n    parser.add_argument('--path', help='path to pca and centroids', required=True)\n    parser.add_argument('--checkpoint', type=str, help='checkpoint for wav2vec model (if using wav2vec features)', required=True)\n    parser.add_argument('--layer', '-l', type=int, help='which layer to read', default=14)\n    parser.add_argument('--max-tsz', type=int, help='batch kmeans up to this much', default=14)\n    return parser",
            "def get_parser():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    parser = argparse.ArgumentParser(description='apply clusters')\n    parser.add_argument('data', help='location of tsv files')\n    parser.add_argument('--split', help='split to process', required=True)\n    parser.add_argument('--labels', help='split to process', default='phn')\n    parser.add_argument('--path', help='path to pca and centroids', required=True)\n    parser.add_argument('--checkpoint', type=str, help='checkpoint for wav2vec model (if using wav2vec features)', required=True)\n    parser.add_argument('--layer', '-l', type=int, help='which layer to read', default=14)\n    parser.add_argument('--max-tsz', type=int, help='batch kmeans up to this much', default=14)\n    return parser",
            "def get_parser():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    parser = argparse.ArgumentParser(description='apply clusters')\n    parser.add_argument('data', help='location of tsv files')\n    parser.add_argument('--split', help='split to process', required=True)\n    parser.add_argument('--labels', help='split to process', default='phn')\n    parser.add_argument('--path', help='path to pca and centroids', required=True)\n    parser.add_argument('--checkpoint', type=str, help='checkpoint for wav2vec model (if using wav2vec features)', required=True)\n    parser.add_argument('--layer', '-l', type=int, help='which layer to read', default=14)\n    parser.add_argument('--max-tsz', type=int, help='batch kmeans up to this much', default=14)\n    return parser",
            "def get_parser():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    parser = argparse.ArgumentParser(description='apply clusters')\n    parser.add_argument('data', help='location of tsv files')\n    parser.add_argument('--split', help='split to process', required=True)\n    parser.add_argument('--labels', help='split to process', default='phn')\n    parser.add_argument('--path', help='path to pca and centroids', required=True)\n    parser.add_argument('--checkpoint', type=str, help='checkpoint for wav2vec model (if using wav2vec features)', required=True)\n    parser.add_argument('--layer', '-l', type=int, help='which layer to read', default=14)\n    parser.add_argument('--max-tsz', type=int, help='batch kmeans up to this much', default=14)\n    return parser"
        ]
    },
    {
        "func_name": "iterate",
        "original": "def iterate():\n    for (fname, lbl) in zip(files, lbls):\n        file = osp.join(root, fname.split('\\t')[0])\n        feats = reader.get_feats(file)\n        yield (feats.data, fname, lbl)",
        "mutated": [
            "def iterate():\n    if False:\n        i = 10\n    for (fname, lbl) in zip(files, lbls):\n        file = osp.join(root, fname.split('\\t')[0])\n        feats = reader.get_feats(file)\n        yield (feats.data, fname, lbl)",
            "def iterate():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    for (fname, lbl) in zip(files, lbls):\n        file = osp.join(root, fname.split('\\t')[0])\n        feats = reader.get_feats(file)\n        yield (feats.data, fname, lbl)",
            "def iterate():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    for (fname, lbl) in zip(files, lbls):\n        file = osp.join(root, fname.split('\\t')[0])\n        feats = reader.get_feats(file)\n        yield (feats.data, fname, lbl)",
            "def iterate():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    for (fname, lbl) in zip(files, lbls):\n        file = osp.join(root, fname.split('\\t')[0])\n        feats = reader.get_feats(file)\n        yield (feats.data, fname, lbl)",
            "def iterate():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    for (fname, lbl) in zip(files, lbls):\n        file = osp.join(root, fname.split('\\t')[0])\n        feats = reader.get_feats(file)\n        yield (feats.data, fname, lbl)"
        ]
    },
    {
        "func_name": "get_iterator",
        "original": "def get_iterator(args):\n    label_path = osp.join(args.data, f'{args.split}.{args.labels}')\n    if osp.exists(label_path):\n        lp = open(label_path, 'r')\n    else:\n        lp = None\n    with open(osp.join(args.data, f'{args.split}.tsv'), 'r') as fp:\n        lines = fp.read().split('\\n')\n        root = lines.pop(0).strip()\n        files = [line.rstrip() for line in lines if len(line) > 0]\n        if lp is not None:\n            lbls = [line.rstrip() for line in lp]\n        else:\n            lbls = [None] * len(files)\n        num = len(files)\n        reader = Wav2VecFeatureReader(args.checkpoint, args.layer)\n\n        def iterate():\n            for (fname, lbl) in zip(files, lbls):\n                file = osp.join(root, fname.split('\\t')[0])\n                feats = reader.get_feats(file)\n                yield (feats.data, fname, lbl)\n        return (iterate, num, root)",
        "mutated": [
            "def get_iterator(args):\n    if False:\n        i = 10\n    label_path = osp.join(args.data, f'{args.split}.{args.labels}')\n    if osp.exists(label_path):\n        lp = open(label_path, 'r')\n    else:\n        lp = None\n    with open(osp.join(args.data, f'{args.split}.tsv'), 'r') as fp:\n        lines = fp.read().split('\\n')\n        root = lines.pop(0).strip()\n        files = [line.rstrip() for line in lines if len(line) > 0]\n        if lp is not None:\n            lbls = [line.rstrip() for line in lp]\n        else:\n            lbls = [None] * len(files)\n        num = len(files)\n        reader = Wav2VecFeatureReader(args.checkpoint, args.layer)\n\n        def iterate():\n            for (fname, lbl) in zip(files, lbls):\n                file = osp.join(root, fname.split('\\t')[0])\n                feats = reader.get_feats(file)\n                yield (feats.data, fname, lbl)\n        return (iterate, num, root)",
            "def get_iterator(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    label_path = osp.join(args.data, f'{args.split}.{args.labels}')\n    if osp.exists(label_path):\n        lp = open(label_path, 'r')\n    else:\n        lp = None\n    with open(osp.join(args.data, f'{args.split}.tsv'), 'r') as fp:\n        lines = fp.read().split('\\n')\n        root = lines.pop(0).strip()\n        files = [line.rstrip() for line in lines if len(line) > 0]\n        if lp is not None:\n            lbls = [line.rstrip() for line in lp]\n        else:\n            lbls = [None] * len(files)\n        num = len(files)\n        reader = Wav2VecFeatureReader(args.checkpoint, args.layer)\n\n        def iterate():\n            for (fname, lbl) in zip(files, lbls):\n                file = osp.join(root, fname.split('\\t')[0])\n                feats = reader.get_feats(file)\n                yield (feats.data, fname, lbl)\n        return (iterate, num, root)",
            "def get_iterator(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    label_path = osp.join(args.data, f'{args.split}.{args.labels}')\n    if osp.exists(label_path):\n        lp = open(label_path, 'r')\n    else:\n        lp = None\n    with open(osp.join(args.data, f'{args.split}.tsv'), 'r') as fp:\n        lines = fp.read().split('\\n')\n        root = lines.pop(0).strip()\n        files = [line.rstrip() for line in lines if len(line) > 0]\n        if lp is not None:\n            lbls = [line.rstrip() for line in lp]\n        else:\n            lbls = [None] * len(files)\n        num = len(files)\n        reader = Wav2VecFeatureReader(args.checkpoint, args.layer)\n\n        def iterate():\n            for (fname, lbl) in zip(files, lbls):\n                file = osp.join(root, fname.split('\\t')[0])\n                feats = reader.get_feats(file)\n                yield (feats.data, fname, lbl)\n        return (iterate, num, root)",
            "def get_iterator(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    label_path = osp.join(args.data, f'{args.split}.{args.labels}')\n    if osp.exists(label_path):\n        lp = open(label_path, 'r')\n    else:\n        lp = None\n    with open(osp.join(args.data, f'{args.split}.tsv'), 'r') as fp:\n        lines = fp.read().split('\\n')\n        root = lines.pop(0).strip()\n        files = [line.rstrip() for line in lines if len(line) > 0]\n        if lp is not None:\n            lbls = [line.rstrip() for line in lp]\n        else:\n            lbls = [None] * len(files)\n        num = len(files)\n        reader = Wav2VecFeatureReader(args.checkpoint, args.layer)\n\n        def iterate():\n            for (fname, lbl) in zip(files, lbls):\n                file = osp.join(root, fname.split('\\t')[0])\n                feats = reader.get_feats(file)\n                yield (feats.data, fname, lbl)\n        return (iterate, num, root)",
            "def get_iterator(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    label_path = osp.join(args.data, f'{args.split}.{args.labels}')\n    if osp.exists(label_path):\n        lp = open(label_path, 'r')\n    else:\n        lp = None\n    with open(osp.join(args.data, f'{args.split}.tsv'), 'r') as fp:\n        lines = fp.read().split('\\n')\n        root = lines.pop(0).strip()\n        files = [line.rstrip() for line in lines if len(line) > 0]\n        if lp is not None:\n            lbls = [line.rstrip() for line in lp]\n        else:\n            lbls = [None] * len(files)\n        num = len(files)\n        reader = Wav2VecFeatureReader(args.checkpoint, args.layer)\n\n        def iterate():\n            for (fname, lbl) in zip(files, lbls):\n                file = osp.join(root, fname.split('\\t')[0])\n                feats = reader.get_feats(file)\n                yield (feats.data, fname, lbl)\n        return (iterate, num, root)"
        ]
    },
    {
        "func_name": "main",
        "original": "def main():\n    parser = get_parser()\n    args = parser.parse_args()\n    spec = osp.basename(args.path)\n    try:\n        faiss_spec = parse_faiss_specs(spec.rstrip('/'))[0]\n    except:\n        print(spec)\n        raise\n    print('Faiss Spec:', faiss_spec, file=sys.stderr)\n    if faiss_spec.pca:\n        A = torch.from_numpy(np.load(osp.join(args.path, 'pca_A.npy'))).cuda()\n        b = torch.from_numpy(np.load(osp.join(args.path, 'pca_b.npy'))).cuda()\n        print('Loaded PCA', file=sys.stderr)\n    centroids = np.load(osp.join(args.path, 'centroids.npy'))\n    print('Loaded centroids', centroids.shape, file=sys.stderr)\n    res = faiss.StandardGpuResources()\n    index_flat = faiss.IndexFlatL2(centroids.shape[1]) if not faiss_spec.sphere else faiss.IndexFlatIP(centroids.shape[1])\n    faiss_index = faiss.index_cpu_to_gpu(res, 0, index_flat)\n    faiss_index.add(centroids)\n    (generator, num, root) = get_iterator(args)\n    iterator = generator()\n    had_labels = False\n    label_path = osp.join(args.path, f'{args.split}.{args.labels}')\n    with torch.no_grad():\n        with open(osp.join(args.path, f'{args.split}.src'), 'w') as fp, open(osp.join(args.path, f'{args.split}.tsv'), 'w') as pp, open(label_path, 'w') as lp:\n            print(root, file=pp)\n            for (f, fname, lbl) in tqdm.tqdm(iterator, total=num):\n                if faiss_spec.pca:\n                    f = torch.mm(f, A) + b\n                if faiss_spec.norm:\n                    f = F.normalize(f, p=2, dim=-1)\n                f = f.cpu().numpy()\n                (_, z) = faiss_index.search(f, 1)\n                print(' '.join((str(x.item()) for x in z)), file=fp)\n                print(fname, file=pp)\n                if lbl is not None:\n                    print(lbl, file=lp)\n                    had_labels = True\n    if not had_labels:\n        os.remove(label_path)",
        "mutated": [
            "def main():\n    if False:\n        i = 10\n    parser = get_parser()\n    args = parser.parse_args()\n    spec = osp.basename(args.path)\n    try:\n        faiss_spec = parse_faiss_specs(spec.rstrip('/'))[0]\n    except:\n        print(spec)\n        raise\n    print('Faiss Spec:', faiss_spec, file=sys.stderr)\n    if faiss_spec.pca:\n        A = torch.from_numpy(np.load(osp.join(args.path, 'pca_A.npy'))).cuda()\n        b = torch.from_numpy(np.load(osp.join(args.path, 'pca_b.npy'))).cuda()\n        print('Loaded PCA', file=sys.stderr)\n    centroids = np.load(osp.join(args.path, 'centroids.npy'))\n    print('Loaded centroids', centroids.shape, file=sys.stderr)\n    res = faiss.StandardGpuResources()\n    index_flat = faiss.IndexFlatL2(centroids.shape[1]) if not faiss_spec.sphere else faiss.IndexFlatIP(centroids.shape[1])\n    faiss_index = faiss.index_cpu_to_gpu(res, 0, index_flat)\n    faiss_index.add(centroids)\n    (generator, num, root) = get_iterator(args)\n    iterator = generator()\n    had_labels = False\n    label_path = osp.join(args.path, f'{args.split}.{args.labels}')\n    with torch.no_grad():\n        with open(osp.join(args.path, f'{args.split}.src'), 'w') as fp, open(osp.join(args.path, f'{args.split}.tsv'), 'w') as pp, open(label_path, 'w') as lp:\n            print(root, file=pp)\n            for (f, fname, lbl) in tqdm.tqdm(iterator, total=num):\n                if faiss_spec.pca:\n                    f = torch.mm(f, A) + b\n                if faiss_spec.norm:\n                    f = F.normalize(f, p=2, dim=-1)\n                f = f.cpu().numpy()\n                (_, z) = faiss_index.search(f, 1)\n                print(' '.join((str(x.item()) for x in z)), file=fp)\n                print(fname, file=pp)\n                if lbl is not None:\n                    print(lbl, file=lp)\n                    had_labels = True\n    if not had_labels:\n        os.remove(label_path)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    parser = get_parser()\n    args = parser.parse_args()\n    spec = osp.basename(args.path)\n    try:\n        faiss_spec = parse_faiss_specs(spec.rstrip('/'))[0]\n    except:\n        print(spec)\n        raise\n    print('Faiss Spec:', faiss_spec, file=sys.stderr)\n    if faiss_spec.pca:\n        A = torch.from_numpy(np.load(osp.join(args.path, 'pca_A.npy'))).cuda()\n        b = torch.from_numpy(np.load(osp.join(args.path, 'pca_b.npy'))).cuda()\n        print('Loaded PCA', file=sys.stderr)\n    centroids = np.load(osp.join(args.path, 'centroids.npy'))\n    print('Loaded centroids', centroids.shape, file=sys.stderr)\n    res = faiss.StandardGpuResources()\n    index_flat = faiss.IndexFlatL2(centroids.shape[1]) if not faiss_spec.sphere else faiss.IndexFlatIP(centroids.shape[1])\n    faiss_index = faiss.index_cpu_to_gpu(res, 0, index_flat)\n    faiss_index.add(centroids)\n    (generator, num, root) = get_iterator(args)\n    iterator = generator()\n    had_labels = False\n    label_path = osp.join(args.path, f'{args.split}.{args.labels}')\n    with torch.no_grad():\n        with open(osp.join(args.path, f'{args.split}.src'), 'w') as fp, open(osp.join(args.path, f'{args.split}.tsv'), 'w') as pp, open(label_path, 'w') as lp:\n            print(root, file=pp)\n            for (f, fname, lbl) in tqdm.tqdm(iterator, total=num):\n                if faiss_spec.pca:\n                    f = torch.mm(f, A) + b\n                if faiss_spec.norm:\n                    f = F.normalize(f, p=2, dim=-1)\n                f = f.cpu().numpy()\n                (_, z) = faiss_index.search(f, 1)\n                print(' '.join((str(x.item()) for x in z)), file=fp)\n                print(fname, file=pp)\n                if lbl is not None:\n                    print(lbl, file=lp)\n                    had_labels = True\n    if not had_labels:\n        os.remove(label_path)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    parser = get_parser()\n    args = parser.parse_args()\n    spec = osp.basename(args.path)\n    try:\n        faiss_spec = parse_faiss_specs(spec.rstrip('/'))[0]\n    except:\n        print(spec)\n        raise\n    print('Faiss Spec:', faiss_spec, file=sys.stderr)\n    if faiss_spec.pca:\n        A = torch.from_numpy(np.load(osp.join(args.path, 'pca_A.npy'))).cuda()\n        b = torch.from_numpy(np.load(osp.join(args.path, 'pca_b.npy'))).cuda()\n        print('Loaded PCA', file=sys.stderr)\n    centroids = np.load(osp.join(args.path, 'centroids.npy'))\n    print('Loaded centroids', centroids.shape, file=sys.stderr)\n    res = faiss.StandardGpuResources()\n    index_flat = faiss.IndexFlatL2(centroids.shape[1]) if not faiss_spec.sphere else faiss.IndexFlatIP(centroids.shape[1])\n    faiss_index = faiss.index_cpu_to_gpu(res, 0, index_flat)\n    faiss_index.add(centroids)\n    (generator, num, root) = get_iterator(args)\n    iterator = generator()\n    had_labels = False\n    label_path = osp.join(args.path, f'{args.split}.{args.labels}')\n    with torch.no_grad():\n        with open(osp.join(args.path, f'{args.split}.src'), 'w') as fp, open(osp.join(args.path, f'{args.split}.tsv'), 'w') as pp, open(label_path, 'w') as lp:\n            print(root, file=pp)\n            for (f, fname, lbl) in tqdm.tqdm(iterator, total=num):\n                if faiss_spec.pca:\n                    f = torch.mm(f, A) + b\n                if faiss_spec.norm:\n                    f = F.normalize(f, p=2, dim=-1)\n                f = f.cpu().numpy()\n                (_, z) = faiss_index.search(f, 1)\n                print(' '.join((str(x.item()) for x in z)), file=fp)\n                print(fname, file=pp)\n                if lbl is not None:\n                    print(lbl, file=lp)\n                    had_labels = True\n    if not had_labels:\n        os.remove(label_path)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    parser = get_parser()\n    args = parser.parse_args()\n    spec = osp.basename(args.path)\n    try:\n        faiss_spec = parse_faiss_specs(spec.rstrip('/'))[0]\n    except:\n        print(spec)\n        raise\n    print('Faiss Spec:', faiss_spec, file=sys.stderr)\n    if faiss_spec.pca:\n        A = torch.from_numpy(np.load(osp.join(args.path, 'pca_A.npy'))).cuda()\n        b = torch.from_numpy(np.load(osp.join(args.path, 'pca_b.npy'))).cuda()\n        print('Loaded PCA', file=sys.stderr)\n    centroids = np.load(osp.join(args.path, 'centroids.npy'))\n    print('Loaded centroids', centroids.shape, file=sys.stderr)\n    res = faiss.StandardGpuResources()\n    index_flat = faiss.IndexFlatL2(centroids.shape[1]) if not faiss_spec.sphere else faiss.IndexFlatIP(centroids.shape[1])\n    faiss_index = faiss.index_cpu_to_gpu(res, 0, index_flat)\n    faiss_index.add(centroids)\n    (generator, num, root) = get_iterator(args)\n    iterator = generator()\n    had_labels = False\n    label_path = osp.join(args.path, f'{args.split}.{args.labels}')\n    with torch.no_grad():\n        with open(osp.join(args.path, f'{args.split}.src'), 'w') as fp, open(osp.join(args.path, f'{args.split}.tsv'), 'w') as pp, open(label_path, 'w') as lp:\n            print(root, file=pp)\n            for (f, fname, lbl) in tqdm.tqdm(iterator, total=num):\n                if faiss_spec.pca:\n                    f = torch.mm(f, A) + b\n                if faiss_spec.norm:\n                    f = F.normalize(f, p=2, dim=-1)\n                f = f.cpu().numpy()\n                (_, z) = faiss_index.search(f, 1)\n                print(' '.join((str(x.item()) for x in z)), file=fp)\n                print(fname, file=pp)\n                if lbl is not None:\n                    print(lbl, file=lp)\n                    had_labels = True\n    if not had_labels:\n        os.remove(label_path)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    parser = get_parser()\n    args = parser.parse_args()\n    spec = osp.basename(args.path)\n    try:\n        faiss_spec = parse_faiss_specs(spec.rstrip('/'))[0]\n    except:\n        print(spec)\n        raise\n    print('Faiss Spec:', faiss_spec, file=sys.stderr)\n    if faiss_spec.pca:\n        A = torch.from_numpy(np.load(osp.join(args.path, 'pca_A.npy'))).cuda()\n        b = torch.from_numpy(np.load(osp.join(args.path, 'pca_b.npy'))).cuda()\n        print('Loaded PCA', file=sys.stderr)\n    centroids = np.load(osp.join(args.path, 'centroids.npy'))\n    print('Loaded centroids', centroids.shape, file=sys.stderr)\n    res = faiss.StandardGpuResources()\n    index_flat = faiss.IndexFlatL2(centroids.shape[1]) if not faiss_spec.sphere else faiss.IndexFlatIP(centroids.shape[1])\n    faiss_index = faiss.index_cpu_to_gpu(res, 0, index_flat)\n    faiss_index.add(centroids)\n    (generator, num, root) = get_iterator(args)\n    iterator = generator()\n    had_labels = False\n    label_path = osp.join(args.path, f'{args.split}.{args.labels}')\n    with torch.no_grad():\n        with open(osp.join(args.path, f'{args.split}.src'), 'w') as fp, open(osp.join(args.path, f'{args.split}.tsv'), 'w') as pp, open(label_path, 'w') as lp:\n            print(root, file=pp)\n            for (f, fname, lbl) in tqdm.tqdm(iterator, total=num):\n                if faiss_spec.pca:\n                    f = torch.mm(f, A) + b\n                if faiss_spec.norm:\n                    f = F.normalize(f, p=2, dim=-1)\n                f = f.cpu().numpy()\n                (_, z) = faiss_index.search(f, 1)\n                print(' '.join((str(x.item()) for x in z)), file=fp)\n                print(fname, file=pp)\n                if lbl is not None:\n                    print(lbl, file=lp)\n                    had_labels = True\n    if not had_labels:\n        os.remove(label_path)"
        ]
    }
]