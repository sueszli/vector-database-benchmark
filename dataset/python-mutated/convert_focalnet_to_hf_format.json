[
    {
        "func_name": "get_focalnet_config",
        "original": "def get_focalnet_config(model_name):\n    depths = [2, 2, 6, 2] if 'tiny' in model_name else [2, 2, 18, 2]\n    use_conv_embed = True if 'large' in model_name or 'huge' in model_name else False\n    use_post_layernorm = True if 'large' in model_name or 'huge' in model_name else False\n    use_layerscale = True if 'large' in model_name or 'huge' in model_name else False\n    if 'large' in model_name or 'xlarge' in model_name or 'huge' in model_name:\n        if 'fl3' in model_name:\n            focal_levels = [3, 3, 3, 3]\n            focal_windows = [5, 5, 5, 5]\n        elif 'fl4' in model_name:\n            focal_levels = [4, 4, 4, 4]\n            focal_windows = [3, 3, 3, 3]\n    if 'tiny' in model_name or 'small' in model_name or 'base' in model_name:\n        focal_windows = [3, 3, 3, 3]\n        if 'lrf' in model_name:\n            focal_levels = [3, 3, 3, 3]\n        else:\n            focal_levels = [2, 2, 2, 2]\n    if 'tiny' in model_name:\n        embed_dim = 96\n    elif 'small' in model_name:\n        embed_dim = 96\n    elif 'base' in model_name:\n        embed_dim = 128\n    elif 'large' in model_name:\n        embed_dim = 192\n    elif 'xlarge' in model_name:\n        embed_dim = 256\n    elif 'huge' in model_name:\n        embed_dim = 352\n    repo_id = 'huggingface/label-files'\n    if 'large' in model_name or 'huge' in model_name:\n        filename = 'imagenet-22k-id2label.json'\n    else:\n        filename = 'imagenet-1k-id2label.json'\n    id2label = json.load(open(hf_hub_download(repo_id, filename, repo_type='dataset'), 'r'))\n    id2label = {int(k): v for (k, v) in id2label.items()}\n    label2id = {v: k for (k, v) in id2label.items()}\n    config = FocalNetConfig(embed_dim=embed_dim, depths=depths, focal_levels=focal_levels, focal_windows=focal_windows, use_conv_embed=use_conv_embed, id2label=id2label, label2id=label2id, use_post_layernorm=use_post_layernorm, use_layerscale=use_layerscale)\n    return config",
        "mutated": [
            "def get_focalnet_config(model_name):\n    if False:\n        i = 10\n    depths = [2, 2, 6, 2] if 'tiny' in model_name else [2, 2, 18, 2]\n    use_conv_embed = True if 'large' in model_name or 'huge' in model_name else False\n    use_post_layernorm = True if 'large' in model_name or 'huge' in model_name else False\n    use_layerscale = True if 'large' in model_name or 'huge' in model_name else False\n    if 'large' in model_name or 'xlarge' in model_name or 'huge' in model_name:\n        if 'fl3' in model_name:\n            focal_levels = [3, 3, 3, 3]\n            focal_windows = [5, 5, 5, 5]\n        elif 'fl4' in model_name:\n            focal_levels = [4, 4, 4, 4]\n            focal_windows = [3, 3, 3, 3]\n    if 'tiny' in model_name or 'small' in model_name or 'base' in model_name:\n        focal_windows = [3, 3, 3, 3]\n        if 'lrf' in model_name:\n            focal_levels = [3, 3, 3, 3]\n        else:\n            focal_levels = [2, 2, 2, 2]\n    if 'tiny' in model_name:\n        embed_dim = 96\n    elif 'small' in model_name:\n        embed_dim = 96\n    elif 'base' in model_name:\n        embed_dim = 128\n    elif 'large' in model_name:\n        embed_dim = 192\n    elif 'xlarge' in model_name:\n        embed_dim = 256\n    elif 'huge' in model_name:\n        embed_dim = 352\n    repo_id = 'huggingface/label-files'\n    if 'large' in model_name or 'huge' in model_name:\n        filename = 'imagenet-22k-id2label.json'\n    else:\n        filename = 'imagenet-1k-id2label.json'\n    id2label = json.load(open(hf_hub_download(repo_id, filename, repo_type='dataset'), 'r'))\n    id2label = {int(k): v for (k, v) in id2label.items()}\n    label2id = {v: k for (k, v) in id2label.items()}\n    config = FocalNetConfig(embed_dim=embed_dim, depths=depths, focal_levels=focal_levels, focal_windows=focal_windows, use_conv_embed=use_conv_embed, id2label=id2label, label2id=label2id, use_post_layernorm=use_post_layernorm, use_layerscale=use_layerscale)\n    return config",
            "def get_focalnet_config(model_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    depths = [2, 2, 6, 2] if 'tiny' in model_name else [2, 2, 18, 2]\n    use_conv_embed = True if 'large' in model_name or 'huge' in model_name else False\n    use_post_layernorm = True if 'large' in model_name or 'huge' in model_name else False\n    use_layerscale = True if 'large' in model_name or 'huge' in model_name else False\n    if 'large' in model_name or 'xlarge' in model_name or 'huge' in model_name:\n        if 'fl3' in model_name:\n            focal_levels = [3, 3, 3, 3]\n            focal_windows = [5, 5, 5, 5]\n        elif 'fl4' in model_name:\n            focal_levels = [4, 4, 4, 4]\n            focal_windows = [3, 3, 3, 3]\n    if 'tiny' in model_name or 'small' in model_name or 'base' in model_name:\n        focal_windows = [3, 3, 3, 3]\n        if 'lrf' in model_name:\n            focal_levels = [3, 3, 3, 3]\n        else:\n            focal_levels = [2, 2, 2, 2]\n    if 'tiny' in model_name:\n        embed_dim = 96\n    elif 'small' in model_name:\n        embed_dim = 96\n    elif 'base' in model_name:\n        embed_dim = 128\n    elif 'large' in model_name:\n        embed_dim = 192\n    elif 'xlarge' in model_name:\n        embed_dim = 256\n    elif 'huge' in model_name:\n        embed_dim = 352\n    repo_id = 'huggingface/label-files'\n    if 'large' in model_name or 'huge' in model_name:\n        filename = 'imagenet-22k-id2label.json'\n    else:\n        filename = 'imagenet-1k-id2label.json'\n    id2label = json.load(open(hf_hub_download(repo_id, filename, repo_type='dataset'), 'r'))\n    id2label = {int(k): v for (k, v) in id2label.items()}\n    label2id = {v: k for (k, v) in id2label.items()}\n    config = FocalNetConfig(embed_dim=embed_dim, depths=depths, focal_levels=focal_levels, focal_windows=focal_windows, use_conv_embed=use_conv_embed, id2label=id2label, label2id=label2id, use_post_layernorm=use_post_layernorm, use_layerscale=use_layerscale)\n    return config",
            "def get_focalnet_config(model_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    depths = [2, 2, 6, 2] if 'tiny' in model_name else [2, 2, 18, 2]\n    use_conv_embed = True if 'large' in model_name or 'huge' in model_name else False\n    use_post_layernorm = True if 'large' in model_name or 'huge' in model_name else False\n    use_layerscale = True if 'large' in model_name or 'huge' in model_name else False\n    if 'large' in model_name or 'xlarge' in model_name or 'huge' in model_name:\n        if 'fl3' in model_name:\n            focal_levels = [3, 3, 3, 3]\n            focal_windows = [5, 5, 5, 5]\n        elif 'fl4' in model_name:\n            focal_levels = [4, 4, 4, 4]\n            focal_windows = [3, 3, 3, 3]\n    if 'tiny' in model_name or 'small' in model_name or 'base' in model_name:\n        focal_windows = [3, 3, 3, 3]\n        if 'lrf' in model_name:\n            focal_levels = [3, 3, 3, 3]\n        else:\n            focal_levels = [2, 2, 2, 2]\n    if 'tiny' in model_name:\n        embed_dim = 96\n    elif 'small' in model_name:\n        embed_dim = 96\n    elif 'base' in model_name:\n        embed_dim = 128\n    elif 'large' in model_name:\n        embed_dim = 192\n    elif 'xlarge' in model_name:\n        embed_dim = 256\n    elif 'huge' in model_name:\n        embed_dim = 352\n    repo_id = 'huggingface/label-files'\n    if 'large' in model_name or 'huge' in model_name:\n        filename = 'imagenet-22k-id2label.json'\n    else:\n        filename = 'imagenet-1k-id2label.json'\n    id2label = json.load(open(hf_hub_download(repo_id, filename, repo_type='dataset'), 'r'))\n    id2label = {int(k): v for (k, v) in id2label.items()}\n    label2id = {v: k for (k, v) in id2label.items()}\n    config = FocalNetConfig(embed_dim=embed_dim, depths=depths, focal_levels=focal_levels, focal_windows=focal_windows, use_conv_embed=use_conv_embed, id2label=id2label, label2id=label2id, use_post_layernorm=use_post_layernorm, use_layerscale=use_layerscale)\n    return config",
            "def get_focalnet_config(model_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    depths = [2, 2, 6, 2] if 'tiny' in model_name else [2, 2, 18, 2]\n    use_conv_embed = True if 'large' in model_name or 'huge' in model_name else False\n    use_post_layernorm = True if 'large' in model_name or 'huge' in model_name else False\n    use_layerscale = True if 'large' in model_name or 'huge' in model_name else False\n    if 'large' in model_name or 'xlarge' in model_name or 'huge' in model_name:\n        if 'fl3' in model_name:\n            focal_levels = [3, 3, 3, 3]\n            focal_windows = [5, 5, 5, 5]\n        elif 'fl4' in model_name:\n            focal_levels = [4, 4, 4, 4]\n            focal_windows = [3, 3, 3, 3]\n    if 'tiny' in model_name or 'small' in model_name or 'base' in model_name:\n        focal_windows = [3, 3, 3, 3]\n        if 'lrf' in model_name:\n            focal_levels = [3, 3, 3, 3]\n        else:\n            focal_levels = [2, 2, 2, 2]\n    if 'tiny' in model_name:\n        embed_dim = 96\n    elif 'small' in model_name:\n        embed_dim = 96\n    elif 'base' in model_name:\n        embed_dim = 128\n    elif 'large' in model_name:\n        embed_dim = 192\n    elif 'xlarge' in model_name:\n        embed_dim = 256\n    elif 'huge' in model_name:\n        embed_dim = 352\n    repo_id = 'huggingface/label-files'\n    if 'large' in model_name or 'huge' in model_name:\n        filename = 'imagenet-22k-id2label.json'\n    else:\n        filename = 'imagenet-1k-id2label.json'\n    id2label = json.load(open(hf_hub_download(repo_id, filename, repo_type='dataset'), 'r'))\n    id2label = {int(k): v for (k, v) in id2label.items()}\n    label2id = {v: k for (k, v) in id2label.items()}\n    config = FocalNetConfig(embed_dim=embed_dim, depths=depths, focal_levels=focal_levels, focal_windows=focal_windows, use_conv_embed=use_conv_embed, id2label=id2label, label2id=label2id, use_post_layernorm=use_post_layernorm, use_layerscale=use_layerscale)\n    return config",
            "def get_focalnet_config(model_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    depths = [2, 2, 6, 2] if 'tiny' in model_name else [2, 2, 18, 2]\n    use_conv_embed = True if 'large' in model_name or 'huge' in model_name else False\n    use_post_layernorm = True if 'large' in model_name or 'huge' in model_name else False\n    use_layerscale = True if 'large' in model_name or 'huge' in model_name else False\n    if 'large' in model_name or 'xlarge' in model_name or 'huge' in model_name:\n        if 'fl3' in model_name:\n            focal_levels = [3, 3, 3, 3]\n            focal_windows = [5, 5, 5, 5]\n        elif 'fl4' in model_name:\n            focal_levels = [4, 4, 4, 4]\n            focal_windows = [3, 3, 3, 3]\n    if 'tiny' in model_name or 'small' in model_name or 'base' in model_name:\n        focal_windows = [3, 3, 3, 3]\n        if 'lrf' in model_name:\n            focal_levels = [3, 3, 3, 3]\n        else:\n            focal_levels = [2, 2, 2, 2]\n    if 'tiny' in model_name:\n        embed_dim = 96\n    elif 'small' in model_name:\n        embed_dim = 96\n    elif 'base' in model_name:\n        embed_dim = 128\n    elif 'large' in model_name:\n        embed_dim = 192\n    elif 'xlarge' in model_name:\n        embed_dim = 256\n    elif 'huge' in model_name:\n        embed_dim = 352\n    repo_id = 'huggingface/label-files'\n    if 'large' in model_name or 'huge' in model_name:\n        filename = 'imagenet-22k-id2label.json'\n    else:\n        filename = 'imagenet-1k-id2label.json'\n    id2label = json.load(open(hf_hub_download(repo_id, filename, repo_type='dataset'), 'r'))\n    id2label = {int(k): v for (k, v) in id2label.items()}\n    label2id = {v: k for (k, v) in id2label.items()}\n    config = FocalNetConfig(embed_dim=embed_dim, depths=depths, focal_levels=focal_levels, focal_windows=focal_windows, use_conv_embed=use_conv_embed, id2label=id2label, label2id=label2id, use_post_layernorm=use_post_layernorm, use_layerscale=use_layerscale)\n    return config"
        ]
    },
    {
        "func_name": "rename_key",
        "original": "def rename_key(name):\n    if 'patch_embed.proj' in name:\n        name = name.replace('patch_embed.proj', 'embeddings.patch_embeddings.projection')\n    if 'patch_embed.norm' in name:\n        name = name.replace('patch_embed.norm', 'embeddings.norm')\n    if 'layers' in name:\n        name = 'encoder.' + name\n    if 'encoder.layers' in name:\n        name = name.replace('encoder.layers', 'encoder.stages')\n    if 'downsample.proj' in name:\n        name = name.replace('downsample.proj', 'downsample.projection')\n    if 'blocks' in name:\n        name = name.replace('blocks', 'layers')\n    if 'modulation.f.weight' in name or 'modulation.f.bias' in name:\n        name = name.replace('modulation.f', 'modulation.projection_in')\n    if 'modulation.h.weight' in name or 'modulation.h.bias' in name:\n        name = name.replace('modulation.h', 'modulation.projection_context')\n    if 'modulation.proj.weight' in name or 'modulation.proj.bias' in name:\n        name = name.replace('modulation.proj', 'modulation.projection_out')\n    if name == 'norm.weight':\n        name = 'layernorm.weight'\n    if name == 'norm.bias':\n        name = 'layernorm.bias'\n    if 'head' in name:\n        name = name.replace('head', 'classifier')\n    else:\n        name = 'focalnet.' + name\n    return name",
        "mutated": [
            "def rename_key(name):\n    if False:\n        i = 10\n    if 'patch_embed.proj' in name:\n        name = name.replace('patch_embed.proj', 'embeddings.patch_embeddings.projection')\n    if 'patch_embed.norm' in name:\n        name = name.replace('patch_embed.norm', 'embeddings.norm')\n    if 'layers' in name:\n        name = 'encoder.' + name\n    if 'encoder.layers' in name:\n        name = name.replace('encoder.layers', 'encoder.stages')\n    if 'downsample.proj' in name:\n        name = name.replace('downsample.proj', 'downsample.projection')\n    if 'blocks' in name:\n        name = name.replace('blocks', 'layers')\n    if 'modulation.f.weight' in name or 'modulation.f.bias' in name:\n        name = name.replace('modulation.f', 'modulation.projection_in')\n    if 'modulation.h.weight' in name or 'modulation.h.bias' in name:\n        name = name.replace('modulation.h', 'modulation.projection_context')\n    if 'modulation.proj.weight' in name or 'modulation.proj.bias' in name:\n        name = name.replace('modulation.proj', 'modulation.projection_out')\n    if name == 'norm.weight':\n        name = 'layernorm.weight'\n    if name == 'norm.bias':\n        name = 'layernorm.bias'\n    if 'head' in name:\n        name = name.replace('head', 'classifier')\n    else:\n        name = 'focalnet.' + name\n    return name",
            "def rename_key(name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if 'patch_embed.proj' in name:\n        name = name.replace('patch_embed.proj', 'embeddings.patch_embeddings.projection')\n    if 'patch_embed.norm' in name:\n        name = name.replace('patch_embed.norm', 'embeddings.norm')\n    if 'layers' in name:\n        name = 'encoder.' + name\n    if 'encoder.layers' in name:\n        name = name.replace('encoder.layers', 'encoder.stages')\n    if 'downsample.proj' in name:\n        name = name.replace('downsample.proj', 'downsample.projection')\n    if 'blocks' in name:\n        name = name.replace('blocks', 'layers')\n    if 'modulation.f.weight' in name or 'modulation.f.bias' in name:\n        name = name.replace('modulation.f', 'modulation.projection_in')\n    if 'modulation.h.weight' in name or 'modulation.h.bias' in name:\n        name = name.replace('modulation.h', 'modulation.projection_context')\n    if 'modulation.proj.weight' in name or 'modulation.proj.bias' in name:\n        name = name.replace('modulation.proj', 'modulation.projection_out')\n    if name == 'norm.weight':\n        name = 'layernorm.weight'\n    if name == 'norm.bias':\n        name = 'layernorm.bias'\n    if 'head' in name:\n        name = name.replace('head', 'classifier')\n    else:\n        name = 'focalnet.' + name\n    return name",
            "def rename_key(name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if 'patch_embed.proj' in name:\n        name = name.replace('patch_embed.proj', 'embeddings.patch_embeddings.projection')\n    if 'patch_embed.norm' in name:\n        name = name.replace('patch_embed.norm', 'embeddings.norm')\n    if 'layers' in name:\n        name = 'encoder.' + name\n    if 'encoder.layers' in name:\n        name = name.replace('encoder.layers', 'encoder.stages')\n    if 'downsample.proj' in name:\n        name = name.replace('downsample.proj', 'downsample.projection')\n    if 'blocks' in name:\n        name = name.replace('blocks', 'layers')\n    if 'modulation.f.weight' in name or 'modulation.f.bias' in name:\n        name = name.replace('modulation.f', 'modulation.projection_in')\n    if 'modulation.h.weight' in name or 'modulation.h.bias' in name:\n        name = name.replace('modulation.h', 'modulation.projection_context')\n    if 'modulation.proj.weight' in name or 'modulation.proj.bias' in name:\n        name = name.replace('modulation.proj', 'modulation.projection_out')\n    if name == 'norm.weight':\n        name = 'layernorm.weight'\n    if name == 'norm.bias':\n        name = 'layernorm.bias'\n    if 'head' in name:\n        name = name.replace('head', 'classifier')\n    else:\n        name = 'focalnet.' + name\n    return name",
            "def rename_key(name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if 'patch_embed.proj' in name:\n        name = name.replace('patch_embed.proj', 'embeddings.patch_embeddings.projection')\n    if 'patch_embed.norm' in name:\n        name = name.replace('patch_embed.norm', 'embeddings.norm')\n    if 'layers' in name:\n        name = 'encoder.' + name\n    if 'encoder.layers' in name:\n        name = name.replace('encoder.layers', 'encoder.stages')\n    if 'downsample.proj' in name:\n        name = name.replace('downsample.proj', 'downsample.projection')\n    if 'blocks' in name:\n        name = name.replace('blocks', 'layers')\n    if 'modulation.f.weight' in name or 'modulation.f.bias' in name:\n        name = name.replace('modulation.f', 'modulation.projection_in')\n    if 'modulation.h.weight' in name or 'modulation.h.bias' in name:\n        name = name.replace('modulation.h', 'modulation.projection_context')\n    if 'modulation.proj.weight' in name or 'modulation.proj.bias' in name:\n        name = name.replace('modulation.proj', 'modulation.projection_out')\n    if name == 'norm.weight':\n        name = 'layernorm.weight'\n    if name == 'norm.bias':\n        name = 'layernorm.bias'\n    if 'head' in name:\n        name = name.replace('head', 'classifier')\n    else:\n        name = 'focalnet.' + name\n    return name",
            "def rename_key(name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if 'patch_embed.proj' in name:\n        name = name.replace('patch_embed.proj', 'embeddings.patch_embeddings.projection')\n    if 'patch_embed.norm' in name:\n        name = name.replace('patch_embed.norm', 'embeddings.norm')\n    if 'layers' in name:\n        name = 'encoder.' + name\n    if 'encoder.layers' in name:\n        name = name.replace('encoder.layers', 'encoder.stages')\n    if 'downsample.proj' in name:\n        name = name.replace('downsample.proj', 'downsample.projection')\n    if 'blocks' in name:\n        name = name.replace('blocks', 'layers')\n    if 'modulation.f.weight' in name or 'modulation.f.bias' in name:\n        name = name.replace('modulation.f', 'modulation.projection_in')\n    if 'modulation.h.weight' in name or 'modulation.h.bias' in name:\n        name = name.replace('modulation.h', 'modulation.projection_context')\n    if 'modulation.proj.weight' in name or 'modulation.proj.bias' in name:\n        name = name.replace('modulation.proj', 'modulation.projection_out')\n    if name == 'norm.weight':\n        name = 'layernorm.weight'\n    if name == 'norm.bias':\n        name = 'layernorm.bias'\n    if 'head' in name:\n        name = name.replace('head', 'classifier')\n    else:\n        name = 'focalnet.' + name\n    return name"
        ]
    },
    {
        "func_name": "convert_focalnet_checkpoint",
        "original": "def convert_focalnet_checkpoint(model_name, pytorch_dump_folder_path, push_to_hub=False):\n    model_name_to_url = {'focalnet-tiny': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_tiny_srf.pth', 'focalnet-tiny-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_tiny_lrf.pth', 'focalnet-small': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_small_srf.pth', 'focalnet-small-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_small_lrf.pth', 'focalnet-base': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_base_srf.pth', 'focalnet-base-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_base_lrf.pth', 'focalnet-large-lrf-fl3': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_large_lrf_384.pth', 'focalnet-large-lrf-fl4': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_large_lrf_384_fl4.pth', 'focalnet-xlarge-lrf-fl3': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_xlarge_lrf_384.pth', 'focalnet-xlarge-lrf-fl4': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_xlarge_lrf_384_fl4.pth'}\n    checkpoint_url = model_name_to_url[model_name]\n    print('Checkpoint URL: ', checkpoint_url)\n    state_dict = torch.hub.load_state_dict_from_url(checkpoint_url, map_location='cpu')['model']\n    for key in state_dict.copy().keys():\n        val = state_dict.pop(key)\n        state_dict[rename_key(key)] = val\n    config = get_focalnet_config(model_name)\n    model = FocalNetForImageClassification(config)\n    model.eval()\n    model.load_state_dict(state_dict)\n    url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    processor = BitImageProcessor(do_resize=True, size={'shortest_edge': 256}, resample=PILImageResampling.BILINEAR, do_center_crop=True, crop_size=224, do_normalize=True, image_mean=IMAGENET_DEFAULT_MEAN, image_std=IMAGENET_DEFAULT_STD)\n    image = Image.open(requests.get(url, stream=True).raw)\n    inputs = processor(images=image, return_tensors='pt')\n    image_transforms = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n    original_pixel_values = image_transforms(image).unsqueeze(0)\n    assert torch.allclose(inputs.pixel_values, original_pixel_values, atol=0.0001)\n    outputs = model(**inputs)\n    predicted_class_idx = outputs.logits.argmax(-1).item()\n    print('Predicted class:', model.config.id2label[predicted_class_idx])\n    print('First values of logits:', outputs.logits[0, :3])\n    if model_name == 'focalnet-tiny':\n        expected_slice = torch.tensor([0.2166, -0.4368, 0.2191])\n    elif model_name == 'focalnet-tiny-lrf':\n        expected_slice = torch.tensor([1.1669, 0.0125, -0.1695])\n    elif model_name == 'focalnet-small':\n        expected_slice = torch.tensor([0.4917, -0.043, 0.1341])\n    elif model_name == 'focalnet-small-lrf':\n        expected_slice = torch.tensor([-0.2588, -0.5342, -0.2331])\n    elif model_name == 'focalnet-base':\n        expected_slice = torch.tensor([-0.1655, -0.409, -0.173])\n    elif model_name == 'focalnet-base-lrf':\n        expected_slice = torch.tensor([0.5306, -0.0483, -0.3928])\n    assert torch.allclose(outputs.logits[0, :3], expected_slice, atol=0.0001)\n    print('Looks ok!')\n    if pytorch_dump_folder_path is not None:\n        print(f'Saving model and processor of {model_name} to {pytorch_dump_folder_path}')\n        model.save_pretrained(pytorch_dump_folder_path)\n        processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        print(f'Pushing model and processor of {model_name} to the hub...')\n        model.push_to_hub(f'{model_name}')\n        processor.push_to_hub(f'{model_name}')",
        "mutated": [
            "def convert_focalnet_checkpoint(model_name, pytorch_dump_folder_path, push_to_hub=False):\n    if False:\n        i = 10\n    model_name_to_url = {'focalnet-tiny': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_tiny_srf.pth', 'focalnet-tiny-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_tiny_lrf.pth', 'focalnet-small': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_small_srf.pth', 'focalnet-small-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_small_lrf.pth', 'focalnet-base': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_base_srf.pth', 'focalnet-base-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_base_lrf.pth', 'focalnet-large-lrf-fl3': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_large_lrf_384.pth', 'focalnet-large-lrf-fl4': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_large_lrf_384_fl4.pth', 'focalnet-xlarge-lrf-fl3': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_xlarge_lrf_384.pth', 'focalnet-xlarge-lrf-fl4': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_xlarge_lrf_384_fl4.pth'}\n    checkpoint_url = model_name_to_url[model_name]\n    print('Checkpoint URL: ', checkpoint_url)\n    state_dict = torch.hub.load_state_dict_from_url(checkpoint_url, map_location='cpu')['model']\n    for key in state_dict.copy().keys():\n        val = state_dict.pop(key)\n        state_dict[rename_key(key)] = val\n    config = get_focalnet_config(model_name)\n    model = FocalNetForImageClassification(config)\n    model.eval()\n    model.load_state_dict(state_dict)\n    url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    processor = BitImageProcessor(do_resize=True, size={'shortest_edge': 256}, resample=PILImageResampling.BILINEAR, do_center_crop=True, crop_size=224, do_normalize=True, image_mean=IMAGENET_DEFAULT_MEAN, image_std=IMAGENET_DEFAULT_STD)\n    image = Image.open(requests.get(url, stream=True).raw)\n    inputs = processor(images=image, return_tensors='pt')\n    image_transforms = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n    original_pixel_values = image_transforms(image).unsqueeze(0)\n    assert torch.allclose(inputs.pixel_values, original_pixel_values, atol=0.0001)\n    outputs = model(**inputs)\n    predicted_class_idx = outputs.logits.argmax(-1).item()\n    print('Predicted class:', model.config.id2label[predicted_class_idx])\n    print('First values of logits:', outputs.logits[0, :3])\n    if model_name == 'focalnet-tiny':\n        expected_slice = torch.tensor([0.2166, -0.4368, 0.2191])\n    elif model_name == 'focalnet-tiny-lrf':\n        expected_slice = torch.tensor([1.1669, 0.0125, -0.1695])\n    elif model_name == 'focalnet-small':\n        expected_slice = torch.tensor([0.4917, -0.043, 0.1341])\n    elif model_name == 'focalnet-small-lrf':\n        expected_slice = torch.tensor([-0.2588, -0.5342, -0.2331])\n    elif model_name == 'focalnet-base':\n        expected_slice = torch.tensor([-0.1655, -0.409, -0.173])\n    elif model_name == 'focalnet-base-lrf':\n        expected_slice = torch.tensor([0.5306, -0.0483, -0.3928])\n    assert torch.allclose(outputs.logits[0, :3], expected_slice, atol=0.0001)\n    print('Looks ok!')\n    if pytorch_dump_folder_path is not None:\n        print(f'Saving model and processor of {model_name} to {pytorch_dump_folder_path}')\n        model.save_pretrained(pytorch_dump_folder_path)\n        processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        print(f'Pushing model and processor of {model_name} to the hub...')\n        model.push_to_hub(f'{model_name}')\n        processor.push_to_hub(f'{model_name}')",
            "def convert_focalnet_checkpoint(model_name, pytorch_dump_folder_path, push_to_hub=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    model_name_to_url = {'focalnet-tiny': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_tiny_srf.pth', 'focalnet-tiny-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_tiny_lrf.pth', 'focalnet-small': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_small_srf.pth', 'focalnet-small-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_small_lrf.pth', 'focalnet-base': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_base_srf.pth', 'focalnet-base-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_base_lrf.pth', 'focalnet-large-lrf-fl3': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_large_lrf_384.pth', 'focalnet-large-lrf-fl4': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_large_lrf_384_fl4.pth', 'focalnet-xlarge-lrf-fl3': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_xlarge_lrf_384.pth', 'focalnet-xlarge-lrf-fl4': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_xlarge_lrf_384_fl4.pth'}\n    checkpoint_url = model_name_to_url[model_name]\n    print('Checkpoint URL: ', checkpoint_url)\n    state_dict = torch.hub.load_state_dict_from_url(checkpoint_url, map_location='cpu')['model']\n    for key in state_dict.copy().keys():\n        val = state_dict.pop(key)\n        state_dict[rename_key(key)] = val\n    config = get_focalnet_config(model_name)\n    model = FocalNetForImageClassification(config)\n    model.eval()\n    model.load_state_dict(state_dict)\n    url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    processor = BitImageProcessor(do_resize=True, size={'shortest_edge': 256}, resample=PILImageResampling.BILINEAR, do_center_crop=True, crop_size=224, do_normalize=True, image_mean=IMAGENET_DEFAULT_MEAN, image_std=IMAGENET_DEFAULT_STD)\n    image = Image.open(requests.get(url, stream=True).raw)\n    inputs = processor(images=image, return_tensors='pt')\n    image_transforms = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n    original_pixel_values = image_transforms(image).unsqueeze(0)\n    assert torch.allclose(inputs.pixel_values, original_pixel_values, atol=0.0001)\n    outputs = model(**inputs)\n    predicted_class_idx = outputs.logits.argmax(-1).item()\n    print('Predicted class:', model.config.id2label[predicted_class_idx])\n    print('First values of logits:', outputs.logits[0, :3])\n    if model_name == 'focalnet-tiny':\n        expected_slice = torch.tensor([0.2166, -0.4368, 0.2191])\n    elif model_name == 'focalnet-tiny-lrf':\n        expected_slice = torch.tensor([1.1669, 0.0125, -0.1695])\n    elif model_name == 'focalnet-small':\n        expected_slice = torch.tensor([0.4917, -0.043, 0.1341])\n    elif model_name == 'focalnet-small-lrf':\n        expected_slice = torch.tensor([-0.2588, -0.5342, -0.2331])\n    elif model_name == 'focalnet-base':\n        expected_slice = torch.tensor([-0.1655, -0.409, -0.173])\n    elif model_name == 'focalnet-base-lrf':\n        expected_slice = torch.tensor([0.5306, -0.0483, -0.3928])\n    assert torch.allclose(outputs.logits[0, :3], expected_slice, atol=0.0001)\n    print('Looks ok!')\n    if pytorch_dump_folder_path is not None:\n        print(f'Saving model and processor of {model_name} to {pytorch_dump_folder_path}')\n        model.save_pretrained(pytorch_dump_folder_path)\n        processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        print(f'Pushing model and processor of {model_name} to the hub...')\n        model.push_to_hub(f'{model_name}')\n        processor.push_to_hub(f'{model_name}')",
            "def convert_focalnet_checkpoint(model_name, pytorch_dump_folder_path, push_to_hub=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    model_name_to_url = {'focalnet-tiny': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_tiny_srf.pth', 'focalnet-tiny-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_tiny_lrf.pth', 'focalnet-small': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_small_srf.pth', 'focalnet-small-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_small_lrf.pth', 'focalnet-base': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_base_srf.pth', 'focalnet-base-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_base_lrf.pth', 'focalnet-large-lrf-fl3': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_large_lrf_384.pth', 'focalnet-large-lrf-fl4': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_large_lrf_384_fl4.pth', 'focalnet-xlarge-lrf-fl3': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_xlarge_lrf_384.pth', 'focalnet-xlarge-lrf-fl4': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_xlarge_lrf_384_fl4.pth'}\n    checkpoint_url = model_name_to_url[model_name]\n    print('Checkpoint URL: ', checkpoint_url)\n    state_dict = torch.hub.load_state_dict_from_url(checkpoint_url, map_location='cpu')['model']\n    for key in state_dict.copy().keys():\n        val = state_dict.pop(key)\n        state_dict[rename_key(key)] = val\n    config = get_focalnet_config(model_name)\n    model = FocalNetForImageClassification(config)\n    model.eval()\n    model.load_state_dict(state_dict)\n    url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    processor = BitImageProcessor(do_resize=True, size={'shortest_edge': 256}, resample=PILImageResampling.BILINEAR, do_center_crop=True, crop_size=224, do_normalize=True, image_mean=IMAGENET_DEFAULT_MEAN, image_std=IMAGENET_DEFAULT_STD)\n    image = Image.open(requests.get(url, stream=True).raw)\n    inputs = processor(images=image, return_tensors='pt')\n    image_transforms = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n    original_pixel_values = image_transforms(image).unsqueeze(0)\n    assert torch.allclose(inputs.pixel_values, original_pixel_values, atol=0.0001)\n    outputs = model(**inputs)\n    predicted_class_idx = outputs.logits.argmax(-1).item()\n    print('Predicted class:', model.config.id2label[predicted_class_idx])\n    print('First values of logits:', outputs.logits[0, :3])\n    if model_name == 'focalnet-tiny':\n        expected_slice = torch.tensor([0.2166, -0.4368, 0.2191])\n    elif model_name == 'focalnet-tiny-lrf':\n        expected_slice = torch.tensor([1.1669, 0.0125, -0.1695])\n    elif model_name == 'focalnet-small':\n        expected_slice = torch.tensor([0.4917, -0.043, 0.1341])\n    elif model_name == 'focalnet-small-lrf':\n        expected_slice = torch.tensor([-0.2588, -0.5342, -0.2331])\n    elif model_name == 'focalnet-base':\n        expected_slice = torch.tensor([-0.1655, -0.409, -0.173])\n    elif model_name == 'focalnet-base-lrf':\n        expected_slice = torch.tensor([0.5306, -0.0483, -0.3928])\n    assert torch.allclose(outputs.logits[0, :3], expected_slice, atol=0.0001)\n    print('Looks ok!')\n    if pytorch_dump_folder_path is not None:\n        print(f'Saving model and processor of {model_name} to {pytorch_dump_folder_path}')\n        model.save_pretrained(pytorch_dump_folder_path)\n        processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        print(f'Pushing model and processor of {model_name} to the hub...')\n        model.push_to_hub(f'{model_name}')\n        processor.push_to_hub(f'{model_name}')",
            "def convert_focalnet_checkpoint(model_name, pytorch_dump_folder_path, push_to_hub=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    model_name_to_url = {'focalnet-tiny': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_tiny_srf.pth', 'focalnet-tiny-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_tiny_lrf.pth', 'focalnet-small': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_small_srf.pth', 'focalnet-small-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_small_lrf.pth', 'focalnet-base': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_base_srf.pth', 'focalnet-base-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_base_lrf.pth', 'focalnet-large-lrf-fl3': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_large_lrf_384.pth', 'focalnet-large-lrf-fl4': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_large_lrf_384_fl4.pth', 'focalnet-xlarge-lrf-fl3': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_xlarge_lrf_384.pth', 'focalnet-xlarge-lrf-fl4': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_xlarge_lrf_384_fl4.pth'}\n    checkpoint_url = model_name_to_url[model_name]\n    print('Checkpoint URL: ', checkpoint_url)\n    state_dict = torch.hub.load_state_dict_from_url(checkpoint_url, map_location='cpu')['model']\n    for key in state_dict.copy().keys():\n        val = state_dict.pop(key)\n        state_dict[rename_key(key)] = val\n    config = get_focalnet_config(model_name)\n    model = FocalNetForImageClassification(config)\n    model.eval()\n    model.load_state_dict(state_dict)\n    url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    processor = BitImageProcessor(do_resize=True, size={'shortest_edge': 256}, resample=PILImageResampling.BILINEAR, do_center_crop=True, crop_size=224, do_normalize=True, image_mean=IMAGENET_DEFAULT_MEAN, image_std=IMAGENET_DEFAULT_STD)\n    image = Image.open(requests.get(url, stream=True).raw)\n    inputs = processor(images=image, return_tensors='pt')\n    image_transforms = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n    original_pixel_values = image_transforms(image).unsqueeze(0)\n    assert torch.allclose(inputs.pixel_values, original_pixel_values, atol=0.0001)\n    outputs = model(**inputs)\n    predicted_class_idx = outputs.logits.argmax(-1).item()\n    print('Predicted class:', model.config.id2label[predicted_class_idx])\n    print('First values of logits:', outputs.logits[0, :3])\n    if model_name == 'focalnet-tiny':\n        expected_slice = torch.tensor([0.2166, -0.4368, 0.2191])\n    elif model_name == 'focalnet-tiny-lrf':\n        expected_slice = torch.tensor([1.1669, 0.0125, -0.1695])\n    elif model_name == 'focalnet-small':\n        expected_slice = torch.tensor([0.4917, -0.043, 0.1341])\n    elif model_name == 'focalnet-small-lrf':\n        expected_slice = torch.tensor([-0.2588, -0.5342, -0.2331])\n    elif model_name == 'focalnet-base':\n        expected_slice = torch.tensor([-0.1655, -0.409, -0.173])\n    elif model_name == 'focalnet-base-lrf':\n        expected_slice = torch.tensor([0.5306, -0.0483, -0.3928])\n    assert torch.allclose(outputs.logits[0, :3], expected_slice, atol=0.0001)\n    print('Looks ok!')\n    if pytorch_dump_folder_path is not None:\n        print(f'Saving model and processor of {model_name} to {pytorch_dump_folder_path}')\n        model.save_pretrained(pytorch_dump_folder_path)\n        processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        print(f'Pushing model and processor of {model_name} to the hub...')\n        model.push_to_hub(f'{model_name}')\n        processor.push_to_hub(f'{model_name}')",
            "def convert_focalnet_checkpoint(model_name, pytorch_dump_folder_path, push_to_hub=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    model_name_to_url = {'focalnet-tiny': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_tiny_srf.pth', 'focalnet-tiny-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_tiny_lrf.pth', 'focalnet-small': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_small_srf.pth', 'focalnet-small-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_small_lrf.pth', 'focalnet-base': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_base_srf.pth', 'focalnet-base-lrf': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_base_lrf.pth', 'focalnet-large-lrf-fl3': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_large_lrf_384.pth', 'focalnet-large-lrf-fl4': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_large_lrf_384_fl4.pth', 'focalnet-xlarge-lrf-fl3': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_xlarge_lrf_384.pth', 'focalnet-xlarge-lrf-fl4': 'https://projects4jw.blob.core.windows.net/focalnet/release/classification/focalnet_xlarge_lrf_384_fl4.pth'}\n    checkpoint_url = model_name_to_url[model_name]\n    print('Checkpoint URL: ', checkpoint_url)\n    state_dict = torch.hub.load_state_dict_from_url(checkpoint_url, map_location='cpu')['model']\n    for key in state_dict.copy().keys():\n        val = state_dict.pop(key)\n        state_dict[rename_key(key)] = val\n    config = get_focalnet_config(model_name)\n    model = FocalNetForImageClassification(config)\n    model.eval()\n    model.load_state_dict(state_dict)\n    url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    processor = BitImageProcessor(do_resize=True, size={'shortest_edge': 256}, resample=PILImageResampling.BILINEAR, do_center_crop=True, crop_size=224, do_normalize=True, image_mean=IMAGENET_DEFAULT_MEAN, image_std=IMAGENET_DEFAULT_STD)\n    image = Image.open(requests.get(url, stream=True).raw)\n    inputs = processor(images=image, return_tensors='pt')\n    image_transforms = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n    original_pixel_values = image_transforms(image).unsqueeze(0)\n    assert torch.allclose(inputs.pixel_values, original_pixel_values, atol=0.0001)\n    outputs = model(**inputs)\n    predicted_class_idx = outputs.logits.argmax(-1).item()\n    print('Predicted class:', model.config.id2label[predicted_class_idx])\n    print('First values of logits:', outputs.logits[0, :3])\n    if model_name == 'focalnet-tiny':\n        expected_slice = torch.tensor([0.2166, -0.4368, 0.2191])\n    elif model_name == 'focalnet-tiny-lrf':\n        expected_slice = torch.tensor([1.1669, 0.0125, -0.1695])\n    elif model_name == 'focalnet-small':\n        expected_slice = torch.tensor([0.4917, -0.043, 0.1341])\n    elif model_name == 'focalnet-small-lrf':\n        expected_slice = torch.tensor([-0.2588, -0.5342, -0.2331])\n    elif model_name == 'focalnet-base':\n        expected_slice = torch.tensor([-0.1655, -0.409, -0.173])\n    elif model_name == 'focalnet-base-lrf':\n        expected_slice = torch.tensor([0.5306, -0.0483, -0.3928])\n    assert torch.allclose(outputs.logits[0, :3], expected_slice, atol=0.0001)\n    print('Looks ok!')\n    if pytorch_dump_folder_path is not None:\n        print(f'Saving model and processor of {model_name} to {pytorch_dump_folder_path}')\n        model.save_pretrained(pytorch_dump_folder_path)\n        processor.save_pretrained(pytorch_dump_folder_path)\n    if push_to_hub:\n        print(f'Pushing model and processor of {model_name} to the hub...')\n        model.push_to_hub(f'{model_name}')\n        processor.push_to_hub(f'{model_name}')"
        ]
    }
]