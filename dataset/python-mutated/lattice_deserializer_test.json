[
    {
        "func_name": "test_lattice_deserializer",
        "original": "def test_lattice_deserializer(device_id):\n    if cntk_device(device_id).type() != DeviceKind_GPU:\n        pytest.skip('test only runs on GPU')\n    try_set_default_device(cntk_device(device_id))\n    data_dir = ''\n    if 'CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY' in os.environ:\n        data_dir = os.environ['CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY']\n    else:\n        print('CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY environment variable is not defined')\n    print(data_dir)\n    data_dir = os.path.join(data_dir, 'Speech', 'AN4Corpus', 'v0')\n    os.chdir(data_dir)\n    feature_dimension = 33\n    feature = C.sequence.input_variable(feature_dimension)\n    label_dimension = 133\n    label = C.sequence.input_variable(label_dimension)\n    axis_lattice = C.Axis.new_unique_dynamic_axis('lattice_axis')\n    lattice = C.sequence.input_variable(1, sequence_axis=axis_lattice)\n    train_feature_filepath = os.path.join(data_dir, 'glob_0000.scp')\n    train_label_filepath = os.path.join(data_dir, 'glob_0000.mlf')\n    train_lattice_index_path = os.path.join(data_dir, 'latticeIndex.txt')\n    mapping_filepath = os.path.join(data_dir, 'state.list')\n    train_feature_stream = C.io.HTKFeatureDeserializer(C.io.StreamDefs(speech_feature=C.io.StreamDef(shape=feature_dimension, scp=train_feature_filepath)))\n    train_label_stream = C.io.HTKMLFDeserializer(mapping_filepath, C.io.StreamDefs(speech_label=C.io.StreamDef(shape=label_dimension, mlf=train_label_filepath)), True)\n    train_lattice_stream = C.io.LatticeDeserializer(train_lattice_index_path, C.io.StreamDefs(speech_lattice=C.io.StreamDef()))\n    train_data_reader = C.io.MinibatchSource([train_feature_stream, train_label_stream, train_lattice_stream], frame_mode=False)\n    train_input_map = {feature: train_data_reader.streams.speech_feature, label: train_data_reader.streams.speech_label, lattice: train_data_reader.streams.speech_lattice}\n    feature_mean = np.fromfile(os.path.join('GlobalStats', 'mean.363'), dtype=float, count=feature_dimension)\n    feature_inverse_stddev = np.fromfile(os.path.join('GlobalStats', 'var.363'), dtype=float, count=feature_dimension)\n    feature_normalized = (feature - feature_mean) * feature_inverse_stddev\n    with C.default_options(activation=C.sigmoid):\n        z = C.layers.Sequential([C.layers.For(range(3), lambda : C.layers.Recurrence(C.layers.LSTM(1024))), C.layers.Dense(label_dimension)])(feature_normalized)\n    mbsize = 1024\n    mbs_per_epoch = 10\n    max_epochs = 2\n    symListPath = os.path.join(data_dir, 'CY2SCH010061231_1369712653.numden.lats.symlist')\n    phonePath = os.path.join(data_dir, 'model.overalltying')\n    stateListPath = os.path.join(data_dir, 'state.list')\n    transProbPath = os.path.join(data_dir, 'model.transprob')\n    criteria = C.lattice_sequence_with_softmax(label, z, z, lattice, symListPath, phonePath, stateListPath, transProbPath)\n    err = C.classification_error(label, z)\n    lr = C.learning_parameter_schedule_per_sample([(3, 0.01), (1, 0.001)])\n    mm = C.momentum_schedule([(1000, 0.9), (0, 0.99)], mbsize)\n    learner = C.momentum_sgd(z.parameters, lr, mm)\n    trainer = C.Trainer(z, (criteria, err), learner)\n    C.logging.log_number_of_parameters(z)\n    progress_printer = C.logging.progress_print.ProgressPrinter(tag='Training', num_epochs=max_epochs)\n    for epoch in range(max_epochs):\n        for mb in range(mbs_per_epoch):\n            minibatch = train_data_reader.next_minibatch(mbsize, input_map=train_input_map)\n            trainer.train_minibatch(minibatch)\n            progress_printer.update_with_trainer(trainer, with_metric=True)\n        progress_printer.epoch_summary(with_metric=True)\n    assert np.allclose(trainer.previous_minibatch_evaluation_average, 0.15064, atol=TOLERANCE_ABSOLUTE)\n    assert np.allclose(trainer.previous_minibatch_loss_average, 0.035923, atol=TOLERANCE_ABSOLUTE)\n    assert trainer.previous_minibatch_sample_count == 218\n    assert trainer.total_number_of_samples_seen == 5750\n    print('Completed successfully.')",
        "mutated": [
            "def test_lattice_deserializer(device_id):\n    if False:\n        i = 10\n    if cntk_device(device_id).type() != DeviceKind_GPU:\n        pytest.skip('test only runs on GPU')\n    try_set_default_device(cntk_device(device_id))\n    data_dir = ''\n    if 'CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY' in os.environ:\n        data_dir = os.environ['CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY']\n    else:\n        print('CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY environment variable is not defined')\n    print(data_dir)\n    data_dir = os.path.join(data_dir, 'Speech', 'AN4Corpus', 'v0')\n    os.chdir(data_dir)\n    feature_dimension = 33\n    feature = C.sequence.input_variable(feature_dimension)\n    label_dimension = 133\n    label = C.sequence.input_variable(label_dimension)\n    axis_lattice = C.Axis.new_unique_dynamic_axis('lattice_axis')\n    lattice = C.sequence.input_variable(1, sequence_axis=axis_lattice)\n    train_feature_filepath = os.path.join(data_dir, 'glob_0000.scp')\n    train_label_filepath = os.path.join(data_dir, 'glob_0000.mlf')\n    train_lattice_index_path = os.path.join(data_dir, 'latticeIndex.txt')\n    mapping_filepath = os.path.join(data_dir, 'state.list')\n    train_feature_stream = C.io.HTKFeatureDeserializer(C.io.StreamDefs(speech_feature=C.io.StreamDef(shape=feature_dimension, scp=train_feature_filepath)))\n    train_label_stream = C.io.HTKMLFDeserializer(mapping_filepath, C.io.StreamDefs(speech_label=C.io.StreamDef(shape=label_dimension, mlf=train_label_filepath)), True)\n    train_lattice_stream = C.io.LatticeDeserializer(train_lattice_index_path, C.io.StreamDefs(speech_lattice=C.io.StreamDef()))\n    train_data_reader = C.io.MinibatchSource([train_feature_stream, train_label_stream, train_lattice_stream], frame_mode=False)\n    train_input_map = {feature: train_data_reader.streams.speech_feature, label: train_data_reader.streams.speech_label, lattice: train_data_reader.streams.speech_lattice}\n    feature_mean = np.fromfile(os.path.join('GlobalStats', 'mean.363'), dtype=float, count=feature_dimension)\n    feature_inverse_stddev = np.fromfile(os.path.join('GlobalStats', 'var.363'), dtype=float, count=feature_dimension)\n    feature_normalized = (feature - feature_mean) * feature_inverse_stddev\n    with C.default_options(activation=C.sigmoid):\n        z = C.layers.Sequential([C.layers.For(range(3), lambda : C.layers.Recurrence(C.layers.LSTM(1024))), C.layers.Dense(label_dimension)])(feature_normalized)\n    mbsize = 1024\n    mbs_per_epoch = 10\n    max_epochs = 2\n    symListPath = os.path.join(data_dir, 'CY2SCH010061231_1369712653.numden.lats.symlist')\n    phonePath = os.path.join(data_dir, 'model.overalltying')\n    stateListPath = os.path.join(data_dir, 'state.list')\n    transProbPath = os.path.join(data_dir, 'model.transprob')\n    criteria = C.lattice_sequence_with_softmax(label, z, z, lattice, symListPath, phonePath, stateListPath, transProbPath)\n    err = C.classification_error(label, z)\n    lr = C.learning_parameter_schedule_per_sample([(3, 0.01), (1, 0.001)])\n    mm = C.momentum_schedule([(1000, 0.9), (0, 0.99)], mbsize)\n    learner = C.momentum_sgd(z.parameters, lr, mm)\n    trainer = C.Trainer(z, (criteria, err), learner)\n    C.logging.log_number_of_parameters(z)\n    progress_printer = C.logging.progress_print.ProgressPrinter(tag='Training', num_epochs=max_epochs)\n    for epoch in range(max_epochs):\n        for mb in range(mbs_per_epoch):\n            minibatch = train_data_reader.next_minibatch(mbsize, input_map=train_input_map)\n            trainer.train_minibatch(minibatch)\n            progress_printer.update_with_trainer(trainer, with_metric=True)\n        progress_printer.epoch_summary(with_metric=True)\n    assert np.allclose(trainer.previous_minibatch_evaluation_average, 0.15064, atol=TOLERANCE_ABSOLUTE)\n    assert np.allclose(trainer.previous_minibatch_loss_average, 0.035923, atol=TOLERANCE_ABSOLUTE)\n    assert trainer.previous_minibatch_sample_count == 218\n    assert trainer.total_number_of_samples_seen == 5750\n    print('Completed successfully.')",
            "def test_lattice_deserializer(device_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if cntk_device(device_id).type() != DeviceKind_GPU:\n        pytest.skip('test only runs on GPU')\n    try_set_default_device(cntk_device(device_id))\n    data_dir = ''\n    if 'CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY' in os.environ:\n        data_dir = os.environ['CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY']\n    else:\n        print('CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY environment variable is not defined')\n    print(data_dir)\n    data_dir = os.path.join(data_dir, 'Speech', 'AN4Corpus', 'v0')\n    os.chdir(data_dir)\n    feature_dimension = 33\n    feature = C.sequence.input_variable(feature_dimension)\n    label_dimension = 133\n    label = C.sequence.input_variable(label_dimension)\n    axis_lattice = C.Axis.new_unique_dynamic_axis('lattice_axis')\n    lattice = C.sequence.input_variable(1, sequence_axis=axis_lattice)\n    train_feature_filepath = os.path.join(data_dir, 'glob_0000.scp')\n    train_label_filepath = os.path.join(data_dir, 'glob_0000.mlf')\n    train_lattice_index_path = os.path.join(data_dir, 'latticeIndex.txt')\n    mapping_filepath = os.path.join(data_dir, 'state.list')\n    train_feature_stream = C.io.HTKFeatureDeserializer(C.io.StreamDefs(speech_feature=C.io.StreamDef(shape=feature_dimension, scp=train_feature_filepath)))\n    train_label_stream = C.io.HTKMLFDeserializer(mapping_filepath, C.io.StreamDefs(speech_label=C.io.StreamDef(shape=label_dimension, mlf=train_label_filepath)), True)\n    train_lattice_stream = C.io.LatticeDeserializer(train_lattice_index_path, C.io.StreamDefs(speech_lattice=C.io.StreamDef()))\n    train_data_reader = C.io.MinibatchSource([train_feature_stream, train_label_stream, train_lattice_stream], frame_mode=False)\n    train_input_map = {feature: train_data_reader.streams.speech_feature, label: train_data_reader.streams.speech_label, lattice: train_data_reader.streams.speech_lattice}\n    feature_mean = np.fromfile(os.path.join('GlobalStats', 'mean.363'), dtype=float, count=feature_dimension)\n    feature_inverse_stddev = np.fromfile(os.path.join('GlobalStats', 'var.363'), dtype=float, count=feature_dimension)\n    feature_normalized = (feature - feature_mean) * feature_inverse_stddev\n    with C.default_options(activation=C.sigmoid):\n        z = C.layers.Sequential([C.layers.For(range(3), lambda : C.layers.Recurrence(C.layers.LSTM(1024))), C.layers.Dense(label_dimension)])(feature_normalized)\n    mbsize = 1024\n    mbs_per_epoch = 10\n    max_epochs = 2\n    symListPath = os.path.join(data_dir, 'CY2SCH010061231_1369712653.numden.lats.symlist')\n    phonePath = os.path.join(data_dir, 'model.overalltying')\n    stateListPath = os.path.join(data_dir, 'state.list')\n    transProbPath = os.path.join(data_dir, 'model.transprob')\n    criteria = C.lattice_sequence_with_softmax(label, z, z, lattice, symListPath, phonePath, stateListPath, transProbPath)\n    err = C.classification_error(label, z)\n    lr = C.learning_parameter_schedule_per_sample([(3, 0.01), (1, 0.001)])\n    mm = C.momentum_schedule([(1000, 0.9), (0, 0.99)], mbsize)\n    learner = C.momentum_sgd(z.parameters, lr, mm)\n    trainer = C.Trainer(z, (criteria, err), learner)\n    C.logging.log_number_of_parameters(z)\n    progress_printer = C.logging.progress_print.ProgressPrinter(tag='Training', num_epochs=max_epochs)\n    for epoch in range(max_epochs):\n        for mb in range(mbs_per_epoch):\n            minibatch = train_data_reader.next_minibatch(mbsize, input_map=train_input_map)\n            trainer.train_minibatch(minibatch)\n            progress_printer.update_with_trainer(trainer, with_metric=True)\n        progress_printer.epoch_summary(with_metric=True)\n    assert np.allclose(trainer.previous_minibatch_evaluation_average, 0.15064, atol=TOLERANCE_ABSOLUTE)\n    assert np.allclose(trainer.previous_minibatch_loss_average, 0.035923, atol=TOLERANCE_ABSOLUTE)\n    assert trainer.previous_minibatch_sample_count == 218\n    assert trainer.total_number_of_samples_seen == 5750\n    print('Completed successfully.')",
            "def test_lattice_deserializer(device_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if cntk_device(device_id).type() != DeviceKind_GPU:\n        pytest.skip('test only runs on GPU')\n    try_set_default_device(cntk_device(device_id))\n    data_dir = ''\n    if 'CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY' in os.environ:\n        data_dir = os.environ['CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY']\n    else:\n        print('CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY environment variable is not defined')\n    print(data_dir)\n    data_dir = os.path.join(data_dir, 'Speech', 'AN4Corpus', 'v0')\n    os.chdir(data_dir)\n    feature_dimension = 33\n    feature = C.sequence.input_variable(feature_dimension)\n    label_dimension = 133\n    label = C.sequence.input_variable(label_dimension)\n    axis_lattice = C.Axis.new_unique_dynamic_axis('lattice_axis')\n    lattice = C.sequence.input_variable(1, sequence_axis=axis_lattice)\n    train_feature_filepath = os.path.join(data_dir, 'glob_0000.scp')\n    train_label_filepath = os.path.join(data_dir, 'glob_0000.mlf')\n    train_lattice_index_path = os.path.join(data_dir, 'latticeIndex.txt')\n    mapping_filepath = os.path.join(data_dir, 'state.list')\n    train_feature_stream = C.io.HTKFeatureDeserializer(C.io.StreamDefs(speech_feature=C.io.StreamDef(shape=feature_dimension, scp=train_feature_filepath)))\n    train_label_stream = C.io.HTKMLFDeserializer(mapping_filepath, C.io.StreamDefs(speech_label=C.io.StreamDef(shape=label_dimension, mlf=train_label_filepath)), True)\n    train_lattice_stream = C.io.LatticeDeserializer(train_lattice_index_path, C.io.StreamDefs(speech_lattice=C.io.StreamDef()))\n    train_data_reader = C.io.MinibatchSource([train_feature_stream, train_label_stream, train_lattice_stream], frame_mode=False)\n    train_input_map = {feature: train_data_reader.streams.speech_feature, label: train_data_reader.streams.speech_label, lattice: train_data_reader.streams.speech_lattice}\n    feature_mean = np.fromfile(os.path.join('GlobalStats', 'mean.363'), dtype=float, count=feature_dimension)\n    feature_inverse_stddev = np.fromfile(os.path.join('GlobalStats', 'var.363'), dtype=float, count=feature_dimension)\n    feature_normalized = (feature - feature_mean) * feature_inverse_stddev\n    with C.default_options(activation=C.sigmoid):\n        z = C.layers.Sequential([C.layers.For(range(3), lambda : C.layers.Recurrence(C.layers.LSTM(1024))), C.layers.Dense(label_dimension)])(feature_normalized)\n    mbsize = 1024\n    mbs_per_epoch = 10\n    max_epochs = 2\n    symListPath = os.path.join(data_dir, 'CY2SCH010061231_1369712653.numden.lats.symlist')\n    phonePath = os.path.join(data_dir, 'model.overalltying')\n    stateListPath = os.path.join(data_dir, 'state.list')\n    transProbPath = os.path.join(data_dir, 'model.transprob')\n    criteria = C.lattice_sequence_with_softmax(label, z, z, lattice, symListPath, phonePath, stateListPath, transProbPath)\n    err = C.classification_error(label, z)\n    lr = C.learning_parameter_schedule_per_sample([(3, 0.01), (1, 0.001)])\n    mm = C.momentum_schedule([(1000, 0.9), (0, 0.99)], mbsize)\n    learner = C.momentum_sgd(z.parameters, lr, mm)\n    trainer = C.Trainer(z, (criteria, err), learner)\n    C.logging.log_number_of_parameters(z)\n    progress_printer = C.logging.progress_print.ProgressPrinter(tag='Training', num_epochs=max_epochs)\n    for epoch in range(max_epochs):\n        for mb in range(mbs_per_epoch):\n            minibatch = train_data_reader.next_minibatch(mbsize, input_map=train_input_map)\n            trainer.train_minibatch(minibatch)\n            progress_printer.update_with_trainer(trainer, with_metric=True)\n        progress_printer.epoch_summary(with_metric=True)\n    assert np.allclose(trainer.previous_minibatch_evaluation_average, 0.15064, atol=TOLERANCE_ABSOLUTE)\n    assert np.allclose(trainer.previous_minibatch_loss_average, 0.035923, atol=TOLERANCE_ABSOLUTE)\n    assert trainer.previous_minibatch_sample_count == 218\n    assert trainer.total_number_of_samples_seen == 5750\n    print('Completed successfully.')",
            "def test_lattice_deserializer(device_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if cntk_device(device_id).type() != DeviceKind_GPU:\n        pytest.skip('test only runs on GPU')\n    try_set_default_device(cntk_device(device_id))\n    data_dir = ''\n    if 'CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY' in os.environ:\n        data_dir = os.environ['CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY']\n    else:\n        print('CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY environment variable is not defined')\n    print(data_dir)\n    data_dir = os.path.join(data_dir, 'Speech', 'AN4Corpus', 'v0')\n    os.chdir(data_dir)\n    feature_dimension = 33\n    feature = C.sequence.input_variable(feature_dimension)\n    label_dimension = 133\n    label = C.sequence.input_variable(label_dimension)\n    axis_lattice = C.Axis.new_unique_dynamic_axis('lattice_axis')\n    lattice = C.sequence.input_variable(1, sequence_axis=axis_lattice)\n    train_feature_filepath = os.path.join(data_dir, 'glob_0000.scp')\n    train_label_filepath = os.path.join(data_dir, 'glob_0000.mlf')\n    train_lattice_index_path = os.path.join(data_dir, 'latticeIndex.txt')\n    mapping_filepath = os.path.join(data_dir, 'state.list')\n    train_feature_stream = C.io.HTKFeatureDeserializer(C.io.StreamDefs(speech_feature=C.io.StreamDef(shape=feature_dimension, scp=train_feature_filepath)))\n    train_label_stream = C.io.HTKMLFDeserializer(mapping_filepath, C.io.StreamDefs(speech_label=C.io.StreamDef(shape=label_dimension, mlf=train_label_filepath)), True)\n    train_lattice_stream = C.io.LatticeDeserializer(train_lattice_index_path, C.io.StreamDefs(speech_lattice=C.io.StreamDef()))\n    train_data_reader = C.io.MinibatchSource([train_feature_stream, train_label_stream, train_lattice_stream], frame_mode=False)\n    train_input_map = {feature: train_data_reader.streams.speech_feature, label: train_data_reader.streams.speech_label, lattice: train_data_reader.streams.speech_lattice}\n    feature_mean = np.fromfile(os.path.join('GlobalStats', 'mean.363'), dtype=float, count=feature_dimension)\n    feature_inverse_stddev = np.fromfile(os.path.join('GlobalStats', 'var.363'), dtype=float, count=feature_dimension)\n    feature_normalized = (feature - feature_mean) * feature_inverse_stddev\n    with C.default_options(activation=C.sigmoid):\n        z = C.layers.Sequential([C.layers.For(range(3), lambda : C.layers.Recurrence(C.layers.LSTM(1024))), C.layers.Dense(label_dimension)])(feature_normalized)\n    mbsize = 1024\n    mbs_per_epoch = 10\n    max_epochs = 2\n    symListPath = os.path.join(data_dir, 'CY2SCH010061231_1369712653.numden.lats.symlist')\n    phonePath = os.path.join(data_dir, 'model.overalltying')\n    stateListPath = os.path.join(data_dir, 'state.list')\n    transProbPath = os.path.join(data_dir, 'model.transprob')\n    criteria = C.lattice_sequence_with_softmax(label, z, z, lattice, symListPath, phonePath, stateListPath, transProbPath)\n    err = C.classification_error(label, z)\n    lr = C.learning_parameter_schedule_per_sample([(3, 0.01), (1, 0.001)])\n    mm = C.momentum_schedule([(1000, 0.9), (0, 0.99)], mbsize)\n    learner = C.momentum_sgd(z.parameters, lr, mm)\n    trainer = C.Trainer(z, (criteria, err), learner)\n    C.logging.log_number_of_parameters(z)\n    progress_printer = C.logging.progress_print.ProgressPrinter(tag='Training', num_epochs=max_epochs)\n    for epoch in range(max_epochs):\n        for mb in range(mbs_per_epoch):\n            minibatch = train_data_reader.next_minibatch(mbsize, input_map=train_input_map)\n            trainer.train_minibatch(minibatch)\n            progress_printer.update_with_trainer(trainer, with_metric=True)\n        progress_printer.epoch_summary(with_metric=True)\n    assert np.allclose(trainer.previous_minibatch_evaluation_average, 0.15064, atol=TOLERANCE_ABSOLUTE)\n    assert np.allclose(trainer.previous_minibatch_loss_average, 0.035923, atol=TOLERANCE_ABSOLUTE)\n    assert trainer.previous_minibatch_sample_count == 218\n    assert trainer.total_number_of_samples_seen == 5750\n    print('Completed successfully.')",
            "def test_lattice_deserializer(device_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if cntk_device(device_id).type() != DeviceKind_GPU:\n        pytest.skip('test only runs on GPU')\n    try_set_default_device(cntk_device(device_id))\n    data_dir = ''\n    if 'CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY' in os.environ:\n        data_dir = os.environ['CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY']\n    else:\n        print('CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY environment variable is not defined')\n    print(data_dir)\n    data_dir = os.path.join(data_dir, 'Speech', 'AN4Corpus', 'v0')\n    os.chdir(data_dir)\n    feature_dimension = 33\n    feature = C.sequence.input_variable(feature_dimension)\n    label_dimension = 133\n    label = C.sequence.input_variable(label_dimension)\n    axis_lattice = C.Axis.new_unique_dynamic_axis('lattice_axis')\n    lattice = C.sequence.input_variable(1, sequence_axis=axis_lattice)\n    train_feature_filepath = os.path.join(data_dir, 'glob_0000.scp')\n    train_label_filepath = os.path.join(data_dir, 'glob_0000.mlf')\n    train_lattice_index_path = os.path.join(data_dir, 'latticeIndex.txt')\n    mapping_filepath = os.path.join(data_dir, 'state.list')\n    train_feature_stream = C.io.HTKFeatureDeserializer(C.io.StreamDefs(speech_feature=C.io.StreamDef(shape=feature_dimension, scp=train_feature_filepath)))\n    train_label_stream = C.io.HTKMLFDeserializer(mapping_filepath, C.io.StreamDefs(speech_label=C.io.StreamDef(shape=label_dimension, mlf=train_label_filepath)), True)\n    train_lattice_stream = C.io.LatticeDeserializer(train_lattice_index_path, C.io.StreamDefs(speech_lattice=C.io.StreamDef()))\n    train_data_reader = C.io.MinibatchSource([train_feature_stream, train_label_stream, train_lattice_stream], frame_mode=False)\n    train_input_map = {feature: train_data_reader.streams.speech_feature, label: train_data_reader.streams.speech_label, lattice: train_data_reader.streams.speech_lattice}\n    feature_mean = np.fromfile(os.path.join('GlobalStats', 'mean.363'), dtype=float, count=feature_dimension)\n    feature_inverse_stddev = np.fromfile(os.path.join('GlobalStats', 'var.363'), dtype=float, count=feature_dimension)\n    feature_normalized = (feature - feature_mean) * feature_inverse_stddev\n    with C.default_options(activation=C.sigmoid):\n        z = C.layers.Sequential([C.layers.For(range(3), lambda : C.layers.Recurrence(C.layers.LSTM(1024))), C.layers.Dense(label_dimension)])(feature_normalized)\n    mbsize = 1024\n    mbs_per_epoch = 10\n    max_epochs = 2\n    symListPath = os.path.join(data_dir, 'CY2SCH010061231_1369712653.numden.lats.symlist')\n    phonePath = os.path.join(data_dir, 'model.overalltying')\n    stateListPath = os.path.join(data_dir, 'state.list')\n    transProbPath = os.path.join(data_dir, 'model.transprob')\n    criteria = C.lattice_sequence_with_softmax(label, z, z, lattice, symListPath, phonePath, stateListPath, transProbPath)\n    err = C.classification_error(label, z)\n    lr = C.learning_parameter_schedule_per_sample([(3, 0.01), (1, 0.001)])\n    mm = C.momentum_schedule([(1000, 0.9), (0, 0.99)], mbsize)\n    learner = C.momentum_sgd(z.parameters, lr, mm)\n    trainer = C.Trainer(z, (criteria, err), learner)\n    C.logging.log_number_of_parameters(z)\n    progress_printer = C.logging.progress_print.ProgressPrinter(tag='Training', num_epochs=max_epochs)\n    for epoch in range(max_epochs):\n        for mb in range(mbs_per_epoch):\n            minibatch = train_data_reader.next_minibatch(mbsize, input_map=train_input_map)\n            trainer.train_minibatch(minibatch)\n            progress_printer.update_with_trainer(trainer, with_metric=True)\n        progress_printer.epoch_summary(with_metric=True)\n    assert np.allclose(trainer.previous_minibatch_evaluation_average, 0.15064, atol=TOLERANCE_ABSOLUTE)\n    assert np.allclose(trainer.previous_minibatch_loss_average, 0.035923, atol=TOLERANCE_ABSOLUTE)\n    assert trainer.previous_minibatch_sample_count == 218\n    assert trainer.total_number_of_samples_seen == 5750\n    print('Completed successfully.')"
        ]
    }
]