[
    {
        "func_name": "__init__",
        "original": "def __init__(self, eval_model, cfg):\n    self._img_shape = (cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH)\n    image_input = input_variable(shape=self._img_shape, dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    dims_input = input_variable((1, 6), dynamic_axes=[Axis.default_batch_axis()], name='dims_input')\n    self._eval_model = eval_model(image_input, dims_input)",
        "mutated": [
            "def __init__(self, eval_model, cfg):\n    if False:\n        i = 10\n    self._img_shape = (cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH)\n    image_input = input_variable(shape=self._img_shape, dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    dims_input = input_variable((1, 6), dynamic_axes=[Axis.default_batch_axis()], name='dims_input')\n    self._eval_model = eval_model(image_input, dims_input)",
            "def __init__(self, eval_model, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self._img_shape = (cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH)\n    image_input = input_variable(shape=self._img_shape, dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    dims_input = input_variable((1, 6), dynamic_axes=[Axis.default_batch_axis()], name='dims_input')\n    self._eval_model = eval_model(image_input, dims_input)",
            "def __init__(self, eval_model, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self._img_shape = (cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH)\n    image_input = input_variable(shape=self._img_shape, dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    dims_input = input_variable((1, 6), dynamic_axes=[Axis.default_batch_axis()], name='dims_input')\n    self._eval_model = eval_model(image_input, dims_input)",
            "def __init__(self, eval_model, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self._img_shape = (cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH)\n    image_input = input_variable(shape=self._img_shape, dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    dims_input = input_variable((1, 6), dynamic_axes=[Axis.default_batch_axis()], name='dims_input')\n    self._eval_model = eval_model(image_input, dims_input)",
            "def __init__(self, eval_model, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self._img_shape = (cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH)\n    image_input = input_variable(shape=self._img_shape, dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    dims_input = input_variable((1, 6), dynamic_axes=[Axis.default_batch_axis()], name='dims_input')\n    self._eval_model = eval_model(image_input, dims_input)"
        ]
    },
    {
        "func_name": "process_image",
        "original": "def process_image(self, img_path):\n    (out_cls_pred, out_rpn_rois, out_bbox_regr, dims) = self.process_image_detailed(img_path)\n    labels = out_cls_pred.argmax(axis=1)\n    regressed_rois = regress_rois(out_rpn_rois, out_bbox_regr, labels, dims)\n    return (regressed_rois, out_cls_pred)",
        "mutated": [
            "def process_image(self, img_path):\n    if False:\n        i = 10\n    (out_cls_pred, out_rpn_rois, out_bbox_regr, dims) = self.process_image_detailed(img_path)\n    labels = out_cls_pred.argmax(axis=1)\n    regressed_rois = regress_rois(out_rpn_rois, out_bbox_regr, labels, dims)\n    return (regressed_rois, out_cls_pred)",
            "def process_image(self, img_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (out_cls_pred, out_rpn_rois, out_bbox_regr, dims) = self.process_image_detailed(img_path)\n    labels = out_cls_pred.argmax(axis=1)\n    regressed_rois = regress_rois(out_rpn_rois, out_bbox_regr, labels, dims)\n    return (regressed_rois, out_cls_pred)",
            "def process_image(self, img_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (out_cls_pred, out_rpn_rois, out_bbox_regr, dims) = self.process_image_detailed(img_path)\n    labels = out_cls_pred.argmax(axis=1)\n    regressed_rois = regress_rois(out_rpn_rois, out_bbox_regr, labels, dims)\n    return (regressed_rois, out_cls_pred)",
            "def process_image(self, img_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (out_cls_pred, out_rpn_rois, out_bbox_regr, dims) = self.process_image_detailed(img_path)\n    labels = out_cls_pred.argmax(axis=1)\n    regressed_rois = regress_rois(out_rpn_rois, out_bbox_regr, labels, dims)\n    return (regressed_rois, out_cls_pred)",
            "def process_image(self, img_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (out_cls_pred, out_rpn_rois, out_bbox_regr, dims) = self.process_image_detailed(img_path)\n    labels = out_cls_pred.argmax(axis=1)\n    regressed_rois = regress_rois(out_rpn_rois, out_bbox_regr, labels, dims)\n    return (regressed_rois, out_cls_pred)"
        ]
    },
    {
        "func_name": "process_image_detailed",
        "original": "def process_image_detailed(self, img_path):\n    (_, cntk_img_input, dims) = load_resize_and_pad(img_path, self._img_shape[2], self._img_shape[1])\n    cntk_dims_input = np.array(dims, dtype=np.float32)\n    cntk_dims_input.shape = (1,) + cntk_dims_input.shape\n    output = self._eval_model.eval({self._eval_model.arguments[0]: [cntk_img_input], self._eval_model.arguments[1]: cntk_dims_input})\n    out_dict = dict([(k.name, k) for k in output])\n    out_cls_pred = output[out_dict['cls_pred']][0]\n    out_rpn_rois = output[out_dict['rpn_rois']][0]\n    out_bbox_regr = output[out_dict['bbox_regr']][0]\n    return (out_cls_pred, out_rpn_rois, out_bbox_regr, dims)",
        "mutated": [
            "def process_image_detailed(self, img_path):\n    if False:\n        i = 10\n    (_, cntk_img_input, dims) = load_resize_and_pad(img_path, self._img_shape[2], self._img_shape[1])\n    cntk_dims_input = np.array(dims, dtype=np.float32)\n    cntk_dims_input.shape = (1,) + cntk_dims_input.shape\n    output = self._eval_model.eval({self._eval_model.arguments[0]: [cntk_img_input], self._eval_model.arguments[1]: cntk_dims_input})\n    out_dict = dict([(k.name, k) for k in output])\n    out_cls_pred = output[out_dict['cls_pred']][0]\n    out_rpn_rois = output[out_dict['rpn_rois']][0]\n    out_bbox_regr = output[out_dict['bbox_regr']][0]\n    return (out_cls_pred, out_rpn_rois, out_bbox_regr, dims)",
            "def process_image_detailed(self, img_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (_, cntk_img_input, dims) = load_resize_and_pad(img_path, self._img_shape[2], self._img_shape[1])\n    cntk_dims_input = np.array(dims, dtype=np.float32)\n    cntk_dims_input.shape = (1,) + cntk_dims_input.shape\n    output = self._eval_model.eval({self._eval_model.arguments[0]: [cntk_img_input], self._eval_model.arguments[1]: cntk_dims_input})\n    out_dict = dict([(k.name, k) for k in output])\n    out_cls_pred = output[out_dict['cls_pred']][0]\n    out_rpn_rois = output[out_dict['rpn_rois']][0]\n    out_bbox_regr = output[out_dict['bbox_regr']][0]\n    return (out_cls_pred, out_rpn_rois, out_bbox_regr, dims)",
            "def process_image_detailed(self, img_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (_, cntk_img_input, dims) = load_resize_and_pad(img_path, self._img_shape[2], self._img_shape[1])\n    cntk_dims_input = np.array(dims, dtype=np.float32)\n    cntk_dims_input.shape = (1,) + cntk_dims_input.shape\n    output = self._eval_model.eval({self._eval_model.arguments[0]: [cntk_img_input], self._eval_model.arguments[1]: cntk_dims_input})\n    out_dict = dict([(k.name, k) for k in output])\n    out_cls_pred = output[out_dict['cls_pred']][0]\n    out_rpn_rois = output[out_dict['rpn_rois']][0]\n    out_bbox_regr = output[out_dict['bbox_regr']][0]\n    return (out_cls_pred, out_rpn_rois, out_bbox_regr, dims)",
            "def process_image_detailed(self, img_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (_, cntk_img_input, dims) = load_resize_and_pad(img_path, self._img_shape[2], self._img_shape[1])\n    cntk_dims_input = np.array(dims, dtype=np.float32)\n    cntk_dims_input.shape = (1,) + cntk_dims_input.shape\n    output = self._eval_model.eval({self._eval_model.arguments[0]: [cntk_img_input], self._eval_model.arguments[1]: cntk_dims_input})\n    out_dict = dict([(k.name, k) for k in output])\n    out_cls_pred = output[out_dict['cls_pred']][0]\n    out_rpn_rois = output[out_dict['rpn_rois']][0]\n    out_bbox_regr = output[out_dict['bbox_regr']][0]\n    return (out_cls_pred, out_rpn_rois, out_bbox_regr, dims)",
            "def process_image_detailed(self, img_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (_, cntk_img_input, dims) = load_resize_and_pad(img_path, self._img_shape[2], self._img_shape[1])\n    cntk_dims_input = np.array(dims, dtype=np.float32)\n    cntk_dims_input.shape = (1,) + cntk_dims_input.shape\n    output = self._eval_model.eval({self._eval_model.arguments[0]: [cntk_img_input], self._eval_model.arguments[1]: cntk_dims_input})\n    out_dict = dict([(k.name, k) for k in output])\n    out_cls_pred = output[out_dict['cls_pred']][0]\n    out_rpn_rois = output[out_dict['rpn_rois']][0]\n    out_bbox_regr = output[out_dict['bbox_regr']][0]\n    return (out_cls_pred, out_rpn_rois, out_bbox_regr, dims)"
        ]
    },
    {
        "func_name": "compute_test_set_aps",
        "original": "def compute_test_set_aps(eval_model, cfg):\n    num_test_images = cfg['DATA'].NUM_TEST_IMAGES\n    classes = cfg['DATA'].CLASSES\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    frcn_eval = eval_model(image_input, dims_input)\n    minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TEST_MAP_FILE, cfg['DATA'].TEST_ROI_FILE, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, randomize=False, use_flipping=False, max_images=cfg['DATA'].NUM_TEST_IMAGES, num_classes=cfg['DATA'].NUM_CLASSES, proposal_provider=None)\n    input_map = {minibatch_source.image_si: image_input, minibatch_source.roi_si: roi_input, minibatch_source.dims_si: dims_input}\n    all_boxes = [[[] for _ in range(num_test_images)] for _ in range(cfg['DATA'].NUM_CLASSES)]\n    print('Evaluating Faster R-CNN model for %s images.' % num_test_images)\n    all_gt_infos = {key: [] for key in classes}\n    for img_i in range(0, num_test_images):\n        mb_data = minibatch_source.next_minibatch(1, input_map=input_map)\n        gt_row = mb_data[roi_input].asarray()\n        gt_row = gt_row.reshape((cfg.INPUT_ROIS_PER_IMAGE, 5))\n        all_gt_boxes = gt_row[np.where(gt_row[:, -1] > 0)]\n        for (cls_index, cls_name) in enumerate(classes):\n            if cls_index == 0:\n                continue\n            cls_gt_boxes = all_gt_boxes[np.where(all_gt_boxes[:, -1] == cls_index)]\n            all_gt_infos[cls_name].append({'bbox': np.array(cls_gt_boxes), 'difficult': [False] * len(cls_gt_boxes), 'det': [False] * len(cls_gt_boxes)})\n        output = frcn_eval.eval({image_input: mb_data[image_input], dims_input: mb_data[dims_input]})\n        out_dict = dict([(k.name, k) for k in output])\n        out_cls_pred = output[out_dict['cls_pred']][0]\n        out_rpn_rois = output[out_dict['rpn_rois']][0]\n        out_bbox_regr = output[out_dict['bbox_regr']][0]\n        labels = out_cls_pred.argmax(axis=1)\n        scores = out_cls_pred.max(axis=1)\n        regressed_rois = regress_rois(out_rpn_rois, out_bbox_regr, labels, mb_data[dims_input].asarray())\n        labels.shape = labels.shape + (1,)\n        scores.shape = scores.shape + (1,)\n        coords_score_label = np.hstack((regressed_rois, scores, labels))\n        for cls_j in range(1, cfg['DATA'].NUM_CLASSES):\n            coords_score_label_for_cls = coords_score_label[np.where(coords_score_label[:, -1] == cls_j)]\n            all_boxes[cls_j][img_i] = coords_score_label_for_cls[:, :-1].astype(np.float32, copy=False)\n        if (img_i + 1) % 100 == 0:\n            print('Processed {} samples'.format(img_i + 1))\n    aps = evaluate_detections(all_boxes, all_gt_infos, classes, use_gpu_nms=cfg.USE_GPU_NMS, device_id=cfg.GPU_ID, nms_threshold=cfg.RESULTS_NMS_THRESHOLD, conf_threshold=cfg.RESULTS_NMS_CONF_THRESHOLD)\n    return aps",
        "mutated": [
            "def compute_test_set_aps(eval_model, cfg):\n    if False:\n        i = 10\n    num_test_images = cfg['DATA'].NUM_TEST_IMAGES\n    classes = cfg['DATA'].CLASSES\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    frcn_eval = eval_model(image_input, dims_input)\n    minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TEST_MAP_FILE, cfg['DATA'].TEST_ROI_FILE, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, randomize=False, use_flipping=False, max_images=cfg['DATA'].NUM_TEST_IMAGES, num_classes=cfg['DATA'].NUM_CLASSES, proposal_provider=None)\n    input_map = {minibatch_source.image_si: image_input, minibatch_source.roi_si: roi_input, minibatch_source.dims_si: dims_input}\n    all_boxes = [[[] for _ in range(num_test_images)] for _ in range(cfg['DATA'].NUM_CLASSES)]\n    print('Evaluating Faster R-CNN model for %s images.' % num_test_images)\n    all_gt_infos = {key: [] for key in classes}\n    for img_i in range(0, num_test_images):\n        mb_data = minibatch_source.next_minibatch(1, input_map=input_map)\n        gt_row = mb_data[roi_input].asarray()\n        gt_row = gt_row.reshape((cfg.INPUT_ROIS_PER_IMAGE, 5))\n        all_gt_boxes = gt_row[np.where(gt_row[:, -1] > 0)]\n        for (cls_index, cls_name) in enumerate(classes):\n            if cls_index == 0:\n                continue\n            cls_gt_boxes = all_gt_boxes[np.where(all_gt_boxes[:, -1] == cls_index)]\n            all_gt_infos[cls_name].append({'bbox': np.array(cls_gt_boxes), 'difficult': [False] * len(cls_gt_boxes), 'det': [False] * len(cls_gt_boxes)})\n        output = frcn_eval.eval({image_input: mb_data[image_input], dims_input: mb_data[dims_input]})\n        out_dict = dict([(k.name, k) for k in output])\n        out_cls_pred = output[out_dict['cls_pred']][0]\n        out_rpn_rois = output[out_dict['rpn_rois']][0]\n        out_bbox_regr = output[out_dict['bbox_regr']][0]\n        labels = out_cls_pred.argmax(axis=1)\n        scores = out_cls_pred.max(axis=1)\n        regressed_rois = regress_rois(out_rpn_rois, out_bbox_regr, labels, mb_data[dims_input].asarray())\n        labels.shape = labels.shape + (1,)\n        scores.shape = scores.shape + (1,)\n        coords_score_label = np.hstack((regressed_rois, scores, labels))\n        for cls_j in range(1, cfg['DATA'].NUM_CLASSES):\n            coords_score_label_for_cls = coords_score_label[np.where(coords_score_label[:, -1] == cls_j)]\n            all_boxes[cls_j][img_i] = coords_score_label_for_cls[:, :-1].astype(np.float32, copy=False)\n        if (img_i + 1) % 100 == 0:\n            print('Processed {} samples'.format(img_i + 1))\n    aps = evaluate_detections(all_boxes, all_gt_infos, classes, use_gpu_nms=cfg.USE_GPU_NMS, device_id=cfg.GPU_ID, nms_threshold=cfg.RESULTS_NMS_THRESHOLD, conf_threshold=cfg.RESULTS_NMS_CONF_THRESHOLD)\n    return aps",
            "def compute_test_set_aps(eval_model, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    num_test_images = cfg['DATA'].NUM_TEST_IMAGES\n    classes = cfg['DATA'].CLASSES\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    frcn_eval = eval_model(image_input, dims_input)\n    minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TEST_MAP_FILE, cfg['DATA'].TEST_ROI_FILE, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, randomize=False, use_flipping=False, max_images=cfg['DATA'].NUM_TEST_IMAGES, num_classes=cfg['DATA'].NUM_CLASSES, proposal_provider=None)\n    input_map = {minibatch_source.image_si: image_input, minibatch_source.roi_si: roi_input, minibatch_source.dims_si: dims_input}\n    all_boxes = [[[] for _ in range(num_test_images)] for _ in range(cfg['DATA'].NUM_CLASSES)]\n    print('Evaluating Faster R-CNN model for %s images.' % num_test_images)\n    all_gt_infos = {key: [] for key in classes}\n    for img_i in range(0, num_test_images):\n        mb_data = minibatch_source.next_minibatch(1, input_map=input_map)\n        gt_row = mb_data[roi_input].asarray()\n        gt_row = gt_row.reshape((cfg.INPUT_ROIS_PER_IMAGE, 5))\n        all_gt_boxes = gt_row[np.where(gt_row[:, -1] > 0)]\n        for (cls_index, cls_name) in enumerate(classes):\n            if cls_index == 0:\n                continue\n            cls_gt_boxes = all_gt_boxes[np.where(all_gt_boxes[:, -1] == cls_index)]\n            all_gt_infos[cls_name].append({'bbox': np.array(cls_gt_boxes), 'difficult': [False] * len(cls_gt_boxes), 'det': [False] * len(cls_gt_boxes)})\n        output = frcn_eval.eval({image_input: mb_data[image_input], dims_input: mb_data[dims_input]})\n        out_dict = dict([(k.name, k) for k in output])\n        out_cls_pred = output[out_dict['cls_pred']][0]\n        out_rpn_rois = output[out_dict['rpn_rois']][0]\n        out_bbox_regr = output[out_dict['bbox_regr']][0]\n        labels = out_cls_pred.argmax(axis=1)\n        scores = out_cls_pred.max(axis=1)\n        regressed_rois = regress_rois(out_rpn_rois, out_bbox_regr, labels, mb_data[dims_input].asarray())\n        labels.shape = labels.shape + (1,)\n        scores.shape = scores.shape + (1,)\n        coords_score_label = np.hstack((regressed_rois, scores, labels))\n        for cls_j in range(1, cfg['DATA'].NUM_CLASSES):\n            coords_score_label_for_cls = coords_score_label[np.where(coords_score_label[:, -1] == cls_j)]\n            all_boxes[cls_j][img_i] = coords_score_label_for_cls[:, :-1].astype(np.float32, copy=False)\n        if (img_i + 1) % 100 == 0:\n            print('Processed {} samples'.format(img_i + 1))\n    aps = evaluate_detections(all_boxes, all_gt_infos, classes, use_gpu_nms=cfg.USE_GPU_NMS, device_id=cfg.GPU_ID, nms_threshold=cfg.RESULTS_NMS_THRESHOLD, conf_threshold=cfg.RESULTS_NMS_CONF_THRESHOLD)\n    return aps",
            "def compute_test_set_aps(eval_model, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    num_test_images = cfg['DATA'].NUM_TEST_IMAGES\n    classes = cfg['DATA'].CLASSES\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    frcn_eval = eval_model(image_input, dims_input)\n    minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TEST_MAP_FILE, cfg['DATA'].TEST_ROI_FILE, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, randomize=False, use_flipping=False, max_images=cfg['DATA'].NUM_TEST_IMAGES, num_classes=cfg['DATA'].NUM_CLASSES, proposal_provider=None)\n    input_map = {minibatch_source.image_si: image_input, minibatch_source.roi_si: roi_input, minibatch_source.dims_si: dims_input}\n    all_boxes = [[[] for _ in range(num_test_images)] for _ in range(cfg['DATA'].NUM_CLASSES)]\n    print('Evaluating Faster R-CNN model for %s images.' % num_test_images)\n    all_gt_infos = {key: [] for key in classes}\n    for img_i in range(0, num_test_images):\n        mb_data = minibatch_source.next_minibatch(1, input_map=input_map)\n        gt_row = mb_data[roi_input].asarray()\n        gt_row = gt_row.reshape((cfg.INPUT_ROIS_PER_IMAGE, 5))\n        all_gt_boxes = gt_row[np.where(gt_row[:, -1] > 0)]\n        for (cls_index, cls_name) in enumerate(classes):\n            if cls_index == 0:\n                continue\n            cls_gt_boxes = all_gt_boxes[np.where(all_gt_boxes[:, -1] == cls_index)]\n            all_gt_infos[cls_name].append({'bbox': np.array(cls_gt_boxes), 'difficult': [False] * len(cls_gt_boxes), 'det': [False] * len(cls_gt_boxes)})\n        output = frcn_eval.eval({image_input: mb_data[image_input], dims_input: mb_data[dims_input]})\n        out_dict = dict([(k.name, k) for k in output])\n        out_cls_pred = output[out_dict['cls_pred']][0]\n        out_rpn_rois = output[out_dict['rpn_rois']][0]\n        out_bbox_regr = output[out_dict['bbox_regr']][0]\n        labels = out_cls_pred.argmax(axis=1)\n        scores = out_cls_pred.max(axis=1)\n        regressed_rois = regress_rois(out_rpn_rois, out_bbox_regr, labels, mb_data[dims_input].asarray())\n        labels.shape = labels.shape + (1,)\n        scores.shape = scores.shape + (1,)\n        coords_score_label = np.hstack((regressed_rois, scores, labels))\n        for cls_j in range(1, cfg['DATA'].NUM_CLASSES):\n            coords_score_label_for_cls = coords_score_label[np.where(coords_score_label[:, -1] == cls_j)]\n            all_boxes[cls_j][img_i] = coords_score_label_for_cls[:, :-1].astype(np.float32, copy=False)\n        if (img_i + 1) % 100 == 0:\n            print('Processed {} samples'.format(img_i + 1))\n    aps = evaluate_detections(all_boxes, all_gt_infos, classes, use_gpu_nms=cfg.USE_GPU_NMS, device_id=cfg.GPU_ID, nms_threshold=cfg.RESULTS_NMS_THRESHOLD, conf_threshold=cfg.RESULTS_NMS_CONF_THRESHOLD)\n    return aps",
            "def compute_test_set_aps(eval_model, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    num_test_images = cfg['DATA'].NUM_TEST_IMAGES\n    classes = cfg['DATA'].CLASSES\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    frcn_eval = eval_model(image_input, dims_input)\n    minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TEST_MAP_FILE, cfg['DATA'].TEST_ROI_FILE, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, randomize=False, use_flipping=False, max_images=cfg['DATA'].NUM_TEST_IMAGES, num_classes=cfg['DATA'].NUM_CLASSES, proposal_provider=None)\n    input_map = {minibatch_source.image_si: image_input, minibatch_source.roi_si: roi_input, minibatch_source.dims_si: dims_input}\n    all_boxes = [[[] for _ in range(num_test_images)] for _ in range(cfg['DATA'].NUM_CLASSES)]\n    print('Evaluating Faster R-CNN model for %s images.' % num_test_images)\n    all_gt_infos = {key: [] for key in classes}\n    for img_i in range(0, num_test_images):\n        mb_data = minibatch_source.next_minibatch(1, input_map=input_map)\n        gt_row = mb_data[roi_input].asarray()\n        gt_row = gt_row.reshape((cfg.INPUT_ROIS_PER_IMAGE, 5))\n        all_gt_boxes = gt_row[np.where(gt_row[:, -1] > 0)]\n        for (cls_index, cls_name) in enumerate(classes):\n            if cls_index == 0:\n                continue\n            cls_gt_boxes = all_gt_boxes[np.where(all_gt_boxes[:, -1] == cls_index)]\n            all_gt_infos[cls_name].append({'bbox': np.array(cls_gt_boxes), 'difficult': [False] * len(cls_gt_boxes), 'det': [False] * len(cls_gt_boxes)})\n        output = frcn_eval.eval({image_input: mb_data[image_input], dims_input: mb_data[dims_input]})\n        out_dict = dict([(k.name, k) for k in output])\n        out_cls_pred = output[out_dict['cls_pred']][0]\n        out_rpn_rois = output[out_dict['rpn_rois']][0]\n        out_bbox_regr = output[out_dict['bbox_regr']][0]\n        labels = out_cls_pred.argmax(axis=1)\n        scores = out_cls_pred.max(axis=1)\n        regressed_rois = regress_rois(out_rpn_rois, out_bbox_regr, labels, mb_data[dims_input].asarray())\n        labels.shape = labels.shape + (1,)\n        scores.shape = scores.shape + (1,)\n        coords_score_label = np.hstack((regressed_rois, scores, labels))\n        for cls_j in range(1, cfg['DATA'].NUM_CLASSES):\n            coords_score_label_for_cls = coords_score_label[np.where(coords_score_label[:, -1] == cls_j)]\n            all_boxes[cls_j][img_i] = coords_score_label_for_cls[:, :-1].astype(np.float32, copy=False)\n        if (img_i + 1) % 100 == 0:\n            print('Processed {} samples'.format(img_i + 1))\n    aps = evaluate_detections(all_boxes, all_gt_infos, classes, use_gpu_nms=cfg.USE_GPU_NMS, device_id=cfg.GPU_ID, nms_threshold=cfg.RESULTS_NMS_THRESHOLD, conf_threshold=cfg.RESULTS_NMS_CONF_THRESHOLD)\n    return aps",
            "def compute_test_set_aps(eval_model, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    num_test_images = cfg['DATA'].NUM_TEST_IMAGES\n    classes = cfg['DATA'].CLASSES\n    image_input = input_variable(shape=(cfg.NUM_CHANNELS, cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH), dynamic_axes=[Axis.default_batch_axis()], name=cfg['MODEL'].FEATURE_NODE_NAME)\n    roi_input = input_variable((cfg.INPUT_ROIS_PER_IMAGE, 5), dynamic_axes=[Axis.default_batch_axis()])\n    dims_input = input_variable(6, dynamic_axes=[Axis.default_batch_axis()])\n    frcn_eval = eval_model(image_input, dims_input)\n    minibatch_source = ObjectDetectionMinibatchSource(cfg['DATA'].TEST_MAP_FILE, cfg['DATA'].TEST_ROI_FILE, max_annotations_per_image=cfg.INPUT_ROIS_PER_IMAGE, pad_width=cfg.IMAGE_WIDTH, pad_height=cfg.IMAGE_HEIGHT, pad_value=cfg['MODEL'].IMG_PAD_COLOR, randomize=False, use_flipping=False, max_images=cfg['DATA'].NUM_TEST_IMAGES, num_classes=cfg['DATA'].NUM_CLASSES, proposal_provider=None)\n    input_map = {minibatch_source.image_si: image_input, minibatch_source.roi_si: roi_input, minibatch_source.dims_si: dims_input}\n    all_boxes = [[[] for _ in range(num_test_images)] for _ in range(cfg['DATA'].NUM_CLASSES)]\n    print('Evaluating Faster R-CNN model for %s images.' % num_test_images)\n    all_gt_infos = {key: [] for key in classes}\n    for img_i in range(0, num_test_images):\n        mb_data = minibatch_source.next_minibatch(1, input_map=input_map)\n        gt_row = mb_data[roi_input].asarray()\n        gt_row = gt_row.reshape((cfg.INPUT_ROIS_PER_IMAGE, 5))\n        all_gt_boxes = gt_row[np.where(gt_row[:, -1] > 0)]\n        for (cls_index, cls_name) in enumerate(classes):\n            if cls_index == 0:\n                continue\n            cls_gt_boxes = all_gt_boxes[np.where(all_gt_boxes[:, -1] == cls_index)]\n            all_gt_infos[cls_name].append({'bbox': np.array(cls_gt_boxes), 'difficult': [False] * len(cls_gt_boxes), 'det': [False] * len(cls_gt_boxes)})\n        output = frcn_eval.eval({image_input: mb_data[image_input], dims_input: mb_data[dims_input]})\n        out_dict = dict([(k.name, k) for k in output])\n        out_cls_pred = output[out_dict['cls_pred']][0]\n        out_rpn_rois = output[out_dict['rpn_rois']][0]\n        out_bbox_regr = output[out_dict['bbox_regr']][0]\n        labels = out_cls_pred.argmax(axis=1)\n        scores = out_cls_pred.max(axis=1)\n        regressed_rois = regress_rois(out_rpn_rois, out_bbox_regr, labels, mb_data[dims_input].asarray())\n        labels.shape = labels.shape + (1,)\n        scores.shape = scores.shape + (1,)\n        coords_score_label = np.hstack((regressed_rois, scores, labels))\n        for cls_j in range(1, cfg['DATA'].NUM_CLASSES):\n            coords_score_label_for_cls = coords_score_label[np.where(coords_score_label[:, -1] == cls_j)]\n            all_boxes[cls_j][img_i] = coords_score_label_for_cls[:, :-1].astype(np.float32, copy=False)\n        if (img_i + 1) % 100 == 0:\n            print('Processed {} samples'.format(img_i + 1))\n    aps = evaluate_detections(all_boxes, all_gt_infos, classes, use_gpu_nms=cfg.USE_GPU_NMS, device_id=cfg.GPU_ID, nms_threshold=cfg.RESULTS_NMS_THRESHOLD, conf_threshold=cfg.RESULTS_NMS_CONF_THRESHOLD)\n    return aps"
        ]
    }
]