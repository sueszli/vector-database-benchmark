[
    {
        "func_name": "retrieve",
        "original": "@classmethod\ndef retrieve(cls, dataset: Dataset, query: str, account: Account, limit: int=10) -> dict:\n    if dataset.available_document_count == 0 or dataset.available_segment_count == 0:\n        return {'query': {'content': query, 'tsne_position': {'x': 0, 'y': 0}}, 'records': []}\n    embedding_model = ModelFactory.get_embedding_model(tenant_id=dataset.tenant_id, model_provider_name=dataset.embedding_model_provider, model_name=dataset.embedding_model)\n    embeddings = CacheEmbedding(embedding_model)\n    vector_index = VectorIndex(dataset=dataset, config=current_app.config, embeddings=embeddings)\n    start = time.perf_counter()\n    documents = vector_index.search(query, search_type='similarity_score_threshold', search_kwargs={'k': 10, 'filter': {'group_id': [dataset.id]}})\n    end = time.perf_counter()\n    logging.debug(f'Hit testing retrieve in {end - start:0.4f} seconds')\n    dataset_query = DatasetQuery(dataset_id=dataset.id, content=query, source='hit_testing', created_by_role='account', created_by=account.id)\n    db.session.add(dataset_query)\n    db.session.commit()\n    return cls.compact_retrieve_response(dataset, embeddings, query, documents)",
        "mutated": [
            "@classmethod\ndef retrieve(cls, dataset: Dataset, query: str, account: Account, limit: int=10) -> dict:\n    if False:\n        i = 10\n    if dataset.available_document_count == 0 or dataset.available_segment_count == 0:\n        return {'query': {'content': query, 'tsne_position': {'x': 0, 'y': 0}}, 'records': []}\n    embedding_model = ModelFactory.get_embedding_model(tenant_id=dataset.tenant_id, model_provider_name=dataset.embedding_model_provider, model_name=dataset.embedding_model)\n    embeddings = CacheEmbedding(embedding_model)\n    vector_index = VectorIndex(dataset=dataset, config=current_app.config, embeddings=embeddings)\n    start = time.perf_counter()\n    documents = vector_index.search(query, search_type='similarity_score_threshold', search_kwargs={'k': 10, 'filter': {'group_id': [dataset.id]}})\n    end = time.perf_counter()\n    logging.debug(f'Hit testing retrieve in {end - start:0.4f} seconds')\n    dataset_query = DatasetQuery(dataset_id=dataset.id, content=query, source='hit_testing', created_by_role='account', created_by=account.id)\n    db.session.add(dataset_query)\n    db.session.commit()\n    return cls.compact_retrieve_response(dataset, embeddings, query, documents)",
            "@classmethod\ndef retrieve(cls, dataset: Dataset, query: str, account: Account, limit: int=10) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if dataset.available_document_count == 0 or dataset.available_segment_count == 0:\n        return {'query': {'content': query, 'tsne_position': {'x': 0, 'y': 0}}, 'records': []}\n    embedding_model = ModelFactory.get_embedding_model(tenant_id=dataset.tenant_id, model_provider_name=dataset.embedding_model_provider, model_name=dataset.embedding_model)\n    embeddings = CacheEmbedding(embedding_model)\n    vector_index = VectorIndex(dataset=dataset, config=current_app.config, embeddings=embeddings)\n    start = time.perf_counter()\n    documents = vector_index.search(query, search_type='similarity_score_threshold', search_kwargs={'k': 10, 'filter': {'group_id': [dataset.id]}})\n    end = time.perf_counter()\n    logging.debug(f'Hit testing retrieve in {end - start:0.4f} seconds')\n    dataset_query = DatasetQuery(dataset_id=dataset.id, content=query, source='hit_testing', created_by_role='account', created_by=account.id)\n    db.session.add(dataset_query)\n    db.session.commit()\n    return cls.compact_retrieve_response(dataset, embeddings, query, documents)",
            "@classmethod\ndef retrieve(cls, dataset: Dataset, query: str, account: Account, limit: int=10) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if dataset.available_document_count == 0 or dataset.available_segment_count == 0:\n        return {'query': {'content': query, 'tsne_position': {'x': 0, 'y': 0}}, 'records': []}\n    embedding_model = ModelFactory.get_embedding_model(tenant_id=dataset.tenant_id, model_provider_name=dataset.embedding_model_provider, model_name=dataset.embedding_model)\n    embeddings = CacheEmbedding(embedding_model)\n    vector_index = VectorIndex(dataset=dataset, config=current_app.config, embeddings=embeddings)\n    start = time.perf_counter()\n    documents = vector_index.search(query, search_type='similarity_score_threshold', search_kwargs={'k': 10, 'filter': {'group_id': [dataset.id]}})\n    end = time.perf_counter()\n    logging.debug(f'Hit testing retrieve in {end - start:0.4f} seconds')\n    dataset_query = DatasetQuery(dataset_id=dataset.id, content=query, source='hit_testing', created_by_role='account', created_by=account.id)\n    db.session.add(dataset_query)\n    db.session.commit()\n    return cls.compact_retrieve_response(dataset, embeddings, query, documents)",
            "@classmethod\ndef retrieve(cls, dataset: Dataset, query: str, account: Account, limit: int=10) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if dataset.available_document_count == 0 or dataset.available_segment_count == 0:\n        return {'query': {'content': query, 'tsne_position': {'x': 0, 'y': 0}}, 'records': []}\n    embedding_model = ModelFactory.get_embedding_model(tenant_id=dataset.tenant_id, model_provider_name=dataset.embedding_model_provider, model_name=dataset.embedding_model)\n    embeddings = CacheEmbedding(embedding_model)\n    vector_index = VectorIndex(dataset=dataset, config=current_app.config, embeddings=embeddings)\n    start = time.perf_counter()\n    documents = vector_index.search(query, search_type='similarity_score_threshold', search_kwargs={'k': 10, 'filter': {'group_id': [dataset.id]}})\n    end = time.perf_counter()\n    logging.debug(f'Hit testing retrieve in {end - start:0.4f} seconds')\n    dataset_query = DatasetQuery(dataset_id=dataset.id, content=query, source='hit_testing', created_by_role='account', created_by=account.id)\n    db.session.add(dataset_query)\n    db.session.commit()\n    return cls.compact_retrieve_response(dataset, embeddings, query, documents)",
            "@classmethod\ndef retrieve(cls, dataset: Dataset, query: str, account: Account, limit: int=10) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if dataset.available_document_count == 0 or dataset.available_segment_count == 0:\n        return {'query': {'content': query, 'tsne_position': {'x': 0, 'y': 0}}, 'records': []}\n    embedding_model = ModelFactory.get_embedding_model(tenant_id=dataset.tenant_id, model_provider_name=dataset.embedding_model_provider, model_name=dataset.embedding_model)\n    embeddings = CacheEmbedding(embedding_model)\n    vector_index = VectorIndex(dataset=dataset, config=current_app.config, embeddings=embeddings)\n    start = time.perf_counter()\n    documents = vector_index.search(query, search_type='similarity_score_threshold', search_kwargs={'k': 10, 'filter': {'group_id': [dataset.id]}})\n    end = time.perf_counter()\n    logging.debug(f'Hit testing retrieve in {end - start:0.4f} seconds')\n    dataset_query = DatasetQuery(dataset_id=dataset.id, content=query, source='hit_testing', created_by_role='account', created_by=account.id)\n    db.session.add(dataset_query)\n    db.session.commit()\n    return cls.compact_retrieve_response(dataset, embeddings, query, documents)"
        ]
    },
    {
        "func_name": "compact_retrieve_response",
        "original": "@classmethod\ndef compact_retrieve_response(cls, dataset: Dataset, embeddings: Embeddings, query: str, documents: List[Document]):\n    text_embeddings = [embeddings.embed_query(query)]\n    text_embeddings.extend(embeddings.embed_documents([document.page_content for document in documents]))\n    tsne_position_data = cls.get_tsne_positions_from_embeddings(text_embeddings)\n    query_position = tsne_position_data.pop(0)\n    i = 0\n    records = []\n    for document in documents:\n        index_node_id = document.metadata['doc_id']\n        segment = db.session.query(DocumentSegment).filter(DocumentSegment.dataset_id == dataset.id, DocumentSegment.enabled == True, DocumentSegment.status == 'completed', DocumentSegment.index_node_id == index_node_id).first()\n        if not segment:\n            i += 1\n            continue\n        record = {'segment': segment, 'score': document.metadata['score'], 'tsne_position': tsne_position_data[i]}\n        records.append(record)\n        i += 1\n    return {'query': {'content': query, 'tsne_position': query_position}, 'records': records}",
        "mutated": [
            "@classmethod\ndef compact_retrieve_response(cls, dataset: Dataset, embeddings: Embeddings, query: str, documents: List[Document]):\n    if False:\n        i = 10\n    text_embeddings = [embeddings.embed_query(query)]\n    text_embeddings.extend(embeddings.embed_documents([document.page_content for document in documents]))\n    tsne_position_data = cls.get_tsne_positions_from_embeddings(text_embeddings)\n    query_position = tsne_position_data.pop(0)\n    i = 0\n    records = []\n    for document in documents:\n        index_node_id = document.metadata['doc_id']\n        segment = db.session.query(DocumentSegment).filter(DocumentSegment.dataset_id == dataset.id, DocumentSegment.enabled == True, DocumentSegment.status == 'completed', DocumentSegment.index_node_id == index_node_id).first()\n        if not segment:\n            i += 1\n            continue\n        record = {'segment': segment, 'score': document.metadata['score'], 'tsne_position': tsne_position_data[i]}\n        records.append(record)\n        i += 1\n    return {'query': {'content': query, 'tsne_position': query_position}, 'records': records}",
            "@classmethod\ndef compact_retrieve_response(cls, dataset: Dataset, embeddings: Embeddings, query: str, documents: List[Document]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    text_embeddings = [embeddings.embed_query(query)]\n    text_embeddings.extend(embeddings.embed_documents([document.page_content for document in documents]))\n    tsne_position_data = cls.get_tsne_positions_from_embeddings(text_embeddings)\n    query_position = tsne_position_data.pop(0)\n    i = 0\n    records = []\n    for document in documents:\n        index_node_id = document.metadata['doc_id']\n        segment = db.session.query(DocumentSegment).filter(DocumentSegment.dataset_id == dataset.id, DocumentSegment.enabled == True, DocumentSegment.status == 'completed', DocumentSegment.index_node_id == index_node_id).first()\n        if not segment:\n            i += 1\n            continue\n        record = {'segment': segment, 'score': document.metadata['score'], 'tsne_position': tsne_position_data[i]}\n        records.append(record)\n        i += 1\n    return {'query': {'content': query, 'tsne_position': query_position}, 'records': records}",
            "@classmethod\ndef compact_retrieve_response(cls, dataset: Dataset, embeddings: Embeddings, query: str, documents: List[Document]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    text_embeddings = [embeddings.embed_query(query)]\n    text_embeddings.extend(embeddings.embed_documents([document.page_content for document in documents]))\n    tsne_position_data = cls.get_tsne_positions_from_embeddings(text_embeddings)\n    query_position = tsne_position_data.pop(0)\n    i = 0\n    records = []\n    for document in documents:\n        index_node_id = document.metadata['doc_id']\n        segment = db.session.query(DocumentSegment).filter(DocumentSegment.dataset_id == dataset.id, DocumentSegment.enabled == True, DocumentSegment.status == 'completed', DocumentSegment.index_node_id == index_node_id).first()\n        if not segment:\n            i += 1\n            continue\n        record = {'segment': segment, 'score': document.metadata['score'], 'tsne_position': tsne_position_data[i]}\n        records.append(record)\n        i += 1\n    return {'query': {'content': query, 'tsne_position': query_position}, 'records': records}",
            "@classmethod\ndef compact_retrieve_response(cls, dataset: Dataset, embeddings: Embeddings, query: str, documents: List[Document]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    text_embeddings = [embeddings.embed_query(query)]\n    text_embeddings.extend(embeddings.embed_documents([document.page_content for document in documents]))\n    tsne_position_data = cls.get_tsne_positions_from_embeddings(text_embeddings)\n    query_position = tsne_position_data.pop(0)\n    i = 0\n    records = []\n    for document in documents:\n        index_node_id = document.metadata['doc_id']\n        segment = db.session.query(DocumentSegment).filter(DocumentSegment.dataset_id == dataset.id, DocumentSegment.enabled == True, DocumentSegment.status == 'completed', DocumentSegment.index_node_id == index_node_id).first()\n        if not segment:\n            i += 1\n            continue\n        record = {'segment': segment, 'score': document.metadata['score'], 'tsne_position': tsne_position_data[i]}\n        records.append(record)\n        i += 1\n    return {'query': {'content': query, 'tsne_position': query_position}, 'records': records}",
            "@classmethod\ndef compact_retrieve_response(cls, dataset: Dataset, embeddings: Embeddings, query: str, documents: List[Document]):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    text_embeddings = [embeddings.embed_query(query)]\n    text_embeddings.extend(embeddings.embed_documents([document.page_content for document in documents]))\n    tsne_position_data = cls.get_tsne_positions_from_embeddings(text_embeddings)\n    query_position = tsne_position_data.pop(0)\n    i = 0\n    records = []\n    for document in documents:\n        index_node_id = document.metadata['doc_id']\n        segment = db.session.query(DocumentSegment).filter(DocumentSegment.dataset_id == dataset.id, DocumentSegment.enabled == True, DocumentSegment.status == 'completed', DocumentSegment.index_node_id == index_node_id).first()\n        if not segment:\n            i += 1\n            continue\n        record = {'segment': segment, 'score': document.metadata['score'], 'tsne_position': tsne_position_data[i]}\n        records.append(record)\n        i += 1\n    return {'query': {'content': query, 'tsne_position': query_position}, 'records': records}"
        ]
    },
    {
        "func_name": "get_tsne_positions_from_embeddings",
        "original": "@classmethod\ndef get_tsne_positions_from_embeddings(cls, embeddings: list):\n    embedding_length = len(embeddings)\n    if embedding_length <= 1:\n        return [{'x': 0, 'y': 0}]\n    concatenate_data = np.array(embeddings).reshape(embedding_length, -1)\n    perplexity = embedding_length / 2 + 1\n    if perplexity >= embedding_length:\n        perplexity = max(embedding_length - 1, 1)\n    tsne = TSNE(n_components=2, perplexity=perplexity, early_exaggeration=12.0)\n    data_tsne = tsne.fit_transform(concatenate_data)\n    tsne_position_data = []\n    for i in range(len(data_tsne)):\n        tsne_position_data.append({'x': float(data_tsne[i][0]), 'y': float(data_tsne[i][1])})\n    return tsne_position_data",
        "mutated": [
            "@classmethod\ndef get_tsne_positions_from_embeddings(cls, embeddings: list):\n    if False:\n        i = 10\n    embedding_length = len(embeddings)\n    if embedding_length <= 1:\n        return [{'x': 0, 'y': 0}]\n    concatenate_data = np.array(embeddings).reshape(embedding_length, -1)\n    perplexity = embedding_length / 2 + 1\n    if perplexity >= embedding_length:\n        perplexity = max(embedding_length - 1, 1)\n    tsne = TSNE(n_components=2, perplexity=perplexity, early_exaggeration=12.0)\n    data_tsne = tsne.fit_transform(concatenate_data)\n    tsne_position_data = []\n    for i in range(len(data_tsne)):\n        tsne_position_data.append({'x': float(data_tsne[i][0]), 'y': float(data_tsne[i][1])})\n    return tsne_position_data",
            "@classmethod\ndef get_tsne_positions_from_embeddings(cls, embeddings: list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    embedding_length = len(embeddings)\n    if embedding_length <= 1:\n        return [{'x': 0, 'y': 0}]\n    concatenate_data = np.array(embeddings).reshape(embedding_length, -1)\n    perplexity = embedding_length / 2 + 1\n    if perplexity >= embedding_length:\n        perplexity = max(embedding_length - 1, 1)\n    tsne = TSNE(n_components=2, perplexity=perplexity, early_exaggeration=12.0)\n    data_tsne = tsne.fit_transform(concatenate_data)\n    tsne_position_data = []\n    for i in range(len(data_tsne)):\n        tsne_position_data.append({'x': float(data_tsne[i][0]), 'y': float(data_tsne[i][1])})\n    return tsne_position_data",
            "@classmethod\ndef get_tsne_positions_from_embeddings(cls, embeddings: list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    embedding_length = len(embeddings)\n    if embedding_length <= 1:\n        return [{'x': 0, 'y': 0}]\n    concatenate_data = np.array(embeddings).reshape(embedding_length, -1)\n    perplexity = embedding_length / 2 + 1\n    if perplexity >= embedding_length:\n        perplexity = max(embedding_length - 1, 1)\n    tsne = TSNE(n_components=2, perplexity=perplexity, early_exaggeration=12.0)\n    data_tsne = tsne.fit_transform(concatenate_data)\n    tsne_position_data = []\n    for i in range(len(data_tsne)):\n        tsne_position_data.append({'x': float(data_tsne[i][0]), 'y': float(data_tsne[i][1])})\n    return tsne_position_data",
            "@classmethod\ndef get_tsne_positions_from_embeddings(cls, embeddings: list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    embedding_length = len(embeddings)\n    if embedding_length <= 1:\n        return [{'x': 0, 'y': 0}]\n    concatenate_data = np.array(embeddings).reshape(embedding_length, -1)\n    perplexity = embedding_length / 2 + 1\n    if perplexity >= embedding_length:\n        perplexity = max(embedding_length - 1, 1)\n    tsne = TSNE(n_components=2, perplexity=perplexity, early_exaggeration=12.0)\n    data_tsne = tsne.fit_transform(concatenate_data)\n    tsne_position_data = []\n    for i in range(len(data_tsne)):\n        tsne_position_data.append({'x': float(data_tsne[i][0]), 'y': float(data_tsne[i][1])})\n    return tsne_position_data",
            "@classmethod\ndef get_tsne_positions_from_embeddings(cls, embeddings: list):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    embedding_length = len(embeddings)\n    if embedding_length <= 1:\n        return [{'x': 0, 'y': 0}]\n    concatenate_data = np.array(embeddings).reshape(embedding_length, -1)\n    perplexity = embedding_length / 2 + 1\n    if perplexity >= embedding_length:\n        perplexity = max(embedding_length - 1, 1)\n    tsne = TSNE(n_components=2, perplexity=perplexity, early_exaggeration=12.0)\n    data_tsne = tsne.fit_transform(concatenate_data)\n    tsne_position_data = []\n    for i in range(len(data_tsne)):\n        tsne_position_data.append({'x': float(data_tsne[i][0]), 'y': float(data_tsne[i][1])})\n    return tsne_position_data"
        ]
    }
]