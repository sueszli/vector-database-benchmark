[
    {
        "func_name": "__init__",
        "original": "def __init__(self, model: RegressionModel, background_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_num_samples: Optional[int]=None, shap_method: Optional[str]=None, **kwargs):\n    \"\"\"ShapExplainer\n\n        **Definitions**\n\n        - A background series is a `TimeSeries` used to train the shap explainer.\n        - A foreground series is a `TimeSeries` that can be explained by a shap explainer after it has been fitted.\n\n        Currently, `ShapExplainer` only works with `RegressionModel` forecasting models.\n        The number of explained horizons (t+1, t+2, ...) can be at most equal to `output_chunk_length` of `model`.\n\n        Parameters\n        ----------\n        model\n            A `RegressionModel` to be explained. It must be fitted first.\n        background_series\n            One or several series to *train* the `ShapExplainer` along with any foreground series.\n            Consider using a reduced well-chosen background to reduce computation time.\n            Optional if `model` was fit on a single target series. By default, it is the `series` used at fitting time.\n            Mandatory if `model` was fit on multiple (list of) target series.\n        background_past_covariates\n            A past covariates series or list of series that the model needs once fitted.\n        background_future_covariates\n            A future covariates series or list of series that the model needs once fitted.\n        background_num_samples\n            Optionally, whether to sample a subset of the original background. Randomly picks\n            `background_num_samples` training samples of the constructed training dataset\n            (using ``shap.utils.sample()``).\n            Generally used for faster computation, especially when `shap_method` is\n            ``\"kernel\"`` or ``\"permutation\"``.\n        shap_method\n            Optionally, the shap method to apply. By default, an attempt is made\n            to select the most appropriate method based on a pre-defined set of known models.\n            internal mapping. Supported values : ``\"permutation\", \"partition\", \"tree\", \"kernel\", \"sampling\", \"linear\",\n            \"deep\", \"gradient\", \"additive\"``.\n        **kwargs\n            Optionally, additional keyword arguments passed to `shap_method`.\n        Examples\n        --------\n        >>> from darts.datasets import AirPassengersDataset\n        >>> from darts.explainability.shap_explainer import ShapExplainer\n        >>> from darts.models import LinearRegressionModel\n        >>> series = AirPassengersDataset().load()\n        >>> model = LinearRegressionModel(lags=12)\n        >>> model.fit(series[:-36])\n        >>> shap_explain = ShapExplainer(model)\n        >>> results = shap_explain.explain()\n        >>> shap_explain.summary_plot()\n        >>> shap_explain.force_plot_from_ts()\n        \"\"\"\n    if not issubclass(type(model), RegressionModel):\n        raise_log(ValueError('Invalid `model` type. Currently, only models of type `RegressionModel` are supported.'), logger)\n    if not model.multi_models:\n        raise_log(ValueError('Invalid `multi_models` value `False`. Currently, ShapExplainer only supports RegressionModels with `multi_models=True`.'), logger)\n    super().__init__(model=model, background_series=background_series, background_past_covariates=background_past_covariates, background_future_covariates=background_future_covariates, requires_background=True, requires_covariates_encoding=True, check_component_names=True, test_stationarity=True)\n    if model._is_probabilistic:\n        logger.warning('The model is probabilistic, but num_samples=1 will be used for explainability.')\n    if shap_method is not None:\n        shap_method = shap_method.upper()\n        if shap_method in _ShapMethod.__members__:\n            self.shap_method = _ShapMethod[shap_method]\n        else:\n            raise_log(ValueError(\"Invalid `shap_method`. Please choose one value among the following: ['partition', 'tree', 'kernel', 'sampling', 'linear', 'deep', 'gradient', 'additive'].\"))\n    else:\n        self.shap_method = None\n    self.explainers = _RegressionShapExplainers(model=self.model, n=self.n, target_components=self.target_components, past_covariates_components=self.past_covariates_components, future_covariates_components=self.future_covariates_components, background_series=self.background_series, background_past_covariates=self.background_past_covariates, background_future_covariates=self.background_future_covariates, shap_method=self.shap_method, background_num_samples=background_num_samples, **kwargs)",
        "mutated": [
            "def __init__(self, model: RegressionModel, background_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_num_samples: Optional[int]=None, shap_method: Optional[str]=None, **kwargs):\n    if False:\n        i = 10\n    'ShapExplainer\\n\\n        **Definitions**\\n\\n        - A background series is a `TimeSeries` used to train the shap explainer.\\n        - A foreground series is a `TimeSeries` that can be explained by a shap explainer after it has been fitted.\\n\\n        Currently, `ShapExplainer` only works with `RegressionModel` forecasting models.\\n        The number of explained horizons (t+1, t+2, ...) can be at most equal to `output_chunk_length` of `model`.\\n\\n        Parameters\\n        ----------\\n        model\\n            A `RegressionModel` to be explained. It must be fitted first.\\n        background_series\\n            One or several series to *train* the `ShapExplainer` along with any foreground series.\\n            Consider using a reduced well-chosen background to reduce computation time.\\n            Optional if `model` was fit on a single target series. By default, it is the `series` used at fitting time.\\n            Mandatory if `model` was fit on multiple (list of) target series.\\n        background_past_covariates\\n            A past covariates series or list of series that the model needs once fitted.\\n        background_future_covariates\\n            A future covariates series or list of series that the model needs once fitted.\\n        background_num_samples\\n            Optionally, whether to sample a subset of the original background. Randomly picks\\n            `background_num_samples` training samples of the constructed training dataset\\n            (using ``shap.utils.sample()``).\\n            Generally used for faster computation, especially when `shap_method` is\\n            ``\"kernel\"`` or ``\"permutation\"``.\\n        shap_method\\n            Optionally, the shap method to apply. By default, an attempt is made\\n            to select the most appropriate method based on a pre-defined set of known models.\\n            internal mapping. Supported values : ``\"permutation\", \"partition\", \"tree\", \"kernel\", \"sampling\", \"linear\",\\n            \"deep\", \"gradient\", \"additive\"``.\\n        **kwargs\\n            Optionally, additional keyword arguments passed to `shap_method`.\\n        Examples\\n        --------\\n        >>> from darts.datasets import AirPassengersDataset\\n        >>> from darts.explainability.shap_explainer import ShapExplainer\\n        >>> from darts.models import LinearRegressionModel\\n        >>> series = AirPassengersDataset().load()\\n        >>> model = LinearRegressionModel(lags=12)\\n        >>> model.fit(series[:-36])\\n        >>> shap_explain = ShapExplainer(model)\\n        >>> results = shap_explain.explain()\\n        >>> shap_explain.summary_plot()\\n        >>> shap_explain.force_plot_from_ts()\\n        '\n    if not issubclass(type(model), RegressionModel):\n        raise_log(ValueError('Invalid `model` type. Currently, only models of type `RegressionModel` are supported.'), logger)\n    if not model.multi_models:\n        raise_log(ValueError('Invalid `multi_models` value `False`. Currently, ShapExplainer only supports RegressionModels with `multi_models=True`.'), logger)\n    super().__init__(model=model, background_series=background_series, background_past_covariates=background_past_covariates, background_future_covariates=background_future_covariates, requires_background=True, requires_covariates_encoding=True, check_component_names=True, test_stationarity=True)\n    if model._is_probabilistic:\n        logger.warning('The model is probabilistic, but num_samples=1 will be used for explainability.')\n    if shap_method is not None:\n        shap_method = shap_method.upper()\n        if shap_method in _ShapMethod.__members__:\n            self.shap_method = _ShapMethod[shap_method]\n        else:\n            raise_log(ValueError(\"Invalid `shap_method`. Please choose one value among the following: ['partition', 'tree', 'kernel', 'sampling', 'linear', 'deep', 'gradient', 'additive'].\"))\n    else:\n        self.shap_method = None\n    self.explainers = _RegressionShapExplainers(model=self.model, n=self.n, target_components=self.target_components, past_covariates_components=self.past_covariates_components, future_covariates_components=self.future_covariates_components, background_series=self.background_series, background_past_covariates=self.background_past_covariates, background_future_covariates=self.background_future_covariates, shap_method=self.shap_method, background_num_samples=background_num_samples, **kwargs)",
            "def __init__(self, model: RegressionModel, background_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_num_samples: Optional[int]=None, shap_method: Optional[str]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'ShapExplainer\\n\\n        **Definitions**\\n\\n        - A background series is a `TimeSeries` used to train the shap explainer.\\n        - A foreground series is a `TimeSeries` that can be explained by a shap explainer after it has been fitted.\\n\\n        Currently, `ShapExplainer` only works with `RegressionModel` forecasting models.\\n        The number of explained horizons (t+1, t+2, ...) can be at most equal to `output_chunk_length` of `model`.\\n\\n        Parameters\\n        ----------\\n        model\\n            A `RegressionModel` to be explained. It must be fitted first.\\n        background_series\\n            One or several series to *train* the `ShapExplainer` along with any foreground series.\\n            Consider using a reduced well-chosen background to reduce computation time.\\n            Optional if `model` was fit on a single target series. By default, it is the `series` used at fitting time.\\n            Mandatory if `model` was fit on multiple (list of) target series.\\n        background_past_covariates\\n            A past covariates series or list of series that the model needs once fitted.\\n        background_future_covariates\\n            A future covariates series or list of series that the model needs once fitted.\\n        background_num_samples\\n            Optionally, whether to sample a subset of the original background. Randomly picks\\n            `background_num_samples` training samples of the constructed training dataset\\n            (using ``shap.utils.sample()``).\\n            Generally used for faster computation, especially when `shap_method` is\\n            ``\"kernel\"`` or ``\"permutation\"``.\\n        shap_method\\n            Optionally, the shap method to apply. By default, an attempt is made\\n            to select the most appropriate method based on a pre-defined set of known models.\\n            internal mapping. Supported values : ``\"permutation\", \"partition\", \"tree\", \"kernel\", \"sampling\", \"linear\",\\n            \"deep\", \"gradient\", \"additive\"``.\\n        **kwargs\\n            Optionally, additional keyword arguments passed to `shap_method`.\\n        Examples\\n        --------\\n        >>> from darts.datasets import AirPassengersDataset\\n        >>> from darts.explainability.shap_explainer import ShapExplainer\\n        >>> from darts.models import LinearRegressionModel\\n        >>> series = AirPassengersDataset().load()\\n        >>> model = LinearRegressionModel(lags=12)\\n        >>> model.fit(series[:-36])\\n        >>> shap_explain = ShapExplainer(model)\\n        >>> results = shap_explain.explain()\\n        >>> shap_explain.summary_plot()\\n        >>> shap_explain.force_plot_from_ts()\\n        '\n    if not issubclass(type(model), RegressionModel):\n        raise_log(ValueError('Invalid `model` type. Currently, only models of type `RegressionModel` are supported.'), logger)\n    if not model.multi_models:\n        raise_log(ValueError('Invalid `multi_models` value `False`. Currently, ShapExplainer only supports RegressionModels with `multi_models=True`.'), logger)\n    super().__init__(model=model, background_series=background_series, background_past_covariates=background_past_covariates, background_future_covariates=background_future_covariates, requires_background=True, requires_covariates_encoding=True, check_component_names=True, test_stationarity=True)\n    if model._is_probabilistic:\n        logger.warning('The model is probabilistic, but num_samples=1 will be used for explainability.')\n    if shap_method is not None:\n        shap_method = shap_method.upper()\n        if shap_method in _ShapMethod.__members__:\n            self.shap_method = _ShapMethod[shap_method]\n        else:\n            raise_log(ValueError(\"Invalid `shap_method`. Please choose one value among the following: ['partition', 'tree', 'kernel', 'sampling', 'linear', 'deep', 'gradient', 'additive'].\"))\n    else:\n        self.shap_method = None\n    self.explainers = _RegressionShapExplainers(model=self.model, n=self.n, target_components=self.target_components, past_covariates_components=self.past_covariates_components, future_covariates_components=self.future_covariates_components, background_series=self.background_series, background_past_covariates=self.background_past_covariates, background_future_covariates=self.background_future_covariates, shap_method=self.shap_method, background_num_samples=background_num_samples, **kwargs)",
            "def __init__(self, model: RegressionModel, background_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_num_samples: Optional[int]=None, shap_method: Optional[str]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'ShapExplainer\\n\\n        **Definitions**\\n\\n        - A background series is a `TimeSeries` used to train the shap explainer.\\n        - A foreground series is a `TimeSeries` that can be explained by a shap explainer after it has been fitted.\\n\\n        Currently, `ShapExplainer` only works with `RegressionModel` forecasting models.\\n        The number of explained horizons (t+1, t+2, ...) can be at most equal to `output_chunk_length` of `model`.\\n\\n        Parameters\\n        ----------\\n        model\\n            A `RegressionModel` to be explained. It must be fitted first.\\n        background_series\\n            One or several series to *train* the `ShapExplainer` along with any foreground series.\\n            Consider using a reduced well-chosen background to reduce computation time.\\n            Optional if `model` was fit on a single target series. By default, it is the `series` used at fitting time.\\n            Mandatory if `model` was fit on multiple (list of) target series.\\n        background_past_covariates\\n            A past covariates series or list of series that the model needs once fitted.\\n        background_future_covariates\\n            A future covariates series or list of series that the model needs once fitted.\\n        background_num_samples\\n            Optionally, whether to sample a subset of the original background. Randomly picks\\n            `background_num_samples` training samples of the constructed training dataset\\n            (using ``shap.utils.sample()``).\\n            Generally used for faster computation, especially when `shap_method` is\\n            ``\"kernel\"`` or ``\"permutation\"``.\\n        shap_method\\n            Optionally, the shap method to apply. By default, an attempt is made\\n            to select the most appropriate method based on a pre-defined set of known models.\\n            internal mapping. Supported values : ``\"permutation\", \"partition\", \"tree\", \"kernel\", \"sampling\", \"linear\",\\n            \"deep\", \"gradient\", \"additive\"``.\\n        **kwargs\\n            Optionally, additional keyword arguments passed to `shap_method`.\\n        Examples\\n        --------\\n        >>> from darts.datasets import AirPassengersDataset\\n        >>> from darts.explainability.shap_explainer import ShapExplainer\\n        >>> from darts.models import LinearRegressionModel\\n        >>> series = AirPassengersDataset().load()\\n        >>> model = LinearRegressionModel(lags=12)\\n        >>> model.fit(series[:-36])\\n        >>> shap_explain = ShapExplainer(model)\\n        >>> results = shap_explain.explain()\\n        >>> shap_explain.summary_plot()\\n        >>> shap_explain.force_plot_from_ts()\\n        '\n    if not issubclass(type(model), RegressionModel):\n        raise_log(ValueError('Invalid `model` type. Currently, only models of type `RegressionModel` are supported.'), logger)\n    if not model.multi_models:\n        raise_log(ValueError('Invalid `multi_models` value `False`. Currently, ShapExplainer only supports RegressionModels with `multi_models=True`.'), logger)\n    super().__init__(model=model, background_series=background_series, background_past_covariates=background_past_covariates, background_future_covariates=background_future_covariates, requires_background=True, requires_covariates_encoding=True, check_component_names=True, test_stationarity=True)\n    if model._is_probabilistic:\n        logger.warning('The model is probabilistic, but num_samples=1 will be used for explainability.')\n    if shap_method is not None:\n        shap_method = shap_method.upper()\n        if shap_method in _ShapMethod.__members__:\n            self.shap_method = _ShapMethod[shap_method]\n        else:\n            raise_log(ValueError(\"Invalid `shap_method`. Please choose one value among the following: ['partition', 'tree', 'kernel', 'sampling', 'linear', 'deep', 'gradient', 'additive'].\"))\n    else:\n        self.shap_method = None\n    self.explainers = _RegressionShapExplainers(model=self.model, n=self.n, target_components=self.target_components, past_covariates_components=self.past_covariates_components, future_covariates_components=self.future_covariates_components, background_series=self.background_series, background_past_covariates=self.background_past_covariates, background_future_covariates=self.background_future_covariates, shap_method=self.shap_method, background_num_samples=background_num_samples, **kwargs)",
            "def __init__(self, model: RegressionModel, background_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_num_samples: Optional[int]=None, shap_method: Optional[str]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'ShapExplainer\\n\\n        **Definitions**\\n\\n        - A background series is a `TimeSeries` used to train the shap explainer.\\n        - A foreground series is a `TimeSeries` that can be explained by a shap explainer after it has been fitted.\\n\\n        Currently, `ShapExplainer` only works with `RegressionModel` forecasting models.\\n        The number of explained horizons (t+1, t+2, ...) can be at most equal to `output_chunk_length` of `model`.\\n\\n        Parameters\\n        ----------\\n        model\\n            A `RegressionModel` to be explained. It must be fitted first.\\n        background_series\\n            One or several series to *train* the `ShapExplainer` along with any foreground series.\\n            Consider using a reduced well-chosen background to reduce computation time.\\n            Optional if `model` was fit on a single target series. By default, it is the `series` used at fitting time.\\n            Mandatory if `model` was fit on multiple (list of) target series.\\n        background_past_covariates\\n            A past covariates series or list of series that the model needs once fitted.\\n        background_future_covariates\\n            A future covariates series or list of series that the model needs once fitted.\\n        background_num_samples\\n            Optionally, whether to sample a subset of the original background. Randomly picks\\n            `background_num_samples` training samples of the constructed training dataset\\n            (using ``shap.utils.sample()``).\\n            Generally used for faster computation, especially when `shap_method` is\\n            ``\"kernel\"`` or ``\"permutation\"``.\\n        shap_method\\n            Optionally, the shap method to apply. By default, an attempt is made\\n            to select the most appropriate method based on a pre-defined set of known models.\\n            internal mapping. Supported values : ``\"permutation\", \"partition\", \"tree\", \"kernel\", \"sampling\", \"linear\",\\n            \"deep\", \"gradient\", \"additive\"``.\\n        **kwargs\\n            Optionally, additional keyword arguments passed to `shap_method`.\\n        Examples\\n        --------\\n        >>> from darts.datasets import AirPassengersDataset\\n        >>> from darts.explainability.shap_explainer import ShapExplainer\\n        >>> from darts.models import LinearRegressionModel\\n        >>> series = AirPassengersDataset().load()\\n        >>> model = LinearRegressionModel(lags=12)\\n        >>> model.fit(series[:-36])\\n        >>> shap_explain = ShapExplainer(model)\\n        >>> results = shap_explain.explain()\\n        >>> shap_explain.summary_plot()\\n        >>> shap_explain.force_plot_from_ts()\\n        '\n    if not issubclass(type(model), RegressionModel):\n        raise_log(ValueError('Invalid `model` type. Currently, only models of type `RegressionModel` are supported.'), logger)\n    if not model.multi_models:\n        raise_log(ValueError('Invalid `multi_models` value `False`. Currently, ShapExplainer only supports RegressionModels with `multi_models=True`.'), logger)\n    super().__init__(model=model, background_series=background_series, background_past_covariates=background_past_covariates, background_future_covariates=background_future_covariates, requires_background=True, requires_covariates_encoding=True, check_component_names=True, test_stationarity=True)\n    if model._is_probabilistic:\n        logger.warning('The model is probabilistic, but num_samples=1 will be used for explainability.')\n    if shap_method is not None:\n        shap_method = shap_method.upper()\n        if shap_method in _ShapMethod.__members__:\n            self.shap_method = _ShapMethod[shap_method]\n        else:\n            raise_log(ValueError(\"Invalid `shap_method`. Please choose one value among the following: ['partition', 'tree', 'kernel', 'sampling', 'linear', 'deep', 'gradient', 'additive'].\"))\n    else:\n        self.shap_method = None\n    self.explainers = _RegressionShapExplainers(model=self.model, n=self.n, target_components=self.target_components, past_covariates_components=self.past_covariates_components, future_covariates_components=self.future_covariates_components, background_series=self.background_series, background_past_covariates=self.background_past_covariates, background_future_covariates=self.background_future_covariates, shap_method=self.shap_method, background_num_samples=background_num_samples, **kwargs)",
            "def __init__(self, model: RegressionModel, background_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, background_num_samples: Optional[int]=None, shap_method: Optional[str]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'ShapExplainer\\n\\n        **Definitions**\\n\\n        - A background series is a `TimeSeries` used to train the shap explainer.\\n        - A foreground series is a `TimeSeries` that can be explained by a shap explainer after it has been fitted.\\n\\n        Currently, `ShapExplainer` only works with `RegressionModel` forecasting models.\\n        The number of explained horizons (t+1, t+2, ...) can be at most equal to `output_chunk_length` of `model`.\\n\\n        Parameters\\n        ----------\\n        model\\n            A `RegressionModel` to be explained. It must be fitted first.\\n        background_series\\n            One or several series to *train* the `ShapExplainer` along with any foreground series.\\n            Consider using a reduced well-chosen background to reduce computation time.\\n            Optional if `model` was fit on a single target series. By default, it is the `series` used at fitting time.\\n            Mandatory if `model` was fit on multiple (list of) target series.\\n        background_past_covariates\\n            A past covariates series or list of series that the model needs once fitted.\\n        background_future_covariates\\n            A future covariates series or list of series that the model needs once fitted.\\n        background_num_samples\\n            Optionally, whether to sample a subset of the original background. Randomly picks\\n            `background_num_samples` training samples of the constructed training dataset\\n            (using ``shap.utils.sample()``).\\n            Generally used for faster computation, especially when `shap_method` is\\n            ``\"kernel\"`` or ``\"permutation\"``.\\n        shap_method\\n            Optionally, the shap method to apply. By default, an attempt is made\\n            to select the most appropriate method based on a pre-defined set of known models.\\n            internal mapping. Supported values : ``\"permutation\", \"partition\", \"tree\", \"kernel\", \"sampling\", \"linear\",\\n            \"deep\", \"gradient\", \"additive\"``.\\n        **kwargs\\n            Optionally, additional keyword arguments passed to `shap_method`.\\n        Examples\\n        --------\\n        >>> from darts.datasets import AirPassengersDataset\\n        >>> from darts.explainability.shap_explainer import ShapExplainer\\n        >>> from darts.models import LinearRegressionModel\\n        >>> series = AirPassengersDataset().load()\\n        >>> model = LinearRegressionModel(lags=12)\\n        >>> model.fit(series[:-36])\\n        >>> shap_explain = ShapExplainer(model)\\n        >>> results = shap_explain.explain()\\n        >>> shap_explain.summary_plot()\\n        >>> shap_explain.force_plot_from_ts()\\n        '\n    if not issubclass(type(model), RegressionModel):\n        raise_log(ValueError('Invalid `model` type. Currently, only models of type `RegressionModel` are supported.'), logger)\n    if not model.multi_models:\n        raise_log(ValueError('Invalid `multi_models` value `False`. Currently, ShapExplainer only supports RegressionModels with `multi_models=True`.'), logger)\n    super().__init__(model=model, background_series=background_series, background_past_covariates=background_past_covariates, background_future_covariates=background_future_covariates, requires_background=True, requires_covariates_encoding=True, check_component_names=True, test_stationarity=True)\n    if model._is_probabilistic:\n        logger.warning('The model is probabilistic, but num_samples=1 will be used for explainability.')\n    if shap_method is not None:\n        shap_method = shap_method.upper()\n        if shap_method in _ShapMethod.__members__:\n            self.shap_method = _ShapMethod[shap_method]\n        else:\n            raise_log(ValueError(\"Invalid `shap_method`. Please choose one value among the following: ['partition', 'tree', 'kernel', 'sampling', 'linear', 'deep', 'gradient', 'additive'].\"))\n    else:\n        self.shap_method = None\n    self.explainers = _RegressionShapExplainers(model=self.model, n=self.n, target_components=self.target_components, past_covariates_components=self.past_covariates_components, future_covariates_components=self.future_covariates_components, background_series=self.background_series, background_past_covariates=self.background_past_covariates, background_future_covariates=self.background_future_covariates, shap_method=self.shap_method, background_num_samples=background_num_samples, **kwargs)"
        ]
    },
    {
        "func_name": "explain",
        "original": "def explain(self, foreground_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, foreground_past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, foreground_future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, horizons: Optional[Sequence[int]]=None, target_components: Optional[Sequence[str]]=None) -> ShapExplainabilityResult:\n    \"\"\"\n        Explains a foreground time series and returns a :class:`ShapExplainabilityResult\n        <darts.explainability.explainability_result.ShapExplainabilityResult>`.\n        The results can be retrieved with method :func:`get_explanation()\n        <darts.explainability.explainability_result.ShapExplainabilityResult.get_explanation>`.\n        The result is a multivariate `TimeSeries` instance containing the 'explanation'\n        for the (horizon, target_component) forecast at any timestamp forecastable corresponding to\n        the foreground `TimeSeries` input.\n\n        The component name convention of this multivariate `TimeSeries` is:\n        ``\"{name}_{type_of_cov}_lag_{idx}\"``, where:\n\n        - ``{name}`` is the component name from the original foreground series (target, past, or future).\n        - ``{type_of_cov}`` is the covariates type. It can take 3 different values:\n          ``\"target\"``, ``\"past_cov\"`` or ``\"future_cov\"``.\n        - ``{idx}`` is the lag index.\n\n        Parameters\n        ----------\n        foreground_series\n            Optionally, one or a sequence of target `TimeSeries` to be explained. Can be multivariate.\n            If not provided, the background `TimeSeries` will be explained instead.\n        foreground_past_covariates\n            Optionally, one or a sequence of past covariates `TimeSeries` if required by the forecasting model.\n        foreground_future_covariates\n            Optionally, one or a sequence of future covariates `TimeSeries` if required by the forecasting model.\n        horizons\n            Optionally, an integer or sequence of integers representing the future time steps to be explained.\n            `1` corresponds to the first timestamp being forecasted.\n            All values must be `<=output_chunk_length` of the explained forecasting model.\n        target_components\n            Optionally, a string or sequence of strings with the target components to explain.\n\n        Returns\n        -------\n        ShapExplainabilityResult\n            The forecast explanations\n\n        Examples\n        --------\n        Say we have a model with 2 target components named ``\"T_0\"`` and ``\"T_1\"``,\n        3 past covariates with default component names ``\"0\"``, ``\"1\"``, and ``\"2\"``,\n        and one future covariate with default component name ``\"0\"``.\n        Also, ``horizons = [1, 2]``.\n        The model is a regression model, with ``lags = 3``, ``lags_past_covariates=[-1, -3]``,\n        ``lags_future_covariates = [0]``.\n\n        We provide `foreground_series`, `foreground_past_covariates`, `foreground_future_covariates` each of length 5.\n\n        >>> explain_results = explainer.explain(\n        >>>     foreground_series=foreground_series,\n        >>>     foreground_past_covariates=foreground_past_covariates,\n        >>>     foreground_future_covariates=foreground_future_covariates,\n        >>>     horizons=[1, 2],\n        >>>     target_names=[\"T_0\", \"T_1\"])\n        >>> output = explain_results.get_explanation(horizon=1, component=\"T_1\")\n        >>> feature_values = explain_results.get_feature_values(horizon=1, component=\"T_1\")\n        >>> shap_objects = explain_results.get_shap_explanation_objects(horizon=1, component=\"T_1\")\n\n        Then the method returns a multivariate TimeSeries containing the *explanations* of\n        the `ShapExplainer`, with the following component names:\n\n             - T_0_target_lag-1\n             - T_0_target_lag-2\n             - T_0_target_lag-3\n             - T_1_target_lag-1\n             - T_1_target_lag-2\n             - T_1_target_lag-3\n             - 0_past_cov_lag-1\n             - 0_past_cov_lag-3\n             - 1_past_cov_lag-1\n             - 1_past_cov_lag-3\n             - 2_past_cov_lag-1\n             - 2_past_cov_lag-3\n             - 0_fut_cov_lag_0\n\n        This series has length 3, as the model can explain 5-3+1 forecasts\n        (timestamp indexes 4, 5, and 6)\n        \"\"\"\n    super().explain(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (foreground_series, foreground_past_covariates, foreground_future_covariates, _, _, _, _) = self._process_foreground(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (horizons, target_names) = self._process_horizons_and_targets(horizons, target_components)\n    shap_values_list = []\n    feature_values_list = []\n    shap_explanation_object_list = []\n    for (idx, foreground_ts) in enumerate(foreground_series):\n        foreground_past_cov_ts = None\n        foreground_future_cov_ts = None\n        if foreground_past_covariates:\n            foreground_past_cov_ts = foreground_past_covariates[idx]\n        if foreground_future_covariates:\n            foreground_future_cov_ts = foreground_future_covariates[idx]\n        foreground_X = self.explainers._create_regression_model_shap_X(foreground_ts, foreground_past_cov_ts, foreground_future_cov_ts, train=False)\n        shap_ = self.explainers.shap_explanations(foreground_X, horizons, target_names)\n        shap_values_dict = {}\n        feature_values_dict = {}\n        shap_explanation_object_dict = {}\n        for h in horizons:\n            shap_values_dict_single_h = {}\n            feature_values_dict_single_h = {}\n            shap_explanation_object_dict_single_h = {}\n            for t in target_names:\n                shap_values_dict_single_h[t] = TimeSeries.from_times_and_values(shap_[h][t].time_index, shap_[h][t].values, columns=shap_[h][t].feature_names)\n                feature_values_dict_single_h[t] = TimeSeries.from_times_and_values(shap_[h][t].time_index, shap_[h][t].data, columns=shap_[h][t].feature_names)\n                shap_explanation_object_dict_single_h[t] = shap_[h][t]\n            shap_values_dict[h] = shap_values_dict_single_h\n            feature_values_dict[h] = feature_values_dict_single_h\n            shap_explanation_object_dict[h] = shap_explanation_object_dict_single_h\n        shap_values_list.append(shap_values_dict)\n        feature_values_list.append(feature_values_dict)\n        shap_explanation_object_list.append(shap_explanation_object_dict)\n    if len(shap_values_list) == 1:\n        shap_values_list = shap_values_list[0]\n        feature_values_list = feature_values_list[0]\n        shap_explanation_object_list = shap_explanation_object_list[0]\n    return ShapExplainabilityResult(shap_values_list, feature_values_list, shap_explanation_object_list)",
        "mutated": [
            "def explain(self, foreground_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, foreground_past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, foreground_future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, horizons: Optional[Sequence[int]]=None, target_components: Optional[Sequence[str]]=None) -> ShapExplainabilityResult:\n    if False:\n        i = 10\n    '\\n        Explains a foreground time series and returns a :class:`ShapExplainabilityResult\\n        <darts.explainability.explainability_result.ShapExplainabilityResult>`.\\n        The results can be retrieved with method :func:`get_explanation()\\n        <darts.explainability.explainability_result.ShapExplainabilityResult.get_explanation>`.\\n        The result is a multivariate `TimeSeries` instance containing the \\'explanation\\'\\n        for the (horizon, target_component) forecast at any timestamp forecastable corresponding to\\n        the foreground `TimeSeries` input.\\n\\n        The component name convention of this multivariate `TimeSeries` is:\\n        ``\"{name}_{type_of_cov}_lag_{idx}\"``, where:\\n\\n        - ``{name}`` is the component name from the original foreground series (target, past, or future).\\n        - ``{type_of_cov}`` is the covariates type. It can take 3 different values:\\n          ``\"target\"``, ``\"past_cov\"`` or ``\"future_cov\"``.\\n        - ``{idx}`` is the lag index.\\n\\n        Parameters\\n        ----------\\n        foreground_series\\n            Optionally, one or a sequence of target `TimeSeries` to be explained. Can be multivariate.\\n            If not provided, the background `TimeSeries` will be explained instead.\\n        foreground_past_covariates\\n            Optionally, one or a sequence of past covariates `TimeSeries` if required by the forecasting model.\\n        foreground_future_covariates\\n            Optionally, one or a sequence of future covariates `TimeSeries` if required by the forecasting model.\\n        horizons\\n            Optionally, an integer or sequence of integers representing the future time steps to be explained.\\n            `1` corresponds to the first timestamp being forecasted.\\n            All values must be `<=output_chunk_length` of the explained forecasting model.\\n        target_components\\n            Optionally, a string or sequence of strings with the target components to explain.\\n\\n        Returns\\n        -------\\n        ShapExplainabilityResult\\n            The forecast explanations\\n\\n        Examples\\n        --------\\n        Say we have a model with 2 target components named ``\"T_0\"`` and ``\"T_1\"``,\\n        3 past covariates with default component names ``\"0\"``, ``\"1\"``, and ``\"2\"``,\\n        and one future covariate with default component name ``\"0\"``.\\n        Also, ``horizons = [1, 2]``.\\n        The model is a regression model, with ``lags = 3``, ``lags_past_covariates=[-1, -3]``,\\n        ``lags_future_covariates = [0]``.\\n\\n        We provide `foreground_series`, `foreground_past_covariates`, `foreground_future_covariates` each of length 5.\\n\\n        >>> explain_results = explainer.explain(\\n        >>>     foreground_series=foreground_series,\\n        >>>     foreground_past_covariates=foreground_past_covariates,\\n        >>>     foreground_future_covariates=foreground_future_covariates,\\n        >>>     horizons=[1, 2],\\n        >>>     target_names=[\"T_0\", \"T_1\"])\\n        >>> output = explain_results.get_explanation(horizon=1, component=\"T_1\")\\n        >>> feature_values = explain_results.get_feature_values(horizon=1, component=\"T_1\")\\n        >>> shap_objects = explain_results.get_shap_explanation_objects(horizon=1, component=\"T_1\")\\n\\n        Then the method returns a multivariate TimeSeries containing the *explanations* of\\n        the `ShapExplainer`, with the following component names:\\n\\n             - T_0_target_lag-1\\n             - T_0_target_lag-2\\n             - T_0_target_lag-3\\n             - T_1_target_lag-1\\n             - T_1_target_lag-2\\n             - T_1_target_lag-3\\n             - 0_past_cov_lag-1\\n             - 0_past_cov_lag-3\\n             - 1_past_cov_lag-1\\n             - 1_past_cov_lag-3\\n             - 2_past_cov_lag-1\\n             - 2_past_cov_lag-3\\n             - 0_fut_cov_lag_0\\n\\n        This series has length 3, as the model can explain 5-3+1 forecasts\\n        (timestamp indexes 4, 5, and 6)\\n        '\n    super().explain(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (foreground_series, foreground_past_covariates, foreground_future_covariates, _, _, _, _) = self._process_foreground(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (horizons, target_names) = self._process_horizons_and_targets(horizons, target_components)\n    shap_values_list = []\n    feature_values_list = []\n    shap_explanation_object_list = []\n    for (idx, foreground_ts) in enumerate(foreground_series):\n        foreground_past_cov_ts = None\n        foreground_future_cov_ts = None\n        if foreground_past_covariates:\n            foreground_past_cov_ts = foreground_past_covariates[idx]\n        if foreground_future_covariates:\n            foreground_future_cov_ts = foreground_future_covariates[idx]\n        foreground_X = self.explainers._create_regression_model_shap_X(foreground_ts, foreground_past_cov_ts, foreground_future_cov_ts, train=False)\n        shap_ = self.explainers.shap_explanations(foreground_X, horizons, target_names)\n        shap_values_dict = {}\n        feature_values_dict = {}\n        shap_explanation_object_dict = {}\n        for h in horizons:\n            shap_values_dict_single_h = {}\n            feature_values_dict_single_h = {}\n            shap_explanation_object_dict_single_h = {}\n            for t in target_names:\n                shap_values_dict_single_h[t] = TimeSeries.from_times_and_values(shap_[h][t].time_index, shap_[h][t].values, columns=shap_[h][t].feature_names)\n                feature_values_dict_single_h[t] = TimeSeries.from_times_and_values(shap_[h][t].time_index, shap_[h][t].data, columns=shap_[h][t].feature_names)\n                shap_explanation_object_dict_single_h[t] = shap_[h][t]\n            shap_values_dict[h] = shap_values_dict_single_h\n            feature_values_dict[h] = feature_values_dict_single_h\n            shap_explanation_object_dict[h] = shap_explanation_object_dict_single_h\n        shap_values_list.append(shap_values_dict)\n        feature_values_list.append(feature_values_dict)\n        shap_explanation_object_list.append(shap_explanation_object_dict)\n    if len(shap_values_list) == 1:\n        shap_values_list = shap_values_list[0]\n        feature_values_list = feature_values_list[0]\n        shap_explanation_object_list = shap_explanation_object_list[0]\n    return ShapExplainabilityResult(shap_values_list, feature_values_list, shap_explanation_object_list)",
            "def explain(self, foreground_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, foreground_past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, foreground_future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, horizons: Optional[Sequence[int]]=None, target_components: Optional[Sequence[str]]=None) -> ShapExplainabilityResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Explains a foreground time series and returns a :class:`ShapExplainabilityResult\\n        <darts.explainability.explainability_result.ShapExplainabilityResult>`.\\n        The results can be retrieved with method :func:`get_explanation()\\n        <darts.explainability.explainability_result.ShapExplainabilityResult.get_explanation>`.\\n        The result is a multivariate `TimeSeries` instance containing the \\'explanation\\'\\n        for the (horizon, target_component) forecast at any timestamp forecastable corresponding to\\n        the foreground `TimeSeries` input.\\n\\n        The component name convention of this multivariate `TimeSeries` is:\\n        ``\"{name}_{type_of_cov}_lag_{idx}\"``, where:\\n\\n        - ``{name}`` is the component name from the original foreground series (target, past, or future).\\n        - ``{type_of_cov}`` is the covariates type. It can take 3 different values:\\n          ``\"target\"``, ``\"past_cov\"`` or ``\"future_cov\"``.\\n        - ``{idx}`` is the lag index.\\n\\n        Parameters\\n        ----------\\n        foreground_series\\n            Optionally, one or a sequence of target `TimeSeries` to be explained. Can be multivariate.\\n            If not provided, the background `TimeSeries` will be explained instead.\\n        foreground_past_covariates\\n            Optionally, one or a sequence of past covariates `TimeSeries` if required by the forecasting model.\\n        foreground_future_covariates\\n            Optionally, one or a sequence of future covariates `TimeSeries` if required by the forecasting model.\\n        horizons\\n            Optionally, an integer or sequence of integers representing the future time steps to be explained.\\n            `1` corresponds to the first timestamp being forecasted.\\n            All values must be `<=output_chunk_length` of the explained forecasting model.\\n        target_components\\n            Optionally, a string or sequence of strings with the target components to explain.\\n\\n        Returns\\n        -------\\n        ShapExplainabilityResult\\n            The forecast explanations\\n\\n        Examples\\n        --------\\n        Say we have a model with 2 target components named ``\"T_0\"`` and ``\"T_1\"``,\\n        3 past covariates with default component names ``\"0\"``, ``\"1\"``, and ``\"2\"``,\\n        and one future covariate with default component name ``\"0\"``.\\n        Also, ``horizons = [1, 2]``.\\n        The model is a regression model, with ``lags = 3``, ``lags_past_covariates=[-1, -3]``,\\n        ``lags_future_covariates = [0]``.\\n\\n        We provide `foreground_series`, `foreground_past_covariates`, `foreground_future_covariates` each of length 5.\\n\\n        >>> explain_results = explainer.explain(\\n        >>>     foreground_series=foreground_series,\\n        >>>     foreground_past_covariates=foreground_past_covariates,\\n        >>>     foreground_future_covariates=foreground_future_covariates,\\n        >>>     horizons=[1, 2],\\n        >>>     target_names=[\"T_0\", \"T_1\"])\\n        >>> output = explain_results.get_explanation(horizon=1, component=\"T_1\")\\n        >>> feature_values = explain_results.get_feature_values(horizon=1, component=\"T_1\")\\n        >>> shap_objects = explain_results.get_shap_explanation_objects(horizon=1, component=\"T_1\")\\n\\n        Then the method returns a multivariate TimeSeries containing the *explanations* of\\n        the `ShapExplainer`, with the following component names:\\n\\n             - T_0_target_lag-1\\n             - T_0_target_lag-2\\n             - T_0_target_lag-3\\n             - T_1_target_lag-1\\n             - T_1_target_lag-2\\n             - T_1_target_lag-3\\n             - 0_past_cov_lag-1\\n             - 0_past_cov_lag-3\\n             - 1_past_cov_lag-1\\n             - 1_past_cov_lag-3\\n             - 2_past_cov_lag-1\\n             - 2_past_cov_lag-3\\n             - 0_fut_cov_lag_0\\n\\n        This series has length 3, as the model can explain 5-3+1 forecasts\\n        (timestamp indexes 4, 5, and 6)\\n        '\n    super().explain(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (foreground_series, foreground_past_covariates, foreground_future_covariates, _, _, _, _) = self._process_foreground(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (horizons, target_names) = self._process_horizons_and_targets(horizons, target_components)\n    shap_values_list = []\n    feature_values_list = []\n    shap_explanation_object_list = []\n    for (idx, foreground_ts) in enumerate(foreground_series):\n        foreground_past_cov_ts = None\n        foreground_future_cov_ts = None\n        if foreground_past_covariates:\n            foreground_past_cov_ts = foreground_past_covariates[idx]\n        if foreground_future_covariates:\n            foreground_future_cov_ts = foreground_future_covariates[idx]\n        foreground_X = self.explainers._create_regression_model_shap_X(foreground_ts, foreground_past_cov_ts, foreground_future_cov_ts, train=False)\n        shap_ = self.explainers.shap_explanations(foreground_X, horizons, target_names)\n        shap_values_dict = {}\n        feature_values_dict = {}\n        shap_explanation_object_dict = {}\n        for h in horizons:\n            shap_values_dict_single_h = {}\n            feature_values_dict_single_h = {}\n            shap_explanation_object_dict_single_h = {}\n            for t in target_names:\n                shap_values_dict_single_h[t] = TimeSeries.from_times_and_values(shap_[h][t].time_index, shap_[h][t].values, columns=shap_[h][t].feature_names)\n                feature_values_dict_single_h[t] = TimeSeries.from_times_and_values(shap_[h][t].time_index, shap_[h][t].data, columns=shap_[h][t].feature_names)\n                shap_explanation_object_dict_single_h[t] = shap_[h][t]\n            shap_values_dict[h] = shap_values_dict_single_h\n            feature_values_dict[h] = feature_values_dict_single_h\n            shap_explanation_object_dict[h] = shap_explanation_object_dict_single_h\n        shap_values_list.append(shap_values_dict)\n        feature_values_list.append(feature_values_dict)\n        shap_explanation_object_list.append(shap_explanation_object_dict)\n    if len(shap_values_list) == 1:\n        shap_values_list = shap_values_list[0]\n        feature_values_list = feature_values_list[0]\n        shap_explanation_object_list = shap_explanation_object_list[0]\n    return ShapExplainabilityResult(shap_values_list, feature_values_list, shap_explanation_object_list)",
            "def explain(self, foreground_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, foreground_past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, foreground_future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, horizons: Optional[Sequence[int]]=None, target_components: Optional[Sequence[str]]=None) -> ShapExplainabilityResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Explains a foreground time series and returns a :class:`ShapExplainabilityResult\\n        <darts.explainability.explainability_result.ShapExplainabilityResult>`.\\n        The results can be retrieved with method :func:`get_explanation()\\n        <darts.explainability.explainability_result.ShapExplainabilityResult.get_explanation>`.\\n        The result is a multivariate `TimeSeries` instance containing the \\'explanation\\'\\n        for the (horizon, target_component) forecast at any timestamp forecastable corresponding to\\n        the foreground `TimeSeries` input.\\n\\n        The component name convention of this multivariate `TimeSeries` is:\\n        ``\"{name}_{type_of_cov}_lag_{idx}\"``, where:\\n\\n        - ``{name}`` is the component name from the original foreground series (target, past, or future).\\n        - ``{type_of_cov}`` is the covariates type. It can take 3 different values:\\n          ``\"target\"``, ``\"past_cov\"`` or ``\"future_cov\"``.\\n        - ``{idx}`` is the lag index.\\n\\n        Parameters\\n        ----------\\n        foreground_series\\n            Optionally, one or a sequence of target `TimeSeries` to be explained. Can be multivariate.\\n            If not provided, the background `TimeSeries` will be explained instead.\\n        foreground_past_covariates\\n            Optionally, one or a sequence of past covariates `TimeSeries` if required by the forecasting model.\\n        foreground_future_covariates\\n            Optionally, one or a sequence of future covariates `TimeSeries` if required by the forecasting model.\\n        horizons\\n            Optionally, an integer or sequence of integers representing the future time steps to be explained.\\n            `1` corresponds to the first timestamp being forecasted.\\n            All values must be `<=output_chunk_length` of the explained forecasting model.\\n        target_components\\n            Optionally, a string or sequence of strings with the target components to explain.\\n\\n        Returns\\n        -------\\n        ShapExplainabilityResult\\n            The forecast explanations\\n\\n        Examples\\n        --------\\n        Say we have a model with 2 target components named ``\"T_0\"`` and ``\"T_1\"``,\\n        3 past covariates with default component names ``\"0\"``, ``\"1\"``, and ``\"2\"``,\\n        and one future covariate with default component name ``\"0\"``.\\n        Also, ``horizons = [1, 2]``.\\n        The model is a regression model, with ``lags = 3``, ``lags_past_covariates=[-1, -3]``,\\n        ``lags_future_covariates = [0]``.\\n\\n        We provide `foreground_series`, `foreground_past_covariates`, `foreground_future_covariates` each of length 5.\\n\\n        >>> explain_results = explainer.explain(\\n        >>>     foreground_series=foreground_series,\\n        >>>     foreground_past_covariates=foreground_past_covariates,\\n        >>>     foreground_future_covariates=foreground_future_covariates,\\n        >>>     horizons=[1, 2],\\n        >>>     target_names=[\"T_0\", \"T_1\"])\\n        >>> output = explain_results.get_explanation(horizon=1, component=\"T_1\")\\n        >>> feature_values = explain_results.get_feature_values(horizon=1, component=\"T_1\")\\n        >>> shap_objects = explain_results.get_shap_explanation_objects(horizon=1, component=\"T_1\")\\n\\n        Then the method returns a multivariate TimeSeries containing the *explanations* of\\n        the `ShapExplainer`, with the following component names:\\n\\n             - T_0_target_lag-1\\n             - T_0_target_lag-2\\n             - T_0_target_lag-3\\n             - T_1_target_lag-1\\n             - T_1_target_lag-2\\n             - T_1_target_lag-3\\n             - 0_past_cov_lag-1\\n             - 0_past_cov_lag-3\\n             - 1_past_cov_lag-1\\n             - 1_past_cov_lag-3\\n             - 2_past_cov_lag-1\\n             - 2_past_cov_lag-3\\n             - 0_fut_cov_lag_0\\n\\n        This series has length 3, as the model can explain 5-3+1 forecasts\\n        (timestamp indexes 4, 5, and 6)\\n        '\n    super().explain(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (foreground_series, foreground_past_covariates, foreground_future_covariates, _, _, _, _) = self._process_foreground(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (horizons, target_names) = self._process_horizons_and_targets(horizons, target_components)\n    shap_values_list = []\n    feature_values_list = []\n    shap_explanation_object_list = []\n    for (idx, foreground_ts) in enumerate(foreground_series):\n        foreground_past_cov_ts = None\n        foreground_future_cov_ts = None\n        if foreground_past_covariates:\n            foreground_past_cov_ts = foreground_past_covariates[idx]\n        if foreground_future_covariates:\n            foreground_future_cov_ts = foreground_future_covariates[idx]\n        foreground_X = self.explainers._create_regression_model_shap_X(foreground_ts, foreground_past_cov_ts, foreground_future_cov_ts, train=False)\n        shap_ = self.explainers.shap_explanations(foreground_X, horizons, target_names)\n        shap_values_dict = {}\n        feature_values_dict = {}\n        shap_explanation_object_dict = {}\n        for h in horizons:\n            shap_values_dict_single_h = {}\n            feature_values_dict_single_h = {}\n            shap_explanation_object_dict_single_h = {}\n            for t in target_names:\n                shap_values_dict_single_h[t] = TimeSeries.from_times_and_values(shap_[h][t].time_index, shap_[h][t].values, columns=shap_[h][t].feature_names)\n                feature_values_dict_single_h[t] = TimeSeries.from_times_and_values(shap_[h][t].time_index, shap_[h][t].data, columns=shap_[h][t].feature_names)\n                shap_explanation_object_dict_single_h[t] = shap_[h][t]\n            shap_values_dict[h] = shap_values_dict_single_h\n            feature_values_dict[h] = feature_values_dict_single_h\n            shap_explanation_object_dict[h] = shap_explanation_object_dict_single_h\n        shap_values_list.append(shap_values_dict)\n        feature_values_list.append(feature_values_dict)\n        shap_explanation_object_list.append(shap_explanation_object_dict)\n    if len(shap_values_list) == 1:\n        shap_values_list = shap_values_list[0]\n        feature_values_list = feature_values_list[0]\n        shap_explanation_object_list = shap_explanation_object_list[0]\n    return ShapExplainabilityResult(shap_values_list, feature_values_list, shap_explanation_object_list)",
            "def explain(self, foreground_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, foreground_past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, foreground_future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, horizons: Optional[Sequence[int]]=None, target_components: Optional[Sequence[str]]=None) -> ShapExplainabilityResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Explains a foreground time series and returns a :class:`ShapExplainabilityResult\\n        <darts.explainability.explainability_result.ShapExplainabilityResult>`.\\n        The results can be retrieved with method :func:`get_explanation()\\n        <darts.explainability.explainability_result.ShapExplainabilityResult.get_explanation>`.\\n        The result is a multivariate `TimeSeries` instance containing the \\'explanation\\'\\n        for the (horizon, target_component) forecast at any timestamp forecastable corresponding to\\n        the foreground `TimeSeries` input.\\n\\n        The component name convention of this multivariate `TimeSeries` is:\\n        ``\"{name}_{type_of_cov}_lag_{idx}\"``, where:\\n\\n        - ``{name}`` is the component name from the original foreground series (target, past, or future).\\n        - ``{type_of_cov}`` is the covariates type. It can take 3 different values:\\n          ``\"target\"``, ``\"past_cov\"`` or ``\"future_cov\"``.\\n        - ``{idx}`` is the lag index.\\n\\n        Parameters\\n        ----------\\n        foreground_series\\n            Optionally, one or a sequence of target `TimeSeries` to be explained. Can be multivariate.\\n            If not provided, the background `TimeSeries` will be explained instead.\\n        foreground_past_covariates\\n            Optionally, one or a sequence of past covariates `TimeSeries` if required by the forecasting model.\\n        foreground_future_covariates\\n            Optionally, one or a sequence of future covariates `TimeSeries` if required by the forecasting model.\\n        horizons\\n            Optionally, an integer or sequence of integers representing the future time steps to be explained.\\n            `1` corresponds to the first timestamp being forecasted.\\n            All values must be `<=output_chunk_length` of the explained forecasting model.\\n        target_components\\n            Optionally, a string or sequence of strings with the target components to explain.\\n\\n        Returns\\n        -------\\n        ShapExplainabilityResult\\n            The forecast explanations\\n\\n        Examples\\n        --------\\n        Say we have a model with 2 target components named ``\"T_0\"`` and ``\"T_1\"``,\\n        3 past covariates with default component names ``\"0\"``, ``\"1\"``, and ``\"2\"``,\\n        and one future covariate with default component name ``\"0\"``.\\n        Also, ``horizons = [1, 2]``.\\n        The model is a regression model, with ``lags = 3``, ``lags_past_covariates=[-1, -3]``,\\n        ``lags_future_covariates = [0]``.\\n\\n        We provide `foreground_series`, `foreground_past_covariates`, `foreground_future_covariates` each of length 5.\\n\\n        >>> explain_results = explainer.explain(\\n        >>>     foreground_series=foreground_series,\\n        >>>     foreground_past_covariates=foreground_past_covariates,\\n        >>>     foreground_future_covariates=foreground_future_covariates,\\n        >>>     horizons=[1, 2],\\n        >>>     target_names=[\"T_0\", \"T_1\"])\\n        >>> output = explain_results.get_explanation(horizon=1, component=\"T_1\")\\n        >>> feature_values = explain_results.get_feature_values(horizon=1, component=\"T_1\")\\n        >>> shap_objects = explain_results.get_shap_explanation_objects(horizon=1, component=\"T_1\")\\n\\n        Then the method returns a multivariate TimeSeries containing the *explanations* of\\n        the `ShapExplainer`, with the following component names:\\n\\n             - T_0_target_lag-1\\n             - T_0_target_lag-2\\n             - T_0_target_lag-3\\n             - T_1_target_lag-1\\n             - T_1_target_lag-2\\n             - T_1_target_lag-3\\n             - 0_past_cov_lag-1\\n             - 0_past_cov_lag-3\\n             - 1_past_cov_lag-1\\n             - 1_past_cov_lag-3\\n             - 2_past_cov_lag-1\\n             - 2_past_cov_lag-3\\n             - 0_fut_cov_lag_0\\n\\n        This series has length 3, as the model can explain 5-3+1 forecasts\\n        (timestamp indexes 4, 5, and 6)\\n        '\n    super().explain(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (foreground_series, foreground_past_covariates, foreground_future_covariates, _, _, _, _) = self._process_foreground(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (horizons, target_names) = self._process_horizons_and_targets(horizons, target_components)\n    shap_values_list = []\n    feature_values_list = []\n    shap_explanation_object_list = []\n    for (idx, foreground_ts) in enumerate(foreground_series):\n        foreground_past_cov_ts = None\n        foreground_future_cov_ts = None\n        if foreground_past_covariates:\n            foreground_past_cov_ts = foreground_past_covariates[idx]\n        if foreground_future_covariates:\n            foreground_future_cov_ts = foreground_future_covariates[idx]\n        foreground_X = self.explainers._create_regression_model_shap_X(foreground_ts, foreground_past_cov_ts, foreground_future_cov_ts, train=False)\n        shap_ = self.explainers.shap_explanations(foreground_X, horizons, target_names)\n        shap_values_dict = {}\n        feature_values_dict = {}\n        shap_explanation_object_dict = {}\n        for h in horizons:\n            shap_values_dict_single_h = {}\n            feature_values_dict_single_h = {}\n            shap_explanation_object_dict_single_h = {}\n            for t in target_names:\n                shap_values_dict_single_h[t] = TimeSeries.from_times_and_values(shap_[h][t].time_index, shap_[h][t].values, columns=shap_[h][t].feature_names)\n                feature_values_dict_single_h[t] = TimeSeries.from_times_and_values(shap_[h][t].time_index, shap_[h][t].data, columns=shap_[h][t].feature_names)\n                shap_explanation_object_dict_single_h[t] = shap_[h][t]\n            shap_values_dict[h] = shap_values_dict_single_h\n            feature_values_dict[h] = feature_values_dict_single_h\n            shap_explanation_object_dict[h] = shap_explanation_object_dict_single_h\n        shap_values_list.append(shap_values_dict)\n        feature_values_list.append(feature_values_dict)\n        shap_explanation_object_list.append(shap_explanation_object_dict)\n    if len(shap_values_list) == 1:\n        shap_values_list = shap_values_list[0]\n        feature_values_list = feature_values_list[0]\n        shap_explanation_object_list = shap_explanation_object_list[0]\n    return ShapExplainabilityResult(shap_values_list, feature_values_list, shap_explanation_object_list)",
            "def explain(self, foreground_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, foreground_past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, foreground_future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]]=None, horizons: Optional[Sequence[int]]=None, target_components: Optional[Sequence[str]]=None) -> ShapExplainabilityResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Explains a foreground time series and returns a :class:`ShapExplainabilityResult\\n        <darts.explainability.explainability_result.ShapExplainabilityResult>`.\\n        The results can be retrieved with method :func:`get_explanation()\\n        <darts.explainability.explainability_result.ShapExplainabilityResult.get_explanation>`.\\n        The result is a multivariate `TimeSeries` instance containing the \\'explanation\\'\\n        for the (horizon, target_component) forecast at any timestamp forecastable corresponding to\\n        the foreground `TimeSeries` input.\\n\\n        The component name convention of this multivariate `TimeSeries` is:\\n        ``\"{name}_{type_of_cov}_lag_{idx}\"``, where:\\n\\n        - ``{name}`` is the component name from the original foreground series (target, past, or future).\\n        - ``{type_of_cov}`` is the covariates type. It can take 3 different values:\\n          ``\"target\"``, ``\"past_cov\"`` or ``\"future_cov\"``.\\n        - ``{idx}`` is the lag index.\\n\\n        Parameters\\n        ----------\\n        foreground_series\\n            Optionally, one or a sequence of target `TimeSeries` to be explained. Can be multivariate.\\n            If not provided, the background `TimeSeries` will be explained instead.\\n        foreground_past_covariates\\n            Optionally, one or a sequence of past covariates `TimeSeries` if required by the forecasting model.\\n        foreground_future_covariates\\n            Optionally, one or a sequence of future covariates `TimeSeries` if required by the forecasting model.\\n        horizons\\n            Optionally, an integer or sequence of integers representing the future time steps to be explained.\\n            `1` corresponds to the first timestamp being forecasted.\\n            All values must be `<=output_chunk_length` of the explained forecasting model.\\n        target_components\\n            Optionally, a string or sequence of strings with the target components to explain.\\n\\n        Returns\\n        -------\\n        ShapExplainabilityResult\\n            The forecast explanations\\n\\n        Examples\\n        --------\\n        Say we have a model with 2 target components named ``\"T_0\"`` and ``\"T_1\"``,\\n        3 past covariates with default component names ``\"0\"``, ``\"1\"``, and ``\"2\"``,\\n        and one future covariate with default component name ``\"0\"``.\\n        Also, ``horizons = [1, 2]``.\\n        The model is a regression model, with ``lags = 3``, ``lags_past_covariates=[-1, -3]``,\\n        ``lags_future_covariates = [0]``.\\n\\n        We provide `foreground_series`, `foreground_past_covariates`, `foreground_future_covariates` each of length 5.\\n\\n        >>> explain_results = explainer.explain(\\n        >>>     foreground_series=foreground_series,\\n        >>>     foreground_past_covariates=foreground_past_covariates,\\n        >>>     foreground_future_covariates=foreground_future_covariates,\\n        >>>     horizons=[1, 2],\\n        >>>     target_names=[\"T_0\", \"T_1\"])\\n        >>> output = explain_results.get_explanation(horizon=1, component=\"T_1\")\\n        >>> feature_values = explain_results.get_feature_values(horizon=1, component=\"T_1\")\\n        >>> shap_objects = explain_results.get_shap_explanation_objects(horizon=1, component=\"T_1\")\\n\\n        Then the method returns a multivariate TimeSeries containing the *explanations* of\\n        the `ShapExplainer`, with the following component names:\\n\\n             - T_0_target_lag-1\\n             - T_0_target_lag-2\\n             - T_0_target_lag-3\\n             - T_1_target_lag-1\\n             - T_1_target_lag-2\\n             - T_1_target_lag-3\\n             - 0_past_cov_lag-1\\n             - 0_past_cov_lag-3\\n             - 1_past_cov_lag-1\\n             - 1_past_cov_lag-3\\n             - 2_past_cov_lag-1\\n             - 2_past_cov_lag-3\\n             - 0_fut_cov_lag_0\\n\\n        This series has length 3, as the model can explain 5-3+1 forecasts\\n        (timestamp indexes 4, 5, and 6)\\n        '\n    super().explain(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (foreground_series, foreground_past_covariates, foreground_future_covariates, _, _, _, _) = self._process_foreground(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (horizons, target_names) = self._process_horizons_and_targets(horizons, target_components)\n    shap_values_list = []\n    feature_values_list = []\n    shap_explanation_object_list = []\n    for (idx, foreground_ts) in enumerate(foreground_series):\n        foreground_past_cov_ts = None\n        foreground_future_cov_ts = None\n        if foreground_past_covariates:\n            foreground_past_cov_ts = foreground_past_covariates[idx]\n        if foreground_future_covariates:\n            foreground_future_cov_ts = foreground_future_covariates[idx]\n        foreground_X = self.explainers._create_regression_model_shap_X(foreground_ts, foreground_past_cov_ts, foreground_future_cov_ts, train=False)\n        shap_ = self.explainers.shap_explanations(foreground_X, horizons, target_names)\n        shap_values_dict = {}\n        feature_values_dict = {}\n        shap_explanation_object_dict = {}\n        for h in horizons:\n            shap_values_dict_single_h = {}\n            feature_values_dict_single_h = {}\n            shap_explanation_object_dict_single_h = {}\n            for t in target_names:\n                shap_values_dict_single_h[t] = TimeSeries.from_times_and_values(shap_[h][t].time_index, shap_[h][t].values, columns=shap_[h][t].feature_names)\n                feature_values_dict_single_h[t] = TimeSeries.from_times_and_values(shap_[h][t].time_index, shap_[h][t].data, columns=shap_[h][t].feature_names)\n                shap_explanation_object_dict_single_h[t] = shap_[h][t]\n            shap_values_dict[h] = shap_values_dict_single_h\n            feature_values_dict[h] = feature_values_dict_single_h\n            shap_explanation_object_dict[h] = shap_explanation_object_dict_single_h\n        shap_values_list.append(shap_values_dict)\n        feature_values_list.append(feature_values_dict)\n        shap_explanation_object_list.append(shap_explanation_object_dict)\n    if len(shap_values_list) == 1:\n        shap_values_list = shap_values_list[0]\n        feature_values_list = feature_values_list[0]\n        shap_explanation_object_list = shap_explanation_object_list[0]\n    return ShapExplainabilityResult(shap_values_list, feature_values_list, shap_explanation_object_list)"
        ]
    },
    {
        "func_name": "summary_plot",
        "original": "def summary_plot(self, horizons: Optional[Union[int, Sequence[int]]]=None, target_components: Optional[Union[str, Sequence[str]]]=None, num_samples: Optional[int]=None, plot_type: Optional[str]='dot', **kwargs) -> Dict[int, Dict[str, shap.Explanation]]:\n    \"\"\"\n        Display a shap plot summary for each horizon and each component dimension of the target.\n        This method reuses the initial background data as foreground (potentially sampled) to give a general importance\n        plot for each feature.\n        If no target names and/or no horizons are provided, all summary plots are produced.\n\n        Parameters\n        ----------\n        horizons\n            Optionally, an integer or sequence of integers representing which points/steps in the future to explain,\n            starting from the first prediction step at 1. `horizons` must `<=output_chunk_length` of the forecasting\n            model.\n        target_components\n            Optionally, a string or sequence of strings with the target components to explain.\n        num_samples\n            Optionally, an integer for sampling the foreground series (based on the background),\n            for the sake of performance.\n        plot_type\n            Optionally, specify which of the shap library plot type to use. Can be one of ``'dot', 'bar', 'violin'``.\n\n        Returns\n        -------\n        shaps_\n            A nested dictionary {horizon : {component : shap.Explaination}} containing the raw Explanations for all\n            the horizons and components.\n        \"\"\"\n    (horizons, target_components) = self._process_horizons_and_targets(horizons, target_components)\n    if num_samples:\n        foreground_X_sampled = shap.utils.sample(self.explainers.background_X, num_samples)\n    else:\n        foreground_X_sampled = self.explainers.background_X\n    shaps_ = self.explainers.shap_explanations(foreground_X_sampled, horizons, target_components)\n    for t in target_components:\n        for h in horizons:\n            plt.title('Target: `{}` - Horizon: {}'.format(t, 't+' + str(h)))\n            shap.summary_plot(shaps_[h][t], foreground_X_sampled, plot_type=plot_type, **kwargs)\n    return shaps_",
        "mutated": [
            "def summary_plot(self, horizons: Optional[Union[int, Sequence[int]]]=None, target_components: Optional[Union[str, Sequence[str]]]=None, num_samples: Optional[int]=None, plot_type: Optional[str]='dot', **kwargs) -> Dict[int, Dict[str, shap.Explanation]]:\n    if False:\n        i = 10\n    \"\\n        Display a shap plot summary for each horizon and each component dimension of the target.\\n        This method reuses the initial background data as foreground (potentially sampled) to give a general importance\\n        plot for each feature.\\n        If no target names and/or no horizons are provided, all summary plots are produced.\\n\\n        Parameters\\n        ----------\\n        horizons\\n            Optionally, an integer or sequence of integers representing which points/steps in the future to explain,\\n            starting from the first prediction step at 1. `horizons` must `<=output_chunk_length` of the forecasting\\n            model.\\n        target_components\\n            Optionally, a string or sequence of strings with the target components to explain.\\n        num_samples\\n            Optionally, an integer for sampling the foreground series (based on the background),\\n            for the sake of performance.\\n        plot_type\\n            Optionally, specify which of the shap library plot type to use. Can be one of ``'dot', 'bar', 'violin'``.\\n\\n        Returns\\n        -------\\n        shaps_\\n            A nested dictionary {horizon : {component : shap.Explaination}} containing the raw Explanations for all\\n            the horizons and components.\\n        \"\n    (horizons, target_components) = self._process_horizons_and_targets(horizons, target_components)\n    if num_samples:\n        foreground_X_sampled = shap.utils.sample(self.explainers.background_X, num_samples)\n    else:\n        foreground_X_sampled = self.explainers.background_X\n    shaps_ = self.explainers.shap_explanations(foreground_X_sampled, horizons, target_components)\n    for t in target_components:\n        for h in horizons:\n            plt.title('Target: `{}` - Horizon: {}'.format(t, 't+' + str(h)))\n            shap.summary_plot(shaps_[h][t], foreground_X_sampled, plot_type=plot_type, **kwargs)\n    return shaps_",
            "def summary_plot(self, horizons: Optional[Union[int, Sequence[int]]]=None, target_components: Optional[Union[str, Sequence[str]]]=None, num_samples: Optional[int]=None, plot_type: Optional[str]='dot', **kwargs) -> Dict[int, Dict[str, shap.Explanation]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Display a shap plot summary for each horizon and each component dimension of the target.\\n        This method reuses the initial background data as foreground (potentially sampled) to give a general importance\\n        plot for each feature.\\n        If no target names and/or no horizons are provided, all summary plots are produced.\\n\\n        Parameters\\n        ----------\\n        horizons\\n            Optionally, an integer or sequence of integers representing which points/steps in the future to explain,\\n            starting from the first prediction step at 1. `horizons` must `<=output_chunk_length` of the forecasting\\n            model.\\n        target_components\\n            Optionally, a string or sequence of strings with the target components to explain.\\n        num_samples\\n            Optionally, an integer for sampling the foreground series (based on the background),\\n            for the sake of performance.\\n        plot_type\\n            Optionally, specify which of the shap library plot type to use. Can be one of ``'dot', 'bar', 'violin'``.\\n\\n        Returns\\n        -------\\n        shaps_\\n            A nested dictionary {horizon : {component : shap.Explaination}} containing the raw Explanations for all\\n            the horizons and components.\\n        \"\n    (horizons, target_components) = self._process_horizons_and_targets(horizons, target_components)\n    if num_samples:\n        foreground_X_sampled = shap.utils.sample(self.explainers.background_X, num_samples)\n    else:\n        foreground_X_sampled = self.explainers.background_X\n    shaps_ = self.explainers.shap_explanations(foreground_X_sampled, horizons, target_components)\n    for t in target_components:\n        for h in horizons:\n            plt.title('Target: `{}` - Horizon: {}'.format(t, 't+' + str(h)))\n            shap.summary_plot(shaps_[h][t], foreground_X_sampled, plot_type=plot_type, **kwargs)\n    return shaps_",
            "def summary_plot(self, horizons: Optional[Union[int, Sequence[int]]]=None, target_components: Optional[Union[str, Sequence[str]]]=None, num_samples: Optional[int]=None, plot_type: Optional[str]='dot', **kwargs) -> Dict[int, Dict[str, shap.Explanation]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Display a shap plot summary for each horizon and each component dimension of the target.\\n        This method reuses the initial background data as foreground (potentially sampled) to give a general importance\\n        plot for each feature.\\n        If no target names and/or no horizons are provided, all summary plots are produced.\\n\\n        Parameters\\n        ----------\\n        horizons\\n            Optionally, an integer or sequence of integers representing which points/steps in the future to explain,\\n            starting from the first prediction step at 1. `horizons` must `<=output_chunk_length` of the forecasting\\n            model.\\n        target_components\\n            Optionally, a string or sequence of strings with the target components to explain.\\n        num_samples\\n            Optionally, an integer for sampling the foreground series (based on the background),\\n            for the sake of performance.\\n        plot_type\\n            Optionally, specify which of the shap library plot type to use. Can be one of ``'dot', 'bar', 'violin'``.\\n\\n        Returns\\n        -------\\n        shaps_\\n            A nested dictionary {horizon : {component : shap.Explaination}} containing the raw Explanations for all\\n            the horizons and components.\\n        \"\n    (horizons, target_components) = self._process_horizons_and_targets(horizons, target_components)\n    if num_samples:\n        foreground_X_sampled = shap.utils.sample(self.explainers.background_X, num_samples)\n    else:\n        foreground_X_sampled = self.explainers.background_X\n    shaps_ = self.explainers.shap_explanations(foreground_X_sampled, horizons, target_components)\n    for t in target_components:\n        for h in horizons:\n            plt.title('Target: `{}` - Horizon: {}'.format(t, 't+' + str(h)))\n            shap.summary_plot(shaps_[h][t], foreground_X_sampled, plot_type=plot_type, **kwargs)\n    return shaps_",
            "def summary_plot(self, horizons: Optional[Union[int, Sequence[int]]]=None, target_components: Optional[Union[str, Sequence[str]]]=None, num_samples: Optional[int]=None, plot_type: Optional[str]='dot', **kwargs) -> Dict[int, Dict[str, shap.Explanation]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Display a shap plot summary for each horizon and each component dimension of the target.\\n        This method reuses the initial background data as foreground (potentially sampled) to give a general importance\\n        plot for each feature.\\n        If no target names and/or no horizons are provided, all summary plots are produced.\\n\\n        Parameters\\n        ----------\\n        horizons\\n            Optionally, an integer or sequence of integers representing which points/steps in the future to explain,\\n            starting from the first prediction step at 1. `horizons` must `<=output_chunk_length` of the forecasting\\n            model.\\n        target_components\\n            Optionally, a string or sequence of strings with the target components to explain.\\n        num_samples\\n            Optionally, an integer for sampling the foreground series (based on the background),\\n            for the sake of performance.\\n        plot_type\\n            Optionally, specify which of the shap library plot type to use. Can be one of ``'dot', 'bar', 'violin'``.\\n\\n        Returns\\n        -------\\n        shaps_\\n            A nested dictionary {horizon : {component : shap.Explaination}} containing the raw Explanations for all\\n            the horizons and components.\\n        \"\n    (horizons, target_components) = self._process_horizons_and_targets(horizons, target_components)\n    if num_samples:\n        foreground_X_sampled = shap.utils.sample(self.explainers.background_X, num_samples)\n    else:\n        foreground_X_sampled = self.explainers.background_X\n    shaps_ = self.explainers.shap_explanations(foreground_X_sampled, horizons, target_components)\n    for t in target_components:\n        for h in horizons:\n            plt.title('Target: `{}` - Horizon: {}'.format(t, 't+' + str(h)))\n            shap.summary_plot(shaps_[h][t], foreground_X_sampled, plot_type=plot_type, **kwargs)\n    return shaps_",
            "def summary_plot(self, horizons: Optional[Union[int, Sequence[int]]]=None, target_components: Optional[Union[str, Sequence[str]]]=None, num_samples: Optional[int]=None, plot_type: Optional[str]='dot', **kwargs) -> Dict[int, Dict[str, shap.Explanation]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Display a shap plot summary for each horizon and each component dimension of the target.\\n        This method reuses the initial background data as foreground (potentially sampled) to give a general importance\\n        plot for each feature.\\n        If no target names and/or no horizons are provided, all summary plots are produced.\\n\\n        Parameters\\n        ----------\\n        horizons\\n            Optionally, an integer or sequence of integers representing which points/steps in the future to explain,\\n            starting from the first prediction step at 1. `horizons` must `<=output_chunk_length` of the forecasting\\n            model.\\n        target_components\\n            Optionally, a string or sequence of strings with the target components to explain.\\n        num_samples\\n            Optionally, an integer for sampling the foreground series (based on the background),\\n            for the sake of performance.\\n        plot_type\\n            Optionally, specify which of the shap library plot type to use. Can be one of ``'dot', 'bar', 'violin'``.\\n\\n        Returns\\n        -------\\n        shaps_\\n            A nested dictionary {horizon : {component : shap.Explaination}} containing the raw Explanations for all\\n            the horizons and components.\\n        \"\n    (horizons, target_components) = self._process_horizons_and_targets(horizons, target_components)\n    if num_samples:\n        foreground_X_sampled = shap.utils.sample(self.explainers.background_X, num_samples)\n    else:\n        foreground_X_sampled = self.explainers.background_X\n    shaps_ = self.explainers.shap_explanations(foreground_X_sampled, horizons, target_components)\n    for t in target_components:\n        for h in horizons:\n            plt.title('Target: `{}` - Horizon: {}'.format(t, 't+' + str(h)))\n            shap.summary_plot(shaps_[h][t], foreground_X_sampled, plot_type=plot_type, **kwargs)\n    return shaps_"
        ]
    },
    {
        "func_name": "force_plot_from_ts",
        "original": "def force_plot_from_ts(self, foreground_series: Optional[TimeSeries]=None, foreground_past_covariates: Optional[TimeSeries]=None, foreground_future_covariates: Optional[TimeSeries]=None, horizon: Optional[int]=1, target_component: Optional[str]=None, **kwargs):\n    \"\"\"\n        Display a shap force_plot for one target and one horizon, for a given foreground_series.\n        It displays shap values of each lag/covariate with an additive force layout.\n\n        Once the plot is displayed, select \"original sample ordering\"\n        to observe the time series chronologically.\n\n        Parameters\n        ----------\n        foreground_series\n            Optionally, the target series to explain. Can be multivariate. If `None`, will use the `background_series`.\n        foreground_past_covariates\n            Optionally, a past covariate series if required by the forecasting model. If `None`, will use the\n            `background_past_covariates`.\n        foreground_future_covariates\n            Optionally, a future covariate series if required by the forecasting model. If `None`, will use the\n            `background_future_covariates`.\n        horizon\n            Optionally, an integer for the point/step in the future to explain, starting from the first prediction\n            step at 1. `horizons` must not be larger than `output_chunk_length`.\n        target_component\n            Optionally, the target component to plot. If the target series is multivariate, the target component\n            must be specified.\n        **kwargs\n            Optionally, additional keyword arguments passed to `shap.force_plot()`.\n        \"\"\"\n    raise_if(target_component is None and len(self.target_components) > 1, 'The component parameter is required when the model has more than one component.')\n    if target_component is None:\n        target_component = self.target_components[0]\n    (foreground_series, foreground_past_covariates, foreground_future_covariates, _, _, _, _) = self._process_foreground(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (horizons, target_components) = self._process_horizons_and_targets(horizon, target_component)\n    (horizon, target_component) = (horizons[0], target_components[0])\n    foreground_X = self.explainers._create_regression_model_shap_X(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    shap_ = self.explainers.shap_explanations(foreground_X, [horizon], [target_component])\n    return shap.force_plot(base_value=shap_[horizon][target_component], features=foreground_X, out_names=target_component, **kwargs)",
        "mutated": [
            "def force_plot_from_ts(self, foreground_series: Optional[TimeSeries]=None, foreground_past_covariates: Optional[TimeSeries]=None, foreground_future_covariates: Optional[TimeSeries]=None, horizon: Optional[int]=1, target_component: Optional[str]=None, **kwargs):\n    if False:\n        i = 10\n    '\\n        Display a shap force_plot for one target and one horizon, for a given foreground_series.\\n        It displays shap values of each lag/covariate with an additive force layout.\\n\\n        Once the plot is displayed, select \"original sample ordering\"\\n        to observe the time series chronologically.\\n\\n        Parameters\\n        ----------\\n        foreground_series\\n            Optionally, the target series to explain. Can be multivariate. If `None`, will use the `background_series`.\\n        foreground_past_covariates\\n            Optionally, a past covariate series if required by the forecasting model. If `None`, will use the\\n            `background_past_covariates`.\\n        foreground_future_covariates\\n            Optionally, a future covariate series if required by the forecasting model. If `None`, will use the\\n            `background_future_covariates`.\\n        horizon\\n            Optionally, an integer for the point/step in the future to explain, starting from the first prediction\\n            step at 1. `horizons` must not be larger than `output_chunk_length`.\\n        target_component\\n            Optionally, the target component to plot. If the target series is multivariate, the target component\\n            must be specified.\\n        **kwargs\\n            Optionally, additional keyword arguments passed to `shap.force_plot()`.\\n        '\n    raise_if(target_component is None and len(self.target_components) > 1, 'The component parameter is required when the model has more than one component.')\n    if target_component is None:\n        target_component = self.target_components[0]\n    (foreground_series, foreground_past_covariates, foreground_future_covariates, _, _, _, _) = self._process_foreground(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (horizons, target_components) = self._process_horizons_and_targets(horizon, target_component)\n    (horizon, target_component) = (horizons[0], target_components[0])\n    foreground_X = self.explainers._create_regression_model_shap_X(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    shap_ = self.explainers.shap_explanations(foreground_X, [horizon], [target_component])\n    return shap.force_plot(base_value=shap_[horizon][target_component], features=foreground_X, out_names=target_component, **kwargs)",
            "def force_plot_from_ts(self, foreground_series: Optional[TimeSeries]=None, foreground_past_covariates: Optional[TimeSeries]=None, foreground_future_covariates: Optional[TimeSeries]=None, horizon: Optional[int]=1, target_component: Optional[str]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Display a shap force_plot for one target and one horizon, for a given foreground_series.\\n        It displays shap values of each lag/covariate with an additive force layout.\\n\\n        Once the plot is displayed, select \"original sample ordering\"\\n        to observe the time series chronologically.\\n\\n        Parameters\\n        ----------\\n        foreground_series\\n            Optionally, the target series to explain. Can be multivariate. If `None`, will use the `background_series`.\\n        foreground_past_covariates\\n            Optionally, a past covariate series if required by the forecasting model. If `None`, will use the\\n            `background_past_covariates`.\\n        foreground_future_covariates\\n            Optionally, a future covariate series if required by the forecasting model. If `None`, will use the\\n            `background_future_covariates`.\\n        horizon\\n            Optionally, an integer for the point/step in the future to explain, starting from the first prediction\\n            step at 1. `horizons` must not be larger than `output_chunk_length`.\\n        target_component\\n            Optionally, the target component to plot. If the target series is multivariate, the target component\\n            must be specified.\\n        **kwargs\\n            Optionally, additional keyword arguments passed to `shap.force_plot()`.\\n        '\n    raise_if(target_component is None and len(self.target_components) > 1, 'The component parameter is required when the model has more than one component.')\n    if target_component is None:\n        target_component = self.target_components[0]\n    (foreground_series, foreground_past_covariates, foreground_future_covariates, _, _, _, _) = self._process_foreground(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (horizons, target_components) = self._process_horizons_and_targets(horizon, target_component)\n    (horizon, target_component) = (horizons[0], target_components[0])\n    foreground_X = self.explainers._create_regression_model_shap_X(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    shap_ = self.explainers.shap_explanations(foreground_X, [horizon], [target_component])\n    return shap.force_plot(base_value=shap_[horizon][target_component], features=foreground_X, out_names=target_component, **kwargs)",
            "def force_plot_from_ts(self, foreground_series: Optional[TimeSeries]=None, foreground_past_covariates: Optional[TimeSeries]=None, foreground_future_covariates: Optional[TimeSeries]=None, horizon: Optional[int]=1, target_component: Optional[str]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Display a shap force_plot for one target and one horizon, for a given foreground_series.\\n        It displays shap values of each lag/covariate with an additive force layout.\\n\\n        Once the plot is displayed, select \"original sample ordering\"\\n        to observe the time series chronologically.\\n\\n        Parameters\\n        ----------\\n        foreground_series\\n            Optionally, the target series to explain. Can be multivariate. If `None`, will use the `background_series`.\\n        foreground_past_covariates\\n            Optionally, a past covariate series if required by the forecasting model. If `None`, will use the\\n            `background_past_covariates`.\\n        foreground_future_covariates\\n            Optionally, a future covariate series if required by the forecasting model. If `None`, will use the\\n            `background_future_covariates`.\\n        horizon\\n            Optionally, an integer for the point/step in the future to explain, starting from the first prediction\\n            step at 1. `horizons` must not be larger than `output_chunk_length`.\\n        target_component\\n            Optionally, the target component to plot. If the target series is multivariate, the target component\\n            must be specified.\\n        **kwargs\\n            Optionally, additional keyword arguments passed to `shap.force_plot()`.\\n        '\n    raise_if(target_component is None and len(self.target_components) > 1, 'The component parameter is required when the model has more than one component.')\n    if target_component is None:\n        target_component = self.target_components[0]\n    (foreground_series, foreground_past_covariates, foreground_future_covariates, _, _, _, _) = self._process_foreground(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (horizons, target_components) = self._process_horizons_and_targets(horizon, target_component)\n    (horizon, target_component) = (horizons[0], target_components[0])\n    foreground_X = self.explainers._create_regression_model_shap_X(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    shap_ = self.explainers.shap_explanations(foreground_X, [horizon], [target_component])\n    return shap.force_plot(base_value=shap_[horizon][target_component], features=foreground_X, out_names=target_component, **kwargs)",
            "def force_plot_from_ts(self, foreground_series: Optional[TimeSeries]=None, foreground_past_covariates: Optional[TimeSeries]=None, foreground_future_covariates: Optional[TimeSeries]=None, horizon: Optional[int]=1, target_component: Optional[str]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Display a shap force_plot for one target and one horizon, for a given foreground_series.\\n        It displays shap values of each lag/covariate with an additive force layout.\\n\\n        Once the plot is displayed, select \"original sample ordering\"\\n        to observe the time series chronologically.\\n\\n        Parameters\\n        ----------\\n        foreground_series\\n            Optionally, the target series to explain. Can be multivariate. If `None`, will use the `background_series`.\\n        foreground_past_covariates\\n            Optionally, a past covariate series if required by the forecasting model. If `None`, will use the\\n            `background_past_covariates`.\\n        foreground_future_covariates\\n            Optionally, a future covariate series if required by the forecasting model. If `None`, will use the\\n            `background_future_covariates`.\\n        horizon\\n            Optionally, an integer for the point/step in the future to explain, starting from the first prediction\\n            step at 1. `horizons` must not be larger than `output_chunk_length`.\\n        target_component\\n            Optionally, the target component to plot. If the target series is multivariate, the target component\\n            must be specified.\\n        **kwargs\\n            Optionally, additional keyword arguments passed to `shap.force_plot()`.\\n        '\n    raise_if(target_component is None and len(self.target_components) > 1, 'The component parameter is required when the model has more than one component.')\n    if target_component is None:\n        target_component = self.target_components[0]\n    (foreground_series, foreground_past_covariates, foreground_future_covariates, _, _, _, _) = self._process_foreground(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (horizons, target_components) = self._process_horizons_and_targets(horizon, target_component)\n    (horizon, target_component) = (horizons[0], target_components[0])\n    foreground_X = self.explainers._create_regression_model_shap_X(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    shap_ = self.explainers.shap_explanations(foreground_X, [horizon], [target_component])\n    return shap.force_plot(base_value=shap_[horizon][target_component], features=foreground_X, out_names=target_component, **kwargs)",
            "def force_plot_from_ts(self, foreground_series: Optional[TimeSeries]=None, foreground_past_covariates: Optional[TimeSeries]=None, foreground_future_covariates: Optional[TimeSeries]=None, horizon: Optional[int]=1, target_component: Optional[str]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Display a shap force_plot for one target and one horizon, for a given foreground_series.\\n        It displays shap values of each lag/covariate with an additive force layout.\\n\\n        Once the plot is displayed, select \"original sample ordering\"\\n        to observe the time series chronologically.\\n\\n        Parameters\\n        ----------\\n        foreground_series\\n            Optionally, the target series to explain. Can be multivariate. If `None`, will use the `background_series`.\\n        foreground_past_covariates\\n            Optionally, a past covariate series if required by the forecasting model. If `None`, will use the\\n            `background_past_covariates`.\\n        foreground_future_covariates\\n            Optionally, a future covariate series if required by the forecasting model. If `None`, will use the\\n            `background_future_covariates`.\\n        horizon\\n            Optionally, an integer for the point/step in the future to explain, starting from the first prediction\\n            step at 1. `horizons` must not be larger than `output_chunk_length`.\\n        target_component\\n            Optionally, the target component to plot. If the target series is multivariate, the target component\\n            must be specified.\\n        **kwargs\\n            Optionally, additional keyword arguments passed to `shap.force_plot()`.\\n        '\n    raise_if(target_component is None and len(self.target_components) > 1, 'The component parameter is required when the model has more than one component.')\n    if target_component is None:\n        target_component = self.target_components[0]\n    (foreground_series, foreground_past_covariates, foreground_future_covariates, _, _, _, _) = self._process_foreground(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    (horizons, target_components) = self._process_horizons_and_targets(horizon, target_component)\n    (horizon, target_component) = (horizons[0], target_components[0])\n    foreground_X = self.explainers._create_regression_model_shap_X(foreground_series, foreground_past_covariates, foreground_future_covariates)\n    shap_ = self.explainers.shap_explanations(foreground_X, [horizon], [target_component])\n    return shap.force_plot(base_value=shap_[horizon][target_component], features=foreground_X, out_names=target_component, **kwargs)"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, model: RegressionModel, n: int, target_components: Sequence[str], past_covariates_components: Sequence[str], future_covariates_components: Sequence[str], background_series: Sequence[TimeSeries], background_past_covariates: Sequence[TimeSeries], background_future_covariates: Sequence[TimeSeries], shap_method: _ShapMethod, background_num_samples: Optional[int]=None, **kwargs):\n    self.model = model\n    self.target_dim = self.model.input_dim['target']\n    self.is_multioutputregressor = isinstance(self.model.model, MultiOutputRegressor)\n    self.target_components = target_components\n    self.past_covariates_components = past_covariates_components\n    self.future_covariates_components = future_covariates_components\n    self.n = n\n    self.shap_method = shap_method\n    self.background_series = background_series\n    self.background_past_covariates = background_past_covariates\n    self.background_future_covariates = background_future_covariates\n    self.single_output = False\n    if self.n == 1 and self.target_dim == 1:\n        self.single_output = True\n    self.background_X = self._create_regression_model_shap_X(self.background_series, self.background_past_covariates, self.background_future_covariates, background_num_samples, train=True)\n    if self.is_multioutputregressor:\n        self.explainers = {}\n        for i in range(self.n):\n            self.explainers[i] = {}\n            for j in range(self.target_dim):\n                self.explainers[i][j] = self._build_explainer_sklearn(self.model.get_multioutput_estimator(horizon=i, target_dim=j), self.background_X, self.shap_method, **kwargs)\n    else:\n        self.explainers = self._build_explainer_sklearn(self.model.model, self.background_X, self.shap_method, **kwargs)",
        "mutated": [
            "def __init__(self, model: RegressionModel, n: int, target_components: Sequence[str], past_covariates_components: Sequence[str], future_covariates_components: Sequence[str], background_series: Sequence[TimeSeries], background_past_covariates: Sequence[TimeSeries], background_future_covariates: Sequence[TimeSeries], shap_method: _ShapMethod, background_num_samples: Optional[int]=None, **kwargs):\n    if False:\n        i = 10\n    self.model = model\n    self.target_dim = self.model.input_dim['target']\n    self.is_multioutputregressor = isinstance(self.model.model, MultiOutputRegressor)\n    self.target_components = target_components\n    self.past_covariates_components = past_covariates_components\n    self.future_covariates_components = future_covariates_components\n    self.n = n\n    self.shap_method = shap_method\n    self.background_series = background_series\n    self.background_past_covariates = background_past_covariates\n    self.background_future_covariates = background_future_covariates\n    self.single_output = False\n    if self.n == 1 and self.target_dim == 1:\n        self.single_output = True\n    self.background_X = self._create_regression_model_shap_X(self.background_series, self.background_past_covariates, self.background_future_covariates, background_num_samples, train=True)\n    if self.is_multioutputregressor:\n        self.explainers = {}\n        for i in range(self.n):\n            self.explainers[i] = {}\n            for j in range(self.target_dim):\n                self.explainers[i][j] = self._build_explainer_sklearn(self.model.get_multioutput_estimator(horizon=i, target_dim=j), self.background_X, self.shap_method, **kwargs)\n    else:\n        self.explainers = self._build_explainer_sklearn(self.model.model, self.background_X, self.shap_method, **kwargs)",
            "def __init__(self, model: RegressionModel, n: int, target_components: Sequence[str], past_covariates_components: Sequence[str], future_covariates_components: Sequence[str], background_series: Sequence[TimeSeries], background_past_covariates: Sequence[TimeSeries], background_future_covariates: Sequence[TimeSeries], shap_method: _ShapMethod, background_num_samples: Optional[int]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.model = model\n    self.target_dim = self.model.input_dim['target']\n    self.is_multioutputregressor = isinstance(self.model.model, MultiOutputRegressor)\n    self.target_components = target_components\n    self.past_covariates_components = past_covariates_components\n    self.future_covariates_components = future_covariates_components\n    self.n = n\n    self.shap_method = shap_method\n    self.background_series = background_series\n    self.background_past_covariates = background_past_covariates\n    self.background_future_covariates = background_future_covariates\n    self.single_output = False\n    if self.n == 1 and self.target_dim == 1:\n        self.single_output = True\n    self.background_X = self._create_regression_model_shap_X(self.background_series, self.background_past_covariates, self.background_future_covariates, background_num_samples, train=True)\n    if self.is_multioutputregressor:\n        self.explainers = {}\n        for i in range(self.n):\n            self.explainers[i] = {}\n            for j in range(self.target_dim):\n                self.explainers[i][j] = self._build_explainer_sklearn(self.model.get_multioutput_estimator(horizon=i, target_dim=j), self.background_X, self.shap_method, **kwargs)\n    else:\n        self.explainers = self._build_explainer_sklearn(self.model.model, self.background_X, self.shap_method, **kwargs)",
            "def __init__(self, model: RegressionModel, n: int, target_components: Sequence[str], past_covariates_components: Sequence[str], future_covariates_components: Sequence[str], background_series: Sequence[TimeSeries], background_past_covariates: Sequence[TimeSeries], background_future_covariates: Sequence[TimeSeries], shap_method: _ShapMethod, background_num_samples: Optional[int]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.model = model\n    self.target_dim = self.model.input_dim['target']\n    self.is_multioutputregressor = isinstance(self.model.model, MultiOutputRegressor)\n    self.target_components = target_components\n    self.past_covariates_components = past_covariates_components\n    self.future_covariates_components = future_covariates_components\n    self.n = n\n    self.shap_method = shap_method\n    self.background_series = background_series\n    self.background_past_covariates = background_past_covariates\n    self.background_future_covariates = background_future_covariates\n    self.single_output = False\n    if self.n == 1 and self.target_dim == 1:\n        self.single_output = True\n    self.background_X = self._create_regression_model_shap_X(self.background_series, self.background_past_covariates, self.background_future_covariates, background_num_samples, train=True)\n    if self.is_multioutputregressor:\n        self.explainers = {}\n        for i in range(self.n):\n            self.explainers[i] = {}\n            for j in range(self.target_dim):\n                self.explainers[i][j] = self._build_explainer_sklearn(self.model.get_multioutput_estimator(horizon=i, target_dim=j), self.background_X, self.shap_method, **kwargs)\n    else:\n        self.explainers = self._build_explainer_sklearn(self.model.model, self.background_X, self.shap_method, **kwargs)",
            "def __init__(self, model: RegressionModel, n: int, target_components: Sequence[str], past_covariates_components: Sequence[str], future_covariates_components: Sequence[str], background_series: Sequence[TimeSeries], background_past_covariates: Sequence[TimeSeries], background_future_covariates: Sequence[TimeSeries], shap_method: _ShapMethod, background_num_samples: Optional[int]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.model = model\n    self.target_dim = self.model.input_dim['target']\n    self.is_multioutputregressor = isinstance(self.model.model, MultiOutputRegressor)\n    self.target_components = target_components\n    self.past_covariates_components = past_covariates_components\n    self.future_covariates_components = future_covariates_components\n    self.n = n\n    self.shap_method = shap_method\n    self.background_series = background_series\n    self.background_past_covariates = background_past_covariates\n    self.background_future_covariates = background_future_covariates\n    self.single_output = False\n    if self.n == 1 and self.target_dim == 1:\n        self.single_output = True\n    self.background_X = self._create_regression_model_shap_X(self.background_series, self.background_past_covariates, self.background_future_covariates, background_num_samples, train=True)\n    if self.is_multioutputregressor:\n        self.explainers = {}\n        for i in range(self.n):\n            self.explainers[i] = {}\n            for j in range(self.target_dim):\n                self.explainers[i][j] = self._build_explainer_sklearn(self.model.get_multioutput_estimator(horizon=i, target_dim=j), self.background_X, self.shap_method, **kwargs)\n    else:\n        self.explainers = self._build_explainer_sklearn(self.model.model, self.background_X, self.shap_method, **kwargs)",
            "def __init__(self, model: RegressionModel, n: int, target_components: Sequence[str], past_covariates_components: Sequence[str], future_covariates_components: Sequence[str], background_series: Sequence[TimeSeries], background_past_covariates: Sequence[TimeSeries], background_future_covariates: Sequence[TimeSeries], shap_method: _ShapMethod, background_num_samples: Optional[int]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.model = model\n    self.target_dim = self.model.input_dim['target']\n    self.is_multioutputregressor = isinstance(self.model.model, MultiOutputRegressor)\n    self.target_components = target_components\n    self.past_covariates_components = past_covariates_components\n    self.future_covariates_components = future_covariates_components\n    self.n = n\n    self.shap_method = shap_method\n    self.background_series = background_series\n    self.background_past_covariates = background_past_covariates\n    self.background_future_covariates = background_future_covariates\n    self.single_output = False\n    if self.n == 1 and self.target_dim == 1:\n        self.single_output = True\n    self.background_X = self._create_regression_model_shap_X(self.background_series, self.background_past_covariates, self.background_future_covariates, background_num_samples, train=True)\n    if self.is_multioutputregressor:\n        self.explainers = {}\n        for i in range(self.n):\n            self.explainers[i] = {}\n            for j in range(self.target_dim):\n                self.explainers[i][j] = self._build_explainer_sklearn(self.model.get_multioutput_estimator(horizon=i, target_dim=j), self.background_X, self.shap_method, **kwargs)\n    else:\n        self.explainers = self._build_explainer_sklearn(self.model.model, self.background_X, self.shap_method, **kwargs)"
        ]
    },
    {
        "func_name": "shap_explanations",
        "original": "def shap_explanations(self, foreground_X: pd.DataFrame, horizons: Optional[Sequence[int]]=None, target_components: Optional[Sequence[str]]=None) -> Dict[int, Dict[str, shap.Explanation]]:\n    \"\"\"\n        Return a dictionary of dictionaries of shap.Explanation instances:\n        - the first dimension corresponds to the n forecasts ahead we want to explain (Horizon).\n        - the second dimension corresponds to each component of the target time series.\n        Parameters\n        ----------\n        foreground_X\n            the Dataframe of lags features specific of darts RegressionModel.\n        horizons\n            Optionally, a list of integers representing which points/steps in the future we want to explain,\n            starting from the first prediction step at 1. Currently, only forecasting models are supported which\n            provide an `output_chunk_length` parameter. `horizons` must not be larger than `output_chunk_length`.\n        target_components\n            Optionally, a list of strings with the target components we want to explain.\n\n        \"\"\"\n    shap_explanations = {}\n    if self.is_multioutputregressor:\n        for h in horizons:\n            tmp_n = {}\n            for (t_idx, t) in enumerate(self.target_components):\n                if t not in target_components:\n                    continue\n                explainer = self.explainers[h - 1][t_idx](foreground_X)\n                explainer.base_values = explainer.base_values.ravel()\n                explainer.time_index = foreground_X.index\n                tmp_n[t] = explainer\n            shap_explanations[h] = tmp_n\n    else:\n        shap_explanation_tmp = self.explainers(foreground_X)\n        for h in horizons:\n            tmp_n = {}\n            for (t_idx, t) in enumerate(target_components):\n                if t not in target_components:\n                    continue\n                if not self.single_output:\n                    tmp_t = shap.Explanation(shap_explanation_tmp.values[:, :, self.target_dim * (h - 1) + t_idx])\n                    tmp_t.data = shap_explanation_tmp.data\n                    tmp_t.base_values = shap_explanation_tmp.base_values[:, self.target_dim * (h - 1) + t_idx].ravel()\n                else:\n                    tmp_t = shap_explanation_tmp\n                    tmp_t.base_values = shap_explanation_tmp.base_values.ravel()\n                tmp_t.feature_names = shap_explanation_tmp.feature_names\n                tmp_t.time_index = foreground_X.index\n                tmp_n[t] = tmp_t\n            shap_explanations[h] = tmp_n\n    return shap_explanations",
        "mutated": [
            "def shap_explanations(self, foreground_X: pd.DataFrame, horizons: Optional[Sequence[int]]=None, target_components: Optional[Sequence[str]]=None) -> Dict[int, Dict[str, shap.Explanation]]:\n    if False:\n        i = 10\n    '\\n        Return a dictionary of dictionaries of shap.Explanation instances:\\n        - the first dimension corresponds to the n forecasts ahead we want to explain (Horizon).\\n        - the second dimension corresponds to each component of the target time series.\\n        Parameters\\n        ----------\\n        foreground_X\\n            the Dataframe of lags features specific of darts RegressionModel.\\n        horizons\\n            Optionally, a list of integers representing which points/steps in the future we want to explain,\\n            starting from the first prediction step at 1. Currently, only forecasting models are supported which\\n            provide an `output_chunk_length` parameter. `horizons` must not be larger than `output_chunk_length`.\\n        target_components\\n            Optionally, a list of strings with the target components we want to explain.\\n\\n        '\n    shap_explanations = {}\n    if self.is_multioutputregressor:\n        for h in horizons:\n            tmp_n = {}\n            for (t_idx, t) in enumerate(self.target_components):\n                if t not in target_components:\n                    continue\n                explainer = self.explainers[h - 1][t_idx](foreground_X)\n                explainer.base_values = explainer.base_values.ravel()\n                explainer.time_index = foreground_X.index\n                tmp_n[t] = explainer\n            shap_explanations[h] = tmp_n\n    else:\n        shap_explanation_tmp = self.explainers(foreground_X)\n        for h in horizons:\n            tmp_n = {}\n            for (t_idx, t) in enumerate(target_components):\n                if t not in target_components:\n                    continue\n                if not self.single_output:\n                    tmp_t = shap.Explanation(shap_explanation_tmp.values[:, :, self.target_dim * (h - 1) + t_idx])\n                    tmp_t.data = shap_explanation_tmp.data\n                    tmp_t.base_values = shap_explanation_tmp.base_values[:, self.target_dim * (h - 1) + t_idx].ravel()\n                else:\n                    tmp_t = shap_explanation_tmp\n                    tmp_t.base_values = shap_explanation_tmp.base_values.ravel()\n                tmp_t.feature_names = shap_explanation_tmp.feature_names\n                tmp_t.time_index = foreground_X.index\n                tmp_n[t] = tmp_t\n            shap_explanations[h] = tmp_n\n    return shap_explanations",
            "def shap_explanations(self, foreground_X: pd.DataFrame, horizons: Optional[Sequence[int]]=None, target_components: Optional[Sequence[str]]=None) -> Dict[int, Dict[str, shap.Explanation]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Return a dictionary of dictionaries of shap.Explanation instances:\\n        - the first dimension corresponds to the n forecasts ahead we want to explain (Horizon).\\n        - the second dimension corresponds to each component of the target time series.\\n        Parameters\\n        ----------\\n        foreground_X\\n            the Dataframe of lags features specific of darts RegressionModel.\\n        horizons\\n            Optionally, a list of integers representing which points/steps in the future we want to explain,\\n            starting from the first prediction step at 1. Currently, only forecasting models are supported which\\n            provide an `output_chunk_length` parameter. `horizons` must not be larger than `output_chunk_length`.\\n        target_components\\n            Optionally, a list of strings with the target components we want to explain.\\n\\n        '\n    shap_explanations = {}\n    if self.is_multioutputregressor:\n        for h in horizons:\n            tmp_n = {}\n            for (t_idx, t) in enumerate(self.target_components):\n                if t not in target_components:\n                    continue\n                explainer = self.explainers[h - 1][t_idx](foreground_X)\n                explainer.base_values = explainer.base_values.ravel()\n                explainer.time_index = foreground_X.index\n                tmp_n[t] = explainer\n            shap_explanations[h] = tmp_n\n    else:\n        shap_explanation_tmp = self.explainers(foreground_X)\n        for h in horizons:\n            tmp_n = {}\n            for (t_idx, t) in enumerate(target_components):\n                if t not in target_components:\n                    continue\n                if not self.single_output:\n                    tmp_t = shap.Explanation(shap_explanation_tmp.values[:, :, self.target_dim * (h - 1) + t_idx])\n                    tmp_t.data = shap_explanation_tmp.data\n                    tmp_t.base_values = shap_explanation_tmp.base_values[:, self.target_dim * (h - 1) + t_idx].ravel()\n                else:\n                    tmp_t = shap_explanation_tmp\n                    tmp_t.base_values = shap_explanation_tmp.base_values.ravel()\n                tmp_t.feature_names = shap_explanation_tmp.feature_names\n                tmp_t.time_index = foreground_X.index\n                tmp_n[t] = tmp_t\n            shap_explanations[h] = tmp_n\n    return shap_explanations",
            "def shap_explanations(self, foreground_X: pd.DataFrame, horizons: Optional[Sequence[int]]=None, target_components: Optional[Sequence[str]]=None) -> Dict[int, Dict[str, shap.Explanation]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Return a dictionary of dictionaries of shap.Explanation instances:\\n        - the first dimension corresponds to the n forecasts ahead we want to explain (Horizon).\\n        - the second dimension corresponds to each component of the target time series.\\n        Parameters\\n        ----------\\n        foreground_X\\n            the Dataframe of lags features specific of darts RegressionModel.\\n        horizons\\n            Optionally, a list of integers representing which points/steps in the future we want to explain,\\n            starting from the first prediction step at 1. Currently, only forecasting models are supported which\\n            provide an `output_chunk_length` parameter. `horizons` must not be larger than `output_chunk_length`.\\n        target_components\\n            Optionally, a list of strings with the target components we want to explain.\\n\\n        '\n    shap_explanations = {}\n    if self.is_multioutputregressor:\n        for h in horizons:\n            tmp_n = {}\n            for (t_idx, t) in enumerate(self.target_components):\n                if t not in target_components:\n                    continue\n                explainer = self.explainers[h - 1][t_idx](foreground_X)\n                explainer.base_values = explainer.base_values.ravel()\n                explainer.time_index = foreground_X.index\n                tmp_n[t] = explainer\n            shap_explanations[h] = tmp_n\n    else:\n        shap_explanation_tmp = self.explainers(foreground_X)\n        for h in horizons:\n            tmp_n = {}\n            for (t_idx, t) in enumerate(target_components):\n                if t not in target_components:\n                    continue\n                if not self.single_output:\n                    tmp_t = shap.Explanation(shap_explanation_tmp.values[:, :, self.target_dim * (h - 1) + t_idx])\n                    tmp_t.data = shap_explanation_tmp.data\n                    tmp_t.base_values = shap_explanation_tmp.base_values[:, self.target_dim * (h - 1) + t_idx].ravel()\n                else:\n                    tmp_t = shap_explanation_tmp\n                    tmp_t.base_values = shap_explanation_tmp.base_values.ravel()\n                tmp_t.feature_names = shap_explanation_tmp.feature_names\n                tmp_t.time_index = foreground_X.index\n                tmp_n[t] = tmp_t\n            shap_explanations[h] = tmp_n\n    return shap_explanations",
            "def shap_explanations(self, foreground_X: pd.DataFrame, horizons: Optional[Sequence[int]]=None, target_components: Optional[Sequence[str]]=None) -> Dict[int, Dict[str, shap.Explanation]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Return a dictionary of dictionaries of shap.Explanation instances:\\n        - the first dimension corresponds to the n forecasts ahead we want to explain (Horizon).\\n        - the second dimension corresponds to each component of the target time series.\\n        Parameters\\n        ----------\\n        foreground_X\\n            the Dataframe of lags features specific of darts RegressionModel.\\n        horizons\\n            Optionally, a list of integers representing which points/steps in the future we want to explain,\\n            starting from the first prediction step at 1. Currently, only forecasting models are supported which\\n            provide an `output_chunk_length` parameter. `horizons` must not be larger than `output_chunk_length`.\\n        target_components\\n            Optionally, a list of strings with the target components we want to explain.\\n\\n        '\n    shap_explanations = {}\n    if self.is_multioutputregressor:\n        for h in horizons:\n            tmp_n = {}\n            for (t_idx, t) in enumerate(self.target_components):\n                if t not in target_components:\n                    continue\n                explainer = self.explainers[h - 1][t_idx](foreground_X)\n                explainer.base_values = explainer.base_values.ravel()\n                explainer.time_index = foreground_X.index\n                tmp_n[t] = explainer\n            shap_explanations[h] = tmp_n\n    else:\n        shap_explanation_tmp = self.explainers(foreground_X)\n        for h in horizons:\n            tmp_n = {}\n            for (t_idx, t) in enumerate(target_components):\n                if t not in target_components:\n                    continue\n                if not self.single_output:\n                    tmp_t = shap.Explanation(shap_explanation_tmp.values[:, :, self.target_dim * (h - 1) + t_idx])\n                    tmp_t.data = shap_explanation_tmp.data\n                    tmp_t.base_values = shap_explanation_tmp.base_values[:, self.target_dim * (h - 1) + t_idx].ravel()\n                else:\n                    tmp_t = shap_explanation_tmp\n                    tmp_t.base_values = shap_explanation_tmp.base_values.ravel()\n                tmp_t.feature_names = shap_explanation_tmp.feature_names\n                tmp_t.time_index = foreground_X.index\n                tmp_n[t] = tmp_t\n            shap_explanations[h] = tmp_n\n    return shap_explanations",
            "def shap_explanations(self, foreground_X: pd.DataFrame, horizons: Optional[Sequence[int]]=None, target_components: Optional[Sequence[str]]=None) -> Dict[int, Dict[str, shap.Explanation]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Return a dictionary of dictionaries of shap.Explanation instances:\\n        - the first dimension corresponds to the n forecasts ahead we want to explain (Horizon).\\n        - the second dimension corresponds to each component of the target time series.\\n        Parameters\\n        ----------\\n        foreground_X\\n            the Dataframe of lags features specific of darts RegressionModel.\\n        horizons\\n            Optionally, a list of integers representing which points/steps in the future we want to explain,\\n            starting from the first prediction step at 1. Currently, only forecasting models are supported which\\n            provide an `output_chunk_length` parameter. `horizons` must not be larger than `output_chunk_length`.\\n        target_components\\n            Optionally, a list of strings with the target components we want to explain.\\n\\n        '\n    shap_explanations = {}\n    if self.is_multioutputregressor:\n        for h in horizons:\n            tmp_n = {}\n            for (t_idx, t) in enumerate(self.target_components):\n                if t not in target_components:\n                    continue\n                explainer = self.explainers[h - 1][t_idx](foreground_X)\n                explainer.base_values = explainer.base_values.ravel()\n                explainer.time_index = foreground_X.index\n                tmp_n[t] = explainer\n            shap_explanations[h] = tmp_n\n    else:\n        shap_explanation_tmp = self.explainers(foreground_X)\n        for h in horizons:\n            tmp_n = {}\n            for (t_idx, t) in enumerate(target_components):\n                if t not in target_components:\n                    continue\n                if not self.single_output:\n                    tmp_t = shap.Explanation(shap_explanation_tmp.values[:, :, self.target_dim * (h - 1) + t_idx])\n                    tmp_t.data = shap_explanation_tmp.data\n                    tmp_t.base_values = shap_explanation_tmp.base_values[:, self.target_dim * (h - 1) + t_idx].ravel()\n                else:\n                    tmp_t = shap_explanation_tmp\n                    tmp_t.base_values = shap_explanation_tmp.base_values.ravel()\n                tmp_t.feature_names = shap_explanation_tmp.feature_names\n                tmp_t.time_index = foreground_X.index\n                tmp_n[t] = tmp_t\n            shap_explanations[h] = tmp_n\n    return shap_explanations"
        ]
    },
    {
        "func_name": "_build_explainer_sklearn",
        "original": "def _build_explainer_sklearn(self, model_sklearn, background_X: pd.DataFrame, shap_method: Optional[ShapMethod]=None, **kwargs):\n    model_name = type(model_sklearn).__name__\n    if shap_method is None:\n        if model_name in self.default_sklearn_shap_explainers:\n            shap_method = self.default_sklearn_shap_explainers[model_name]\n        else:\n            shap_method = _ShapMethod.KERNEL\n    if shap_method == _ShapMethod.TREE:\n        if kwargs.get('feature_perturbation') == 'interventional':\n            explainer = shap.TreeExplainer(model_sklearn, background_X, **kwargs)\n        else:\n            explainer = shap.TreeExplainer(model_sklearn, **kwargs)\n    elif shap_method == _ShapMethod.PERMUTATION:\n        explainer = shap.PermutationExplainer(model_sklearn.predict, background_X, **kwargs)\n    elif shap_method == _ShapMethod.PARTITION:\n        explainer = shap.PermutationExplainer(model_sklearn.predict, background_X, **kwargs)\n    elif shap_method == _ShapMethod.KERNEL:\n        explainer = shap.KernelExplainer(model_sklearn.predict, background_X, keep_index=True, **kwargs)\n    elif shap_method == _ShapMethod.LINEAR:\n        explainer = shap.LinearExplainer(model_sklearn, background_X, **kwargs)\n    elif shap_method == _ShapMethod.DEEP:\n        explainer = shap.LinearExplainer(model_sklearn, background_X, **kwargs)\n    elif shap_method == _ShapMethod.ADDITIVE:\n        explainer = shap.AdditiveExplainer(model_sklearn, background_X, **kwargs)\n    else:\n        raise ValueError('shap_method must be one of the following: ' + ', '.join([e.value for e in _ShapMethod]))\n    logger.info('The shap method used is of type: ' + str(type(explainer)))\n    return explainer",
        "mutated": [
            "def _build_explainer_sklearn(self, model_sklearn, background_X: pd.DataFrame, shap_method: Optional[ShapMethod]=None, **kwargs):\n    if False:\n        i = 10\n    model_name = type(model_sklearn).__name__\n    if shap_method is None:\n        if model_name in self.default_sklearn_shap_explainers:\n            shap_method = self.default_sklearn_shap_explainers[model_name]\n        else:\n            shap_method = _ShapMethod.KERNEL\n    if shap_method == _ShapMethod.TREE:\n        if kwargs.get('feature_perturbation') == 'interventional':\n            explainer = shap.TreeExplainer(model_sklearn, background_X, **kwargs)\n        else:\n            explainer = shap.TreeExplainer(model_sklearn, **kwargs)\n    elif shap_method == _ShapMethod.PERMUTATION:\n        explainer = shap.PermutationExplainer(model_sklearn.predict, background_X, **kwargs)\n    elif shap_method == _ShapMethod.PARTITION:\n        explainer = shap.PermutationExplainer(model_sklearn.predict, background_X, **kwargs)\n    elif shap_method == _ShapMethod.KERNEL:\n        explainer = shap.KernelExplainer(model_sklearn.predict, background_X, keep_index=True, **kwargs)\n    elif shap_method == _ShapMethod.LINEAR:\n        explainer = shap.LinearExplainer(model_sklearn, background_X, **kwargs)\n    elif shap_method == _ShapMethod.DEEP:\n        explainer = shap.LinearExplainer(model_sklearn, background_X, **kwargs)\n    elif shap_method == _ShapMethod.ADDITIVE:\n        explainer = shap.AdditiveExplainer(model_sklearn, background_X, **kwargs)\n    else:\n        raise ValueError('shap_method must be one of the following: ' + ', '.join([e.value for e in _ShapMethod]))\n    logger.info('The shap method used is of type: ' + str(type(explainer)))\n    return explainer",
            "def _build_explainer_sklearn(self, model_sklearn, background_X: pd.DataFrame, shap_method: Optional[ShapMethod]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    model_name = type(model_sklearn).__name__\n    if shap_method is None:\n        if model_name in self.default_sklearn_shap_explainers:\n            shap_method = self.default_sklearn_shap_explainers[model_name]\n        else:\n            shap_method = _ShapMethod.KERNEL\n    if shap_method == _ShapMethod.TREE:\n        if kwargs.get('feature_perturbation') == 'interventional':\n            explainer = shap.TreeExplainer(model_sklearn, background_X, **kwargs)\n        else:\n            explainer = shap.TreeExplainer(model_sklearn, **kwargs)\n    elif shap_method == _ShapMethod.PERMUTATION:\n        explainer = shap.PermutationExplainer(model_sklearn.predict, background_X, **kwargs)\n    elif shap_method == _ShapMethod.PARTITION:\n        explainer = shap.PermutationExplainer(model_sklearn.predict, background_X, **kwargs)\n    elif shap_method == _ShapMethod.KERNEL:\n        explainer = shap.KernelExplainer(model_sklearn.predict, background_X, keep_index=True, **kwargs)\n    elif shap_method == _ShapMethod.LINEAR:\n        explainer = shap.LinearExplainer(model_sklearn, background_X, **kwargs)\n    elif shap_method == _ShapMethod.DEEP:\n        explainer = shap.LinearExplainer(model_sklearn, background_X, **kwargs)\n    elif shap_method == _ShapMethod.ADDITIVE:\n        explainer = shap.AdditiveExplainer(model_sklearn, background_X, **kwargs)\n    else:\n        raise ValueError('shap_method must be one of the following: ' + ', '.join([e.value for e in _ShapMethod]))\n    logger.info('The shap method used is of type: ' + str(type(explainer)))\n    return explainer",
            "def _build_explainer_sklearn(self, model_sklearn, background_X: pd.DataFrame, shap_method: Optional[ShapMethod]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    model_name = type(model_sklearn).__name__\n    if shap_method is None:\n        if model_name in self.default_sklearn_shap_explainers:\n            shap_method = self.default_sklearn_shap_explainers[model_name]\n        else:\n            shap_method = _ShapMethod.KERNEL\n    if shap_method == _ShapMethod.TREE:\n        if kwargs.get('feature_perturbation') == 'interventional':\n            explainer = shap.TreeExplainer(model_sklearn, background_X, **kwargs)\n        else:\n            explainer = shap.TreeExplainer(model_sklearn, **kwargs)\n    elif shap_method == _ShapMethod.PERMUTATION:\n        explainer = shap.PermutationExplainer(model_sklearn.predict, background_X, **kwargs)\n    elif shap_method == _ShapMethod.PARTITION:\n        explainer = shap.PermutationExplainer(model_sklearn.predict, background_X, **kwargs)\n    elif shap_method == _ShapMethod.KERNEL:\n        explainer = shap.KernelExplainer(model_sklearn.predict, background_X, keep_index=True, **kwargs)\n    elif shap_method == _ShapMethod.LINEAR:\n        explainer = shap.LinearExplainer(model_sklearn, background_X, **kwargs)\n    elif shap_method == _ShapMethod.DEEP:\n        explainer = shap.LinearExplainer(model_sklearn, background_X, **kwargs)\n    elif shap_method == _ShapMethod.ADDITIVE:\n        explainer = shap.AdditiveExplainer(model_sklearn, background_X, **kwargs)\n    else:\n        raise ValueError('shap_method must be one of the following: ' + ', '.join([e.value for e in _ShapMethod]))\n    logger.info('The shap method used is of type: ' + str(type(explainer)))\n    return explainer",
            "def _build_explainer_sklearn(self, model_sklearn, background_X: pd.DataFrame, shap_method: Optional[ShapMethod]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    model_name = type(model_sklearn).__name__\n    if shap_method is None:\n        if model_name in self.default_sklearn_shap_explainers:\n            shap_method = self.default_sklearn_shap_explainers[model_name]\n        else:\n            shap_method = _ShapMethod.KERNEL\n    if shap_method == _ShapMethod.TREE:\n        if kwargs.get('feature_perturbation') == 'interventional':\n            explainer = shap.TreeExplainer(model_sklearn, background_X, **kwargs)\n        else:\n            explainer = shap.TreeExplainer(model_sklearn, **kwargs)\n    elif shap_method == _ShapMethod.PERMUTATION:\n        explainer = shap.PermutationExplainer(model_sklearn.predict, background_X, **kwargs)\n    elif shap_method == _ShapMethod.PARTITION:\n        explainer = shap.PermutationExplainer(model_sklearn.predict, background_X, **kwargs)\n    elif shap_method == _ShapMethod.KERNEL:\n        explainer = shap.KernelExplainer(model_sklearn.predict, background_X, keep_index=True, **kwargs)\n    elif shap_method == _ShapMethod.LINEAR:\n        explainer = shap.LinearExplainer(model_sklearn, background_X, **kwargs)\n    elif shap_method == _ShapMethod.DEEP:\n        explainer = shap.LinearExplainer(model_sklearn, background_X, **kwargs)\n    elif shap_method == _ShapMethod.ADDITIVE:\n        explainer = shap.AdditiveExplainer(model_sklearn, background_X, **kwargs)\n    else:\n        raise ValueError('shap_method must be one of the following: ' + ', '.join([e.value for e in _ShapMethod]))\n    logger.info('The shap method used is of type: ' + str(type(explainer)))\n    return explainer",
            "def _build_explainer_sklearn(self, model_sklearn, background_X: pd.DataFrame, shap_method: Optional[ShapMethod]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    model_name = type(model_sklearn).__name__\n    if shap_method is None:\n        if model_name in self.default_sklearn_shap_explainers:\n            shap_method = self.default_sklearn_shap_explainers[model_name]\n        else:\n            shap_method = _ShapMethod.KERNEL\n    if shap_method == _ShapMethod.TREE:\n        if kwargs.get('feature_perturbation') == 'interventional':\n            explainer = shap.TreeExplainer(model_sklearn, background_X, **kwargs)\n        else:\n            explainer = shap.TreeExplainer(model_sklearn, **kwargs)\n    elif shap_method == _ShapMethod.PERMUTATION:\n        explainer = shap.PermutationExplainer(model_sklearn.predict, background_X, **kwargs)\n    elif shap_method == _ShapMethod.PARTITION:\n        explainer = shap.PermutationExplainer(model_sklearn.predict, background_X, **kwargs)\n    elif shap_method == _ShapMethod.KERNEL:\n        explainer = shap.KernelExplainer(model_sklearn.predict, background_X, keep_index=True, **kwargs)\n    elif shap_method == _ShapMethod.LINEAR:\n        explainer = shap.LinearExplainer(model_sklearn, background_X, **kwargs)\n    elif shap_method == _ShapMethod.DEEP:\n        explainer = shap.LinearExplainer(model_sklearn, background_X, **kwargs)\n    elif shap_method == _ShapMethod.ADDITIVE:\n        explainer = shap.AdditiveExplainer(model_sklearn, background_X, **kwargs)\n    else:\n        raise ValueError('shap_method must be one of the following: ' + ', '.join([e.value for e in _ShapMethod]))\n    logger.info('The shap method used is of type: ' + str(type(explainer)))\n    return explainer"
        ]
    },
    {
        "func_name": "_create_regression_model_shap_X",
        "original": "def _create_regression_model_shap_X(self, target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]], past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]], future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]], n_samples: Optional[int]=None, train: bool=False) -> pd.DataFrame:\n    \"\"\"\n        Creates the shap format input for regression models.\n        The output is a pandas DataFrame representing all lags of different covariates, and with adequate\n        column names in order to map feature / shap values.\n        It uses create_lagged_data also used in RegressionModel to build the tabular dataset.\n\n        \"\"\"\n    lags_list = self.model._get_lags('target')\n    lags_past_covariates_list = self.model._get_lags('past')\n    lags_future_covariates_list = self.model._get_lags('future')\n    (X, indexes) = create_lagged_prediction_data(target_series=target_series if lags_list else None, past_covariates=past_covariates if lags_past_covariates_list else None, future_covariates=future_covariates if lags_future_covariates_list else None, lags=lags_list, lags_past_covariates=lags_past_covariates_list if past_covariates else None, lags_future_covariates=lags_future_covariates_list if future_covariates else None, uses_static_covariates=self.model.uses_static_covariates, last_static_covariates_shape=self.model._static_covariates_shape)\n    X = X[:, :, 0]\n    if train:\n        X = pd.DataFrame(X)\n        if len(X) <= MIN_BACKGROUND_SAMPLE:\n            raise_log(ValueError('The number of samples in the background dataset is too small to compute shap values.'))\n    else:\n        X = pd.DataFrame(X, index=indexes[0])\n    if n_samples:\n        X = shap.utils.sample(X, n_samples)\n    X = X.rename(columns={name: self.model.lagged_feature_names[idx] for (idx, name) in enumerate(X.columns.to_list())})\n    return X",
        "mutated": [
            "def _create_regression_model_shap_X(self, target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]], past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]], future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]], n_samples: Optional[int]=None, train: bool=False) -> pd.DataFrame:\n    if False:\n        i = 10\n    '\\n        Creates the shap format input for regression models.\\n        The output is a pandas DataFrame representing all lags of different covariates, and with adequate\\n        column names in order to map feature / shap values.\\n        It uses create_lagged_data also used in RegressionModel to build the tabular dataset.\\n\\n        '\n    lags_list = self.model._get_lags('target')\n    lags_past_covariates_list = self.model._get_lags('past')\n    lags_future_covariates_list = self.model._get_lags('future')\n    (X, indexes) = create_lagged_prediction_data(target_series=target_series if lags_list else None, past_covariates=past_covariates if lags_past_covariates_list else None, future_covariates=future_covariates if lags_future_covariates_list else None, lags=lags_list, lags_past_covariates=lags_past_covariates_list if past_covariates else None, lags_future_covariates=lags_future_covariates_list if future_covariates else None, uses_static_covariates=self.model.uses_static_covariates, last_static_covariates_shape=self.model._static_covariates_shape)\n    X = X[:, :, 0]\n    if train:\n        X = pd.DataFrame(X)\n        if len(X) <= MIN_BACKGROUND_SAMPLE:\n            raise_log(ValueError('The number of samples in the background dataset is too small to compute shap values.'))\n    else:\n        X = pd.DataFrame(X, index=indexes[0])\n    if n_samples:\n        X = shap.utils.sample(X, n_samples)\n    X = X.rename(columns={name: self.model.lagged_feature_names[idx] for (idx, name) in enumerate(X.columns.to_list())})\n    return X",
            "def _create_regression_model_shap_X(self, target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]], past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]], future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]], n_samples: Optional[int]=None, train: bool=False) -> pd.DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Creates the shap format input for regression models.\\n        The output is a pandas DataFrame representing all lags of different covariates, and with adequate\\n        column names in order to map feature / shap values.\\n        It uses create_lagged_data also used in RegressionModel to build the tabular dataset.\\n\\n        '\n    lags_list = self.model._get_lags('target')\n    lags_past_covariates_list = self.model._get_lags('past')\n    lags_future_covariates_list = self.model._get_lags('future')\n    (X, indexes) = create_lagged_prediction_data(target_series=target_series if lags_list else None, past_covariates=past_covariates if lags_past_covariates_list else None, future_covariates=future_covariates if lags_future_covariates_list else None, lags=lags_list, lags_past_covariates=lags_past_covariates_list if past_covariates else None, lags_future_covariates=lags_future_covariates_list if future_covariates else None, uses_static_covariates=self.model.uses_static_covariates, last_static_covariates_shape=self.model._static_covariates_shape)\n    X = X[:, :, 0]\n    if train:\n        X = pd.DataFrame(X)\n        if len(X) <= MIN_BACKGROUND_SAMPLE:\n            raise_log(ValueError('The number of samples in the background dataset is too small to compute shap values.'))\n    else:\n        X = pd.DataFrame(X, index=indexes[0])\n    if n_samples:\n        X = shap.utils.sample(X, n_samples)\n    X = X.rename(columns={name: self.model.lagged_feature_names[idx] for (idx, name) in enumerate(X.columns.to_list())})\n    return X",
            "def _create_regression_model_shap_X(self, target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]], past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]], future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]], n_samples: Optional[int]=None, train: bool=False) -> pd.DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Creates the shap format input for regression models.\\n        The output is a pandas DataFrame representing all lags of different covariates, and with adequate\\n        column names in order to map feature / shap values.\\n        It uses create_lagged_data also used in RegressionModel to build the tabular dataset.\\n\\n        '\n    lags_list = self.model._get_lags('target')\n    lags_past_covariates_list = self.model._get_lags('past')\n    lags_future_covariates_list = self.model._get_lags('future')\n    (X, indexes) = create_lagged_prediction_data(target_series=target_series if lags_list else None, past_covariates=past_covariates if lags_past_covariates_list else None, future_covariates=future_covariates if lags_future_covariates_list else None, lags=lags_list, lags_past_covariates=lags_past_covariates_list if past_covariates else None, lags_future_covariates=lags_future_covariates_list if future_covariates else None, uses_static_covariates=self.model.uses_static_covariates, last_static_covariates_shape=self.model._static_covariates_shape)\n    X = X[:, :, 0]\n    if train:\n        X = pd.DataFrame(X)\n        if len(X) <= MIN_BACKGROUND_SAMPLE:\n            raise_log(ValueError('The number of samples in the background dataset is too small to compute shap values.'))\n    else:\n        X = pd.DataFrame(X, index=indexes[0])\n    if n_samples:\n        X = shap.utils.sample(X, n_samples)\n    X = X.rename(columns={name: self.model.lagged_feature_names[idx] for (idx, name) in enumerate(X.columns.to_list())})\n    return X",
            "def _create_regression_model_shap_X(self, target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]], past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]], future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]], n_samples: Optional[int]=None, train: bool=False) -> pd.DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Creates the shap format input for regression models.\\n        The output is a pandas DataFrame representing all lags of different covariates, and with adequate\\n        column names in order to map feature / shap values.\\n        It uses create_lagged_data also used in RegressionModel to build the tabular dataset.\\n\\n        '\n    lags_list = self.model._get_lags('target')\n    lags_past_covariates_list = self.model._get_lags('past')\n    lags_future_covariates_list = self.model._get_lags('future')\n    (X, indexes) = create_lagged_prediction_data(target_series=target_series if lags_list else None, past_covariates=past_covariates if lags_past_covariates_list else None, future_covariates=future_covariates if lags_future_covariates_list else None, lags=lags_list, lags_past_covariates=lags_past_covariates_list if past_covariates else None, lags_future_covariates=lags_future_covariates_list if future_covariates else None, uses_static_covariates=self.model.uses_static_covariates, last_static_covariates_shape=self.model._static_covariates_shape)\n    X = X[:, :, 0]\n    if train:\n        X = pd.DataFrame(X)\n        if len(X) <= MIN_BACKGROUND_SAMPLE:\n            raise_log(ValueError('The number of samples in the background dataset is too small to compute shap values.'))\n    else:\n        X = pd.DataFrame(X, index=indexes[0])\n    if n_samples:\n        X = shap.utils.sample(X, n_samples)\n    X = X.rename(columns={name: self.model.lagged_feature_names[idx] for (idx, name) in enumerate(X.columns.to_list())})\n    return X",
            "def _create_regression_model_shap_X(self, target_series: Optional[Union[TimeSeries, Sequence[TimeSeries]]], past_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]], future_covariates: Optional[Union[TimeSeries, Sequence[TimeSeries]]], n_samples: Optional[int]=None, train: bool=False) -> pd.DataFrame:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Creates the shap format input for regression models.\\n        The output is a pandas DataFrame representing all lags of different covariates, and with adequate\\n        column names in order to map feature / shap values.\\n        It uses create_lagged_data also used in RegressionModel to build the tabular dataset.\\n\\n        '\n    lags_list = self.model._get_lags('target')\n    lags_past_covariates_list = self.model._get_lags('past')\n    lags_future_covariates_list = self.model._get_lags('future')\n    (X, indexes) = create_lagged_prediction_data(target_series=target_series if lags_list else None, past_covariates=past_covariates if lags_past_covariates_list else None, future_covariates=future_covariates if lags_future_covariates_list else None, lags=lags_list, lags_past_covariates=lags_past_covariates_list if past_covariates else None, lags_future_covariates=lags_future_covariates_list if future_covariates else None, uses_static_covariates=self.model.uses_static_covariates, last_static_covariates_shape=self.model._static_covariates_shape)\n    X = X[:, :, 0]\n    if train:\n        X = pd.DataFrame(X)\n        if len(X) <= MIN_BACKGROUND_SAMPLE:\n            raise_log(ValueError('The number of samples in the background dataset is too small to compute shap values.'))\n    else:\n        X = pd.DataFrame(X, index=indexes[0])\n    if n_samples:\n        X = shap.utils.sample(X, n_samples)\n    X = X.rename(columns={name: self.model.lagged_feature_names[idx] for (idx, name) in enumerate(X.columns.to_list())})\n    return X"
        ]
    }
]