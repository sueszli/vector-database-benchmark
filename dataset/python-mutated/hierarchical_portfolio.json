[
    {
        "func_name": "__init__",
        "original": "def __init__(self, returns=None, cov_matrix=None):\n    \"\"\"\n        :param returns: asset historical returns\n        :type returns: pd.DataFrame\n        :param cov_matrix: covariance of asset returns\n        :type cov_matrix: pd.DataFrame.\n        :raises TypeError: if ``returns`` is not a dataframe\n        \"\"\"\n    if returns is None and cov_matrix is None:\n        raise ValueError('Either returns or cov_matrix must be provided')\n    if returns is not None and (not isinstance(returns, pd.DataFrame)):\n        raise TypeError('returns are not a dataframe')\n    self.returns = returns\n    self.cov_matrix = cov_matrix\n    self.clusters = None\n    if returns is None:\n        tickers = list(cov_matrix.columns)\n    else:\n        tickers = list(returns.columns)\n    super().__init__(len(tickers), tickers)",
        "mutated": [
            "def __init__(self, returns=None, cov_matrix=None):\n    if False:\n        i = 10\n    '\\n        :param returns: asset historical returns\\n        :type returns: pd.DataFrame\\n        :param cov_matrix: covariance of asset returns\\n        :type cov_matrix: pd.DataFrame.\\n        :raises TypeError: if ``returns`` is not a dataframe\\n        '\n    if returns is None and cov_matrix is None:\n        raise ValueError('Either returns or cov_matrix must be provided')\n    if returns is not None and (not isinstance(returns, pd.DataFrame)):\n        raise TypeError('returns are not a dataframe')\n    self.returns = returns\n    self.cov_matrix = cov_matrix\n    self.clusters = None\n    if returns is None:\n        tickers = list(cov_matrix.columns)\n    else:\n        tickers = list(returns.columns)\n    super().__init__(len(tickers), tickers)",
            "def __init__(self, returns=None, cov_matrix=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        :param returns: asset historical returns\\n        :type returns: pd.DataFrame\\n        :param cov_matrix: covariance of asset returns\\n        :type cov_matrix: pd.DataFrame.\\n        :raises TypeError: if ``returns`` is not a dataframe\\n        '\n    if returns is None and cov_matrix is None:\n        raise ValueError('Either returns or cov_matrix must be provided')\n    if returns is not None and (not isinstance(returns, pd.DataFrame)):\n        raise TypeError('returns are not a dataframe')\n    self.returns = returns\n    self.cov_matrix = cov_matrix\n    self.clusters = None\n    if returns is None:\n        tickers = list(cov_matrix.columns)\n    else:\n        tickers = list(returns.columns)\n    super().__init__(len(tickers), tickers)",
            "def __init__(self, returns=None, cov_matrix=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        :param returns: asset historical returns\\n        :type returns: pd.DataFrame\\n        :param cov_matrix: covariance of asset returns\\n        :type cov_matrix: pd.DataFrame.\\n        :raises TypeError: if ``returns`` is not a dataframe\\n        '\n    if returns is None and cov_matrix is None:\n        raise ValueError('Either returns or cov_matrix must be provided')\n    if returns is not None and (not isinstance(returns, pd.DataFrame)):\n        raise TypeError('returns are not a dataframe')\n    self.returns = returns\n    self.cov_matrix = cov_matrix\n    self.clusters = None\n    if returns is None:\n        tickers = list(cov_matrix.columns)\n    else:\n        tickers = list(returns.columns)\n    super().__init__(len(tickers), tickers)",
            "def __init__(self, returns=None, cov_matrix=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        :param returns: asset historical returns\\n        :type returns: pd.DataFrame\\n        :param cov_matrix: covariance of asset returns\\n        :type cov_matrix: pd.DataFrame.\\n        :raises TypeError: if ``returns`` is not a dataframe\\n        '\n    if returns is None and cov_matrix is None:\n        raise ValueError('Either returns or cov_matrix must be provided')\n    if returns is not None and (not isinstance(returns, pd.DataFrame)):\n        raise TypeError('returns are not a dataframe')\n    self.returns = returns\n    self.cov_matrix = cov_matrix\n    self.clusters = None\n    if returns is None:\n        tickers = list(cov_matrix.columns)\n    else:\n        tickers = list(returns.columns)\n    super().__init__(len(tickers), tickers)",
            "def __init__(self, returns=None, cov_matrix=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        :param returns: asset historical returns\\n        :type returns: pd.DataFrame\\n        :param cov_matrix: covariance of asset returns\\n        :type cov_matrix: pd.DataFrame.\\n        :raises TypeError: if ``returns`` is not a dataframe\\n        '\n    if returns is None and cov_matrix is None:\n        raise ValueError('Either returns or cov_matrix must be provided')\n    if returns is not None and (not isinstance(returns, pd.DataFrame)):\n        raise TypeError('returns are not a dataframe')\n    self.returns = returns\n    self.cov_matrix = cov_matrix\n    self.clusters = None\n    if returns is None:\n        tickers = list(cov_matrix.columns)\n    else:\n        tickers = list(returns.columns)\n    super().__init__(len(tickers), tickers)"
        ]
    },
    {
        "func_name": "_get_cluster_var",
        "original": "@staticmethod\ndef _get_cluster_var(cov, cluster_items):\n    \"\"\"\n        Compute the variance per cluster\n\n        :param cov: covariance matrix\n        :type cov: np.ndarray\n        :param cluster_items: tickers in the cluster\n        :type cluster_items: list\n        :return: the variance per cluster\n        :rtype: float\n        \"\"\"\n    cov_slice = cov.loc[cluster_items, cluster_items]\n    weights = 1 / np.diag(cov_slice)\n    weights /= weights.sum()\n    return np.linalg.multi_dot((weights, cov_slice, weights))",
        "mutated": [
            "@staticmethod\ndef _get_cluster_var(cov, cluster_items):\n    if False:\n        i = 10\n    '\\n        Compute the variance per cluster\\n\\n        :param cov: covariance matrix\\n        :type cov: np.ndarray\\n        :param cluster_items: tickers in the cluster\\n        :type cluster_items: list\\n        :return: the variance per cluster\\n        :rtype: float\\n        '\n    cov_slice = cov.loc[cluster_items, cluster_items]\n    weights = 1 / np.diag(cov_slice)\n    weights /= weights.sum()\n    return np.linalg.multi_dot((weights, cov_slice, weights))",
            "@staticmethod\ndef _get_cluster_var(cov, cluster_items):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Compute the variance per cluster\\n\\n        :param cov: covariance matrix\\n        :type cov: np.ndarray\\n        :param cluster_items: tickers in the cluster\\n        :type cluster_items: list\\n        :return: the variance per cluster\\n        :rtype: float\\n        '\n    cov_slice = cov.loc[cluster_items, cluster_items]\n    weights = 1 / np.diag(cov_slice)\n    weights /= weights.sum()\n    return np.linalg.multi_dot((weights, cov_slice, weights))",
            "@staticmethod\ndef _get_cluster_var(cov, cluster_items):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Compute the variance per cluster\\n\\n        :param cov: covariance matrix\\n        :type cov: np.ndarray\\n        :param cluster_items: tickers in the cluster\\n        :type cluster_items: list\\n        :return: the variance per cluster\\n        :rtype: float\\n        '\n    cov_slice = cov.loc[cluster_items, cluster_items]\n    weights = 1 / np.diag(cov_slice)\n    weights /= weights.sum()\n    return np.linalg.multi_dot((weights, cov_slice, weights))",
            "@staticmethod\ndef _get_cluster_var(cov, cluster_items):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Compute the variance per cluster\\n\\n        :param cov: covariance matrix\\n        :type cov: np.ndarray\\n        :param cluster_items: tickers in the cluster\\n        :type cluster_items: list\\n        :return: the variance per cluster\\n        :rtype: float\\n        '\n    cov_slice = cov.loc[cluster_items, cluster_items]\n    weights = 1 / np.diag(cov_slice)\n    weights /= weights.sum()\n    return np.linalg.multi_dot((weights, cov_slice, weights))",
            "@staticmethod\ndef _get_cluster_var(cov, cluster_items):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Compute the variance per cluster\\n\\n        :param cov: covariance matrix\\n        :type cov: np.ndarray\\n        :param cluster_items: tickers in the cluster\\n        :type cluster_items: list\\n        :return: the variance per cluster\\n        :rtype: float\\n        '\n    cov_slice = cov.loc[cluster_items, cluster_items]\n    weights = 1 / np.diag(cov_slice)\n    weights /= weights.sum()\n    return np.linalg.multi_dot((weights, cov_slice, weights))"
        ]
    },
    {
        "func_name": "_get_quasi_diag",
        "original": "@staticmethod\ndef _get_quasi_diag(link):\n    \"\"\"\n        Sort clustered items by distance\n\n        :param link: linkage matrix after clustering\n        :type link: np.ndarray\n        :return: sorted list of indices\n        :rtype: list\n        \"\"\"\n    return sch.to_tree(link, rd=False).pre_order()",
        "mutated": [
            "@staticmethod\ndef _get_quasi_diag(link):\n    if False:\n        i = 10\n    '\\n        Sort clustered items by distance\\n\\n        :param link: linkage matrix after clustering\\n        :type link: np.ndarray\\n        :return: sorted list of indices\\n        :rtype: list\\n        '\n    return sch.to_tree(link, rd=False).pre_order()",
            "@staticmethod\ndef _get_quasi_diag(link):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Sort clustered items by distance\\n\\n        :param link: linkage matrix after clustering\\n        :type link: np.ndarray\\n        :return: sorted list of indices\\n        :rtype: list\\n        '\n    return sch.to_tree(link, rd=False).pre_order()",
            "@staticmethod\ndef _get_quasi_diag(link):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Sort clustered items by distance\\n\\n        :param link: linkage matrix after clustering\\n        :type link: np.ndarray\\n        :return: sorted list of indices\\n        :rtype: list\\n        '\n    return sch.to_tree(link, rd=False).pre_order()",
            "@staticmethod\ndef _get_quasi_diag(link):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Sort clustered items by distance\\n\\n        :param link: linkage matrix after clustering\\n        :type link: np.ndarray\\n        :return: sorted list of indices\\n        :rtype: list\\n        '\n    return sch.to_tree(link, rd=False).pre_order()",
            "@staticmethod\ndef _get_quasi_diag(link):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Sort clustered items by distance\\n\\n        :param link: linkage matrix after clustering\\n        :type link: np.ndarray\\n        :return: sorted list of indices\\n        :rtype: list\\n        '\n    return sch.to_tree(link, rd=False).pre_order()"
        ]
    },
    {
        "func_name": "_raw_hrp_allocation",
        "original": "@staticmethod\ndef _raw_hrp_allocation(cov, ordered_tickers):\n    \"\"\"\n        Given the clusters, compute the portfolio that minimises risk by\n        recursively traversing the hierarchical tree from the top.\n\n        :param cov: covariance matrix\n        :type cov: np.ndarray\n        :param ordered_tickers: list of tickers ordered by distance\n        :type ordered_tickers: str list\n        :return: raw portfolio weights\n        :rtype: pd.Series\n        \"\"\"\n    w = pd.Series(1, index=ordered_tickers)\n    cluster_items = [ordered_tickers]\n    while len(cluster_items) > 0:\n        cluster_items = [i[j:k] for i in cluster_items for (j, k) in ((0, len(i) // 2), (len(i) // 2, len(i))) if len(i) > 1]\n        for i in range(0, len(cluster_items), 2):\n            first_cluster = cluster_items[i]\n            second_cluster = cluster_items[i + 1]\n            first_variance = HRPOpt._get_cluster_var(cov, first_cluster)\n            second_variance = HRPOpt._get_cluster_var(cov, second_cluster)\n            alpha = 1 - first_variance / (first_variance + second_variance)\n            w[first_cluster] *= alpha\n            w[second_cluster] *= 1 - alpha\n    return w",
        "mutated": [
            "@staticmethod\ndef _raw_hrp_allocation(cov, ordered_tickers):\n    if False:\n        i = 10\n    '\\n        Given the clusters, compute the portfolio that minimises risk by\\n        recursively traversing the hierarchical tree from the top.\\n\\n        :param cov: covariance matrix\\n        :type cov: np.ndarray\\n        :param ordered_tickers: list of tickers ordered by distance\\n        :type ordered_tickers: str list\\n        :return: raw portfolio weights\\n        :rtype: pd.Series\\n        '\n    w = pd.Series(1, index=ordered_tickers)\n    cluster_items = [ordered_tickers]\n    while len(cluster_items) > 0:\n        cluster_items = [i[j:k] for i in cluster_items for (j, k) in ((0, len(i) // 2), (len(i) // 2, len(i))) if len(i) > 1]\n        for i in range(0, len(cluster_items), 2):\n            first_cluster = cluster_items[i]\n            second_cluster = cluster_items[i + 1]\n            first_variance = HRPOpt._get_cluster_var(cov, first_cluster)\n            second_variance = HRPOpt._get_cluster_var(cov, second_cluster)\n            alpha = 1 - first_variance / (first_variance + second_variance)\n            w[first_cluster] *= alpha\n            w[second_cluster] *= 1 - alpha\n    return w",
            "@staticmethod\ndef _raw_hrp_allocation(cov, ordered_tickers):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Given the clusters, compute the portfolio that minimises risk by\\n        recursively traversing the hierarchical tree from the top.\\n\\n        :param cov: covariance matrix\\n        :type cov: np.ndarray\\n        :param ordered_tickers: list of tickers ordered by distance\\n        :type ordered_tickers: str list\\n        :return: raw portfolio weights\\n        :rtype: pd.Series\\n        '\n    w = pd.Series(1, index=ordered_tickers)\n    cluster_items = [ordered_tickers]\n    while len(cluster_items) > 0:\n        cluster_items = [i[j:k] for i in cluster_items for (j, k) in ((0, len(i) // 2), (len(i) // 2, len(i))) if len(i) > 1]\n        for i in range(0, len(cluster_items), 2):\n            first_cluster = cluster_items[i]\n            second_cluster = cluster_items[i + 1]\n            first_variance = HRPOpt._get_cluster_var(cov, first_cluster)\n            second_variance = HRPOpt._get_cluster_var(cov, second_cluster)\n            alpha = 1 - first_variance / (first_variance + second_variance)\n            w[first_cluster] *= alpha\n            w[second_cluster] *= 1 - alpha\n    return w",
            "@staticmethod\ndef _raw_hrp_allocation(cov, ordered_tickers):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Given the clusters, compute the portfolio that minimises risk by\\n        recursively traversing the hierarchical tree from the top.\\n\\n        :param cov: covariance matrix\\n        :type cov: np.ndarray\\n        :param ordered_tickers: list of tickers ordered by distance\\n        :type ordered_tickers: str list\\n        :return: raw portfolio weights\\n        :rtype: pd.Series\\n        '\n    w = pd.Series(1, index=ordered_tickers)\n    cluster_items = [ordered_tickers]\n    while len(cluster_items) > 0:\n        cluster_items = [i[j:k] for i in cluster_items for (j, k) in ((0, len(i) // 2), (len(i) // 2, len(i))) if len(i) > 1]\n        for i in range(0, len(cluster_items), 2):\n            first_cluster = cluster_items[i]\n            second_cluster = cluster_items[i + 1]\n            first_variance = HRPOpt._get_cluster_var(cov, first_cluster)\n            second_variance = HRPOpt._get_cluster_var(cov, second_cluster)\n            alpha = 1 - first_variance / (first_variance + second_variance)\n            w[first_cluster] *= alpha\n            w[second_cluster] *= 1 - alpha\n    return w",
            "@staticmethod\ndef _raw_hrp_allocation(cov, ordered_tickers):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Given the clusters, compute the portfolio that minimises risk by\\n        recursively traversing the hierarchical tree from the top.\\n\\n        :param cov: covariance matrix\\n        :type cov: np.ndarray\\n        :param ordered_tickers: list of tickers ordered by distance\\n        :type ordered_tickers: str list\\n        :return: raw portfolio weights\\n        :rtype: pd.Series\\n        '\n    w = pd.Series(1, index=ordered_tickers)\n    cluster_items = [ordered_tickers]\n    while len(cluster_items) > 0:\n        cluster_items = [i[j:k] for i in cluster_items for (j, k) in ((0, len(i) // 2), (len(i) // 2, len(i))) if len(i) > 1]\n        for i in range(0, len(cluster_items), 2):\n            first_cluster = cluster_items[i]\n            second_cluster = cluster_items[i + 1]\n            first_variance = HRPOpt._get_cluster_var(cov, first_cluster)\n            second_variance = HRPOpt._get_cluster_var(cov, second_cluster)\n            alpha = 1 - first_variance / (first_variance + second_variance)\n            w[first_cluster] *= alpha\n            w[second_cluster] *= 1 - alpha\n    return w",
            "@staticmethod\ndef _raw_hrp_allocation(cov, ordered_tickers):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Given the clusters, compute the portfolio that minimises risk by\\n        recursively traversing the hierarchical tree from the top.\\n\\n        :param cov: covariance matrix\\n        :type cov: np.ndarray\\n        :param ordered_tickers: list of tickers ordered by distance\\n        :type ordered_tickers: str list\\n        :return: raw portfolio weights\\n        :rtype: pd.Series\\n        '\n    w = pd.Series(1, index=ordered_tickers)\n    cluster_items = [ordered_tickers]\n    while len(cluster_items) > 0:\n        cluster_items = [i[j:k] for i in cluster_items for (j, k) in ((0, len(i) // 2), (len(i) // 2, len(i))) if len(i) > 1]\n        for i in range(0, len(cluster_items), 2):\n            first_cluster = cluster_items[i]\n            second_cluster = cluster_items[i + 1]\n            first_variance = HRPOpt._get_cluster_var(cov, first_cluster)\n            second_variance = HRPOpt._get_cluster_var(cov, second_cluster)\n            alpha = 1 - first_variance / (first_variance + second_variance)\n            w[first_cluster] *= alpha\n            w[second_cluster] *= 1 - alpha\n    return w"
        ]
    },
    {
        "func_name": "optimize",
        "original": "def optimize(self, linkage_method='single'):\n    \"\"\"\n        Construct a hierarchical risk parity portfolio, using Scipy hierarchical clustering\n        (see `here <https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html>`_)\n\n        :param linkage_method: which scipy linkage method to use\n        :type linkage_method: str\n        :return: weights for the HRP portfolio\n        :rtype: OrderedDict\n        \"\"\"\n    if linkage_method not in sch._LINKAGE_METHODS:\n        raise ValueError('linkage_method must be one recognised by scipy')\n    if self.returns is None:\n        cov = self.cov_matrix\n        corr = risk_models.cov_to_corr(self.cov_matrix).round(6)\n    else:\n        (corr, cov) = (self.returns.corr(), self.returns.cov())\n    matrix = np.sqrt(np.clip((1.0 - corr) / 2.0, a_min=0.0, a_max=1.0))\n    dist = ssd.squareform(matrix, checks=False)\n    self.clusters = sch.linkage(dist, linkage_method)\n    sort_ix = HRPOpt._get_quasi_diag(self.clusters)\n    ordered_tickers = corr.index[sort_ix].tolist()\n    hrp = HRPOpt._raw_hrp_allocation(cov, ordered_tickers)\n    weights = collections.OrderedDict(hrp.sort_index())\n    self.set_weights(weights)\n    return weights",
        "mutated": [
            "def optimize(self, linkage_method='single'):\n    if False:\n        i = 10\n    '\\n        Construct a hierarchical risk parity portfolio, using Scipy hierarchical clustering\\n        (see `here <https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html>`_)\\n\\n        :param linkage_method: which scipy linkage method to use\\n        :type linkage_method: str\\n        :return: weights for the HRP portfolio\\n        :rtype: OrderedDict\\n        '\n    if linkage_method not in sch._LINKAGE_METHODS:\n        raise ValueError('linkage_method must be one recognised by scipy')\n    if self.returns is None:\n        cov = self.cov_matrix\n        corr = risk_models.cov_to_corr(self.cov_matrix).round(6)\n    else:\n        (corr, cov) = (self.returns.corr(), self.returns.cov())\n    matrix = np.sqrt(np.clip((1.0 - corr) / 2.0, a_min=0.0, a_max=1.0))\n    dist = ssd.squareform(matrix, checks=False)\n    self.clusters = sch.linkage(dist, linkage_method)\n    sort_ix = HRPOpt._get_quasi_diag(self.clusters)\n    ordered_tickers = corr.index[sort_ix].tolist()\n    hrp = HRPOpt._raw_hrp_allocation(cov, ordered_tickers)\n    weights = collections.OrderedDict(hrp.sort_index())\n    self.set_weights(weights)\n    return weights",
            "def optimize(self, linkage_method='single'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Construct a hierarchical risk parity portfolio, using Scipy hierarchical clustering\\n        (see `here <https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html>`_)\\n\\n        :param linkage_method: which scipy linkage method to use\\n        :type linkage_method: str\\n        :return: weights for the HRP portfolio\\n        :rtype: OrderedDict\\n        '\n    if linkage_method not in sch._LINKAGE_METHODS:\n        raise ValueError('linkage_method must be one recognised by scipy')\n    if self.returns is None:\n        cov = self.cov_matrix\n        corr = risk_models.cov_to_corr(self.cov_matrix).round(6)\n    else:\n        (corr, cov) = (self.returns.corr(), self.returns.cov())\n    matrix = np.sqrt(np.clip((1.0 - corr) / 2.0, a_min=0.0, a_max=1.0))\n    dist = ssd.squareform(matrix, checks=False)\n    self.clusters = sch.linkage(dist, linkage_method)\n    sort_ix = HRPOpt._get_quasi_diag(self.clusters)\n    ordered_tickers = corr.index[sort_ix].tolist()\n    hrp = HRPOpt._raw_hrp_allocation(cov, ordered_tickers)\n    weights = collections.OrderedDict(hrp.sort_index())\n    self.set_weights(weights)\n    return weights",
            "def optimize(self, linkage_method='single'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Construct a hierarchical risk parity portfolio, using Scipy hierarchical clustering\\n        (see `here <https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html>`_)\\n\\n        :param linkage_method: which scipy linkage method to use\\n        :type linkage_method: str\\n        :return: weights for the HRP portfolio\\n        :rtype: OrderedDict\\n        '\n    if linkage_method not in sch._LINKAGE_METHODS:\n        raise ValueError('linkage_method must be one recognised by scipy')\n    if self.returns is None:\n        cov = self.cov_matrix\n        corr = risk_models.cov_to_corr(self.cov_matrix).round(6)\n    else:\n        (corr, cov) = (self.returns.corr(), self.returns.cov())\n    matrix = np.sqrt(np.clip((1.0 - corr) / 2.0, a_min=0.0, a_max=1.0))\n    dist = ssd.squareform(matrix, checks=False)\n    self.clusters = sch.linkage(dist, linkage_method)\n    sort_ix = HRPOpt._get_quasi_diag(self.clusters)\n    ordered_tickers = corr.index[sort_ix].tolist()\n    hrp = HRPOpt._raw_hrp_allocation(cov, ordered_tickers)\n    weights = collections.OrderedDict(hrp.sort_index())\n    self.set_weights(weights)\n    return weights",
            "def optimize(self, linkage_method='single'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Construct a hierarchical risk parity portfolio, using Scipy hierarchical clustering\\n        (see `here <https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html>`_)\\n\\n        :param linkage_method: which scipy linkage method to use\\n        :type linkage_method: str\\n        :return: weights for the HRP portfolio\\n        :rtype: OrderedDict\\n        '\n    if linkage_method not in sch._LINKAGE_METHODS:\n        raise ValueError('linkage_method must be one recognised by scipy')\n    if self.returns is None:\n        cov = self.cov_matrix\n        corr = risk_models.cov_to_corr(self.cov_matrix).round(6)\n    else:\n        (corr, cov) = (self.returns.corr(), self.returns.cov())\n    matrix = np.sqrt(np.clip((1.0 - corr) / 2.0, a_min=0.0, a_max=1.0))\n    dist = ssd.squareform(matrix, checks=False)\n    self.clusters = sch.linkage(dist, linkage_method)\n    sort_ix = HRPOpt._get_quasi_diag(self.clusters)\n    ordered_tickers = corr.index[sort_ix].tolist()\n    hrp = HRPOpt._raw_hrp_allocation(cov, ordered_tickers)\n    weights = collections.OrderedDict(hrp.sort_index())\n    self.set_weights(weights)\n    return weights",
            "def optimize(self, linkage_method='single'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Construct a hierarchical risk parity portfolio, using Scipy hierarchical clustering\\n        (see `here <https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html>`_)\\n\\n        :param linkage_method: which scipy linkage method to use\\n        :type linkage_method: str\\n        :return: weights for the HRP portfolio\\n        :rtype: OrderedDict\\n        '\n    if linkage_method not in sch._LINKAGE_METHODS:\n        raise ValueError('linkage_method must be one recognised by scipy')\n    if self.returns is None:\n        cov = self.cov_matrix\n        corr = risk_models.cov_to_corr(self.cov_matrix).round(6)\n    else:\n        (corr, cov) = (self.returns.corr(), self.returns.cov())\n    matrix = np.sqrt(np.clip((1.0 - corr) / 2.0, a_min=0.0, a_max=1.0))\n    dist = ssd.squareform(matrix, checks=False)\n    self.clusters = sch.linkage(dist, linkage_method)\n    sort_ix = HRPOpt._get_quasi_diag(self.clusters)\n    ordered_tickers = corr.index[sort_ix].tolist()\n    hrp = HRPOpt._raw_hrp_allocation(cov, ordered_tickers)\n    weights = collections.OrderedDict(hrp.sort_index())\n    self.set_weights(weights)\n    return weights"
        ]
    },
    {
        "func_name": "portfolio_performance",
        "original": "def portfolio_performance(self, verbose=False, risk_free_rate=0.02, frequency=252):\n    \"\"\"\n        After optimising, calculate (and optionally print) the performance of the optimal\n        portfolio. Currently calculates expected return, volatility, and the Sharpe ratio\n        assuming returns are daily\n\n        :param verbose: whether performance should be printed, defaults to False\n        :type verbose: bool, optional\n        :param risk_free_rate: risk-free rate of borrowing/lending, defaults to 0.02.\n                               The period of the risk-free rate should correspond to the\n                               frequency of expected returns.\n        :type risk_free_rate: float, optional\n        :param frequency: number of time periods in a year, defaults to 252 (the number\n                            of trading days in a year)\n        :type frequency: int, optional\n        :raises ValueError: if weights have not been calculated yet\n        :return: expected return, volatility, Sharpe ratio.\n        :rtype: (float, float, float)\n        \"\"\"\n    if self.returns is None:\n        cov = self.cov_matrix\n        mu = None\n    else:\n        cov = self.returns.cov() * frequency\n        mu = self.returns.mean() * frequency\n    return base_optimizer.portfolio_performance(self.weights, mu, cov, verbose, risk_free_rate)",
        "mutated": [
            "def portfolio_performance(self, verbose=False, risk_free_rate=0.02, frequency=252):\n    if False:\n        i = 10\n    '\\n        After optimising, calculate (and optionally print) the performance of the optimal\\n        portfolio. Currently calculates expected return, volatility, and the Sharpe ratio\\n        assuming returns are daily\\n\\n        :param verbose: whether performance should be printed, defaults to False\\n        :type verbose: bool, optional\\n        :param risk_free_rate: risk-free rate of borrowing/lending, defaults to 0.02.\\n                               The period of the risk-free rate should correspond to the\\n                               frequency of expected returns.\\n        :type risk_free_rate: float, optional\\n        :param frequency: number of time periods in a year, defaults to 252 (the number\\n                            of trading days in a year)\\n        :type frequency: int, optional\\n        :raises ValueError: if weights have not been calculated yet\\n        :return: expected return, volatility, Sharpe ratio.\\n        :rtype: (float, float, float)\\n        '\n    if self.returns is None:\n        cov = self.cov_matrix\n        mu = None\n    else:\n        cov = self.returns.cov() * frequency\n        mu = self.returns.mean() * frequency\n    return base_optimizer.portfolio_performance(self.weights, mu, cov, verbose, risk_free_rate)",
            "def portfolio_performance(self, verbose=False, risk_free_rate=0.02, frequency=252):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        After optimising, calculate (and optionally print) the performance of the optimal\\n        portfolio. Currently calculates expected return, volatility, and the Sharpe ratio\\n        assuming returns are daily\\n\\n        :param verbose: whether performance should be printed, defaults to False\\n        :type verbose: bool, optional\\n        :param risk_free_rate: risk-free rate of borrowing/lending, defaults to 0.02.\\n                               The period of the risk-free rate should correspond to the\\n                               frequency of expected returns.\\n        :type risk_free_rate: float, optional\\n        :param frequency: number of time periods in a year, defaults to 252 (the number\\n                            of trading days in a year)\\n        :type frequency: int, optional\\n        :raises ValueError: if weights have not been calculated yet\\n        :return: expected return, volatility, Sharpe ratio.\\n        :rtype: (float, float, float)\\n        '\n    if self.returns is None:\n        cov = self.cov_matrix\n        mu = None\n    else:\n        cov = self.returns.cov() * frequency\n        mu = self.returns.mean() * frequency\n    return base_optimizer.portfolio_performance(self.weights, mu, cov, verbose, risk_free_rate)",
            "def portfolio_performance(self, verbose=False, risk_free_rate=0.02, frequency=252):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        After optimising, calculate (and optionally print) the performance of the optimal\\n        portfolio. Currently calculates expected return, volatility, and the Sharpe ratio\\n        assuming returns are daily\\n\\n        :param verbose: whether performance should be printed, defaults to False\\n        :type verbose: bool, optional\\n        :param risk_free_rate: risk-free rate of borrowing/lending, defaults to 0.02.\\n                               The period of the risk-free rate should correspond to the\\n                               frequency of expected returns.\\n        :type risk_free_rate: float, optional\\n        :param frequency: number of time periods in a year, defaults to 252 (the number\\n                            of trading days in a year)\\n        :type frequency: int, optional\\n        :raises ValueError: if weights have not been calculated yet\\n        :return: expected return, volatility, Sharpe ratio.\\n        :rtype: (float, float, float)\\n        '\n    if self.returns is None:\n        cov = self.cov_matrix\n        mu = None\n    else:\n        cov = self.returns.cov() * frequency\n        mu = self.returns.mean() * frequency\n    return base_optimizer.portfolio_performance(self.weights, mu, cov, verbose, risk_free_rate)",
            "def portfolio_performance(self, verbose=False, risk_free_rate=0.02, frequency=252):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        After optimising, calculate (and optionally print) the performance of the optimal\\n        portfolio. Currently calculates expected return, volatility, and the Sharpe ratio\\n        assuming returns are daily\\n\\n        :param verbose: whether performance should be printed, defaults to False\\n        :type verbose: bool, optional\\n        :param risk_free_rate: risk-free rate of borrowing/lending, defaults to 0.02.\\n                               The period of the risk-free rate should correspond to the\\n                               frequency of expected returns.\\n        :type risk_free_rate: float, optional\\n        :param frequency: number of time periods in a year, defaults to 252 (the number\\n                            of trading days in a year)\\n        :type frequency: int, optional\\n        :raises ValueError: if weights have not been calculated yet\\n        :return: expected return, volatility, Sharpe ratio.\\n        :rtype: (float, float, float)\\n        '\n    if self.returns is None:\n        cov = self.cov_matrix\n        mu = None\n    else:\n        cov = self.returns.cov() * frequency\n        mu = self.returns.mean() * frequency\n    return base_optimizer.portfolio_performance(self.weights, mu, cov, verbose, risk_free_rate)",
            "def portfolio_performance(self, verbose=False, risk_free_rate=0.02, frequency=252):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        After optimising, calculate (and optionally print) the performance of the optimal\\n        portfolio. Currently calculates expected return, volatility, and the Sharpe ratio\\n        assuming returns are daily\\n\\n        :param verbose: whether performance should be printed, defaults to False\\n        :type verbose: bool, optional\\n        :param risk_free_rate: risk-free rate of borrowing/lending, defaults to 0.02.\\n                               The period of the risk-free rate should correspond to the\\n                               frequency of expected returns.\\n        :type risk_free_rate: float, optional\\n        :param frequency: number of time periods in a year, defaults to 252 (the number\\n                            of trading days in a year)\\n        :type frequency: int, optional\\n        :raises ValueError: if weights have not been calculated yet\\n        :return: expected return, volatility, Sharpe ratio.\\n        :rtype: (float, float, float)\\n        '\n    if self.returns is None:\n        cov = self.cov_matrix\n        mu = None\n    else:\n        cov = self.returns.cov() * frequency\n        mu = self.returns.mean() * frequency\n    return base_optimizer.portfolio_performance(self.weights, mu, cov, verbose, risk_free_rate)"
        ]
    }
]