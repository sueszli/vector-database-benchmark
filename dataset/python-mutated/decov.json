[
    {
        "func_name": "__init__",
        "original": "def __init__(self, reduce='half_squared_sum'):\n    self.h_centered = None\n    self.covariance = None\n    if reduce not in ('half_squared_sum', 'no'):\n        raise ValueError(\"only 'half_squared_sum' and 'no' are valid for 'reduce', but '%s' is given\" % reduce)\n    self.reduce = reduce",
        "mutated": [
            "def __init__(self, reduce='half_squared_sum'):\n    if False:\n        i = 10\n    self.h_centered = None\n    self.covariance = None\n    if reduce not in ('half_squared_sum', 'no'):\n        raise ValueError(\"only 'half_squared_sum' and 'no' are valid for 'reduce', but '%s' is given\" % reduce)\n    self.reduce = reduce",
            "def __init__(self, reduce='half_squared_sum'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.h_centered = None\n    self.covariance = None\n    if reduce not in ('half_squared_sum', 'no'):\n        raise ValueError(\"only 'half_squared_sum' and 'no' are valid for 'reduce', but '%s' is given\" % reduce)\n    self.reduce = reduce",
            "def __init__(self, reduce='half_squared_sum'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.h_centered = None\n    self.covariance = None\n    if reduce not in ('half_squared_sum', 'no'):\n        raise ValueError(\"only 'half_squared_sum' and 'no' are valid for 'reduce', but '%s' is given\" % reduce)\n    self.reduce = reduce",
            "def __init__(self, reduce='half_squared_sum'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.h_centered = None\n    self.covariance = None\n    if reduce not in ('half_squared_sum', 'no'):\n        raise ValueError(\"only 'half_squared_sum' and 'no' are valid for 'reduce', but '%s' is given\" % reduce)\n    self.reduce = reduce",
            "def __init__(self, reduce='half_squared_sum'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.h_centered = None\n    self.covariance = None\n    if reduce not in ('half_squared_sum', 'no'):\n        raise ValueError(\"only 'half_squared_sum' and 'no' are valid for 'reduce', but '%s' is given\" % reduce)\n    self.reduce = reduce"
        ]
    },
    {
        "func_name": "check_type_forward",
        "original": "def check_type_forward(self, in_types):\n    type_check._argname(in_types, ('h',))\n    (h_type,) = in_types\n    type_check.expect(h_type.dtype.kind == 'f', h_type.ndim == 2)",
        "mutated": [
            "def check_type_forward(self, in_types):\n    if False:\n        i = 10\n    type_check._argname(in_types, ('h',))\n    (h_type,) = in_types\n    type_check.expect(h_type.dtype.kind == 'f', h_type.ndim == 2)",
            "def check_type_forward(self, in_types):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    type_check._argname(in_types, ('h',))\n    (h_type,) = in_types\n    type_check.expect(h_type.dtype.kind == 'f', h_type.ndim == 2)",
            "def check_type_forward(self, in_types):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    type_check._argname(in_types, ('h',))\n    (h_type,) = in_types\n    type_check.expect(h_type.dtype.kind == 'f', h_type.ndim == 2)",
            "def check_type_forward(self, in_types):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    type_check._argname(in_types, ('h',))\n    (h_type,) = in_types\n    type_check.expect(h_type.dtype.kind == 'f', h_type.ndim == 2)",
            "def check_type_forward(self, in_types):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    type_check._argname(in_types, ('h',))\n    (h_type,) = in_types\n    type_check.expect(h_type.dtype.kind == 'f', h_type.ndim == 2)"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, inputs):\n    xp = backend.get_array_module(*inputs)\n    (h,) = inputs\n    self.h_centered = h - h.mean(axis=0, keepdims=True)\n    self.covariance = self.h_centered.T.dot(self.h_centered)\n    xp.fill_diagonal(self.covariance, 0.0)\n    self.covariance /= len(h)\n    if self.reduce == 'half_squared_sum':\n        cost = xp.vdot(self.covariance, self.covariance)\n        cost *= h.dtype.type(0.5)\n        return (utils.force_array(cost),)\n    else:\n        return (self.covariance,)",
        "mutated": [
            "def forward(self, inputs):\n    if False:\n        i = 10\n    xp = backend.get_array_module(*inputs)\n    (h,) = inputs\n    self.h_centered = h - h.mean(axis=0, keepdims=True)\n    self.covariance = self.h_centered.T.dot(self.h_centered)\n    xp.fill_diagonal(self.covariance, 0.0)\n    self.covariance /= len(h)\n    if self.reduce == 'half_squared_sum':\n        cost = xp.vdot(self.covariance, self.covariance)\n        cost *= h.dtype.type(0.5)\n        return (utils.force_array(cost),)\n    else:\n        return (self.covariance,)",
            "def forward(self, inputs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    xp = backend.get_array_module(*inputs)\n    (h,) = inputs\n    self.h_centered = h - h.mean(axis=0, keepdims=True)\n    self.covariance = self.h_centered.T.dot(self.h_centered)\n    xp.fill_diagonal(self.covariance, 0.0)\n    self.covariance /= len(h)\n    if self.reduce == 'half_squared_sum':\n        cost = xp.vdot(self.covariance, self.covariance)\n        cost *= h.dtype.type(0.5)\n        return (utils.force_array(cost),)\n    else:\n        return (self.covariance,)",
            "def forward(self, inputs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    xp = backend.get_array_module(*inputs)\n    (h,) = inputs\n    self.h_centered = h - h.mean(axis=0, keepdims=True)\n    self.covariance = self.h_centered.T.dot(self.h_centered)\n    xp.fill_diagonal(self.covariance, 0.0)\n    self.covariance /= len(h)\n    if self.reduce == 'half_squared_sum':\n        cost = xp.vdot(self.covariance, self.covariance)\n        cost *= h.dtype.type(0.5)\n        return (utils.force_array(cost),)\n    else:\n        return (self.covariance,)",
            "def forward(self, inputs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    xp = backend.get_array_module(*inputs)\n    (h,) = inputs\n    self.h_centered = h - h.mean(axis=0, keepdims=True)\n    self.covariance = self.h_centered.T.dot(self.h_centered)\n    xp.fill_diagonal(self.covariance, 0.0)\n    self.covariance /= len(h)\n    if self.reduce == 'half_squared_sum':\n        cost = xp.vdot(self.covariance, self.covariance)\n        cost *= h.dtype.type(0.5)\n        return (utils.force_array(cost),)\n    else:\n        return (self.covariance,)",
            "def forward(self, inputs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    xp = backend.get_array_module(*inputs)\n    (h,) = inputs\n    self.h_centered = h - h.mean(axis=0, keepdims=True)\n    self.covariance = self.h_centered.T.dot(self.h_centered)\n    xp.fill_diagonal(self.covariance, 0.0)\n    self.covariance /= len(h)\n    if self.reduce == 'half_squared_sum':\n        cost = xp.vdot(self.covariance, self.covariance)\n        cost *= h.dtype.type(0.5)\n        return (utils.force_array(cost),)\n    else:\n        return (self.covariance,)"
        ]
    },
    {
        "func_name": "backward",
        "original": "def backward(self, inputs, grad_outputs):\n    xp = backend.get_array_module(*inputs)\n    (h,) = inputs\n    (gcost,) = grad_outputs\n    gcost_div_n = gcost / gcost.dtype.type(len(h))\n    if self.reduce == 'half_squared_sum':\n        gh = 2.0 * self.h_centered.dot(self.covariance)\n        gh *= gcost_div_n\n    else:\n        xp.fill_diagonal(gcost_div_n, 0.0)\n        gh = self.h_centered.dot(gcost_div_n + gcost_div_n.T)\n    return (gh,)",
        "mutated": [
            "def backward(self, inputs, grad_outputs):\n    if False:\n        i = 10\n    xp = backend.get_array_module(*inputs)\n    (h,) = inputs\n    (gcost,) = grad_outputs\n    gcost_div_n = gcost / gcost.dtype.type(len(h))\n    if self.reduce == 'half_squared_sum':\n        gh = 2.0 * self.h_centered.dot(self.covariance)\n        gh *= gcost_div_n\n    else:\n        xp.fill_diagonal(gcost_div_n, 0.0)\n        gh = self.h_centered.dot(gcost_div_n + gcost_div_n.T)\n    return (gh,)",
            "def backward(self, inputs, grad_outputs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    xp = backend.get_array_module(*inputs)\n    (h,) = inputs\n    (gcost,) = grad_outputs\n    gcost_div_n = gcost / gcost.dtype.type(len(h))\n    if self.reduce == 'half_squared_sum':\n        gh = 2.0 * self.h_centered.dot(self.covariance)\n        gh *= gcost_div_n\n    else:\n        xp.fill_diagonal(gcost_div_n, 0.0)\n        gh = self.h_centered.dot(gcost_div_n + gcost_div_n.T)\n    return (gh,)",
            "def backward(self, inputs, grad_outputs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    xp = backend.get_array_module(*inputs)\n    (h,) = inputs\n    (gcost,) = grad_outputs\n    gcost_div_n = gcost / gcost.dtype.type(len(h))\n    if self.reduce == 'half_squared_sum':\n        gh = 2.0 * self.h_centered.dot(self.covariance)\n        gh *= gcost_div_n\n    else:\n        xp.fill_diagonal(gcost_div_n, 0.0)\n        gh = self.h_centered.dot(gcost_div_n + gcost_div_n.T)\n    return (gh,)",
            "def backward(self, inputs, grad_outputs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    xp = backend.get_array_module(*inputs)\n    (h,) = inputs\n    (gcost,) = grad_outputs\n    gcost_div_n = gcost / gcost.dtype.type(len(h))\n    if self.reduce == 'half_squared_sum':\n        gh = 2.0 * self.h_centered.dot(self.covariance)\n        gh *= gcost_div_n\n    else:\n        xp.fill_diagonal(gcost_div_n, 0.0)\n        gh = self.h_centered.dot(gcost_div_n + gcost_div_n.T)\n    return (gh,)",
            "def backward(self, inputs, grad_outputs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    xp = backend.get_array_module(*inputs)\n    (h,) = inputs\n    (gcost,) = grad_outputs\n    gcost_div_n = gcost / gcost.dtype.type(len(h))\n    if self.reduce == 'half_squared_sum':\n        gh = 2.0 * self.h_centered.dot(self.covariance)\n        gh *= gcost_div_n\n    else:\n        xp.fill_diagonal(gcost_div_n, 0.0)\n        gh = self.h_centered.dot(gcost_div_n + gcost_div_n.T)\n    return (gh,)"
        ]
    },
    {
        "func_name": "decov",
        "original": "def decov(h, reduce='half_squared_sum'):\n    \"\"\"Computes the DeCov loss of ``h``\n\n    The output is a variable whose value depends on the value of\n    the option ``reduce``. If it is ``'no'``, it holds a matrix\n    whose size is same as the number of columns of ``y``.\n    If it is ``'half_squared_sum'``, it holds the half of the\n    squared Frobenius norm (i.e. squared of the L2 norm of a matrix flattened\n    to a vector) of the matrix.\n\n    Args:\n        h (:class:`~chainer.Variable` or :ref:`ndarray`):\n            Variable holding a matrix where the first dimension\n            corresponds to the batches.\n        reduce (str): Reduction option. Its value must be either\n            ``'half_squared_sum'`` or ``'no'``.\n            Otherwise, :class:`ValueError` is raised.\n\n    Returns:\n        ~chainer.Variable:\n            A variable holding a scalar of the DeCov loss.\n            If ``reduce`` is ``'no'``, the output variable holds\n            2-dimensional array matrix of shape ``(N, N)`` where\n            ``N`` is the number of columns of ``y``.\n            If it is ``'half_squared_sum'``, the output variable\n            holds a scalar value.\n\n    .. note::\n\n       See https://arxiv.org/abs/1511.06068 for details.\n\n    \"\"\"\n    return DeCov(reduce)(h)",
        "mutated": [
            "def decov(h, reduce='half_squared_sum'):\n    if False:\n        i = 10\n    \"Computes the DeCov loss of ``h``\\n\\n    The output is a variable whose value depends on the value of\\n    the option ``reduce``. If it is ``'no'``, it holds a matrix\\n    whose size is same as the number of columns of ``y``.\\n    If it is ``'half_squared_sum'``, it holds the half of the\\n    squared Frobenius norm (i.e. squared of the L2 norm of a matrix flattened\\n    to a vector) of the matrix.\\n\\n    Args:\\n        h (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Variable holding a matrix where the first dimension\\n            corresponds to the batches.\\n        reduce (str): Reduction option. Its value must be either\\n            ``'half_squared_sum'`` or ``'no'``.\\n            Otherwise, :class:`ValueError` is raised.\\n\\n    Returns:\\n        ~chainer.Variable:\\n            A variable holding a scalar of the DeCov loss.\\n            If ``reduce`` is ``'no'``, the output variable holds\\n            2-dimensional array matrix of shape ``(N, N)`` where\\n            ``N`` is the number of columns of ``y``.\\n            If it is ``'half_squared_sum'``, the output variable\\n            holds a scalar value.\\n\\n    .. note::\\n\\n       See https://arxiv.org/abs/1511.06068 for details.\\n\\n    \"\n    return DeCov(reduce)(h)",
            "def decov(h, reduce='half_squared_sum'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Computes the DeCov loss of ``h``\\n\\n    The output is a variable whose value depends on the value of\\n    the option ``reduce``. If it is ``'no'``, it holds a matrix\\n    whose size is same as the number of columns of ``y``.\\n    If it is ``'half_squared_sum'``, it holds the half of the\\n    squared Frobenius norm (i.e. squared of the L2 norm of a matrix flattened\\n    to a vector) of the matrix.\\n\\n    Args:\\n        h (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Variable holding a matrix where the first dimension\\n            corresponds to the batches.\\n        reduce (str): Reduction option. Its value must be either\\n            ``'half_squared_sum'`` or ``'no'``.\\n            Otherwise, :class:`ValueError` is raised.\\n\\n    Returns:\\n        ~chainer.Variable:\\n            A variable holding a scalar of the DeCov loss.\\n            If ``reduce`` is ``'no'``, the output variable holds\\n            2-dimensional array matrix of shape ``(N, N)`` where\\n            ``N`` is the number of columns of ``y``.\\n            If it is ``'half_squared_sum'``, the output variable\\n            holds a scalar value.\\n\\n    .. note::\\n\\n       See https://arxiv.org/abs/1511.06068 for details.\\n\\n    \"\n    return DeCov(reduce)(h)",
            "def decov(h, reduce='half_squared_sum'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Computes the DeCov loss of ``h``\\n\\n    The output is a variable whose value depends on the value of\\n    the option ``reduce``. If it is ``'no'``, it holds a matrix\\n    whose size is same as the number of columns of ``y``.\\n    If it is ``'half_squared_sum'``, it holds the half of the\\n    squared Frobenius norm (i.e. squared of the L2 norm of a matrix flattened\\n    to a vector) of the matrix.\\n\\n    Args:\\n        h (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Variable holding a matrix where the first dimension\\n            corresponds to the batches.\\n        reduce (str): Reduction option. Its value must be either\\n            ``'half_squared_sum'`` or ``'no'``.\\n            Otherwise, :class:`ValueError` is raised.\\n\\n    Returns:\\n        ~chainer.Variable:\\n            A variable holding a scalar of the DeCov loss.\\n            If ``reduce`` is ``'no'``, the output variable holds\\n            2-dimensional array matrix of shape ``(N, N)`` where\\n            ``N`` is the number of columns of ``y``.\\n            If it is ``'half_squared_sum'``, the output variable\\n            holds a scalar value.\\n\\n    .. note::\\n\\n       See https://arxiv.org/abs/1511.06068 for details.\\n\\n    \"\n    return DeCov(reduce)(h)",
            "def decov(h, reduce='half_squared_sum'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Computes the DeCov loss of ``h``\\n\\n    The output is a variable whose value depends on the value of\\n    the option ``reduce``. If it is ``'no'``, it holds a matrix\\n    whose size is same as the number of columns of ``y``.\\n    If it is ``'half_squared_sum'``, it holds the half of the\\n    squared Frobenius norm (i.e. squared of the L2 norm of a matrix flattened\\n    to a vector) of the matrix.\\n\\n    Args:\\n        h (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Variable holding a matrix where the first dimension\\n            corresponds to the batches.\\n        reduce (str): Reduction option. Its value must be either\\n            ``'half_squared_sum'`` or ``'no'``.\\n            Otherwise, :class:`ValueError` is raised.\\n\\n    Returns:\\n        ~chainer.Variable:\\n            A variable holding a scalar of the DeCov loss.\\n            If ``reduce`` is ``'no'``, the output variable holds\\n            2-dimensional array matrix of shape ``(N, N)`` where\\n            ``N`` is the number of columns of ``y``.\\n            If it is ``'half_squared_sum'``, the output variable\\n            holds a scalar value.\\n\\n    .. note::\\n\\n       See https://arxiv.org/abs/1511.06068 for details.\\n\\n    \"\n    return DeCov(reduce)(h)",
            "def decov(h, reduce='half_squared_sum'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Computes the DeCov loss of ``h``\\n\\n    The output is a variable whose value depends on the value of\\n    the option ``reduce``. If it is ``'no'``, it holds a matrix\\n    whose size is same as the number of columns of ``y``.\\n    If it is ``'half_squared_sum'``, it holds the half of the\\n    squared Frobenius norm (i.e. squared of the L2 norm of a matrix flattened\\n    to a vector) of the matrix.\\n\\n    Args:\\n        h (:class:`~chainer.Variable` or :ref:`ndarray`):\\n            Variable holding a matrix where the first dimension\\n            corresponds to the batches.\\n        reduce (str): Reduction option. Its value must be either\\n            ``'half_squared_sum'`` or ``'no'``.\\n            Otherwise, :class:`ValueError` is raised.\\n\\n    Returns:\\n        ~chainer.Variable:\\n            A variable holding a scalar of the DeCov loss.\\n            If ``reduce`` is ``'no'``, the output variable holds\\n            2-dimensional array matrix of shape ``(N, N)`` where\\n            ``N`` is the number of columns of ``y``.\\n            If it is ``'half_squared_sum'``, the output variable\\n            holds a scalar value.\\n\\n    .. note::\\n\\n       See https://arxiv.org/abs/1511.06068 for details.\\n\\n    \"\n    return DeCov(reduce)(h)"
        ]
    }
]