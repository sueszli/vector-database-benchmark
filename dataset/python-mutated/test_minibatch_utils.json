[
    {
        "func_name": "test_minibatch_cyclic_iterator",
        "original": "def test_minibatch_cyclic_iterator(self):\n    for config in CONFIGS:\n        mini_batch_size = config['mini_batch_size']\n        num_sgd_iter = config['num_sgd_iter']\n        agent_steps = config['agent_steps']\n        seq_lens = config.get('seq_lens')\n        max_seq_len = None\n        if seq_lens:\n            max_seq_len = max(seq_lens)\n        padding = config.get('padding', False)\n        num_env_steps = max(agent_steps)\n        for backend in ['tf', 'numpy']:\n            sample_batches = {f'pol{i}': SampleBatch({'obs': np.arange(agent_steps[i]), 'seq_lens': seq_lens}) if not seq_lens or not padding else SampleBatch({'obs': np.concatenate([np.concatenate([np.arange(s), np.zeros(shape=(max_seq_len - s,))]) for s in seq_lens]), 'seq_lens': seq_lens}) for i in range(len(agent_steps))}\n            if backend == 'tf':\n                for (pid, batch) in sample_batches.items():\n                    batch['obs'] = tf.convert_to_tensor(batch['obs'])\n                    if seq_lens:\n                        batch['seq_lens'] = tf.convert_to_tensor(batch['seq_lens'], dtype=tf.int32)\n            mb = MultiAgentBatch(sample_batches, num_env_steps)\n            batch_iter = MiniBatchCyclicIterator(mb, mini_batch_size, num_sgd_iter)\n            print(config)\n            iteration_counter = 0\n            for batch in batch_iter:\n                print(batch)\n                print('-' * 80)\n                print(batch['pol0']['obs'])\n                print('*' * 80)\n                for policy_batch in batch.policy_batches.values():\n                    check(policy_batch.count, mini_batch_size)\n                iteration_counter += 1\n            total_steps = iteration_counter * mini_batch_size\n            for (policy_idx, policy_batch) in enumerate(batch.policy_batches.values()):\n                expected_last_item = (total_steps - 1) % agent_steps[policy_idx]\n                if seq_lens and seq_lens[-1] < max_seq_len:\n                    expected_last_item = 0.0\n                check(policy_batch['obs'][-1], expected_last_item)\n            expected_iteration_counter = np.ceil(num_sgd_iter * max(agent_steps) / mini_batch_size)\n            if not seq_lens:\n                check(iteration_counter, expected_iteration_counter)\n            print(f'iteration_counter: {iteration_counter}')",
        "mutated": [
            "def test_minibatch_cyclic_iterator(self):\n    if False:\n        i = 10\n    for config in CONFIGS:\n        mini_batch_size = config['mini_batch_size']\n        num_sgd_iter = config['num_sgd_iter']\n        agent_steps = config['agent_steps']\n        seq_lens = config.get('seq_lens')\n        max_seq_len = None\n        if seq_lens:\n            max_seq_len = max(seq_lens)\n        padding = config.get('padding', False)\n        num_env_steps = max(agent_steps)\n        for backend in ['tf', 'numpy']:\n            sample_batches = {f'pol{i}': SampleBatch({'obs': np.arange(agent_steps[i]), 'seq_lens': seq_lens}) if not seq_lens or not padding else SampleBatch({'obs': np.concatenate([np.concatenate([np.arange(s), np.zeros(shape=(max_seq_len - s,))]) for s in seq_lens]), 'seq_lens': seq_lens}) for i in range(len(agent_steps))}\n            if backend == 'tf':\n                for (pid, batch) in sample_batches.items():\n                    batch['obs'] = tf.convert_to_tensor(batch['obs'])\n                    if seq_lens:\n                        batch['seq_lens'] = tf.convert_to_tensor(batch['seq_lens'], dtype=tf.int32)\n            mb = MultiAgentBatch(sample_batches, num_env_steps)\n            batch_iter = MiniBatchCyclicIterator(mb, mini_batch_size, num_sgd_iter)\n            print(config)\n            iteration_counter = 0\n            for batch in batch_iter:\n                print(batch)\n                print('-' * 80)\n                print(batch['pol0']['obs'])\n                print('*' * 80)\n                for policy_batch in batch.policy_batches.values():\n                    check(policy_batch.count, mini_batch_size)\n                iteration_counter += 1\n            total_steps = iteration_counter * mini_batch_size\n            for (policy_idx, policy_batch) in enumerate(batch.policy_batches.values()):\n                expected_last_item = (total_steps - 1) % agent_steps[policy_idx]\n                if seq_lens and seq_lens[-1] < max_seq_len:\n                    expected_last_item = 0.0\n                check(policy_batch['obs'][-1], expected_last_item)\n            expected_iteration_counter = np.ceil(num_sgd_iter * max(agent_steps) / mini_batch_size)\n            if not seq_lens:\n                check(iteration_counter, expected_iteration_counter)\n            print(f'iteration_counter: {iteration_counter}')",
            "def test_minibatch_cyclic_iterator(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    for config in CONFIGS:\n        mini_batch_size = config['mini_batch_size']\n        num_sgd_iter = config['num_sgd_iter']\n        agent_steps = config['agent_steps']\n        seq_lens = config.get('seq_lens')\n        max_seq_len = None\n        if seq_lens:\n            max_seq_len = max(seq_lens)\n        padding = config.get('padding', False)\n        num_env_steps = max(agent_steps)\n        for backend in ['tf', 'numpy']:\n            sample_batches = {f'pol{i}': SampleBatch({'obs': np.arange(agent_steps[i]), 'seq_lens': seq_lens}) if not seq_lens or not padding else SampleBatch({'obs': np.concatenate([np.concatenate([np.arange(s), np.zeros(shape=(max_seq_len - s,))]) for s in seq_lens]), 'seq_lens': seq_lens}) for i in range(len(agent_steps))}\n            if backend == 'tf':\n                for (pid, batch) in sample_batches.items():\n                    batch['obs'] = tf.convert_to_tensor(batch['obs'])\n                    if seq_lens:\n                        batch['seq_lens'] = tf.convert_to_tensor(batch['seq_lens'], dtype=tf.int32)\n            mb = MultiAgentBatch(sample_batches, num_env_steps)\n            batch_iter = MiniBatchCyclicIterator(mb, mini_batch_size, num_sgd_iter)\n            print(config)\n            iteration_counter = 0\n            for batch in batch_iter:\n                print(batch)\n                print('-' * 80)\n                print(batch['pol0']['obs'])\n                print('*' * 80)\n                for policy_batch in batch.policy_batches.values():\n                    check(policy_batch.count, mini_batch_size)\n                iteration_counter += 1\n            total_steps = iteration_counter * mini_batch_size\n            for (policy_idx, policy_batch) in enumerate(batch.policy_batches.values()):\n                expected_last_item = (total_steps - 1) % agent_steps[policy_idx]\n                if seq_lens and seq_lens[-1] < max_seq_len:\n                    expected_last_item = 0.0\n                check(policy_batch['obs'][-1], expected_last_item)\n            expected_iteration_counter = np.ceil(num_sgd_iter * max(agent_steps) / mini_batch_size)\n            if not seq_lens:\n                check(iteration_counter, expected_iteration_counter)\n            print(f'iteration_counter: {iteration_counter}')",
            "def test_minibatch_cyclic_iterator(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    for config in CONFIGS:\n        mini_batch_size = config['mini_batch_size']\n        num_sgd_iter = config['num_sgd_iter']\n        agent_steps = config['agent_steps']\n        seq_lens = config.get('seq_lens')\n        max_seq_len = None\n        if seq_lens:\n            max_seq_len = max(seq_lens)\n        padding = config.get('padding', False)\n        num_env_steps = max(agent_steps)\n        for backend in ['tf', 'numpy']:\n            sample_batches = {f'pol{i}': SampleBatch({'obs': np.arange(agent_steps[i]), 'seq_lens': seq_lens}) if not seq_lens or not padding else SampleBatch({'obs': np.concatenate([np.concatenate([np.arange(s), np.zeros(shape=(max_seq_len - s,))]) for s in seq_lens]), 'seq_lens': seq_lens}) for i in range(len(agent_steps))}\n            if backend == 'tf':\n                for (pid, batch) in sample_batches.items():\n                    batch['obs'] = tf.convert_to_tensor(batch['obs'])\n                    if seq_lens:\n                        batch['seq_lens'] = tf.convert_to_tensor(batch['seq_lens'], dtype=tf.int32)\n            mb = MultiAgentBatch(sample_batches, num_env_steps)\n            batch_iter = MiniBatchCyclicIterator(mb, mini_batch_size, num_sgd_iter)\n            print(config)\n            iteration_counter = 0\n            for batch in batch_iter:\n                print(batch)\n                print('-' * 80)\n                print(batch['pol0']['obs'])\n                print('*' * 80)\n                for policy_batch in batch.policy_batches.values():\n                    check(policy_batch.count, mini_batch_size)\n                iteration_counter += 1\n            total_steps = iteration_counter * mini_batch_size\n            for (policy_idx, policy_batch) in enumerate(batch.policy_batches.values()):\n                expected_last_item = (total_steps - 1) % agent_steps[policy_idx]\n                if seq_lens and seq_lens[-1] < max_seq_len:\n                    expected_last_item = 0.0\n                check(policy_batch['obs'][-1], expected_last_item)\n            expected_iteration_counter = np.ceil(num_sgd_iter * max(agent_steps) / mini_batch_size)\n            if not seq_lens:\n                check(iteration_counter, expected_iteration_counter)\n            print(f'iteration_counter: {iteration_counter}')",
            "def test_minibatch_cyclic_iterator(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    for config in CONFIGS:\n        mini_batch_size = config['mini_batch_size']\n        num_sgd_iter = config['num_sgd_iter']\n        agent_steps = config['agent_steps']\n        seq_lens = config.get('seq_lens')\n        max_seq_len = None\n        if seq_lens:\n            max_seq_len = max(seq_lens)\n        padding = config.get('padding', False)\n        num_env_steps = max(agent_steps)\n        for backend in ['tf', 'numpy']:\n            sample_batches = {f'pol{i}': SampleBatch({'obs': np.arange(agent_steps[i]), 'seq_lens': seq_lens}) if not seq_lens or not padding else SampleBatch({'obs': np.concatenate([np.concatenate([np.arange(s), np.zeros(shape=(max_seq_len - s,))]) for s in seq_lens]), 'seq_lens': seq_lens}) for i in range(len(agent_steps))}\n            if backend == 'tf':\n                for (pid, batch) in sample_batches.items():\n                    batch['obs'] = tf.convert_to_tensor(batch['obs'])\n                    if seq_lens:\n                        batch['seq_lens'] = tf.convert_to_tensor(batch['seq_lens'], dtype=tf.int32)\n            mb = MultiAgentBatch(sample_batches, num_env_steps)\n            batch_iter = MiniBatchCyclicIterator(mb, mini_batch_size, num_sgd_iter)\n            print(config)\n            iteration_counter = 0\n            for batch in batch_iter:\n                print(batch)\n                print('-' * 80)\n                print(batch['pol0']['obs'])\n                print('*' * 80)\n                for policy_batch in batch.policy_batches.values():\n                    check(policy_batch.count, mini_batch_size)\n                iteration_counter += 1\n            total_steps = iteration_counter * mini_batch_size\n            for (policy_idx, policy_batch) in enumerate(batch.policy_batches.values()):\n                expected_last_item = (total_steps - 1) % agent_steps[policy_idx]\n                if seq_lens and seq_lens[-1] < max_seq_len:\n                    expected_last_item = 0.0\n                check(policy_batch['obs'][-1], expected_last_item)\n            expected_iteration_counter = np.ceil(num_sgd_iter * max(agent_steps) / mini_batch_size)\n            if not seq_lens:\n                check(iteration_counter, expected_iteration_counter)\n            print(f'iteration_counter: {iteration_counter}')",
            "def test_minibatch_cyclic_iterator(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    for config in CONFIGS:\n        mini_batch_size = config['mini_batch_size']\n        num_sgd_iter = config['num_sgd_iter']\n        agent_steps = config['agent_steps']\n        seq_lens = config.get('seq_lens')\n        max_seq_len = None\n        if seq_lens:\n            max_seq_len = max(seq_lens)\n        padding = config.get('padding', False)\n        num_env_steps = max(agent_steps)\n        for backend in ['tf', 'numpy']:\n            sample_batches = {f'pol{i}': SampleBatch({'obs': np.arange(agent_steps[i]), 'seq_lens': seq_lens}) if not seq_lens or not padding else SampleBatch({'obs': np.concatenate([np.concatenate([np.arange(s), np.zeros(shape=(max_seq_len - s,))]) for s in seq_lens]), 'seq_lens': seq_lens}) for i in range(len(agent_steps))}\n            if backend == 'tf':\n                for (pid, batch) in sample_batches.items():\n                    batch['obs'] = tf.convert_to_tensor(batch['obs'])\n                    if seq_lens:\n                        batch['seq_lens'] = tf.convert_to_tensor(batch['seq_lens'], dtype=tf.int32)\n            mb = MultiAgentBatch(sample_batches, num_env_steps)\n            batch_iter = MiniBatchCyclicIterator(mb, mini_batch_size, num_sgd_iter)\n            print(config)\n            iteration_counter = 0\n            for batch in batch_iter:\n                print(batch)\n                print('-' * 80)\n                print(batch['pol0']['obs'])\n                print('*' * 80)\n                for policy_batch in batch.policy_batches.values():\n                    check(policy_batch.count, mini_batch_size)\n                iteration_counter += 1\n            total_steps = iteration_counter * mini_batch_size\n            for (policy_idx, policy_batch) in enumerate(batch.policy_batches.values()):\n                expected_last_item = (total_steps - 1) % agent_steps[policy_idx]\n                if seq_lens and seq_lens[-1] < max_seq_len:\n                    expected_last_item = 0.0\n                check(policy_batch['obs'][-1], expected_last_item)\n            expected_iteration_counter = np.ceil(num_sgd_iter * max(agent_steps) / mini_batch_size)\n            if not seq_lens:\n                check(iteration_counter, expected_iteration_counter)\n            print(f'iteration_counter: {iteration_counter}')"
        ]
    }
]