[
    {
        "func_name": "pretty_board",
        "original": "def pretty_board(time_step):\n    \"\"\"Returns the board in `time_step` in a human readable format.\"\"\"\n    info_state = time_step.observations['info_state'][0]\n    x_locations = np.nonzero(info_state[9:18])[0]\n    o_locations = np.nonzero(info_state[18:])[0]\n    board = np.full(3 * 3, '.')\n    board[x_locations] = 'X'\n    board[o_locations] = '0'\n    board = np.reshape(board, (3, 3))\n    return board",
        "mutated": [
            "def pretty_board(time_step):\n    if False:\n        i = 10\n    'Returns the board in `time_step` in a human readable format.'\n    info_state = time_step.observations['info_state'][0]\n    x_locations = np.nonzero(info_state[9:18])[0]\n    o_locations = np.nonzero(info_state[18:])[0]\n    board = np.full(3 * 3, '.')\n    board[x_locations] = 'X'\n    board[o_locations] = '0'\n    board = np.reshape(board, (3, 3))\n    return board",
            "def pretty_board(time_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Returns the board in `time_step` in a human readable format.'\n    info_state = time_step.observations['info_state'][0]\n    x_locations = np.nonzero(info_state[9:18])[0]\n    o_locations = np.nonzero(info_state[18:])[0]\n    board = np.full(3 * 3, '.')\n    board[x_locations] = 'X'\n    board[o_locations] = '0'\n    board = np.reshape(board, (3, 3))\n    return board",
            "def pretty_board(time_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Returns the board in `time_step` in a human readable format.'\n    info_state = time_step.observations['info_state'][0]\n    x_locations = np.nonzero(info_state[9:18])[0]\n    o_locations = np.nonzero(info_state[18:])[0]\n    board = np.full(3 * 3, '.')\n    board[x_locations] = 'X'\n    board[o_locations] = '0'\n    board = np.reshape(board, (3, 3))\n    return board",
            "def pretty_board(time_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Returns the board in `time_step` in a human readable format.'\n    info_state = time_step.observations['info_state'][0]\n    x_locations = np.nonzero(info_state[9:18])[0]\n    o_locations = np.nonzero(info_state[18:])[0]\n    board = np.full(3 * 3, '.')\n    board[x_locations] = 'X'\n    board[o_locations] = '0'\n    board = np.reshape(board, (3, 3))\n    return board",
            "def pretty_board(time_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Returns the board in `time_step` in a human readable format.'\n    info_state = time_step.observations['info_state'][0]\n    x_locations = np.nonzero(info_state[9:18])[0]\n    o_locations = np.nonzero(info_state[18:])[0]\n    board = np.full(3 * 3, '.')\n    board[x_locations] = 'X'\n    board[o_locations] = '0'\n    board = np.reshape(board, (3, 3))\n    return board"
        ]
    },
    {
        "func_name": "command_line_action",
        "original": "def command_line_action(time_step):\n    \"\"\"Gets a valid action from the user on the command line.\"\"\"\n    current_player = time_step.observations['current_player']\n    legal_actions = time_step.observations['legal_actions'][current_player]\n    action = -1\n    while action not in legal_actions:\n        print('Choose an action from {}:'.format(legal_actions))\n        sys.stdout.flush()\n        action_str = input()\n        try:\n            action = int(action_str)\n        except ValueError:\n            continue\n    return action",
        "mutated": [
            "def command_line_action(time_step):\n    if False:\n        i = 10\n    'Gets a valid action from the user on the command line.'\n    current_player = time_step.observations['current_player']\n    legal_actions = time_step.observations['legal_actions'][current_player]\n    action = -1\n    while action not in legal_actions:\n        print('Choose an action from {}:'.format(legal_actions))\n        sys.stdout.flush()\n        action_str = input()\n        try:\n            action = int(action_str)\n        except ValueError:\n            continue\n    return action",
            "def command_line_action(time_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Gets a valid action from the user on the command line.'\n    current_player = time_step.observations['current_player']\n    legal_actions = time_step.observations['legal_actions'][current_player]\n    action = -1\n    while action not in legal_actions:\n        print('Choose an action from {}:'.format(legal_actions))\n        sys.stdout.flush()\n        action_str = input()\n        try:\n            action = int(action_str)\n        except ValueError:\n            continue\n    return action",
            "def command_line_action(time_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Gets a valid action from the user on the command line.'\n    current_player = time_step.observations['current_player']\n    legal_actions = time_step.observations['legal_actions'][current_player]\n    action = -1\n    while action not in legal_actions:\n        print('Choose an action from {}:'.format(legal_actions))\n        sys.stdout.flush()\n        action_str = input()\n        try:\n            action = int(action_str)\n        except ValueError:\n            continue\n    return action",
            "def command_line_action(time_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Gets a valid action from the user on the command line.'\n    current_player = time_step.observations['current_player']\n    legal_actions = time_step.observations['legal_actions'][current_player]\n    action = -1\n    while action not in legal_actions:\n        print('Choose an action from {}:'.format(legal_actions))\n        sys.stdout.flush()\n        action_str = input()\n        try:\n            action = int(action_str)\n        except ValueError:\n            continue\n    return action",
            "def command_line_action(time_step):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Gets a valid action from the user on the command line.'\n    current_player = time_step.observations['current_player']\n    legal_actions = time_step.observations['legal_actions'][current_player]\n    action = -1\n    while action not in legal_actions:\n        print('Choose an action from {}:'.format(legal_actions))\n        sys.stdout.flush()\n        action_str = input()\n        try:\n            action = int(action_str)\n        except ValueError:\n            continue\n    return action"
        ]
    },
    {
        "func_name": "eval_against_random_bots",
        "original": "def eval_against_random_bots(env, trained_agents, random_agents, num_episodes):\n    \"\"\"Evaluates `trained_agents` against `random_agents` for `num_episodes`.\"\"\"\n    wins = np.zeros(2)\n    for player_pos in range(2):\n        if player_pos == 0:\n            cur_agents = [trained_agents[0], random_agents[1]]\n        else:\n            cur_agents = [random_agents[0], trained_agents[1]]\n        for _ in range(num_episodes):\n            time_step = env.reset()\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = cur_agents[player_id].step(time_step, is_evaluation=True)\n                time_step = env.step([agent_output.action])\n            if time_step.rewards[player_pos] > 0:\n                wins[player_pos] += 1\n    return wins / num_episodes",
        "mutated": [
            "def eval_against_random_bots(env, trained_agents, random_agents, num_episodes):\n    if False:\n        i = 10\n    'Evaluates `trained_agents` against `random_agents` for `num_episodes`.'\n    wins = np.zeros(2)\n    for player_pos in range(2):\n        if player_pos == 0:\n            cur_agents = [trained_agents[0], random_agents[1]]\n        else:\n            cur_agents = [random_agents[0], trained_agents[1]]\n        for _ in range(num_episodes):\n            time_step = env.reset()\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = cur_agents[player_id].step(time_step, is_evaluation=True)\n                time_step = env.step([agent_output.action])\n            if time_step.rewards[player_pos] > 0:\n                wins[player_pos] += 1\n    return wins / num_episodes",
            "def eval_against_random_bots(env, trained_agents, random_agents, num_episodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Evaluates `trained_agents` against `random_agents` for `num_episodes`.'\n    wins = np.zeros(2)\n    for player_pos in range(2):\n        if player_pos == 0:\n            cur_agents = [trained_agents[0], random_agents[1]]\n        else:\n            cur_agents = [random_agents[0], trained_agents[1]]\n        for _ in range(num_episodes):\n            time_step = env.reset()\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = cur_agents[player_id].step(time_step, is_evaluation=True)\n                time_step = env.step([agent_output.action])\n            if time_step.rewards[player_pos] > 0:\n                wins[player_pos] += 1\n    return wins / num_episodes",
            "def eval_against_random_bots(env, trained_agents, random_agents, num_episodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Evaluates `trained_agents` against `random_agents` for `num_episodes`.'\n    wins = np.zeros(2)\n    for player_pos in range(2):\n        if player_pos == 0:\n            cur_agents = [trained_agents[0], random_agents[1]]\n        else:\n            cur_agents = [random_agents[0], trained_agents[1]]\n        for _ in range(num_episodes):\n            time_step = env.reset()\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = cur_agents[player_id].step(time_step, is_evaluation=True)\n                time_step = env.step([agent_output.action])\n            if time_step.rewards[player_pos] > 0:\n                wins[player_pos] += 1\n    return wins / num_episodes",
            "def eval_against_random_bots(env, trained_agents, random_agents, num_episodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Evaluates `trained_agents` against `random_agents` for `num_episodes`.'\n    wins = np.zeros(2)\n    for player_pos in range(2):\n        if player_pos == 0:\n            cur_agents = [trained_agents[0], random_agents[1]]\n        else:\n            cur_agents = [random_agents[0], trained_agents[1]]\n        for _ in range(num_episodes):\n            time_step = env.reset()\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = cur_agents[player_id].step(time_step, is_evaluation=True)\n                time_step = env.step([agent_output.action])\n            if time_step.rewards[player_pos] > 0:\n                wins[player_pos] += 1\n    return wins / num_episodes",
            "def eval_against_random_bots(env, trained_agents, random_agents, num_episodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Evaluates `trained_agents` against `random_agents` for `num_episodes`.'\n    wins = np.zeros(2)\n    for player_pos in range(2):\n        if player_pos == 0:\n            cur_agents = [trained_agents[0], random_agents[1]]\n        else:\n            cur_agents = [random_agents[0], trained_agents[1]]\n        for _ in range(num_episodes):\n            time_step = env.reset()\n            while not time_step.last():\n                player_id = time_step.observations['current_player']\n                agent_output = cur_agents[player_id].step(time_step, is_evaluation=True)\n                time_step = env.step([agent_output.action])\n            if time_step.rewards[player_pos] > 0:\n                wins[player_pos] += 1\n    return wins / num_episodes"
        ]
    },
    {
        "func_name": "main",
        "original": "def main(_):\n    game = 'tic_tac_toe'\n    num_players = 2\n    env = rl_environment.Environment(game)\n    num_actions = env.action_spec()['num_actions']\n    agents = [tabular_qlearner.QLearner(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    random_agents = [random_agent.RandomAgent(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    training_episodes = FLAGS.num_episodes\n    for cur_episode in range(training_episodes):\n        if cur_episode % int(10000.0) == 0:\n            win_rates = eval_against_random_bots(env, agents, random_agents, 1000)\n            logging.info('Starting episode %s, win_rates %s', cur_episode, win_rates)\n        time_step = env.reset()\n        while not time_step.last():\n            player_id = time_step.observations['current_player']\n            agent_output = agents[player_id].step(time_step)\n            time_step = env.step([agent_output.action])\n        for agent in agents:\n            agent.step(time_step)\n    if not FLAGS.interactive_play:\n        return\n    human_player = 1\n    while True:\n        logging.info('You are playing as %s', 'O' if human_player else 'X')\n        time_step = env.reset()\n        while not time_step.last():\n            player_id = time_step.observations['current_player']\n            if player_id == human_player:\n                agent_out = agents[human_player].step(time_step, is_evaluation=True)\n                logging.info('\\n%s', agent_out.probs.reshape((3, 3)))\n                logging.info('\\n%s', pretty_board(time_step))\n                action = command_line_action(time_step)\n            else:\n                agent_out = agents[1 - human_player].step(time_step, is_evaluation=True)\n                action = agent_out.action\n            time_step = env.step([action])\n        logging.info('\\n%s', pretty_board(time_step))\n        logging.info('End of game!')\n        if time_step.rewards[human_player] > 0:\n            logging.info('You win')\n        elif time_step.rewards[human_player] < 0:\n            logging.info('You lose')\n        else:\n            logging.info('Draw')\n        human_player = 1 - human_player",
        "mutated": [
            "def main(_):\n    if False:\n        i = 10\n    game = 'tic_tac_toe'\n    num_players = 2\n    env = rl_environment.Environment(game)\n    num_actions = env.action_spec()['num_actions']\n    agents = [tabular_qlearner.QLearner(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    random_agents = [random_agent.RandomAgent(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    training_episodes = FLAGS.num_episodes\n    for cur_episode in range(training_episodes):\n        if cur_episode % int(10000.0) == 0:\n            win_rates = eval_against_random_bots(env, agents, random_agents, 1000)\n            logging.info('Starting episode %s, win_rates %s', cur_episode, win_rates)\n        time_step = env.reset()\n        while not time_step.last():\n            player_id = time_step.observations['current_player']\n            agent_output = agents[player_id].step(time_step)\n            time_step = env.step([agent_output.action])\n        for agent in agents:\n            agent.step(time_step)\n    if not FLAGS.interactive_play:\n        return\n    human_player = 1\n    while True:\n        logging.info('You are playing as %s', 'O' if human_player else 'X')\n        time_step = env.reset()\n        while not time_step.last():\n            player_id = time_step.observations['current_player']\n            if player_id == human_player:\n                agent_out = agents[human_player].step(time_step, is_evaluation=True)\n                logging.info('\\n%s', agent_out.probs.reshape((3, 3)))\n                logging.info('\\n%s', pretty_board(time_step))\n                action = command_line_action(time_step)\n            else:\n                agent_out = agents[1 - human_player].step(time_step, is_evaluation=True)\n                action = agent_out.action\n            time_step = env.step([action])\n        logging.info('\\n%s', pretty_board(time_step))\n        logging.info('End of game!')\n        if time_step.rewards[human_player] > 0:\n            logging.info('You win')\n        elif time_step.rewards[human_player] < 0:\n            logging.info('You lose')\n        else:\n            logging.info('Draw')\n        human_player = 1 - human_player",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    game = 'tic_tac_toe'\n    num_players = 2\n    env = rl_environment.Environment(game)\n    num_actions = env.action_spec()['num_actions']\n    agents = [tabular_qlearner.QLearner(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    random_agents = [random_agent.RandomAgent(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    training_episodes = FLAGS.num_episodes\n    for cur_episode in range(training_episodes):\n        if cur_episode % int(10000.0) == 0:\n            win_rates = eval_against_random_bots(env, agents, random_agents, 1000)\n            logging.info('Starting episode %s, win_rates %s', cur_episode, win_rates)\n        time_step = env.reset()\n        while not time_step.last():\n            player_id = time_step.observations['current_player']\n            agent_output = agents[player_id].step(time_step)\n            time_step = env.step([agent_output.action])\n        for agent in agents:\n            agent.step(time_step)\n    if not FLAGS.interactive_play:\n        return\n    human_player = 1\n    while True:\n        logging.info('You are playing as %s', 'O' if human_player else 'X')\n        time_step = env.reset()\n        while not time_step.last():\n            player_id = time_step.observations['current_player']\n            if player_id == human_player:\n                agent_out = agents[human_player].step(time_step, is_evaluation=True)\n                logging.info('\\n%s', agent_out.probs.reshape((3, 3)))\n                logging.info('\\n%s', pretty_board(time_step))\n                action = command_line_action(time_step)\n            else:\n                agent_out = agents[1 - human_player].step(time_step, is_evaluation=True)\n                action = agent_out.action\n            time_step = env.step([action])\n        logging.info('\\n%s', pretty_board(time_step))\n        logging.info('End of game!')\n        if time_step.rewards[human_player] > 0:\n            logging.info('You win')\n        elif time_step.rewards[human_player] < 0:\n            logging.info('You lose')\n        else:\n            logging.info('Draw')\n        human_player = 1 - human_player",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    game = 'tic_tac_toe'\n    num_players = 2\n    env = rl_environment.Environment(game)\n    num_actions = env.action_spec()['num_actions']\n    agents = [tabular_qlearner.QLearner(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    random_agents = [random_agent.RandomAgent(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    training_episodes = FLAGS.num_episodes\n    for cur_episode in range(training_episodes):\n        if cur_episode % int(10000.0) == 0:\n            win_rates = eval_against_random_bots(env, agents, random_agents, 1000)\n            logging.info('Starting episode %s, win_rates %s', cur_episode, win_rates)\n        time_step = env.reset()\n        while not time_step.last():\n            player_id = time_step.observations['current_player']\n            agent_output = agents[player_id].step(time_step)\n            time_step = env.step([agent_output.action])\n        for agent in agents:\n            agent.step(time_step)\n    if not FLAGS.interactive_play:\n        return\n    human_player = 1\n    while True:\n        logging.info('You are playing as %s', 'O' if human_player else 'X')\n        time_step = env.reset()\n        while not time_step.last():\n            player_id = time_step.observations['current_player']\n            if player_id == human_player:\n                agent_out = agents[human_player].step(time_step, is_evaluation=True)\n                logging.info('\\n%s', agent_out.probs.reshape((3, 3)))\n                logging.info('\\n%s', pretty_board(time_step))\n                action = command_line_action(time_step)\n            else:\n                agent_out = agents[1 - human_player].step(time_step, is_evaluation=True)\n                action = agent_out.action\n            time_step = env.step([action])\n        logging.info('\\n%s', pretty_board(time_step))\n        logging.info('End of game!')\n        if time_step.rewards[human_player] > 0:\n            logging.info('You win')\n        elif time_step.rewards[human_player] < 0:\n            logging.info('You lose')\n        else:\n            logging.info('Draw')\n        human_player = 1 - human_player",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    game = 'tic_tac_toe'\n    num_players = 2\n    env = rl_environment.Environment(game)\n    num_actions = env.action_spec()['num_actions']\n    agents = [tabular_qlearner.QLearner(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    random_agents = [random_agent.RandomAgent(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    training_episodes = FLAGS.num_episodes\n    for cur_episode in range(training_episodes):\n        if cur_episode % int(10000.0) == 0:\n            win_rates = eval_against_random_bots(env, agents, random_agents, 1000)\n            logging.info('Starting episode %s, win_rates %s', cur_episode, win_rates)\n        time_step = env.reset()\n        while not time_step.last():\n            player_id = time_step.observations['current_player']\n            agent_output = agents[player_id].step(time_step)\n            time_step = env.step([agent_output.action])\n        for agent in agents:\n            agent.step(time_step)\n    if not FLAGS.interactive_play:\n        return\n    human_player = 1\n    while True:\n        logging.info('You are playing as %s', 'O' if human_player else 'X')\n        time_step = env.reset()\n        while not time_step.last():\n            player_id = time_step.observations['current_player']\n            if player_id == human_player:\n                agent_out = agents[human_player].step(time_step, is_evaluation=True)\n                logging.info('\\n%s', agent_out.probs.reshape((3, 3)))\n                logging.info('\\n%s', pretty_board(time_step))\n                action = command_line_action(time_step)\n            else:\n                agent_out = agents[1 - human_player].step(time_step, is_evaluation=True)\n                action = agent_out.action\n            time_step = env.step([action])\n        logging.info('\\n%s', pretty_board(time_step))\n        logging.info('End of game!')\n        if time_step.rewards[human_player] > 0:\n            logging.info('You win')\n        elif time_step.rewards[human_player] < 0:\n            logging.info('You lose')\n        else:\n            logging.info('Draw')\n        human_player = 1 - human_player",
            "def main(_):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    game = 'tic_tac_toe'\n    num_players = 2\n    env = rl_environment.Environment(game)\n    num_actions = env.action_spec()['num_actions']\n    agents = [tabular_qlearner.QLearner(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    random_agents = [random_agent.RandomAgent(player_id=idx, num_actions=num_actions) for idx in range(num_players)]\n    training_episodes = FLAGS.num_episodes\n    for cur_episode in range(training_episodes):\n        if cur_episode % int(10000.0) == 0:\n            win_rates = eval_against_random_bots(env, agents, random_agents, 1000)\n            logging.info('Starting episode %s, win_rates %s', cur_episode, win_rates)\n        time_step = env.reset()\n        while not time_step.last():\n            player_id = time_step.observations['current_player']\n            agent_output = agents[player_id].step(time_step)\n            time_step = env.step([agent_output.action])\n        for agent in agents:\n            agent.step(time_step)\n    if not FLAGS.interactive_play:\n        return\n    human_player = 1\n    while True:\n        logging.info('You are playing as %s', 'O' if human_player else 'X')\n        time_step = env.reset()\n        while not time_step.last():\n            player_id = time_step.observations['current_player']\n            if player_id == human_player:\n                agent_out = agents[human_player].step(time_step, is_evaluation=True)\n                logging.info('\\n%s', agent_out.probs.reshape((3, 3)))\n                logging.info('\\n%s', pretty_board(time_step))\n                action = command_line_action(time_step)\n            else:\n                agent_out = agents[1 - human_player].step(time_step, is_evaluation=True)\n                action = agent_out.action\n            time_step = env.step([action])\n        logging.info('\\n%s', pretty_board(time_step))\n        logging.info('End of game!')\n        if time_step.rewards[human_player] > 0:\n            logging.info('You win')\n        elif time_step.rewards[human_player] < 0:\n            logging.info('You lose')\n        else:\n            logging.info('Draw')\n        human_player = 1 - human_player"
        ]
    }
]