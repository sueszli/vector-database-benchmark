[
    {
        "func_name": "get_followers",
        "original": "def get_followers(browser, self_username, username, grab, relationship_data, live_match, store_locally, logger, logfolder, verified_only=False):\n    \"\"\"Get entire list of followers using graphql queries.\"\"\"\n    user_data = {}\n    variables = {}\n    all_followers = []\n    sc_rolled = 0\n    grab_notifier = False\n    local_read_failure = False\n    passed_time = 'time loop'\n    if username not in relationship_data:\n        relationship_data.update({username: {'all_following': [], 'all_followers': []}})\n    grab_info = 'at \"full\" range' if grab == 'full' else 'at the range of {}'.format(grab)\n    tense = 'live' if live_match is True or not relationship_data[username]['all_followers'] else 'fresh'\n    logger.info('Retrieving {} `Followers` data of {} {}'.format(tense, username, grab_info))\n    user_link = 'https://www.instagram.com/{}/'.format(username)\n    web_address_navigator(browser, user_link)\n    (followers_count, _) = get_relationship_counts(browser, username, logger)\n    if grab != 'full' and grab > followers_count:\n        logger.info('You have requested higher amount than existing followers count  ~gonna grab all available')\n        grab = followers_count\n    (following_status, _) = get_following_status(browser, 'profile', self_username, username, None, logger, logfolder)\n    is_private = is_private_profile(browser, logger, following_status == 'Following')\n    if not username == self_username and (is_private is None or (is_private is True and following_status not in ['Following', True]) or following_status == 'Blocked'):\n        logger.info(\"This user is private and we are not following. '{}':'{}'\".format(is_private, following_status))\n        return all_followers\n    match = None if live_match is True else 10 if relationship_data[username]['all_followers'] else None\n    all_prior_followers = relationship_data[username]['all_followers'] if match is not None else None\n    graphql_endpoint = 'view-source:https://www.instagram.com/graphql/query/'\n    graphql_followers = graphql_endpoint + '?query_hash=37479f2b8209594dde7facb0d904896a'\n    try:\n        user_data['id'] = browser.execute_script('return window.__additionalData[Object.keys(window.__additionalData)[0]].data.graphql.user.id')\n    except WebDriverException:\n        user_data['id'] = browser.execute_script('return window._sharedData.entry_data.ProfilePage[0].graphql.user.id')\n    variables['id'] = user_data['id']\n    variables['first'] = 50\n    try:\n        has_next_data = True\n        filename = None\n        graphql_queries = None\n        query_date = None\n        url = '{}&variables={}'.format(graphql_followers, str(json.dumps(variables)))\n        web_address_navigator(browser, url)\n        try:\n            filename = '{}graphql_queries.json'.format(logfolder)\n            query_date = datetime.today().strftime('%d-%m-%Y')\n            if not os.path.isfile(filename):\n                with interruption_handler():\n                    with open(filename, 'w') as graphql_queries_file:\n                        json.dump({username: {query_date: {'sc_rolled': 0}}}, graphql_queries_file)\n                        graphql_queries_file.close()\n            with open(filename) as graphql_queries_file:\n                graphql_queries = json.load(graphql_queries_file)\n                stored_usernames = list((name for (name, date) in graphql_queries.items()))\n                if username not in stored_usernames:\n                    graphql_queries[username] = {query_date: {'sc_rolled': 0}}\n                stored_query_dates = list((date for (date, score) in graphql_queries[username].items()))\n                if query_date not in stored_query_dates:\n                    graphql_queries[username][query_date] = {'sc_rolled': 0}\n        except Exception as exc:\n            logger.info('Error occurred while getting `scroll` data from graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n            local_read_failure = True\n        start_time = time.time()\n        highest_value = followers_count if grab == 'full' else grab\n        while has_next_data:\n            try:\n                pre = browser.find_element(By.TAG_NAME, 'pre').text\n            except NoSuchElementException as exc:\n                logger.info('Encountered an error to find `pre` in page!\\t~grabbed {} usernames \\n\\t{}'.format(len(set(all_followers)), str(exc).encode('utf-8')))\n                return all_followers\n            data = json.loads(pre)['data']\n            page_info = data['user']['edge_followed_by']['page_info']\n            edges = data['user']['edge_followed_by']['edges']\n            for user in edges:\n                if verified_only:\n                    if user['node']['is_verified']:\n                        all_followers.append(user['node']['username'])\n                else:\n                    all_followers.append(user['node']['username'])\n            grabbed = len(set(all_followers))\n            progress_tracker(grabbed, highest_value, start_time, logger)\n            print('\\n')\n            finish_time = time.time()\n            diff_time = finish_time - start_time\n            (diff_n, diff_s) = (diff_time / 60 / 60, 'hours') if diff_time / 60 / 60 >= 1 else (diff_time / 60, 'minutes') if diff_time / 60 >= 1 else (diff_time, 'seconds')\n            diff_n = truncate_float(diff_n, 2)\n            passed_time = '{} {}'.format(diff_n, diff_s)\n            if match is not None:\n                matched_followers = len(set(all_followers)) - len(set(all_followers) - set(all_prior_followers))\n                if matched_followers >= match:\n                    new_followers = set(all_followers) - set(all_prior_followers)\n                    all_followers = all_followers + all_prior_followers\n                    logger.info('Grabbed {} new usernames from `Followers` in {}  ~total of {} usernames'.format(len(set(new_followers)), passed_time, len(set(all_followers))))\n                    grab_notifier = True\n                    break\n            if grab != 'full' and grabbed >= grab:\n                logger.info('Grabbed {} usernames from `Followers` as requested at {}'.format(grabbed, passed_time))\n                grab_notifier = True\n                break\n            has_next_data = page_info['has_next_page']\n            if has_next_data:\n                variables['after'] = page_info['end_cursor']\n                url = '{}&variables={}'.format(graphql_followers, str(json.dumps(variables)))\n                web_address_navigator(browser, url)\n                sc_rolled += 1\n                if local_read_failure is not True:\n                    try:\n                        with interruption_handler():\n                            with open(filename, 'w') as graphql_queries_file:\n                                graphql_queries[username][query_date]['sc_rolled'] += 1\n                                json.dump(graphql_queries, graphql_queries_file)\n                    except Exception as exc:\n                        logger.info('Error occurred while writing `scroll` data to graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n                if sc_rolled > 91:\n                    logger.info('Queried too much! ~ sleeping a bit :>')\n                    sleep(600)\n                    sc_rolled = 0\n    except BaseException as exc:\n        logger.info('Unable to get `Followers` data:\\n\\t{}\\n'.format(str(exc).encode('utf-8')))\n    all_followers = sorted(set(all_followers), key=lambda x: all_followers.index(x))\n    if grab_notifier is False:\n        logger.info('Grabbed {} usernames from `Followers` in {}'.format(len(all_followers), passed_time))\n    if len(all_followers) > 0:\n        if store_locally is True and relationship_data[username]['all_followers'] != all_followers:\n            store_followers_data(username, grab, all_followers, logger, logfolder)\n        elif store_locally is True:\n            logger.info('The `Followers` data is identical with the data in previous query  ~not storing the file again')\n        if grab == 'full':\n            relationship_data[username].update({'all_followers': all_followers})\n    sleep_t = sc_rolled * 6\n    sleep_t = sleep_t if sleep_t < 600 else random.randint(585, 655)\n    (sleep_n, sleep_s) = (sleep_t / 60, 'minutes') if sleep_t / 60 >= 1 else (sleep_t, 'seconds')\n    sleep_n = truncate_float(sleep_n, 4)\n    logger.info('Zz :[ time to take a good nap  ~sleeping {} {}'.format(sleep_n, sleep_s))\n    sleep(sleep_t)\n    logger.info(\"Yawn :] let's go!\\n\")\n    return all_followers",
        "mutated": [
            "def get_followers(browser, self_username, username, grab, relationship_data, live_match, store_locally, logger, logfolder, verified_only=False):\n    if False:\n        i = 10\n    'Get entire list of followers using graphql queries.'\n    user_data = {}\n    variables = {}\n    all_followers = []\n    sc_rolled = 0\n    grab_notifier = False\n    local_read_failure = False\n    passed_time = 'time loop'\n    if username not in relationship_data:\n        relationship_data.update({username: {'all_following': [], 'all_followers': []}})\n    grab_info = 'at \"full\" range' if grab == 'full' else 'at the range of {}'.format(grab)\n    tense = 'live' if live_match is True or not relationship_data[username]['all_followers'] else 'fresh'\n    logger.info('Retrieving {} `Followers` data of {} {}'.format(tense, username, grab_info))\n    user_link = 'https://www.instagram.com/{}/'.format(username)\n    web_address_navigator(browser, user_link)\n    (followers_count, _) = get_relationship_counts(browser, username, logger)\n    if grab != 'full' and grab > followers_count:\n        logger.info('You have requested higher amount than existing followers count  ~gonna grab all available')\n        grab = followers_count\n    (following_status, _) = get_following_status(browser, 'profile', self_username, username, None, logger, logfolder)\n    is_private = is_private_profile(browser, logger, following_status == 'Following')\n    if not username == self_username and (is_private is None or (is_private is True and following_status not in ['Following', True]) or following_status == 'Blocked'):\n        logger.info(\"This user is private and we are not following. '{}':'{}'\".format(is_private, following_status))\n        return all_followers\n    match = None if live_match is True else 10 if relationship_data[username]['all_followers'] else None\n    all_prior_followers = relationship_data[username]['all_followers'] if match is not None else None\n    graphql_endpoint = 'view-source:https://www.instagram.com/graphql/query/'\n    graphql_followers = graphql_endpoint + '?query_hash=37479f2b8209594dde7facb0d904896a'\n    try:\n        user_data['id'] = browser.execute_script('return window.__additionalData[Object.keys(window.__additionalData)[0]].data.graphql.user.id')\n    except WebDriverException:\n        user_data['id'] = browser.execute_script('return window._sharedData.entry_data.ProfilePage[0].graphql.user.id')\n    variables['id'] = user_data['id']\n    variables['first'] = 50\n    try:\n        has_next_data = True\n        filename = None\n        graphql_queries = None\n        query_date = None\n        url = '{}&variables={}'.format(graphql_followers, str(json.dumps(variables)))\n        web_address_navigator(browser, url)\n        try:\n            filename = '{}graphql_queries.json'.format(logfolder)\n            query_date = datetime.today().strftime('%d-%m-%Y')\n            if not os.path.isfile(filename):\n                with interruption_handler():\n                    with open(filename, 'w') as graphql_queries_file:\n                        json.dump({username: {query_date: {'sc_rolled': 0}}}, graphql_queries_file)\n                        graphql_queries_file.close()\n            with open(filename) as graphql_queries_file:\n                graphql_queries = json.load(graphql_queries_file)\n                stored_usernames = list((name for (name, date) in graphql_queries.items()))\n                if username not in stored_usernames:\n                    graphql_queries[username] = {query_date: {'sc_rolled': 0}}\n                stored_query_dates = list((date for (date, score) in graphql_queries[username].items()))\n                if query_date not in stored_query_dates:\n                    graphql_queries[username][query_date] = {'sc_rolled': 0}\n        except Exception as exc:\n            logger.info('Error occurred while getting `scroll` data from graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n            local_read_failure = True\n        start_time = time.time()\n        highest_value = followers_count if grab == 'full' else grab\n        while has_next_data:\n            try:\n                pre = browser.find_element(By.TAG_NAME, 'pre').text\n            except NoSuchElementException as exc:\n                logger.info('Encountered an error to find `pre` in page!\\t~grabbed {} usernames \\n\\t{}'.format(len(set(all_followers)), str(exc).encode('utf-8')))\n                return all_followers\n            data = json.loads(pre)['data']\n            page_info = data['user']['edge_followed_by']['page_info']\n            edges = data['user']['edge_followed_by']['edges']\n            for user in edges:\n                if verified_only:\n                    if user['node']['is_verified']:\n                        all_followers.append(user['node']['username'])\n                else:\n                    all_followers.append(user['node']['username'])\n            grabbed = len(set(all_followers))\n            progress_tracker(grabbed, highest_value, start_time, logger)\n            print('\\n')\n            finish_time = time.time()\n            diff_time = finish_time - start_time\n            (diff_n, diff_s) = (diff_time / 60 / 60, 'hours') if diff_time / 60 / 60 >= 1 else (diff_time / 60, 'minutes') if diff_time / 60 >= 1 else (diff_time, 'seconds')\n            diff_n = truncate_float(diff_n, 2)\n            passed_time = '{} {}'.format(diff_n, diff_s)\n            if match is not None:\n                matched_followers = len(set(all_followers)) - len(set(all_followers) - set(all_prior_followers))\n                if matched_followers >= match:\n                    new_followers = set(all_followers) - set(all_prior_followers)\n                    all_followers = all_followers + all_prior_followers\n                    logger.info('Grabbed {} new usernames from `Followers` in {}  ~total of {} usernames'.format(len(set(new_followers)), passed_time, len(set(all_followers))))\n                    grab_notifier = True\n                    break\n            if grab != 'full' and grabbed >= grab:\n                logger.info('Grabbed {} usernames from `Followers` as requested at {}'.format(grabbed, passed_time))\n                grab_notifier = True\n                break\n            has_next_data = page_info['has_next_page']\n            if has_next_data:\n                variables['after'] = page_info['end_cursor']\n                url = '{}&variables={}'.format(graphql_followers, str(json.dumps(variables)))\n                web_address_navigator(browser, url)\n                sc_rolled += 1\n                if local_read_failure is not True:\n                    try:\n                        with interruption_handler():\n                            with open(filename, 'w') as graphql_queries_file:\n                                graphql_queries[username][query_date]['sc_rolled'] += 1\n                                json.dump(graphql_queries, graphql_queries_file)\n                    except Exception as exc:\n                        logger.info('Error occurred while writing `scroll` data to graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n                if sc_rolled > 91:\n                    logger.info('Queried too much! ~ sleeping a bit :>')\n                    sleep(600)\n                    sc_rolled = 0\n    except BaseException as exc:\n        logger.info('Unable to get `Followers` data:\\n\\t{}\\n'.format(str(exc).encode('utf-8')))\n    all_followers = sorted(set(all_followers), key=lambda x: all_followers.index(x))\n    if grab_notifier is False:\n        logger.info('Grabbed {} usernames from `Followers` in {}'.format(len(all_followers), passed_time))\n    if len(all_followers) > 0:\n        if store_locally is True and relationship_data[username]['all_followers'] != all_followers:\n            store_followers_data(username, grab, all_followers, logger, logfolder)\n        elif store_locally is True:\n            logger.info('The `Followers` data is identical with the data in previous query  ~not storing the file again')\n        if grab == 'full':\n            relationship_data[username].update({'all_followers': all_followers})\n    sleep_t = sc_rolled * 6\n    sleep_t = sleep_t if sleep_t < 600 else random.randint(585, 655)\n    (sleep_n, sleep_s) = (sleep_t / 60, 'minutes') if sleep_t / 60 >= 1 else (sleep_t, 'seconds')\n    sleep_n = truncate_float(sleep_n, 4)\n    logger.info('Zz :[ time to take a good nap  ~sleeping {} {}'.format(sleep_n, sleep_s))\n    sleep(sleep_t)\n    logger.info(\"Yawn :] let's go!\\n\")\n    return all_followers",
            "def get_followers(browser, self_username, username, grab, relationship_data, live_match, store_locally, logger, logfolder, verified_only=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Get entire list of followers using graphql queries.'\n    user_data = {}\n    variables = {}\n    all_followers = []\n    sc_rolled = 0\n    grab_notifier = False\n    local_read_failure = False\n    passed_time = 'time loop'\n    if username not in relationship_data:\n        relationship_data.update({username: {'all_following': [], 'all_followers': []}})\n    grab_info = 'at \"full\" range' if grab == 'full' else 'at the range of {}'.format(grab)\n    tense = 'live' if live_match is True or not relationship_data[username]['all_followers'] else 'fresh'\n    logger.info('Retrieving {} `Followers` data of {} {}'.format(tense, username, grab_info))\n    user_link = 'https://www.instagram.com/{}/'.format(username)\n    web_address_navigator(browser, user_link)\n    (followers_count, _) = get_relationship_counts(browser, username, logger)\n    if grab != 'full' and grab > followers_count:\n        logger.info('You have requested higher amount than existing followers count  ~gonna grab all available')\n        grab = followers_count\n    (following_status, _) = get_following_status(browser, 'profile', self_username, username, None, logger, logfolder)\n    is_private = is_private_profile(browser, logger, following_status == 'Following')\n    if not username == self_username and (is_private is None or (is_private is True and following_status not in ['Following', True]) or following_status == 'Blocked'):\n        logger.info(\"This user is private and we are not following. '{}':'{}'\".format(is_private, following_status))\n        return all_followers\n    match = None if live_match is True else 10 if relationship_data[username]['all_followers'] else None\n    all_prior_followers = relationship_data[username]['all_followers'] if match is not None else None\n    graphql_endpoint = 'view-source:https://www.instagram.com/graphql/query/'\n    graphql_followers = graphql_endpoint + '?query_hash=37479f2b8209594dde7facb0d904896a'\n    try:\n        user_data['id'] = browser.execute_script('return window.__additionalData[Object.keys(window.__additionalData)[0]].data.graphql.user.id')\n    except WebDriverException:\n        user_data['id'] = browser.execute_script('return window._sharedData.entry_data.ProfilePage[0].graphql.user.id')\n    variables['id'] = user_data['id']\n    variables['first'] = 50\n    try:\n        has_next_data = True\n        filename = None\n        graphql_queries = None\n        query_date = None\n        url = '{}&variables={}'.format(graphql_followers, str(json.dumps(variables)))\n        web_address_navigator(browser, url)\n        try:\n            filename = '{}graphql_queries.json'.format(logfolder)\n            query_date = datetime.today().strftime('%d-%m-%Y')\n            if not os.path.isfile(filename):\n                with interruption_handler():\n                    with open(filename, 'w') as graphql_queries_file:\n                        json.dump({username: {query_date: {'sc_rolled': 0}}}, graphql_queries_file)\n                        graphql_queries_file.close()\n            with open(filename) as graphql_queries_file:\n                graphql_queries = json.load(graphql_queries_file)\n                stored_usernames = list((name for (name, date) in graphql_queries.items()))\n                if username not in stored_usernames:\n                    graphql_queries[username] = {query_date: {'sc_rolled': 0}}\n                stored_query_dates = list((date for (date, score) in graphql_queries[username].items()))\n                if query_date not in stored_query_dates:\n                    graphql_queries[username][query_date] = {'sc_rolled': 0}\n        except Exception as exc:\n            logger.info('Error occurred while getting `scroll` data from graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n            local_read_failure = True\n        start_time = time.time()\n        highest_value = followers_count if grab == 'full' else grab\n        while has_next_data:\n            try:\n                pre = browser.find_element(By.TAG_NAME, 'pre').text\n            except NoSuchElementException as exc:\n                logger.info('Encountered an error to find `pre` in page!\\t~grabbed {} usernames \\n\\t{}'.format(len(set(all_followers)), str(exc).encode('utf-8')))\n                return all_followers\n            data = json.loads(pre)['data']\n            page_info = data['user']['edge_followed_by']['page_info']\n            edges = data['user']['edge_followed_by']['edges']\n            for user in edges:\n                if verified_only:\n                    if user['node']['is_verified']:\n                        all_followers.append(user['node']['username'])\n                else:\n                    all_followers.append(user['node']['username'])\n            grabbed = len(set(all_followers))\n            progress_tracker(grabbed, highest_value, start_time, logger)\n            print('\\n')\n            finish_time = time.time()\n            diff_time = finish_time - start_time\n            (diff_n, diff_s) = (diff_time / 60 / 60, 'hours') if diff_time / 60 / 60 >= 1 else (diff_time / 60, 'minutes') if diff_time / 60 >= 1 else (diff_time, 'seconds')\n            diff_n = truncate_float(diff_n, 2)\n            passed_time = '{} {}'.format(diff_n, diff_s)\n            if match is not None:\n                matched_followers = len(set(all_followers)) - len(set(all_followers) - set(all_prior_followers))\n                if matched_followers >= match:\n                    new_followers = set(all_followers) - set(all_prior_followers)\n                    all_followers = all_followers + all_prior_followers\n                    logger.info('Grabbed {} new usernames from `Followers` in {}  ~total of {} usernames'.format(len(set(new_followers)), passed_time, len(set(all_followers))))\n                    grab_notifier = True\n                    break\n            if grab != 'full' and grabbed >= grab:\n                logger.info('Grabbed {} usernames from `Followers` as requested at {}'.format(grabbed, passed_time))\n                grab_notifier = True\n                break\n            has_next_data = page_info['has_next_page']\n            if has_next_data:\n                variables['after'] = page_info['end_cursor']\n                url = '{}&variables={}'.format(graphql_followers, str(json.dumps(variables)))\n                web_address_navigator(browser, url)\n                sc_rolled += 1\n                if local_read_failure is not True:\n                    try:\n                        with interruption_handler():\n                            with open(filename, 'w') as graphql_queries_file:\n                                graphql_queries[username][query_date]['sc_rolled'] += 1\n                                json.dump(graphql_queries, graphql_queries_file)\n                    except Exception as exc:\n                        logger.info('Error occurred while writing `scroll` data to graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n                if sc_rolled > 91:\n                    logger.info('Queried too much! ~ sleeping a bit :>')\n                    sleep(600)\n                    sc_rolled = 0\n    except BaseException as exc:\n        logger.info('Unable to get `Followers` data:\\n\\t{}\\n'.format(str(exc).encode('utf-8')))\n    all_followers = sorted(set(all_followers), key=lambda x: all_followers.index(x))\n    if grab_notifier is False:\n        logger.info('Grabbed {} usernames from `Followers` in {}'.format(len(all_followers), passed_time))\n    if len(all_followers) > 0:\n        if store_locally is True and relationship_data[username]['all_followers'] != all_followers:\n            store_followers_data(username, grab, all_followers, logger, logfolder)\n        elif store_locally is True:\n            logger.info('The `Followers` data is identical with the data in previous query  ~not storing the file again')\n        if grab == 'full':\n            relationship_data[username].update({'all_followers': all_followers})\n    sleep_t = sc_rolled * 6\n    sleep_t = sleep_t if sleep_t < 600 else random.randint(585, 655)\n    (sleep_n, sleep_s) = (sleep_t / 60, 'minutes') if sleep_t / 60 >= 1 else (sleep_t, 'seconds')\n    sleep_n = truncate_float(sleep_n, 4)\n    logger.info('Zz :[ time to take a good nap  ~sleeping {} {}'.format(sleep_n, sleep_s))\n    sleep(sleep_t)\n    logger.info(\"Yawn :] let's go!\\n\")\n    return all_followers",
            "def get_followers(browser, self_username, username, grab, relationship_data, live_match, store_locally, logger, logfolder, verified_only=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Get entire list of followers using graphql queries.'\n    user_data = {}\n    variables = {}\n    all_followers = []\n    sc_rolled = 0\n    grab_notifier = False\n    local_read_failure = False\n    passed_time = 'time loop'\n    if username not in relationship_data:\n        relationship_data.update({username: {'all_following': [], 'all_followers': []}})\n    grab_info = 'at \"full\" range' if grab == 'full' else 'at the range of {}'.format(grab)\n    tense = 'live' if live_match is True or not relationship_data[username]['all_followers'] else 'fresh'\n    logger.info('Retrieving {} `Followers` data of {} {}'.format(tense, username, grab_info))\n    user_link = 'https://www.instagram.com/{}/'.format(username)\n    web_address_navigator(browser, user_link)\n    (followers_count, _) = get_relationship_counts(browser, username, logger)\n    if grab != 'full' and grab > followers_count:\n        logger.info('You have requested higher amount than existing followers count  ~gonna grab all available')\n        grab = followers_count\n    (following_status, _) = get_following_status(browser, 'profile', self_username, username, None, logger, logfolder)\n    is_private = is_private_profile(browser, logger, following_status == 'Following')\n    if not username == self_username and (is_private is None or (is_private is True and following_status not in ['Following', True]) or following_status == 'Blocked'):\n        logger.info(\"This user is private and we are not following. '{}':'{}'\".format(is_private, following_status))\n        return all_followers\n    match = None if live_match is True else 10 if relationship_data[username]['all_followers'] else None\n    all_prior_followers = relationship_data[username]['all_followers'] if match is not None else None\n    graphql_endpoint = 'view-source:https://www.instagram.com/graphql/query/'\n    graphql_followers = graphql_endpoint + '?query_hash=37479f2b8209594dde7facb0d904896a'\n    try:\n        user_data['id'] = browser.execute_script('return window.__additionalData[Object.keys(window.__additionalData)[0]].data.graphql.user.id')\n    except WebDriverException:\n        user_data['id'] = browser.execute_script('return window._sharedData.entry_data.ProfilePage[0].graphql.user.id')\n    variables['id'] = user_data['id']\n    variables['first'] = 50\n    try:\n        has_next_data = True\n        filename = None\n        graphql_queries = None\n        query_date = None\n        url = '{}&variables={}'.format(graphql_followers, str(json.dumps(variables)))\n        web_address_navigator(browser, url)\n        try:\n            filename = '{}graphql_queries.json'.format(logfolder)\n            query_date = datetime.today().strftime('%d-%m-%Y')\n            if not os.path.isfile(filename):\n                with interruption_handler():\n                    with open(filename, 'w') as graphql_queries_file:\n                        json.dump({username: {query_date: {'sc_rolled': 0}}}, graphql_queries_file)\n                        graphql_queries_file.close()\n            with open(filename) as graphql_queries_file:\n                graphql_queries = json.load(graphql_queries_file)\n                stored_usernames = list((name for (name, date) in graphql_queries.items()))\n                if username not in stored_usernames:\n                    graphql_queries[username] = {query_date: {'sc_rolled': 0}}\n                stored_query_dates = list((date for (date, score) in graphql_queries[username].items()))\n                if query_date not in stored_query_dates:\n                    graphql_queries[username][query_date] = {'sc_rolled': 0}\n        except Exception as exc:\n            logger.info('Error occurred while getting `scroll` data from graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n            local_read_failure = True\n        start_time = time.time()\n        highest_value = followers_count if grab == 'full' else grab\n        while has_next_data:\n            try:\n                pre = browser.find_element(By.TAG_NAME, 'pre').text\n            except NoSuchElementException as exc:\n                logger.info('Encountered an error to find `pre` in page!\\t~grabbed {} usernames \\n\\t{}'.format(len(set(all_followers)), str(exc).encode('utf-8')))\n                return all_followers\n            data = json.loads(pre)['data']\n            page_info = data['user']['edge_followed_by']['page_info']\n            edges = data['user']['edge_followed_by']['edges']\n            for user in edges:\n                if verified_only:\n                    if user['node']['is_verified']:\n                        all_followers.append(user['node']['username'])\n                else:\n                    all_followers.append(user['node']['username'])\n            grabbed = len(set(all_followers))\n            progress_tracker(grabbed, highest_value, start_time, logger)\n            print('\\n')\n            finish_time = time.time()\n            diff_time = finish_time - start_time\n            (diff_n, diff_s) = (diff_time / 60 / 60, 'hours') if diff_time / 60 / 60 >= 1 else (diff_time / 60, 'minutes') if diff_time / 60 >= 1 else (diff_time, 'seconds')\n            diff_n = truncate_float(diff_n, 2)\n            passed_time = '{} {}'.format(diff_n, diff_s)\n            if match is not None:\n                matched_followers = len(set(all_followers)) - len(set(all_followers) - set(all_prior_followers))\n                if matched_followers >= match:\n                    new_followers = set(all_followers) - set(all_prior_followers)\n                    all_followers = all_followers + all_prior_followers\n                    logger.info('Grabbed {} new usernames from `Followers` in {}  ~total of {} usernames'.format(len(set(new_followers)), passed_time, len(set(all_followers))))\n                    grab_notifier = True\n                    break\n            if grab != 'full' and grabbed >= grab:\n                logger.info('Grabbed {} usernames from `Followers` as requested at {}'.format(grabbed, passed_time))\n                grab_notifier = True\n                break\n            has_next_data = page_info['has_next_page']\n            if has_next_data:\n                variables['after'] = page_info['end_cursor']\n                url = '{}&variables={}'.format(graphql_followers, str(json.dumps(variables)))\n                web_address_navigator(browser, url)\n                sc_rolled += 1\n                if local_read_failure is not True:\n                    try:\n                        with interruption_handler():\n                            with open(filename, 'w') as graphql_queries_file:\n                                graphql_queries[username][query_date]['sc_rolled'] += 1\n                                json.dump(graphql_queries, graphql_queries_file)\n                    except Exception as exc:\n                        logger.info('Error occurred while writing `scroll` data to graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n                if sc_rolled > 91:\n                    logger.info('Queried too much! ~ sleeping a bit :>')\n                    sleep(600)\n                    sc_rolled = 0\n    except BaseException as exc:\n        logger.info('Unable to get `Followers` data:\\n\\t{}\\n'.format(str(exc).encode('utf-8')))\n    all_followers = sorted(set(all_followers), key=lambda x: all_followers.index(x))\n    if grab_notifier is False:\n        logger.info('Grabbed {} usernames from `Followers` in {}'.format(len(all_followers), passed_time))\n    if len(all_followers) > 0:\n        if store_locally is True and relationship_data[username]['all_followers'] != all_followers:\n            store_followers_data(username, grab, all_followers, logger, logfolder)\n        elif store_locally is True:\n            logger.info('The `Followers` data is identical with the data in previous query  ~not storing the file again')\n        if grab == 'full':\n            relationship_data[username].update({'all_followers': all_followers})\n    sleep_t = sc_rolled * 6\n    sleep_t = sleep_t if sleep_t < 600 else random.randint(585, 655)\n    (sleep_n, sleep_s) = (sleep_t / 60, 'minutes') if sleep_t / 60 >= 1 else (sleep_t, 'seconds')\n    sleep_n = truncate_float(sleep_n, 4)\n    logger.info('Zz :[ time to take a good nap  ~sleeping {} {}'.format(sleep_n, sleep_s))\n    sleep(sleep_t)\n    logger.info(\"Yawn :] let's go!\\n\")\n    return all_followers",
            "def get_followers(browser, self_username, username, grab, relationship_data, live_match, store_locally, logger, logfolder, verified_only=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Get entire list of followers using graphql queries.'\n    user_data = {}\n    variables = {}\n    all_followers = []\n    sc_rolled = 0\n    grab_notifier = False\n    local_read_failure = False\n    passed_time = 'time loop'\n    if username not in relationship_data:\n        relationship_data.update({username: {'all_following': [], 'all_followers': []}})\n    grab_info = 'at \"full\" range' if grab == 'full' else 'at the range of {}'.format(grab)\n    tense = 'live' if live_match is True or not relationship_data[username]['all_followers'] else 'fresh'\n    logger.info('Retrieving {} `Followers` data of {} {}'.format(tense, username, grab_info))\n    user_link = 'https://www.instagram.com/{}/'.format(username)\n    web_address_navigator(browser, user_link)\n    (followers_count, _) = get_relationship_counts(browser, username, logger)\n    if grab != 'full' and grab > followers_count:\n        logger.info('You have requested higher amount than existing followers count  ~gonna grab all available')\n        grab = followers_count\n    (following_status, _) = get_following_status(browser, 'profile', self_username, username, None, logger, logfolder)\n    is_private = is_private_profile(browser, logger, following_status == 'Following')\n    if not username == self_username and (is_private is None or (is_private is True and following_status not in ['Following', True]) or following_status == 'Blocked'):\n        logger.info(\"This user is private and we are not following. '{}':'{}'\".format(is_private, following_status))\n        return all_followers\n    match = None if live_match is True else 10 if relationship_data[username]['all_followers'] else None\n    all_prior_followers = relationship_data[username]['all_followers'] if match is not None else None\n    graphql_endpoint = 'view-source:https://www.instagram.com/graphql/query/'\n    graphql_followers = graphql_endpoint + '?query_hash=37479f2b8209594dde7facb0d904896a'\n    try:\n        user_data['id'] = browser.execute_script('return window.__additionalData[Object.keys(window.__additionalData)[0]].data.graphql.user.id')\n    except WebDriverException:\n        user_data['id'] = browser.execute_script('return window._sharedData.entry_data.ProfilePage[0].graphql.user.id')\n    variables['id'] = user_data['id']\n    variables['first'] = 50\n    try:\n        has_next_data = True\n        filename = None\n        graphql_queries = None\n        query_date = None\n        url = '{}&variables={}'.format(graphql_followers, str(json.dumps(variables)))\n        web_address_navigator(browser, url)\n        try:\n            filename = '{}graphql_queries.json'.format(logfolder)\n            query_date = datetime.today().strftime('%d-%m-%Y')\n            if not os.path.isfile(filename):\n                with interruption_handler():\n                    with open(filename, 'w') as graphql_queries_file:\n                        json.dump({username: {query_date: {'sc_rolled': 0}}}, graphql_queries_file)\n                        graphql_queries_file.close()\n            with open(filename) as graphql_queries_file:\n                graphql_queries = json.load(graphql_queries_file)\n                stored_usernames = list((name for (name, date) in graphql_queries.items()))\n                if username not in stored_usernames:\n                    graphql_queries[username] = {query_date: {'sc_rolled': 0}}\n                stored_query_dates = list((date for (date, score) in graphql_queries[username].items()))\n                if query_date not in stored_query_dates:\n                    graphql_queries[username][query_date] = {'sc_rolled': 0}\n        except Exception as exc:\n            logger.info('Error occurred while getting `scroll` data from graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n            local_read_failure = True\n        start_time = time.time()\n        highest_value = followers_count if grab == 'full' else grab\n        while has_next_data:\n            try:\n                pre = browser.find_element(By.TAG_NAME, 'pre').text\n            except NoSuchElementException as exc:\n                logger.info('Encountered an error to find `pre` in page!\\t~grabbed {} usernames \\n\\t{}'.format(len(set(all_followers)), str(exc).encode('utf-8')))\n                return all_followers\n            data = json.loads(pre)['data']\n            page_info = data['user']['edge_followed_by']['page_info']\n            edges = data['user']['edge_followed_by']['edges']\n            for user in edges:\n                if verified_only:\n                    if user['node']['is_verified']:\n                        all_followers.append(user['node']['username'])\n                else:\n                    all_followers.append(user['node']['username'])\n            grabbed = len(set(all_followers))\n            progress_tracker(grabbed, highest_value, start_time, logger)\n            print('\\n')\n            finish_time = time.time()\n            diff_time = finish_time - start_time\n            (diff_n, diff_s) = (diff_time / 60 / 60, 'hours') if diff_time / 60 / 60 >= 1 else (diff_time / 60, 'minutes') if diff_time / 60 >= 1 else (diff_time, 'seconds')\n            diff_n = truncate_float(diff_n, 2)\n            passed_time = '{} {}'.format(diff_n, diff_s)\n            if match is not None:\n                matched_followers = len(set(all_followers)) - len(set(all_followers) - set(all_prior_followers))\n                if matched_followers >= match:\n                    new_followers = set(all_followers) - set(all_prior_followers)\n                    all_followers = all_followers + all_prior_followers\n                    logger.info('Grabbed {} new usernames from `Followers` in {}  ~total of {} usernames'.format(len(set(new_followers)), passed_time, len(set(all_followers))))\n                    grab_notifier = True\n                    break\n            if grab != 'full' and grabbed >= grab:\n                logger.info('Grabbed {} usernames from `Followers` as requested at {}'.format(grabbed, passed_time))\n                grab_notifier = True\n                break\n            has_next_data = page_info['has_next_page']\n            if has_next_data:\n                variables['after'] = page_info['end_cursor']\n                url = '{}&variables={}'.format(graphql_followers, str(json.dumps(variables)))\n                web_address_navigator(browser, url)\n                sc_rolled += 1\n                if local_read_failure is not True:\n                    try:\n                        with interruption_handler():\n                            with open(filename, 'w') as graphql_queries_file:\n                                graphql_queries[username][query_date]['sc_rolled'] += 1\n                                json.dump(graphql_queries, graphql_queries_file)\n                    except Exception as exc:\n                        logger.info('Error occurred while writing `scroll` data to graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n                if sc_rolled > 91:\n                    logger.info('Queried too much! ~ sleeping a bit :>')\n                    sleep(600)\n                    sc_rolled = 0\n    except BaseException as exc:\n        logger.info('Unable to get `Followers` data:\\n\\t{}\\n'.format(str(exc).encode('utf-8')))\n    all_followers = sorted(set(all_followers), key=lambda x: all_followers.index(x))\n    if grab_notifier is False:\n        logger.info('Grabbed {} usernames from `Followers` in {}'.format(len(all_followers), passed_time))\n    if len(all_followers) > 0:\n        if store_locally is True and relationship_data[username]['all_followers'] != all_followers:\n            store_followers_data(username, grab, all_followers, logger, logfolder)\n        elif store_locally is True:\n            logger.info('The `Followers` data is identical with the data in previous query  ~not storing the file again')\n        if grab == 'full':\n            relationship_data[username].update({'all_followers': all_followers})\n    sleep_t = sc_rolled * 6\n    sleep_t = sleep_t if sleep_t < 600 else random.randint(585, 655)\n    (sleep_n, sleep_s) = (sleep_t / 60, 'minutes') if sleep_t / 60 >= 1 else (sleep_t, 'seconds')\n    sleep_n = truncate_float(sleep_n, 4)\n    logger.info('Zz :[ time to take a good nap  ~sleeping {} {}'.format(sleep_n, sleep_s))\n    sleep(sleep_t)\n    logger.info(\"Yawn :] let's go!\\n\")\n    return all_followers",
            "def get_followers(browser, self_username, username, grab, relationship_data, live_match, store_locally, logger, logfolder, verified_only=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Get entire list of followers using graphql queries.'\n    user_data = {}\n    variables = {}\n    all_followers = []\n    sc_rolled = 0\n    grab_notifier = False\n    local_read_failure = False\n    passed_time = 'time loop'\n    if username not in relationship_data:\n        relationship_data.update({username: {'all_following': [], 'all_followers': []}})\n    grab_info = 'at \"full\" range' if grab == 'full' else 'at the range of {}'.format(grab)\n    tense = 'live' if live_match is True or not relationship_data[username]['all_followers'] else 'fresh'\n    logger.info('Retrieving {} `Followers` data of {} {}'.format(tense, username, grab_info))\n    user_link = 'https://www.instagram.com/{}/'.format(username)\n    web_address_navigator(browser, user_link)\n    (followers_count, _) = get_relationship_counts(browser, username, logger)\n    if grab != 'full' and grab > followers_count:\n        logger.info('You have requested higher amount than existing followers count  ~gonna grab all available')\n        grab = followers_count\n    (following_status, _) = get_following_status(browser, 'profile', self_username, username, None, logger, logfolder)\n    is_private = is_private_profile(browser, logger, following_status == 'Following')\n    if not username == self_username and (is_private is None or (is_private is True and following_status not in ['Following', True]) or following_status == 'Blocked'):\n        logger.info(\"This user is private and we are not following. '{}':'{}'\".format(is_private, following_status))\n        return all_followers\n    match = None if live_match is True else 10 if relationship_data[username]['all_followers'] else None\n    all_prior_followers = relationship_data[username]['all_followers'] if match is not None else None\n    graphql_endpoint = 'view-source:https://www.instagram.com/graphql/query/'\n    graphql_followers = graphql_endpoint + '?query_hash=37479f2b8209594dde7facb0d904896a'\n    try:\n        user_data['id'] = browser.execute_script('return window.__additionalData[Object.keys(window.__additionalData)[0]].data.graphql.user.id')\n    except WebDriverException:\n        user_data['id'] = browser.execute_script('return window._sharedData.entry_data.ProfilePage[0].graphql.user.id')\n    variables['id'] = user_data['id']\n    variables['first'] = 50\n    try:\n        has_next_data = True\n        filename = None\n        graphql_queries = None\n        query_date = None\n        url = '{}&variables={}'.format(graphql_followers, str(json.dumps(variables)))\n        web_address_navigator(browser, url)\n        try:\n            filename = '{}graphql_queries.json'.format(logfolder)\n            query_date = datetime.today().strftime('%d-%m-%Y')\n            if not os.path.isfile(filename):\n                with interruption_handler():\n                    with open(filename, 'w') as graphql_queries_file:\n                        json.dump({username: {query_date: {'sc_rolled': 0}}}, graphql_queries_file)\n                        graphql_queries_file.close()\n            with open(filename) as graphql_queries_file:\n                graphql_queries = json.load(graphql_queries_file)\n                stored_usernames = list((name for (name, date) in graphql_queries.items()))\n                if username not in stored_usernames:\n                    graphql_queries[username] = {query_date: {'sc_rolled': 0}}\n                stored_query_dates = list((date for (date, score) in graphql_queries[username].items()))\n                if query_date not in stored_query_dates:\n                    graphql_queries[username][query_date] = {'sc_rolled': 0}\n        except Exception as exc:\n            logger.info('Error occurred while getting `scroll` data from graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n            local_read_failure = True\n        start_time = time.time()\n        highest_value = followers_count if grab == 'full' else grab\n        while has_next_data:\n            try:\n                pre = browser.find_element(By.TAG_NAME, 'pre').text\n            except NoSuchElementException as exc:\n                logger.info('Encountered an error to find `pre` in page!\\t~grabbed {} usernames \\n\\t{}'.format(len(set(all_followers)), str(exc).encode('utf-8')))\n                return all_followers\n            data = json.loads(pre)['data']\n            page_info = data['user']['edge_followed_by']['page_info']\n            edges = data['user']['edge_followed_by']['edges']\n            for user in edges:\n                if verified_only:\n                    if user['node']['is_verified']:\n                        all_followers.append(user['node']['username'])\n                else:\n                    all_followers.append(user['node']['username'])\n            grabbed = len(set(all_followers))\n            progress_tracker(grabbed, highest_value, start_time, logger)\n            print('\\n')\n            finish_time = time.time()\n            diff_time = finish_time - start_time\n            (diff_n, diff_s) = (diff_time / 60 / 60, 'hours') if diff_time / 60 / 60 >= 1 else (diff_time / 60, 'minutes') if diff_time / 60 >= 1 else (diff_time, 'seconds')\n            diff_n = truncate_float(diff_n, 2)\n            passed_time = '{} {}'.format(diff_n, diff_s)\n            if match is not None:\n                matched_followers = len(set(all_followers)) - len(set(all_followers) - set(all_prior_followers))\n                if matched_followers >= match:\n                    new_followers = set(all_followers) - set(all_prior_followers)\n                    all_followers = all_followers + all_prior_followers\n                    logger.info('Grabbed {} new usernames from `Followers` in {}  ~total of {} usernames'.format(len(set(new_followers)), passed_time, len(set(all_followers))))\n                    grab_notifier = True\n                    break\n            if grab != 'full' and grabbed >= grab:\n                logger.info('Grabbed {} usernames from `Followers` as requested at {}'.format(grabbed, passed_time))\n                grab_notifier = True\n                break\n            has_next_data = page_info['has_next_page']\n            if has_next_data:\n                variables['after'] = page_info['end_cursor']\n                url = '{}&variables={}'.format(graphql_followers, str(json.dumps(variables)))\n                web_address_navigator(browser, url)\n                sc_rolled += 1\n                if local_read_failure is not True:\n                    try:\n                        with interruption_handler():\n                            with open(filename, 'w') as graphql_queries_file:\n                                graphql_queries[username][query_date]['sc_rolled'] += 1\n                                json.dump(graphql_queries, graphql_queries_file)\n                    except Exception as exc:\n                        logger.info('Error occurred while writing `scroll` data to graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n                if sc_rolled > 91:\n                    logger.info('Queried too much! ~ sleeping a bit :>')\n                    sleep(600)\n                    sc_rolled = 0\n    except BaseException as exc:\n        logger.info('Unable to get `Followers` data:\\n\\t{}\\n'.format(str(exc).encode('utf-8')))\n    all_followers = sorted(set(all_followers), key=lambda x: all_followers.index(x))\n    if grab_notifier is False:\n        logger.info('Grabbed {} usernames from `Followers` in {}'.format(len(all_followers), passed_time))\n    if len(all_followers) > 0:\n        if store_locally is True and relationship_data[username]['all_followers'] != all_followers:\n            store_followers_data(username, grab, all_followers, logger, logfolder)\n        elif store_locally is True:\n            logger.info('The `Followers` data is identical with the data in previous query  ~not storing the file again')\n        if grab == 'full':\n            relationship_data[username].update({'all_followers': all_followers})\n    sleep_t = sc_rolled * 6\n    sleep_t = sleep_t if sleep_t < 600 else random.randint(585, 655)\n    (sleep_n, sleep_s) = (sleep_t / 60, 'minutes') if sleep_t / 60 >= 1 else (sleep_t, 'seconds')\n    sleep_n = truncate_float(sleep_n, 4)\n    logger.info('Zz :[ time to take a good nap  ~sleeping {} {}'.format(sleep_n, sleep_s))\n    sleep(sleep_t)\n    logger.info(\"Yawn :] let's go!\\n\")\n    return all_followers"
        ]
    },
    {
        "func_name": "get_following",
        "original": "def get_following(browser, self_username, username, grab, relationship_data, live_match, store_locally, logger, logfolder):\n    \"\"\"Get entire list of following using graphql queries.\"\"\"\n    user_data = {}\n    variables = {}\n    if username not in relationship_data:\n        relationship_data.update({username: {'all_following': [], 'all_followers': []}})\n    grab_info = 'at \"full\" range' if grab == 'full' else 'at the range of {}'.format(grab)\n    tense = 'live' if live_match is True or not relationship_data[username]['all_following'] else 'fresh'\n    logger.info('Retrieving {} `Following` data of {} {}'.format(tense, username, grab_info))\n    user_link = 'https://www.instagram.com/{}/'.format(username)\n    web_address_navigator(browser, user_link)\n    (_, following_count) = get_relationship_counts(browser, username, logger)\n    if grab != 'full' and grab > following_count:\n        logger.info('You have requested higher amount than existing following count  ~gonna grab all available')\n        grab = following_count\n    (following_status, _) = get_following_status(browser, 'profile', self_username, username, None, logger, logfolder)\n    is_private = is_private_profile(browser, logger, following_status == 'Following')\n    if not username == self_username and (is_private is None or (is_private is True and following_status not in ['Following', True]) or following_status == 'Blocked'):\n        logger.info(\"This user is private and we are not following. '{}':'{}'\".format(is_private, following_status))\n        return False\n    match = None if live_match is True else 10 if relationship_data[username]['all_following'] else None\n    all_prior_following = relationship_data[username]['all_following'] if match is not None else None\n    graphql_endpoint = 'view-source:https://www.instagram.com/graphql/query/'\n    graphql_following = graphql_endpoint + '?query_hash=58712303d941c6855d4e888c5f0cd22f'\n    try:\n        user_data['id'] = browser.execute_script('return window.__additionalData[Object.keys(window.__additionalData)[0]].data.graphql.user.id')\n    except WebDriverException:\n        user_data['id'] = browser.execute_script('return window._sharedData.entry_data.ProfilePage[0].graphql.user.id')\n    variables['id'] = user_data['id']\n    variables['first'] = 50\n    sc_rolled = 0\n    grab_notifier = False\n    local_read_failure = False\n    passed_time = 'time loop'\n    all_following = []\n    try:\n        filename = None\n        query_date = None\n        graphql_queries = None\n        has_next_data = True\n        url = '{}&variables={}'.format(graphql_following, str(json.dumps(variables)))\n        web_address_navigator(browser, url)\n        try:\n            filename = '{}graphql_queries.json'.format(logfolder)\n            query_date = datetime.today().strftime('%d-%m-%Y')\n            if not os.path.isfile(filename):\n                with interruption_handler():\n                    with open(filename, 'w') as graphql_queries_file:\n                        json.dump({username: {query_date: {'sc_rolled': 0}}}, graphql_queries_file)\n                        graphql_queries_file.close()\n            with open(filename) as graphql_queries_file:\n                graphql_queries = json.load(graphql_queries_file)\n                stored_usernames = list((name for (name, date) in graphql_queries.items()))\n                if username not in stored_usernames:\n                    graphql_queries[username] = {query_date: {'sc_rolled': 0}}\n                stored_query_dates = list((date for (date, score) in graphql_queries[username].items()))\n                if query_date not in stored_query_dates:\n                    graphql_queries[username][query_date] = {'sc_rolled': 0}\n        except Exception as exc:\n            logger.info('Error occurred while getting `scroll` data from graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n            local_read_failure = True\n        start_time = time.time()\n        highest_value = following_count if grab == 'full' else grab\n        while has_next_data:\n            try:\n                pre = browser.find_element(By.TAG_NAME, 'pre').text\n            except NoSuchElementException as exc:\n                logger.info('Encountered an error to find `pre` in page!\\t~grabbed {} usernames \\n\\t{}'.format(len(set(all_following)), str(exc).encode('utf-8')))\n                return all_following\n            data = json.loads(pre)['data']\n            page_info = data['user']['edge_follow']['page_info']\n            edges = data['user']['edge_follow']['edges']\n            for user in edges:\n                all_following.append(user['node']['username'])\n            grabbed = len(set(all_following))\n            progress_tracker(grabbed, highest_value, start_time, logger)\n            print('\\n')\n            finish_time = time.time()\n            diff_time = finish_time - start_time\n            (diff_n, diff_s) = (diff_time / 60 / 60, 'hours') if diff_time / 60 / 60 >= 1 else (diff_time / 60, 'minutes') if diff_time / 60 >= 1 else (diff_time, 'seconds')\n            diff_n = truncate_float(diff_n, 2)\n            passed_time = '{} {}'.format(diff_n, diff_s)\n            if match is not None:\n                matched_following = len(set(all_following)) - len(set(all_following) - set(all_prior_following))\n                if matched_following >= match:\n                    new_following = set(all_following) - set(all_prior_following)\n                    all_following = all_following + all_prior_following\n                    logger.info('Grabbed {} new usernames from `Following` in {}  ~total of {} usernames'.format(len(set(new_following)), passed_time, len(set(all_following))))\n                    grab_notifier = True\n                    break\n            if grab != 'full' and grabbed >= grab:\n                logger.info('Grabbed {} usernames from `Following` as requested at {}'.format(grabbed, passed_time))\n                grab_notifier = True\n                break\n            has_next_data = page_info['has_next_page']\n            if has_next_data:\n                variables['after'] = page_info['end_cursor']\n                url = '{}&variables={}'.format(graphql_following, str(json.dumps(variables)))\n                web_address_navigator(browser, url)\n                sc_rolled += 1\n                if local_read_failure is not True:\n                    try:\n                        with interruption_handler():\n                            with open(filename, 'w') as graphql_queries_file:\n                                graphql_queries[username][query_date]['sc_rolled'] += 1\n                                json.dump(graphql_queries, graphql_queries_file)\n                    except Exception as exc:\n                        logger.info('Error occurred while writing `scroll` data to graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n                if sc_rolled > 91:\n                    logger.info('Queried too much! ~ sleeping a bit :>')\n                    sleep(600)\n                    sc_rolled = 0\n    except BaseException as exc:\n        logger.info('Unable to get `Following` data:\\n\\t{}\\n'.format(str(exc).encode('utf-8')))\n    all_following = sorted(set(all_following), key=lambda x: all_following.index(x))\n    if grab_notifier is False:\n        logger.info('Grabbed {} usernames from `Following` in {}'.format(len(all_following), passed_time))\n    if len(all_following) > 0:\n        if store_locally is True and relationship_data[username]['all_following'] != all_following:\n            store_following_data(username, grab, all_following, logger, logfolder)\n        elif store_locally is True:\n            logger.info('The `Following` data is identical with the data in previous query  ~not storing the file again')\n        if grab == 'full':\n            relationship_data[username].update({'all_following': all_following})\n    sleep_t = sc_rolled * 6\n    sleep_t = sleep_t if sleep_t < 600 else random.randint(585, 655)\n    (sleep_n, sleep_s) = (sleep_t / 60, 'minutes') if sleep_t / 60 >= 1 else (sleep_t, 'seconds')\n    sleep_n = truncate_float(sleep_n, 4)\n    logger.info('Zz :[ time to take a good nap  ~sleeping {} {}'.format(sleep_n, sleep_s))\n    sleep(sleep_t)\n    logger.info(\"Yawn :] let's go!\\n\")\n    return all_following",
        "mutated": [
            "def get_following(browser, self_username, username, grab, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n    'Get entire list of following using graphql queries.'\n    user_data = {}\n    variables = {}\n    if username not in relationship_data:\n        relationship_data.update({username: {'all_following': [], 'all_followers': []}})\n    grab_info = 'at \"full\" range' if grab == 'full' else 'at the range of {}'.format(grab)\n    tense = 'live' if live_match is True or not relationship_data[username]['all_following'] else 'fresh'\n    logger.info('Retrieving {} `Following` data of {} {}'.format(tense, username, grab_info))\n    user_link = 'https://www.instagram.com/{}/'.format(username)\n    web_address_navigator(browser, user_link)\n    (_, following_count) = get_relationship_counts(browser, username, logger)\n    if grab != 'full' and grab > following_count:\n        logger.info('You have requested higher amount than existing following count  ~gonna grab all available')\n        grab = following_count\n    (following_status, _) = get_following_status(browser, 'profile', self_username, username, None, logger, logfolder)\n    is_private = is_private_profile(browser, logger, following_status == 'Following')\n    if not username == self_username and (is_private is None or (is_private is True and following_status not in ['Following', True]) or following_status == 'Blocked'):\n        logger.info(\"This user is private and we are not following. '{}':'{}'\".format(is_private, following_status))\n        return False\n    match = None if live_match is True else 10 if relationship_data[username]['all_following'] else None\n    all_prior_following = relationship_data[username]['all_following'] if match is not None else None\n    graphql_endpoint = 'view-source:https://www.instagram.com/graphql/query/'\n    graphql_following = graphql_endpoint + '?query_hash=58712303d941c6855d4e888c5f0cd22f'\n    try:\n        user_data['id'] = browser.execute_script('return window.__additionalData[Object.keys(window.__additionalData)[0]].data.graphql.user.id')\n    except WebDriverException:\n        user_data['id'] = browser.execute_script('return window._sharedData.entry_data.ProfilePage[0].graphql.user.id')\n    variables['id'] = user_data['id']\n    variables['first'] = 50\n    sc_rolled = 0\n    grab_notifier = False\n    local_read_failure = False\n    passed_time = 'time loop'\n    all_following = []\n    try:\n        filename = None\n        query_date = None\n        graphql_queries = None\n        has_next_data = True\n        url = '{}&variables={}'.format(graphql_following, str(json.dumps(variables)))\n        web_address_navigator(browser, url)\n        try:\n            filename = '{}graphql_queries.json'.format(logfolder)\n            query_date = datetime.today().strftime('%d-%m-%Y')\n            if not os.path.isfile(filename):\n                with interruption_handler():\n                    with open(filename, 'w') as graphql_queries_file:\n                        json.dump({username: {query_date: {'sc_rolled': 0}}}, graphql_queries_file)\n                        graphql_queries_file.close()\n            with open(filename) as graphql_queries_file:\n                graphql_queries = json.load(graphql_queries_file)\n                stored_usernames = list((name for (name, date) in graphql_queries.items()))\n                if username not in stored_usernames:\n                    graphql_queries[username] = {query_date: {'sc_rolled': 0}}\n                stored_query_dates = list((date for (date, score) in graphql_queries[username].items()))\n                if query_date not in stored_query_dates:\n                    graphql_queries[username][query_date] = {'sc_rolled': 0}\n        except Exception as exc:\n            logger.info('Error occurred while getting `scroll` data from graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n            local_read_failure = True\n        start_time = time.time()\n        highest_value = following_count if grab == 'full' else grab\n        while has_next_data:\n            try:\n                pre = browser.find_element(By.TAG_NAME, 'pre').text\n            except NoSuchElementException as exc:\n                logger.info('Encountered an error to find `pre` in page!\\t~grabbed {} usernames \\n\\t{}'.format(len(set(all_following)), str(exc).encode('utf-8')))\n                return all_following\n            data = json.loads(pre)['data']\n            page_info = data['user']['edge_follow']['page_info']\n            edges = data['user']['edge_follow']['edges']\n            for user in edges:\n                all_following.append(user['node']['username'])\n            grabbed = len(set(all_following))\n            progress_tracker(grabbed, highest_value, start_time, logger)\n            print('\\n')\n            finish_time = time.time()\n            diff_time = finish_time - start_time\n            (diff_n, diff_s) = (diff_time / 60 / 60, 'hours') if diff_time / 60 / 60 >= 1 else (diff_time / 60, 'minutes') if diff_time / 60 >= 1 else (diff_time, 'seconds')\n            diff_n = truncate_float(diff_n, 2)\n            passed_time = '{} {}'.format(diff_n, diff_s)\n            if match is not None:\n                matched_following = len(set(all_following)) - len(set(all_following) - set(all_prior_following))\n                if matched_following >= match:\n                    new_following = set(all_following) - set(all_prior_following)\n                    all_following = all_following + all_prior_following\n                    logger.info('Grabbed {} new usernames from `Following` in {}  ~total of {} usernames'.format(len(set(new_following)), passed_time, len(set(all_following))))\n                    grab_notifier = True\n                    break\n            if grab != 'full' and grabbed >= grab:\n                logger.info('Grabbed {} usernames from `Following` as requested at {}'.format(grabbed, passed_time))\n                grab_notifier = True\n                break\n            has_next_data = page_info['has_next_page']\n            if has_next_data:\n                variables['after'] = page_info['end_cursor']\n                url = '{}&variables={}'.format(graphql_following, str(json.dumps(variables)))\n                web_address_navigator(browser, url)\n                sc_rolled += 1\n                if local_read_failure is not True:\n                    try:\n                        with interruption_handler():\n                            with open(filename, 'w') as graphql_queries_file:\n                                graphql_queries[username][query_date]['sc_rolled'] += 1\n                                json.dump(graphql_queries, graphql_queries_file)\n                    except Exception as exc:\n                        logger.info('Error occurred while writing `scroll` data to graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n                if sc_rolled > 91:\n                    logger.info('Queried too much! ~ sleeping a bit :>')\n                    sleep(600)\n                    sc_rolled = 0\n    except BaseException as exc:\n        logger.info('Unable to get `Following` data:\\n\\t{}\\n'.format(str(exc).encode('utf-8')))\n    all_following = sorted(set(all_following), key=lambda x: all_following.index(x))\n    if grab_notifier is False:\n        logger.info('Grabbed {} usernames from `Following` in {}'.format(len(all_following), passed_time))\n    if len(all_following) > 0:\n        if store_locally is True and relationship_data[username]['all_following'] != all_following:\n            store_following_data(username, grab, all_following, logger, logfolder)\n        elif store_locally is True:\n            logger.info('The `Following` data is identical with the data in previous query  ~not storing the file again')\n        if grab == 'full':\n            relationship_data[username].update({'all_following': all_following})\n    sleep_t = sc_rolled * 6\n    sleep_t = sleep_t if sleep_t < 600 else random.randint(585, 655)\n    (sleep_n, sleep_s) = (sleep_t / 60, 'minutes') if sleep_t / 60 >= 1 else (sleep_t, 'seconds')\n    sleep_n = truncate_float(sleep_n, 4)\n    logger.info('Zz :[ time to take a good nap  ~sleeping {} {}'.format(sleep_n, sleep_s))\n    sleep(sleep_t)\n    logger.info(\"Yawn :] let's go!\\n\")\n    return all_following",
            "def get_following(browser, self_username, username, grab, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Get entire list of following using graphql queries.'\n    user_data = {}\n    variables = {}\n    if username not in relationship_data:\n        relationship_data.update({username: {'all_following': [], 'all_followers': []}})\n    grab_info = 'at \"full\" range' if grab == 'full' else 'at the range of {}'.format(grab)\n    tense = 'live' if live_match is True or not relationship_data[username]['all_following'] else 'fresh'\n    logger.info('Retrieving {} `Following` data of {} {}'.format(tense, username, grab_info))\n    user_link = 'https://www.instagram.com/{}/'.format(username)\n    web_address_navigator(browser, user_link)\n    (_, following_count) = get_relationship_counts(browser, username, logger)\n    if grab != 'full' and grab > following_count:\n        logger.info('You have requested higher amount than existing following count  ~gonna grab all available')\n        grab = following_count\n    (following_status, _) = get_following_status(browser, 'profile', self_username, username, None, logger, logfolder)\n    is_private = is_private_profile(browser, logger, following_status == 'Following')\n    if not username == self_username and (is_private is None or (is_private is True and following_status not in ['Following', True]) or following_status == 'Blocked'):\n        logger.info(\"This user is private and we are not following. '{}':'{}'\".format(is_private, following_status))\n        return False\n    match = None if live_match is True else 10 if relationship_data[username]['all_following'] else None\n    all_prior_following = relationship_data[username]['all_following'] if match is not None else None\n    graphql_endpoint = 'view-source:https://www.instagram.com/graphql/query/'\n    graphql_following = graphql_endpoint + '?query_hash=58712303d941c6855d4e888c5f0cd22f'\n    try:\n        user_data['id'] = browser.execute_script('return window.__additionalData[Object.keys(window.__additionalData)[0]].data.graphql.user.id')\n    except WebDriverException:\n        user_data['id'] = browser.execute_script('return window._sharedData.entry_data.ProfilePage[0].graphql.user.id')\n    variables['id'] = user_data['id']\n    variables['first'] = 50\n    sc_rolled = 0\n    grab_notifier = False\n    local_read_failure = False\n    passed_time = 'time loop'\n    all_following = []\n    try:\n        filename = None\n        query_date = None\n        graphql_queries = None\n        has_next_data = True\n        url = '{}&variables={}'.format(graphql_following, str(json.dumps(variables)))\n        web_address_navigator(browser, url)\n        try:\n            filename = '{}graphql_queries.json'.format(logfolder)\n            query_date = datetime.today().strftime('%d-%m-%Y')\n            if not os.path.isfile(filename):\n                with interruption_handler():\n                    with open(filename, 'w') as graphql_queries_file:\n                        json.dump({username: {query_date: {'sc_rolled': 0}}}, graphql_queries_file)\n                        graphql_queries_file.close()\n            with open(filename) as graphql_queries_file:\n                graphql_queries = json.load(graphql_queries_file)\n                stored_usernames = list((name for (name, date) in graphql_queries.items()))\n                if username not in stored_usernames:\n                    graphql_queries[username] = {query_date: {'sc_rolled': 0}}\n                stored_query_dates = list((date for (date, score) in graphql_queries[username].items()))\n                if query_date not in stored_query_dates:\n                    graphql_queries[username][query_date] = {'sc_rolled': 0}\n        except Exception as exc:\n            logger.info('Error occurred while getting `scroll` data from graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n            local_read_failure = True\n        start_time = time.time()\n        highest_value = following_count if grab == 'full' else grab\n        while has_next_data:\n            try:\n                pre = browser.find_element(By.TAG_NAME, 'pre').text\n            except NoSuchElementException as exc:\n                logger.info('Encountered an error to find `pre` in page!\\t~grabbed {} usernames \\n\\t{}'.format(len(set(all_following)), str(exc).encode('utf-8')))\n                return all_following\n            data = json.loads(pre)['data']\n            page_info = data['user']['edge_follow']['page_info']\n            edges = data['user']['edge_follow']['edges']\n            for user in edges:\n                all_following.append(user['node']['username'])\n            grabbed = len(set(all_following))\n            progress_tracker(grabbed, highest_value, start_time, logger)\n            print('\\n')\n            finish_time = time.time()\n            diff_time = finish_time - start_time\n            (diff_n, diff_s) = (diff_time / 60 / 60, 'hours') if diff_time / 60 / 60 >= 1 else (diff_time / 60, 'minutes') if diff_time / 60 >= 1 else (diff_time, 'seconds')\n            diff_n = truncate_float(diff_n, 2)\n            passed_time = '{} {}'.format(diff_n, diff_s)\n            if match is not None:\n                matched_following = len(set(all_following)) - len(set(all_following) - set(all_prior_following))\n                if matched_following >= match:\n                    new_following = set(all_following) - set(all_prior_following)\n                    all_following = all_following + all_prior_following\n                    logger.info('Grabbed {} new usernames from `Following` in {}  ~total of {} usernames'.format(len(set(new_following)), passed_time, len(set(all_following))))\n                    grab_notifier = True\n                    break\n            if grab != 'full' and grabbed >= grab:\n                logger.info('Grabbed {} usernames from `Following` as requested at {}'.format(grabbed, passed_time))\n                grab_notifier = True\n                break\n            has_next_data = page_info['has_next_page']\n            if has_next_data:\n                variables['after'] = page_info['end_cursor']\n                url = '{}&variables={}'.format(graphql_following, str(json.dumps(variables)))\n                web_address_navigator(browser, url)\n                sc_rolled += 1\n                if local_read_failure is not True:\n                    try:\n                        with interruption_handler():\n                            with open(filename, 'w') as graphql_queries_file:\n                                graphql_queries[username][query_date]['sc_rolled'] += 1\n                                json.dump(graphql_queries, graphql_queries_file)\n                    except Exception as exc:\n                        logger.info('Error occurred while writing `scroll` data to graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n                if sc_rolled > 91:\n                    logger.info('Queried too much! ~ sleeping a bit :>')\n                    sleep(600)\n                    sc_rolled = 0\n    except BaseException as exc:\n        logger.info('Unable to get `Following` data:\\n\\t{}\\n'.format(str(exc).encode('utf-8')))\n    all_following = sorted(set(all_following), key=lambda x: all_following.index(x))\n    if grab_notifier is False:\n        logger.info('Grabbed {} usernames from `Following` in {}'.format(len(all_following), passed_time))\n    if len(all_following) > 0:\n        if store_locally is True and relationship_data[username]['all_following'] != all_following:\n            store_following_data(username, grab, all_following, logger, logfolder)\n        elif store_locally is True:\n            logger.info('The `Following` data is identical with the data in previous query  ~not storing the file again')\n        if grab == 'full':\n            relationship_data[username].update({'all_following': all_following})\n    sleep_t = sc_rolled * 6\n    sleep_t = sleep_t if sleep_t < 600 else random.randint(585, 655)\n    (sleep_n, sleep_s) = (sleep_t / 60, 'minutes') if sleep_t / 60 >= 1 else (sleep_t, 'seconds')\n    sleep_n = truncate_float(sleep_n, 4)\n    logger.info('Zz :[ time to take a good nap  ~sleeping {} {}'.format(sleep_n, sleep_s))\n    sleep(sleep_t)\n    logger.info(\"Yawn :] let's go!\\n\")\n    return all_following",
            "def get_following(browser, self_username, username, grab, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Get entire list of following using graphql queries.'\n    user_data = {}\n    variables = {}\n    if username not in relationship_data:\n        relationship_data.update({username: {'all_following': [], 'all_followers': []}})\n    grab_info = 'at \"full\" range' if grab == 'full' else 'at the range of {}'.format(grab)\n    tense = 'live' if live_match is True or not relationship_data[username]['all_following'] else 'fresh'\n    logger.info('Retrieving {} `Following` data of {} {}'.format(tense, username, grab_info))\n    user_link = 'https://www.instagram.com/{}/'.format(username)\n    web_address_navigator(browser, user_link)\n    (_, following_count) = get_relationship_counts(browser, username, logger)\n    if grab != 'full' and grab > following_count:\n        logger.info('You have requested higher amount than existing following count  ~gonna grab all available')\n        grab = following_count\n    (following_status, _) = get_following_status(browser, 'profile', self_username, username, None, logger, logfolder)\n    is_private = is_private_profile(browser, logger, following_status == 'Following')\n    if not username == self_username and (is_private is None or (is_private is True and following_status not in ['Following', True]) or following_status == 'Blocked'):\n        logger.info(\"This user is private and we are not following. '{}':'{}'\".format(is_private, following_status))\n        return False\n    match = None if live_match is True else 10 if relationship_data[username]['all_following'] else None\n    all_prior_following = relationship_data[username]['all_following'] if match is not None else None\n    graphql_endpoint = 'view-source:https://www.instagram.com/graphql/query/'\n    graphql_following = graphql_endpoint + '?query_hash=58712303d941c6855d4e888c5f0cd22f'\n    try:\n        user_data['id'] = browser.execute_script('return window.__additionalData[Object.keys(window.__additionalData)[0]].data.graphql.user.id')\n    except WebDriverException:\n        user_data['id'] = browser.execute_script('return window._sharedData.entry_data.ProfilePage[0].graphql.user.id')\n    variables['id'] = user_data['id']\n    variables['first'] = 50\n    sc_rolled = 0\n    grab_notifier = False\n    local_read_failure = False\n    passed_time = 'time loop'\n    all_following = []\n    try:\n        filename = None\n        query_date = None\n        graphql_queries = None\n        has_next_data = True\n        url = '{}&variables={}'.format(graphql_following, str(json.dumps(variables)))\n        web_address_navigator(browser, url)\n        try:\n            filename = '{}graphql_queries.json'.format(logfolder)\n            query_date = datetime.today().strftime('%d-%m-%Y')\n            if not os.path.isfile(filename):\n                with interruption_handler():\n                    with open(filename, 'w') as graphql_queries_file:\n                        json.dump({username: {query_date: {'sc_rolled': 0}}}, graphql_queries_file)\n                        graphql_queries_file.close()\n            with open(filename) as graphql_queries_file:\n                graphql_queries = json.load(graphql_queries_file)\n                stored_usernames = list((name for (name, date) in graphql_queries.items()))\n                if username not in stored_usernames:\n                    graphql_queries[username] = {query_date: {'sc_rolled': 0}}\n                stored_query_dates = list((date for (date, score) in graphql_queries[username].items()))\n                if query_date not in stored_query_dates:\n                    graphql_queries[username][query_date] = {'sc_rolled': 0}\n        except Exception as exc:\n            logger.info('Error occurred while getting `scroll` data from graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n            local_read_failure = True\n        start_time = time.time()\n        highest_value = following_count if grab == 'full' else grab\n        while has_next_data:\n            try:\n                pre = browser.find_element(By.TAG_NAME, 'pre').text\n            except NoSuchElementException as exc:\n                logger.info('Encountered an error to find `pre` in page!\\t~grabbed {} usernames \\n\\t{}'.format(len(set(all_following)), str(exc).encode('utf-8')))\n                return all_following\n            data = json.loads(pre)['data']\n            page_info = data['user']['edge_follow']['page_info']\n            edges = data['user']['edge_follow']['edges']\n            for user in edges:\n                all_following.append(user['node']['username'])\n            grabbed = len(set(all_following))\n            progress_tracker(grabbed, highest_value, start_time, logger)\n            print('\\n')\n            finish_time = time.time()\n            diff_time = finish_time - start_time\n            (diff_n, diff_s) = (diff_time / 60 / 60, 'hours') if diff_time / 60 / 60 >= 1 else (diff_time / 60, 'minutes') if diff_time / 60 >= 1 else (diff_time, 'seconds')\n            diff_n = truncate_float(diff_n, 2)\n            passed_time = '{} {}'.format(diff_n, diff_s)\n            if match is not None:\n                matched_following = len(set(all_following)) - len(set(all_following) - set(all_prior_following))\n                if matched_following >= match:\n                    new_following = set(all_following) - set(all_prior_following)\n                    all_following = all_following + all_prior_following\n                    logger.info('Grabbed {} new usernames from `Following` in {}  ~total of {} usernames'.format(len(set(new_following)), passed_time, len(set(all_following))))\n                    grab_notifier = True\n                    break\n            if grab != 'full' and grabbed >= grab:\n                logger.info('Grabbed {} usernames from `Following` as requested at {}'.format(grabbed, passed_time))\n                grab_notifier = True\n                break\n            has_next_data = page_info['has_next_page']\n            if has_next_data:\n                variables['after'] = page_info['end_cursor']\n                url = '{}&variables={}'.format(graphql_following, str(json.dumps(variables)))\n                web_address_navigator(browser, url)\n                sc_rolled += 1\n                if local_read_failure is not True:\n                    try:\n                        with interruption_handler():\n                            with open(filename, 'w') as graphql_queries_file:\n                                graphql_queries[username][query_date]['sc_rolled'] += 1\n                                json.dump(graphql_queries, graphql_queries_file)\n                    except Exception as exc:\n                        logger.info('Error occurred while writing `scroll` data to graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n                if sc_rolled > 91:\n                    logger.info('Queried too much! ~ sleeping a bit :>')\n                    sleep(600)\n                    sc_rolled = 0\n    except BaseException as exc:\n        logger.info('Unable to get `Following` data:\\n\\t{}\\n'.format(str(exc).encode('utf-8')))\n    all_following = sorted(set(all_following), key=lambda x: all_following.index(x))\n    if grab_notifier is False:\n        logger.info('Grabbed {} usernames from `Following` in {}'.format(len(all_following), passed_time))\n    if len(all_following) > 0:\n        if store_locally is True and relationship_data[username]['all_following'] != all_following:\n            store_following_data(username, grab, all_following, logger, logfolder)\n        elif store_locally is True:\n            logger.info('The `Following` data is identical with the data in previous query  ~not storing the file again')\n        if grab == 'full':\n            relationship_data[username].update({'all_following': all_following})\n    sleep_t = sc_rolled * 6\n    sleep_t = sleep_t if sleep_t < 600 else random.randint(585, 655)\n    (sleep_n, sleep_s) = (sleep_t / 60, 'minutes') if sleep_t / 60 >= 1 else (sleep_t, 'seconds')\n    sleep_n = truncate_float(sleep_n, 4)\n    logger.info('Zz :[ time to take a good nap  ~sleeping {} {}'.format(sleep_n, sleep_s))\n    sleep(sleep_t)\n    logger.info(\"Yawn :] let's go!\\n\")\n    return all_following",
            "def get_following(browser, self_username, username, grab, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Get entire list of following using graphql queries.'\n    user_data = {}\n    variables = {}\n    if username not in relationship_data:\n        relationship_data.update({username: {'all_following': [], 'all_followers': []}})\n    grab_info = 'at \"full\" range' if grab == 'full' else 'at the range of {}'.format(grab)\n    tense = 'live' if live_match is True or not relationship_data[username]['all_following'] else 'fresh'\n    logger.info('Retrieving {} `Following` data of {} {}'.format(tense, username, grab_info))\n    user_link = 'https://www.instagram.com/{}/'.format(username)\n    web_address_navigator(browser, user_link)\n    (_, following_count) = get_relationship_counts(browser, username, logger)\n    if grab != 'full' and grab > following_count:\n        logger.info('You have requested higher amount than existing following count  ~gonna grab all available')\n        grab = following_count\n    (following_status, _) = get_following_status(browser, 'profile', self_username, username, None, logger, logfolder)\n    is_private = is_private_profile(browser, logger, following_status == 'Following')\n    if not username == self_username and (is_private is None or (is_private is True and following_status not in ['Following', True]) or following_status == 'Blocked'):\n        logger.info(\"This user is private and we are not following. '{}':'{}'\".format(is_private, following_status))\n        return False\n    match = None if live_match is True else 10 if relationship_data[username]['all_following'] else None\n    all_prior_following = relationship_data[username]['all_following'] if match is not None else None\n    graphql_endpoint = 'view-source:https://www.instagram.com/graphql/query/'\n    graphql_following = graphql_endpoint + '?query_hash=58712303d941c6855d4e888c5f0cd22f'\n    try:\n        user_data['id'] = browser.execute_script('return window.__additionalData[Object.keys(window.__additionalData)[0]].data.graphql.user.id')\n    except WebDriverException:\n        user_data['id'] = browser.execute_script('return window._sharedData.entry_data.ProfilePage[0].graphql.user.id')\n    variables['id'] = user_data['id']\n    variables['first'] = 50\n    sc_rolled = 0\n    grab_notifier = False\n    local_read_failure = False\n    passed_time = 'time loop'\n    all_following = []\n    try:\n        filename = None\n        query_date = None\n        graphql_queries = None\n        has_next_data = True\n        url = '{}&variables={}'.format(graphql_following, str(json.dumps(variables)))\n        web_address_navigator(browser, url)\n        try:\n            filename = '{}graphql_queries.json'.format(logfolder)\n            query_date = datetime.today().strftime('%d-%m-%Y')\n            if not os.path.isfile(filename):\n                with interruption_handler():\n                    with open(filename, 'w') as graphql_queries_file:\n                        json.dump({username: {query_date: {'sc_rolled': 0}}}, graphql_queries_file)\n                        graphql_queries_file.close()\n            with open(filename) as graphql_queries_file:\n                graphql_queries = json.load(graphql_queries_file)\n                stored_usernames = list((name for (name, date) in graphql_queries.items()))\n                if username not in stored_usernames:\n                    graphql_queries[username] = {query_date: {'sc_rolled': 0}}\n                stored_query_dates = list((date for (date, score) in graphql_queries[username].items()))\n                if query_date not in stored_query_dates:\n                    graphql_queries[username][query_date] = {'sc_rolled': 0}\n        except Exception as exc:\n            logger.info('Error occurred while getting `scroll` data from graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n            local_read_failure = True\n        start_time = time.time()\n        highest_value = following_count if grab == 'full' else grab\n        while has_next_data:\n            try:\n                pre = browser.find_element(By.TAG_NAME, 'pre').text\n            except NoSuchElementException as exc:\n                logger.info('Encountered an error to find `pre` in page!\\t~grabbed {} usernames \\n\\t{}'.format(len(set(all_following)), str(exc).encode('utf-8')))\n                return all_following\n            data = json.loads(pre)['data']\n            page_info = data['user']['edge_follow']['page_info']\n            edges = data['user']['edge_follow']['edges']\n            for user in edges:\n                all_following.append(user['node']['username'])\n            grabbed = len(set(all_following))\n            progress_tracker(grabbed, highest_value, start_time, logger)\n            print('\\n')\n            finish_time = time.time()\n            diff_time = finish_time - start_time\n            (diff_n, diff_s) = (diff_time / 60 / 60, 'hours') if diff_time / 60 / 60 >= 1 else (diff_time / 60, 'minutes') if diff_time / 60 >= 1 else (diff_time, 'seconds')\n            diff_n = truncate_float(diff_n, 2)\n            passed_time = '{} {}'.format(diff_n, diff_s)\n            if match is not None:\n                matched_following = len(set(all_following)) - len(set(all_following) - set(all_prior_following))\n                if matched_following >= match:\n                    new_following = set(all_following) - set(all_prior_following)\n                    all_following = all_following + all_prior_following\n                    logger.info('Grabbed {} new usernames from `Following` in {}  ~total of {} usernames'.format(len(set(new_following)), passed_time, len(set(all_following))))\n                    grab_notifier = True\n                    break\n            if grab != 'full' and grabbed >= grab:\n                logger.info('Grabbed {} usernames from `Following` as requested at {}'.format(grabbed, passed_time))\n                grab_notifier = True\n                break\n            has_next_data = page_info['has_next_page']\n            if has_next_data:\n                variables['after'] = page_info['end_cursor']\n                url = '{}&variables={}'.format(graphql_following, str(json.dumps(variables)))\n                web_address_navigator(browser, url)\n                sc_rolled += 1\n                if local_read_failure is not True:\n                    try:\n                        with interruption_handler():\n                            with open(filename, 'w') as graphql_queries_file:\n                                graphql_queries[username][query_date]['sc_rolled'] += 1\n                                json.dump(graphql_queries, graphql_queries_file)\n                    except Exception as exc:\n                        logger.info('Error occurred while writing `scroll` data to graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n                if sc_rolled > 91:\n                    logger.info('Queried too much! ~ sleeping a bit :>')\n                    sleep(600)\n                    sc_rolled = 0\n    except BaseException as exc:\n        logger.info('Unable to get `Following` data:\\n\\t{}\\n'.format(str(exc).encode('utf-8')))\n    all_following = sorted(set(all_following), key=lambda x: all_following.index(x))\n    if grab_notifier is False:\n        logger.info('Grabbed {} usernames from `Following` in {}'.format(len(all_following), passed_time))\n    if len(all_following) > 0:\n        if store_locally is True and relationship_data[username]['all_following'] != all_following:\n            store_following_data(username, grab, all_following, logger, logfolder)\n        elif store_locally is True:\n            logger.info('The `Following` data is identical with the data in previous query  ~not storing the file again')\n        if grab == 'full':\n            relationship_data[username].update({'all_following': all_following})\n    sleep_t = sc_rolled * 6\n    sleep_t = sleep_t if sleep_t < 600 else random.randint(585, 655)\n    (sleep_n, sleep_s) = (sleep_t / 60, 'minutes') if sleep_t / 60 >= 1 else (sleep_t, 'seconds')\n    sleep_n = truncate_float(sleep_n, 4)\n    logger.info('Zz :[ time to take a good nap  ~sleeping {} {}'.format(sleep_n, sleep_s))\n    sleep(sleep_t)\n    logger.info(\"Yawn :] let's go!\\n\")\n    return all_following",
            "def get_following(browser, self_username, username, grab, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Get entire list of following using graphql queries.'\n    user_data = {}\n    variables = {}\n    if username not in relationship_data:\n        relationship_data.update({username: {'all_following': [], 'all_followers': []}})\n    grab_info = 'at \"full\" range' if grab == 'full' else 'at the range of {}'.format(grab)\n    tense = 'live' if live_match is True or not relationship_data[username]['all_following'] else 'fresh'\n    logger.info('Retrieving {} `Following` data of {} {}'.format(tense, username, grab_info))\n    user_link = 'https://www.instagram.com/{}/'.format(username)\n    web_address_navigator(browser, user_link)\n    (_, following_count) = get_relationship_counts(browser, username, logger)\n    if grab != 'full' and grab > following_count:\n        logger.info('You have requested higher amount than existing following count  ~gonna grab all available')\n        grab = following_count\n    (following_status, _) = get_following_status(browser, 'profile', self_username, username, None, logger, logfolder)\n    is_private = is_private_profile(browser, logger, following_status == 'Following')\n    if not username == self_username and (is_private is None or (is_private is True and following_status not in ['Following', True]) or following_status == 'Blocked'):\n        logger.info(\"This user is private and we are not following. '{}':'{}'\".format(is_private, following_status))\n        return False\n    match = None if live_match is True else 10 if relationship_data[username]['all_following'] else None\n    all_prior_following = relationship_data[username]['all_following'] if match is not None else None\n    graphql_endpoint = 'view-source:https://www.instagram.com/graphql/query/'\n    graphql_following = graphql_endpoint + '?query_hash=58712303d941c6855d4e888c5f0cd22f'\n    try:\n        user_data['id'] = browser.execute_script('return window.__additionalData[Object.keys(window.__additionalData)[0]].data.graphql.user.id')\n    except WebDriverException:\n        user_data['id'] = browser.execute_script('return window._sharedData.entry_data.ProfilePage[0].graphql.user.id')\n    variables['id'] = user_data['id']\n    variables['first'] = 50\n    sc_rolled = 0\n    grab_notifier = False\n    local_read_failure = False\n    passed_time = 'time loop'\n    all_following = []\n    try:\n        filename = None\n        query_date = None\n        graphql_queries = None\n        has_next_data = True\n        url = '{}&variables={}'.format(graphql_following, str(json.dumps(variables)))\n        web_address_navigator(browser, url)\n        try:\n            filename = '{}graphql_queries.json'.format(logfolder)\n            query_date = datetime.today().strftime('%d-%m-%Y')\n            if not os.path.isfile(filename):\n                with interruption_handler():\n                    with open(filename, 'w') as graphql_queries_file:\n                        json.dump({username: {query_date: {'sc_rolled': 0}}}, graphql_queries_file)\n                        graphql_queries_file.close()\n            with open(filename) as graphql_queries_file:\n                graphql_queries = json.load(graphql_queries_file)\n                stored_usernames = list((name for (name, date) in graphql_queries.items()))\n                if username not in stored_usernames:\n                    graphql_queries[username] = {query_date: {'sc_rolled': 0}}\n                stored_query_dates = list((date for (date, score) in graphql_queries[username].items()))\n                if query_date not in stored_query_dates:\n                    graphql_queries[username][query_date] = {'sc_rolled': 0}\n        except Exception as exc:\n            logger.info('Error occurred while getting `scroll` data from graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n            local_read_failure = True\n        start_time = time.time()\n        highest_value = following_count if grab == 'full' else grab\n        while has_next_data:\n            try:\n                pre = browser.find_element(By.TAG_NAME, 'pre').text\n            except NoSuchElementException as exc:\n                logger.info('Encountered an error to find `pre` in page!\\t~grabbed {} usernames \\n\\t{}'.format(len(set(all_following)), str(exc).encode('utf-8')))\n                return all_following\n            data = json.loads(pre)['data']\n            page_info = data['user']['edge_follow']['page_info']\n            edges = data['user']['edge_follow']['edges']\n            for user in edges:\n                all_following.append(user['node']['username'])\n            grabbed = len(set(all_following))\n            progress_tracker(grabbed, highest_value, start_time, logger)\n            print('\\n')\n            finish_time = time.time()\n            diff_time = finish_time - start_time\n            (diff_n, diff_s) = (diff_time / 60 / 60, 'hours') if diff_time / 60 / 60 >= 1 else (diff_time / 60, 'minutes') if diff_time / 60 >= 1 else (diff_time, 'seconds')\n            diff_n = truncate_float(diff_n, 2)\n            passed_time = '{} {}'.format(diff_n, diff_s)\n            if match is not None:\n                matched_following = len(set(all_following)) - len(set(all_following) - set(all_prior_following))\n                if matched_following >= match:\n                    new_following = set(all_following) - set(all_prior_following)\n                    all_following = all_following + all_prior_following\n                    logger.info('Grabbed {} new usernames from `Following` in {}  ~total of {} usernames'.format(len(set(new_following)), passed_time, len(set(all_following))))\n                    grab_notifier = True\n                    break\n            if grab != 'full' and grabbed >= grab:\n                logger.info('Grabbed {} usernames from `Following` as requested at {}'.format(grabbed, passed_time))\n                grab_notifier = True\n                break\n            has_next_data = page_info['has_next_page']\n            if has_next_data:\n                variables['after'] = page_info['end_cursor']\n                url = '{}&variables={}'.format(graphql_following, str(json.dumps(variables)))\n                web_address_navigator(browser, url)\n                sc_rolled += 1\n                if local_read_failure is not True:\n                    try:\n                        with interruption_handler():\n                            with open(filename, 'w') as graphql_queries_file:\n                                graphql_queries[username][query_date]['sc_rolled'] += 1\n                                json.dump(graphql_queries, graphql_queries_file)\n                    except Exception as exc:\n                        logger.info('Error occurred while writing `scroll` data to graphql_queries.json\\n{}\\n'.format(str(exc).encode('utf-8')))\n                if sc_rolled > 91:\n                    logger.info('Queried too much! ~ sleeping a bit :>')\n                    sleep(600)\n                    sc_rolled = 0\n    except BaseException as exc:\n        logger.info('Unable to get `Following` data:\\n\\t{}\\n'.format(str(exc).encode('utf-8')))\n    all_following = sorted(set(all_following), key=lambda x: all_following.index(x))\n    if grab_notifier is False:\n        logger.info('Grabbed {} usernames from `Following` in {}'.format(len(all_following), passed_time))\n    if len(all_following) > 0:\n        if store_locally is True and relationship_data[username]['all_following'] != all_following:\n            store_following_data(username, grab, all_following, logger, logfolder)\n        elif store_locally is True:\n            logger.info('The `Following` data is identical with the data in previous query  ~not storing the file again')\n        if grab == 'full':\n            relationship_data[username].update({'all_following': all_following})\n    sleep_t = sc_rolled * 6\n    sleep_t = sleep_t if sleep_t < 600 else random.randint(585, 655)\n    (sleep_n, sleep_s) = (sleep_t / 60, 'minutes') if sleep_t / 60 >= 1 else (sleep_t, 'seconds')\n    sleep_n = truncate_float(sleep_n, 4)\n    logger.info('Zz :[ time to take a good nap  ~sleeping {} {}'.format(sleep_n, sleep_s))\n    sleep(sleep_t)\n    logger.info(\"Yawn :] let's go!\\n\")\n    return all_following"
        ]
    },
    {
        "func_name": "get_unfollowers",
        "original": "def get_unfollowers(browser, self_username, username, compare_by, compare_track, relationship_data, live_match, store_locally, print_out, logger, logfolder):\n    if compare_by not in ['latest', 'day', 'month', 'year', 'earliest']:\n        logger.info('Please choose a valid compare point to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    elif compare_track not in ['first', 'median', 'last']:\n        logger.info('Please choose a valid compare track to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    elif username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    (prior_followers, selected_filename) = load_followers_data(username, compare_by, compare_track, logger, logfolder)\n    if not prior_followers and selected_filename is None:\n        logger.info(\"Generate `Followers` data to find Unfollowers in future!  ~couldn't pick Unfollowers\")\n        return ([], [])\n    current_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not current_followers:\n        return (False, False)\n    all_unfollowers = [follower for follower in prior_followers if follower not in current_followers]\n    if len(all_unfollowers) > 0:\n        current_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n        active_unfollowers = [unfollower for unfollower in current_following if unfollower in all_unfollowers]\n        logger.info('Unfollowers found from {}!  total: {}  |  active: {}  :|\\n'.format(selected_filename, len(all_unfollowers), len(active_unfollowers)))\n        if store_locally is True:\n            store_all_unfollowers(username, all_unfollowers, logger, logfolder)\n            store_active_unfollowers(username, active_unfollowers, logger, logfolder)\n        if print_out is True:\n            logger.info('Unfollowers of {}:\\n\\n\\tAll Unfollowers: {}\\n\\n\\tActive Unfollowers: {}\\n'.format(username, all_unfollowers, active_unfollowers))\n    else:\n        logger.info('Yay! You have no any Unfollowers from {}!  ^v^'.format(selected_filename))\n        return ([], [])\n    return (all_unfollowers, active_unfollowers)",
        "mutated": [
            "def get_unfollowers(browser, self_username, username, compare_by, compare_track, relationship_data, live_match, store_locally, print_out, logger, logfolder):\n    if False:\n        i = 10\n    if compare_by not in ['latest', 'day', 'month', 'year', 'earliest']:\n        logger.info('Please choose a valid compare point to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    elif compare_track not in ['first', 'median', 'last']:\n        logger.info('Please choose a valid compare track to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    elif username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    (prior_followers, selected_filename) = load_followers_data(username, compare_by, compare_track, logger, logfolder)\n    if not prior_followers and selected_filename is None:\n        logger.info(\"Generate `Followers` data to find Unfollowers in future!  ~couldn't pick Unfollowers\")\n        return ([], [])\n    current_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not current_followers:\n        return (False, False)\n    all_unfollowers = [follower for follower in prior_followers if follower not in current_followers]\n    if len(all_unfollowers) > 0:\n        current_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n        active_unfollowers = [unfollower for unfollower in current_following if unfollower in all_unfollowers]\n        logger.info('Unfollowers found from {}!  total: {}  |  active: {}  :|\\n'.format(selected_filename, len(all_unfollowers), len(active_unfollowers)))\n        if store_locally is True:\n            store_all_unfollowers(username, all_unfollowers, logger, logfolder)\n            store_active_unfollowers(username, active_unfollowers, logger, logfolder)\n        if print_out is True:\n            logger.info('Unfollowers of {}:\\n\\n\\tAll Unfollowers: {}\\n\\n\\tActive Unfollowers: {}\\n'.format(username, all_unfollowers, active_unfollowers))\n    else:\n        logger.info('Yay! You have no any Unfollowers from {}!  ^v^'.format(selected_filename))\n        return ([], [])\n    return (all_unfollowers, active_unfollowers)",
            "def get_unfollowers(browser, self_username, username, compare_by, compare_track, relationship_data, live_match, store_locally, print_out, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if compare_by not in ['latest', 'day', 'month', 'year', 'earliest']:\n        logger.info('Please choose a valid compare point to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    elif compare_track not in ['first', 'median', 'last']:\n        logger.info('Please choose a valid compare track to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    elif username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    (prior_followers, selected_filename) = load_followers_data(username, compare_by, compare_track, logger, logfolder)\n    if not prior_followers and selected_filename is None:\n        logger.info(\"Generate `Followers` data to find Unfollowers in future!  ~couldn't pick Unfollowers\")\n        return ([], [])\n    current_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not current_followers:\n        return (False, False)\n    all_unfollowers = [follower for follower in prior_followers if follower not in current_followers]\n    if len(all_unfollowers) > 0:\n        current_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n        active_unfollowers = [unfollower for unfollower in current_following if unfollower in all_unfollowers]\n        logger.info('Unfollowers found from {}!  total: {}  |  active: {}  :|\\n'.format(selected_filename, len(all_unfollowers), len(active_unfollowers)))\n        if store_locally is True:\n            store_all_unfollowers(username, all_unfollowers, logger, logfolder)\n            store_active_unfollowers(username, active_unfollowers, logger, logfolder)\n        if print_out is True:\n            logger.info('Unfollowers of {}:\\n\\n\\tAll Unfollowers: {}\\n\\n\\tActive Unfollowers: {}\\n'.format(username, all_unfollowers, active_unfollowers))\n    else:\n        logger.info('Yay! You have no any Unfollowers from {}!  ^v^'.format(selected_filename))\n        return ([], [])\n    return (all_unfollowers, active_unfollowers)",
            "def get_unfollowers(browser, self_username, username, compare_by, compare_track, relationship_data, live_match, store_locally, print_out, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if compare_by not in ['latest', 'day', 'month', 'year', 'earliest']:\n        logger.info('Please choose a valid compare point to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    elif compare_track not in ['first', 'median', 'last']:\n        logger.info('Please choose a valid compare track to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    elif username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    (prior_followers, selected_filename) = load_followers_data(username, compare_by, compare_track, logger, logfolder)\n    if not prior_followers and selected_filename is None:\n        logger.info(\"Generate `Followers` data to find Unfollowers in future!  ~couldn't pick Unfollowers\")\n        return ([], [])\n    current_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not current_followers:\n        return (False, False)\n    all_unfollowers = [follower for follower in prior_followers if follower not in current_followers]\n    if len(all_unfollowers) > 0:\n        current_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n        active_unfollowers = [unfollower for unfollower in current_following if unfollower in all_unfollowers]\n        logger.info('Unfollowers found from {}!  total: {}  |  active: {}  :|\\n'.format(selected_filename, len(all_unfollowers), len(active_unfollowers)))\n        if store_locally is True:\n            store_all_unfollowers(username, all_unfollowers, logger, logfolder)\n            store_active_unfollowers(username, active_unfollowers, logger, logfolder)\n        if print_out is True:\n            logger.info('Unfollowers of {}:\\n\\n\\tAll Unfollowers: {}\\n\\n\\tActive Unfollowers: {}\\n'.format(username, all_unfollowers, active_unfollowers))\n    else:\n        logger.info('Yay! You have no any Unfollowers from {}!  ^v^'.format(selected_filename))\n        return ([], [])\n    return (all_unfollowers, active_unfollowers)",
            "def get_unfollowers(browser, self_username, username, compare_by, compare_track, relationship_data, live_match, store_locally, print_out, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if compare_by not in ['latest', 'day', 'month', 'year', 'earliest']:\n        logger.info('Please choose a valid compare point to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    elif compare_track not in ['first', 'median', 'last']:\n        logger.info('Please choose a valid compare track to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    elif username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    (prior_followers, selected_filename) = load_followers_data(username, compare_by, compare_track, logger, logfolder)\n    if not prior_followers and selected_filename is None:\n        logger.info(\"Generate `Followers` data to find Unfollowers in future!  ~couldn't pick Unfollowers\")\n        return ([], [])\n    current_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not current_followers:\n        return (False, False)\n    all_unfollowers = [follower for follower in prior_followers if follower not in current_followers]\n    if len(all_unfollowers) > 0:\n        current_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n        active_unfollowers = [unfollower for unfollower in current_following if unfollower in all_unfollowers]\n        logger.info('Unfollowers found from {}!  total: {}  |  active: {}  :|\\n'.format(selected_filename, len(all_unfollowers), len(active_unfollowers)))\n        if store_locally is True:\n            store_all_unfollowers(username, all_unfollowers, logger, logfolder)\n            store_active_unfollowers(username, active_unfollowers, logger, logfolder)\n        if print_out is True:\n            logger.info('Unfollowers of {}:\\n\\n\\tAll Unfollowers: {}\\n\\n\\tActive Unfollowers: {}\\n'.format(username, all_unfollowers, active_unfollowers))\n    else:\n        logger.info('Yay! You have no any Unfollowers from {}!  ^v^'.format(selected_filename))\n        return ([], [])\n    return (all_unfollowers, active_unfollowers)",
            "def get_unfollowers(browser, self_username, username, compare_by, compare_track, relationship_data, live_match, store_locally, print_out, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if compare_by not in ['latest', 'day', 'month', 'year', 'earliest']:\n        logger.info('Please choose a valid compare point to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    elif compare_track not in ['first', 'median', 'last']:\n        logger.info('Please choose a valid compare track to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    elif username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Unfollowers  ~leaving out of an invalid value')\n        return ([], [])\n    (prior_followers, selected_filename) = load_followers_data(username, compare_by, compare_track, logger, logfolder)\n    if not prior_followers and selected_filename is None:\n        logger.info(\"Generate `Followers` data to find Unfollowers in future!  ~couldn't pick Unfollowers\")\n        return ([], [])\n    current_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not current_followers:\n        return (False, False)\n    all_unfollowers = [follower for follower in prior_followers if follower not in current_followers]\n    if len(all_unfollowers) > 0:\n        current_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n        active_unfollowers = [unfollower for unfollower in current_following if unfollower in all_unfollowers]\n        logger.info('Unfollowers found from {}!  total: {}  |  active: {}  :|\\n'.format(selected_filename, len(all_unfollowers), len(active_unfollowers)))\n        if store_locally is True:\n            store_all_unfollowers(username, all_unfollowers, logger, logfolder)\n            store_active_unfollowers(username, active_unfollowers, logger, logfolder)\n        if print_out is True:\n            logger.info('Unfollowers of {}:\\n\\n\\tAll Unfollowers: {}\\n\\n\\tActive Unfollowers: {}\\n'.format(username, all_unfollowers, active_unfollowers))\n    else:\n        logger.info('Yay! You have no any Unfollowers from {}!  ^v^'.format(selected_filename))\n        return ([], [])\n    return (all_unfollowers, active_unfollowers)"
        ]
    },
    {
        "func_name": "get_nonfollowers",
        "original": "def get_nonfollowers(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    \"\"\"Finds Nonfollowers of a given user\"\"\"\n    if username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Nonfollowers  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    nonfollowers = [user for user in all_following if user not in all_followers]\n    nonfollowers = sorted(set(nonfollowers), key=nonfollowers.index)\n    logger.info('There are {0} Nonfollowers of {1}  ~the users {1} is following WHO do not follow back\\n'.format(len(nonfollowers), username))\n    store_nonfollowers(username, len(all_followers), len(all_following), nonfollowers, logger, logfolder)\n    return nonfollowers",
        "mutated": [
            "def get_nonfollowers(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n    'Finds Nonfollowers of a given user'\n    if username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Nonfollowers  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    nonfollowers = [user for user in all_following if user not in all_followers]\n    nonfollowers = sorted(set(nonfollowers), key=nonfollowers.index)\n    logger.info('There are {0} Nonfollowers of {1}  ~the users {1} is following WHO do not follow back\\n'.format(len(nonfollowers), username))\n    store_nonfollowers(username, len(all_followers), len(all_following), nonfollowers, logger, logfolder)\n    return nonfollowers",
            "def get_nonfollowers(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Finds Nonfollowers of a given user'\n    if username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Nonfollowers  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    nonfollowers = [user for user in all_following if user not in all_followers]\n    nonfollowers = sorted(set(nonfollowers), key=nonfollowers.index)\n    logger.info('There are {0} Nonfollowers of {1}  ~the users {1} is following WHO do not follow back\\n'.format(len(nonfollowers), username))\n    store_nonfollowers(username, len(all_followers), len(all_following), nonfollowers, logger, logfolder)\n    return nonfollowers",
            "def get_nonfollowers(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Finds Nonfollowers of a given user'\n    if username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Nonfollowers  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    nonfollowers = [user for user in all_following if user not in all_followers]\n    nonfollowers = sorted(set(nonfollowers), key=nonfollowers.index)\n    logger.info('There are {0} Nonfollowers of {1}  ~the users {1} is following WHO do not follow back\\n'.format(len(nonfollowers), username))\n    store_nonfollowers(username, len(all_followers), len(all_following), nonfollowers, logger, logfolder)\n    return nonfollowers",
            "def get_nonfollowers(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Finds Nonfollowers of a given user'\n    if username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Nonfollowers  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    nonfollowers = [user for user in all_following if user not in all_followers]\n    nonfollowers = sorted(set(nonfollowers), key=nonfollowers.index)\n    logger.info('There are {0} Nonfollowers of {1}  ~the users {1} is following WHO do not follow back\\n'.format(len(nonfollowers), username))\n    store_nonfollowers(username, len(all_followers), len(all_following), nonfollowers, logger, logfolder)\n    return nonfollowers",
            "def get_nonfollowers(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Finds Nonfollowers of a given user'\n    if username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Nonfollowers  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    nonfollowers = [user for user in all_following if user not in all_followers]\n    nonfollowers = sorted(set(nonfollowers), key=nonfollowers.index)\n    logger.info('There are {0} Nonfollowers of {1}  ~the users {1} is following WHO do not follow back\\n'.format(len(nonfollowers), username))\n    store_nonfollowers(username, len(all_followers), len(all_following), nonfollowers, logger, logfolder)\n    return nonfollowers"
        ]
    },
    {
        "func_name": "get_fans",
        "original": "def get_fans(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    \"\"\"Find Fans of a given user\"\"\"\n    if username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Fans  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    fans = [user for user in all_followers if user not in all_following]\n    fans = sorted(set(fans), key=fans.index)\n    logger.info('There are {0} Fans of {1}  ~the users following {1} WHOM {1} does not follow back\\n'.format(len(fans), username))\n    store_fans(username, len(all_followers), len(all_following), fans, logger, logfolder)\n    return fans",
        "mutated": [
            "def get_fans(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n    'Find Fans of a given user'\n    if username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Fans  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    fans = [user for user in all_followers if user not in all_following]\n    fans = sorted(set(fans), key=fans.index)\n    logger.info('There are {0} Fans of {1}  ~the users following {1} WHOM {1} does not follow back\\n'.format(len(fans), username))\n    store_fans(username, len(all_followers), len(all_following), fans, logger, logfolder)\n    return fans",
            "def get_fans(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Find Fans of a given user'\n    if username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Fans  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    fans = [user for user in all_followers if user not in all_following]\n    fans = sorted(set(fans), key=fans.index)\n    logger.info('There are {0} Fans of {1}  ~the users following {1} WHOM {1} does not follow back\\n'.format(len(fans), username))\n    store_fans(username, len(all_followers), len(all_following), fans, logger, logfolder)\n    return fans",
            "def get_fans(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Find Fans of a given user'\n    if username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Fans  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    fans = [user for user in all_followers if user not in all_following]\n    fans = sorted(set(fans), key=fans.index)\n    logger.info('There are {0} Fans of {1}  ~the users following {1} WHOM {1} does not follow back\\n'.format(len(fans), username))\n    store_fans(username, len(all_followers), len(all_following), fans, logger, logfolder)\n    return fans",
            "def get_fans(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Find Fans of a given user'\n    if username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Fans  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    fans = [user for user in all_followers if user not in all_following]\n    fans = sorted(set(fans), key=fans.index)\n    logger.info('There are {0} Fans of {1}  ~the users following {1} WHOM {1} does not follow back\\n'.format(len(fans), username))\n    store_fans(username, len(all_followers), len(all_following), fans, logger, logfolder)\n    return fans",
            "def get_fans(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Find Fans of a given user'\n    if username is None or not isinstance(username, str):\n        logger.info('Please enter a username to pick Fans  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    fans = [user for user in all_followers if user not in all_following]\n    fans = sorted(set(fans), key=fans.index)\n    logger.info('There are {0} Fans of {1}  ~the users following {1} WHOM {1} does not follow back\\n'.format(len(fans), username))\n    store_fans(username, len(all_followers), len(all_following), fans, logger, logfolder)\n    return fans"
        ]
    },
    {
        "func_name": "get_mutual_following",
        "original": "def get_mutual_following(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    \"\"\"Find Mutual Following of a given user\"\"\"\n    if username is None or type(username) != str:\n        logger.info('Please enter a username to pick Mutual Following  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    mutual_following = [user for user in all_following if user in all_followers]\n    mutual_following = sorted(set(mutual_following), key=mutual_following.index)\n    logger.info('There are {0} Mutual Following of {1}  ~the users {1} is following WHO also follow back\\n'.format(len(mutual_following), username))\n    store_mutual_following(username, len(all_followers), len(all_following), mutual_following, logger, logfolder)\n    return mutual_following",
        "mutated": [
            "def get_mutual_following(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n    'Find Mutual Following of a given user'\n    if username is None or type(username) != str:\n        logger.info('Please enter a username to pick Mutual Following  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    mutual_following = [user for user in all_following if user in all_followers]\n    mutual_following = sorted(set(mutual_following), key=mutual_following.index)\n    logger.info('There are {0} Mutual Following of {1}  ~the users {1} is following WHO also follow back\\n'.format(len(mutual_following), username))\n    store_mutual_following(username, len(all_followers), len(all_following), mutual_following, logger, logfolder)\n    return mutual_following",
            "def get_mutual_following(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Find Mutual Following of a given user'\n    if username is None or type(username) != str:\n        logger.info('Please enter a username to pick Mutual Following  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    mutual_following = [user for user in all_following if user in all_followers]\n    mutual_following = sorted(set(mutual_following), key=mutual_following.index)\n    logger.info('There are {0} Mutual Following of {1}  ~the users {1} is following WHO also follow back\\n'.format(len(mutual_following), username))\n    store_mutual_following(username, len(all_followers), len(all_following), mutual_following, logger, logfolder)\n    return mutual_following",
            "def get_mutual_following(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Find Mutual Following of a given user'\n    if username is None or type(username) != str:\n        logger.info('Please enter a username to pick Mutual Following  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    mutual_following = [user for user in all_following if user in all_followers]\n    mutual_following = sorted(set(mutual_following), key=mutual_following.index)\n    logger.info('There are {0} Mutual Following of {1}  ~the users {1} is following WHO also follow back\\n'.format(len(mutual_following), username))\n    store_mutual_following(username, len(all_followers), len(all_following), mutual_following, logger, logfolder)\n    return mutual_following",
            "def get_mutual_following(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Find Mutual Following of a given user'\n    if username is None or type(username) != str:\n        logger.info('Please enter a username to pick Mutual Following  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    mutual_following = [user for user in all_following if user in all_followers]\n    mutual_following = sorted(set(mutual_following), key=mutual_following.index)\n    logger.info('There are {0} Mutual Following of {1}  ~the users {1} is following WHO also follow back\\n'.format(len(mutual_following), username))\n    store_mutual_following(username, len(all_followers), len(all_following), mutual_following, logger, logfolder)\n    return mutual_following",
            "def get_mutual_following(browser, self_username, username, relationship_data, live_match, store_locally, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Find Mutual Following of a given user'\n    if username is None or type(username) != str:\n        logger.info('Please enter a username to pick Mutual Following  ~leaving out of an invalid value')\n        return []\n    all_followers = get_followers(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    if not all_followers:\n        return False\n    all_following = get_following(browser, self_username, username, 'full', relationship_data, live_match, store_locally, logger, logfolder)\n    mutual_following = [user for user in all_following if user in all_followers]\n    mutual_following = sorted(set(mutual_following), key=mutual_following.index)\n    logger.info('There are {0} Mutual Following of {1}  ~the users {1} is following WHO also follow back\\n'.format(len(mutual_following), username))\n    store_mutual_following(username, len(all_followers), len(all_following), mutual_following, logger, logfolder)\n    return mutual_following"
        ]
    },
    {
        "func_name": "store_followers_data",
        "original": "def store_followers_data(username, grab, grabbed_followers, logger, logfolder):\n    \"\"\"Store grabbed `Followers` data in a local storage at generated date\"\"\"\n    query_date = datetime.today().strftime('%d-%m-%Y')\n    grabbed_followers_size = len(grabbed_followers)\n    file_directory = '{}/relationship_data/{}/followers/'.format(logfolder, username)\n    file_name = '{}{}~{}~{}'.format(file_directory, query_date, grab, grabbed_followers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as followers_data:\n            with interruption_handler():\n                json.dump(grabbed_followers, followers_data)\n        logger.info('Stored `Followers` data at {} local file'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store `Followers` data in a local file :Z\\n{}'.format(str(exc).encode('utf-8')))",
        "mutated": [
            "def store_followers_data(username, grab, grabbed_followers, logger, logfolder):\n    if False:\n        i = 10\n    'Store grabbed `Followers` data in a local storage at generated date'\n    query_date = datetime.today().strftime('%d-%m-%Y')\n    grabbed_followers_size = len(grabbed_followers)\n    file_directory = '{}/relationship_data/{}/followers/'.format(logfolder, username)\n    file_name = '{}{}~{}~{}'.format(file_directory, query_date, grab, grabbed_followers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as followers_data:\n            with interruption_handler():\n                json.dump(grabbed_followers, followers_data)\n        logger.info('Stored `Followers` data at {} local file'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store `Followers` data in a local file :Z\\n{}'.format(str(exc).encode('utf-8')))",
            "def store_followers_data(username, grab, grabbed_followers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Store grabbed `Followers` data in a local storage at generated date'\n    query_date = datetime.today().strftime('%d-%m-%Y')\n    grabbed_followers_size = len(grabbed_followers)\n    file_directory = '{}/relationship_data/{}/followers/'.format(logfolder, username)\n    file_name = '{}{}~{}~{}'.format(file_directory, query_date, grab, grabbed_followers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as followers_data:\n            with interruption_handler():\n                json.dump(grabbed_followers, followers_data)\n        logger.info('Stored `Followers` data at {} local file'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store `Followers` data in a local file :Z\\n{}'.format(str(exc).encode('utf-8')))",
            "def store_followers_data(username, grab, grabbed_followers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Store grabbed `Followers` data in a local storage at generated date'\n    query_date = datetime.today().strftime('%d-%m-%Y')\n    grabbed_followers_size = len(grabbed_followers)\n    file_directory = '{}/relationship_data/{}/followers/'.format(logfolder, username)\n    file_name = '{}{}~{}~{}'.format(file_directory, query_date, grab, grabbed_followers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as followers_data:\n            with interruption_handler():\n                json.dump(grabbed_followers, followers_data)\n        logger.info('Stored `Followers` data at {} local file'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store `Followers` data in a local file :Z\\n{}'.format(str(exc).encode('utf-8')))",
            "def store_followers_data(username, grab, grabbed_followers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Store grabbed `Followers` data in a local storage at generated date'\n    query_date = datetime.today().strftime('%d-%m-%Y')\n    grabbed_followers_size = len(grabbed_followers)\n    file_directory = '{}/relationship_data/{}/followers/'.format(logfolder, username)\n    file_name = '{}{}~{}~{}'.format(file_directory, query_date, grab, grabbed_followers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as followers_data:\n            with interruption_handler():\n                json.dump(grabbed_followers, followers_data)\n        logger.info('Stored `Followers` data at {} local file'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store `Followers` data in a local file :Z\\n{}'.format(str(exc).encode('utf-8')))",
            "def store_followers_data(username, grab, grabbed_followers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Store grabbed `Followers` data in a local storage at generated date'\n    query_date = datetime.today().strftime('%d-%m-%Y')\n    grabbed_followers_size = len(grabbed_followers)\n    file_directory = '{}/relationship_data/{}/followers/'.format(logfolder, username)\n    file_name = '{}{}~{}~{}'.format(file_directory, query_date, grab, grabbed_followers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as followers_data:\n            with interruption_handler():\n                json.dump(grabbed_followers, followers_data)\n        logger.info('Stored `Followers` data at {} local file'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store `Followers` data in a local file :Z\\n{}'.format(str(exc).encode('utf-8')))"
        ]
    },
    {
        "func_name": "store_following_data",
        "original": "def store_following_data(username, grab, grabbed_following, logger, logfolder):\n    \"\"\"Store grabbed `Following` data in a local storage at generated date\"\"\"\n    query_date = datetime.today().strftime('%d-%m-%Y')\n    grabbed_following_size = len(grabbed_following)\n    file_directory = '{}/relationship_data/{}/following/'.format(logfolder, username)\n    file_name = '{}{}~{}~{}'.format(file_directory, query_date, grab, grabbed_following_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as following_data:\n            with interruption_handler():\n                json.dump(grabbed_following, following_data)\n        logger.info('Stored `Following` data at {} local file'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store `Following` data in a local file :Z\\n{}'.format(str(exc).encode('utf-8')))",
        "mutated": [
            "def store_following_data(username, grab, grabbed_following, logger, logfolder):\n    if False:\n        i = 10\n    'Store grabbed `Following` data in a local storage at generated date'\n    query_date = datetime.today().strftime('%d-%m-%Y')\n    grabbed_following_size = len(grabbed_following)\n    file_directory = '{}/relationship_data/{}/following/'.format(logfolder, username)\n    file_name = '{}{}~{}~{}'.format(file_directory, query_date, grab, grabbed_following_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as following_data:\n            with interruption_handler():\n                json.dump(grabbed_following, following_data)\n        logger.info('Stored `Following` data at {} local file'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store `Following` data in a local file :Z\\n{}'.format(str(exc).encode('utf-8')))",
            "def store_following_data(username, grab, grabbed_following, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Store grabbed `Following` data in a local storage at generated date'\n    query_date = datetime.today().strftime('%d-%m-%Y')\n    grabbed_following_size = len(grabbed_following)\n    file_directory = '{}/relationship_data/{}/following/'.format(logfolder, username)\n    file_name = '{}{}~{}~{}'.format(file_directory, query_date, grab, grabbed_following_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as following_data:\n            with interruption_handler():\n                json.dump(grabbed_following, following_data)\n        logger.info('Stored `Following` data at {} local file'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store `Following` data in a local file :Z\\n{}'.format(str(exc).encode('utf-8')))",
            "def store_following_data(username, grab, grabbed_following, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Store grabbed `Following` data in a local storage at generated date'\n    query_date = datetime.today().strftime('%d-%m-%Y')\n    grabbed_following_size = len(grabbed_following)\n    file_directory = '{}/relationship_data/{}/following/'.format(logfolder, username)\n    file_name = '{}{}~{}~{}'.format(file_directory, query_date, grab, grabbed_following_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as following_data:\n            with interruption_handler():\n                json.dump(grabbed_following, following_data)\n        logger.info('Stored `Following` data at {} local file'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store `Following` data in a local file :Z\\n{}'.format(str(exc).encode('utf-8')))",
            "def store_following_data(username, grab, grabbed_following, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Store grabbed `Following` data in a local storage at generated date'\n    query_date = datetime.today().strftime('%d-%m-%Y')\n    grabbed_following_size = len(grabbed_following)\n    file_directory = '{}/relationship_data/{}/following/'.format(logfolder, username)\n    file_name = '{}{}~{}~{}'.format(file_directory, query_date, grab, grabbed_following_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as following_data:\n            with interruption_handler():\n                json.dump(grabbed_following, following_data)\n        logger.info('Stored `Following` data at {} local file'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store `Following` data in a local file :Z\\n{}'.format(str(exc).encode('utf-8')))",
            "def store_following_data(username, grab, grabbed_following, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Store grabbed `Following` data in a local storage at generated date'\n    query_date = datetime.today().strftime('%d-%m-%Y')\n    grabbed_following_size = len(grabbed_following)\n    file_directory = '{}/relationship_data/{}/following/'.format(logfolder, username)\n    file_name = '{}{}~{}~{}'.format(file_directory, query_date, grab, grabbed_following_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as following_data:\n            with interruption_handler():\n                json.dump(grabbed_following, following_data)\n        logger.info('Stored `Following` data at {} local file'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store `Following` data in a local file :Z\\n{}'.format(str(exc).encode('utf-8')))"
        ]
    },
    {
        "func_name": "store_all_unfollowers",
        "original": "def store_all_unfollowers(username, all_unfollowers, logger, logfolder):\n    \"\"\"Store all Unfollowers data in a local storage at generated date\"\"\"\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    all_unfollowers_size = len(all_unfollowers)\n    file_directory = '{}/relationship_data/{}/unfollowers/all_unfollowers/'.format(logfolder, username)\n    file_name = '{}{}~all~{}'.format(file_directory, generation_date, all_unfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as unfollowers_data:\n            with interruption_handler():\n                json.dump(all_unfollowers, unfollowers_data)\n        logger.info('Stored all Unfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store all Unfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
        "mutated": [
            "def store_all_unfollowers(username, all_unfollowers, logger, logfolder):\n    if False:\n        i = 10\n    'Store all Unfollowers data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    all_unfollowers_size = len(all_unfollowers)\n    file_directory = '{}/relationship_data/{}/unfollowers/all_unfollowers/'.format(logfolder, username)\n    file_name = '{}{}~all~{}'.format(file_directory, generation_date, all_unfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as unfollowers_data:\n            with interruption_handler():\n                json.dump(all_unfollowers, unfollowers_data)\n        logger.info('Stored all Unfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store all Unfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_all_unfollowers(username, all_unfollowers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Store all Unfollowers data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    all_unfollowers_size = len(all_unfollowers)\n    file_directory = '{}/relationship_data/{}/unfollowers/all_unfollowers/'.format(logfolder, username)\n    file_name = '{}{}~all~{}'.format(file_directory, generation_date, all_unfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as unfollowers_data:\n            with interruption_handler():\n                json.dump(all_unfollowers, unfollowers_data)\n        logger.info('Stored all Unfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store all Unfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_all_unfollowers(username, all_unfollowers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Store all Unfollowers data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    all_unfollowers_size = len(all_unfollowers)\n    file_directory = '{}/relationship_data/{}/unfollowers/all_unfollowers/'.format(logfolder, username)\n    file_name = '{}{}~all~{}'.format(file_directory, generation_date, all_unfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as unfollowers_data:\n            with interruption_handler():\n                json.dump(all_unfollowers, unfollowers_data)\n        logger.info('Stored all Unfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store all Unfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_all_unfollowers(username, all_unfollowers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Store all Unfollowers data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    all_unfollowers_size = len(all_unfollowers)\n    file_directory = '{}/relationship_data/{}/unfollowers/all_unfollowers/'.format(logfolder, username)\n    file_name = '{}{}~all~{}'.format(file_directory, generation_date, all_unfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as unfollowers_data:\n            with interruption_handler():\n                json.dump(all_unfollowers, unfollowers_data)\n        logger.info('Stored all Unfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store all Unfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_all_unfollowers(username, all_unfollowers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Store all Unfollowers data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    all_unfollowers_size = len(all_unfollowers)\n    file_directory = '{}/relationship_data/{}/unfollowers/all_unfollowers/'.format(logfolder, username)\n    file_name = '{}{}~all~{}'.format(file_directory, generation_date, all_unfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as unfollowers_data:\n            with interruption_handler():\n                json.dump(all_unfollowers, unfollowers_data)\n        logger.info('Stored all Unfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store all Unfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))"
        ]
    },
    {
        "func_name": "store_active_unfollowers",
        "original": "def store_active_unfollowers(username, active_unfollowers, logger, logfolder):\n    \"\"\"Store active Unfollowers data in a local storage at generated date\"\"\"\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    active_unfollowers_size = len(active_unfollowers)\n    file_directory = '{}/relationship_data/{}/unfollowers/active_unfollowers/'.format(logfolder, username)\n    file_name = '{}{}~active~{}'.format(file_directory, generation_date, active_unfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as active_unfollowers_data:\n            with interruption_handler():\n                json.dump(active_unfollowers, active_unfollowers_data)\n        logger.info('Stored active Unfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store active Unfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
        "mutated": [
            "def store_active_unfollowers(username, active_unfollowers, logger, logfolder):\n    if False:\n        i = 10\n    'Store active Unfollowers data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    active_unfollowers_size = len(active_unfollowers)\n    file_directory = '{}/relationship_data/{}/unfollowers/active_unfollowers/'.format(logfolder, username)\n    file_name = '{}{}~active~{}'.format(file_directory, generation_date, active_unfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as active_unfollowers_data:\n            with interruption_handler():\n                json.dump(active_unfollowers, active_unfollowers_data)\n        logger.info('Stored active Unfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store active Unfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_active_unfollowers(username, active_unfollowers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Store active Unfollowers data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    active_unfollowers_size = len(active_unfollowers)\n    file_directory = '{}/relationship_data/{}/unfollowers/active_unfollowers/'.format(logfolder, username)\n    file_name = '{}{}~active~{}'.format(file_directory, generation_date, active_unfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as active_unfollowers_data:\n            with interruption_handler():\n                json.dump(active_unfollowers, active_unfollowers_data)\n        logger.info('Stored active Unfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store active Unfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_active_unfollowers(username, active_unfollowers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Store active Unfollowers data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    active_unfollowers_size = len(active_unfollowers)\n    file_directory = '{}/relationship_data/{}/unfollowers/active_unfollowers/'.format(logfolder, username)\n    file_name = '{}{}~active~{}'.format(file_directory, generation_date, active_unfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as active_unfollowers_data:\n            with interruption_handler():\n                json.dump(active_unfollowers, active_unfollowers_data)\n        logger.info('Stored active Unfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store active Unfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_active_unfollowers(username, active_unfollowers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Store active Unfollowers data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    active_unfollowers_size = len(active_unfollowers)\n    file_directory = '{}/relationship_data/{}/unfollowers/active_unfollowers/'.format(logfolder, username)\n    file_name = '{}{}~active~{}'.format(file_directory, generation_date, active_unfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as active_unfollowers_data:\n            with interruption_handler():\n                json.dump(active_unfollowers, active_unfollowers_data)\n        logger.info('Stored active Unfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store active Unfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_active_unfollowers(username, active_unfollowers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Store active Unfollowers data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    active_unfollowers_size = len(active_unfollowers)\n    file_directory = '{}/relationship_data/{}/unfollowers/active_unfollowers/'.format(logfolder, username)\n    file_name = '{}{}~active~{}'.format(file_directory, generation_date, active_unfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as active_unfollowers_data:\n            with interruption_handler():\n                json.dump(active_unfollowers, active_unfollowers_data)\n        logger.info('Stored active Unfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store active Unfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))"
        ]
    },
    {
        "func_name": "store_nonfollowers",
        "original": "def store_nonfollowers(username, followers_size, following_size, nonfollowers, logger, logfolder):\n    \"\"\"Store Nonfollowers data in a local storage at generated date\"\"\"\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    nonfollowers_size = len(nonfollowers)\n    file_directory = '{}/relationship_data/{}/nonfollowers/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, nonfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as nonfollowers_data:\n            with interruption_handler():\n                json.dump(nonfollowers, nonfollowers_data)\n        logger.info('Stored Nonfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Nonfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
        "mutated": [
            "def store_nonfollowers(username, followers_size, following_size, nonfollowers, logger, logfolder):\n    if False:\n        i = 10\n    'Store Nonfollowers data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    nonfollowers_size = len(nonfollowers)\n    file_directory = '{}/relationship_data/{}/nonfollowers/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, nonfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as nonfollowers_data:\n            with interruption_handler():\n                json.dump(nonfollowers, nonfollowers_data)\n        logger.info('Stored Nonfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Nonfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_nonfollowers(username, followers_size, following_size, nonfollowers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Store Nonfollowers data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    nonfollowers_size = len(nonfollowers)\n    file_directory = '{}/relationship_data/{}/nonfollowers/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, nonfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as nonfollowers_data:\n            with interruption_handler():\n                json.dump(nonfollowers, nonfollowers_data)\n        logger.info('Stored Nonfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Nonfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_nonfollowers(username, followers_size, following_size, nonfollowers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Store Nonfollowers data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    nonfollowers_size = len(nonfollowers)\n    file_directory = '{}/relationship_data/{}/nonfollowers/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, nonfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as nonfollowers_data:\n            with interruption_handler():\n                json.dump(nonfollowers, nonfollowers_data)\n        logger.info('Stored Nonfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Nonfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_nonfollowers(username, followers_size, following_size, nonfollowers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Store Nonfollowers data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    nonfollowers_size = len(nonfollowers)\n    file_directory = '{}/relationship_data/{}/nonfollowers/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, nonfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as nonfollowers_data:\n            with interruption_handler():\n                json.dump(nonfollowers, nonfollowers_data)\n        logger.info('Stored Nonfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Nonfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_nonfollowers(username, followers_size, following_size, nonfollowers, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Store Nonfollowers data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    nonfollowers_size = len(nonfollowers)\n    file_directory = '{}/relationship_data/{}/nonfollowers/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, nonfollowers_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as nonfollowers_data:\n            with interruption_handler():\n                json.dump(nonfollowers, nonfollowers_data)\n        logger.info('Stored Nonfollowers data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Nonfollowers data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))"
        ]
    },
    {
        "func_name": "store_fans",
        "original": "def store_fans(username, followers_size, following_size, fans, logger, logfolder):\n    \"\"\"Store Fans data in a local storage at generated date\"\"\"\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    fans_size = len(fans)\n    file_directory = '{}/relationship_data/{}/fans/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, fans_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as fans_data:\n            with interruption_handler():\n                json.dump(fans, fans_data)\n        logger.info('Stored Fans data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Fans data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
        "mutated": [
            "def store_fans(username, followers_size, following_size, fans, logger, logfolder):\n    if False:\n        i = 10\n    'Store Fans data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    fans_size = len(fans)\n    file_directory = '{}/relationship_data/{}/fans/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, fans_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as fans_data:\n            with interruption_handler():\n                json.dump(fans, fans_data)\n        logger.info('Stored Fans data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Fans data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_fans(username, followers_size, following_size, fans, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Store Fans data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    fans_size = len(fans)\n    file_directory = '{}/relationship_data/{}/fans/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, fans_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as fans_data:\n            with interruption_handler():\n                json.dump(fans, fans_data)\n        logger.info('Stored Fans data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Fans data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_fans(username, followers_size, following_size, fans, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Store Fans data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    fans_size = len(fans)\n    file_directory = '{}/relationship_data/{}/fans/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, fans_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as fans_data:\n            with interruption_handler():\n                json.dump(fans, fans_data)\n        logger.info('Stored Fans data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Fans data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_fans(username, followers_size, following_size, fans, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Store Fans data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    fans_size = len(fans)\n    file_directory = '{}/relationship_data/{}/fans/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, fans_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as fans_data:\n            with interruption_handler():\n                json.dump(fans, fans_data)\n        logger.info('Stored Fans data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Fans data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_fans(username, followers_size, following_size, fans, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Store Fans data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    fans_size = len(fans)\n    file_directory = '{}/relationship_data/{}/fans/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, fans_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as fans_data:\n            with interruption_handler():\n                json.dump(fans, fans_data)\n        logger.info('Stored Fans data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Fans data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))"
        ]
    },
    {
        "func_name": "store_mutual_following",
        "original": "def store_mutual_following(username, followers_size, following_size, mutual_following, logger, logfolder):\n    \"\"\"Store Mutual Following data in a local storage at generated date\"\"\"\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    mutual_following_size = len(mutual_following)\n    file_directory = '{}/relationship_data/{}/mutual_following/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, mutual_following_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as mutual_following_data:\n            with interruption_handler():\n                json.dump(mutual_following, mutual_following_data)\n        logger.info('Stored Mutual Following data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Mutual Following data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
        "mutated": [
            "def store_mutual_following(username, followers_size, following_size, mutual_following, logger, logfolder):\n    if False:\n        i = 10\n    'Store Mutual Following data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    mutual_following_size = len(mutual_following)\n    file_directory = '{}/relationship_data/{}/mutual_following/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, mutual_following_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as mutual_following_data:\n            with interruption_handler():\n                json.dump(mutual_following, mutual_following_data)\n        logger.info('Stored Mutual Following data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Mutual Following data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_mutual_following(username, followers_size, following_size, mutual_following, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Store Mutual Following data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    mutual_following_size = len(mutual_following)\n    file_directory = '{}/relationship_data/{}/mutual_following/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, mutual_following_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as mutual_following_data:\n            with interruption_handler():\n                json.dump(mutual_following, mutual_following_data)\n        logger.info('Stored Mutual Following data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Mutual Following data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_mutual_following(username, followers_size, following_size, mutual_following, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Store Mutual Following data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    mutual_following_size = len(mutual_following)\n    file_directory = '{}/relationship_data/{}/mutual_following/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, mutual_following_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as mutual_following_data:\n            with interruption_handler():\n                json.dump(mutual_following, mutual_following_data)\n        logger.info('Stored Mutual Following data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Mutual Following data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_mutual_following(username, followers_size, following_size, mutual_following, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Store Mutual Following data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    mutual_following_size = len(mutual_following)\n    file_directory = '{}/relationship_data/{}/mutual_following/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, mutual_following_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as mutual_following_data:\n            with interruption_handler():\n                json.dump(mutual_following, mutual_following_data)\n        logger.info('Stored Mutual Following data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Mutual Following data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))",
            "def store_mutual_following(username, followers_size, following_size, mutual_following, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Store Mutual Following data in a local storage at generated date'\n    generation_date = datetime.today().strftime('%d-%m-%Y')\n    mutual_following_size = len(mutual_following)\n    file_directory = '{}/relationship_data/{}/mutual_following/'.format(logfolder, username)\n    file_name = '{}{}~[{}-{}]~{}'.format(file_directory, generation_date, followers_size, following_size, mutual_following_size)\n    file_index = 0\n    final_file = '{}.json'.format(file_name)\n    try:\n        if not os.path.exists(file_directory):\n            os.makedirs(file_directory)\n        while os.path.isfile(final_file):\n            file_index += 1\n            final_file = '{}({}).json'.format(file_name, file_index)\n        with open(final_file, 'w') as mutual_following_data:\n            with interruption_handler():\n                json.dump(mutual_following, mutual_following_data)\n        logger.info('Stored Mutual Following data at {} local file\\n'.format(final_file))\n    except Exception as exc:\n        logger.info('Failed to store Mutual Following data in a local file :Z\\n{}\\n'.format(str(exc).encode('utf-8')))"
        ]
    },
    {
        "func_name": "load_followers_data",
        "original": "def load_followers_data(username, compare_by, compare_track, logger, logfolder):\n    \"\"\"Write grabbed `followers` data into local storage\"\"\"\n    tracked_filenames = []\n    structured_entries = {}\n    selected_filename = None\n    files_location = '{}/relationship_data/{}/followers'.format(logfolder, username)\n    followers_data_files = [os.path.basename(file) for file in glob.glob('{}/*~full*.json'.format(files_location))]\n    if not followers_data_files:\n        logger.info('There are no any `Followers` data files in the {} location to compare'.format(files_location))\n        return ([], None)\n    for data_file in followers_data_files:\n        tracked_filenames.append(data_file[:10])\n    sorted_filenames = sorted(tracked_filenames, key=lambda x: datetime.strptime(x, '%d-%m-%Y'))\n    this_day = datetime.today().strftime('%d')\n    this_month = datetime.today().strftime('%m')\n    this_year = datetime.today().strftime('%Y')\n    for entry in sorted_filenames:\n        (entry_day, entry_month, entry_year) = entry.split('-')\n        structured_entries.setdefault('years', {}).setdefault(entry_year, {}).setdefault('months', {}).setdefault(entry_month, {}).setdefault('days', {}).setdefault(entry_day, {}).setdefault('entries', []).append(entry)\n    if compare_by == 'latest':\n        selected_filename = sorted_filenames[-1]\n    elif compare_by == 'day':\n        latest_day = sorted_filenames[-1]\n        current_day = datetime.today().strftime('%d-%m-%Y')\n        if latest_day == current_day:\n            data_for_today = structured_entries['years'][this_year]['months'][this_month]['days'][this_day]['entries']\n            if compare_track == 'first' or len(data_for_today) <= 1:\n                selected_filename = data_for_today[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_today) / 2)\n                selected_filename = data_for_today[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_today[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for today!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'month':\n        latest_month = sorted_filenames[-1][-7:]\n        current_month = datetime.today().strftime('%m-%Y')\n        if latest_month == current_month:\n            data_for_month = []\n            for day in structured_entries['years'][this_year]['months'][this_month]['days']:\n                data_for_month.extend(structured_entries['years'][this_year]['months'][this_month]['days'][day]['entries'])\n            if compare_track == 'first' or len(data_for_month) <= 1:\n                selected_filename = data_for_month[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_month) / 2)\n                selected_filename = data_for_month[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_month[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for this month!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'year':\n        latest_year = sorted_filenames[-1][-4:]\n        if latest_year == this_year:\n            data_for_year = []\n            for month in structured_entries['years'][this_year]['months']:\n                for day in structured_entries['years'][this_year]['months'][month]['days']:\n                    data_for_year.extend(structured_entries['years'][this_year]['months'][month]['days'][day]['entries'])\n            if compare_track == 'first' or len(data_for_year) <= 1:\n                selected_filename = data_for_year[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_year) / 2)\n                selected_filename = data_for_year[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_year[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for this year!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'earliest':\n        selected_filename = sorted_filenames[0]\n    selected_file = glob.glob('{}/{}~full*.json'.format(files_location, selected_filename))[0]\n    with open(selected_file) as followers_data_file:\n        followers_data = json.load(followers_data_file)\n    logger.info('Took prior `Followers` data file from {} with {} usernames to be compared with live data\\n'.format(selected_filename, len(followers_data)))\n    return (followers_data, selected_filename)",
        "mutated": [
            "def load_followers_data(username, compare_by, compare_track, logger, logfolder):\n    if False:\n        i = 10\n    'Write grabbed `followers` data into local storage'\n    tracked_filenames = []\n    structured_entries = {}\n    selected_filename = None\n    files_location = '{}/relationship_data/{}/followers'.format(logfolder, username)\n    followers_data_files = [os.path.basename(file) for file in glob.glob('{}/*~full*.json'.format(files_location))]\n    if not followers_data_files:\n        logger.info('There are no any `Followers` data files in the {} location to compare'.format(files_location))\n        return ([], None)\n    for data_file in followers_data_files:\n        tracked_filenames.append(data_file[:10])\n    sorted_filenames = sorted(tracked_filenames, key=lambda x: datetime.strptime(x, '%d-%m-%Y'))\n    this_day = datetime.today().strftime('%d')\n    this_month = datetime.today().strftime('%m')\n    this_year = datetime.today().strftime('%Y')\n    for entry in sorted_filenames:\n        (entry_day, entry_month, entry_year) = entry.split('-')\n        structured_entries.setdefault('years', {}).setdefault(entry_year, {}).setdefault('months', {}).setdefault(entry_month, {}).setdefault('days', {}).setdefault(entry_day, {}).setdefault('entries', []).append(entry)\n    if compare_by == 'latest':\n        selected_filename = sorted_filenames[-1]\n    elif compare_by == 'day':\n        latest_day = sorted_filenames[-1]\n        current_day = datetime.today().strftime('%d-%m-%Y')\n        if latest_day == current_day:\n            data_for_today = structured_entries['years'][this_year]['months'][this_month]['days'][this_day]['entries']\n            if compare_track == 'first' or len(data_for_today) <= 1:\n                selected_filename = data_for_today[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_today) / 2)\n                selected_filename = data_for_today[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_today[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for today!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'month':\n        latest_month = sorted_filenames[-1][-7:]\n        current_month = datetime.today().strftime('%m-%Y')\n        if latest_month == current_month:\n            data_for_month = []\n            for day in structured_entries['years'][this_year]['months'][this_month]['days']:\n                data_for_month.extend(structured_entries['years'][this_year]['months'][this_month]['days'][day]['entries'])\n            if compare_track == 'first' or len(data_for_month) <= 1:\n                selected_filename = data_for_month[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_month) / 2)\n                selected_filename = data_for_month[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_month[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for this month!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'year':\n        latest_year = sorted_filenames[-1][-4:]\n        if latest_year == this_year:\n            data_for_year = []\n            for month in structured_entries['years'][this_year]['months']:\n                for day in structured_entries['years'][this_year]['months'][month]['days']:\n                    data_for_year.extend(structured_entries['years'][this_year]['months'][month]['days'][day]['entries'])\n            if compare_track == 'first' or len(data_for_year) <= 1:\n                selected_filename = data_for_year[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_year) / 2)\n                selected_filename = data_for_year[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_year[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for this year!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'earliest':\n        selected_filename = sorted_filenames[0]\n    selected_file = glob.glob('{}/{}~full*.json'.format(files_location, selected_filename))[0]\n    with open(selected_file) as followers_data_file:\n        followers_data = json.load(followers_data_file)\n    logger.info('Took prior `Followers` data file from {} with {} usernames to be compared with live data\\n'.format(selected_filename, len(followers_data)))\n    return (followers_data, selected_filename)",
            "def load_followers_data(username, compare_by, compare_track, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Write grabbed `followers` data into local storage'\n    tracked_filenames = []\n    structured_entries = {}\n    selected_filename = None\n    files_location = '{}/relationship_data/{}/followers'.format(logfolder, username)\n    followers_data_files = [os.path.basename(file) for file in glob.glob('{}/*~full*.json'.format(files_location))]\n    if not followers_data_files:\n        logger.info('There are no any `Followers` data files in the {} location to compare'.format(files_location))\n        return ([], None)\n    for data_file in followers_data_files:\n        tracked_filenames.append(data_file[:10])\n    sorted_filenames = sorted(tracked_filenames, key=lambda x: datetime.strptime(x, '%d-%m-%Y'))\n    this_day = datetime.today().strftime('%d')\n    this_month = datetime.today().strftime('%m')\n    this_year = datetime.today().strftime('%Y')\n    for entry in sorted_filenames:\n        (entry_day, entry_month, entry_year) = entry.split('-')\n        structured_entries.setdefault('years', {}).setdefault(entry_year, {}).setdefault('months', {}).setdefault(entry_month, {}).setdefault('days', {}).setdefault(entry_day, {}).setdefault('entries', []).append(entry)\n    if compare_by == 'latest':\n        selected_filename = sorted_filenames[-1]\n    elif compare_by == 'day':\n        latest_day = sorted_filenames[-1]\n        current_day = datetime.today().strftime('%d-%m-%Y')\n        if latest_day == current_day:\n            data_for_today = structured_entries['years'][this_year]['months'][this_month]['days'][this_day]['entries']\n            if compare_track == 'first' or len(data_for_today) <= 1:\n                selected_filename = data_for_today[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_today) / 2)\n                selected_filename = data_for_today[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_today[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for today!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'month':\n        latest_month = sorted_filenames[-1][-7:]\n        current_month = datetime.today().strftime('%m-%Y')\n        if latest_month == current_month:\n            data_for_month = []\n            for day in structured_entries['years'][this_year]['months'][this_month]['days']:\n                data_for_month.extend(structured_entries['years'][this_year]['months'][this_month]['days'][day]['entries'])\n            if compare_track == 'first' or len(data_for_month) <= 1:\n                selected_filename = data_for_month[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_month) / 2)\n                selected_filename = data_for_month[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_month[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for this month!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'year':\n        latest_year = sorted_filenames[-1][-4:]\n        if latest_year == this_year:\n            data_for_year = []\n            for month in structured_entries['years'][this_year]['months']:\n                for day in structured_entries['years'][this_year]['months'][month]['days']:\n                    data_for_year.extend(structured_entries['years'][this_year]['months'][month]['days'][day]['entries'])\n            if compare_track == 'first' or len(data_for_year) <= 1:\n                selected_filename = data_for_year[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_year) / 2)\n                selected_filename = data_for_year[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_year[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for this year!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'earliest':\n        selected_filename = sorted_filenames[0]\n    selected_file = glob.glob('{}/{}~full*.json'.format(files_location, selected_filename))[0]\n    with open(selected_file) as followers_data_file:\n        followers_data = json.load(followers_data_file)\n    logger.info('Took prior `Followers` data file from {} with {} usernames to be compared with live data\\n'.format(selected_filename, len(followers_data)))\n    return (followers_data, selected_filename)",
            "def load_followers_data(username, compare_by, compare_track, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Write grabbed `followers` data into local storage'\n    tracked_filenames = []\n    structured_entries = {}\n    selected_filename = None\n    files_location = '{}/relationship_data/{}/followers'.format(logfolder, username)\n    followers_data_files = [os.path.basename(file) for file in glob.glob('{}/*~full*.json'.format(files_location))]\n    if not followers_data_files:\n        logger.info('There are no any `Followers` data files in the {} location to compare'.format(files_location))\n        return ([], None)\n    for data_file in followers_data_files:\n        tracked_filenames.append(data_file[:10])\n    sorted_filenames = sorted(tracked_filenames, key=lambda x: datetime.strptime(x, '%d-%m-%Y'))\n    this_day = datetime.today().strftime('%d')\n    this_month = datetime.today().strftime('%m')\n    this_year = datetime.today().strftime('%Y')\n    for entry in sorted_filenames:\n        (entry_day, entry_month, entry_year) = entry.split('-')\n        structured_entries.setdefault('years', {}).setdefault(entry_year, {}).setdefault('months', {}).setdefault(entry_month, {}).setdefault('days', {}).setdefault(entry_day, {}).setdefault('entries', []).append(entry)\n    if compare_by == 'latest':\n        selected_filename = sorted_filenames[-1]\n    elif compare_by == 'day':\n        latest_day = sorted_filenames[-1]\n        current_day = datetime.today().strftime('%d-%m-%Y')\n        if latest_day == current_day:\n            data_for_today = structured_entries['years'][this_year]['months'][this_month]['days'][this_day]['entries']\n            if compare_track == 'first' or len(data_for_today) <= 1:\n                selected_filename = data_for_today[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_today) / 2)\n                selected_filename = data_for_today[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_today[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for today!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'month':\n        latest_month = sorted_filenames[-1][-7:]\n        current_month = datetime.today().strftime('%m-%Y')\n        if latest_month == current_month:\n            data_for_month = []\n            for day in structured_entries['years'][this_year]['months'][this_month]['days']:\n                data_for_month.extend(structured_entries['years'][this_year]['months'][this_month]['days'][day]['entries'])\n            if compare_track == 'first' or len(data_for_month) <= 1:\n                selected_filename = data_for_month[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_month) / 2)\n                selected_filename = data_for_month[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_month[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for this month!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'year':\n        latest_year = sorted_filenames[-1][-4:]\n        if latest_year == this_year:\n            data_for_year = []\n            for month in structured_entries['years'][this_year]['months']:\n                for day in structured_entries['years'][this_year]['months'][month]['days']:\n                    data_for_year.extend(structured_entries['years'][this_year]['months'][month]['days'][day]['entries'])\n            if compare_track == 'first' or len(data_for_year) <= 1:\n                selected_filename = data_for_year[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_year) / 2)\n                selected_filename = data_for_year[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_year[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for this year!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'earliest':\n        selected_filename = sorted_filenames[0]\n    selected_file = glob.glob('{}/{}~full*.json'.format(files_location, selected_filename))[0]\n    with open(selected_file) as followers_data_file:\n        followers_data = json.load(followers_data_file)\n    logger.info('Took prior `Followers` data file from {} with {} usernames to be compared with live data\\n'.format(selected_filename, len(followers_data)))\n    return (followers_data, selected_filename)",
            "def load_followers_data(username, compare_by, compare_track, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Write grabbed `followers` data into local storage'\n    tracked_filenames = []\n    structured_entries = {}\n    selected_filename = None\n    files_location = '{}/relationship_data/{}/followers'.format(logfolder, username)\n    followers_data_files = [os.path.basename(file) for file in glob.glob('{}/*~full*.json'.format(files_location))]\n    if not followers_data_files:\n        logger.info('There are no any `Followers` data files in the {} location to compare'.format(files_location))\n        return ([], None)\n    for data_file in followers_data_files:\n        tracked_filenames.append(data_file[:10])\n    sorted_filenames = sorted(tracked_filenames, key=lambda x: datetime.strptime(x, '%d-%m-%Y'))\n    this_day = datetime.today().strftime('%d')\n    this_month = datetime.today().strftime('%m')\n    this_year = datetime.today().strftime('%Y')\n    for entry in sorted_filenames:\n        (entry_day, entry_month, entry_year) = entry.split('-')\n        structured_entries.setdefault('years', {}).setdefault(entry_year, {}).setdefault('months', {}).setdefault(entry_month, {}).setdefault('days', {}).setdefault(entry_day, {}).setdefault('entries', []).append(entry)\n    if compare_by == 'latest':\n        selected_filename = sorted_filenames[-1]\n    elif compare_by == 'day':\n        latest_day = sorted_filenames[-1]\n        current_day = datetime.today().strftime('%d-%m-%Y')\n        if latest_day == current_day:\n            data_for_today = structured_entries['years'][this_year]['months'][this_month]['days'][this_day]['entries']\n            if compare_track == 'first' or len(data_for_today) <= 1:\n                selected_filename = data_for_today[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_today) / 2)\n                selected_filename = data_for_today[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_today[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for today!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'month':\n        latest_month = sorted_filenames[-1][-7:]\n        current_month = datetime.today().strftime('%m-%Y')\n        if latest_month == current_month:\n            data_for_month = []\n            for day in structured_entries['years'][this_year]['months'][this_month]['days']:\n                data_for_month.extend(structured_entries['years'][this_year]['months'][this_month]['days'][day]['entries'])\n            if compare_track == 'first' or len(data_for_month) <= 1:\n                selected_filename = data_for_month[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_month) / 2)\n                selected_filename = data_for_month[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_month[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for this month!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'year':\n        latest_year = sorted_filenames[-1][-4:]\n        if latest_year == this_year:\n            data_for_year = []\n            for month in structured_entries['years'][this_year]['months']:\n                for day in structured_entries['years'][this_year]['months'][month]['days']:\n                    data_for_year.extend(structured_entries['years'][this_year]['months'][month]['days'][day]['entries'])\n            if compare_track == 'first' or len(data_for_year) <= 1:\n                selected_filename = data_for_year[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_year) / 2)\n                selected_filename = data_for_year[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_year[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for this year!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'earliest':\n        selected_filename = sorted_filenames[0]\n    selected_file = glob.glob('{}/{}~full*.json'.format(files_location, selected_filename))[0]\n    with open(selected_file) as followers_data_file:\n        followers_data = json.load(followers_data_file)\n    logger.info('Took prior `Followers` data file from {} with {} usernames to be compared with live data\\n'.format(selected_filename, len(followers_data)))\n    return (followers_data, selected_filename)",
            "def load_followers_data(username, compare_by, compare_track, logger, logfolder):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Write grabbed `followers` data into local storage'\n    tracked_filenames = []\n    structured_entries = {}\n    selected_filename = None\n    files_location = '{}/relationship_data/{}/followers'.format(logfolder, username)\n    followers_data_files = [os.path.basename(file) for file in glob.glob('{}/*~full*.json'.format(files_location))]\n    if not followers_data_files:\n        logger.info('There are no any `Followers` data files in the {} location to compare'.format(files_location))\n        return ([], None)\n    for data_file in followers_data_files:\n        tracked_filenames.append(data_file[:10])\n    sorted_filenames = sorted(tracked_filenames, key=lambda x: datetime.strptime(x, '%d-%m-%Y'))\n    this_day = datetime.today().strftime('%d')\n    this_month = datetime.today().strftime('%m')\n    this_year = datetime.today().strftime('%Y')\n    for entry in sorted_filenames:\n        (entry_day, entry_month, entry_year) = entry.split('-')\n        structured_entries.setdefault('years', {}).setdefault(entry_year, {}).setdefault('months', {}).setdefault(entry_month, {}).setdefault('days', {}).setdefault(entry_day, {}).setdefault('entries', []).append(entry)\n    if compare_by == 'latest':\n        selected_filename = sorted_filenames[-1]\n    elif compare_by == 'day':\n        latest_day = sorted_filenames[-1]\n        current_day = datetime.today().strftime('%d-%m-%Y')\n        if latest_day == current_day:\n            data_for_today = structured_entries['years'][this_year]['months'][this_month]['days'][this_day]['entries']\n            if compare_track == 'first' or len(data_for_today) <= 1:\n                selected_filename = data_for_today[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_today) / 2)\n                selected_filename = data_for_today[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_today[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for today!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'month':\n        latest_month = sorted_filenames[-1][-7:]\n        current_month = datetime.today().strftime('%m-%Y')\n        if latest_month == current_month:\n            data_for_month = []\n            for day in structured_entries['years'][this_year]['months'][this_month]['days']:\n                data_for_month.extend(structured_entries['years'][this_year]['months'][this_month]['days'][day]['entries'])\n            if compare_track == 'first' or len(data_for_month) <= 1:\n                selected_filename = data_for_month[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_month) / 2)\n                selected_filename = data_for_month[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_month[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for this month!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'year':\n        latest_year = sorted_filenames[-1][-4:]\n        if latest_year == this_year:\n            data_for_year = []\n            for month in structured_entries['years'][this_year]['months']:\n                for day in structured_entries['years'][this_year]['months'][month]['days']:\n                    data_for_year.extend(structured_entries['years'][this_year]['months'][month]['days'][day]['entries'])\n            if compare_track == 'first' or len(data_for_year) <= 1:\n                selected_filename = data_for_year[0]\n            if compare_track == 'median':\n                median_index = int(len(data_for_year) / 2)\n                selected_filename = data_for_year[median_index]\n            if compare_track == 'last':\n                selected_filename = data_for_year[-1]\n        else:\n            selected_filename = sorted_filenames[-1]\n            logger.info('No any data exists for this year!  ~choosing the last existing data from {}'.format(selected_filename))\n    elif compare_by == 'earliest':\n        selected_filename = sorted_filenames[0]\n    selected_file = glob.glob('{}/{}~full*.json'.format(files_location, selected_filename))[0]\n    with open(selected_file) as followers_data_file:\n        followers_data = json.load(followers_data_file)\n    logger.info('Took prior `Followers` data file from {} with {} usernames to be compared with live data\\n'.format(selected_filename, len(followers_data)))\n    return (followers_data, selected_filename)"
        ]
    }
]