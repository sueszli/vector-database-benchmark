[
    {
        "func_name": "find_threshold_cli",
        "original": "@app.command('find-threshold', context_settings={'allow_extra_args': False, 'ignore_unknown_options': True})\ndef find_threshold_cli(model: str=Arg(..., help='Model name or path'), data_path: Path=Arg(..., help='Location of binary evaluation data in .spacy format', exists=True), pipe_name: str=Arg(..., help='Name of pipe to examine thresholds for'), threshold_key: str=Arg(..., help=\"Key of threshold attribute in component's configuration\"), scores_key: str=Arg(..., help='Metric to optimize'), n_trials: int=Opt(_DEFAULTS['n_trials'], '--n_trials', '-n', help='Number of trials to determine optimal thresholds'), code_path: Optional[Path]=Opt(None, '--code', '-c', help='Path to Python file with additional code (registered functions) to be imported'), use_gpu: int=Opt(_DEFAULTS['use_gpu'], '--gpu-id', '-g', help='GPU ID or -1 for CPU'), gold_preproc: bool=Opt(_DEFAULTS['gold_preproc'], '--gold-preproc', '-G', help='Use gold preprocessing'), verbose: bool=Opt(False, '--verbose', '-V', '-VV', help='Display more information for debugging purposes')):\n    \"\"\"\n    Runs prediction trials for a trained model with varying tresholds to maximize\n    the specified metric. The search space for the threshold is traversed linearly\n    from 0 to 1 in `n_trials` steps. Results are displayed in a table on `stdout`\n    (the corresponding API call to `spacy.cli.find_threshold.find_threshold()`\n    returns all results).\n\n    This is applicable only for components whose predictions are influenced by\n    thresholds - e.g. `textcat_multilabel` and `spancat`, but not `textcat`. Note\n    that the full path to the corresponding threshold attribute in the config has to\n    be provided.\n\n    DOCS: https://spacy.io/api/cli#find-threshold\n    \"\"\"\n    if verbose:\n        util.logger.setLevel(logging.DEBUG)\n    import_code(code_path)\n    find_threshold(model=model, data_path=data_path, pipe_name=pipe_name, threshold_key=threshold_key, scores_key=scores_key, n_trials=n_trials, use_gpu=use_gpu, gold_preproc=gold_preproc, silent=False)",
        "mutated": [
            "@app.command('find-threshold', context_settings={'allow_extra_args': False, 'ignore_unknown_options': True})\ndef find_threshold_cli(model: str=Arg(..., help='Model name or path'), data_path: Path=Arg(..., help='Location of binary evaluation data in .spacy format', exists=True), pipe_name: str=Arg(..., help='Name of pipe to examine thresholds for'), threshold_key: str=Arg(..., help=\"Key of threshold attribute in component's configuration\"), scores_key: str=Arg(..., help='Metric to optimize'), n_trials: int=Opt(_DEFAULTS['n_trials'], '--n_trials', '-n', help='Number of trials to determine optimal thresholds'), code_path: Optional[Path]=Opt(None, '--code', '-c', help='Path to Python file with additional code (registered functions) to be imported'), use_gpu: int=Opt(_DEFAULTS['use_gpu'], '--gpu-id', '-g', help='GPU ID or -1 for CPU'), gold_preproc: bool=Opt(_DEFAULTS['gold_preproc'], '--gold-preproc', '-G', help='Use gold preprocessing'), verbose: bool=Opt(False, '--verbose', '-V', '-VV', help='Display more information for debugging purposes')):\n    if False:\n        i = 10\n    '\\n    Runs prediction trials for a trained model with varying tresholds to maximize\\n    the specified metric. The search space for the threshold is traversed linearly\\n    from 0 to 1 in `n_trials` steps. Results are displayed in a table on `stdout`\\n    (the corresponding API call to `spacy.cli.find_threshold.find_threshold()`\\n    returns all results).\\n\\n    This is applicable only for components whose predictions are influenced by\\n    thresholds - e.g. `textcat_multilabel` and `spancat`, but not `textcat`. Note\\n    that the full path to the corresponding threshold attribute in the config has to\\n    be provided.\\n\\n    DOCS: https://spacy.io/api/cli#find-threshold\\n    '\n    if verbose:\n        util.logger.setLevel(logging.DEBUG)\n    import_code(code_path)\n    find_threshold(model=model, data_path=data_path, pipe_name=pipe_name, threshold_key=threshold_key, scores_key=scores_key, n_trials=n_trials, use_gpu=use_gpu, gold_preproc=gold_preproc, silent=False)",
            "@app.command('find-threshold', context_settings={'allow_extra_args': False, 'ignore_unknown_options': True})\ndef find_threshold_cli(model: str=Arg(..., help='Model name or path'), data_path: Path=Arg(..., help='Location of binary evaluation data in .spacy format', exists=True), pipe_name: str=Arg(..., help='Name of pipe to examine thresholds for'), threshold_key: str=Arg(..., help=\"Key of threshold attribute in component's configuration\"), scores_key: str=Arg(..., help='Metric to optimize'), n_trials: int=Opt(_DEFAULTS['n_trials'], '--n_trials', '-n', help='Number of trials to determine optimal thresholds'), code_path: Optional[Path]=Opt(None, '--code', '-c', help='Path to Python file with additional code (registered functions) to be imported'), use_gpu: int=Opt(_DEFAULTS['use_gpu'], '--gpu-id', '-g', help='GPU ID or -1 for CPU'), gold_preproc: bool=Opt(_DEFAULTS['gold_preproc'], '--gold-preproc', '-G', help='Use gold preprocessing'), verbose: bool=Opt(False, '--verbose', '-V', '-VV', help='Display more information for debugging purposes')):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Runs prediction trials for a trained model with varying tresholds to maximize\\n    the specified metric. The search space for the threshold is traversed linearly\\n    from 0 to 1 in `n_trials` steps. Results are displayed in a table on `stdout`\\n    (the corresponding API call to `spacy.cli.find_threshold.find_threshold()`\\n    returns all results).\\n\\n    This is applicable only for components whose predictions are influenced by\\n    thresholds - e.g. `textcat_multilabel` and `spancat`, but not `textcat`. Note\\n    that the full path to the corresponding threshold attribute in the config has to\\n    be provided.\\n\\n    DOCS: https://spacy.io/api/cli#find-threshold\\n    '\n    if verbose:\n        util.logger.setLevel(logging.DEBUG)\n    import_code(code_path)\n    find_threshold(model=model, data_path=data_path, pipe_name=pipe_name, threshold_key=threshold_key, scores_key=scores_key, n_trials=n_trials, use_gpu=use_gpu, gold_preproc=gold_preproc, silent=False)",
            "@app.command('find-threshold', context_settings={'allow_extra_args': False, 'ignore_unknown_options': True})\ndef find_threshold_cli(model: str=Arg(..., help='Model name or path'), data_path: Path=Arg(..., help='Location of binary evaluation data in .spacy format', exists=True), pipe_name: str=Arg(..., help='Name of pipe to examine thresholds for'), threshold_key: str=Arg(..., help=\"Key of threshold attribute in component's configuration\"), scores_key: str=Arg(..., help='Metric to optimize'), n_trials: int=Opt(_DEFAULTS['n_trials'], '--n_trials', '-n', help='Number of trials to determine optimal thresholds'), code_path: Optional[Path]=Opt(None, '--code', '-c', help='Path to Python file with additional code (registered functions) to be imported'), use_gpu: int=Opt(_DEFAULTS['use_gpu'], '--gpu-id', '-g', help='GPU ID or -1 for CPU'), gold_preproc: bool=Opt(_DEFAULTS['gold_preproc'], '--gold-preproc', '-G', help='Use gold preprocessing'), verbose: bool=Opt(False, '--verbose', '-V', '-VV', help='Display more information for debugging purposes')):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Runs prediction trials for a trained model with varying tresholds to maximize\\n    the specified metric. The search space for the threshold is traversed linearly\\n    from 0 to 1 in `n_trials` steps. Results are displayed in a table on `stdout`\\n    (the corresponding API call to `spacy.cli.find_threshold.find_threshold()`\\n    returns all results).\\n\\n    This is applicable only for components whose predictions are influenced by\\n    thresholds - e.g. `textcat_multilabel` and `spancat`, but not `textcat`. Note\\n    that the full path to the corresponding threshold attribute in the config has to\\n    be provided.\\n\\n    DOCS: https://spacy.io/api/cli#find-threshold\\n    '\n    if verbose:\n        util.logger.setLevel(logging.DEBUG)\n    import_code(code_path)\n    find_threshold(model=model, data_path=data_path, pipe_name=pipe_name, threshold_key=threshold_key, scores_key=scores_key, n_trials=n_trials, use_gpu=use_gpu, gold_preproc=gold_preproc, silent=False)",
            "@app.command('find-threshold', context_settings={'allow_extra_args': False, 'ignore_unknown_options': True})\ndef find_threshold_cli(model: str=Arg(..., help='Model name or path'), data_path: Path=Arg(..., help='Location of binary evaluation data in .spacy format', exists=True), pipe_name: str=Arg(..., help='Name of pipe to examine thresholds for'), threshold_key: str=Arg(..., help=\"Key of threshold attribute in component's configuration\"), scores_key: str=Arg(..., help='Metric to optimize'), n_trials: int=Opt(_DEFAULTS['n_trials'], '--n_trials', '-n', help='Number of trials to determine optimal thresholds'), code_path: Optional[Path]=Opt(None, '--code', '-c', help='Path to Python file with additional code (registered functions) to be imported'), use_gpu: int=Opt(_DEFAULTS['use_gpu'], '--gpu-id', '-g', help='GPU ID or -1 for CPU'), gold_preproc: bool=Opt(_DEFAULTS['gold_preproc'], '--gold-preproc', '-G', help='Use gold preprocessing'), verbose: bool=Opt(False, '--verbose', '-V', '-VV', help='Display more information for debugging purposes')):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Runs prediction trials for a trained model with varying tresholds to maximize\\n    the specified metric. The search space for the threshold is traversed linearly\\n    from 0 to 1 in `n_trials` steps. Results are displayed in a table on `stdout`\\n    (the corresponding API call to `spacy.cli.find_threshold.find_threshold()`\\n    returns all results).\\n\\n    This is applicable only for components whose predictions are influenced by\\n    thresholds - e.g. `textcat_multilabel` and `spancat`, but not `textcat`. Note\\n    that the full path to the corresponding threshold attribute in the config has to\\n    be provided.\\n\\n    DOCS: https://spacy.io/api/cli#find-threshold\\n    '\n    if verbose:\n        util.logger.setLevel(logging.DEBUG)\n    import_code(code_path)\n    find_threshold(model=model, data_path=data_path, pipe_name=pipe_name, threshold_key=threshold_key, scores_key=scores_key, n_trials=n_trials, use_gpu=use_gpu, gold_preproc=gold_preproc, silent=False)",
            "@app.command('find-threshold', context_settings={'allow_extra_args': False, 'ignore_unknown_options': True})\ndef find_threshold_cli(model: str=Arg(..., help='Model name or path'), data_path: Path=Arg(..., help='Location of binary evaluation data in .spacy format', exists=True), pipe_name: str=Arg(..., help='Name of pipe to examine thresholds for'), threshold_key: str=Arg(..., help=\"Key of threshold attribute in component's configuration\"), scores_key: str=Arg(..., help='Metric to optimize'), n_trials: int=Opt(_DEFAULTS['n_trials'], '--n_trials', '-n', help='Number of trials to determine optimal thresholds'), code_path: Optional[Path]=Opt(None, '--code', '-c', help='Path to Python file with additional code (registered functions) to be imported'), use_gpu: int=Opt(_DEFAULTS['use_gpu'], '--gpu-id', '-g', help='GPU ID or -1 for CPU'), gold_preproc: bool=Opt(_DEFAULTS['gold_preproc'], '--gold-preproc', '-G', help='Use gold preprocessing'), verbose: bool=Opt(False, '--verbose', '-V', '-VV', help='Display more information for debugging purposes')):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Runs prediction trials for a trained model with varying tresholds to maximize\\n    the specified metric. The search space for the threshold is traversed linearly\\n    from 0 to 1 in `n_trials` steps. Results are displayed in a table on `stdout`\\n    (the corresponding API call to `spacy.cli.find_threshold.find_threshold()`\\n    returns all results).\\n\\n    This is applicable only for components whose predictions are influenced by\\n    thresholds - e.g. `textcat_multilabel` and `spancat`, but not `textcat`. Note\\n    that the full path to the corresponding threshold attribute in the config has to\\n    be provided.\\n\\n    DOCS: https://spacy.io/api/cli#find-threshold\\n    '\n    if verbose:\n        util.logger.setLevel(logging.DEBUG)\n    import_code(code_path)\n    find_threshold(model=model, data_path=data_path, pipe_name=pipe_name, threshold_key=threshold_key, scores_key=scores_key, n_trials=n_trials, use_gpu=use_gpu, gold_preproc=gold_preproc, silent=False)"
        ]
    },
    {
        "func_name": "set_nested_item",
        "original": "def set_nested_item(config: Dict[str, Any], keys: List[str], value: float) -> Dict[str, Any]:\n    \"\"\"Set item in nested dictionary. Adapted from https://stackoverflow.com/a/54138200.\n        config (Dict[str, Any]): Configuration dictionary.\n        keys (List[Any]): Path to value to set.\n        value (float): Value to set.\n        RETURNS (Dict[str, Any]): Updated dictionary.\n        \"\"\"\n    functools.reduce(operator.getitem, keys[:-1], config)[keys[-1]] = value\n    return config",
        "mutated": [
            "def set_nested_item(config: Dict[str, Any], keys: List[str], value: float) -> Dict[str, Any]:\n    if False:\n        i = 10\n    'Set item in nested dictionary. Adapted from https://stackoverflow.com/a/54138200.\\n        config (Dict[str, Any]): Configuration dictionary.\\n        keys (List[Any]): Path to value to set.\\n        value (float): Value to set.\\n        RETURNS (Dict[str, Any]): Updated dictionary.\\n        '\n    functools.reduce(operator.getitem, keys[:-1], config)[keys[-1]] = value\n    return config",
            "def set_nested_item(config: Dict[str, Any], keys: List[str], value: float) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Set item in nested dictionary. Adapted from https://stackoverflow.com/a/54138200.\\n        config (Dict[str, Any]): Configuration dictionary.\\n        keys (List[Any]): Path to value to set.\\n        value (float): Value to set.\\n        RETURNS (Dict[str, Any]): Updated dictionary.\\n        '\n    functools.reduce(operator.getitem, keys[:-1], config)[keys[-1]] = value\n    return config",
            "def set_nested_item(config: Dict[str, Any], keys: List[str], value: float) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Set item in nested dictionary. Adapted from https://stackoverflow.com/a/54138200.\\n        config (Dict[str, Any]): Configuration dictionary.\\n        keys (List[Any]): Path to value to set.\\n        value (float): Value to set.\\n        RETURNS (Dict[str, Any]): Updated dictionary.\\n        '\n    functools.reduce(operator.getitem, keys[:-1], config)[keys[-1]] = value\n    return config",
            "def set_nested_item(config: Dict[str, Any], keys: List[str], value: float) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Set item in nested dictionary. Adapted from https://stackoverflow.com/a/54138200.\\n        config (Dict[str, Any]): Configuration dictionary.\\n        keys (List[Any]): Path to value to set.\\n        value (float): Value to set.\\n        RETURNS (Dict[str, Any]): Updated dictionary.\\n        '\n    functools.reduce(operator.getitem, keys[:-1], config)[keys[-1]] = value\n    return config",
            "def set_nested_item(config: Dict[str, Any], keys: List[str], value: float) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Set item in nested dictionary. Adapted from https://stackoverflow.com/a/54138200.\\n        config (Dict[str, Any]): Configuration dictionary.\\n        keys (List[Any]): Path to value to set.\\n        value (float): Value to set.\\n        RETURNS (Dict[str, Any]): Updated dictionary.\\n        '\n    functools.reduce(operator.getitem, keys[:-1], config)[keys[-1]] = value\n    return config"
        ]
    },
    {
        "func_name": "filter_config",
        "original": "def filter_config(config: Dict[str, Any], keys: List[str], full_key: str) -> Dict[str, Any]:\n    \"\"\"Filters provided config dictionary so that only the specified keys path remains.\n        config (Dict[str, Any]): Configuration dictionary.\n        keys (List[Any]): Path to value to set.\n        full_key (str): Full user-specified key.\n        RETURNS (Dict[str, Any]): Filtered dictionary.\n        \"\"\"\n    if keys[0] not in config:\n        wasabi.msg.fail(title=f'Failed to look up `{full_key}` in config: sub-key {[keys[0]]} not found.', text=f'Make sure you specified {[keys[0]]} correctly. The following sub-keys are available instead: {list(config.keys())}', exits=1)\n    return {keys[0]: filter_config(config[keys[0]], keys[1:], full_key) if len(keys) > 1 else config[keys[0]]}",
        "mutated": [
            "def filter_config(config: Dict[str, Any], keys: List[str], full_key: str) -> Dict[str, Any]:\n    if False:\n        i = 10\n    'Filters provided config dictionary so that only the specified keys path remains.\\n        config (Dict[str, Any]): Configuration dictionary.\\n        keys (List[Any]): Path to value to set.\\n        full_key (str): Full user-specified key.\\n        RETURNS (Dict[str, Any]): Filtered dictionary.\\n        '\n    if keys[0] not in config:\n        wasabi.msg.fail(title=f'Failed to look up `{full_key}` in config: sub-key {[keys[0]]} not found.', text=f'Make sure you specified {[keys[0]]} correctly. The following sub-keys are available instead: {list(config.keys())}', exits=1)\n    return {keys[0]: filter_config(config[keys[0]], keys[1:], full_key) if len(keys) > 1 else config[keys[0]]}",
            "def filter_config(config: Dict[str, Any], keys: List[str], full_key: str) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Filters provided config dictionary so that only the specified keys path remains.\\n        config (Dict[str, Any]): Configuration dictionary.\\n        keys (List[Any]): Path to value to set.\\n        full_key (str): Full user-specified key.\\n        RETURNS (Dict[str, Any]): Filtered dictionary.\\n        '\n    if keys[0] not in config:\n        wasabi.msg.fail(title=f'Failed to look up `{full_key}` in config: sub-key {[keys[0]]} not found.', text=f'Make sure you specified {[keys[0]]} correctly. The following sub-keys are available instead: {list(config.keys())}', exits=1)\n    return {keys[0]: filter_config(config[keys[0]], keys[1:], full_key) if len(keys) > 1 else config[keys[0]]}",
            "def filter_config(config: Dict[str, Any], keys: List[str], full_key: str) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Filters provided config dictionary so that only the specified keys path remains.\\n        config (Dict[str, Any]): Configuration dictionary.\\n        keys (List[Any]): Path to value to set.\\n        full_key (str): Full user-specified key.\\n        RETURNS (Dict[str, Any]): Filtered dictionary.\\n        '\n    if keys[0] not in config:\n        wasabi.msg.fail(title=f'Failed to look up `{full_key}` in config: sub-key {[keys[0]]} not found.', text=f'Make sure you specified {[keys[0]]} correctly. The following sub-keys are available instead: {list(config.keys())}', exits=1)\n    return {keys[0]: filter_config(config[keys[0]], keys[1:], full_key) if len(keys) > 1 else config[keys[0]]}",
            "def filter_config(config: Dict[str, Any], keys: List[str], full_key: str) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Filters provided config dictionary so that only the specified keys path remains.\\n        config (Dict[str, Any]): Configuration dictionary.\\n        keys (List[Any]): Path to value to set.\\n        full_key (str): Full user-specified key.\\n        RETURNS (Dict[str, Any]): Filtered dictionary.\\n        '\n    if keys[0] not in config:\n        wasabi.msg.fail(title=f'Failed to look up `{full_key}` in config: sub-key {[keys[0]]} not found.', text=f'Make sure you specified {[keys[0]]} correctly. The following sub-keys are available instead: {list(config.keys())}', exits=1)\n    return {keys[0]: filter_config(config[keys[0]], keys[1:], full_key) if len(keys) > 1 else config[keys[0]]}",
            "def filter_config(config: Dict[str, Any], keys: List[str], full_key: str) -> Dict[str, Any]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Filters provided config dictionary so that only the specified keys path remains.\\n        config (Dict[str, Any]): Configuration dictionary.\\n        keys (List[Any]): Path to value to set.\\n        full_key (str): Full user-specified key.\\n        RETURNS (Dict[str, Any]): Filtered dictionary.\\n        '\n    if keys[0] not in config:\n        wasabi.msg.fail(title=f'Failed to look up `{full_key}` in config: sub-key {[keys[0]]} not found.', text=f'Make sure you specified {[keys[0]]} correctly. The following sub-keys are available instead: {list(config.keys())}', exits=1)\n    return {keys[0]: filter_config(config[keys[0]], keys[1:], full_key) if len(keys) > 1 else config[keys[0]]}"
        ]
    },
    {
        "func_name": "find_threshold",
        "original": "def find_threshold(model: str, data_path: Path, pipe_name: str, threshold_key: str, scores_key: str, *, n_trials: int=_DEFAULTS['n_trials'], use_gpu: int=_DEFAULTS['use_gpu'], gold_preproc: bool=_DEFAULTS['gold_preproc'], silent: bool=True) -> Tuple[float, float, Dict[float, float]]:\n    \"\"\"\n    Runs prediction trials for models with varying tresholds to maximize the specified metric.\n    model (Union[str, Path]): Pipeline to evaluate. Can be a package or a path to a data directory.\n    data_path (Path): Path to file with DocBin with docs to use for threshold search.\n    pipe_name (str): Name of pipe to examine thresholds for.\n    threshold_key (str): Key of threshold attribute in component's configuration.\n    scores_key (str): Name of score to metric to optimize.\n    n_trials (int): Number of trials to determine optimal thresholds.\n    use_gpu (int): GPU ID or -1 for CPU.\n    gold_preproc (bool): Whether to use gold preprocessing. Gold preprocessing helps the annotations align to the\n        tokenization, and may result in sequences of more consistent length. However, it may reduce runtime accuracy due\n        to train/test skew.\n    silent (bool): Whether to print non-error-related output to stdout.\n    RETURNS (Tuple[float, float, Dict[float, float]]): Best found threshold, the corresponding score, scores for all\n        evaluated thresholds.\n    \"\"\"\n    setup_gpu(use_gpu, silent=silent)\n    data_path = util.ensure_path(data_path)\n    if not data_path.exists():\n        wasabi.msg.fail('Evaluation data not found', data_path, exits=1)\n    nlp = util.load_model(model)\n    if pipe_name not in nlp.component_names:\n        raise AttributeError(Errors.E001.format(name=pipe_name, opts=nlp.component_names))\n    pipe = nlp.get_pipe(pipe_name)\n    if not hasattr(pipe, 'scorer'):\n        raise AttributeError(Errors.E1045)\n    if type(pipe) == TextCategorizer:\n        wasabi.msg.warn(\"The `textcat` component doesn't use a threshold as it's not applicable to the concept of exclusive classes. All thresholds will yield the same results.\")\n    if not silent:\n        wasabi.msg.info(title=f\"Optimizing for {scores_key} for component '{pipe_name}' with {n_trials} trials.\")\n    corpus = Corpus(data_path, gold_preproc=gold_preproc)\n    dev_dataset = list(corpus(nlp))\n    config_keys = threshold_key.split('.')\n\n    def set_nested_item(config: Dict[str, Any], keys: List[str], value: float) -> Dict[str, Any]:\n        \"\"\"Set item in nested dictionary. Adapted from https://stackoverflow.com/a/54138200.\n        config (Dict[str, Any]): Configuration dictionary.\n        keys (List[Any]): Path to value to set.\n        value (float): Value to set.\n        RETURNS (Dict[str, Any]): Updated dictionary.\n        \"\"\"\n        functools.reduce(operator.getitem, keys[:-1], config)[keys[-1]] = value\n        return config\n\n    def filter_config(config: Dict[str, Any], keys: List[str], full_key: str) -> Dict[str, Any]:\n        \"\"\"Filters provided config dictionary so that only the specified keys path remains.\n        config (Dict[str, Any]): Configuration dictionary.\n        keys (List[Any]): Path to value to set.\n        full_key (str): Full user-specified key.\n        RETURNS (Dict[str, Any]): Filtered dictionary.\n        \"\"\"\n        if keys[0] not in config:\n            wasabi.msg.fail(title=f'Failed to look up `{full_key}` in config: sub-key {[keys[0]]} not found.', text=f'Make sure you specified {[keys[0]]} correctly. The following sub-keys are available instead: {list(config.keys())}', exits=1)\n        return {keys[0]: filter_config(config[keys[0]], keys[1:], full_key) if len(keys) > 1 else config[keys[0]]}\n    scores: Dict[float, float] = {}\n    config_keys_full = ['components', pipe_name, *config_keys]\n    table_col_widths = (10, 10)\n    thresholds = numpy.linspace(0, 1, n_trials)\n    print(wasabi.tables.row(['Threshold', f'{scores_key}'], widths=table_col_widths))\n    for threshold in thresholds:\n        nlp = util.load_model(model, config=set_nested_item(filter_config(nlp.config, config_keys_full, '.'.join(config_keys_full)).copy(), config_keys_full, threshold))\n        if hasattr(pipe, 'cfg'):\n            setattr(nlp.get_pipe(pipe_name), 'cfg', set_nested_item(getattr(pipe, 'cfg'), config_keys, threshold))\n        eval_scores = nlp.evaluate(dev_dataset)\n        if scores_key not in eval_scores:\n            wasabi.msg.fail(title=f'Failed to look up score `{scores_key}` in evaluation results.', text=f'Make sure you specified the correct value for `scores_key`. The following scores are available: {list(eval_scores.keys())}', exits=1)\n        scores[threshold] = eval_scores[scores_key]\n        if not isinstance(scores[threshold], (float, int)):\n            wasabi.msg.fail(f\"Returned score for key '{scores_key}' is not numeric. Threshold optimization only works for numeric scores.\", exits=1)\n        print(wasabi.row([round(threshold, 3), round(scores[threshold], 3)], widths=table_col_widths))\n    best_threshold = max(scores.keys(), key=lambda key: scores[key])\n    if len(set(scores.values())) == 1:\n        wasabi.msg.warn(title='All scores are identical. Verify that all settings are correct.', text='' if not isinstance(pipe, MultiLabel_TextCategorizer) or scores_key in ('cats_macro_f', 'cats_micro_f') else 'Use `cats_macro_f` or `cats_micro_f` when optimizing the threshold for `textcat_multilabel`.')\n    elif not silent:\n        print(f'\\nBest threshold: {round(best_threshold, ndigits=4)} with {scores_key} value of {scores[best_threshold]}.')\n    return (best_threshold, scores[best_threshold], scores)",
        "mutated": [
            "def find_threshold(model: str, data_path: Path, pipe_name: str, threshold_key: str, scores_key: str, *, n_trials: int=_DEFAULTS['n_trials'], use_gpu: int=_DEFAULTS['use_gpu'], gold_preproc: bool=_DEFAULTS['gold_preproc'], silent: bool=True) -> Tuple[float, float, Dict[float, float]]:\n    if False:\n        i = 10\n    \"\\n    Runs prediction trials for models with varying tresholds to maximize the specified metric.\\n    model (Union[str, Path]): Pipeline to evaluate. Can be a package or a path to a data directory.\\n    data_path (Path): Path to file with DocBin with docs to use for threshold search.\\n    pipe_name (str): Name of pipe to examine thresholds for.\\n    threshold_key (str): Key of threshold attribute in component's configuration.\\n    scores_key (str): Name of score to metric to optimize.\\n    n_trials (int): Number of trials to determine optimal thresholds.\\n    use_gpu (int): GPU ID or -1 for CPU.\\n    gold_preproc (bool): Whether to use gold preprocessing. Gold preprocessing helps the annotations align to the\\n        tokenization, and may result in sequences of more consistent length. However, it may reduce runtime accuracy due\\n        to train/test skew.\\n    silent (bool): Whether to print non-error-related output to stdout.\\n    RETURNS (Tuple[float, float, Dict[float, float]]): Best found threshold, the corresponding score, scores for all\\n        evaluated thresholds.\\n    \"\n    setup_gpu(use_gpu, silent=silent)\n    data_path = util.ensure_path(data_path)\n    if not data_path.exists():\n        wasabi.msg.fail('Evaluation data not found', data_path, exits=1)\n    nlp = util.load_model(model)\n    if pipe_name not in nlp.component_names:\n        raise AttributeError(Errors.E001.format(name=pipe_name, opts=nlp.component_names))\n    pipe = nlp.get_pipe(pipe_name)\n    if not hasattr(pipe, 'scorer'):\n        raise AttributeError(Errors.E1045)\n    if type(pipe) == TextCategorizer:\n        wasabi.msg.warn(\"The `textcat` component doesn't use a threshold as it's not applicable to the concept of exclusive classes. All thresholds will yield the same results.\")\n    if not silent:\n        wasabi.msg.info(title=f\"Optimizing for {scores_key} for component '{pipe_name}' with {n_trials} trials.\")\n    corpus = Corpus(data_path, gold_preproc=gold_preproc)\n    dev_dataset = list(corpus(nlp))\n    config_keys = threshold_key.split('.')\n\n    def set_nested_item(config: Dict[str, Any], keys: List[str], value: float) -> Dict[str, Any]:\n        \"\"\"Set item in nested dictionary. Adapted from https://stackoverflow.com/a/54138200.\n        config (Dict[str, Any]): Configuration dictionary.\n        keys (List[Any]): Path to value to set.\n        value (float): Value to set.\n        RETURNS (Dict[str, Any]): Updated dictionary.\n        \"\"\"\n        functools.reduce(operator.getitem, keys[:-1], config)[keys[-1]] = value\n        return config\n\n    def filter_config(config: Dict[str, Any], keys: List[str], full_key: str) -> Dict[str, Any]:\n        \"\"\"Filters provided config dictionary so that only the specified keys path remains.\n        config (Dict[str, Any]): Configuration dictionary.\n        keys (List[Any]): Path to value to set.\n        full_key (str): Full user-specified key.\n        RETURNS (Dict[str, Any]): Filtered dictionary.\n        \"\"\"\n        if keys[0] not in config:\n            wasabi.msg.fail(title=f'Failed to look up `{full_key}` in config: sub-key {[keys[0]]} not found.', text=f'Make sure you specified {[keys[0]]} correctly. The following sub-keys are available instead: {list(config.keys())}', exits=1)\n        return {keys[0]: filter_config(config[keys[0]], keys[1:], full_key) if len(keys) > 1 else config[keys[0]]}\n    scores: Dict[float, float] = {}\n    config_keys_full = ['components', pipe_name, *config_keys]\n    table_col_widths = (10, 10)\n    thresholds = numpy.linspace(0, 1, n_trials)\n    print(wasabi.tables.row(['Threshold', f'{scores_key}'], widths=table_col_widths))\n    for threshold in thresholds:\n        nlp = util.load_model(model, config=set_nested_item(filter_config(nlp.config, config_keys_full, '.'.join(config_keys_full)).copy(), config_keys_full, threshold))\n        if hasattr(pipe, 'cfg'):\n            setattr(nlp.get_pipe(pipe_name), 'cfg', set_nested_item(getattr(pipe, 'cfg'), config_keys, threshold))\n        eval_scores = nlp.evaluate(dev_dataset)\n        if scores_key not in eval_scores:\n            wasabi.msg.fail(title=f'Failed to look up score `{scores_key}` in evaluation results.', text=f'Make sure you specified the correct value for `scores_key`. The following scores are available: {list(eval_scores.keys())}', exits=1)\n        scores[threshold] = eval_scores[scores_key]\n        if not isinstance(scores[threshold], (float, int)):\n            wasabi.msg.fail(f\"Returned score for key '{scores_key}' is not numeric. Threshold optimization only works for numeric scores.\", exits=1)\n        print(wasabi.row([round(threshold, 3), round(scores[threshold], 3)], widths=table_col_widths))\n    best_threshold = max(scores.keys(), key=lambda key: scores[key])\n    if len(set(scores.values())) == 1:\n        wasabi.msg.warn(title='All scores are identical. Verify that all settings are correct.', text='' if not isinstance(pipe, MultiLabel_TextCategorizer) or scores_key in ('cats_macro_f', 'cats_micro_f') else 'Use `cats_macro_f` or `cats_micro_f` when optimizing the threshold for `textcat_multilabel`.')\n    elif not silent:\n        print(f'\\nBest threshold: {round(best_threshold, ndigits=4)} with {scores_key} value of {scores[best_threshold]}.')\n    return (best_threshold, scores[best_threshold], scores)",
            "def find_threshold(model: str, data_path: Path, pipe_name: str, threshold_key: str, scores_key: str, *, n_trials: int=_DEFAULTS['n_trials'], use_gpu: int=_DEFAULTS['use_gpu'], gold_preproc: bool=_DEFAULTS['gold_preproc'], silent: bool=True) -> Tuple[float, float, Dict[float, float]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Runs prediction trials for models with varying tresholds to maximize the specified metric.\\n    model (Union[str, Path]): Pipeline to evaluate. Can be a package or a path to a data directory.\\n    data_path (Path): Path to file with DocBin with docs to use for threshold search.\\n    pipe_name (str): Name of pipe to examine thresholds for.\\n    threshold_key (str): Key of threshold attribute in component's configuration.\\n    scores_key (str): Name of score to metric to optimize.\\n    n_trials (int): Number of trials to determine optimal thresholds.\\n    use_gpu (int): GPU ID or -1 for CPU.\\n    gold_preproc (bool): Whether to use gold preprocessing. Gold preprocessing helps the annotations align to the\\n        tokenization, and may result in sequences of more consistent length. However, it may reduce runtime accuracy due\\n        to train/test skew.\\n    silent (bool): Whether to print non-error-related output to stdout.\\n    RETURNS (Tuple[float, float, Dict[float, float]]): Best found threshold, the corresponding score, scores for all\\n        evaluated thresholds.\\n    \"\n    setup_gpu(use_gpu, silent=silent)\n    data_path = util.ensure_path(data_path)\n    if not data_path.exists():\n        wasabi.msg.fail('Evaluation data not found', data_path, exits=1)\n    nlp = util.load_model(model)\n    if pipe_name not in nlp.component_names:\n        raise AttributeError(Errors.E001.format(name=pipe_name, opts=nlp.component_names))\n    pipe = nlp.get_pipe(pipe_name)\n    if not hasattr(pipe, 'scorer'):\n        raise AttributeError(Errors.E1045)\n    if type(pipe) == TextCategorizer:\n        wasabi.msg.warn(\"The `textcat` component doesn't use a threshold as it's not applicable to the concept of exclusive classes. All thresholds will yield the same results.\")\n    if not silent:\n        wasabi.msg.info(title=f\"Optimizing for {scores_key} for component '{pipe_name}' with {n_trials} trials.\")\n    corpus = Corpus(data_path, gold_preproc=gold_preproc)\n    dev_dataset = list(corpus(nlp))\n    config_keys = threshold_key.split('.')\n\n    def set_nested_item(config: Dict[str, Any], keys: List[str], value: float) -> Dict[str, Any]:\n        \"\"\"Set item in nested dictionary. Adapted from https://stackoverflow.com/a/54138200.\n        config (Dict[str, Any]): Configuration dictionary.\n        keys (List[Any]): Path to value to set.\n        value (float): Value to set.\n        RETURNS (Dict[str, Any]): Updated dictionary.\n        \"\"\"\n        functools.reduce(operator.getitem, keys[:-1], config)[keys[-1]] = value\n        return config\n\n    def filter_config(config: Dict[str, Any], keys: List[str], full_key: str) -> Dict[str, Any]:\n        \"\"\"Filters provided config dictionary so that only the specified keys path remains.\n        config (Dict[str, Any]): Configuration dictionary.\n        keys (List[Any]): Path to value to set.\n        full_key (str): Full user-specified key.\n        RETURNS (Dict[str, Any]): Filtered dictionary.\n        \"\"\"\n        if keys[0] not in config:\n            wasabi.msg.fail(title=f'Failed to look up `{full_key}` in config: sub-key {[keys[0]]} not found.', text=f'Make sure you specified {[keys[0]]} correctly. The following sub-keys are available instead: {list(config.keys())}', exits=1)\n        return {keys[0]: filter_config(config[keys[0]], keys[1:], full_key) if len(keys) > 1 else config[keys[0]]}\n    scores: Dict[float, float] = {}\n    config_keys_full = ['components', pipe_name, *config_keys]\n    table_col_widths = (10, 10)\n    thresholds = numpy.linspace(0, 1, n_trials)\n    print(wasabi.tables.row(['Threshold', f'{scores_key}'], widths=table_col_widths))\n    for threshold in thresholds:\n        nlp = util.load_model(model, config=set_nested_item(filter_config(nlp.config, config_keys_full, '.'.join(config_keys_full)).copy(), config_keys_full, threshold))\n        if hasattr(pipe, 'cfg'):\n            setattr(nlp.get_pipe(pipe_name), 'cfg', set_nested_item(getattr(pipe, 'cfg'), config_keys, threshold))\n        eval_scores = nlp.evaluate(dev_dataset)\n        if scores_key not in eval_scores:\n            wasabi.msg.fail(title=f'Failed to look up score `{scores_key}` in evaluation results.', text=f'Make sure you specified the correct value for `scores_key`. The following scores are available: {list(eval_scores.keys())}', exits=1)\n        scores[threshold] = eval_scores[scores_key]\n        if not isinstance(scores[threshold], (float, int)):\n            wasabi.msg.fail(f\"Returned score for key '{scores_key}' is not numeric. Threshold optimization only works for numeric scores.\", exits=1)\n        print(wasabi.row([round(threshold, 3), round(scores[threshold], 3)], widths=table_col_widths))\n    best_threshold = max(scores.keys(), key=lambda key: scores[key])\n    if len(set(scores.values())) == 1:\n        wasabi.msg.warn(title='All scores are identical. Verify that all settings are correct.', text='' if not isinstance(pipe, MultiLabel_TextCategorizer) or scores_key in ('cats_macro_f', 'cats_micro_f') else 'Use `cats_macro_f` or `cats_micro_f` when optimizing the threshold for `textcat_multilabel`.')\n    elif not silent:\n        print(f'\\nBest threshold: {round(best_threshold, ndigits=4)} with {scores_key} value of {scores[best_threshold]}.')\n    return (best_threshold, scores[best_threshold], scores)",
            "def find_threshold(model: str, data_path: Path, pipe_name: str, threshold_key: str, scores_key: str, *, n_trials: int=_DEFAULTS['n_trials'], use_gpu: int=_DEFAULTS['use_gpu'], gold_preproc: bool=_DEFAULTS['gold_preproc'], silent: bool=True) -> Tuple[float, float, Dict[float, float]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Runs prediction trials for models with varying tresholds to maximize the specified metric.\\n    model (Union[str, Path]): Pipeline to evaluate. Can be a package or a path to a data directory.\\n    data_path (Path): Path to file with DocBin with docs to use for threshold search.\\n    pipe_name (str): Name of pipe to examine thresholds for.\\n    threshold_key (str): Key of threshold attribute in component's configuration.\\n    scores_key (str): Name of score to metric to optimize.\\n    n_trials (int): Number of trials to determine optimal thresholds.\\n    use_gpu (int): GPU ID or -1 for CPU.\\n    gold_preproc (bool): Whether to use gold preprocessing. Gold preprocessing helps the annotations align to the\\n        tokenization, and may result in sequences of more consistent length. However, it may reduce runtime accuracy due\\n        to train/test skew.\\n    silent (bool): Whether to print non-error-related output to stdout.\\n    RETURNS (Tuple[float, float, Dict[float, float]]): Best found threshold, the corresponding score, scores for all\\n        evaluated thresholds.\\n    \"\n    setup_gpu(use_gpu, silent=silent)\n    data_path = util.ensure_path(data_path)\n    if not data_path.exists():\n        wasabi.msg.fail('Evaluation data not found', data_path, exits=1)\n    nlp = util.load_model(model)\n    if pipe_name not in nlp.component_names:\n        raise AttributeError(Errors.E001.format(name=pipe_name, opts=nlp.component_names))\n    pipe = nlp.get_pipe(pipe_name)\n    if not hasattr(pipe, 'scorer'):\n        raise AttributeError(Errors.E1045)\n    if type(pipe) == TextCategorizer:\n        wasabi.msg.warn(\"The `textcat` component doesn't use a threshold as it's not applicable to the concept of exclusive classes. All thresholds will yield the same results.\")\n    if not silent:\n        wasabi.msg.info(title=f\"Optimizing for {scores_key} for component '{pipe_name}' with {n_trials} trials.\")\n    corpus = Corpus(data_path, gold_preproc=gold_preproc)\n    dev_dataset = list(corpus(nlp))\n    config_keys = threshold_key.split('.')\n\n    def set_nested_item(config: Dict[str, Any], keys: List[str], value: float) -> Dict[str, Any]:\n        \"\"\"Set item in nested dictionary. Adapted from https://stackoverflow.com/a/54138200.\n        config (Dict[str, Any]): Configuration dictionary.\n        keys (List[Any]): Path to value to set.\n        value (float): Value to set.\n        RETURNS (Dict[str, Any]): Updated dictionary.\n        \"\"\"\n        functools.reduce(operator.getitem, keys[:-1], config)[keys[-1]] = value\n        return config\n\n    def filter_config(config: Dict[str, Any], keys: List[str], full_key: str) -> Dict[str, Any]:\n        \"\"\"Filters provided config dictionary so that only the specified keys path remains.\n        config (Dict[str, Any]): Configuration dictionary.\n        keys (List[Any]): Path to value to set.\n        full_key (str): Full user-specified key.\n        RETURNS (Dict[str, Any]): Filtered dictionary.\n        \"\"\"\n        if keys[0] not in config:\n            wasabi.msg.fail(title=f'Failed to look up `{full_key}` in config: sub-key {[keys[0]]} not found.', text=f'Make sure you specified {[keys[0]]} correctly. The following sub-keys are available instead: {list(config.keys())}', exits=1)\n        return {keys[0]: filter_config(config[keys[0]], keys[1:], full_key) if len(keys) > 1 else config[keys[0]]}\n    scores: Dict[float, float] = {}\n    config_keys_full = ['components', pipe_name, *config_keys]\n    table_col_widths = (10, 10)\n    thresholds = numpy.linspace(0, 1, n_trials)\n    print(wasabi.tables.row(['Threshold', f'{scores_key}'], widths=table_col_widths))\n    for threshold in thresholds:\n        nlp = util.load_model(model, config=set_nested_item(filter_config(nlp.config, config_keys_full, '.'.join(config_keys_full)).copy(), config_keys_full, threshold))\n        if hasattr(pipe, 'cfg'):\n            setattr(nlp.get_pipe(pipe_name), 'cfg', set_nested_item(getattr(pipe, 'cfg'), config_keys, threshold))\n        eval_scores = nlp.evaluate(dev_dataset)\n        if scores_key not in eval_scores:\n            wasabi.msg.fail(title=f'Failed to look up score `{scores_key}` in evaluation results.', text=f'Make sure you specified the correct value for `scores_key`. The following scores are available: {list(eval_scores.keys())}', exits=1)\n        scores[threshold] = eval_scores[scores_key]\n        if not isinstance(scores[threshold], (float, int)):\n            wasabi.msg.fail(f\"Returned score for key '{scores_key}' is not numeric. Threshold optimization only works for numeric scores.\", exits=1)\n        print(wasabi.row([round(threshold, 3), round(scores[threshold], 3)], widths=table_col_widths))\n    best_threshold = max(scores.keys(), key=lambda key: scores[key])\n    if len(set(scores.values())) == 1:\n        wasabi.msg.warn(title='All scores are identical. Verify that all settings are correct.', text='' if not isinstance(pipe, MultiLabel_TextCategorizer) or scores_key in ('cats_macro_f', 'cats_micro_f') else 'Use `cats_macro_f` or `cats_micro_f` when optimizing the threshold for `textcat_multilabel`.')\n    elif not silent:\n        print(f'\\nBest threshold: {round(best_threshold, ndigits=4)} with {scores_key} value of {scores[best_threshold]}.')\n    return (best_threshold, scores[best_threshold], scores)",
            "def find_threshold(model: str, data_path: Path, pipe_name: str, threshold_key: str, scores_key: str, *, n_trials: int=_DEFAULTS['n_trials'], use_gpu: int=_DEFAULTS['use_gpu'], gold_preproc: bool=_DEFAULTS['gold_preproc'], silent: bool=True) -> Tuple[float, float, Dict[float, float]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Runs prediction trials for models with varying tresholds to maximize the specified metric.\\n    model (Union[str, Path]): Pipeline to evaluate. Can be a package or a path to a data directory.\\n    data_path (Path): Path to file with DocBin with docs to use for threshold search.\\n    pipe_name (str): Name of pipe to examine thresholds for.\\n    threshold_key (str): Key of threshold attribute in component's configuration.\\n    scores_key (str): Name of score to metric to optimize.\\n    n_trials (int): Number of trials to determine optimal thresholds.\\n    use_gpu (int): GPU ID or -1 for CPU.\\n    gold_preproc (bool): Whether to use gold preprocessing. Gold preprocessing helps the annotations align to the\\n        tokenization, and may result in sequences of more consistent length. However, it may reduce runtime accuracy due\\n        to train/test skew.\\n    silent (bool): Whether to print non-error-related output to stdout.\\n    RETURNS (Tuple[float, float, Dict[float, float]]): Best found threshold, the corresponding score, scores for all\\n        evaluated thresholds.\\n    \"\n    setup_gpu(use_gpu, silent=silent)\n    data_path = util.ensure_path(data_path)\n    if not data_path.exists():\n        wasabi.msg.fail('Evaluation data not found', data_path, exits=1)\n    nlp = util.load_model(model)\n    if pipe_name not in nlp.component_names:\n        raise AttributeError(Errors.E001.format(name=pipe_name, opts=nlp.component_names))\n    pipe = nlp.get_pipe(pipe_name)\n    if not hasattr(pipe, 'scorer'):\n        raise AttributeError(Errors.E1045)\n    if type(pipe) == TextCategorizer:\n        wasabi.msg.warn(\"The `textcat` component doesn't use a threshold as it's not applicable to the concept of exclusive classes. All thresholds will yield the same results.\")\n    if not silent:\n        wasabi.msg.info(title=f\"Optimizing for {scores_key} for component '{pipe_name}' with {n_trials} trials.\")\n    corpus = Corpus(data_path, gold_preproc=gold_preproc)\n    dev_dataset = list(corpus(nlp))\n    config_keys = threshold_key.split('.')\n\n    def set_nested_item(config: Dict[str, Any], keys: List[str], value: float) -> Dict[str, Any]:\n        \"\"\"Set item in nested dictionary. Adapted from https://stackoverflow.com/a/54138200.\n        config (Dict[str, Any]): Configuration dictionary.\n        keys (List[Any]): Path to value to set.\n        value (float): Value to set.\n        RETURNS (Dict[str, Any]): Updated dictionary.\n        \"\"\"\n        functools.reduce(operator.getitem, keys[:-1], config)[keys[-1]] = value\n        return config\n\n    def filter_config(config: Dict[str, Any], keys: List[str], full_key: str) -> Dict[str, Any]:\n        \"\"\"Filters provided config dictionary so that only the specified keys path remains.\n        config (Dict[str, Any]): Configuration dictionary.\n        keys (List[Any]): Path to value to set.\n        full_key (str): Full user-specified key.\n        RETURNS (Dict[str, Any]): Filtered dictionary.\n        \"\"\"\n        if keys[0] not in config:\n            wasabi.msg.fail(title=f'Failed to look up `{full_key}` in config: sub-key {[keys[0]]} not found.', text=f'Make sure you specified {[keys[0]]} correctly. The following sub-keys are available instead: {list(config.keys())}', exits=1)\n        return {keys[0]: filter_config(config[keys[0]], keys[1:], full_key) if len(keys) > 1 else config[keys[0]]}\n    scores: Dict[float, float] = {}\n    config_keys_full = ['components', pipe_name, *config_keys]\n    table_col_widths = (10, 10)\n    thresholds = numpy.linspace(0, 1, n_trials)\n    print(wasabi.tables.row(['Threshold', f'{scores_key}'], widths=table_col_widths))\n    for threshold in thresholds:\n        nlp = util.load_model(model, config=set_nested_item(filter_config(nlp.config, config_keys_full, '.'.join(config_keys_full)).copy(), config_keys_full, threshold))\n        if hasattr(pipe, 'cfg'):\n            setattr(nlp.get_pipe(pipe_name), 'cfg', set_nested_item(getattr(pipe, 'cfg'), config_keys, threshold))\n        eval_scores = nlp.evaluate(dev_dataset)\n        if scores_key not in eval_scores:\n            wasabi.msg.fail(title=f'Failed to look up score `{scores_key}` in evaluation results.', text=f'Make sure you specified the correct value for `scores_key`. The following scores are available: {list(eval_scores.keys())}', exits=1)\n        scores[threshold] = eval_scores[scores_key]\n        if not isinstance(scores[threshold], (float, int)):\n            wasabi.msg.fail(f\"Returned score for key '{scores_key}' is not numeric. Threshold optimization only works for numeric scores.\", exits=1)\n        print(wasabi.row([round(threshold, 3), round(scores[threshold], 3)], widths=table_col_widths))\n    best_threshold = max(scores.keys(), key=lambda key: scores[key])\n    if len(set(scores.values())) == 1:\n        wasabi.msg.warn(title='All scores are identical. Verify that all settings are correct.', text='' if not isinstance(pipe, MultiLabel_TextCategorizer) or scores_key in ('cats_macro_f', 'cats_micro_f') else 'Use `cats_macro_f` or `cats_micro_f` when optimizing the threshold for `textcat_multilabel`.')\n    elif not silent:\n        print(f'\\nBest threshold: {round(best_threshold, ndigits=4)} with {scores_key} value of {scores[best_threshold]}.')\n    return (best_threshold, scores[best_threshold], scores)",
            "def find_threshold(model: str, data_path: Path, pipe_name: str, threshold_key: str, scores_key: str, *, n_trials: int=_DEFAULTS['n_trials'], use_gpu: int=_DEFAULTS['use_gpu'], gold_preproc: bool=_DEFAULTS['gold_preproc'], silent: bool=True) -> Tuple[float, float, Dict[float, float]]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Runs prediction trials for models with varying tresholds to maximize the specified metric.\\n    model (Union[str, Path]): Pipeline to evaluate. Can be a package or a path to a data directory.\\n    data_path (Path): Path to file with DocBin with docs to use for threshold search.\\n    pipe_name (str): Name of pipe to examine thresholds for.\\n    threshold_key (str): Key of threshold attribute in component's configuration.\\n    scores_key (str): Name of score to metric to optimize.\\n    n_trials (int): Number of trials to determine optimal thresholds.\\n    use_gpu (int): GPU ID or -1 for CPU.\\n    gold_preproc (bool): Whether to use gold preprocessing. Gold preprocessing helps the annotations align to the\\n        tokenization, and may result in sequences of more consistent length. However, it may reduce runtime accuracy due\\n        to train/test skew.\\n    silent (bool): Whether to print non-error-related output to stdout.\\n    RETURNS (Tuple[float, float, Dict[float, float]]): Best found threshold, the corresponding score, scores for all\\n        evaluated thresholds.\\n    \"\n    setup_gpu(use_gpu, silent=silent)\n    data_path = util.ensure_path(data_path)\n    if not data_path.exists():\n        wasabi.msg.fail('Evaluation data not found', data_path, exits=1)\n    nlp = util.load_model(model)\n    if pipe_name not in nlp.component_names:\n        raise AttributeError(Errors.E001.format(name=pipe_name, opts=nlp.component_names))\n    pipe = nlp.get_pipe(pipe_name)\n    if not hasattr(pipe, 'scorer'):\n        raise AttributeError(Errors.E1045)\n    if type(pipe) == TextCategorizer:\n        wasabi.msg.warn(\"The `textcat` component doesn't use a threshold as it's not applicable to the concept of exclusive classes. All thresholds will yield the same results.\")\n    if not silent:\n        wasabi.msg.info(title=f\"Optimizing for {scores_key} for component '{pipe_name}' with {n_trials} trials.\")\n    corpus = Corpus(data_path, gold_preproc=gold_preproc)\n    dev_dataset = list(corpus(nlp))\n    config_keys = threshold_key.split('.')\n\n    def set_nested_item(config: Dict[str, Any], keys: List[str], value: float) -> Dict[str, Any]:\n        \"\"\"Set item in nested dictionary. Adapted from https://stackoverflow.com/a/54138200.\n        config (Dict[str, Any]): Configuration dictionary.\n        keys (List[Any]): Path to value to set.\n        value (float): Value to set.\n        RETURNS (Dict[str, Any]): Updated dictionary.\n        \"\"\"\n        functools.reduce(operator.getitem, keys[:-1], config)[keys[-1]] = value\n        return config\n\n    def filter_config(config: Dict[str, Any], keys: List[str], full_key: str) -> Dict[str, Any]:\n        \"\"\"Filters provided config dictionary so that only the specified keys path remains.\n        config (Dict[str, Any]): Configuration dictionary.\n        keys (List[Any]): Path to value to set.\n        full_key (str): Full user-specified key.\n        RETURNS (Dict[str, Any]): Filtered dictionary.\n        \"\"\"\n        if keys[0] not in config:\n            wasabi.msg.fail(title=f'Failed to look up `{full_key}` in config: sub-key {[keys[0]]} not found.', text=f'Make sure you specified {[keys[0]]} correctly. The following sub-keys are available instead: {list(config.keys())}', exits=1)\n        return {keys[0]: filter_config(config[keys[0]], keys[1:], full_key) if len(keys) > 1 else config[keys[0]]}\n    scores: Dict[float, float] = {}\n    config_keys_full = ['components', pipe_name, *config_keys]\n    table_col_widths = (10, 10)\n    thresholds = numpy.linspace(0, 1, n_trials)\n    print(wasabi.tables.row(['Threshold', f'{scores_key}'], widths=table_col_widths))\n    for threshold in thresholds:\n        nlp = util.load_model(model, config=set_nested_item(filter_config(nlp.config, config_keys_full, '.'.join(config_keys_full)).copy(), config_keys_full, threshold))\n        if hasattr(pipe, 'cfg'):\n            setattr(nlp.get_pipe(pipe_name), 'cfg', set_nested_item(getattr(pipe, 'cfg'), config_keys, threshold))\n        eval_scores = nlp.evaluate(dev_dataset)\n        if scores_key not in eval_scores:\n            wasabi.msg.fail(title=f'Failed to look up score `{scores_key}` in evaluation results.', text=f'Make sure you specified the correct value for `scores_key`. The following scores are available: {list(eval_scores.keys())}', exits=1)\n        scores[threshold] = eval_scores[scores_key]\n        if not isinstance(scores[threshold], (float, int)):\n            wasabi.msg.fail(f\"Returned score for key '{scores_key}' is not numeric. Threshold optimization only works for numeric scores.\", exits=1)\n        print(wasabi.row([round(threshold, 3), round(scores[threshold], 3)], widths=table_col_widths))\n    best_threshold = max(scores.keys(), key=lambda key: scores[key])\n    if len(set(scores.values())) == 1:\n        wasabi.msg.warn(title='All scores are identical. Verify that all settings are correct.', text='' if not isinstance(pipe, MultiLabel_TextCategorizer) or scores_key in ('cats_macro_f', 'cats_micro_f') else 'Use `cats_macro_f` or `cats_micro_f` when optimizing the threshold for `textcat_multilabel`.')\n    elif not silent:\n        print(f'\\nBest threshold: {round(best_threshold, ndigits=4)} with {scores_key} value of {scores[best_threshold]}.')\n    return (best_threshold, scores[best_threshold], scores)"
        ]
    }
]