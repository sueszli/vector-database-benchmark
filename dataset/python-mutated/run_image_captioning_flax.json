[
    {
        "func_name": "shift_tokens_right",
        "original": "def shift_tokens_right(input_ids: np.ndarray, pad_token_id: int, decoder_start_token_id: int) -> np.ndarray:\n    \"\"\"\n    Shift input ids one token to the right.\n    \"\"\"\n    shifted_input_ids = np.zeros_like(input_ids)\n    shifted_input_ids[:, 1:] = input_ids[:, :-1]\n    shifted_input_ids[:, 0] = decoder_start_token_id\n    shifted_input_ids = np.where(shifted_input_ids == -100, pad_token_id, shifted_input_ids)\n    return shifted_input_ids",
        "mutated": [
            "def shift_tokens_right(input_ids: np.ndarray, pad_token_id: int, decoder_start_token_id: int) -> np.ndarray:\n    if False:\n        i = 10\n    '\\n    Shift input ids one token to the right.\\n    '\n    shifted_input_ids = np.zeros_like(input_ids)\n    shifted_input_ids[:, 1:] = input_ids[:, :-1]\n    shifted_input_ids[:, 0] = decoder_start_token_id\n    shifted_input_ids = np.where(shifted_input_ids == -100, pad_token_id, shifted_input_ids)\n    return shifted_input_ids",
            "def shift_tokens_right(input_ids: np.ndarray, pad_token_id: int, decoder_start_token_id: int) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Shift input ids one token to the right.\\n    '\n    shifted_input_ids = np.zeros_like(input_ids)\n    shifted_input_ids[:, 1:] = input_ids[:, :-1]\n    shifted_input_ids[:, 0] = decoder_start_token_id\n    shifted_input_ids = np.where(shifted_input_ids == -100, pad_token_id, shifted_input_ids)\n    return shifted_input_ids",
            "def shift_tokens_right(input_ids: np.ndarray, pad_token_id: int, decoder_start_token_id: int) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Shift input ids one token to the right.\\n    '\n    shifted_input_ids = np.zeros_like(input_ids)\n    shifted_input_ids[:, 1:] = input_ids[:, :-1]\n    shifted_input_ids[:, 0] = decoder_start_token_id\n    shifted_input_ids = np.where(shifted_input_ids == -100, pad_token_id, shifted_input_ids)\n    return shifted_input_ids",
            "def shift_tokens_right(input_ids: np.ndarray, pad_token_id: int, decoder_start_token_id: int) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Shift input ids one token to the right.\\n    '\n    shifted_input_ids = np.zeros_like(input_ids)\n    shifted_input_ids[:, 1:] = input_ids[:, :-1]\n    shifted_input_ids[:, 0] = decoder_start_token_id\n    shifted_input_ids = np.where(shifted_input_ids == -100, pad_token_id, shifted_input_ids)\n    return shifted_input_ids",
            "def shift_tokens_right(input_ids: np.ndarray, pad_token_id: int, decoder_start_token_id: int) -> np.ndarray:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Shift input ids one token to the right.\\n    '\n    shifted_input_ids = np.zeros_like(input_ids)\n    shifted_input_ids[:, 1:] = input_ids[:, :-1]\n    shifted_input_ids[:, 0] = decoder_start_token_id\n    shifted_input_ids = np.where(shifted_input_ids == -100, pad_token_id, shifted_input_ids)\n    return shifted_input_ids"
        ]
    },
    {
        "func_name": "__post_init__",
        "original": "def __post_init__(self):\n    if self.output_dir is not None:\n        self.output_dir = os.path.expanduser(self.output_dir)",
        "mutated": [
            "def __post_init__(self):\n    if False:\n        i = 10\n    if self.output_dir is not None:\n        self.output_dir = os.path.expanduser(self.output_dir)",
            "def __post_init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if self.output_dir is not None:\n        self.output_dir = os.path.expanduser(self.output_dir)",
            "def __post_init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if self.output_dir is not None:\n        self.output_dir = os.path.expanduser(self.output_dir)",
            "def __post_init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if self.output_dir is not None:\n        self.output_dir = os.path.expanduser(self.output_dir)",
            "def __post_init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if self.output_dir is not None:\n        self.output_dir = os.path.expanduser(self.output_dir)"
        ]
    },
    {
        "func_name": "to_dict",
        "original": "def to_dict(self):\n    \"\"\"\n        Serializes this instance while replace `Enum` by their values (for JSON serialization support). It obfuscates\n        the token values by removing their value.\n        \"\"\"\n    d = asdict(self)\n    for (k, v) in d.items():\n        if isinstance(v, Enum):\n            d[k] = v.value\n        if isinstance(v, list) and len(v) > 0 and isinstance(v[0], Enum):\n            d[k] = [x.value for x in v]\n        if k.endswith('_token'):\n            d[k] = f'<{k.upper()}>'\n    return d",
        "mutated": [
            "def to_dict(self):\n    if False:\n        i = 10\n    '\\n        Serializes this instance while replace `Enum` by their values (for JSON serialization support). It obfuscates\\n        the token values by removing their value.\\n        '\n    d = asdict(self)\n    for (k, v) in d.items():\n        if isinstance(v, Enum):\n            d[k] = v.value\n        if isinstance(v, list) and len(v) > 0 and isinstance(v[0], Enum):\n            d[k] = [x.value for x in v]\n        if k.endswith('_token'):\n            d[k] = f'<{k.upper()}>'\n    return d",
            "def to_dict(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Serializes this instance while replace `Enum` by their values (for JSON serialization support). It obfuscates\\n        the token values by removing their value.\\n        '\n    d = asdict(self)\n    for (k, v) in d.items():\n        if isinstance(v, Enum):\n            d[k] = v.value\n        if isinstance(v, list) and len(v) > 0 and isinstance(v[0], Enum):\n            d[k] = [x.value for x in v]\n        if k.endswith('_token'):\n            d[k] = f'<{k.upper()}>'\n    return d",
            "def to_dict(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Serializes this instance while replace `Enum` by their values (for JSON serialization support). It obfuscates\\n        the token values by removing their value.\\n        '\n    d = asdict(self)\n    for (k, v) in d.items():\n        if isinstance(v, Enum):\n            d[k] = v.value\n        if isinstance(v, list) and len(v) > 0 and isinstance(v[0], Enum):\n            d[k] = [x.value for x in v]\n        if k.endswith('_token'):\n            d[k] = f'<{k.upper()}>'\n    return d",
            "def to_dict(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Serializes this instance while replace `Enum` by their values (for JSON serialization support). It obfuscates\\n        the token values by removing their value.\\n        '\n    d = asdict(self)\n    for (k, v) in d.items():\n        if isinstance(v, Enum):\n            d[k] = v.value\n        if isinstance(v, list) and len(v) > 0 and isinstance(v[0], Enum):\n            d[k] = [x.value for x in v]\n        if k.endswith('_token'):\n            d[k] = f'<{k.upper()}>'\n    return d",
            "def to_dict(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Serializes this instance while replace `Enum` by their values (for JSON serialization support). It obfuscates\\n        the token values by removing their value.\\n        '\n    d = asdict(self)\n    for (k, v) in d.items():\n        if isinstance(v, Enum):\n            d[k] = v.value\n        if isinstance(v, list) and len(v) > 0 and isinstance(v[0], Enum):\n            d[k] = [x.value for x in v]\n        if k.endswith('_token'):\n            d[k] = f'<{k.upper()}>'\n    return d"
        ]
    },
    {
        "func_name": "__post_init__",
        "original": "def __post_init__(self):\n    if self.dataset_name is None and self.train_file is None and (self.validation_file is None):\n        raise ValueError('Need either a dataset name or a training/validation file.')\n    else:\n        if self.train_file is not None:\n            extension = self.train_file.split('.')[-1]\n            if extension not in ['csv', 'json']:\n                raise ValueError(f'`train_file` should be a csv or a json file, got {extension}.')\n        if self.validation_file is not None:\n            extension = self.validation_file.split('.')[-1]\n            if extension not in ['csv', 'json']:\n                raise ValueError(f'`validation_file` should be a csv or a json file, got {extension}.')\n    if self.val_max_target_length is None:\n        self.val_max_target_length = self.max_target_length",
        "mutated": [
            "def __post_init__(self):\n    if False:\n        i = 10\n    if self.dataset_name is None and self.train_file is None and (self.validation_file is None):\n        raise ValueError('Need either a dataset name or a training/validation file.')\n    else:\n        if self.train_file is not None:\n            extension = self.train_file.split('.')[-1]\n            if extension not in ['csv', 'json']:\n                raise ValueError(f'`train_file` should be a csv or a json file, got {extension}.')\n        if self.validation_file is not None:\n            extension = self.validation_file.split('.')[-1]\n            if extension not in ['csv', 'json']:\n                raise ValueError(f'`validation_file` should be a csv or a json file, got {extension}.')\n    if self.val_max_target_length is None:\n        self.val_max_target_length = self.max_target_length",
            "def __post_init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if self.dataset_name is None and self.train_file is None and (self.validation_file is None):\n        raise ValueError('Need either a dataset name or a training/validation file.')\n    else:\n        if self.train_file is not None:\n            extension = self.train_file.split('.')[-1]\n            if extension not in ['csv', 'json']:\n                raise ValueError(f'`train_file` should be a csv or a json file, got {extension}.')\n        if self.validation_file is not None:\n            extension = self.validation_file.split('.')[-1]\n            if extension not in ['csv', 'json']:\n                raise ValueError(f'`validation_file` should be a csv or a json file, got {extension}.')\n    if self.val_max_target_length is None:\n        self.val_max_target_length = self.max_target_length",
            "def __post_init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if self.dataset_name is None and self.train_file is None and (self.validation_file is None):\n        raise ValueError('Need either a dataset name or a training/validation file.')\n    else:\n        if self.train_file is not None:\n            extension = self.train_file.split('.')[-1]\n            if extension not in ['csv', 'json']:\n                raise ValueError(f'`train_file` should be a csv or a json file, got {extension}.')\n        if self.validation_file is not None:\n            extension = self.validation_file.split('.')[-1]\n            if extension not in ['csv', 'json']:\n                raise ValueError(f'`validation_file` should be a csv or a json file, got {extension}.')\n    if self.val_max_target_length is None:\n        self.val_max_target_length = self.max_target_length",
            "def __post_init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if self.dataset_name is None and self.train_file is None and (self.validation_file is None):\n        raise ValueError('Need either a dataset name or a training/validation file.')\n    else:\n        if self.train_file is not None:\n            extension = self.train_file.split('.')[-1]\n            if extension not in ['csv', 'json']:\n                raise ValueError(f'`train_file` should be a csv or a json file, got {extension}.')\n        if self.validation_file is not None:\n            extension = self.validation_file.split('.')[-1]\n            if extension not in ['csv', 'json']:\n                raise ValueError(f'`validation_file` should be a csv or a json file, got {extension}.')\n    if self.val_max_target_length is None:\n        self.val_max_target_length = self.max_target_length",
            "def __post_init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if self.dataset_name is None and self.train_file is None and (self.validation_file is None):\n        raise ValueError('Need either a dataset name or a training/validation file.')\n    else:\n        if self.train_file is not None:\n            extension = self.train_file.split('.')[-1]\n            if extension not in ['csv', 'json']:\n                raise ValueError(f'`train_file` should be a csv or a json file, got {extension}.')\n        if self.validation_file is not None:\n            extension = self.validation_file.split('.')[-1]\n            if extension not in ['csv', 'json']:\n                raise ValueError(f'`validation_file` should be a csv or a json file, got {extension}.')\n    if self.val_max_target_length is None:\n        self.val_max_target_length = self.max_target_length"
        ]
    },
    {
        "func_name": "replicate",
        "original": "def replicate(self):\n    return jax_utils.replicate(self).replace(dropout_rng=shard_prng_key(self.dropout_rng))",
        "mutated": [
            "def replicate(self):\n    if False:\n        i = 10\n    return jax_utils.replicate(self).replace(dropout_rng=shard_prng_key(self.dropout_rng))",
            "def replicate(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return jax_utils.replicate(self).replace(dropout_rng=shard_prng_key(self.dropout_rng))",
            "def replicate(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return jax_utils.replicate(self).replace(dropout_rng=shard_prng_key(self.dropout_rng))",
            "def replicate(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return jax_utils.replicate(self).replace(dropout_rng=shard_prng_key(self.dropout_rng))",
            "def replicate(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return jax_utils.replicate(self).replace(dropout_rng=shard_prng_key(self.dropout_rng))"
        ]
    },
    {
        "func_name": "data_loader",
        "original": "def data_loader(rng: jax.random.PRNGKey, dataset: Dataset, batch_size: int, shuffle: bool=False):\n    \"\"\"\n    Returns batches of size `batch_size` from truncated `dataset`, sharded over all local devices.\n    Shuffle batches if `shuffle` is `True`.\n    \"\"\"\n    steps = len(dataset) // batch_size\n    if shuffle:\n        batch_idx = jax.random.permutation(rng, len(dataset))\n        batch_idx = np.asarray(batch_idx)\n    else:\n        batch_idx = np.arange(len(dataset))\n    for idx in range(steps):\n        start_idx = batch_size * idx\n        end_idx = batch_size * (idx + 1)\n        selected_indices = batch_idx[start_idx:end_idx]\n        batch = dataset[selected_indices]\n        batch = shard(batch)\n        yield batch",
        "mutated": [
            "def data_loader(rng: jax.random.PRNGKey, dataset: Dataset, batch_size: int, shuffle: bool=False):\n    if False:\n        i = 10\n    '\\n    Returns batches of size `batch_size` from truncated `dataset`, sharded over all local devices.\\n    Shuffle batches if `shuffle` is `True`.\\n    '\n    steps = len(dataset) // batch_size\n    if shuffle:\n        batch_idx = jax.random.permutation(rng, len(dataset))\n        batch_idx = np.asarray(batch_idx)\n    else:\n        batch_idx = np.arange(len(dataset))\n    for idx in range(steps):\n        start_idx = batch_size * idx\n        end_idx = batch_size * (idx + 1)\n        selected_indices = batch_idx[start_idx:end_idx]\n        batch = dataset[selected_indices]\n        batch = shard(batch)\n        yield batch",
            "def data_loader(rng: jax.random.PRNGKey, dataset: Dataset, batch_size: int, shuffle: bool=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Returns batches of size `batch_size` from truncated `dataset`, sharded over all local devices.\\n    Shuffle batches if `shuffle` is `True`.\\n    '\n    steps = len(dataset) // batch_size\n    if shuffle:\n        batch_idx = jax.random.permutation(rng, len(dataset))\n        batch_idx = np.asarray(batch_idx)\n    else:\n        batch_idx = np.arange(len(dataset))\n    for idx in range(steps):\n        start_idx = batch_size * idx\n        end_idx = batch_size * (idx + 1)\n        selected_indices = batch_idx[start_idx:end_idx]\n        batch = dataset[selected_indices]\n        batch = shard(batch)\n        yield batch",
            "def data_loader(rng: jax.random.PRNGKey, dataset: Dataset, batch_size: int, shuffle: bool=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Returns batches of size `batch_size` from truncated `dataset`, sharded over all local devices.\\n    Shuffle batches if `shuffle` is `True`.\\n    '\n    steps = len(dataset) // batch_size\n    if shuffle:\n        batch_idx = jax.random.permutation(rng, len(dataset))\n        batch_idx = np.asarray(batch_idx)\n    else:\n        batch_idx = np.arange(len(dataset))\n    for idx in range(steps):\n        start_idx = batch_size * idx\n        end_idx = batch_size * (idx + 1)\n        selected_indices = batch_idx[start_idx:end_idx]\n        batch = dataset[selected_indices]\n        batch = shard(batch)\n        yield batch",
            "def data_loader(rng: jax.random.PRNGKey, dataset: Dataset, batch_size: int, shuffle: bool=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Returns batches of size `batch_size` from truncated `dataset`, sharded over all local devices.\\n    Shuffle batches if `shuffle` is `True`.\\n    '\n    steps = len(dataset) // batch_size\n    if shuffle:\n        batch_idx = jax.random.permutation(rng, len(dataset))\n        batch_idx = np.asarray(batch_idx)\n    else:\n        batch_idx = np.arange(len(dataset))\n    for idx in range(steps):\n        start_idx = batch_size * idx\n        end_idx = batch_size * (idx + 1)\n        selected_indices = batch_idx[start_idx:end_idx]\n        batch = dataset[selected_indices]\n        batch = shard(batch)\n        yield batch",
            "def data_loader(rng: jax.random.PRNGKey, dataset: Dataset, batch_size: int, shuffle: bool=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Returns batches of size `batch_size` from truncated `dataset`, sharded over all local devices.\\n    Shuffle batches if `shuffle` is `True`.\\n    '\n    steps = len(dataset) // batch_size\n    if shuffle:\n        batch_idx = jax.random.permutation(rng, len(dataset))\n        batch_idx = np.asarray(batch_idx)\n    else:\n        batch_idx = np.arange(len(dataset))\n    for idx in range(steps):\n        start_idx = batch_size * idx\n        end_idx = batch_size * (idx + 1)\n        selected_indices = batch_idx[start_idx:end_idx]\n        batch = dataset[selected_indices]\n        batch = shard(batch)\n        yield batch"
        ]
    },
    {
        "func_name": "write_metric",
        "original": "def write_metric(summary_writer, metrics, train_time, step, metric_key_prefix='train'):\n    if train_time:\n        summary_writer.scalar('train_time', train_time, step)\n        metrics = get_metrics(metrics)\n        for (key, vals) in metrics.items():\n            tag = f'{metric_key_prefix}_{key}'\n            for (i, val) in enumerate(vals):\n                summary_writer.scalar(tag, val, step - len(vals) + i + 1)\n    else:\n        for (metric_name, value) in metrics.items():\n            summary_writer.scalar(f'{metric_key_prefix}_{metric_name}', value, step)",
        "mutated": [
            "def write_metric(summary_writer, metrics, train_time, step, metric_key_prefix='train'):\n    if False:\n        i = 10\n    if train_time:\n        summary_writer.scalar('train_time', train_time, step)\n        metrics = get_metrics(metrics)\n        for (key, vals) in metrics.items():\n            tag = f'{metric_key_prefix}_{key}'\n            for (i, val) in enumerate(vals):\n                summary_writer.scalar(tag, val, step - len(vals) + i + 1)\n    else:\n        for (metric_name, value) in metrics.items():\n            summary_writer.scalar(f'{metric_key_prefix}_{metric_name}', value, step)",
            "def write_metric(summary_writer, metrics, train_time, step, metric_key_prefix='train'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if train_time:\n        summary_writer.scalar('train_time', train_time, step)\n        metrics = get_metrics(metrics)\n        for (key, vals) in metrics.items():\n            tag = f'{metric_key_prefix}_{key}'\n            for (i, val) in enumerate(vals):\n                summary_writer.scalar(tag, val, step - len(vals) + i + 1)\n    else:\n        for (metric_name, value) in metrics.items():\n            summary_writer.scalar(f'{metric_key_prefix}_{metric_name}', value, step)",
            "def write_metric(summary_writer, metrics, train_time, step, metric_key_prefix='train'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if train_time:\n        summary_writer.scalar('train_time', train_time, step)\n        metrics = get_metrics(metrics)\n        for (key, vals) in metrics.items():\n            tag = f'{metric_key_prefix}_{key}'\n            for (i, val) in enumerate(vals):\n                summary_writer.scalar(tag, val, step - len(vals) + i + 1)\n    else:\n        for (metric_name, value) in metrics.items():\n            summary_writer.scalar(f'{metric_key_prefix}_{metric_name}', value, step)",
            "def write_metric(summary_writer, metrics, train_time, step, metric_key_prefix='train'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if train_time:\n        summary_writer.scalar('train_time', train_time, step)\n        metrics = get_metrics(metrics)\n        for (key, vals) in metrics.items():\n            tag = f'{metric_key_prefix}_{key}'\n            for (i, val) in enumerate(vals):\n                summary_writer.scalar(tag, val, step - len(vals) + i + 1)\n    else:\n        for (metric_name, value) in metrics.items():\n            summary_writer.scalar(f'{metric_key_prefix}_{metric_name}', value, step)",
            "def write_metric(summary_writer, metrics, train_time, step, metric_key_prefix='train'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if train_time:\n        summary_writer.scalar('train_time', train_time, step)\n        metrics = get_metrics(metrics)\n        for (key, vals) in metrics.items():\n            tag = f'{metric_key_prefix}_{key}'\n            for (i, val) in enumerate(vals):\n                summary_writer.scalar(tag, val, step - len(vals) + i + 1)\n    else:\n        for (metric_name, value) in metrics.items():\n            summary_writer.scalar(f'{metric_key_prefix}_{metric_name}', value, step)"
        ]
    },
    {
        "func_name": "create_learning_rate_fn",
        "original": "def create_learning_rate_fn(train_ds_size: int, train_batch_size: int, num_train_epochs: int, num_warmup_steps: int, learning_rate: float) -> Callable[[int], jnp.ndarray]:\n    \"\"\"Returns a linear warmup, linear_decay learning rate function.\"\"\"\n    steps_per_epoch = train_ds_size // train_batch_size\n    num_train_steps = steps_per_epoch * num_train_epochs\n    warmup_fn = optax.linear_schedule(init_value=0.0, end_value=learning_rate, transition_steps=num_warmup_steps)\n    decay_fn = optax.linear_schedule(init_value=learning_rate, end_value=0, transition_steps=num_train_steps - num_warmup_steps)\n    schedule_fn = optax.join_schedules(schedules=[warmup_fn, decay_fn], boundaries=[num_warmup_steps])\n    return schedule_fn",
        "mutated": [
            "def create_learning_rate_fn(train_ds_size: int, train_batch_size: int, num_train_epochs: int, num_warmup_steps: int, learning_rate: float) -> Callable[[int], jnp.ndarray]:\n    if False:\n        i = 10\n    'Returns a linear warmup, linear_decay learning rate function.'\n    steps_per_epoch = train_ds_size // train_batch_size\n    num_train_steps = steps_per_epoch * num_train_epochs\n    warmup_fn = optax.linear_schedule(init_value=0.0, end_value=learning_rate, transition_steps=num_warmup_steps)\n    decay_fn = optax.linear_schedule(init_value=learning_rate, end_value=0, transition_steps=num_train_steps - num_warmup_steps)\n    schedule_fn = optax.join_schedules(schedules=[warmup_fn, decay_fn], boundaries=[num_warmup_steps])\n    return schedule_fn",
            "def create_learning_rate_fn(train_ds_size: int, train_batch_size: int, num_train_epochs: int, num_warmup_steps: int, learning_rate: float) -> Callable[[int], jnp.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Returns a linear warmup, linear_decay learning rate function.'\n    steps_per_epoch = train_ds_size // train_batch_size\n    num_train_steps = steps_per_epoch * num_train_epochs\n    warmup_fn = optax.linear_schedule(init_value=0.0, end_value=learning_rate, transition_steps=num_warmup_steps)\n    decay_fn = optax.linear_schedule(init_value=learning_rate, end_value=0, transition_steps=num_train_steps - num_warmup_steps)\n    schedule_fn = optax.join_schedules(schedules=[warmup_fn, decay_fn], boundaries=[num_warmup_steps])\n    return schedule_fn",
            "def create_learning_rate_fn(train_ds_size: int, train_batch_size: int, num_train_epochs: int, num_warmup_steps: int, learning_rate: float) -> Callable[[int], jnp.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Returns a linear warmup, linear_decay learning rate function.'\n    steps_per_epoch = train_ds_size // train_batch_size\n    num_train_steps = steps_per_epoch * num_train_epochs\n    warmup_fn = optax.linear_schedule(init_value=0.0, end_value=learning_rate, transition_steps=num_warmup_steps)\n    decay_fn = optax.linear_schedule(init_value=learning_rate, end_value=0, transition_steps=num_train_steps - num_warmup_steps)\n    schedule_fn = optax.join_schedules(schedules=[warmup_fn, decay_fn], boundaries=[num_warmup_steps])\n    return schedule_fn",
            "def create_learning_rate_fn(train_ds_size: int, train_batch_size: int, num_train_epochs: int, num_warmup_steps: int, learning_rate: float) -> Callable[[int], jnp.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Returns a linear warmup, linear_decay learning rate function.'\n    steps_per_epoch = train_ds_size // train_batch_size\n    num_train_steps = steps_per_epoch * num_train_epochs\n    warmup_fn = optax.linear_schedule(init_value=0.0, end_value=learning_rate, transition_steps=num_warmup_steps)\n    decay_fn = optax.linear_schedule(init_value=learning_rate, end_value=0, transition_steps=num_train_steps - num_warmup_steps)\n    schedule_fn = optax.join_schedules(schedules=[warmup_fn, decay_fn], boundaries=[num_warmup_steps])\n    return schedule_fn",
            "def create_learning_rate_fn(train_ds_size: int, train_batch_size: int, num_train_epochs: int, num_warmup_steps: int, learning_rate: float) -> Callable[[int], jnp.ndarray]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Returns a linear warmup, linear_decay learning rate function.'\n    steps_per_epoch = train_ds_size // train_batch_size\n    num_train_steps = steps_per_epoch * num_train_epochs\n    warmup_fn = optax.linear_schedule(init_value=0.0, end_value=learning_rate, transition_steps=num_warmup_steps)\n    decay_fn = optax.linear_schedule(init_value=learning_rate, end_value=0, transition_steps=num_train_steps - num_warmup_steps)\n    schedule_fn = optax.join_schedules(schedules=[warmup_fn, decay_fn], boundaries=[num_warmup_steps])\n    return schedule_fn"
        ]
    },
    {
        "func_name": "filter_fn",
        "original": "def filter_fn(examples):\n    \"\"\"remove problematic images\"\"\"\n    bools = []\n    for image_file in examples[image_column]:\n        try:\n            image = Image.open(image_file)\n            image_processor(images=image, return_tensors='np')\n            bools.append(True)\n        except Exception:\n            bools.append(False)\n    return bools",
        "mutated": [
            "def filter_fn(examples):\n    if False:\n        i = 10\n    'remove problematic images'\n    bools = []\n    for image_file in examples[image_column]:\n        try:\n            image = Image.open(image_file)\n            image_processor(images=image, return_tensors='np')\n            bools.append(True)\n        except Exception:\n            bools.append(False)\n    return bools",
            "def filter_fn(examples):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'remove problematic images'\n    bools = []\n    for image_file in examples[image_column]:\n        try:\n            image = Image.open(image_file)\n            image_processor(images=image, return_tensors='np')\n            bools.append(True)\n        except Exception:\n            bools.append(False)\n    return bools",
            "def filter_fn(examples):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'remove problematic images'\n    bools = []\n    for image_file in examples[image_column]:\n        try:\n            image = Image.open(image_file)\n            image_processor(images=image, return_tensors='np')\n            bools.append(True)\n        except Exception:\n            bools.append(False)\n    return bools",
            "def filter_fn(examples):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'remove problematic images'\n    bools = []\n    for image_file in examples[image_column]:\n        try:\n            image = Image.open(image_file)\n            image_processor(images=image, return_tensors='np')\n            bools.append(True)\n        except Exception:\n            bools.append(False)\n    return bools",
            "def filter_fn(examples):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'remove problematic images'\n    bools = []\n    for image_file in examples[image_column]:\n        try:\n            image = Image.open(image_file)\n            image_processor(images=image, return_tensors='np')\n            bools.append(True)\n        except Exception:\n            bools.append(False)\n    return bools"
        ]
    },
    {
        "func_name": "tokenization_fn",
        "original": "def tokenization_fn(examples, max_target_length):\n    \"\"\"Run tokenization on captions.\"\"\"\n    captions = []\n    for caption in examples[caption_column]:\n        captions.append(caption.lower() + ' ' + tokenizer.eos_token)\n    targets = captions\n    model_inputs = {}\n    labels = tokenizer(text_target=targets, max_length=max_target_length, padding='max_length', truncation=True, return_tensors='np')\n    model_inputs['labels'] = labels['input_ids']\n    decoder_input_ids = shift_tokens_right_fn(labels['input_ids'], model.config.pad_token_id, model.config.decoder_start_token_id)\n    model_inputs['decoder_input_ids'] = np.asarray(decoder_input_ids)\n    model_inputs['decoder_attention_mask'] = labels['attention_mask']\n    model_inputs[image_column] = examples[image_column]\n    return model_inputs",
        "mutated": [
            "def tokenization_fn(examples, max_target_length):\n    if False:\n        i = 10\n    'Run tokenization on captions.'\n    captions = []\n    for caption in examples[caption_column]:\n        captions.append(caption.lower() + ' ' + tokenizer.eos_token)\n    targets = captions\n    model_inputs = {}\n    labels = tokenizer(text_target=targets, max_length=max_target_length, padding='max_length', truncation=True, return_tensors='np')\n    model_inputs['labels'] = labels['input_ids']\n    decoder_input_ids = shift_tokens_right_fn(labels['input_ids'], model.config.pad_token_id, model.config.decoder_start_token_id)\n    model_inputs['decoder_input_ids'] = np.asarray(decoder_input_ids)\n    model_inputs['decoder_attention_mask'] = labels['attention_mask']\n    model_inputs[image_column] = examples[image_column]\n    return model_inputs",
            "def tokenization_fn(examples, max_target_length):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Run tokenization on captions.'\n    captions = []\n    for caption in examples[caption_column]:\n        captions.append(caption.lower() + ' ' + tokenizer.eos_token)\n    targets = captions\n    model_inputs = {}\n    labels = tokenizer(text_target=targets, max_length=max_target_length, padding='max_length', truncation=True, return_tensors='np')\n    model_inputs['labels'] = labels['input_ids']\n    decoder_input_ids = shift_tokens_right_fn(labels['input_ids'], model.config.pad_token_id, model.config.decoder_start_token_id)\n    model_inputs['decoder_input_ids'] = np.asarray(decoder_input_ids)\n    model_inputs['decoder_attention_mask'] = labels['attention_mask']\n    model_inputs[image_column] = examples[image_column]\n    return model_inputs",
            "def tokenization_fn(examples, max_target_length):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Run tokenization on captions.'\n    captions = []\n    for caption in examples[caption_column]:\n        captions.append(caption.lower() + ' ' + tokenizer.eos_token)\n    targets = captions\n    model_inputs = {}\n    labels = tokenizer(text_target=targets, max_length=max_target_length, padding='max_length', truncation=True, return_tensors='np')\n    model_inputs['labels'] = labels['input_ids']\n    decoder_input_ids = shift_tokens_right_fn(labels['input_ids'], model.config.pad_token_id, model.config.decoder_start_token_id)\n    model_inputs['decoder_input_ids'] = np.asarray(decoder_input_ids)\n    model_inputs['decoder_attention_mask'] = labels['attention_mask']\n    model_inputs[image_column] = examples[image_column]\n    return model_inputs",
            "def tokenization_fn(examples, max_target_length):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Run tokenization on captions.'\n    captions = []\n    for caption in examples[caption_column]:\n        captions.append(caption.lower() + ' ' + tokenizer.eos_token)\n    targets = captions\n    model_inputs = {}\n    labels = tokenizer(text_target=targets, max_length=max_target_length, padding='max_length', truncation=True, return_tensors='np')\n    model_inputs['labels'] = labels['input_ids']\n    decoder_input_ids = shift_tokens_right_fn(labels['input_ids'], model.config.pad_token_id, model.config.decoder_start_token_id)\n    model_inputs['decoder_input_ids'] = np.asarray(decoder_input_ids)\n    model_inputs['decoder_attention_mask'] = labels['attention_mask']\n    model_inputs[image_column] = examples[image_column]\n    return model_inputs",
            "def tokenization_fn(examples, max_target_length):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Run tokenization on captions.'\n    captions = []\n    for caption in examples[caption_column]:\n        captions.append(caption.lower() + ' ' + tokenizer.eos_token)\n    targets = captions\n    model_inputs = {}\n    labels = tokenizer(text_target=targets, max_length=max_target_length, padding='max_length', truncation=True, return_tensors='np')\n    model_inputs['labels'] = labels['input_ids']\n    decoder_input_ids = shift_tokens_right_fn(labels['input_ids'], model.config.pad_token_id, model.config.decoder_start_token_id)\n    model_inputs['decoder_input_ids'] = np.asarray(decoder_input_ids)\n    model_inputs['decoder_attention_mask'] = labels['attention_mask']\n    model_inputs[image_column] = examples[image_column]\n    return model_inputs"
        ]
    },
    {
        "func_name": "image_processing_fn",
        "original": "def image_processing_fn(examples, check_image=True):\n    \"\"\"\n        Run preprocessing on images\n\n        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\n        Otherwise, an exception will be thrown.\n        \"\"\"\n    model_inputs = {}\n    if check_image:\n        images = []\n        to_keep = []\n        for image_file in examples[image_column]:\n            try:\n                img = Image.open(image_file)\n                images.append(img)\n                to_keep.append(True)\n            except Exception:\n                to_keep.append(False)\n        for (k, v) in examples.items():\n            if k != image_column:\n                model_inputs[k] = v[to_keep]\n    else:\n        images = [Image.open(image_file) for image_file in examples[image_column]]\n    encoder_inputs = image_processor(images=images, return_tensors='np')\n    model_inputs['pixel_values'] = encoder_inputs.pixel_values\n    return model_inputs",
        "mutated": [
            "def image_processing_fn(examples, check_image=True):\n    if False:\n        i = 10\n    '\\n        Run preprocessing on images\\n\\n        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\\n        Otherwise, an exception will be thrown.\\n        '\n    model_inputs = {}\n    if check_image:\n        images = []\n        to_keep = []\n        for image_file in examples[image_column]:\n            try:\n                img = Image.open(image_file)\n                images.append(img)\n                to_keep.append(True)\n            except Exception:\n                to_keep.append(False)\n        for (k, v) in examples.items():\n            if k != image_column:\n                model_inputs[k] = v[to_keep]\n    else:\n        images = [Image.open(image_file) for image_file in examples[image_column]]\n    encoder_inputs = image_processor(images=images, return_tensors='np')\n    model_inputs['pixel_values'] = encoder_inputs.pixel_values\n    return model_inputs",
            "def image_processing_fn(examples, check_image=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Run preprocessing on images\\n\\n        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\\n        Otherwise, an exception will be thrown.\\n        '\n    model_inputs = {}\n    if check_image:\n        images = []\n        to_keep = []\n        for image_file in examples[image_column]:\n            try:\n                img = Image.open(image_file)\n                images.append(img)\n                to_keep.append(True)\n            except Exception:\n                to_keep.append(False)\n        for (k, v) in examples.items():\n            if k != image_column:\n                model_inputs[k] = v[to_keep]\n    else:\n        images = [Image.open(image_file) for image_file in examples[image_column]]\n    encoder_inputs = image_processor(images=images, return_tensors='np')\n    model_inputs['pixel_values'] = encoder_inputs.pixel_values\n    return model_inputs",
            "def image_processing_fn(examples, check_image=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Run preprocessing on images\\n\\n        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\\n        Otherwise, an exception will be thrown.\\n        '\n    model_inputs = {}\n    if check_image:\n        images = []\n        to_keep = []\n        for image_file in examples[image_column]:\n            try:\n                img = Image.open(image_file)\n                images.append(img)\n                to_keep.append(True)\n            except Exception:\n                to_keep.append(False)\n        for (k, v) in examples.items():\n            if k != image_column:\n                model_inputs[k] = v[to_keep]\n    else:\n        images = [Image.open(image_file) for image_file in examples[image_column]]\n    encoder_inputs = image_processor(images=images, return_tensors='np')\n    model_inputs['pixel_values'] = encoder_inputs.pixel_values\n    return model_inputs",
            "def image_processing_fn(examples, check_image=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Run preprocessing on images\\n\\n        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\\n        Otherwise, an exception will be thrown.\\n        '\n    model_inputs = {}\n    if check_image:\n        images = []\n        to_keep = []\n        for image_file in examples[image_column]:\n            try:\n                img = Image.open(image_file)\n                images.append(img)\n                to_keep.append(True)\n            except Exception:\n                to_keep.append(False)\n        for (k, v) in examples.items():\n            if k != image_column:\n                model_inputs[k] = v[to_keep]\n    else:\n        images = [Image.open(image_file) for image_file in examples[image_column]]\n    encoder_inputs = image_processor(images=images, return_tensors='np')\n    model_inputs['pixel_values'] = encoder_inputs.pixel_values\n    return model_inputs",
            "def image_processing_fn(examples, check_image=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Run preprocessing on images\\n\\n        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\\n        Otherwise, an exception will be thrown.\\n        '\n    model_inputs = {}\n    if check_image:\n        images = []\n        to_keep = []\n        for image_file in examples[image_column]:\n            try:\n                img = Image.open(image_file)\n                images.append(img)\n                to_keep.append(True)\n            except Exception:\n                to_keep.append(False)\n        for (k, v) in examples.items():\n            if k != image_column:\n                model_inputs[k] = v[to_keep]\n    else:\n        images = [Image.open(image_file) for image_file in examples[image_column]]\n    encoder_inputs = image_processor(images=images, return_tensors='np')\n    model_inputs['pixel_values'] = encoder_inputs.pixel_values\n    return model_inputs"
        ]
    },
    {
        "func_name": "preprocess_fn",
        "original": "def preprocess_fn(examples, max_target_length, check_image=True):\n    \"\"\"Run tokenization + image processing\"\"\"\n    model_inputs = {}\n    model_inputs.update(tokenization_fn(examples, max_target_length))\n    model_inputs.update(image_processing_fn(model_inputs, check_image=check_image))\n    model_inputs.pop(image_column)\n    return model_inputs",
        "mutated": [
            "def preprocess_fn(examples, max_target_length, check_image=True):\n    if False:\n        i = 10\n    'Run tokenization + image processing'\n    model_inputs = {}\n    model_inputs.update(tokenization_fn(examples, max_target_length))\n    model_inputs.update(image_processing_fn(model_inputs, check_image=check_image))\n    model_inputs.pop(image_column)\n    return model_inputs",
            "def preprocess_fn(examples, max_target_length, check_image=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Run tokenization + image processing'\n    model_inputs = {}\n    model_inputs.update(tokenization_fn(examples, max_target_length))\n    model_inputs.update(image_processing_fn(model_inputs, check_image=check_image))\n    model_inputs.pop(image_column)\n    return model_inputs",
            "def preprocess_fn(examples, max_target_length, check_image=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Run tokenization + image processing'\n    model_inputs = {}\n    model_inputs.update(tokenization_fn(examples, max_target_length))\n    model_inputs.update(image_processing_fn(model_inputs, check_image=check_image))\n    model_inputs.pop(image_column)\n    return model_inputs",
            "def preprocess_fn(examples, max_target_length, check_image=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Run tokenization + image processing'\n    model_inputs = {}\n    model_inputs.update(tokenization_fn(examples, max_target_length))\n    model_inputs.update(image_processing_fn(model_inputs, check_image=check_image))\n    model_inputs.pop(image_column)\n    return model_inputs",
            "def preprocess_fn(examples, max_target_length, check_image=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Run tokenization + image processing'\n    model_inputs = {}\n    model_inputs.update(tokenization_fn(examples, max_target_length))\n    model_inputs.update(image_processing_fn(model_inputs, check_image=check_image))\n    model_inputs.pop(image_column)\n    return model_inputs"
        ]
    },
    {
        "func_name": "blockwise_data_loader",
        "original": "def blockwise_data_loader(rng: jax.random.PRNGKey, ds: Dataset, block_size: int, batch_size: int, shuffle: bool=False, keep_in_memory: bool=False, split: str=''):\n    \"\"\"\n        Wrap the simple `data_loader` in a block-wise way if `block_size` > 0, else it's the same as `data_loader`.\n\n        If `block_size` > 0, it requires `ds` to have a column that gives image paths in order to perform image\n        processing (with the column name being specified by `image_column`). The tokenization should be done before\n        training in this case.\n        \"\"\"\n    if shuffle:\n        indices = jax.random.permutation(rng, len(ds))\n        indices = np.asarray(indices)\n    else:\n        indices = np.arange(len(ds))\n    _block_size = len(ds) if not block_size else block_size\n    steps_per_block = _block_size // batch_size\n    num_examples = len(ds)\n    steps = num_examples // batch_size\n    num_splits = steps // steps_per_block + int(steps % steps_per_block > 0)\n    for idx in range(num_splits):\n        if not block_size:\n            _ds = ds\n        else:\n            start_idx = block_size * idx\n            end_idx = block_size * (idx + 1)\n            selected_indices = indices[start_idx:end_idx]\n            _ds = ds.select(selected_indices)\n            _ds = _ds.map(image_processing_fn, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=[image_column], load_from_cache_file=not data_args.overwrite_cache, features=features, keep_in_memory=keep_in_memory, fn_kwargs={'check_image': False}, desc=f'Running image processing on {split} dataset'.replace('  ', ' '))\n            _ds = _ds.with_format('numpy')\n        loader = data_loader(rng, _ds, batch_size=batch_size, shuffle=False)\n        for batch in loader:\n            yield batch",
        "mutated": [
            "def blockwise_data_loader(rng: jax.random.PRNGKey, ds: Dataset, block_size: int, batch_size: int, shuffle: bool=False, keep_in_memory: bool=False, split: str=''):\n    if False:\n        i = 10\n    \"\\n        Wrap the simple `data_loader` in a block-wise way if `block_size` > 0, else it's the same as `data_loader`.\\n\\n        If `block_size` > 0, it requires `ds` to have a column that gives image paths in order to perform image\\n        processing (with the column name being specified by `image_column`). The tokenization should be done before\\n        training in this case.\\n        \"\n    if shuffle:\n        indices = jax.random.permutation(rng, len(ds))\n        indices = np.asarray(indices)\n    else:\n        indices = np.arange(len(ds))\n    _block_size = len(ds) if not block_size else block_size\n    steps_per_block = _block_size // batch_size\n    num_examples = len(ds)\n    steps = num_examples // batch_size\n    num_splits = steps // steps_per_block + int(steps % steps_per_block > 0)\n    for idx in range(num_splits):\n        if not block_size:\n            _ds = ds\n        else:\n            start_idx = block_size * idx\n            end_idx = block_size * (idx + 1)\n            selected_indices = indices[start_idx:end_idx]\n            _ds = ds.select(selected_indices)\n            _ds = _ds.map(image_processing_fn, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=[image_column], load_from_cache_file=not data_args.overwrite_cache, features=features, keep_in_memory=keep_in_memory, fn_kwargs={'check_image': False}, desc=f'Running image processing on {split} dataset'.replace('  ', ' '))\n            _ds = _ds.with_format('numpy')\n        loader = data_loader(rng, _ds, batch_size=batch_size, shuffle=False)\n        for batch in loader:\n            yield batch",
            "def blockwise_data_loader(rng: jax.random.PRNGKey, ds: Dataset, block_size: int, batch_size: int, shuffle: bool=False, keep_in_memory: bool=False, split: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Wrap the simple `data_loader` in a block-wise way if `block_size` > 0, else it's the same as `data_loader`.\\n\\n        If `block_size` > 0, it requires `ds` to have a column that gives image paths in order to perform image\\n        processing (with the column name being specified by `image_column`). The tokenization should be done before\\n        training in this case.\\n        \"\n    if shuffle:\n        indices = jax.random.permutation(rng, len(ds))\n        indices = np.asarray(indices)\n    else:\n        indices = np.arange(len(ds))\n    _block_size = len(ds) if not block_size else block_size\n    steps_per_block = _block_size // batch_size\n    num_examples = len(ds)\n    steps = num_examples // batch_size\n    num_splits = steps // steps_per_block + int(steps % steps_per_block > 0)\n    for idx in range(num_splits):\n        if not block_size:\n            _ds = ds\n        else:\n            start_idx = block_size * idx\n            end_idx = block_size * (idx + 1)\n            selected_indices = indices[start_idx:end_idx]\n            _ds = ds.select(selected_indices)\n            _ds = _ds.map(image_processing_fn, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=[image_column], load_from_cache_file=not data_args.overwrite_cache, features=features, keep_in_memory=keep_in_memory, fn_kwargs={'check_image': False}, desc=f'Running image processing on {split} dataset'.replace('  ', ' '))\n            _ds = _ds.with_format('numpy')\n        loader = data_loader(rng, _ds, batch_size=batch_size, shuffle=False)\n        for batch in loader:\n            yield batch",
            "def blockwise_data_loader(rng: jax.random.PRNGKey, ds: Dataset, block_size: int, batch_size: int, shuffle: bool=False, keep_in_memory: bool=False, split: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Wrap the simple `data_loader` in a block-wise way if `block_size` > 0, else it's the same as `data_loader`.\\n\\n        If `block_size` > 0, it requires `ds` to have a column that gives image paths in order to perform image\\n        processing (with the column name being specified by `image_column`). The tokenization should be done before\\n        training in this case.\\n        \"\n    if shuffle:\n        indices = jax.random.permutation(rng, len(ds))\n        indices = np.asarray(indices)\n    else:\n        indices = np.arange(len(ds))\n    _block_size = len(ds) if not block_size else block_size\n    steps_per_block = _block_size // batch_size\n    num_examples = len(ds)\n    steps = num_examples // batch_size\n    num_splits = steps // steps_per_block + int(steps % steps_per_block > 0)\n    for idx in range(num_splits):\n        if not block_size:\n            _ds = ds\n        else:\n            start_idx = block_size * idx\n            end_idx = block_size * (idx + 1)\n            selected_indices = indices[start_idx:end_idx]\n            _ds = ds.select(selected_indices)\n            _ds = _ds.map(image_processing_fn, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=[image_column], load_from_cache_file=not data_args.overwrite_cache, features=features, keep_in_memory=keep_in_memory, fn_kwargs={'check_image': False}, desc=f'Running image processing on {split} dataset'.replace('  ', ' '))\n            _ds = _ds.with_format('numpy')\n        loader = data_loader(rng, _ds, batch_size=batch_size, shuffle=False)\n        for batch in loader:\n            yield batch",
            "def blockwise_data_loader(rng: jax.random.PRNGKey, ds: Dataset, block_size: int, batch_size: int, shuffle: bool=False, keep_in_memory: bool=False, split: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Wrap the simple `data_loader` in a block-wise way if `block_size` > 0, else it's the same as `data_loader`.\\n\\n        If `block_size` > 0, it requires `ds` to have a column that gives image paths in order to perform image\\n        processing (with the column name being specified by `image_column`). The tokenization should be done before\\n        training in this case.\\n        \"\n    if shuffle:\n        indices = jax.random.permutation(rng, len(ds))\n        indices = np.asarray(indices)\n    else:\n        indices = np.arange(len(ds))\n    _block_size = len(ds) if not block_size else block_size\n    steps_per_block = _block_size // batch_size\n    num_examples = len(ds)\n    steps = num_examples // batch_size\n    num_splits = steps // steps_per_block + int(steps % steps_per_block > 0)\n    for idx in range(num_splits):\n        if not block_size:\n            _ds = ds\n        else:\n            start_idx = block_size * idx\n            end_idx = block_size * (idx + 1)\n            selected_indices = indices[start_idx:end_idx]\n            _ds = ds.select(selected_indices)\n            _ds = _ds.map(image_processing_fn, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=[image_column], load_from_cache_file=not data_args.overwrite_cache, features=features, keep_in_memory=keep_in_memory, fn_kwargs={'check_image': False}, desc=f'Running image processing on {split} dataset'.replace('  ', ' '))\n            _ds = _ds.with_format('numpy')\n        loader = data_loader(rng, _ds, batch_size=batch_size, shuffle=False)\n        for batch in loader:\n            yield batch",
            "def blockwise_data_loader(rng: jax.random.PRNGKey, ds: Dataset, block_size: int, batch_size: int, shuffle: bool=False, keep_in_memory: bool=False, split: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Wrap the simple `data_loader` in a block-wise way if `block_size` > 0, else it's the same as `data_loader`.\\n\\n        If `block_size` > 0, it requires `ds` to have a column that gives image paths in order to perform image\\n        processing (with the column name being specified by `image_column`). The tokenization should be done before\\n        training in this case.\\n        \"\n    if shuffle:\n        indices = jax.random.permutation(rng, len(ds))\n        indices = np.asarray(indices)\n    else:\n        indices = np.arange(len(ds))\n    _block_size = len(ds) if not block_size else block_size\n    steps_per_block = _block_size // batch_size\n    num_examples = len(ds)\n    steps = num_examples // batch_size\n    num_splits = steps // steps_per_block + int(steps % steps_per_block > 0)\n    for idx in range(num_splits):\n        if not block_size:\n            _ds = ds\n        else:\n            start_idx = block_size * idx\n            end_idx = block_size * (idx + 1)\n            selected_indices = indices[start_idx:end_idx]\n            _ds = ds.select(selected_indices)\n            _ds = _ds.map(image_processing_fn, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=[image_column], load_from_cache_file=not data_args.overwrite_cache, features=features, keep_in_memory=keep_in_memory, fn_kwargs={'check_image': False}, desc=f'Running image processing on {split} dataset'.replace('  ', ' '))\n            _ds = _ds.with_format('numpy')\n        loader = data_loader(rng, _ds, batch_size=batch_size, shuffle=False)\n        for batch in loader:\n            yield batch"
        ]
    },
    {
        "func_name": "postprocess_text",
        "original": "def postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n    preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in preds]\n    labels = ['\\n'.join(nltk.sent_tokenize(label)) for label in labels]\n    return (preds, labels)",
        "mutated": [
            "def postprocess_text(preds, labels):\n    if False:\n        i = 10\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n    preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in preds]\n    labels = ['\\n'.join(nltk.sent_tokenize(label)) for label in labels]\n    return (preds, labels)",
            "def postprocess_text(preds, labels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n    preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in preds]\n    labels = ['\\n'.join(nltk.sent_tokenize(label)) for label in labels]\n    return (preds, labels)",
            "def postprocess_text(preds, labels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n    preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in preds]\n    labels = ['\\n'.join(nltk.sent_tokenize(label)) for label in labels]\n    return (preds, labels)",
            "def postprocess_text(preds, labels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n    preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in preds]\n    labels = ['\\n'.join(nltk.sent_tokenize(label)) for label in labels]\n    return (preds, labels)",
            "def postprocess_text(preds, labels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n    preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in preds]\n    labels = ['\\n'.join(nltk.sent_tokenize(label)) for label in labels]\n    return (preds, labels)"
        ]
    },
    {
        "func_name": "compute_metrics",
        "original": "def compute_metrics(preds, labels):\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    (decoded_preds, decoded_labels) = postprocess_text(decoded_preds, decoded_labels)\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    result = {key: value.mid.fmeasure * 100 for (key, value) in result.items()}\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result['gen_len'] = np.mean(prediction_lens)\n    result = {k: round(v, 6) for (k, v) in result.items()}\n    return (result, decoded_preds, decoded_labels)",
        "mutated": [
            "def compute_metrics(preds, labels):\n    if False:\n        i = 10\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    (decoded_preds, decoded_labels) = postprocess_text(decoded_preds, decoded_labels)\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    result = {key: value.mid.fmeasure * 100 for (key, value) in result.items()}\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result['gen_len'] = np.mean(prediction_lens)\n    result = {k: round(v, 6) for (k, v) in result.items()}\n    return (result, decoded_preds, decoded_labels)",
            "def compute_metrics(preds, labels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    (decoded_preds, decoded_labels) = postprocess_text(decoded_preds, decoded_labels)\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    result = {key: value.mid.fmeasure * 100 for (key, value) in result.items()}\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result['gen_len'] = np.mean(prediction_lens)\n    result = {k: round(v, 6) for (k, v) in result.items()}\n    return (result, decoded_preds, decoded_labels)",
            "def compute_metrics(preds, labels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    (decoded_preds, decoded_labels) = postprocess_text(decoded_preds, decoded_labels)\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    result = {key: value.mid.fmeasure * 100 for (key, value) in result.items()}\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result['gen_len'] = np.mean(prediction_lens)\n    result = {k: round(v, 6) for (k, v) in result.items()}\n    return (result, decoded_preds, decoded_labels)",
            "def compute_metrics(preds, labels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    (decoded_preds, decoded_labels) = postprocess_text(decoded_preds, decoded_labels)\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    result = {key: value.mid.fmeasure * 100 for (key, value) in result.items()}\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result['gen_len'] = np.mean(prediction_lens)\n    result = {k: round(v, 6) for (k, v) in result.items()}\n    return (result, decoded_preds, decoded_labels)",
            "def compute_metrics(preds, labels):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    (decoded_preds, decoded_labels) = postprocess_text(decoded_preds, decoded_labels)\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    result = {key: value.mid.fmeasure * 100 for (key, value) in result.items()}\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result['gen_len'] = np.mean(prediction_lens)\n    result = {k: round(v, 6) for (k, v) in result.items()}\n    return (result, decoded_preds, decoded_labels)"
        ]
    },
    {
        "func_name": "decay_mask_fn",
        "original": "def decay_mask_fn(params):\n    flat_params = traverse_util.flatten_dict(params)\n    layer_norm_candidates = ['layernorm', 'layer_norm', 'ln']\n    layer_norm_named_params = {layer[-2:] for layer_norm_name in layer_norm_candidates for layer in flat_params.keys() if layer_norm_name in ''.join(layer).lower()}\n    flat_mask = {path: path[-1] != 'bias' and path[-2:] not in layer_norm_named_params for path in flat_params}\n    return traverse_util.unflatten_dict(flat_mask)",
        "mutated": [
            "def decay_mask_fn(params):\n    if False:\n        i = 10\n    flat_params = traverse_util.flatten_dict(params)\n    layer_norm_candidates = ['layernorm', 'layer_norm', 'ln']\n    layer_norm_named_params = {layer[-2:] for layer_norm_name in layer_norm_candidates for layer in flat_params.keys() if layer_norm_name in ''.join(layer).lower()}\n    flat_mask = {path: path[-1] != 'bias' and path[-2:] not in layer_norm_named_params for path in flat_params}\n    return traverse_util.unflatten_dict(flat_mask)",
            "def decay_mask_fn(params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    flat_params = traverse_util.flatten_dict(params)\n    layer_norm_candidates = ['layernorm', 'layer_norm', 'ln']\n    layer_norm_named_params = {layer[-2:] for layer_norm_name in layer_norm_candidates for layer in flat_params.keys() if layer_norm_name in ''.join(layer).lower()}\n    flat_mask = {path: path[-1] != 'bias' and path[-2:] not in layer_norm_named_params for path in flat_params}\n    return traverse_util.unflatten_dict(flat_mask)",
            "def decay_mask_fn(params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    flat_params = traverse_util.flatten_dict(params)\n    layer_norm_candidates = ['layernorm', 'layer_norm', 'ln']\n    layer_norm_named_params = {layer[-2:] for layer_norm_name in layer_norm_candidates for layer in flat_params.keys() if layer_norm_name in ''.join(layer).lower()}\n    flat_mask = {path: path[-1] != 'bias' and path[-2:] not in layer_norm_named_params for path in flat_params}\n    return traverse_util.unflatten_dict(flat_mask)",
            "def decay_mask_fn(params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    flat_params = traverse_util.flatten_dict(params)\n    layer_norm_candidates = ['layernorm', 'layer_norm', 'ln']\n    layer_norm_named_params = {layer[-2:] for layer_norm_name in layer_norm_candidates for layer in flat_params.keys() if layer_norm_name in ''.join(layer).lower()}\n    flat_mask = {path: path[-1] != 'bias' and path[-2:] not in layer_norm_named_params for path in flat_params}\n    return traverse_util.unflatten_dict(flat_mask)",
            "def decay_mask_fn(params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    flat_params = traverse_util.flatten_dict(params)\n    layer_norm_candidates = ['layernorm', 'layer_norm', 'ln']\n    layer_norm_named_params = {layer[-2:] for layer_norm_name in layer_norm_candidates for layer in flat_params.keys() if layer_norm_name in ''.join(layer).lower()}\n    flat_mask = {path: path[-1] != 'bias' and path[-2:] not in layer_norm_named_params for path in flat_params}\n    return traverse_util.unflatten_dict(flat_mask)"
        ]
    },
    {
        "func_name": "loss_fn",
        "original": "def loss_fn(logits, labels, padding_mask, label_smoothing_factor=0.0):\n    \"\"\"\n        The label smoothing implementation is adapted from Flax's official example:\n        https://github.com/google/flax/blob/87a211135c6a377c8f29048a1cac3840e38b9da4/examples/wmt/train.py#L104\n        \"\"\"\n    vocab_size = logits.shape[-1]\n    confidence = 1.0 - label_smoothing_factor\n    low_confidence = (1.0 - confidence) / (vocab_size - 1)\n    normalizing_constant = -(confidence * jnp.log(confidence) + (vocab_size - 1) * low_confidence * jnp.log(low_confidence + 1e-20))\n    soft_labels = onehot(labels, vocab_size, on_value=confidence, off_value=low_confidence)\n    loss = optax.softmax_cross_entropy(logits, soft_labels)\n    loss = loss - normalizing_constant\n    loss = loss * padding_mask\n    loss = loss.sum()\n    num_labels = padding_mask.sum()\n    return (loss, num_labels)",
        "mutated": [
            "def loss_fn(logits, labels, padding_mask, label_smoothing_factor=0.0):\n    if False:\n        i = 10\n    \"\\n        The label smoothing implementation is adapted from Flax's official example:\\n        https://github.com/google/flax/blob/87a211135c6a377c8f29048a1cac3840e38b9da4/examples/wmt/train.py#L104\\n        \"\n    vocab_size = logits.shape[-1]\n    confidence = 1.0 - label_smoothing_factor\n    low_confidence = (1.0 - confidence) / (vocab_size - 1)\n    normalizing_constant = -(confidence * jnp.log(confidence) + (vocab_size - 1) * low_confidence * jnp.log(low_confidence + 1e-20))\n    soft_labels = onehot(labels, vocab_size, on_value=confidence, off_value=low_confidence)\n    loss = optax.softmax_cross_entropy(logits, soft_labels)\n    loss = loss - normalizing_constant\n    loss = loss * padding_mask\n    loss = loss.sum()\n    num_labels = padding_mask.sum()\n    return (loss, num_labels)",
            "def loss_fn(logits, labels, padding_mask, label_smoothing_factor=0.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        The label smoothing implementation is adapted from Flax's official example:\\n        https://github.com/google/flax/blob/87a211135c6a377c8f29048a1cac3840e38b9da4/examples/wmt/train.py#L104\\n        \"\n    vocab_size = logits.shape[-1]\n    confidence = 1.0 - label_smoothing_factor\n    low_confidence = (1.0 - confidence) / (vocab_size - 1)\n    normalizing_constant = -(confidence * jnp.log(confidence) + (vocab_size - 1) * low_confidence * jnp.log(low_confidence + 1e-20))\n    soft_labels = onehot(labels, vocab_size, on_value=confidence, off_value=low_confidence)\n    loss = optax.softmax_cross_entropy(logits, soft_labels)\n    loss = loss - normalizing_constant\n    loss = loss * padding_mask\n    loss = loss.sum()\n    num_labels = padding_mask.sum()\n    return (loss, num_labels)",
            "def loss_fn(logits, labels, padding_mask, label_smoothing_factor=0.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        The label smoothing implementation is adapted from Flax's official example:\\n        https://github.com/google/flax/blob/87a211135c6a377c8f29048a1cac3840e38b9da4/examples/wmt/train.py#L104\\n        \"\n    vocab_size = logits.shape[-1]\n    confidence = 1.0 - label_smoothing_factor\n    low_confidence = (1.0 - confidence) / (vocab_size - 1)\n    normalizing_constant = -(confidence * jnp.log(confidence) + (vocab_size - 1) * low_confidence * jnp.log(low_confidence + 1e-20))\n    soft_labels = onehot(labels, vocab_size, on_value=confidence, off_value=low_confidence)\n    loss = optax.softmax_cross_entropy(logits, soft_labels)\n    loss = loss - normalizing_constant\n    loss = loss * padding_mask\n    loss = loss.sum()\n    num_labels = padding_mask.sum()\n    return (loss, num_labels)",
            "def loss_fn(logits, labels, padding_mask, label_smoothing_factor=0.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        The label smoothing implementation is adapted from Flax's official example:\\n        https://github.com/google/flax/blob/87a211135c6a377c8f29048a1cac3840e38b9da4/examples/wmt/train.py#L104\\n        \"\n    vocab_size = logits.shape[-1]\n    confidence = 1.0 - label_smoothing_factor\n    low_confidence = (1.0 - confidence) / (vocab_size - 1)\n    normalizing_constant = -(confidence * jnp.log(confidence) + (vocab_size - 1) * low_confidence * jnp.log(low_confidence + 1e-20))\n    soft_labels = onehot(labels, vocab_size, on_value=confidence, off_value=low_confidence)\n    loss = optax.softmax_cross_entropy(logits, soft_labels)\n    loss = loss - normalizing_constant\n    loss = loss * padding_mask\n    loss = loss.sum()\n    num_labels = padding_mask.sum()\n    return (loss, num_labels)",
            "def loss_fn(logits, labels, padding_mask, label_smoothing_factor=0.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        The label smoothing implementation is adapted from Flax's official example:\\n        https://github.com/google/flax/blob/87a211135c6a377c8f29048a1cac3840e38b9da4/examples/wmt/train.py#L104\\n        \"\n    vocab_size = logits.shape[-1]\n    confidence = 1.0 - label_smoothing_factor\n    low_confidence = (1.0 - confidence) / (vocab_size - 1)\n    normalizing_constant = -(confidence * jnp.log(confidence) + (vocab_size - 1) * low_confidence * jnp.log(low_confidence + 1e-20))\n    soft_labels = onehot(labels, vocab_size, on_value=confidence, off_value=low_confidence)\n    loss = optax.softmax_cross_entropy(logits, soft_labels)\n    loss = loss - normalizing_constant\n    loss = loss * padding_mask\n    loss = loss.sum()\n    num_labels = padding_mask.sum()\n    return (loss, num_labels)"
        ]
    },
    {
        "func_name": "compute_loss",
        "original": "def compute_loss(params):\n    labels = batch.pop('labels')\n    logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n    (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n    return (loss, num_labels)",
        "mutated": [
            "def compute_loss(params):\n    if False:\n        i = 10\n    labels = batch.pop('labels')\n    logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n    (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n    return (loss, num_labels)",
            "def compute_loss(params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    labels = batch.pop('labels')\n    logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n    (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n    return (loss, num_labels)",
            "def compute_loss(params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    labels = batch.pop('labels')\n    logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n    (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n    return (loss, num_labels)",
            "def compute_loss(params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    labels = batch.pop('labels')\n    logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n    (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n    return (loss, num_labels)",
            "def compute_loss(params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    labels = batch.pop('labels')\n    logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n    (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n    return (loss, num_labels)"
        ]
    },
    {
        "func_name": "train_step",
        "original": "def train_step(state, batch, label_smoothing_factor=0.0):\n    (dropout_rng, new_dropout_rng) = jax.random.split(state.dropout_rng)\n\n    def compute_loss(params):\n        labels = batch.pop('labels')\n        logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n        (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n        return (loss, num_labels)\n    grad_fn = jax.value_and_grad(compute_loss, has_aux=True)\n    ((loss, num_labels), grad) = grad_fn(state.params)\n    num_labels = jax.lax.psum(num_labels, 'batch')\n    loss = jax.lax.psum(loss, 'batch')\n    loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n    grad = jax.lax.psum(grad, 'batch')\n    grad = jax.tree_util.tree_map(lambda x: x / num_labels, grad)\n    new_state = state.apply_gradients(grads=grad, dropout_rng=new_dropout_rng)\n    metrics = {'loss': loss, 'learning_rate': linear_decay_lr_schedule_fn(state.step)}\n    return (new_state, metrics)",
        "mutated": [
            "def train_step(state, batch, label_smoothing_factor=0.0):\n    if False:\n        i = 10\n    (dropout_rng, new_dropout_rng) = jax.random.split(state.dropout_rng)\n\n    def compute_loss(params):\n        labels = batch.pop('labels')\n        logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n        (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n        return (loss, num_labels)\n    grad_fn = jax.value_and_grad(compute_loss, has_aux=True)\n    ((loss, num_labels), grad) = grad_fn(state.params)\n    num_labels = jax.lax.psum(num_labels, 'batch')\n    loss = jax.lax.psum(loss, 'batch')\n    loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n    grad = jax.lax.psum(grad, 'batch')\n    grad = jax.tree_util.tree_map(lambda x: x / num_labels, grad)\n    new_state = state.apply_gradients(grads=grad, dropout_rng=new_dropout_rng)\n    metrics = {'loss': loss, 'learning_rate': linear_decay_lr_schedule_fn(state.step)}\n    return (new_state, metrics)",
            "def train_step(state, batch, label_smoothing_factor=0.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (dropout_rng, new_dropout_rng) = jax.random.split(state.dropout_rng)\n\n    def compute_loss(params):\n        labels = batch.pop('labels')\n        logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n        (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n        return (loss, num_labels)\n    grad_fn = jax.value_and_grad(compute_loss, has_aux=True)\n    ((loss, num_labels), grad) = grad_fn(state.params)\n    num_labels = jax.lax.psum(num_labels, 'batch')\n    loss = jax.lax.psum(loss, 'batch')\n    loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n    grad = jax.lax.psum(grad, 'batch')\n    grad = jax.tree_util.tree_map(lambda x: x / num_labels, grad)\n    new_state = state.apply_gradients(grads=grad, dropout_rng=new_dropout_rng)\n    metrics = {'loss': loss, 'learning_rate': linear_decay_lr_schedule_fn(state.step)}\n    return (new_state, metrics)",
            "def train_step(state, batch, label_smoothing_factor=0.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (dropout_rng, new_dropout_rng) = jax.random.split(state.dropout_rng)\n\n    def compute_loss(params):\n        labels = batch.pop('labels')\n        logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n        (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n        return (loss, num_labels)\n    grad_fn = jax.value_and_grad(compute_loss, has_aux=True)\n    ((loss, num_labels), grad) = grad_fn(state.params)\n    num_labels = jax.lax.psum(num_labels, 'batch')\n    loss = jax.lax.psum(loss, 'batch')\n    loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n    grad = jax.lax.psum(grad, 'batch')\n    grad = jax.tree_util.tree_map(lambda x: x / num_labels, grad)\n    new_state = state.apply_gradients(grads=grad, dropout_rng=new_dropout_rng)\n    metrics = {'loss': loss, 'learning_rate': linear_decay_lr_schedule_fn(state.step)}\n    return (new_state, metrics)",
            "def train_step(state, batch, label_smoothing_factor=0.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (dropout_rng, new_dropout_rng) = jax.random.split(state.dropout_rng)\n\n    def compute_loss(params):\n        labels = batch.pop('labels')\n        logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n        (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n        return (loss, num_labels)\n    grad_fn = jax.value_and_grad(compute_loss, has_aux=True)\n    ((loss, num_labels), grad) = grad_fn(state.params)\n    num_labels = jax.lax.psum(num_labels, 'batch')\n    loss = jax.lax.psum(loss, 'batch')\n    loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n    grad = jax.lax.psum(grad, 'batch')\n    grad = jax.tree_util.tree_map(lambda x: x / num_labels, grad)\n    new_state = state.apply_gradients(grads=grad, dropout_rng=new_dropout_rng)\n    metrics = {'loss': loss, 'learning_rate': linear_decay_lr_schedule_fn(state.step)}\n    return (new_state, metrics)",
            "def train_step(state, batch, label_smoothing_factor=0.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (dropout_rng, new_dropout_rng) = jax.random.split(state.dropout_rng)\n\n    def compute_loss(params):\n        labels = batch.pop('labels')\n        logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n        (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n        return (loss, num_labels)\n    grad_fn = jax.value_and_grad(compute_loss, has_aux=True)\n    ((loss, num_labels), grad) = grad_fn(state.params)\n    num_labels = jax.lax.psum(num_labels, 'batch')\n    loss = jax.lax.psum(loss, 'batch')\n    loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n    grad = jax.lax.psum(grad, 'batch')\n    grad = jax.tree_util.tree_map(lambda x: x / num_labels, grad)\n    new_state = state.apply_gradients(grads=grad, dropout_rng=new_dropout_rng)\n    metrics = {'loss': loss, 'learning_rate': linear_decay_lr_schedule_fn(state.step)}\n    return (new_state, metrics)"
        ]
    },
    {
        "func_name": "eval_step",
        "original": "def eval_step(params, batch, label_smoothing_factor=0.0):\n    labels = batch.pop('labels')\n    logits = model(**batch, params=params, train=False)[0]\n    (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n    num_labels = jax.lax.psum(num_labels, 'batch')\n    loss = jax.lax.psum(loss, 'batch')\n    loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n    metrics = {'loss': loss}\n    return metrics",
        "mutated": [
            "def eval_step(params, batch, label_smoothing_factor=0.0):\n    if False:\n        i = 10\n    labels = batch.pop('labels')\n    logits = model(**batch, params=params, train=False)[0]\n    (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n    num_labels = jax.lax.psum(num_labels, 'batch')\n    loss = jax.lax.psum(loss, 'batch')\n    loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n    metrics = {'loss': loss}\n    return metrics",
            "def eval_step(params, batch, label_smoothing_factor=0.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    labels = batch.pop('labels')\n    logits = model(**batch, params=params, train=False)[0]\n    (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n    num_labels = jax.lax.psum(num_labels, 'batch')\n    loss = jax.lax.psum(loss, 'batch')\n    loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n    metrics = {'loss': loss}\n    return metrics",
            "def eval_step(params, batch, label_smoothing_factor=0.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    labels = batch.pop('labels')\n    logits = model(**batch, params=params, train=False)[0]\n    (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n    num_labels = jax.lax.psum(num_labels, 'batch')\n    loss = jax.lax.psum(loss, 'batch')\n    loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n    metrics = {'loss': loss}\n    return metrics",
            "def eval_step(params, batch, label_smoothing_factor=0.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    labels = batch.pop('labels')\n    logits = model(**batch, params=params, train=False)[0]\n    (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n    num_labels = jax.lax.psum(num_labels, 'batch')\n    loss = jax.lax.psum(loss, 'batch')\n    loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n    metrics = {'loss': loss}\n    return metrics",
            "def eval_step(params, batch, label_smoothing_factor=0.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    labels = batch.pop('labels')\n    logits = model(**batch, params=params, train=False)[0]\n    (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n    num_labels = jax.lax.psum(num_labels, 'batch')\n    loss = jax.lax.psum(loss, 'batch')\n    loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n    metrics = {'loss': loss}\n    return metrics"
        ]
    },
    {
        "func_name": "generate_step",
        "original": "def generate_step(params, batch):\n    model.params = params\n    output_ids = model.generate(batch['pixel_values'], **gen_kwargs)\n    return output_ids.sequences",
        "mutated": [
            "def generate_step(params, batch):\n    if False:\n        i = 10\n    model.params = params\n    output_ids = model.generate(batch['pixel_values'], **gen_kwargs)\n    return output_ids.sequences",
            "def generate_step(params, batch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    model.params = params\n    output_ids = model.generate(batch['pixel_values'], **gen_kwargs)\n    return output_ids.sequences",
            "def generate_step(params, batch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    model.params = params\n    output_ids = model.generate(batch['pixel_values'], **gen_kwargs)\n    return output_ids.sequences",
            "def generate_step(params, batch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    model.params = params\n    output_ids = model.generate(batch['pixel_values'], **gen_kwargs)\n    return output_ids.sequences",
            "def generate_step(params, batch):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    model.params = params\n    output_ids = model.generate(batch['pixel_values'], **gen_kwargs)\n    return output_ids.sequences"
        ]
    },
    {
        "func_name": "save_ckpt",
        "original": "def save_ckpt(ckpt_dir: str, commit_msg: str=''):\n    \"\"\"save checkpoints and push to Hugging Face Hub if specified\"\"\"\n    if jax.process_index() == 0:\n        params = jax.device_get(jax.tree_util.tree_map(lambda x: x[0], state.params))\n        model.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir), params=params)\n        tokenizer.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir))\n        if training_args.push_to_hub:\n            repo.push_to_hub(commit_message=commit_msg, blocking=False)",
        "mutated": [
            "def save_ckpt(ckpt_dir: str, commit_msg: str=''):\n    if False:\n        i = 10\n    'save checkpoints and push to Hugging Face Hub if specified'\n    if jax.process_index() == 0:\n        params = jax.device_get(jax.tree_util.tree_map(lambda x: x[0], state.params))\n        model.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir), params=params)\n        tokenizer.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir))\n        if training_args.push_to_hub:\n            repo.push_to_hub(commit_message=commit_msg, blocking=False)",
            "def save_ckpt(ckpt_dir: str, commit_msg: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'save checkpoints and push to Hugging Face Hub if specified'\n    if jax.process_index() == 0:\n        params = jax.device_get(jax.tree_util.tree_map(lambda x: x[0], state.params))\n        model.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir), params=params)\n        tokenizer.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir))\n        if training_args.push_to_hub:\n            repo.push_to_hub(commit_message=commit_msg, blocking=False)",
            "def save_ckpt(ckpt_dir: str, commit_msg: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'save checkpoints and push to Hugging Face Hub if specified'\n    if jax.process_index() == 0:\n        params = jax.device_get(jax.tree_util.tree_map(lambda x: x[0], state.params))\n        model.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir), params=params)\n        tokenizer.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir))\n        if training_args.push_to_hub:\n            repo.push_to_hub(commit_message=commit_msg, blocking=False)",
            "def save_ckpt(ckpt_dir: str, commit_msg: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'save checkpoints and push to Hugging Face Hub if specified'\n    if jax.process_index() == 0:\n        params = jax.device_get(jax.tree_util.tree_map(lambda x: x[0], state.params))\n        model.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir), params=params)\n        tokenizer.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir))\n        if training_args.push_to_hub:\n            repo.push_to_hub(commit_message=commit_msg, blocking=False)",
            "def save_ckpt(ckpt_dir: str, commit_msg: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'save checkpoints and push to Hugging Face Hub if specified'\n    if jax.process_index() == 0:\n        params = jax.device_get(jax.tree_util.tree_map(lambda x: x[0], state.params))\n        model.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir), params=params)\n        tokenizer.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir))\n        if training_args.push_to_hub:\n            repo.push_to_hub(commit_message=commit_msg, blocking=False)"
        ]
    },
    {
        "func_name": "evaluation_loop",
        "original": "def evaluation_loop(rng: jax.random.PRNGKey, dataset: Dataset, metric_key_prefix: str='eval', ckpt_dir: str='', is_prediction=False):\n    logger.info(f\"*** {('Predict' if is_prediction else 'Evaluate')} ***\")\n    metrics = []\n    preds = []\n    labels = []\n    batches = blockwise_data_loader(rng, dataset, block_size=training_args.block_size, batch_size=eval_batch_size, keep_in_memory=False, shuffle=False, split='prediction' if is_prediction else 'validation')\n    steps = len(dataset) // eval_batch_size\n    for _ in tqdm(range(steps), desc=f\"{('Predicting' if is_prediction else 'Evaluating')}...\", position=2, leave=False):\n        batch = next(batches)\n        _labels = batch.get('labels', None)\n        if not is_prediction and _labels is None:\n            raise ValueError('Evaluation requires the validation dataset to have `labels`')\n        if _labels is not None:\n            _metrics = p_eval_step(state.params, batch)\n            metrics.append(_metrics)\n        if data_args.predict_with_generate:\n            generated_ids = p_generate_step(state.params, batch)\n            preds.extend(jax.device_get(generated_ids.reshape(-1, gen_kwargs['max_length'])))\n            if _labels is not None:\n                labels.extend(jax.device_get(_labels.reshape(-1, _labels.shape[-1])))\n    if metrics:\n        metrics = get_metrics(metrics)\n        metrics = jax.tree_util.tree_map(jnp.mean, metrics)\n    generations = []\n    rouge_desc = ''\n    if data_args.predict_with_generate:\n        if labels:\n            (rouge_metrics, decoded_preds, decoded_labels) = compute_metrics(preds, labels)\n            metrics.update(rouge_metrics)\n            rouge_desc = ' '.join([f\"{('Predict' if is_prediction else 'Eval')} {key}: {value} |\" for (key, value) in rouge_metrics.items()])\n            for (pred, label) in zip(decoded_preds, decoded_labels):\n                pred = pred.replace('\\n', ' ')\n                label = label.replace('\\n', ' ')\n                generations.append({'label': label, 'pred': pred})\n        else:\n            decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n            decoded_preds = [pred.strip() for pred in decoded_preds]\n            decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in decoded_preds]\n            for pred in decoded_preds:\n                pred = pred.replace('\\n', ' ')\n                generations.append({'pred': pred})\n    if metrics:\n        desc = f\"{('Predict' if is_prediction else 'Eval')} Loss: {metrics['loss']} | {rouge_desc})\"\n        if training_args.do_train and (not is_prediction):\n            desc = f'Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | ' + desc\n            epochs.write(desc)\n            epochs.desc = desc\n        logger.info(desc)\n    if jax.process_index() == 0:\n        if not os.path.isdir(os.path.join(training_args.output_dir, ckpt_dir)):\n            os.makedirs(os.path.join(training_args.output_dir, ckpt_dir), exist_ok=True)\n        if metrics:\n            if has_tensorboard and training_args.do_train:\n                write_metric(summary_writer, metrics, train_time=None, step=cur_step, metric_key_prefix=metric_key_prefix)\n            metrics = {f'{metric_key_prefix}_{metric_name}': round(value.item(), 6) for (metric_name, value) in metrics.items()}\n            _path = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_results.json')\n            with open(_path, 'w') as f:\n                json.dump(metrics, f, indent=4, sort_keys=True)\n            with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                fp.write(desc + '\\n')\n        if generations:\n            output_file = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_generation.json')\n            with open(output_file, 'w', encoding='UTF-8') as fp:\n                json.dump(generations, fp, ensure_ascii=False, indent=4)",
        "mutated": [
            "def evaluation_loop(rng: jax.random.PRNGKey, dataset: Dataset, metric_key_prefix: str='eval', ckpt_dir: str='', is_prediction=False):\n    if False:\n        i = 10\n    logger.info(f\"*** {('Predict' if is_prediction else 'Evaluate')} ***\")\n    metrics = []\n    preds = []\n    labels = []\n    batches = blockwise_data_loader(rng, dataset, block_size=training_args.block_size, batch_size=eval_batch_size, keep_in_memory=False, shuffle=False, split='prediction' if is_prediction else 'validation')\n    steps = len(dataset) // eval_batch_size\n    for _ in tqdm(range(steps), desc=f\"{('Predicting' if is_prediction else 'Evaluating')}...\", position=2, leave=False):\n        batch = next(batches)\n        _labels = batch.get('labels', None)\n        if not is_prediction and _labels is None:\n            raise ValueError('Evaluation requires the validation dataset to have `labels`')\n        if _labels is not None:\n            _metrics = p_eval_step(state.params, batch)\n            metrics.append(_metrics)\n        if data_args.predict_with_generate:\n            generated_ids = p_generate_step(state.params, batch)\n            preds.extend(jax.device_get(generated_ids.reshape(-1, gen_kwargs['max_length'])))\n            if _labels is not None:\n                labels.extend(jax.device_get(_labels.reshape(-1, _labels.shape[-1])))\n    if metrics:\n        metrics = get_metrics(metrics)\n        metrics = jax.tree_util.tree_map(jnp.mean, metrics)\n    generations = []\n    rouge_desc = ''\n    if data_args.predict_with_generate:\n        if labels:\n            (rouge_metrics, decoded_preds, decoded_labels) = compute_metrics(preds, labels)\n            metrics.update(rouge_metrics)\n            rouge_desc = ' '.join([f\"{('Predict' if is_prediction else 'Eval')} {key}: {value} |\" for (key, value) in rouge_metrics.items()])\n            for (pred, label) in zip(decoded_preds, decoded_labels):\n                pred = pred.replace('\\n', ' ')\n                label = label.replace('\\n', ' ')\n                generations.append({'label': label, 'pred': pred})\n        else:\n            decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n            decoded_preds = [pred.strip() for pred in decoded_preds]\n            decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in decoded_preds]\n            for pred in decoded_preds:\n                pred = pred.replace('\\n', ' ')\n                generations.append({'pred': pred})\n    if metrics:\n        desc = f\"{('Predict' if is_prediction else 'Eval')} Loss: {metrics['loss']} | {rouge_desc})\"\n        if training_args.do_train and (not is_prediction):\n            desc = f'Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | ' + desc\n            epochs.write(desc)\n            epochs.desc = desc\n        logger.info(desc)\n    if jax.process_index() == 0:\n        if not os.path.isdir(os.path.join(training_args.output_dir, ckpt_dir)):\n            os.makedirs(os.path.join(training_args.output_dir, ckpt_dir), exist_ok=True)\n        if metrics:\n            if has_tensorboard and training_args.do_train:\n                write_metric(summary_writer, metrics, train_time=None, step=cur_step, metric_key_prefix=metric_key_prefix)\n            metrics = {f'{metric_key_prefix}_{metric_name}': round(value.item(), 6) for (metric_name, value) in metrics.items()}\n            _path = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_results.json')\n            with open(_path, 'w') as f:\n                json.dump(metrics, f, indent=4, sort_keys=True)\n            with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                fp.write(desc + '\\n')\n        if generations:\n            output_file = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_generation.json')\n            with open(output_file, 'w', encoding='UTF-8') as fp:\n                json.dump(generations, fp, ensure_ascii=False, indent=4)",
            "def evaluation_loop(rng: jax.random.PRNGKey, dataset: Dataset, metric_key_prefix: str='eval', ckpt_dir: str='', is_prediction=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    logger.info(f\"*** {('Predict' if is_prediction else 'Evaluate')} ***\")\n    metrics = []\n    preds = []\n    labels = []\n    batches = blockwise_data_loader(rng, dataset, block_size=training_args.block_size, batch_size=eval_batch_size, keep_in_memory=False, shuffle=False, split='prediction' if is_prediction else 'validation')\n    steps = len(dataset) // eval_batch_size\n    for _ in tqdm(range(steps), desc=f\"{('Predicting' if is_prediction else 'Evaluating')}...\", position=2, leave=False):\n        batch = next(batches)\n        _labels = batch.get('labels', None)\n        if not is_prediction and _labels is None:\n            raise ValueError('Evaluation requires the validation dataset to have `labels`')\n        if _labels is not None:\n            _metrics = p_eval_step(state.params, batch)\n            metrics.append(_metrics)\n        if data_args.predict_with_generate:\n            generated_ids = p_generate_step(state.params, batch)\n            preds.extend(jax.device_get(generated_ids.reshape(-1, gen_kwargs['max_length'])))\n            if _labels is not None:\n                labels.extend(jax.device_get(_labels.reshape(-1, _labels.shape[-1])))\n    if metrics:\n        metrics = get_metrics(metrics)\n        metrics = jax.tree_util.tree_map(jnp.mean, metrics)\n    generations = []\n    rouge_desc = ''\n    if data_args.predict_with_generate:\n        if labels:\n            (rouge_metrics, decoded_preds, decoded_labels) = compute_metrics(preds, labels)\n            metrics.update(rouge_metrics)\n            rouge_desc = ' '.join([f\"{('Predict' if is_prediction else 'Eval')} {key}: {value} |\" for (key, value) in rouge_metrics.items()])\n            for (pred, label) in zip(decoded_preds, decoded_labels):\n                pred = pred.replace('\\n', ' ')\n                label = label.replace('\\n', ' ')\n                generations.append({'label': label, 'pred': pred})\n        else:\n            decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n            decoded_preds = [pred.strip() for pred in decoded_preds]\n            decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in decoded_preds]\n            for pred in decoded_preds:\n                pred = pred.replace('\\n', ' ')\n                generations.append({'pred': pred})\n    if metrics:\n        desc = f\"{('Predict' if is_prediction else 'Eval')} Loss: {metrics['loss']} | {rouge_desc})\"\n        if training_args.do_train and (not is_prediction):\n            desc = f'Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | ' + desc\n            epochs.write(desc)\n            epochs.desc = desc\n        logger.info(desc)\n    if jax.process_index() == 0:\n        if not os.path.isdir(os.path.join(training_args.output_dir, ckpt_dir)):\n            os.makedirs(os.path.join(training_args.output_dir, ckpt_dir), exist_ok=True)\n        if metrics:\n            if has_tensorboard and training_args.do_train:\n                write_metric(summary_writer, metrics, train_time=None, step=cur_step, metric_key_prefix=metric_key_prefix)\n            metrics = {f'{metric_key_prefix}_{metric_name}': round(value.item(), 6) for (metric_name, value) in metrics.items()}\n            _path = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_results.json')\n            with open(_path, 'w') as f:\n                json.dump(metrics, f, indent=4, sort_keys=True)\n            with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                fp.write(desc + '\\n')\n        if generations:\n            output_file = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_generation.json')\n            with open(output_file, 'w', encoding='UTF-8') as fp:\n                json.dump(generations, fp, ensure_ascii=False, indent=4)",
            "def evaluation_loop(rng: jax.random.PRNGKey, dataset: Dataset, metric_key_prefix: str='eval', ckpt_dir: str='', is_prediction=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    logger.info(f\"*** {('Predict' if is_prediction else 'Evaluate')} ***\")\n    metrics = []\n    preds = []\n    labels = []\n    batches = blockwise_data_loader(rng, dataset, block_size=training_args.block_size, batch_size=eval_batch_size, keep_in_memory=False, shuffle=False, split='prediction' if is_prediction else 'validation')\n    steps = len(dataset) // eval_batch_size\n    for _ in tqdm(range(steps), desc=f\"{('Predicting' if is_prediction else 'Evaluating')}...\", position=2, leave=False):\n        batch = next(batches)\n        _labels = batch.get('labels', None)\n        if not is_prediction and _labels is None:\n            raise ValueError('Evaluation requires the validation dataset to have `labels`')\n        if _labels is not None:\n            _metrics = p_eval_step(state.params, batch)\n            metrics.append(_metrics)\n        if data_args.predict_with_generate:\n            generated_ids = p_generate_step(state.params, batch)\n            preds.extend(jax.device_get(generated_ids.reshape(-1, gen_kwargs['max_length'])))\n            if _labels is not None:\n                labels.extend(jax.device_get(_labels.reshape(-1, _labels.shape[-1])))\n    if metrics:\n        metrics = get_metrics(metrics)\n        metrics = jax.tree_util.tree_map(jnp.mean, metrics)\n    generations = []\n    rouge_desc = ''\n    if data_args.predict_with_generate:\n        if labels:\n            (rouge_metrics, decoded_preds, decoded_labels) = compute_metrics(preds, labels)\n            metrics.update(rouge_metrics)\n            rouge_desc = ' '.join([f\"{('Predict' if is_prediction else 'Eval')} {key}: {value} |\" for (key, value) in rouge_metrics.items()])\n            for (pred, label) in zip(decoded_preds, decoded_labels):\n                pred = pred.replace('\\n', ' ')\n                label = label.replace('\\n', ' ')\n                generations.append({'label': label, 'pred': pred})\n        else:\n            decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n            decoded_preds = [pred.strip() for pred in decoded_preds]\n            decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in decoded_preds]\n            for pred in decoded_preds:\n                pred = pred.replace('\\n', ' ')\n                generations.append({'pred': pred})\n    if metrics:\n        desc = f\"{('Predict' if is_prediction else 'Eval')} Loss: {metrics['loss']} | {rouge_desc})\"\n        if training_args.do_train and (not is_prediction):\n            desc = f'Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | ' + desc\n            epochs.write(desc)\n            epochs.desc = desc\n        logger.info(desc)\n    if jax.process_index() == 0:\n        if not os.path.isdir(os.path.join(training_args.output_dir, ckpt_dir)):\n            os.makedirs(os.path.join(training_args.output_dir, ckpt_dir), exist_ok=True)\n        if metrics:\n            if has_tensorboard and training_args.do_train:\n                write_metric(summary_writer, metrics, train_time=None, step=cur_step, metric_key_prefix=metric_key_prefix)\n            metrics = {f'{metric_key_prefix}_{metric_name}': round(value.item(), 6) for (metric_name, value) in metrics.items()}\n            _path = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_results.json')\n            with open(_path, 'w') as f:\n                json.dump(metrics, f, indent=4, sort_keys=True)\n            with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                fp.write(desc + '\\n')\n        if generations:\n            output_file = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_generation.json')\n            with open(output_file, 'w', encoding='UTF-8') as fp:\n                json.dump(generations, fp, ensure_ascii=False, indent=4)",
            "def evaluation_loop(rng: jax.random.PRNGKey, dataset: Dataset, metric_key_prefix: str='eval', ckpt_dir: str='', is_prediction=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    logger.info(f\"*** {('Predict' if is_prediction else 'Evaluate')} ***\")\n    metrics = []\n    preds = []\n    labels = []\n    batches = blockwise_data_loader(rng, dataset, block_size=training_args.block_size, batch_size=eval_batch_size, keep_in_memory=False, shuffle=False, split='prediction' if is_prediction else 'validation')\n    steps = len(dataset) // eval_batch_size\n    for _ in tqdm(range(steps), desc=f\"{('Predicting' if is_prediction else 'Evaluating')}...\", position=2, leave=False):\n        batch = next(batches)\n        _labels = batch.get('labels', None)\n        if not is_prediction and _labels is None:\n            raise ValueError('Evaluation requires the validation dataset to have `labels`')\n        if _labels is not None:\n            _metrics = p_eval_step(state.params, batch)\n            metrics.append(_metrics)\n        if data_args.predict_with_generate:\n            generated_ids = p_generate_step(state.params, batch)\n            preds.extend(jax.device_get(generated_ids.reshape(-1, gen_kwargs['max_length'])))\n            if _labels is not None:\n                labels.extend(jax.device_get(_labels.reshape(-1, _labels.shape[-1])))\n    if metrics:\n        metrics = get_metrics(metrics)\n        metrics = jax.tree_util.tree_map(jnp.mean, metrics)\n    generations = []\n    rouge_desc = ''\n    if data_args.predict_with_generate:\n        if labels:\n            (rouge_metrics, decoded_preds, decoded_labels) = compute_metrics(preds, labels)\n            metrics.update(rouge_metrics)\n            rouge_desc = ' '.join([f\"{('Predict' if is_prediction else 'Eval')} {key}: {value} |\" for (key, value) in rouge_metrics.items()])\n            for (pred, label) in zip(decoded_preds, decoded_labels):\n                pred = pred.replace('\\n', ' ')\n                label = label.replace('\\n', ' ')\n                generations.append({'label': label, 'pred': pred})\n        else:\n            decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n            decoded_preds = [pred.strip() for pred in decoded_preds]\n            decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in decoded_preds]\n            for pred in decoded_preds:\n                pred = pred.replace('\\n', ' ')\n                generations.append({'pred': pred})\n    if metrics:\n        desc = f\"{('Predict' if is_prediction else 'Eval')} Loss: {metrics['loss']} | {rouge_desc})\"\n        if training_args.do_train and (not is_prediction):\n            desc = f'Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | ' + desc\n            epochs.write(desc)\n            epochs.desc = desc\n        logger.info(desc)\n    if jax.process_index() == 0:\n        if not os.path.isdir(os.path.join(training_args.output_dir, ckpt_dir)):\n            os.makedirs(os.path.join(training_args.output_dir, ckpt_dir), exist_ok=True)\n        if metrics:\n            if has_tensorboard and training_args.do_train:\n                write_metric(summary_writer, metrics, train_time=None, step=cur_step, metric_key_prefix=metric_key_prefix)\n            metrics = {f'{metric_key_prefix}_{metric_name}': round(value.item(), 6) for (metric_name, value) in metrics.items()}\n            _path = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_results.json')\n            with open(_path, 'w') as f:\n                json.dump(metrics, f, indent=4, sort_keys=True)\n            with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                fp.write(desc + '\\n')\n        if generations:\n            output_file = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_generation.json')\n            with open(output_file, 'w', encoding='UTF-8') as fp:\n                json.dump(generations, fp, ensure_ascii=False, indent=4)",
            "def evaluation_loop(rng: jax.random.PRNGKey, dataset: Dataset, metric_key_prefix: str='eval', ckpt_dir: str='', is_prediction=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    logger.info(f\"*** {('Predict' if is_prediction else 'Evaluate')} ***\")\n    metrics = []\n    preds = []\n    labels = []\n    batches = blockwise_data_loader(rng, dataset, block_size=training_args.block_size, batch_size=eval_batch_size, keep_in_memory=False, shuffle=False, split='prediction' if is_prediction else 'validation')\n    steps = len(dataset) // eval_batch_size\n    for _ in tqdm(range(steps), desc=f\"{('Predicting' if is_prediction else 'Evaluating')}...\", position=2, leave=False):\n        batch = next(batches)\n        _labels = batch.get('labels', None)\n        if not is_prediction and _labels is None:\n            raise ValueError('Evaluation requires the validation dataset to have `labels`')\n        if _labels is not None:\n            _metrics = p_eval_step(state.params, batch)\n            metrics.append(_metrics)\n        if data_args.predict_with_generate:\n            generated_ids = p_generate_step(state.params, batch)\n            preds.extend(jax.device_get(generated_ids.reshape(-1, gen_kwargs['max_length'])))\n            if _labels is not None:\n                labels.extend(jax.device_get(_labels.reshape(-1, _labels.shape[-1])))\n    if metrics:\n        metrics = get_metrics(metrics)\n        metrics = jax.tree_util.tree_map(jnp.mean, metrics)\n    generations = []\n    rouge_desc = ''\n    if data_args.predict_with_generate:\n        if labels:\n            (rouge_metrics, decoded_preds, decoded_labels) = compute_metrics(preds, labels)\n            metrics.update(rouge_metrics)\n            rouge_desc = ' '.join([f\"{('Predict' if is_prediction else 'Eval')} {key}: {value} |\" for (key, value) in rouge_metrics.items()])\n            for (pred, label) in zip(decoded_preds, decoded_labels):\n                pred = pred.replace('\\n', ' ')\n                label = label.replace('\\n', ' ')\n                generations.append({'label': label, 'pred': pred})\n        else:\n            decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n            decoded_preds = [pred.strip() for pred in decoded_preds]\n            decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in decoded_preds]\n            for pred in decoded_preds:\n                pred = pred.replace('\\n', ' ')\n                generations.append({'pred': pred})\n    if metrics:\n        desc = f\"{('Predict' if is_prediction else 'Eval')} Loss: {metrics['loss']} | {rouge_desc})\"\n        if training_args.do_train and (not is_prediction):\n            desc = f'Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | ' + desc\n            epochs.write(desc)\n            epochs.desc = desc\n        logger.info(desc)\n    if jax.process_index() == 0:\n        if not os.path.isdir(os.path.join(training_args.output_dir, ckpt_dir)):\n            os.makedirs(os.path.join(training_args.output_dir, ckpt_dir), exist_ok=True)\n        if metrics:\n            if has_tensorboard and training_args.do_train:\n                write_metric(summary_writer, metrics, train_time=None, step=cur_step, metric_key_prefix=metric_key_prefix)\n            metrics = {f'{metric_key_prefix}_{metric_name}': round(value.item(), 6) for (metric_name, value) in metrics.items()}\n            _path = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_results.json')\n            with open(_path, 'w') as f:\n                json.dump(metrics, f, indent=4, sort_keys=True)\n            with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                fp.write(desc + '\\n')\n        if generations:\n            output_file = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_generation.json')\n            with open(output_file, 'w', encoding='UTF-8') as fp:\n                json.dump(generations, fp, ensure_ascii=False, indent=4)"
        ]
    },
    {
        "func_name": "evaluate",
        "original": "def evaluate(rng: jax.random.PRNGKey, dataset: Dataset, ckpt_dir: str=''):\n    evaluation_loop(rng, dataset, metric_key_prefix='eval', ckpt_dir=ckpt_dir)",
        "mutated": [
            "def evaluate(rng: jax.random.PRNGKey, dataset: Dataset, ckpt_dir: str=''):\n    if False:\n        i = 10\n    evaluation_loop(rng, dataset, metric_key_prefix='eval', ckpt_dir=ckpt_dir)",
            "def evaluate(rng: jax.random.PRNGKey, dataset: Dataset, ckpt_dir: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    evaluation_loop(rng, dataset, metric_key_prefix='eval', ckpt_dir=ckpt_dir)",
            "def evaluate(rng: jax.random.PRNGKey, dataset: Dataset, ckpt_dir: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    evaluation_loop(rng, dataset, metric_key_prefix='eval', ckpt_dir=ckpt_dir)",
            "def evaluate(rng: jax.random.PRNGKey, dataset: Dataset, ckpt_dir: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    evaluation_loop(rng, dataset, metric_key_prefix='eval', ckpt_dir=ckpt_dir)",
            "def evaluate(rng: jax.random.PRNGKey, dataset: Dataset, ckpt_dir: str=''):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    evaluation_loop(rng, dataset, metric_key_prefix='eval', ckpt_dir=ckpt_dir)"
        ]
    },
    {
        "func_name": "predict",
        "original": "def predict(rng: jax.random.PRNGKey, dataset: Dataset):\n    evaluation_loop(rng, dataset, metric_key_prefix='test', is_prediction=True)",
        "mutated": [
            "def predict(rng: jax.random.PRNGKey, dataset: Dataset):\n    if False:\n        i = 10\n    evaluation_loop(rng, dataset, metric_key_prefix='test', is_prediction=True)",
            "def predict(rng: jax.random.PRNGKey, dataset: Dataset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    evaluation_loop(rng, dataset, metric_key_prefix='test', is_prediction=True)",
            "def predict(rng: jax.random.PRNGKey, dataset: Dataset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    evaluation_loop(rng, dataset, metric_key_prefix='test', is_prediction=True)",
            "def predict(rng: jax.random.PRNGKey, dataset: Dataset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    evaluation_loop(rng, dataset, metric_key_prefix='test', is_prediction=True)",
            "def predict(rng: jax.random.PRNGKey, dataset: Dataset):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    evaluation_loop(rng, dataset, metric_key_prefix='test', is_prediction=True)"
        ]
    },
    {
        "func_name": "main",
        "original": "def main():\n    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n    if len(sys.argv) == 2 and sys.argv[1].endswith('.json'):\n        (model_args, data_args, training_args) = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n    else:\n        (model_args, data_args, training_args) = parser.parse_args_into_dataclasses()\n    if model_args.use_auth_token is not None:\n        warnings.warn('The `use_auth_token` argument is deprecated and will be removed in v4.34. Please use `token` instead.', FutureWarning)\n        if model_args.token is not None:\n            raise ValueError('`token` and `use_auth_token` are both specified. Please set only the argument `token`.')\n        model_args.token = model_args.use_auth_token\n    send_example_telemetry('run_image_captioning', model_args, data_args, framework='flax')\n    if os.path.exists(training_args.output_dir) and os.listdir(training_args.output_dir) and training_args.do_train and (not training_args.overwrite_output_dir):\n        raise ValueError(f'Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.')\n    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s', datefmt='%m/%d/%Y %H:%M:%S', level=logging.INFO)\n    logger.setLevel(logging.INFO if jax.process_index() == 0 else logging.ERROR)\n    if jax.process_index() == 0:\n        datasets.utils.logging.set_verbosity_warning()\n        transformers.utils.logging.set_verbosity_info()\n    else:\n        datasets.utils.logging.set_verbosity_error()\n        transformers.utils.logging.set_verbosity_error()\n    logger.info(f'Training/evaluation parameters {training_args}')\n    if training_args.push_to_hub:\n        repo_name = training_args.hub_model_id\n        if repo_name is None:\n            repo_name = Path(training_args.output_dir).absolute().name\n        repo_id = create_repo(repo_name, exist_ok=True, token=training_args.hub_token).repo_id\n        repo = Repository(training_args.output_dir, clone_from=repo_id, token=training_args.hub_token)\n    if data_args.dataset_name is not None:\n        dataset = load_dataset(data_args.dataset_name, data_args.dataset_config_name, cache_dir=model_args.cache_dir, keep_in_memory=False, data_dir=data_args.data_dir, token=model_args.token)\n    else:\n        data_files = {}\n        if data_args.train_file is not None:\n            data_files['train'] = data_args.train_file\n            extension = data_args.train_file.split('.')[-1]\n        if data_args.validation_file is not None:\n            data_files['validation'] = data_args.validation_file\n            extension = data_args.validation_file.split('.')[-1]\n        if data_args.test_file is not None:\n            data_files['test'] = data_args.test_file\n            extension = data_args.test_file.split('.')[-1]\n        dataset = load_dataset(extension, data_files=data_files, cache_dir=model_args.cache_dir, token=model_args.token)\n    model = FlaxVisionEncoderDecoderModel.from_pretrained(model_args.model_name_or_path, seed=training_args.seed, dtype=getattr(jnp, model_args.dtype), token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    image_processor = AutoImageProcessor.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir, token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    tokenizer = AutoTokenizer.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir, use_fast=model_args.use_fast_tokenizer, token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    tokenizer.pad_token = tokenizer.convert_ids_to_tokens(model.config.pad_token_id)\n    if training_args.do_train:\n        column_names = dataset['train'].column_names\n    elif training_args.do_eval:\n        column_names = dataset['validation'].column_names\n    elif training_args.do_predict:\n        column_names = dataset['test'].column_names\n    else:\n        logger.info('There is nothing to do. Please pass `do_train`, `do_eval` and/or `do_predict`.')\n        return\n    dataset_columns = image_captioning_name_mapping.get(data_args.dataset_name, None)\n    if data_args.image_column is None:\n        if dataset_columns is None:\n            raise ValueError(f\"`--dataset_name` {data_args.dataset_name} not found in dataset '{data_args.dataset_name}'. Make sure to set `--dataset_name` to the correct dataset name, one of {', '.join(image_captioning_name_mapping.keys())}.\")\n        image_column = dataset_columns[0]\n    else:\n        image_column = data_args.image_column\n        if image_column not in column_names:\n            raise ValueError(f\"--image_column' value '{data_args.image_column}' needs to be one of: {', '.join(column_names)}\")\n    if data_args.caption_column is None:\n        if dataset_columns is None:\n            raise ValueError(f\"`--dataset_name` {data_args.dataset_name} not found in dataset '{data_args.dataset_name}'. Make sure to set `--dataset_name` to the correct dataset name, one of {', '.join(image_captioning_name_mapping.keys())}.\")\n        caption_column = dataset_columns[1]\n    else:\n        caption_column = data_args.caption_column\n        if caption_column not in column_names:\n            raise ValueError(f\"--caption_column' value '{data_args.caption_column}' needs to be one of: {', '.join(column_names)}\")\n    model_module = __import__(model.__module__, fromlist=['shift_tokens_right'])\n    shift_tokens_right_fn = getattr(model_module, 'shift_tokens_right', shift_tokens_right)\n\n    def filter_fn(examples):\n        \"\"\"remove problematic images\"\"\"\n        bools = []\n        for image_file in examples[image_column]:\n            try:\n                image = Image.open(image_file)\n                image_processor(images=image, return_tensors='np')\n                bools.append(True)\n            except Exception:\n                bools.append(False)\n        return bools\n\n    def tokenization_fn(examples, max_target_length):\n        \"\"\"Run tokenization on captions.\"\"\"\n        captions = []\n        for caption in examples[caption_column]:\n            captions.append(caption.lower() + ' ' + tokenizer.eos_token)\n        targets = captions\n        model_inputs = {}\n        labels = tokenizer(text_target=targets, max_length=max_target_length, padding='max_length', truncation=True, return_tensors='np')\n        model_inputs['labels'] = labels['input_ids']\n        decoder_input_ids = shift_tokens_right_fn(labels['input_ids'], model.config.pad_token_id, model.config.decoder_start_token_id)\n        model_inputs['decoder_input_ids'] = np.asarray(decoder_input_ids)\n        model_inputs['decoder_attention_mask'] = labels['attention_mask']\n        model_inputs[image_column] = examples[image_column]\n        return model_inputs\n\n    def image_processing_fn(examples, check_image=True):\n        \"\"\"\n        Run preprocessing on images\n\n        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\n        Otherwise, an exception will be thrown.\n        \"\"\"\n        model_inputs = {}\n        if check_image:\n            images = []\n            to_keep = []\n            for image_file in examples[image_column]:\n                try:\n                    img = Image.open(image_file)\n                    images.append(img)\n                    to_keep.append(True)\n                except Exception:\n                    to_keep.append(False)\n            for (k, v) in examples.items():\n                if k != image_column:\n                    model_inputs[k] = v[to_keep]\n        else:\n            images = [Image.open(image_file) for image_file in examples[image_column]]\n        encoder_inputs = image_processor(images=images, return_tensors='np')\n        model_inputs['pixel_values'] = encoder_inputs.pixel_values\n        return model_inputs\n\n    def preprocess_fn(examples, max_target_length, check_image=True):\n        \"\"\"Run tokenization + image processing\"\"\"\n        model_inputs = {}\n        model_inputs.update(tokenization_fn(examples, max_target_length))\n        model_inputs.update(image_processing_fn(model_inputs, check_image=check_image))\n        model_inputs.pop(image_column)\n        return model_inputs\n    features = datasets.Features({'pixel_values': datasets.Array3D(shape=(getattr(model.config.encoder, 'num_channels', 3), model.config.encoder.image_size, model.config.encoder.image_size), dtype='float32'), 'labels': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None), 'decoder_input_ids': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None), 'decoder_attention_mask': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None)})\n    run_img_proc_at_beginning = training_args.block_size == 0\n    function_kwarg = preprocess_fn if run_img_proc_at_beginning else tokenization_fn\n    features_kwarg = features if run_img_proc_at_beginning else None\n    remove_columns_kwarg = [x for x in column_names if x != image_column or run_img_proc_at_beginning]\n    processor_names = 'tokenizer and image processor' if run_img_proc_at_beginning else 'tokenizer'\n    train_batch_size = int(training_args.per_device_train_batch_size) * jax.device_count()\n    eval_batch_size = int(training_args.per_device_eval_batch_size) * jax.device_count()\n    if training_args.block_size % train_batch_size > 0 or training_args.block_size % eval_batch_size > 0:\n        raise ValueError(f'`training_args.block_size` needs to be a multiple of the global train/eval batch size. Got {training_args.block_size}, {train_batch_size} and {eval_batch_size} respectively instead.')\n    if training_args.do_train:\n        if 'train' not in dataset:\n            raise ValueError('--do_train requires a train dataset')\n        train_dataset = dataset['train']\n        if data_args.max_train_samples is not None:\n            max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n            train_dataset = train_dataset.select(range(max_train_samples))\n        if not run_img_proc_at_beginning:\n            train_dataset = train_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        train_dataset = train_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on train dataset', fn_kwargs={'max_target_length': data_args.max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            train_dataset = train_dataset.with_format('numpy')\n        steps_per_epoch = len(train_dataset) // train_batch_size\n        num_train_examples_per_epoch = steps_per_epoch * train_batch_size\n        num_epochs = int(training_args.num_train_epochs)\n        total_train_steps = steps_per_epoch * num_epochs\n    else:\n        num_train_examples_per_epoch = 0\n    if training_args.do_eval:\n        if 'validation' not in dataset:\n            raise ValueError('--do_eval requires a validation dataset')\n        eval_dataset = dataset['validation']\n        if data_args.max_eval_samples is not None:\n            max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n            eval_dataset = eval_dataset.select(range(max_eval_samples))\n        if not run_img_proc_at_beginning:\n            eval_dataset = eval_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        eval_dataset = eval_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on validation dataset', fn_kwargs={'max_target_length': data_args.val_max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            eval_dataset = eval_dataset.with_format('numpy')\n        num_eval_examples = len(eval_dataset)\n        eval_steps = num_eval_examples // eval_batch_size\n    if training_args.do_predict:\n        if 'test' not in dataset:\n            raise ValueError('--do_predict requires a test dataset')\n        predict_dataset = dataset['test']\n        if data_args.max_predict_samples is not None:\n            max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)\n            predict_dataset = predict_dataset.select(range(max_predict_samples))\n        if not run_img_proc_at_beginning:\n            predict_dataset = predict_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        predict_dataset = predict_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on prediction dataset', fn_kwargs={'max_target_length': data_args.val_max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            predict_dataset = predict_dataset.with_format('numpy')\n        num_test_examples = len(predict_dataset)\n        test_steps = num_test_examples // eval_batch_size\n\n    def blockwise_data_loader(rng: jax.random.PRNGKey, ds: Dataset, block_size: int, batch_size: int, shuffle: bool=False, keep_in_memory: bool=False, split: str=''):\n        \"\"\"\n        Wrap the simple `data_loader` in a block-wise way if `block_size` > 0, else it's the same as `data_loader`.\n\n        If `block_size` > 0, it requires `ds` to have a column that gives image paths in order to perform image\n        processing (with the column name being specified by `image_column`). The tokenization should be done before\n        training in this case.\n        \"\"\"\n        if shuffle:\n            indices = jax.random.permutation(rng, len(ds))\n            indices = np.asarray(indices)\n        else:\n            indices = np.arange(len(ds))\n        _block_size = len(ds) if not block_size else block_size\n        steps_per_block = _block_size // batch_size\n        num_examples = len(ds)\n        steps = num_examples // batch_size\n        num_splits = steps // steps_per_block + int(steps % steps_per_block > 0)\n        for idx in range(num_splits):\n            if not block_size:\n                _ds = ds\n            else:\n                start_idx = block_size * idx\n                end_idx = block_size * (idx + 1)\n                selected_indices = indices[start_idx:end_idx]\n                _ds = ds.select(selected_indices)\n                _ds = _ds.map(image_processing_fn, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=[image_column], load_from_cache_file=not data_args.overwrite_cache, features=features, keep_in_memory=keep_in_memory, fn_kwargs={'check_image': False}, desc=f'Running image processing on {split} dataset'.replace('  ', ' '))\n                _ds = _ds.with_format('numpy')\n            loader = data_loader(rng, _ds, batch_size=batch_size, shuffle=False)\n            for batch in loader:\n                yield batch\n    metric = evaluate.load('rouge')\n\n    def postprocess_text(preds, labels):\n        preds = [pred.strip() for pred in preds]\n        labels = [label.strip() for label in labels]\n        preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in preds]\n        labels = ['\\n'.join(nltk.sent_tokenize(label)) for label in labels]\n        return (preds, labels)\n\n    def compute_metrics(preds, labels):\n        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n        (decoded_preds, decoded_labels) = postprocess_text(decoded_preds, decoded_labels)\n        result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n        result = {key: value.mid.fmeasure * 100 for (key, value) in result.items()}\n        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n        result['gen_len'] = np.mean(prediction_lens)\n        result = {k: round(v, 6) for (k, v) in result.items()}\n        return (result, decoded_preds, decoded_labels)\n    has_tensorboard = is_tensorboard_available()\n    if has_tensorboard and jax.process_index() == 0:\n        try:\n            from flax.metrics.tensorboard import SummaryWriter\n            summary_writer = SummaryWriter(log_dir=Path(training_args.output_dir))\n        except ImportError as ie:\n            has_tensorboard = False\n            logger.warning(f'Unable to display metrics through TensorBoard because some package are not installed: {ie}')\n    else:\n        logger.warning('Unable to display metrics through TensorBoard because the package is not installed: Please run pip install tensorboard to enable.')\n    rng = jax.random.PRNGKey(training_args.seed)\n    (rng, dropout_rng) = jax.random.split(rng)\n    linear_decay_lr_schedule_fn = create_learning_rate_fn(num_train_examples_per_epoch, train_batch_size, training_args.num_train_epochs, training_args.warmup_steps, training_args.learning_rate)\n\n    def decay_mask_fn(params):\n        flat_params = traverse_util.flatten_dict(params)\n        layer_norm_candidates = ['layernorm', 'layer_norm', 'ln']\n        layer_norm_named_params = {layer[-2:] for layer_norm_name in layer_norm_candidates for layer in flat_params.keys() if layer_norm_name in ''.join(layer).lower()}\n        flat_mask = {path: path[-1] != 'bias' and path[-2:] not in layer_norm_named_params for path in flat_params}\n        return traverse_util.unflatten_dict(flat_mask)\n    adamw = optax.adamw(learning_rate=linear_decay_lr_schedule_fn, b1=training_args.adam_beta1, b2=training_args.adam_beta2, eps=training_args.adam_epsilon, weight_decay=training_args.weight_decay, mask=decay_mask_fn)\n    state = TrainState.create(apply_fn=model.__call__, params=model.params, tx=adamw, dropout_rng=dropout_rng)\n\n    def loss_fn(logits, labels, padding_mask, label_smoothing_factor=0.0):\n        \"\"\"\n        The label smoothing implementation is adapted from Flax's official example:\n        https://github.com/google/flax/blob/87a211135c6a377c8f29048a1cac3840e38b9da4/examples/wmt/train.py#L104\n        \"\"\"\n        vocab_size = logits.shape[-1]\n        confidence = 1.0 - label_smoothing_factor\n        low_confidence = (1.0 - confidence) / (vocab_size - 1)\n        normalizing_constant = -(confidence * jnp.log(confidence) + (vocab_size - 1) * low_confidence * jnp.log(low_confidence + 1e-20))\n        soft_labels = onehot(labels, vocab_size, on_value=confidence, off_value=low_confidence)\n        loss = optax.softmax_cross_entropy(logits, soft_labels)\n        loss = loss - normalizing_constant\n        loss = loss * padding_mask\n        loss = loss.sum()\n        num_labels = padding_mask.sum()\n        return (loss, num_labels)\n\n    def train_step(state, batch, label_smoothing_factor=0.0):\n        (dropout_rng, new_dropout_rng) = jax.random.split(state.dropout_rng)\n\n        def compute_loss(params):\n            labels = batch.pop('labels')\n            logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n            (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n            return (loss, num_labels)\n        grad_fn = jax.value_and_grad(compute_loss, has_aux=True)\n        ((loss, num_labels), grad) = grad_fn(state.params)\n        num_labels = jax.lax.psum(num_labels, 'batch')\n        loss = jax.lax.psum(loss, 'batch')\n        loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n        grad = jax.lax.psum(grad, 'batch')\n        grad = jax.tree_util.tree_map(lambda x: x / num_labels, grad)\n        new_state = state.apply_gradients(grads=grad, dropout_rng=new_dropout_rng)\n        metrics = {'loss': loss, 'learning_rate': linear_decay_lr_schedule_fn(state.step)}\n        return (new_state, metrics)\n\n    def eval_step(params, batch, label_smoothing_factor=0.0):\n        labels = batch.pop('labels')\n        logits = model(**batch, params=params, train=False)[0]\n        (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n        num_labels = jax.lax.psum(num_labels, 'batch')\n        loss = jax.lax.psum(loss, 'batch')\n        loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n        metrics = {'loss': loss}\n        return metrics\n    max_length = data_args.val_max_target_length if data_args.val_max_target_length is not None else model.config.max_length\n    num_beams = data_args.num_beams if data_args.num_beams is not None else model.config.num_beams\n    gen_kwargs = {'max_length': max_length, 'num_beams': num_beams}\n\n    def generate_step(params, batch):\n        model.params = params\n        output_ids = model.generate(batch['pixel_values'], **gen_kwargs)\n        return output_ids.sequences\n    p_train_step = jax.pmap(partial(train_step, label_smoothing_factor=training_args.label_smoothing_factor), 'batch', donate_argnums=(0,))\n    p_eval_step = jax.pmap(partial(eval_step, label_smoothing_factor=training_args.label_smoothing_factor), 'batch')\n    p_generate_step = jax.pmap(generate_step, 'batch')\n    state = state.replicate()\n    if training_args.do_train:\n        logger.info('***** Running training *****')\n        logger.info(f'  Num train examples = {num_train_examples_per_epoch}')\n        logger.info(f'  Num Epochs = {num_epochs}')\n        logger.info(f'  Instantaneous train batch size per device = {training_args.per_device_train_batch_size}')\n        logger.info(f'  Total train batch size (w. parallel & distributed) = {train_batch_size}')\n        logger.info(f'  Optimization steps per epoch = {steps_per_epoch}')\n        logger.info(f'  Total optimization steps = {total_train_steps}')\n    if training_args.do_eval:\n        logger.info(f'  Num evaluation examples = {num_eval_examples}')\n        logger.info(f'  Instantaneous evaluation batch size per device = {training_args.per_device_eval_batch_size}')\n        logger.info(f'  Total evaluation batch size (w. parallel & distributed) = {eval_batch_size}')\n        logger.info(f'  Evaluation steps = {eval_steps}')\n    if training_args.do_predict:\n        logger.info(f'  Num test examples = {num_test_examples}')\n        logger.info(f'  Instantaneous test batch size per device = {training_args.per_device_eval_batch_size}')\n        logger.info(f'  Total test batch size (w. parallel & distributed) = {eval_batch_size}')\n        logger.info(f'  Test steps = {test_steps}')\n    if not os.path.isdir(os.path.join(training_args.output_dir)):\n        os.makedirs(os.path.join(training_args.output_dir), exist_ok=True)\n\n    def save_ckpt(ckpt_dir: str, commit_msg: str=''):\n        \"\"\"save checkpoints and push to Hugging Face Hub if specified\"\"\"\n        if jax.process_index() == 0:\n            params = jax.device_get(jax.tree_util.tree_map(lambda x: x[0], state.params))\n            model.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir), params=params)\n            tokenizer.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir))\n            if training_args.push_to_hub:\n                repo.push_to_hub(commit_message=commit_msg, blocking=False)\n\n    def evaluation_loop(rng: jax.random.PRNGKey, dataset: Dataset, metric_key_prefix: str='eval', ckpt_dir: str='', is_prediction=False):\n        logger.info(f\"*** {('Predict' if is_prediction else 'Evaluate')} ***\")\n        metrics = []\n        preds = []\n        labels = []\n        batches = blockwise_data_loader(rng, dataset, block_size=training_args.block_size, batch_size=eval_batch_size, keep_in_memory=False, shuffle=False, split='prediction' if is_prediction else 'validation')\n        steps = len(dataset) // eval_batch_size\n        for _ in tqdm(range(steps), desc=f\"{('Predicting' if is_prediction else 'Evaluating')}...\", position=2, leave=False):\n            batch = next(batches)\n            _labels = batch.get('labels', None)\n            if not is_prediction and _labels is None:\n                raise ValueError('Evaluation requires the validation dataset to have `labels`')\n            if _labels is not None:\n                _metrics = p_eval_step(state.params, batch)\n                metrics.append(_metrics)\n            if data_args.predict_with_generate:\n                generated_ids = p_generate_step(state.params, batch)\n                preds.extend(jax.device_get(generated_ids.reshape(-1, gen_kwargs['max_length'])))\n                if _labels is not None:\n                    labels.extend(jax.device_get(_labels.reshape(-1, _labels.shape[-1])))\n        if metrics:\n            metrics = get_metrics(metrics)\n            metrics = jax.tree_util.tree_map(jnp.mean, metrics)\n        generations = []\n        rouge_desc = ''\n        if data_args.predict_with_generate:\n            if labels:\n                (rouge_metrics, decoded_preds, decoded_labels) = compute_metrics(preds, labels)\n                metrics.update(rouge_metrics)\n                rouge_desc = ' '.join([f\"{('Predict' if is_prediction else 'Eval')} {key}: {value} |\" for (key, value) in rouge_metrics.items()])\n                for (pred, label) in zip(decoded_preds, decoded_labels):\n                    pred = pred.replace('\\n', ' ')\n                    label = label.replace('\\n', ' ')\n                    generations.append({'label': label, 'pred': pred})\n            else:\n                decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n                decoded_preds = [pred.strip() for pred in decoded_preds]\n                decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in decoded_preds]\n                for pred in decoded_preds:\n                    pred = pred.replace('\\n', ' ')\n                    generations.append({'pred': pred})\n        if metrics:\n            desc = f\"{('Predict' if is_prediction else 'Eval')} Loss: {metrics['loss']} | {rouge_desc})\"\n            if training_args.do_train and (not is_prediction):\n                desc = f'Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | ' + desc\n                epochs.write(desc)\n                epochs.desc = desc\n            logger.info(desc)\n        if jax.process_index() == 0:\n            if not os.path.isdir(os.path.join(training_args.output_dir, ckpt_dir)):\n                os.makedirs(os.path.join(training_args.output_dir, ckpt_dir), exist_ok=True)\n            if metrics:\n                if has_tensorboard and training_args.do_train:\n                    write_metric(summary_writer, metrics, train_time=None, step=cur_step, metric_key_prefix=metric_key_prefix)\n                metrics = {f'{metric_key_prefix}_{metric_name}': round(value.item(), 6) for (metric_name, value) in metrics.items()}\n                _path = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_results.json')\n                with open(_path, 'w') as f:\n                    json.dump(metrics, f, indent=4, sort_keys=True)\n                with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                    fp.write(desc + '\\n')\n            if generations:\n                output_file = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_generation.json')\n                with open(output_file, 'w', encoding='UTF-8') as fp:\n                    json.dump(generations, fp, ensure_ascii=False, indent=4)\n\n    def evaluate(rng: jax.random.PRNGKey, dataset: Dataset, ckpt_dir: str=''):\n        evaluation_loop(rng, dataset, metric_key_prefix='eval', ckpt_dir=ckpt_dir)\n\n    def predict(rng: jax.random.PRNGKey, dataset: Dataset):\n        evaluation_loop(rng, dataset, metric_key_prefix='test', is_prediction=True)\n    input_rng = None\n    if training_args.do_train:\n        cur_step = 0\n        train_time = 0\n        epochs = tqdm(range(num_epochs), desc=f'Epoch ... (1/{num_epochs})', position=0)\n        for epoch in epochs:\n            (rng, input_rng) = jax.random.split(rng)\n            train_metrics = []\n            train_batches = blockwise_data_loader(input_rng, train_dataset, block_size=training_args.block_size, batch_size=train_batch_size, keep_in_memory=True, shuffle=True, split='train')\n            for (batch_idx, _) in enumerate(tqdm(range(steps_per_epoch), desc='Training...', position=1, leave=False)):\n                cur_step += 1\n                batch = next(train_batches)\n                batch_start = time.time()\n                (state, train_metric) = p_train_step(state, batch)\n                train_metrics.append(train_metric)\n                train_time += time.time() - batch_start\n                time_per_step = train_time / cur_step\n                if training_args.logging_steps > 0 and cur_step % training_args.logging_steps == 0:\n                    _train_metric = unreplicate(train_metric)\n                    desc = f\"Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | Loss: {_train_metric['loss']} | Learning Rate: {_train_metric['learning_rate']} | Time per step: {time_per_step})\"\n                    epochs.desc = desc\n                    epochs.write(desc)\n                    logger.info(desc)\n                    with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                        fp.write(desc + '\\n')\n                    if has_tensorboard and jax.process_index() == 0:\n                        write_metric(summary_writer, train_metrics, train_time=train_time, step=cur_step, metric_key_prefix='train')\n                if training_args.do_eval and (training_args.eval_steps is not None and training_args.eval_steps > 0) and (cur_step % training_args.eval_steps == 0):\n                    ckpt_dir = f'ckpt_epoch_{epoch + 1}_step_{cur_step}'\n                    commit_msg = f'Saving weights and logs of epoch {epoch + 1} - step {cur_step}'\n                    evaluate(input_rng, eval_dataset, ckpt_dir)\n                    save_ckpt(ckpt_dir=ckpt_dir, commit_msg=commit_msg)\n            if training_args.logging_steps <= 0:\n                logger.info(desc)\n                with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                    fp.write(desc + '\\n')\n                if has_tensorboard and jax.process_index() == 0:\n                    write_metric(summary_writer, train_metrics, train_time=train_time, step=cur_step, metric_key_prefix='train')\n            if training_args.do_eval and (training_args.eval_steps is None or training_args.eval_steps <= 0):\n                ckpt_dir = f'ckpt_epoch_{epoch + 1}_step_{cur_step}'\n                commit_msg = f'Saving weights and logs of epoch {epoch + 1} - step {cur_step}'\n                evaluate(input_rng, eval_dataset, ckpt_dir)\n                save_ckpt(ckpt_dir=ckpt_dir, commit_msg=commit_msg)\n    if input_rng is None:\n        (rng, input_rng) = jax.random.split(rng)\n    if training_args.do_eval and (not training_args.do_train):\n        evaluate(input_rng, eval_dataset)\n    if training_args.do_predict:\n        predict(input_rng, predict_dataset)",
        "mutated": [
            "def main():\n    if False:\n        i = 10\n    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n    if len(sys.argv) == 2 and sys.argv[1].endswith('.json'):\n        (model_args, data_args, training_args) = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n    else:\n        (model_args, data_args, training_args) = parser.parse_args_into_dataclasses()\n    if model_args.use_auth_token is not None:\n        warnings.warn('The `use_auth_token` argument is deprecated and will be removed in v4.34. Please use `token` instead.', FutureWarning)\n        if model_args.token is not None:\n            raise ValueError('`token` and `use_auth_token` are both specified. Please set only the argument `token`.')\n        model_args.token = model_args.use_auth_token\n    send_example_telemetry('run_image_captioning', model_args, data_args, framework='flax')\n    if os.path.exists(training_args.output_dir) and os.listdir(training_args.output_dir) and training_args.do_train and (not training_args.overwrite_output_dir):\n        raise ValueError(f'Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.')\n    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s', datefmt='%m/%d/%Y %H:%M:%S', level=logging.INFO)\n    logger.setLevel(logging.INFO if jax.process_index() == 0 else logging.ERROR)\n    if jax.process_index() == 0:\n        datasets.utils.logging.set_verbosity_warning()\n        transformers.utils.logging.set_verbosity_info()\n    else:\n        datasets.utils.logging.set_verbosity_error()\n        transformers.utils.logging.set_verbosity_error()\n    logger.info(f'Training/evaluation parameters {training_args}')\n    if training_args.push_to_hub:\n        repo_name = training_args.hub_model_id\n        if repo_name is None:\n            repo_name = Path(training_args.output_dir).absolute().name\n        repo_id = create_repo(repo_name, exist_ok=True, token=training_args.hub_token).repo_id\n        repo = Repository(training_args.output_dir, clone_from=repo_id, token=training_args.hub_token)\n    if data_args.dataset_name is not None:\n        dataset = load_dataset(data_args.dataset_name, data_args.dataset_config_name, cache_dir=model_args.cache_dir, keep_in_memory=False, data_dir=data_args.data_dir, token=model_args.token)\n    else:\n        data_files = {}\n        if data_args.train_file is not None:\n            data_files['train'] = data_args.train_file\n            extension = data_args.train_file.split('.')[-1]\n        if data_args.validation_file is not None:\n            data_files['validation'] = data_args.validation_file\n            extension = data_args.validation_file.split('.')[-1]\n        if data_args.test_file is not None:\n            data_files['test'] = data_args.test_file\n            extension = data_args.test_file.split('.')[-1]\n        dataset = load_dataset(extension, data_files=data_files, cache_dir=model_args.cache_dir, token=model_args.token)\n    model = FlaxVisionEncoderDecoderModel.from_pretrained(model_args.model_name_or_path, seed=training_args.seed, dtype=getattr(jnp, model_args.dtype), token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    image_processor = AutoImageProcessor.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir, token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    tokenizer = AutoTokenizer.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir, use_fast=model_args.use_fast_tokenizer, token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    tokenizer.pad_token = tokenizer.convert_ids_to_tokens(model.config.pad_token_id)\n    if training_args.do_train:\n        column_names = dataset['train'].column_names\n    elif training_args.do_eval:\n        column_names = dataset['validation'].column_names\n    elif training_args.do_predict:\n        column_names = dataset['test'].column_names\n    else:\n        logger.info('There is nothing to do. Please pass `do_train`, `do_eval` and/or `do_predict`.')\n        return\n    dataset_columns = image_captioning_name_mapping.get(data_args.dataset_name, None)\n    if data_args.image_column is None:\n        if dataset_columns is None:\n            raise ValueError(f\"`--dataset_name` {data_args.dataset_name} not found in dataset '{data_args.dataset_name}'. Make sure to set `--dataset_name` to the correct dataset name, one of {', '.join(image_captioning_name_mapping.keys())}.\")\n        image_column = dataset_columns[0]\n    else:\n        image_column = data_args.image_column\n        if image_column not in column_names:\n            raise ValueError(f\"--image_column' value '{data_args.image_column}' needs to be one of: {', '.join(column_names)}\")\n    if data_args.caption_column is None:\n        if dataset_columns is None:\n            raise ValueError(f\"`--dataset_name` {data_args.dataset_name} not found in dataset '{data_args.dataset_name}'. Make sure to set `--dataset_name` to the correct dataset name, one of {', '.join(image_captioning_name_mapping.keys())}.\")\n        caption_column = dataset_columns[1]\n    else:\n        caption_column = data_args.caption_column\n        if caption_column not in column_names:\n            raise ValueError(f\"--caption_column' value '{data_args.caption_column}' needs to be one of: {', '.join(column_names)}\")\n    model_module = __import__(model.__module__, fromlist=['shift_tokens_right'])\n    shift_tokens_right_fn = getattr(model_module, 'shift_tokens_right', shift_tokens_right)\n\n    def filter_fn(examples):\n        \"\"\"remove problematic images\"\"\"\n        bools = []\n        for image_file in examples[image_column]:\n            try:\n                image = Image.open(image_file)\n                image_processor(images=image, return_tensors='np')\n                bools.append(True)\n            except Exception:\n                bools.append(False)\n        return bools\n\n    def tokenization_fn(examples, max_target_length):\n        \"\"\"Run tokenization on captions.\"\"\"\n        captions = []\n        for caption in examples[caption_column]:\n            captions.append(caption.lower() + ' ' + tokenizer.eos_token)\n        targets = captions\n        model_inputs = {}\n        labels = tokenizer(text_target=targets, max_length=max_target_length, padding='max_length', truncation=True, return_tensors='np')\n        model_inputs['labels'] = labels['input_ids']\n        decoder_input_ids = shift_tokens_right_fn(labels['input_ids'], model.config.pad_token_id, model.config.decoder_start_token_id)\n        model_inputs['decoder_input_ids'] = np.asarray(decoder_input_ids)\n        model_inputs['decoder_attention_mask'] = labels['attention_mask']\n        model_inputs[image_column] = examples[image_column]\n        return model_inputs\n\n    def image_processing_fn(examples, check_image=True):\n        \"\"\"\n        Run preprocessing on images\n\n        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\n        Otherwise, an exception will be thrown.\n        \"\"\"\n        model_inputs = {}\n        if check_image:\n            images = []\n            to_keep = []\n            for image_file in examples[image_column]:\n                try:\n                    img = Image.open(image_file)\n                    images.append(img)\n                    to_keep.append(True)\n                except Exception:\n                    to_keep.append(False)\n            for (k, v) in examples.items():\n                if k != image_column:\n                    model_inputs[k] = v[to_keep]\n        else:\n            images = [Image.open(image_file) for image_file in examples[image_column]]\n        encoder_inputs = image_processor(images=images, return_tensors='np')\n        model_inputs['pixel_values'] = encoder_inputs.pixel_values\n        return model_inputs\n\n    def preprocess_fn(examples, max_target_length, check_image=True):\n        \"\"\"Run tokenization + image processing\"\"\"\n        model_inputs = {}\n        model_inputs.update(tokenization_fn(examples, max_target_length))\n        model_inputs.update(image_processing_fn(model_inputs, check_image=check_image))\n        model_inputs.pop(image_column)\n        return model_inputs\n    features = datasets.Features({'pixel_values': datasets.Array3D(shape=(getattr(model.config.encoder, 'num_channels', 3), model.config.encoder.image_size, model.config.encoder.image_size), dtype='float32'), 'labels': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None), 'decoder_input_ids': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None), 'decoder_attention_mask': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None)})\n    run_img_proc_at_beginning = training_args.block_size == 0\n    function_kwarg = preprocess_fn if run_img_proc_at_beginning else tokenization_fn\n    features_kwarg = features if run_img_proc_at_beginning else None\n    remove_columns_kwarg = [x for x in column_names if x != image_column or run_img_proc_at_beginning]\n    processor_names = 'tokenizer and image processor' if run_img_proc_at_beginning else 'tokenizer'\n    train_batch_size = int(training_args.per_device_train_batch_size) * jax.device_count()\n    eval_batch_size = int(training_args.per_device_eval_batch_size) * jax.device_count()\n    if training_args.block_size % train_batch_size > 0 or training_args.block_size % eval_batch_size > 0:\n        raise ValueError(f'`training_args.block_size` needs to be a multiple of the global train/eval batch size. Got {training_args.block_size}, {train_batch_size} and {eval_batch_size} respectively instead.')\n    if training_args.do_train:\n        if 'train' not in dataset:\n            raise ValueError('--do_train requires a train dataset')\n        train_dataset = dataset['train']\n        if data_args.max_train_samples is not None:\n            max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n            train_dataset = train_dataset.select(range(max_train_samples))\n        if not run_img_proc_at_beginning:\n            train_dataset = train_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        train_dataset = train_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on train dataset', fn_kwargs={'max_target_length': data_args.max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            train_dataset = train_dataset.with_format('numpy')\n        steps_per_epoch = len(train_dataset) // train_batch_size\n        num_train_examples_per_epoch = steps_per_epoch * train_batch_size\n        num_epochs = int(training_args.num_train_epochs)\n        total_train_steps = steps_per_epoch * num_epochs\n    else:\n        num_train_examples_per_epoch = 0\n    if training_args.do_eval:\n        if 'validation' not in dataset:\n            raise ValueError('--do_eval requires a validation dataset')\n        eval_dataset = dataset['validation']\n        if data_args.max_eval_samples is not None:\n            max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n            eval_dataset = eval_dataset.select(range(max_eval_samples))\n        if not run_img_proc_at_beginning:\n            eval_dataset = eval_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        eval_dataset = eval_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on validation dataset', fn_kwargs={'max_target_length': data_args.val_max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            eval_dataset = eval_dataset.with_format('numpy')\n        num_eval_examples = len(eval_dataset)\n        eval_steps = num_eval_examples // eval_batch_size\n    if training_args.do_predict:\n        if 'test' not in dataset:\n            raise ValueError('--do_predict requires a test dataset')\n        predict_dataset = dataset['test']\n        if data_args.max_predict_samples is not None:\n            max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)\n            predict_dataset = predict_dataset.select(range(max_predict_samples))\n        if not run_img_proc_at_beginning:\n            predict_dataset = predict_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        predict_dataset = predict_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on prediction dataset', fn_kwargs={'max_target_length': data_args.val_max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            predict_dataset = predict_dataset.with_format('numpy')\n        num_test_examples = len(predict_dataset)\n        test_steps = num_test_examples // eval_batch_size\n\n    def blockwise_data_loader(rng: jax.random.PRNGKey, ds: Dataset, block_size: int, batch_size: int, shuffle: bool=False, keep_in_memory: bool=False, split: str=''):\n        \"\"\"\n        Wrap the simple `data_loader` in a block-wise way if `block_size` > 0, else it's the same as `data_loader`.\n\n        If `block_size` > 0, it requires `ds` to have a column that gives image paths in order to perform image\n        processing (with the column name being specified by `image_column`). The tokenization should be done before\n        training in this case.\n        \"\"\"\n        if shuffle:\n            indices = jax.random.permutation(rng, len(ds))\n            indices = np.asarray(indices)\n        else:\n            indices = np.arange(len(ds))\n        _block_size = len(ds) if not block_size else block_size\n        steps_per_block = _block_size // batch_size\n        num_examples = len(ds)\n        steps = num_examples // batch_size\n        num_splits = steps // steps_per_block + int(steps % steps_per_block > 0)\n        for idx in range(num_splits):\n            if not block_size:\n                _ds = ds\n            else:\n                start_idx = block_size * idx\n                end_idx = block_size * (idx + 1)\n                selected_indices = indices[start_idx:end_idx]\n                _ds = ds.select(selected_indices)\n                _ds = _ds.map(image_processing_fn, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=[image_column], load_from_cache_file=not data_args.overwrite_cache, features=features, keep_in_memory=keep_in_memory, fn_kwargs={'check_image': False}, desc=f'Running image processing on {split} dataset'.replace('  ', ' '))\n                _ds = _ds.with_format('numpy')\n            loader = data_loader(rng, _ds, batch_size=batch_size, shuffle=False)\n            for batch in loader:\n                yield batch\n    metric = evaluate.load('rouge')\n\n    def postprocess_text(preds, labels):\n        preds = [pred.strip() for pred in preds]\n        labels = [label.strip() for label in labels]\n        preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in preds]\n        labels = ['\\n'.join(nltk.sent_tokenize(label)) for label in labels]\n        return (preds, labels)\n\n    def compute_metrics(preds, labels):\n        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n        (decoded_preds, decoded_labels) = postprocess_text(decoded_preds, decoded_labels)\n        result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n        result = {key: value.mid.fmeasure * 100 for (key, value) in result.items()}\n        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n        result['gen_len'] = np.mean(prediction_lens)\n        result = {k: round(v, 6) for (k, v) in result.items()}\n        return (result, decoded_preds, decoded_labels)\n    has_tensorboard = is_tensorboard_available()\n    if has_tensorboard and jax.process_index() == 0:\n        try:\n            from flax.metrics.tensorboard import SummaryWriter\n            summary_writer = SummaryWriter(log_dir=Path(training_args.output_dir))\n        except ImportError as ie:\n            has_tensorboard = False\n            logger.warning(f'Unable to display metrics through TensorBoard because some package are not installed: {ie}')\n    else:\n        logger.warning('Unable to display metrics through TensorBoard because the package is not installed: Please run pip install tensorboard to enable.')\n    rng = jax.random.PRNGKey(training_args.seed)\n    (rng, dropout_rng) = jax.random.split(rng)\n    linear_decay_lr_schedule_fn = create_learning_rate_fn(num_train_examples_per_epoch, train_batch_size, training_args.num_train_epochs, training_args.warmup_steps, training_args.learning_rate)\n\n    def decay_mask_fn(params):\n        flat_params = traverse_util.flatten_dict(params)\n        layer_norm_candidates = ['layernorm', 'layer_norm', 'ln']\n        layer_norm_named_params = {layer[-2:] for layer_norm_name in layer_norm_candidates for layer in flat_params.keys() if layer_norm_name in ''.join(layer).lower()}\n        flat_mask = {path: path[-1] != 'bias' and path[-2:] not in layer_norm_named_params for path in flat_params}\n        return traverse_util.unflatten_dict(flat_mask)\n    adamw = optax.adamw(learning_rate=linear_decay_lr_schedule_fn, b1=training_args.adam_beta1, b2=training_args.adam_beta2, eps=training_args.adam_epsilon, weight_decay=training_args.weight_decay, mask=decay_mask_fn)\n    state = TrainState.create(apply_fn=model.__call__, params=model.params, tx=adamw, dropout_rng=dropout_rng)\n\n    def loss_fn(logits, labels, padding_mask, label_smoothing_factor=0.0):\n        \"\"\"\n        The label smoothing implementation is adapted from Flax's official example:\n        https://github.com/google/flax/blob/87a211135c6a377c8f29048a1cac3840e38b9da4/examples/wmt/train.py#L104\n        \"\"\"\n        vocab_size = logits.shape[-1]\n        confidence = 1.0 - label_smoothing_factor\n        low_confidence = (1.0 - confidence) / (vocab_size - 1)\n        normalizing_constant = -(confidence * jnp.log(confidence) + (vocab_size - 1) * low_confidence * jnp.log(low_confidence + 1e-20))\n        soft_labels = onehot(labels, vocab_size, on_value=confidence, off_value=low_confidence)\n        loss = optax.softmax_cross_entropy(logits, soft_labels)\n        loss = loss - normalizing_constant\n        loss = loss * padding_mask\n        loss = loss.sum()\n        num_labels = padding_mask.sum()\n        return (loss, num_labels)\n\n    def train_step(state, batch, label_smoothing_factor=0.0):\n        (dropout_rng, new_dropout_rng) = jax.random.split(state.dropout_rng)\n\n        def compute_loss(params):\n            labels = batch.pop('labels')\n            logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n            (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n            return (loss, num_labels)\n        grad_fn = jax.value_and_grad(compute_loss, has_aux=True)\n        ((loss, num_labels), grad) = grad_fn(state.params)\n        num_labels = jax.lax.psum(num_labels, 'batch')\n        loss = jax.lax.psum(loss, 'batch')\n        loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n        grad = jax.lax.psum(grad, 'batch')\n        grad = jax.tree_util.tree_map(lambda x: x / num_labels, grad)\n        new_state = state.apply_gradients(grads=grad, dropout_rng=new_dropout_rng)\n        metrics = {'loss': loss, 'learning_rate': linear_decay_lr_schedule_fn(state.step)}\n        return (new_state, metrics)\n\n    def eval_step(params, batch, label_smoothing_factor=0.0):\n        labels = batch.pop('labels')\n        logits = model(**batch, params=params, train=False)[0]\n        (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n        num_labels = jax.lax.psum(num_labels, 'batch')\n        loss = jax.lax.psum(loss, 'batch')\n        loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n        metrics = {'loss': loss}\n        return metrics\n    max_length = data_args.val_max_target_length if data_args.val_max_target_length is not None else model.config.max_length\n    num_beams = data_args.num_beams if data_args.num_beams is not None else model.config.num_beams\n    gen_kwargs = {'max_length': max_length, 'num_beams': num_beams}\n\n    def generate_step(params, batch):\n        model.params = params\n        output_ids = model.generate(batch['pixel_values'], **gen_kwargs)\n        return output_ids.sequences\n    p_train_step = jax.pmap(partial(train_step, label_smoothing_factor=training_args.label_smoothing_factor), 'batch', donate_argnums=(0,))\n    p_eval_step = jax.pmap(partial(eval_step, label_smoothing_factor=training_args.label_smoothing_factor), 'batch')\n    p_generate_step = jax.pmap(generate_step, 'batch')\n    state = state.replicate()\n    if training_args.do_train:\n        logger.info('***** Running training *****')\n        logger.info(f'  Num train examples = {num_train_examples_per_epoch}')\n        logger.info(f'  Num Epochs = {num_epochs}')\n        logger.info(f'  Instantaneous train batch size per device = {training_args.per_device_train_batch_size}')\n        logger.info(f'  Total train batch size (w. parallel & distributed) = {train_batch_size}')\n        logger.info(f'  Optimization steps per epoch = {steps_per_epoch}')\n        logger.info(f'  Total optimization steps = {total_train_steps}')\n    if training_args.do_eval:\n        logger.info(f'  Num evaluation examples = {num_eval_examples}')\n        logger.info(f'  Instantaneous evaluation batch size per device = {training_args.per_device_eval_batch_size}')\n        logger.info(f'  Total evaluation batch size (w. parallel & distributed) = {eval_batch_size}')\n        logger.info(f'  Evaluation steps = {eval_steps}')\n    if training_args.do_predict:\n        logger.info(f'  Num test examples = {num_test_examples}')\n        logger.info(f'  Instantaneous test batch size per device = {training_args.per_device_eval_batch_size}')\n        logger.info(f'  Total test batch size (w. parallel & distributed) = {eval_batch_size}')\n        logger.info(f'  Test steps = {test_steps}')\n    if not os.path.isdir(os.path.join(training_args.output_dir)):\n        os.makedirs(os.path.join(training_args.output_dir), exist_ok=True)\n\n    def save_ckpt(ckpt_dir: str, commit_msg: str=''):\n        \"\"\"save checkpoints and push to Hugging Face Hub if specified\"\"\"\n        if jax.process_index() == 0:\n            params = jax.device_get(jax.tree_util.tree_map(lambda x: x[0], state.params))\n            model.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir), params=params)\n            tokenizer.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir))\n            if training_args.push_to_hub:\n                repo.push_to_hub(commit_message=commit_msg, blocking=False)\n\n    def evaluation_loop(rng: jax.random.PRNGKey, dataset: Dataset, metric_key_prefix: str='eval', ckpt_dir: str='', is_prediction=False):\n        logger.info(f\"*** {('Predict' if is_prediction else 'Evaluate')} ***\")\n        metrics = []\n        preds = []\n        labels = []\n        batches = blockwise_data_loader(rng, dataset, block_size=training_args.block_size, batch_size=eval_batch_size, keep_in_memory=False, shuffle=False, split='prediction' if is_prediction else 'validation')\n        steps = len(dataset) // eval_batch_size\n        for _ in tqdm(range(steps), desc=f\"{('Predicting' if is_prediction else 'Evaluating')}...\", position=2, leave=False):\n            batch = next(batches)\n            _labels = batch.get('labels', None)\n            if not is_prediction and _labels is None:\n                raise ValueError('Evaluation requires the validation dataset to have `labels`')\n            if _labels is not None:\n                _metrics = p_eval_step(state.params, batch)\n                metrics.append(_metrics)\n            if data_args.predict_with_generate:\n                generated_ids = p_generate_step(state.params, batch)\n                preds.extend(jax.device_get(generated_ids.reshape(-1, gen_kwargs['max_length'])))\n                if _labels is not None:\n                    labels.extend(jax.device_get(_labels.reshape(-1, _labels.shape[-1])))\n        if metrics:\n            metrics = get_metrics(metrics)\n            metrics = jax.tree_util.tree_map(jnp.mean, metrics)\n        generations = []\n        rouge_desc = ''\n        if data_args.predict_with_generate:\n            if labels:\n                (rouge_metrics, decoded_preds, decoded_labels) = compute_metrics(preds, labels)\n                metrics.update(rouge_metrics)\n                rouge_desc = ' '.join([f\"{('Predict' if is_prediction else 'Eval')} {key}: {value} |\" for (key, value) in rouge_metrics.items()])\n                for (pred, label) in zip(decoded_preds, decoded_labels):\n                    pred = pred.replace('\\n', ' ')\n                    label = label.replace('\\n', ' ')\n                    generations.append({'label': label, 'pred': pred})\n            else:\n                decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n                decoded_preds = [pred.strip() for pred in decoded_preds]\n                decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in decoded_preds]\n                for pred in decoded_preds:\n                    pred = pred.replace('\\n', ' ')\n                    generations.append({'pred': pred})\n        if metrics:\n            desc = f\"{('Predict' if is_prediction else 'Eval')} Loss: {metrics['loss']} | {rouge_desc})\"\n            if training_args.do_train and (not is_prediction):\n                desc = f'Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | ' + desc\n                epochs.write(desc)\n                epochs.desc = desc\n            logger.info(desc)\n        if jax.process_index() == 0:\n            if not os.path.isdir(os.path.join(training_args.output_dir, ckpt_dir)):\n                os.makedirs(os.path.join(training_args.output_dir, ckpt_dir), exist_ok=True)\n            if metrics:\n                if has_tensorboard and training_args.do_train:\n                    write_metric(summary_writer, metrics, train_time=None, step=cur_step, metric_key_prefix=metric_key_prefix)\n                metrics = {f'{metric_key_prefix}_{metric_name}': round(value.item(), 6) for (metric_name, value) in metrics.items()}\n                _path = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_results.json')\n                with open(_path, 'w') as f:\n                    json.dump(metrics, f, indent=4, sort_keys=True)\n                with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                    fp.write(desc + '\\n')\n            if generations:\n                output_file = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_generation.json')\n                with open(output_file, 'w', encoding='UTF-8') as fp:\n                    json.dump(generations, fp, ensure_ascii=False, indent=4)\n\n    def evaluate(rng: jax.random.PRNGKey, dataset: Dataset, ckpt_dir: str=''):\n        evaluation_loop(rng, dataset, metric_key_prefix='eval', ckpt_dir=ckpt_dir)\n\n    def predict(rng: jax.random.PRNGKey, dataset: Dataset):\n        evaluation_loop(rng, dataset, metric_key_prefix='test', is_prediction=True)\n    input_rng = None\n    if training_args.do_train:\n        cur_step = 0\n        train_time = 0\n        epochs = tqdm(range(num_epochs), desc=f'Epoch ... (1/{num_epochs})', position=0)\n        for epoch in epochs:\n            (rng, input_rng) = jax.random.split(rng)\n            train_metrics = []\n            train_batches = blockwise_data_loader(input_rng, train_dataset, block_size=training_args.block_size, batch_size=train_batch_size, keep_in_memory=True, shuffle=True, split='train')\n            for (batch_idx, _) in enumerate(tqdm(range(steps_per_epoch), desc='Training...', position=1, leave=False)):\n                cur_step += 1\n                batch = next(train_batches)\n                batch_start = time.time()\n                (state, train_metric) = p_train_step(state, batch)\n                train_metrics.append(train_metric)\n                train_time += time.time() - batch_start\n                time_per_step = train_time / cur_step\n                if training_args.logging_steps > 0 and cur_step % training_args.logging_steps == 0:\n                    _train_metric = unreplicate(train_metric)\n                    desc = f\"Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | Loss: {_train_metric['loss']} | Learning Rate: {_train_metric['learning_rate']} | Time per step: {time_per_step})\"\n                    epochs.desc = desc\n                    epochs.write(desc)\n                    logger.info(desc)\n                    with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                        fp.write(desc + '\\n')\n                    if has_tensorboard and jax.process_index() == 0:\n                        write_metric(summary_writer, train_metrics, train_time=train_time, step=cur_step, metric_key_prefix='train')\n                if training_args.do_eval and (training_args.eval_steps is not None and training_args.eval_steps > 0) and (cur_step % training_args.eval_steps == 0):\n                    ckpt_dir = f'ckpt_epoch_{epoch + 1}_step_{cur_step}'\n                    commit_msg = f'Saving weights and logs of epoch {epoch + 1} - step {cur_step}'\n                    evaluate(input_rng, eval_dataset, ckpt_dir)\n                    save_ckpt(ckpt_dir=ckpt_dir, commit_msg=commit_msg)\n            if training_args.logging_steps <= 0:\n                logger.info(desc)\n                with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                    fp.write(desc + '\\n')\n                if has_tensorboard and jax.process_index() == 0:\n                    write_metric(summary_writer, train_metrics, train_time=train_time, step=cur_step, metric_key_prefix='train')\n            if training_args.do_eval and (training_args.eval_steps is None or training_args.eval_steps <= 0):\n                ckpt_dir = f'ckpt_epoch_{epoch + 1}_step_{cur_step}'\n                commit_msg = f'Saving weights and logs of epoch {epoch + 1} - step {cur_step}'\n                evaluate(input_rng, eval_dataset, ckpt_dir)\n                save_ckpt(ckpt_dir=ckpt_dir, commit_msg=commit_msg)\n    if input_rng is None:\n        (rng, input_rng) = jax.random.split(rng)\n    if training_args.do_eval and (not training_args.do_train):\n        evaluate(input_rng, eval_dataset)\n    if training_args.do_predict:\n        predict(input_rng, predict_dataset)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n    if len(sys.argv) == 2 and sys.argv[1].endswith('.json'):\n        (model_args, data_args, training_args) = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n    else:\n        (model_args, data_args, training_args) = parser.parse_args_into_dataclasses()\n    if model_args.use_auth_token is not None:\n        warnings.warn('The `use_auth_token` argument is deprecated and will be removed in v4.34. Please use `token` instead.', FutureWarning)\n        if model_args.token is not None:\n            raise ValueError('`token` and `use_auth_token` are both specified. Please set only the argument `token`.')\n        model_args.token = model_args.use_auth_token\n    send_example_telemetry('run_image_captioning', model_args, data_args, framework='flax')\n    if os.path.exists(training_args.output_dir) and os.listdir(training_args.output_dir) and training_args.do_train and (not training_args.overwrite_output_dir):\n        raise ValueError(f'Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.')\n    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s', datefmt='%m/%d/%Y %H:%M:%S', level=logging.INFO)\n    logger.setLevel(logging.INFO if jax.process_index() == 0 else logging.ERROR)\n    if jax.process_index() == 0:\n        datasets.utils.logging.set_verbosity_warning()\n        transformers.utils.logging.set_verbosity_info()\n    else:\n        datasets.utils.logging.set_verbosity_error()\n        transformers.utils.logging.set_verbosity_error()\n    logger.info(f'Training/evaluation parameters {training_args}')\n    if training_args.push_to_hub:\n        repo_name = training_args.hub_model_id\n        if repo_name is None:\n            repo_name = Path(training_args.output_dir).absolute().name\n        repo_id = create_repo(repo_name, exist_ok=True, token=training_args.hub_token).repo_id\n        repo = Repository(training_args.output_dir, clone_from=repo_id, token=training_args.hub_token)\n    if data_args.dataset_name is not None:\n        dataset = load_dataset(data_args.dataset_name, data_args.dataset_config_name, cache_dir=model_args.cache_dir, keep_in_memory=False, data_dir=data_args.data_dir, token=model_args.token)\n    else:\n        data_files = {}\n        if data_args.train_file is not None:\n            data_files['train'] = data_args.train_file\n            extension = data_args.train_file.split('.')[-1]\n        if data_args.validation_file is not None:\n            data_files['validation'] = data_args.validation_file\n            extension = data_args.validation_file.split('.')[-1]\n        if data_args.test_file is not None:\n            data_files['test'] = data_args.test_file\n            extension = data_args.test_file.split('.')[-1]\n        dataset = load_dataset(extension, data_files=data_files, cache_dir=model_args.cache_dir, token=model_args.token)\n    model = FlaxVisionEncoderDecoderModel.from_pretrained(model_args.model_name_or_path, seed=training_args.seed, dtype=getattr(jnp, model_args.dtype), token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    image_processor = AutoImageProcessor.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir, token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    tokenizer = AutoTokenizer.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir, use_fast=model_args.use_fast_tokenizer, token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    tokenizer.pad_token = tokenizer.convert_ids_to_tokens(model.config.pad_token_id)\n    if training_args.do_train:\n        column_names = dataset['train'].column_names\n    elif training_args.do_eval:\n        column_names = dataset['validation'].column_names\n    elif training_args.do_predict:\n        column_names = dataset['test'].column_names\n    else:\n        logger.info('There is nothing to do. Please pass `do_train`, `do_eval` and/or `do_predict`.')\n        return\n    dataset_columns = image_captioning_name_mapping.get(data_args.dataset_name, None)\n    if data_args.image_column is None:\n        if dataset_columns is None:\n            raise ValueError(f\"`--dataset_name` {data_args.dataset_name} not found in dataset '{data_args.dataset_name}'. Make sure to set `--dataset_name` to the correct dataset name, one of {', '.join(image_captioning_name_mapping.keys())}.\")\n        image_column = dataset_columns[0]\n    else:\n        image_column = data_args.image_column\n        if image_column not in column_names:\n            raise ValueError(f\"--image_column' value '{data_args.image_column}' needs to be one of: {', '.join(column_names)}\")\n    if data_args.caption_column is None:\n        if dataset_columns is None:\n            raise ValueError(f\"`--dataset_name` {data_args.dataset_name} not found in dataset '{data_args.dataset_name}'. Make sure to set `--dataset_name` to the correct dataset name, one of {', '.join(image_captioning_name_mapping.keys())}.\")\n        caption_column = dataset_columns[1]\n    else:\n        caption_column = data_args.caption_column\n        if caption_column not in column_names:\n            raise ValueError(f\"--caption_column' value '{data_args.caption_column}' needs to be one of: {', '.join(column_names)}\")\n    model_module = __import__(model.__module__, fromlist=['shift_tokens_right'])\n    shift_tokens_right_fn = getattr(model_module, 'shift_tokens_right', shift_tokens_right)\n\n    def filter_fn(examples):\n        \"\"\"remove problematic images\"\"\"\n        bools = []\n        for image_file in examples[image_column]:\n            try:\n                image = Image.open(image_file)\n                image_processor(images=image, return_tensors='np')\n                bools.append(True)\n            except Exception:\n                bools.append(False)\n        return bools\n\n    def tokenization_fn(examples, max_target_length):\n        \"\"\"Run tokenization on captions.\"\"\"\n        captions = []\n        for caption in examples[caption_column]:\n            captions.append(caption.lower() + ' ' + tokenizer.eos_token)\n        targets = captions\n        model_inputs = {}\n        labels = tokenizer(text_target=targets, max_length=max_target_length, padding='max_length', truncation=True, return_tensors='np')\n        model_inputs['labels'] = labels['input_ids']\n        decoder_input_ids = shift_tokens_right_fn(labels['input_ids'], model.config.pad_token_id, model.config.decoder_start_token_id)\n        model_inputs['decoder_input_ids'] = np.asarray(decoder_input_ids)\n        model_inputs['decoder_attention_mask'] = labels['attention_mask']\n        model_inputs[image_column] = examples[image_column]\n        return model_inputs\n\n    def image_processing_fn(examples, check_image=True):\n        \"\"\"\n        Run preprocessing on images\n\n        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\n        Otherwise, an exception will be thrown.\n        \"\"\"\n        model_inputs = {}\n        if check_image:\n            images = []\n            to_keep = []\n            for image_file in examples[image_column]:\n                try:\n                    img = Image.open(image_file)\n                    images.append(img)\n                    to_keep.append(True)\n                except Exception:\n                    to_keep.append(False)\n            for (k, v) in examples.items():\n                if k != image_column:\n                    model_inputs[k] = v[to_keep]\n        else:\n            images = [Image.open(image_file) for image_file in examples[image_column]]\n        encoder_inputs = image_processor(images=images, return_tensors='np')\n        model_inputs['pixel_values'] = encoder_inputs.pixel_values\n        return model_inputs\n\n    def preprocess_fn(examples, max_target_length, check_image=True):\n        \"\"\"Run tokenization + image processing\"\"\"\n        model_inputs = {}\n        model_inputs.update(tokenization_fn(examples, max_target_length))\n        model_inputs.update(image_processing_fn(model_inputs, check_image=check_image))\n        model_inputs.pop(image_column)\n        return model_inputs\n    features = datasets.Features({'pixel_values': datasets.Array3D(shape=(getattr(model.config.encoder, 'num_channels', 3), model.config.encoder.image_size, model.config.encoder.image_size), dtype='float32'), 'labels': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None), 'decoder_input_ids': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None), 'decoder_attention_mask': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None)})\n    run_img_proc_at_beginning = training_args.block_size == 0\n    function_kwarg = preprocess_fn if run_img_proc_at_beginning else tokenization_fn\n    features_kwarg = features if run_img_proc_at_beginning else None\n    remove_columns_kwarg = [x for x in column_names if x != image_column or run_img_proc_at_beginning]\n    processor_names = 'tokenizer and image processor' if run_img_proc_at_beginning else 'tokenizer'\n    train_batch_size = int(training_args.per_device_train_batch_size) * jax.device_count()\n    eval_batch_size = int(training_args.per_device_eval_batch_size) * jax.device_count()\n    if training_args.block_size % train_batch_size > 0 or training_args.block_size % eval_batch_size > 0:\n        raise ValueError(f'`training_args.block_size` needs to be a multiple of the global train/eval batch size. Got {training_args.block_size}, {train_batch_size} and {eval_batch_size} respectively instead.')\n    if training_args.do_train:\n        if 'train' not in dataset:\n            raise ValueError('--do_train requires a train dataset')\n        train_dataset = dataset['train']\n        if data_args.max_train_samples is not None:\n            max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n            train_dataset = train_dataset.select(range(max_train_samples))\n        if not run_img_proc_at_beginning:\n            train_dataset = train_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        train_dataset = train_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on train dataset', fn_kwargs={'max_target_length': data_args.max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            train_dataset = train_dataset.with_format('numpy')\n        steps_per_epoch = len(train_dataset) // train_batch_size\n        num_train_examples_per_epoch = steps_per_epoch * train_batch_size\n        num_epochs = int(training_args.num_train_epochs)\n        total_train_steps = steps_per_epoch * num_epochs\n    else:\n        num_train_examples_per_epoch = 0\n    if training_args.do_eval:\n        if 'validation' not in dataset:\n            raise ValueError('--do_eval requires a validation dataset')\n        eval_dataset = dataset['validation']\n        if data_args.max_eval_samples is not None:\n            max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n            eval_dataset = eval_dataset.select(range(max_eval_samples))\n        if not run_img_proc_at_beginning:\n            eval_dataset = eval_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        eval_dataset = eval_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on validation dataset', fn_kwargs={'max_target_length': data_args.val_max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            eval_dataset = eval_dataset.with_format('numpy')\n        num_eval_examples = len(eval_dataset)\n        eval_steps = num_eval_examples // eval_batch_size\n    if training_args.do_predict:\n        if 'test' not in dataset:\n            raise ValueError('--do_predict requires a test dataset')\n        predict_dataset = dataset['test']\n        if data_args.max_predict_samples is not None:\n            max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)\n            predict_dataset = predict_dataset.select(range(max_predict_samples))\n        if not run_img_proc_at_beginning:\n            predict_dataset = predict_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        predict_dataset = predict_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on prediction dataset', fn_kwargs={'max_target_length': data_args.val_max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            predict_dataset = predict_dataset.with_format('numpy')\n        num_test_examples = len(predict_dataset)\n        test_steps = num_test_examples // eval_batch_size\n\n    def blockwise_data_loader(rng: jax.random.PRNGKey, ds: Dataset, block_size: int, batch_size: int, shuffle: bool=False, keep_in_memory: bool=False, split: str=''):\n        \"\"\"\n        Wrap the simple `data_loader` in a block-wise way if `block_size` > 0, else it's the same as `data_loader`.\n\n        If `block_size` > 0, it requires `ds` to have a column that gives image paths in order to perform image\n        processing (with the column name being specified by `image_column`). The tokenization should be done before\n        training in this case.\n        \"\"\"\n        if shuffle:\n            indices = jax.random.permutation(rng, len(ds))\n            indices = np.asarray(indices)\n        else:\n            indices = np.arange(len(ds))\n        _block_size = len(ds) if not block_size else block_size\n        steps_per_block = _block_size // batch_size\n        num_examples = len(ds)\n        steps = num_examples // batch_size\n        num_splits = steps // steps_per_block + int(steps % steps_per_block > 0)\n        for idx in range(num_splits):\n            if not block_size:\n                _ds = ds\n            else:\n                start_idx = block_size * idx\n                end_idx = block_size * (idx + 1)\n                selected_indices = indices[start_idx:end_idx]\n                _ds = ds.select(selected_indices)\n                _ds = _ds.map(image_processing_fn, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=[image_column], load_from_cache_file=not data_args.overwrite_cache, features=features, keep_in_memory=keep_in_memory, fn_kwargs={'check_image': False}, desc=f'Running image processing on {split} dataset'.replace('  ', ' '))\n                _ds = _ds.with_format('numpy')\n            loader = data_loader(rng, _ds, batch_size=batch_size, shuffle=False)\n            for batch in loader:\n                yield batch\n    metric = evaluate.load('rouge')\n\n    def postprocess_text(preds, labels):\n        preds = [pred.strip() for pred in preds]\n        labels = [label.strip() for label in labels]\n        preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in preds]\n        labels = ['\\n'.join(nltk.sent_tokenize(label)) for label in labels]\n        return (preds, labels)\n\n    def compute_metrics(preds, labels):\n        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n        (decoded_preds, decoded_labels) = postprocess_text(decoded_preds, decoded_labels)\n        result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n        result = {key: value.mid.fmeasure * 100 for (key, value) in result.items()}\n        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n        result['gen_len'] = np.mean(prediction_lens)\n        result = {k: round(v, 6) for (k, v) in result.items()}\n        return (result, decoded_preds, decoded_labels)\n    has_tensorboard = is_tensorboard_available()\n    if has_tensorboard and jax.process_index() == 0:\n        try:\n            from flax.metrics.tensorboard import SummaryWriter\n            summary_writer = SummaryWriter(log_dir=Path(training_args.output_dir))\n        except ImportError as ie:\n            has_tensorboard = False\n            logger.warning(f'Unable to display metrics through TensorBoard because some package are not installed: {ie}')\n    else:\n        logger.warning('Unable to display metrics through TensorBoard because the package is not installed: Please run pip install tensorboard to enable.')\n    rng = jax.random.PRNGKey(training_args.seed)\n    (rng, dropout_rng) = jax.random.split(rng)\n    linear_decay_lr_schedule_fn = create_learning_rate_fn(num_train_examples_per_epoch, train_batch_size, training_args.num_train_epochs, training_args.warmup_steps, training_args.learning_rate)\n\n    def decay_mask_fn(params):\n        flat_params = traverse_util.flatten_dict(params)\n        layer_norm_candidates = ['layernorm', 'layer_norm', 'ln']\n        layer_norm_named_params = {layer[-2:] for layer_norm_name in layer_norm_candidates for layer in flat_params.keys() if layer_norm_name in ''.join(layer).lower()}\n        flat_mask = {path: path[-1] != 'bias' and path[-2:] not in layer_norm_named_params for path in flat_params}\n        return traverse_util.unflatten_dict(flat_mask)\n    adamw = optax.adamw(learning_rate=linear_decay_lr_schedule_fn, b1=training_args.adam_beta1, b2=training_args.adam_beta2, eps=training_args.adam_epsilon, weight_decay=training_args.weight_decay, mask=decay_mask_fn)\n    state = TrainState.create(apply_fn=model.__call__, params=model.params, tx=adamw, dropout_rng=dropout_rng)\n\n    def loss_fn(logits, labels, padding_mask, label_smoothing_factor=0.0):\n        \"\"\"\n        The label smoothing implementation is adapted from Flax's official example:\n        https://github.com/google/flax/blob/87a211135c6a377c8f29048a1cac3840e38b9da4/examples/wmt/train.py#L104\n        \"\"\"\n        vocab_size = logits.shape[-1]\n        confidence = 1.0 - label_smoothing_factor\n        low_confidence = (1.0 - confidence) / (vocab_size - 1)\n        normalizing_constant = -(confidence * jnp.log(confidence) + (vocab_size - 1) * low_confidence * jnp.log(low_confidence + 1e-20))\n        soft_labels = onehot(labels, vocab_size, on_value=confidence, off_value=low_confidence)\n        loss = optax.softmax_cross_entropy(logits, soft_labels)\n        loss = loss - normalizing_constant\n        loss = loss * padding_mask\n        loss = loss.sum()\n        num_labels = padding_mask.sum()\n        return (loss, num_labels)\n\n    def train_step(state, batch, label_smoothing_factor=0.0):\n        (dropout_rng, new_dropout_rng) = jax.random.split(state.dropout_rng)\n\n        def compute_loss(params):\n            labels = batch.pop('labels')\n            logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n            (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n            return (loss, num_labels)\n        grad_fn = jax.value_and_grad(compute_loss, has_aux=True)\n        ((loss, num_labels), grad) = grad_fn(state.params)\n        num_labels = jax.lax.psum(num_labels, 'batch')\n        loss = jax.lax.psum(loss, 'batch')\n        loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n        grad = jax.lax.psum(grad, 'batch')\n        grad = jax.tree_util.tree_map(lambda x: x / num_labels, grad)\n        new_state = state.apply_gradients(grads=grad, dropout_rng=new_dropout_rng)\n        metrics = {'loss': loss, 'learning_rate': linear_decay_lr_schedule_fn(state.step)}\n        return (new_state, metrics)\n\n    def eval_step(params, batch, label_smoothing_factor=0.0):\n        labels = batch.pop('labels')\n        logits = model(**batch, params=params, train=False)[0]\n        (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n        num_labels = jax.lax.psum(num_labels, 'batch')\n        loss = jax.lax.psum(loss, 'batch')\n        loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n        metrics = {'loss': loss}\n        return metrics\n    max_length = data_args.val_max_target_length if data_args.val_max_target_length is not None else model.config.max_length\n    num_beams = data_args.num_beams if data_args.num_beams is not None else model.config.num_beams\n    gen_kwargs = {'max_length': max_length, 'num_beams': num_beams}\n\n    def generate_step(params, batch):\n        model.params = params\n        output_ids = model.generate(batch['pixel_values'], **gen_kwargs)\n        return output_ids.sequences\n    p_train_step = jax.pmap(partial(train_step, label_smoothing_factor=training_args.label_smoothing_factor), 'batch', donate_argnums=(0,))\n    p_eval_step = jax.pmap(partial(eval_step, label_smoothing_factor=training_args.label_smoothing_factor), 'batch')\n    p_generate_step = jax.pmap(generate_step, 'batch')\n    state = state.replicate()\n    if training_args.do_train:\n        logger.info('***** Running training *****')\n        logger.info(f'  Num train examples = {num_train_examples_per_epoch}')\n        logger.info(f'  Num Epochs = {num_epochs}')\n        logger.info(f'  Instantaneous train batch size per device = {training_args.per_device_train_batch_size}')\n        logger.info(f'  Total train batch size (w. parallel & distributed) = {train_batch_size}')\n        logger.info(f'  Optimization steps per epoch = {steps_per_epoch}')\n        logger.info(f'  Total optimization steps = {total_train_steps}')\n    if training_args.do_eval:\n        logger.info(f'  Num evaluation examples = {num_eval_examples}')\n        logger.info(f'  Instantaneous evaluation batch size per device = {training_args.per_device_eval_batch_size}')\n        logger.info(f'  Total evaluation batch size (w. parallel & distributed) = {eval_batch_size}')\n        logger.info(f'  Evaluation steps = {eval_steps}')\n    if training_args.do_predict:\n        logger.info(f'  Num test examples = {num_test_examples}')\n        logger.info(f'  Instantaneous test batch size per device = {training_args.per_device_eval_batch_size}')\n        logger.info(f'  Total test batch size (w. parallel & distributed) = {eval_batch_size}')\n        logger.info(f'  Test steps = {test_steps}')\n    if not os.path.isdir(os.path.join(training_args.output_dir)):\n        os.makedirs(os.path.join(training_args.output_dir), exist_ok=True)\n\n    def save_ckpt(ckpt_dir: str, commit_msg: str=''):\n        \"\"\"save checkpoints and push to Hugging Face Hub if specified\"\"\"\n        if jax.process_index() == 0:\n            params = jax.device_get(jax.tree_util.tree_map(lambda x: x[0], state.params))\n            model.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir), params=params)\n            tokenizer.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir))\n            if training_args.push_to_hub:\n                repo.push_to_hub(commit_message=commit_msg, blocking=False)\n\n    def evaluation_loop(rng: jax.random.PRNGKey, dataset: Dataset, metric_key_prefix: str='eval', ckpt_dir: str='', is_prediction=False):\n        logger.info(f\"*** {('Predict' if is_prediction else 'Evaluate')} ***\")\n        metrics = []\n        preds = []\n        labels = []\n        batches = blockwise_data_loader(rng, dataset, block_size=training_args.block_size, batch_size=eval_batch_size, keep_in_memory=False, shuffle=False, split='prediction' if is_prediction else 'validation')\n        steps = len(dataset) // eval_batch_size\n        for _ in tqdm(range(steps), desc=f\"{('Predicting' if is_prediction else 'Evaluating')}...\", position=2, leave=False):\n            batch = next(batches)\n            _labels = batch.get('labels', None)\n            if not is_prediction and _labels is None:\n                raise ValueError('Evaluation requires the validation dataset to have `labels`')\n            if _labels is not None:\n                _metrics = p_eval_step(state.params, batch)\n                metrics.append(_metrics)\n            if data_args.predict_with_generate:\n                generated_ids = p_generate_step(state.params, batch)\n                preds.extend(jax.device_get(generated_ids.reshape(-1, gen_kwargs['max_length'])))\n                if _labels is not None:\n                    labels.extend(jax.device_get(_labels.reshape(-1, _labels.shape[-1])))\n        if metrics:\n            metrics = get_metrics(metrics)\n            metrics = jax.tree_util.tree_map(jnp.mean, metrics)\n        generations = []\n        rouge_desc = ''\n        if data_args.predict_with_generate:\n            if labels:\n                (rouge_metrics, decoded_preds, decoded_labels) = compute_metrics(preds, labels)\n                metrics.update(rouge_metrics)\n                rouge_desc = ' '.join([f\"{('Predict' if is_prediction else 'Eval')} {key}: {value} |\" for (key, value) in rouge_metrics.items()])\n                for (pred, label) in zip(decoded_preds, decoded_labels):\n                    pred = pred.replace('\\n', ' ')\n                    label = label.replace('\\n', ' ')\n                    generations.append({'label': label, 'pred': pred})\n            else:\n                decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n                decoded_preds = [pred.strip() for pred in decoded_preds]\n                decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in decoded_preds]\n                for pred in decoded_preds:\n                    pred = pred.replace('\\n', ' ')\n                    generations.append({'pred': pred})\n        if metrics:\n            desc = f\"{('Predict' if is_prediction else 'Eval')} Loss: {metrics['loss']} | {rouge_desc})\"\n            if training_args.do_train and (not is_prediction):\n                desc = f'Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | ' + desc\n                epochs.write(desc)\n                epochs.desc = desc\n            logger.info(desc)\n        if jax.process_index() == 0:\n            if not os.path.isdir(os.path.join(training_args.output_dir, ckpt_dir)):\n                os.makedirs(os.path.join(training_args.output_dir, ckpt_dir), exist_ok=True)\n            if metrics:\n                if has_tensorboard and training_args.do_train:\n                    write_metric(summary_writer, metrics, train_time=None, step=cur_step, metric_key_prefix=metric_key_prefix)\n                metrics = {f'{metric_key_prefix}_{metric_name}': round(value.item(), 6) for (metric_name, value) in metrics.items()}\n                _path = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_results.json')\n                with open(_path, 'w') as f:\n                    json.dump(metrics, f, indent=4, sort_keys=True)\n                with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                    fp.write(desc + '\\n')\n            if generations:\n                output_file = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_generation.json')\n                with open(output_file, 'w', encoding='UTF-8') as fp:\n                    json.dump(generations, fp, ensure_ascii=False, indent=4)\n\n    def evaluate(rng: jax.random.PRNGKey, dataset: Dataset, ckpt_dir: str=''):\n        evaluation_loop(rng, dataset, metric_key_prefix='eval', ckpt_dir=ckpt_dir)\n\n    def predict(rng: jax.random.PRNGKey, dataset: Dataset):\n        evaluation_loop(rng, dataset, metric_key_prefix='test', is_prediction=True)\n    input_rng = None\n    if training_args.do_train:\n        cur_step = 0\n        train_time = 0\n        epochs = tqdm(range(num_epochs), desc=f'Epoch ... (1/{num_epochs})', position=0)\n        for epoch in epochs:\n            (rng, input_rng) = jax.random.split(rng)\n            train_metrics = []\n            train_batches = blockwise_data_loader(input_rng, train_dataset, block_size=training_args.block_size, batch_size=train_batch_size, keep_in_memory=True, shuffle=True, split='train')\n            for (batch_idx, _) in enumerate(tqdm(range(steps_per_epoch), desc='Training...', position=1, leave=False)):\n                cur_step += 1\n                batch = next(train_batches)\n                batch_start = time.time()\n                (state, train_metric) = p_train_step(state, batch)\n                train_metrics.append(train_metric)\n                train_time += time.time() - batch_start\n                time_per_step = train_time / cur_step\n                if training_args.logging_steps > 0 and cur_step % training_args.logging_steps == 0:\n                    _train_metric = unreplicate(train_metric)\n                    desc = f\"Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | Loss: {_train_metric['loss']} | Learning Rate: {_train_metric['learning_rate']} | Time per step: {time_per_step})\"\n                    epochs.desc = desc\n                    epochs.write(desc)\n                    logger.info(desc)\n                    with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                        fp.write(desc + '\\n')\n                    if has_tensorboard and jax.process_index() == 0:\n                        write_metric(summary_writer, train_metrics, train_time=train_time, step=cur_step, metric_key_prefix='train')\n                if training_args.do_eval and (training_args.eval_steps is not None and training_args.eval_steps > 0) and (cur_step % training_args.eval_steps == 0):\n                    ckpt_dir = f'ckpt_epoch_{epoch + 1}_step_{cur_step}'\n                    commit_msg = f'Saving weights and logs of epoch {epoch + 1} - step {cur_step}'\n                    evaluate(input_rng, eval_dataset, ckpt_dir)\n                    save_ckpt(ckpt_dir=ckpt_dir, commit_msg=commit_msg)\n            if training_args.logging_steps <= 0:\n                logger.info(desc)\n                with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                    fp.write(desc + '\\n')\n                if has_tensorboard and jax.process_index() == 0:\n                    write_metric(summary_writer, train_metrics, train_time=train_time, step=cur_step, metric_key_prefix='train')\n            if training_args.do_eval and (training_args.eval_steps is None or training_args.eval_steps <= 0):\n                ckpt_dir = f'ckpt_epoch_{epoch + 1}_step_{cur_step}'\n                commit_msg = f'Saving weights and logs of epoch {epoch + 1} - step {cur_step}'\n                evaluate(input_rng, eval_dataset, ckpt_dir)\n                save_ckpt(ckpt_dir=ckpt_dir, commit_msg=commit_msg)\n    if input_rng is None:\n        (rng, input_rng) = jax.random.split(rng)\n    if training_args.do_eval and (not training_args.do_train):\n        evaluate(input_rng, eval_dataset)\n    if training_args.do_predict:\n        predict(input_rng, predict_dataset)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n    if len(sys.argv) == 2 and sys.argv[1].endswith('.json'):\n        (model_args, data_args, training_args) = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n    else:\n        (model_args, data_args, training_args) = parser.parse_args_into_dataclasses()\n    if model_args.use_auth_token is not None:\n        warnings.warn('The `use_auth_token` argument is deprecated and will be removed in v4.34. Please use `token` instead.', FutureWarning)\n        if model_args.token is not None:\n            raise ValueError('`token` and `use_auth_token` are both specified. Please set only the argument `token`.')\n        model_args.token = model_args.use_auth_token\n    send_example_telemetry('run_image_captioning', model_args, data_args, framework='flax')\n    if os.path.exists(training_args.output_dir) and os.listdir(training_args.output_dir) and training_args.do_train and (not training_args.overwrite_output_dir):\n        raise ValueError(f'Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.')\n    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s', datefmt='%m/%d/%Y %H:%M:%S', level=logging.INFO)\n    logger.setLevel(logging.INFO if jax.process_index() == 0 else logging.ERROR)\n    if jax.process_index() == 0:\n        datasets.utils.logging.set_verbosity_warning()\n        transformers.utils.logging.set_verbosity_info()\n    else:\n        datasets.utils.logging.set_verbosity_error()\n        transformers.utils.logging.set_verbosity_error()\n    logger.info(f'Training/evaluation parameters {training_args}')\n    if training_args.push_to_hub:\n        repo_name = training_args.hub_model_id\n        if repo_name is None:\n            repo_name = Path(training_args.output_dir).absolute().name\n        repo_id = create_repo(repo_name, exist_ok=True, token=training_args.hub_token).repo_id\n        repo = Repository(training_args.output_dir, clone_from=repo_id, token=training_args.hub_token)\n    if data_args.dataset_name is not None:\n        dataset = load_dataset(data_args.dataset_name, data_args.dataset_config_name, cache_dir=model_args.cache_dir, keep_in_memory=False, data_dir=data_args.data_dir, token=model_args.token)\n    else:\n        data_files = {}\n        if data_args.train_file is not None:\n            data_files['train'] = data_args.train_file\n            extension = data_args.train_file.split('.')[-1]\n        if data_args.validation_file is not None:\n            data_files['validation'] = data_args.validation_file\n            extension = data_args.validation_file.split('.')[-1]\n        if data_args.test_file is not None:\n            data_files['test'] = data_args.test_file\n            extension = data_args.test_file.split('.')[-1]\n        dataset = load_dataset(extension, data_files=data_files, cache_dir=model_args.cache_dir, token=model_args.token)\n    model = FlaxVisionEncoderDecoderModel.from_pretrained(model_args.model_name_or_path, seed=training_args.seed, dtype=getattr(jnp, model_args.dtype), token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    image_processor = AutoImageProcessor.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir, token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    tokenizer = AutoTokenizer.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir, use_fast=model_args.use_fast_tokenizer, token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    tokenizer.pad_token = tokenizer.convert_ids_to_tokens(model.config.pad_token_id)\n    if training_args.do_train:\n        column_names = dataset['train'].column_names\n    elif training_args.do_eval:\n        column_names = dataset['validation'].column_names\n    elif training_args.do_predict:\n        column_names = dataset['test'].column_names\n    else:\n        logger.info('There is nothing to do. Please pass `do_train`, `do_eval` and/or `do_predict`.')\n        return\n    dataset_columns = image_captioning_name_mapping.get(data_args.dataset_name, None)\n    if data_args.image_column is None:\n        if dataset_columns is None:\n            raise ValueError(f\"`--dataset_name` {data_args.dataset_name} not found in dataset '{data_args.dataset_name}'. Make sure to set `--dataset_name` to the correct dataset name, one of {', '.join(image_captioning_name_mapping.keys())}.\")\n        image_column = dataset_columns[0]\n    else:\n        image_column = data_args.image_column\n        if image_column not in column_names:\n            raise ValueError(f\"--image_column' value '{data_args.image_column}' needs to be one of: {', '.join(column_names)}\")\n    if data_args.caption_column is None:\n        if dataset_columns is None:\n            raise ValueError(f\"`--dataset_name` {data_args.dataset_name} not found in dataset '{data_args.dataset_name}'. Make sure to set `--dataset_name` to the correct dataset name, one of {', '.join(image_captioning_name_mapping.keys())}.\")\n        caption_column = dataset_columns[1]\n    else:\n        caption_column = data_args.caption_column\n        if caption_column not in column_names:\n            raise ValueError(f\"--caption_column' value '{data_args.caption_column}' needs to be one of: {', '.join(column_names)}\")\n    model_module = __import__(model.__module__, fromlist=['shift_tokens_right'])\n    shift_tokens_right_fn = getattr(model_module, 'shift_tokens_right', shift_tokens_right)\n\n    def filter_fn(examples):\n        \"\"\"remove problematic images\"\"\"\n        bools = []\n        for image_file in examples[image_column]:\n            try:\n                image = Image.open(image_file)\n                image_processor(images=image, return_tensors='np')\n                bools.append(True)\n            except Exception:\n                bools.append(False)\n        return bools\n\n    def tokenization_fn(examples, max_target_length):\n        \"\"\"Run tokenization on captions.\"\"\"\n        captions = []\n        for caption in examples[caption_column]:\n            captions.append(caption.lower() + ' ' + tokenizer.eos_token)\n        targets = captions\n        model_inputs = {}\n        labels = tokenizer(text_target=targets, max_length=max_target_length, padding='max_length', truncation=True, return_tensors='np')\n        model_inputs['labels'] = labels['input_ids']\n        decoder_input_ids = shift_tokens_right_fn(labels['input_ids'], model.config.pad_token_id, model.config.decoder_start_token_id)\n        model_inputs['decoder_input_ids'] = np.asarray(decoder_input_ids)\n        model_inputs['decoder_attention_mask'] = labels['attention_mask']\n        model_inputs[image_column] = examples[image_column]\n        return model_inputs\n\n    def image_processing_fn(examples, check_image=True):\n        \"\"\"\n        Run preprocessing on images\n\n        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\n        Otherwise, an exception will be thrown.\n        \"\"\"\n        model_inputs = {}\n        if check_image:\n            images = []\n            to_keep = []\n            for image_file in examples[image_column]:\n                try:\n                    img = Image.open(image_file)\n                    images.append(img)\n                    to_keep.append(True)\n                except Exception:\n                    to_keep.append(False)\n            for (k, v) in examples.items():\n                if k != image_column:\n                    model_inputs[k] = v[to_keep]\n        else:\n            images = [Image.open(image_file) for image_file in examples[image_column]]\n        encoder_inputs = image_processor(images=images, return_tensors='np')\n        model_inputs['pixel_values'] = encoder_inputs.pixel_values\n        return model_inputs\n\n    def preprocess_fn(examples, max_target_length, check_image=True):\n        \"\"\"Run tokenization + image processing\"\"\"\n        model_inputs = {}\n        model_inputs.update(tokenization_fn(examples, max_target_length))\n        model_inputs.update(image_processing_fn(model_inputs, check_image=check_image))\n        model_inputs.pop(image_column)\n        return model_inputs\n    features = datasets.Features({'pixel_values': datasets.Array3D(shape=(getattr(model.config.encoder, 'num_channels', 3), model.config.encoder.image_size, model.config.encoder.image_size), dtype='float32'), 'labels': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None), 'decoder_input_ids': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None), 'decoder_attention_mask': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None)})\n    run_img_proc_at_beginning = training_args.block_size == 0\n    function_kwarg = preprocess_fn if run_img_proc_at_beginning else tokenization_fn\n    features_kwarg = features if run_img_proc_at_beginning else None\n    remove_columns_kwarg = [x for x in column_names if x != image_column or run_img_proc_at_beginning]\n    processor_names = 'tokenizer and image processor' if run_img_proc_at_beginning else 'tokenizer'\n    train_batch_size = int(training_args.per_device_train_batch_size) * jax.device_count()\n    eval_batch_size = int(training_args.per_device_eval_batch_size) * jax.device_count()\n    if training_args.block_size % train_batch_size > 0 or training_args.block_size % eval_batch_size > 0:\n        raise ValueError(f'`training_args.block_size` needs to be a multiple of the global train/eval batch size. Got {training_args.block_size}, {train_batch_size} and {eval_batch_size} respectively instead.')\n    if training_args.do_train:\n        if 'train' not in dataset:\n            raise ValueError('--do_train requires a train dataset')\n        train_dataset = dataset['train']\n        if data_args.max_train_samples is not None:\n            max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n            train_dataset = train_dataset.select(range(max_train_samples))\n        if not run_img_proc_at_beginning:\n            train_dataset = train_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        train_dataset = train_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on train dataset', fn_kwargs={'max_target_length': data_args.max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            train_dataset = train_dataset.with_format('numpy')\n        steps_per_epoch = len(train_dataset) // train_batch_size\n        num_train_examples_per_epoch = steps_per_epoch * train_batch_size\n        num_epochs = int(training_args.num_train_epochs)\n        total_train_steps = steps_per_epoch * num_epochs\n    else:\n        num_train_examples_per_epoch = 0\n    if training_args.do_eval:\n        if 'validation' not in dataset:\n            raise ValueError('--do_eval requires a validation dataset')\n        eval_dataset = dataset['validation']\n        if data_args.max_eval_samples is not None:\n            max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n            eval_dataset = eval_dataset.select(range(max_eval_samples))\n        if not run_img_proc_at_beginning:\n            eval_dataset = eval_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        eval_dataset = eval_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on validation dataset', fn_kwargs={'max_target_length': data_args.val_max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            eval_dataset = eval_dataset.with_format('numpy')\n        num_eval_examples = len(eval_dataset)\n        eval_steps = num_eval_examples // eval_batch_size\n    if training_args.do_predict:\n        if 'test' not in dataset:\n            raise ValueError('--do_predict requires a test dataset')\n        predict_dataset = dataset['test']\n        if data_args.max_predict_samples is not None:\n            max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)\n            predict_dataset = predict_dataset.select(range(max_predict_samples))\n        if not run_img_proc_at_beginning:\n            predict_dataset = predict_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        predict_dataset = predict_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on prediction dataset', fn_kwargs={'max_target_length': data_args.val_max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            predict_dataset = predict_dataset.with_format('numpy')\n        num_test_examples = len(predict_dataset)\n        test_steps = num_test_examples // eval_batch_size\n\n    def blockwise_data_loader(rng: jax.random.PRNGKey, ds: Dataset, block_size: int, batch_size: int, shuffle: bool=False, keep_in_memory: bool=False, split: str=''):\n        \"\"\"\n        Wrap the simple `data_loader` in a block-wise way if `block_size` > 0, else it's the same as `data_loader`.\n\n        If `block_size` > 0, it requires `ds` to have a column that gives image paths in order to perform image\n        processing (with the column name being specified by `image_column`). The tokenization should be done before\n        training in this case.\n        \"\"\"\n        if shuffle:\n            indices = jax.random.permutation(rng, len(ds))\n            indices = np.asarray(indices)\n        else:\n            indices = np.arange(len(ds))\n        _block_size = len(ds) if not block_size else block_size\n        steps_per_block = _block_size // batch_size\n        num_examples = len(ds)\n        steps = num_examples // batch_size\n        num_splits = steps // steps_per_block + int(steps % steps_per_block > 0)\n        for idx in range(num_splits):\n            if not block_size:\n                _ds = ds\n            else:\n                start_idx = block_size * idx\n                end_idx = block_size * (idx + 1)\n                selected_indices = indices[start_idx:end_idx]\n                _ds = ds.select(selected_indices)\n                _ds = _ds.map(image_processing_fn, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=[image_column], load_from_cache_file=not data_args.overwrite_cache, features=features, keep_in_memory=keep_in_memory, fn_kwargs={'check_image': False}, desc=f'Running image processing on {split} dataset'.replace('  ', ' '))\n                _ds = _ds.with_format('numpy')\n            loader = data_loader(rng, _ds, batch_size=batch_size, shuffle=False)\n            for batch in loader:\n                yield batch\n    metric = evaluate.load('rouge')\n\n    def postprocess_text(preds, labels):\n        preds = [pred.strip() for pred in preds]\n        labels = [label.strip() for label in labels]\n        preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in preds]\n        labels = ['\\n'.join(nltk.sent_tokenize(label)) for label in labels]\n        return (preds, labels)\n\n    def compute_metrics(preds, labels):\n        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n        (decoded_preds, decoded_labels) = postprocess_text(decoded_preds, decoded_labels)\n        result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n        result = {key: value.mid.fmeasure * 100 for (key, value) in result.items()}\n        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n        result['gen_len'] = np.mean(prediction_lens)\n        result = {k: round(v, 6) for (k, v) in result.items()}\n        return (result, decoded_preds, decoded_labels)\n    has_tensorboard = is_tensorboard_available()\n    if has_tensorboard and jax.process_index() == 0:\n        try:\n            from flax.metrics.tensorboard import SummaryWriter\n            summary_writer = SummaryWriter(log_dir=Path(training_args.output_dir))\n        except ImportError as ie:\n            has_tensorboard = False\n            logger.warning(f'Unable to display metrics through TensorBoard because some package are not installed: {ie}')\n    else:\n        logger.warning('Unable to display metrics through TensorBoard because the package is not installed: Please run pip install tensorboard to enable.')\n    rng = jax.random.PRNGKey(training_args.seed)\n    (rng, dropout_rng) = jax.random.split(rng)\n    linear_decay_lr_schedule_fn = create_learning_rate_fn(num_train_examples_per_epoch, train_batch_size, training_args.num_train_epochs, training_args.warmup_steps, training_args.learning_rate)\n\n    def decay_mask_fn(params):\n        flat_params = traverse_util.flatten_dict(params)\n        layer_norm_candidates = ['layernorm', 'layer_norm', 'ln']\n        layer_norm_named_params = {layer[-2:] for layer_norm_name in layer_norm_candidates for layer in flat_params.keys() if layer_norm_name in ''.join(layer).lower()}\n        flat_mask = {path: path[-1] != 'bias' and path[-2:] not in layer_norm_named_params for path in flat_params}\n        return traverse_util.unflatten_dict(flat_mask)\n    adamw = optax.adamw(learning_rate=linear_decay_lr_schedule_fn, b1=training_args.adam_beta1, b2=training_args.adam_beta2, eps=training_args.adam_epsilon, weight_decay=training_args.weight_decay, mask=decay_mask_fn)\n    state = TrainState.create(apply_fn=model.__call__, params=model.params, tx=adamw, dropout_rng=dropout_rng)\n\n    def loss_fn(logits, labels, padding_mask, label_smoothing_factor=0.0):\n        \"\"\"\n        The label smoothing implementation is adapted from Flax's official example:\n        https://github.com/google/flax/blob/87a211135c6a377c8f29048a1cac3840e38b9da4/examples/wmt/train.py#L104\n        \"\"\"\n        vocab_size = logits.shape[-1]\n        confidence = 1.0 - label_smoothing_factor\n        low_confidence = (1.0 - confidence) / (vocab_size - 1)\n        normalizing_constant = -(confidence * jnp.log(confidence) + (vocab_size - 1) * low_confidence * jnp.log(low_confidence + 1e-20))\n        soft_labels = onehot(labels, vocab_size, on_value=confidence, off_value=low_confidence)\n        loss = optax.softmax_cross_entropy(logits, soft_labels)\n        loss = loss - normalizing_constant\n        loss = loss * padding_mask\n        loss = loss.sum()\n        num_labels = padding_mask.sum()\n        return (loss, num_labels)\n\n    def train_step(state, batch, label_smoothing_factor=0.0):\n        (dropout_rng, new_dropout_rng) = jax.random.split(state.dropout_rng)\n\n        def compute_loss(params):\n            labels = batch.pop('labels')\n            logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n            (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n            return (loss, num_labels)\n        grad_fn = jax.value_and_grad(compute_loss, has_aux=True)\n        ((loss, num_labels), grad) = grad_fn(state.params)\n        num_labels = jax.lax.psum(num_labels, 'batch')\n        loss = jax.lax.psum(loss, 'batch')\n        loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n        grad = jax.lax.psum(grad, 'batch')\n        grad = jax.tree_util.tree_map(lambda x: x / num_labels, grad)\n        new_state = state.apply_gradients(grads=grad, dropout_rng=new_dropout_rng)\n        metrics = {'loss': loss, 'learning_rate': linear_decay_lr_schedule_fn(state.step)}\n        return (new_state, metrics)\n\n    def eval_step(params, batch, label_smoothing_factor=0.0):\n        labels = batch.pop('labels')\n        logits = model(**batch, params=params, train=False)[0]\n        (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n        num_labels = jax.lax.psum(num_labels, 'batch')\n        loss = jax.lax.psum(loss, 'batch')\n        loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n        metrics = {'loss': loss}\n        return metrics\n    max_length = data_args.val_max_target_length if data_args.val_max_target_length is not None else model.config.max_length\n    num_beams = data_args.num_beams if data_args.num_beams is not None else model.config.num_beams\n    gen_kwargs = {'max_length': max_length, 'num_beams': num_beams}\n\n    def generate_step(params, batch):\n        model.params = params\n        output_ids = model.generate(batch['pixel_values'], **gen_kwargs)\n        return output_ids.sequences\n    p_train_step = jax.pmap(partial(train_step, label_smoothing_factor=training_args.label_smoothing_factor), 'batch', donate_argnums=(0,))\n    p_eval_step = jax.pmap(partial(eval_step, label_smoothing_factor=training_args.label_smoothing_factor), 'batch')\n    p_generate_step = jax.pmap(generate_step, 'batch')\n    state = state.replicate()\n    if training_args.do_train:\n        logger.info('***** Running training *****')\n        logger.info(f'  Num train examples = {num_train_examples_per_epoch}')\n        logger.info(f'  Num Epochs = {num_epochs}')\n        logger.info(f'  Instantaneous train batch size per device = {training_args.per_device_train_batch_size}')\n        logger.info(f'  Total train batch size (w. parallel & distributed) = {train_batch_size}')\n        logger.info(f'  Optimization steps per epoch = {steps_per_epoch}')\n        logger.info(f'  Total optimization steps = {total_train_steps}')\n    if training_args.do_eval:\n        logger.info(f'  Num evaluation examples = {num_eval_examples}')\n        logger.info(f'  Instantaneous evaluation batch size per device = {training_args.per_device_eval_batch_size}')\n        logger.info(f'  Total evaluation batch size (w. parallel & distributed) = {eval_batch_size}')\n        logger.info(f'  Evaluation steps = {eval_steps}')\n    if training_args.do_predict:\n        logger.info(f'  Num test examples = {num_test_examples}')\n        logger.info(f'  Instantaneous test batch size per device = {training_args.per_device_eval_batch_size}')\n        logger.info(f'  Total test batch size (w. parallel & distributed) = {eval_batch_size}')\n        logger.info(f'  Test steps = {test_steps}')\n    if not os.path.isdir(os.path.join(training_args.output_dir)):\n        os.makedirs(os.path.join(training_args.output_dir), exist_ok=True)\n\n    def save_ckpt(ckpt_dir: str, commit_msg: str=''):\n        \"\"\"save checkpoints and push to Hugging Face Hub if specified\"\"\"\n        if jax.process_index() == 0:\n            params = jax.device_get(jax.tree_util.tree_map(lambda x: x[0], state.params))\n            model.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir), params=params)\n            tokenizer.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir))\n            if training_args.push_to_hub:\n                repo.push_to_hub(commit_message=commit_msg, blocking=False)\n\n    def evaluation_loop(rng: jax.random.PRNGKey, dataset: Dataset, metric_key_prefix: str='eval', ckpt_dir: str='', is_prediction=False):\n        logger.info(f\"*** {('Predict' if is_prediction else 'Evaluate')} ***\")\n        metrics = []\n        preds = []\n        labels = []\n        batches = blockwise_data_loader(rng, dataset, block_size=training_args.block_size, batch_size=eval_batch_size, keep_in_memory=False, shuffle=False, split='prediction' if is_prediction else 'validation')\n        steps = len(dataset) // eval_batch_size\n        for _ in tqdm(range(steps), desc=f\"{('Predicting' if is_prediction else 'Evaluating')}...\", position=2, leave=False):\n            batch = next(batches)\n            _labels = batch.get('labels', None)\n            if not is_prediction and _labels is None:\n                raise ValueError('Evaluation requires the validation dataset to have `labels`')\n            if _labels is not None:\n                _metrics = p_eval_step(state.params, batch)\n                metrics.append(_metrics)\n            if data_args.predict_with_generate:\n                generated_ids = p_generate_step(state.params, batch)\n                preds.extend(jax.device_get(generated_ids.reshape(-1, gen_kwargs['max_length'])))\n                if _labels is not None:\n                    labels.extend(jax.device_get(_labels.reshape(-1, _labels.shape[-1])))\n        if metrics:\n            metrics = get_metrics(metrics)\n            metrics = jax.tree_util.tree_map(jnp.mean, metrics)\n        generations = []\n        rouge_desc = ''\n        if data_args.predict_with_generate:\n            if labels:\n                (rouge_metrics, decoded_preds, decoded_labels) = compute_metrics(preds, labels)\n                metrics.update(rouge_metrics)\n                rouge_desc = ' '.join([f\"{('Predict' if is_prediction else 'Eval')} {key}: {value} |\" for (key, value) in rouge_metrics.items()])\n                for (pred, label) in zip(decoded_preds, decoded_labels):\n                    pred = pred.replace('\\n', ' ')\n                    label = label.replace('\\n', ' ')\n                    generations.append({'label': label, 'pred': pred})\n            else:\n                decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n                decoded_preds = [pred.strip() for pred in decoded_preds]\n                decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in decoded_preds]\n                for pred in decoded_preds:\n                    pred = pred.replace('\\n', ' ')\n                    generations.append({'pred': pred})\n        if metrics:\n            desc = f\"{('Predict' if is_prediction else 'Eval')} Loss: {metrics['loss']} | {rouge_desc})\"\n            if training_args.do_train and (not is_prediction):\n                desc = f'Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | ' + desc\n                epochs.write(desc)\n                epochs.desc = desc\n            logger.info(desc)\n        if jax.process_index() == 0:\n            if not os.path.isdir(os.path.join(training_args.output_dir, ckpt_dir)):\n                os.makedirs(os.path.join(training_args.output_dir, ckpt_dir), exist_ok=True)\n            if metrics:\n                if has_tensorboard and training_args.do_train:\n                    write_metric(summary_writer, metrics, train_time=None, step=cur_step, metric_key_prefix=metric_key_prefix)\n                metrics = {f'{metric_key_prefix}_{metric_name}': round(value.item(), 6) for (metric_name, value) in metrics.items()}\n                _path = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_results.json')\n                with open(_path, 'w') as f:\n                    json.dump(metrics, f, indent=4, sort_keys=True)\n                with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                    fp.write(desc + '\\n')\n            if generations:\n                output_file = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_generation.json')\n                with open(output_file, 'w', encoding='UTF-8') as fp:\n                    json.dump(generations, fp, ensure_ascii=False, indent=4)\n\n    def evaluate(rng: jax.random.PRNGKey, dataset: Dataset, ckpt_dir: str=''):\n        evaluation_loop(rng, dataset, metric_key_prefix='eval', ckpt_dir=ckpt_dir)\n\n    def predict(rng: jax.random.PRNGKey, dataset: Dataset):\n        evaluation_loop(rng, dataset, metric_key_prefix='test', is_prediction=True)\n    input_rng = None\n    if training_args.do_train:\n        cur_step = 0\n        train_time = 0\n        epochs = tqdm(range(num_epochs), desc=f'Epoch ... (1/{num_epochs})', position=0)\n        for epoch in epochs:\n            (rng, input_rng) = jax.random.split(rng)\n            train_metrics = []\n            train_batches = blockwise_data_loader(input_rng, train_dataset, block_size=training_args.block_size, batch_size=train_batch_size, keep_in_memory=True, shuffle=True, split='train')\n            for (batch_idx, _) in enumerate(tqdm(range(steps_per_epoch), desc='Training...', position=1, leave=False)):\n                cur_step += 1\n                batch = next(train_batches)\n                batch_start = time.time()\n                (state, train_metric) = p_train_step(state, batch)\n                train_metrics.append(train_metric)\n                train_time += time.time() - batch_start\n                time_per_step = train_time / cur_step\n                if training_args.logging_steps > 0 and cur_step % training_args.logging_steps == 0:\n                    _train_metric = unreplicate(train_metric)\n                    desc = f\"Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | Loss: {_train_metric['loss']} | Learning Rate: {_train_metric['learning_rate']} | Time per step: {time_per_step})\"\n                    epochs.desc = desc\n                    epochs.write(desc)\n                    logger.info(desc)\n                    with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                        fp.write(desc + '\\n')\n                    if has_tensorboard and jax.process_index() == 0:\n                        write_metric(summary_writer, train_metrics, train_time=train_time, step=cur_step, metric_key_prefix='train')\n                if training_args.do_eval and (training_args.eval_steps is not None and training_args.eval_steps > 0) and (cur_step % training_args.eval_steps == 0):\n                    ckpt_dir = f'ckpt_epoch_{epoch + 1}_step_{cur_step}'\n                    commit_msg = f'Saving weights and logs of epoch {epoch + 1} - step {cur_step}'\n                    evaluate(input_rng, eval_dataset, ckpt_dir)\n                    save_ckpt(ckpt_dir=ckpt_dir, commit_msg=commit_msg)\n            if training_args.logging_steps <= 0:\n                logger.info(desc)\n                with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                    fp.write(desc + '\\n')\n                if has_tensorboard and jax.process_index() == 0:\n                    write_metric(summary_writer, train_metrics, train_time=train_time, step=cur_step, metric_key_prefix='train')\n            if training_args.do_eval and (training_args.eval_steps is None or training_args.eval_steps <= 0):\n                ckpt_dir = f'ckpt_epoch_{epoch + 1}_step_{cur_step}'\n                commit_msg = f'Saving weights and logs of epoch {epoch + 1} - step {cur_step}'\n                evaluate(input_rng, eval_dataset, ckpt_dir)\n                save_ckpt(ckpt_dir=ckpt_dir, commit_msg=commit_msg)\n    if input_rng is None:\n        (rng, input_rng) = jax.random.split(rng)\n    if training_args.do_eval and (not training_args.do_train):\n        evaluate(input_rng, eval_dataset)\n    if training_args.do_predict:\n        predict(input_rng, predict_dataset)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n    if len(sys.argv) == 2 and sys.argv[1].endswith('.json'):\n        (model_args, data_args, training_args) = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n    else:\n        (model_args, data_args, training_args) = parser.parse_args_into_dataclasses()\n    if model_args.use_auth_token is not None:\n        warnings.warn('The `use_auth_token` argument is deprecated and will be removed in v4.34. Please use `token` instead.', FutureWarning)\n        if model_args.token is not None:\n            raise ValueError('`token` and `use_auth_token` are both specified. Please set only the argument `token`.')\n        model_args.token = model_args.use_auth_token\n    send_example_telemetry('run_image_captioning', model_args, data_args, framework='flax')\n    if os.path.exists(training_args.output_dir) and os.listdir(training_args.output_dir) and training_args.do_train and (not training_args.overwrite_output_dir):\n        raise ValueError(f'Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.')\n    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s', datefmt='%m/%d/%Y %H:%M:%S', level=logging.INFO)\n    logger.setLevel(logging.INFO if jax.process_index() == 0 else logging.ERROR)\n    if jax.process_index() == 0:\n        datasets.utils.logging.set_verbosity_warning()\n        transformers.utils.logging.set_verbosity_info()\n    else:\n        datasets.utils.logging.set_verbosity_error()\n        transformers.utils.logging.set_verbosity_error()\n    logger.info(f'Training/evaluation parameters {training_args}')\n    if training_args.push_to_hub:\n        repo_name = training_args.hub_model_id\n        if repo_name is None:\n            repo_name = Path(training_args.output_dir).absolute().name\n        repo_id = create_repo(repo_name, exist_ok=True, token=training_args.hub_token).repo_id\n        repo = Repository(training_args.output_dir, clone_from=repo_id, token=training_args.hub_token)\n    if data_args.dataset_name is not None:\n        dataset = load_dataset(data_args.dataset_name, data_args.dataset_config_name, cache_dir=model_args.cache_dir, keep_in_memory=False, data_dir=data_args.data_dir, token=model_args.token)\n    else:\n        data_files = {}\n        if data_args.train_file is not None:\n            data_files['train'] = data_args.train_file\n            extension = data_args.train_file.split('.')[-1]\n        if data_args.validation_file is not None:\n            data_files['validation'] = data_args.validation_file\n            extension = data_args.validation_file.split('.')[-1]\n        if data_args.test_file is not None:\n            data_files['test'] = data_args.test_file\n            extension = data_args.test_file.split('.')[-1]\n        dataset = load_dataset(extension, data_files=data_files, cache_dir=model_args.cache_dir, token=model_args.token)\n    model = FlaxVisionEncoderDecoderModel.from_pretrained(model_args.model_name_or_path, seed=training_args.seed, dtype=getattr(jnp, model_args.dtype), token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    image_processor = AutoImageProcessor.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir, token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    tokenizer = AutoTokenizer.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir, use_fast=model_args.use_fast_tokenizer, token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    tokenizer.pad_token = tokenizer.convert_ids_to_tokens(model.config.pad_token_id)\n    if training_args.do_train:\n        column_names = dataset['train'].column_names\n    elif training_args.do_eval:\n        column_names = dataset['validation'].column_names\n    elif training_args.do_predict:\n        column_names = dataset['test'].column_names\n    else:\n        logger.info('There is nothing to do. Please pass `do_train`, `do_eval` and/or `do_predict`.')\n        return\n    dataset_columns = image_captioning_name_mapping.get(data_args.dataset_name, None)\n    if data_args.image_column is None:\n        if dataset_columns is None:\n            raise ValueError(f\"`--dataset_name` {data_args.dataset_name} not found in dataset '{data_args.dataset_name}'. Make sure to set `--dataset_name` to the correct dataset name, one of {', '.join(image_captioning_name_mapping.keys())}.\")\n        image_column = dataset_columns[0]\n    else:\n        image_column = data_args.image_column\n        if image_column not in column_names:\n            raise ValueError(f\"--image_column' value '{data_args.image_column}' needs to be one of: {', '.join(column_names)}\")\n    if data_args.caption_column is None:\n        if dataset_columns is None:\n            raise ValueError(f\"`--dataset_name` {data_args.dataset_name} not found in dataset '{data_args.dataset_name}'. Make sure to set `--dataset_name` to the correct dataset name, one of {', '.join(image_captioning_name_mapping.keys())}.\")\n        caption_column = dataset_columns[1]\n    else:\n        caption_column = data_args.caption_column\n        if caption_column not in column_names:\n            raise ValueError(f\"--caption_column' value '{data_args.caption_column}' needs to be one of: {', '.join(column_names)}\")\n    model_module = __import__(model.__module__, fromlist=['shift_tokens_right'])\n    shift_tokens_right_fn = getattr(model_module, 'shift_tokens_right', shift_tokens_right)\n\n    def filter_fn(examples):\n        \"\"\"remove problematic images\"\"\"\n        bools = []\n        for image_file in examples[image_column]:\n            try:\n                image = Image.open(image_file)\n                image_processor(images=image, return_tensors='np')\n                bools.append(True)\n            except Exception:\n                bools.append(False)\n        return bools\n\n    def tokenization_fn(examples, max_target_length):\n        \"\"\"Run tokenization on captions.\"\"\"\n        captions = []\n        for caption in examples[caption_column]:\n            captions.append(caption.lower() + ' ' + tokenizer.eos_token)\n        targets = captions\n        model_inputs = {}\n        labels = tokenizer(text_target=targets, max_length=max_target_length, padding='max_length', truncation=True, return_tensors='np')\n        model_inputs['labels'] = labels['input_ids']\n        decoder_input_ids = shift_tokens_right_fn(labels['input_ids'], model.config.pad_token_id, model.config.decoder_start_token_id)\n        model_inputs['decoder_input_ids'] = np.asarray(decoder_input_ids)\n        model_inputs['decoder_attention_mask'] = labels['attention_mask']\n        model_inputs[image_column] = examples[image_column]\n        return model_inputs\n\n    def image_processing_fn(examples, check_image=True):\n        \"\"\"\n        Run preprocessing on images\n\n        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\n        Otherwise, an exception will be thrown.\n        \"\"\"\n        model_inputs = {}\n        if check_image:\n            images = []\n            to_keep = []\n            for image_file in examples[image_column]:\n                try:\n                    img = Image.open(image_file)\n                    images.append(img)\n                    to_keep.append(True)\n                except Exception:\n                    to_keep.append(False)\n            for (k, v) in examples.items():\n                if k != image_column:\n                    model_inputs[k] = v[to_keep]\n        else:\n            images = [Image.open(image_file) for image_file in examples[image_column]]\n        encoder_inputs = image_processor(images=images, return_tensors='np')\n        model_inputs['pixel_values'] = encoder_inputs.pixel_values\n        return model_inputs\n\n    def preprocess_fn(examples, max_target_length, check_image=True):\n        \"\"\"Run tokenization + image processing\"\"\"\n        model_inputs = {}\n        model_inputs.update(tokenization_fn(examples, max_target_length))\n        model_inputs.update(image_processing_fn(model_inputs, check_image=check_image))\n        model_inputs.pop(image_column)\n        return model_inputs\n    features = datasets.Features({'pixel_values': datasets.Array3D(shape=(getattr(model.config.encoder, 'num_channels', 3), model.config.encoder.image_size, model.config.encoder.image_size), dtype='float32'), 'labels': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None), 'decoder_input_ids': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None), 'decoder_attention_mask': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None)})\n    run_img_proc_at_beginning = training_args.block_size == 0\n    function_kwarg = preprocess_fn if run_img_proc_at_beginning else tokenization_fn\n    features_kwarg = features if run_img_proc_at_beginning else None\n    remove_columns_kwarg = [x for x in column_names if x != image_column or run_img_proc_at_beginning]\n    processor_names = 'tokenizer and image processor' if run_img_proc_at_beginning else 'tokenizer'\n    train_batch_size = int(training_args.per_device_train_batch_size) * jax.device_count()\n    eval_batch_size = int(training_args.per_device_eval_batch_size) * jax.device_count()\n    if training_args.block_size % train_batch_size > 0 or training_args.block_size % eval_batch_size > 0:\n        raise ValueError(f'`training_args.block_size` needs to be a multiple of the global train/eval batch size. Got {training_args.block_size}, {train_batch_size} and {eval_batch_size} respectively instead.')\n    if training_args.do_train:\n        if 'train' not in dataset:\n            raise ValueError('--do_train requires a train dataset')\n        train_dataset = dataset['train']\n        if data_args.max_train_samples is not None:\n            max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n            train_dataset = train_dataset.select(range(max_train_samples))\n        if not run_img_proc_at_beginning:\n            train_dataset = train_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        train_dataset = train_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on train dataset', fn_kwargs={'max_target_length': data_args.max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            train_dataset = train_dataset.with_format('numpy')\n        steps_per_epoch = len(train_dataset) // train_batch_size\n        num_train_examples_per_epoch = steps_per_epoch * train_batch_size\n        num_epochs = int(training_args.num_train_epochs)\n        total_train_steps = steps_per_epoch * num_epochs\n    else:\n        num_train_examples_per_epoch = 0\n    if training_args.do_eval:\n        if 'validation' not in dataset:\n            raise ValueError('--do_eval requires a validation dataset')\n        eval_dataset = dataset['validation']\n        if data_args.max_eval_samples is not None:\n            max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n            eval_dataset = eval_dataset.select(range(max_eval_samples))\n        if not run_img_proc_at_beginning:\n            eval_dataset = eval_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        eval_dataset = eval_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on validation dataset', fn_kwargs={'max_target_length': data_args.val_max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            eval_dataset = eval_dataset.with_format('numpy')\n        num_eval_examples = len(eval_dataset)\n        eval_steps = num_eval_examples // eval_batch_size\n    if training_args.do_predict:\n        if 'test' not in dataset:\n            raise ValueError('--do_predict requires a test dataset')\n        predict_dataset = dataset['test']\n        if data_args.max_predict_samples is not None:\n            max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)\n            predict_dataset = predict_dataset.select(range(max_predict_samples))\n        if not run_img_proc_at_beginning:\n            predict_dataset = predict_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        predict_dataset = predict_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on prediction dataset', fn_kwargs={'max_target_length': data_args.val_max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            predict_dataset = predict_dataset.with_format('numpy')\n        num_test_examples = len(predict_dataset)\n        test_steps = num_test_examples // eval_batch_size\n\n    def blockwise_data_loader(rng: jax.random.PRNGKey, ds: Dataset, block_size: int, batch_size: int, shuffle: bool=False, keep_in_memory: bool=False, split: str=''):\n        \"\"\"\n        Wrap the simple `data_loader` in a block-wise way if `block_size` > 0, else it's the same as `data_loader`.\n\n        If `block_size` > 0, it requires `ds` to have a column that gives image paths in order to perform image\n        processing (with the column name being specified by `image_column`). The tokenization should be done before\n        training in this case.\n        \"\"\"\n        if shuffle:\n            indices = jax.random.permutation(rng, len(ds))\n            indices = np.asarray(indices)\n        else:\n            indices = np.arange(len(ds))\n        _block_size = len(ds) if not block_size else block_size\n        steps_per_block = _block_size // batch_size\n        num_examples = len(ds)\n        steps = num_examples // batch_size\n        num_splits = steps // steps_per_block + int(steps % steps_per_block > 0)\n        for idx in range(num_splits):\n            if not block_size:\n                _ds = ds\n            else:\n                start_idx = block_size * idx\n                end_idx = block_size * (idx + 1)\n                selected_indices = indices[start_idx:end_idx]\n                _ds = ds.select(selected_indices)\n                _ds = _ds.map(image_processing_fn, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=[image_column], load_from_cache_file=not data_args.overwrite_cache, features=features, keep_in_memory=keep_in_memory, fn_kwargs={'check_image': False}, desc=f'Running image processing on {split} dataset'.replace('  ', ' '))\n                _ds = _ds.with_format('numpy')\n            loader = data_loader(rng, _ds, batch_size=batch_size, shuffle=False)\n            for batch in loader:\n                yield batch\n    metric = evaluate.load('rouge')\n\n    def postprocess_text(preds, labels):\n        preds = [pred.strip() for pred in preds]\n        labels = [label.strip() for label in labels]\n        preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in preds]\n        labels = ['\\n'.join(nltk.sent_tokenize(label)) for label in labels]\n        return (preds, labels)\n\n    def compute_metrics(preds, labels):\n        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n        (decoded_preds, decoded_labels) = postprocess_text(decoded_preds, decoded_labels)\n        result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n        result = {key: value.mid.fmeasure * 100 for (key, value) in result.items()}\n        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n        result['gen_len'] = np.mean(prediction_lens)\n        result = {k: round(v, 6) for (k, v) in result.items()}\n        return (result, decoded_preds, decoded_labels)\n    has_tensorboard = is_tensorboard_available()\n    if has_tensorboard and jax.process_index() == 0:\n        try:\n            from flax.metrics.tensorboard import SummaryWriter\n            summary_writer = SummaryWriter(log_dir=Path(training_args.output_dir))\n        except ImportError as ie:\n            has_tensorboard = False\n            logger.warning(f'Unable to display metrics through TensorBoard because some package are not installed: {ie}')\n    else:\n        logger.warning('Unable to display metrics through TensorBoard because the package is not installed: Please run pip install tensorboard to enable.')\n    rng = jax.random.PRNGKey(training_args.seed)\n    (rng, dropout_rng) = jax.random.split(rng)\n    linear_decay_lr_schedule_fn = create_learning_rate_fn(num_train_examples_per_epoch, train_batch_size, training_args.num_train_epochs, training_args.warmup_steps, training_args.learning_rate)\n\n    def decay_mask_fn(params):\n        flat_params = traverse_util.flatten_dict(params)\n        layer_norm_candidates = ['layernorm', 'layer_norm', 'ln']\n        layer_norm_named_params = {layer[-2:] for layer_norm_name in layer_norm_candidates for layer in flat_params.keys() if layer_norm_name in ''.join(layer).lower()}\n        flat_mask = {path: path[-1] != 'bias' and path[-2:] not in layer_norm_named_params for path in flat_params}\n        return traverse_util.unflatten_dict(flat_mask)\n    adamw = optax.adamw(learning_rate=linear_decay_lr_schedule_fn, b1=training_args.adam_beta1, b2=training_args.adam_beta2, eps=training_args.adam_epsilon, weight_decay=training_args.weight_decay, mask=decay_mask_fn)\n    state = TrainState.create(apply_fn=model.__call__, params=model.params, tx=adamw, dropout_rng=dropout_rng)\n\n    def loss_fn(logits, labels, padding_mask, label_smoothing_factor=0.0):\n        \"\"\"\n        The label smoothing implementation is adapted from Flax's official example:\n        https://github.com/google/flax/blob/87a211135c6a377c8f29048a1cac3840e38b9da4/examples/wmt/train.py#L104\n        \"\"\"\n        vocab_size = logits.shape[-1]\n        confidence = 1.0 - label_smoothing_factor\n        low_confidence = (1.0 - confidence) / (vocab_size - 1)\n        normalizing_constant = -(confidence * jnp.log(confidence) + (vocab_size - 1) * low_confidence * jnp.log(low_confidence + 1e-20))\n        soft_labels = onehot(labels, vocab_size, on_value=confidence, off_value=low_confidence)\n        loss = optax.softmax_cross_entropy(logits, soft_labels)\n        loss = loss - normalizing_constant\n        loss = loss * padding_mask\n        loss = loss.sum()\n        num_labels = padding_mask.sum()\n        return (loss, num_labels)\n\n    def train_step(state, batch, label_smoothing_factor=0.0):\n        (dropout_rng, new_dropout_rng) = jax.random.split(state.dropout_rng)\n\n        def compute_loss(params):\n            labels = batch.pop('labels')\n            logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n            (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n            return (loss, num_labels)\n        grad_fn = jax.value_and_grad(compute_loss, has_aux=True)\n        ((loss, num_labels), grad) = grad_fn(state.params)\n        num_labels = jax.lax.psum(num_labels, 'batch')\n        loss = jax.lax.psum(loss, 'batch')\n        loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n        grad = jax.lax.psum(grad, 'batch')\n        grad = jax.tree_util.tree_map(lambda x: x / num_labels, grad)\n        new_state = state.apply_gradients(grads=grad, dropout_rng=new_dropout_rng)\n        metrics = {'loss': loss, 'learning_rate': linear_decay_lr_schedule_fn(state.step)}\n        return (new_state, metrics)\n\n    def eval_step(params, batch, label_smoothing_factor=0.0):\n        labels = batch.pop('labels')\n        logits = model(**batch, params=params, train=False)[0]\n        (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n        num_labels = jax.lax.psum(num_labels, 'batch')\n        loss = jax.lax.psum(loss, 'batch')\n        loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n        metrics = {'loss': loss}\n        return metrics\n    max_length = data_args.val_max_target_length if data_args.val_max_target_length is not None else model.config.max_length\n    num_beams = data_args.num_beams if data_args.num_beams is not None else model.config.num_beams\n    gen_kwargs = {'max_length': max_length, 'num_beams': num_beams}\n\n    def generate_step(params, batch):\n        model.params = params\n        output_ids = model.generate(batch['pixel_values'], **gen_kwargs)\n        return output_ids.sequences\n    p_train_step = jax.pmap(partial(train_step, label_smoothing_factor=training_args.label_smoothing_factor), 'batch', donate_argnums=(0,))\n    p_eval_step = jax.pmap(partial(eval_step, label_smoothing_factor=training_args.label_smoothing_factor), 'batch')\n    p_generate_step = jax.pmap(generate_step, 'batch')\n    state = state.replicate()\n    if training_args.do_train:\n        logger.info('***** Running training *****')\n        logger.info(f'  Num train examples = {num_train_examples_per_epoch}')\n        logger.info(f'  Num Epochs = {num_epochs}')\n        logger.info(f'  Instantaneous train batch size per device = {training_args.per_device_train_batch_size}')\n        logger.info(f'  Total train batch size (w. parallel & distributed) = {train_batch_size}')\n        logger.info(f'  Optimization steps per epoch = {steps_per_epoch}')\n        logger.info(f'  Total optimization steps = {total_train_steps}')\n    if training_args.do_eval:\n        logger.info(f'  Num evaluation examples = {num_eval_examples}')\n        logger.info(f'  Instantaneous evaluation batch size per device = {training_args.per_device_eval_batch_size}')\n        logger.info(f'  Total evaluation batch size (w. parallel & distributed) = {eval_batch_size}')\n        logger.info(f'  Evaluation steps = {eval_steps}')\n    if training_args.do_predict:\n        logger.info(f'  Num test examples = {num_test_examples}')\n        logger.info(f'  Instantaneous test batch size per device = {training_args.per_device_eval_batch_size}')\n        logger.info(f'  Total test batch size (w. parallel & distributed) = {eval_batch_size}')\n        logger.info(f'  Test steps = {test_steps}')\n    if not os.path.isdir(os.path.join(training_args.output_dir)):\n        os.makedirs(os.path.join(training_args.output_dir), exist_ok=True)\n\n    def save_ckpt(ckpt_dir: str, commit_msg: str=''):\n        \"\"\"save checkpoints and push to Hugging Face Hub if specified\"\"\"\n        if jax.process_index() == 0:\n            params = jax.device_get(jax.tree_util.tree_map(lambda x: x[0], state.params))\n            model.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir), params=params)\n            tokenizer.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir))\n            if training_args.push_to_hub:\n                repo.push_to_hub(commit_message=commit_msg, blocking=False)\n\n    def evaluation_loop(rng: jax.random.PRNGKey, dataset: Dataset, metric_key_prefix: str='eval', ckpt_dir: str='', is_prediction=False):\n        logger.info(f\"*** {('Predict' if is_prediction else 'Evaluate')} ***\")\n        metrics = []\n        preds = []\n        labels = []\n        batches = blockwise_data_loader(rng, dataset, block_size=training_args.block_size, batch_size=eval_batch_size, keep_in_memory=False, shuffle=False, split='prediction' if is_prediction else 'validation')\n        steps = len(dataset) // eval_batch_size\n        for _ in tqdm(range(steps), desc=f\"{('Predicting' if is_prediction else 'Evaluating')}...\", position=2, leave=False):\n            batch = next(batches)\n            _labels = batch.get('labels', None)\n            if not is_prediction and _labels is None:\n                raise ValueError('Evaluation requires the validation dataset to have `labels`')\n            if _labels is not None:\n                _metrics = p_eval_step(state.params, batch)\n                metrics.append(_metrics)\n            if data_args.predict_with_generate:\n                generated_ids = p_generate_step(state.params, batch)\n                preds.extend(jax.device_get(generated_ids.reshape(-1, gen_kwargs['max_length'])))\n                if _labels is not None:\n                    labels.extend(jax.device_get(_labels.reshape(-1, _labels.shape[-1])))\n        if metrics:\n            metrics = get_metrics(metrics)\n            metrics = jax.tree_util.tree_map(jnp.mean, metrics)\n        generations = []\n        rouge_desc = ''\n        if data_args.predict_with_generate:\n            if labels:\n                (rouge_metrics, decoded_preds, decoded_labels) = compute_metrics(preds, labels)\n                metrics.update(rouge_metrics)\n                rouge_desc = ' '.join([f\"{('Predict' if is_prediction else 'Eval')} {key}: {value} |\" for (key, value) in rouge_metrics.items()])\n                for (pred, label) in zip(decoded_preds, decoded_labels):\n                    pred = pred.replace('\\n', ' ')\n                    label = label.replace('\\n', ' ')\n                    generations.append({'label': label, 'pred': pred})\n            else:\n                decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n                decoded_preds = [pred.strip() for pred in decoded_preds]\n                decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in decoded_preds]\n                for pred in decoded_preds:\n                    pred = pred.replace('\\n', ' ')\n                    generations.append({'pred': pred})\n        if metrics:\n            desc = f\"{('Predict' if is_prediction else 'Eval')} Loss: {metrics['loss']} | {rouge_desc})\"\n            if training_args.do_train and (not is_prediction):\n                desc = f'Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | ' + desc\n                epochs.write(desc)\n                epochs.desc = desc\n            logger.info(desc)\n        if jax.process_index() == 0:\n            if not os.path.isdir(os.path.join(training_args.output_dir, ckpt_dir)):\n                os.makedirs(os.path.join(training_args.output_dir, ckpt_dir), exist_ok=True)\n            if metrics:\n                if has_tensorboard and training_args.do_train:\n                    write_metric(summary_writer, metrics, train_time=None, step=cur_step, metric_key_prefix=metric_key_prefix)\n                metrics = {f'{metric_key_prefix}_{metric_name}': round(value.item(), 6) for (metric_name, value) in metrics.items()}\n                _path = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_results.json')\n                with open(_path, 'w') as f:\n                    json.dump(metrics, f, indent=4, sort_keys=True)\n                with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                    fp.write(desc + '\\n')\n            if generations:\n                output_file = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_generation.json')\n                with open(output_file, 'w', encoding='UTF-8') as fp:\n                    json.dump(generations, fp, ensure_ascii=False, indent=4)\n\n    def evaluate(rng: jax.random.PRNGKey, dataset: Dataset, ckpt_dir: str=''):\n        evaluation_loop(rng, dataset, metric_key_prefix='eval', ckpt_dir=ckpt_dir)\n\n    def predict(rng: jax.random.PRNGKey, dataset: Dataset):\n        evaluation_loop(rng, dataset, metric_key_prefix='test', is_prediction=True)\n    input_rng = None\n    if training_args.do_train:\n        cur_step = 0\n        train_time = 0\n        epochs = tqdm(range(num_epochs), desc=f'Epoch ... (1/{num_epochs})', position=0)\n        for epoch in epochs:\n            (rng, input_rng) = jax.random.split(rng)\n            train_metrics = []\n            train_batches = blockwise_data_loader(input_rng, train_dataset, block_size=training_args.block_size, batch_size=train_batch_size, keep_in_memory=True, shuffle=True, split='train')\n            for (batch_idx, _) in enumerate(tqdm(range(steps_per_epoch), desc='Training...', position=1, leave=False)):\n                cur_step += 1\n                batch = next(train_batches)\n                batch_start = time.time()\n                (state, train_metric) = p_train_step(state, batch)\n                train_metrics.append(train_metric)\n                train_time += time.time() - batch_start\n                time_per_step = train_time / cur_step\n                if training_args.logging_steps > 0 and cur_step % training_args.logging_steps == 0:\n                    _train_metric = unreplicate(train_metric)\n                    desc = f\"Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | Loss: {_train_metric['loss']} | Learning Rate: {_train_metric['learning_rate']} | Time per step: {time_per_step})\"\n                    epochs.desc = desc\n                    epochs.write(desc)\n                    logger.info(desc)\n                    with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                        fp.write(desc + '\\n')\n                    if has_tensorboard and jax.process_index() == 0:\n                        write_metric(summary_writer, train_metrics, train_time=train_time, step=cur_step, metric_key_prefix='train')\n                if training_args.do_eval and (training_args.eval_steps is not None and training_args.eval_steps > 0) and (cur_step % training_args.eval_steps == 0):\n                    ckpt_dir = f'ckpt_epoch_{epoch + 1}_step_{cur_step}'\n                    commit_msg = f'Saving weights and logs of epoch {epoch + 1} - step {cur_step}'\n                    evaluate(input_rng, eval_dataset, ckpt_dir)\n                    save_ckpt(ckpt_dir=ckpt_dir, commit_msg=commit_msg)\n            if training_args.logging_steps <= 0:\n                logger.info(desc)\n                with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                    fp.write(desc + '\\n')\n                if has_tensorboard and jax.process_index() == 0:\n                    write_metric(summary_writer, train_metrics, train_time=train_time, step=cur_step, metric_key_prefix='train')\n            if training_args.do_eval and (training_args.eval_steps is None or training_args.eval_steps <= 0):\n                ckpt_dir = f'ckpt_epoch_{epoch + 1}_step_{cur_step}'\n                commit_msg = f'Saving weights and logs of epoch {epoch + 1} - step {cur_step}'\n                evaluate(input_rng, eval_dataset, ckpt_dir)\n                save_ckpt(ckpt_dir=ckpt_dir, commit_msg=commit_msg)\n    if input_rng is None:\n        (rng, input_rng) = jax.random.split(rng)\n    if training_args.do_eval and (not training_args.do_train):\n        evaluate(input_rng, eval_dataset)\n    if training_args.do_predict:\n        predict(input_rng, predict_dataset)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n    if len(sys.argv) == 2 and sys.argv[1].endswith('.json'):\n        (model_args, data_args, training_args) = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n    else:\n        (model_args, data_args, training_args) = parser.parse_args_into_dataclasses()\n    if model_args.use_auth_token is not None:\n        warnings.warn('The `use_auth_token` argument is deprecated and will be removed in v4.34. Please use `token` instead.', FutureWarning)\n        if model_args.token is not None:\n            raise ValueError('`token` and `use_auth_token` are both specified. Please set only the argument `token`.')\n        model_args.token = model_args.use_auth_token\n    send_example_telemetry('run_image_captioning', model_args, data_args, framework='flax')\n    if os.path.exists(training_args.output_dir) and os.listdir(training_args.output_dir) and training_args.do_train and (not training_args.overwrite_output_dir):\n        raise ValueError(f'Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.')\n    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s', datefmt='%m/%d/%Y %H:%M:%S', level=logging.INFO)\n    logger.setLevel(logging.INFO if jax.process_index() == 0 else logging.ERROR)\n    if jax.process_index() == 0:\n        datasets.utils.logging.set_verbosity_warning()\n        transformers.utils.logging.set_verbosity_info()\n    else:\n        datasets.utils.logging.set_verbosity_error()\n        transformers.utils.logging.set_verbosity_error()\n    logger.info(f'Training/evaluation parameters {training_args}')\n    if training_args.push_to_hub:\n        repo_name = training_args.hub_model_id\n        if repo_name is None:\n            repo_name = Path(training_args.output_dir).absolute().name\n        repo_id = create_repo(repo_name, exist_ok=True, token=training_args.hub_token).repo_id\n        repo = Repository(training_args.output_dir, clone_from=repo_id, token=training_args.hub_token)\n    if data_args.dataset_name is not None:\n        dataset = load_dataset(data_args.dataset_name, data_args.dataset_config_name, cache_dir=model_args.cache_dir, keep_in_memory=False, data_dir=data_args.data_dir, token=model_args.token)\n    else:\n        data_files = {}\n        if data_args.train_file is not None:\n            data_files['train'] = data_args.train_file\n            extension = data_args.train_file.split('.')[-1]\n        if data_args.validation_file is not None:\n            data_files['validation'] = data_args.validation_file\n            extension = data_args.validation_file.split('.')[-1]\n        if data_args.test_file is not None:\n            data_files['test'] = data_args.test_file\n            extension = data_args.test_file.split('.')[-1]\n        dataset = load_dataset(extension, data_files=data_files, cache_dir=model_args.cache_dir, token=model_args.token)\n    model = FlaxVisionEncoderDecoderModel.from_pretrained(model_args.model_name_or_path, seed=training_args.seed, dtype=getattr(jnp, model_args.dtype), token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    image_processor = AutoImageProcessor.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir, token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    tokenizer = AutoTokenizer.from_pretrained(model_args.model_name_or_path, cache_dir=model_args.cache_dir, use_fast=model_args.use_fast_tokenizer, token=model_args.token, trust_remote_code=model_args.trust_remote_code)\n    tokenizer.pad_token = tokenizer.convert_ids_to_tokens(model.config.pad_token_id)\n    if training_args.do_train:\n        column_names = dataset['train'].column_names\n    elif training_args.do_eval:\n        column_names = dataset['validation'].column_names\n    elif training_args.do_predict:\n        column_names = dataset['test'].column_names\n    else:\n        logger.info('There is nothing to do. Please pass `do_train`, `do_eval` and/or `do_predict`.')\n        return\n    dataset_columns = image_captioning_name_mapping.get(data_args.dataset_name, None)\n    if data_args.image_column is None:\n        if dataset_columns is None:\n            raise ValueError(f\"`--dataset_name` {data_args.dataset_name} not found in dataset '{data_args.dataset_name}'. Make sure to set `--dataset_name` to the correct dataset name, one of {', '.join(image_captioning_name_mapping.keys())}.\")\n        image_column = dataset_columns[0]\n    else:\n        image_column = data_args.image_column\n        if image_column not in column_names:\n            raise ValueError(f\"--image_column' value '{data_args.image_column}' needs to be one of: {', '.join(column_names)}\")\n    if data_args.caption_column is None:\n        if dataset_columns is None:\n            raise ValueError(f\"`--dataset_name` {data_args.dataset_name} not found in dataset '{data_args.dataset_name}'. Make sure to set `--dataset_name` to the correct dataset name, one of {', '.join(image_captioning_name_mapping.keys())}.\")\n        caption_column = dataset_columns[1]\n    else:\n        caption_column = data_args.caption_column\n        if caption_column not in column_names:\n            raise ValueError(f\"--caption_column' value '{data_args.caption_column}' needs to be one of: {', '.join(column_names)}\")\n    model_module = __import__(model.__module__, fromlist=['shift_tokens_right'])\n    shift_tokens_right_fn = getattr(model_module, 'shift_tokens_right', shift_tokens_right)\n\n    def filter_fn(examples):\n        \"\"\"remove problematic images\"\"\"\n        bools = []\n        for image_file in examples[image_column]:\n            try:\n                image = Image.open(image_file)\n                image_processor(images=image, return_tensors='np')\n                bools.append(True)\n            except Exception:\n                bools.append(False)\n        return bools\n\n    def tokenization_fn(examples, max_target_length):\n        \"\"\"Run tokenization on captions.\"\"\"\n        captions = []\n        for caption in examples[caption_column]:\n            captions.append(caption.lower() + ' ' + tokenizer.eos_token)\n        targets = captions\n        model_inputs = {}\n        labels = tokenizer(text_target=targets, max_length=max_target_length, padding='max_length', truncation=True, return_tensors='np')\n        model_inputs['labels'] = labels['input_ids']\n        decoder_input_ids = shift_tokens_right_fn(labels['input_ids'], model.config.pad_token_id, model.config.decoder_start_token_id)\n        model_inputs['decoder_input_ids'] = np.asarray(decoder_input_ids)\n        model_inputs['decoder_attention_mask'] = labels['attention_mask']\n        model_inputs[image_column] = examples[image_column]\n        return model_inputs\n\n    def image_processing_fn(examples, check_image=True):\n        \"\"\"\n        Run preprocessing on images\n\n        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\n        Otherwise, an exception will be thrown.\n        \"\"\"\n        model_inputs = {}\n        if check_image:\n            images = []\n            to_keep = []\n            for image_file in examples[image_column]:\n                try:\n                    img = Image.open(image_file)\n                    images.append(img)\n                    to_keep.append(True)\n                except Exception:\n                    to_keep.append(False)\n            for (k, v) in examples.items():\n                if k != image_column:\n                    model_inputs[k] = v[to_keep]\n        else:\n            images = [Image.open(image_file) for image_file in examples[image_column]]\n        encoder_inputs = image_processor(images=images, return_tensors='np')\n        model_inputs['pixel_values'] = encoder_inputs.pixel_values\n        return model_inputs\n\n    def preprocess_fn(examples, max_target_length, check_image=True):\n        \"\"\"Run tokenization + image processing\"\"\"\n        model_inputs = {}\n        model_inputs.update(tokenization_fn(examples, max_target_length))\n        model_inputs.update(image_processing_fn(model_inputs, check_image=check_image))\n        model_inputs.pop(image_column)\n        return model_inputs\n    features = datasets.Features({'pixel_values': datasets.Array3D(shape=(getattr(model.config.encoder, 'num_channels', 3), model.config.encoder.image_size, model.config.encoder.image_size), dtype='float32'), 'labels': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None), 'decoder_input_ids': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None), 'decoder_attention_mask': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None)})\n    run_img_proc_at_beginning = training_args.block_size == 0\n    function_kwarg = preprocess_fn if run_img_proc_at_beginning else tokenization_fn\n    features_kwarg = features if run_img_proc_at_beginning else None\n    remove_columns_kwarg = [x for x in column_names if x != image_column or run_img_proc_at_beginning]\n    processor_names = 'tokenizer and image processor' if run_img_proc_at_beginning else 'tokenizer'\n    train_batch_size = int(training_args.per_device_train_batch_size) * jax.device_count()\n    eval_batch_size = int(training_args.per_device_eval_batch_size) * jax.device_count()\n    if training_args.block_size % train_batch_size > 0 or training_args.block_size % eval_batch_size > 0:\n        raise ValueError(f'`training_args.block_size` needs to be a multiple of the global train/eval batch size. Got {training_args.block_size}, {train_batch_size} and {eval_batch_size} respectively instead.')\n    if training_args.do_train:\n        if 'train' not in dataset:\n            raise ValueError('--do_train requires a train dataset')\n        train_dataset = dataset['train']\n        if data_args.max_train_samples is not None:\n            max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n            train_dataset = train_dataset.select(range(max_train_samples))\n        if not run_img_proc_at_beginning:\n            train_dataset = train_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        train_dataset = train_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on train dataset', fn_kwargs={'max_target_length': data_args.max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            train_dataset = train_dataset.with_format('numpy')\n        steps_per_epoch = len(train_dataset) // train_batch_size\n        num_train_examples_per_epoch = steps_per_epoch * train_batch_size\n        num_epochs = int(training_args.num_train_epochs)\n        total_train_steps = steps_per_epoch * num_epochs\n    else:\n        num_train_examples_per_epoch = 0\n    if training_args.do_eval:\n        if 'validation' not in dataset:\n            raise ValueError('--do_eval requires a validation dataset')\n        eval_dataset = dataset['validation']\n        if data_args.max_eval_samples is not None:\n            max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n            eval_dataset = eval_dataset.select(range(max_eval_samples))\n        if not run_img_proc_at_beginning:\n            eval_dataset = eval_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        eval_dataset = eval_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on validation dataset', fn_kwargs={'max_target_length': data_args.val_max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            eval_dataset = eval_dataset.with_format('numpy')\n        num_eval_examples = len(eval_dataset)\n        eval_steps = num_eval_examples // eval_batch_size\n    if training_args.do_predict:\n        if 'test' not in dataset:\n            raise ValueError('--do_predict requires a test dataset')\n        predict_dataset = dataset['test']\n        if data_args.max_predict_samples is not None:\n            max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)\n            predict_dataset = predict_dataset.select(range(max_predict_samples))\n        if not run_img_proc_at_beginning:\n            predict_dataset = predict_dataset.filter(filter_fn, batched=True, num_proc=data_args.preprocessing_num_workers)\n        predict_dataset = predict_dataset.map(function=function_kwarg, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=remove_columns_kwarg, load_from_cache_file=not data_args.overwrite_cache, desc=f'Running {processor_names} on prediction dataset', fn_kwargs={'max_target_length': data_args.val_max_target_length}, features=features_kwarg)\n        if run_img_proc_at_beginning:\n            predict_dataset = predict_dataset.with_format('numpy')\n        num_test_examples = len(predict_dataset)\n        test_steps = num_test_examples // eval_batch_size\n\n    def blockwise_data_loader(rng: jax.random.PRNGKey, ds: Dataset, block_size: int, batch_size: int, shuffle: bool=False, keep_in_memory: bool=False, split: str=''):\n        \"\"\"\n        Wrap the simple `data_loader` in a block-wise way if `block_size` > 0, else it's the same as `data_loader`.\n\n        If `block_size` > 0, it requires `ds` to have a column that gives image paths in order to perform image\n        processing (with the column name being specified by `image_column`). The tokenization should be done before\n        training in this case.\n        \"\"\"\n        if shuffle:\n            indices = jax.random.permutation(rng, len(ds))\n            indices = np.asarray(indices)\n        else:\n            indices = np.arange(len(ds))\n        _block_size = len(ds) if not block_size else block_size\n        steps_per_block = _block_size // batch_size\n        num_examples = len(ds)\n        steps = num_examples // batch_size\n        num_splits = steps // steps_per_block + int(steps % steps_per_block > 0)\n        for idx in range(num_splits):\n            if not block_size:\n                _ds = ds\n            else:\n                start_idx = block_size * idx\n                end_idx = block_size * (idx + 1)\n                selected_indices = indices[start_idx:end_idx]\n                _ds = ds.select(selected_indices)\n                _ds = _ds.map(image_processing_fn, batched=True, num_proc=data_args.preprocessing_num_workers, remove_columns=[image_column], load_from_cache_file=not data_args.overwrite_cache, features=features, keep_in_memory=keep_in_memory, fn_kwargs={'check_image': False}, desc=f'Running image processing on {split} dataset'.replace('  ', ' '))\n                _ds = _ds.with_format('numpy')\n            loader = data_loader(rng, _ds, batch_size=batch_size, shuffle=False)\n            for batch in loader:\n                yield batch\n    metric = evaluate.load('rouge')\n\n    def postprocess_text(preds, labels):\n        preds = [pred.strip() for pred in preds]\n        labels = [label.strip() for label in labels]\n        preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in preds]\n        labels = ['\\n'.join(nltk.sent_tokenize(label)) for label in labels]\n        return (preds, labels)\n\n    def compute_metrics(preds, labels):\n        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n        (decoded_preds, decoded_labels) = postprocess_text(decoded_preds, decoded_labels)\n        result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n        result = {key: value.mid.fmeasure * 100 for (key, value) in result.items()}\n        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n        result['gen_len'] = np.mean(prediction_lens)\n        result = {k: round(v, 6) for (k, v) in result.items()}\n        return (result, decoded_preds, decoded_labels)\n    has_tensorboard = is_tensorboard_available()\n    if has_tensorboard and jax.process_index() == 0:\n        try:\n            from flax.metrics.tensorboard import SummaryWriter\n            summary_writer = SummaryWriter(log_dir=Path(training_args.output_dir))\n        except ImportError as ie:\n            has_tensorboard = False\n            logger.warning(f'Unable to display metrics through TensorBoard because some package are not installed: {ie}')\n    else:\n        logger.warning('Unable to display metrics through TensorBoard because the package is not installed: Please run pip install tensorboard to enable.')\n    rng = jax.random.PRNGKey(training_args.seed)\n    (rng, dropout_rng) = jax.random.split(rng)\n    linear_decay_lr_schedule_fn = create_learning_rate_fn(num_train_examples_per_epoch, train_batch_size, training_args.num_train_epochs, training_args.warmup_steps, training_args.learning_rate)\n\n    def decay_mask_fn(params):\n        flat_params = traverse_util.flatten_dict(params)\n        layer_norm_candidates = ['layernorm', 'layer_norm', 'ln']\n        layer_norm_named_params = {layer[-2:] for layer_norm_name in layer_norm_candidates for layer in flat_params.keys() if layer_norm_name in ''.join(layer).lower()}\n        flat_mask = {path: path[-1] != 'bias' and path[-2:] not in layer_norm_named_params for path in flat_params}\n        return traverse_util.unflatten_dict(flat_mask)\n    adamw = optax.adamw(learning_rate=linear_decay_lr_schedule_fn, b1=training_args.adam_beta1, b2=training_args.adam_beta2, eps=training_args.adam_epsilon, weight_decay=training_args.weight_decay, mask=decay_mask_fn)\n    state = TrainState.create(apply_fn=model.__call__, params=model.params, tx=adamw, dropout_rng=dropout_rng)\n\n    def loss_fn(logits, labels, padding_mask, label_smoothing_factor=0.0):\n        \"\"\"\n        The label smoothing implementation is adapted from Flax's official example:\n        https://github.com/google/flax/blob/87a211135c6a377c8f29048a1cac3840e38b9da4/examples/wmt/train.py#L104\n        \"\"\"\n        vocab_size = logits.shape[-1]\n        confidence = 1.0 - label_smoothing_factor\n        low_confidence = (1.0 - confidence) / (vocab_size - 1)\n        normalizing_constant = -(confidence * jnp.log(confidence) + (vocab_size - 1) * low_confidence * jnp.log(low_confidence + 1e-20))\n        soft_labels = onehot(labels, vocab_size, on_value=confidence, off_value=low_confidence)\n        loss = optax.softmax_cross_entropy(logits, soft_labels)\n        loss = loss - normalizing_constant\n        loss = loss * padding_mask\n        loss = loss.sum()\n        num_labels = padding_mask.sum()\n        return (loss, num_labels)\n\n    def train_step(state, batch, label_smoothing_factor=0.0):\n        (dropout_rng, new_dropout_rng) = jax.random.split(state.dropout_rng)\n\n        def compute_loss(params):\n            labels = batch.pop('labels')\n            logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n            (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n            return (loss, num_labels)\n        grad_fn = jax.value_and_grad(compute_loss, has_aux=True)\n        ((loss, num_labels), grad) = grad_fn(state.params)\n        num_labels = jax.lax.psum(num_labels, 'batch')\n        loss = jax.lax.psum(loss, 'batch')\n        loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n        grad = jax.lax.psum(grad, 'batch')\n        grad = jax.tree_util.tree_map(lambda x: x / num_labels, grad)\n        new_state = state.apply_gradients(grads=grad, dropout_rng=new_dropout_rng)\n        metrics = {'loss': loss, 'learning_rate': linear_decay_lr_schedule_fn(state.step)}\n        return (new_state, metrics)\n\n    def eval_step(params, batch, label_smoothing_factor=0.0):\n        labels = batch.pop('labels')\n        logits = model(**batch, params=params, train=False)[0]\n        (loss, num_labels) = loss_fn(logits, labels, batch['decoder_attention_mask'], label_smoothing_factor)\n        num_labels = jax.lax.psum(num_labels, 'batch')\n        loss = jax.lax.psum(loss, 'batch')\n        loss = jax.tree_util.tree_map(lambda x: x / num_labels, loss)\n        metrics = {'loss': loss}\n        return metrics\n    max_length = data_args.val_max_target_length if data_args.val_max_target_length is not None else model.config.max_length\n    num_beams = data_args.num_beams if data_args.num_beams is not None else model.config.num_beams\n    gen_kwargs = {'max_length': max_length, 'num_beams': num_beams}\n\n    def generate_step(params, batch):\n        model.params = params\n        output_ids = model.generate(batch['pixel_values'], **gen_kwargs)\n        return output_ids.sequences\n    p_train_step = jax.pmap(partial(train_step, label_smoothing_factor=training_args.label_smoothing_factor), 'batch', donate_argnums=(0,))\n    p_eval_step = jax.pmap(partial(eval_step, label_smoothing_factor=training_args.label_smoothing_factor), 'batch')\n    p_generate_step = jax.pmap(generate_step, 'batch')\n    state = state.replicate()\n    if training_args.do_train:\n        logger.info('***** Running training *****')\n        logger.info(f'  Num train examples = {num_train_examples_per_epoch}')\n        logger.info(f'  Num Epochs = {num_epochs}')\n        logger.info(f'  Instantaneous train batch size per device = {training_args.per_device_train_batch_size}')\n        logger.info(f'  Total train batch size (w. parallel & distributed) = {train_batch_size}')\n        logger.info(f'  Optimization steps per epoch = {steps_per_epoch}')\n        logger.info(f'  Total optimization steps = {total_train_steps}')\n    if training_args.do_eval:\n        logger.info(f'  Num evaluation examples = {num_eval_examples}')\n        logger.info(f'  Instantaneous evaluation batch size per device = {training_args.per_device_eval_batch_size}')\n        logger.info(f'  Total evaluation batch size (w. parallel & distributed) = {eval_batch_size}')\n        logger.info(f'  Evaluation steps = {eval_steps}')\n    if training_args.do_predict:\n        logger.info(f'  Num test examples = {num_test_examples}')\n        logger.info(f'  Instantaneous test batch size per device = {training_args.per_device_eval_batch_size}')\n        logger.info(f'  Total test batch size (w. parallel & distributed) = {eval_batch_size}')\n        logger.info(f'  Test steps = {test_steps}')\n    if not os.path.isdir(os.path.join(training_args.output_dir)):\n        os.makedirs(os.path.join(training_args.output_dir), exist_ok=True)\n\n    def save_ckpt(ckpt_dir: str, commit_msg: str=''):\n        \"\"\"save checkpoints and push to Hugging Face Hub if specified\"\"\"\n        if jax.process_index() == 0:\n            params = jax.device_get(jax.tree_util.tree_map(lambda x: x[0], state.params))\n            model.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir), params=params)\n            tokenizer.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir))\n            if training_args.push_to_hub:\n                repo.push_to_hub(commit_message=commit_msg, blocking=False)\n\n    def evaluation_loop(rng: jax.random.PRNGKey, dataset: Dataset, metric_key_prefix: str='eval', ckpt_dir: str='', is_prediction=False):\n        logger.info(f\"*** {('Predict' if is_prediction else 'Evaluate')} ***\")\n        metrics = []\n        preds = []\n        labels = []\n        batches = blockwise_data_loader(rng, dataset, block_size=training_args.block_size, batch_size=eval_batch_size, keep_in_memory=False, shuffle=False, split='prediction' if is_prediction else 'validation')\n        steps = len(dataset) // eval_batch_size\n        for _ in tqdm(range(steps), desc=f\"{('Predicting' if is_prediction else 'Evaluating')}...\", position=2, leave=False):\n            batch = next(batches)\n            _labels = batch.get('labels', None)\n            if not is_prediction and _labels is None:\n                raise ValueError('Evaluation requires the validation dataset to have `labels`')\n            if _labels is not None:\n                _metrics = p_eval_step(state.params, batch)\n                metrics.append(_metrics)\n            if data_args.predict_with_generate:\n                generated_ids = p_generate_step(state.params, batch)\n                preds.extend(jax.device_get(generated_ids.reshape(-1, gen_kwargs['max_length'])))\n                if _labels is not None:\n                    labels.extend(jax.device_get(_labels.reshape(-1, _labels.shape[-1])))\n        if metrics:\n            metrics = get_metrics(metrics)\n            metrics = jax.tree_util.tree_map(jnp.mean, metrics)\n        generations = []\n        rouge_desc = ''\n        if data_args.predict_with_generate:\n            if labels:\n                (rouge_metrics, decoded_preds, decoded_labels) = compute_metrics(preds, labels)\n                metrics.update(rouge_metrics)\n                rouge_desc = ' '.join([f\"{('Predict' if is_prediction else 'Eval')} {key}: {value} |\" for (key, value) in rouge_metrics.items()])\n                for (pred, label) in zip(decoded_preds, decoded_labels):\n                    pred = pred.replace('\\n', ' ')\n                    label = label.replace('\\n', ' ')\n                    generations.append({'label': label, 'pred': pred})\n            else:\n                decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n                decoded_preds = [pred.strip() for pred in decoded_preds]\n                decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred)) for pred in decoded_preds]\n                for pred in decoded_preds:\n                    pred = pred.replace('\\n', ' ')\n                    generations.append({'pred': pred})\n        if metrics:\n            desc = f\"{('Predict' if is_prediction else 'Eval')} Loss: {metrics['loss']} | {rouge_desc})\"\n            if training_args.do_train and (not is_prediction):\n                desc = f'Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | ' + desc\n                epochs.write(desc)\n                epochs.desc = desc\n            logger.info(desc)\n        if jax.process_index() == 0:\n            if not os.path.isdir(os.path.join(training_args.output_dir, ckpt_dir)):\n                os.makedirs(os.path.join(training_args.output_dir, ckpt_dir), exist_ok=True)\n            if metrics:\n                if has_tensorboard and training_args.do_train:\n                    write_metric(summary_writer, metrics, train_time=None, step=cur_step, metric_key_prefix=metric_key_prefix)\n                metrics = {f'{metric_key_prefix}_{metric_name}': round(value.item(), 6) for (metric_name, value) in metrics.items()}\n                _path = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_results.json')\n                with open(_path, 'w') as f:\n                    json.dump(metrics, f, indent=4, sort_keys=True)\n                with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                    fp.write(desc + '\\n')\n            if generations:\n                output_file = os.path.join(training_args.output_dir, ckpt_dir, f'{metric_key_prefix}_generation.json')\n                with open(output_file, 'w', encoding='UTF-8') as fp:\n                    json.dump(generations, fp, ensure_ascii=False, indent=4)\n\n    def evaluate(rng: jax.random.PRNGKey, dataset: Dataset, ckpt_dir: str=''):\n        evaluation_loop(rng, dataset, metric_key_prefix='eval', ckpt_dir=ckpt_dir)\n\n    def predict(rng: jax.random.PRNGKey, dataset: Dataset):\n        evaluation_loop(rng, dataset, metric_key_prefix='test', is_prediction=True)\n    input_rng = None\n    if training_args.do_train:\n        cur_step = 0\n        train_time = 0\n        epochs = tqdm(range(num_epochs), desc=f'Epoch ... (1/{num_epochs})', position=0)\n        for epoch in epochs:\n            (rng, input_rng) = jax.random.split(rng)\n            train_metrics = []\n            train_batches = blockwise_data_loader(input_rng, train_dataset, block_size=training_args.block_size, batch_size=train_batch_size, keep_in_memory=True, shuffle=True, split='train')\n            for (batch_idx, _) in enumerate(tqdm(range(steps_per_epoch), desc='Training...', position=1, leave=False)):\n                cur_step += 1\n                batch = next(train_batches)\n                batch_start = time.time()\n                (state, train_metric) = p_train_step(state, batch)\n                train_metrics.append(train_metric)\n                train_time += time.time() - batch_start\n                time_per_step = train_time / cur_step\n                if training_args.logging_steps > 0 and cur_step % training_args.logging_steps == 0:\n                    _train_metric = unreplicate(train_metric)\n                    desc = f\"Epoch... ({epoch + 1}/{num_epochs} | Step: {cur_step} | Loss: {_train_metric['loss']} | Learning Rate: {_train_metric['learning_rate']} | Time per step: {time_per_step})\"\n                    epochs.desc = desc\n                    epochs.write(desc)\n                    logger.info(desc)\n                    with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                        fp.write(desc + '\\n')\n                    if has_tensorboard and jax.process_index() == 0:\n                        write_metric(summary_writer, train_metrics, train_time=train_time, step=cur_step, metric_key_prefix='train')\n                if training_args.do_eval and (training_args.eval_steps is not None and training_args.eval_steps > 0) and (cur_step % training_args.eval_steps == 0):\n                    ckpt_dir = f'ckpt_epoch_{epoch + 1}_step_{cur_step}'\n                    commit_msg = f'Saving weights and logs of epoch {epoch + 1} - step {cur_step}'\n                    evaluate(input_rng, eval_dataset, ckpt_dir)\n                    save_ckpt(ckpt_dir=ckpt_dir, commit_msg=commit_msg)\n            if training_args.logging_steps <= 0:\n                logger.info(desc)\n                with open(os.path.join(training_args.output_dir, 'log'), 'a', encoding='UTF-8') as fp:\n                    fp.write(desc + '\\n')\n                if has_tensorboard and jax.process_index() == 0:\n                    write_metric(summary_writer, train_metrics, train_time=train_time, step=cur_step, metric_key_prefix='train')\n            if training_args.do_eval and (training_args.eval_steps is None or training_args.eval_steps <= 0):\n                ckpt_dir = f'ckpt_epoch_{epoch + 1}_step_{cur_step}'\n                commit_msg = f'Saving weights and logs of epoch {epoch + 1} - step {cur_step}'\n                evaluate(input_rng, eval_dataset, ckpt_dir)\n                save_ckpt(ckpt_dir=ckpt_dir, commit_msg=commit_msg)\n    if input_rng is None:\n        (rng, input_rng) = jax.random.split(rng)\n    if training_args.do_eval and (not training_args.do_train):\n        evaluate(input_rng, eval_dataset)\n    if training_args.do_predict:\n        predict(input_rng, predict_dataset)"
        ]
    }
]