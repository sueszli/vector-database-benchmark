[
    {
        "func_name": "test_pytorch_espresso",
        "original": "@pytest.mark.skip_module('espresso')\n@pytest.mark.skip_framework('tensorflow', 'tensorflow2v1', 'keras', 'kerastf', 'mxnet', 'non_dl_frameworks')\n@pytest.mark.parametrize('device_type', ['cpu'])\ndef test_pytorch_espresso(art_warning, expected_values, device_type):\n    import torch\n    from art.estimators.speech_recognition.pytorch_espresso import PyTorchEspresso\n    try:\n        speech_recognizer = PyTorchEspresso(model='librispeech_transformer', espresso_config_filepath=None, device_type=device_type)\n        expected_data = expected_values()\n        x1 = expected_data['x1']\n        x2 = expected_data['x2']\n        x3 = expected_data['x3']\n        expected_transcriptions1 = expected_data['expected_transcriptions1']\n        expected_transcriptions2 = expected_data['expected_transcriptions2']\n        expected_gradients1 = expected_data['expected_gradients1']\n        expected_gradients2 = expected_data['expected_gradients2']\n        expected_gradients3 = expected_data['expected_gradients3']\n        x = np.array([np.array(x1 * 100, dtype=ART_NUMPY_DTYPE), np.array(x2 * 100, dtype=ART_NUMPY_DTYPE), np.array(x3 * 100, dtype=ART_NUMPY_DTYPE)])\n        y = np.array(['SIX', 'HI', 'GOOD'])\n        _ = speech_recognizer.predict(x[[0]], batch_size=2)\n        transcriptions = speech_recognizer.predict(x, batch_size=2)\n        assert (expected_transcriptions1 == transcriptions).all()\n        transcriptions = speech_recognizer.predict(np.array([x[0]]), batch_size=2)\n        assert (expected_transcriptions2 == transcriptions).all()\n        grads = speech_recognizer.loss_gradient(x, y)\n        assert grads[0].shape == (1300,)\n        assert grads[1].shape == (1500,)\n        assert grads[2].shape == (1400,)\n        np.testing.assert_array_almost_equal(grads[0][:20], expected_gradients1, decimal=-2)\n        np.testing.assert_array_almost_equal(grads[1][:20], expected_gradients2, decimal=-2)\n        np.testing.assert_array_almost_equal(grads[2][:20], expected_gradients3, decimal=-2)\n        with pytest.raises(NotImplementedError):\n            speech_recognizer.fit(x=x, y=y, batch_size=2, nb_epochs=5)\n        local_batch_size = len(x)\n        real_lengths = np.array([x_.shape[0] for x_ in x])\n        local_max_length = np.max(real_lengths)\n        input_mask = np.zeros([local_batch_size, local_max_length], dtype=np.float64)\n        original_input = np.zeros([local_batch_size, local_max_length], dtype=np.float64)\n        for local_batch_size_idx in range(local_batch_size):\n            input_mask[local_batch_size_idx, :len(x[local_batch_size_idx])] = 1\n            original_input[local_batch_size_idx, :len(x[local_batch_size_idx])] = x[local_batch_size_idx]\n        (loss, decoded_output) = speech_recognizer.compute_loss_and_decoded_output(masked_adv_input=torch.tensor(original_input), original_output=y)\n        assert loss.detach().numpy() == pytest.approx(46.3156, abs=20.0)\n        assert all(decoded_output == ['EH', 'EH', 'EH'])\n    except ARTTestException as e:\n        art_warning(e)",
        "mutated": [
            "@pytest.mark.skip_module('espresso')\n@pytest.mark.skip_framework('tensorflow', 'tensorflow2v1', 'keras', 'kerastf', 'mxnet', 'non_dl_frameworks')\n@pytest.mark.parametrize('device_type', ['cpu'])\ndef test_pytorch_espresso(art_warning, expected_values, device_type):\n    if False:\n        i = 10\n    import torch\n    from art.estimators.speech_recognition.pytorch_espresso import PyTorchEspresso\n    try:\n        speech_recognizer = PyTorchEspresso(model='librispeech_transformer', espresso_config_filepath=None, device_type=device_type)\n        expected_data = expected_values()\n        x1 = expected_data['x1']\n        x2 = expected_data['x2']\n        x3 = expected_data['x3']\n        expected_transcriptions1 = expected_data['expected_transcriptions1']\n        expected_transcriptions2 = expected_data['expected_transcriptions2']\n        expected_gradients1 = expected_data['expected_gradients1']\n        expected_gradients2 = expected_data['expected_gradients2']\n        expected_gradients3 = expected_data['expected_gradients3']\n        x = np.array([np.array(x1 * 100, dtype=ART_NUMPY_DTYPE), np.array(x2 * 100, dtype=ART_NUMPY_DTYPE), np.array(x3 * 100, dtype=ART_NUMPY_DTYPE)])\n        y = np.array(['SIX', 'HI', 'GOOD'])\n        _ = speech_recognizer.predict(x[[0]], batch_size=2)\n        transcriptions = speech_recognizer.predict(x, batch_size=2)\n        assert (expected_transcriptions1 == transcriptions).all()\n        transcriptions = speech_recognizer.predict(np.array([x[0]]), batch_size=2)\n        assert (expected_transcriptions2 == transcriptions).all()\n        grads = speech_recognizer.loss_gradient(x, y)\n        assert grads[0].shape == (1300,)\n        assert grads[1].shape == (1500,)\n        assert grads[2].shape == (1400,)\n        np.testing.assert_array_almost_equal(grads[0][:20], expected_gradients1, decimal=-2)\n        np.testing.assert_array_almost_equal(grads[1][:20], expected_gradients2, decimal=-2)\n        np.testing.assert_array_almost_equal(grads[2][:20], expected_gradients3, decimal=-2)\n        with pytest.raises(NotImplementedError):\n            speech_recognizer.fit(x=x, y=y, batch_size=2, nb_epochs=5)\n        local_batch_size = len(x)\n        real_lengths = np.array([x_.shape[0] for x_ in x])\n        local_max_length = np.max(real_lengths)\n        input_mask = np.zeros([local_batch_size, local_max_length], dtype=np.float64)\n        original_input = np.zeros([local_batch_size, local_max_length], dtype=np.float64)\n        for local_batch_size_idx in range(local_batch_size):\n            input_mask[local_batch_size_idx, :len(x[local_batch_size_idx])] = 1\n            original_input[local_batch_size_idx, :len(x[local_batch_size_idx])] = x[local_batch_size_idx]\n        (loss, decoded_output) = speech_recognizer.compute_loss_and_decoded_output(masked_adv_input=torch.tensor(original_input), original_output=y)\n        assert loss.detach().numpy() == pytest.approx(46.3156, abs=20.0)\n        assert all(decoded_output == ['EH', 'EH', 'EH'])\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_module('espresso')\n@pytest.mark.skip_framework('tensorflow', 'tensorflow2v1', 'keras', 'kerastf', 'mxnet', 'non_dl_frameworks')\n@pytest.mark.parametrize('device_type', ['cpu'])\ndef test_pytorch_espresso(art_warning, expected_values, device_type):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    import torch\n    from art.estimators.speech_recognition.pytorch_espresso import PyTorchEspresso\n    try:\n        speech_recognizer = PyTorchEspresso(model='librispeech_transformer', espresso_config_filepath=None, device_type=device_type)\n        expected_data = expected_values()\n        x1 = expected_data['x1']\n        x2 = expected_data['x2']\n        x3 = expected_data['x3']\n        expected_transcriptions1 = expected_data['expected_transcriptions1']\n        expected_transcriptions2 = expected_data['expected_transcriptions2']\n        expected_gradients1 = expected_data['expected_gradients1']\n        expected_gradients2 = expected_data['expected_gradients2']\n        expected_gradients3 = expected_data['expected_gradients3']\n        x = np.array([np.array(x1 * 100, dtype=ART_NUMPY_DTYPE), np.array(x2 * 100, dtype=ART_NUMPY_DTYPE), np.array(x3 * 100, dtype=ART_NUMPY_DTYPE)])\n        y = np.array(['SIX', 'HI', 'GOOD'])\n        _ = speech_recognizer.predict(x[[0]], batch_size=2)\n        transcriptions = speech_recognizer.predict(x, batch_size=2)\n        assert (expected_transcriptions1 == transcriptions).all()\n        transcriptions = speech_recognizer.predict(np.array([x[0]]), batch_size=2)\n        assert (expected_transcriptions2 == transcriptions).all()\n        grads = speech_recognizer.loss_gradient(x, y)\n        assert grads[0].shape == (1300,)\n        assert grads[1].shape == (1500,)\n        assert grads[2].shape == (1400,)\n        np.testing.assert_array_almost_equal(grads[0][:20], expected_gradients1, decimal=-2)\n        np.testing.assert_array_almost_equal(grads[1][:20], expected_gradients2, decimal=-2)\n        np.testing.assert_array_almost_equal(grads[2][:20], expected_gradients3, decimal=-2)\n        with pytest.raises(NotImplementedError):\n            speech_recognizer.fit(x=x, y=y, batch_size=2, nb_epochs=5)\n        local_batch_size = len(x)\n        real_lengths = np.array([x_.shape[0] for x_ in x])\n        local_max_length = np.max(real_lengths)\n        input_mask = np.zeros([local_batch_size, local_max_length], dtype=np.float64)\n        original_input = np.zeros([local_batch_size, local_max_length], dtype=np.float64)\n        for local_batch_size_idx in range(local_batch_size):\n            input_mask[local_batch_size_idx, :len(x[local_batch_size_idx])] = 1\n            original_input[local_batch_size_idx, :len(x[local_batch_size_idx])] = x[local_batch_size_idx]\n        (loss, decoded_output) = speech_recognizer.compute_loss_and_decoded_output(masked_adv_input=torch.tensor(original_input), original_output=y)\n        assert loss.detach().numpy() == pytest.approx(46.3156, abs=20.0)\n        assert all(decoded_output == ['EH', 'EH', 'EH'])\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_module('espresso')\n@pytest.mark.skip_framework('tensorflow', 'tensorflow2v1', 'keras', 'kerastf', 'mxnet', 'non_dl_frameworks')\n@pytest.mark.parametrize('device_type', ['cpu'])\ndef test_pytorch_espresso(art_warning, expected_values, device_type):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    import torch\n    from art.estimators.speech_recognition.pytorch_espresso import PyTorchEspresso\n    try:\n        speech_recognizer = PyTorchEspresso(model='librispeech_transformer', espresso_config_filepath=None, device_type=device_type)\n        expected_data = expected_values()\n        x1 = expected_data['x1']\n        x2 = expected_data['x2']\n        x3 = expected_data['x3']\n        expected_transcriptions1 = expected_data['expected_transcriptions1']\n        expected_transcriptions2 = expected_data['expected_transcriptions2']\n        expected_gradients1 = expected_data['expected_gradients1']\n        expected_gradients2 = expected_data['expected_gradients2']\n        expected_gradients3 = expected_data['expected_gradients3']\n        x = np.array([np.array(x1 * 100, dtype=ART_NUMPY_DTYPE), np.array(x2 * 100, dtype=ART_NUMPY_DTYPE), np.array(x3 * 100, dtype=ART_NUMPY_DTYPE)])\n        y = np.array(['SIX', 'HI', 'GOOD'])\n        _ = speech_recognizer.predict(x[[0]], batch_size=2)\n        transcriptions = speech_recognizer.predict(x, batch_size=2)\n        assert (expected_transcriptions1 == transcriptions).all()\n        transcriptions = speech_recognizer.predict(np.array([x[0]]), batch_size=2)\n        assert (expected_transcriptions2 == transcriptions).all()\n        grads = speech_recognizer.loss_gradient(x, y)\n        assert grads[0].shape == (1300,)\n        assert grads[1].shape == (1500,)\n        assert grads[2].shape == (1400,)\n        np.testing.assert_array_almost_equal(grads[0][:20], expected_gradients1, decimal=-2)\n        np.testing.assert_array_almost_equal(grads[1][:20], expected_gradients2, decimal=-2)\n        np.testing.assert_array_almost_equal(grads[2][:20], expected_gradients3, decimal=-2)\n        with pytest.raises(NotImplementedError):\n            speech_recognizer.fit(x=x, y=y, batch_size=2, nb_epochs=5)\n        local_batch_size = len(x)\n        real_lengths = np.array([x_.shape[0] for x_ in x])\n        local_max_length = np.max(real_lengths)\n        input_mask = np.zeros([local_batch_size, local_max_length], dtype=np.float64)\n        original_input = np.zeros([local_batch_size, local_max_length], dtype=np.float64)\n        for local_batch_size_idx in range(local_batch_size):\n            input_mask[local_batch_size_idx, :len(x[local_batch_size_idx])] = 1\n            original_input[local_batch_size_idx, :len(x[local_batch_size_idx])] = x[local_batch_size_idx]\n        (loss, decoded_output) = speech_recognizer.compute_loss_and_decoded_output(masked_adv_input=torch.tensor(original_input), original_output=y)\n        assert loss.detach().numpy() == pytest.approx(46.3156, abs=20.0)\n        assert all(decoded_output == ['EH', 'EH', 'EH'])\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_module('espresso')\n@pytest.mark.skip_framework('tensorflow', 'tensorflow2v1', 'keras', 'kerastf', 'mxnet', 'non_dl_frameworks')\n@pytest.mark.parametrize('device_type', ['cpu'])\ndef test_pytorch_espresso(art_warning, expected_values, device_type):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    import torch\n    from art.estimators.speech_recognition.pytorch_espresso import PyTorchEspresso\n    try:\n        speech_recognizer = PyTorchEspresso(model='librispeech_transformer', espresso_config_filepath=None, device_type=device_type)\n        expected_data = expected_values()\n        x1 = expected_data['x1']\n        x2 = expected_data['x2']\n        x3 = expected_data['x3']\n        expected_transcriptions1 = expected_data['expected_transcriptions1']\n        expected_transcriptions2 = expected_data['expected_transcriptions2']\n        expected_gradients1 = expected_data['expected_gradients1']\n        expected_gradients2 = expected_data['expected_gradients2']\n        expected_gradients3 = expected_data['expected_gradients3']\n        x = np.array([np.array(x1 * 100, dtype=ART_NUMPY_DTYPE), np.array(x2 * 100, dtype=ART_NUMPY_DTYPE), np.array(x3 * 100, dtype=ART_NUMPY_DTYPE)])\n        y = np.array(['SIX', 'HI', 'GOOD'])\n        _ = speech_recognizer.predict(x[[0]], batch_size=2)\n        transcriptions = speech_recognizer.predict(x, batch_size=2)\n        assert (expected_transcriptions1 == transcriptions).all()\n        transcriptions = speech_recognizer.predict(np.array([x[0]]), batch_size=2)\n        assert (expected_transcriptions2 == transcriptions).all()\n        grads = speech_recognizer.loss_gradient(x, y)\n        assert grads[0].shape == (1300,)\n        assert grads[1].shape == (1500,)\n        assert grads[2].shape == (1400,)\n        np.testing.assert_array_almost_equal(grads[0][:20], expected_gradients1, decimal=-2)\n        np.testing.assert_array_almost_equal(grads[1][:20], expected_gradients2, decimal=-2)\n        np.testing.assert_array_almost_equal(grads[2][:20], expected_gradients3, decimal=-2)\n        with pytest.raises(NotImplementedError):\n            speech_recognizer.fit(x=x, y=y, batch_size=2, nb_epochs=5)\n        local_batch_size = len(x)\n        real_lengths = np.array([x_.shape[0] for x_ in x])\n        local_max_length = np.max(real_lengths)\n        input_mask = np.zeros([local_batch_size, local_max_length], dtype=np.float64)\n        original_input = np.zeros([local_batch_size, local_max_length], dtype=np.float64)\n        for local_batch_size_idx in range(local_batch_size):\n            input_mask[local_batch_size_idx, :len(x[local_batch_size_idx])] = 1\n            original_input[local_batch_size_idx, :len(x[local_batch_size_idx])] = x[local_batch_size_idx]\n        (loss, decoded_output) = speech_recognizer.compute_loss_and_decoded_output(masked_adv_input=torch.tensor(original_input), original_output=y)\n        assert loss.detach().numpy() == pytest.approx(46.3156, abs=20.0)\n        assert all(decoded_output == ['EH', 'EH', 'EH'])\n    except ARTTestException as e:\n        art_warning(e)",
            "@pytest.mark.skip_module('espresso')\n@pytest.mark.skip_framework('tensorflow', 'tensorflow2v1', 'keras', 'kerastf', 'mxnet', 'non_dl_frameworks')\n@pytest.mark.parametrize('device_type', ['cpu'])\ndef test_pytorch_espresso(art_warning, expected_values, device_type):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    import torch\n    from art.estimators.speech_recognition.pytorch_espresso import PyTorchEspresso\n    try:\n        speech_recognizer = PyTorchEspresso(model='librispeech_transformer', espresso_config_filepath=None, device_type=device_type)\n        expected_data = expected_values()\n        x1 = expected_data['x1']\n        x2 = expected_data['x2']\n        x3 = expected_data['x3']\n        expected_transcriptions1 = expected_data['expected_transcriptions1']\n        expected_transcriptions2 = expected_data['expected_transcriptions2']\n        expected_gradients1 = expected_data['expected_gradients1']\n        expected_gradients2 = expected_data['expected_gradients2']\n        expected_gradients3 = expected_data['expected_gradients3']\n        x = np.array([np.array(x1 * 100, dtype=ART_NUMPY_DTYPE), np.array(x2 * 100, dtype=ART_NUMPY_DTYPE), np.array(x3 * 100, dtype=ART_NUMPY_DTYPE)])\n        y = np.array(['SIX', 'HI', 'GOOD'])\n        _ = speech_recognizer.predict(x[[0]], batch_size=2)\n        transcriptions = speech_recognizer.predict(x, batch_size=2)\n        assert (expected_transcriptions1 == transcriptions).all()\n        transcriptions = speech_recognizer.predict(np.array([x[0]]), batch_size=2)\n        assert (expected_transcriptions2 == transcriptions).all()\n        grads = speech_recognizer.loss_gradient(x, y)\n        assert grads[0].shape == (1300,)\n        assert grads[1].shape == (1500,)\n        assert grads[2].shape == (1400,)\n        np.testing.assert_array_almost_equal(grads[0][:20], expected_gradients1, decimal=-2)\n        np.testing.assert_array_almost_equal(grads[1][:20], expected_gradients2, decimal=-2)\n        np.testing.assert_array_almost_equal(grads[2][:20], expected_gradients3, decimal=-2)\n        with pytest.raises(NotImplementedError):\n            speech_recognizer.fit(x=x, y=y, batch_size=2, nb_epochs=5)\n        local_batch_size = len(x)\n        real_lengths = np.array([x_.shape[0] for x_ in x])\n        local_max_length = np.max(real_lengths)\n        input_mask = np.zeros([local_batch_size, local_max_length], dtype=np.float64)\n        original_input = np.zeros([local_batch_size, local_max_length], dtype=np.float64)\n        for local_batch_size_idx in range(local_batch_size):\n            input_mask[local_batch_size_idx, :len(x[local_batch_size_idx])] = 1\n            original_input[local_batch_size_idx, :len(x[local_batch_size_idx])] = x[local_batch_size_idx]\n        (loss, decoded_output) = speech_recognizer.compute_loss_and_decoded_output(masked_adv_input=torch.tensor(original_input), original_output=y)\n        assert loss.detach().numpy() == pytest.approx(46.3156, abs=20.0)\n        assert all(decoded_output == ['EH', 'EH', 'EH'])\n    except ARTTestException as e:\n        art_warning(e)"
        ]
    }
]