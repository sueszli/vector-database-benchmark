[
    {
        "func_name": "print_all_node_names",
        "original": "def print_all_node_names(model_file, is_BrainScript=True):\n    loaded_model = load_model(model_file)\n    if is_BrainScript:\n        loaded_model = combine([loaded_model.outputs[0]])\n    node_list = graph.depth_first_search(loaded_model, lambda x: x.is_output)\n    print('printing node information in the format')\n    print('node name (tensor shape)')\n    for node in node_list:\n        print(node.name, node.shape)",
        "mutated": [
            "def print_all_node_names(model_file, is_BrainScript=True):\n    if False:\n        i = 10\n    loaded_model = load_model(model_file)\n    if is_BrainScript:\n        loaded_model = combine([loaded_model.outputs[0]])\n    node_list = graph.depth_first_search(loaded_model, lambda x: x.is_output)\n    print('printing node information in the format')\n    print('node name (tensor shape)')\n    for node in node_list:\n        print(node.name, node.shape)",
            "def print_all_node_names(model_file, is_BrainScript=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    loaded_model = load_model(model_file)\n    if is_BrainScript:\n        loaded_model = combine([loaded_model.outputs[0]])\n    node_list = graph.depth_first_search(loaded_model, lambda x: x.is_output)\n    print('printing node information in the format')\n    print('node name (tensor shape)')\n    for node in node_list:\n        print(node.name, node.shape)",
            "def print_all_node_names(model_file, is_BrainScript=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    loaded_model = load_model(model_file)\n    if is_BrainScript:\n        loaded_model = combine([loaded_model.outputs[0]])\n    node_list = graph.depth_first_search(loaded_model, lambda x: x.is_output)\n    print('printing node information in the format')\n    print('node name (tensor shape)')\n    for node in node_list:\n        print(node.name, node.shape)",
            "def print_all_node_names(model_file, is_BrainScript=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    loaded_model = load_model(model_file)\n    if is_BrainScript:\n        loaded_model = combine([loaded_model.outputs[0]])\n    node_list = graph.depth_first_search(loaded_model, lambda x: x.is_output)\n    print('printing node information in the format')\n    print('node name (tensor shape)')\n    for node in node_list:\n        print(node.name, node.shape)",
            "def print_all_node_names(model_file, is_BrainScript=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    loaded_model = load_model(model_file)\n    if is_BrainScript:\n        loaded_model = combine([loaded_model.outputs[0]])\n    node_list = graph.depth_first_search(loaded_model, lambda x: x.is_output)\n    print('printing node information in the format')\n    print('node name (tensor shape)')\n    for node in node_list:\n        print(node.name, node.shape)"
        ]
    },
    {
        "func_name": "save_as_png",
        "original": "def save_as_png(val_array, img_file_name, dim=28):\n    img_array = val_array.reshape((dim, dim))\n    img_array = np.clip(img_array, 0, img_array.max())\n    img_array *= 255.0 / img_array.max()\n    img_array = np.rint(img_array).astype('uint8')\n    try:\n        os.remove(img_file_name)\n    except OSError:\n        pass\n    im = Image.fromarray(img_array)\n    im2 = im.resize((224, 224))\n    im2.save(img_file_name)",
        "mutated": [
            "def save_as_png(val_array, img_file_name, dim=28):\n    if False:\n        i = 10\n    img_array = val_array.reshape((dim, dim))\n    img_array = np.clip(img_array, 0, img_array.max())\n    img_array *= 255.0 / img_array.max()\n    img_array = np.rint(img_array).astype('uint8')\n    try:\n        os.remove(img_file_name)\n    except OSError:\n        pass\n    im = Image.fromarray(img_array)\n    im2 = im.resize((224, 224))\n    im2.save(img_file_name)",
            "def save_as_png(val_array, img_file_name, dim=28):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    img_array = val_array.reshape((dim, dim))\n    img_array = np.clip(img_array, 0, img_array.max())\n    img_array *= 255.0 / img_array.max()\n    img_array = np.rint(img_array).astype('uint8')\n    try:\n        os.remove(img_file_name)\n    except OSError:\n        pass\n    im = Image.fromarray(img_array)\n    im2 = im.resize((224, 224))\n    im2.save(img_file_name)",
            "def save_as_png(val_array, img_file_name, dim=28):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    img_array = val_array.reshape((dim, dim))\n    img_array = np.clip(img_array, 0, img_array.max())\n    img_array *= 255.0 / img_array.max()\n    img_array = np.rint(img_array).astype('uint8')\n    try:\n        os.remove(img_file_name)\n    except OSError:\n        pass\n    im = Image.fromarray(img_array)\n    im2 = im.resize((224, 224))\n    im2.save(img_file_name)",
            "def save_as_png(val_array, img_file_name, dim=28):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    img_array = val_array.reshape((dim, dim))\n    img_array = np.clip(img_array, 0, img_array.max())\n    img_array *= 255.0 / img_array.max()\n    img_array = np.rint(img_array).astype('uint8')\n    try:\n        os.remove(img_file_name)\n    except OSError:\n        pass\n    im = Image.fromarray(img_array)\n    im2 = im.resize((224, 224))\n    im2.save(img_file_name)",
            "def save_as_png(val_array, img_file_name, dim=28):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    img_array = val_array.reshape((dim, dim))\n    img_array = np.clip(img_array, 0, img_array.max())\n    img_array *= 255.0 / img_array.max()\n    img_array = np.rint(img_array).astype('uint8')\n    try:\n        os.remove(img_file_name)\n    except OSError:\n        pass\n    im = Image.fromarray(img_array)\n    im2 = im.resize((224, 224))\n    im2.save(img_file_name)"
        ]
    },
    {
        "func_name": "generate_visualization",
        "original": "def generate_visualization(use_brain_script_model, testing=False):\n    num_objects_to_eval = 5\n    if use_brain_script_model:\n        model_file_name = '07_Deconvolution_BS.model'\n        encoder_output_file_name = 'encoder_output_BS.txt'\n        decoder_output_file_name = 'decoder_output_BS.txt'\n        enc_node_name = 'z.pool1'\n        input_node_name = 'f2'\n        output_node_name = 'z'\n    else:\n        model_file_name = '07_Deconvolution_PY.model'\n        encoder_output_file_name = 'encoder_output_PY.txt'\n        decoder_output_file_name = 'decoder_output_PY.txt'\n        enc_node_name = 'pooling_node'\n        input_node_name = 'input_node'\n        output_node_name = 'output_node'\n    output_path = os.path.join(abs_path, 'Output')\n    model_file = os.path.join(model_path, model_file_name)\n    data_file = os.path.join(data_path, 'Test-28x28_cntk_text.txt')\n    if not (os.path.exists(model_file) and os.path.exists(data_file)):\n        print(\"Cannot find required data or model. Please get the MNIST data set and run 'cntk configFile=07_Deconvolution_BS.cntk' or 'python 07_Deconvolution_PY.py' to create the model.\")\n        exit(0)\n    minibatch_source = MinibatchSource(CTFDeserializer(data_file, StreamDefs(features=StreamDef(field='features', shape=28 * 28), labels=StreamDef(field='labels', shape=10))), randomize=False, max_sweeps=1)\n    loaded_model = load_model(model_file)\n    output_nodes = combine([loaded_model.find_by_name(input_node_name).owner, loaded_model.find_by_name(enc_node_name).owner, loaded_model.find_by_name(output_node_name).owner])\n    features_si = minibatch_source['features']\n    with open(os.path.join(output_path, decoder_output_file_name), 'wb') as decoder_text_file:\n        with open(os.path.join(output_path, encoder_output_file_name), 'wb') as encoder_text_file:\n            for i in range(0, num_objects_to_eval):\n                mb = minibatch_source.next_minibatch(1)\n                raw_dict = output_nodes.eval(mb[features_si])\n                output_dict = {}\n                for key in raw_dict.keys():\n                    output_dict[key.name] = raw_dict[key]\n                encoder_input = output_dict[input_node_name]\n                encoder_output = output_dict[enc_node_name]\n                decoder_output = output_dict[output_node_name]\n                in_values = encoder_input[0][0].flatten()[np.newaxis]\n                enc_values = encoder_output[0][0].flatten()[np.newaxis]\n                out_values = decoder_output[0][0].flatten()[np.newaxis]\n                if not testing:\n                    np.savetxt(decoder_text_file, out_values, fmt='%.6f')\n                    np.savetxt(encoder_text_file, enc_values, fmt='%.6f')\n                    save_as_png(in_values, os.path.join(output_path, 'imageAutoEncoder_%s__input.png' % i))\n                    save_as_png(out_values, os.path.join(output_path, 'imageAutoEncoder_%s_output.png' % i))\n                    enc_dim = 7\n                    if enc_values.size == enc_dim * enc_dim:\n                        save_as_png(enc_values, os.path.join(output_path, 'imageAutoEncoder_%s_encoding.png' % i), dim=enc_dim)\n    print('Done. Wrote output to %s' % output_path)",
        "mutated": [
            "def generate_visualization(use_brain_script_model, testing=False):\n    if False:\n        i = 10\n    num_objects_to_eval = 5\n    if use_brain_script_model:\n        model_file_name = '07_Deconvolution_BS.model'\n        encoder_output_file_name = 'encoder_output_BS.txt'\n        decoder_output_file_name = 'decoder_output_BS.txt'\n        enc_node_name = 'z.pool1'\n        input_node_name = 'f2'\n        output_node_name = 'z'\n    else:\n        model_file_name = '07_Deconvolution_PY.model'\n        encoder_output_file_name = 'encoder_output_PY.txt'\n        decoder_output_file_name = 'decoder_output_PY.txt'\n        enc_node_name = 'pooling_node'\n        input_node_name = 'input_node'\n        output_node_name = 'output_node'\n    output_path = os.path.join(abs_path, 'Output')\n    model_file = os.path.join(model_path, model_file_name)\n    data_file = os.path.join(data_path, 'Test-28x28_cntk_text.txt')\n    if not (os.path.exists(model_file) and os.path.exists(data_file)):\n        print(\"Cannot find required data or model. Please get the MNIST data set and run 'cntk configFile=07_Deconvolution_BS.cntk' or 'python 07_Deconvolution_PY.py' to create the model.\")\n        exit(0)\n    minibatch_source = MinibatchSource(CTFDeserializer(data_file, StreamDefs(features=StreamDef(field='features', shape=28 * 28), labels=StreamDef(field='labels', shape=10))), randomize=False, max_sweeps=1)\n    loaded_model = load_model(model_file)\n    output_nodes = combine([loaded_model.find_by_name(input_node_name).owner, loaded_model.find_by_name(enc_node_name).owner, loaded_model.find_by_name(output_node_name).owner])\n    features_si = minibatch_source['features']\n    with open(os.path.join(output_path, decoder_output_file_name), 'wb') as decoder_text_file:\n        with open(os.path.join(output_path, encoder_output_file_name), 'wb') as encoder_text_file:\n            for i in range(0, num_objects_to_eval):\n                mb = minibatch_source.next_minibatch(1)\n                raw_dict = output_nodes.eval(mb[features_si])\n                output_dict = {}\n                for key in raw_dict.keys():\n                    output_dict[key.name] = raw_dict[key]\n                encoder_input = output_dict[input_node_name]\n                encoder_output = output_dict[enc_node_name]\n                decoder_output = output_dict[output_node_name]\n                in_values = encoder_input[0][0].flatten()[np.newaxis]\n                enc_values = encoder_output[0][0].flatten()[np.newaxis]\n                out_values = decoder_output[0][0].flatten()[np.newaxis]\n                if not testing:\n                    np.savetxt(decoder_text_file, out_values, fmt='%.6f')\n                    np.savetxt(encoder_text_file, enc_values, fmt='%.6f')\n                    save_as_png(in_values, os.path.join(output_path, 'imageAutoEncoder_%s__input.png' % i))\n                    save_as_png(out_values, os.path.join(output_path, 'imageAutoEncoder_%s_output.png' % i))\n                    enc_dim = 7\n                    if enc_values.size == enc_dim * enc_dim:\n                        save_as_png(enc_values, os.path.join(output_path, 'imageAutoEncoder_%s_encoding.png' % i), dim=enc_dim)\n    print('Done. Wrote output to %s' % output_path)",
            "def generate_visualization(use_brain_script_model, testing=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    num_objects_to_eval = 5\n    if use_brain_script_model:\n        model_file_name = '07_Deconvolution_BS.model'\n        encoder_output_file_name = 'encoder_output_BS.txt'\n        decoder_output_file_name = 'decoder_output_BS.txt'\n        enc_node_name = 'z.pool1'\n        input_node_name = 'f2'\n        output_node_name = 'z'\n    else:\n        model_file_name = '07_Deconvolution_PY.model'\n        encoder_output_file_name = 'encoder_output_PY.txt'\n        decoder_output_file_name = 'decoder_output_PY.txt'\n        enc_node_name = 'pooling_node'\n        input_node_name = 'input_node'\n        output_node_name = 'output_node'\n    output_path = os.path.join(abs_path, 'Output')\n    model_file = os.path.join(model_path, model_file_name)\n    data_file = os.path.join(data_path, 'Test-28x28_cntk_text.txt')\n    if not (os.path.exists(model_file) and os.path.exists(data_file)):\n        print(\"Cannot find required data or model. Please get the MNIST data set and run 'cntk configFile=07_Deconvolution_BS.cntk' or 'python 07_Deconvolution_PY.py' to create the model.\")\n        exit(0)\n    minibatch_source = MinibatchSource(CTFDeserializer(data_file, StreamDefs(features=StreamDef(field='features', shape=28 * 28), labels=StreamDef(field='labels', shape=10))), randomize=False, max_sweeps=1)\n    loaded_model = load_model(model_file)\n    output_nodes = combine([loaded_model.find_by_name(input_node_name).owner, loaded_model.find_by_name(enc_node_name).owner, loaded_model.find_by_name(output_node_name).owner])\n    features_si = minibatch_source['features']\n    with open(os.path.join(output_path, decoder_output_file_name), 'wb') as decoder_text_file:\n        with open(os.path.join(output_path, encoder_output_file_name), 'wb') as encoder_text_file:\n            for i in range(0, num_objects_to_eval):\n                mb = minibatch_source.next_minibatch(1)\n                raw_dict = output_nodes.eval(mb[features_si])\n                output_dict = {}\n                for key in raw_dict.keys():\n                    output_dict[key.name] = raw_dict[key]\n                encoder_input = output_dict[input_node_name]\n                encoder_output = output_dict[enc_node_name]\n                decoder_output = output_dict[output_node_name]\n                in_values = encoder_input[0][0].flatten()[np.newaxis]\n                enc_values = encoder_output[0][0].flatten()[np.newaxis]\n                out_values = decoder_output[0][0].flatten()[np.newaxis]\n                if not testing:\n                    np.savetxt(decoder_text_file, out_values, fmt='%.6f')\n                    np.savetxt(encoder_text_file, enc_values, fmt='%.6f')\n                    save_as_png(in_values, os.path.join(output_path, 'imageAutoEncoder_%s__input.png' % i))\n                    save_as_png(out_values, os.path.join(output_path, 'imageAutoEncoder_%s_output.png' % i))\n                    enc_dim = 7\n                    if enc_values.size == enc_dim * enc_dim:\n                        save_as_png(enc_values, os.path.join(output_path, 'imageAutoEncoder_%s_encoding.png' % i), dim=enc_dim)\n    print('Done. Wrote output to %s' % output_path)",
            "def generate_visualization(use_brain_script_model, testing=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    num_objects_to_eval = 5\n    if use_brain_script_model:\n        model_file_name = '07_Deconvolution_BS.model'\n        encoder_output_file_name = 'encoder_output_BS.txt'\n        decoder_output_file_name = 'decoder_output_BS.txt'\n        enc_node_name = 'z.pool1'\n        input_node_name = 'f2'\n        output_node_name = 'z'\n    else:\n        model_file_name = '07_Deconvolution_PY.model'\n        encoder_output_file_name = 'encoder_output_PY.txt'\n        decoder_output_file_name = 'decoder_output_PY.txt'\n        enc_node_name = 'pooling_node'\n        input_node_name = 'input_node'\n        output_node_name = 'output_node'\n    output_path = os.path.join(abs_path, 'Output')\n    model_file = os.path.join(model_path, model_file_name)\n    data_file = os.path.join(data_path, 'Test-28x28_cntk_text.txt')\n    if not (os.path.exists(model_file) and os.path.exists(data_file)):\n        print(\"Cannot find required data or model. Please get the MNIST data set and run 'cntk configFile=07_Deconvolution_BS.cntk' or 'python 07_Deconvolution_PY.py' to create the model.\")\n        exit(0)\n    minibatch_source = MinibatchSource(CTFDeserializer(data_file, StreamDefs(features=StreamDef(field='features', shape=28 * 28), labels=StreamDef(field='labels', shape=10))), randomize=False, max_sweeps=1)\n    loaded_model = load_model(model_file)\n    output_nodes = combine([loaded_model.find_by_name(input_node_name).owner, loaded_model.find_by_name(enc_node_name).owner, loaded_model.find_by_name(output_node_name).owner])\n    features_si = minibatch_source['features']\n    with open(os.path.join(output_path, decoder_output_file_name), 'wb') as decoder_text_file:\n        with open(os.path.join(output_path, encoder_output_file_name), 'wb') as encoder_text_file:\n            for i in range(0, num_objects_to_eval):\n                mb = minibatch_source.next_minibatch(1)\n                raw_dict = output_nodes.eval(mb[features_si])\n                output_dict = {}\n                for key in raw_dict.keys():\n                    output_dict[key.name] = raw_dict[key]\n                encoder_input = output_dict[input_node_name]\n                encoder_output = output_dict[enc_node_name]\n                decoder_output = output_dict[output_node_name]\n                in_values = encoder_input[0][0].flatten()[np.newaxis]\n                enc_values = encoder_output[0][0].flatten()[np.newaxis]\n                out_values = decoder_output[0][0].flatten()[np.newaxis]\n                if not testing:\n                    np.savetxt(decoder_text_file, out_values, fmt='%.6f')\n                    np.savetxt(encoder_text_file, enc_values, fmt='%.6f')\n                    save_as_png(in_values, os.path.join(output_path, 'imageAutoEncoder_%s__input.png' % i))\n                    save_as_png(out_values, os.path.join(output_path, 'imageAutoEncoder_%s_output.png' % i))\n                    enc_dim = 7\n                    if enc_values.size == enc_dim * enc_dim:\n                        save_as_png(enc_values, os.path.join(output_path, 'imageAutoEncoder_%s_encoding.png' % i), dim=enc_dim)\n    print('Done. Wrote output to %s' % output_path)",
            "def generate_visualization(use_brain_script_model, testing=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    num_objects_to_eval = 5\n    if use_brain_script_model:\n        model_file_name = '07_Deconvolution_BS.model'\n        encoder_output_file_name = 'encoder_output_BS.txt'\n        decoder_output_file_name = 'decoder_output_BS.txt'\n        enc_node_name = 'z.pool1'\n        input_node_name = 'f2'\n        output_node_name = 'z'\n    else:\n        model_file_name = '07_Deconvolution_PY.model'\n        encoder_output_file_name = 'encoder_output_PY.txt'\n        decoder_output_file_name = 'decoder_output_PY.txt'\n        enc_node_name = 'pooling_node'\n        input_node_name = 'input_node'\n        output_node_name = 'output_node'\n    output_path = os.path.join(abs_path, 'Output')\n    model_file = os.path.join(model_path, model_file_name)\n    data_file = os.path.join(data_path, 'Test-28x28_cntk_text.txt')\n    if not (os.path.exists(model_file) and os.path.exists(data_file)):\n        print(\"Cannot find required data or model. Please get the MNIST data set and run 'cntk configFile=07_Deconvolution_BS.cntk' or 'python 07_Deconvolution_PY.py' to create the model.\")\n        exit(0)\n    minibatch_source = MinibatchSource(CTFDeserializer(data_file, StreamDefs(features=StreamDef(field='features', shape=28 * 28), labels=StreamDef(field='labels', shape=10))), randomize=False, max_sweeps=1)\n    loaded_model = load_model(model_file)\n    output_nodes = combine([loaded_model.find_by_name(input_node_name).owner, loaded_model.find_by_name(enc_node_name).owner, loaded_model.find_by_name(output_node_name).owner])\n    features_si = minibatch_source['features']\n    with open(os.path.join(output_path, decoder_output_file_name), 'wb') as decoder_text_file:\n        with open(os.path.join(output_path, encoder_output_file_name), 'wb') as encoder_text_file:\n            for i in range(0, num_objects_to_eval):\n                mb = minibatch_source.next_minibatch(1)\n                raw_dict = output_nodes.eval(mb[features_si])\n                output_dict = {}\n                for key in raw_dict.keys():\n                    output_dict[key.name] = raw_dict[key]\n                encoder_input = output_dict[input_node_name]\n                encoder_output = output_dict[enc_node_name]\n                decoder_output = output_dict[output_node_name]\n                in_values = encoder_input[0][0].flatten()[np.newaxis]\n                enc_values = encoder_output[0][0].flatten()[np.newaxis]\n                out_values = decoder_output[0][0].flatten()[np.newaxis]\n                if not testing:\n                    np.savetxt(decoder_text_file, out_values, fmt='%.6f')\n                    np.savetxt(encoder_text_file, enc_values, fmt='%.6f')\n                    save_as_png(in_values, os.path.join(output_path, 'imageAutoEncoder_%s__input.png' % i))\n                    save_as_png(out_values, os.path.join(output_path, 'imageAutoEncoder_%s_output.png' % i))\n                    enc_dim = 7\n                    if enc_values.size == enc_dim * enc_dim:\n                        save_as_png(enc_values, os.path.join(output_path, 'imageAutoEncoder_%s_encoding.png' % i), dim=enc_dim)\n    print('Done. Wrote output to %s' % output_path)",
            "def generate_visualization(use_brain_script_model, testing=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    num_objects_to_eval = 5\n    if use_brain_script_model:\n        model_file_name = '07_Deconvolution_BS.model'\n        encoder_output_file_name = 'encoder_output_BS.txt'\n        decoder_output_file_name = 'decoder_output_BS.txt'\n        enc_node_name = 'z.pool1'\n        input_node_name = 'f2'\n        output_node_name = 'z'\n    else:\n        model_file_name = '07_Deconvolution_PY.model'\n        encoder_output_file_name = 'encoder_output_PY.txt'\n        decoder_output_file_name = 'decoder_output_PY.txt'\n        enc_node_name = 'pooling_node'\n        input_node_name = 'input_node'\n        output_node_name = 'output_node'\n    output_path = os.path.join(abs_path, 'Output')\n    model_file = os.path.join(model_path, model_file_name)\n    data_file = os.path.join(data_path, 'Test-28x28_cntk_text.txt')\n    if not (os.path.exists(model_file) and os.path.exists(data_file)):\n        print(\"Cannot find required data or model. Please get the MNIST data set and run 'cntk configFile=07_Deconvolution_BS.cntk' or 'python 07_Deconvolution_PY.py' to create the model.\")\n        exit(0)\n    minibatch_source = MinibatchSource(CTFDeserializer(data_file, StreamDefs(features=StreamDef(field='features', shape=28 * 28), labels=StreamDef(field='labels', shape=10))), randomize=False, max_sweeps=1)\n    loaded_model = load_model(model_file)\n    output_nodes = combine([loaded_model.find_by_name(input_node_name).owner, loaded_model.find_by_name(enc_node_name).owner, loaded_model.find_by_name(output_node_name).owner])\n    features_si = minibatch_source['features']\n    with open(os.path.join(output_path, decoder_output_file_name), 'wb') as decoder_text_file:\n        with open(os.path.join(output_path, encoder_output_file_name), 'wb') as encoder_text_file:\n            for i in range(0, num_objects_to_eval):\n                mb = minibatch_source.next_minibatch(1)\n                raw_dict = output_nodes.eval(mb[features_si])\n                output_dict = {}\n                for key in raw_dict.keys():\n                    output_dict[key.name] = raw_dict[key]\n                encoder_input = output_dict[input_node_name]\n                encoder_output = output_dict[enc_node_name]\n                decoder_output = output_dict[output_node_name]\n                in_values = encoder_input[0][0].flatten()[np.newaxis]\n                enc_values = encoder_output[0][0].flatten()[np.newaxis]\n                out_values = decoder_output[0][0].flatten()[np.newaxis]\n                if not testing:\n                    np.savetxt(decoder_text_file, out_values, fmt='%.6f')\n                    np.savetxt(encoder_text_file, enc_values, fmt='%.6f')\n                    save_as_png(in_values, os.path.join(output_path, 'imageAutoEncoder_%s__input.png' % i))\n                    save_as_png(out_values, os.path.join(output_path, 'imageAutoEncoder_%s_output.png' % i))\n                    enc_dim = 7\n                    if enc_values.size == enc_dim * enc_dim:\n                        save_as_png(enc_values, os.path.join(output_path, 'imageAutoEncoder_%s_encoding.png' % i), dim=enc_dim)\n    print('Done. Wrote output to %s' % output_path)"
        ]
    }
]