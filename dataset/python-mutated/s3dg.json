[
    {
        "func_name": "s3dg_arg_scope",
        "original": "def s3dg_arg_scope(weight_decay=1e-07, batch_norm_decay=0.999, batch_norm_epsilon=0.001):\n    \"\"\"Defines default arg_scope for S3D-G.\n\n  Args:\n    weight_decay: The weight decay to use for regularizing the model.\n    batch_norm_decay: Decay for batch norm moving average.\n    batch_norm_epsilon: Small float added to variance to avoid dividing by zero\n      in batch norm.\n\n  Returns:\n    sc: An arg_scope to use for the models.\n  \"\"\"\n    batch_norm_params = {'decay': batch_norm_decay, 'epsilon': batch_norm_epsilon, 'fused': False, 'variables_collections': {'beta': None, 'gamma': None, 'moving_mean': ['moving_vars'], 'moving_variance': ['moving_vars']}}\n    with arg_scope([layers.conv3d, conv3d_spatiotemporal], weights_regularizer=layers.l2_regularizer(weight_decay), activation_fn=tf.nn.relu, normalizer_fn=layers.batch_norm, normalizer_params=batch_norm_params):\n        with arg_scope([conv3d_spatiotemporal], separable=True) as sc:\n            return sc",
        "mutated": [
            "def s3dg_arg_scope(weight_decay=1e-07, batch_norm_decay=0.999, batch_norm_epsilon=0.001):\n    if False:\n        i = 10\n    'Defines default arg_scope for S3D-G.\\n\\n  Args:\\n    weight_decay: The weight decay to use for regularizing the model.\\n    batch_norm_decay: Decay for batch norm moving average.\\n    batch_norm_epsilon: Small float added to variance to avoid dividing by zero\\n      in batch norm.\\n\\n  Returns:\\n    sc: An arg_scope to use for the models.\\n  '\n    batch_norm_params = {'decay': batch_norm_decay, 'epsilon': batch_norm_epsilon, 'fused': False, 'variables_collections': {'beta': None, 'gamma': None, 'moving_mean': ['moving_vars'], 'moving_variance': ['moving_vars']}}\n    with arg_scope([layers.conv3d, conv3d_spatiotemporal], weights_regularizer=layers.l2_regularizer(weight_decay), activation_fn=tf.nn.relu, normalizer_fn=layers.batch_norm, normalizer_params=batch_norm_params):\n        with arg_scope([conv3d_spatiotemporal], separable=True) as sc:\n            return sc",
            "def s3dg_arg_scope(weight_decay=1e-07, batch_norm_decay=0.999, batch_norm_epsilon=0.001):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Defines default arg_scope for S3D-G.\\n\\n  Args:\\n    weight_decay: The weight decay to use for regularizing the model.\\n    batch_norm_decay: Decay for batch norm moving average.\\n    batch_norm_epsilon: Small float added to variance to avoid dividing by zero\\n      in batch norm.\\n\\n  Returns:\\n    sc: An arg_scope to use for the models.\\n  '\n    batch_norm_params = {'decay': batch_norm_decay, 'epsilon': batch_norm_epsilon, 'fused': False, 'variables_collections': {'beta': None, 'gamma': None, 'moving_mean': ['moving_vars'], 'moving_variance': ['moving_vars']}}\n    with arg_scope([layers.conv3d, conv3d_spatiotemporal], weights_regularizer=layers.l2_regularizer(weight_decay), activation_fn=tf.nn.relu, normalizer_fn=layers.batch_norm, normalizer_params=batch_norm_params):\n        with arg_scope([conv3d_spatiotemporal], separable=True) as sc:\n            return sc",
            "def s3dg_arg_scope(weight_decay=1e-07, batch_norm_decay=0.999, batch_norm_epsilon=0.001):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Defines default arg_scope for S3D-G.\\n\\n  Args:\\n    weight_decay: The weight decay to use for regularizing the model.\\n    batch_norm_decay: Decay for batch norm moving average.\\n    batch_norm_epsilon: Small float added to variance to avoid dividing by zero\\n      in batch norm.\\n\\n  Returns:\\n    sc: An arg_scope to use for the models.\\n  '\n    batch_norm_params = {'decay': batch_norm_decay, 'epsilon': batch_norm_epsilon, 'fused': False, 'variables_collections': {'beta': None, 'gamma': None, 'moving_mean': ['moving_vars'], 'moving_variance': ['moving_vars']}}\n    with arg_scope([layers.conv3d, conv3d_spatiotemporal], weights_regularizer=layers.l2_regularizer(weight_decay), activation_fn=tf.nn.relu, normalizer_fn=layers.batch_norm, normalizer_params=batch_norm_params):\n        with arg_scope([conv3d_spatiotemporal], separable=True) as sc:\n            return sc",
            "def s3dg_arg_scope(weight_decay=1e-07, batch_norm_decay=0.999, batch_norm_epsilon=0.001):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Defines default arg_scope for S3D-G.\\n\\n  Args:\\n    weight_decay: The weight decay to use for regularizing the model.\\n    batch_norm_decay: Decay for batch norm moving average.\\n    batch_norm_epsilon: Small float added to variance to avoid dividing by zero\\n      in batch norm.\\n\\n  Returns:\\n    sc: An arg_scope to use for the models.\\n  '\n    batch_norm_params = {'decay': batch_norm_decay, 'epsilon': batch_norm_epsilon, 'fused': False, 'variables_collections': {'beta': None, 'gamma': None, 'moving_mean': ['moving_vars'], 'moving_variance': ['moving_vars']}}\n    with arg_scope([layers.conv3d, conv3d_spatiotemporal], weights_regularizer=layers.l2_regularizer(weight_decay), activation_fn=tf.nn.relu, normalizer_fn=layers.batch_norm, normalizer_params=batch_norm_params):\n        with arg_scope([conv3d_spatiotemporal], separable=True) as sc:\n            return sc",
            "def s3dg_arg_scope(weight_decay=1e-07, batch_norm_decay=0.999, batch_norm_epsilon=0.001):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Defines default arg_scope for S3D-G.\\n\\n  Args:\\n    weight_decay: The weight decay to use for regularizing the model.\\n    batch_norm_decay: Decay for batch norm moving average.\\n    batch_norm_epsilon: Small float added to variance to avoid dividing by zero\\n      in batch norm.\\n\\n  Returns:\\n    sc: An arg_scope to use for the models.\\n  '\n    batch_norm_params = {'decay': batch_norm_decay, 'epsilon': batch_norm_epsilon, 'fused': False, 'variables_collections': {'beta': None, 'gamma': None, 'moving_mean': ['moving_vars'], 'moving_variance': ['moving_vars']}}\n    with arg_scope([layers.conv3d, conv3d_spatiotemporal], weights_regularizer=layers.l2_regularizer(weight_decay), activation_fn=tf.nn.relu, normalizer_fn=layers.batch_norm, normalizer_params=batch_norm_params):\n        with arg_scope([conv3d_spatiotemporal], separable=True) as sc:\n            return sc"
        ]
    },
    {
        "func_name": "self_gating",
        "original": "def self_gating(input_tensor, scope, data_format='NDHWC'):\n    \"\"\"Feature gating as used in S3D-G.\n\n  Transforms the input features by aggregating features from all\n  spatial and temporal locations, and applying gating conditioned\n  on the aggregated features. More details can be found at:\n  https://arxiv.org/abs/1712.04851\n\n  Args:\n    input_tensor: A 5-D float tensor of size [batch_size, num_frames,\n      height, width, channels].\n    scope: scope for `variable_scope`.\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\n      The data format of the input and output data. With the default format\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\n      data storage order is:\n      [batch, in_channels, in_depth, in_height, in_width].\n\n  Returns:\n    A tensor with the same shape as input_tensor.\n  \"\"\"\n    index_c = data_format.index('C')\n    index_d = data_format.index('D')\n    index_h = data_format.index('H')\n    index_w = data_format.index('W')\n    input_shape = input_tensor.get_shape().as_list()\n    t = input_shape[index_d]\n    w = input_shape[index_w]\n    h = input_shape[index_h]\n    num_channels = input_shape[index_c]\n    spatiotemporal_average = layers.avg_pool3d(input_tensor, [t, w, h], stride=1, data_format=data_format, scope=scope + '/self_gating/avg_pool3d')\n    weights = layers.conv3d(spatiotemporal_average, num_channels, [1, 1, 1], activation_fn=None, normalizer_fn=None, biases_initializer=None, data_format=data_format, weights_initializer=trunc_normal(0.01), scope=scope + '/self_gating/transformer_W')\n    tile_multiples = [1, t, w, h]\n    tile_multiples.insert(index_c, 1)\n    weights = tf.tile(weights, tile_multiples)\n    weights = tf.nn.sigmoid(weights)\n    return tf.multiply(weights, input_tensor)",
        "mutated": [
            "def self_gating(input_tensor, scope, data_format='NDHWC'):\n    if False:\n        i = 10\n    'Feature gating as used in S3D-G.\\n\\n  Transforms the input features by aggregating features from all\\n  spatial and temporal locations, and applying gating conditioned\\n  on the aggregated features. More details can be found at:\\n  https://arxiv.org/abs/1712.04851\\n\\n  Args:\\n    input_tensor: A 5-D float tensor of size [batch_size, num_frames,\\n      height, width, channels].\\n    scope: scope for `variable_scope`.\\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\\n      The data format of the input and output data. With the default format\\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\\n      data storage order is:\\n      [batch, in_channels, in_depth, in_height, in_width].\\n\\n  Returns:\\n    A tensor with the same shape as input_tensor.\\n  '\n    index_c = data_format.index('C')\n    index_d = data_format.index('D')\n    index_h = data_format.index('H')\n    index_w = data_format.index('W')\n    input_shape = input_tensor.get_shape().as_list()\n    t = input_shape[index_d]\n    w = input_shape[index_w]\n    h = input_shape[index_h]\n    num_channels = input_shape[index_c]\n    spatiotemporal_average = layers.avg_pool3d(input_tensor, [t, w, h], stride=1, data_format=data_format, scope=scope + '/self_gating/avg_pool3d')\n    weights = layers.conv3d(spatiotemporal_average, num_channels, [1, 1, 1], activation_fn=None, normalizer_fn=None, biases_initializer=None, data_format=data_format, weights_initializer=trunc_normal(0.01), scope=scope + '/self_gating/transformer_W')\n    tile_multiples = [1, t, w, h]\n    tile_multiples.insert(index_c, 1)\n    weights = tf.tile(weights, tile_multiples)\n    weights = tf.nn.sigmoid(weights)\n    return tf.multiply(weights, input_tensor)",
            "def self_gating(input_tensor, scope, data_format='NDHWC'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Feature gating as used in S3D-G.\\n\\n  Transforms the input features by aggregating features from all\\n  spatial and temporal locations, and applying gating conditioned\\n  on the aggregated features. More details can be found at:\\n  https://arxiv.org/abs/1712.04851\\n\\n  Args:\\n    input_tensor: A 5-D float tensor of size [batch_size, num_frames,\\n      height, width, channels].\\n    scope: scope for `variable_scope`.\\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\\n      The data format of the input and output data. With the default format\\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\\n      data storage order is:\\n      [batch, in_channels, in_depth, in_height, in_width].\\n\\n  Returns:\\n    A tensor with the same shape as input_tensor.\\n  '\n    index_c = data_format.index('C')\n    index_d = data_format.index('D')\n    index_h = data_format.index('H')\n    index_w = data_format.index('W')\n    input_shape = input_tensor.get_shape().as_list()\n    t = input_shape[index_d]\n    w = input_shape[index_w]\n    h = input_shape[index_h]\n    num_channels = input_shape[index_c]\n    spatiotemporal_average = layers.avg_pool3d(input_tensor, [t, w, h], stride=1, data_format=data_format, scope=scope + '/self_gating/avg_pool3d')\n    weights = layers.conv3d(spatiotemporal_average, num_channels, [1, 1, 1], activation_fn=None, normalizer_fn=None, biases_initializer=None, data_format=data_format, weights_initializer=trunc_normal(0.01), scope=scope + '/self_gating/transformer_W')\n    tile_multiples = [1, t, w, h]\n    tile_multiples.insert(index_c, 1)\n    weights = tf.tile(weights, tile_multiples)\n    weights = tf.nn.sigmoid(weights)\n    return tf.multiply(weights, input_tensor)",
            "def self_gating(input_tensor, scope, data_format='NDHWC'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Feature gating as used in S3D-G.\\n\\n  Transforms the input features by aggregating features from all\\n  spatial and temporal locations, and applying gating conditioned\\n  on the aggregated features. More details can be found at:\\n  https://arxiv.org/abs/1712.04851\\n\\n  Args:\\n    input_tensor: A 5-D float tensor of size [batch_size, num_frames,\\n      height, width, channels].\\n    scope: scope for `variable_scope`.\\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\\n      The data format of the input and output data. With the default format\\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\\n      data storage order is:\\n      [batch, in_channels, in_depth, in_height, in_width].\\n\\n  Returns:\\n    A tensor with the same shape as input_tensor.\\n  '\n    index_c = data_format.index('C')\n    index_d = data_format.index('D')\n    index_h = data_format.index('H')\n    index_w = data_format.index('W')\n    input_shape = input_tensor.get_shape().as_list()\n    t = input_shape[index_d]\n    w = input_shape[index_w]\n    h = input_shape[index_h]\n    num_channels = input_shape[index_c]\n    spatiotemporal_average = layers.avg_pool3d(input_tensor, [t, w, h], stride=1, data_format=data_format, scope=scope + '/self_gating/avg_pool3d')\n    weights = layers.conv3d(spatiotemporal_average, num_channels, [1, 1, 1], activation_fn=None, normalizer_fn=None, biases_initializer=None, data_format=data_format, weights_initializer=trunc_normal(0.01), scope=scope + '/self_gating/transformer_W')\n    tile_multiples = [1, t, w, h]\n    tile_multiples.insert(index_c, 1)\n    weights = tf.tile(weights, tile_multiples)\n    weights = tf.nn.sigmoid(weights)\n    return tf.multiply(weights, input_tensor)",
            "def self_gating(input_tensor, scope, data_format='NDHWC'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Feature gating as used in S3D-G.\\n\\n  Transforms the input features by aggregating features from all\\n  spatial and temporal locations, and applying gating conditioned\\n  on the aggregated features. More details can be found at:\\n  https://arxiv.org/abs/1712.04851\\n\\n  Args:\\n    input_tensor: A 5-D float tensor of size [batch_size, num_frames,\\n      height, width, channels].\\n    scope: scope for `variable_scope`.\\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\\n      The data format of the input and output data. With the default format\\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\\n      data storage order is:\\n      [batch, in_channels, in_depth, in_height, in_width].\\n\\n  Returns:\\n    A tensor with the same shape as input_tensor.\\n  '\n    index_c = data_format.index('C')\n    index_d = data_format.index('D')\n    index_h = data_format.index('H')\n    index_w = data_format.index('W')\n    input_shape = input_tensor.get_shape().as_list()\n    t = input_shape[index_d]\n    w = input_shape[index_w]\n    h = input_shape[index_h]\n    num_channels = input_shape[index_c]\n    spatiotemporal_average = layers.avg_pool3d(input_tensor, [t, w, h], stride=1, data_format=data_format, scope=scope + '/self_gating/avg_pool3d')\n    weights = layers.conv3d(spatiotemporal_average, num_channels, [1, 1, 1], activation_fn=None, normalizer_fn=None, biases_initializer=None, data_format=data_format, weights_initializer=trunc_normal(0.01), scope=scope + '/self_gating/transformer_W')\n    tile_multiples = [1, t, w, h]\n    tile_multiples.insert(index_c, 1)\n    weights = tf.tile(weights, tile_multiples)\n    weights = tf.nn.sigmoid(weights)\n    return tf.multiply(weights, input_tensor)",
            "def self_gating(input_tensor, scope, data_format='NDHWC'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Feature gating as used in S3D-G.\\n\\n  Transforms the input features by aggregating features from all\\n  spatial and temporal locations, and applying gating conditioned\\n  on the aggregated features. More details can be found at:\\n  https://arxiv.org/abs/1712.04851\\n\\n  Args:\\n    input_tensor: A 5-D float tensor of size [batch_size, num_frames,\\n      height, width, channels].\\n    scope: scope for `variable_scope`.\\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\\n      The data format of the input and output data. With the default format\\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\\n      data storage order is:\\n      [batch, in_channels, in_depth, in_height, in_width].\\n\\n  Returns:\\n    A tensor with the same shape as input_tensor.\\n  '\n    index_c = data_format.index('C')\n    index_d = data_format.index('D')\n    index_h = data_format.index('H')\n    index_w = data_format.index('W')\n    input_shape = input_tensor.get_shape().as_list()\n    t = input_shape[index_d]\n    w = input_shape[index_w]\n    h = input_shape[index_h]\n    num_channels = input_shape[index_c]\n    spatiotemporal_average = layers.avg_pool3d(input_tensor, [t, w, h], stride=1, data_format=data_format, scope=scope + '/self_gating/avg_pool3d')\n    weights = layers.conv3d(spatiotemporal_average, num_channels, [1, 1, 1], activation_fn=None, normalizer_fn=None, biases_initializer=None, data_format=data_format, weights_initializer=trunc_normal(0.01), scope=scope + '/self_gating/transformer_W')\n    tile_multiples = [1, t, w, h]\n    tile_multiples.insert(index_c, 1)\n    weights = tf.tile(weights, tile_multiples)\n    weights = tf.nn.sigmoid(weights)\n    return tf.multiply(weights, input_tensor)"
        ]
    },
    {
        "func_name": "gating_fn",
        "original": "def gating_fn(inputs, scope):\n    return self_gating(inputs, scope, data_format=data_format)",
        "mutated": [
            "def gating_fn(inputs, scope):\n    if False:\n        i = 10\n    return self_gating(inputs, scope, data_format=data_format)",
            "def gating_fn(inputs, scope):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return self_gating(inputs, scope, data_format=data_format)",
            "def gating_fn(inputs, scope):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return self_gating(inputs, scope, data_format=data_format)",
            "def gating_fn(inputs, scope):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return self_gating(inputs, scope, data_format=data_format)",
            "def gating_fn(inputs, scope):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return self_gating(inputs, scope, data_format=data_format)"
        ]
    },
    {
        "func_name": "s3dg_base",
        "original": "def s3dg_base(inputs, first_temporal_kernel_size=3, temporal_conv_startat='Conv2d_2c_3x3', gating_startat='Conv2d_2c_3x3', final_endpoint='Mixed_5c', min_depth=16, depth_multiplier=1.0, data_format='NDHWC', scope='InceptionV1'):\n    \"\"\"Defines the I3D/S3DG base architecture.\n\n  Note that we use the names as defined in Inception V1 to facilitate checkpoint\n  conversion from an image-trained Inception V1 checkpoint to I3D checkpoint.\n\n  Args:\n    inputs: A 5-D float tensor of size [batch_size, num_frames, height, width,\n      channels].\n    first_temporal_kernel_size: Specifies the temporal kernel size for the first\n      conv3d filter. A larger value slows down the model but provides little\n      accuracy improvement. The default is 7 in the original I3D and S3D-G but 3\n      gives better performance. Must be set to one of 1, 3, 5 or 7.\n    temporal_conv_startat: Specifies the first conv block to use 3D or separable\n      3D convs rather than 2D convs (implemented as [1, k, k] 3D conv). This is\n      used to construct the inverted pyramid models. 'Conv2d_2c_3x3' is the\n      first valid block to use separable 3D convs. If provided block name is\n      not present, all valid blocks will use separable 3D convs. Note that\n      'Conv2d_1a_7x7' cannot be made into a separable 3D conv, but can be made\n      into a 2D or 3D conv using the `first_temporal_kernel_size` option.\n    gating_startat: Specifies the first conv block to use self gating.\n      'Conv2d_2c_3x3' is the first valid block to use self gating. If provided\n      block name is not present, all valid blocks will use separable 3D convs.\n    final_endpoint: Specifies the endpoint to construct the network up to. It\n      can be one of ['Conv2d_1a_7x7', 'MaxPool_2a_3x3', 'Conv2d_2b_1x1',\n      'Conv2d_2c_3x3', 'MaxPool_3a_3x3', 'Mixed_3b', 'Mixed_3c',\n      'MaxPool_4a_3x3', 'Mixed_4b', 'Mixed_4c', 'Mixed_4d', 'Mixed_4e',\n      'Mixed_4f', 'MaxPool_5a_2x2', 'Mixed_5b', 'Mixed_5c']\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\n      Enforced when depth_multiplier < 1, and not an active constraint when\n      depth_multiplier >= 1.\n    depth_multiplier: Float multiplier for the depth (number of channels)\n      for all convolution ops. The value must be greater than zero. Typical\n      usage will be to set this value in (0, 1) to reduce the number of\n      parameters or computation cost of the model.\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\n      The data format of the input and output data. With the default format\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\n      data storage order is:\n      [batch, in_channels, in_depth, in_height, in_width].\n    scope: Optional variable_scope.\n\n  Returns:\n    A dictionary from components of the network to the corresponding activation.\n\n  Raises:\n    ValueError: if final_endpoint is not set to one of the predefined values, or\n      if depth_multiplier <= 0.\n  \"\"\"\n    assert data_format in ['NDHWC', 'NCDHW']\n    end_points = {}\n    t = 1\n    use_gating = False\n    self_gating_fn = None\n\n    def gating_fn(inputs, scope):\n        return self_gating(inputs, scope, data_format=data_format)\n    if depth_multiplier <= 0:\n        raise ValueError('depth_multiplier is not greater than zero.')\n    depth = lambda d: max(int(d * depth_multiplier), min_depth)\n    with tf.variable_scope(scope, 'InceptionV1', [inputs]):\n        with arg_scope([layers.conv3d], weights_initializer=trunc_normal(0.01)):\n            with arg_scope([layers.conv3d, layers.max_pool3d, conv3d_spatiotemporal], stride=1, data_format=data_format, padding='SAME'):\n                end_point = 'Conv2d_1a_7x7'\n                if first_temporal_kernel_size not in [1, 3, 5, 7]:\n                    raise ValueError('first_temporal_kernel_size can only be 1, 3, 5 or 7.')\n                net = conv3d_spatiotemporal(inputs, depth(64), [first_temporal_kernel_size, 7, 7], stride=2, separable=False, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_2a_3x3'\n                net = layers.max_pool3d(net, [1, 3, 3], stride=[1, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Conv2d_2b_1x1'\n                net = layers.conv3d(net, depth(64), [1, 1, 1], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Conv2d_2c_3x3'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = conv3d_spatiotemporal(net, depth(192), [t, 3, 3], scope=end_point)\n                if use_gating:\n                    net = self_gating(net, scope=end_point, data_format=data_format)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_3a_3x3'\n                net = layers.max_pool3d(net, [1, 3, 3], stride=[1, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_3b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(64), num_outputs_1_0a=depth(96), num_outputs_1_0b=depth(128), num_outputs_2_0a=depth(16), num_outputs_2_0b=depth(32), num_outputs_3_0b=depth(32), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_3c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(128), num_outputs_1_0a=depth(128), num_outputs_1_0b=depth(192), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(96), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_4a_3x3'\n                net = layers.max_pool3d(net, [3, 3, 3], stride=[2, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(192), num_outputs_1_0a=depth(96), num_outputs_1_0b=depth(208), num_outputs_2_0a=depth(16), num_outputs_2_0b=depth(48), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(160), num_outputs_1_0a=depth(112), num_outputs_1_0b=depth(224), num_outputs_2_0a=depth(24), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4d'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(128), num_outputs_1_0a=depth(128), num_outputs_1_0b=depth(256), num_outputs_2_0a=depth(24), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4e'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(112), num_outputs_1_0a=depth(144), num_outputs_1_0b=depth(288), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4f'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(256), num_outputs_1_0a=depth(160), num_outputs_1_0b=depth(320), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_5a_2x2'\n                net = layers.max_pool3d(net, [2, 2, 2], stride=[2, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_5b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(256), num_outputs_1_0a=depth(160), num_outputs_1_0b=depth(320), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_5c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(384), num_outputs_1_0a=depth(192), num_outputs_1_0b=depth(384), num_outputs_2_0a=depth(48), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n        raise ValueError('Unknown final endpoint %s' % final_endpoint)",
        "mutated": [
            "def s3dg_base(inputs, first_temporal_kernel_size=3, temporal_conv_startat='Conv2d_2c_3x3', gating_startat='Conv2d_2c_3x3', final_endpoint='Mixed_5c', min_depth=16, depth_multiplier=1.0, data_format='NDHWC', scope='InceptionV1'):\n    if False:\n        i = 10\n    'Defines the I3D/S3DG base architecture.\\n\\n  Note that we use the names as defined in Inception V1 to facilitate checkpoint\\n  conversion from an image-trained Inception V1 checkpoint to I3D checkpoint.\\n\\n  Args:\\n    inputs: A 5-D float tensor of size [batch_size, num_frames, height, width,\\n      channels].\\n    first_temporal_kernel_size: Specifies the temporal kernel size for the first\\n      conv3d filter. A larger value slows down the model but provides little\\n      accuracy improvement. The default is 7 in the original I3D and S3D-G but 3\\n      gives better performance. Must be set to one of 1, 3, 5 or 7.\\n    temporal_conv_startat: Specifies the first conv block to use 3D or separable\\n      3D convs rather than 2D convs (implemented as [1, k, k] 3D conv). This is\\n      used to construct the inverted pyramid models. \\'Conv2d_2c_3x3\\' is the\\n      first valid block to use separable 3D convs. If provided block name is\\n      not present, all valid blocks will use separable 3D convs. Note that\\n      \\'Conv2d_1a_7x7\\' cannot be made into a separable 3D conv, but can be made\\n      into a 2D or 3D conv using the `first_temporal_kernel_size` option.\\n    gating_startat: Specifies the first conv block to use self gating.\\n      \\'Conv2d_2c_3x3\\' is the first valid block to use self gating. If provided\\n      block name is not present, all valid blocks will use separable 3D convs.\\n    final_endpoint: Specifies the endpoint to construct the network up to. It\\n      can be one of [\\'Conv2d_1a_7x7\\', \\'MaxPool_2a_3x3\\', \\'Conv2d_2b_1x1\\',\\n      \\'Conv2d_2c_3x3\\', \\'MaxPool_3a_3x3\\', \\'Mixed_3b\\', \\'Mixed_3c\\',\\n      \\'MaxPool_4a_3x3\\', \\'Mixed_4b\\', \\'Mixed_4c\\', \\'Mixed_4d\\', \\'Mixed_4e\\',\\n      \\'Mixed_4f\\', \\'MaxPool_5a_2x2\\', \\'Mixed_5b\\', \\'Mixed_5c\\']\\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\\n      Enforced when depth_multiplier < 1, and not an active constraint when\\n      depth_multiplier >= 1.\\n    depth_multiplier: Float multiplier for the depth (number of channels)\\n      for all convolution ops. The value must be greater than zero. Typical\\n      usage will be to set this value in (0, 1) to reduce the number of\\n      parameters or computation cost of the model.\\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\\n      The data format of the input and output data. With the default format\\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\\n      data storage order is:\\n      [batch, in_channels, in_depth, in_height, in_width].\\n    scope: Optional variable_scope.\\n\\n  Returns:\\n    A dictionary from components of the network to the corresponding activation.\\n\\n  Raises:\\n    ValueError: if final_endpoint is not set to one of the predefined values, or\\n      if depth_multiplier <= 0.\\n  '\n    assert data_format in ['NDHWC', 'NCDHW']\n    end_points = {}\n    t = 1\n    use_gating = False\n    self_gating_fn = None\n\n    def gating_fn(inputs, scope):\n        return self_gating(inputs, scope, data_format=data_format)\n    if depth_multiplier <= 0:\n        raise ValueError('depth_multiplier is not greater than zero.')\n    depth = lambda d: max(int(d * depth_multiplier), min_depth)\n    with tf.variable_scope(scope, 'InceptionV1', [inputs]):\n        with arg_scope([layers.conv3d], weights_initializer=trunc_normal(0.01)):\n            with arg_scope([layers.conv3d, layers.max_pool3d, conv3d_spatiotemporal], stride=1, data_format=data_format, padding='SAME'):\n                end_point = 'Conv2d_1a_7x7'\n                if first_temporal_kernel_size not in [1, 3, 5, 7]:\n                    raise ValueError('first_temporal_kernel_size can only be 1, 3, 5 or 7.')\n                net = conv3d_spatiotemporal(inputs, depth(64), [first_temporal_kernel_size, 7, 7], stride=2, separable=False, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_2a_3x3'\n                net = layers.max_pool3d(net, [1, 3, 3], stride=[1, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Conv2d_2b_1x1'\n                net = layers.conv3d(net, depth(64), [1, 1, 1], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Conv2d_2c_3x3'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = conv3d_spatiotemporal(net, depth(192), [t, 3, 3], scope=end_point)\n                if use_gating:\n                    net = self_gating(net, scope=end_point, data_format=data_format)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_3a_3x3'\n                net = layers.max_pool3d(net, [1, 3, 3], stride=[1, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_3b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(64), num_outputs_1_0a=depth(96), num_outputs_1_0b=depth(128), num_outputs_2_0a=depth(16), num_outputs_2_0b=depth(32), num_outputs_3_0b=depth(32), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_3c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(128), num_outputs_1_0a=depth(128), num_outputs_1_0b=depth(192), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(96), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_4a_3x3'\n                net = layers.max_pool3d(net, [3, 3, 3], stride=[2, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(192), num_outputs_1_0a=depth(96), num_outputs_1_0b=depth(208), num_outputs_2_0a=depth(16), num_outputs_2_0b=depth(48), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(160), num_outputs_1_0a=depth(112), num_outputs_1_0b=depth(224), num_outputs_2_0a=depth(24), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4d'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(128), num_outputs_1_0a=depth(128), num_outputs_1_0b=depth(256), num_outputs_2_0a=depth(24), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4e'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(112), num_outputs_1_0a=depth(144), num_outputs_1_0b=depth(288), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4f'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(256), num_outputs_1_0a=depth(160), num_outputs_1_0b=depth(320), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_5a_2x2'\n                net = layers.max_pool3d(net, [2, 2, 2], stride=[2, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_5b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(256), num_outputs_1_0a=depth(160), num_outputs_1_0b=depth(320), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_5c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(384), num_outputs_1_0a=depth(192), num_outputs_1_0b=depth(384), num_outputs_2_0a=depth(48), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n        raise ValueError('Unknown final endpoint %s' % final_endpoint)",
            "def s3dg_base(inputs, first_temporal_kernel_size=3, temporal_conv_startat='Conv2d_2c_3x3', gating_startat='Conv2d_2c_3x3', final_endpoint='Mixed_5c', min_depth=16, depth_multiplier=1.0, data_format='NDHWC', scope='InceptionV1'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Defines the I3D/S3DG base architecture.\\n\\n  Note that we use the names as defined in Inception V1 to facilitate checkpoint\\n  conversion from an image-trained Inception V1 checkpoint to I3D checkpoint.\\n\\n  Args:\\n    inputs: A 5-D float tensor of size [batch_size, num_frames, height, width,\\n      channels].\\n    first_temporal_kernel_size: Specifies the temporal kernel size for the first\\n      conv3d filter. A larger value slows down the model but provides little\\n      accuracy improvement. The default is 7 in the original I3D and S3D-G but 3\\n      gives better performance. Must be set to one of 1, 3, 5 or 7.\\n    temporal_conv_startat: Specifies the first conv block to use 3D or separable\\n      3D convs rather than 2D convs (implemented as [1, k, k] 3D conv). This is\\n      used to construct the inverted pyramid models. \\'Conv2d_2c_3x3\\' is the\\n      first valid block to use separable 3D convs. If provided block name is\\n      not present, all valid blocks will use separable 3D convs. Note that\\n      \\'Conv2d_1a_7x7\\' cannot be made into a separable 3D conv, but can be made\\n      into a 2D or 3D conv using the `first_temporal_kernel_size` option.\\n    gating_startat: Specifies the first conv block to use self gating.\\n      \\'Conv2d_2c_3x3\\' is the first valid block to use self gating. If provided\\n      block name is not present, all valid blocks will use separable 3D convs.\\n    final_endpoint: Specifies the endpoint to construct the network up to. It\\n      can be one of [\\'Conv2d_1a_7x7\\', \\'MaxPool_2a_3x3\\', \\'Conv2d_2b_1x1\\',\\n      \\'Conv2d_2c_3x3\\', \\'MaxPool_3a_3x3\\', \\'Mixed_3b\\', \\'Mixed_3c\\',\\n      \\'MaxPool_4a_3x3\\', \\'Mixed_4b\\', \\'Mixed_4c\\', \\'Mixed_4d\\', \\'Mixed_4e\\',\\n      \\'Mixed_4f\\', \\'MaxPool_5a_2x2\\', \\'Mixed_5b\\', \\'Mixed_5c\\']\\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\\n      Enforced when depth_multiplier < 1, and not an active constraint when\\n      depth_multiplier >= 1.\\n    depth_multiplier: Float multiplier for the depth (number of channels)\\n      for all convolution ops. The value must be greater than zero. Typical\\n      usage will be to set this value in (0, 1) to reduce the number of\\n      parameters or computation cost of the model.\\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\\n      The data format of the input and output data. With the default format\\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\\n      data storage order is:\\n      [batch, in_channels, in_depth, in_height, in_width].\\n    scope: Optional variable_scope.\\n\\n  Returns:\\n    A dictionary from components of the network to the corresponding activation.\\n\\n  Raises:\\n    ValueError: if final_endpoint is not set to one of the predefined values, or\\n      if depth_multiplier <= 0.\\n  '\n    assert data_format in ['NDHWC', 'NCDHW']\n    end_points = {}\n    t = 1\n    use_gating = False\n    self_gating_fn = None\n\n    def gating_fn(inputs, scope):\n        return self_gating(inputs, scope, data_format=data_format)\n    if depth_multiplier <= 0:\n        raise ValueError('depth_multiplier is not greater than zero.')\n    depth = lambda d: max(int(d * depth_multiplier), min_depth)\n    with tf.variable_scope(scope, 'InceptionV1', [inputs]):\n        with arg_scope([layers.conv3d], weights_initializer=trunc_normal(0.01)):\n            with arg_scope([layers.conv3d, layers.max_pool3d, conv3d_spatiotemporal], stride=1, data_format=data_format, padding='SAME'):\n                end_point = 'Conv2d_1a_7x7'\n                if first_temporal_kernel_size not in [1, 3, 5, 7]:\n                    raise ValueError('first_temporal_kernel_size can only be 1, 3, 5 or 7.')\n                net = conv3d_spatiotemporal(inputs, depth(64), [first_temporal_kernel_size, 7, 7], stride=2, separable=False, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_2a_3x3'\n                net = layers.max_pool3d(net, [1, 3, 3], stride=[1, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Conv2d_2b_1x1'\n                net = layers.conv3d(net, depth(64), [1, 1, 1], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Conv2d_2c_3x3'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = conv3d_spatiotemporal(net, depth(192), [t, 3, 3], scope=end_point)\n                if use_gating:\n                    net = self_gating(net, scope=end_point, data_format=data_format)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_3a_3x3'\n                net = layers.max_pool3d(net, [1, 3, 3], stride=[1, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_3b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(64), num_outputs_1_0a=depth(96), num_outputs_1_0b=depth(128), num_outputs_2_0a=depth(16), num_outputs_2_0b=depth(32), num_outputs_3_0b=depth(32), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_3c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(128), num_outputs_1_0a=depth(128), num_outputs_1_0b=depth(192), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(96), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_4a_3x3'\n                net = layers.max_pool3d(net, [3, 3, 3], stride=[2, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(192), num_outputs_1_0a=depth(96), num_outputs_1_0b=depth(208), num_outputs_2_0a=depth(16), num_outputs_2_0b=depth(48), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(160), num_outputs_1_0a=depth(112), num_outputs_1_0b=depth(224), num_outputs_2_0a=depth(24), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4d'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(128), num_outputs_1_0a=depth(128), num_outputs_1_0b=depth(256), num_outputs_2_0a=depth(24), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4e'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(112), num_outputs_1_0a=depth(144), num_outputs_1_0b=depth(288), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4f'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(256), num_outputs_1_0a=depth(160), num_outputs_1_0b=depth(320), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_5a_2x2'\n                net = layers.max_pool3d(net, [2, 2, 2], stride=[2, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_5b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(256), num_outputs_1_0a=depth(160), num_outputs_1_0b=depth(320), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_5c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(384), num_outputs_1_0a=depth(192), num_outputs_1_0b=depth(384), num_outputs_2_0a=depth(48), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n        raise ValueError('Unknown final endpoint %s' % final_endpoint)",
            "def s3dg_base(inputs, first_temporal_kernel_size=3, temporal_conv_startat='Conv2d_2c_3x3', gating_startat='Conv2d_2c_3x3', final_endpoint='Mixed_5c', min_depth=16, depth_multiplier=1.0, data_format='NDHWC', scope='InceptionV1'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Defines the I3D/S3DG base architecture.\\n\\n  Note that we use the names as defined in Inception V1 to facilitate checkpoint\\n  conversion from an image-trained Inception V1 checkpoint to I3D checkpoint.\\n\\n  Args:\\n    inputs: A 5-D float tensor of size [batch_size, num_frames, height, width,\\n      channels].\\n    first_temporal_kernel_size: Specifies the temporal kernel size for the first\\n      conv3d filter. A larger value slows down the model but provides little\\n      accuracy improvement. The default is 7 in the original I3D and S3D-G but 3\\n      gives better performance. Must be set to one of 1, 3, 5 or 7.\\n    temporal_conv_startat: Specifies the first conv block to use 3D or separable\\n      3D convs rather than 2D convs (implemented as [1, k, k] 3D conv). This is\\n      used to construct the inverted pyramid models. \\'Conv2d_2c_3x3\\' is the\\n      first valid block to use separable 3D convs. If provided block name is\\n      not present, all valid blocks will use separable 3D convs. Note that\\n      \\'Conv2d_1a_7x7\\' cannot be made into a separable 3D conv, but can be made\\n      into a 2D or 3D conv using the `first_temporal_kernel_size` option.\\n    gating_startat: Specifies the first conv block to use self gating.\\n      \\'Conv2d_2c_3x3\\' is the first valid block to use self gating. If provided\\n      block name is not present, all valid blocks will use separable 3D convs.\\n    final_endpoint: Specifies the endpoint to construct the network up to. It\\n      can be one of [\\'Conv2d_1a_7x7\\', \\'MaxPool_2a_3x3\\', \\'Conv2d_2b_1x1\\',\\n      \\'Conv2d_2c_3x3\\', \\'MaxPool_3a_3x3\\', \\'Mixed_3b\\', \\'Mixed_3c\\',\\n      \\'MaxPool_4a_3x3\\', \\'Mixed_4b\\', \\'Mixed_4c\\', \\'Mixed_4d\\', \\'Mixed_4e\\',\\n      \\'Mixed_4f\\', \\'MaxPool_5a_2x2\\', \\'Mixed_5b\\', \\'Mixed_5c\\']\\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\\n      Enforced when depth_multiplier < 1, and not an active constraint when\\n      depth_multiplier >= 1.\\n    depth_multiplier: Float multiplier for the depth (number of channels)\\n      for all convolution ops. The value must be greater than zero. Typical\\n      usage will be to set this value in (0, 1) to reduce the number of\\n      parameters or computation cost of the model.\\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\\n      The data format of the input and output data. With the default format\\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\\n      data storage order is:\\n      [batch, in_channels, in_depth, in_height, in_width].\\n    scope: Optional variable_scope.\\n\\n  Returns:\\n    A dictionary from components of the network to the corresponding activation.\\n\\n  Raises:\\n    ValueError: if final_endpoint is not set to one of the predefined values, or\\n      if depth_multiplier <= 0.\\n  '\n    assert data_format in ['NDHWC', 'NCDHW']\n    end_points = {}\n    t = 1\n    use_gating = False\n    self_gating_fn = None\n\n    def gating_fn(inputs, scope):\n        return self_gating(inputs, scope, data_format=data_format)\n    if depth_multiplier <= 0:\n        raise ValueError('depth_multiplier is not greater than zero.')\n    depth = lambda d: max(int(d * depth_multiplier), min_depth)\n    with tf.variable_scope(scope, 'InceptionV1', [inputs]):\n        with arg_scope([layers.conv3d], weights_initializer=trunc_normal(0.01)):\n            with arg_scope([layers.conv3d, layers.max_pool3d, conv3d_spatiotemporal], stride=1, data_format=data_format, padding='SAME'):\n                end_point = 'Conv2d_1a_7x7'\n                if first_temporal_kernel_size not in [1, 3, 5, 7]:\n                    raise ValueError('first_temporal_kernel_size can only be 1, 3, 5 or 7.')\n                net = conv3d_spatiotemporal(inputs, depth(64), [first_temporal_kernel_size, 7, 7], stride=2, separable=False, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_2a_3x3'\n                net = layers.max_pool3d(net, [1, 3, 3], stride=[1, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Conv2d_2b_1x1'\n                net = layers.conv3d(net, depth(64), [1, 1, 1], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Conv2d_2c_3x3'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = conv3d_spatiotemporal(net, depth(192), [t, 3, 3], scope=end_point)\n                if use_gating:\n                    net = self_gating(net, scope=end_point, data_format=data_format)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_3a_3x3'\n                net = layers.max_pool3d(net, [1, 3, 3], stride=[1, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_3b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(64), num_outputs_1_0a=depth(96), num_outputs_1_0b=depth(128), num_outputs_2_0a=depth(16), num_outputs_2_0b=depth(32), num_outputs_3_0b=depth(32), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_3c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(128), num_outputs_1_0a=depth(128), num_outputs_1_0b=depth(192), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(96), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_4a_3x3'\n                net = layers.max_pool3d(net, [3, 3, 3], stride=[2, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(192), num_outputs_1_0a=depth(96), num_outputs_1_0b=depth(208), num_outputs_2_0a=depth(16), num_outputs_2_0b=depth(48), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(160), num_outputs_1_0a=depth(112), num_outputs_1_0b=depth(224), num_outputs_2_0a=depth(24), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4d'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(128), num_outputs_1_0a=depth(128), num_outputs_1_0b=depth(256), num_outputs_2_0a=depth(24), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4e'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(112), num_outputs_1_0a=depth(144), num_outputs_1_0b=depth(288), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4f'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(256), num_outputs_1_0a=depth(160), num_outputs_1_0b=depth(320), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_5a_2x2'\n                net = layers.max_pool3d(net, [2, 2, 2], stride=[2, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_5b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(256), num_outputs_1_0a=depth(160), num_outputs_1_0b=depth(320), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_5c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(384), num_outputs_1_0a=depth(192), num_outputs_1_0b=depth(384), num_outputs_2_0a=depth(48), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n        raise ValueError('Unknown final endpoint %s' % final_endpoint)",
            "def s3dg_base(inputs, first_temporal_kernel_size=3, temporal_conv_startat='Conv2d_2c_3x3', gating_startat='Conv2d_2c_3x3', final_endpoint='Mixed_5c', min_depth=16, depth_multiplier=1.0, data_format='NDHWC', scope='InceptionV1'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Defines the I3D/S3DG base architecture.\\n\\n  Note that we use the names as defined in Inception V1 to facilitate checkpoint\\n  conversion from an image-trained Inception V1 checkpoint to I3D checkpoint.\\n\\n  Args:\\n    inputs: A 5-D float tensor of size [batch_size, num_frames, height, width,\\n      channels].\\n    first_temporal_kernel_size: Specifies the temporal kernel size for the first\\n      conv3d filter. A larger value slows down the model but provides little\\n      accuracy improvement. The default is 7 in the original I3D and S3D-G but 3\\n      gives better performance. Must be set to one of 1, 3, 5 or 7.\\n    temporal_conv_startat: Specifies the first conv block to use 3D or separable\\n      3D convs rather than 2D convs (implemented as [1, k, k] 3D conv). This is\\n      used to construct the inverted pyramid models. \\'Conv2d_2c_3x3\\' is the\\n      first valid block to use separable 3D convs. If provided block name is\\n      not present, all valid blocks will use separable 3D convs. Note that\\n      \\'Conv2d_1a_7x7\\' cannot be made into a separable 3D conv, but can be made\\n      into a 2D or 3D conv using the `first_temporal_kernel_size` option.\\n    gating_startat: Specifies the first conv block to use self gating.\\n      \\'Conv2d_2c_3x3\\' is the first valid block to use self gating. If provided\\n      block name is not present, all valid blocks will use separable 3D convs.\\n    final_endpoint: Specifies the endpoint to construct the network up to. It\\n      can be one of [\\'Conv2d_1a_7x7\\', \\'MaxPool_2a_3x3\\', \\'Conv2d_2b_1x1\\',\\n      \\'Conv2d_2c_3x3\\', \\'MaxPool_3a_3x3\\', \\'Mixed_3b\\', \\'Mixed_3c\\',\\n      \\'MaxPool_4a_3x3\\', \\'Mixed_4b\\', \\'Mixed_4c\\', \\'Mixed_4d\\', \\'Mixed_4e\\',\\n      \\'Mixed_4f\\', \\'MaxPool_5a_2x2\\', \\'Mixed_5b\\', \\'Mixed_5c\\']\\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\\n      Enforced when depth_multiplier < 1, and not an active constraint when\\n      depth_multiplier >= 1.\\n    depth_multiplier: Float multiplier for the depth (number of channels)\\n      for all convolution ops. The value must be greater than zero. Typical\\n      usage will be to set this value in (0, 1) to reduce the number of\\n      parameters or computation cost of the model.\\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\\n      The data format of the input and output data. With the default format\\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\\n      data storage order is:\\n      [batch, in_channels, in_depth, in_height, in_width].\\n    scope: Optional variable_scope.\\n\\n  Returns:\\n    A dictionary from components of the network to the corresponding activation.\\n\\n  Raises:\\n    ValueError: if final_endpoint is not set to one of the predefined values, or\\n      if depth_multiplier <= 0.\\n  '\n    assert data_format in ['NDHWC', 'NCDHW']\n    end_points = {}\n    t = 1\n    use_gating = False\n    self_gating_fn = None\n\n    def gating_fn(inputs, scope):\n        return self_gating(inputs, scope, data_format=data_format)\n    if depth_multiplier <= 0:\n        raise ValueError('depth_multiplier is not greater than zero.')\n    depth = lambda d: max(int(d * depth_multiplier), min_depth)\n    with tf.variable_scope(scope, 'InceptionV1', [inputs]):\n        with arg_scope([layers.conv3d], weights_initializer=trunc_normal(0.01)):\n            with arg_scope([layers.conv3d, layers.max_pool3d, conv3d_spatiotemporal], stride=1, data_format=data_format, padding='SAME'):\n                end_point = 'Conv2d_1a_7x7'\n                if first_temporal_kernel_size not in [1, 3, 5, 7]:\n                    raise ValueError('first_temporal_kernel_size can only be 1, 3, 5 or 7.')\n                net = conv3d_spatiotemporal(inputs, depth(64), [first_temporal_kernel_size, 7, 7], stride=2, separable=False, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_2a_3x3'\n                net = layers.max_pool3d(net, [1, 3, 3], stride=[1, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Conv2d_2b_1x1'\n                net = layers.conv3d(net, depth(64), [1, 1, 1], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Conv2d_2c_3x3'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = conv3d_spatiotemporal(net, depth(192), [t, 3, 3], scope=end_point)\n                if use_gating:\n                    net = self_gating(net, scope=end_point, data_format=data_format)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_3a_3x3'\n                net = layers.max_pool3d(net, [1, 3, 3], stride=[1, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_3b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(64), num_outputs_1_0a=depth(96), num_outputs_1_0b=depth(128), num_outputs_2_0a=depth(16), num_outputs_2_0b=depth(32), num_outputs_3_0b=depth(32), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_3c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(128), num_outputs_1_0a=depth(128), num_outputs_1_0b=depth(192), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(96), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_4a_3x3'\n                net = layers.max_pool3d(net, [3, 3, 3], stride=[2, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(192), num_outputs_1_0a=depth(96), num_outputs_1_0b=depth(208), num_outputs_2_0a=depth(16), num_outputs_2_0b=depth(48), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(160), num_outputs_1_0a=depth(112), num_outputs_1_0b=depth(224), num_outputs_2_0a=depth(24), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4d'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(128), num_outputs_1_0a=depth(128), num_outputs_1_0b=depth(256), num_outputs_2_0a=depth(24), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4e'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(112), num_outputs_1_0a=depth(144), num_outputs_1_0b=depth(288), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4f'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(256), num_outputs_1_0a=depth(160), num_outputs_1_0b=depth(320), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_5a_2x2'\n                net = layers.max_pool3d(net, [2, 2, 2], stride=[2, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_5b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(256), num_outputs_1_0a=depth(160), num_outputs_1_0b=depth(320), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_5c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(384), num_outputs_1_0a=depth(192), num_outputs_1_0b=depth(384), num_outputs_2_0a=depth(48), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n        raise ValueError('Unknown final endpoint %s' % final_endpoint)",
            "def s3dg_base(inputs, first_temporal_kernel_size=3, temporal_conv_startat='Conv2d_2c_3x3', gating_startat='Conv2d_2c_3x3', final_endpoint='Mixed_5c', min_depth=16, depth_multiplier=1.0, data_format='NDHWC', scope='InceptionV1'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Defines the I3D/S3DG base architecture.\\n\\n  Note that we use the names as defined in Inception V1 to facilitate checkpoint\\n  conversion from an image-trained Inception V1 checkpoint to I3D checkpoint.\\n\\n  Args:\\n    inputs: A 5-D float tensor of size [batch_size, num_frames, height, width,\\n      channels].\\n    first_temporal_kernel_size: Specifies the temporal kernel size for the first\\n      conv3d filter. A larger value slows down the model but provides little\\n      accuracy improvement. The default is 7 in the original I3D and S3D-G but 3\\n      gives better performance. Must be set to one of 1, 3, 5 or 7.\\n    temporal_conv_startat: Specifies the first conv block to use 3D or separable\\n      3D convs rather than 2D convs (implemented as [1, k, k] 3D conv). This is\\n      used to construct the inverted pyramid models. \\'Conv2d_2c_3x3\\' is the\\n      first valid block to use separable 3D convs. If provided block name is\\n      not present, all valid blocks will use separable 3D convs. Note that\\n      \\'Conv2d_1a_7x7\\' cannot be made into a separable 3D conv, but can be made\\n      into a 2D or 3D conv using the `first_temporal_kernel_size` option.\\n    gating_startat: Specifies the first conv block to use self gating.\\n      \\'Conv2d_2c_3x3\\' is the first valid block to use self gating. If provided\\n      block name is not present, all valid blocks will use separable 3D convs.\\n    final_endpoint: Specifies the endpoint to construct the network up to. It\\n      can be one of [\\'Conv2d_1a_7x7\\', \\'MaxPool_2a_3x3\\', \\'Conv2d_2b_1x1\\',\\n      \\'Conv2d_2c_3x3\\', \\'MaxPool_3a_3x3\\', \\'Mixed_3b\\', \\'Mixed_3c\\',\\n      \\'MaxPool_4a_3x3\\', \\'Mixed_4b\\', \\'Mixed_4c\\', \\'Mixed_4d\\', \\'Mixed_4e\\',\\n      \\'Mixed_4f\\', \\'MaxPool_5a_2x2\\', \\'Mixed_5b\\', \\'Mixed_5c\\']\\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\\n      Enforced when depth_multiplier < 1, and not an active constraint when\\n      depth_multiplier >= 1.\\n    depth_multiplier: Float multiplier for the depth (number of channels)\\n      for all convolution ops. The value must be greater than zero. Typical\\n      usage will be to set this value in (0, 1) to reduce the number of\\n      parameters or computation cost of the model.\\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\\n      The data format of the input and output data. With the default format\\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\\n      data storage order is:\\n      [batch, in_channels, in_depth, in_height, in_width].\\n    scope: Optional variable_scope.\\n\\n  Returns:\\n    A dictionary from components of the network to the corresponding activation.\\n\\n  Raises:\\n    ValueError: if final_endpoint is not set to one of the predefined values, or\\n      if depth_multiplier <= 0.\\n  '\n    assert data_format in ['NDHWC', 'NCDHW']\n    end_points = {}\n    t = 1\n    use_gating = False\n    self_gating_fn = None\n\n    def gating_fn(inputs, scope):\n        return self_gating(inputs, scope, data_format=data_format)\n    if depth_multiplier <= 0:\n        raise ValueError('depth_multiplier is not greater than zero.')\n    depth = lambda d: max(int(d * depth_multiplier), min_depth)\n    with tf.variable_scope(scope, 'InceptionV1', [inputs]):\n        with arg_scope([layers.conv3d], weights_initializer=trunc_normal(0.01)):\n            with arg_scope([layers.conv3d, layers.max_pool3d, conv3d_spatiotemporal], stride=1, data_format=data_format, padding='SAME'):\n                end_point = 'Conv2d_1a_7x7'\n                if first_temporal_kernel_size not in [1, 3, 5, 7]:\n                    raise ValueError('first_temporal_kernel_size can only be 1, 3, 5 or 7.')\n                net = conv3d_spatiotemporal(inputs, depth(64), [first_temporal_kernel_size, 7, 7], stride=2, separable=False, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_2a_3x3'\n                net = layers.max_pool3d(net, [1, 3, 3], stride=[1, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Conv2d_2b_1x1'\n                net = layers.conv3d(net, depth(64), [1, 1, 1], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Conv2d_2c_3x3'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = conv3d_spatiotemporal(net, depth(192), [t, 3, 3], scope=end_point)\n                if use_gating:\n                    net = self_gating(net, scope=end_point, data_format=data_format)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_3a_3x3'\n                net = layers.max_pool3d(net, [1, 3, 3], stride=[1, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_3b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(64), num_outputs_1_0a=depth(96), num_outputs_1_0b=depth(128), num_outputs_2_0a=depth(16), num_outputs_2_0b=depth(32), num_outputs_3_0b=depth(32), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_3c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(128), num_outputs_1_0a=depth(128), num_outputs_1_0b=depth(192), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(96), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_4a_3x3'\n                net = layers.max_pool3d(net, [3, 3, 3], stride=[2, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(192), num_outputs_1_0a=depth(96), num_outputs_1_0b=depth(208), num_outputs_2_0a=depth(16), num_outputs_2_0b=depth(48), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(160), num_outputs_1_0a=depth(112), num_outputs_1_0b=depth(224), num_outputs_2_0a=depth(24), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4d'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(128), num_outputs_1_0a=depth(128), num_outputs_1_0b=depth(256), num_outputs_2_0a=depth(24), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4e'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(112), num_outputs_1_0a=depth(144), num_outputs_1_0b=depth(288), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(64), num_outputs_3_0b=depth(64), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_4f'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(256), num_outputs_1_0a=depth(160), num_outputs_1_0b=depth(320), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'MaxPool_5a_2x2'\n                net = layers.max_pool3d(net, [2, 2, 2], stride=[2, 2, 2], scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_5b'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(256), num_outputs_1_0a=depth(160), num_outputs_1_0b=depth(320), num_outputs_2_0a=depth(32), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n                end_point = 'Mixed_5c'\n                if temporal_conv_startat == end_point:\n                    t = 3\n                if gating_startat == end_point:\n                    use_gating = True\n                    self_gating_fn = gating_fn\n                net = inception_block_v1_3d(net, num_outputs_0_0a=depth(384), num_outputs_1_0a=depth(192), num_outputs_1_0b=depth(384), num_outputs_2_0a=depth(48), num_outputs_2_0b=depth(128), num_outputs_3_0b=depth(128), temporal_kernel_size=t, self_gating_fn=self_gating_fn, data_format=data_format, scope=end_point)\n                end_points[end_point] = net\n                if final_endpoint == end_point:\n                    return (net, end_points)\n        raise ValueError('Unknown final endpoint %s' % final_endpoint)"
        ]
    },
    {
        "func_name": "s3dg",
        "original": "def s3dg(inputs, num_classes=1000, first_temporal_kernel_size=3, temporal_conv_startat='Conv2d_2c_3x3', gating_startat='Conv2d_2c_3x3', final_endpoint='Mixed_5c', min_depth=16, depth_multiplier=1.0, dropout_keep_prob=0.8, is_training=True, prediction_fn=layers.softmax, spatial_squeeze=True, reuse=None, data_format='NDHWC', scope='InceptionV1'):\n    \"\"\"Defines the S3D-G architecture.\n\n  The default image size used to train this network is 224x224.\n\n  Args:\n    inputs: A 5-D float tensor of size [batch_size, num_frames, height, width,\n      channels].\n    num_classes: number of predicted classes.\n    first_temporal_kernel_size: Specifies the temporal kernel size for the first\n      conv3d filter. A larger value slows down the model but provides little\n      accuracy improvement. Must be set to one of 1, 3, 5 or 7.\n    temporal_conv_startat: Specifies the first conv block to use separable 3D\n      convs rather than 2D convs (implemented as [1, k, k] 3D conv). This is\n      used to construct the inverted pyramid models. 'Conv2d_2c_3x3' is the\n      first valid block to use separable 3D convs. If provided block name is\n      not present, all valid blocks will use separable 3D convs.\n    gating_startat: Specifies the first conv block to use self gating.\n      'Conv2d_2c_3x3' is the first valid block to use self gating. If provided\n      block name is not present, all valid blocks will use separable 3D convs.\n    final_endpoint: Specifies the endpoint to construct the network up to. It\n      can be one of ['Conv2d_1a_7x7', 'MaxPool_2a_3x3', 'Conv2d_2b_1x1',\n      'Conv2d_2c_3x3', 'MaxPool_3a_3x3', 'Mixed_3b', 'Mixed_3c',\n      'MaxPool_4a_3x3', 'Mixed_4b', 'Mixed_4c', 'Mixed_4d', 'Mixed_4e',\n      'Mixed_4f', 'MaxPool_5a_2x2', 'Mixed_5b', 'Mixed_5c']\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\n      Enforced when depth_multiplier < 1, and not an active constraint when\n      depth_multiplier >= 1.\n    depth_multiplier: Float multiplier for the depth (number of channels)\n      for all convolution ops. The value must be greater than zero. Typical\n      usage will be to set this value in (0, 1) to reduce the number of\n      parameters or computation cost of the model.\n    dropout_keep_prob: the percentage of activation values that are retained.\n    is_training: whether is training or not.\n    prediction_fn: a function to get predictions out of logits.\n    spatial_squeeze: if True, logits is of shape is [B, C], if false logits is\n        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\n    reuse: whether or not the network and its variables should be reused. To be\n      able to reuse 'scope' must be given.\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\n      The data format of the input and output data. With the default format\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\n      data storage order is:\n      [batch, in_channels, in_depth, in_height, in_width].\n    scope: Optional variable_scope.\n\n  Returns:\n    logits: the pre-softmax activations, a tensor of size\n      [batch_size, num_classes]\n    end_points: a dictionary from components of the network to the corresponding\n      activation.\n  \"\"\"\n    assert data_format in ['NDHWC', 'NCDHW']\n    with tf.variable_scope(scope, 'InceptionV1', [inputs, num_classes], reuse=reuse) as scope:\n        with arg_scope([layers.batch_norm, layers.dropout], is_training=is_training):\n            (net, end_points) = s3dg_base(inputs, first_temporal_kernel_size=first_temporal_kernel_size, temporal_conv_startat=temporal_conv_startat, gating_startat=gating_startat, final_endpoint=final_endpoint, min_depth=min_depth, depth_multiplier=depth_multiplier, data_format=data_format, scope=scope)\n            with tf.variable_scope('Logits'):\n                if data_format.startswith('NC'):\n                    net = tf.transpose(net, [0, 2, 3, 4, 1])\n                kernel_size = i3d_utils.reduced_kernel_size_3d(net, [2, 7, 7])\n                net = layers.avg_pool3d(net, kernel_size, stride=1, data_format='NDHWC', scope='AvgPool_0a_7x7')\n                net = layers.dropout(net, dropout_keep_prob, scope='Dropout_0b')\n                logits = layers.conv3d(net, num_classes, [1, 1, 1], activation_fn=None, normalizer_fn=None, data_format='NDHWC', scope='Conv2d_0c_1x1')\n                logits = tf.reduce_mean(logits, axis=1)\n                if spatial_squeeze:\n                    logits = tf.squeeze(logits, [1, 2], name='SpatialSqueeze')\n                end_points['Logits'] = logits\n                end_points['Predictions'] = prediction_fn(logits, scope='Predictions')\n    return (logits, end_points)",
        "mutated": [
            "def s3dg(inputs, num_classes=1000, first_temporal_kernel_size=3, temporal_conv_startat='Conv2d_2c_3x3', gating_startat='Conv2d_2c_3x3', final_endpoint='Mixed_5c', min_depth=16, depth_multiplier=1.0, dropout_keep_prob=0.8, is_training=True, prediction_fn=layers.softmax, spatial_squeeze=True, reuse=None, data_format='NDHWC', scope='InceptionV1'):\n    if False:\n        i = 10\n    'Defines the S3D-G architecture.\\n\\n  The default image size used to train this network is 224x224.\\n\\n  Args:\\n    inputs: A 5-D float tensor of size [batch_size, num_frames, height, width,\\n      channels].\\n    num_classes: number of predicted classes.\\n    first_temporal_kernel_size: Specifies the temporal kernel size for the first\\n      conv3d filter. A larger value slows down the model but provides little\\n      accuracy improvement. Must be set to one of 1, 3, 5 or 7.\\n    temporal_conv_startat: Specifies the first conv block to use separable 3D\\n      convs rather than 2D convs (implemented as [1, k, k] 3D conv). This is\\n      used to construct the inverted pyramid models. \\'Conv2d_2c_3x3\\' is the\\n      first valid block to use separable 3D convs. If provided block name is\\n      not present, all valid blocks will use separable 3D convs.\\n    gating_startat: Specifies the first conv block to use self gating.\\n      \\'Conv2d_2c_3x3\\' is the first valid block to use self gating. If provided\\n      block name is not present, all valid blocks will use separable 3D convs.\\n    final_endpoint: Specifies the endpoint to construct the network up to. It\\n      can be one of [\\'Conv2d_1a_7x7\\', \\'MaxPool_2a_3x3\\', \\'Conv2d_2b_1x1\\',\\n      \\'Conv2d_2c_3x3\\', \\'MaxPool_3a_3x3\\', \\'Mixed_3b\\', \\'Mixed_3c\\',\\n      \\'MaxPool_4a_3x3\\', \\'Mixed_4b\\', \\'Mixed_4c\\', \\'Mixed_4d\\', \\'Mixed_4e\\',\\n      \\'Mixed_4f\\', \\'MaxPool_5a_2x2\\', \\'Mixed_5b\\', \\'Mixed_5c\\']\\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\\n      Enforced when depth_multiplier < 1, and not an active constraint when\\n      depth_multiplier >= 1.\\n    depth_multiplier: Float multiplier for the depth (number of channels)\\n      for all convolution ops. The value must be greater than zero. Typical\\n      usage will be to set this value in (0, 1) to reduce the number of\\n      parameters or computation cost of the model.\\n    dropout_keep_prob: the percentage of activation values that are retained.\\n    is_training: whether is training or not.\\n    prediction_fn: a function to get predictions out of logits.\\n    spatial_squeeze: if True, logits is of shape is [B, C], if false logits is\\n        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\\n    reuse: whether or not the network and its variables should be reused. To be\\n      able to reuse \\'scope\\' must be given.\\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\\n      The data format of the input and output data. With the default format\\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\\n      data storage order is:\\n      [batch, in_channels, in_depth, in_height, in_width].\\n    scope: Optional variable_scope.\\n\\n  Returns:\\n    logits: the pre-softmax activations, a tensor of size\\n      [batch_size, num_classes]\\n    end_points: a dictionary from components of the network to the corresponding\\n      activation.\\n  '\n    assert data_format in ['NDHWC', 'NCDHW']\n    with tf.variable_scope(scope, 'InceptionV1', [inputs, num_classes], reuse=reuse) as scope:\n        with arg_scope([layers.batch_norm, layers.dropout], is_training=is_training):\n            (net, end_points) = s3dg_base(inputs, first_temporal_kernel_size=first_temporal_kernel_size, temporal_conv_startat=temporal_conv_startat, gating_startat=gating_startat, final_endpoint=final_endpoint, min_depth=min_depth, depth_multiplier=depth_multiplier, data_format=data_format, scope=scope)\n            with tf.variable_scope('Logits'):\n                if data_format.startswith('NC'):\n                    net = tf.transpose(net, [0, 2, 3, 4, 1])\n                kernel_size = i3d_utils.reduced_kernel_size_3d(net, [2, 7, 7])\n                net = layers.avg_pool3d(net, kernel_size, stride=1, data_format='NDHWC', scope='AvgPool_0a_7x7')\n                net = layers.dropout(net, dropout_keep_prob, scope='Dropout_0b')\n                logits = layers.conv3d(net, num_classes, [1, 1, 1], activation_fn=None, normalizer_fn=None, data_format='NDHWC', scope='Conv2d_0c_1x1')\n                logits = tf.reduce_mean(logits, axis=1)\n                if spatial_squeeze:\n                    logits = tf.squeeze(logits, [1, 2], name='SpatialSqueeze')\n                end_points['Logits'] = logits\n                end_points['Predictions'] = prediction_fn(logits, scope='Predictions')\n    return (logits, end_points)",
            "def s3dg(inputs, num_classes=1000, first_temporal_kernel_size=3, temporal_conv_startat='Conv2d_2c_3x3', gating_startat='Conv2d_2c_3x3', final_endpoint='Mixed_5c', min_depth=16, depth_multiplier=1.0, dropout_keep_prob=0.8, is_training=True, prediction_fn=layers.softmax, spatial_squeeze=True, reuse=None, data_format='NDHWC', scope='InceptionV1'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Defines the S3D-G architecture.\\n\\n  The default image size used to train this network is 224x224.\\n\\n  Args:\\n    inputs: A 5-D float tensor of size [batch_size, num_frames, height, width,\\n      channels].\\n    num_classes: number of predicted classes.\\n    first_temporal_kernel_size: Specifies the temporal kernel size for the first\\n      conv3d filter. A larger value slows down the model but provides little\\n      accuracy improvement. Must be set to one of 1, 3, 5 or 7.\\n    temporal_conv_startat: Specifies the first conv block to use separable 3D\\n      convs rather than 2D convs (implemented as [1, k, k] 3D conv). This is\\n      used to construct the inverted pyramid models. \\'Conv2d_2c_3x3\\' is the\\n      first valid block to use separable 3D convs. If provided block name is\\n      not present, all valid blocks will use separable 3D convs.\\n    gating_startat: Specifies the first conv block to use self gating.\\n      \\'Conv2d_2c_3x3\\' is the first valid block to use self gating. If provided\\n      block name is not present, all valid blocks will use separable 3D convs.\\n    final_endpoint: Specifies the endpoint to construct the network up to. It\\n      can be one of [\\'Conv2d_1a_7x7\\', \\'MaxPool_2a_3x3\\', \\'Conv2d_2b_1x1\\',\\n      \\'Conv2d_2c_3x3\\', \\'MaxPool_3a_3x3\\', \\'Mixed_3b\\', \\'Mixed_3c\\',\\n      \\'MaxPool_4a_3x3\\', \\'Mixed_4b\\', \\'Mixed_4c\\', \\'Mixed_4d\\', \\'Mixed_4e\\',\\n      \\'Mixed_4f\\', \\'MaxPool_5a_2x2\\', \\'Mixed_5b\\', \\'Mixed_5c\\']\\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\\n      Enforced when depth_multiplier < 1, and not an active constraint when\\n      depth_multiplier >= 1.\\n    depth_multiplier: Float multiplier for the depth (number of channels)\\n      for all convolution ops. The value must be greater than zero. Typical\\n      usage will be to set this value in (0, 1) to reduce the number of\\n      parameters or computation cost of the model.\\n    dropout_keep_prob: the percentage of activation values that are retained.\\n    is_training: whether is training or not.\\n    prediction_fn: a function to get predictions out of logits.\\n    spatial_squeeze: if True, logits is of shape is [B, C], if false logits is\\n        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\\n    reuse: whether or not the network and its variables should be reused. To be\\n      able to reuse \\'scope\\' must be given.\\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\\n      The data format of the input and output data. With the default format\\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\\n      data storage order is:\\n      [batch, in_channels, in_depth, in_height, in_width].\\n    scope: Optional variable_scope.\\n\\n  Returns:\\n    logits: the pre-softmax activations, a tensor of size\\n      [batch_size, num_classes]\\n    end_points: a dictionary from components of the network to the corresponding\\n      activation.\\n  '\n    assert data_format in ['NDHWC', 'NCDHW']\n    with tf.variable_scope(scope, 'InceptionV1', [inputs, num_classes], reuse=reuse) as scope:\n        with arg_scope([layers.batch_norm, layers.dropout], is_training=is_training):\n            (net, end_points) = s3dg_base(inputs, first_temporal_kernel_size=first_temporal_kernel_size, temporal_conv_startat=temporal_conv_startat, gating_startat=gating_startat, final_endpoint=final_endpoint, min_depth=min_depth, depth_multiplier=depth_multiplier, data_format=data_format, scope=scope)\n            with tf.variable_scope('Logits'):\n                if data_format.startswith('NC'):\n                    net = tf.transpose(net, [0, 2, 3, 4, 1])\n                kernel_size = i3d_utils.reduced_kernel_size_3d(net, [2, 7, 7])\n                net = layers.avg_pool3d(net, kernel_size, stride=1, data_format='NDHWC', scope='AvgPool_0a_7x7')\n                net = layers.dropout(net, dropout_keep_prob, scope='Dropout_0b')\n                logits = layers.conv3d(net, num_classes, [1, 1, 1], activation_fn=None, normalizer_fn=None, data_format='NDHWC', scope='Conv2d_0c_1x1')\n                logits = tf.reduce_mean(logits, axis=1)\n                if spatial_squeeze:\n                    logits = tf.squeeze(logits, [1, 2], name='SpatialSqueeze')\n                end_points['Logits'] = logits\n                end_points['Predictions'] = prediction_fn(logits, scope='Predictions')\n    return (logits, end_points)",
            "def s3dg(inputs, num_classes=1000, first_temporal_kernel_size=3, temporal_conv_startat='Conv2d_2c_3x3', gating_startat='Conv2d_2c_3x3', final_endpoint='Mixed_5c', min_depth=16, depth_multiplier=1.0, dropout_keep_prob=0.8, is_training=True, prediction_fn=layers.softmax, spatial_squeeze=True, reuse=None, data_format='NDHWC', scope='InceptionV1'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Defines the S3D-G architecture.\\n\\n  The default image size used to train this network is 224x224.\\n\\n  Args:\\n    inputs: A 5-D float tensor of size [batch_size, num_frames, height, width,\\n      channels].\\n    num_classes: number of predicted classes.\\n    first_temporal_kernel_size: Specifies the temporal kernel size for the first\\n      conv3d filter. A larger value slows down the model but provides little\\n      accuracy improvement. Must be set to one of 1, 3, 5 or 7.\\n    temporal_conv_startat: Specifies the first conv block to use separable 3D\\n      convs rather than 2D convs (implemented as [1, k, k] 3D conv). This is\\n      used to construct the inverted pyramid models. \\'Conv2d_2c_3x3\\' is the\\n      first valid block to use separable 3D convs. If provided block name is\\n      not present, all valid blocks will use separable 3D convs.\\n    gating_startat: Specifies the first conv block to use self gating.\\n      \\'Conv2d_2c_3x3\\' is the first valid block to use self gating. If provided\\n      block name is not present, all valid blocks will use separable 3D convs.\\n    final_endpoint: Specifies the endpoint to construct the network up to. It\\n      can be one of [\\'Conv2d_1a_7x7\\', \\'MaxPool_2a_3x3\\', \\'Conv2d_2b_1x1\\',\\n      \\'Conv2d_2c_3x3\\', \\'MaxPool_3a_3x3\\', \\'Mixed_3b\\', \\'Mixed_3c\\',\\n      \\'MaxPool_4a_3x3\\', \\'Mixed_4b\\', \\'Mixed_4c\\', \\'Mixed_4d\\', \\'Mixed_4e\\',\\n      \\'Mixed_4f\\', \\'MaxPool_5a_2x2\\', \\'Mixed_5b\\', \\'Mixed_5c\\']\\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\\n      Enforced when depth_multiplier < 1, and not an active constraint when\\n      depth_multiplier >= 1.\\n    depth_multiplier: Float multiplier for the depth (number of channels)\\n      for all convolution ops. The value must be greater than zero. Typical\\n      usage will be to set this value in (0, 1) to reduce the number of\\n      parameters or computation cost of the model.\\n    dropout_keep_prob: the percentage of activation values that are retained.\\n    is_training: whether is training or not.\\n    prediction_fn: a function to get predictions out of logits.\\n    spatial_squeeze: if True, logits is of shape is [B, C], if false logits is\\n        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\\n    reuse: whether or not the network and its variables should be reused. To be\\n      able to reuse \\'scope\\' must be given.\\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\\n      The data format of the input and output data. With the default format\\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\\n      data storage order is:\\n      [batch, in_channels, in_depth, in_height, in_width].\\n    scope: Optional variable_scope.\\n\\n  Returns:\\n    logits: the pre-softmax activations, a tensor of size\\n      [batch_size, num_classes]\\n    end_points: a dictionary from components of the network to the corresponding\\n      activation.\\n  '\n    assert data_format in ['NDHWC', 'NCDHW']\n    with tf.variable_scope(scope, 'InceptionV1', [inputs, num_classes], reuse=reuse) as scope:\n        with arg_scope([layers.batch_norm, layers.dropout], is_training=is_training):\n            (net, end_points) = s3dg_base(inputs, first_temporal_kernel_size=first_temporal_kernel_size, temporal_conv_startat=temporal_conv_startat, gating_startat=gating_startat, final_endpoint=final_endpoint, min_depth=min_depth, depth_multiplier=depth_multiplier, data_format=data_format, scope=scope)\n            with tf.variable_scope('Logits'):\n                if data_format.startswith('NC'):\n                    net = tf.transpose(net, [0, 2, 3, 4, 1])\n                kernel_size = i3d_utils.reduced_kernel_size_3d(net, [2, 7, 7])\n                net = layers.avg_pool3d(net, kernel_size, stride=1, data_format='NDHWC', scope='AvgPool_0a_7x7')\n                net = layers.dropout(net, dropout_keep_prob, scope='Dropout_0b')\n                logits = layers.conv3d(net, num_classes, [1, 1, 1], activation_fn=None, normalizer_fn=None, data_format='NDHWC', scope='Conv2d_0c_1x1')\n                logits = tf.reduce_mean(logits, axis=1)\n                if spatial_squeeze:\n                    logits = tf.squeeze(logits, [1, 2], name='SpatialSqueeze')\n                end_points['Logits'] = logits\n                end_points['Predictions'] = prediction_fn(logits, scope='Predictions')\n    return (logits, end_points)",
            "def s3dg(inputs, num_classes=1000, first_temporal_kernel_size=3, temporal_conv_startat='Conv2d_2c_3x3', gating_startat='Conv2d_2c_3x3', final_endpoint='Mixed_5c', min_depth=16, depth_multiplier=1.0, dropout_keep_prob=0.8, is_training=True, prediction_fn=layers.softmax, spatial_squeeze=True, reuse=None, data_format='NDHWC', scope='InceptionV1'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Defines the S3D-G architecture.\\n\\n  The default image size used to train this network is 224x224.\\n\\n  Args:\\n    inputs: A 5-D float tensor of size [batch_size, num_frames, height, width,\\n      channels].\\n    num_classes: number of predicted classes.\\n    first_temporal_kernel_size: Specifies the temporal kernel size for the first\\n      conv3d filter. A larger value slows down the model but provides little\\n      accuracy improvement. Must be set to one of 1, 3, 5 or 7.\\n    temporal_conv_startat: Specifies the first conv block to use separable 3D\\n      convs rather than 2D convs (implemented as [1, k, k] 3D conv). This is\\n      used to construct the inverted pyramid models. \\'Conv2d_2c_3x3\\' is the\\n      first valid block to use separable 3D convs. If provided block name is\\n      not present, all valid blocks will use separable 3D convs.\\n    gating_startat: Specifies the first conv block to use self gating.\\n      \\'Conv2d_2c_3x3\\' is the first valid block to use self gating. If provided\\n      block name is not present, all valid blocks will use separable 3D convs.\\n    final_endpoint: Specifies the endpoint to construct the network up to. It\\n      can be one of [\\'Conv2d_1a_7x7\\', \\'MaxPool_2a_3x3\\', \\'Conv2d_2b_1x1\\',\\n      \\'Conv2d_2c_3x3\\', \\'MaxPool_3a_3x3\\', \\'Mixed_3b\\', \\'Mixed_3c\\',\\n      \\'MaxPool_4a_3x3\\', \\'Mixed_4b\\', \\'Mixed_4c\\', \\'Mixed_4d\\', \\'Mixed_4e\\',\\n      \\'Mixed_4f\\', \\'MaxPool_5a_2x2\\', \\'Mixed_5b\\', \\'Mixed_5c\\']\\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\\n      Enforced when depth_multiplier < 1, and not an active constraint when\\n      depth_multiplier >= 1.\\n    depth_multiplier: Float multiplier for the depth (number of channels)\\n      for all convolution ops. The value must be greater than zero. Typical\\n      usage will be to set this value in (0, 1) to reduce the number of\\n      parameters or computation cost of the model.\\n    dropout_keep_prob: the percentage of activation values that are retained.\\n    is_training: whether is training or not.\\n    prediction_fn: a function to get predictions out of logits.\\n    spatial_squeeze: if True, logits is of shape is [B, C], if false logits is\\n        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\\n    reuse: whether or not the network and its variables should be reused. To be\\n      able to reuse \\'scope\\' must be given.\\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\\n      The data format of the input and output data. With the default format\\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\\n      data storage order is:\\n      [batch, in_channels, in_depth, in_height, in_width].\\n    scope: Optional variable_scope.\\n\\n  Returns:\\n    logits: the pre-softmax activations, a tensor of size\\n      [batch_size, num_classes]\\n    end_points: a dictionary from components of the network to the corresponding\\n      activation.\\n  '\n    assert data_format in ['NDHWC', 'NCDHW']\n    with tf.variable_scope(scope, 'InceptionV1', [inputs, num_classes], reuse=reuse) as scope:\n        with arg_scope([layers.batch_norm, layers.dropout], is_training=is_training):\n            (net, end_points) = s3dg_base(inputs, first_temporal_kernel_size=first_temporal_kernel_size, temporal_conv_startat=temporal_conv_startat, gating_startat=gating_startat, final_endpoint=final_endpoint, min_depth=min_depth, depth_multiplier=depth_multiplier, data_format=data_format, scope=scope)\n            with tf.variable_scope('Logits'):\n                if data_format.startswith('NC'):\n                    net = tf.transpose(net, [0, 2, 3, 4, 1])\n                kernel_size = i3d_utils.reduced_kernel_size_3d(net, [2, 7, 7])\n                net = layers.avg_pool3d(net, kernel_size, stride=1, data_format='NDHWC', scope='AvgPool_0a_7x7')\n                net = layers.dropout(net, dropout_keep_prob, scope='Dropout_0b')\n                logits = layers.conv3d(net, num_classes, [1, 1, 1], activation_fn=None, normalizer_fn=None, data_format='NDHWC', scope='Conv2d_0c_1x1')\n                logits = tf.reduce_mean(logits, axis=1)\n                if spatial_squeeze:\n                    logits = tf.squeeze(logits, [1, 2], name='SpatialSqueeze')\n                end_points['Logits'] = logits\n                end_points['Predictions'] = prediction_fn(logits, scope='Predictions')\n    return (logits, end_points)",
            "def s3dg(inputs, num_classes=1000, first_temporal_kernel_size=3, temporal_conv_startat='Conv2d_2c_3x3', gating_startat='Conv2d_2c_3x3', final_endpoint='Mixed_5c', min_depth=16, depth_multiplier=1.0, dropout_keep_prob=0.8, is_training=True, prediction_fn=layers.softmax, spatial_squeeze=True, reuse=None, data_format='NDHWC', scope='InceptionV1'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Defines the S3D-G architecture.\\n\\n  The default image size used to train this network is 224x224.\\n\\n  Args:\\n    inputs: A 5-D float tensor of size [batch_size, num_frames, height, width,\\n      channels].\\n    num_classes: number of predicted classes.\\n    first_temporal_kernel_size: Specifies the temporal kernel size for the first\\n      conv3d filter. A larger value slows down the model but provides little\\n      accuracy improvement. Must be set to one of 1, 3, 5 or 7.\\n    temporal_conv_startat: Specifies the first conv block to use separable 3D\\n      convs rather than 2D convs (implemented as [1, k, k] 3D conv). This is\\n      used to construct the inverted pyramid models. \\'Conv2d_2c_3x3\\' is the\\n      first valid block to use separable 3D convs. If provided block name is\\n      not present, all valid blocks will use separable 3D convs.\\n    gating_startat: Specifies the first conv block to use self gating.\\n      \\'Conv2d_2c_3x3\\' is the first valid block to use self gating. If provided\\n      block name is not present, all valid blocks will use separable 3D convs.\\n    final_endpoint: Specifies the endpoint to construct the network up to. It\\n      can be one of [\\'Conv2d_1a_7x7\\', \\'MaxPool_2a_3x3\\', \\'Conv2d_2b_1x1\\',\\n      \\'Conv2d_2c_3x3\\', \\'MaxPool_3a_3x3\\', \\'Mixed_3b\\', \\'Mixed_3c\\',\\n      \\'MaxPool_4a_3x3\\', \\'Mixed_4b\\', \\'Mixed_4c\\', \\'Mixed_4d\\', \\'Mixed_4e\\',\\n      \\'Mixed_4f\\', \\'MaxPool_5a_2x2\\', \\'Mixed_5b\\', \\'Mixed_5c\\']\\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\\n      Enforced when depth_multiplier < 1, and not an active constraint when\\n      depth_multiplier >= 1.\\n    depth_multiplier: Float multiplier for the depth (number of channels)\\n      for all convolution ops. The value must be greater than zero. Typical\\n      usage will be to set this value in (0, 1) to reduce the number of\\n      parameters or computation cost of the model.\\n    dropout_keep_prob: the percentage of activation values that are retained.\\n    is_training: whether is training or not.\\n    prediction_fn: a function to get predictions out of logits.\\n    spatial_squeeze: if True, logits is of shape is [B, C], if false logits is\\n        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\\n    reuse: whether or not the network and its variables should be reused. To be\\n      able to reuse \\'scope\\' must be given.\\n    data_format: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to \"NDHWC\".\\n      The data format of the input and output data. With the default format\\n      \"NDHWC\", the data is stored in the order of: [batch, in_depth, in_height,\\n      in_width, in_channels]. Alternatively, the format could be \"NCDHW\", the\\n      data storage order is:\\n      [batch, in_channels, in_depth, in_height, in_width].\\n    scope: Optional variable_scope.\\n\\n  Returns:\\n    logits: the pre-softmax activations, a tensor of size\\n      [batch_size, num_classes]\\n    end_points: a dictionary from components of the network to the corresponding\\n      activation.\\n  '\n    assert data_format in ['NDHWC', 'NCDHW']\n    with tf.variable_scope(scope, 'InceptionV1', [inputs, num_classes], reuse=reuse) as scope:\n        with arg_scope([layers.batch_norm, layers.dropout], is_training=is_training):\n            (net, end_points) = s3dg_base(inputs, first_temporal_kernel_size=first_temporal_kernel_size, temporal_conv_startat=temporal_conv_startat, gating_startat=gating_startat, final_endpoint=final_endpoint, min_depth=min_depth, depth_multiplier=depth_multiplier, data_format=data_format, scope=scope)\n            with tf.variable_scope('Logits'):\n                if data_format.startswith('NC'):\n                    net = tf.transpose(net, [0, 2, 3, 4, 1])\n                kernel_size = i3d_utils.reduced_kernel_size_3d(net, [2, 7, 7])\n                net = layers.avg_pool3d(net, kernel_size, stride=1, data_format='NDHWC', scope='AvgPool_0a_7x7')\n                net = layers.dropout(net, dropout_keep_prob, scope='Dropout_0b')\n                logits = layers.conv3d(net, num_classes, [1, 1, 1], activation_fn=None, normalizer_fn=None, data_format='NDHWC', scope='Conv2d_0c_1x1')\n                logits = tf.reduce_mean(logits, axis=1)\n                if spatial_squeeze:\n                    logits = tf.squeeze(logits, [1, 2], name='SpatialSqueeze')\n                end_points['Logits'] = logits\n                end_points['Predictions'] = prediction_fn(logits, scope='Predictions')\n    return (logits, end_points)"
        ]
    }
]