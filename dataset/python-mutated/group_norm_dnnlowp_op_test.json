[
    {
        "func_name": "test_dnnlowp_group_norm",
        "original": "@given(N=st.integers(0, 4), G=st.integers(2, 4), K=st.integers(2, 12), H=st.integers(4, 16), W=st.integers(4, 16), order=st.sampled_from(['NCHW', 'NHWC']), in_quantized=st.booleans(), out_quantized=st.booleans(), weight_quantized=st.booleans(), **hu.gcs_cpu_only)\ndef test_dnnlowp_group_norm(self, N, G, K, H, W, order, in_quantized, out_quantized, weight_quantized, gc, dc):\n    C = G * K\n    X = np.random.rand(N, C, H, W).astype(np.float32) * 5.0 - 1.0\n    if order == 'NHWC':\n        X = utils.NCHW2NHWC(X)\n    gamma = np.random.rand(C).astype(np.float32) * 2.0 - 1.0\n    beta = np.random.randn(C).astype(np.float32) - 0.5\n    Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n    outputs = []\n    op_engine_list = [('GroupNorm', ''), ('GroupNorm', 'DNNLOWP'), ('Int8GroupNorm', 'DNNLOWP')]\n    for (op_type, engine) in op_engine_list:\n        net = core.Net('test_net')\n        do_quantize = 'DNNLOWP' in engine and in_quantized\n        do_dequantize = 'DNNLOWP' in engine and out_quantized\n        do_quantize_weight = engine == 'DNNLOWP' and weight_quantized and (len(outputs) > 0)\n        if do_quantize:\n            quantize = core.CreateOperator('Quantize', ['X'], ['X_q'], engine=engine, device_option=gc)\n            net.Proto().op.extend([quantize])\n        if do_quantize_weight:\n            (int8_given_tensor_fill, gamma_q_param) = dnnlowp_utils.create_int8_given_tensor_fill(gamma, 'gamma_q')\n            net.Proto().op.extend([int8_given_tensor_fill])\n            X_min = 0 if X.size == 0 else X.min()\n            X_max = 0 if X.size == 0 else X.max()\n            X_q_param = dnnlowp_utils.choose_quantization_params(X_min, X_max)\n            int8_bias_tensor_fill = dnnlowp_utils.create_int8_bias_tensor_fill(beta, 'beta_q', X_q_param, gamma_q_param)\n            net.Proto().op.extend([int8_bias_tensor_fill])\n        group_norm = core.CreateOperator(op_type, ['X_q' if do_quantize else 'X', 'gamma_q' if do_quantize_weight else 'gamma', 'beta_q' if do_quantize_weight else 'beta'], ['Y_q' if do_dequantize else 'Y'], dequantize_output=0 if do_dequantize else 1, group=G, order=order, is_test=True, engine=engine, device_option=gc)\n        if do_quantize_weight:\n            dnnlowp_utils.add_quantization_param_args(group_norm, outputs[0][0])\n        net.Proto().op.extend([group_norm])\n        if do_dequantize:\n            dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n            net.Proto().op.extend([dequantize])\n        self.ws.create_blob('X').feed(X, device_option=gc)\n        self.ws.create_blob('gamma').feed(gamma, device_option=gc)\n        self.ws.create_blob('beta').feed(beta, device_option=gc)\n        self.ws.run(net)\n        outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n    check_quantized_results_close(outputs, atol_scale=2.0)",
        "mutated": [
            "@given(N=st.integers(0, 4), G=st.integers(2, 4), K=st.integers(2, 12), H=st.integers(4, 16), W=st.integers(4, 16), order=st.sampled_from(['NCHW', 'NHWC']), in_quantized=st.booleans(), out_quantized=st.booleans(), weight_quantized=st.booleans(), **hu.gcs_cpu_only)\ndef test_dnnlowp_group_norm(self, N, G, K, H, W, order, in_quantized, out_quantized, weight_quantized, gc, dc):\n    if False:\n        i = 10\n    C = G * K\n    X = np.random.rand(N, C, H, W).astype(np.float32) * 5.0 - 1.0\n    if order == 'NHWC':\n        X = utils.NCHW2NHWC(X)\n    gamma = np.random.rand(C).astype(np.float32) * 2.0 - 1.0\n    beta = np.random.randn(C).astype(np.float32) - 0.5\n    Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n    outputs = []\n    op_engine_list = [('GroupNorm', ''), ('GroupNorm', 'DNNLOWP'), ('Int8GroupNorm', 'DNNLOWP')]\n    for (op_type, engine) in op_engine_list:\n        net = core.Net('test_net')\n        do_quantize = 'DNNLOWP' in engine and in_quantized\n        do_dequantize = 'DNNLOWP' in engine and out_quantized\n        do_quantize_weight = engine == 'DNNLOWP' and weight_quantized and (len(outputs) > 0)\n        if do_quantize:\n            quantize = core.CreateOperator('Quantize', ['X'], ['X_q'], engine=engine, device_option=gc)\n            net.Proto().op.extend([quantize])\n        if do_quantize_weight:\n            (int8_given_tensor_fill, gamma_q_param) = dnnlowp_utils.create_int8_given_tensor_fill(gamma, 'gamma_q')\n            net.Proto().op.extend([int8_given_tensor_fill])\n            X_min = 0 if X.size == 0 else X.min()\n            X_max = 0 if X.size == 0 else X.max()\n            X_q_param = dnnlowp_utils.choose_quantization_params(X_min, X_max)\n            int8_bias_tensor_fill = dnnlowp_utils.create_int8_bias_tensor_fill(beta, 'beta_q', X_q_param, gamma_q_param)\n            net.Proto().op.extend([int8_bias_tensor_fill])\n        group_norm = core.CreateOperator(op_type, ['X_q' if do_quantize else 'X', 'gamma_q' if do_quantize_weight else 'gamma', 'beta_q' if do_quantize_weight else 'beta'], ['Y_q' if do_dequantize else 'Y'], dequantize_output=0 if do_dequantize else 1, group=G, order=order, is_test=True, engine=engine, device_option=gc)\n        if do_quantize_weight:\n            dnnlowp_utils.add_quantization_param_args(group_norm, outputs[0][0])\n        net.Proto().op.extend([group_norm])\n        if do_dequantize:\n            dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n            net.Proto().op.extend([dequantize])\n        self.ws.create_blob('X').feed(X, device_option=gc)\n        self.ws.create_blob('gamma').feed(gamma, device_option=gc)\n        self.ws.create_blob('beta').feed(beta, device_option=gc)\n        self.ws.run(net)\n        outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n    check_quantized_results_close(outputs, atol_scale=2.0)",
            "@given(N=st.integers(0, 4), G=st.integers(2, 4), K=st.integers(2, 12), H=st.integers(4, 16), W=st.integers(4, 16), order=st.sampled_from(['NCHW', 'NHWC']), in_quantized=st.booleans(), out_quantized=st.booleans(), weight_quantized=st.booleans(), **hu.gcs_cpu_only)\ndef test_dnnlowp_group_norm(self, N, G, K, H, W, order, in_quantized, out_quantized, weight_quantized, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    C = G * K\n    X = np.random.rand(N, C, H, W).astype(np.float32) * 5.0 - 1.0\n    if order == 'NHWC':\n        X = utils.NCHW2NHWC(X)\n    gamma = np.random.rand(C).astype(np.float32) * 2.0 - 1.0\n    beta = np.random.randn(C).astype(np.float32) - 0.5\n    Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n    outputs = []\n    op_engine_list = [('GroupNorm', ''), ('GroupNorm', 'DNNLOWP'), ('Int8GroupNorm', 'DNNLOWP')]\n    for (op_type, engine) in op_engine_list:\n        net = core.Net('test_net')\n        do_quantize = 'DNNLOWP' in engine and in_quantized\n        do_dequantize = 'DNNLOWP' in engine and out_quantized\n        do_quantize_weight = engine == 'DNNLOWP' and weight_quantized and (len(outputs) > 0)\n        if do_quantize:\n            quantize = core.CreateOperator('Quantize', ['X'], ['X_q'], engine=engine, device_option=gc)\n            net.Proto().op.extend([quantize])\n        if do_quantize_weight:\n            (int8_given_tensor_fill, gamma_q_param) = dnnlowp_utils.create_int8_given_tensor_fill(gamma, 'gamma_q')\n            net.Proto().op.extend([int8_given_tensor_fill])\n            X_min = 0 if X.size == 0 else X.min()\n            X_max = 0 if X.size == 0 else X.max()\n            X_q_param = dnnlowp_utils.choose_quantization_params(X_min, X_max)\n            int8_bias_tensor_fill = dnnlowp_utils.create_int8_bias_tensor_fill(beta, 'beta_q', X_q_param, gamma_q_param)\n            net.Proto().op.extend([int8_bias_tensor_fill])\n        group_norm = core.CreateOperator(op_type, ['X_q' if do_quantize else 'X', 'gamma_q' if do_quantize_weight else 'gamma', 'beta_q' if do_quantize_weight else 'beta'], ['Y_q' if do_dequantize else 'Y'], dequantize_output=0 if do_dequantize else 1, group=G, order=order, is_test=True, engine=engine, device_option=gc)\n        if do_quantize_weight:\n            dnnlowp_utils.add_quantization_param_args(group_norm, outputs[0][0])\n        net.Proto().op.extend([group_norm])\n        if do_dequantize:\n            dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n            net.Proto().op.extend([dequantize])\n        self.ws.create_blob('X').feed(X, device_option=gc)\n        self.ws.create_blob('gamma').feed(gamma, device_option=gc)\n        self.ws.create_blob('beta').feed(beta, device_option=gc)\n        self.ws.run(net)\n        outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n    check_quantized_results_close(outputs, atol_scale=2.0)",
            "@given(N=st.integers(0, 4), G=st.integers(2, 4), K=st.integers(2, 12), H=st.integers(4, 16), W=st.integers(4, 16), order=st.sampled_from(['NCHW', 'NHWC']), in_quantized=st.booleans(), out_quantized=st.booleans(), weight_quantized=st.booleans(), **hu.gcs_cpu_only)\ndef test_dnnlowp_group_norm(self, N, G, K, H, W, order, in_quantized, out_quantized, weight_quantized, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    C = G * K\n    X = np.random.rand(N, C, H, W).astype(np.float32) * 5.0 - 1.0\n    if order == 'NHWC':\n        X = utils.NCHW2NHWC(X)\n    gamma = np.random.rand(C).astype(np.float32) * 2.0 - 1.0\n    beta = np.random.randn(C).astype(np.float32) - 0.5\n    Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n    outputs = []\n    op_engine_list = [('GroupNorm', ''), ('GroupNorm', 'DNNLOWP'), ('Int8GroupNorm', 'DNNLOWP')]\n    for (op_type, engine) in op_engine_list:\n        net = core.Net('test_net')\n        do_quantize = 'DNNLOWP' in engine and in_quantized\n        do_dequantize = 'DNNLOWP' in engine and out_quantized\n        do_quantize_weight = engine == 'DNNLOWP' and weight_quantized and (len(outputs) > 0)\n        if do_quantize:\n            quantize = core.CreateOperator('Quantize', ['X'], ['X_q'], engine=engine, device_option=gc)\n            net.Proto().op.extend([quantize])\n        if do_quantize_weight:\n            (int8_given_tensor_fill, gamma_q_param) = dnnlowp_utils.create_int8_given_tensor_fill(gamma, 'gamma_q')\n            net.Proto().op.extend([int8_given_tensor_fill])\n            X_min = 0 if X.size == 0 else X.min()\n            X_max = 0 if X.size == 0 else X.max()\n            X_q_param = dnnlowp_utils.choose_quantization_params(X_min, X_max)\n            int8_bias_tensor_fill = dnnlowp_utils.create_int8_bias_tensor_fill(beta, 'beta_q', X_q_param, gamma_q_param)\n            net.Proto().op.extend([int8_bias_tensor_fill])\n        group_norm = core.CreateOperator(op_type, ['X_q' if do_quantize else 'X', 'gamma_q' if do_quantize_weight else 'gamma', 'beta_q' if do_quantize_weight else 'beta'], ['Y_q' if do_dequantize else 'Y'], dequantize_output=0 if do_dequantize else 1, group=G, order=order, is_test=True, engine=engine, device_option=gc)\n        if do_quantize_weight:\n            dnnlowp_utils.add_quantization_param_args(group_norm, outputs[0][0])\n        net.Proto().op.extend([group_norm])\n        if do_dequantize:\n            dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n            net.Proto().op.extend([dequantize])\n        self.ws.create_blob('X').feed(X, device_option=gc)\n        self.ws.create_blob('gamma').feed(gamma, device_option=gc)\n        self.ws.create_blob('beta').feed(beta, device_option=gc)\n        self.ws.run(net)\n        outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n    check_quantized_results_close(outputs, atol_scale=2.0)",
            "@given(N=st.integers(0, 4), G=st.integers(2, 4), K=st.integers(2, 12), H=st.integers(4, 16), W=st.integers(4, 16), order=st.sampled_from(['NCHW', 'NHWC']), in_quantized=st.booleans(), out_quantized=st.booleans(), weight_quantized=st.booleans(), **hu.gcs_cpu_only)\ndef test_dnnlowp_group_norm(self, N, G, K, H, W, order, in_quantized, out_quantized, weight_quantized, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    C = G * K\n    X = np.random.rand(N, C, H, W).astype(np.float32) * 5.0 - 1.0\n    if order == 'NHWC':\n        X = utils.NCHW2NHWC(X)\n    gamma = np.random.rand(C).astype(np.float32) * 2.0 - 1.0\n    beta = np.random.randn(C).astype(np.float32) - 0.5\n    Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n    outputs = []\n    op_engine_list = [('GroupNorm', ''), ('GroupNorm', 'DNNLOWP'), ('Int8GroupNorm', 'DNNLOWP')]\n    for (op_type, engine) in op_engine_list:\n        net = core.Net('test_net')\n        do_quantize = 'DNNLOWP' in engine and in_quantized\n        do_dequantize = 'DNNLOWP' in engine and out_quantized\n        do_quantize_weight = engine == 'DNNLOWP' and weight_quantized and (len(outputs) > 0)\n        if do_quantize:\n            quantize = core.CreateOperator('Quantize', ['X'], ['X_q'], engine=engine, device_option=gc)\n            net.Proto().op.extend([quantize])\n        if do_quantize_weight:\n            (int8_given_tensor_fill, gamma_q_param) = dnnlowp_utils.create_int8_given_tensor_fill(gamma, 'gamma_q')\n            net.Proto().op.extend([int8_given_tensor_fill])\n            X_min = 0 if X.size == 0 else X.min()\n            X_max = 0 if X.size == 0 else X.max()\n            X_q_param = dnnlowp_utils.choose_quantization_params(X_min, X_max)\n            int8_bias_tensor_fill = dnnlowp_utils.create_int8_bias_tensor_fill(beta, 'beta_q', X_q_param, gamma_q_param)\n            net.Proto().op.extend([int8_bias_tensor_fill])\n        group_norm = core.CreateOperator(op_type, ['X_q' if do_quantize else 'X', 'gamma_q' if do_quantize_weight else 'gamma', 'beta_q' if do_quantize_weight else 'beta'], ['Y_q' if do_dequantize else 'Y'], dequantize_output=0 if do_dequantize else 1, group=G, order=order, is_test=True, engine=engine, device_option=gc)\n        if do_quantize_weight:\n            dnnlowp_utils.add_quantization_param_args(group_norm, outputs[0][0])\n        net.Proto().op.extend([group_norm])\n        if do_dequantize:\n            dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n            net.Proto().op.extend([dequantize])\n        self.ws.create_blob('X').feed(X, device_option=gc)\n        self.ws.create_blob('gamma').feed(gamma, device_option=gc)\n        self.ws.create_blob('beta').feed(beta, device_option=gc)\n        self.ws.run(net)\n        outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n    check_quantized_results_close(outputs, atol_scale=2.0)",
            "@given(N=st.integers(0, 4), G=st.integers(2, 4), K=st.integers(2, 12), H=st.integers(4, 16), W=st.integers(4, 16), order=st.sampled_from(['NCHW', 'NHWC']), in_quantized=st.booleans(), out_quantized=st.booleans(), weight_quantized=st.booleans(), **hu.gcs_cpu_only)\ndef test_dnnlowp_group_norm(self, N, G, K, H, W, order, in_quantized, out_quantized, weight_quantized, gc, dc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    C = G * K\n    X = np.random.rand(N, C, H, W).astype(np.float32) * 5.0 - 1.0\n    if order == 'NHWC':\n        X = utils.NCHW2NHWC(X)\n    gamma = np.random.rand(C).astype(np.float32) * 2.0 - 1.0\n    beta = np.random.randn(C).astype(np.float32) - 0.5\n    Output = collections.namedtuple('Output', ['Y', 'op_type', 'engine'])\n    outputs = []\n    op_engine_list = [('GroupNorm', ''), ('GroupNorm', 'DNNLOWP'), ('Int8GroupNorm', 'DNNLOWP')]\n    for (op_type, engine) in op_engine_list:\n        net = core.Net('test_net')\n        do_quantize = 'DNNLOWP' in engine and in_quantized\n        do_dequantize = 'DNNLOWP' in engine and out_quantized\n        do_quantize_weight = engine == 'DNNLOWP' and weight_quantized and (len(outputs) > 0)\n        if do_quantize:\n            quantize = core.CreateOperator('Quantize', ['X'], ['X_q'], engine=engine, device_option=gc)\n            net.Proto().op.extend([quantize])\n        if do_quantize_weight:\n            (int8_given_tensor_fill, gamma_q_param) = dnnlowp_utils.create_int8_given_tensor_fill(gamma, 'gamma_q')\n            net.Proto().op.extend([int8_given_tensor_fill])\n            X_min = 0 if X.size == 0 else X.min()\n            X_max = 0 if X.size == 0 else X.max()\n            X_q_param = dnnlowp_utils.choose_quantization_params(X_min, X_max)\n            int8_bias_tensor_fill = dnnlowp_utils.create_int8_bias_tensor_fill(beta, 'beta_q', X_q_param, gamma_q_param)\n            net.Proto().op.extend([int8_bias_tensor_fill])\n        group_norm = core.CreateOperator(op_type, ['X_q' if do_quantize else 'X', 'gamma_q' if do_quantize_weight else 'gamma', 'beta_q' if do_quantize_weight else 'beta'], ['Y_q' if do_dequantize else 'Y'], dequantize_output=0 if do_dequantize else 1, group=G, order=order, is_test=True, engine=engine, device_option=gc)\n        if do_quantize_weight:\n            dnnlowp_utils.add_quantization_param_args(group_norm, outputs[0][0])\n        net.Proto().op.extend([group_norm])\n        if do_dequantize:\n            dequantize = core.CreateOperator('Dequantize', ['Y_q'], ['Y'], engine=engine, device_option=gc)\n            net.Proto().op.extend([dequantize])\n        self.ws.create_blob('X').feed(X, device_option=gc)\n        self.ws.create_blob('gamma').feed(gamma, device_option=gc)\n        self.ws.create_blob('beta').feed(beta, device_option=gc)\n        self.ws.run(net)\n        outputs.append(Output(Y=self.ws.blobs['Y'].fetch(), op_type=op_type, engine=engine))\n    check_quantized_results_close(outputs, atol_scale=2.0)"
        ]
    }
]