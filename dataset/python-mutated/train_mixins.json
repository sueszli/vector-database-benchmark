[
    {
        "func_name": "anchor_target_3d",
        "original": "def anchor_target_3d(self, anchor_list, gt_bboxes_list, input_metas, gt_bboxes_ignore_list=None, gt_labels_list=None, label_channels=1, num_classes=1, sampling=True):\n    \"\"\"Compute regression and classification targets for anchors.\n\n        Args:\n            anchor_list (list[list]): Multi level anchors of each image.\n            gt_bboxes_list (list[:obj:`BaseInstance3DBoxes`]): Ground truth\n                bboxes of each image.\n            input_metas (list[dict]): Meta info of each image.\n            gt_bboxes_ignore_list (list): Ignore list of gt bboxes.\n            gt_labels_list (list[torch.Tensor]): Gt labels of batches.\n            label_channels (int): The channel of labels.\n            num_classes (int): The number of classes.\n            sampling (bool): Whether to sample anchors.\n\n        Returns:\n            tuple (list, list, list, list, list, list, int, int):\n                Anchor targets, including labels, label weights,\n                bbox targets, bbox weights, direction targets,\n                direction weights, number of positive anchors and\n                number of negative anchors.\n        \"\"\"\n    num_imgs = len(input_metas)\n    assert len(anchor_list) == num_imgs\n    if isinstance(anchor_list[0][0], list):\n        num_level_anchors = [sum([anchor.size(0) for anchor in anchors]) for anchors in anchor_list[0]]\n        for i in range(num_imgs):\n            anchor_list[i] = anchor_list[i][0]\n    else:\n        num_level_anchors = [anchors.view(-1, self.box_code_size).size(0) for anchors in anchor_list[0]]\n        for i in range(num_imgs):\n            anchor_list[i] = torch.cat(anchor_list[i])\n    if gt_bboxes_ignore_list is None:\n        gt_bboxes_ignore_list = [None for _ in range(num_imgs)]\n    if gt_labels_list is None:\n        gt_labels_list = [None for _ in range(num_imgs)]\n    (all_labels, all_label_weights, all_bbox_targets, all_bbox_weights, all_dir_targets, all_dir_weights, pos_inds_list, neg_inds_list) = multi_apply(self.anchor_target_3d_single, anchor_list, gt_bboxes_list, gt_bboxes_ignore_list, gt_labels_list, input_metas, label_channels=label_channels, num_classes=num_classes, sampling=sampling)\n    if any([labels is None for labels in all_labels]):\n        return None\n    num_total_pos = sum([max(inds.numel(), 1) for inds in pos_inds_list])\n    num_total_neg = sum([max(inds.numel(), 1) for inds in neg_inds_list])\n    labels_list = images_to_levels(all_labels, num_level_anchors)\n    label_weights_list = images_to_levels(all_label_weights, num_level_anchors)\n    bbox_targets_list = images_to_levels(all_bbox_targets, num_level_anchors)\n    bbox_weights_list = images_to_levels(all_bbox_weights, num_level_anchors)\n    dir_targets_list = images_to_levels(all_dir_targets, num_level_anchors)\n    dir_weights_list = images_to_levels(all_dir_weights, num_level_anchors)\n    return (labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_pos, num_total_neg)",
        "mutated": [
            "def anchor_target_3d(self, anchor_list, gt_bboxes_list, input_metas, gt_bboxes_ignore_list=None, gt_labels_list=None, label_channels=1, num_classes=1, sampling=True):\n    if False:\n        i = 10\n    'Compute regression and classification targets for anchors.\\n\\n        Args:\\n            anchor_list (list[list]): Multi level anchors of each image.\\n            gt_bboxes_list (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each image.\\n            input_metas (list[dict]): Meta info of each image.\\n            gt_bboxes_ignore_list (list): Ignore list of gt bboxes.\\n            gt_labels_list (list[torch.Tensor]): Gt labels of batches.\\n            label_channels (int): The channel of labels.\\n            num_classes (int): The number of classes.\\n            sampling (bool): Whether to sample anchors.\\n\\n        Returns:\\n            tuple (list, list, list, list, list, list, int, int):\\n                Anchor targets, including labels, label weights,\\n                bbox targets, bbox weights, direction targets,\\n                direction weights, number of positive anchors and\\n                number of negative anchors.\\n        '\n    num_imgs = len(input_metas)\n    assert len(anchor_list) == num_imgs\n    if isinstance(anchor_list[0][0], list):\n        num_level_anchors = [sum([anchor.size(0) for anchor in anchors]) for anchors in anchor_list[0]]\n        for i in range(num_imgs):\n            anchor_list[i] = anchor_list[i][0]\n    else:\n        num_level_anchors = [anchors.view(-1, self.box_code_size).size(0) for anchors in anchor_list[0]]\n        for i in range(num_imgs):\n            anchor_list[i] = torch.cat(anchor_list[i])\n    if gt_bboxes_ignore_list is None:\n        gt_bboxes_ignore_list = [None for _ in range(num_imgs)]\n    if gt_labels_list is None:\n        gt_labels_list = [None for _ in range(num_imgs)]\n    (all_labels, all_label_weights, all_bbox_targets, all_bbox_weights, all_dir_targets, all_dir_weights, pos_inds_list, neg_inds_list) = multi_apply(self.anchor_target_3d_single, anchor_list, gt_bboxes_list, gt_bboxes_ignore_list, gt_labels_list, input_metas, label_channels=label_channels, num_classes=num_classes, sampling=sampling)\n    if any([labels is None for labels in all_labels]):\n        return None\n    num_total_pos = sum([max(inds.numel(), 1) for inds in pos_inds_list])\n    num_total_neg = sum([max(inds.numel(), 1) for inds in neg_inds_list])\n    labels_list = images_to_levels(all_labels, num_level_anchors)\n    label_weights_list = images_to_levels(all_label_weights, num_level_anchors)\n    bbox_targets_list = images_to_levels(all_bbox_targets, num_level_anchors)\n    bbox_weights_list = images_to_levels(all_bbox_weights, num_level_anchors)\n    dir_targets_list = images_to_levels(all_dir_targets, num_level_anchors)\n    dir_weights_list = images_to_levels(all_dir_weights, num_level_anchors)\n    return (labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_pos, num_total_neg)",
            "def anchor_target_3d(self, anchor_list, gt_bboxes_list, input_metas, gt_bboxes_ignore_list=None, gt_labels_list=None, label_channels=1, num_classes=1, sampling=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Compute regression and classification targets for anchors.\\n\\n        Args:\\n            anchor_list (list[list]): Multi level anchors of each image.\\n            gt_bboxes_list (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each image.\\n            input_metas (list[dict]): Meta info of each image.\\n            gt_bboxes_ignore_list (list): Ignore list of gt bboxes.\\n            gt_labels_list (list[torch.Tensor]): Gt labels of batches.\\n            label_channels (int): The channel of labels.\\n            num_classes (int): The number of classes.\\n            sampling (bool): Whether to sample anchors.\\n\\n        Returns:\\n            tuple (list, list, list, list, list, list, int, int):\\n                Anchor targets, including labels, label weights,\\n                bbox targets, bbox weights, direction targets,\\n                direction weights, number of positive anchors and\\n                number of negative anchors.\\n        '\n    num_imgs = len(input_metas)\n    assert len(anchor_list) == num_imgs\n    if isinstance(anchor_list[0][0], list):\n        num_level_anchors = [sum([anchor.size(0) for anchor in anchors]) for anchors in anchor_list[0]]\n        for i in range(num_imgs):\n            anchor_list[i] = anchor_list[i][0]\n    else:\n        num_level_anchors = [anchors.view(-1, self.box_code_size).size(0) for anchors in anchor_list[0]]\n        for i in range(num_imgs):\n            anchor_list[i] = torch.cat(anchor_list[i])\n    if gt_bboxes_ignore_list is None:\n        gt_bboxes_ignore_list = [None for _ in range(num_imgs)]\n    if gt_labels_list is None:\n        gt_labels_list = [None for _ in range(num_imgs)]\n    (all_labels, all_label_weights, all_bbox_targets, all_bbox_weights, all_dir_targets, all_dir_weights, pos_inds_list, neg_inds_list) = multi_apply(self.anchor_target_3d_single, anchor_list, gt_bboxes_list, gt_bboxes_ignore_list, gt_labels_list, input_metas, label_channels=label_channels, num_classes=num_classes, sampling=sampling)\n    if any([labels is None for labels in all_labels]):\n        return None\n    num_total_pos = sum([max(inds.numel(), 1) for inds in pos_inds_list])\n    num_total_neg = sum([max(inds.numel(), 1) for inds in neg_inds_list])\n    labels_list = images_to_levels(all_labels, num_level_anchors)\n    label_weights_list = images_to_levels(all_label_weights, num_level_anchors)\n    bbox_targets_list = images_to_levels(all_bbox_targets, num_level_anchors)\n    bbox_weights_list = images_to_levels(all_bbox_weights, num_level_anchors)\n    dir_targets_list = images_to_levels(all_dir_targets, num_level_anchors)\n    dir_weights_list = images_to_levels(all_dir_weights, num_level_anchors)\n    return (labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_pos, num_total_neg)",
            "def anchor_target_3d(self, anchor_list, gt_bboxes_list, input_metas, gt_bboxes_ignore_list=None, gt_labels_list=None, label_channels=1, num_classes=1, sampling=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Compute regression and classification targets for anchors.\\n\\n        Args:\\n            anchor_list (list[list]): Multi level anchors of each image.\\n            gt_bboxes_list (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each image.\\n            input_metas (list[dict]): Meta info of each image.\\n            gt_bboxes_ignore_list (list): Ignore list of gt bboxes.\\n            gt_labels_list (list[torch.Tensor]): Gt labels of batches.\\n            label_channels (int): The channel of labels.\\n            num_classes (int): The number of classes.\\n            sampling (bool): Whether to sample anchors.\\n\\n        Returns:\\n            tuple (list, list, list, list, list, list, int, int):\\n                Anchor targets, including labels, label weights,\\n                bbox targets, bbox weights, direction targets,\\n                direction weights, number of positive anchors and\\n                number of negative anchors.\\n        '\n    num_imgs = len(input_metas)\n    assert len(anchor_list) == num_imgs\n    if isinstance(anchor_list[0][0], list):\n        num_level_anchors = [sum([anchor.size(0) for anchor in anchors]) for anchors in anchor_list[0]]\n        for i in range(num_imgs):\n            anchor_list[i] = anchor_list[i][0]\n    else:\n        num_level_anchors = [anchors.view(-1, self.box_code_size).size(0) for anchors in anchor_list[0]]\n        for i in range(num_imgs):\n            anchor_list[i] = torch.cat(anchor_list[i])\n    if gt_bboxes_ignore_list is None:\n        gt_bboxes_ignore_list = [None for _ in range(num_imgs)]\n    if gt_labels_list is None:\n        gt_labels_list = [None for _ in range(num_imgs)]\n    (all_labels, all_label_weights, all_bbox_targets, all_bbox_weights, all_dir_targets, all_dir_weights, pos_inds_list, neg_inds_list) = multi_apply(self.anchor_target_3d_single, anchor_list, gt_bboxes_list, gt_bboxes_ignore_list, gt_labels_list, input_metas, label_channels=label_channels, num_classes=num_classes, sampling=sampling)\n    if any([labels is None for labels in all_labels]):\n        return None\n    num_total_pos = sum([max(inds.numel(), 1) for inds in pos_inds_list])\n    num_total_neg = sum([max(inds.numel(), 1) for inds in neg_inds_list])\n    labels_list = images_to_levels(all_labels, num_level_anchors)\n    label_weights_list = images_to_levels(all_label_weights, num_level_anchors)\n    bbox_targets_list = images_to_levels(all_bbox_targets, num_level_anchors)\n    bbox_weights_list = images_to_levels(all_bbox_weights, num_level_anchors)\n    dir_targets_list = images_to_levels(all_dir_targets, num_level_anchors)\n    dir_weights_list = images_to_levels(all_dir_weights, num_level_anchors)\n    return (labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_pos, num_total_neg)",
            "def anchor_target_3d(self, anchor_list, gt_bboxes_list, input_metas, gt_bboxes_ignore_list=None, gt_labels_list=None, label_channels=1, num_classes=1, sampling=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Compute regression and classification targets for anchors.\\n\\n        Args:\\n            anchor_list (list[list]): Multi level anchors of each image.\\n            gt_bboxes_list (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each image.\\n            input_metas (list[dict]): Meta info of each image.\\n            gt_bboxes_ignore_list (list): Ignore list of gt bboxes.\\n            gt_labels_list (list[torch.Tensor]): Gt labels of batches.\\n            label_channels (int): The channel of labels.\\n            num_classes (int): The number of classes.\\n            sampling (bool): Whether to sample anchors.\\n\\n        Returns:\\n            tuple (list, list, list, list, list, list, int, int):\\n                Anchor targets, including labels, label weights,\\n                bbox targets, bbox weights, direction targets,\\n                direction weights, number of positive anchors and\\n                number of negative anchors.\\n        '\n    num_imgs = len(input_metas)\n    assert len(anchor_list) == num_imgs\n    if isinstance(anchor_list[0][0], list):\n        num_level_anchors = [sum([anchor.size(0) for anchor in anchors]) for anchors in anchor_list[0]]\n        for i in range(num_imgs):\n            anchor_list[i] = anchor_list[i][0]\n    else:\n        num_level_anchors = [anchors.view(-1, self.box_code_size).size(0) for anchors in anchor_list[0]]\n        for i in range(num_imgs):\n            anchor_list[i] = torch.cat(anchor_list[i])\n    if gt_bboxes_ignore_list is None:\n        gt_bboxes_ignore_list = [None for _ in range(num_imgs)]\n    if gt_labels_list is None:\n        gt_labels_list = [None for _ in range(num_imgs)]\n    (all_labels, all_label_weights, all_bbox_targets, all_bbox_weights, all_dir_targets, all_dir_weights, pos_inds_list, neg_inds_list) = multi_apply(self.anchor_target_3d_single, anchor_list, gt_bboxes_list, gt_bboxes_ignore_list, gt_labels_list, input_metas, label_channels=label_channels, num_classes=num_classes, sampling=sampling)\n    if any([labels is None for labels in all_labels]):\n        return None\n    num_total_pos = sum([max(inds.numel(), 1) for inds in pos_inds_list])\n    num_total_neg = sum([max(inds.numel(), 1) for inds in neg_inds_list])\n    labels_list = images_to_levels(all_labels, num_level_anchors)\n    label_weights_list = images_to_levels(all_label_weights, num_level_anchors)\n    bbox_targets_list = images_to_levels(all_bbox_targets, num_level_anchors)\n    bbox_weights_list = images_to_levels(all_bbox_weights, num_level_anchors)\n    dir_targets_list = images_to_levels(all_dir_targets, num_level_anchors)\n    dir_weights_list = images_to_levels(all_dir_weights, num_level_anchors)\n    return (labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_pos, num_total_neg)",
            "def anchor_target_3d(self, anchor_list, gt_bboxes_list, input_metas, gt_bboxes_ignore_list=None, gt_labels_list=None, label_channels=1, num_classes=1, sampling=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Compute regression and classification targets for anchors.\\n\\n        Args:\\n            anchor_list (list[list]): Multi level anchors of each image.\\n            gt_bboxes_list (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each image.\\n            input_metas (list[dict]): Meta info of each image.\\n            gt_bboxes_ignore_list (list): Ignore list of gt bboxes.\\n            gt_labels_list (list[torch.Tensor]): Gt labels of batches.\\n            label_channels (int): The channel of labels.\\n            num_classes (int): The number of classes.\\n            sampling (bool): Whether to sample anchors.\\n\\n        Returns:\\n            tuple (list, list, list, list, list, list, int, int):\\n                Anchor targets, including labels, label weights,\\n                bbox targets, bbox weights, direction targets,\\n                direction weights, number of positive anchors and\\n                number of negative anchors.\\n        '\n    num_imgs = len(input_metas)\n    assert len(anchor_list) == num_imgs\n    if isinstance(anchor_list[0][0], list):\n        num_level_anchors = [sum([anchor.size(0) for anchor in anchors]) for anchors in anchor_list[0]]\n        for i in range(num_imgs):\n            anchor_list[i] = anchor_list[i][0]\n    else:\n        num_level_anchors = [anchors.view(-1, self.box_code_size).size(0) for anchors in anchor_list[0]]\n        for i in range(num_imgs):\n            anchor_list[i] = torch.cat(anchor_list[i])\n    if gt_bboxes_ignore_list is None:\n        gt_bboxes_ignore_list = [None for _ in range(num_imgs)]\n    if gt_labels_list is None:\n        gt_labels_list = [None for _ in range(num_imgs)]\n    (all_labels, all_label_weights, all_bbox_targets, all_bbox_weights, all_dir_targets, all_dir_weights, pos_inds_list, neg_inds_list) = multi_apply(self.anchor_target_3d_single, anchor_list, gt_bboxes_list, gt_bboxes_ignore_list, gt_labels_list, input_metas, label_channels=label_channels, num_classes=num_classes, sampling=sampling)\n    if any([labels is None for labels in all_labels]):\n        return None\n    num_total_pos = sum([max(inds.numel(), 1) for inds in pos_inds_list])\n    num_total_neg = sum([max(inds.numel(), 1) for inds in neg_inds_list])\n    labels_list = images_to_levels(all_labels, num_level_anchors)\n    label_weights_list = images_to_levels(all_label_weights, num_level_anchors)\n    bbox_targets_list = images_to_levels(all_bbox_targets, num_level_anchors)\n    bbox_weights_list = images_to_levels(all_bbox_weights, num_level_anchors)\n    dir_targets_list = images_to_levels(all_dir_targets, num_level_anchors)\n    dir_weights_list = images_to_levels(all_dir_weights, num_level_anchors)\n    return (labels_list, label_weights_list, bbox_targets_list, bbox_weights_list, dir_targets_list, dir_weights_list, num_total_pos, num_total_neg)"
        ]
    },
    {
        "func_name": "anchor_target_3d_single",
        "original": "def anchor_target_3d_single(self, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, label_channels=1, num_classes=1, sampling=True):\n    \"\"\"Compute targets of anchors in single batch.\n\n        Args:\n            anchors (torch.Tensor): Concatenated multi-level anchor.\n            gt_bboxes (:obj:`BaseInstance3DBoxes`): Gt bboxes.\n            gt_bboxes_ignore (torch.Tensor): Ignored gt bboxes.\n            gt_labels (torch.Tensor): Gt class labels.\n            input_meta (dict): Meta info of each image.\n            label_channels (int): The channel of labels.\n            num_classes (int): The number of classes.\n            sampling (bool): Whether to sample anchors.\n\n        Returns:\n            tuple[torch.Tensor]: Anchor targets.\n        \"\"\"\n    if isinstance(self.bbox_assigner, list) and (not isinstance(anchors, list)):\n        feat_size = anchors.size(0) * anchors.size(1) * anchors.size(2)\n        rot_angles = anchors.size(-2)\n        assert len(self.bbox_assigner) == anchors.size(-3)\n        (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds) = ([], [], [], [], [], [], [], [])\n        current_anchor_num = 0\n        for (i, assigner) in enumerate(self.bbox_assigner):\n            current_anchors = anchors[..., i, :, :].reshape(-1, self.box_code_size)\n            current_anchor_num += current_anchors.size(0)\n            if self.assign_per_class:\n                gt_per_cls = gt_labels == i\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes[gt_per_cls, :], gt_bboxes_ignore, gt_labels[gt_per_cls], input_meta, num_classes, sampling)\n            else:\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)\n            (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds) = anchor_targets\n            total_labels.append(labels.reshape(feat_size, 1, rot_angles))\n            total_label_weights.append(label_weights.reshape(feat_size, 1, rot_angles))\n            total_bbox_targets.append(bbox_targets.reshape(feat_size, 1, rot_angles, anchors.size(-1)))\n            total_bbox_weights.append(bbox_weights.reshape(feat_size, 1, rot_angles, anchors.size(-1)))\n            total_dir_targets.append(dir_targets.reshape(feat_size, 1, rot_angles))\n            total_dir_weights.append(dir_weights.reshape(feat_size, 1, rot_angles))\n            total_pos_inds.append(pos_inds)\n            total_neg_inds.append(neg_inds)\n        total_labels = torch.cat(total_labels, dim=-2).reshape(-1)\n        total_label_weights = torch.cat(total_label_weights, dim=-2).reshape(-1)\n        total_bbox_targets = torch.cat(total_bbox_targets, dim=-3).reshape(-1, anchors.size(-1))\n        total_bbox_weights = torch.cat(total_bbox_weights, dim=-3).reshape(-1, anchors.size(-1))\n        total_dir_targets = torch.cat(total_dir_targets, dim=-2).reshape(-1)\n        total_dir_weights = torch.cat(total_dir_weights, dim=-2).reshape(-1)\n        total_pos_inds = torch.cat(total_pos_inds, dim=0).reshape(-1)\n        total_neg_inds = torch.cat(total_neg_inds, dim=0).reshape(-1)\n        return (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds)\n    elif isinstance(self.bbox_assigner, list) and isinstance(anchors, list):\n        assert len(self.bbox_assigner) == len(anchors), 'The number of bbox assigners and anchors should be the same.'\n        (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds) = ([], [], [], [], [], [], [], [])\n        current_anchor_num = 0\n        for (i, assigner) in enumerate(self.bbox_assigner):\n            current_anchors = anchors[i]\n            current_anchor_num += current_anchors.size(0)\n            if self.assign_per_class:\n                gt_per_cls = gt_labels == i\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes[gt_per_cls, :], gt_bboxes_ignore, gt_labels[gt_per_cls], input_meta, num_classes, sampling)\n            else:\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)\n            (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds) = anchor_targets\n            total_labels.append(labels)\n            total_label_weights.append(label_weights)\n            total_bbox_targets.append(bbox_targets.reshape(-1, anchors[i].size(-1)))\n            total_bbox_weights.append(bbox_weights.reshape(-1, anchors[i].size(-1)))\n            total_dir_targets.append(dir_targets)\n            total_dir_weights.append(dir_weights)\n            total_pos_inds.append(pos_inds)\n            total_neg_inds.append(neg_inds)\n        total_labels = torch.cat(total_labels, dim=0)\n        total_label_weights = torch.cat(total_label_weights, dim=0)\n        total_bbox_targets = torch.cat(total_bbox_targets, dim=0)\n        total_bbox_weights = torch.cat(total_bbox_weights, dim=0)\n        total_dir_targets = torch.cat(total_dir_targets, dim=0)\n        total_dir_weights = torch.cat(total_dir_weights, dim=0)\n        total_pos_inds = torch.cat(total_pos_inds, dim=0)\n        total_neg_inds = torch.cat(total_neg_inds, dim=0)\n        return (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds)\n    else:\n        return self.anchor_target_single_assigner(self.bbox_assigner, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)",
        "mutated": [
            "def anchor_target_3d_single(self, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, label_channels=1, num_classes=1, sampling=True):\n    if False:\n        i = 10\n    'Compute targets of anchors in single batch.\\n\\n        Args:\\n            anchors (torch.Tensor): Concatenated multi-level anchor.\\n            gt_bboxes (:obj:`BaseInstance3DBoxes`): Gt bboxes.\\n            gt_bboxes_ignore (torch.Tensor): Ignored gt bboxes.\\n            gt_labels (torch.Tensor): Gt class labels.\\n            input_meta (dict): Meta info of each image.\\n            label_channels (int): The channel of labels.\\n            num_classes (int): The number of classes.\\n            sampling (bool): Whether to sample anchors.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Anchor targets.\\n        '\n    if isinstance(self.bbox_assigner, list) and (not isinstance(anchors, list)):\n        feat_size = anchors.size(0) * anchors.size(1) * anchors.size(2)\n        rot_angles = anchors.size(-2)\n        assert len(self.bbox_assigner) == anchors.size(-3)\n        (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds) = ([], [], [], [], [], [], [], [])\n        current_anchor_num = 0\n        for (i, assigner) in enumerate(self.bbox_assigner):\n            current_anchors = anchors[..., i, :, :].reshape(-1, self.box_code_size)\n            current_anchor_num += current_anchors.size(0)\n            if self.assign_per_class:\n                gt_per_cls = gt_labels == i\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes[gt_per_cls, :], gt_bboxes_ignore, gt_labels[gt_per_cls], input_meta, num_classes, sampling)\n            else:\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)\n            (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds) = anchor_targets\n            total_labels.append(labels.reshape(feat_size, 1, rot_angles))\n            total_label_weights.append(label_weights.reshape(feat_size, 1, rot_angles))\n            total_bbox_targets.append(bbox_targets.reshape(feat_size, 1, rot_angles, anchors.size(-1)))\n            total_bbox_weights.append(bbox_weights.reshape(feat_size, 1, rot_angles, anchors.size(-1)))\n            total_dir_targets.append(dir_targets.reshape(feat_size, 1, rot_angles))\n            total_dir_weights.append(dir_weights.reshape(feat_size, 1, rot_angles))\n            total_pos_inds.append(pos_inds)\n            total_neg_inds.append(neg_inds)\n        total_labels = torch.cat(total_labels, dim=-2).reshape(-1)\n        total_label_weights = torch.cat(total_label_weights, dim=-2).reshape(-1)\n        total_bbox_targets = torch.cat(total_bbox_targets, dim=-3).reshape(-1, anchors.size(-1))\n        total_bbox_weights = torch.cat(total_bbox_weights, dim=-3).reshape(-1, anchors.size(-1))\n        total_dir_targets = torch.cat(total_dir_targets, dim=-2).reshape(-1)\n        total_dir_weights = torch.cat(total_dir_weights, dim=-2).reshape(-1)\n        total_pos_inds = torch.cat(total_pos_inds, dim=0).reshape(-1)\n        total_neg_inds = torch.cat(total_neg_inds, dim=0).reshape(-1)\n        return (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds)\n    elif isinstance(self.bbox_assigner, list) and isinstance(anchors, list):\n        assert len(self.bbox_assigner) == len(anchors), 'The number of bbox assigners and anchors should be the same.'\n        (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds) = ([], [], [], [], [], [], [], [])\n        current_anchor_num = 0\n        for (i, assigner) in enumerate(self.bbox_assigner):\n            current_anchors = anchors[i]\n            current_anchor_num += current_anchors.size(0)\n            if self.assign_per_class:\n                gt_per_cls = gt_labels == i\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes[gt_per_cls, :], gt_bboxes_ignore, gt_labels[gt_per_cls], input_meta, num_classes, sampling)\n            else:\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)\n            (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds) = anchor_targets\n            total_labels.append(labels)\n            total_label_weights.append(label_weights)\n            total_bbox_targets.append(bbox_targets.reshape(-1, anchors[i].size(-1)))\n            total_bbox_weights.append(bbox_weights.reshape(-1, anchors[i].size(-1)))\n            total_dir_targets.append(dir_targets)\n            total_dir_weights.append(dir_weights)\n            total_pos_inds.append(pos_inds)\n            total_neg_inds.append(neg_inds)\n        total_labels = torch.cat(total_labels, dim=0)\n        total_label_weights = torch.cat(total_label_weights, dim=0)\n        total_bbox_targets = torch.cat(total_bbox_targets, dim=0)\n        total_bbox_weights = torch.cat(total_bbox_weights, dim=0)\n        total_dir_targets = torch.cat(total_dir_targets, dim=0)\n        total_dir_weights = torch.cat(total_dir_weights, dim=0)\n        total_pos_inds = torch.cat(total_pos_inds, dim=0)\n        total_neg_inds = torch.cat(total_neg_inds, dim=0)\n        return (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds)\n    else:\n        return self.anchor_target_single_assigner(self.bbox_assigner, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)",
            "def anchor_target_3d_single(self, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, label_channels=1, num_classes=1, sampling=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Compute targets of anchors in single batch.\\n\\n        Args:\\n            anchors (torch.Tensor): Concatenated multi-level anchor.\\n            gt_bboxes (:obj:`BaseInstance3DBoxes`): Gt bboxes.\\n            gt_bboxes_ignore (torch.Tensor): Ignored gt bboxes.\\n            gt_labels (torch.Tensor): Gt class labels.\\n            input_meta (dict): Meta info of each image.\\n            label_channels (int): The channel of labels.\\n            num_classes (int): The number of classes.\\n            sampling (bool): Whether to sample anchors.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Anchor targets.\\n        '\n    if isinstance(self.bbox_assigner, list) and (not isinstance(anchors, list)):\n        feat_size = anchors.size(0) * anchors.size(1) * anchors.size(2)\n        rot_angles = anchors.size(-2)\n        assert len(self.bbox_assigner) == anchors.size(-3)\n        (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds) = ([], [], [], [], [], [], [], [])\n        current_anchor_num = 0\n        for (i, assigner) in enumerate(self.bbox_assigner):\n            current_anchors = anchors[..., i, :, :].reshape(-1, self.box_code_size)\n            current_anchor_num += current_anchors.size(0)\n            if self.assign_per_class:\n                gt_per_cls = gt_labels == i\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes[gt_per_cls, :], gt_bboxes_ignore, gt_labels[gt_per_cls], input_meta, num_classes, sampling)\n            else:\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)\n            (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds) = anchor_targets\n            total_labels.append(labels.reshape(feat_size, 1, rot_angles))\n            total_label_weights.append(label_weights.reshape(feat_size, 1, rot_angles))\n            total_bbox_targets.append(bbox_targets.reshape(feat_size, 1, rot_angles, anchors.size(-1)))\n            total_bbox_weights.append(bbox_weights.reshape(feat_size, 1, rot_angles, anchors.size(-1)))\n            total_dir_targets.append(dir_targets.reshape(feat_size, 1, rot_angles))\n            total_dir_weights.append(dir_weights.reshape(feat_size, 1, rot_angles))\n            total_pos_inds.append(pos_inds)\n            total_neg_inds.append(neg_inds)\n        total_labels = torch.cat(total_labels, dim=-2).reshape(-1)\n        total_label_weights = torch.cat(total_label_weights, dim=-2).reshape(-1)\n        total_bbox_targets = torch.cat(total_bbox_targets, dim=-3).reshape(-1, anchors.size(-1))\n        total_bbox_weights = torch.cat(total_bbox_weights, dim=-3).reshape(-1, anchors.size(-1))\n        total_dir_targets = torch.cat(total_dir_targets, dim=-2).reshape(-1)\n        total_dir_weights = torch.cat(total_dir_weights, dim=-2).reshape(-1)\n        total_pos_inds = torch.cat(total_pos_inds, dim=0).reshape(-1)\n        total_neg_inds = torch.cat(total_neg_inds, dim=0).reshape(-1)\n        return (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds)\n    elif isinstance(self.bbox_assigner, list) and isinstance(anchors, list):\n        assert len(self.bbox_assigner) == len(anchors), 'The number of bbox assigners and anchors should be the same.'\n        (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds) = ([], [], [], [], [], [], [], [])\n        current_anchor_num = 0\n        for (i, assigner) in enumerate(self.bbox_assigner):\n            current_anchors = anchors[i]\n            current_anchor_num += current_anchors.size(0)\n            if self.assign_per_class:\n                gt_per_cls = gt_labels == i\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes[gt_per_cls, :], gt_bboxes_ignore, gt_labels[gt_per_cls], input_meta, num_classes, sampling)\n            else:\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)\n            (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds) = anchor_targets\n            total_labels.append(labels)\n            total_label_weights.append(label_weights)\n            total_bbox_targets.append(bbox_targets.reshape(-1, anchors[i].size(-1)))\n            total_bbox_weights.append(bbox_weights.reshape(-1, anchors[i].size(-1)))\n            total_dir_targets.append(dir_targets)\n            total_dir_weights.append(dir_weights)\n            total_pos_inds.append(pos_inds)\n            total_neg_inds.append(neg_inds)\n        total_labels = torch.cat(total_labels, dim=0)\n        total_label_weights = torch.cat(total_label_weights, dim=0)\n        total_bbox_targets = torch.cat(total_bbox_targets, dim=0)\n        total_bbox_weights = torch.cat(total_bbox_weights, dim=0)\n        total_dir_targets = torch.cat(total_dir_targets, dim=0)\n        total_dir_weights = torch.cat(total_dir_weights, dim=0)\n        total_pos_inds = torch.cat(total_pos_inds, dim=0)\n        total_neg_inds = torch.cat(total_neg_inds, dim=0)\n        return (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds)\n    else:\n        return self.anchor_target_single_assigner(self.bbox_assigner, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)",
            "def anchor_target_3d_single(self, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, label_channels=1, num_classes=1, sampling=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Compute targets of anchors in single batch.\\n\\n        Args:\\n            anchors (torch.Tensor): Concatenated multi-level anchor.\\n            gt_bboxes (:obj:`BaseInstance3DBoxes`): Gt bboxes.\\n            gt_bboxes_ignore (torch.Tensor): Ignored gt bboxes.\\n            gt_labels (torch.Tensor): Gt class labels.\\n            input_meta (dict): Meta info of each image.\\n            label_channels (int): The channel of labels.\\n            num_classes (int): The number of classes.\\n            sampling (bool): Whether to sample anchors.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Anchor targets.\\n        '\n    if isinstance(self.bbox_assigner, list) and (not isinstance(anchors, list)):\n        feat_size = anchors.size(0) * anchors.size(1) * anchors.size(2)\n        rot_angles = anchors.size(-2)\n        assert len(self.bbox_assigner) == anchors.size(-3)\n        (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds) = ([], [], [], [], [], [], [], [])\n        current_anchor_num = 0\n        for (i, assigner) in enumerate(self.bbox_assigner):\n            current_anchors = anchors[..., i, :, :].reshape(-1, self.box_code_size)\n            current_anchor_num += current_anchors.size(0)\n            if self.assign_per_class:\n                gt_per_cls = gt_labels == i\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes[gt_per_cls, :], gt_bboxes_ignore, gt_labels[gt_per_cls], input_meta, num_classes, sampling)\n            else:\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)\n            (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds) = anchor_targets\n            total_labels.append(labels.reshape(feat_size, 1, rot_angles))\n            total_label_weights.append(label_weights.reshape(feat_size, 1, rot_angles))\n            total_bbox_targets.append(bbox_targets.reshape(feat_size, 1, rot_angles, anchors.size(-1)))\n            total_bbox_weights.append(bbox_weights.reshape(feat_size, 1, rot_angles, anchors.size(-1)))\n            total_dir_targets.append(dir_targets.reshape(feat_size, 1, rot_angles))\n            total_dir_weights.append(dir_weights.reshape(feat_size, 1, rot_angles))\n            total_pos_inds.append(pos_inds)\n            total_neg_inds.append(neg_inds)\n        total_labels = torch.cat(total_labels, dim=-2).reshape(-1)\n        total_label_weights = torch.cat(total_label_weights, dim=-2).reshape(-1)\n        total_bbox_targets = torch.cat(total_bbox_targets, dim=-3).reshape(-1, anchors.size(-1))\n        total_bbox_weights = torch.cat(total_bbox_weights, dim=-3).reshape(-1, anchors.size(-1))\n        total_dir_targets = torch.cat(total_dir_targets, dim=-2).reshape(-1)\n        total_dir_weights = torch.cat(total_dir_weights, dim=-2).reshape(-1)\n        total_pos_inds = torch.cat(total_pos_inds, dim=0).reshape(-1)\n        total_neg_inds = torch.cat(total_neg_inds, dim=0).reshape(-1)\n        return (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds)\n    elif isinstance(self.bbox_assigner, list) and isinstance(anchors, list):\n        assert len(self.bbox_assigner) == len(anchors), 'The number of bbox assigners and anchors should be the same.'\n        (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds) = ([], [], [], [], [], [], [], [])\n        current_anchor_num = 0\n        for (i, assigner) in enumerate(self.bbox_assigner):\n            current_anchors = anchors[i]\n            current_anchor_num += current_anchors.size(0)\n            if self.assign_per_class:\n                gt_per_cls = gt_labels == i\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes[gt_per_cls, :], gt_bboxes_ignore, gt_labels[gt_per_cls], input_meta, num_classes, sampling)\n            else:\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)\n            (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds) = anchor_targets\n            total_labels.append(labels)\n            total_label_weights.append(label_weights)\n            total_bbox_targets.append(bbox_targets.reshape(-1, anchors[i].size(-1)))\n            total_bbox_weights.append(bbox_weights.reshape(-1, anchors[i].size(-1)))\n            total_dir_targets.append(dir_targets)\n            total_dir_weights.append(dir_weights)\n            total_pos_inds.append(pos_inds)\n            total_neg_inds.append(neg_inds)\n        total_labels = torch.cat(total_labels, dim=0)\n        total_label_weights = torch.cat(total_label_weights, dim=0)\n        total_bbox_targets = torch.cat(total_bbox_targets, dim=0)\n        total_bbox_weights = torch.cat(total_bbox_weights, dim=0)\n        total_dir_targets = torch.cat(total_dir_targets, dim=0)\n        total_dir_weights = torch.cat(total_dir_weights, dim=0)\n        total_pos_inds = torch.cat(total_pos_inds, dim=0)\n        total_neg_inds = torch.cat(total_neg_inds, dim=0)\n        return (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds)\n    else:\n        return self.anchor_target_single_assigner(self.bbox_assigner, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)",
            "def anchor_target_3d_single(self, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, label_channels=1, num_classes=1, sampling=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Compute targets of anchors in single batch.\\n\\n        Args:\\n            anchors (torch.Tensor): Concatenated multi-level anchor.\\n            gt_bboxes (:obj:`BaseInstance3DBoxes`): Gt bboxes.\\n            gt_bboxes_ignore (torch.Tensor): Ignored gt bboxes.\\n            gt_labels (torch.Tensor): Gt class labels.\\n            input_meta (dict): Meta info of each image.\\n            label_channels (int): The channel of labels.\\n            num_classes (int): The number of classes.\\n            sampling (bool): Whether to sample anchors.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Anchor targets.\\n        '\n    if isinstance(self.bbox_assigner, list) and (not isinstance(anchors, list)):\n        feat_size = anchors.size(0) * anchors.size(1) * anchors.size(2)\n        rot_angles = anchors.size(-2)\n        assert len(self.bbox_assigner) == anchors.size(-3)\n        (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds) = ([], [], [], [], [], [], [], [])\n        current_anchor_num = 0\n        for (i, assigner) in enumerate(self.bbox_assigner):\n            current_anchors = anchors[..., i, :, :].reshape(-1, self.box_code_size)\n            current_anchor_num += current_anchors.size(0)\n            if self.assign_per_class:\n                gt_per_cls = gt_labels == i\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes[gt_per_cls, :], gt_bboxes_ignore, gt_labels[gt_per_cls], input_meta, num_classes, sampling)\n            else:\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)\n            (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds) = anchor_targets\n            total_labels.append(labels.reshape(feat_size, 1, rot_angles))\n            total_label_weights.append(label_weights.reshape(feat_size, 1, rot_angles))\n            total_bbox_targets.append(bbox_targets.reshape(feat_size, 1, rot_angles, anchors.size(-1)))\n            total_bbox_weights.append(bbox_weights.reshape(feat_size, 1, rot_angles, anchors.size(-1)))\n            total_dir_targets.append(dir_targets.reshape(feat_size, 1, rot_angles))\n            total_dir_weights.append(dir_weights.reshape(feat_size, 1, rot_angles))\n            total_pos_inds.append(pos_inds)\n            total_neg_inds.append(neg_inds)\n        total_labels = torch.cat(total_labels, dim=-2).reshape(-1)\n        total_label_weights = torch.cat(total_label_weights, dim=-2).reshape(-1)\n        total_bbox_targets = torch.cat(total_bbox_targets, dim=-3).reshape(-1, anchors.size(-1))\n        total_bbox_weights = torch.cat(total_bbox_weights, dim=-3).reshape(-1, anchors.size(-1))\n        total_dir_targets = torch.cat(total_dir_targets, dim=-2).reshape(-1)\n        total_dir_weights = torch.cat(total_dir_weights, dim=-2).reshape(-1)\n        total_pos_inds = torch.cat(total_pos_inds, dim=0).reshape(-1)\n        total_neg_inds = torch.cat(total_neg_inds, dim=0).reshape(-1)\n        return (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds)\n    elif isinstance(self.bbox_assigner, list) and isinstance(anchors, list):\n        assert len(self.bbox_assigner) == len(anchors), 'The number of bbox assigners and anchors should be the same.'\n        (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds) = ([], [], [], [], [], [], [], [])\n        current_anchor_num = 0\n        for (i, assigner) in enumerate(self.bbox_assigner):\n            current_anchors = anchors[i]\n            current_anchor_num += current_anchors.size(0)\n            if self.assign_per_class:\n                gt_per_cls = gt_labels == i\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes[gt_per_cls, :], gt_bboxes_ignore, gt_labels[gt_per_cls], input_meta, num_classes, sampling)\n            else:\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)\n            (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds) = anchor_targets\n            total_labels.append(labels)\n            total_label_weights.append(label_weights)\n            total_bbox_targets.append(bbox_targets.reshape(-1, anchors[i].size(-1)))\n            total_bbox_weights.append(bbox_weights.reshape(-1, anchors[i].size(-1)))\n            total_dir_targets.append(dir_targets)\n            total_dir_weights.append(dir_weights)\n            total_pos_inds.append(pos_inds)\n            total_neg_inds.append(neg_inds)\n        total_labels = torch.cat(total_labels, dim=0)\n        total_label_weights = torch.cat(total_label_weights, dim=0)\n        total_bbox_targets = torch.cat(total_bbox_targets, dim=0)\n        total_bbox_weights = torch.cat(total_bbox_weights, dim=0)\n        total_dir_targets = torch.cat(total_dir_targets, dim=0)\n        total_dir_weights = torch.cat(total_dir_weights, dim=0)\n        total_pos_inds = torch.cat(total_pos_inds, dim=0)\n        total_neg_inds = torch.cat(total_neg_inds, dim=0)\n        return (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds)\n    else:\n        return self.anchor_target_single_assigner(self.bbox_assigner, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)",
            "def anchor_target_3d_single(self, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, label_channels=1, num_classes=1, sampling=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Compute targets of anchors in single batch.\\n\\n        Args:\\n            anchors (torch.Tensor): Concatenated multi-level anchor.\\n            gt_bboxes (:obj:`BaseInstance3DBoxes`): Gt bboxes.\\n            gt_bboxes_ignore (torch.Tensor): Ignored gt bboxes.\\n            gt_labels (torch.Tensor): Gt class labels.\\n            input_meta (dict): Meta info of each image.\\n            label_channels (int): The channel of labels.\\n            num_classes (int): The number of classes.\\n            sampling (bool): Whether to sample anchors.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Anchor targets.\\n        '\n    if isinstance(self.bbox_assigner, list) and (not isinstance(anchors, list)):\n        feat_size = anchors.size(0) * anchors.size(1) * anchors.size(2)\n        rot_angles = anchors.size(-2)\n        assert len(self.bbox_assigner) == anchors.size(-3)\n        (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds) = ([], [], [], [], [], [], [], [])\n        current_anchor_num = 0\n        for (i, assigner) in enumerate(self.bbox_assigner):\n            current_anchors = anchors[..., i, :, :].reshape(-1, self.box_code_size)\n            current_anchor_num += current_anchors.size(0)\n            if self.assign_per_class:\n                gt_per_cls = gt_labels == i\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes[gt_per_cls, :], gt_bboxes_ignore, gt_labels[gt_per_cls], input_meta, num_classes, sampling)\n            else:\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)\n            (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds) = anchor_targets\n            total_labels.append(labels.reshape(feat_size, 1, rot_angles))\n            total_label_weights.append(label_weights.reshape(feat_size, 1, rot_angles))\n            total_bbox_targets.append(bbox_targets.reshape(feat_size, 1, rot_angles, anchors.size(-1)))\n            total_bbox_weights.append(bbox_weights.reshape(feat_size, 1, rot_angles, anchors.size(-1)))\n            total_dir_targets.append(dir_targets.reshape(feat_size, 1, rot_angles))\n            total_dir_weights.append(dir_weights.reshape(feat_size, 1, rot_angles))\n            total_pos_inds.append(pos_inds)\n            total_neg_inds.append(neg_inds)\n        total_labels = torch.cat(total_labels, dim=-2).reshape(-1)\n        total_label_weights = torch.cat(total_label_weights, dim=-2).reshape(-1)\n        total_bbox_targets = torch.cat(total_bbox_targets, dim=-3).reshape(-1, anchors.size(-1))\n        total_bbox_weights = torch.cat(total_bbox_weights, dim=-3).reshape(-1, anchors.size(-1))\n        total_dir_targets = torch.cat(total_dir_targets, dim=-2).reshape(-1)\n        total_dir_weights = torch.cat(total_dir_weights, dim=-2).reshape(-1)\n        total_pos_inds = torch.cat(total_pos_inds, dim=0).reshape(-1)\n        total_neg_inds = torch.cat(total_neg_inds, dim=0).reshape(-1)\n        return (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds)\n    elif isinstance(self.bbox_assigner, list) and isinstance(anchors, list):\n        assert len(self.bbox_assigner) == len(anchors), 'The number of bbox assigners and anchors should be the same.'\n        (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds) = ([], [], [], [], [], [], [], [])\n        current_anchor_num = 0\n        for (i, assigner) in enumerate(self.bbox_assigner):\n            current_anchors = anchors[i]\n            current_anchor_num += current_anchors.size(0)\n            if self.assign_per_class:\n                gt_per_cls = gt_labels == i\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes[gt_per_cls, :], gt_bboxes_ignore, gt_labels[gt_per_cls], input_meta, num_classes, sampling)\n            else:\n                anchor_targets = self.anchor_target_single_assigner(assigner, current_anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)\n            (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds) = anchor_targets\n            total_labels.append(labels)\n            total_label_weights.append(label_weights)\n            total_bbox_targets.append(bbox_targets.reshape(-1, anchors[i].size(-1)))\n            total_bbox_weights.append(bbox_weights.reshape(-1, anchors[i].size(-1)))\n            total_dir_targets.append(dir_targets)\n            total_dir_weights.append(dir_weights)\n            total_pos_inds.append(pos_inds)\n            total_neg_inds.append(neg_inds)\n        total_labels = torch.cat(total_labels, dim=0)\n        total_label_weights = torch.cat(total_label_weights, dim=0)\n        total_bbox_targets = torch.cat(total_bbox_targets, dim=0)\n        total_bbox_weights = torch.cat(total_bbox_weights, dim=0)\n        total_dir_targets = torch.cat(total_dir_targets, dim=0)\n        total_dir_weights = torch.cat(total_dir_weights, dim=0)\n        total_pos_inds = torch.cat(total_pos_inds, dim=0)\n        total_neg_inds = torch.cat(total_neg_inds, dim=0)\n        return (total_labels, total_label_weights, total_bbox_targets, total_bbox_weights, total_dir_targets, total_dir_weights, total_pos_inds, total_neg_inds)\n    else:\n        return self.anchor_target_single_assigner(self.bbox_assigner, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes, sampling)"
        ]
    },
    {
        "func_name": "anchor_target_single_assigner",
        "original": "def anchor_target_single_assigner(self, bbox_assigner, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes=1, sampling=True):\n    \"\"\"Assign anchors and encode positive anchors.\n\n        Args:\n            bbox_assigner (BaseAssigner): assign positive and negative boxes.\n            anchors (torch.Tensor): Concatenated multi-level anchor.\n            gt_bboxes (:obj:`BaseInstance3DBoxes`): Gt bboxes.\n            gt_bboxes_ignore (torch.Tensor): Ignored gt bboxes.\n            gt_labels (torch.Tensor): Gt class labels.\n            input_meta (dict): Meta info of each image.\n            num_classes (int): The number of classes.\n            sampling (bool): Whether to sample anchors.\n\n        Returns:\n            tuple[torch.Tensor]: Anchor targets.\n        \"\"\"\n    anchors = anchors.reshape(-1, anchors.size(-1))\n    num_valid_anchors = anchors.shape[0]\n    bbox_targets = torch.zeros_like(anchors)\n    bbox_weights = torch.zeros_like(anchors)\n    dir_targets = anchors.new_zeros(anchors.shape[0], dtype=torch.long)\n    dir_weights = anchors.new_zeros(anchors.shape[0], dtype=torch.float)\n    labels = anchors.new_zeros(num_valid_anchors, dtype=torch.long)\n    label_weights = anchors.new_zeros(num_valid_anchors, dtype=torch.float)\n    if len(gt_bboxes) > 0:\n        if not isinstance(gt_bboxes, torch.Tensor):\n            gt_bboxes = gt_bboxes.tensor.to(anchors.device)\n        assign_result = bbox_assigner.assign(anchors, gt_bboxes, gt_bboxes_ignore, gt_labels)\n        sampling_result = self.bbox_sampler.sample(assign_result, anchors, gt_bboxes)\n        pos_inds = sampling_result.pos_inds\n        neg_inds = sampling_result.neg_inds\n    else:\n        pos_inds = torch.nonzero(anchors.new_zeros((anchors.shape[0],), dtype=torch.bool) > 0, as_tuple=False).squeeze(-1).unique()\n        neg_inds = torch.nonzero(anchors.new_zeros((anchors.shape[0],), dtype=torch.bool) == 0, as_tuple=False).squeeze(-1).unique()\n    if gt_labels is not None:\n        labels += num_classes\n    if len(pos_inds) > 0:\n        pos_bbox_targets = self.bbox_coder.encode(sampling_result.pos_bboxes, sampling_result.pos_gt_bboxes)\n        pos_dir_targets = get_direction_target(sampling_result.pos_bboxes, pos_bbox_targets, self.dir_offset, self.dir_limit_offset, one_hot=False)\n        bbox_targets[pos_inds, :] = pos_bbox_targets\n        bbox_weights[pos_inds, :] = 1.0\n        dir_targets[pos_inds] = pos_dir_targets\n        dir_weights[pos_inds] = 1.0\n        if gt_labels is None:\n            labels[pos_inds] = 1\n        else:\n            labels[pos_inds] = gt_labels[sampling_result.pos_assigned_gt_inds]\n        if self.train_cfg.pos_weight <= 0:\n            label_weights[pos_inds] = 1.0\n        else:\n            label_weights[pos_inds] = self.train_cfg.pos_weight\n    if len(neg_inds) > 0:\n        label_weights[neg_inds] = 1.0\n    return (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds)",
        "mutated": [
            "def anchor_target_single_assigner(self, bbox_assigner, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes=1, sampling=True):\n    if False:\n        i = 10\n    'Assign anchors and encode positive anchors.\\n\\n        Args:\\n            bbox_assigner (BaseAssigner): assign positive and negative boxes.\\n            anchors (torch.Tensor): Concatenated multi-level anchor.\\n            gt_bboxes (:obj:`BaseInstance3DBoxes`): Gt bboxes.\\n            gt_bboxes_ignore (torch.Tensor): Ignored gt bboxes.\\n            gt_labels (torch.Tensor): Gt class labels.\\n            input_meta (dict): Meta info of each image.\\n            num_classes (int): The number of classes.\\n            sampling (bool): Whether to sample anchors.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Anchor targets.\\n        '\n    anchors = anchors.reshape(-1, anchors.size(-1))\n    num_valid_anchors = anchors.shape[0]\n    bbox_targets = torch.zeros_like(anchors)\n    bbox_weights = torch.zeros_like(anchors)\n    dir_targets = anchors.new_zeros(anchors.shape[0], dtype=torch.long)\n    dir_weights = anchors.new_zeros(anchors.shape[0], dtype=torch.float)\n    labels = anchors.new_zeros(num_valid_anchors, dtype=torch.long)\n    label_weights = anchors.new_zeros(num_valid_anchors, dtype=torch.float)\n    if len(gt_bboxes) > 0:\n        if not isinstance(gt_bboxes, torch.Tensor):\n            gt_bboxes = gt_bboxes.tensor.to(anchors.device)\n        assign_result = bbox_assigner.assign(anchors, gt_bboxes, gt_bboxes_ignore, gt_labels)\n        sampling_result = self.bbox_sampler.sample(assign_result, anchors, gt_bboxes)\n        pos_inds = sampling_result.pos_inds\n        neg_inds = sampling_result.neg_inds\n    else:\n        pos_inds = torch.nonzero(anchors.new_zeros((anchors.shape[0],), dtype=torch.bool) > 0, as_tuple=False).squeeze(-1).unique()\n        neg_inds = torch.nonzero(anchors.new_zeros((anchors.shape[0],), dtype=torch.bool) == 0, as_tuple=False).squeeze(-1).unique()\n    if gt_labels is not None:\n        labels += num_classes\n    if len(pos_inds) > 0:\n        pos_bbox_targets = self.bbox_coder.encode(sampling_result.pos_bboxes, sampling_result.pos_gt_bboxes)\n        pos_dir_targets = get_direction_target(sampling_result.pos_bboxes, pos_bbox_targets, self.dir_offset, self.dir_limit_offset, one_hot=False)\n        bbox_targets[pos_inds, :] = pos_bbox_targets\n        bbox_weights[pos_inds, :] = 1.0\n        dir_targets[pos_inds] = pos_dir_targets\n        dir_weights[pos_inds] = 1.0\n        if gt_labels is None:\n            labels[pos_inds] = 1\n        else:\n            labels[pos_inds] = gt_labels[sampling_result.pos_assigned_gt_inds]\n        if self.train_cfg.pos_weight <= 0:\n            label_weights[pos_inds] = 1.0\n        else:\n            label_weights[pos_inds] = self.train_cfg.pos_weight\n    if len(neg_inds) > 0:\n        label_weights[neg_inds] = 1.0\n    return (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds)",
            "def anchor_target_single_assigner(self, bbox_assigner, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes=1, sampling=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Assign anchors and encode positive anchors.\\n\\n        Args:\\n            bbox_assigner (BaseAssigner): assign positive and negative boxes.\\n            anchors (torch.Tensor): Concatenated multi-level anchor.\\n            gt_bboxes (:obj:`BaseInstance3DBoxes`): Gt bboxes.\\n            gt_bboxes_ignore (torch.Tensor): Ignored gt bboxes.\\n            gt_labels (torch.Tensor): Gt class labels.\\n            input_meta (dict): Meta info of each image.\\n            num_classes (int): The number of classes.\\n            sampling (bool): Whether to sample anchors.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Anchor targets.\\n        '\n    anchors = anchors.reshape(-1, anchors.size(-1))\n    num_valid_anchors = anchors.shape[0]\n    bbox_targets = torch.zeros_like(anchors)\n    bbox_weights = torch.zeros_like(anchors)\n    dir_targets = anchors.new_zeros(anchors.shape[0], dtype=torch.long)\n    dir_weights = anchors.new_zeros(anchors.shape[0], dtype=torch.float)\n    labels = anchors.new_zeros(num_valid_anchors, dtype=torch.long)\n    label_weights = anchors.new_zeros(num_valid_anchors, dtype=torch.float)\n    if len(gt_bboxes) > 0:\n        if not isinstance(gt_bboxes, torch.Tensor):\n            gt_bboxes = gt_bboxes.tensor.to(anchors.device)\n        assign_result = bbox_assigner.assign(anchors, gt_bboxes, gt_bboxes_ignore, gt_labels)\n        sampling_result = self.bbox_sampler.sample(assign_result, anchors, gt_bboxes)\n        pos_inds = sampling_result.pos_inds\n        neg_inds = sampling_result.neg_inds\n    else:\n        pos_inds = torch.nonzero(anchors.new_zeros((anchors.shape[0],), dtype=torch.bool) > 0, as_tuple=False).squeeze(-1).unique()\n        neg_inds = torch.nonzero(anchors.new_zeros((anchors.shape[0],), dtype=torch.bool) == 0, as_tuple=False).squeeze(-1).unique()\n    if gt_labels is not None:\n        labels += num_classes\n    if len(pos_inds) > 0:\n        pos_bbox_targets = self.bbox_coder.encode(sampling_result.pos_bboxes, sampling_result.pos_gt_bboxes)\n        pos_dir_targets = get_direction_target(sampling_result.pos_bboxes, pos_bbox_targets, self.dir_offset, self.dir_limit_offset, one_hot=False)\n        bbox_targets[pos_inds, :] = pos_bbox_targets\n        bbox_weights[pos_inds, :] = 1.0\n        dir_targets[pos_inds] = pos_dir_targets\n        dir_weights[pos_inds] = 1.0\n        if gt_labels is None:\n            labels[pos_inds] = 1\n        else:\n            labels[pos_inds] = gt_labels[sampling_result.pos_assigned_gt_inds]\n        if self.train_cfg.pos_weight <= 0:\n            label_weights[pos_inds] = 1.0\n        else:\n            label_weights[pos_inds] = self.train_cfg.pos_weight\n    if len(neg_inds) > 0:\n        label_weights[neg_inds] = 1.0\n    return (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds)",
            "def anchor_target_single_assigner(self, bbox_assigner, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes=1, sampling=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Assign anchors and encode positive anchors.\\n\\n        Args:\\n            bbox_assigner (BaseAssigner): assign positive and negative boxes.\\n            anchors (torch.Tensor): Concatenated multi-level anchor.\\n            gt_bboxes (:obj:`BaseInstance3DBoxes`): Gt bboxes.\\n            gt_bboxes_ignore (torch.Tensor): Ignored gt bboxes.\\n            gt_labels (torch.Tensor): Gt class labels.\\n            input_meta (dict): Meta info of each image.\\n            num_classes (int): The number of classes.\\n            sampling (bool): Whether to sample anchors.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Anchor targets.\\n        '\n    anchors = anchors.reshape(-1, anchors.size(-1))\n    num_valid_anchors = anchors.shape[0]\n    bbox_targets = torch.zeros_like(anchors)\n    bbox_weights = torch.zeros_like(anchors)\n    dir_targets = anchors.new_zeros(anchors.shape[0], dtype=torch.long)\n    dir_weights = anchors.new_zeros(anchors.shape[0], dtype=torch.float)\n    labels = anchors.new_zeros(num_valid_anchors, dtype=torch.long)\n    label_weights = anchors.new_zeros(num_valid_anchors, dtype=torch.float)\n    if len(gt_bboxes) > 0:\n        if not isinstance(gt_bboxes, torch.Tensor):\n            gt_bboxes = gt_bboxes.tensor.to(anchors.device)\n        assign_result = bbox_assigner.assign(anchors, gt_bboxes, gt_bboxes_ignore, gt_labels)\n        sampling_result = self.bbox_sampler.sample(assign_result, anchors, gt_bboxes)\n        pos_inds = sampling_result.pos_inds\n        neg_inds = sampling_result.neg_inds\n    else:\n        pos_inds = torch.nonzero(anchors.new_zeros((anchors.shape[0],), dtype=torch.bool) > 0, as_tuple=False).squeeze(-1).unique()\n        neg_inds = torch.nonzero(anchors.new_zeros((anchors.shape[0],), dtype=torch.bool) == 0, as_tuple=False).squeeze(-1).unique()\n    if gt_labels is not None:\n        labels += num_classes\n    if len(pos_inds) > 0:\n        pos_bbox_targets = self.bbox_coder.encode(sampling_result.pos_bboxes, sampling_result.pos_gt_bboxes)\n        pos_dir_targets = get_direction_target(sampling_result.pos_bboxes, pos_bbox_targets, self.dir_offset, self.dir_limit_offset, one_hot=False)\n        bbox_targets[pos_inds, :] = pos_bbox_targets\n        bbox_weights[pos_inds, :] = 1.0\n        dir_targets[pos_inds] = pos_dir_targets\n        dir_weights[pos_inds] = 1.0\n        if gt_labels is None:\n            labels[pos_inds] = 1\n        else:\n            labels[pos_inds] = gt_labels[sampling_result.pos_assigned_gt_inds]\n        if self.train_cfg.pos_weight <= 0:\n            label_weights[pos_inds] = 1.0\n        else:\n            label_weights[pos_inds] = self.train_cfg.pos_weight\n    if len(neg_inds) > 0:\n        label_weights[neg_inds] = 1.0\n    return (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds)",
            "def anchor_target_single_assigner(self, bbox_assigner, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes=1, sampling=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Assign anchors and encode positive anchors.\\n\\n        Args:\\n            bbox_assigner (BaseAssigner): assign positive and negative boxes.\\n            anchors (torch.Tensor): Concatenated multi-level anchor.\\n            gt_bboxes (:obj:`BaseInstance3DBoxes`): Gt bboxes.\\n            gt_bboxes_ignore (torch.Tensor): Ignored gt bboxes.\\n            gt_labels (torch.Tensor): Gt class labels.\\n            input_meta (dict): Meta info of each image.\\n            num_classes (int): The number of classes.\\n            sampling (bool): Whether to sample anchors.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Anchor targets.\\n        '\n    anchors = anchors.reshape(-1, anchors.size(-1))\n    num_valid_anchors = anchors.shape[0]\n    bbox_targets = torch.zeros_like(anchors)\n    bbox_weights = torch.zeros_like(anchors)\n    dir_targets = anchors.new_zeros(anchors.shape[0], dtype=torch.long)\n    dir_weights = anchors.new_zeros(anchors.shape[0], dtype=torch.float)\n    labels = anchors.new_zeros(num_valid_anchors, dtype=torch.long)\n    label_weights = anchors.new_zeros(num_valid_anchors, dtype=torch.float)\n    if len(gt_bboxes) > 0:\n        if not isinstance(gt_bboxes, torch.Tensor):\n            gt_bboxes = gt_bboxes.tensor.to(anchors.device)\n        assign_result = bbox_assigner.assign(anchors, gt_bboxes, gt_bboxes_ignore, gt_labels)\n        sampling_result = self.bbox_sampler.sample(assign_result, anchors, gt_bboxes)\n        pos_inds = sampling_result.pos_inds\n        neg_inds = sampling_result.neg_inds\n    else:\n        pos_inds = torch.nonzero(anchors.new_zeros((anchors.shape[0],), dtype=torch.bool) > 0, as_tuple=False).squeeze(-1).unique()\n        neg_inds = torch.nonzero(anchors.new_zeros((anchors.shape[0],), dtype=torch.bool) == 0, as_tuple=False).squeeze(-1).unique()\n    if gt_labels is not None:\n        labels += num_classes\n    if len(pos_inds) > 0:\n        pos_bbox_targets = self.bbox_coder.encode(sampling_result.pos_bboxes, sampling_result.pos_gt_bboxes)\n        pos_dir_targets = get_direction_target(sampling_result.pos_bboxes, pos_bbox_targets, self.dir_offset, self.dir_limit_offset, one_hot=False)\n        bbox_targets[pos_inds, :] = pos_bbox_targets\n        bbox_weights[pos_inds, :] = 1.0\n        dir_targets[pos_inds] = pos_dir_targets\n        dir_weights[pos_inds] = 1.0\n        if gt_labels is None:\n            labels[pos_inds] = 1\n        else:\n            labels[pos_inds] = gt_labels[sampling_result.pos_assigned_gt_inds]\n        if self.train_cfg.pos_weight <= 0:\n            label_weights[pos_inds] = 1.0\n        else:\n            label_weights[pos_inds] = self.train_cfg.pos_weight\n    if len(neg_inds) > 0:\n        label_weights[neg_inds] = 1.0\n    return (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds)",
            "def anchor_target_single_assigner(self, bbox_assigner, anchors, gt_bboxes, gt_bboxes_ignore, gt_labels, input_meta, num_classes=1, sampling=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Assign anchors and encode positive anchors.\\n\\n        Args:\\n            bbox_assigner (BaseAssigner): assign positive and negative boxes.\\n            anchors (torch.Tensor): Concatenated multi-level anchor.\\n            gt_bboxes (:obj:`BaseInstance3DBoxes`): Gt bboxes.\\n            gt_bboxes_ignore (torch.Tensor): Ignored gt bboxes.\\n            gt_labels (torch.Tensor): Gt class labels.\\n            input_meta (dict): Meta info of each image.\\n            num_classes (int): The number of classes.\\n            sampling (bool): Whether to sample anchors.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Anchor targets.\\n        '\n    anchors = anchors.reshape(-1, anchors.size(-1))\n    num_valid_anchors = anchors.shape[0]\n    bbox_targets = torch.zeros_like(anchors)\n    bbox_weights = torch.zeros_like(anchors)\n    dir_targets = anchors.new_zeros(anchors.shape[0], dtype=torch.long)\n    dir_weights = anchors.new_zeros(anchors.shape[0], dtype=torch.float)\n    labels = anchors.new_zeros(num_valid_anchors, dtype=torch.long)\n    label_weights = anchors.new_zeros(num_valid_anchors, dtype=torch.float)\n    if len(gt_bboxes) > 0:\n        if not isinstance(gt_bboxes, torch.Tensor):\n            gt_bboxes = gt_bboxes.tensor.to(anchors.device)\n        assign_result = bbox_assigner.assign(anchors, gt_bboxes, gt_bboxes_ignore, gt_labels)\n        sampling_result = self.bbox_sampler.sample(assign_result, anchors, gt_bboxes)\n        pos_inds = sampling_result.pos_inds\n        neg_inds = sampling_result.neg_inds\n    else:\n        pos_inds = torch.nonzero(anchors.new_zeros((anchors.shape[0],), dtype=torch.bool) > 0, as_tuple=False).squeeze(-1).unique()\n        neg_inds = torch.nonzero(anchors.new_zeros((anchors.shape[0],), dtype=torch.bool) == 0, as_tuple=False).squeeze(-1).unique()\n    if gt_labels is not None:\n        labels += num_classes\n    if len(pos_inds) > 0:\n        pos_bbox_targets = self.bbox_coder.encode(sampling_result.pos_bboxes, sampling_result.pos_gt_bboxes)\n        pos_dir_targets = get_direction_target(sampling_result.pos_bboxes, pos_bbox_targets, self.dir_offset, self.dir_limit_offset, one_hot=False)\n        bbox_targets[pos_inds, :] = pos_bbox_targets\n        bbox_weights[pos_inds, :] = 1.0\n        dir_targets[pos_inds] = pos_dir_targets\n        dir_weights[pos_inds] = 1.0\n        if gt_labels is None:\n            labels[pos_inds] = 1\n        else:\n            labels[pos_inds] = gt_labels[sampling_result.pos_assigned_gt_inds]\n        if self.train_cfg.pos_weight <= 0:\n            label_weights[pos_inds] = 1.0\n        else:\n            label_weights[pos_inds] = self.train_cfg.pos_weight\n    if len(neg_inds) > 0:\n        label_weights[neg_inds] = 1.0\n    return (labels, label_weights, bbox_targets, bbox_weights, dir_targets, dir_weights, pos_inds, neg_inds)"
        ]
    },
    {
        "func_name": "get_direction_target",
        "original": "def get_direction_target(anchors, reg_targets, dir_offset=0, dir_limit_offset=0, num_bins=2, one_hot=True):\n    \"\"\"Encode direction to 0 ~ num_bins-1.\n\n    Args:\n        anchors (torch.Tensor): Concatenated multi-level anchor.\n        reg_targets (torch.Tensor): Bbox regression targets.\n        dir_offset (int): Direction offset.\n        num_bins (int): Number of bins to divide 2*PI.\n        one_hot (bool): Whether to encode as one hot.\n\n    Returns:\n        torch.Tensor: Encoded direction targets.\n    \"\"\"\n    rot_gt = reg_targets[..., 6] + anchors[..., 6]\n    offset_rot = limit_period(rot_gt - dir_offset, dir_limit_offset, 2 * np.pi)\n    dir_cls_targets = torch.floor(offset_rot / (2 * np.pi / num_bins)).long()\n    dir_cls_targets = torch.clamp(dir_cls_targets, min=0, max=num_bins - 1)\n    if one_hot:\n        dir_targets = torch.zeros(*list(dir_cls_targets.shape), num_bins, dtype=anchors.dtype, device=dir_cls_targets.device)\n        dir_targets.scatter_(dir_cls_targets.unsqueeze(dim=-1).long(), 1.0)\n        dir_cls_targets = dir_targets\n    return dir_cls_targets",
        "mutated": [
            "def get_direction_target(anchors, reg_targets, dir_offset=0, dir_limit_offset=0, num_bins=2, one_hot=True):\n    if False:\n        i = 10\n    'Encode direction to 0 ~ num_bins-1.\\n\\n    Args:\\n        anchors (torch.Tensor): Concatenated multi-level anchor.\\n        reg_targets (torch.Tensor): Bbox regression targets.\\n        dir_offset (int): Direction offset.\\n        num_bins (int): Number of bins to divide 2*PI.\\n        one_hot (bool): Whether to encode as one hot.\\n\\n    Returns:\\n        torch.Tensor: Encoded direction targets.\\n    '\n    rot_gt = reg_targets[..., 6] + anchors[..., 6]\n    offset_rot = limit_period(rot_gt - dir_offset, dir_limit_offset, 2 * np.pi)\n    dir_cls_targets = torch.floor(offset_rot / (2 * np.pi / num_bins)).long()\n    dir_cls_targets = torch.clamp(dir_cls_targets, min=0, max=num_bins - 1)\n    if one_hot:\n        dir_targets = torch.zeros(*list(dir_cls_targets.shape), num_bins, dtype=anchors.dtype, device=dir_cls_targets.device)\n        dir_targets.scatter_(dir_cls_targets.unsqueeze(dim=-1).long(), 1.0)\n        dir_cls_targets = dir_targets\n    return dir_cls_targets",
            "def get_direction_target(anchors, reg_targets, dir_offset=0, dir_limit_offset=0, num_bins=2, one_hot=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Encode direction to 0 ~ num_bins-1.\\n\\n    Args:\\n        anchors (torch.Tensor): Concatenated multi-level anchor.\\n        reg_targets (torch.Tensor): Bbox regression targets.\\n        dir_offset (int): Direction offset.\\n        num_bins (int): Number of bins to divide 2*PI.\\n        one_hot (bool): Whether to encode as one hot.\\n\\n    Returns:\\n        torch.Tensor: Encoded direction targets.\\n    '\n    rot_gt = reg_targets[..., 6] + anchors[..., 6]\n    offset_rot = limit_period(rot_gt - dir_offset, dir_limit_offset, 2 * np.pi)\n    dir_cls_targets = torch.floor(offset_rot / (2 * np.pi / num_bins)).long()\n    dir_cls_targets = torch.clamp(dir_cls_targets, min=0, max=num_bins - 1)\n    if one_hot:\n        dir_targets = torch.zeros(*list(dir_cls_targets.shape), num_bins, dtype=anchors.dtype, device=dir_cls_targets.device)\n        dir_targets.scatter_(dir_cls_targets.unsqueeze(dim=-1).long(), 1.0)\n        dir_cls_targets = dir_targets\n    return dir_cls_targets",
            "def get_direction_target(anchors, reg_targets, dir_offset=0, dir_limit_offset=0, num_bins=2, one_hot=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Encode direction to 0 ~ num_bins-1.\\n\\n    Args:\\n        anchors (torch.Tensor): Concatenated multi-level anchor.\\n        reg_targets (torch.Tensor): Bbox regression targets.\\n        dir_offset (int): Direction offset.\\n        num_bins (int): Number of bins to divide 2*PI.\\n        one_hot (bool): Whether to encode as one hot.\\n\\n    Returns:\\n        torch.Tensor: Encoded direction targets.\\n    '\n    rot_gt = reg_targets[..., 6] + anchors[..., 6]\n    offset_rot = limit_period(rot_gt - dir_offset, dir_limit_offset, 2 * np.pi)\n    dir_cls_targets = torch.floor(offset_rot / (2 * np.pi / num_bins)).long()\n    dir_cls_targets = torch.clamp(dir_cls_targets, min=0, max=num_bins - 1)\n    if one_hot:\n        dir_targets = torch.zeros(*list(dir_cls_targets.shape), num_bins, dtype=anchors.dtype, device=dir_cls_targets.device)\n        dir_targets.scatter_(dir_cls_targets.unsqueeze(dim=-1).long(), 1.0)\n        dir_cls_targets = dir_targets\n    return dir_cls_targets",
            "def get_direction_target(anchors, reg_targets, dir_offset=0, dir_limit_offset=0, num_bins=2, one_hot=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Encode direction to 0 ~ num_bins-1.\\n\\n    Args:\\n        anchors (torch.Tensor): Concatenated multi-level anchor.\\n        reg_targets (torch.Tensor): Bbox regression targets.\\n        dir_offset (int): Direction offset.\\n        num_bins (int): Number of bins to divide 2*PI.\\n        one_hot (bool): Whether to encode as one hot.\\n\\n    Returns:\\n        torch.Tensor: Encoded direction targets.\\n    '\n    rot_gt = reg_targets[..., 6] + anchors[..., 6]\n    offset_rot = limit_period(rot_gt - dir_offset, dir_limit_offset, 2 * np.pi)\n    dir_cls_targets = torch.floor(offset_rot / (2 * np.pi / num_bins)).long()\n    dir_cls_targets = torch.clamp(dir_cls_targets, min=0, max=num_bins - 1)\n    if one_hot:\n        dir_targets = torch.zeros(*list(dir_cls_targets.shape), num_bins, dtype=anchors.dtype, device=dir_cls_targets.device)\n        dir_targets.scatter_(dir_cls_targets.unsqueeze(dim=-1).long(), 1.0)\n        dir_cls_targets = dir_targets\n    return dir_cls_targets",
            "def get_direction_target(anchors, reg_targets, dir_offset=0, dir_limit_offset=0, num_bins=2, one_hot=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Encode direction to 0 ~ num_bins-1.\\n\\n    Args:\\n        anchors (torch.Tensor): Concatenated multi-level anchor.\\n        reg_targets (torch.Tensor): Bbox regression targets.\\n        dir_offset (int): Direction offset.\\n        num_bins (int): Number of bins to divide 2*PI.\\n        one_hot (bool): Whether to encode as one hot.\\n\\n    Returns:\\n        torch.Tensor: Encoded direction targets.\\n    '\n    rot_gt = reg_targets[..., 6] + anchors[..., 6]\n    offset_rot = limit_period(rot_gt - dir_offset, dir_limit_offset, 2 * np.pi)\n    dir_cls_targets = torch.floor(offset_rot / (2 * np.pi / num_bins)).long()\n    dir_cls_targets = torch.clamp(dir_cls_targets, min=0, max=num_bins - 1)\n    if one_hot:\n        dir_targets = torch.zeros(*list(dir_cls_targets.shape), num_bins, dtype=anchors.dtype, device=dir_cls_targets.device)\n        dir_targets.scatter_(dir_cls_targets.unsqueeze(dim=-1).long(), 1.0)\n        dir_cls_targets = dir_targets\n    return dir_cls_targets"
        ]
    }
]