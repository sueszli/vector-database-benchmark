[
    {
        "func_name": "upgrade",
        "original": "def upgrade():\n    \"\"\"Apply Change ``TaskInstance`` and ``TaskReschedule`` tables from execution_date to run_id.\"\"\"\n    conn = op.get_bind()\n    dialect_name = conn.dialect.name\n    dt_type = TIMESTAMP\n    string_id_col_type = StringID()\n    if dialect_name == 'sqlite':\n        naming_convention = {'uq': '%(table_name)s_%(column_0_N_name)s_key'}\n        with op.batch_alter_table('dag_run', naming_convention=naming_convention, recreate='always') as batch_op:\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n    elif dialect_name == 'mysql':\n        with op.batch_alter_table('dag_run') as batch_op:\n            batch_op.alter_column('dag_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            inspector = sa.inspect(conn.engine)\n            unique_keys = inspector.get_unique_constraints('dag_run')\n            for unique_key in unique_keys:\n                batch_op.drop_constraint(unique_key['name'], type_='unique')\n            batch_op.create_unique_constraint('dag_run_dag_id_execution_date_key', ['dag_id', 'execution_date'])\n            batch_op.create_unique_constraint('dag_run_dag_id_run_id_key', ['dag_id', 'run_id'])\n    elif dialect_name == 'mssql':\n        with op.batch_alter_table('dag_run') as batch_op:\n            batch_op.drop_index('idx_not_null_dag_id_execution_date')\n            batch_op.drop_index('idx_not_null_dag_id_run_id')\n            batch_op.drop_index('dag_id_state')\n            batch_op.drop_index('idx_dag_run_dag_id')\n            batch_op.drop_index('idx_dag_run_running_dags')\n            batch_op.drop_index('idx_dag_run_queued_dags')\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.create_unique_constraint('dag_run_dag_id_execution_date_key', ['dag_id', 'execution_date'])\n            batch_op.create_unique_constraint('dag_run_dag_id_run_id_key', ['dag_id', 'run_id'])\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)\n            batch_op.create_index('idx_dag_run_dag_id', ['dag_id'])\n            batch_op.create_index('idx_dag_run_running_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='running'\"))\n            batch_op.create_index('idx_dag_run_queued_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='queued'\"))\n    else:\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n    op.add_column('task_instance', sa.Column('run_id', type_=string_id_col_type, nullable=True))\n    op.add_column('task_reschedule', sa.Column('run_id', type_=string_id_col_type, nullable=True))\n    update_query = _multi_table_update(dialect_name, task_reschedule, task_reschedule.c.run_id)\n    op.execute(update_query)\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.alter_column('run_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.drop_constraint('task_reschedule_dag_task_date_fkey', type_='foreignkey')\n        if dialect_name == 'mysql':\n            batch_op.drop_index('task_reschedule_dag_task_date_fkey')\n            batch_op.alter_column('dag_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n        batch_op.drop_index('idx_task_reschedule_dag_task_date')\n    if dialect_name == 'postgresql':\n        op.execute('\\n            CREATE TABLE new_task_instance AS SELECT\\n                ti.task_id,\\n                ti.dag_id,\\n                dag_run.run_id,\\n                ti.start_date,\\n                ti.end_date,\\n                ti.duration,\\n                ti.state,\\n                ti.try_number,\\n                ti.hostname,\\n                ti.unixname,\\n                ti.job_id,\\n                ti.pool,\\n                ti.queue,\\n                ti.priority_weight,\\n                ti.operator,\\n                ti.queued_dttm,\\n                ti.pid,\\n                ti.max_tries,\\n                ti.executor_config,\\n                ti.pool_slots,\\n                ti.queued_by_job_id,\\n                ti.external_executor_id,\\n                ti.trigger_id,\\n                ti.trigger_timeout,\\n                ti.next_method,\\n                ti.next_kwargs\\n            FROM task_instance ti\\n            INNER JOIN dag_run ON dag_run.dag_id = ti.dag_id AND dag_run.execution_date = ti.execution_date;\\n        ')\n        op.drop_table('task_instance')\n        op.rename_table('new_task_instance', 'task_instance')\n        with op.batch_alter_table('task_instance', schema=None) as batch_op:\n            batch_op.alter_column('pool', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n            batch_op.alter_column('max_tries', existing_type=sa.Integer(), server_default='-1')\n            batch_op.alter_column('pool_slots', existing_type=sa.Integer(), existing_nullable=True, nullable=False)\n    else:\n        update_query = _multi_table_update(dialect_name, task_instance, task_instance.c.run_id)\n        op.execute(update_query)\n    with op.batch_alter_table('task_instance', schema=None) as batch_op:\n        if dialect_name != 'postgresql':\n            if dialect_name == 'mssql':\n                constraints = get_mssql_table_constraints(conn, 'task_instance')\n                (pk, _) = constraints['PRIMARY KEY'].popitem()\n                batch_op.drop_constraint(pk, type_='primary')\n            elif dialect_name not in 'sqlite':\n                batch_op.drop_constraint('task_instance_pkey', type_='primary')\n            batch_op.drop_index('ti_dag_date')\n            batch_op.drop_index('ti_state_lkp')\n            batch_op.drop_column('execution_date')\n        batch_op.alter_column('run_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.alter_column('dag_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.create_primary_key('task_instance_pkey', ['dag_id', 'task_id', 'run_id'])\n        batch_op.create_foreign_key('task_instance_dag_run_fkey', 'dag_run', ['dag_id', 'run_id'], ['dag_id', 'run_id'], ondelete='CASCADE')\n        batch_op.create_index('ti_dag_run', ['dag_id', 'run_id'])\n        batch_op.create_index('ti_state_lkp', ['dag_id', 'task_id', 'run_id', 'state'])\n        if dialect_name == 'postgresql':\n            batch_op.create_index('ti_dag_state', ['dag_id', 'state'])\n            batch_op.create_index('ti_job_id', ['job_id'])\n            batch_op.create_index('ti_pool', ['pool', 'state', 'priority_weight'])\n            batch_op.create_index('ti_state', ['state'])\n            batch_op.create_foreign_key('task_instance_trigger_id_fkey', 'trigger', ['trigger_id'], ['id'], ondelete='CASCADE')\n            batch_op.create_index('ti_trigger_id', ['trigger_id'])\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.drop_column('execution_date')\n        batch_op.create_index('idx_task_reschedule_dag_task_run', ['dag_id', 'task_id', 'run_id'], unique=False)\n        batch_op.create_foreign_key('task_reschedule_ti_fkey', 'task_instance', ['dag_id', 'task_id', 'run_id'], ['dag_id', 'task_id', 'run_id'], ondelete='CASCADE')\n        ondelete = 'CASCADE' if dialect_name != 'mssql' else 'NO ACTION'\n        batch_op.create_foreign_key('task_reschedule_dr_fkey', 'dag_run', ['dag_id', 'run_id'], ['dag_id', 'run_id'], ondelete=ondelete)",
        "mutated": [
            "def upgrade():\n    if False:\n        i = 10\n    'Apply Change ``TaskInstance`` and ``TaskReschedule`` tables from execution_date to run_id.'\n    conn = op.get_bind()\n    dialect_name = conn.dialect.name\n    dt_type = TIMESTAMP\n    string_id_col_type = StringID()\n    if dialect_name == 'sqlite':\n        naming_convention = {'uq': '%(table_name)s_%(column_0_N_name)s_key'}\n        with op.batch_alter_table('dag_run', naming_convention=naming_convention, recreate='always') as batch_op:\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n    elif dialect_name == 'mysql':\n        with op.batch_alter_table('dag_run') as batch_op:\n            batch_op.alter_column('dag_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            inspector = sa.inspect(conn.engine)\n            unique_keys = inspector.get_unique_constraints('dag_run')\n            for unique_key in unique_keys:\n                batch_op.drop_constraint(unique_key['name'], type_='unique')\n            batch_op.create_unique_constraint('dag_run_dag_id_execution_date_key', ['dag_id', 'execution_date'])\n            batch_op.create_unique_constraint('dag_run_dag_id_run_id_key', ['dag_id', 'run_id'])\n    elif dialect_name == 'mssql':\n        with op.batch_alter_table('dag_run') as batch_op:\n            batch_op.drop_index('idx_not_null_dag_id_execution_date')\n            batch_op.drop_index('idx_not_null_dag_id_run_id')\n            batch_op.drop_index('dag_id_state')\n            batch_op.drop_index('idx_dag_run_dag_id')\n            batch_op.drop_index('idx_dag_run_running_dags')\n            batch_op.drop_index('idx_dag_run_queued_dags')\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.create_unique_constraint('dag_run_dag_id_execution_date_key', ['dag_id', 'execution_date'])\n            batch_op.create_unique_constraint('dag_run_dag_id_run_id_key', ['dag_id', 'run_id'])\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)\n            batch_op.create_index('idx_dag_run_dag_id', ['dag_id'])\n            batch_op.create_index('idx_dag_run_running_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='running'\"))\n            batch_op.create_index('idx_dag_run_queued_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='queued'\"))\n    else:\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n    op.add_column('task_instance', sa.Column('run_id', type_=string_id_col_type, nullable=True))\n    op.add_column('task_reschedule', sa.Column('run_id', type_=string_id_col_type, nullable=True))\n    update_query = _multi_table_update(dialect_name, task_reschedule, task_reschedule.c.run_id)\n    op.execute(update_query)\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.alter_column('run_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.drop_constraint('task_reschedule_dag_task_date_fkey', type_='foreignkey')\n        if dialect_name == 'mysql':\n            batch_op.drop_index('task_reschedule_dag_task_date_fkey')\n            batch_op.alter_column('dag_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n        batch_op.drop_index('idx_task_reschedule_dag_task_date')\n    if dialect_name == 'postgresql':\n        op.execute('\\n            CREATE TABLE new_task_instance AS SELECT\\n                ti.task_id,\\n                ti.dag_id,\\n                dag_run.run_id,\\n                ti.start_date,\\n                ti.end_date,\\n                ti.duration,\\n                ti.state,\\n                ti.try_number,\\n                ti.hostname,\\n                ti.unixname,\\n                ti.job_id,\\n                ti.pool,\\n                ti.queue,\\n                ti.priority_weight,\\n                ti.operator,\\n                ti.queued_dttm,\\n                ti.pid,\\n                ti.max_tries,\\n                ti.executor_config,\\n                ti.pool_slots,\\n                ti.queued_by_job_id,\\n                ti.external_executor_id,\\n                ti.trigger_id,\\n                ti.trigger_timeout,\\n                ti.next_method,\\n                ti.next_kwargs\\n            FROM task_instance ti\\n            INNER JOIN dag_run ON dag_run.dag_id = ti.dag_id AND dag_run.execution_date = ti.execution_date;\\n        ')\n        op.drop_table('task_instance')\n        op.rename_table('new_task_instance', 'task_instance')\n        with op.batch_alter_table('task_instance', schema=None) as batch_op:\n            batch_op.alter_column('pool', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n            batch_op.alter_column('max_tries', existing_type=sa.Integer(), server_default='-1')\n            batch_op.alter_column('pool_slots', existing_type=sa.Integer(), existing_nullable=True, nullable=False)\n    else:\n        update_query = _multi_table_update(dialect_name, task_instance, task_instance.c.run_id)\n        op.execute(update_query)\n    with op.batch_alter_table('task_instance', schema=None) as batch_op:\n        if dialect_name != 'postgresql':\n            if dialect_name == 'mssql':\n                constraints = get_mssql_table_constraints(conn, 'task_instance')\n                (pk, _) = constraints['PRIMARY KEY'].popitem()\n                batch_op.drop_constraint(pk, type_='primary')\n            elif dialect_name not in 'sqlite':\n                batch_op.drop_constraint('task_instance_pkey', type_='primary')\n            batch_op.drop_index('ti_dag_date')\n            batch_op.drop_index('ti_state_lkp')\n            batch_op.drop_column('execution_date')\n        batch_op.alter_column('run_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.alter_column('dag_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.create_primary_key('task_instance_pkey', ['dag_id', 'task_id', 'run_id'])\n        batch_op.create_foreign_key('task_instance_dag_run_fkey', 'dag_run', ['dag_id', 'run_id'], ['dag_id', 'run_id'], ondelete='CASCADE')\n        batch_op.create_index('ti_dag_run', ['dag_id', 'run_id'])\n        batch_op.create_index('ti_state_lkp', ['dag_id', 'task_id', 'run_id', 'state'])\n        if dialect_name == 'postgresql':\n            batch_op.create_index('ti_dag_state', ['dag_id', 'state'])\n            batch_op.create_index('ti_job_id', ['job_id'])\n            batch_op.create_index('ti_pool', ['pool', 'state', 'priority_weight'])\n            batch_op.create_index('ti_state', ['state'])\n            batch_op.create_foreign_key('task_instance_trigger_id_fkey', 'trigger', ['trigger_id'], ['id'], ondelete='CASCADE')\n            batch_op.create_index('ti_trigger_id', ['trigger_id'])\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.drop_column('execution_date')\n        batch_op.create_index('idx_task_reschedule_dag_task_run', ['dag_id', 'task_id', 'run_id'], unique=False)\n        batch_op.create_foreign_key('task_reschedule_ti_fkey', 'task_instance', ['dag_id', 'task_id', 'run_id'], ['dag_id', 'task_id', 'run_id'], ondelete='CASCADE')\n        ondelete = 'CASCADE' if dialect_name != 'mssql' else 'NO ACTION'\n        batch_op.create_foreign_key('task_reschedule_dr_fkey', 'dag_run', ['dag_id', 'run_id'], ['dag_id', 'run_id'], ondelete=ondelete)",
            "def upgrade():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Apply Change ``TaskInstance`` and ``TaskReschedule`` tables from execution_date to run_id.'\n    conn = op.get_bind()\n    dialect_name = conn.dialect.name\n    dt_type = TIMESTAMP\n    string_id_col_type = StringID()\n    if dialect_name == 'sqlite':\n        naming_convention = {'uq': '%(table_name)s_%(column_0_N_name)s_key'}\n        with op.batch_alter_table('dag_run', naming_convention=naming_convention, recreate='always') as batch_op:\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n    elif dialect_name == 'mysql':\n        with op.batch_alter_table('dag_run') as batch_op:\n            batch_op.alter_column('dag_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            inspector = sa.inspect(conn.engine)\n            unique_keys = inspector.get_unique_constraints('dag_run')\n            for unique_key in unique_keys:\n                batch_op.drop_constraint(unique_key['name'], type_='unique')\n            batch_op.create_unique_constraint('dag_run_dag_id_execution_date_key', ['dag_id', 'execution_date'])\n            batch_op.create_unique_constraint('dag_run_dag_id_run_id_key', ['dag_id', 'run_id'])\n    elif dialect_name == 'mssql':\n        with op.batch_alter_table('dag_run') as batch_op:\n            batch_op.drop_index('idx_not_null_dag_id_execution_date')\n            batch_op.drop_index('idx_not_null_dag_id_run_id')\n            batch_op.drop_index('dag_id_state')\n            batch_op.drop_index('idx_dag_run_dag_id')\n            batch_op.drop_index('idx_dag_run_running_dags')\n            batch_op.drop_index('idx_dag_run_queued_dags')\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.create_unique_constraint('dag_run_dag_id_execution_date_key', ['dag_id', 'execution_date'])\n            batch_op.create_unique_constraint('dag_run_dag_id_run_id_key', ['dag_id', 'run_id'])\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)\n            batch_op.create_index('idx_dag_run_dag_id', ['dag_id'])\n            batch_op.create_index('idx_dag_run_running_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='running'\"))\n            batch_op.create_index('idx_dag_run_queued_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='queued'\"))\n    else:\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n    op.add_column('task_instance', sa.Column('run_id', type_=string_id_col_type, nullable=True))\n    op.add_column('task_reschedule', sa.Column('run_id', type_=string_id_col_type, nullable=True))\n    update_query = _multi_table_update(dialect_name, task_reschedule, task_reschedule.c.run_id)\n    op.execute(update_query)\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.alter_column('run_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.drop_constraint('task_reschedule_dag_task_date_fkey', type_='foreignkey')\n        if dialect_name == 'mysql':\n            batch_op.drop_index('task_reschedule_dag_task_date_fkey')\n            batch_op.alter_column('dag_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n        batch_op.drop_index('idx_task_reschedule_dag_task_date')\n    if dialect_name == 'postgresql':\n        op.execute('\\n            CREATE TABLE new_task_instance AS SELECT\\n                ti.task_id,\\n                ti.dag_id,\\n                dag_run.run_id,\\n                ti.start_date,\\n                ti.end_date,\\n                ti.duration,\\n                ti.state,\\n                ti.try_number,\\n                ti.hostname,\\n                ti.unixname,\\n                ti.job_id,\\n                ti.pool,\\n                ti.queue,\\n                ti.priority_weight,\\n                ti.operator,\\n                ti.queued_dttm,\\n                ti.pid,\\n                ti.max_tries,\\n                ti.executor_config,\\n                ti.pool_slots,\\n                ti.queued_by_job_id,\\n                ti.external_executor_id,\\n                ti.trigger_id,\\n                ti.trigger_timeout,\\n                ti.next_method,\\n                ti.next_kwargs\\n            FROM task_instance ti\\n            INNER JOIN dag_run ON dag_run.dag_id = ti.dag_id AND dag_run.execution_date = ti.execution_date;\\n        ')\n        op.drop_table('task_instance')\n        op.rename_table('new_task_instance', 'task_instance')\n        with op.batch_alter_table('task_instance', schema=None) as batch_op:\n            batch_op.alter_column('pool', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n            batch_op.alter_column('max_tries', existing_type=sa.Integer(), server_default='-1')\n            batch_op.alter_column('pool_slots', existing_type=sa.Integer(), existing_nullable=True, nullable=False)\n    else:\n        update_query = _multi_table_update(dialect_name, task_instance, task_instance.c.run_id)\n        op.execute(update_query)\n    with op.batch_alter_table('task_instance', schema=None) as batch_op:\n        if dialect_name != 'postgresql':\n            if dialect_name == 'mssql':\n                constraints = get_mssql_table_constraints(conn, 'task_instance')\n                (pk, _) = constraints['PRIMARY KEY'].popitem()\n                batch_op.drop_constraint(pk, type_='primary')\n            elif dialect_name not in 'sqlite':\n                batch_op.drop_constraint('task_instance_pkey', type_='primary')\n            batch_op.drop_index('ti_dag_date')\n            batch_op.drop_index('ti_state_lkp')\n            batch_op.drop_column('execution_date')\n        batch_op.alter_column('run_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.alter_column('dag_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.create_primary_key('task_instance_pkey', ['dag_id', 'task_id', 'run_id'])\n        batch_op.create_foreign_key('task_instance_dag_run_fkey', 'dag_run', ['dag_id', 'run_id'], ['dag_id', 'run_id'], ondelete='CASCADE')\n        batch_op.create_index('ti_dag_run', ['dag_id', 'run_id'])\n        batch_op.create_index('ti_state_lkp', ['dag_id', 'task_id', 'run_id', 'state'])\n        if dialect_name == 'postgresql':\n            batch_op.create_index('ti_dag_state', ['dag_id', 'state'])\n            batch_op.create_index('ti_job_id', ['job_id'])\n            batch_op.create_index('ti_pool', ['pool', 'state', 'priority_weight'])\n            batch_op.create_index('ti_state', ['state'])\n            batch_op.create_foreign_key('task_instance_trigger_id_fkey', 'trigger', ['trigger_id'], ['id'], ondelete='CASCADE')\n            batch_op.create_index('ti_trigger_id', ['trigger_id'])\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.drop_column('execution_date')\n        batch_op.create_index('idx_task_reschedule_dag_task_run', ['dag_id', 'task_id', 'run_id'], unique=False)\n        batch_op.create_foreign_key('task_reschedule_ti_fkey', 'task_instance', ['dag_id', 'task_id', 'run_id'], ['dag_id', 'task_id', 'run_id'], ondelete='CASCADE')\n        ondelete = 'CASCADE' if dialect_name != 'mssql' else 'NO ACTION'\n        batch_op.create_foreign_key('task_reschedule_dr_fkey', 'dag_run', ['dag_id', 'run_id'], ['dag_id', 'run_id'], ondelete=ondelete)",
            "def upgrade():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Apply Change ``TaskInstance`` and ``TaskReschedule`` tables from execution_date to run_id.'\n    conn = op.get_bind()\n    dialect_name = conn.dialect.name\n    dt_type = TIMESTAMP\n    string_id_col_type = StringID()\n    if dialect_name == 'sqlite':\n        naming_convention = {'uq': '%(table_name)s_%(column_0_N_name)s_key'}\n        with op.batch_alter_table('dag_run', naming_convention=naming_convention, recreate='always') as batch_op:\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n    elif dialect_name == 'mysql':\n        with op.batch_alter_table('dag_run') as batch_op:\n            batch_op.alter_column('dag_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            inspector = sa.inspect(conn.engine)\n            unique_keys = inspector.get_unique_constraints('dag_run')\n            for unique_key in unique_keys:\n                batch_op.drop_constraint(unique_key['name'], type_='unique')\n            batch_op.create_unique_constraint('dag_run_dag_id_execution_date_key', ['dag_id', 'execution_date'])\n            batch_op.create_unique_constraint('dag_run_dag_id_run_id_key', ['dag_id', 'run_id'])\n    elif dialect_name == 'mssql':\n        with op.batch_alter_table('dag_run') as batch_op:\n            batch_op.drop_index('idx_not_null_dag_id_execution_date')\n            batch_op.drop_index('idx_not_null_dag_id_run_id')\n            batch_op.drop_index('dag_id_state')\n            batch_op.drop_index('idx_dag_run_dag_id')\n            batch_op.drop_index('idx_dag_run_running_dags')\n            batch_op.drop_index('idx_dag_run_queued_dags')\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.create_unique_constraint('dag_run_dag_id_execution_date_key', ['dag_id', 'execution_date'])\n            batch_op.create_unique_constraint('dag_run_dag_id_run_id_key', ['dag_id', 'run_id'])\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)\n            batch_op.create_index('idx_dag_run_dag_id', ['dag_id'])\n            batch_op.create_index('idx_dag_run_running_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='running'\"))\n            batch_op.create_index('idx_dag_run_queued_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='queued'\"))\n    else:\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n    op.add_column('task_instance', sa.Column('run_id', type_=string_id_col_type, nullable=True))\n    op.add_column('task_reschedule', sa.Column('run_id', type_=string_id_col_type, nullable=True))\n    update_query = _multi_table_update(dialect_name, task_reschedule, task_reschedule.c.run_id)\n    op.execute(update_query)\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.alter_column('run_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.drop_constraint('task_reschedule_dag_task_date_fkey', type_='foreignkey')\n        if dialect_name == 'mysql':\n            batch_op.drop_index('task_reschedule_dag_task_date_fkey')\n            batch_op.alter_column('dag_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n        batch_op.drop_index('idx_task_reschedule_dag_task_date')\n    if dialect_name == 'postgresql':\n        op.execute('\\n            CREATE TABLE new_task_instance AS SELECT\\n                ti.task_id,\\n                ti.dag_id,\\n                dag_run.run_id,\\n                ti.start_date,\\n                ti.end_date,\\n                ti.duration,\\n                ti.state,\\n                ti.try_number,\\n                ti.hostname,\\n                ti.unixname,\\n                ti.job_id,\\n                ti.pool,\\n                ti.queue,\\n                ti.priority_weight,\\n                ti.operator,\\n                ti.queued_dttm,\\n                ti.pid,\\n                ti.max_tries,\\n                ti.executor_config,\\n                ti.pool_slots,\\n                ti.queued_by_job_id,\\n                ti.external_executor_id,\\n                ti.trigger_id,\\n                ti.trigger_timeout,\\n                ti.next_method,\\n                ti.next_kwargs\\n            FROM task_instance ti\\n            INNER JOIN dag_run ON dag_run.dag_id = ti.dag_id AND dag_run.execution_date = ti.execution_date;\\n        ')\n        op.drop_table('task_instance')\n        op.rename_table('new_task_instance', 'task_instance')\n        with op.batch_alter_table('task_instance', schema=None) as batch_op:\n            batch_op.alter_column('pool', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n            batch_op.alter_column('max_tries', existing_type=sa.Integer(), server_default='-1')\n            batch_op.alter_column('pool_slots', existing_type=sa.Integer(), existing_nullable=True, nullable=False)\n    else:\n        update_query = _multi_table_update(dialect_name, task_instance, task_instance.c.run_id)\n        op.execute(update_query)\n    with op.batch_alter_table('task_instance', schema=None) as batch_op:\n        if dialect_name != 'postgresql':\n            if dialect_name == 'mssql':\n                constraints = get_mssql_table_constraints(conn, 'task_instance')\n                (pk, _) = constraints['PRIMARY KEY'].popitem()\n                batch_op.drop_constraint(pk, type_='primary')\n            elif dialect_name not in 'sqlite':\n                batch_op.drop_constraint('task_instance_pkey', type_='primary')\n            batch_op.drop_index('ti_dag_date')\n            batch_op.drop_index('ti_state_lkp')\n            batch_op.drop_column('execution_date')\n        batch_op.alter_column('run_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.alter_column('dag_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.create_primary_key('task_instance_pkey', ['dag_id', 'task_id', 'run_id'])\n        batch_op.create_foreign_key('task_instance_dag_run_fkey', 'dag_run', ['dag_id', 'run_id'], ['dag_id', 'run_id'], ondelete='CASCADE')\n        batch_op.create_index('ti_dag_run', ['dag_id', 'run_id'])\n        batch_op.create_index('ti_state_lkp', ['dag_id', 'task_id', 'run_id', 'state'])\n        if dialect_name == 'postgresql':\n            batch_op.create_index('ti_dag_state', ['dag_id', 'state'])\n            batch_op.create_index('ti_job_id', ['job_id'])\n            batch_op.create_index('ti_pool', ['pool', 'state', 'priority_weight'])\n            batch_op.create_index('ti_state', ['state'])\n            batch_op.create_foreign_key('task_instance_trigger_id_fkey', 'trigger', ['trigger_id'], ['id'], ondelete='CASCADE')\n            batch_op.create_index('ti_trigger_id', ['trigger_id'])\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.drop_column('execution_date')\n        batch_op.create_index('idx_task_reschedule_dag_task_run', ['dag_id', 'task_id', 'run_id'], unique=False)\n        batch_op.create_foreign_key('task_reschedule_ti_fkey', 'task_instance', ['dag_id', 'task_id', 'run_id'], ['dag_id', 'task_id', 'run_id'], ondelete='CASCADE')\n        ondelete = 'CASCADE' if dialect_name != 'mssql' else 'NO ACTION'\n        batch_op.create_foreign_key('task_reschedule_dr_fkey', 'dag_run', ['dag_id', 'run_id'], ['dag_id', 'run_id'], ondelete=ondelete)",
            "def upgrade():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Apply Change ``TaskInstance`` and ``TaskReschedule`` tables from execution_date to run_id.'\n    conn = op.get_bind()\n    dialect_name = conn.dialect.name\n    dt_type = TIMESTAMP\n    string_id_col_type = StringID()\n    if dialect_name == 'sqlite':\n        naming_convention = {'uq': '%(table_name)s_%(column_0_N_name)s_key'}\n        with op.batch_alter_table('dag_run', naming_convention=naming_convention, recreate='always') as batch_op:\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n    elif dialect_name == 'mysql':\n        with op.batch_alter_table('dag_run') as batch_op:\n            batch_op.alter_column('dag_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            inspector = sa.inspect(conn.engine)\n            unique_keys = inspector.get_unique_constraints('dag_run')\n            for unique_key in unique_keys:\n                batch_op.drop_constraint(unique_key['name'], type_='unique')\n            batch_op.create_unique_constraint('dag_run_dag_id_execution_date_key', ['dag_id', 'execution_date'])\n            batch_op.create_unique_constraint('dag_run_dag_id_run_id_key', ['dag_id', 'run_id'])\n    elif dialect_name == 'mssql':\n        with op.batch_alter_table('dag_run') as batch_op:\n            batch_op.drop_index('idx_not_null_dag_id_execution_date')\n            batch_op.drop_index('idx_not_null_dag_id_run_id')\n            batch_op.drop_index('dag_id_state')\n            batch_op.drop_index('idx_dag_run_dag_id')\n            batch_op.drop_index('idx_dag_run_running_dags')\n            batch_op.drop_index('idx_dag_run_queued_dags')\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.create_unique_constraint('dag_run_dag_id_execution_date_key', ['dag_id', 'execution_date'])\n            batch_op.create_unique_constraint('dag_run_dag_id_run_id_key', ['dag_id', 'run_id'])\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)\n            batch_op.create_index('idx_dag_run_dag_id', ['dag_id'])\n            batch_op.create_index('idx_dag_run_running_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='running'\"))\n            batch_op.create_index('idx_dag_run_queued_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='queued'\"))\n    else:\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n    op.add_column('task_instance', sa.Column('run_id', type_=string_id_col_type, nullable=True))\n    op.add_column('task_reschedule', sa.Column('run_id', type_=string_id_col_type, nullable=True))\n    update_query = _multi_table_update(dialect_name, task_reschedule, task_reschedule.c.run_id)\n    op.execute(update_query)\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.alter_column('run_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.drop_constraint('task_reschedule_dag_task_date_fkey', type_='foreignkey')\n        if dialect_name == 'mysql':\n            batch_op.drop_index('task_reschedule_dag_task_date_fkey')\n            batch_op.alter_column('dag_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n        batch_op.drop_index('idx_task_reschedule_dag_task_date')\n    if dialect_name == 'postgresql':\n        op.execute('\\n            CREATE TABLE new_task_instance AS SELECT\\n                ti.task_id,\\n                ti.dag_id,\\n                dag_run.run_id,\\n                ti.start_date,\\n                ti.end_date,\\n                ti.duration,\\n                ti.state,\\n                ti.try_number,\\n                ti.hostname,\\n                ti.unixname,\\n                ti.job_id,\\n                ti.pool,\\n                ti.queue,\\n                ti.priority_weight,\\n                ti.operator,\\n                ti.queued_dttm,\\n                ti.pid,\\n                ti.max_tries,\\n                ti.executor_config,\\n                ti.pool_slots,\\n                ti.queued_by_job_id,\\n                ti.external_executor_id,\\n                ti.trigger_id,\\n                ti.trigger_timeout,\\n                ti.next_method,\\n                ti.next_kwargs\\n            FROM task_instance ti\\n            INNER JOIN dag_run ON dag_run.dag_id = ti.dag_id AND dag_run.execution_date = ti.execution_date;\\n        ')\n        op.drop_table('task_instance')\n        op.rename_table('new_task_instance', 'task_instance')\n        with op.batch_alter_table('task_instance', schema=None) as batch_op:\n            batch_op.alter_column('pool', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n            batch_op.alter_column('max_tries', existing_type=sa.Integer(), server_default='-1')\n            batch_op.alter_column('pool_slots', existing_type=sa.Integer(), existing_nullable=True, nullable=False)\n    else:\n        update_query = _multi_table_update(dialect_name, task_instance, task_instance.c.run_id)\n        op.execute(update_query)\n    with op.batch_alter_table('task_instance', schema=None) as batch_op:\n        if dialect_name != 'postgresql':\n            if dialect_name == 'mssql':\n                constraints = get_mssql_table_constraints(conn, 'task_instance')\n                (pk, _) = constraints['PRIMARY KEY'].popitem()\n                batch_op.drop_constraint(pk, type_='primary')\n            elif dialect_name not in 'sqlite':\n                batch_op.drop_constraint('task_instance_pkey', type_='primary')\n            batch_op.drop_index('ti_dag_date')\n            batch_op.drop_index('ti_state_lkp')\n            batch_op.drop_column('execution_date')\n        batch_op.alter_column('run_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.alter_column('dag_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.create_primary_key('task_instance_pkey', ['dag_id', 'task_id', 'run_id'])\n        batch_op.create_foreign_key('task_instance_dag_run_fkey', 'dag_run', ['dag_id', 'run_id'], ['dag_id', 'run_id'], ondelete='CASCADE')\n        batch_op.create_index('ti_dag_run', ['dag_id', 'run_id'])\n        batch_op.create_index('ti_state_lkp', ['dag_id', 'task_id', 'run_id', 'state'])\n        if dialect_name == 'postgresql':\n            batch_op.create_index('ti_dag_state', ['dag_id', 'state'])\n            batch_op.create_index('ti_job_id', ['job_id'])\n            batch_op.create_index('ti_pool', ['pool', 'state', 'priority_weight'])\n            batch_op.create_index('ti_state', ['state'])\n            batch_op.create_foreign_key('task_instance_trigger_id_fkey', 'trigger', ['trigger_id'], ['id'], ondelete='CASCADE')\n            batch_op.create_index('ti_trigger_id', ['trigger_id'])\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.drop_column('execution_date')\n        batch_op.create_index('idx_task_reschedule_dag_task_run', ['dag_id', 'task_id', 'run_id'], unique=False)\n        batch_op.create_foreign_key('task_reschedule_ti_fkey', 'task_instance', ['dag_id', 'task_id', 'run_id'], ['dag_id', 'task_id', 'run_id'], ondelete='CASCADE')\n        ondelete = 'CASCADE' if dialect_name != 'mssql' else 'NO ACTION'\n        batch_op.create_foreign_key('task_reschedule_dr_fkey', 'dag_run', ['dag_id', 'run_id'], ['dag_id', 'run_id'], ondelete=ondelete)",
            "def upgrade():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Apply Change ``TaskInstance`` and ``TaskReschedule`` tables from execution_date to run_id.'\n    conn = op.get_bind()\n    dialect_name = conn.dialect.name\n    dt_type = TIMESTAMP\n    string_id_col_type = StringID()\n    if dialect_name == 'sqlite':\n        naming_convention = {'uq': '%(table_name)s_%(column_0_N_name)s_key'}\n        with op.batch_alter_table('dag_run', naming_convention=naming_convention, recreate='always') as batch_op:\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n    elif dialect_name == 'mysql':\n        with op.batch_alter_table('dag_run') as batch_op:\n            batch_op.alter_column('dag_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            inspector = sa.inspect(conn.engine)\n            unique_keys = inspector.get_unique_constraints('dag_run')\n            for unique_key in unique_keys:\n                batch_op.drop_constraint(unique_key['name'], type_='unique')\n            batch_op.create_unique_constraint('dag_run_dag_id_execution_date_key', ['dag_id', 'execution_date'])\n            batch_op.create_unique_constraint('dag_run_dag_id_run_id_key', ['dag_id', 'run_id'])\n    elif dialect_name == 'mssql':\n        with op.batch_alter_table('dag_run') as batch_op:\n            batch_op.drop_index('idx_not_null_dag_id_execution_date')\n            batch_op.drop_index('idx_not_null_dag_id_run_id')\n            batch_op.drop_index('dag_id_state')\n            batch_op.drop_index('idx_dag_run_dag_id')\n            batch_op.drop_index('idx_dag_run_running_dags')\n            batch_op.drop_index('idx_dag_run_queued_dags')\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.create_unique_constraint('dag_run_dag_id_execution_date_key', ['dag_id', 'execution_date'])\n            batch_op.create_unique_constraint('dag_run_dag_id_run_id_key', ['dag_id', 'run_id'])\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)\n            batch_op.create_index('idx_dag_run_dag_id', ['dag_id'])\n            batch_op.create_index('idx_dag_run_running_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='running'\"))\n            batch_op.create_index('idx_dag_run_queued_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='queued'\"))\n    else:\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=False)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=False)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=False)\n    op.add_column('task_instance', sa.Column('run_id', type_=string_id_col_type, nullable=True))\n    op.add_column('task_reschedule', sa.Column('run_id', type_=string_id_col_type, nullable=True))\n    update_query = _multi_table_update(dialect_name, task_reschedule, task_reschedule.c.run_id)\n    op.execute(update_query)\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.alter_column('run_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.drop_constraint('task_reschedule_dag_task_date_fkey', type_='foreignkey')\n        if dialect_name == 'mysql':\n            batch_op.drop_index('task_reschedule_dag_task_date_fkey')\n            batch_op.alter_column('dag_id', existing_type=sa.String(length=ID_LEN), type_=string_id_col_type, nullable=False)\n        batch_op.drop_index('idx_task_reschedule_dag_task_date')\n    if dialect_name == 'postgresql':\n        op.execute('\\n            CREATE TABLE new_task_instance AS SELECT\\n                ti.task_id,\\n                ti.dag_id,\\n                dag_run.run_id,\\n                ti.start_date,\\n                ti.end_date,\\n                ti.duration,\\n                ti.state,\\n                ti.try_number,\\n                ti.hostname,\\n                ti.unixname,\\n                ti.job_id,\\n                ti.pool,\\n                ti.queue,\\n                ti.priority_weight,\\n                ti.operator,\\n                ti.queued_dttm,\\n                ti.pid,\\n                ti.max_tries,\\n                ti.executor_config,\\n                ti.pool_slots,\\n                ti.queued_by_job_id,\\n                ti.external_executor_id,\\n                ti.trigger_id,\\n                ti.trigger_timeout,\\n                ti.next_method,\\n                ti.next_kwargs\\n            FROM task_instance ti\\n            INNER JOIN dag_run ON dag_run.dag_id = ti.dag_id AND dag_run.execution_date = ti.execution_date;\\n        ')\n        op.drop_table('task_instance')\n        op.rename_table('new_task_instance', 'task_instance')\n        with op.batch_alter_table('task_instance', schema=None) as batch_op:\n            batch_op.alter_column('pool', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n            batch_op.alter_column('max_tries', existing_type=sa.Integer(), server_default='-1')\n            batch_op.alter_column('pool_slots', existing_type=sa.Integer(), existing_nullable=True, nullable=False)\n    else:\n        update_query = _multi_table_update(dialect_name, task_instance, task_instance.c.run_id)\n        op.execute(update_query)\n    with op.batch_alter_table('task_instance', schema=None) as batch_op:\n        if dialect_name != 'postgresql':\n            if dialect_name == 'mssql':\n                constraints = get_mssql_table_constraints(conn, 'task_instance')\n                (pk, _) = constraints['PRIMARY KEY'].popitem()\n                batch_op.drop_constraint(pk, type_='primary')\n            elif dialect_name not in 'sqlite':\n                batch_op.drop_constraint('task_instance_pkey', type_='primary')\n            batch_op.drop_index('ti_dag_date')\n            batch_op.drop_index('ti_state_lkp')\n            batch_op.drop_column('execution_date')\n        batch_op.alter_column('run_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.alter_column('dag_id', existing_type=string_id_col_type, existing_nullable=True, nullable=False)\n        batch_op.create_primary_key('task_instance_pkey', ['dag_id', 'task_id', 'run_id'])\n        batch_op.create_foreign_key('task_instance_dag_run_fkey', 'dag_run', ['dag_id', 'run_id'], ['dag_id', 'run_id'], ondelete='CASCADE')\n        batch_op.create_index('ti_dag_run', ['dag_id', 'run_id'])\n        batch_op.create_index('ti_state_lkp', ['dag_id', 'task_id', 'run_id', 'state'])\n        if dialect_name == 'postgresql':\n            batch_op.create_index('ti_dag_state', ['dag_id', 'state'])\n            batch_op.create_index('ti_job_id', ['job_id'])\n            batch_op.create_index('ti_pool', ['pool', 'state', 'priority_weight'])\n            batch_op.create_index('ti_state', ['state'])\n            batch_op.create_foreign_key('task_instance_trigger_id_fkey', 'trigger', ['trigger_id'], ['id'], ondelete='CASCADE')\n            batch_op.create_index('ti_trigger_id', ['trigger_id'])\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.drop_column('execution_date')\n        batch_op.create_index('idx_task_reschedule_dag_task_run', ['dag_id', 'task_id', 'run_id'], unique=False)\n        batch_op.create_foreign_key('task_reschedule_ti_fkey', 'task_instance', ['dag_id', 'task_id', 'run_id'], ['dag_id', 'task_id', 'run_id'], ondelete='CASCADE')\n        ondelete = 'CASCADE' if dialect_name != 'mssql' else 'NO ACTION'\n        batch_op.create_foreign_key('task_reschedule_dr_fkey', 'dag_run', ['dag_id', 'run_id'], ['dag_id', 'run_id'], ondelete=ondelete)"
        ]
    },
    {
        "func_name": "downgrade",
        "original": "def downgrade():\n    \"\"\"Unapply Change ``TaskInstance`` and ``TaskReschedule`` tables from execution_date to run_id.\"\"\"\n    dialect_name = op.get_bind().dialect.name\n    dt_type = TIMESTAMP\n    string_id_col_type = StringID()\n    op.add_column('task_instance', sa.Column('execution_date', dt_type, nullable=True))\n    op.add_column('task_reschedule', sa.Column('execution_date', dt_type, nullable=True))\n    update_query = _multi_table_update(dialect_name, task_instance, task_instance.c.execution_date)\n    op.execute(update_query)\n    update_query = _multi_table_update(dialect_name, task_reschedule, task_reschedule.c.execution_date)\n    op.execute(update_query)\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.alter_column('execution_date', existing_type=dt_type, existing_nullable=True, nullable=False)\n        batch_op.drop_constraint('task_reschedule_ti_fkey', type_='foreignkey')\n        batch_op.drop_constraint('task_reschedule_dr_fkey', type_='foreignkey')\n        batch_op.drop_index('idx_task_reschedule_dag_task_run')\n    with op.batch_alter_table('task_instance', schema=None) as batch_op:\n        batch_op.drop_constraint('task_instance_pkey', type_='primary')\n        batch_op.alter_column('execution_date', existing_type=dt_type, existing_nullable=True, nullable=False)\n        if dialect_name != 'mssql':\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, existing_nullable=False, nullable=True)\n        batch_op.create_primary_key('task_instance_pkey', ['dag_id', 'task_id', 'execution_date'])\n        batch_op.drop_constraint('task_instance_dag_run_fkey', type_='foreignkey')\n        batch_op.drop_index('ti_dag_run')\n        batch_op.drop_index('ti_state_lkp')\n        batch_op.create_index('ti_state_lkp', ['dag_id', 'task_id', 'execution_date', 'state'])\n        batch_op.create_index('ti_dag_date', ['dag_id', 'execution_date'], unique=False)\n        batch_op.drop_column('run_id')\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.drop_column('run_id')\n        batch_op.create_index('idx_task_reschedule_dag_task_date', ['dag_id', 'task_id', 'execution_date'], unique=False)\n        batch_op.create_foreign_key('task_reschedule_dag_task_date_fkey', 'task_instance', ['dag_id', 'task_id', 'execution_date'], ['dag_id', 'task_id', 'execution_date'], ondelete='CASCADE')\n        if dialect_name == 'mysql':\n            batch_op.create_index('task_reschedule_dag_task_date_fkey', ['dag_id', 'execution_date'], unique=False)\n    if dialect_name == 'mssql':\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.drop_constraint('dag_run_dag_id_execution_date_key', type_='unique')\n            batch_op.drop_constraint('dag_run_dag_id_run_id_key', type_='unique')\n            batch_op.drop_index('dag_id_state')\n            batch_op.drop_index('idx_dag_run_running_dags')\n            batch_op.drop_index('idx_dag_run_queued_dags')\n            batch_op.drop_index('idx_dag_run_dag_id')\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=True)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=True)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=True)\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)\n            batch_op.create_index('idx_dag_run_dag_id', ['dag_id'])\n            batch_op.create_index('idx_dag_run_running_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='running'\"))\n            batch_op.create_index('idx_dag_run_queued_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='queued'\"))\n        op.execute('CREATE UNIQUE NONCLUSTERED INDEX idx_not_null_dag_id_execution_date\\n                    ON dag_run(dag_id,execution_date)\\n                    WHERE dag_id IS NOT NULL and execution_date is not null')\n        op.execute('CREATE UNIQUE NONCLUSTERED INDEX idx_not_null_dag_id_run_id\\n                     ON dag_run(dag_id,run_id)\\n                     WHERE dag_id IS NOT NULL and run_id is not null')\n    else:\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.drop_index('dag_id_state')\n            batch_op.alter_column('run_id', existing_type=sa.VARCHAR(length=250), nullable=True)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=True)\n            batch_op.alter_column('dag_id', existing_type=sa.VARCHAR(length=250), nullable=True)\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)",
        "mutated": [
            "def downgrade():\n    if False:\n        i = 10\n    'Unapply Change ``TaskInstance`` and ``TaskReschedule`` tables from execution_date to run_id.'\n    dialect_name = op.get_bind().dialect.name\n    dt_type = TIMESTAMP\n    string_id_col_type = StringID()\n    op.add_column('task_instance', sa.Column('execution_date', dt_type, nullable=True))\n    op.add_column('task_reschedule', sa.Column('execution_date', dt_type, nullable=True))\n    update_query = _multi_table_update(dialect_name, task_instance, task_instance.c.execution_date)\n    op.execute(update_query)\n    update_query = _multi_table_update(dialect_name, task_reschedule, task_reschedule.c.execution_date)\n    op.execute(update_query)\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.alter_column('execution_date', existing_type=dt_type, existing_nullable=True, nullable=False)\n        batch_op.drop_constraint('task_reschedule_ti_fkey', type_='foreignkey')\n        batch_op.drop_constraint('task_reschedule_dr_fkey', type_='foreignkey')\n        batch_op.drop_index('idx_task_reschedule_dag_task_run')\n    with op.batch_alter_table('task_instance', schema=None) as batch_op:\n        batch_op.drop_constraint('task_instance_pkey', type_='primary')\n        batch_op.alter_column('execution_date', existing_type=dt_type, existing_nullable=True, nullable=False)\n        if dialect_name != 'mssql':\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, existing_nullable=False, nullable=True)\n        batch_op.create_primary_key('task_instance_pkey', ['dag_id', 'task_id', 'execution_date'])\n        batch_op.drop_constraint('task_instance_dag_run_fkey', type_='foreignkey')\n        batch_op.drop_index('ti_dag_run')\n        batch_op.drop_index('ti_state_lkp')\n        batch_op.create_index('ti_state_lkp', ['dag_id', 'task_id', 'execution_date', 'state'])\n        batch_op.create_index('ti_dag_date', ['dag_id', 'execution_date'], unique=False)\n        batch_op.drop_column('run_id')\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.drop_column('run_id')\n        batch_op.create_index('idx_task_reschedule_dag_task_date', ['dag_id', 'task_id', 'execution_date'], unique=False)\n        batch_op.create_foreign_key('task_reschedule_dag_task_date_fkey', 'task_instance', ['dag_id', 'task_id', 'execution_date'], ['dag_id', 'task_id', 'execution_date'], ondelete='CASCADE')\n        if dialect_name == 'mysql':\n            batch_op.create_index('task_reschedule_dag_task_date_fkey', ['dag_id', 'execution_date'], unique=False)\n    if dialect_name == 'mssql':\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.drop_constraint('dag_run_dag_id_execution_date_key', type_='unique')\n            batch_op.drop_constraint('dag_run_dag_id_run_id_key', type_='unique')\n            batch_op.drop_index('dag_id_state')\n            batch_op.drop_index('idx_dag_run_running_dags')\n            batch_op.drop_index('idx_dag_run_queued_dags')\n            batch_op.drop_index('idx_dag_run_dag_id')\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=True)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=True)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=True)\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)\n            batch_op.create_index('idx_dag_run_dag_id', ['dag_id'])\n            batch_op.create_index('idx_dag_run_running_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='running'\"))\n            batch_op.create_index('idx_dag_run_queued_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='queued'\"))\n        op.execute('CREATE UNIQUE NONCLUSTERED INDEX idx_not_null_dag_id_execution_date\\n                    ON dag_run(dag_id,execution_date)\\n                    WHERE dag_id IS NOT NULL and execution_date is not null')\n        op.execute('CREATE UNIQUE NONCLUSTERED INDEX idx_not_null_dag_id_run_id\\n                     ON dag_run(dag_id,run_id)\\n                     WHERE dag_id IS NOT NULL and run_id is not null')\n    else:\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.drop_index('dag_id_state')\n            batch_op.alter_column('run_id', existing_type=sa.VARCHAR(length=250), nullable=True)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=True)\n            batch_op.alter_column('dag_id', existing_type=sa.VARCHAR(length=250), nullable=True)\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)",
            "def downgrade():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Unapply Change ``TaskInstance`` and ``TaskReschedule`` tables from execution_date to run_id.'\n    dialect_name = op.get_bind().dialect.name\n    dt_type = TIMESTAMP\n    string_id_col_type = StringID()\n    op.add_column('task_instance', sa.Column('execution_date', dt_type, nullable=True))\n    op.add_column('task_reschedule', sa.Column('execution_date', dt_type, nullable=True))\n    update_query = _multi_table_update(dialect_name, task_instance, task_instance.c.execution_date)\n    op.execute(update_query)\n    update_query = _multi_table_update(dialect_name, task_reschedule, task_reschedule.c.execution_date)\n    op.execute(update_query)\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.alter_column('execution_date', existing_type=dt_type, existing_nullable=True, nullable=False)\n        batch_op.drop_constraint('task_reschedule_ti_fkey', type_='foreignkey')\n        batch_op.drop_constraint('task_reschedule_dr_fkey', type_='foreignkey')\n        batch_op.drop_index('idx_task_reschedule_dag_task_run')\n    with op.batch_alter_table('task_instance', schema=None) as batch_op:\n        batch_op.drop_constraint('task_instance_pkey', type_='primary')\n        batch_op.alter_column('execution_date', existing_type=dt_type, existing_nullable=True, nullable=False)\n        if dialect_name != 'mssql':\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, existing_nullable=False, nullable=True)\n        batch_op.create_primary_key('task_instance_pkey', ['dag_id', 'task_id', 'execution_date'])\n        batch_op.drop_constraint('task_instance_dag_run_fkey', type_='foreignkey')\n        batch_op.drop_index('ti_dag_run')\n        batch_op.drop_index('ti_state_lkp')\n        batch_op.create_index('ti_state_lkp', ['dag_id', 'task_id', 'execution_date', 'state'])\n        batch_op.create_index('ti_dag_date', ['dag_id', 'execution_date'], unique=False)\n        batch_op.drop_column('run_id')\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.drop_column('run_id')\n        batch_op.create_index('idx_task_reschedule_dag_task_date', ['dag_id', 'task_id', 'execution_date'], unique=False)\n        batch_op.create_foreign_key('task_reschedule_dag_task_date_fkey', 'task_instance', ['dag_id', 'task_id', 'execution_date'], ['dag_id', 'task_id', 'execution_date'], ondelete='CASCADE')\n        if dialect_name == 'mysql':\n            batch_op.create_index('task_reschedule_dag_task_date_fkey', ['dag_id', 'execution_date'], unique=False)\n    if dialect_name == 'mssql':\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.drop_constraint('dag_run_dag_id_execution_date_key', type_='unique')\n            batch_op.drop_constraint('dag_run_dag_id_run_id_key', type_='unique')\n            batch_op.drop_index('dag_id_state')\n            batch_op.drop_index('idx_dag_run_running_dags')\n            batch_op.drop_index('idx_dag_run_queued_dags')\n            batch_op.drop_index('idx_dag_run_dag_id')\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=True)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=True)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=True)\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)\n            batch_op.create_index('idx_dag_run_dag_id', ['dag_id'])\n            batch_op.create_index('idx_dag_run_running_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='running'\"))\n            batch_op.create_index('idx_dag_run_queued_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='queued'\"))\n        op.execute('CREATE UNIQUE NONCLUSTERED INDEX idx_not_null_dag_id_execution_date\\n                    ON dag_run(dag_id,execution_date)\\n                    WHERE dag_id IS NOT NULL and execution_date is not null')\n        op.execute('CREATE UNIQUE NONCLUSTERED INDEX idx_not_null_dag_id_run_id\\n                     ON dag_run(dag_id,run_id)\\n                     WHERE dag_id IS NOT NULL and run_id is not null')\n    else:\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.drop_index('dag_id_state')\n            batch_op.alter_column('run_id', existing_type=sa.VARCHAR(length=250), nullable=True)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=True)\n            batch_op.alter_column('dag_id', existing_type=sa.VARCHAR(length=250), nullable=True)\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)",
            "def downgrade():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Unapply Change ``TaskInstance`` and ``TaskReschedule`` tables from execution_date to run_id.'\n    dialect_name = op.get_bind().dialect.name\n    dt_type = TIMESTAMP\n    string_id_col_type = StringID()\n    op.add_column('task_instance', sa.Column('execution_date', dt_type, nullable=True))\n    op.add_column('task_reschedule', sa.Column('execution_date', dt_type, nullable=True))\n    update_query = _multi_table_update(dialect_name, task_instance, task_instance.c.execution_date)\n    op.execute(update_query)\n    update_query = _multi_table_update(dialect_name, task_reschedule, task_reschedule.c.execution_date)\n    op.execute(update_query)\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.alter_column('execution_date', existing_type=dt_type, existing_nullable=True, nullable=False)\n        batch_op.drop_constraint('task_reschedule_ti_fkey', type_='foreignkey')\n        batch_op.drop_constraint('task_reschedule_dr_fkey', type_='foreignkey')\n        batch_op.drop_index('idx_task_reschedule_dag_task_run')\n    with op.batch_alter_table('task_instance', schema=None) as batch_op:\n        batch_op.drop_constraint('task_instance_pkey', type_='primary')\n        batch_op.alter_column('execution_date', existing_type=dt_type, existing_nullable=True, nullable=False)\n        if dialect_name != 'mssql':\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, existing_nullable=False, nullable=True)\n        batch_op.create_primary_key('task_instance_pkey', ['dag_id', 'task_id', 'execution_date'])\n        batch_op.drop_constraint('task_instance_dag_run_fkey', type_='foreignkey')\n        batch_op.drop_index('ti_dag_run')\n        batch_op.drop_index('ti_state_lkp')\n        batch_op.create_index('ti_state_lkp', ['dag_id', 'task_id', 'execution_date', 'state'])\n        batch_op.create_index('ti_dag_date', ['dag_id', 'execution_date'], unique=False)\n        batch_op.drop_column('run_id')\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.drop_column('run_id')\n        batch_op.create_index('idx_task_reschedule_dag_task_date', ['dag_id', 'task_id', 'execution_date'], unique=False)\n        batch_op.create_foreign_key('task_reschedule_dag_task_date_fkey', 'task_instance', ['dag_id', 'task_id', 'execution_date'], ['dag_id', 'task_id', 'execution_date'], ondelete='CASCADE')\n        if dialect_name == 'mysql':\n            batch_op.create_index('task_reschedule_dag_task_date_fkey', ['dag_id', 'execution_date'], unique=False)\n    if dialect_name == 'mssql':\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.drop_constraint('dag_run_dag_id_execution_date_key', type_='unique')\n            batch_op.drop_constraint('dag_run_dag_id_run_id_key', type_='unique')\n            batch_op.drop_index('dag_id_state')\n            batch_op.drop_index('idx_dag_run_running_dags')\n            batch_op.drop_index('idx_dag_run_queued_dags')\n            batch_op.drop_index('idx_dag_run_dag_id')\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=True)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=True)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=True)\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)\n            batch_op.create_index('idx_dag_run_dag_id', ['dag_id'])\n            batch_op.create_index('idx_dag_run_running_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='running'\"))\n            batch_op.create_index('idx_dag_run_queued_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='queued'\"))\n        op.execute('CREATE UNIQUE NONCLUSTERED INDEX idx_not_null_dag_id_execution_date\\n                    ON dag_run(dag_id,execution_date)\\n                    WHERE dag_id IS NOT NULL and execution_date is not null')\n        op.execute('CREATE UNIQUE NONCLUSTERED INDEX idx_not_null_dag_id_run_id\\n                     ON dag_run(dag_id,run_id)\\n                     WHERE dag_id IS NOT NULL and run_id is not null')\n    else:\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.drop_index('dag_id_state')\n            batch_op.alter_column('run_id', existing_type=sa.VARCHAR(length=250), nullable=True)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=True)\n            batch_op.alter_column('dag_id', existing_type=sa.VARCHAR(length=250), nullable=True)\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)",
            "def downgrade():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Unapply Change ``TaskInstance`` and ``TaskReschedule`` tables from execution_date to run_id.'\n    dialect_name = op.get_bind().dialect.name\n    dt_type = TIMESTAMP\n    string_id_col_type = StringID()\n    op.add_column('task_instance', sa.Column('execution_date', dt_type, nullable=True))\n    op.add_column('task_reschedule', sa.Column('execution_date', dt_type, nullable=True))\n    update_query = _multi_table_update(dialect_name, task_instance, task_instance.c.execution_date)\n    op.execute(update_query)\n    update_query = _multi_table_update(dialect_name, task_reschedule, task_reschedule.c.execution_date)\n    op.execute(update_query)\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.alter_column('execution_date', existing_type=dt_type, existing_nullable=True, nullable=False)\n        batch_op.drop_constraint('task_reschedule_ti_fkey', type_='foreignkey')\n        batch_op.drop_constraint('task_reschedule_dr_fkey', type_='foreignkey')\n        batch_op.drop_index('idx_task_reschedule_dag_task_run')\n    with op.batch_alter_table('task_instance', schema=None) as batch_op:\n        batch_op.drop_constraint('task_instance_pkey', type_='primary')\n        batch_op.alter_column('execution_date', existing_type=dt_type, existing_nullable=True, nullable=False)\n        if dialect_name != 'mssql':\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, existing_nullable=False, nullable=True)\n        batch_op.create_primary_key('task_instance_pkey', ['dag_id', 'task_id', 'execution_date'])\n        batch_op.drop_constraint('task_instance_dag_run_fkey', type_='foreignkey')\n        batch_op.drop_index('ti_dag_run')\n        batch_op.drop_index('ti_state_lkp')\n        batch_op.create_index('ti_state_lkp', ['dag_id', 'task_id', 'execution_date', 'state'])\n        batch_op.create_index('ti_dag_date', ['dag_id', 'execution_date'], unique=False)\n        batch_op.drop_column('run_id')\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.drop_column('run_id')\n        batch_op.create_index('idx_task_reschedule_dag_task_date', ['dag_id', 'task_id', 'execution_date'], unique=False)\n        batch_op.create_foreign_key('task_reschedule_dag_task_date_fkey', 'task_instance', ['dag_id', 'task_id', 'execution_date'], ['dag_id', 'task_id', 'execution_date'], ondelete='CASCADE')\n        if dialect_name == 'mysql':\n            batch_op.create_index('task_reschedule_dag_task_date_fkey', ['dag_id', 'execution_date'], unique=False)\n    if dialect_name == 'mssql':\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.drop_constraint('dag_run_dag_id_execution_date_key', type_='unique')\n            batch_op.drop_constraint('dag_run_dag_id_run_id_key', type_='unique')\n            batch_op.drop_index('dag_id_state')\n            batch_op.drop_index('idx_dag_run_running_dags')\n            batch_op.drop_index('idx_dag_run_queued_dags')\n            batch_op.drop_index('idx_dag_run_dag_id')\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=True)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=True)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=True)\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)\n            batch_op.create_index('idx_dag_run_dag_id', ['dag_id'])\n            batch_op.create_index('idx_dag_run_running_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='running'\"))\n            batch_op.create_index('idx_dag_run_queued_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='queued'\"))\n        op.execute('CREATE UNIQUE NONCLUSTERED INDEX idx_not_null_dag_id_execution_date\\n                    ON dag_run(dag_id,execution_date)\\n                    WHERE dag_id IS NOT NULL and execution_date is not null')\n        op.execute('CREATE UNIQUE NONCLUSTERED INDEX idx_not_null_dag_id_run_id\\n                     ON dag_run(dag_id,run_id)\\n                     WHERE dag_id IS NOT NULL and run_id is not null')\n    else:\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.drop_index('dag_id_state')\n            batch_op.alter_column('run_id', existing_type=sa.VARCHAR(length=250), nullable=True)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=True)\n            batch_op.alter_column('dag_id', existing_type=sa.VARCHAR(length=250), nullable=True)\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)",
            "def downgrade():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Unapply Change ``TaskInstance`` and ``TaskReschedule`` tables from execution_date to run_id.'\n    dialect_name = op.get_bind().dialect.name\n    dt_type = TIMESTAMP\n    string_id_col_type = StringID()\n    op.add_column('task_instance', sa.Column('execution_date', dt_type, nullable=True))\n    op.add_column('task_reschedule', sa.Column('execution_date', dt_type, nullable=True))\n    update_query = _multi_table_update(dialect_name, task_instance, task_instance.c.execution_date)\n    op.execute(update_query)\n    update_query = _multi_table_update(dialect_name, task_reschedule, task_reschedule.c.execution_date)\n    op.execute(update_query)\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.alter_column('execution_date', existing_type=dt_type, existing_nullable=True, nullable=False)\n        batch_op.drop_constraint('task_reschedule_ti_fkey', type_='foreignkey')\n        batch_op.drop_constraint('task_reschedule_dr_fkey', type_='foreignkey')\n        batch_op.drop_index('idx_task_reschedule_dag_task_run')\n    with op.batch_alter_table('task_instance', schema=None) as batch_op:\n        batch_op.drop_constraint('task_instance_pkey', type_='primary')\n        batch_op.alter_column('execution_date', existing_type=dt_type, existing_nullable=True, nullable=False)\n        if dialect_name != 'mssql':\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, existing_nullable=False, nullable=True)\n        batch_op.create_primary_key('task_instance_pkey', ['dag_id', 'task_id', 'execution_date'])\n        batch_op.drop_constraint('task_instance_dag_run_fkey', type_='foreignkey')\n        batch_op.drop_index('ti_dag_run')\n        batch_op.drop_index('ti_state_lkp')\n        batch_op.create_index('ti_state_lkp', ['dag_id', 'task_id', 'execution_date', 'state'])\n        batch_op.create_index('ti_dag_date', ['dag_id', 'execution_date'], unique=False)\n        batch_op.drop_column('run_id')\n    with op.batch_alter_table('task_reschedule', schema=None) as batch_op:\n        batch_op.drop_column('run_id')\n        batch_op.create_index('idx_task_reschedule_dag_task_date', ['dag_id', 'task_id', 'execution_date'], unique=False)\n        batch_op.create_foreign_key('task_reschedule_dag_task_date_fkey', 'task_instance', ['dag_id', 'task_id', 'execution_date'], ['dag_id', 'task_id', 'execution_date'], ondelete='CASCADE')\n        if dialect_name == 'mysql':\n            batch_op.create_index('task_reschedule_dag_task_date_fkey', ['dag_id', 'execution_date'], unique=False)\n    if dialect_name == 'mssql':\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.drop_constraint('dag_run_dag_id_execution_date_key', type_='unique')\n            batch_op.drop_constraint('dag_run_dag_id_run_id_key', type_='unique')\n            batch_op.drop_index('dag_id_state')\n            batch_op.drop_index('idx_dag_run_running_dags')\n            batch_op.drop_index('idx_dag_run_queued_dags')\n            batch_op.drop_index('idx_dag_run_dag_id')\n            batch_op.alter_column('dag_id', existing_type=string_id_col_type, nullable=True)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=True)\n            batch_op.alter_column('run_id', existing_type=string_id_col_type, nullable=True)\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)\n            batch_op.create_index('idx_dag_run_dag_id', ['dag_id'])\n            batch_op.create_index('idx_dag_run_running_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='running'\"))\n            batch_op.create_index('idx_dag_run_queued_dags', ['state', 'dag_id'], mssql_where=sa.text(\"state='queued'\"))\n        op.execute('CREATE UNIQUE NONCLUSTERED INDEX idx_not_null_dag_id_execution_date\\n                    ON dag_run(dag_id,execution_date)\\n                    WHERE dag_id IS NOT NULL and execution_date is not null')\n        op.execute('CREATE UNIQUE NONCLUSTERED INDEX idx_not_null_dag_id_run_id\\n                     ON dag_run(dag_id,run_id)\\n                     WHERE dag_id IS NOT NULL and run_id is not null')\n    else:\n        with op.batch_alter_table('dag_run', schema=None) as batch_op:\n            batch_op.drop_index('dag_id_state')\n            batch_op.alter_column('run_id', existing_type=sa.VARCHAR(length=250), nullable=True)\n            batch_op.alter_column('execution_date', existing_type=dt_type, nullable=True)\n            batch_op.alter_column('dag_id', existing_type=sa.VARCHAR(length=250), nullable=True)\n            batch_op.create_index('dag_id_state', ['dag_id', 'state'], unique=False)"
        ]
    },
    {
        "func_name": "_multi_table_update",
        "original": "def _multi_table_update(dialect_name, target, column):\n    condition = dag_run.c.dag_id == target.c.dag_id\n    if column == target.c.run_id:\n        condition = and_(condition, dag_run.c.execution_date == target.c.execution_date)\n    else:\n        condition = and_(condition, dag_run.c.run_id == target.c.run_id)\n    if dialect_name == 'sqlite':\n        sub_q = select(dag_run.c[column.name]).where(condition)\n        return target.update().values({column: sub_q})\n    else:\n        return target.update().where(condition).values({column: dag_run.c[column.name]})",
        "mutated": [
            "def _multi_table_update(dialect_name, target, column):\n    if False:\n        i = 10\n    condition = dag_run.c.dag_id == target.c.dag_id\n    if column == target.c.run_id:\n        condition = and_(condition, dag_run.c.execution_date == target.c.execution_date)\n    else:\n        condition = and_(condition, dag_run.c.run_id == target.c.run_id)\n    if dialect_name == 'sqlite':\n        sub_q = select(dag_run.c[column.name]).where(condition)\n        return target.update().values({column: sub_q})\n    else:\n        return target.update().where(condition).values({column: dag_run.c[column.name]})",
            "def _multi_table_update(dialect_name, target, column):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    condition = dag_run.c.dag_id == target.c.dag_id\n    if column == target.c.run_id:\n        condition = and_(condition, dag_run.c.execution_date == target.c.execution_date)\n    else:\n        condition = and_(condition, dag_run.c.run_id == target.c.run_id)\n    if dialect_name == 'sqlite':\n        sub_q = select(dag_run.c[column.name]).where(condition)\n        return target.update().values({column: sub_q})\n    else:\n        return target.update().where(condition).values({column: dag_run.c[column.name]})",
            "def _multi_table_update(dialect_name, target, column):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    condition = dag_run.c.dag_id == target.c.dag_id\n    if column == target.c.run_id:\n        condition = and_(condition, dag_run.c.execution_date == target.c.execution_date)\n    else:\n        condition = and_(condition, dag_run.c.run_id == target.c.run_id)\n    if dialect_name == 'sqlite':\n        sub_q = select(dag_run.c[column.name]).where(condition)\n        return target.update().values({column: sub_q})\n    else:\n        return target.update().where(condition).values({column: dag_run.c[column.name]})",
            "def _multi_table_update(dialect_name, target, column):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    condition = dag_run.c.dag_id == target.c.dag_id\n    if column == target.c.run_id:\n        condition = and_(condition, dag_run.c.execution_date == target.c.execution_date)\n    else:\n        condition = and_(condition, dag_run.c.run_id == target.c.run_id)\n    if dialect_name == 'sqlite':\n        sub_q = select(dag_run.c[column.name]).where(condition)\n        return target.update().values({column: sub_q})\n    else:\n        return target.update().where(condition).values({column: dag_run.c[column.name]})",
            "def _multi_table_update(dialect_name, target, column):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    condition = dag_run.c.dag_id == target.c.dag_id\n    if column == target.c.run_id:\n        condition = and_(condition, dag_run.c.execution_date == target.c.execution_date)\n    else:\n        condition = and_(condition, dag_run.c.run_id == target.c.run_id)\n    if dialect_name == 'sqlite':\n        sub_q = select(dag_run.c[column.name]).where(condition)\n        return target.update().values({column: sub_q})\n    else:\n        return target.update().where(condition).values({column: dag_run.c[column.name]})"
        ]
    }
]