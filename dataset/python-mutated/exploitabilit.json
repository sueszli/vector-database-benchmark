[
    {
        "func_name": "unreg_exploitability",
        "original": "def unreg_exploitability(dist, payoff_tensor, aggregate=np.mean):\n    \"\"\"Compute (avg, max) exploitability of dist for non-symmetric game.\n\n  Args:\n    dist: list of 1-d np.arrays, current estimate of nash distribution\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\n      can also be list of (A1 x ... x An) np.arrays\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\n  Returns:\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\n  \"\"\"\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        u_i_br = np.max(nabla_i)\n        u_i_dist = nabla_i.dot(dist[i])\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)",
        "mutated": [
            "def unreg_exploitability(dist, payoff_tensor, aggregate=np.mean):\n    if False:\n        i = 10\n    'Compute (avg, max) exploitability of dist for non-symmetric game.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\\n      can also be list of (A1 x ... x An) np.arrays\\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\\n  Returns:\\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\\n  '\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        u_i_br = np.max(nabla_i)\n        u_i_dist = nabla_i.dot(dist[i])\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)",
            "def unreg_exploitability(dist, payoff_tensor, aggregate=np.mean):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Compute (avg, max) exploitability of dist for non-symmetric game.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\\n      can also be list of (A1 x ... x An) np.arrays\\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\\n  Returns:\\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\\n  '\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        u_i_br = np.max(nabla_i)\n        u_i_dist = nabla_i.dot(dist[i])\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)",
            "def unreg_exploitability(dist, payoff_tensor, aggregate=np.mean):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Compute (avg, max) exploitability of dist for non-symmetric game.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\\n      can also be list of (A1 x ... x An) np.arrays\\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\\n  Returns:\\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\\n  '\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        u_i_br = np.max(nabla_i)\n        u_i_dist = nabla_i.dot(dist[i])\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)",
            "def unreg_exploitability(dist, payoff_tensor, aggregate=np.mean):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Compute (avg, max) exploitability of dist for non-symmetric game.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\\n      can also be list of (A1 x ... x An) np.arrays\\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\\n  Returns:\\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\\n  '\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        u_i_br = np.max(nabla_i)\n        u_i_dist = nabla_i.dot(dist[i])\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)",
            "def unreg_exploitability(dist, payoff_tensor, aggregate=np.mean):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Compute (avg, max) exploitability of dist for non-symmetric game.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\\n      can also be list of (A1 x ... x An) np.arrays\\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\\n  Returns:\\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\\n  '\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        u_i_br = np.max(nabla_i)\n        u_i_dist = nabla_i.dot(dist[i])\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)"
        ]
    },
    {
        "func_name": "ate_exploitability",
        "original": "def ate_exploitability(dist, payoff_tensor, p=1, aggregate=np.mean):\n    \"\"\"Compute Tsallis regularized exploitability of dist for non-symmetric game.\n\n  Args:\n    dist: list of 1-d np.arrays, current estimate of nash distribution\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\n      assumed to be non-negative. can also be list of (A1 x ... x An) np.arrays\n    p: float in [0, 1], Tsallis entropy-regularization --> 0 as p --> 0\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\n  Returns:\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\n  \"\"\"\n    if np.min(payoff_tensor) < 0.0:\n        raise ValueError('payoff tensor must be non-negative')\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        dist_i = dist[i]\n        if p > 0:\n            power = 1.0 / p\n            s = np.linalg.norm(nabla_i, ord=power)\n            br_i = (nabla_i / np.linalg.norm(nabla_i, ord=power)) ** power\n        else:\n            power = np.inf\n            s = np.linalg.norm(nabla_i, ord=power)\n            br_i = np.zeros_like(dist_i)\n            maxima = nabla_i == s\n            br_i[maxima] = 1.0 / maxima.sum()\n        u_i_br = nabla_i.dot(br_i) + s / (p + 1) * (1 - np.sum(br_i ** (p + 1)))\n        u_i_dist = nabla_i.dot(dist_i) + s / (p + 1) * (1 - np.sum(dist_i ** (p + 1)))\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)",
        "mutated": [
            "def ate_exploitability(dist, payoff_tensor, p=1, aggregate=np.mean):\n    if False:\n        i = 10\n    'Compute Tsallis regularized exploitability of dist for non-symmetric game.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\\n      assumed to be non-negative. can also be list of (A1 x ... x An) np.arrays\\n    p: float in [0, 1], Tsallis entropy-regularization --> 0 as p --> 0\\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\\n  Returns:\\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\\n  '\n    if np.min(payoff_tensor) < 0.0:\n        raise ValueError('payoff tensor must be non-negative')\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        dist_i = dist[i]\n        if p > 0:\n            power = 1.0 / p\n            s = np.linalg.norm(nabla_i, ord=power)\n            br_i = (nabla_i / np.linalg.norm(nabla_i, ord=power)) ** power\n        else:\n            power = np.inf\n            s = np.linalg.norm(nabla_i, ord=power)\n            br_i = np.zeros_like(dist_i)\n            maxima = nabla_i == s\n            br_i[maxima] = 1.0 / maxima.sum()\n        u_i_br = nabla_i.dot(br_i) + s / (p + 1) * (1 - np.sum(br_i ** (p + 1)))\n        u_i_dist = nabla_i.dot(dist_i) + s / (p + 1) * (1 - np.sum(dist_i ** (p + 1)))\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)",
            "def ate_exploitability(dist, payoff_tensor, p=1, aggregate=np.mean):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Compute Tsallis regularized exploitability of dist for non-symmetric game.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\\n      assumed to be non-negative. can also be list of (A1 x ... x An) np.arrays\\n    p: float in [0, 1], Tsallis entropy-regularization --> 0 as p --> 0\\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\\n  Returns:\\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\\n  '\n    if np.min(payoff_tensor) < 0.0:\n        raise ValueError('payoff tensor must be non-negative')\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        dist_i = dist[i]\n        if p > 0:\n            power = 1.0 / p\n            s = np.linalg.norm(nabla_i, ord=power)\n            br_i = (nabla_i / np.linalg.norm(nabla_i, ord=power)) ** power\n        else:\n            power = np.inf\n            s = np.linalg.norm(nabla_i, ord=power)\n            br_i = np.zeros_like(dist_i)\n            maxima = nabla_i == s\n            br_i[maxima] = 1.0 / maxima.sum()\n        u_i_br = nabla_i.dot(br_i) + s / (p + 1) * (1 - np.sum(br_i ** (p + 1)))\n        u_i_dist = nabla_i.dot(dist_i) + s / (p + 1) * (1 - np.sum(dist_i ** (p + 1)))\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)",
            "def ate_exploitability(dist, payoff_tensor, p=1, aggregate=np.mean):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Compute Tsallis regularized exploitability of dist for non-symmetric game.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\\n      assumed to be non-negative. can also be list of (A1 x ... x An) np.arrays\\n    p: float in [0, 1], Tsallis entropy-regularization --> 0 as p --> 0\\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\\n  Returns:\\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\\n  '\n    if np.min(payoff_tensor) < 0.0:\n        raise ValueError('payoff tensor must be non-negative')\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        dist_i = dist[i]\n        if p > 0:\n            power = 1.0 / p\n            s = np.linalg.norm(nabla_i, ord=power)\n            br_i = (nabla_i / np.linalg.norm(nabla_i, ord=power)) ** power\n        else:\n            power = np.inf\n            s = np.linalg.norm(nabla_i, ord=power)\n            br_i = np.zeros_like(dist_i)\n            maxima = nabla_i == s\n            br_i[maxima] = 1.0 / maxima.sum()\n        u_i_br = nabla_i.dot(br_i) + s / (p + 1) * (1 - np.sum(br_i ** (p + 1)))\n        u_i_dist = nabla_i.dot(dist_i) + s / (p + 1) * (1 - np.sum(dist_i ** (p + 1)))\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)",
            "def ate_exploitability(dist, payoff_tensor, p=1, aggregate=np.mean):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Compute Tsallis regularized exploitability of dist for non-symmetric game.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\\n      assumed to be non-negative. can also be list of (A1 x ... x An) np.arrays\\n    p: float in [0, 1], Tsallis entropy-regularization --> 0 as p --> 0\\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\\n  Returns:\\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\\n  '\n    if np.min(payoff_tensor) < 0.0:\n        raise ValueError('payoff tensor must be non-negative')\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        dist_i = dist[i]\n        if p > 0:\n            power = 1.0 / p\n            s = np.linalg.norm(nabla_i, ord=power)\n            br_i = (nabla_i / np.linalg.norm(nabla_i, ord=power)) ** power\n        else:\n            power = np.inf\n            s = np.linalg.norm(nabla_i, ord=power)\n            br_i = np.zeros_like(dist_i)\n            maxima = nabla_i == s\n            br_i[maxima] = 1.0 / maxima.sum()\n        u_i_br = nabla_i.dot(br_i) + s / (p + 1) * (1 - np.sum(br_i ** (p + 1)))\n        u_i_dist = nabla_i.dot(dist_i) + s / (p + 1) * (1 - np.sum(dist_i ** (p + 1)))\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)",
            "def ate_exploitability(dist, payoff_tensor, p=1, aggregate=np.mean):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Compute Tsallis regularized exploitability of dist for non-symmetric game.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\\n      assumed to be non-negative. can also be list of (A1 x ... x An) np.arrays\\n    p: float in [0, 1], Tsallis entropy-regularization --> 0 as p --> 0\\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\\n  Returns:\\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\\n  '\n    if np.min(payoff_tensor) < 0.0:\n        raise ValueError('payoff tensor must be non-negative')\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        dist_i = dist[i]\n        if p > 0:\n            power = 1.0 / p\n            s = np.linalg.norm(nabla_i, ord=power)\n            br_i = (nabla_i / np.linalg.norm(nabla_i, ord=power)) ** power\n        else:\n            power = np.inf\n            s = np.linalg.norm(nabla_i, ord=power)\n            br_i = np.zeros_like(dist_i)\n            maxima = nabla_i == s\n            br_i[maxima] = 1.0 / maxima.sum()\n        u_i_br = nabla_i.dot(br_i) + s / (p + 1) * (1 - np.sum(br_i ** (p + 1)))\n        u_i_dist = nabla_i.dot(dist_i) + s / (p + 1) * (1 - np.sum(dist_i ** (p + 1)))\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)"
        ]
    },
    {
        "func_name": "qre_exploitability",
        "original": "def qre_exploitability(dist, payoff_tensor, temperature=0.0, aggregate=np.mean):\n    \"\"\"Compute Shannon regularized exploitability of dist for non-symmetric game.\n\n  Args:\n    dist: list of 1-d np.arrays, current estimate of nash distribution\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\n      assumed to be non-negative. can also be list of (A1 x ... x An) np.arrays\n    temperature: non-negative float\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\n  Returns:\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\n  \"\"\"\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        dist_i = dist[i]\n        if temperature > 0:\n            br_i = special.softmax(nabla_i / temperature)\n        else:\n            br_i = np.zeros_like(dist_i)\n            maxima = nabla_i == np.max(nabla_i)\n            br_i[maxima] = 1.0 / maxima.sum()\n        u_i_br = nabla_i.dot(br_i) + temperature * special.entr(br_i).sum()\n        u_i_dist = nabla_i.dot(dist_i) + temperature * special.entr(dist_i).sum()\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)",
        "mutated": [
            "def qre_exploitability(dist, payoff_tensor, temperature=0.0, aggregate=np.mean):\n    if False:\n        i = 10\n    'Compute Shannon regularized exploitability of dist for non-symmetric game.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\\n      assumed to be non-negative. can also be list of (A1 x ... x An) np.arrays\\n    temperature: non-negative float\\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\\n  Returns:\\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\\n  '\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        dist_i = dist[i]\n        if temperature > 0:\n            br_i = special.softmax(nabla_i / temperature)\n        else:\n            br_i = np.zeros_like(dist_i)\n            maxima = nabla_i == np.max(nabla_i)\n            br_i[maxima] = 1.0 / maxima.sum()\n        u_i_br = nabla_i.dot(br_i) + temperature * special.entr(br_i).sum()\n        u_i_dist = nabla_i.dot(dist_i) + temperature * special.entr(dist_i).sum()\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)",
            "def qre_exploitability(dist, payoff_tensor, temperature=0.0, aggregate=np.mean):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Compute Shannon regularized exploitability of dist for non-symmetric game.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\\n      assumed to be non-negative. can also be list of (A1 x ... x An) np.arrays\\n    temperature: non-negative float\\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\\n  Returns:\\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\\n  '\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        dist_i = dist[i]\n        if temperature > 0:\n            br_i = special.softmax(nabla_i / temperature)\n        else:\n            br_i = np.zeros_like(dist_i)\n            maxima = nabla_i == np.max(nabla_i)\n            br_i[maxima] = 1.0 / maxima.sum()\n        u_i_br = nabla_i.dot(br_i) + temperature * special.entr(br_i).sum()\n        u_i_dist = nabla_i.dot(dist_i) + temperature * special.entr(dist_i).sum()\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)",
            "def qre_exploitability(dist, payoff_tensor, temperature=0.0, aggregate=np.mean):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Compute Shannon regularized exploitability of dist for non-symmetric game.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\\n      assumed to be non-negative. can also be list of (A1 x ... x An) np.arrays\\n    temperature: non-negative float\\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\\n  Returns:\\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\\n  '\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        dist_i = dist[i]\n        if temperature > 0:\n            br_i = special.softmax(nabla_i / temperature)\n        else:\n            br_i = np.zeros_like(dist_i)\n            maxima = nabla_i == np.max(nabla_i)\n            br_i[maxima] = 1.0 / maxima.sum()\n        u_i_br = nabla_i.dot(br_i) + temperature * special.entr(br_i).sum()\n        u_i_dist = nabla_i.dot(dist_i) + temperature * special.entr(dist_i).sum()\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)",
            "def qre_exploitability(dist, payoff_tensor, temperature=0.0, aggregate=np.mean):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Compute Shannon regularized exploitability of dist for non-symmetric game.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\\n      assumed to be non-negative. can also be list of (A1 x ... x An) np.arrays\\n    temperature: non-negative float\\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\\n  Returns:\\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\\n  '\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        dist_i = dist[i]\n        if temperature > 0:\n            br_i = special.softmax(nabla_i / temperature)\n        else:\n            br_i = np.zeros_like(dist_i)\n            maxima = nabla_i == np.max(nabla_i)\n            br_i[maxima] = 1.0 / maxima.sum()\n        u_i_br = nabla_i.dot(br_i) + temperature * special.entr(br_i).sum()\n        u_i_dist = nabla_i.dot(dist_i) + temperature * special.entr(dist_i).sum()\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)",
            "def qre_exploitability(dist, payoff_tensor, temperature=0.0, aggregate=np.mean):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Compute Shannon regularized exploitability of dist for non-symmetric game.\\n\\n  Args:\\n    dist: list of 1-d np.arrays, current estimate of nash distribution\\n    payoff_tensor: (n x A1 x ... x An) np.array, payoffs for each joint action\\n      assumed to be non-negative. can also be list of (A1 x ... x An) np.arrays\\n    temperature: non-negative float\\n    aggregate: function to reduce individual exp_is to scalar, e.g., mean or max\\n  Returns:\\n    exploitability (float): avg_i payoff_i of best response_i - payoff_i of dist\\n  '\n    num_players = len(payoff_tensor)\n    exp_i = []\n    for i in range(num_players):\n        nabla_i = misc.pt_reduce(payoff_tensor[i], dist, [i])\n        dist_i = dist[i]\n        if temperature > 0:\n            br_i = special.softmax(nabla_i / temperature)\n        else:\n            br_i = np.zeros_like(dist_i)\n            maxima = nabla_i == np.max(nabla_i)\n            br_i[maxima] = 1.0 / maxima.sum()\n        u_i_br = nabla_i.dot(br_i) + temperature * special.entr(br_i).sum()\n        u_i_dist = nabla_i.dot(dist_i) + temperature * special.entr(dist_i).sum()\n        exp_i.append(u_i_br - u_i_dist)\n    return aggregate(exp_i)"
        ]
    }
]