[
    {
        "func_name": "__init__",
        "original": "def __init__(self, *, model_size: Optional[str]='XS', cnn_multiplier: Optional[int]=None, gray_scaled: bool):\n    \"\"\"Initializes a ConvTransposeAtari instance.\n\n        Args:\n            model_size: The \"Model Size\" used according to [1] Appendinx B.\n                Use None for manually setting the `cnn_multiplier`.\n            cnn_multiplier: Optional override for the additional factor used to multiply\n                the number of filters with each CNN transpose layer. Starting with\n                8 * `cnn_multiplier` filters in the first CNN transpose layer, the\n                number of filters then decreases via `4*cnn_multiplier`,\n                `2*cnn_multiplier`, till `1*cnn_multiplier`.\n            gray_scaled: Whether the last Conv2DTranspose layer's output has only 1\n                color channel (gray_scaled=True) or 3 RGB channels (gray_scaled=False).\n        \"\"\"\n    super().__init__(name='image_decoder')\n    self.model_size = model_size\n    cnn_multiplier = get_cnn_multiplier(self.model_size, override=cnn_multiplier)\n    self.input_dims = (4, 4, 8 * cnn_multiplier)\n    self.gray_scaled = gray_scaled\n    self.dense_layer = tf.keras.layers.Dense(units=int(np.prod(self.input_dims)), activation=None, use_bias=True)\n    self.conv_transpose_layers = [tf.keras.layers.Conv2DTranspose(filters=4 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False), tf.keras.layers.Conv2DTranspose(filters=2 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False), tf.keras.layers.Conv2DTranspose(filters=1 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False)]\n    self.layer_normalizations = []\n    for _ in range(len(self.conv_transpose_layers)):\n        self.layer_normalizations.append(tf.keras.layers.LayerNormalization())\n    self.output_conv2d_transpose = tf.keras.layers.Conv2DTranspose(filters=1 if self.gray_scaled else 3, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=True)\n    dl_type = tf.keras.mixed_precision.global_policy().compute_dtype or tf.float32\n    self.call = tf.function(input_signature=[tf.TensorSpec(shape=[None, get_gru_units(model_size)], dtype=dl_type), tf.TensorSpec(shape=[None, get_num_z_categoricals(model_size), get_num_z_classes(model_size)], dtype=dl_type)])(self.call)",
        "mutated": [
            "def __init__(self, *, model_size: Optional[str]='XS', cnn_multiplier: Optional[int]=None, gray_scaled: bool):\n    if False:\n        i = 10\n    'Initializes a ConvTransposeAtari instance.\\n\\n        Args:\\n            model_size: The \"Model Size\" used according to [1] Appendinx B.\\n                Use None for manually setting the `cnn_multiplier`.\\n            cnn_multiplier: Optional override for the additional factor used to multiply\\n                the number of filters with each CNN transpose layer. Starting with\\n                8 * `cnn_multiplier` filters in the first CNN transpose layer, the\\n                number of filters then decreases via `4*cnn_multiplier`,\\n                `2*cnn_multiplier`, till `1*cnn_multiplier`.\\n            gray_scaled: Whether the last Conv2DTranspose layer\\'s output has only 1\\n                color channel (gray_scaled=True) or 3 RGB channels (gray_scaled=False).\\n        '\n    super().__init__(name='image_decoder')\n    self.model_size = model_size\n    cnn_multiplier = get_cnn_multiplier(self.model_size, override=cnn_multiplier)\n    self.input_dims = (4, 4, 8 * cnn_multiplier)\n    self.gray_scaled = gray_scaled\n    self.dense_layer = tf.keras.layers.Dense(units=int(np.prod(self.input_dims)), activation=None, use_bias=True)\n    self.conv_transpose_layers = [tf.keras.layers.Conv2DTranspose(filters=4 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False), tf.keras.layers.Conv2DTranspose(filters=2 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False), tf.keras.layers.Conv2DTranspose(filters=1 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False)]\n    self.layer_normalizations = []\n    for _ in range(len(self.conv_transpose_layers)):\n        self.layer_normalizations.append(tf.keras.layers.LayerNormalization())\n    self.output_conv2d_transpose = tf.keras.layers.Conv2DTranspose(filters=1 if self.gray_scaled else 3, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=True)\n    dl_type = tf.keras.mixed_precision.global_policy().compute_dtype or tf.float32\n    self.call = tf.function(input_signature=[tf.TensorSpec(shape=[None, get_gru_units(model_size)], dtype=dl_type), tf.TensorSpec(shape=[None, get_num_z_categoricals(model_size), get_num_z_classes(model_size)], dtype=dl_type)])(self.call)",
            "def __init__(self, *, model_size: Optional[str]='XS', cnn_multiplier: Optional[int]=None, gray_scaled: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Initializes a ConvTransposeAtari instance.\\n\\n        Args:\\n            model_size: The \"Model Size\" used according to [1] Appendinx B.\\n                Use None for manually setting the `cnn_multiplier`.\\n            cnn_multiplier: Optional override for the additional factor used to multiply\\n                the number of filters with each CNN transpose layer. Starting with\\n                8 * `cnn_multiplier` filters in the first CNN transpose layer, the\\n                number of filters then decreases via `4*cnn_multiplier`,\\n                `2*cnn_multiplier`, till `1*cnn_multiplier`.\\n            gray_scaled: Whether the last Conv2DTranspose layer\\'s output has only 1\\n                color channel (gray_scaled=True) or 3 RGB channels (gray_scaled=False).\\n        '\n    super().__init__(name='image_decoder')\n    self.model_size = model_size\n    cnn_multiplier = get_cnn_multiplier(self.model_size, override=cnn_multiplier)\n    self.input_dims = (4, 4, 8 * cnn_multiplier)\n    self.gray_scaled = gray_scaled\n    self.dense_layer = tf.keras.layers.Dense(units=int(np.prod(self.input_dims)), activation=None, use_bias=True)\n    self.conv_transpose_layers = [tf.keras.layers.Conv2DTranspose(filters=4 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False), tf.keras.layers.Conv2DTranspose(filters=2 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False), tf.keras.layers.Conv2DTranspose(filters=1 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False)]\n    self.layer_normalizations = []\n    for _ in range(len(self.conv_transpose_layers)):\n        self.layer_normalizations.append(tf.keras.layers.LayerNormalization())\n    self.output_conv2d_transpose = tf.keras.layers.Conv2DTranspose(filters=1 if self.gray_scaled else 3, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=True)\n    dl_type = tf.keras.mixed_precision.global_policy().compute_dtype or tf.float32\n    self.call = tf.function(input_signature=[tf.TensorSpec(shape=[None, get_gru_units(model_size)], dtype=dl_type), tf.TensorSpec(shape=[None, get_num_z_categoricals(model_size), get_num_z_classes(model_size)], dtype=dl_type)])(self.call)",
            "def __init__(self, *, model_size: Optional[str]='XS', cnn_multiplier: Optional[int]=None, gray_scaled: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Initializes a ConvTransposeAtari instance.\\n\\n        Args:\\n            model_size: The \"Model Size\" used according to [1] Appendinx B.\\n                Use None for manually setting the `cnn_multiplier`.\\n            cnn_multiplier: Optional override for the additional factor used to multiply\\n                the number of filters with each CNN transpose layer. Starting with\\n                8 * `cnn_multiplier` filters in the first CNN transpose layer, the\\n                number of filters then decreases via `4*cnn_multiplier`,\\n                `2*cnn_multiplier`, till `1*cnn_multiplier`.\\n            gray_scaled: Whether the last Conv2DTranspose layer\\'s output has only 1\\n                color channel (gray_scaled=True) or 3 RGB channels (gray_scaled=False).\\n        '\n    super().__init__(name='image_decoder')\n    self.model_size = model_size\n    cnn_multiplier = get_cnn_multiplier(self.model_size, override=cnn_multiplier)\n    self.input_dims = (4, 4, 8 * cnn_multiplier)\n    self.gray_scaled = gray_scaled\n    self.dense_layer = tf.keras.layers.Dense(units=int(np.prod(self.input_dims)), activation=None, use_bias=True)\n    self.conv_transpose_layers = [tf.keras.layers.Conv2DTranspose(filters=4 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False), tf.keras.layers.Conv2DTranspose(filters=2 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False), tf.keras.layers.Conv2DTranspose(filters=1 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False)]\n    self.layer_normalizations = []\n    for _ in range(len(self.conv_transpose_layers)):\n        self.layer_normalizations.append(tf.keras.layers.LayerNormalization())\n    self.output_conv2d_transpose = tf.keras.layers.Conv2DTranspose(filters=1 if self.gray_scaled else 3, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=True)\n    dl_type = tf.keras.mixed_precision.global_policy().compute_dtype or tf.float32\n    self.call = tf.function(input_signature=[tf.TensorSpec(shape=[None, get_gru_units(model_size)], dtype=dl_type), tf.TensorSpec(shape=[None, get_num_z_categoricals(model_size), get_num_z_classes(model_size)], dtype=dl_type)])(self.call)",
            "def __init__(self, *, model_size: Optional[str]='XS', cnn_multiplier: Optional[int]=None, gray_scaled: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Initializes a ConvTransposeAtari instance.\\n\\n        Args:\\n            model_size: The \"Model Size\" used according to [1] Appendinx B.\\n                Use None for manually setting the `cnn_multiplier`.\\n            cnn_multiplier: Optional override for the additional factor used to multiply\\n                the number of filters with each CNN transpose layer. Starting with\\n                8 * `cnn_multiplier` filters in the first CNN transpose layer, the\\n                number of filters then decreases via `4*cnn_multiplier`,\\n                `2*cnn_multiplier`, till `1*cnn_multiplier`.\\n            gray_scaled: Whether the last Conv2DTranspose layer\\'s output has only 1\\n                color channel (gray_scaled=True) or 3 RGB channels (gray_scaled=False).\\n        '\n    super().__init__(name='image_decoder')\n    self.model_size = model_size\n    cnn_multiplier = get_cnn_multiplier(self.model_size, override=cnn_multiplier)\n    self.input_dims = (4, 4, 8 * cnn_multiplier)\n    self.gray_scaled = gray_scaled\n    self.dense_layer = tf.keras.layers.Dense(units=int(np.prod(self.input_dims)), activation=None, use_bias=True)\n    self.conv_transpose_layers = [tf.keras.layers.Conv2DTranspose(filters=4 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False), tf.keras.layers.Conv2DTranspose(filters=2 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False), tf.keras.layers.Conv2DTranspose(filters=1 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False)]\n    self.layer_normalizations = []\n    for _ in range(len(self.conv_transpose_layers)):\n        self.layer_normalizations.append(tf.keras.layers.LayerNormalization())\n    self.output_conv2d_transpose = tf.keras.layers.Conv2DTranspose(filters=1 if self.gray_scaled else 3, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=True)\n    dl_type = tf.keras.mixed_precision.global_policy().compute_dtype or tf.float32\n    self.call = tf.function(input_signature=[tf.TensorSpec(shape=[None, get_gru_units(model_size)], dtype=dl_type), tf.TensorSpec(shape=[None, get_num_z_categoricals(model_size), get_num_z_classes(model_size)], dtype=dl_type)])(self.call)",
            "def __init__(self, *, model_size: Optional[str]='XS', cnn_multiplier: Optional[int]=None, gray_scaled: bool):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Initializes a ConvTransposeAtari instance.\\n\\n        Args:\\n            model_size: The \"Model Size\" used according to [1] Appendinx B.\\n                Use None for manually setting the `cnn_multiplier`.\\n            cnn_multiplier: Optional override for the additional factor used to multiply\\n                the number of filters with each CNN transpose layer. Starting with\\n                8 * `cnn_multiplier` filters in the first CNN transpose layer, the\\n                number of filters then decreases via `4*cnn_multiplier`,\\n                `2*cnn_multiplier`, till `1*cnn_multiplier`.\\n            gray_scaled: Whether the last Conv2DTranspose layer\\'s output has only 1\\n                color channel (gray_scaled=True) or 3 RGB channels (gray_scaled=False).\\n        '\n    super().__init__(name='image_decoder')\n    self.model_size = model_size\n    cnn_multiplier = get_cnn_multiplier(self.model_size, override=cnn_multiplier)\n    self.input_dims = (4, 4, 8 * cnn_multiplier)\n    self.gray_scaled = gray_scaled\n    self.dense_layer = tf.keras.layers.Dense(units=int(np.prod(self.input_dims)), activation=None, use_bias=True)\n    self.conv_transpose_layers = [tf.keras.layers.Conv2DTranspose(filters=4 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False), tf.keras.layers.Conv2DTranspose(filters=2 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False), tf.keras.layers.Conv2DTranspose(filters=1 * cnn_multiplier, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=False)]\n    self.layer_normalizations = []\n    for _ in range(len(self.conv_transpose_layers)):\n        self.layer_normalizations.append(tf.keras.layers.LayerNormalization())\n    self.output_conv2d_transpose = tf.keras.layers.Conv2DTranspose(filters=1 if self.gray_scaled else 3, kernel_size=4, strides=(2, 2), padding='same', activation=None, use_bias=True)\n    dl_type = tf.keras.mixed_precision.global_policy().compute_dtype or tf.float32\n    self.call = tf.function(input_signature=[tf.TensorSpec(shape=[None, get_gru_units(model_size)], dtype=dl_type), tf.TensorSpec(shape=[None, get_num_z_categoricals(model_size), get_num_z_classes(model_size)], dtype=dl_type)])(self.call)"
        ]
    },
    {
        "func_name": "call",
        "original": "def call(self, h, z):\n    \"\"\"Performs a forward pass through the Conv2D transpose decoder.\n\n        Args:\n            h: The deterministic hidden state of the sequence model.\n            z: The sequence of stochastic discrete representations of the original\n                observation input. Note: `z` is not used for the dynamics predictor\n                model (which predicts z from h).\n        \"\"\"\n    assert len(z.shape) == 3\n    z_shape = tf.shape(z)\n    z = tf.reshape(z, shape=(z_shape[0], -1))\n    assert len(z.shape) == 2\n    input_ = tf.concat([h, z], axis=-1)\n    input_.set_shape([None, get_num_z_categoricals(self.model_size) * get_num_z_classes(self.model_size) + get_gru_units(self.model_size)])\n    out = self.dense_layer(input_)\n    out = tf.reshape(out, shape=(-1,) + self.input_dims)\n    for (conv_transpose_2d, layer_norm) in zip(self.conv_transpose_layers, self.layer_normalizations):\n        out = tf.nn.silu(layer_norm(inputs=conv_transpose_2d(out)))\n    out = self.output_conv2d_transpose(out)\n    out += 0.5\n    out_shape = tf.shape(out)\n    loc = tf.reshape(out, shape=(out_shape[0], -1))\n    return loc",
        "mutated": [
            "def call(self, h, z):\n    if False:\n        i = 10\n    'Performs a forward pass through the Conv2D transpose decoder.\\n\\n        Args:\\n            h: The deterministic hidden state of the sequence model.\\n            z: The sequence of stochastic discrete representations of the original\\n                observation input. Note: `z` is not used for the dynamics predictor\\n                model (which predicts z from h).\\n        '\n    assert len(z.shape) == 3\n    z_shape = tf.shape(z)\n    z = tf.reshape(z, shape=(z_shape[0], -1))\n    assert len(z.shape) == 2\n    input_ = tf.concat([h, z], axis=-1)\n    input_.set_shape([None, get_num_z_categoricals(self.model_size) * get_num_z_classes(self.model_size) + get_gru_units(self.model_size)])\n    out = self.dense_layer(input_)\n    out = tf.reshape(out, shape=(-1,) + self.input_dims)\n    for (conv_transpose_2d, layer_norm) in zip(self.conv_transpose_layers, self.layer_normalizations):\n        out = tf.nn.silu(layer_norm(inputs=conv_transpose_2d(out)))\n    out = self.output_conv2d_transpose(out)\n    out += 0.5\n    out_shape = tf.shape(out)\n    loc = tf.reshape(out, shape=(out_shape[0], -1))\n    return loc",
            "def call(self, h, z):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Performs a forward pass through the Conv2D transpose decoder.\\n\\n        Args:\\n            h: The deterministic hidden state of the sequence model.\\n            z: The sequence of stochastic discrete representations of the original\\n                observation input. Note: `z` is not used for the dynamics predictor\\n                model (which predicts z from h).\\n        '\n    assert len(z.shape) == 3\n    z_shape = tf.shape(z)\n    z = tf.reshape(z, shape=(z_shape[0], -1))\n    assert len(z.shape) == 2\n    input_ = tf.concat([h, z], axis=-1)\n    input_.set_shape([None, get_num_z_categoricals(self.model_size) * get_num_z_classes(self.model_size) + get_gru_units(self.model_size)])\n    out = self.dense_layer(input_)\n    out = tf.reshape(out, shape=(-1,) + self.input_dims)\n    for (conv_transpose_2d, layer_norm) in zip(self.conv_transpose_layers, self.layer_normalizations):\n        out = tf.nn.silu(layer_norm(inputs=conv_transpose_2d(out)))\n    out = self.output_conv2d_transpose(out)\n    out += 0.5\n    out_shape = tf.shape(out)\n    loc = tf.reshape(out, shape=(out_shape[0], -1))\n    return loc",
            "def call(self, h, z):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Performs a forward pass through the Conv2D transpose decoder.\\n\\n        Args:\\n            h: The deterministic hidden state of the sequence model.\\n            z: The sequence of stochastic discrete representations of the original\\n                observation input. Note: `z` is not used for the dynamics predictor\\n                model (which predicts z from h).\\n        '\n    assert len(z.shape) == 3\n    z_shape = tf.shape(z)\n    z = tf.reshape(z, shape=(z_shape[0], -1))\n    assert len(z.shape) == 2\n    input_ = tf.concat([h, z], axis=-1)\n    input_.set_shape([None, get_num_z_categoricals(self.model_size) * get_num_z_classes(self.model_size) + get_gru_units(self.model_size)])\n    out = self.dense_layer(input_)\n    out = tf.reshape(out, shape=(-1,) + self.input_dims)\n    for (conv_transpose_2d, layer_norm) in zip(self.conv_transpose_layers, self.layer_normalizations):\n        out = tf.nn.silu(layer_norm(inputs=conv_transpose_2d(out)))\n    out = self.output_conv2d_transpose(out)\n    out += 0.5\n    out_shape = tf.shape(out)\n    loc = tf.reshape(out, shape=(out_shape[0], -1))\n    return loc",
            "def call(self, h, z):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Performs a forward pass through the Conv2D transpose decoder.\\n\\n        Args:\\n            h: The deterministic hidden state of the sequence model.\\n            z: The sequence of stochastic discrete representations of the original\\n                observation input. Note: `z` is not used for the dynamics predictor\\n                model (which predicts z from h).\\n        '\n    assert len(z.shape) == 3\n    z_shape = tf.shape(z)\n    z = tf.reshape(z, shape=(z_shape[0], -1))\n    assert len(z.shape) == 2\n    input_ = tf.concat([h, z], axis=-1)\n    input_.set_shape([None, get_num_z_categoricals(self.model_size) * get_num_z_classes(self.model_size) + get_gru_units(self.model_size)])\n    out = self.dense_layer(input_)\n    out = tf.reshape(out, shape=(-1,) + self.input_dims)\n    for (conv_transpose_2d, layer_norm) in zip(self.conv_transpose_layers, self.layer_normalizations):\n        out = tf.nn.silu(layer_norm(inputs=conv_transpose_2d(out)))\n    out = self.output_conv2d_transpose(out)\n    out += 0.5\n    out_shape = tf.shape(out)\n    loc = tf.reshape(out, shape=(out_shape[0], -1))\n    return loc",
            "def call(self, h, z):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Performs a forward pass through the Conv2D transpose decoder.\\n\\n        Args:\\n            h: The deterministic hidden state of the sequence model.\\n            z: The sequence of stochastic discrete representations of the original\\n                observation input. Note: `z` is not used for the dynamics predictor\\n                model (which predicts z from h).\\n        '\n    assert len(z.shape) == 3\n    z_shape = tf.shape(z)\n    z = tf.reshape(z, shape=(z_shape[0], -1))\n    assert len(z.shape) == 2\n    input_ = tf.concat([h, z], axis=-1)\n    input_.set_shape([None, get_num_z_categoricals(self.model_size) * get_num_z_classes(self.model_size) + get_gru_units(self.model_size)])\n    out = self.dense_layer(input_)\n    out = tf.reshape(out, shape=(-1,) + self.input_dims)\n    for (conv_transpose_2d, layer_norm) in zip(self.conv_transpose_layers, self.layer_normalizations):\n        out = tf.nn.silu(layer_norm(inputs=conv_transpose_2d(out)))\n    out = self.output_conv2d_transpose(out)\n    out += 0.5\n    out_shape = tf.shape(out)\n    loc = tf.reshape(out, shape=(out_shape[0], -1))\n    return loc"
        ]
    }
]