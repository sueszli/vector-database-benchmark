[
    {
        "func_name": "__init__",
        "original": "def __init__(self, in_channel, num_convs=3, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), act_cfg=dict(type='ReLU'), init_cfg=None):\n    super().__init__(init_cfg=init_cfg)\n    conv_channels = [in_channel for _ in range(num_convs - 1)]\n    conv_channels.append(1)\n    self.mlp = nn.Sequential()\n    prev_channels = in_channel\n    for i in range(num_convs):\n        self.mlp.add_module(f'layer{i}', ConvModule(prev_channels, conv_channels[i], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg if i < num_convs - 1 else None, act_cfg=act_cfg if i < num_convs - 1 else None, bias=True, inplace=True))\n        prev_channels = conv_channels[i]",
        "mutated": [
            "def __init__(self, in_channel, num_convs=3, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), act_cfg=dict(type='ReLU'), init_cfg=None):\n    if False:\n        i = 10\n    super().__init__(init_cfg=init_cfg)\n    conv_channels = [in_channel for _ in range(num_convs - 1)]\n    conv_channels.append(1)\n    self.mlp = nn.Sequential()\n    prev_channels = in_channel\n    for i in range(num_convs):\n        self.mlp.add_module(f'layer{i}', ConvModule(prev_channels, conv_channels[i], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg if i < num_convs - 1 else None, act_cfg=act_cfg if i < num_convs - 1 else None, bias=True, inplace=True))\n        prev_channels = conv_channels[i]",
            "def __init__(self, in_channel, num_convs=3, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), act_cfg=dict(type='ReLU'), init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super().__init__(init_cfg=init_cfg)\n    conv_channels = [in_channel for _ in range(num_convs - 1)]\n    conv_channels.append(1)\n    self.mlp = nn.Sequential()\n    prev_channels = in_channel\n    for i in range(num_convs):\n        self.mlp.add_module(f'layer{i}', ConvModule(prev_channels, conv_channels[i], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg if i < num_convs - 1 else None, act_cfg=act_cfg if i < num_convs - 1 else None, bias=True, inplace=True))\n        prev_channels = conv_channels[i]",
            "def __init__(self, in_channel, num_convs=3, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), act_cfg=dict(type='ReLU'), init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super().__init__(init_cfg=init_cfg)\n    conv_channels = [in_channel for _ in range(num_convs - 1)]\n    conv_channels.append(1)\n    self.mlp = nn.Sequential()\n    prev_channels = in_channel\n    for i in range(num_convs):\n        self.mlp.add_module(f'layer{i}', ConvModule(prev_channels, conv_channels[i], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg if i < num_convs - 1 else None, act_cfg=act_cfg if i < num_convs - 1 else None, bias=True, inplace=True))\n        prev_channels = conv_channels[i]",
            "def __init__(self, in_channel, num_convs=3, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), act_cfg=dict(type='ReLU'), init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super().__init__(init_cfg=init_cfg)\n    conv_channels = [in_channel for _ in range(num_convs - 1)]\n    conv_channels.append(1)\n    self.mlp = nn.Sequential()\n    prev_channels = in_channel\n    for i in range(num_convs):\n        self.mlp.add_module(f'layer{i}', ConvModule(prev_channels, conv_channels[i], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg if i < num_convs - 1 else None, act_cfg=act_cfg if i < num_convs - 1 else None, bias=True, inplace=True))\n        prev_channels = conv_channels[i]",
            "def __init__(self, in_channel, num_convs=3, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), act_cfg=dict(type='ReLU'), init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super().__init__(init_cfg=init_cfg)\n    conv_channels = [in_channel for _ in range(num_convs - 1)]\n    conv_channels.append(1)\n    self.mlp = nn.Sequential()\n    prev_channels = in_channel\n    for i in range(num_convs):\n        self.mlp.add_module(f'layer{i}', ConvModule(prev_channels, conv_channels[i], 1, padding=0, conv_cfg=conv_cfg, norm_cfg=norm_cfg if i < num_convs - 1 else None, act_cfg=act_cfg if i < num_convs - 1 else None, bias=True, inplace=True))\n        prev_channels = conv_channels[i]"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, seed_features):\n    \"\"\"Forward pass.\n\n        Args:\n            seed_features (torch.Tensor): seed features, dims:\n                (batch_size, feature_dim, num_seed)\n\n        Returns:\n            torch.Tensor: objectness logits, dim:\n                (batch_size, 1, num_seed)\n        \"\"\"\n    return self.mlp(seed_features)",
        "mutated": [
            "def forward(self, seed_features):\n    if False:\n        i = 10\n    'Forward pass.\\n\\n        Args:\\n            seed_features (torch.Tensor): seed features, dims:\\n                (batch_size, feature_dim, num_seed)\\n\\n        Returns:\\n            torch.Tensor: objectness logits, dim:\\n                (batch_size, 1, num_seed)\\n        '\n    return self.mlp(seed_features)",
            "def forward(self, seed_features):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Forward pass.\\n\\n        Args:\\n            seed_features (torch.Tensor): seed features, dims:\\n                (batch_size, feature_dim, num_seed)\\n\\n        Returns:\\n            torch.Tensor: objectness logits, dim:\\n                (batch_size, 1, num_seed)\\n        '\n    return self.mlp(seed_features)",
            "def forward(self, seed_features):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Forward pass.\\n\\n        Args:\\n            seed_features (torch.Tensor): seed features, dims:\\n                (batch_size, feature_dim, num_seed)\\n\\n        Returns:\\n            torch.Tensor: objectness logits, dim:\\n                (batch_size, 1, num_seed)\\n        '\n    return self.mlp(seed_features)",
            "def forward(self, seed_features):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Forward pass.\\n\\n        Args:\\n            seed_features (torch.Tensor): seed features, dims:\\n                (batch_size, feature_dim, num_seed)\\n\\n        Returns:\\n            torch.Tensor: objectness logits, dim:\\n                (batch_size, 1, num_seed)\\n        '\n    return self.mlp(seed_features)",
            "def forward(self, seed_features):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Forward pass.\\n\\n        Args:\\n            seed_features (torch.Tensor): seed features, dims:\\n                (batch_size, feature_dim, num_seed)\\n\\n        Returns:\\n            torch.Tensor: objectness logits, dim:\\n                (batch_size, 1, num_seed)\\n        '\n    return self.mlp(seed_features)"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, xyz, features, sample_inds):\n    \"\"\"Forward pass.\n\n        Args:\n            xyz\uff1a (B, N, 3) the coordinates of the features.\n            features (Tensor): (B, C, N) features to sample.\n            sample_inds (Tensor): (B, M) the given index,\n                where M is the number of points.\n\n        Returns:\n            Tensor: (B, M, 3) coordinates of sampled features\n            Tensor: (B, C, M) the sampled features.\n            Tensor: (B, M) the given index.\n        \"\"\"\n    xyz_t = xyz.transpose(1, 2).contiguous()\n    new_xyz = gather_points(xyz_t, sample_inds).transpose(1, 2).contiguous()\n    new_features = gather_points(features, sample_inds).contiguous()\n    return (new_xyz, new_features, sample_inds)",
        "mutated": [
            "def forward(self, xyz, features, sample_inds):\n    if False:\n        i = 10\n    'Forward pass.\\n\\n        Args:\\n            xyz\uff1a (B, N, 3) the coordinates of the features.\\n            features (Tensor): (B, C, N) features to sample.\\n            sample_inds (Tensor): (B, M) the given index,\\n                where M is the number of points.\\n\\n        Returns:\\n            Tensor: (B, M, 3) coordinates of sampled features\\n            Tensor: (B, C, M) the sampled features.\\n            Tensor: (B, M) the given index.\\n        '\n    xyz_t = xyz.transpose(1, 2).contiguous()\n    new_xyz = gather_points(xyz_t, sample_inds).transpose(1, 2).contiguous()\n    new_features = gather_points(features, sample_inds).contiguous()\n    return (new_xyz, new_features, sample_inds)",
            "def forward(self, xyz, features, sample_inds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Forward pass.\\n\\n        Args:\\n            xyz\uff1a (B, N, 3) the coordinates of the features.\\n            features (Tensor): (B, C, N) features to sample.\\n            sample_inds (Tensor): (B, M) the given index,\\n                where M is the number of points.\\n\\n        Returns:\\n            Tensor: (B, M, 3) coordinates of sampled features\\n            Tensor: (B, C, M) the sampled features.\\n            Tensor: (B, M) the given index.\\n        '\n    xyz_t = xyz.transpose(1, 2).contiguous()\n    new_xyz = gather_points(xyz_t, sample_inds).transpose(1, 2).contiguous()\n    new_features = gather_points(features, sample_inds).contiguous()\n    return (new_xyz, new_features, sample_inds)",
            "def forward(self, xyz, features, sample_inds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Forward pass.\\n\\n        Args:\\n            xyz\uff1a (B, N, 3) the coordinates of the features.\\n            features (Tensor): (B, C, N) features to sample.\\n            sample_inds (Tensor): (B, M) the given index,\\n                where M is the number of points.\\n\\n        Returns:\\n            Tensor: (B, M, 3) coordinates of sampled features\\n            Tensor: (B, C, M) the sampled features.\\n            Tensor: (B, M) the given index.\\n        '\n    xyz_t = xyz.transpose(1, 2).contiguous()\n    new_xyz = gather_points(xyz_t, sample_inds).transpose(1, 2).contiguous()\n    new_features = gather_points(features, sample_inds).contiguous()\n    return (new_xyz, new_features, sample_inds)",
            "def forward(self, xyz, features, sample_inds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Forward pass.\\n\\n        Args:\\n            xyz\uff1a (B, N, 3) the coordinates of the features.\\n            features (Tensor): (B, C, N) features to sample.\\n            sample_inds (Tensor): (B, M) the given index,\\n                where M is the number of points.\\n\\n        Returns:\\n            Tensor: (B, M, 3) coordinates of sampled features\\n            Tensor: (B, C, M) the sampled features.\\n            Tensor: (B, M) the given index.\\n        '\n    xyz_t = xyz.transpose(1, 2).contiguous()\n    new_xyz = gather_points(xyz_t, sample_inds).transpose(1, 2).contiguous()\n    new_features = gather_points(features, sample_inds).contiguous()\n    return (new_xyz, new_features, sample_inds)",
            "def forward(self, xyz, features, sample_inds):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Forward pass.\\n\\n        Args:\\n            xyz\uff1a (B, N, 3) the coordinates of the features.\\n            features (Tensor): (B, C, N) features to sample.\\n            sample_inds (Tensor): (B, M) the given index,\\n                where M is the number of points.\\n\\n        Returns:\\n            Tensor: (B, M, 3) coordinates of sampled features\\n            Tensor: (B, C, M) the sampled features.\\n            Tensor: (B, M) the given index.\\n        '\n    xyz_t = xyz.transpose(1, 2).contiguous()\n    new_xyz = gather_points(xyz_t, sample_inds).transpose(1, 2).contiguous()\n    new_features = gather_points(features, sample_inds).contiguous()\n    return (new_xyz, new_features, sample_inds)"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, num_classes, in_channels, bbox_coder, num_decoder_layers, transformerlayers, decoder_self_posembeds=dict(type='ConvBNPositionalEncoding', input_channel=6, num_pos_feats=288), decoder_cross_posembeds=dict(type='ConvBNPositionalEncoding', input_channel=3, num_pos_feats=288), train_cfg=None, test_cfg=None, num_proposal=128, pred_layer_cfg=None, size_cls_agnostic=True, gt_per_seed=3, sampling_objectness_loss=None, objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, size_reg_loss=None, semantic_loss=None, init_cfg=None):\n    super(GroupFree3DHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.num_proposal = num_proposal\n    self.in_channels = in_channels\n    self.num_decoder_layers = num_decoder_layers\n    self.size_cls_agnostic = size_cls_agnostic\n    self.gt_per_seed = gt_per_seed\n    if isinstance(transformerlayers, ConfigDict):\n        transformerlayers = [copy.deepcopy(transformerlayers) for _ in range(num_decoder_layers)]\n    else:\n        assert isinstance(transformerlayers, list) and len(transformerlayers) == num_decoder_layers\n    self.decoder_layers = nn.ModuleList()\n    for i in range(self.num_decoder_layers):\n        self.decoder_layers.append(build_transformer_layer(transformerlayers[i]))\n    self.embed_dims = self.decoder_layers[0].embed_dims\n    assert self.embed_dims == decoder_self_posembeds['num_pos_feats']\n    assert self.embed_dims == decoder_cross_posembeds['num_pos_feats']\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.gsample_module = GeneralSamplingModule()\n    self.fps_module = Points_Sampler([self.num_proposal])\n    self.points_obj_cls = PointsObjClsModule(self.in_channels)\n    self.fp16_enabled = False\n    self.conv_pred = BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels())\n    self.decoder_query_proj = nn.Conv1d(self.embed_dims, self.embed_dims, kernel_size=1)\n    self.decoder_key_proj = nn.Conv1d(self.embed_dims, self.embed_dims, kernel_size=1)\n    self.decoder_self_posembeds = nn.ModuleList()\n    for _ in range(self.num_decoder_layers):\n        self.decoder_self_posembeds.append(build_positional_encoding(decoder_self_posembeds))\n    self.decoder_cross_posembeds = nn.ModuleList()\n    for _ in range(self.num_decoder_layers):\n        self.decoder_cross_posembeds.append(build_positional_encoding(decoder_cross_posembeds))\n    self.prediction_heads = nn.ModuleList()\n    for i in range(self.num_decoder_layers):\n        self.prediction_heads.append(BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels()))\n    self.sampling_objectness_loss = build_loss(sampling_objectness_loss)\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.semantic_loss = build_loss(semantic_loss)\n    if self.size_cls_agnostic:\n        self.size_reg_loss = build_loss(size_reg_loss)\n    else:\n        self.size_res_loss = build_loss(size_res_loss)\n        self.size_class_loss = build_loss(size_class_loss)",
        "mutated": [
            "def __init__(self, num_classes, in_channels, bbox_coder, num_decoder_layers, transformerlayers, decoder_self_posembeds=dict(type='ConvBNPositionalEncoding', input_channel=6, num_pos_feats=288), decoder_cross_posembeds=dict(type='ConvBNPositionalEncoding', input_channel=3, num_pos_feats=288), train_cfg=None, test_cfg=None, num_proposal=128, pred_layer_cfg=None, size_cls_agnostic=True, gt_per_seed=3, sampling_objectness_loss=None, objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, size_reg_loss=None, semantic_loss=None, init_cfg=None):\n    if False:\n        i = 10\n    super(GroupFree3DHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.num_proposal = num_proposal\n    self.in_channels = in_channels\n    self.num_decoder_layers = num_decoder_layers\n    self.size_cls_agnostic = size_cls_agnostic\n    self.gt_per_seed = gt_per_seed\n    if isinstance(transformerlayers, ConfigDict):\n        transformerlayers = [copy.deepcopy(transformerlayers) for _ in range(num_decoder_layers)]\n    else:\n        assert isinstance(transformerlayers, list) and len(transformerlayers) == num_decoder_layers\n    self.decoder_layers = nn.ModuleList()\n    for i in range(self.num_decoder_layers):\n        self.decoder_layers.append(build_transformer_layer(transformerlayers[i]))\n    self.embed_dims = self.decoder_layers[0].embed_dims\n    assert self.embed_dims == decoder_self_posembeds['num_pos_feats']\n    assert self.embed_dims == decoder_cross_posembeds['num_pos_feats']\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.gsample_module = GeneralSamplingModule()\n    self.fps_module = Points_Sampler([self.num_proposal])\n    self.points_obj_cls = PointsObjClsModule(self.in_channels)\n    self.fp16_enabled = False\n    self.conv_pred = BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels())\n    self.decoder_query_proj = nn.Conv1d(self.embed_dims, self.embed_dims, kernel_size=1)\n    self.decoder_key_proj = nn.Conv1d(self.embed_dims, self.embed_dims, kernel_size=1)\n    self.decoder_self_posembeds = nn.ModuleList()\n    for _ in range(self.num_decoder_layers):\n        self.decoder_self_posembeds.append(build_positional_encoding(decoder_self_posembeds))\n    self.decoder_cross_posembeds = nn.ModuleList()\n    for _ in range(self.num_decoder_layers):\n        self.decoder_cross_posembeds.append(build_positional_encoding(decoder_cross_posembeds))\n    self.prediction_heads = nn.ModuleList()\n    for i in range(self.num_decoder_layers):\n        self.prediction_heads.append(BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels()))\n    self.sampling_objectness_loss = build_loss(sampling_objectness_loss)\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.semantic_loss = build_loss(semantic_loss)\n    if self.size_cls_agnostic:\n        self.size_reg_loss = build_loss(size_reg_loss)\n    else:\n        self.size_res_loss = build_loss(size_res_loss)\n        self.size_class_loss = build_loss(size_class_loss)",
            "def __init__(self, num_classes, in_channels, bbox_coder, num_decoder_layers, transformerlayers, decoder_self_posembeds=dict(type='ConvBNPositionalEncoding', input_channel=6, num_pos_feats=288), decoder_cross_posembeds=dict(type='ConvBNPositionalEncoding', input_channel=3, num_pos_feats=288), train_cfg=None, test_cfg=None, num_proposal=128, pred_layer_cfg=None, size_cls_agnostic=True, gt_per_seed=3, sampling_objectness_loss=None, objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, size_reg_loss=None, semantic_loss=None, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super(GroupFree3DHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.num_proposal = num_proposal\n    self.in_channels = in_channels\n    self.num_decoder_layers = num_decoder_layers\n    self.size_cls_agnostic = size_cls_agnostic\n    self.gt_per_seed = gt_per_seed\n    if isinstance(transformerlayers, ConfigDict):\n        transformerlayers = [copy.deepcopy(transformerlayers) for _ in range(num_decoder_layers)]\n    else:\n        assert isinstance(transformerlayers, list) and len(transformerlayers) == num_decoder_layers\n    self.decoder_layers = nn.ModuleList()\n    for i in range(self.num_decoder_layers):\n        self.decoder_layers.append(build_transformer_layer(transformerlayers[i]))\n    self.embed_dims = self.decoder_layers[0].embed_dims\n    assert self.embed_dims == decoder_self_posembeds['num_pos_feats']\n    assert self.embed_dims == decoder_cross_posembeds['num_pos_feats']\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.gsample_module = GeneralSamplingModule()\n    self.fps_module = Points_Sampler([self.num_proposal])\n    self.points_obj_cls = PointsObjClsModule(self.in_channels)\n    self.fp16_enabled = False\n    self.conv_pred = BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels())\n    self.decoder_query_proj = nn.Conv1d(self.embed_dims, self.embed_dims, kernel_size=1)\n    self.decoder_key_proj = nn.Conv1d(self.embed_dims, self.embed_dims, kernel_size=1)\n    self.decoder_self_posembeds = nn.ModuleList()\n    for _ in range(self.num_decoder_layers):\n        self.decoder_self_posembeds.append(build_positional_encoding(decoder_self_posembeds))\n    self.decoder_cross_posembeds = nn.ModuleList()\n    for _ in range(self.num_decoder_layers):\n        self.decoder_cross_posembeds.append(build_positional_encoding(decoder_cross_posembeds))\n    self.prediction_heads = nn.ModuleList()\n    for i in range(self.num_decoder_layers):\n        self.prediction_heads.append(BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels()))\n    self.sampling_objectness_loss = build_loss(sampling_objectness_loss)\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.semantic_loss = build_loss(semantic_loss)\n    if self.size_cls_agnostic:\n        self.size_reg_loss = build_loss(size_reg_loss)\n    else:\n        self.size_res_loss = build_loss(size_res_loss)\n        self.size_class_loss = build_loss(size_class_loss)",
            "def __init__(self, num_classes, in_channels, bbox_coder, num_decoder_layers, transformerlayers, decoder_self_posembeds=dict(type='ConvBNPositionalEncoding', input_channel=6, num_pos_feats=288), decoder_cross_posembeds=dict(type='ConvBNPositionalEncoding', input_channel=3, num_pos_feats=288), train_cfg=None, test_cfg=None, num_proposal=128, pred_layer_cfg=None, size_cls_agnostic=True, gt_per_seed=3, sampling_objectness_loss=None, objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, size_reg_loss=None, semantic_loss=None, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super(GroupFree3DHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.num_proposal = num_proposal\n    self.in_channels = in_channels\n    self.num_decoder_layers = num_decoder_layers\n    self.size_cls_agnostic = size_cls_agnostic\n    self.gt_per_seed = gt_per_seed\n    if isinstance(transformerlayers, ConfigDict):\n        transformerlayers = [copy.deepcopy(transformerlayers) for _ in range(num_decoder_layers)]\n    else:\n        assert isinstance(transformerlayers, list) and len(transformerlayers) == num_decoder_layers\n    self.decoder_layers = nn.ModuleList()\n    for i in range(self.num_decoder_layers):\n        self.decoder_layers.append(build_transformer_layer(transformerlayers[i]))\n    self.embed_dims = self.decoder_layers[0].embed_dims\n    assert self.embed_dims == decoder_self_posembeds['num_pos_feats']\n    assert self.embed_dims == decoder_cross_posembeds['num_pos_feats']\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.gsample_module = GeneralSamplingModule()\n    self.fps_module = Points_Sampler([self.num_proposal])\n    self.points_obj_cls = PointsObjClsModule(self.in_channels)\n    self.fp16_enabled = False\n    self.conv_pred = BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels())\n    self.decoder_query_proj = nn.Conv1d(self.embed_dims, self.embed_dims, kernel_size=1)\n    self.decoder_key_proj = nn.Conv1d(self.embed_dims, self.embed_dims, kernel_size=1)\n    self.decoder_self_posembeds = nn.ModuleList()\n    for _ in range(self.num_decoder_layers):\n        self.decoder_self_posembeds.append(build_positional_encoding(decoder_self_posembeds))\n    self.decoder_cross_posembeds = nn.ModuleList()\n    for _ in range(self.num_decoder_layers):\n        self.decoder_cross_posembeds.append(build_positional_encoding(decoder_cross_posembeds))\n    self.prediction_heads = nn.ModuleList()\n    for i in range(self.num_decoder_layers):\n        self.prediction_heads.append(BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels()))\n    self.sampling_objectness_loss = build_loss(sampling_objectness_loss)\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.semantic_loss = build_loss(semantic_loss)\n    if self.size_cls_agnostic:\n        self.size_reg_loss = build_loss(size_reg_loss)\n    else:\n        self.size_res_loss = build_loss(size_res_loss)\n        self.size_class_loss = build_loss(size_class_loss)",
            "def __init__(self, num_classes, in_channels, bbox_coder, num_decoder_layers, transformerlayers, decoder_self_posembeds=dict(type='ConvBNPositionalEncoding', input_channel=6, num_pos_feats=288), decoder_cross_posembeds=dict(type='ConvBNPositionalEncoding', input_channel=3, num_pos_feats=288), train_cfg=None, test_cfg=None, num_proposal=128, pred_layer_cfg=None, size_cls_agnostic=True, gt_per_seed=3, sampling_objectness_loss=None, objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, size_reg_loss=None, semantic_loss=None, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super(GroupFree3DHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.num_proposal = num_proposal\n    self.in_channels = in_channels\n    self.num_decoder_layers = num_decoder_layers\n    self.size_cls_agnostic = size_cls_agnostic\n    self.gt_per_seed = gt_per_seed\n    if isinstance(transformerlayers, ConfigDict):\n        transformerlayers = [copy.deepcopy(transformerlayers) for _ in range(num_decoder_layers)]\n    else:\n        assert isinstance(transformerlayers, list) and len(transformerlayers) == num_decoder_layers\n    self.decoder_layers = nn.ModuleList()\n    for i in range(self.num_decoder_layers):\n        self.decoder_layers.append(build_transformer_layer(transformerlayers[i]))\n    self.embed_dims = self.decoder_layers[0].embed_dims\n    assert self.embed_dims == decoder_self_posembeds['num_pos_feats']\n    assert self.embed_dims == decoder_cross_posembeds['num_pos_feats']\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.gsample_module = GeneralSamplingModule()\n    self.fps_module = Points_Sampler([self.num_proposal])\n    self.points_obj_cls = PointsObjClsModule(self.in_channels)\n    self.fp16_enabled = False\n    self.conv_pred = BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels())\n    self.decoder_query_proj = nn.Conv1d(self.embed_dims, self.embed_dims, kernel_size=1)\n    self.decoder_key_proj = nn.Conv1d(self.embed_dims, self.embed_dims, kernel_size=1)\n    self.decoder_self_posembeds = nn.ModuleList()\n    for _ in range(self.num_decoder_layers):\n        self.decoder_self_posembeds.append(build_positional_encoding(decoder_self_posembeds))\n    self.decoder_cross_posembeds = nn.ModuleList()\n    for _ in range(self.num_decoder_layers):\n        self.decoder_cross_posembeds.append(build_positional_encoding(decoder_cross_posembeds))\n    self.prediction_heads = nn.ModuleList()\n    for i in range(self.num_decoder_layers):\n        self.prediction_heads.append(BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels()))\n    self.sampling_objectness_loss = build_loss(sampling_objectness_loss)\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.semantic_loss = build_loss(semantic_loss)\n    if self.size_cls_agnostic:\n        self.size_reg_loss = build_loss(size_reg_loss)\n    else:\n        self.size_res_loss = build_loss(size_res_loss)\n        self.size_class_loss = build_loss(size_class_loss)",
            "def __init__(self, num_classes, in_channels, bbox_coder, num_decoder_layers, transformerlayers, decoder_self_posembeds=dict(type='ConvBNPositionalEncoding', input_channel=6, num_pos_feats=288), decoder_cross_posembeds=dict(type='ConvBNPositionalEncoding', input_channel=3, num_pos_feats=288), train_cfg=None, test_cfg=None, num_proposal=128, pred_layer_cfg=None, size_cls_agnostic=True, gt_per_seed=3, sampling_objectness_loss=None, objectness_loss=None, center_loss=None, dir_class_loss=None, dir_res_loss=None, size_class_loss=None, size_res_loss=None, size_reg_loss=None, semantic_loss=None, init_cfg=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super(GroupFree3DHead, self).__init__(init_cfg=init_cfg)\n    self.num_classes = num_classes\n    self.train_cfg = train_cfg\n    self.test_cfg = test_cfg\n    self.num_proposal = num_proposal\n    self.in_channels = in_channels\n    self.num_decoder_layers = num_decoder_layers\n    self.size_cls_agnostic = size_cls_agnostic\n    self.gt_per_seed = gt_per_seed\n    if isinstance(transformerlayers, ConfigDict):\n        transformerlayers = [copy.deepcopy(transformerlayers) for _ in range(num_decoder_layers)]\n    else:\n        assert isinstance(transformerlayers, list) and len(transformerlayers) == num_decoder_layers\n    self.decoder_layers = nn.ModuleList()\n    for i in range(self.num_decoder_layers):\n        self.decoder_layers.append(build_transformer_layer(transformerlayers[i]))\n    self.embed_dims = self.decoder_layers[0].embed_dims\n    assert self.embed_dims == decoder_self_posembeds['num_pos_feats']\n    assert self.embed_dims == decoder_cross_posembeds['num_pos_feats']\n    self.bbox_coder = build_bbox_coder(bbox_coder)\n    self.num_sizes = self.bbox_coder.num_sizes\n    self.num_dir_bins = self.bbox_coder.num_dir_bins\n    self.gsample_module = GeneralSamplingModule()\n    self.fps_module = Points_Sampler([self.num_proposal])\n    self.points_obj_cls = PointsObjClsModule(self.in_channels)\n    self.fp16_enabled = False\n    self.conv_pred = BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels())\n    self.decoder_query_proj = nn.Conv1d(self.embed_dims, self.embed_dims, kernel_size=1)\n    self.decoder_key_proj = nn.Conv1d(self.embed_dims, self.embed_dims, kernel_size=1)\n    self.decoder_self_posembeds = nn.ModuleList()\n    for _ in range(self.num_decoder_layers):\n        self.decoder_self_posembeds.append(build_positional_encoding(decoder_self_posembeds))\n    self.decoder_cross_posembeds = nn.ModuleList()\n    for _ in range(self.num_decoder_layers):\n        self.decoder_cross_posembeds.append(build_positional_encoding(decoder_cross_posembeds))\n    self.prediction_heads = nn.ModuleList()\n    for i in range(self.num_decoder_layers):\n        self.prediction_heads.append(BaseConvBboxHead(**pred_layer_cfg, num_cls_out_channels=self._get_cls_out_channels(), num_reg_out_channels=self._get_reg_out_channels()))\n    self.sampling_objectness_loss = build_loss(sampling_objectness_loss)\n    self.objectness_loss = build_loss(objectness_loss)\n    self.center_loss = build_loss(center_loss)\n    self.dir_res_loss = build_loss(dir_res_loss)\n    self.dir_class_loss = build_loss(dir_class_loss)\n    self.semantic_loss = build_loss(semantic_loss)\n    if self.size_cls_agnostic:\n        self.size_reg_loss = build_loss(size_reg_loss)\n    else:\n        self.size_res_loss = build_loss(size_res_loss)\n        self.size_class_loss = build_loss(size_class_loss)"
        ]
    },
    {
        "func_name": "init_weights",
        "original": "def init_weights(self):\n    \"\"\"Initialize weights of transformer decoder in GroupFree3DHead.\"\"\"\n    for m in self.decoder_layers.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')\n    for m in self.decoder_self_posembeds.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')\n    for m in self.decoder_cross_posembeds.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')",
        "mutated": [
            "def init_weights(self):\n    if False:\n        i = 10\n    'Initialize weights of transformer decoder in GroupFree3DHead.'\n    for m in self.decoder_layers.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')\n    for m in self.decoder_self_posembeds.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')\n    for m in self.decoder_cross_posembeds.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Initialize weights of transformer decoder in GroupFree3DHead.'\n    for m in self.decoder_layers.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')\n    for m in self.decoder_self_posembeds.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')\n    for m in self.decoder_cross_posembeds.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Initialize weights of transformer decoder in GroupFree3DHead.'\n    for m in self.decoder_layers.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')\n    for m in self.decoder_self_posembeds.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')\n    for m in self.decoder_cross_posembeds.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Initialize weights of transformer decoder in GroupFree3DHead.'\n    for m in self.decoder_layers.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')\n    for m in self.decoder_self_posembeds.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')\n    for m in self.decoder_cross_posembeds.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')",
            "def init_weights(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Initialize weights of transformer decoder in GroupFree3DHead.'\n    for m in self.decoder_layers.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')\n    for m in self.decoder_self_posembeds.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')\n    for m in self.decoder_cross_posembeds.parameters():\n        if m.dim() > 1:\n            xavier_init(m, distribution='uniform')"
        ]
    },
    {
        "func_name": "_get_cls_out_channels",
        "original": "def _get_cls_out_channels(self):\n    \"\"\"Return the channel number of classification outputs.\"\"\"\n    return self.num_classes + 1",
        "mutated": [
            "def _get_cls_out_channels(self):\n    if False:\n        i = 10\n    'Return the channel number of classification outputs.'\n    return self.num_classes + 1",
            "def _get_cls_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Return the channel number of classification outputs.'\n    return self.num_classes + 1",
            "def _get_cls_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Return the channel number of classification outputs.'\n    return self.num_classes + 1",
            "def _get_cls_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Return the channel number of classification outputs.'\n    return self.num_classes + 1",
            "def _get_cls_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Return the channel number of classification outputs.'\n    return self.num_classes + 1"
        ]
    },
    {
        "func_name": "_get_reg_out_channels",
        "original": "def _get_reg_out_channels(self):\n    \"\"\"Return the channel number of regression outputs.\"\"\"\n    if self.size_cls_agnostic:\n        return 6 + self.num_dir_bins * 2\n    else:\n        return 3 + self.num_dir_bins * 2 + self.num_sizes * 4",
        "mutated": [
            "def _get_reg_out_channels(self):\n    if False:\n        i = 10\n    'Return the channel number of regression outputs.'\n    if self.size_cls_agnostic:\n        return 6 + self.num_dir_bins * 2\n    else:\n        return 3 + self.num_dir_bins * 2 + self.num_sizes * 4",
            "def _get_reg_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Return the channel number of regression outputs.'\n    if self.size_cls_agnostic:\n        return 6 + self.num_dir_bins * 2\n    else:\n        return 3 + self.num_dir_bins * 2 + self.num_sizes * 4",
            "def _get_reg_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Return the channel number of regression outputs.'\n    if self.size_cls_agnostic:\n        return 6 + self.num_dir_bins * 2\n    else:\n        return 3 + self.num_dir_bins * 2 + self.num_sizes * 4",
            "def _get_reg_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Return the channel number of regression outputs.'\n    if self.size_cls_agnostic:\n        return 6 + self.num_dir_bins * 2\n    else:\n        return 3 + self.num_dir_bins * 2 + self.num_sizes * 4",
            "def _get_reg_out_channels(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Return the channel number of regression outputs.'\n    if self.size_cls_agnostic:\n        return 6 + self.num_dir_bins * 2\n    else:\n        return 3 + self.num_dir_bins * 2 + self.num_sizes * 4"
        ]
    },
    {
        "func_name": "_extract_input",
        "original": "def _extract_input(self, feat_dict):\n    \"\"\"Extract inputs from features dictionary.\n\n        Args:\n            feat_dict (dict): Feature dict from backbone.\n\n        Returns:\n            torch.Tensor: Coordinates of input points.\n            torch.Tensor: Features of input points.\n            torch.Tensor: Indices of input points.\n        \"\"\"\n    seed_points = feat_dict['fp_xyz'][-1]\n    seed_features = feat_dict['fp_features'][-1]\n    seed_indices = feat_dict['fp_indices'][-1]\n    return (seed_points, seed_features, seed_indices)",
        "mutated": [
            "def _extract_input(self, feat_dict):\n    if False:\n        i = 10\n    'Extract inputs from features dictionary.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n\\n        Returns:\\n            torch.Tensor: Coordinates of input points.\\n            torch.Tensor: Features of input points.\\n            torch.Tensor: Indices of input points.\\n        '\n    seed_points = feat_dict['fp_xyz'][-1]\n    seed_features = feat_dict['fp_features'][-1]\n    seed_indices = feat_dict['fp_indices'][-1]\n    return (seed_points, seed_features, seed_indices)",
            "def _extract_input(self, feat_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Extract inputs from features dictionary.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n\\n        Returns:\\n            torch.Tensor: Coordinates of input points.\\n            torch.Tensor: Features of input points.\\n            torch.Tensor: Indices of input points.\\n        '\n    seed_points = feat_dict['fp_xyz'][-1]\n    seed_features = feat_dict['fp_features'][-1]\n    seed_indices = feat_dict['fp_indices'][-1]\n    return (seed_points, seed_features, seed_indices)",
            "def _extract_input(self, feat_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Extract inputs from features dictionary.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n\\n        Returns:\\n            torch.Tensor: Coordinates of input points.\\n            torch.Tensor: Features of input points.\\n            torch.Tensor: Indices of input points.\\n        '\n    seed_points = feat_dict['fp_xyz'][-1]\n    seed_features = feat_dict['fp_features'][-1]\n    seed_indices = feat_dict['fp_indices'][-1]\n    return (seed_points, seed_features, seed_indices)",
            "def _extract_input(self, feat_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Extract inputs from features dictionary.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n\\n        Returns:\\n            torch.Tensor: Coordinates of input points.\\n            torch.Tensor: Features of input points.\\n            torch.Tensor: Indices of input points.\\n        '\n    seed_points = feat_dict['fp_xyz'][-1]\n    seed_features = feat_dict['fp_features'][-1]\n    seed_indices = feat_dict['fp_indices'][-1]\n    return (seed_points, seed_features, seed_indices)",
            "def _extract_input(self, feat_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Extract inputs from features dictionary.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n\\n        Returns:\\n            torch.Tensor: Coordinates of input points.\\n            torch.Tensor: Features of input points.\\n            torch.Tensor: Indices of input points.\\n        '\n    seed_points = feat_dict['fp_xyz'][-1]\n    seed_features = feat_dict['fp_features'][-1]\n    seed_indices = feat_dict['fp_indices'][-1]\n    return (seed_points, seed_features, seed_indices)"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, feat_dict, sample_mod):\n    \"\"\"Forward pass.\n\n        Note:\n            The forward of GroupFree3DHead is divided into 2 steps:\n\n                1. Initial object candidates sampling.\n                2. Iterative object box prediction by transformer decoder.\n\n        Args:\n            feat_dict (dict): Feature dict from backbone.\n            sample_mod (str): sample mode for initial candidates sampling.\n\n        Returns:\n            results (dict): Predictions of GroupFree3D head.\n        \"\"\"\n    assert sample_mod in ['fps', 'kps']\n    (seed_xyz, seed_features, seed_indices) = self._extract_input(feat_dict)\n    results = dict(seed_points=seed_xyz, seed_features=seed_features, seed_indices=seed_indices)\n    if sample_mod == 'fps':\n        sample_inds = self.fps_module(seed_xyz, seed_features)\n    elif sample_mod == 'kps':\n        points_obj_cls_logits = self.points_obj_cls(seed_features)\n        points_obj_cls_scores = points_obj_cls_logits.sigmoid().squeeze(1)\n        sample_inds = torch.topk(points_obj_cls_scores, self.num_proposal)[1].int()\n        results['seeds_obj_cls_logits'] = points_obj_cls_logits\n    else:\n        raise NotImplementedError(f'Sample mode {sample_mod} is not supported!')\n    (candidate_xyz, candidate_features, sample_inds) = self.gsample_module(seed_xyz, seed_features, sample_inds)\n    results['query_points_xyz'] = candidate_xyz\n    results['query_points_feature'] = candidate_features\n    results['query_points_sample_inds'] = sample_inds.long()\n    prefix = 'proposal.'\n    (cls_predictions, reg_predictions) = self.conv_pred(candidate_features)\n    decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, candidate_xyz, prefix)\n    results.update(decode_res)\n    bbox3d = self.bbox_coder.decode(results, prefix)\n    base_bbox3d = bbox3d[:, :, :6].detach().clone()\n    query = self.decoder_query_proj(candidate_features).permute(2, 0, 1)\n    key = self.decoder_key_proj(seed_features).permute(2, 0, 1)\n    value = key\n    results['num_decoder_layers'] = 0\n    for i in range(self.num_decoder_layers):\n        prefix = f's{i}.'\n        query_pos = self.decoder_self_posembeds[i](base_bbox3d).permute(2, 0, 1)\n        key_pos = self.decoder_cross_posembeds[i](seed_xyz).permute(2, 0, 1)\n        query = self.decoder_layers[i](query, key, value, query_pos=query_pos, key_pos=key_pos).permute(1, 2, 0)\n        results[f'{prefix}query'] = query\n        (cls_predictions, reg_predictions) = self.prediction_heads[i](query)\n        decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, candidate_xyz, prefix)\n        results.update(decode_res)\n        bbox3d = self.bbox_coder.decode(results, prefix)\n        results[f'{prefix}bbox3d'] = bbox3d\n        base_bbox3d = bbox3d[:, :, :6].detach().clone()\n        query = query.permute(2, 0, 1)\n        results['num_decoder_layers'] += 1\n    return results",
        "mutated": [
            "def forward(self, feat_dict, sample_mod):\n    if False:\n        i = 10\n    'Forward pass.\\n\\n        Note:\\n            The forward of GroupFree3DHead is divided into 2 steps:\\n\\n                1. Initial object candidates sampling.\\n                2. Iterative object box prediction by transformer decoder.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n            sample_mod (str): sample mode for initial candidates sampling.\\n\\n        Returns:\\n            results (dict): Predictions of GroupFree3D head.\\n        '\n    assert sample_mod in ['fps', 'kps']\n    (seed_xyz, seed_features, seed_indices) = self._extract_input(feat_dict)\n    results = dict(seed_points=seed_xyz, seed_features=seed_features, seed_indices=seed_indices)\n    if sample_mod == 'fps':\n        sample_inds = self.fps_module(seed_xyz, seed_features)\n    elif sample_mod == 'kps':\n        points_obj_cls_logits = self.points_obj_cls(seed_features)\n        points_obj_cls_scores = points_obj_cls_logits.sigmoid().squeeze(1)\n        sample_inds = torch.topk(points_obj_cls_scores, self.num_proposal)[1].int()\n        results['seeds_obj_cls_logits'] = points_obj_cls_logits\n    else:\n        raise NotImplementedError(f'Sample mode {sample_mod} is not supported!')\n    (candidate_xyz, candidate_features, sample_inds) = self.gsample_module(seed_xyz, seed_features, sample_inds)\n    results['query_points_xyz'] = candidate_xyz\n    results['query_points_feature'] = candidate_features\n    results['query_points_sample_inds'] = sample_inds.long()\n    prefix = 'proposal.'\n    (cls_predictions, reg_predictions) = self.conv_pred(candidate_features)\n    decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, candidate_xyz, prefix)\n    results.update(decode_res)\n    bbox3d = self.bbox_coder.decode(results, prefix)\n    base_bbox3d = bbox3d[:, :, :6].detach().clone()\n    query = self.decoder_query_proj(candidate_features).permute(2, 0, 1)\n    key = self.decoder_key_proj(seed_features).permute(2, 0, 1)\n    value = key\n    results['num_decoder_layers'] = 0\n    for i in range(self.num_decoder_layers):\n        prefix = f's{i}.'\n        query_pos = self.decoder_self_posembeds[i](base_bbox3d).permute(2, 0, 1)\n        key_pos = self.decoder_cross_posembeds[i](seed_xyz).permute(2, 0, 1)\n        query = self.decoder_layers[i](query, key, value, query_pos=query_pos, key_pos=key_pos).permute(1, 2, 0)\n        results[f'{prefix}query'] = query\n        (cls_predictions, reg_predictions) = self.prediction_heads[i](query)\n        decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, candidate_xyz, prefix)\n        results.update(decode_res)\n        bbox3d = self.bbox_coder.decode(results, prefix)\n        results[f'{prefix}bbox3d'] = bbox3d\n        base_bbox3d = bbox3d[:, :, :6].detach().clone()\n        query = query.permute(2, 0, 1)\n        results['num_decoder_layers'] += 1\n    return results",
            "def forward(self, feat_dict, sample_mod):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Forward pass.\\n\\n        Note:\\n            The forward of GroupFree3DHead is divided into 2 steps:\\n\\n                1. Initial object candidates sampling.\\n                2. Iterative object box prediction by transformer decoder.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n            sample_mod (str): sample mode for initial candidates sampling.\\n\\n        Returns:\\n            results (dict): Predictions of GroupFree3D head.\\n        '\n    assert sample_mod in ['fps', 'kps']\n    (seed_xyz, seed_features, seed_indices) = self._extract_input(feat_dict)\n    results = dict(seed_points=seed_xyz, seed_features=seed_features, seed_indices=seed_indices)\n    if sample_mod == 'fps':\n        sample_inds = self.fps_module(seed_xyz, seed_features)\n    elif sample_mod == 'kps':\n        points_obj_cls_logits = self.points_obj_cls(seed_features)\n        points_obj_cls_scores = points_obj_cls_logits.sigmoid().squeeze(1)\n        sample_inds = torch.topk(points_obj_cls_scores, self.num_proposal)[1].int()\n        results['seeds_obj_cls_logits'] = points_obj_cls_logits\n    else:\n        raise NotImplementedError(f'Sample mode {sample_mod} is not supported!')\n    (candidate_xyz, candidate_features, sample_inds) = self.gsample_module(seed_xyz, seed_features, sample_inds)\n    results['query_points_xyz'] = candidate_xyz\n    results['query_points_feature'] = candidate_features\n    results['query_points_sample_inds'] = sample_inds.long()\n    prefix = 'proposal.'\n    (cls_predictions, reg_predictions) = self.conv_pred(candidate_features)\n    decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, candidate_xyz, prefix)\n    results.update(decode_res)\n    bbox3d = self.bbox_coder.decode(results, prefix)\n    base_bbox3d = bbox3d[:, :, :6].detach().clone()\n    query = self.decoder_query_proj(candidate_features).permute(2, 0, 1)\n    key = self.decoder_key_proj(seed_features).permute(2, 0, 1)\n    value = key\n    results['num_decoder_layers'] = 0\n    for i in range(self.num_decoder_layers):\n        prefix = f's{i}.'\n        query_pos = self.decoder_self_posembeds[i](base_bbox3d).permute(2, 0, 1)\n        key_pos = self.decoder_cross_posembeds[i](seed_xyz).permute(2, 0, 1)\n        query = self.decoder_layers[i](query, key, value, query_pos=query_pos, key_pos=key_pos).permute(1, 2, 0)\n        results[f'{prefix}query'] = query\n        (cls_predictions, reg_predictions) = self.prediction_heads[i](query)\n        decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, candidate_xyz, prefix)\n        results.update(decode_res)\n        bbox3d = self.bbox_coder.decode(results, prefix)\n        results[f'{prefix}bbox3d'] = bbox3d\n        base_bbox3d = bbox3d[:, :, :6].detach().clone()\n        query = query.permute(2, 0, 1)\n        results['num_decoder_layers'] += 1\n    return results",
            "def forward(self, feat_dict, sample_mod):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Forward pass.\\n\\n        Note:\\n            The forward of GroupFree3DHead is divided into 2 steps:\\n\\n                1. Initial object candidates sampling.\\n                2. Iterative object box prediction by transformer decoder.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n            sample_mod (str): sample mode for initial candidates sampling.\\n\\n        Returns:\\n            results (dict): Predictions of GroupFree3D head.\\n        '\n    assert sample_mod in ['fps', 'kps']\n    (seed_xyz, seed_features, seed_indices) = self._extract_input(feat_dict)\n    results = dict(seed_points=seed_xyz, seed_features=seed_features, seed_indices=seed_indices)\n    if sample_mod == 'fps':\n        sample_inds = self.fps_module(seed_xyz, seed_features)\n    elif sample_mod == 'kps':\n        points_obj_cls_logits = self.points_obj_cls(seed_features)\n        points_obj_cls_scores = points_obj_cls_logits.sigmoid().squeeze(1)\n        sample_inds = torch.topk(points_obj_cls_scores, self.num_proposal)[1].int()\n        results['seeds_obj_cls_logits'] = points_obj_cls_logits\n    else:\n        raise NotImplementedError(f'Sample mode {sample_mod} is not supported!')\n    (candidate_xyz, candidate_features, sample_inds) = self.gsample_module(seed_xyz, seed_features, sample_inds)\n    results['query_points_xyz'] = candidate_xyz\n    results['query_points_feature'] = candidate_features\n    results['query_points_sample_inds'] = sample_inds.long()\n    prefix = 'proposal.'\n    (cls_predictions, reg_predictions) = self.conv_pred(candidate_features)\n    decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, candidate_xyz, prefix)\n    results.update(decode_res)\n    bbox3d = self.bbox_coder.decode(results, prefix)\n    base_bbox3d = bbox3d[:, :, :6].detach().clone()\n    query = self.decoder_query_proj(candidate_features).permute(2, 0, 1)\n    key = self.decoder_key_proj(seed_features).permute(2, 0, 1)\n    value = key\n    results['num_decoder_layers'] = 0\n    for i in range(self.num_decoder_layers):\n        prefix = f's{i}.'\n        query_pos = self.decoder_self_posembeds[i](base_bbox3d).permute(2, 0, 1)\n        key_pos = self.decoder_cross_posembeds[i](seed_xyz).permute(2, 0, 1)\n        query = self.decoder_layers[i](query, key, value, query_pos=query_pos, key_pos=key_pos).permute(1, 2, 0)\n        results[f'{prefix}query'] = query\n        (cls_predictions, reg_predictions) = self.prediction_heads[i](query)\n        decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, candidate_xyz, prefix)\n        results.update(decode_res)\n        bbox3d = self.bbox_coder.decode(results, prefix)\n        results[f'{prefix}bbox3d'] = bbox3d\n        base_bbox3d = bbox3d[:, :, :6].detach().clone()\n        query = query.permute(2, 0, 1)\n        results['num_decoder_layers'] += 1\n    return results",
            "def forward(self, feat_dict, sample_mod):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Forward pass.\\n\\n        Note:\\n            The forward of GroupFree3DHead is divided into 2 steps:\\n\\n                1. Initial object candidates sampling.\\n                2. Iterative object box prediction by transformer decoder.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n            sample_mod (str): sample mode for initial candidates sampling.\\n\\n        Returns:\\n            results (dict): Predictions of GroupFree3D head.\\n        '\n    assert sample_mod in ['fps', 'kps']\n    (seed_xyz, seed_features, seed_indices) = self._extract_input(feat_dict)\n    results = dict(seed_points=seed_xyz, seed_features=seed_features, seed_indices=seed_indices)\n    if sample_mod == 'fps':\n        sample_inds = self.fps_module(seed_xyz, seed_features)\n    elif sample_mod == 'kps':\n        points_obj_cls_logits = self.points_obj_cls(seed_features)\n        points_obj_cls_scores = points_obj_cls_logits.sigmoid().squeeze(1)\n        sample_inds = torch.topk(points_obj_cls_scores, self.num_proposal)[1].int()\n        results['seeds_obj_cls_logits'] = points_obj_cls_logits\n    else:\n        raise NotImplementedError(f'Sample mode {sample_mod} is not supported!')\n    (candidate_xyz, candidate_features, sample_inds) = self.gsample_module(seed_xyz, seed_features, sample_inds)\n    results['query_points_xyz'] = candidate_xyz\n    results['query_points_feature'] = candidate_features\n    results['query_points_sample_inds'] = sample_inds.long()\n    prefix = 'proposal.'\n    (cls_predictions, reg_predictions) = self.conv_pred(candidate_features)\n    decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, candidate_xyz, prefix)\n    results.update(decode_res)\n    bbox3d = self.bbox_coder.decode(results, prefix)\n    base_bbox3d = bbox3d[:, :, :6].detach().clone()\n    query = self.decoder_query_proj(candidate_features).permute(2, 0, 1)\n    key = self.decoder_key_proj(seed_features).permute(2, 0, 1)\n    value = key\n    results['num_decoder_layers'] = 0\n    for i in range(self.num_decoder_layers):\n        prefix = f's{i}.'\n        query_pos = self.decoder_self_posembeds[i](base_bbox3d).permute(2, 0, 1)\n        key_pos = self.decoder_cross_posembeds[i](seed_xyz).permute(2, 0, 1)\n        query = self.decoder_layers[i](query, key, value, query_pos=query_pos, key_pos=key_pos).permute(1, 2, 0)\n        results[f'{prefix}query'] = query\n        (cls_predictions, reg_predictions) = self.prediction_heads[i](query)\n        decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, candidate_xyz, prefix)\n        results.update(decode_res)\n        bbox3d = self.bbox_coder.decode(results, prefix)\n        results[f'{prefix}bbox3d'] = bbox3d\n        base_bbox3d = bbox3d[:, :, :6].detach().clone()\n        query = query.permute(2, 0, 1)\n        results['num_decoder_layers'] += 1\n    return results",
            "def forward(self, feat_dict, sample_mod):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Forward pass.\\n\\n        Note:\\n            The forward of GroupFree3DHead is divided into 2 steps:\\n\\n                1. Initial object candidates sampling.\\n                2. Iterative object box prediction by transformer decoder.\\n\\n        Args:\\n            feat_dict (dict): Feature dict from backbone.\\n            sample_mod (str): sample mode for initial candidates sampling.\\n\\n        Returns:\\n            results (dict): Predictions of GroupFree3D head.\\n        '\n    assert sample_mod in ['fps', 'kps']\n    (seed_xyz, seed_features, seed_indices) = self._extract_input(feat_dict)\n    results = dict(seed_points=seed_xyz, seed_features=seed_features, seed_indices=seed_indices)\n    if sample_mod == 'fps':\n        sample_inds = self.fps_module(seed_xyz, seed_features)\n    elif sample_mod == 'kps':\n        points_obj_cls_logits = self.points_obj_cls(seed_features)\n        points_obj_cls_scores = points_obj_cls_logits.sigmoid().squeeze(1)\n        sample_inds = torch.topk(points_obj_cls_scores, self.num_proposal)[1].int()\n        results['seeds_obj_cls_logits'] = points_obj_cls_logits\n    else:\n        raise NotImplementedError(f'Sample mode {sample_mod} is not supported!')\n    (candidate_xyz, candidate_features, sample_inds) = self.gsample_module(seed_xyz, seed_features, sample_inds)\n    results['query_points_xyz'] = candidate_xyz\n    results['query_points_feature'] = candidate_features\n    results['query_points_sample_inds'] = sample_inds.long()\n    prefix = 'proposal.'\n    (cls_predictions, reg_predictions) = self.conv_pred(candidate_features)\n    decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, candidate_xyz, prefix)\n    results.update(decode_res)\n    bbox3d = self.bbox_coder.decode(results, prefix)\n    base_bbox3d = bbox3d[:, :, :6].detach().clone()\n    query = self.decoder_query_proj(candidate_features).permute(2, 0, 1)\n    key = self.decoder_key_proj(seed_features).permute(2, 0, 1)\n    value = key\n    results['num_decoder_layers'] = 0\n    for i in range(self.num_decoder_layers):\n        prefix = f's{i}.'\n        query_pos = self.decoder_self_posembeds[i](base_bbox3d).permute(2, 0, 1)\n        key_pos = self.decoder_cross_posembeds[i](seed_xyz).permute(2, 0, 1)\n        query = self.decoder_layers[i](query, key, value, query_pos=query_pos, key_pos=key_pos).permute(1, 2, 0)\n        results[f'{prefix}query'] = query\n        (cls_predictions, reg_predictions) = self.prediction_heads[i](query)\n        decode_res = self.bbox_coder.split_pred(cls_predictions, reg_predictions, candidate_xyz, prefix)\n        results.update(decode_res)\n        bbox3d = self.bbox_coder.decode(results, prefix)\n        results[f'{prefix}bbox3d'] = bbox3d\n        base_bbox3d = bbox3d[:, :, :6].detach().clone()\n        query = query.permute(2, 0, 1)\n        results['num_decoder_layers'] += 1\n    return results"
        ]
    },
    {
        "func_name": "loss",
        "original": "@force_fp32(apply_to=('bbox_preds',))\ndef loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, gt_bboxes_ignore=None, ret_target=False):\n    \"\"\"Compute loss.\n\n        Args:\n            bbox_preds (dict): Predictions from forward of vote head.\n            points (list[torch.Tensor]): Input points.\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\n                bboxes of each sample.\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\n                semantic mask.\n            pts_instance_mask (list[torch.Tensor]): Point-wise\n                instance mask.\n            img_metas (list[dict]): Contain pcd and img's meta info.\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\n                which bounding.\n            ret_target (Bool): Return targets or not.\n\n        Returns:\n            dict: Losses of GroupFree3D.\n        \"\"\"\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (sampling_targets, sampling_weights, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = targets\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    losses = dict()\n    sampling_obj_score = bbox_preds['seeds_obj_cls_logits'].reshape(-1, 1)\n    sampling_objectness_loss = self.sampling_objectness_loss(sampling_obj_score, 1 - sampling_targets.reshape(-1), sampling_weights.reshape(-1), avg_factor=batch_size)\n    losses['sampling_objectness_loss'] = sampling_objectness_loss\n    prefixes = ['proposal.'] + [f's{i}.' for i in range(bbox_preds['num_decoder_layers'])]\n    num_stages = len(prefixes)\n    for prefix in prefixes:\n        obj_score = bbox_preds[f'{prefix}obj_scores'].transpose(2, 1)\n        objectness_loss = self.objectness_loss(obj_score.reshape(-1, 1), 1 - objectness_targets.reshape(-1), objectness_weights.reshape(-1), avg_factor=batch_size)\n        losses[f'{prefix}objectness_loss'] = objectness_loss / num_stages\n        box_loss_weights_expand = box_loss_weights.unsqueeze(-1).expand(-1, -1, 3)\n        center_loss = self.center_loss(bbox_preds[f'{prefix}center'], assigned_center_targets, weight=box_loss_weights_expand)\n        losses[f'{prefix}center_loss'] = center_loss / num_stages\n        dir_class_loss = self.dir_class_loss(bbox_preds[f'{prefix}dir_class'].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n        losses[f'{prefix}dir_class_loss'] = dir_class_loss / num_stages\n        heading_label_one_hot = size_class_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n        heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n        dir_res_norm = torch.sum(bbox_preds[f'{prefix}dir_res_norm'] * heading_label_one_hot, -1)\n        dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n        losses[f'{prefix}dir_res_loss'] = dir_res_loss / num_stages\n        if self.size_cls_agnostic:\n            size_reg_loss = self.size_reg_loss(bbox_preds[f'{prefix}size'], assigned_size_targets, weight=box_loss_weights_expand)\n            losses[f'{prefix}size_reg_loss'] = size_reg_loss / num_stages\n        else:\n            size_class_loss = self.size_class_loss(bbox_preds[f'{prefix}size_class'].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n            losses[f'{prefix}size_class_loss'] = size_class_loss / num_stages\n            one_hot_size_targets = size_class_targets.new_zeros((batch_size, proposal_num, self.num_sizes))\n            one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n            one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).expand(-1, -1, -1, 3).contiguous()\n            size_residual_norm = torch.sum(bbox_preds[f'{prefix}size_res_norm'] * one_hot_size_targets_expand, 2)\n            box_loss_weights_expand = box_loss_weights.unsqueeze(-1).expand(-1, -1, 3)\n            size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n            losses[f'{prefix}size_res_loss'] = size_res_loss / num_stages\n        semantic_loss = self.semantic_loss(bbox_preds[f'{prefix}sem_scores'].transpose(2, 1), mask_targets, weight=box_loss_weights)\n        losses[f'{prefix}semantic_loss'] = semantic_loss / num_stages\n    if ret_target:\n        losses['targets'] = targets\n    return losses",
        "mutated": [
            "@force_fp32(apply_to=('bbox_preds',))\ndef loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, gt_bboxes_ignore=None, ret_target=False):\n    if False:\n        i = 10\n    \"Compute loss.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of vote head.\\n            points (list[torch.Tensor]): Input points.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each sample.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\\n                semantic mask.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise\\n                instance mask.\\n            img_metas (list[dict]): Contain pcd and img's meta info.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding.\\n            ret_target (Bool): Return targets or not.\\n\\n        Returns:\\n            dict: Losses of GroupFree3D.\\n        \"\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (sampling_targets, sampling_weights, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = targets\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    losses = dict()\n    sampling_obj_score = bbox_preds['seeds_obj_cls_logits'].reshape(-1, 1)\n    sampling_objectness_loss = self.sampling_objectness_loss(sampling_obj_score, 1 - sampling_targets.reshape(-1), sampling_weights.reshape(-1), avg_factor=batch_size)\n    losses['sampling_objectness_loss'] = sampling_objectness_loss\n    prefixes = ['proposal.'] + [f's{i}.' for i in range(bbox_preds['num_decoder_layers'])]\n    num_stages = len(prefixes)\n    for prefix in prefixes:\n        obj_score = bbox_preds[f'{prefix}obj_scores'].transpose(2, 1)\n        objectness_loss = self.objectness_loss(obj_score.reshape(-1, 1), 1 - objectness_targets.reshape(-1), objectness_weights.reshape(-1), avg_factor=batch_size)\n        losses[f'{prefix}objectness_loss'] = objectness_loss / num_stages\n        box_loss_weights_expand = box_loss_weights.unsqueeze(-1).expand(-1, -1, 3)\n        center_loss = self.center_loss(bbox_preds[f'{prefix}center'], assigned_center_targets, weight=box_loss_weights_expand)\n        losses[f'{prefix}center_loss'] = center_loss / num_stages\n        dir_class_loss = self.dir_class_loss(bbox_preds[f'{prefix}dir_class'].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n        losses[f'{prefix}dir_class_loss'] = dir_class_loss / num_stages\n        heading_label_one_hot = size_class_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n        heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n        dir_res_norm = torch.sum(bbox_preds[f'{prefix}dir_res_norm'] * heading_label_one_hot, -1)\n        dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n        losses[f'{prefix}dir_res_loss'] = dir_res_loss / num_stages\n        if self.size_cls_agnostic:\n            size_reg_loss = self.size_reg_loss(bbox_preds[f'{prefix}size'], assigned_size_targets, weight=box_loss_weights_expand)\n            losses[f'{prefix}size_reg_loss'] = size_reg_loss / num_stages\n        else:\n            size_class_loss = self.size_class_loss(bbox_preds[f'{prefix}size_class'].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n            losses[f'{prefix}size_class_loss'] = size_class_loss / num_stages\n            one_hot_size_targets = size_class_targets.new_zeros((batch_size, proposal_num, self.num_sizes))\n            one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n            one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).expand(-1, -1, -1, 3).contiguous()\n            size_residual_norm = torch.sum(bbox_preds[f'{prefix}size_res_norm'] * one_hot_size_targets_expand, 2)\n            box_loss_weights_expand = box_loss_weights.unsqueeze(-1).expand(-1, -1, 3)\n            size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n            losses[f'{prefix}size_res_loss'] = size_res_loss / num_stages\n        semantic_loss = self.semantic_loss(bbox_preds[f'{prefix}sem_scores'].transpose(2, 1), mask_targets, weight=box_loss_weights)\n        losses[f'{prefix}semantic_loss'] = semantic_loss / num_stages\n    if ret_target:\n        losses['targets'] = targets\n    return losses",
            "@force_fp32(apply_to=('bbox_preds',))\ndef loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, gt_bboxes_ignore=None, ret_target=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Compute loss.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of vote head.\\n            points (list[torch.Tensor]): Input points.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each sample.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\\n                semantic mask.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise\\n                instance mask.\\n            img_metas (list[dict]): Contain pcd and img's meta info.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding.\\n            ret_target (Bool): Return targets or not.\\n\\n        Returns:\\n            dict: Losses of GroupFree3D.\\n        \"\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (sampling_targets, sampling_weights, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = targets\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    losses = dict()\n    sampling_obj_score = bbox_preds['seeds_obj_cls_logits'].reshape(-1, 1)\n    sampling_objectness_loss = self.sampling_objectness_loss(sampling_obj_score, 1 - sampling_targets.reshape(-1), sampling_weights.reshape(-1), avg_factor=batch_size)\n    losses['sampling_objectness_loss'] = sampling_objectness_loss\n    prefixes = ['proposal.'] + [f's{i}.' for i in range(bbox_preds['num_decoder_layers'])]\n    num_stages = len(prefixes)\n    for prefix in prefixes:\n        obj_score = bbox_preds[f'{prefix}obj_scores'].transpose(2, 1)\n        objectness_loss = self.objectness_loss(obj_score.reshape(-1, 1), 1 - objectness_targets.reshape(-1), objectness_weights.reshape(-1), avg_factor=batch_size)\n        losses[f'{prefix}objectness_loss'] = objectness_loss / num_stages\n        box_loss_weights_expand = box_loss_weights.unsqueeze(-1).expand(-1, -1, 3)\n        center_loss = self.center_loss(bbox_preds[f'{prefix}center'], assigned_center_targets, weight=box_loss_weights_expand)\n        losses[f'{prefix}center_loss'] = center_loss / num_stages\n        dir_class_loss = self.dir_class_loss(bbox_preds[f'{prefix}dir_class'].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n        losses[f'{prefix}dir_class_loss'] = dir_class_loss / num_stages\n        heading_label_one_hot = size_class_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n        heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n        dir_res_norm = torch.sum(bbox_preds[f'{prefix}dir_res_norm'] * heading_label_one_hot, -1)\n        dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n        losses[f'{prefix}dir_res_loss'] = dir_res_loss / num_stages\n        if self.size_cls_agnostic:\n            size_reg_loss = self.size_reg_loss(bbox_preds[f'{prefix}size'], assigned_size_targets, weight=box_loss_weights_expand)\n            losses[f'{prefix}size_reg_loss'] = size_reg_loss / num_stages\n        else:\n            size_class_loss = self.size_class_loss(bbox_preds[f'{prefix}size_class'].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n            losses[f'{prefix}size_class_loss'] = size_class_loss / num_stages\n            one_hot_size_targets = size_class_targets.new_zeros((batch_size, proposal_num, self.num_sizes))\n            one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n            one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).expand(-1, -1, -1, 3).contiguous()\n            size_residual_norm = torch.sum(bbox_preds[f'{prefix}size_res_norm'] * one_hot_size_targets_expand, 2)\n            box_loss_weights_expand = box_loss_weights.unsqueeze(-1).expand(-1, -1, 3)\n            size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n            losses[f'{prefix}size_res_loss'] = size_res_loss / num_stages\n        semantic_loss = self.semantic_loss(bbox_preds[f'{prefix}sem_scores'].transpose(2, 1), mask_targets, weight=box_loss_weights)\n        losses[f'{prefix}semantic_loss'] = semantic_loss / num_stages\n    if ret_target:\n        losses['targets'] = targets\n    return losses",
            "@force_fp32(apply_to=('bbox_preds',))\ndef loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, gt_bboxes_ignore=None, ret_target=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Compute loss.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of vote head.\\n            points (list[torch.Tensor]): Input points.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each sample.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\\n                semantic mask.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise\\n                instance mask.\\n            img_metas (list[dict]): Contain pcd and img's meta info.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding.\\n            ret_target (Bool): Return targets or not.\\n\\n        Returns:\\n            dict: Losses of GroupFree3D.\\n        \"\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (sampling_targets, sampling_weights, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = targets\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    losses = dict()\n    sampling_obj_score = bbox_preds['seeds_obj_cls_logits'].reshape(-1, 1)\n    sampling_objectness_loss = self.sampling_objectness_loss(sampling_obj_score, 1 - sampling_targets.reshape(-1), sampling_weights.reshape(-1), avg_factor=batch_size)\n    losses['sampling_objectness_loss'] = sampling_objectness_loss\n    prefixes = ['proposal.'] + [f's{i}.' for i in range(bbox_preds['num_decoder_layers'])]\n    num_stages = len(prefixes)\n    for prefix in prefixes:\n        obj_score = bbox_preds[f'{prefix}obj_scores'].transpose(2, 1)\n        objectness_loss = self.objectness_loss(obj_score.reshape(-1, 1), 1 - objectness_targets.reshape(-1), objectness_weights.reshape(-1), avg_factor=batch_size)\n        losses[f'{prefix}objectness_loss'] = objectness_loss / num_stages\n        box_loss_weights_expand = box_loss_weights.unsqueeze(-1).expand(-1, -1, 3)\n        center_loss = self.center_loss(bbox_preds[f'{prefix}center'], assigned_center_targets, weight=box_loss_weights_expand)\n        losses[f'{prefix}center_loss'] = center_loss / num_stages\n        dir_class_loss = self.dir_class_loss(bbox_preds[f'{prefix}dir_class'].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n        losses[f'{prefix}dir_class_loss'] = dir_class_loss / num_stages\n        heading_label_one_hot = size_class_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n        heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n        dir_res_norm = torch.sum(bbox_preds[f'{prefix}dir_res_norm'] * heading_label_one_hot, -1)\n        dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n        losses[f'{prefix}dir_res_loss'] = dir_res_loss / num_stages\n        if self.size_cls_agnostic:\n            size_reg_loss = self.size_reg_loss(bbox_preds[f'{prefix}size'], assigned_size_targets, weight=box_loss_weights_expand)\n            losses[f'{prefix}size_reg_loss'] = size_reg_loss / num_stages\n        else:\n            size_class_loss = self.size_class_loss(bbox_preds[f'{prefix}size_class'].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n            losses[f'{prefix}size_class_loss'] = size_class_loss / num_stages\n            one_hot_size_targets = size_class_targets.new_zeros((batch_size, proposal_num, self.num_sizes))\n            one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n            one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).expand(-1, -1, -1, 3).contiguous()\n            size_residual_norm = torch.sum(bbox_preds[f'{prefix}size_res_norm'] * one_hot_size_targets_expand, 2)\n            box_loss_weights_expand = box_loss_weights.unsqueeze(-1).expand(-1, -1, 3)\n            size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n            losses[f'{prefix}size_res_loss'] = size_res_loss / num_stages\n        semantic_loss = self.semantic_loss(bbox_preds[f'{prefix}sem_scores'].transpose(2, 1), mask_targets, weight=box_loss_weights)\n        losses[f'{prefix}semantic_loss'] = semantic_loss / num_stages\n    if ret_target:\n        losses['targets'] = targets\n    return losses",
            "@force_fp32(apply_to=('bbox_preds',))\ndef loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, gt_bboxes_ignore=None, ret_target=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Compute loss.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of vote head.\\n            points (list[torch.Tensor]): Input points.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each sample.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\\n                semantic mask.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise\\n                instance mask.\\n            img_metas (list[dict]): Contain pcd and img's meta info.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding.\\n            ret_target (Bool): Return targets or not.\\n\\n        Returns:\\n            dict: Losses of GroupFree3D.\\n        \"\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (sampling_targets, sampling_weights, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = targets\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    losses = dict()\n    sampling_obj_score = bbox_preds['seeds_obj_cls_logits'].reshape(-1, 1)\n    sampling_objectness_loss = self.sampling_objectness_loss(sampling_obj_score, 1 - sampling_targets.reshape(-1), sampling_weights.reshape(-1), avg_factor=batch_size)\n    losses['sampling_objectness_loss'] = sampling_objectness_loss\n    prefixes = ['proposal.'] + [f's{i}.' for i in range(bbox_preds['num_decoder_layers'])]\n    num_stages = len(prefixes)\n    for prefix in prefixes:\n        obj_score = bbox_preds[f'{prefix}obj_scores'].transpose(2, 1)\n        objectness_loss = self.objectness_loss(obj_score.reshape(-1, 1), 1 - objectness_targets.reshape(-1), objectness_weights.reshape(-1), avg_factor=batch_size)\n        losses[f'{prefix}objectness_loss'] = objectness_loss / num_stages\n        box_loss_weights_expand = box_loss_weights.unsqueeze(-1).expand(-1, -1, 3)\n        center_loss = self.center_loss(bbox_preds[f'{prefix}center'], assigned_center_targets, weight=box_loss_weights_expand)\n        losses[f'{prefix}center_loss'] = center_loss / num_stages\n        dir_class_loss = self.dir_class_loss(bbox_preds[f'{prefix}dir_class'].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n        losses[f'{prefix}dir_class_loss'] = dir_class_loss / num_stages\n        heading_label_one_hot = size_class_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n        heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n        dir_res_norm = torch.sum(bbox_preds[f'{prefix}dir_res_norm'] * heading_label_one_hot, -1)\n        dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n        losses[f'{prefix}dir_res_loss'] = dir_res_loss / num_stages\n        if self.size_cls_agnostic:\n            size_reg_loss = self.size_reg_loss(bbox_preds[f'{prefix}size'], assigned_size_targets, weight=box_loss_weights_expand)\n            losses[f'{prefix}size_reg_loss'] = size_reg_loss / num_stages\n        else:\n            size_class_loss = self.size_class_loss(bbox_preds[f'{prefix}size_class'].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n            losses[f'{prefix}size_class_loss'] = size_class_loss / num_stages\n            one_hot_size_targets = size_class_targets.new_zeros((batch_size, proposal_num, self.num_sizes))\n            one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n            one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).expand(-1, -1, -1, 3).contiguous()\n            size_residual_norm = torch.sum(bbox_preds[f'{prefix}size_res_norm'] * one_hot_size_targets_expand, 2)\n            box_loss_weights_expand = box_loss_weights.unsqueeze(-1).expand(-1, -1, 3)\n            size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n            losses[f'{prefix}size_res_loss'] = size_res_loss / num_stages\n        semantic_loss = self.semantic_loss(bbox_preds[f'{prefix}sem_scores'].transpose(2, 1), mask_targets, weight=box_loss_weights)\n        losses[f'{prefix}semantic_loss'] = semantic_loss / num_stages\n    if ret_target:\n        losses['targets'] = targets\n    return losses",
            "@force_fp32(apply_to=('bbox_preds',))\ndef loss(self, bbox_preds, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, img_metas=None, gt_bboxes_ignore=None, ret_target=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Compute loss.\\n\\n        Args:\\n            bbox_preds (dict): Predictions from forward of vote head.\\n            points (list[torch.Tensor]): Input points.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each sample.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each sample.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise\\n                semantic mask.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise\\n                instance mask.\\n            img_metas (list[dict]): Contain pcd and img's meta info.\\n            gt_bboxes_ignore (list[torch.Tensor]): Specify\\n                which bounding.\\n            ret_target (Bool): Return targets or not.\\n\\n        Returns:\\n            dict: Losses of GroupFree3D.\\n        \"\n    targets = self.get_targets(points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, bbox_preds)\n    (sampling_targets, sampling_weights, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights) = targets\n    (batch_size, proposal_num) = size_class_targets.shape[:2]\n    losses = dict()\n    sampling_obj_score = bbox_preds['seeds_obj_cls_logits'].reshape(-1, 1)\n    sampling_objectness_loss = self.sampling_objectness_loss(sampling_obj_score, 1 - sampling_targets.reshape(-1), sampling_weights.reshape(-1), avg_factor=batch_size)\n    losses['sampling_objectness_loss'] = sampling_objectness_loss\n    prefixes = ['proposal.'] + [f's{i}.' for i in range(bbox_preds['num_decoder_layers'])]\n    num_stages = len(prefixes)\n    for prefix in prefixes:\n        obj_score = bbox_preds[f'{prefix}obj_scores'].transpose(2, 1)\n        objectness_loss = self.objectness_loss(obj_score.reshape(-1, 1), 1 - objectness_targets.reshape(-1), objectness_weights.reshape(-1), avg_factor=batch_size)\n        losses[f'{prefix}objectness_loss'] = objectness_loss / num_stages\n        box_loss_weights_expand = box_loss_weights.unsqueeze(-1).expand(-1, -1, 3)\n        center_loss = self.center_loss(bbox_preds[f'{prefix}center'], assigned_center_targets, weight=box_loss_weights_expand)\n        losses[f'{prefix}center_loss'] = center_loss / num_stages\n        dir_class_loss = self.dir_class_loss(bbox_preds[f'{prefix}dir_class'].transpose(2, 1), dir_class_targets, weight=box_loss_weights)\n        losses[f'{prefix}dir_class_loss'] = dir_class_loss / num_stages\n        heading_label_one_hot = size_class_targets.new_zeros((batch_size, proposal_num, self.num_dir_bins))\n        heading_label_one_hot.scatter_(2, dir_class_targets.unsqueeze(-1), 1)\n        dir_res_norm = torch.sum(bbox_preds[f'{prefix}dir_res_norm'] * heading_label_one_hot, -1)\n        dir_res_loss = self.dir_res_loss(dir_res_norm, dir_res_targets, weight=box_loss_weights)\n        losses[f'{prefix}dir_res_loss'] = dir_res_loss / num_stages\n        if self.size_cls_agnostic:\n            size_reg_loss = self.size_reg_loss(bbox_preds[f'{prefix}size'], assigned_size_targets, weight=box_loss_weights_expand)\n            losses[f'{prefix}size_reg_loss'] = size_reg_loss / num_stages\n        else:\n            size_class_loss = self.size_class_loss(bbox_preds[f'{prefix}size_class'].transpose(2, 1), size_class_targets, weight=box_loss_weights)\n            losses[f'{prefix}size_class_loss'] = size_class_loss / num_stages\n            one_hot_size_targets = size_class_targets.new_zeros((batch_size, proposal_num, self.num_sizes))\n            one_hot_size_targets.scatter_(2, size_class_targets.unsqueeze(-1), 1)\n            one_hot_size_targets_expand = one_hot_size_targets.unsqueeze(-1).expand(-1, -1, -1, 3).contiguous()\n            size_residual_norm = torch.sum(bbox_preds[f'{prefix}size_res_norm'] * one_hot_size_targets_expand, 2)\n            box_loss_weights_expand = box_loss_weights.unsqueeze(-1).expand(-1, -1, 3)\n            size_res_loss = self.size_res_loss(size_residual_norm, size_res_targets, weight=box_loss_weights_expand)\n            losses[f'{prefix}size_res_loss'] = size_res_loss / num_stages\n        semantic_loss = self.semantic_loss(bbox_preds[f'{prefix}sem_scores'].transpose(2, 1), mask_targets, weight=box_loss_weights)\n        losses[f'{prefix}semantic_loss'] = semantic_loss / num_stages\n    if ret_target:\n        losses['targets'] = targets\n    return losses"
        ]
    },
    {
        "func_name": "get_targets",
        "original": "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None, max_gt_num=64):\n    \"\"\"Generate targets of GroupFree3D head.\n\n        Args:\n            points (list[torch.Tensor]): Points of each batch.\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\n                bboxes of each batch.\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\n                label of each batch.\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\n                label of each batch.\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\n            max_gt_num (int): Max number of GTs for single batch.\n\n        Returns:\n            tuple[torch.Tensor]: Targets of GroupFree3D head.\n        \"\"\"\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    max_gt_nums = [max_gt_num for _ in range(len(gt_labels_3d))]\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    seed_points = [bbox_preds['seed_points'][i] for i in range(len(gt_labels_3d))]\n    seed_indices = [bbox_preds['seed_indices'][i] for i in range(len(gt_labels_3d))]\n    candidate_indices = [bbox_preds['query_points_sample_inds'][i] for i in range(len(gt_labels_3d))]\n    (sampling_targets, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, max_gt_nums, seed_points, seed_indices, candidate_indices)\n    for index in range(len(gt_labels_3d)):\n        pad_num = max_gt_num - gt_labels_3d[index].shape[0]\n        valid_gt_masks[index] = F.pad(valid_gt_masks[index], (0, pad_num))\n    sampling_targets = torch.stack(sampling_targets)\n    sampling_weights = (sampling_targets >= 0).float()\n    sampling_normalizer = sampling_weights.sum(dim=1, keepdim=True).float()\n    sampling_weights /= sampling_normalizer.clamp(min=1.0)\n    assigned_size_targets = torch.stack(assigned_size_targets)\n    center_targets = torch.stack(center_targets)\n    valid_gt_masks = torch.stack(valid_gt_masks)\n    assigned_center_targets = torch.stack(assigned_center_targets)\n    objectness_targets = torch.stack(objectness_targets)\n    objectness_weights = torch.stack(objectness_masks)\n    cls_normalizer = objectness_weights.sum(dim=1, keepdim=True).float()\n    objectness_weights /= cls_normalizer.clamp(min=1.0)\n    box_loss_weights = objectness_targets.float() / (objectness_targets.sum().float() + EPS)\n    valid_gt_weights = valid_gt_masks.float() / (valid_gt_masks.sum().float() + EPS)\n    dir_class_targets = torch.stack(dir_class_targets)\n    dir_res_targets = torch.stack(dir_res_targets)\n    size_class_targets = torch.stack(size_class_targets)\n    size_res_targets = torch.stack(size_res_targets)\n    mask_targets = torch.stack(mask_targets)\n    return (sampling_targets, sampling_weights, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights)",
        "mutated": [
            "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None, max_gt_num=64):\n    if False:\n        i = 10\n    'Generate targets of GroupFree3D head.\\n\\n        Args:\\n            points (list[torch.Tensor]): Points of each batch.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each batch.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\\n                label of each batch.\\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\\n            max_gt_num (int): Max number of GTs for single batch.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of GroupFree3D head.\\n        '\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    max_gt_nums = [max_gt_num for _ in range(len(gt_labels_3d))]\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    seed_points = [bbox_preds['seed_points'][i] for i in range(len(gt_labels_3d))]\n    seed_indices = [bbox_preds['seed_indices'][i] for i in range(len(gt_labels_3d))]\n    candidate_indices = [bbox_preds['query_points_sample_inds'][i] for i in range(len(gt_labels_3d))]\n    (sampling_targets, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, max_gt_nums, seed_points, seed_indices, candidate_indices)\n    for index in range(len(gt_labels_3d)):\n        pad_num = max_gt_num - gt_labels_3d[index].shape[0]\n        valid_gt_masks[index] = F.pad(valid_gt_masks[index], (0, pad_num))\n    sampling_targets = torch.stack(sampling_targets)\n    sampling_weights = (sampling_targets >= 0).float()\n    sampling_normalizer = sampling_weights.sum(dim=1, keepdim=True).float()\n    sampling_weights /= sampling_normalizer.clamp(min=1.0)\n    assigned_size_targets = torch.stack(assigned_size_targets)\n    center_targets = torch.stack(center_targets)\n    valid_gt_masks = torch.stack(valid_gt_masks)\n    assigned_center_targets = torch.stack(assigned_center_targets)\n    objectness_targets = torch.stack(objectness_targets)\n    objectness_weights = torch.stack(objectness_masks)\n    cls_normalizer = objectness_weights.sum(dim=1, keepdim=True).float()\n    objectness_weights /= cls_normalizer.clamp(min=1.0)\n    box_loss_weights = objectness_targets.float() / (objectness_targets.sum().float() + EPS)\n    valid_gt_weights = valid_gt_masks.float() / (valid_gt_masks.sum().float() + EPS)\n    dir_class_targets = torch.stack(dir_class_targets)\n    dir_res_targets = torch.stack(dir_res_targets)\n    size_class_targets = torch.stack(size_class_targets)\n    size_res_targets = torch.stack(size_res_targets)\n    mask_targets = torch.stack(mask_targets)\n    return (sampling_targets, sampling_weights, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights)",
            "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None, max_gt_num=64):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Generate targets of GroupFree3D head.\\n\\n        Args:\\n            points (list[torch.Tensor]): Points of each batch.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each batch.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\\n                label of each batch.\\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\\n            max_gt_num (int): Max number of GTs for single batch.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of GroupFree3D head.\\n        '\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    max_gt_nums = [max_gt_num for _ in range(len(gt_labels_3d))]\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    seed_points = [bbox_preds['seed_points'][i] for i in range(len(gt_labels_3d))]\n    seed_indices = [bbox_preds['seed_indices'][i] for i in range(len(gt_labels_3d))]\n    candidate_indices = [bbox_preds['query_points_sample_inds'][i] for i in range(len(gt_labels_3d))]\n    (sampling_targets, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, max_gt_nums, seed_points, seed_indices, candidate_indices)\n    for index in range(len(gt_labels_3d)):\n        pad_num = max_gt_num - gt_labels_3d[index].shape[0]\n        valid_gt_masks[index] = F.pad(valid_gt_masks[index], (0, pad_num))\n    sampling_targets = torch.stack(sampling_targets)\n    sampling_weights = (sampling_targets >= 0).float()\n    sampling_normalizer = sampling_weights.sum(dim=1, keepdim=True).float()\n    sampling_weights /= sampling_normalizer.clamp(min=1.0)\n    assigned_size_targets = torch.stack(assigned_size_targets)\n    center_targets = torch.stack(center_targets)\n    valid_gt_masks = torch.stack(valid_gt_masks)\n    assigned_center_targets = torch.stack(assigned_center_targets)\n    objectness_targets = torch.stack(objectness_targets)\n    objectness_weights = torch.stack(objectness_masks)\n    cls_normalizer = objectness_weights.sum(dim=1, keepdim=True).float()\n    objectness_weights /= cls_normalizer.clamp(min=1.0)\n    box_loss_weights = objectness_targets.float() / (objectness_targets.sum().float() + EPS)\n    valid_gt_weights = valid_gt_masks.float() / (valid_gt_masks.sum().float() + EPS)\n    dir_class_targets = torch.stack(dir_class_targets)\n    dir_res_targets = torch.stack(dir_res_targets)\n    size_class_targets = torch.stack(size_class_targets)\n    size_res_targets = torch.stack(size_res_targets)\n    mask_targets = torch.stack(mask_targets)\n    return (sampling_targets, sampling_weights, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights)",
            "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None, max_gt_num=64):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Generate targets of GroupFree3D head.\\n\\n        Args:\\n            points (list[torch.Tensor]): Points of each batch.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each batch.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\\n                label of each batch.\\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\\n            max_gt_num (int): Max number of GTs for single batch.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of GroupFree3D head.\\n        '\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    max_gt_nums = [max_gt_num for _ in range(len(gt_labels_3d))]\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    seed_points = [bbox_preds['seed_points'][i] for i in range(len(gt_labels_3d))]\n    seed_indices = [bbox_preds['seed_indices'][i] for i in range(len(gt_labels_3d))]\n    candidate_indices = [bbox_preds['query_points_sample_inds'][i] for i in range(len(gt_labels_3d))]\n    (sampling_targets, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, max_gt_nums, seed_points, seed_indices, candidate_indices)\n    for index in range(len(gt_labels_3d)):\n        pad_num = max_gt_num - gt_labels_3d[index].shape[0]\n        valid_gt_masks[index] = F.pad(valid_gt_masks[index], (0, pad_num))\n    sampling_targets = torch.stack(sampling_targets)\n    sampling_weights = (sampling_targets >= 0).float()\n    sampling_normalizer = sampling_weights.sum(dim=1, keepdim=True).float()\n    sampling_weights /= sampling_normalizer.clamp(min=1.0)\n    assigned_size_targets = torch.stack(assigned_size_targets)\n    center_targets = torch.stack(center_targets)\n    valid_gt_masks = torch.stack(valid_gt_masks)\n    assigned_center_targets = torch.stack(assigned_center_targets)\n    objectness_targets = torch.stack(objectness_targets)\n    objectness_weights = torch.stack(objectness_masks)\n    cls_normalizer = objectness_weights.sum(dim=1, keepdim=True).float()\n    objectness_weights /= cls_normalizer.clamp(min=1.0)\n    box_loss_weights = objectness_targets.float() / (objectness_targets.sum().float() + EPS)\n    valid_gt_weights = valid_gt_masks.float() / (valid_gt_masks.sum().float() + EPS)\n    dir_class_targets = torch.stack(dir_class_targets)\n    dir_res_targets = torch.stack(dir_res_targets)\n    size_class_targets = torch.stack(size_class_targets)\n    size_res_targets = torch.stack(size_res_targets)\n    mask_targets = torch.stack(mask_targets)\n    return (sampling_targets, sampling_weights, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights)",
            "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None, max_gt_num=64):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Generate targets of GroupFree3D head.\\n\\n        Args:\\n            points (list[torch.Tensor]): Points of each batch.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each batch.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\\n                label of each batch.\\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\\n            max_gt_num (int): Max number of GTs for single batch.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of GroupFree3D head.\\n        '\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    max_gt_nums = [max_gt_num for _ in range(len(gt_labels_3d))]\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    seed_points = [bbox_preds['seed_points'][i] for i in range(len(gt_labels_3d))]\n    seed_indices = [bbox_preds['seed_indices'][i] for i in range(len(gt_labels_3d))]\n    candidate_indices = [bbox_preds['query_points_sample_inds'][i] for i in range(len(gt_labels_3d))]\n    (sampling_targets, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, max_gt_nums, seed_points, seed_indices, candidate_indices)\n    for index in range(len(gt_labels_3d)):\n        pad_num = max_gt_num - gt_labels_3d[index].shape[0]\n        valid_gt_masks[index] = F.pad(valid_gt_masks[index], (0, pad_num))\n    sampling_targets = torch.stack(sampling_targets)\n    sampling_weights = (sampling_targets >= 0).float()\n    sampling_normalizer = sampling_weights.sum(dim=1, keepdim=True).float()\n    sampling_weights /= sampling_normalizer.clamp(min=1.0)\n    assigned_size_targets = torch.stack(assigned_size_targets)\n    center_targets = torch.stack(center_targets)\n    valid_gt_masks = torch.stack(valid_gt_masks)\n    assigned_center_targets = torch.stack(assigned_center_targets)\n    objectness_targets = torch.stack(objectness_targets)\n    objectness_weights = torch.stack(objectness_masks)\n    cls_normalizer = objectness_weights.sum(dim=1, keepdim=True).float()\n    objectness_weights /= cls_normalizer.clamp(min=1.0)\n    box_loss_weights = objectness_targets.float() / (objectness_targets.sum().float() + EPS)\n    valid_gt_weights = valid_gt_masks.float() / (valid_gt_masks.sum().float() + EPS)\n    dir_class_targets = torch.stack(dir_class_targets)\n    dir_res_targets = torch.stack(dir_res_targets)\n    size_class_targets = torch.stack(size_class_targets)\n    size_res_targets = torch.stack(size_res_targets)\n    mask_targets = torch.stack(mask_targets)\n    return (sampling_targets, sampling_weights, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights)",
            "def get_targets(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, bbox_preds=None, max_gt_num=64):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Generate targets of GroupFree3D head.\\n\\n        Args:\\n            points (list[torch.Tensor]): Points of each batch.\\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`]): Ground truth\\n                bboxes of each batch.\\n            gt_labels_3d (list[torch.Tensor]): Labels of each batch.\\n            pts_semantic_mask (list[torch.Tensor]): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (list[torch.Tensor]): Point-wise instance\\n                label of each batch.\\n            bbox_preds (torch.Tensor): Bounding box predictions of vote head.\\n            max_gt_num (int): Max number of GTs for single batch.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of GroupFree3D head.\\n        '\n    valid_gt_masks = list()\n    gt_num = list()\n    for index in range(len(gt_labels_3d)):\n        if len(gt_labels_3d[index]) == 0:\n            fake_box = gt_bboxes_3d[index].tensor.new_zeros(1, gt_bboxes_3d[index].tensor.shape[-1])\n            gt_bboxes_3d[index] = gt_bboxes_3d[index].new_box(fake_box)\n            gt_labels_3d[index] = gt_labels_3d[index].new_zeros(1)\n            valid_gt_masks.append(gt_labels_3d[index].new_zeros(1))\n            gt_num.append(1)\n        else:\n            valid_gt_masks.append(gt_labels_3d[index].new_ones(gt_labels_3d[index].shape))\n            gt_num.append(gt_labels_3d[index].shape[0])\n    max_gt_nums = [max_gt_num for _ in range(len(gt_labels_3d))]\n    if pts_semantic_mask is None:\n        pts_semantic_mask = [None for i in range(len(gt_labels_3d))]\n        pts_instance_mask = [None for i in range(len(gt_labels_3d))]\n    seed_points = [bbox_preds['seed_points'][i] for i in range(len(gt_labels_3d))]\n    seed_indices = [bbox_preds['seed_indices'][i] for i in range(len(gt_labels_3d))]\n    candidate_indices = [bbox_preds['query_points_sample_inds'][i] for i in range(len(gt_labels_3d))]\n    (sampling_targets, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks) = multi_apply(self.get_targets_single, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask, pts_instance_mask, max_gt_nums, seed_points, seed_indices, candidate_indices)\n    for index in range(len(gt_labels_3d)):\n        pad_num = max_gt_num - gt_labels_3d[index].shape[0]\n        valid_gt_masks[index] = F.pad(valid_gt_masks[index], (0, pad_num))\n    sampling_targets = torch.stack(sampling_targets)\n    sampling_weights = (sampling_targets >= 0).float()\n    sampling_normalizer = sampling_weights.sum(dim=1, keepdim=True).float()\n    sampling_weights /= sampling_normalizer.clamp(min=1.0)\n    assigned_size_targets = torch.stack(assigned_size_targets)\n    center_targets = torch.stack(center_targets)\n    valid_gt_masks = torch.stack(valid_gt_masks)\n    assigned_center_targets = torch.stack(assigned_center_targets)\n    objectness_targets = torch.stack(objectness_targets)\n    objectness_weights = torch.stack(objectness_masks)\n    cls_normalizer = objectness_weights.sum(dim=1, keepdim=True).float()\n    objectness_weights /= cls_normalizer.clamp(min=1.0)\n    box_loss_weights = objectness_targets.float() / (objectness_targets.sum().float() + EPS)\n    valid_gt_weights = valid_gt_masks.float() / (valid_gt_masks.sum().float() + EPS)\n    dir_class_targets = torch.stack(dir_class_targets)\n    dir_res_targets = torch.stack(dir_res_targets)\n    size_class_targets = torch.stack(size_class_targets)\n    size_res_targets = torch.stack(size_res_targets)\n    mask_targets = torch.stack(mask_targets)\n    return (sampling_targets, sampling_weights, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, valid_gt_masks, objectness_targets, objectness_weights, box_loss_weights, valid_gt_weights)"
        ]
    },
    {
        "func_name": "get_targets_single",
        "original": "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, max_gt_nums=None, seed_points=None, seed_indices=None, candidate_indices=None, seed_points_obj_topk=4):\n    \"\"\"Generate targets of GroupFree3D head for single batch.\n\n        Args:\n            points (torch.Tensor): Points of each batch.\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\n                boxes of each batch.\n            gt_labels_3d (torch.Tensor): Labels of each batch.\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\n                label of each batch.\n            pts_instance_mask (torch.Tensor): Point-wise instance\n                label of each batch.\n            max_gt_nums (int): Max number of GTs for single batch.\n            seed_points (torch.Tensor): Coordinates of seed points.\n            seed_indices (torch.Tensor): Indices of seed points.\n            candidate_indices (torch.Tensor): Indices of object candidates.\n            seed_points_obj_topk (int): k value of k-Closest Points Sampling.\n\n        Returns:\n            tuple[torch.Tensor]: Targets of GroupFree3D head.\n        \"\"\"\n    assert self.bbox_coder.with_rot or pts_semantic_mask is not None\n    gt_bboxes_3d = gt_bboxes_3d.to(points.device)\n    (center_targets, size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets) = self.bbox_coder.encode(gt_bboxes_3d, gt_labels_3d)\n    pad_num = max_gt_nums - gt_labels_3d.shape[0]\n    box_label_mask = points.new_zeros([max_gt_nums])\n    box_label_mask[:gt_labels_3d.shape[0]] = 1\n    gt_bboxes_pad = F.pad(gt_bboxes_3d.tensor, (0, 0, 0, pad_num))\n    gt_bboxes_pad[gt_labels_3d.shape[0]:, 0:3] += 1000\n    gt_bboxes_3d = gt_bboxes_3d.new_box(gt_bboxes_pad)\n    gt_labels_3d = F.pad(gt_labels_3d, (0, pad_num))\n    center_targets = F.pad(center_targets, (0, 0, 0, pad_num), value=1000)\n    size_targets = F.pad(size_targets, (0, 0, 0, pad_num))\n    size_class_targets = F.pad(size_class_targets, (0, pad_num))\n    size_res_targets = F.pad(size_res_targets, (0, 0, 0, pad_num))\n    dir_class_targets = F.pad(dir_class_targets, (0, pad_num))\n    dir_res_targets = F.pad(dir_res_targets, (0, pad_num))\n    num_points = points.shape[0]\n    pts_obj_mask = points.new_zeros([num_points], dtype=torch.long)\n    pts_instance_label = points.new_zeros([num_points], dtype=torch.long) - 1\n    if self.bbox_coder.with_rot:\n        vote_targets = points.new_zeros([num_points, 4 * self.gt_per_seed])\n        vote_target_idx = points.new_zeros([num_points], dtype=torch.long)\n        box_indices_all = gt_bboxes_3d.points_in_boxes_part(points)\n        for i in range(gt_labels_3d.shape[0]):\n            box_indices = box_indices_all[:, i]\n            indices = torch.nonzero(box_indices, as_tuple=False).squeeze(-1)\n            selected_points = points[indices]\n            pts_obj_mask[indices] = 1\n            vote_targets_tmp = vote_targets[indices]\n            votes = gt_bboxes_3d.gravity_center[i].unsqueeze(0) - selected_points[:, :3]\n            for j in range(self.gt_per_seed):\n                column_indices = torch.nonzero(vote_target_idx[indices] == j, as_tuple=False).squeeze(-1)\n                vote_targets_tmp[column_indices, int(j * 3):int(j * 3 + 3)] = votes[column_indices]\n                vote_targets_tmp[column_indices, j + 3 * self.gt_per_seed] = i\n                if j == 0:\n                    vote_targets_tmp[column_indices, :3 * self.gt_per_seed] = votes[column_indices].repeat(1, self.gt_per_seed)\n                    vote_targets_tmp[column_indices, 3 * self.gt_per_seed:] = i\n            vote_targets[indices] = vote_targets_tmp\n            vote_target_idx[indices] = torch.clamp(vote_target_idx[indices] + 1, max=2)\n        dist = points.new_zeros([num_points, self.gt_per_seed]) + 1000\n        for j in range(self.gt_per_seed):\n            dist[:, j] = (vote_targets[:, 3 * j:3 * j + 3] ** 2).sum(-1)\n        instance_indices = torch.argmin(dist, dim=-1).unsqueeze(-1) + 3 * self.gt_per_seed\n        instance_lable = torch.gather(vote_targets, 1, instance_indices).squeeze(-1)\n        pts_instance_label = instance_lable.long()\n        pts_instance_label[pts_obj_mask == 0] = -1\n    elif pts_semantic_mask is not None:\n        for i in torch.unique(pts_instance_mask):\n            indices = torch.nonzero(pts_instance_mask == i, as_tuple=False).squeeze(-1)\n            if pts_semantic_mask[indices[0]] < self.num_classes:\n                selected_points = points[indices, :3]\n                center = 0.5 * (selected_points.min(0)[0] + selected_points.max(0)[0])\n                delta_xyz = center - center_targets\n                instance_lable = torch.argmin((delta_xyz ** 2).sum(-1))\n                pts_instance_label[indices] = instance_lable\n                pts_obj_mask[indices] = 1\n    else:\n        raise NotImplementedError\n    gt_num = gt_labels_3d.shape[0]\n    num_seed = seed_points.shape[0]\n    num_candidate = candidate_indices.shape[0]\n    object_assignment = torch.gather(pts_instance_label, 0, seed_indices)\n    object_assignment[object_assignment < 0] = gt_num - 1\n    object_assignment_one_hot = gt_bboxes_3d.tensor.new_zeros((num_seed, gt_num))\n    object_assignment_one_hot.scatter_(1, object_assignment.unsqueeze(-1), 1)\n    delta_xyz = seed_points.unsqueeze(1) - gt_bboxes_3d.gravity_center.unsqueeze(0)\n    delta_xyz = delta_xyz / (gt_bboxes_3d.dims.unsqueeze(0) + EPS)\n    new_dist = torch.sum(delta_xyz ** 2, dim=-1)\n    euclidean_dist1 = torch.sqrt(new_dist + EPS)\n    euclidean_dist1 = euclidean_dist1 * object_assignment_one_hot + 100 * (1 - object_assignment_one_hot)\n    euclidean_dist1 = euclidean_dist1.permute(1, 0)\n    topk_inds = torch.topk(euclidean_dist1, seed_points_obj_topk, largest=False)[1] * box_label_mask[:, None] + (box_label_mask[:, None] - 1)\n    topk_inds = topk_inds.long()\n    topk_inds = topk_inds.view(-1).contiguous()\n    sampling_targets = torch.zeros(num_seed + 1, dtype=torch.long).to(points.device)\n    sampling_targets[topk_inds] = 1\n    sampling_targets = sampling_targets[:num_seed]\n    objectness_label_mask = torch.gather(pts_instance_label, 0, seed_indices)\n    sampling_targets[objectness_label_mask < 0] = 0\n    seed_obj_gt = torch.gather(pts_obj_mask, 0, seed_indices)\n    objectness_targets = torch.gather(seed_obj_gt, 0, candidate_indices)\n    seed_instance_label = torch.gather(pts_instance_label, 0, seed_indices)\n    query_points_instance_label = torch.gather(seed_instance_label, 0, candidate_indices)\n    assignment = query_points_instance_label\n    assignment[assignment < 0] = gt_num - 1\n    assignment_expand = assignment.unsqueeze(1).expand(-1, 3)\n    assigned_center_targets = center_targets[assignment]\n    assigned_size_targets = size_targets[assignment]\n    dir_class_targets = dir_class_targets[assignment]\n    dir_res_targets = dir_res_targets[assignment]\n    dir_res_targets /= np.pi / self.num_dir_bins\n    size_class_targets = size_class_targets[assignment]\n    size_res_targets = torch.gather(size_res_targets, 0, assignment_expand)\n    one_hot_size_targets = gt_bboxes_3d.tensor.new_zeros((num_candidate, self.num_sizes))\n    one_hot_size_targets.scatter_(1, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets = one_hot_size_targets.unsqueeze(-1).expand(-1, -1, 3)\n    mean_sizes = size_res_targets.new_tensor(self.bbox_coder.mean_sizes).unsqueeze(0)\n    pos_mean_sizes = torch.sum(one_hot_size_targets * mean_sizes, 1)\n    size_res_targets /= pos_mean_sizes\n    mask_targets = gt_labels_3d[assignment].long()\n    objectness_masks = points.new_ones(num_candidate)\n    return (sampling_targets, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks)",
        "mutated": [
            "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, max_gt_nums=None, seed_points=None, seed_indices=None, candidate_indices=None, seed_points_obj_topk=4):\n    if False:\n        i = 10\n    'Generate targets of GroupFree3D head for single batch.\\n\\n        Args:\\n            points (torch.Tensor): Points of each batch.\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\\n                boxes of each batch.\\n            gt_labels_3d (torch.Tensor): Labels of each batch.\\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (torch.Tensor): Point-wise instance\\n                label of each batch.\\n            max_gt_nums (int): Max number of GTs for single batch.\\n            seed_points (torch.Tensor): Coordinates of seed points.\\n            seed_indices (torch.Tensor): Indices of seed points.\\n            candidate_indices (torch.Tensor): Indices of object candidates.\\n            seed_points_obj_topk (int): k value of k-Closest Points Sampling.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of GroupFree3D head.\\n        '\n    assert self.bbox_coder.with_rot or pts_semantic_mask is not None\n    gt_bboxes_3d = gt_bboxes_3d.to(points.device)\n    (center_targets, size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets) = self.bbox_coder.encode(gt_bboxes_3d, gt_labels_3d)\n    pad_num = max_gt_nums - gt_labels_3d.shape[0]\n    box_label_mask = points.new_zeros([max_gt_nums])\n    box_label_mask[:gt_labels_3d.shape[0]] = 1\n    gt_bboxes_pad = F.pad(gt_bboxes_3d.tensor, (0, 0, 0, pad_num))\n    gt_bboxes_pad[gt_labels_3d.shape[0]:, 0:3] += 1000\n    gt_bboxes_3d = gt_bboxes_3d.new_box(gt_bboxes_pad)\n    gt_labels_3d = F.pad(gt_labels_3d, (0, pad_num))\n    center_targets = F.pad(center_targets, (0, 0, 0, pad_num), value=1000)\n    size_targets = F.pad(size_targets, (0, 0, 0, pad_num))\n    size_class_targets = F.pad(size_class_targets, (0, pad_num))\n    size_res_targets = F.pad(size_res_targets, (0, 0, 0, pad_num))\n    dir_class_targets = F.pad(dir_class_targets, (0, pad_num))\n    dir_res_targets = F.pad(dir_res_targets, (0, pad_num))\n    num_points = points.shape[0]\n    pts_obj_mask = points.new_zeros([num_points], dtype=torch.long)\n    pts_instance_label = points.new_zeros([num_points], dtype=torch.long) - 1\n    if self.bbox_coder.with_rot:\n        vote_targets = points.new_zeros([num_points, 4 * self.gt_per_seed])\n        vote_target_idx = points.new_zeros([num_points], dtype=torch.long)\n        box_indices_all = gt_bboxes_3d.points_in_boxes_part(points)\n        for i in range(gt_labels_3d.shape[0]):\n            box_indices = box_indices_all[:, i]\n            indices = torch.nonzero(box_indices, as_tuple=False).squeeze(-1)\n            selected_points = points[indices]\n            pts_obj_mask[indices] = 1\n            vote_targets_tmp = vote_targets[indices]\n            votes = gt_bboxes_3d.gravity_center[i].unsqueeze(0) - selected_points[:, :3]\n            for j in range(self.gt_per_seed):\n                column_indices = torch.nonzero(vote_target_idx[indices] == j, as_tuple=False).squeeze(-1)\n                vote_targets_tmp[column_indices, int(j * 3):int(j * 3 + 3)] = votes[column_indices]\n                vote_targets_tmp[column_indices, j + 3 * self.gt_per_seed] = i\n                if j == 0:\n                    vote_targets_tmp[column_indices, :3 * self.gt_per_seed] = votes[column_indices].repeat(1, self.gt_per_seed)\n                    vote_targets_tmp[column_indices, 3 * self.gt_per_seed:] = i\n            vote_targets[indices] = vote_targets_tmp\n            vote_target_idx[indices] = torch.clamp(vote_target_idx[indices] + 1, max=2)\n        dist = points.new_zeros([num_points, self.gt_per_seed]) + 1000\n        for j in range(self.gt_per_seed):\n            dist[:, j] = (vote_targets[:, 3 * j:3 * j + 3] ** 2).sum(-1)\n        instance_indices = torch.argmin(dist, dim=-1).unsqueeze(-1) + 3 * self.gt_per_seed\n        instance_lable = torch.gather(vote_targets, 1, instance_indices).squeeze(-1)\n        pts_instance_label = instance_lable.long()\n        pts_instance_label[pts_obj_mask == 0] = -1\n    elif pts_semantic_mask is not None:\n        for i in torch.unique(pts_instance_mask):\n            indices = torch.nonzero(pts_instance_mask == i, as_tuple=False).squeeze(-1)\n            if pts_semantic_mask[indices[0]] < self.num_classes:\n                selected_points = points[indices, :3]\n                center = 0.5 * (selected_points.min(0)[0] + selected_points.max(0)[0])\n                delta_xyz = center - center_targets\n                instance_lable = torch.argmin((delta_xyz ** 2).sum(-1))\n                pts_instance_label[indices] = instance_lable\n                pts_obj_mask[indices] = 1\n    else:\n        raise NotImplementedError\n    gt_num = gt_labels_3d.shape[0]\n    num_seed = seed_points.shape[0]\n    num_candidate = candidate_indices.shape[0]\n    object_assignment = torch.gather(pts_instance_label, 0, seed_indices)\n    object_assignment[object_assignment < 0] = gt_num - 1\n    object_assignment_one_hot = gt_bboxes_3d.tensor.new_zeros((num_seed, gt_num))\n    object_assignment_one_hot.scatter_(1, object_assignment.unsqueeze(-1), 1)\n    delta_xyz = seed_points.unsqueeze(1) - gt_bboxes_3d.gravity_center.unsqueeze(0)\n    delta_xyz = delta_xyz / (gt_bboxes_3d.dims.unsqueeze(0) + EPS)\n    new_dist = torch.sum(delta_xyz ** 2, dim=-1)\n    euclidean_dist1 = torch.sqrt(new_dist + EPS)\n    euclidean_dist1 = euclidean_dist1 * object_assignment_one_hot + 100 * (1 - object_assignment_one_hot)\n    euclidean_dist1 = euclidean_dist1.permute(1, 0)\n    topk_inds = torch.topk(euclidean_dist1, seed_points_obj_topk, largest=False)[1] * box_label_mask[:, None] + (box_label_mask[:, None] - 1)\n    topk_inds = topk_inds.long()\n    topk_inds = topk_inds.view(-1).contiguous()\n    sampling_targets = torch.zeros(num_seed + 1, dtype=torch.long).to(points.device)\n    sampling_targets[topk_inds] = 1\n    sampling_targets = sampling_targets[:num_seed]\n    objectness_label_mask = torch.gather(pts_instance_label, 0, seed_indices)\n    sampling_targets[objectness_label_mask < 0] = 0\n    seed_obj_gt = torch.gather(pts_obj_mask, 0, seed_indices)\n    objectness_targets = torch.gather(seed_obj_gt, 0, candidate_indices)\n    seed_instance_label = torch.gather(pts_instance_label, 0, seed_indices)\n    query_points_instance_label = torch.gather(seed_instance_label, 0, candidate_indices)\n    assignment = query_points_instance_label\n    assignment[assignment < 0] = gt_num - 1\n    assignment_expand = assignment.unsqueeze(1).expand(-1, 3)\n    assigned_center_targets = center_targets[assignment]\n    assigned_size_targets = size_targets[assignment]\n    dir_class_targets = dir_class_targets[assignment]\n    dir_res_targets = dir_res_targets[assignment]\n    dir_res_targets /= np.pi / self.num_dir_bins\n    size_class_targets = size_class_targets[assignment]\n    size_res_targets = torch.gather(size_res_targets, 0, assignment_expand)\n    one_hot_size_targets = gt_bboxes_3d.tensor.new_zeros((num_candidate, self.num_sizes))\n    one_hot_size_targets.scatter_(1, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets = one_hot_size_targets.unsqueeze(-1).expand(-1, -1, 3)\n    mean_sizes = size_res_targets.new_tensor(self.bbox_coder.mean_sizes).unsqueeze(0)\n    pos_mean_sizes = torch.sum(one_hot_size_targets * mean_sizes, 1)\n    size_res_targets /= pos_mean_sizes\n    mask_targets = gt_labels_3d[assignment].long()\n    objectness_masks = points.new_ones(num_candidate)\n    return (sampling_targets, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks)",
            "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, max_gt_nums=None, seed_points=None, seed_indices=None, candidate_indices=None, seed_points_obj_topk=4):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Generate targets of GroupFree3D head for single batch.\\n\\n        Args:\\n            points (torch.Tensor): Points of each batch.\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\\n                boxes of each batch.\\n            gt_labels_3d (torch.Tensor): Labels of each batch.\\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (torch.Tensor): Point-wise instance\\n                label of each batch.\\n            max_gt_nums (int): Max number of GTs for single batch.\\n            seed_points (torch.Tensor): Coordinates of seed points.\\n            seed_indices (torch.Tensor): Indices of seed points.\\n            candidate_indices (torch.Tensor): Indices of object candidates.\\n            seed_points_obj_topk (int): k value of k-Closest Points Sampling.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of GroupFree3D head.\\n        '\n    assert self.bbox_coder.with_rot or pts_semantic_mask is not None\n    gt_bboxes_3d = gt_bboxes_3d.to(points.device)\n    (center_targets, size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets) = self.bbox_coder.encode(gt_bboxes_3d, gt_labels_3d)\n    pad_num = max_gt_nums - gt_labels_3d.shape[0]\n    box_label_mask = points.new_zeros([max_gt_nums])\n    box_label_mask[:gt_labels_3d.shape[0]] = 1\n    gt_bboxes_pad = F.pad(gt_bboxes_3d.tensor, (0, 0, 0, pad_num))\n    gt_bboxes_pad[gt_labels_3d.shape[0]:, 0:3] += 1000\n    gt_bboxes_3d = gt_bboxes_3d.new_box(gt_bboxes_pad)\n    gt_labels_3d = F.pad(gt_labels_3d, (0, pad_num))\n    center_targets = F.pad(center_targets, (0, 0, 0, pad_num), value=1000)\n    size_targets = F.pad(size_targets, (0, 0, 0, pad_num))\n    size_class_targets = F.pad(size_class_targets, (0, pad_num))\n    size_res_targets = F.pad(size_res_targets, (0, 0, 0, pad_num))\n    dir_class_targets = F.pad(dir_class_targets, (0, pad_num))\n    dir_res_targets = F.pad(dir_res_targets, (0, pad_num))\n    num_points = points.shape[0]\n    pts_obj_mask = points.new_zeros([num_points], dtype=torch.long)\n    pts_instance_label = points.new_zeros([num_points], dtype=torch.long) - 1\n    if self.bbox_coder.with_rot:\n        vote_targets = points.new_zeros([num_points, 4 * self.gt_per_seed])\n        vote_target_idx = points.new_zeros([num_points], dtype=torch.long)\n        box_indices_all = gt_bboxes_3d.points_in_boxes_part(points)\n        for i in range(gt_labels_3d.shape[0]):\n            box_indices = box_indices_all[:, i]\n            indices = torch.nonzero(box_indices, as_tuple=False).squeeze(-1)\n            selected_points = points[indices]\n            pts_obj_mask[indices] = 1\n            vote_targets_tmp = vote_targets[indices]\n            votes = gt_bboxes_3d.gravity_center[i].unsqueeze(0) - selected_points[:, :3]\n            for j in range(self.gt_per_seed):\n                column_indices = torch.nonzero(vote_target_idx[indices] == j, as_tuple=False).squeeze(-1)\n                vote_targets_tmp[column_indices, int(j * 3):int(j * 3 + 3)] = votes[column_indices]\n                vote_targets_tmp[column_indices, j + 3 * self.gt_per_seed] = i\n                if j == 0:\n                    vote_targets_tmp[column_indices, :3 * self.gt_per_seed] = votes[column_indices].repeat(1, self.gt_per_seed)\n                    vote_targets_tmp[column_indices, 3 * self.gt_per_seed:] = i\n            vote_targets[indices] = vote_targets_tmp\n            vote_target_idx[indices] = torch.clamp(vote_target_idx[indices] + 1, max=2)\n        dist = points.new_zeros([num_points, self.gt_per_seed]) + 1000\n        for j in range(self.gt_per_seed):\n            dist[:, j] = (vote_targets[:, 3 * j:3 * j + 3] ** 2).sum(-1)\n        instance_indices = torch.argmin(dist, dim=-1).unsqueeze(-1) + 3 * self.gt_per_seed\n        instance_lable = torch.gather(vote_targets, 1, instance_indices).squeeze(-1)\n        pts_instance_label = instance_lable.long()\n        pts_instance_label[pts_obj_mask == 0] = -1\n    elif pts_semantic_mask is not None:\n        for i in torch.unique(pts_instance_mask):\n            indices = torch.nonzero(pts_instance_mask == i, as_tuple=False).squeeze(-1)\n            if pts_semantic_mask[indices[0]] < self.num_classes:\n                selected_points = points[indices, :3]\n                center = 0.5 * (selected_points.min(0)[0] + selected_points.max(0)[0])\n                delta_xyz = center - center_targets\n                instance_lable = torch.argmin((delta_xyz ** 2).sum(-1))\n                pts_instance_label[indices] = instance_lable\n                pts_obj_mask[indices] = 1\n    else:\n        raise NotImplementedError\n    gt_num = gt_labels_3d.shape[0]\n    num_seed = seed_points.shape[0]\n    num_candidate = candidate_indices.shape[0]\n    object_assignment = torch.gather(pts_instance_label, 0, seed_indices)\n    object_assignment[object_assignment < 0] = gt_num - 1\n    object_assignment_one_hot = gt_bboxes_3d.tensor.new_zeros((num_seed, gt_num))\n    object_assignment_one_hot.scatter_(1, object_assignment.unsqueeze(-1), 1)\n    delta_xyz = seed_points.unsqueeze(1) - gt_bboxes_3d.gravity_center.unsqueeze(0)\n    delta_xyz = delta_xyz / (gt_bboxes_3d.dims.unsqueeze(0) + EPS)\n    new_dist = torch.sum(delta_xyz ** 2, dim=-1)\n    euclidean_dist1 = torch.sqrt(new_dist + EPS)\n    euclidean_dist1 = euclidean_dist1 * object_assignment_one_hot + 100 * (1 - object_assignment_one_hot)\n    euclidean_dist1 = euclidean_dist1.permute(1, 0)\n    topk_inds = torch.topk(euclidean_dist1, seed_points_obj_topk, largest=False)[1] * box_label_mask[:, None] + (box_label_mask[:, None] - 1)\n    topk_inds = topk_inds.long()\n    topk_inds = topk_inds.view(-1).contiguous()\n    sampling_targets = torch.zeros(num_seed + 1, dtype=torch.long).to(points.device)\n    sampling_targets[topk_inds] = 1\n    sampling_targets = sampling_targets[:num_seed]\n    objectness_label_mask = torch.gather(pts_instance_label, 0, seed_indices)\n    sampling_targets[objectness_label_mask < 0] = 0\n    seed_obj_gt = torch.gather(pts_obj_mask, 0, seed_indices)\n    objectness_targets = torch.gather(seed_obj_gt, 0, candidate_indices)\n    seed_instance_label = torch.gather(pts_instance_label, 0, seed_indices)\n    query_points_instance_label = torch.gather(seed_instance_label, 0, candidate_indices)\n    assignment = query_points_instance_label\n    assignment[assignment < 0] = gt_num - 1\n    assignment_expand = assignment.unsqueeze(1).expand(-1, 3)\n    assigned_center_targets = center_targets[assignment]\n    assigned_size_targets = size_targets[assignment]\n    dir_class_targets = dir_class_targets[assignment]\n    dir_res_targets = dir_res_targets[assignment]\n    dir_res_targets /= np.pi / self.num_dir_bins\n    size_class_targets = size_class_targets[assignment]\n    size_res_targets = torch.gather(size_res_targets, 0, assignment_expand)\n    one_hot_size_targets = gt_bboxes_3d.tensor.new_zeros((num_candidate, self.num_sizes))\n    one_hot_size_targets.scatter_(1, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets = one_hot_size_targets.unsqueeze(-1).expand(-1, -1, 3)\n    mean_sizes = size_res_targets.new_tensor(self.bbox_coder.mean_sizes).unsqueeze(0)\n    pos_mean_sizes = torch.sum(one_hot_size_targets * mean_sizes, 1)\n    size_res_targets /= pos_mean_sizes\n    mask_targets = gt_labels_3d[assignment].long()\n    objectness_masks = points.new_ones(num_candidate)\n    return (sampling_targets, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks)",
            "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, max_gt_nums=None, seed_points=None, seed_indices=None, candidate_indices=None, seed_points_obj_topk=4):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Generate targets of GroupFree3D head for single batch.\\n\\n        Args:\\n            points (torch.Tensor): Points of each batch.\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\\n                boxes of each batch.\\n            gt_labels_3d (torch.Tensor): Labels of each batch.\\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (torch.Tensor): Point-wise instance\\n                label of each batch.\\n            max_gt_nums (int): Max number of GTs for single batch.\\n            seed_points (torch.Tensor): Coordinates of seed points.\\n            seed_indices (torch.Tensor): Indices of seed points.\\n            candidate_indices (torch.Tensor): Indices of object candidates.\\n            seed_points_obj_topk (int): k value of k-Closest Points Sampling.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of GroupFree3D head.\\n        '\n    assert self.bbox_coder.with_rot or pts_semantic_mask is not None\n    gt_bboxes_3d = gt_bboxes_3d.to(points.device)\n    (center_targets, size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets) = self.bbox_coder.encode(gt_bboxes_3d, gt_labels_3d)\n    pad_num = max_gt_nums - gt_labels_3d.shape[0]\n    box_label_mask = points.new_zeros([max_gt_nums])\n    box_label_mask[:gt_labels_3d.shape[0]] = 1\n    gt_bboxes_pad = F.pad(gt_bboxes_3d.tensor, (0, 0, 0, pad_num))\n    gt_bboxes_pad[gt_labels_3d.shape[0]:, 0:3] += 1000\n    gt_bboxes_3d = gt_bboxes_3d.new_box(gt_bboxes_pad)\n    gt_labels_3d = F.pad(gt_labels_3d, (0, pad_num))\n    center_targets = F.pad(center_targets, (0, 0, 0, pad_num), value=1000)\n    size_targets = F.pad(size_targets, (0, 0, 0, pad_num))\n    size_class_targets = F.pad(size_class_targets, (0, pad_num))\n    size_res_targets = F.pad(size_res_targets, (0, 0, 0, pad_num))\n    dir_class_targets = F.pad(dir_class_targets, (0, pad_num))\n    dir_res_targets = F.pad(dir_res_targets, (0, pad_num))\n    num_points = points.shape[0]\n    pts_obj_mask = points.new_zeros([num_points], dtype=torch.long)\n    pts_instance_label = points.new_zeros([num_points], dtype=torch.long) - 1\n    if self.bbox_coder.with_rot:\n        vote_targets = points.new_zeros([num_points, 4 * self.gt_per_seed])\n        vote_target_idx = points.new_zeros([num_points], dtype=torch.long)\n        box_indices_all = gt_bboxes_3d.points_in_boxes_part(points)\n        for i in range(gt_labels_3d.shape[0]):\n            box_indices = box_indices_all[:, i]\n            indices = torch.nonzero(box_indices, as_tuple=False).squeeze(-1)\n            selected_points = points[indices]\n            pts_obj_mask[indices] = 1\n            vote_targets_tmp = vote_targets[indices]\n            votes = gt_bboxes_3d.gravity_center[i].unsqueeze(0) - selected_points[:, :3]\n            for j in range(self.gt_per_seed):\n                column_indices = torch.nonzero(vote_target_idx[indices] == j, as_tuple=False).squeeze(-1)\n                vote_targets_tmp[column_indices, int(j * 3):int(j * 3 + 3)] = votes[column_indices]\n                vote_targets_tmp[column_indices, j + 3 * self.gt_per_seed] = i\n                if j == 0:\n                    vote_targets_tmp[column_indices, :3 * self.gt_per_seed] = votes[column_indices].repeat(1, self.gt_per_seed)\n                    vote_targets_tmp[column_indices, 3 * self.gt_per_seed:] = i\n            vote_targets[indices] = vote_targets_tmp\n            vote_target_idx[indices] = torch.clamp(vote_target_idx[indices] + 1, max=2)\n        dist = points.new_zeros([num_points, self.gt_per_seed]) + 1000\n        for j in range(self.gt_per_seed):\n            dist[:, j] = (vote_targets[:, 3 * j:3 * j + 3] ** 2).sum(-1)\n        instance_indices = torch.argmin(dist, dim=-1).unsqueeze(-1) + 3 * self.gt_per_seed\n        instance_lable = torch.gather(vote_targets, 1, instance_indices).squeeze(-1)\n        pts_instance_label = instance_lable.long()\n        pts_instance_label[pts_obj_mask == 0] = -1\n    elif pts_semantic_mask is not None:\n        for i in torch.unique(pts_instance_mask):\n            indices = torch.nonzero(pts_instance_mask == i, as_tuple=False).squeeze(-1)\n            if pts_semantic_mask[indices[0]] < self.num_classes:\n                selected_points = points[indices, :3]\n                center = 0.5 * (selected_points.min(0)[0] + selected_points.max(0)[0])\n                delta_xyz = center - center_targets\n                instance_lable = torch.argmin((delta_xyz ** 2).sum(-1))\n                pts_instance_label[indices] = instance_lable\n                pts_obj_mask[indices] = 1\n    else:\n        raise NotImplementedError\n    gt_num = gt_labels_3d.shape[0]\n    num_seed = seed_points.shape[0]\n    num_candidate = candidate_indices.shape[0]\n    object_assignment = torch.gather(pts_instance_label, 0, seed_indices)\n    object_assignment[object_assignment < 0] = gt_num - 1\n    object_assignment_one_hot = gt_bboxes_3d.tensor.new_zeros((num_seed, gt_num))\n    object_assignment_one_hot.scatter_(1, object_assignment.unsqueeze(-1), 1)\n    delta_xyz = seed_points.unsqueeze(1) - gt_bboxes_3d.gravity_center.unsqueeze(0)\n    delta_xyz = delta_xyz / (gt_bboxes_3d.dims.unsqueeze(0) + EPS)\n    new_dist = torch.sum(delta_xyz ** 2, dim=-1)\n    euclidean_dist1 = torch.sqrt(new_dist + EPS)\n    euclidean_dist1 = euclidean_dist1 * object_assignment_one_hot + 100 * (1 - object_assignment_one_hot)\n    euclidean_dist1 = euclidean_dist1.permute(1, 0)\n    topk_inds = torch.topk(euclidean_dist1, seed_points_obj_topk, largest=False)[1] * box_label_mask[:, None] + (box_label_mask[:, None] - 1)\n    topk_inds = topk_inds.long()\n    topk_inds = topk_inds.view(-1).contiguous()\n    sampling_targets = torch.zeros(num_seed + 1, dtype=torch.long).to(points.device)\n    sampling_targets[topk_inds] = 1\n    sampling_targets = sampling_targets[:num_seed]\n    objectness_label_mask = torch.gather(pts_instance_label, 0, seed_indices)\n    sampling_targets[objectness_label_mask < 0] = 0\n    seed_obj_gt = torch.gather(pts_obj_mask, 0, seed_indices)\n    objectness_targets = torch.gather(seed_obj_gt, 0, candidate_indices)\n    seed_instance_label = torch.gather(pts_instance_label, 0, seed_indices)\n    query_points_instance_label = torch.gather(seed_instance_label, 0, candidate_indices)\n    assignment = query_points_instance_label\n    assignment[assignment < 0] = gt_num - 1\n    assignment_expand = assignment.unsqueeze(1).expand(-1, 3)\n    assigned_center_targets = center_targets[assignment]\n    assigned_size_targets = size_targets[assignment]\n    dir_class_targets = dir_class_targets[assignment]\n    dir_res_targets = dir_res_targets[assignment]\n    dir_res_targets /= np.pi / self.num_dir_bins\n    size_class_targets = size_class_targets[assignment]\n    size_res_targets = torch.gather(size_res_targets, 0, assignment_expand)\n    one_hot_size_targets = gt_bboxes_3d.tensor.new_zeros((num_candidate, self.num_sizes))\n    one_hot_size_targets.scatter_(1, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets = one_hot_size_targets.unsqueeze(-1).expand(-1, -1, 3)\n    mean_sizes = size_res_targets.new_tensor(self.bbox_coder.mean_sizes).unsqueeze(0)\n    pos_mean_sizes = torch.sum(one_hot_size_targets * mean_sizes, 1)\n    size_res_targets /= pos_mean_sizes\n    mask_targets = gt_labels_3d[assignment].long()\n    objectness_masks = points.new_ones(num_candidate)\n    return (sampling_targets, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks)",
            "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, max_gt_nums=None, seed_points=None, seed_indices=None, candidate_indices=None, seed_points_obj_topk=4):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Generate targets of GroupFree3D head for single batch.\\n\\n        Args:\\n            points (torch.Tensor): Points of each batch.\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\\n                boxes of each batch.\\n            gt_labels_3d (torch.Tensor): Labels of each batch.\\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (torch.Tensor): Point-wise instance\\n                label of each batch.\\n            max_gt_nums (int): Max number of GTs for single batch.\\n            seed_points (torch.Tensor): Coordinates of seed points.\\n            seed_indices (torch.Tensor): Indices of seed points.\\n            candidate_indices (torch.Tensor): Indices of object candidates.\\n            seed_points_obj_topk (int): k value of k-Closest Points Sampling.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of GroupFree3D head.\\n        '\n    assert self.bbox_coder.with_rot or pts_semantic_mask is not None\n    gt_bboxes_3d = gt_bboxes_3d.to(points.device)\n    (center_targets, size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets) = self.bbox_coder.encode(gt_bboxes_3d, gt_labels_3d)\n    pad_num = max_gt_nums - gt_labels_3d.shape[0]\n    box_label_mask = points.new_zeros([max_gt_nums])\n    box_label_mask[:gt_labels_3d.shape[0]] = 1\n    gt_bboxes_pad = F.pad(gt_bboxes_3d.tensor, (0, 0, 0, pad_num))\n    gt_bboxes_pad[gt_labels_3d.shape[0]:, 0:3] += 1000\n    gt_bboxes_3d = gt_bboxes_3d.new_box(gt_bboxes_pad)\n    gt_labels_3d = F.pad(gt_labels_3d, (0, pad_num))\n    center_targets = F.pad(center_targets, (0, 0, 0, pad_num), value=1000)\n    size_targets = F.pad(size_targets, (0, 0, 0, pad_num))\n    size_class_targets = F.pad(size_class_targets, (0, pad_num))\n    size_res_targets = F.pad(size_res_targets, (0, 0, 0, pad_num))\n    dir_class_targets = F.pad(dir_class_targets, (0, pad_num))\n    dir_res_targets = F.pad(dir_res_targets, (0, pad_num))\n    num_points = points.shape[0]\n    pts_obj_mask = points.new_zeros([num_points], dtype=torch.long)\n    pts_instance_label = points.new_zeros([num_points], dtype=torch.long) - 1\n    if self.bbox_coder.with_rot:\n        vote_targets = points.new_zeros([num_points, 4 * self.gt_per_seed])\n        vote_target_idx = points.new_zeros([num_points], dtype=torch.long)\n        box_indices_all = gt_bboxes_3d.points_in_boxes_part(points)\n        for i in range(gt_labels_3d.shape[0]):\n            box_indices = box_indices_all[:, i]\n            indices = torch.nonzero(box_indices, as_tuple=False).squeeze(-1)\n            selected_points = points[indices]\n            pts_obj_mask[indices] = 1\n            vote_targets_tmp = vote_targets[indices]\n            votes = gt_bboxes_3d.gravity_center[i].unsqueeze(0) - selected_points[:, :3]\n            for j in range(self.gt_per_seed):\n                column_indices = torch.nonzero(vote_target_idx[indices] == j, as_tuple=False).squeeze(-1)\n                vote_targets_tmp[column_indices, int(j * 3):int(j * 3 + 3)] = votes[column_indices]\n                vote_targets_tmp[column_indices, j + 3 * self.gt_per_seed] = i\n                if j == 0:\n                    vote_targets_tmp[column_indices, :3 * self.gt_per_seed] = votes[column_indices].repeat(1, self.gt_per_seed)\n                    vote_targets_tmp[column_indices, 3 * self.gt_per_seed:] = i\n            vote_targets[indices] = vote_targets_tmp\n            vote_target_idx[indices] = torch.clamp(vote_target_idx[indices] + 1, max=2)\n        dist = points.new_zeros([num_points, self.gt_per_seed]) + 1000\n        for j in range(self.gt_per_seed):\n            dist[:, j] = (vote_targets[:, 3 * j:3 * j + 3] ** 2).sum(-1)\n        instance_indices = torch.argmin(dist, dim=-1).unsqueeze(-1) + 3 * self.gt_per_seed\n        instance_lable = torch.gather(vote_targets, 1, instance_indices).squeeze(-1)\n        pts_instance_label = instance_lable.long()\n        pts_instance_label[pts_obj_mask == 0] = -1\n    elif pts_semantic_mask is not None:\n        for i in torch.unique(pts_instance_mask):\n            indices = torch.nonzero(pts_instance_mask == i, as_tuple=False).squeeze(-1)\n            if pts_semantic_mask[indices[0]] < self.num_classes:\n                selected_points = points[indices, :3]\n                center = 0.5 * (selected_points.min(0)[0] + selected_points.max(0)[0])\n                delta_xyz = center - center_targets\n                instance_lable = torch.argmin((delta_xyz ** 2).sum(-1))\n                pts_instance_label[indices] = instance_lable\n                pts_obj_mask[indices] = 1\n    else:\n        raise NotImplementedError\n    gt_num = gt_labels_3d.shape[0]\n    num_seed = seed_points.shape[0]\n    num_candidate = candidate_indices.shape[0]\n    object_assignment = torch.gather(pts_instance_label, 0, seed_indices)\n    object_assignment[object_assignment < 0] = gt_num - 1\n    object_assignment_one_hot = gt_bboxes_3d.tensor.new_zeros((num_seed, gt_num))\n    object_assignment_one_hot.scatter_(1, object_assignment.unsqueeze(-1), 1)\n    delta_xyz = seed_points.unsqueeze(1) - gt_bboxes_3d.gravity_center.unsqueeze(0)\n    delta_xyz = delta_xyz / (gt_bboxes_3d.dims.unsqueeze(0) + EPS)\n    new_dist = torch.sum(delta_xyz ** 2, dim=-1)\n    euclidean_dist1 = torch.sqrt(new_dist + EPS)\n    euclidean_dist1 = euclidean_dist1 * object_assignment_one_hot + 100 * (1 - object_assignment_one_hot)\n    euclidean_dist1 = euclidean_dist1.permute(1, 0)\n    topk_inds = torch.topk(euclidean_dist1, seed_points_obj_topk, largest=False)[1] * box_label_mask[:, None] + (box_label_mask[:, None] - 1)\n    topk_inds = topk_inds.long()\n    topk_inds = topk_inds.view(-1).contiguous()\n    sampling_targets = torch.zeros(num_seed + 1, dtype=torch.long).to(points.device)\n    sampling_targets[topk_inds] = 1\n    sampling_targets = sampling_targets[:num_seed]\n    objectness_label_mask = torch.gather(pts_instance_label, 0, seed_indices)\n    sampling_targets[objectness_label_mask < 0] = 0\n    seed_obj_gt = torch.gather(pts_obj_mask, 0, seed_indices)\n    objectness_targets = torch.gather(seed_obj_gt, 0, candidate_indices)\n    seed_instance_label = torch.gather(pts_instance_label, 0, seed_indices)\n    query_points_instance_label = torch.gather(seed_instance_label, 0, candidate_indices)\n    assignment = query_points_instance_label\n    assignment[assignment < 0] = gt_num - 1\n    assignment_expand = assignment.unsqueeze(1).expand(-1, 3)\n    assigned_center_targets = center_targets[assignment]\n    assigned_size_targets = size_targets[assignment]\n    dir_class_targets = dir_class_targets[assignment]\n    dir_res_targets = dir_res_targets[assignment]\n    dir_res_targets /= np.pi / self.num_dir_bins\n    size_class_targets = size_class_targets[assignment]\n    size_res_targets = torch.gather(size_res_targets, 0, assignment_expand)\n    one_hot_size_targets = gt_bboxes_3d.tensor.new_zeros((num_candidate, self.num_sizes))\n    one_hot_size_targets.scatter_(1, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets = one_hot_size_targets.unsqueeze(-1).expand(-1, -1, 3)\n    mean_sizes = size_res_targets.new_tensor(self.bbox_coder.mean_sizes).unsqueeze(0)\n    pos_mean_sizes = torch.sum(one_hot_size_targets * mean_sizes, 1)\n    size_res_targets /= pos_mean_sizes\n    mask_targets = gt_labels_3d[assignment].long()\n    objectness_masks = points.new_ones(num_candidate)\n    return (sampling_targets, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks)",
            "def get_targets_single(self, points, gt_bboxes_3d, gt_labels_3d, pts_semantic_mask=None, pts_instance_mask=None, max_gt_nums=None, seed_points=None, seed_indices=None, candidate_indices=None, seed_points_obj_topk=4):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Generate targets of GroupFree3D head for single batch.\\n\\n        Args:\\n            points (torch.Tensor): Points of each batch.\\n            gt_bboxes_3d (:obj:`BaseInstance3DBoxes`): Ground truth\\n                boxes of each batch.\\n            gt_labels_3d (torch.Tensor): Labels of each batch.\\n            pts_semantic_mask (torch.Tensor): Point-wise semantic\\n                label of each batch.\\n            pts_instance_mask (torch.Tensor): Point-wise instance\\n                label of each batch.\\n            max_gt_nums (int): Max number of GTs for single batch.\\n            seed_points (torch.Tensor): Coordinates of seed points.\\n            seed_indices (torch.Tensor): Indices of seed points.\\n            candidate_indices (torch.Tensor): Indices of object candidates.\\n            seed_points_obj_topk (int): k value of k-Closest Points Sampling.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Targets of GroupFree3D head.\\n        '\n    assert self.bbox_coder.with_rot or pts_semantic_mask is not None\n    gt_bboxes_3d = gt_bboxes_3d.to(points.device)\n    (center_targets, size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets) = self.bbox_coder.encode(gt_bboxes_3d, gt_labels_3d)\n    pad_num = max_gt_nums - gt_labels_3d.shape[0]\n    box_label_mask = points.new_zeros([max_gt_nums])\n    box_label_mask[:gt_labels_3d.shape[0]] = 1\n    gt_bboxes_pad = F.pad(gt_bboxes_3d.tensor, (0, 0, 0, pad_num))\n    gt_bboxes_pad[gt_labels_3d.shape[0]:, 0:3] += 1000\n    gt_bboxes_3d = gt_bboxes_3d.new_box(gt_bboxes_pad)\n    gt_labels_3d = F.pad(gt_labels_3d, (0, pad_num))\n    center_targets = F.pad(center_targets, (0, 0, 0, pad_num), value=1000)\n    size_targets = F.pad(size_targets, (0, 0, 0, pad_num))\n    size_class_targets = F.pad(size_class_targets, (0, pad_num))\n    size_res_targets = F.pad(size_res_targets, (0, 0, 0, pad_num))\n    dir_class_targets = F.pad(dir_class_targets, (0, pad_num))\n    dir_res_targets = F.pad(dir_res_targets, (0, pad_num))\n    num_points = points.shape[0]\n    pts_obj_mask = points.new_zeros([num_points], dtype=torch.long)\n    pts_instance_label = points.new_zeros([num_points], dtype=torch.long) - 1\n    if self.bbox_coder.with_rot:\n        vote_targets = points.new_zeros([num_points, 4 * self.gt_per_seed])\n        vote_target_idx = points.new_zeros([num_points], dtype=torch.long)\n        box_indices_all = gt_bboxes_3d.points_in_boxes_part(points)\n        for i in range(gt_labels_3d.shape[0]):\n            box_indices = box_indices_all[:, i]\n            indices = torch.nonzero(box_indices, as_tuple=False).squeeze(-1)\n            selected_points = points[indices]\n            pts_obj_mask[indices] = 1\n            vote_targets_tmp = vote_targets[indices]\n            votes = gt_bboxes_3d.gravity_center[i].unsqueeze(0) - selected_points[:, :3]\n            for j in range(self.gt_per_seed):\n                column_indices = torch.nonzero(vote_target_idx[indices] == j, as_tuple=False).squeeze(-1)\n                vote_targets_tmp[column_indices, int(j * 3):int(j * 3 + 3)] = votes[column_indices]\n                vote_targets_tmp[column_indices, j + 3 * self.gt_per_seed] = i\n                if j == 0:\n                    vote_targets_tmp[column_indices, :3 * self.gt_per_seed] = votes[column_indices].repeat(1, self.gt_per_seed)\n                    vote_targets_tmp[column_indices, 3 * self.gt_per_seed:] = i\n            vote_targets[indices] = vote_targets_tmp\n            vote_target_idx[indices] = torch.clamp(vote_target_idx[indices] + 1, max=2)\n        dist = points.new_zeros([num_points, self.gt_per_seed]) + 1000\n        for j in range(self.gt_per_seed):\n            dist[:, j] = (vote_targets[:, 3 * j:3 * j + 3] ** 2).sum(-1)\n        instance_indices = torch.argmin(dist, dim=-1).unsqueeze(-1) + 3 * self.gt_per_seed\n        instance_lable = torch.gather(vote_targets, 1, instance_indices).squeeze(-1)\n        pts_instance_label = instance_lable.long()\n        pts_instance_label[pts_obj_mask == 0] = -1\n    elif pts_semantic_mask is not None:\n        for i in torch.unique(pts_instance_mask):\n            indices = torch.nonzero(pts_instance_mask == i, as_tuple=False).squeeze(-1)\n            if pts_semantic_mask[indices[0]] < self.num_classes:\n                selected_points = points[indices, :3]\n                center = 0.5 * (selected_points.min(0)[0] + selected_points.max(0)[0])\n                delta_xyz = center - center_targets\n                instance_lable = torch.argmin((delta_xyz ** 2).sum(-1))\n                pts_instance_label[indices] = instance_lable\n                pts_obj_mask[indices] = 1\n    else:\n        raise NotImplementedError\n    gt_num = gt_labels_3d.shape[0]\n    num_seed = seed_points.shape[0]\n    num_candidate = candidate_indices.shape[0]\n    object_assignment = torch.gather(pts_instance_label, 0, seed_indices)\n    object_assignment[object_assignment < 0] = gt_num - 1\n    object_assignment_one_hot = gt_bboxes_3d.tensor.new_zeros((num_seed, gt_num))\n    object_assignment_one_hot.scatter_(1, object_assignment.unsqueeze(-1), 1)\n    delta_xyz = seed_points.unsqueeze(1) - gt_bboxes_3d.gravity_center.unsqueeze(0)\n    delta_xyz = delta_xyz / (gt_bboxes_3d.dims.unsqueeze(0) + EPS)\n    new_dist = torch.sum(delta_xyz ** 2, dim=-1)\n    euclidean_dist1 = torch.sqrt(new_dist + EPS)\n    euclidean_dist1 = euclidean_dist1 * object_assignment_one_hot + 100 * (1 - object_assignment_one_hot)\n    euclidean_dist1 = euclidean_dist1.permute(1, 0)\n    topk_inds = torch.topk(euclidean_dist1, seed_points_obj_topk, largest=False)[1] * box_label_mask[:, None] + (box_label_mask[:, None] - 1)\n    topk_inds = topk_inds.long()\n    topk_inds = topk_inds.view(-1).contiguous()\n    sampling_targets = torch.zeros(num_seed + 1, dtype=torch.long).to(points.device)\n    sampling_targets[topk_inds] = 1\n    sampling_targets = sampling_targets[:num_seed]\n    objectness_label_mask = torch.gather(pts_instance_label, 0, seed_indices)\n    sampling_targets[objectness_label_mask < 0] = 0\n    seed_obj_gt = torch.gather(pts_obj_mask, 0, seed_indices)\n    objectness_targets = torch.gather(seed_obj_gt, 0, candidate_indices)\n    seed_instance_label = torch.gather(pts_instance_label, 0, seed_indices)\n    query_points_instance_label = torch.gather(seed_instance_label, 0, candidate_indices)\n    assignment = query_points_instance_label\n    assignment[assignment < 0] = gt_num - 1\n    assignment_expand = assignment.unsqueeze(1).expand(-1, 3)\n    assigned_center_targets = center_targets[assignment]\n    assigned_size_targets = size_targets[assignment]\n    dir_class_targets = dir_class_targets[assignment]\n    dir_res_targets = dir_res_targets[assignment]\n    dir_res_targets /= np.pi / self.num_dir_bins\n    size_class_targets = size_class_targets[assignment]\n    size_res_targets = torch.gather(size_res_targets, 0, assignment_expand)\n    one_hot_size_targets = gt_bboxes_3d.tensor.new_zeros((num_candidate, self.num_sizes))\n    one_hot_size_targets.scatter_(1, size_class_targets.unsqueeze(-1), 1)\n    one_hot_size_targets = one_hot_size_targets.unsqueeze(-1).expand(-1, -1, 3)\n    mean_sizes = size_res_targets.new_tensor(self.bbox_coder.mean_sizes).unsqueeze(0)\n    pos_mean_sizes = torch.sum(one_hot_size_targets * mean_sizes, 1)\n    size_res_targets /= pos_mean_sizes\n    mask_targets = gt_labels_3d[assignment].long()\n    objectness_masks = points.new_ones(num_candidate)\n    return (sampling_targets, assigned_size_targets, size_class_targets, size_res_targets, dir_class_targets, dir_res_targets, center_targets, assigned_center_targets, mask_targets, objectness_targets, objectness_masks)"
        ]
    },
    {
        "func_name": "get_bboxes",
        "original": "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, use_nms=True):\n    \"\"\"Generate bboxes from GroupFree3D head predictions.\n\n        Args:\n            points (torch.Tensor): Input points.\n            bbox_preds (dict): Predictions from GroupFree3D head.\n            input_metas (list[dict]): Point cloud and image's meta info.\n            rescale (bool): Whether to rescale bboxes.\n            use_nms (bool): Whether to apply NMS, skip nms postprocessing\n                while using GroupFree3D head in rpn stage.\n\n        Returns:\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\n        \"\"\"\n    assert self.test_cfg['prediction_stages'] in ['last', 'all', 'last_three']\n    prefixes = list()\n    if self.test_cfg['prediction_stages'] == 'last':\n        prefixes = [f's{self.num_decoder_layers - 1}.']\n    elif self.test_cfg['prediction_stages'] == 'all':\n        prefixes = ['proposal.'] + [f's{i}.' for i in range(self.num_decoder_layers)]\n    elif self.test_cfg['prediction_stages'] == 'last_three':\n        prefixes = [f's{i}.' for i in range(self.num_decoder_layers - 3, self.num_decoder_layers)]\n    else:\n        raise NotImplementedError\n    obj_scores = list()\n    sem_scores = list()\n    bbox3d = list()\n    for prefix in prefixes:\n        obj_score = bbox_preds[f'{prefix}obj_scores'][..., -1].sigmoid()\n        sem_score = bbox_preds[f'{prefix}sem_scores'].softmax(-1)\n        bbox = self.bbox_coder.decode(bbox_preds, prefix)\n        obj_scores.append(obj_score)\n        sem_scores.append(sem_score)\n        bbox3d.append(bbox)\n    obj_scores = torch.cat(obj_scores, dim=1)\n    sem_scores = torch.cat(sem_scores, dim=1)\n    bbox3d = torch.cat(bbox3d, dim=1)\n    if use_nms:\n        batch_size = bbox3d.shape[0]\n        results = list()\n        for b in range(batch_size):\n            (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n            bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n            results.append((bbox, score_selected, labels))\n        return results\n    else:\n        return bbox3d",
        "mutated": [
            "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, use_nms=True):\n    if False:\n        i = 10\n    \"Generate bboxes from GroupFree3D head predictions.\\n\\n        Args:\\n            points (torch.Tensor): Input points.\\n            bbox_preds (dict): Predictions from GroupFree3D head.\\n            input_metas (list[dict]): Point cloud and image's meta info.\\n            rescale (bool): Whether to rescale bboxes.\\n            use_nms (bool): Whether to apply NMS, skip nms postprocessing\\n                while using GroupFree3D head in rpn stage.\\n\\n        Returns:\\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\\n        \"\n    assert self.test_cfg['prediction_stages'] in ['last', 'all', 'last_three']\n    prefixes = list()\n    if self.test_cfg['prediction_stages'] == 'last':\n        prefixes = [f's{self.num_decoder_layers - 1}.']\n    elif self.test_cfg['prediction_stages'] == 'all':\n        prefixes = ['proposal.'] + [f's{i}.' for i in range(self.num_decoder_layers)]\n    elif self.test_cfg['prediction_stages'] == 'last_three':\n        prefixes = [f's{i}.' for i in range(self.num_decoder_layers - 3, self.num_decoder_layers)]\n    else:\n        raise NotImplementedError\n    obj_scores = list()\n    sem_scores = list()\n    bbox3d = list()\n    for prefix in prefixes:\n        obj_score = bbox_preds[f'{prefix}obj_scores'][..., -1].sigmoid()\n        sem_score = bbox_preds[f'{prefix}sem_scores'].softmax(-1)\n        bbox = self.bbox_coder.decode(bbox_preds, prefix)\n        obj_scores.append(obj_score)\n        sem_scores.append(sem_score)\n        bbox3d.append(bbox)\n    obj_scores = torch.cat(obj_scores, dim=1)\n    sem_scores = torch.cat(sem_scores, dim=1)\n    bbox3d = torch.cat(bbox3d, dim=1)\n    if use_nms:\n        batch_size = bbox3d.shape[0]\n        results = list()\n        for b in range(batch_size):\n            (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n            bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n            results.append((bbox, score_selected, labels))\n        return results\n    else:\n        return bbox3d",
            "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, use_nms=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Generate bboxes from GroupFree3D head predictions.\\n\\n        Args:\\n            points (torch.Tensor): Input points.\\n            bbox_preds (dict): Predictions from GroupFree3D head.\\n            input_metas (list[dict]): Point cloud and image's meta info.\\n            rescale (bool): Whether to rescale bboxes.\\n            use_nms (bool): Whether to apply NMS, skip nms postprocessing\\n                while using GroupFree3D head in rpn stage.\\n\\n        Returns:\\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\\n        \"\n    assert self.test_cfg['prediction_stages'] in ['last', 'all', 'last_three']\n    prefixes = list()\n    if self.test_cfg['prediction_stages'] == 'last':\n        prefixes = [f's{self.num_decoder_layers - 1}.']\n    elif self.test_cfg['prediction_stages'] == 'all':\n        prefixes = ['proposal.'] + [f's{i}.' for i in range(self.num_decoder_layers)]\n    elif self.test_cfg['prediction_stages'] == 'last_three':\n        prefixes = [f's{i}.' for i in range(self.num_decoder_layers - 3, self.num_decoder_layers)]\n    else:\n        raise NotImplementedError\n    obj_scores = list()\n    sem_scores = list()\n    bbox3d = list()\n    for prefix in prefixes:\n        obj_score = bbox_preds[f'{prefix}obj_scores'][..., -1].sigmoid()\n        sem_score = bbox_preds[f'{prefix}sem_scores'].softmax(-1)\n        bbox = self.bbox_coder.decode(bbox_preds, prefix)\n        obj_scores.append(obj_score)\n        sem_scores.append(sem_score)\n        bbox3d.append(bbox)\n    obj_scores = torch.cat(obj_scores, dim=1)\n    sem_scores = torch.cat(sem_scores, dim=1)\n    bbox3d = torch.cat(bbox3d, dim=1)\n    if use_nms:\n        batch_size = bbox3d.shape[0]\n        results = list()\n        for b in range(batch_size):\n            (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n            bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n            results.append((bbox, score_selected, labels))\n        return results\n    else:\n        return bbox3d",
            "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, use_nms=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Generate bboxes from GroupFree3D head predictions.\\n\\n        Args:\\n            points (torch.Tensor): Input points.\\n            bbox_preds (dict): Predictions from GroupFree3D head.\\n            input_metas (list[dict]): Point cloud and image's meta info.\\n            rescale (bool): Whether to rescale bboxes.\\n            use_nms (bool): Whether to apply NMS, skip nms postprocessing\\n                while using GroupFree3D head in rpn stage.\\n\\n        Returns:\\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\\n        \"\n    assert self.test_cfg['prediction_stages'] in ['last', 'all', 'last_three']\n    prefixes = list()\n    if self.test_cfg['prediction_stages'] == 'last':\n        prefixes = [f's{self.num_decoder_layers - 1}.']\n    elif self.test_cfg['prediction_stages'] == 'all':\n        prefixes = ['proposal.'] + [f's{i}.' for i in range(self.num_decoder_layers)]\n    elif self.test_cfg['prediction_stages'] == 'last_three':\n        prefixes = [f's{i}.' for i in range(self.num_decoder_layers - 3, self.num_decoder_layers)]\n    else:\n        raise NotImplementedError\n    obj_scores = list()\n    sem_scores = list()\n    bbox3d = list()\n    for prefix in prefixes:\n        obj_score = bbox_preds[f'{prefix}obj_scores'][..., -1].sigmoid()\n        sem_score = bbox_preds[f'{prefix}sem_scores'].softmax(-1)\n        bbox = self.bbox_coder.decode(bbox_preds, prefix)\n        obj_scores.append(obj_score)\n        sem_scores.append(sem_score)\n        bbox3d.append(bbox)\n    obj_scores = torch.cat(obj_scores, dim=1)\n    sem_scores = torch.cat(sem_scores, dim=1)\n    bbox3d = torch.cat(bbox3d, dim=1)\n    if use_nms:\n        batch_size = bbox3d.shape[0]\n        results = list()\n        for b in range(batch_size):\n            (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n            bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n            results.append((bbox, score_selected, labels))\n        return results\n    else:\n        return bbox3d",
            "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, use_nms=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Generate bboxes from GroupFree3D head predictions.\\n\\n        Args:\\n            points (torch.Tensor): Input points.\\n            bbox_preds (dict): Predictions from GroupFree3D head.\\n            input_metas (list[dict]): Point cloud and image's meta info.\\n            rescale (bool): Whether to rescale bboxes.\\n            use_nms (bool): Whether to apply NMS, skip nms postprocessing\\n                while using GroupFree3D head in rpn stage.\\n\\n        Returns:\\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\\n        \"\n    assert self.test_cfg['prediction_stages'] in ['last', 'all', 'last_three']\n    prefixes = list()\n    if self.test_cfg['prediction_stages'] == 'last':\n        prefixes = [f's{self.num_decoder_layers - 1}.']\n    elif self.test_cfg['prediction_stages'] == 'all':\n        prefixes = ['proposal.'] + [f's{i}.' for i in range(self.num_decoder_layers)]\n    elif self.test_cfg['prediction_stages'] == 'last_three':\n        prefixes = [f's{i}.' for i in range(self.num_decoder_layers - 3, self.num_decoder_layers)]\n    else:\n        raise NotImplementedError\n    obj_scores = list()\n    sem_scores = list()\n    bbox3d = list()\n    for prefix in prefixes:\n        obj_score = bbox_preds[f'{prefix}obj_scores'][..., -1].sigmoid()\n        sem_score = bbox_preds[f'{prefix}sem_scores'].softmax(-1)\n        bbox = self.bbox_coder.decode(bbox_preds, prefix)\n        obj_scores.append(obj_score)\n        sem_scores.append(sem_score)\n        bbox3d.append(bbox)\n    obj_scores = torch.cat(obj_scores, dim=1)\n    sem_scores = torch.cat(sem_scores, dim=1)\n    bbox3d = torch.cat(bbox3d, dim=1)\n    if use_nms:\n        batch_size = bbox3d.shape[0]\n        results = list()\n        for b in range(batch_size):\n            (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n            bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n            results.append((bbox, score_selected, labels))\n        return results\n    else:\n        return bbox3d",
            "def get_bboxes(self, points, bbox_preds, input_metas, rescale=False, use_nms=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Generate bboxes from GroupFree3D head predictions.\\n\\n        Args:\\n            points (torch.Tensor): Input points.\\n            bbox_preds (dict): Predictions from GroupFree3D head.\\n            input_metas (list[dict]): Point cloud and image's meta info.\\n            rescale (bool): Whether to rescale bboxes.\\n            use_nms (bool): Whether to apply NMS, skip nms postprocessing\\n                while using GroupFree3D head in rpn stage.\\n\\n        Returns:\\n            list[tuple[torch.Tensor]]: Bounding boxes, scores and labels.\\n        \"\n    assert self.test_cfg['prediction_stages'] in ['last', 'all', 'last_three']\n    prefixes = list()\n    if self.test_cfg['prediction_stages'] == 'last':\n        prefixes = [f's{self.num_decoder_layers - 1}.']\n    elif self.test_cfg['prediction_stages'] == 'all':\n        prefixes = ['proposal.'] + [f's{i}.' for i in range(self.num_decoder_layers)]\n    elif self.test_cfg['prediction_stages'] == 'last_three':\n        prefixes = [f's{i}.' for i in range(self.num_decoder_layers - 3, self.num_decoder_layers)]\n    else:\n        raise NotImplementedError\n    obj_scores = list()\n    sem_scores = list()\n    bbox3d = list()\n    for prefix in prefixes:\n        obj_score = bbox_preds[f'{prefix}obj_scores'][..., -1].sigmoid()\n        sem_score = bbox_preds[f'{prefix}sem_scores'].softmax(-1)\n        bbox = self.bbox_coder.decode(bbox_preds, prefix)\n        obj_scores.append(obj_score)\n        sem_scores.append(sem_score)\n        bbox3d.append(bbox)\n    obj_scores = torch.cat(obj_scores, dim=1)\n    sem_scores = torch.cat(sem_scores, dim=1)\n    bbox3d = torch.cat(bbox3d, dim=1)\n    if use_nms:\n        batch_size = bbox3d.shape[0]\n        results = list()\n        for b in range(batch_size):\n            (bbox_selected, score_selected, labels) = self.multiclass_nms_single(obj_scores[b], sem_scores[b], bbox3d[b], points[b, ..., :3], input_metas[b])\n            bbox = input_metas[b]['box_type_3d'](bbox_selected, box_dim=bbox_selected.shape[-1], with_yaw=self.bbox_coder.with_rot)\n            results.append((bbox, score_selected, labels))\n        return results\n    else:\n        return bbox3d"
        ]
    },
    {
        "func_name": "multiclass_nms_single",
        "original": "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    \"\"\"Multi-class nms in single batch.\n\n        Args:\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\n            bbox (torch.Tensor): Predicted bounding boxes.\n            points (torch.Tensor): Input points.\n            input_meta (dict): Point cloud and image's meta info.\n\n        Returns:\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\n        \"\"\"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)",
        "mutated": [
            "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    if False:\n        i = 10\n    \"Multi-class nms in single batch.\\n\\n        Args:\\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\\n            bbox (torch.Tensor): Predicted bounding boxes.\\n            points (torch.Tensor): Input points.\\n            input_meta (dict): Point cloud and image's meta info.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\\n        \"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)",
            "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Multi-class nms in single batch.\\n\\n        Args:\\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\\n            bbox (torch.Tensor): Predicted bounding boxes.\\n            points (torch.Tensor): Input points.\\n            input_meta (dict): Point cloud and image's meta info.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\\n        \"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)",
            "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Multi-class nms in single batch.\\n\\n        Args:\\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\\n            bbox (torch.Tensor): Predicted bounding boxes.\\n            points (torch.Tensor): Input points.\\n            input_meta (dict): Point cloud and image's meta info.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\\n        \"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)",
            "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Multi-class nms in single batch.\\n\\n        Args:\\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\\n            bbox (torch.Tensor): Predicted bounding boxes.\\n            points (torch.Tensor): Input points.\\n            input_meta (dict): Point cloud and image's meta info.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\\n        \"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)",
            "def multiclass_nms_single(self, obj_scores, sem_scores, bbox, points, input_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Multi-class nms in single batch.\\n\\n        Args:\\n            obj_scores (torch.Tensor): Objectness score of bounding boxes.\\n            sem_scores (torch.Tensor): semantic class score of bounding boxes.\\n            bbox (torch.Tensor): Predicted bounding boxes.\\n            points (torch.Tensor): Input points.\\n            input_meta (dict): Point cloud and image's meta info.\\n\\n        Returns:\\n            tuple[torch.Tensor]: Bounding boxes, scores and labels.\\n        \"\n    bbox = input_meta['box_type_3d'](bbox, box_dim=bbox.shape[-1], with_yaw=self.bbox_coder.with_rot, origin=(0.5, 0.5, 0.5))\n    box_indices = bbox.points_in_boxes_all(points)\n    corner3d = bbox.corners\n    minmax_box3d = corner3d.new(torch.Size((corner3d.shape[0], 6)))\n    minmax_box3d[:, :3] = torch.min(corner3d, dim=1)[0]\n    minmax_box3d[:, 3:] = torch.max(corner3d, dim=1)[0]\n    nonempty_box_mask = box_indices.T.sum(1) > 5\n    bbox_classes = torch.argmax(sem_scores, -1)\n    nms_selected = aligned_3d_nms(minmax_box3d[nonempty_box_mask], obj_scores[nonempty_box_mask], bbox_classes[nonempty_box_mask], self.test_cfg.nms_thr)\n    scores_mask = obj_scores > self.test_cfg.score_thr\n    nonempty_box_inds = torch.nonzero(nonempty_box_mask, as_tuple=False).flatten()\n    nonempty_mask = torch.zeros_like(bbox_classes).scatter(0, nonempty_box_inds[nms_selected], 1)\n    selected = nonempty_mask.bool() & scores_mask.bool()\n    if self.test_cfg.per_class_proposal:\n        (bbox_selected, score_selected, labels) = ([], [], [])\n        for k in range(sem_scores.shape[-1]):\n            bbox_selected.append(bbox[selected].tensor)\n            score_selected.append(obj_scores[selected] * sem_scores[selected][:, k])\n            labels.append(torch.zeros_like(bbox_classes[selected]).fill_(k))\n        bbox_selected = torch.cat(bbox_selected, 0)\n        score_selected = torch.cat(score_selected, 0)\n        labels = torch.cat(labels, 0)\n    else:\n        bbox_selected = bbox[selected].tensor\n        score_selected = obj_scores[selected]\n        labels = bbox_classes[selected]\n    return (bbox_selected, score_selected, labels)"
        ]
    }
]