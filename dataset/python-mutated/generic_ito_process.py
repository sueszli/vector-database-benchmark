"""Defines class to describe any Ito processes.

Uses Euler scheme for sampling and ADI scheme for solving the associated
Feynman-Kac equation.
"""
import tensorflow.compat.v2 as tf
from tf_quant_finance.math.pde import fd_solvers
from tf_quant_finance.models import euler_sampling
from tf_quant_finance.models import ito_process

class GenericItoProcess(ito_process.ItoProcess):
    """Generic Ito process defined from a drift and volatility function."""

    def __init__(self, dim, drift_fn, volatility_fn, dtype=None, name=None):
        if False:
            while True:
                i = 10
        'Initializes the Ito process with given drift and volatility functions.\n\n    Represents a general Ito process:\n\n    ```None\n      dX_i = a_i(t, X) dt + Sum(S_{ij}(t, X) dW_j for 1 <= j <= n), 1 <= i <= n\n    ```\n\n    The vector coefficient `a_i` is referred to as the drift of the process and\n    the matrix `b_{ij}` as the volatility of the process. For the process to be\n    well defined, these coefficients need to satisfy certain technical\n    conditions which may be found in Ref. [1]. The vector `dW_j` represents\n    independent Brownian increments.\n\n    #### Example. Sampling from 2-dimensional Ito process of the form:\n\n    ```none\n    dX_1 = mu_1 * sqrt(t) dt + s11 * dW_1 + s12 * dW_2\n    dX_2 = mu_2 * sqrt(t) dt + s21 * dW_1 + s22 * dW_2\n    ```\n\n    ```python\n    mu = np.array([0.2, 0.7])\n    s = np.array([[0.3, 0.1], [0.1, 0.3]])\n    num_samples = 10000\n    dim = 2\n    dtype=tf.float64\n\n    # Define drift and volatility functions\n    def drift_fn(t, x):\n      return mu * tf.sqrt(t) * tf.ones([num_samples, dim], dtype=dtype)\n\n    def vol_fn(t, x):\n      return s * tf.ones([num_samples, dim, dim], dtype=dtype)\n\n    # Initialize `GenericItoProcess`\n    process = GenericItoProcess(dim=2, drift_fn=drift_fn, volatility_fn=vol_fn,\n                                dtype=dtype)\n    # Set starting location\n    x0 = np.array([0.1, -1.1])\n    # Sample `num_samples` paths at specified `times` locations using built-in\n    # Euler scheme.\n    times = [0.1, 1.0, 2.0]\n    paths = process.sample_paths(\n              times,\n              num_samples=num_samples,\n              initial_state=x0,\n              time_step=0.01,\n              seed=42)\n    ```\n\n    #### References\n    [1]: Brent Oksendal. Stochastic Differential Equations: An Introduction with\n      Applications. Springer. 2010.\n\n    Args:\n      dim: Python int greater than or equal to 1. The dimension of the Ito\n        process.\n      drift_fn: A Python callable to compute the drift of the process. The\n        callable should accept two real `Tensor` arguments of the same dtype.\n        The first argument is the scalar time t, the second argument is the\n        value of Ito process X - `Tensor` of shape\n        `batch_shape + sample_shape + [dim]`, where `batch_shape` represents\n        a batch of models and `sample_shape` represents samples for each of the\n        models. The result is value of drift a(t, X). The return value of the\n        callable is a real `Tensor` of the same dtype as the input arguments and\n        of shape `batch_shape + sample_shape + [dim]`. For example,\n        `sample_shape` can stand for `[num_samples]` for Monte Carlo sampling,\n        or `[num_grid_points_1, ..., num_grid_points_dim]` for Finite Difference\n        solvers.\n      volatility_fn: A Python callable to compute the volatility of the process.\n        The callable should accept two real `Tensor` arguments of the same dtype\n        and shape `times_shape`. The first argument is the scalar time t, the\n        second argument is the value of Ito process X - `Tensor` of shape\n        `batch_shape + sample_shape + [dim]`, where `batch_shape` represents\n        a batch of models and `sample_shape` represents samples for each of the\n        models. The result is value of volatility S_{ij}(t, X). The return value\n        of the callable is a real `Tensor` of the same dtype as the input\n        arguments and of shape `batch_shape + sample_shape + [dim, dim]`. For\n        example, `sample_shape` can stand for `[num_samples]` for Monte Carlo\n        sampling, or `[num_grid_points_1, ..., num_grid_points_dim]` for Finite\n        Difference solvers.\n      dtype: The default dtype to use when converting values to `Tensor`s.\n        Default value: None which means that default dtypes inferred by\n          TensorFlow are used.\n      name: str. The name scope under which ops created by the methods of this\n        class are nested.\n        Default value: None which maps to the default name\n          `generic_ito_process`.\n\n    Raises:\n      ValueError if the dimension is less than 1, or if either `drift_fn`\n        or `volatility_fn` is not supplied.\n    '
        if dim < 1:
            raise ValueError('Dimension must be 1 or greater.')
        if drift_fn is None or volatility_fn is None:
            raise ValueError('Both drift and volatility functions must be supplied.')
        self._dim = dim
        self._drift_fn = drift_fn
        self._volatility_fn = volatility_fn
        self._dtype = dtype
        self._name = name or 'generic_ito_process'

    def dim(self):
        if False:
            i = 10
            return i + 15
        'The dimension of the process.'
        return self._dim

    def dtype(self):
        if False:
            i = 10
            return i + 15
        'The data type of process realizations.'
        return self._dtype

    def name(self):
        if False:
            while True:
                i = 10
        'The name to give to ops created by this class.'
        return self._name

    def drift_fn(self):
        if False:
            while True:
                i = 10
        'Python callable calculating instantaneous drift.\n\n    The callable should accept two real `Tensor` arguments of the same dtype.\n    The first argument is the scalar time t, the second argument is the value of\n    Ito process X - `Tensor` of shape\n    `batch_shape + sample_shape + [dim]`, where `batch_shape` represents a batch\n    of models and `sample_shape` represents samples for each of the models. The\n    result is value of drift a(t, X). The return value of the callable is a real\n    `Tensor` of the same dtype as the input arguments and of shape\n    `batch_shape + sample_shape + [dim]`. For example, `sample_shape` can stand\n    for `[num_samples]` for Monte Carlo sampling, or\n    `[num_grid_points_1, ..., num_grid_points_dim]` for Finite Difference\n    solvers.\n\n    Returns:\n      The instantaneous drift rate callable.\n    '
        return self._drift_fn

    def volatility_fn(self):
        if False:
            while True:
                i = 10
        'Python callable calculating the instantaneous volatility.\n\n    The callable should accept two real `Tensor` arguments of the same dtype and\n    shape `times_shape`. The first argument is the scalar time t, the second\n    argument is the value of Ito process X - `Tensor` of shape\n    `batch_shape + sample_shape + [dim]`, where `batch_shape` represents a batch\n    of models and `sample_shape` represents samples for each of the models. The\n    result is value of volatility S_{ij}(t, X). The return value of the callable\n    is a real `Tensor` of the same dtype as the input arguments and of shape\n    `batch_shape + sample_shape + [dim, dim]`. For example, `sample_shape` can\n    stand for `[num_samples]` for Monte Carlo sampling, or\n    `[num_grid_points_1, ..., num_grid_points_dim]` for Finite Difference\n    solvers.\n\n    Returns:\n      The instantaneous volatility callable.\n    '
        return self._volatility_fn

    def sample_paths(self, times, num_samples=1, initial_state=None, random_type=None, seed=None, swap_memory=True, name=None, time_step=None, num_time_steps=None, skip=0, precompute_normal_draws=True, times_grid=None, normal_draws=None, watch_params=None, validate_args=False):
        if False:
            return 10
        "Returns a sample of paths from the process using Euler sampling.\n\n    The default implementation uses the Euler scheme. However, for particular\n    types of Ito processes more efficient schemes can be used.\n\n    Args:\n      times: Rank 1 `Tensor` of increasing positive real values. The times at\n        which the path points are to be evaluated.\n      num_samples: Positive scalar `int`. The number of paths to draw.\n        Default value: 1.\n      initial_state: `Tensor` of shape broadcastable\n        `batch_shape + [num_samples, dim]`. The initial state of the process.\n        `batch_shape` represents the shape of the independent batches of the\n        stochastic process as in the `drift_fn` and `volatility_fn` of the\n        underlying class. Note that the `batch_shape` is inferred from\n        the `initial_state` and hence when sampling is requested for a batch of\n        stochastic processes, the shape of `initial_state` should be as least\n        `batch_shape + [1, 1]`.\n        Default value: None which maps to a zero initial state.\n      random_type: Enum value of `RandomType`. The type of (quasi)-random number\n        generator to use to generate the paths.\n        Default value: None which maps to the standard pseudo-random numbers.\n      seed: Seed for the random number generator. The seed is\n        only relevant if `random_type` is one of\n        `[STATELESS, PSEUDO, HALTON_RANDOMIZED, PSEUDO_ANTITHETIC,\n          STATELESS_ANTITHETIC]`. For `PSEUDO`, `PSEUDO_ANTITHETIC` and\n        `HALTON_RANDOMIZED` the seed should be an Python integer. For\n        `STATELESS` and  `STATELESS_ANTITHETIC `must be supplied as an integer\n        `Tensor` of shape `[2]`.\n        Default value: `None` which means no seed is set.\n      swap_memory: A Python bool. Whether GPU-CPU memory swap is enabled for\n        this op. See an equivalent flag in `tf.while_loop` documentation for\n        more details. Useful when computing a gradient of the op since\n        `tf.while_loop` is used to propagate stochastic process in time.\n        Default value: True.\n      name: Python string. The name to give this op.\n        Default value: `None` which maps to `sample_paths` is used.\n      time_step: An optional scalar real `Tensor` - maximal distance between\n        points in the time grid.\n        Either this or `num_time_steps` should be supplied.\n        Default value: `None`.\n      num_time_steps: An optional Scalar integer `Tensor` - a total number of\n        time steps performed by the algorithm. The maximal distance between\n        points in grid is bounded by\n        `times[-1] / (num_time_steps - times.shape[0])`.\n        Either this or `time_step` should be supplied.\n        Default value: `None`.\n      skip: `int32` 0-d `Tensor`. The number of initial points of the Sobol or\n        Halton sequence to skip. Used only when `random_type` is 'SOBOL',\n        'HALTON', or 'HALTON_RANDOMIZED', otherwise ignored.\n        Default value: `0`.\n      precompute_normal_draws: Python bool. Indicates whether the noise\n        increments in Euler scheme are precomputed upfront (see\n        `models.euler_sampling.sample`). For `HALTON` and `SOBOL` random types\n        the increments are always precomputed. While the resulting graph\n        consumes more memory, the performance gains might be significant.\n        Default value: `True`.\n      times_grid: An optional rank 1 `Tensor` representing time discretization\n        grid. If `times` are not on the grid, then the nearest points from the\n        grid are used.\n        Default value: `None`, which means that times grid is computed using\n        `time_step` and `num_time_steps`.\n      normal_draws: A `Tensor` of shape\n        `batch_shape + [num_samples, num_time_points, dim]`\n        and the same `dtype` as `times`. Represents random normal draws to\n        compute increments `N(0, t_{n+1}) - N(0, t_n)`. `batch_shape` is the\n        shape of the independent batches of the stochastic process. When\n        supplied, `num_sample`, `time_step` and `num_time_steps` arguments are\n        ignored and the first dimensions of `normal_draws` are used instead.\n      watch_params: An optional list of zero-dimensional `Tensor`s of the same\n        `dtype` as `initial_state`. If provided, specifies `Tensor`s with\n        respect to which the differentiation of the sampling function will\n        happen. A more efficient algorithm is used when `watch_params` are\n        specified. Note the the function becomes differentiable onlhy wrt to\n        these `Tensor`s and the `initial_state`. The gradient wrt any other\n        `Tensor` is set to be zero.\n      validate_args: Python `bool`. When `True` and `normal_draws` are supplied,\n        checks that `tf.shape(normal_draws)[1]` is equal to `num_time_steps`\n        that is either supplied as an argument or computed from `time_step`.\n        When `False` invalid dimension may silently render incorrect outputs.\n        Default value: `False`.\n\n    Returns:\n     A real `Tensor` of shape `batch_shape + [num_samples, k, n]` where `k`\n     is the size of the `times`, and `n` is the dimension of the process.\n\n    Raises:\n      ValueError:\n        (a) When `times_grid` is not supplied, and neither `num_time_steps` nor\n          `time_step` are supplied or if both are supplied.\n        (b) If `normal_draws` is supplied and `dim` is mismatched.\n      tf.errors.InvalidArgumentError: If `normal_draws` is supplied and\n        `num_time_steps` is mismatched.\n    "
        name = name or self._name + '_sample_path'
        with tf.name_scope(name):
            return euler_sampling.sample(dim=self._dim, drift_fn=self._drift_fn, volatility_fn=self._volatility_fn, times=times, num_samples=num_samples, initial_state=initial_state, random_type=random_type, time_step=time_step, num_time_steps=num_time_steps, seed=seed, swap_memory=swap_memory, skip=skip, precompute_normal_draws=precompute_normal_draws, times_grid=times_grid, normal_draws=normal_draws, watch_params=watch_params, dtype=self._dtype, name=name)

    def fd_solver_backward(self, start_time, end_time, coord_grid, values_grid, discounting=None, one_step_fn=None, boundary_conditions=None, start_step_count=0, num_steps=None, time_step=None, values_transform_fn=None, dtype=None, name=None, **kwargs):
        if False:
            print('Hello World!')
        "Returns a solver for Feynman-Kac PDE associated to the process.\n\n    This method applies a finite difference method to solve the final value\n    problem as it appears in the Feynman-Kac formula associated to this Ito\n    process. The Feynman-Kac PDE is closely related to the backward Kolomogorov\n    equation associated to the stochastic process and allows for the inclusion\n    of a discounting function.\n\n    For more details of the Feynman-Kac theorem see [1]. The PDE solved by this\n    method is:\n\n    ```None\n      V_t + Sum[mu_i(t, x) V_i, 1<=i<=n] +\n        (1/2) Sum[ D_{ij} V_{ij}, 1 <= i,j <= n] - r(t, x) V = 0\n    ```\n\n    In the above, `V_t` is the derivative of `V` with respect to `t`,\n    `V_i` is the partial derivative with respect to `x_i` and `V_{ij}` the\n    (mixed) partial derivative with respect to `x_i` and `x_j`. `mu_i` is the\n    drift of this process and `D_{ij}` are the components of the diffusion\n    tensor:\n\n    ```None\n      D_{ij}(t,x) = (Sigma(t,x) . Transpose[Sigma(t,x)])_{ij}\n    ```\n\n    This method evolves a spatially discretized solution of the above PDE from\n    time `t0` to time `t1 < t0` (i.e. backwards in time).\n    The solution `V(t,x)` is assumed to be discretized on an `n`-dimensional\n    rectangular grid. A rectangular grid, G, in n-dimensions may be described\n    by specifying the coordinates of the points along each axis. For example,\n    a 2 x 4 grid in two dimensions can be specified by taking the cartesian\n    product of [1, 3] and [5, 6, 7, 8] to yield the grid points with\n    coordinates: `[(1, 5), (1, 6), (1, 7), (1, 8), (3, 5) ... (3, 8)]`.\n\n    This method allows batching of solutions. In this context, batching means\n    the ability to represent and evolve multiple independent functions `V`\n    (e.g. V1, V2 ...) simultaneously. A single discretized solution is specified\n    by stating its values at each grid point. This can be represented as a\n    `Tensor` of shape [d1, d2, ... dn] where di is the grid size along the `i`th\n    axis. A batch of such solutions is represented by a `Tensor` of shape:\n    `batch_shape + payoff_shape + [d1, d2, ... dn]` where `batch_shape` is the\n    batch of processes as in the underlying `drift_fn` and `volatility_fn` and\n    `payoff_shape` are the equations to be solved for each batch element.\n\n    The evolution of the solution from `t0` to `t1` is often done by\n    discretizing the differential equation to a difference equation along\n    the spatial and temporal axes. The temporal discretization is given by a\n    (sequence of) time steps [dt_1, dt_2, ... dt_k] such that the sum of the\n    time steps is equal to the total time step `t0 - t1`. If a uniform time\n    step is used, it may equivalently be specified by stating the number of\n    steps (n_steps) to take. This method provides both options via the\n    `time_step` and `num_steps` parameters. However, not all methods need\n    discretization along time direction (e.g. method of lines) so this argument\n    may not be applicable to some implementations.\n\n    The workhorse of this method is the `one_step_fn`. For the commonly used\n    methods, see functions in `math.pde.steppers` module.\n\n    The mapping between the arguments of this method and the above\n    equation are described in the Args section below.\n\n    For a simple instructive example of implementation of this method, see\n    `models.GenericItoProcess.fd_solver_backward`.\n\n    #### Examples\n    ```python\n    import tensorflow as tf\n    import numpy as np\n\n    import tf_quant_finance as tff\n    dtype = tf.float64\n\n    # Specify volatilities, interest rates and strikes for the options\n    volatilities = tf.constant([[0.3], [0.15], [0.1]], dtype)\n    rates = tf.constant([[0.01], [0.03], [0.01]], dtype)\n    expiries = 1.0\n\n    # Define Generic Ito Process\n\n    # Process dimensionality\n    dim = 1\n\n    # Batch size of the process\n    num_processes = 3\n\n    def drift_fn(t, x):\n      del t\n      # `x` is expected to be of shape [num_processes] + sample_shape + [dim]\n      # We need to expand rank of rates to\n      # `[num_processes] + extra_rank * [1] + [1]`\n      expand_rank = x.shape.rank - 2\n      rates_expand = tf.reshape(\n          rates, [num_processes] + (expand_rank + 1) * [1])\n      # Output is of shape [num_processes] + sample_shape + [dim]\n      return rates_expand * x\n\n    def vol_fn(t, x):\n      del t\n      # `x` is expected to be of shape [num_processes] + sample_shape + [dim]\n      # As before, need to expand rank of volatilities to\n      # `[num_processes] + extra_rank * [1] + [1]`\n      expand_rank = x.shape.rank - 2\n      volatilities_expand = tf.reshape(\n          volatilities, [num_processes] + (expand_rank + 1) * [1])\n      # Output is of shape [num_processes] + sample_shape + [dim, dim]\n      return (tf.expand_dims(volatilities_expand * x, axis=-1)\n              * tf.eye(dim, batch_shape=x.shape.as_list()[:-1], dtype=x.dtype))\n\n    process = tff.models.GenericItoProcess(dim=dim,\n                                           drift_fn=drift_fn,\n                                           volatility_fn=vol_fn,\n                                           dtype=dtype)\n    # Define a 2 strikes for each batch process,\n    num_strikes = 2\n    # Shape [num_processes, num_strikes, 1]. Here 1 at the end is just for\n    # convenience\n    strikes = tf.constant([[[50], [60]], [[100], [90]], [[120], [90]]], dtype)\n\n    # Price a batch of European call options\n    @tff.math.pde.boundary_conditions.dirichlet\n    def upper_boundary_fn(t, grid):\n      del grid\n      # Shape (num_processes, num_strikes)\n      return tf.squeeze(s_max - strikes * tf.exp(-rates  * (expiries - t)))\n\n    # Define discounting function\n    def discounting(t, x):\n      del t, x\n      rates_expand = tf.expand_dims(rates, axis=-1)\n      # Shape compatible with (num_processes, num_strikes)\n      return rates_expand\n\n    # Build a uniform grid\n    s_min = 0\n    s_max = 200\n    num_grid_points = 256  # Number of grid points\n\n    grid = tff.math.pde.grids.uniform_grid(minimums=[s_min],\n                                           maximums=[s_max],\n                                           sizes=[num_grid_points],\n                                           dtype=dtype)\n\n    # Shape [num_processes, num_strikes, num_grid_points]\n    final_value_grid = tf.nn.relu(grid[0] - strikes)\n\n    # Estimated prices for the European options\n    process.fd_solver_backward(\n        start_time=expiries,\n        end_time=0,\n        time_step=0.1,\n        coord_grid=grid,\n        values_grid=final_value_grid,\n        discounting=discounting,\n        boundary_condtions=[(None, upper_boundary_fn)])[0]\n    # Shape of the output is [num_processes, num_strikes, num_grid_points]\n    ```\n\n    Args:\n      start_time: Real positive scalar `Tensor`. The start time of the grid.\n        Corresponds to time `t0` above.\n      end_time: Real scalar `Tensor` smaller than the `start_time` and greater\n        than zero. The time to step back to. Corresponds to time `t1` above.\n      coord_grid: List of `n` rank 1 real `Tensor`s. `n` is the dimension of the\n        domain. The i-th `Tensor` has shape, `[d_i]` where `d_i` is the size of\n        the grid along axis `i`. The coordinates of the grid points. Corresponds\n        to the spatial grid `G` above.\n      values_grid: Real `Tensor` containing the function values at time\n        `start_time` which have to be stepped back to time `end_time`. The shape\n        of the `Tensor` must broadcast with\n        `batch_shape + payoff_shape + [d_1, d_2, ..., d_n]`. `batch_shape`\n        represents the batch of the processes as in the underlying `drift_fn`\n        and `volatility_fn`. `payoff_shape` specifies equations to be solved for\n        each batch element (with potentially different boundary/final conditions\n        and for various coordinate grids). When the batch dimensions\n        `batch_shape` or `payoff_shape` are present, the shape of values_grid`\n        must be at least `batch_shape + payoff_shape + dim * [1]`.\n      discounting: Callable corresponding to `r(t,x)` above. If not supplied,\n        zero discounting is assumed.\n      one_step_fn: The transition kernel. A callable that consumes the following\n        arguments by keyword:\n          1. 'time': Current time\n          2. 'next_time': The next time to step to. For the backwards in time\n            evolution, this time will be smaller than the current time.\n          3. 'coord_grid': The coordinate grid.\n          4. 'values_grid': The values grid.\n          5. 'boundary_conditions': The boundary conditions.\n          6. 'quadratic_coeff': A callable returning the quadratic coefficients\n            of the PDE (i.e. `(1/2)D_{ij}(t, x)` above). The callable accepts\n            the time and  coordinate grid as keyword arguments and returns a\n            `Tensor` with shape that broadcasts with `[dim, dim]`.\n          7. 'linear_coeff': A callable returning the linear coefficients of the\n            PDE (i.e. `mu_i(t, x)` above). Accepts time and coordinate grid as\n            keyword arguments and returns a `Tensor` with shape that broadcasts\n            with `[dim]`.\n          8. 'constant_coeff': A callable returning the coefficient of the\n            linear homogeneous term (i.e. `r(t,x)` above). Same spec as above.\n            The `one_step_fn` callable returns a 2-tuple containing the next\n            coordinate grid, next values grid.\n      boundary_conditions: The boundary conditions. Only rectangular boundary\n        conditions are supported. A list of tuples of size `n` (space dimension\n        of the PDE). The elements of the Tuple can be either a Python Callable\n        or `None` representing the boundary conditions at the minimum and\n        maximum values of the spatial variable indexed by the position in the\n        list. E.g., for `n=2`, the length of `boundary_conditions` should be 2,\n        `boundary_conditions[0][0]` describes the boundary `(y_min, x)`, and\n        `boundary_conditions[1][0]`- the boundary `(y, x_min)`. `None` values\n        mean that the second order terms for that dimension on the boundary are\n        assumed to be zero, i.e., if `boundary_conditions[k][0]` is `None`,\n        'dV/dt + Sum[a_ij d2(A_ij V)/dx_i dx_j, 1 <= i, j <= n, i!=k+1, j!=k+1]\n           + Sum[b_i d(B_i V)/dx_i, 1 <= i <= n] + c V = 0.'\n        For not `None` values, the boundary conditions are accepted in the form\n        `alpha(t, x) V + beta(t, x) V_n = gamma(t, x)`, where `V_n` is the\n        derivative with respect to the exterior normal to the boundary.\n        Each callable receives the current time `t` and the `coord_grid` at the\n        current time, and should return a tuple of `alpha`, `beta`, and `gamma`.\n        Each can be a number, a zero-rank `Tensor` or a `Tensor` whose shape is\n        the grid shape with the corresponding dimension removed.\n        For example, for a two-dimensional grid of shape `(b, ny, nx)`, where\n        `b` is the batch size, `boundary_conditions[0][i]` with `i = 0, 1`\n        should return a tuple of either numbers, zero-rank tensors or tensors of\n        shape `(b, nx)`. Similarly for `boundary_conditions[1][i]`, except the\n        tensor shape should be `(b, ny)`. `alpha` and `beta` can also be `None`\n        in case of Neumann and Dirichlet conditions, respectively.\n        Default value: `None`. Unlike setting `None` to individual elements of\n        `boundary_conditions`, setting the entire `boundary_conditions` object\n        to `None` means Dirichlet conditions with zero value on all boundaries\n        are applied.\n      start_step_count: Scalar integer `Tensor`. Initial value for the number of\n        time steps performed.\n        Default value: 0 (i.e. no previous steps performed).\n      num_steps: Positive int scalar `Tensor`. The number of time steps to take\n        when moving from `start_time` to `end_time`. Either this argument or the\n        `time_step` argument must be supplied (but not both). If num steps is\n        `k>=1`, uniform time steps of size `(t0 - t1)/k` are taken to evolve the\n        solution from `t0` to `t1`. Corresponds to the `n_steps` parameter\n        above.\n      time_step: The time step to take. Either this argument or the `num_steps`\n        argument must be supplied (but not both). The type of this argument may\n        be one of the following (in order of generality): (a) None in which case\n          `num_steps` must be supplied. (b) A positive real scalar `Tensor`. The\n          maximum time step to take. If the value of this argument is `dt`, then\n          the total number of steps taken is N = (t0 - t1) / dt rounded up to\n          the nearest integer. The first N-1 steps are of size dt and the last\n          step is of size `t0 - t1 - (N-1) * dt`. (c) A callable accepting the\n          current time and returning the size of the step to take. The input and\n          the output are real scalar `Tensor`s.\n      values_transform_fn: An optional callable applied to transform the\n        solution values at each time step. The callable is invoked after the\n        time step has been performed. The callable should accept the time of the\n        grid, the coordinate grid and the values grid and should return the\n        values grid. All input arguments to be passed by keyword.\n      dtype: The dtype to use.\n      name: The name to give to the ops.\n        Default value: None which means `solve_backward` is used.\n      **kwargs: Additional keyword args:\n        (1) pde_solver_fn: Function to solve the PDE that accepts all the above\n          arguments by name and returns the same tuple object as required below.\n          Defaults to `tff.math.pde.fd_solvers.solve_backward`.\n\n    Returns:\n      A tuple object containing at least the following attributes:\n        final_values_grid: A `Tensor` of same shape and dtype as `values_grid`.\n          Contains the final state of the values grid at time `end_time`.\n        final_coord_grid: A list of `Tensor`s of the same specification as\n          the input `coord_grid`. Final state of the coordinate grid at time\n          `end_time`.\n        step_count: The total step count (i.e. the sum of the `start_step_count`\n          and the number of steps performed in this call.).\n        final_time: The final time at which the evolution stopped. This value\n          is given by `max(min(end_time, start_time), 0)`.\n    "
        pde_solver_fn = kwargs.get('pde_solver_fn', fd_solvers.solve_backward)
        values_grid_shape = _get_static_shape(values_grid)
        batch_shape = values_grid_shape[:-self.dim()]
        (second_order_coeff_fn, first_order_coeff_fn, zeroth_order_coeff_fn) = _backward_pde_coeffs(self._drift_fn, self._volatility_fn, discounting, batch_shape=batch_shape, dim=self.dim())
        return pde_solver_fn(start_time=start_time, end_time=end_time, coord_grid=coord_grid, values_grid=values_grid, num_steps=num_steps, start_step_count=start_step_count, time_step=time_step, one_step_fn=one_step_fn, boundary_conditions=boundary_conditions, values_transform_fn=values_transform_fn, second_order_coeff_fn=second_order_coeff_fn, first_order_coeff_fn=first_order_coeff_fn, zeroth_order_coeff_fn=zeroth_order_coeff_fn, dtype=dtype, name=name)

    def fd_solver_forward(self, start_time, end_time, coord_grid, values_grid, one_step_fn=None, boundary_conditions=None, start_step_count=0, num_steps=None, time_step=None, values_transform_fn=None, dtype=None, name=None, **kwargs):
        if False:
            while True:
                i = 10
        "Returns a solver for the Fokker Plank equation of this process.\n\n    The Fokker Plank equation (also known as the Kolmogorov Forward equation)\n    associated to this Ito process is given by:\n\n    ```None\n      V_t + Sum[(mu_i(t, x) V)_i, 1<=i<=n]\n        - (1/2) Sum[ (D_{ij} V)_{ij}, 1 <= i,j <= n] = 0\n    ```\n\n    with the initial value condition $$V(0, x) = u(x)$$.\n\n    This method evolves a spatially discretized solution of the above PDE from\n    time `t0` to time `t1 > t0` (i.e. forwards in time).\n    The solution `V(t,x)` is assumed to be discretized on an `n`-dimensional\n    rectangular grid. A rectangular grid, G, in n-dimensions may be described\n    by specifying the coordinates of the points along each axis. For example,\n    a 2 x 4 grid in two dimensions can be specified by taking the cartesian\n    product of [1, 3] and [5, 6, 7, 8] to yield the grid points with\n    coordinates: `[(1, 5), (1, 6), (1, 7), (1, 8), (3, 5) ... (3, 8)]`.\n\n    This method allows batching of solutions. In this context, batching means\n    the ability to represent and evolve multiple independent functions `V`\n    (e.g. V1, V2 ...) simultaneously. A single discretized solution is specified\n    by stating its values at each grid point. This can be represented as a\n    `Tensor` of shape [d1, d2, ... dn] where di is the grid size along the `i`th\n    axis. A batch of such solutions is represented by a `Tensor` of shape:\n    `batch_shape + payoff_shape + [d1, d2, ... dn]` where `batch_shape` is the\n    batch of processes as in the underlying `drift_fn` and `volatility_fn` and\n    `payoff_shape` are the equations to be solved for each batch element.\n\n    The evolution of the solution from `t0` to `t1` is often done by\n    discretizing the differential equation to a difference equation along\n    the spatial and temporal axes. The temporal discretization is given by a\n    (sequence of) time steps [dt_1, dt_2, ... dt_k] such that the sum of the\n    time steps is equal to the total time step `t1 - t0`. If a uniform time\n    step is used, it may equivalently be specified by stating the number of\n    steps (n_steps) to take. This method provides both options via the\n    `time_step` and `num_steps` parameters. However, not all methods need\n    discretization along time direction (e.g. method of lines) so this argument\n    may not be applicable to some implementations.\n\n    The workhorse of this method is the `one_step_fn`. For the commonly used\n    methods, see functions in `math.pde.steppers` module.\n\n    The mapping between the arguments of this method and the above\n    equation are described in the Args section below.\n\n    For a simple instructive example of implementation of this method, see\n    `models.GenericItoProcess.fd_solver_forward`.\n\n    Args:\n      start_time: Real positive scalar `Tensor`. The start time of the grid.\n        Corresponds to time `t0` above.\n      end_time: Real scalar `Tensor` smaller than the `start_time` and greater\n        than zero. The time to step back to. Corresponds to time `t1` above.\n      coord_grid: List of `n` rank 1 real `Tensor`s. `n` is the dimension of the\n        domain. The i-th `Tensor` has shape, `[d_i]` where `d_i` is the size of\n        the grid along axis `i`. The coordinates of the grid points. Corresponds\n        to the spatial grid `G` above.\n      values_grid: Real `Tensor` containing the function values at time\n        `start_time` which have to be stepped back to time `end_time`. The shape\n        of the `Tensor` must broadcast with\n        `batch_shape + payoff_shape + [d_1, d_2, ..., d_n]`. `batch_shape`\n        represents the batch of the processes as in the underlying `drift_fn`\n        and `volatility_fn`. `payoff_shape` specifies equations to be solved for\n        each batch element (with potentially different boundary/final conditions\n        and for various coordinate grids). When the batch dimensions\n        `batch_shape` or `payoff_shape` are present, the shape of values_grid`\n        must be at least `batch_shape + payoff_shape + dim * [1]`.\n      one_step_fn: The transition kernel. A callable that consumes the following\n        arguments by keyword:\n          1. 'time': Current time\n          2. 'next_time': The next time to step to. For the backwards in time\n            evolution, this time will be smaller than the current time.\n          3. 'coord_grid': The coordinate grid.\n          4. 'values_grid': The values grid.\n          5. 'quadratic_coeff': A callable returning the quadratic coefficients\n            of the PDE (i.e. `(1/2)D_{ij}(t, x)` above). The callable accepts\n            the time and  coordinate grid as keyword arguments and returns a\n            `Tensor` with shape that broadcasts with `[dim, dim]`.\n          6. 'linear_coeff': A callable returning the linear coefficients of the\n            PDE (i.e. `mu_i(t, x)` above). Accepts time and coordinate grid as\n            keyword arguments and returns a `Tensor` with shape that broadcasts\n            with `[dim]`.\n          7. 'constant_coeff': A callable returning the coefficient of the\n            linear homogeneous term (i.e. `r(t,x)` above). Same spec as above.\n            The `one_step_fn` callable returns a 2-tuple containing the next\n            coordinate grid, next values grid.\n      boundary_conditions: The boundary conditions. Only rectangular boundary\n        conditions are supported. A list of tuples of size `n` (space dimension\n        of the PDE). The elements of the Tuple can be either a Python Callable\n        or `None` representing the boundary conditions at the minimum and\n        maximum values of the spatial variable indexed by the position in the\n        list. E.g., for `n=2`, the length of `boundary_conditions` should be 2,\n        `boundary_conditions[0][0]` describes the boundary `(y_min, x)`, and\n        `boundary_conditions[1][0]`- the boundary `(y, x_min)`. `None` values\n        mean that the second order terms for that dimension on the boundary are\n        assumed to be zero, i.e., if `boundary_conditions[k][0]` is `None`,\n        'dV/dt + Sum[a_ij d2(A_ij V)/dx_i dx_j, 1 <= i, j <= n, i!=k+1, j!=k+1]\n           + Sum[b_i d(B_i V)/dx_i, 1 <= i <= n] + c V = 0.'\n        For not `None` values, the boundary conditions are accepted in the form\n        `alpha(t, x) V + beta(t, x) V_n = gamma(t, x)`, where `V_n` is the\n        derivative with respect to the exterior normal to the boundary.\n        Each callable receives the current time `t` and the `coord_grid` at the\n        current time, and should return a tuple of `alpha`, `beta`, and `gamma`.\n        Each can be a number, a zero-rank `Tensor` or a `Tensor` whose shape is\n        the grid shape with the corresponding dimension removed.\n        For example, for a two-dimensional grid of shape `(b, ny, nx)`, where\n        `b` is the batch size, `boundary_conditions[0][i]` with `i = 0, 1`\n        should return a tuple of either numbers, zero-rank tensors or tensors of\n        shape `(b, nx)`. Similarly for `boundary_conditions[1][i]`, except the\n        tensor shape should be `(b, ny)`. `alpha` and `beta` can also be `None`\n        in case of Neumann and Dirichlet conditions, respectively.\n        Default value: `None`. Unlike setting `None` to individual elements of\n        `boundary_conditions`, setting the entire `boundary_conditions` object\n        to `None` means Dirichlet conditions with zero value on all boundaries\n        are applied.\n      start_step_count: Scalar integer `Tensor`. Initial value for the number of\n        time steps performed.\n        Default value: 0 (i.e. no previous steps performed).\n      num_steps: Positive int scalar `Tensor`. The number of time steps to take\n        when moving from `start_time` to `end_time`. Either this argument or the\n        `time_step` argument must be supplied (but not both). If num steps is\n        `k>=1`, uniform time steps of size `(t0 - t1)/k` are taken to evolve the\n        solution from `t0` to `t1`. Corresponds to the `n_steps` parameter\n        above.\n      time_step: The time step to take. Either this argument or the `num_steps`\n        argument must be supplied (but not both). The type of this argument may\n        be one of the following (in order of generality): (a) None in which case\n          `num_steps` must be supplied. (b) A positive real scalar `Tensor`. The\n          maximum time step to take. If the value of this argument is `dt`, then\n          the total number of steps taken is N = (t1 - t0) / dt rounded up to\n          the nearest integer. The first N-1 steps are of size dt and the last\n          step is of size `t1 - t0 - (N-1) * dt`. (c) A callable accepting the\n          current time and returning the size of the step to take. The input and\n          the output are real scalar `Tensor`s.\n      values_transform_fn: An optional callable applied to transform the\n        solution values at each time step. The callable is invoked after the\n        time step has been performed. The callable should accept the time of the\n        grid, the coordinate grid and the values grid and should return the\n        values grid. All input arguments to be passed by keyword.\n      dtype: The dtype to use.\n      name: The name to give to the ops.\n        Default value: None which means `solve_forward` is used.\n      **kwargs: Additional keyword args:\n        (1) pde_solver_fn: Function to solve the PDE that accepts all the above\n          arguments by name and returns the same tuple object as required below.\n          Defaults to `tff.math.pde.fd_solvers.solve_forward`.\n\n    Returns:\n      A tuple object containing at least the following attributes:\n        final_values_grid: A `Tensor` of same shape and dtype as `values_grid`.\n          Contains the final state of the values grid at time `end_time`.\n        final_coord_grid: A list of `Tensor`s of the same specification as\n          the input `coord_grid`. Final state of the coordinate grid at time\n          `end_time`.\n        step_count: The total step count (i.e. the sum of the `start_step_count`\n          and the number of steps performed in this call.).\n        final_time: The final time at which the evolution stopped. This value\n          is given by `max(min(end_time, start_time), 0)`.\n    "
        pde_solver_fn = kwargs.get('pde_solver_fn', fd_solvers.solve_forward)
        values_grid_shape = _get_static_shape(values_grid)
        batch_shape = values_grid_shape[:-self.dim()]
        (backward_second_order, backward_first_order, backward_zeroth_order) = _backward_pde_coeffs(self._drift_fn, self._volatility_fn, discounting=None, batch_shape=batch_shape, dim=self.dim())
        inner_second_order_coeff_fn = lambda t, x: -backward_second_order(t, x)
        inner_first_order_coeff_fn = backward_first_order
        zeroth_order_coeff_fn = backward_zeroth_order
        return pde_solver_fn(start_time=start_time, end_time=end_time, coord_grid=coord_grid, values_grid=values_grid, num_steps=num_steps, start_step_count=start_step_count, time_step=time_step, one_step_fn=one_step_fn, boundary_conditions=boundary_conditions, values_transform_fn=values_transform_fn, inner_second_order_coeff_fn=inner_second_order_coeff_fn, inner_first_order_coeff_fn=inner_first_order_coeff_fn, zeroth_order_coeff_fn=zeroth_order_coeff_fn, dtype=dtype, name=name)

def _backward_pde_coeffs(drift_fn, volatility_fn, discounting, batch_shape, dim):
    if False:
        i = 10
        return i + 15
    'Returns coeffs of the backward PDE.'

    def second_order_coeff_fn(t, coord_grid):
        if False:
            for i in range(10):
                print('nop')
        coord_grid = _broadcast_batch_shape(_coord_grid_to_mesh_grid(coord_grid), batch_shape, dim)
        sigma = volatility_fn(t, coord_grid)
        sigma_times_sigma_t = tf.linalg.matmul(sigma, sigma, transpose_b=True)
        rank = len(sigma.shape.as_list())
        perm = [rank - 2, rank - 1] + list(range(rank - 2))
        sigma_times_sigma_t = tf.transpose(sigma_times_sigma_t, perm)
        return sigma_times_sigma_t / 2

    def first_order_coeff_fn(t, coord_grid):
        if False:
            for i in range(10):
                print('nop')
        coord_grid = _broadcast_batch_shape(_coord_grid_to_mesh_grid(coord_grid), batch_shape, dim)
        mu = drift_fn(t, coord_grid)
        rank = len(mu.shape.as_list())
        perm = [rank - 1] + list(range(rank - 1))
        mu = tf.transpose(mu, perm)
        return mu

    def zeroth_order_coeff_fn(t, coord_grid):
        if False:
            while True:
                i = 10
        coord_grid = _broadcast_batch_shape(_coord_grid_to_mesh_grid(coord_grid), batch_shape, dim)
        if not discounting:
            return None
        return -discounting(t, coord_grid)
    return (second_order_coeff_fn, first_order_coeff_fn, zeroth_order_coeff_fn)

def _coord_grid_to_mesh_grid(coord_grid):
    if False:
        print('Hello World!')
    if len(coord_grid) == 1:
        return tf.expand_dims(coord_grid[0], -1)
    return tf.stack(values=tf.meshgrid(*coord_grid, indexing='ij'), axis=-1)

def _get_static_shape(t):
    if False:
        for i in range(10):
            print('nop')
    t_shape = t.shape.as_list()
    if None in t_shape:
        t_shape = tf.shape(t)
    return t_shape

def _broadcast_batch_shape(x, batch_shape, dim):
    if False:
        while True:
            i = 10
    x_shape_no_batch = _get_static_shape(x)[-dim - 1:]
    if isinstance(x_shape_no_batch, list) and isinstance(batch_shape, list):
        return tf.broadcast_to(x, batch_shape + x_shape_no_batch)
    else:
        output_shape = tf.concat([batch_shape, x_shape_no_batch], axis=0)
        return tf.broadcast_to(x, output_shape)