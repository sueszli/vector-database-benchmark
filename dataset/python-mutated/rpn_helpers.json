[
    {
        "func_name": "create_rpn",
        "original": "def create_rpn(conv_out, scaled_gt_boxes, im_info, cfg, add_loss_functions=True):\n    \"\"\"\n    Creates a region proposal network for object detection as proposed in the \"Faster R-CNN\" paper:\n        Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun:\n        \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\"\n\n    Outputs object detection proposals by applying estimated bounding-box\n    transformations to a set of regular boxes (called \"anchors\").\n\n    Args:\n        conv_out:        The convolutional feature map, i.e. the output of the conv layers from the pretrained classification network\n        scaled_gt_boxes: The ground truth boxes as (x1, y1, x2, y2, label). Coordinates are absolute pixels wrt. the input image.\n        im_info:         A CNTK variable or constant containing\n                         (pad_width, pad_height, scaled_image_width, scaled_image_height, orig_img_width, orig_img_height)\n                         e.g. (1000, 1000, 1000, 600, 500, 300) for an original image of 600x300 that is scaled and padded to 1000x1000\n        cfg:             The configuration dictionary\n        add_loss_functions: If set to True rpn_losses will be returned, otherwise None is returned for the losses\n\n    Returns:\n        rpn_rois - the proposed ROIs\n        rpn_losses - the losses (SmoothL1 loss for bbox regression plus cross entropy for objectness)\n    \"\"\"\n    num_channels = cfg['MODEL'].RPN_NUM_CHANNELS\n    rpn_conv_3x3 = Convolution((3, 3), num_channels, activation=relu, pad=True, strides=1, init=normal(scale=0.01), init_bias=0.0)(conv_out)\n    rpn_cls_score = Convolution((1, 1), 18, activation=None, name='rpn_cls_score', init=normal(scale=0.01), init_bias=0.0)(rpn_conv_3x3)\n    rpn_bbox_pred = Convolution((1, 1), 36, activation=None, name='rpn_bbox_pred', init=normal(scale=0.01), init_bias=0.0)(rpn_conv_3x3)\n    num_predictions = int(rpn_cls_score.shape[0] / 2)\n    rpn_cls_score_rshp = reshape(rpn_cls_score, (2, num_predictions, rpn_cls_score.shape[1], rpn_cls_score.shape[2]), name='rpn_cls_score_rshp')\n    p_rpn_cls_score_rshp = cntk.placeholder()\n    rpn_cls_sm = softmax(p_rpn_cls_score_rshp, axis=0)\n    rpn_cls_prob = cntk.as_block(rpn_cls_sm, [(p_rpn_cls_score_rshp, rpn_cls_score_rshp)], 'Softmax', 'rpn_cls_prob')\n    rpn_cls_prob_reshape = reshape(rpn_cls_prob, rpn_cls_score.shape, name='rpn_cls_prob_reshape')\n    rpn_rois = create_proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg)\n    rpn_losses = None\n    if add_loss_functions:\n        proposal_layer_params = \"'feat_stride': {}\\n'scales':\\n - {}\".format(cfg['MODEL'].FEATURE_STRIDE, '\\n - '.join([str(v) for v in cfg['DATA'].PROPOSAL_LAYER_SCALES]))\n        atl = user_function(AnchorTargetLayer(rpn_cls_score, scaled_gt_boxes, im_info, rpn_batch_size=cfg['TRAIN'].RPN_BATCHSIZE, rpn_fg_fraction=cfg['TRAIN'].RPN_FG_FRACTION, clobber_positives=cfg['TRAIN'].RPN_CLOBBER_POSITIVES, positive_overlap=cfg['TRAIN'].RPN_POSITIVE_OVERLAP, negative_overlap=cfg['TRAIN'].RPN_NEGATIVE_OVERLAP, param_str=proposal_layer_params))\n        rpn_labels = atl.outputs[0]\n        rpn_bbox_targets = atl.outputs[1]\n        rpn_bbox_inside_weights = atl.outputs[2]\n        p_rpn_labels = cntk.placeholder()\n        p_rpn_cls_score_rshp = cntk.placeholder()\n        keeps = cntk.greater_equal(p_rpn_labels, 0.0)\n        fg_labels = element_times(p_rpn_labels, keeps, name='fg_targets')\n        bg_labels = minus(1, fg_labels, name='bg_targets')\n        rpn_labels_ignore = splice(bg_labels, fg_labels, axis=0)\n        rpn_ce = cross_entropy_with_softmax(p_rpn_cls_score_rshp, rpn_labels_ignore, axis=0)\n        rpn_loss_cls = element_times(rpn_ce, keeps)\n        cls_num_terms = reduce_sum(keeps)\n        cls_normalization_factor = 1.0 / cls_num_terms\n        normalized_rpn_cls_loss = reduce_sum(rpn_loss_cls) * cls_normalization_factor\n        reduced_rpn_loss_cls = cntk.as_block(normalized_rpn_cls_loss, [(p_rpn_labels, rpn_labels), (p_rpn_cls_score_rshp, rpn_cls_score_rshp)], 'CE_with_ignore', 'norm_rpn_cls_loss')\n        p_rpn_bbox_pred = cntk.placeholder()\n        p_rpn_bbox_targets = cntk.placeholder()\n        p_rpn_bbox_inside_weights = cntk.placeholder()\n        rpn_loss_bbox = SmoothL1Loss(cfg.SIGMA_RPN_L1, p_rpn_bbox_pred, p_rpn_bbox_targets, p_rpn_bbox_inside_weights, 1.0)\n        bbox_normalization_factor = 1.0 / cfg['TRAIN'].RPN_BATCHSIZE\n        normalized_rpn_bbox_loss = reduce_sum(rpn_loss_bbox) * bbox_normalization_factor\n        reduced_rpn_loss_bbox = cntk.as_block(normalized_rpn_bbox_loss, [(p_rpn_bbox_pred, rpn_bbox_pred), (p_rpn_bbox_targets, rpn_bbox_targets), (p_rpn_bbox_inside_weights, rpn_bbox_inside_weights)], 'SmoothL1Loss', 'norm_rpn_bbox_loss')\n        rpn_losses = plus(reduced_rpn_loss_cls, reduced_rpn_loss_bbox, name='rpn_losses')\n    return (rpn_rois, rpn_losses)",
        "mutated": [
            "def create_rpn(conv_out, scaled_gt_boxes, im_info, cfg, add_loss_functions=True):\n    if False:\n        i = 10\n    '\\n    Creates a region proposal network for object detection as proposed in the \"Faster R-CNN\" paper:\\n        Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun:\\n        \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\"\\n\\n    Outputs object detection proposals by applying estimated bounding-box\\n    transformations to a set of regular boxes (called \"anchors\").\\n\\n    Args:\\n        conv_out:        The convolutional feature map, i.e. the output of the conv layers from the pretrained classification network\\n        scaled_gt_boxes: The ground truth boxes as (x1, y1, x2, y2, label). Coordinates are absolute pixels wrt. the input image.\\n        im_info:         A CNTK variable or constant containing\\n                         (pad_width, pad_height, scaled_image_width, scaled_image_height, orig_img_width, orig_img_height)\\n                         e.g. (1000, 1000, 1000, 600, 500, 300) for an original image of 600x300 that is scaled and padded to 1000x1000\\n        cfg:             The configuration dictionary\\n        add_loss_functions: If set to True rpn_losses will be returned, otherwise None is returned for the losses\\n\\n    Returns:\\n        rpn_rois - the proposed ROIs\\n        rpn_losses - the losses (SmoothL1 loss for bbox regression plus cross entropy for objectness)\\n    '\n    num_channels = cfg['MODEL'].RPN_NUM_CHANNELS\n    rpn_conv_3x3 = Convolution((3, 3), num_channels, activation=relu, pad=True, strides=1, init=normal(scale=0.01), init_bias=0.0)(conv_out)\n    rpn_cls_score = Convolution((1, 1), 18, activation=None, name='rpn_cls_score', init=normal(scale=0.01), init_bias=0.0)(rpn_conv_3x3)\n    rpn_bbox_pred = Convolution((1, 1), 36, activation=None, name='rpn_bbox_pred', init=normal(scale=0.01), init_bias=0.0)(rpn_conv_3x3)\n    num_predictions = int(rpn_cls_score.shape[0] / 2)\n    rpn_cls_score_rshp = reshape(rpn_cls_score, (2, num_predictions, rpn_cls_score.shape[1], rpn_cls_score.shape[2]), name='rpn_cls_score_rshp')\n    p_rpn_cls_score_rshp = cntk.placeholder()\n    rpn_cls_sm = softmax(p_rpn_cls_score_rshp, axis=0)\n    rpn_cls_prob = cntk.as_block(rpn_cls_sm, [(p_rpn_cls_score_rshp, rpn_cls_score_rshp)], 'Softmax', 'rpn_cls_prob')\n    rpn_cls_prob_reshape = reshape(rpn_cls_prob, rpn_cls_score.shape, name='rpn_cls_prob_reshape')\n    rpn_rois = create_proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg)\n    rpn_losses = None\n    if add_loss_functions:\n        proposal_layer_params = \"'feat_stride': {}\\n'scales':\\n - {}\".format(cfg['MODEL'].FEATURE_STRIDE, '\\n - '.join([str(v) for v in cfg['DATA'].PROPOSAL_LAYER_SCALES]))\n        atl = user_function(AnchorTargetLayer(rpn_cls_score, scaled_gt_boxes, im_info, rpn_batch_size=cfg['TRAIN'].RPN_BATCHSIZE, rpn_fg_fraction=cfg['TRAIN'].RPN_FG_FRACTION, clobber_positives=cfg['TRAIN'].RPN_CLOBBER_POSITIVES, positive_overlap=cfg['TRAIN'].RPN_POSITIVE_OVERLAP, negative_overlap=cfg['TRAIN'].RPN_NEGATIVE_OVERLAP, param_str=proposal_layer_params))\n        rpn_labels = atl.outputs[0]\n        rpn_bbox_targets = atl.outputs[1]\n        rpn_bbox_inside_weights = atl.outputs[2]\n        p_rpn_labels = cntk.placeholder()\n        p_rpn_cls_score_rshp = cntk.placeholder()\n        keeps = cntk.greater_equal(p_rpn_labels, 0.0)\n        fg_labels = element_times(p_rpn_labels, keeps, name='fg_targets')\n        bg_labels = minus(1, fg_labels, name='bg_targets')\n        rpn_labels_ignore = splice(bg_labels, fg_labels, axis=0)\n        rpn_ce = cross_entropy_with_softmax(p_rpn_cls_score_rshp, rpn_labels_ignore, axis=0)\n        rpn_loss_cls = element_times(rpn_ce, keeps)\n        cls_num_terms = reduce_sum(keeps)\n        cls_normalization_factor = 1.0 / cls_num_terms\n        normalized_rpn_cls_loss = reduce_sum(rpn_loss_cls) * cls_normalization_factor\n        reduced_rpn_loss_cls = cntk.as_block(normalized_rpn_cls_loss, [(p_rpn_labels, rpn_labels), (p_rpn_cls_score_rshp, rpn_cls_score_rshp)], 'CE_with_ignore', 'norm_rpn_cls_loss')\n        p_rpn_bbox_pred = cntk.placeholder()\n        p_rpn_bbox_targets = cntk.placeholder()\n        p_rpn_bbox_inside_weights = cntk.placeholder()\n        rpn_loss_bbox = SmoothL1Loss(cfg.SIGMA_RPN_L1, p_rpn_bbox_pred, p_rpn_bbox_targets, p_rpn_bbox_inside_weights, 1.0)\n        bbox_normalization_factor = 1.0 / cfg['TRAIN'].RPN_BATCHSIZE\n        normalized_rpn_bbox_loss = reduce_sum(rpn_loss_bbox) * bbox_normalization_factor\n        reduced_rpn_loss_bbox = cntk.as_block(normalized_rpn_bbox_loss, [(p_rpn_bbox_pred, rpn_bbox_pred), (p_rpn_bbox_targets, rpn_bbox_targets), (p_rpn_bbox_inside_weights, rpn_bbox_inside_weights)], 'SmoothL1Loss', 'norm_rpn_bbox_loss')\n        rpn_losses = plus(reduced_rpn_loss_cls, reduced_rpn_loss_bbox, name='rpn_losses')\n    return (rpn_rois, rpn_losses)",
            "def create_rpn(conv_out, scaled_gt_boxes, im_info, cfg, add_loss_functions=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Creates a region proposal network for object detection as proposed in the \"Faster R-CNN\" paper:\\n        Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun:\\n        \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\"\\n\\n    Outputs object detection proposals by applying estimated bounding-box\\n    transformations to a set of regular boxes (called \"anchors\").\\n\\n    Args:\\n        conv_out:        The convolutional feature map, i.e. the output of the conv layers from the pretrained classification network\\n        scaled_gt_boxes: The ground truth boxes as (x1, y1, x2, y2, label). Coordinates are absolute pixels wrt. the input image.\\n        im_info:         A CNTK variable or constant containing\\n                         (pad_width, pad_height, scaled_image_width, scaled_image_height, orig_img_width, orig_img_height)\\n                         e.g. (1000, 1000, 1000, 600, 500, 300) for an original image of 600x300 that is scaled and padded to 1000x1000\\n        cfg:             The configuration dictionary\\n        add_loss_functions: If set to True rpn_losses will be returned, otherwise None is returned for the losses\\n\\n    Returns:\\n        rpn_rois - the proposed ROIs\\n        rpn_losses - the losses (SmoothL1 loss for bbox regression plus cross entropy for objectness)\\n    '\n    num_channels = cfg['MODEL'].RPN_NUM_CHANNELS\n    rpn_conv_3x3 = Convolution((3, 3), num_channels, activation=relu, pad=True, strides=1, init=normal(scale=0.01), init_bias=0.0)(conv_out)\n    rpn_cls_score = Convolution((1, 1), 18, activation=None, name='rpn_cls_score', init=normal(scale=0.01), init_bias=0.0)(rpn_conv_3x3)\n    rpn_bbox_pred = Convolution((1, 1), 36, activation=None, name='rpn_bbox_pred', init=normal(scale=0.01), init_bias=0.0)(rpn_conv_3x3)\n    num_predictions = int(rpn_cls_score.shape[0] / 2)\n    rpn_cls_score_rshp = reshape(rpn_cls_score, (2, num_predictions, rpn_cls_score.shape[1], rpn_cls_score.shape[2]), name='rpn_cls_score_rshp')\n    p_rpn_cls_score_rshp = cntk.placeholder()\n    rpn_cls_sm = softmax(p_rpn_cls_score_rshp, axis=0)\n    rpn_cls_prob = cntk.as_block(rpn_cls_sm, [(p_rpn_cls_score_rshp, rpn_cls_score_rshp)], 'Softmax', 'rpn_cls_prob')\n    rpn_cls_prob_reshape = reshape(rpn_cls_prob, rpn_cls_score.shape, name='rpn_cls_prob_reshape')\n    rpn_rois = create_proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg)\n    rpn_losses = None\n    if add_loss_functions:\n        proposal_layer_params = \"'feat_stride': {}\\n'scales':\\n - {}\".format(cfg['MODEL'].FEATURE_STRIDE, '\\n - '.join([str(v) for v in cfg['DATA'].PROPOSAL_LAYER_SCALES]))\n        atl = user_function(AnchorTargetLayer(rpn_cls_score, scaled_gt_boxes, im_info, rpn_batch_size=cfg['TRAIN'].RPN_BATCHSIZE, rpn_fg_fraction=cfg['TRAIN'].RPN_FG_FRACTION, clobber_positives=cfg['TRAIN'].RPN_CLOBBER_POSITIVES, positive_overlap=cfg['TRAIN'].RPN_POSITIVE_OVERLAP, negative_overlap=cfg['TRAIN'].RPN_NEGATIVE_OVERLAP, param_str=proposal_layer_params))\n        rpn_labels = atl.outputs[0]\n        rpn_bbox_targets = atl.outputs[1]\n        rpn_bbox_inside_weights = atl.outputs[2]\n        p_rpn_labels = cntk.placeholder()\n        p_rpn_cls_score_rshp = cntk.placeholder()\n        keeps = cntk.greater_equal(p_rpn_labels, 0.0)\n        fg_labels = element_times(p_rpn_labels, keeps, name='fg_targets')\n        bg_labels = minus(1, fg_labels, name='bg_targets')\n        rpn_labels_ignore = splice(bg_labels, fg_labels, axis=0)\n        rpn_ce = cross_entropy_with_softmax(p_rpn_cls_score_rshp, rpn_labels_ignore, axis=0)\n        rpn_loss_cls = element_times(rpn_ce, keeps)\n        cls_num_terms = reduce_sum(keeps)\n        cls_normalization_factor = 1.0 / cls_num_terms\n        normalized_rpn_cls_loss = reduce_sum(rpn_loss_cls) * cls_normalization_factor\n        reduced_rpn_loss_cls = cntk.as_block(normalized_rpn_cls_loss, [(p_rpn_labels, rpn_labels), (p_rpn_cls_score_rshp, rpn_cls_score_rshp)], 'CE_with_ignore', 'norm_rpn_cls_loss')\n        p_rpn_bbox_pred = cntk.placeholder()\n        p_rpn_bbox_targets = cntk.placeholder()\n        p_rpn_bbox_inside_weights = cntk.placeholder()\n        rpn_loss_bbox = SmoothL1Loss(cfg.SIGMA_RPN_L1, p_rpn_bbox_pred, p_rpn_bbox_targets, p_rpn_bbox_inside_weights, 1.0)\n        bbox_normalization_factor = 1.0 / cfg['TRAIN'].RPN_BATCHSIZE\n        normalized_rpn_bbox_loss = reduce_sum(rpn_loss_bbox) * bbox_normalization_factor\n        reduced_rpn_loss_bbox = cntk.as_block(normalized_rpn_bbox_loss, [(p_rpn_bbox_pred, rpn_bbox_pred), (p_rpn_bbox_targets, rpn_bbox_targets), (p_rpn_bbox_inside_weights, rpn_bbox_inside_weights)], 'SmoothL1Loss', 'norm_rpn_bbox_loss')\n        rpn_losses = plus(reduced_rpn_loss_cls, reduced_rpn_loss_bbox, name='rpn_losses')\n    return (rpn_rois, rpn_losses)",
            "def create_rpn(conv_out, scaled_gt_boxes, im_info, cfg, add_loss_functions=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Creates a region proposal network for object detection as proposed in the \"Faster R-CNN\" paper:\\n        Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun:\\n        \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\"\\n\\n    Outputs object detection proposals by applying estimated bounding-box\\n    transformations to a set of regular boxes (called \"anchors\").\\n\\n    Args:\\n        conv_out:        The convolutional feature map, i.e. the output of the conv layers from the pretrained classification network\\n        scaled_gt_boxes: The ground truth boxes as (x1, y1, x2, y2, label). Coordinates are absolute pixels wrt. the input image.\\n        im_info:         A CNTK variable or constant containing\\n                         (pad_width, pad_height, scaled_image_width, scaled_image_height, orig_img_width, orig_img_height)\\n                         e.g. (1000, 1000, 1000, 600, 500, 300) for an original image of 600x300 that is scaled and padded to 1000x1000\\n        cfg:             The configuration dictionary\\n        add_loss_functions: If set to True rpn_losses will be returned, otherwise None is returned for the losses\\n\\n    Returns:\\n        rpn_rois - the proposed ROIs\\n        rpn_losses - the losses (SmoothL1 loss for bbox regression plus cross entropy for objectness)\\n    '\n    num_channels = cfg['MODEL'].RPN_NUM_CHANNELS\n    rpn_conv_3x3 = Convolution((3, 3), num_channels, activation=relu, pad=True, strides=1, init=normal(scale=0.01), init_bias=0.0)(conv_out)\n    rpn_cls_score = Convolution((1, 1), 18, activation=None, name='rpn_cls_score', init=normal(scale=0.01), init_bias=0.0)(rpn_conv_3x3)\n    rpn_bbox_pred = Convolution((1, 1), 36, activation=None, name='rpn_bbox_pred', init=normal(scale=0.01), init_bias=0.0)(rpn_conv_3x3)\n    num_predictions = int(rpn_cls_score.shape[0] / 2)\n    rpn_cls_score_rshp = reshape(rpn_cls_score, (2, num_predictions, rpn_cls_score.shape[1], rpn_cls_score.shape[2]), name='rpn_cls_score_rshp')\n    p_rpn_cls_score_rshp = cntk.placeholder()\n    rpn_cls_sm = softmax(p_rpn_cls_score_rshp, axis=0)\n    rpn_cls_prob = cntk.as_block(rpn_cls_sm, [(p_rpn_cls_score_rshp, rpn_cls_score_rshp)], 'Softmax', 'rpn_cls_prob')\n    rpn_cls_prob_reshape = reshape(rpn_cls_prob, rpn_cls_score.shape, name='rpn_cls_prob_reshape')\n    rpn_rois = create_proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg)\n    rpn_losses = None\n    if add_loss_functions:\n        proposal_layer_params = \"'feat_stride': {}\\n'scales':\\n - {}\".format(cfg['MODEL'].FEATURE_STRIDE, '\\n - '.join([str(v) for v in cfg['DATA'].PROPOSAL_LAYER_SCALES]))\n        atl = user_function(AnchorTargetLayer(rpn_cls_score, scaled_gt_boxes, im_info, rpn_batch_size=cfg['TRAIN'].RPN_BATCHSIZE, rpn_fg_fraction=cfg['TRAIN'].RPN_FG_FRACTION, clobber_positives=cfg['TRAIN'].RPN_CLOBBER_POSITIVES, positive_overlap=cfg['TRAIN'].RPN_POSITIVE_OVERLAP, negative_overlap=cfg['TRAIN'].RPN_NEGATIVE_OVERLAP, param_str=proposal_layer_params))\n        rpn_labels = atl.outputs[0]\n        rpn_bbox_targets = atl.outputs[1]\n        rpn_bbox_inside_weights = atl.outputs[2]\n        p_rpn_labels = cntk.placeholder()\n        p_rpn_cls_score_rshp = cntk.placeholder()\n        keeps = cntk.greater_equal(p_rpn_labels, 0.0)\n        fg_labels = element_times(p_rpn_labels, keeps, name='fg_targets')\n        bg_labels = minus(1, fg_labels, name='bg_targets')\n        rpn_labels_ignore = splice(bg_labels, fg_labels, axis=0)\n        rpn_ce = cross_entropy_with_softmax(p_rpn_cls_score_rshp, rpn_labels_ignore, axis=0)\n        rpn_loss_cls = element_times(rpn_ce, keeps)\n        cls_num_terms = reduce_sum(keeps)\n        cls_normalization_factor = 1.0 / cls_num_terms\n        normalized_rpn_cls_loss = reduce_sum(rpn_loss_cls) * cls_normalization_factor\n        reduced_rpn_loss_cls = cntk.as_block(normalized_rpn_cls_loss, [(p_rpn_labels, rpn_labels), (p_rpn_cls_score_rshp, rpn_cls_score_rshp)], 'CE_with_ignore', 'norm_rpn_cls_loss')\n        p_rpn_bbox_pred = cntk.placeholder()\n        p_rpn_bbox_targets = cntk.placeholder()\n        p_rpn_bbox_inside_weights = cntk.placeholder()\n        rpn_loss_bbox = SmoothL1Loss(cfg.SIGMA_RPN_L1, p_rpn_bbox_pred, p_rpn_bbox_targets, p_rpn_bbox_inside_weights, 1.0)\n        bbox_normalization_factor = 1.0 / cfg['TRAIN'].RPN_BATCHSIZE\n        normalized_rpn_bbox_loss = reduce_sum(rpn_loss_bbox) * bbox_normalization_factor\n        reduced_rpn_loss_bbox = cntk.as_block(normalized_rpn_bbox_loss, [(p_rpn_bbox_pred, rpn_bbox_pred), (p_rpn_bbox_targets, rpn_bbox_targets), (p_rpn_bbox_inside_weights, rpn_bbox_inside_weights)], 'SmoothL1Loss', 'norm_rpn_bbox_loss')\n        rpn_losses = plus(reduced_rpn_loss_cls, reduced_rpn_loss_bbox, name='rpn_losses')\n    return (rpn_rois, rpn_losses)",
            "def create_rpn(conv_out, scaled_gt_boxes, im_info, cfg, add_loss_functions=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Creates a region proposal network for object detection as proposed in the \"Faster R-CNN\" paper:\\n        Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun:\\n        \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\"\\n\\n    Outputs object detection proposals by applying estimated bounding-box\\n    transformations to a set of regular boxes (called \"anchors\").\\n\\n    Args:\\n        conv_out:        The convolutional feature map, i.e. the output of the conv layers from the pretrained classification network\\n        scaled_gt_boxes: The ground truth boxes as (x1, y1, x2, y2, label). Coordinates are absolute pixels wrt. the input image.\\n        im_info:         A CNTK variable or constant containing\\n                         (pad_width, pad_height, scaled_image_width, scaled_image_height, orig_img_width, orig_img_height)\\n                         e.g. (1000, 1000, 1000, 600, 500, 300) for an original image of 600x300 that is scaled and padded to 1000x1000\\n        cfg:             The configuration dictionary\\n        add_loss_functions: If set to True rpn_losses will be returned, otherwise None is returned for the losses\\n\\n    Returns:\\n        rpn_rois - the proposed ROIs\\n        rpn_losses - the losses (SmoothL1 loss for bbox regression plus cross entropy for objectness)\\n    '\n    num_channels = cfg['MODEL'].RPN_NUM_CHANNELS\n    rpn_conv_3x3 = Convolution((3, 3), num_channels, activation=relu, pad=True, strides=1, init=normal(scale=0.01), init_bias=0.0)(conv_out)\n    rpn_cls_score = Convolution((1, 1), 18, activation=None, name='rpn_cls_score', init=normal(scale=0.01), init_bias=0.0)(rpn_conv_3x3)\n    rpn_bbox_pred = Convolution((1, 1), 36, activation=None, name='rpn_bbox_pred', init=normal(scale=0.01), init_bias=0.0)(rpn_conv_3x3)\n    num_predictions = int(rpn_cls_score.shape[0] / 2)\n    rpn_cls_score_rshp = reshape(rpn_cls_score, (2, num_predictions, rpn_cls_score.shape[1], rpn_cls_score.shape[2]), name='rpn_cls_score_rshp')\n    p_rpn_cls_score_rshp = cntk.placeholder()\n    rpn_cls_sm = softmax(p_rpn_cls_score_rshp, axis=0)\n    rpn_cls_prob = cntk.as_block(rpn_cls_sm, [(p_rpn_cls_score_rshp, rpn_cls_score_rshp)], 'Softmax', 'rpn_cls_prob')\n    rpn_cls_prob_reshape = reshape(rpn_cls_prob, rpn_cls_score.shape, name='rpn_cls_prob_reshape')\n    rpn_rois = create_proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg)\n    rpn_losses = None\n    if add_loss_functions:\n        proposal_layer_params = \"'feat_stride': {}\\n'scales':\\n - {}\".format(cfg['MODEL'].FEATURE_STRIDE, '\\n - '.join([str(v) for v in cfg['DATA'].PROPOSAL_LAYER_SCALES]))\n        atl = user_function(AnchorTargetLayer(rpn_cls_score, scaled_gt_boxes, im_info, rpn_batch_size=cfg['TRAIN'].RPN_BATCHSIZE, rpn_fg_fraction=cfg['TRAIN'].RPN_FG_FRACTION, clobber_positives=cfg['TRAIN'].RPN_CLOBBER_POSITIVES, positive_overlap=cfg['TRAIN'].RPN_POSITIVE_OVERLAP, negative_overlap=cfg['TRAIN'].RPN_NEGATIVE_OVERLAP, param_str=proposal_layer_params))\n        rpn_labels = atl.outputs[0]\n        rpn_bbox_targets = atl.outputs[1]\n        rpn_bbox_inside_weights = atl.outputs[2]\n        p_rpn_labels = cntk.placeholder()\n        p_rpn_cls_score_rshp = cntk.placeholder()\n        keeps = cntk.greater_equal(p_rpn_labels, 0.0)\n        fg_labels = element_times(p_rpn_labels, keeps, name='fg_targets')\n        bg_labels = minus(1, fg_labels, name='bg_targets')\n        rpn_labels_ignore = splice(bg_labels, fg_labels, axis=0)\n        rpn_ce = cross_entropy_with_softmax(p_rpn_cls_score_rshp, rpn_labels_ignore, axis=0)\n        rpn_loss_cls = element_times(rpn_ce, keeps)\n        cls_num_terms = reduce_sum(keeps)\n        cls_normalization_factor = 1.0 / cls_num_terms\n        normalized_rpn_cls_loss = reduce_sum(rpn_loss_cls) * cls_normalization_factor\n        reduced_rpn_loss_cls = cntk.as_block(normalized_rpn_cls_loss, [(p_rpn_labels, rpn_labels), (p_rpn_cls_score_rshp, rpn_cls_score_rshp)], 'CE_with_ignore', 'norm_rpn_cls_loss')\n        p_rpn_bbox_pred = cntk.placeholder()\n        p_rpn_bbox_targets = cntk.placeholder()\n        p_rpn_bbox_inside_weights = cntk.placeholder()\n        rpn_loss_bbox = SmoothL1Loss(cfg.SIGMA_RPN_L1, p_rpn_bbox_pred, p_rpn_bbox_targets, p_rpn_bbox_inside_weights, 1.0)\n        bbox_normalization_factor = 1.0 / cfg['TRAIN'].RPN_BATCHSIZE\n        normalized_rpn_bbox_loss = reduce_sum(rpn_loss_bbox) * bbox_normalization_factor\n        reduced_rpn_loss_bbox = cntk.as_block(normalized_rpn_bbox_loss, [(p_rpn_bbox_pred, rpn_bbox_pred), (p_rpn_bbox_targets, rpn_bbox_targets), (p_rpn_bbox_inside_weights, rpn_bbox_inside_weights)], 'SmoothL1Loss', 'norm_rpn_bbox_loss')\n        rpn_losses = plus(reduced_rpn_loss_cls, reduced_rpn_loss_bbox, name='rpn_losses')\n    return (rpn_rois, rpn_losses)",
            "def create_rpn(conv_out, scaled_gt_boxes, im_info, cfg, add_loss_functions=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Creates a region proposal network for object detection as proposed in the \"Faster R-CNN\" paper:\\n        Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun:\\n        \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\"\\n\\n    Outputs object detection proposals by applying estimated bounding-box\\n    transformations to a set of regular boxes (called \"anchors\").\\n\\n    Args:\\n        conv_out:        The convolutional feature map, i.e. the output of the conv layers from the pretrained classification network\\n        scaled_gt_boxes: The ground truth boxes as (x1, y1, x2, y2, label). Coordinates are absolute pixels wrt. the input image.\\n        im_info:         A CNTK variable or constant containing\\n                         (pad_width, pad_height, scaled_image_width, scaled_image_height, orig_img_width, orig_img_height)\\n                         e.g. (1000, 1000, 1000, 600, 500, 300) for an original image of 600x300 that is scaled and padded to 1000x1000\\n        cfg:             The configuration dictionary\\n        add_loss_functions: If set to True rpn_losses will be returned, otherwise None is returned for the losses\\n\\n    Returns:\\n        rpn_rois - the proposed ROIs\\n        rpn_losses - the losses (SmoothL1 loss for bbox regression plus cross entropy for objectness)\\n    '\n    num_channels = cfg['MODEL'].RPN_NUM_CHANNELS\n    rpn_conv_3x3 = Convolution((3, 3), num_channels, activation=relu, pad=True, strides=1, init=normal(scale=0.01), init_bias=0.0)(conv_out)\n    rpn_cls_score = Convolution((1, 1), 18, activation=None, name='rpn_cls_score', init=normal(scale=0.01), init_bias=0.0)(rpn_conv_3x3)\n    rpn_bbox_pred = Convolution((1, 1), 36, activation=None, name='rpn_bbox_pred', init=normal(scale=0.01), init_bias=0.0)(rpn_conv_3x3)\n    num_predictions = int(rpn_cls_score.shape[0] / 2)\n    rpn_cls_score_rshp = reshape(rpn_cls_score, (2, num_predictions, rpn_cls_score.shape[1], rpn_cls_score.shape[2]), name='rpn_cls_score_rshp')\n    p_rpn_cls_score_rshp = cntk.placeholder()\n    rpn_cls_sm = softmax(p_rpn_cls_score_rshp, axis=0)\n    rpn_cls_prob = cntk.as_block(rpn_cls_sm, [(p_rpn_cls_score_rshp, rpn_cls_score_rshp)], 'Softmax', 'rpn_cls_prob')\n    rpn_cls_prob_reshape = reshape(rpn_cls_prob, rpn_cls_score.shape, name='rpn_cls_prob_reshape')\n    rpn_rois = create_proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg)\n    rpn_losses = None\n    if add_loss_functions:\n        proposal_layer_params = \"'feat_stride': {}\\n'scales':\\n - {}\".format(cfg['MODEL'].FEATURE_STRIDE, '\\n - '.join([str(v) for v in cfg['DATA'].PROPOSAL_LAYER_SCALES]))\n        atl = user_function(AnchorTargetLayer(rpn_cls_score, scaled_gt_boxes, im_info, rpn_batch_size=cfg['TRAIN'].RPN_BATCHSIZE, rpn_fg_fraction=cfg['TRAIN'].RPN_FG_FRACTION, clobber_positives=cfg['TRAIN'].RPN_CLOBBER_POSITIVES, positive_overlap=cfg['TRAIN'].RPN_POSITIVE_OVERLAP, negative_overlap=cfg['TRAIN'].RPN_NEGATIVE_OVERLAP, param_str=proposal_layer_params))\n        rpn_labels = atl.outputs[0]\n        rpn_bbox_targets = atl.outputs[1]\n        rpn_bbox_inside_weights = atl.outputs[2]\n        p_rpn_labels = cntk.placeholder()\n        p_rpn_cls_score_rshp = cntk.placeholder()\n        keeps = cntk.greater_equal(p_rpn_labels, 0.0)\n        fg_labels = element_times(p_rpn_labels, keeps, name='fg_targets')\n        bg_labels = minus(1, fg_labels, name='bg_targets')\n        rpn_labels_ignore = splice(bg_labels, fg_labels, axis=0)\n        rpn_ce = cross_entropy_with_softmax(p_rpn_cls_score_rshp, rpn_labels_ignore, axis=0)\n        rpn_loss_cls = element_times(rpn_ce, keeps)\n        cls_num_terms = reduce_sum(keeps)\n        cls_normalization_factor = 1.0 / cls_num_terms\n        normalized_rpn_cls_loss = reduce_sum(rpn_loss_cls) * cls_normalization_factor\n        reduced_rpn_loss_cls = cntk.as_block(normalized_rpn_cls_loss, [(p_rpn_labels, rpn_labels), (p_rpn_cls_score_rshp, rpn_cls_score_rshp)], 'CE_with_ignore', 'norm_rpn_cls_loss')\n        p_rpn_bbox_pred = cntk.placeholder()\n        p_rpn_bbox_targets = cntk.placeholder()\n        p_rpn_bbox_inside_weights = cntk.placeholder()\n        rpn_loss_bbox = SmoothL1Loss(cfg.SIGMA_RPN_L1, p_rpn_bbox_pred, p_rpn_bbox_targets, p_rpn_bbox_inside_weights, 1.0)\n        bbox_normalization_factor = 1.0 / cfg['TRAIN'].RPN_BATCHSIZE\n        normalized_rpn_bbox_loss = reduce_sum(rpn_loss_bbox) * bbox_normalization_factor\n        reduced_rpn_loss_bbox = cntk.as_block(normalized_rpn_bbox_loss, [(p_rpn_bbox_pred, rpn_bbox_pred), (p_rpn_bbox_targets, rpn_bbox_targets), (p_rpn_bbox_inside_weights, rpn_bbox_inside_weights)], 'SmoothL1Loss', 'norm_rpn_bbox_loss')\n        rpn_losses = plus(reduced_rpn_loss_cls, reduced_rpn_loss_bbox, name='rpn_losses')\n    return (rpn_rois, rpn_losses)"
        ]
    },
    {
        "func_name": "create_proposal_layer",
        "original": "def create_proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg, use_native_proposal_layer=False):\n    layer_config = {}\n    layer_config['feat_stride'] = cfg['MODEL'].FEATURE_STRIDE\n    layer_config['scales'] = cfg['DATA'].PROPOSAL_LAYER_SCALES\n    layer_config['train_pre_nms_topN'] = cfg['TRAIN'].RPN_PRE_NMS_TOP_N\n    layer_config['train_post_nms_topN'] = cfg['TRAIN'].RPN_POST_NMS_TOP_N\n    layer_config['train_nms_thresh'] = float(cfg['TRAIN'].RPN_NMS_THRESH)\n    layer_config['train_min_size'] = float(cfg['TRAIN'].RPN_MIN_SIZE)\n    layer_config['test_pre_nms_topN'] = cfg['TEST'].RPN_PRE_NMS_TOP_N\n    layer_config['test_post_nms_topN'] = cfg['TEST'].RPN_POST_NMS_TOP_N\n    layer_config['test_nms_thresh'] = float(cfg['TEST'].RPN_NMS_THRESH)\n    layer_config['test_min_size'] = float(cfg['TEST'].RPN_MIN_SIZE)\n    if use_native_proposal_layer:\n        cntk.ops.register_native_user_function('ProposalLayerOp', 'Cntk.ProposalLayerLib-' + cntk.__version__.rstrip('+'), 'CreateProposalLayer')\n        rpn_rois_raw = ops.native_user_function('ProposalLayerOp', [rpn_cls_prob_reshape, rpn_bbox_pred, im_info], layer_config, 'native_proposal_layer')\n    else:\n        rpn_rois_raw = user_function(ProposalLayer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, layer_config))\n    return alias(rpn_rois_raw, name='rpn_rois')",
        "mutated": [
            "def create_proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg, use_native_proposal_layer=False):\n    if False:\n        i = 10\n    layer_config = {}\n    layer_config['feat_stride'] = cfg['MODEL'].FEATURE_STRIDE\n    layer_config['scales'] = cfg['DATA'].PROPOSAL_LAYER_SCALES\n    layer_config['train_pre_nms_topN'] = cfg['TRAIN'].RPN_PRE_NMS_TOP_N\n    layer_config['train_post_nms_topN'] = cfg['TRAIN'].RPN_POST_NMS_TOP_N\n    layer_config['train_nms_thresh'] = float(cfg['TRAIN'].RPN_NMS_THRESH)\n    layer_config['train_min_size'] = float(cfg['TRAIN'].RPN_MIN_SIZE)\n    layer_config['test_pre_nms_topN'] = cfg['TEST'].RPN_PRE_NMS_TOP_N\n    layer_config['test_post_nms_topN'] = cfg['TEST'].RPN_POST_NMS_TOP_N\n    layer_config['test_nms_thresh'] = float(cfg['TEST'].RPN_NMS_THRESH)\n    layer_config['test_min_size'] = float(cfg['TEST'].RPN_MIN_SIZE)\n    if use_native_proposal_layer:\n        cntk.ops.register_native_user_function('ProposalLayerOp', 'Cntk.ProposalLayerLib-' + cntk.__version__.rstrip('+'), 'CreateProposalLayer')\n        rpn_rois_raw = ops.native_user_function('ProposalLayerOp', [rpn_cls_prob_reshape, rpn_bbox_pred, im_info], layer_config, 'native_proposal_layer')\n    else:\n        rpn_rois_raw = user_function(ProposalLayer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, layer_config))\n    return alias(rpn_rois_raw, name='rpn_rois')",
            "def create_proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg, use_native_proposal_layer=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    layer_config = {}\n    layer_config['feat_stride'] = cfg['MODEL'].FEATURE_STRIDE\n    layer_config['scales'] = cfg['DATA'].PROPOSAL_LAYER_SCALES\n    layer_config['train_pre_nms_topN'] = cfg['TRAIN'].RPN_PRE_NMS_TOP_N\n    layer_config['train_post_nms_topN'] = cfg['TRAIN'].RPN_POST_NMS_TOP_N\n    layer_config['train_nms_thresh'] = float(cfg['TRAIN'].RPN_NMS_THRESH)\n    layer_config['train_min_size'] = float(cfg['TRAIN'].RPN_MIN_SIZE)\n    layer_config['test_pre_nms_topN'] = cfg['TEST'].RPN_PRE_NMS_TOP_N\n    layer_config['test_post_nms_topN'] = cfg['TEST'].RPN_POST_NMS_TOP_N\n    layer_config['test_nms_thresh'] = float(cfg['TEST'].RPN_NMS_THRESH)\n    layer_config['test_min_size'] = float(cfg['TEST'].RPN_MIN_SIZE)\n    if use_native_proposal_layer:\n        cntk.ops.register_native_user_function('ProposalLayerOp', 'Cntk.ProposalLayerLib-' + cntk.__version__.rstrip('+'), 'CreateProposalLayer')\n        rpn_rois_raw = ops.native_user_function('ProposalLayerOp', [rpn_cls_prob_reshape, rpn_bbox_pred, im_info], layer_config, 'native_proposal_layer')\n    else:\n        rpn_rois_raw = user_function(ProposalLayer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, layer_config))\n    return alias(rpn_rois_raw, name='rpn_rois')",
            "def create_proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg, use_native_proposal_layer=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    layer_config = {}\n    layer_config['feat_stride'] = cfg['MODEL'].FEATURE_STRIDE\n    layer_config['scales'] = cfg['DATA'].PROPOSAL_LAYER_SCALES\n    layer_config['train_pre_nms_topN'] = cfg['TRAIN'].RPN_PRE_NMS_TOP_N\n    layer_config['train_post_nms_topN'] = cfg['TRAIN'].RPN_POST_NMS_TOP_N\n    layer_config['train_nms_thresh'] = float(cfg['TRAIN'].RPN_NMS_THRESH)\n    layer_config['train_min_size'] = float(cfg['TRAIN'].RPN_MIN_SIZE)\n    layer_config['test_pre_nms_topN'] = cfg['TEST'].RPN_PRE_NMS_TOP_N\n    layer_config['test_post_nms_topN'] = cfg['TEST'].RPN_POST_NMS_TOP_N\n    layer_config['test_nms_thresh'] = float(cfg['TEST'].RPN_NMS_THRESH)\n    layer_config['test_min_size'] = float(cfg['TEST'].RPN_MIN_SIZE)\n    if use_native_proposal_layer:\n        cntk.ops.register_native_user_function('ProposalLayerOp', 'Cntk.ProposalLayerLib-' + cntk.__version__.rstrip('+'), 'CreateProposalLayer')\n        rpn_rois_raw = ops.native_user_function('ProposalLayerOp', [rpn_cls_prob_reshape, rpn_bbox_pred, im_info], layer_config, 'native_proposal_layer')\n    else:\n        rpn_rois_raw = user_function(ProposalLayer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, layer_config))\n    return alias(rpn_rois_raw, name='rpn_rois')",
            "def create_proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg, use_native_proposal_layer=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    layer_config = {}\n    layer_config['feat_stride'] = cfg['MODEL'].FEATURE_STRIDE\n    layer_config['scales'] = cfg['DATA'].PROPOSAL_LAYER_SCALES\n    layer_config['train_pre_nms_topN'] = cfg['TRAIN'].RPN_PRE_NMS_TOP_N\n    layer_config['train_post_nms_topN'] = cfg['TRAIN'].RPN_POST_NMS_TOP_N\n    layer_config['train_nms_thresh'] = float(cfg['TRAIN'].RPN_NMS_THRESH)\n    layer_config['train_min_size'] = float(cfg['TRAIN'].RPN_MIN_SIZE)\n    layer_config['test_pre_nms_topN'] = cfg['TEST'].RPN_PRE_NMS_TOP_N\n    layer_config['test_post_nms_topN'] = cfg['TEST'].RPN_POST_NMS_TOP_N\n    layer_config['test_nms_thresh'] = float(cfg['TEST'].RPN_NMS_THRESH)\n    layer_config['test_min_size'] = float(cfg['TEST'].RPN_MIN_SIZE)\n    if use_native_proposal_layer:\n        cntk.ops.register_native_user_function('ProposalLayerOp', 'Cntk.ProposalLayerLib-' + cntk.__version__.rstrip('+'), 'CreateProposalLayer')\n        rpn_rois_raw = ops.native_user_function('ProposalLayerOp', [rpn_cls_prob_reshape, rpn_bbox_pred, im_info], layer_config, 'native_proposal_layer')\n    else:\n        rpn_rois_raw = user_function(ProposalLayer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, layer_config))\n    return alias(rpn_rois_raw, name='rpn_rois')",
            "def create_proposal_layer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, cfg, use_native_proposal_layer=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    layer_config = {}\n    layer_config['feat_stride'] = cfg['MODEL'].FEATURE_STRIDE\n    layer_config['scales'] = cfg['DATA'].PROPOSAL_LAYER_SCALES\n    layer_config['train_pre_nms_topN'] = cfg['TRAIN'].RPN_PRE_NMS_TOP_N\n    layer_config['train_post_nms_topN'] = cfg['TRAIN'].RPN_POST_NMS_TOP_N\n    layer_config['train_nms_thresh'] = float(cfg['TRAIN'].RPN_NMS_THRESH)\n    layer_config['train_min_size'] = float(cfg['TRAIN'].RPN_MIN_SIZE)\n    layer_config['test_pre_nms_topN'] = cfg['TEST'].RPN_PRE_NMS_TOP_N\n    layer_config['test_post_nms_topN'] = cfg['TEST'].RPN_POST_NMS_TOP_N\n    layer_config['test_nms_thresh'] = float(cfg['TEST'].RPN_NMS_THRESH)\n    layer_config['test_min_size'] = float(cfg['TEST'].RPN_MIN_SIZE)\n    if use_native_proposal_layer:\n        cntk.ops.register_native_user_function('ProposalLayerOp', 'Cntk.ProposalLayerLib-' + cntk.__version__.rstrip('+'), 'CreateProposalLayer')\n        rpn_rois_raw = ops.native_user_function('ProposalLayerOp', [rpn_cls_prob_reshape, rpn_bbox_pred, im_info], layer_config, 'native_proposal_layer')\n    else:\n        rpn_rois_raw = user_function(ProposalLayer(rpn_cls_prob_reshape, rpn_bbox_pred, im_info, layer_config))\n    return alias(rpn_rois_raw, name='rpn_rois')"
        ]
    },
    {
        "func_name": "create_proposal_target_layer",
        "original": "def create_proposal_target_layer(rpn_rois, scaled_gt_boxes, cfg):\n    \"\"\"\n    Creates a proposal target layer that is used for training an object detection network as proposed in the \"Faster R-CNN\" paper:\n        Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun:\n        \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\"\n\n    Assigns object detection proposals to ground-truth targets.\n    Produces proposal classification labels and bounding-box regression targets.\n    It also adds gt_boxes to candidates and samples fg and bg rois for training.\n\n    Args:\n        rpn_rois:        The proposed ROIs, e.g. from a region proposal network\n        scaled_gt_boxes: The ground truth boxes as (x1, y1, x2, y2, label). Coordinates are absolute pixels wrt. the input image.\n        num_classes:     The number of classes in the data set\n\n    Returns:\n        rpn_target_rois - a set of rois containing the ground truth and a number of sampled fg and bg ROIs\n        label_targets - the target labels for the rois\n        bbox_targets - the regression coefficient targets for the rois\n        bbox_inside_weights - the weights for the regression loss\n    \"\"\"\n    ptl_param_string = \"'num_classes': {}\".format(cfg['DATA'].NUM_CLASSES)\n    ptl = user_function(ProposalTargetLayer(rpn_rois, scaled_gt_boxes, batch_size=cfg.NUM_ROI_PROPOSALS, fg_fraction=cfg['TRAIN'].FG_FRACTION, normalize_targets=cfg.BBOX_NORMALIZE_TARGETS, normalize_means=cfg.BBOX_NORMALIZE_MEANS, normalize_stds=cfg.BBOX_NORMALIZE_STDS, fg_thresh=cfg['TRAIN'].FG_THRESH, bg_thresh_hi=cfg['TRAIN'].BG_THRESH_HI, bg_thresh_lo=cfg['TRAIN'].BG_THRESH_LO, param_str=ptl_param_string))\n    rois = alias(ptl.outputs[0], name='rpn_target_rois')\n    label_targets = ptl.outputs[1]\n    bbox_targets = ptl.outputs[2]\n    bbox_inside_weights = ptl.outputs[3]\n    return (rois, label_targets, bbox_targets, bbox_inside_weights)",
        "mutated": [
            "def create_proposal_target_layer(rpn_rois, scaled_gt_boxes, cfg):\n    if False:\n        i = 10\n    '\\n    Creates a proposal target layer that is used for training an object detection network as proposed in the \"Faster R-CNN\" paper:\\n        Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun:\\n        \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\"\\n\\n    Assigns object detection proposals to ground-truth targets.\\n    Produces proposal classification labels and bounding-box regression targets.\\n    It also adds gt_boxes to candidates and samples fg and bg rois for training.\\n\\n    Args:\\n        rpn_rois:        The proposed ROIs, e.g. from a region proposal network\\n        scaled_gt_boxes: The ground truth boxes as (x1, y1, x2, y2, label). Coordinates are absolute pixels wrt. the input image.\\n        num_classes:     The number of classes in the data set\\n\\n    Returns:\\n        rpn_target_rois - a set of rois containing the ground truth and a number of sampled fg and bg ROIs\\n        label_targets - the target labels for the rois\\n        bbox_targets - the regression coefficient targets for the rois\\n        bbox_inside_weights - the weights for the regression loss\\n    '\n    ptl_param_string = \"'num_classes': {}\".format(cfg['DATA'].NUM_CLASSES)\n    ptl = user_function(ProposalTargetLayer(rpn_rois, scaled_gt_boxes, batch_size=cfg.NUM_ROI_PROPOSALS, fg_fraction=cfg['TRAIN'].FG_FRACTION, normalize_targets=cfg.BBOX_NORMALIZE_TARGETS, normalize_means=cfg.BBOX_NORMALIZE_MEANS, normalize_stds=cfg.BBOX_NORMALIZE_STDS, fg_thresh=cfg['TRAIN'].FG_THRESH, bg_thresh_hi=cfg['TRAIN'].BG_THRESH_HI, bg_thresh_lo=cfg['TRAIN'].BG_THRESH_LO, param_str=ptl_param_string))\n    rois = alias(ptl.outputs[0], name='rpn_target_rois')\n    label_targets = ptl.outputs[1]\n    bbox_targets = ptl.outputs[2]\n    bbox_inside_weights = ptl.outputs[3]\n    return (rois, label_targets, bbox_targets, bbox_inside_weights)",
            "def create_proposal_target_layer(rpn_rois, scaled_gt_boxes, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Creates a proposal target layer that is used for training an object detection network as proposed in the \"Faster R-CNN\" paper:\\n        Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun:\\n        \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\"\\n\\n    Assigns object detection proposals to ground-truth targets.\\n    Produces proposal classification labels and bounding-box regression targets.\\n    It also adds gt_boxes to candidates and samples fg and bg rois for training.\\n\\n    Args:\\n        rpn_rois:        The proposed ROIs, e.g. from a region proposal network\\n        scaled_gt_boxes: The ground truth boxes as (x1, y1, x2, y2, label). Coordinates are absolute pixels wrt. the input image.\\n        num_classes:     The number of classes in the data set\\n\\n    Returns:\\n        rpn_target_rois - a set of rois containing the ground truth and a number of sampled fg and bg ROIs\\n        label_targets - the target labels for the rois\\n        bbox_targets - the regression coefficient targets for the rois\\n        bbox_inside_weights - the weights for the regression loss\\n    '\n    ptl_param_string = \"'num_classes': {}\".format(cfg['DATA'].NUM_CLASSES)\n    ptl = user_function(ProposalTargetLayer(rpn_rois, scaled_gt_boxes, batch_size=cfg.NUM_ROI_PROPOSALS, fg_fraction=cfg['TRAIN'].FG_FRACTION, normalize_targets=cfg.BBOX_NORMALIZE_TARGETS, normalize_means=cfg.BBOX_NORMALIZE_MEANS, normalize_stds=cfg.BBOX_NORMALIZE_STDS, fg_thresh=cfg['TRAIN'].FG_THRESH, bg_thresh_hi=cfg['TRAIN'].BG_THRESH_HI, bg_thresh_lo=cfg['TRAIN'].BG_THRESH_LO, param_str=ptl_param_string))\n    rois = alias(ptl.outputs[0], name='rpn_target_rois')\n    label_targets = ptl.outputs[1]\n    bbox_targets = ptl.outputs[2]\n    bbox_inside_weights = ptl.outputs[3]\n    return (rois, label_targets, bbox_targets, bbox_inside_weights)",
            "def create_proposal_target_layer(rpn_rois, scaled_gt_boxes, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Creates a proposal target layer that is used for training an object detection network as proposed in the \"Faster R-CNN\" paper:\\n        Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun:\\n        \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\"\\n\\n    Assigns object detection proposals to ground-truth targets.\\n    Produces proposal classification labels and bounding-box regression targets.\\n    It also adds gt_boxes to candidates and samples fg and bg rois for training.\\n\\n    Args:\\n        rpn_rois:        The proposed ROIs, e.g. from a region proposal network\\n        scaled_gt_boxes: The ground truth boxes as (x1, y1, x2, y2, label). Coordinates are absolute pixels wrt. the input image.\\n        num_classes:     The number of classes in the data set\\n\\n    Returns:\\n        rpn_target_rois - a set of rois containing the ground truth and a number of sampled fg and bg ROIs\\n        label_targets - the target labels for the rois\\n        bbox_targets - the regression coefficient targets for the rois\\n        bbox_inside_weights - the weights for the regression loss\\n    '\n    ptl_param_string = \"'num_classes': {}\".format(cfg['DATA'].NUM_CLASSES)\n    ptl = user_function(ProposalTargetLayer(rpn_rois, scaled_gt_boxes, batch_size=cfg.NUM_ROI_PROPOSALS, fg_fraction=cfg['TRAIN'].FG_FRACTION, normalize_targets=cfg.BBOX_NORMALIZE_TARGETS, normalize_means=cfg.BBOX_NORMALIZE_MEANS, normalize_stds=cfg.BBOX_NORMALIZE_STDS, fg_thresh=cfg['TRAIN'].FG_THRESH, bg_thresh_hi=cfg['TRAIN'].BG_THRESH_HI, bg_thresh_lo=cfg['TRAIN'].BG_THRESH_LO, param_str=ptl_param_string))\n    rois = alias(ptl.outputs[0], name='rpn_target_rois')\n    label_targets = ptl.outputs[1]\n    bbox_targets = ptl.outputs[2]\n    bbox_inside_weights = ptl.outputs[3]\n    return (rois, label_targets, bbox_targets, bbox_inside_weights)",
            "def create_proposal_target_layer(rpn_rois, scaled_gt_boxes, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Creates a proposal target layer that is used for training an object detection network as proposed in the \"Faster R-CNN\" paper:\\n        Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun:\\n        \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\"\\n\\n    Assigns object detection proposals to ground-truth targets.\\n    Produces proposal classification labels and bounding-box regression targets.\\n    It also adds gt_boxes to candidates and samples fg and bg rois for training.\\n\\n    Args:\\n        rpn_rois:        The proposed ROIs, e.g. from a region proposal network\\n        scaled_gt_boxes: The ground truth boxes as (x1, y1, x2, y2, label). Coordinates are absolute pixels wrt. the input image.\\n        num_classes:     The number of classes in the data set\\n\\n    Returns:\\n        rpn_target_rois - a set of rois containing the ground truth and a number of sampled fg and bg ROIs\\n        label_targets - the target labels for the rois\\n        bbox_targets - the regression coefficient targets for the rois\\n        bbox_inside_weights - the weights for the regression loss\\n    '\n    ptl_param_string = \"'num_classes': {}\".format(cfg['DATA'].NUM_CLASSES)\n    ptl = user_function(ProposalTargetLayer(rpn_rois, scaled_gt_boxes, batch_size=cfg.NUM_ROI_PROPOSALS, fg_fraction=cfg['TRAIN'].FG_FRACTION, normalize_targets=cfg.BBOX_NORMALIZE_TARGETS, normalize_means=cfg.BBOX_NORMALIZE_MEANS, normalize_stds=cfg.BBOX_NORMALIZE_STDS, fg_thresh=cfg['TRAIN'].FG_THRESH, bg_thresh_hi=cfg['TRAIN'].BG_THRESH_HI, bg_thresh_lo=cfg['TRAIN'].BG_THRESH_LO, param_str=ptl_param_string))\n    rois = alias(ptl.outputs[0], name='rpn_target_rois')\n    label_targets = ptl.outputs[1]\n    bbox_targets = ptl.outputs[2]\n    bbox_inside_weights = ptl.outputs[3]\n    return (rois, label_targets, bbox_targets, bbox_inside_weights)",
            "def create_proposal_target_layer(rpn_rois, scaled_gt_boxes, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Creates a proposal target layer that is used for training an object detection network as proposed in the \"Faster R-CNN\" paper:\\n        Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun:\\n        \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\"\\n\\n    Assigns object detection proposals to ground-truth targets.\\n    Produces proposal classification labels and bounding-box regression targets.\\n    It also adds gt_boxes to candidates and samples fg and bg rois for training.\\n\\n    Args:\\n        rpn_rois:        The proposed ROIs, e.g. from a region proposal network\\n        scaled_gt_boxes: The ground truth boxes as (x1, y1, x2, y2, label). Coordinates are absolute pixels wrt. the input image.\\n        num_classes:     The number of classes in the data set\\n\\n    Returns:\\n        rpn_target_rois - a set of rois containing the ground truth and a number of sampled fg and bg ROIs\\n        label_targets - the target labels for the rois\\n        bbox_targets - the regression coefficient targets for the rois\\n        bbox_inside_weights - the weights for the regression loss\\n    '\n    ptl_param_string = \"'num_classes': {}\".format(cfg['DATA'].NUM_CLASSES)\n    ptl = user_function(ProposalTargetLayer(rpn_rois, scaled_gt_boxes, batch_size=cfg.NUM_ROI_PROPOSALS, fg_fraction=cfg['TRAIN'].FG_FRACTION, normalize_targets=cfg.BBOX_NORMALIZE_TARGETS, normalize_means=cfg.BBOX_NORMALIZE_MEANS, normalize_stds=cfg.BBOX_NORMALIZE_STDS, fg_thresh=cfg['TRAIN'].FG_THRESH, bg_thresh_hi=cfg['TRAIN'].BG_THRESH_HI, bg_thresh_lo=cfg['TRAIN'].BG_THRESH_LO, param_str=ptl_param_string))\n    rois = alias(ptl.outputs[0], name='rpn_target_rois')\n    label_targets = ptl.outputs[1]\n    bbox_targets = ptl.outputs[2]\n    bbox_inside_weights = ptl.outputs[3]\n    return (rois, label_targets, bbox_targets, bbox_inside_weights)"
        ]
    }
]