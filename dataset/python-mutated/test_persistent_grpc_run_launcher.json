[
    {
        "func_name": "test_run_always_finishes",
        "original": "def test_run_always_finishes():\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='nope', python_file=file_relative_path(__file__, 'test_default_run_launcher.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, wait_on_exit=False) as server_process:\n            with WorkspaceProcessContext(instance, GrpcServerTarget(host='localhost', socket=server_process.socket, port=server_process.port, location_name='test')) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('slow_job')\n                dagster_run = instance.create_run_for_job(job_def=slow_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n                run_id = dagster_run.run_id\n                assert instance.get_run_by_id(run_id).status == DagsterRunStatus.NOT_STARTED\n                instance.launch_run(run_id=run_id, workspace=workspace)\n        dagster_run = instance.get_run_by_id(run_id)\n        assert not dagster_run.is_finished\n        assert server_process.server_process.poll() is None\n        dagster_run = poll_for_finished_run(instance, run_id)\n        assert dagster_run.status == DagsterRunStatus.SUCCESS\n        start_time = time.time()\n        while server_process.server_process.poll() is None:\n            time.sleep(0.05)\n            assert time.time() - start_time < 5\n        server_process.wait()",
        "mutated": [
            "def test_run_always_finishes():\n    if False:\n        i = 10\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='nope', python_file=file_relative_path(__file__, 'test_default_run_launcher.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, wait_on_exit=False) as server_process:\n            with WorkspaceProcessContext(instance, GrpcServerTarget(host='localhost', socket=server_process.socket, port=server_process.port, location_name='test')) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('slow_job')\n                dagster_run = instance.create_run_for_job(job_def=slow_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n                run_id = dagster_run.run_id\n                assert instance.get_run_by_id(run_id).status == DagsterRunStatus.NOT_STARTED\n                instance.launch_run(run_id=run_id, workspace=workspace)\n        dagster_run = instance.get_run_by_id(run_id)\n        assert not dagster_run.is_finished\n        assert server_process.server_process.poll() is None\n        dagster_run = poll_for_finished_run(instance, run_id)\n        assert dagster_run.status == DagsterRunStatus.SUCCESS\n        start_time = time.time()\n        while server_process.server_process.poll() is None:\n            time.sleep(0.05)\n            assert time.time() - start_time < 5\n        server_process.wait()",
            "def test_run_always_finishes():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='nope', python_file=file_relative_path(__file__, 'test_default_run_launcher.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, wait_on_exit=False) as server_process:\n            with WorkspaceProcessContext(instance, GrpcServerTarget(host='localhost', socket=server_process.socket, port=server_process.port, location_name='test')) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('slow_job')\n                dagster_run = instance.create_run_for_job(job_def=slow_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n                run_id = dagster_run.run_id\n                assert instance.get_run_by_id(run_id).status == DagsterRunStatus.NOT_STARTED\n                instance.launch_run(run_id=run_id, workspace=workspace)\n        dagster_run = instance.get_run_by_id(run_id)\n        assert not dagster_run.is_finished\n        assert server_process.server_process.poll() is None\n        dagster_run = poll_for_finished_run(instance, run_id)\n        assert dagster_run.status == DagsterRunStatus.SUCCESS\n        start_time = time.time()\n        while server_process.server_process.poll() is None:\n            time.sleep(0.05)\n            assert time.time() - start_time < 5\n        server_process.wait()",
            "def test_run_always_finishes():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='nope', python_file=file_relative_path(__file__, 'test_default_run_launcher.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, wait_on_exit=False) as server_process:\n            with WorkspaceProcessContext(instance, GrpcServerTarget(host='localhost', socket=server_process.socket, port=server_process.port, location_name='test')) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('slow_job')\n                dagster_run = instance.create_run_for_job(job_def=slow_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n                run_id = dagster_run.run_id\n                assert instance.get_run_by_id(run_id).status == DagsterRunStatus.NOT_STARTED\n                instance.launch_run(run_id=run_id, workspace=workspace)\n        dagster_run = instance.get_run_by_id(run_id)\n        assert not dagster_run.is_finished\n        assert server_process.server_process.poll() is None\n        dagster_run = poll_for_finished_run(instance, run_id)\n        assert dagster_run.status == DagsterRunStatus.SUCCESS\n        start_time = time.time()\n        while server_process.server_process.poll() is None:\n            time.sleep(0.05)\n            assert time.time() - start_time < 5\n        server_process.wait()",
            "def test_run_always_finishes():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='nope', python_file=file_relative_path(__file__, 'test_default_run_launcher.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, wait_on_exit=False) as server_process:\n            with WorkspaceProcessContext(instance, GrpcServerTarget(host='localhost', socket=server_process.socket, port=server_process.port, location_name='test')) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('slow_job')\n                dagster_run = instance.create_run_for_job(job_def=slow_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n                run_id = dagster_run.run_id\n                assert instance.get_run_by_id(run_id).status == DagsterRunStatus.NOT_STARTED\n                instance.launch_run(run_id=run_id, workspace=workspace)\n        dagster_run = instance.get_run_by_id(run_id)\n        assert not dagster_run.is_finished\n        assert server_process.server_process.poll() is None\n        dagster_run = poll_for_finished_run(instance, run_id)\n        assert dagster_run.status == DagsterRunStatus.SUCCESS\n        start_time = time.time()\n        while server_process.server_process.poll() is None:\n            time.sleep(0.05)\n            assert time.time() - start_time < 5\n        server_process.wait()",
            "def test_run_always_finishes():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='nope', python_file=file_relative_path(__file__, 'test_default_run_launcher.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, wait_on_exit=False) as server_process:\n            with WorkspaceProcessContext(instance, GrpcServerTarget(host='localhost', socket=server_process.socket, port=server_process.port, location_name='test')) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('slow_job')\n                dagster_run = instance.create_run_for_job(job_def=slow_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n                run_id = dagster_run.run_id\n                assert instance.get_run_by_id(run_id).status == DagsterRunStatus.NOT_STARTED\n                instance.launch_run(run_id=run_id, workspace=workspace)\n        dagster_run = instance.get_run_by_id(run_id)\n        assert not dagster_run.is_finished\n        assert server_process.server_process.poll() is None\n        dagster_run = poll_for_finished_run(instance, run_id)\n        assert dagster_run.status == DagsterRunStatus.SUCCESS\n        start_time = time.time()\n        while server_process.server_process.poll() is None:\n            time.sleep(0.05)\n            assert time.time() - start_time < 5\n        server_process.wait()"
        ]
    },
    {
        "func_name": "test_run_from_pending_repository",
        "original": "def test_run_from_pending_repository():\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='pending', python_file=file_relative_path(__file__, 'pending_repository.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, wait_on_exit=False) as server_process:\n            with WorkspaceProcessContext(instance, GrpcServerTarget(host='localhost', socket=server_process.socket, port=server_process.port, location_name='test2')) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                code_location = workspace.get_code_location('test2')\n                external_job = code_location.get_repository('pending').get_full_external_job('my_cool_asset_job')\n                external_execution_plan = code_location.get_external_execution_plan(external_job=external_job, run_config={}, step_keys_to_execute=None, known_state=None)\n                call_counts = instance.run_storage.get_cursor_values({'compute_cacheable_data_called_a', 'compute_cacheable_data_called_b', 'get_definitions_called_a', 'get_definitions_called_b'})\n                assert call_counts.get('compute_cacheable_data_called_a') == '1'\n                assert call_counts.get('compute_cacheable_data_called_b') == '1'\n                assert call_counts.get('get_definitions_called_a') == '1'\n                assert call_counts.get('get_definitions_called_b') == '1'\n                dagster_run = instance.create_run(job_name='my_cool_asset_job', run_id='xyzabc', run_config=None, resolved_op_selection=None, step_keys_to_execute=None, status=None, tags=None, root_run_id=None, parent_run_id=None, job_snapshot=external_job.job_snapshot, execution_plan_snapshot=external_execution_plan.execution_plan_snapshot, parent_job_snapshot=external_job.parent_job_snapshot, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin(), asset_selection=None, op_selection=None, asset_check_selection=None)\n                run_id = dagster_run.run_id\n                assert instance.get_run_by_id(run_id).status == DagsterRunStatus.NOT_STARTED\n                instance.launch_run(run_id=run_id, workspace=workspace)\n        dagster_run = instance.get_run_by_id(run_id)\n        assert not dagster_run.is_finished\n        assert server_process.server_process.poll() is None\n        dagster_run = poll_for_finished_run(instance, run_id)\n        assert dagster_run.status == DagsterRunStatus.SUCCESS\n        start_time = time.time()\n        while server_process.server_process.poll() is None:\n            time.sleep(0.05)\n            assert time.time() - start_time < 5\n        server_process.wait()\n        call_counts = instance.run_storage.get_cursor_values({'compute_cacheable_data_called_a', 'compute_cacheable_data_called_b', 'get_definitions_called_a', 'get_definitions_called_b'})\n        assert call_counts.get('compute_cacheable_data_called_a') == '1'\n        assert call_counts.get('compute_cacheable_data_called_b') == '1'\n        assert int(call_counts.get('get_definitions_called_a')) < 6\n        assert int(call_counts.get('get_definitions_called_b')) < 6",
        "mutated": [
            "def test_run_from_pending_repository():\n    if False:\n        i = 10\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='pending', python_file=file_relative_path(__file__, 'pending_repository.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, wait_on_exit=False) as server_process:\n            with WorkspaceProcessContext(instance, GrpcServerTarget(host='localhost', socket=server_process.socket, port=server_process.port, location_name='test2')) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                code_location = workspace.get_code_location('test2')\n                external_job = code_location.get_repository('pending').get_full_external_job('my_cool_asset_job')\n                external_execution_plan = code_location.get_external_execution_plan(external_job=external_job, run_config={}, step_keys_to_execute=None, known_state=None)\n                call_counts = instance.run_storage.get_cursor_values({'compute_cacheable_data_called_a', 'compute_cacheable_data_called_b', 'get_definitions_called_a', 'get_definitions_called_b'})\n                assert call_counts.get('compute_cacheable_data_called_a') == '1'\n                assert call_counts.get('compute_cacheable_data_called_b') == '1'\n                assert call_counts.get('get_definitions_called_a') == '1'\n                assert call_counts.get('get_definitions_called_b') == '1'\n                dagster_run = instance.create_run(job_name='my_cool_asset_job', run_id='xyzabc', run_config=None, resolved_op_selection=None, step_keys_to_execute=None, status=None, tags=None, root_run_id=None, parent_run_id=None, job_snapshot=external_job.job_snapshot, execution_plan_snapshot=external_execution_plan.execution_plan_snapshot, parent_job_snapshot=external_job.parent_job_snapshot, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin(), asset_selection=None, op_selection=None, asset_check_selection=None)\n                run_id = dagster_run.run_id\n                assert instance.get_run_by_id(run_id).status == DagsterRunStatus.NOT_STARTED\n                instance.launch_run(run_id=run_id, workspace=workspace)\n        dagster_run = instance.get_run_by_id(run_id)\n        assert not dagster_run.is_finished\n        assert server_process.server_process.poll() is None\n        dagster_run = poll_for_finished_run(instance, run_id)\n        assert dagster_run.status == DagsterRunStatus.SUCCESS\n        start_time = time.time()\n        while server_process.server_process.poll() is None:\n            time.sleep(0.05)\n            assert time.time() - start_time < 5\n        server_process.wait()\n        call_counts = instance.run_storage.get_cursor_values({'compute_cacheable_data_called_a', 'compute_cacheable_data_called_b', 'get_definitions_called_a', 'get_definitions_called_b'})\n        assert call_counts.get('compute_cacheable_data_called_a') == '1'\n        assert call_counts.get('compute_cacheable_data_called_b') == '1'\n        assert int(call_counts.get('get_definitions_called_a')) < 6\n        assert int(call_counts.get('get_definitions_called_b')) < 6",
            "def test_run_from_pending_repository():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='pending', python_file=file_relative_path(__file__, 'pending_repository.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, wait_on_exit=False) as server_process:\n            with WorkspaceProcessContext(instance, GrpcServerTarget(host='localhost', socket=server_process.socket, port=server_process.port, location_name='test2')) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                code_location = workspace.get_code_location('test2')\n                external_job = code_location.get_repository('pending').get_full_external_job('my_cool_asset_job')\n                external_execution_plan = code_location.get_external_execution_plan(external_job=external_job, run_config={}, step_keys_to_execute=None, known_state=None)\n                call_counts = instance.run_storage.get_cursor_values({'compute_cacheable_data_called_a', 'compute_cacheable_data_called_b', 'get_definitions_called_a', 'get_definitions_called_b'})\n                assert call_counts.get('compute_cacheable_data_called_a') == '1'\n                assert call_counts.get('compute_cacheable_data_called_b') == '1'\n                assert call_counts.get('get_definitions_called_a') == '1'\n                assert call_counts.get('get_definitions_called_b') == '1'\n                dagster_run = instance.create_run(job_name='my_cool_asset_job', run_id='xyzabc', run_config=None, resolved_op_selection=None, step_keys_to_execute=None, status=None, tags=None, root_run_id=None, parent_run_id=None, job_snapshot=external_job.job_snapshot, execution_plan_snapshot=external_execution_plan.execution_plan_snapshot, parent_job_snapshot=external_job.parent_job_snapshot, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin(), asset_selection=None, op_selection=None, asset_check_selection=None)\n                run_id = dagster_run.run_id\n                assert instance.get_run_by_id(run_id).status == DagsterRunStatus.NOT_STARTED\n                instance.launch_run(run_id=run_id, workspace=workspace)\n        dagster_run = instance.get_run_by_id(run_id)\n        assert not dagster_run.is_finished\n        assert server_process.server_process.poll() is None\n        dagster_run = poll_for_finished_run(instance, run_id)\n        assert dagster_run.status == DagsterRunStatus.SUCCESS\n        start_time = time.time()\n        while server_process.server_process.poll() is None:\n            time.sleep(0.05)\n            assert time.time() - start_time < 5\n        server_process.wait()\n        call_counts = instance.run_storage.get_cursor_values({'compute_cacheable_data_called_a', 'compute_cacheable_data_called_b', 'get_definitions_called_a', 'get_definitions_called_b'})\n        assert call_counts.get('compute_cacheable_data_called_a') == '1'\n        assert call_counts.get('compute_cacheable_data_called_b') == '1'\n        assert int(call_counts.get('get_definitions_called_a')) < 6\n        assert int(call_counts.get('get_definitions_called_b')) < 6",
            "def test_run_from_pending_repository():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='pending', python_file=file_relative_path(__file__, 'pending_repository.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, wait_on_exit=False) as server_process:\n            with WorkspaceProcessContext(instance, GrpcServerTarget(host='localhost', socket=server_process.socket, port=server_process.port, location_name='test2')) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                code_location = workspace.get_code_location('test2')\n                external_job = code_location.get_repository('pending').get_full_external_job('my_cool_asset_job')\n                external_execution_plan = code_location.get_external_execution_plan(external_job=external_job, run_config={}, step_keys_to_execute=None, known_state=None)\n                call_counts = instance.run_storage.get_cursor_values({'compute_cacheable_data_called_a', 'compute_cacheable_data_called_b', 'get_definitions_called_a', 'get_definitions_called_b'})\n                assert call_counts.get('compute_cacheable_data_called_a') == '1'\n                assert call_counts.get('compute_cacheable_data_called_b') == '1'\n                assert call_counts.get('get_definitions_called_a') == '1'\n                assert call_counts.get('get_definitions_called_b') == '1'\n                dagster_run = instance.create_run(job_name='my_cool_asset_job', run_id='xyzabc', run_config=None, resolved_op_selection=None, step_keys_to_execute=None, status=None, tags=None, root_run_id=None, parent_run_id=None, job_snapshot=external_job.job_snapshot, execution_plan_snapshot=external_execution_plan.execution_plan_snapshot, parent_job_snapshot=external_job.parent_job_snapshot, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin(), asset_selection=None, op_selection=None, asset_check_selection=None)\n                run_id = dagster_run.run_id\n                assert instance.get_run_by_id(run_id).status == DagsterRunStatus.NOT_STARTED\n                instance.launch_run(run_id=run_id, workspace=workspace)\n        dagster_run = instance.get_run_by_id(run_id)\n        assert not dagster_run.is_finished\n        assert server_process.server_process.poll() is None\n        dagster_run = poll_for_finished_run(instance, run_id)\n        assert dagster_run.status == DagsterRunStatus.SUCCESS\n        start_time = time.time()\n        while server_process.server_process.poll() is None:\n            time.sleep(0.05)\n            assert time.time() - start_time < 5\n        server_process.wait()\n        call_counts = instance.run_storage.get_cursor_values({'compute_cacheable_data_called_a', 'compute_cacheable_data_called_b', 'get_definitions_called_a', 'get_definitions_called_b'})\n        assert call_counts.get('compute_cacheable_data_called_a') == '1'\n        assert call_counts.get('compute_cacheable_data_called_b') == '1'\n        assert int(call_counts.get('get_definitions_called_a')) < 6\n        assert int(call_counts.get('get_definitions_called_b')) < 6",
            "def test_run_from_pending_repository():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='pending', python_file=file_relative_path(__file__, 'pending_repository.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, wait_on_exit=False) as server_process:\n            with WorkspaceProcessContext(instance, GrpcServerTarget(host='localhost', socket=server_process.socket, port=server_process.port, location_name='test2')) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                code_location = workspace.get_code_location('test2')\n                external_job = code_location.get_repository('pending').get_full_external_job('my_cool_asset_job')\n                external_execution_plan = code_location.get_external_execution_plan(external_job=external_job, run_config={}, step_keys_to_execute=None, known_state=None)\n                call_counts = instance.run_storage.get_cursor_values({'compute_cacheable_data_called_a', 'compute_cacheable_data_called_b', 'get_definitions_called_a', 'get_definitions_called_b'})\n                assert call_counts.get('compute_cacheable_data_called_a') == '1'\n                assert call_counts.get('compute_cacheable_data_called_b') == '1'\n                assert call_counts.get('get_definitions_called_a') == '1'\n                assert call_counts.get('get_definitions_called_b') == '1'\n                dagster_run = instance.create_run(job_name='my_cool_asset_job', run_id='xyzabc', run_config=None, resolved_op_selection=None, step_keys_to_execute=None, status=None, tags=None, root_run_id=None, parent_run_id=None, job_snapshot=external_job.job_snapshot, execution_plan_snapshot=external_execution_plan.execution_plan_snapshot, parent_job_snapshot=external_job.parent_job_snapshot, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin(), asset_selection=None, op_selection=None, asset_check_selection=None)\n                run_id = dagster_run.run_id\n                assert instance.get_run_by_id(run_id).status == DagsterRunStatus.NOT_STARTED\n                instance.launch_run(run_id=run_id, workspace=workspace)\n        dagster_run = instance.get_run_by_id(run_id)\n        assert not dagster_run.is_finished\n        assert server_process.server_process.poll() is None\n        dagster_run = poll_for_finished_run(instance, run_id)\n        assert dagster_run.status == DagsterRunStatus.SUCCESS\n        start_time = time.time()\n        while server_process.server_process.poll() is None:\n            time.sleep(0.05)\n            assert time.time() - start_time < 5\n        server_process.wait()\n        call_counts = instance.run_storage.get_cursor_values({'compute_cacheable_data_called_a', 'compute_cacheable_data_called_b', 'get_definitions_called_a', 'get_definitions_called_b'})\n        assert call_counts.get('compute_cacheable_data_called_a') == '1'\n        assert call_counts.get('compute_cacheable_data_called_b') == '1'\n        assert int(call_counts.get('get_definitions_called_a')) < 6\n        assert int(call_counts.get('get_definitions_called_b')) < 6",
            "def test_run_from_pending_repository():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='pending', python_file=file_relative_path(__file__, 'pending_repository.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, wait_on_exit=False) as server_process:\n            with WorkspaceProcessContext(instance, GrpcServerTarget(host='localhost', socket=server_process.socket, port=server_process.port, location_name='test2')) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                code_location = workspace.get_code_location('test2')\n                external_job = code_location.get_repository('pending').get_full_external_job('my_cool_asset_job')\n                external_execution_plan = code_location.get_external_execution_plan(external_job=external_job, run_config={}, step_keys_to_execute=None, known_state=None)\n                call_counts = instance.run_storage.get_cursor_values({'compute_cacheable_data_called_a', 'compute_cacheable_data_called_b', 'get_definitions_called_a', 'get_definitions_called_b'})\n                assert call_counts.get('compute_cacheable_data_called_a') == '1'\n                assert call_counts.get('compute_cacheable_data_called_b') == '1'\n                assert call_counts.get('get_definitions_called_a') == '1'\n                assert call_counts.get('get_definitions_called_b') == '1'\n                dagster_run = instance.create_run(job_name='my_cool_asset_job', run_id='xyzabc', run_config=None, resolved_op_selection=None, step_keys_to_execute=None, status=None, tags=None, root_run_id=None, parent_run_id=None, job_snapshot=external_job.job_snapshot, execution_plan_snapshot=external_execution_plan.execution_plan_snapshot, parent_job_snapshot=external_job.parent_job_snapshot, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin(), asset_selection=None, op_selection=None, asset_check_selection=None)\n                run_id = dagster_run.run_id\n                assert instance.get_run_by_id(run_id).status == DagsterRunStatus.NOT_STARTED\n                instance.launch_run(run_id=run_id, workspace=workspace)\n        dagster_run = instance.get_run_by_id(run_id)\n        assert not dagster_run.is_finished\n        assert server_process.server_process.poll() is None\n        dagster_run = poll_for_finished_run(instance, run_id)\n        assert dagster_run.status == DagsterRunStatus.SUCCESS\n        start_time = time.time()\n        while server_process.server_process.poll() is None:\n            time.sleep(0.05)\n            assert time.time() - start_time < 5\n        server_process.wait()\n        call_counts = instance.run_storage.get_cursor_values({'compute_cacheable_data_called_a', 'compute_cacheable_data_called_b', 'get_definitions_called_a', 'get_definitions_called_b'})\n        assert call_counts.get('compute_cacheable_data_called_a') == '1'\n        assert call_counts.get('compute_cacheable_data_called_b') == '1'\n        assert int(call_counts.get('get_definitions_called_a')) < 6\n        assert int(call_counts.get('get_definitions_called_b')) < 6"
        ]
    },
    {
        "func_name": "test_terminate_after_shutdown",
        "original": "def test_terminate_after_shutdown():\n    with instance_for_test() as instance:\n        with WorkspaceProcessContext(instance, PythonFileTarget(python_file=file_relative_path(__file__, 'test_default_run_launcher.py'), attribute='nope', working_directory=None, location_name='test')) as workspace_process_context:\n            workspace = workspace_process_context.create_request_context()\n            external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('sleepy_job')\n            dagster_run = instance.create_run_for_job(job_def=sleepy_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n            instance.launch_run(dagster_run.run_id, workspace)\n            poll_for_step_start(instance, dagster_run.run_id)\n            code_location = workspace.get_code_location('test')\n            code_location.grpc_server_registry.get_grpc_endpoint(code_location.origin).create_client().shutdown_server()\n            external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('math_diamond')\n            doomed_to_fail_dagster_run = instance.create_run_for_job(job_def=math_diamond, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n            with pytest.raises(DagsterLaunchFailedError):\n                instance.launch_run(doomed_to_fail_dagster_run.run_id, workspace)\n            launcher = instance.run_launcher\n            assert launcher.terminate(dagster_run.run_id)",
        "mutated": [
            "def test_terminate_after_shutdown():\n    if False:\n        i = 10\n    with instance_for_test() as instance:\n        with WorkspaceProcessContext(instance, PythonFileTarget(python_file=file_relative_path(__file__, 'test_default_run_launcher.py'), attribute='nope', working_directory=None, location_name='test')) as workspace_process_context:\n            workspace = workspace_process_context.create_request_context()\n            external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('sleepy_job')\n            dagster_run = instance.create_run_for_job(job_def=sleepy_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n            instance.launch_run(dagster_run.run_id, workspace)\n            poll_for_step_start(instance, dagster_run.run_id)\n            code_location = workspace.get_code_location('test')\n            code_location.grpc_server_registry.get_grpc_endpoint(code_location.origin).create_client().shutdown_server()\n            external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('math_diamond')\n            doomed_to_fail_dagster_run = instance.create_run_for_job(job_def=math_diamond, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n            with pytest.raises(DagsterLaunchFailedError):\n                instance.launch_run(doomed_to_fail_dagster_run.run_id, workspace)\n            launcher = instance.run_launcher\n            assert launcher.terminate(dagster_run.run_id)",
            "def test_terminate_after_shutdown():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with instance_for_test() as instance:\n        with WorkspaceProcessContext(instance, PythonFileTarget(python_file=file_relative_path(__file__, 'test_default_run_launcher.py'), attribute='nope', working_directory=None, location_name='test')) as workspace_process_context:\n            workspace = workspace_process_context.create_request_context()\n            external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('sleepy_job')\n            dagster_run = instance.create_run_for_job(job_def=sleepy_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n            instance.launch_run(dagster_run.run_id, workspace)\n            poll_for_step_start(instance, dagster_run.run_id)\n            code_location = workspace.get_code_location('test')\n            code_location.grpc_server_registry.get_grpc_endpoint(code_location.origin).create_client().shutdown_server()\n            external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('math_diamond')\n            doomed_to_fail_dagster_run = instance.create_run_for_job(job_def=math_diamond, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n            with pytest.raises(DagsterLaunchFailedError):\n                instance.launch_run(doomed_to_fail_dagster_run.run_id, workspace)\n            launcher = instance.run_launcher\n            assert launcher.terminate(dagster_run.run_id)",
            "def test_terminate_after_shutdown():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with instance_for_test() as instance:\n        with WorkspaceProcessContext(instance, PythonFileTarget(python_file=file_relative_path(__file__, 'test_default_run_launcher.py'), attribute='nope', working_directory=None, location_name='test')) as workspace_process_context:\n            workspace = workspace_process_context.create_request_context()\n            external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('sleepy_job')\n            dagster_run = instance.create_run_for_job(job_def=sleepy_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n            instance.launch_run(dagster_run.run_id, workspace)\n            poll_for_step_start(instance, dagster_run.run_id)\n            code_location = workspace.get_code_location('test')\n            code_location.grpc_server_registry.get_grpc_endpoint(code_location.origin).create_client().shutdown_server()\n            external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('math_diamond')\n            doomed_to_fail_dagster_run = instance.create_run_for_job(job_def=math_diamond, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n            with pytest.raises(DagsterLaunchFailedError):\n                instance.launch_run(doomed_to_fail_dagster_run.run_id, workspace)\n            launcher = instance.run_launcher\n            assert launcher.terminate(dagster_run.run_id)",
            "def test_terminate_after_shutdown():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with instance_for_test() as instance:\n        with WorkspaceProcessContext(instance, PythonFileTarget(python_file=file_relative_path(__file__, 'test_default_run_launcher.py'), attribute='nope', working_directory=None, location_name='test')) as workspace_process_context:\n            workspace = workspace_process_context.create_request_context()\n            external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('sleepy_job')\n            dagster_run = instance.create_run_for_job(job_def=sleepy_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n            instance.launch_run(dagster_run.run_id, workspace)\n            poll_for_step_start(instance, dagster_run.run_id)\n            code_location = workspace.get_code_location('test')\n            code_location.grpc_server_registry.get_grpc_endpoint(code_location.origin).create_client().shutdown_server()\n            external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('math_diamond')\n            doomed_to_fail_dagster_run = instance.create_run_for_job(job_def=math_diamond, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n            with pytest.raises(DagsterLaunchFailedError):\n                instance.launch_run(doomed_to_fail_dagster_run.run_id, workspace)\n            launcher = instance.run_launcher\n            assert launcher.terminate(dagster_run.run_id)",
            "def test_terminate_after_shutdown():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with instance_for_test() as instance:\n        with WorkspaceProcessContext(instance, PythonFileTarget(python_file=file_relative_path(__file__, 'test_default_run_launcher.py'), attribute='nope', working_directory=None, location_name='test')) as workspace_process_context:\n            workspace = workspace_process_context.create_request_context()\n            external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('sleepy_job')\n            dagster_run = instance.create_run_for_job(job_def=sleepy_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n            instance.launch_run(dagster_run.run_id, workspace)\n            poll_for_step_start(instance, dagster_run.run_id)\n            code_location = workspace.get_code_location('test')\n            code_location.grpc_server_registry.get_grpc_endpoint(code_location.origin).create_client().shutdown_server()\n            external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('math_diamond')\n            doomed_to_fail_dagster_run = instance.create_run_for_job(job_def=math_diamond, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n            with pytest.raises(DagsterLaunchFailedError):\n                instance.launch_run(doomed_to_fail_dagster_run.run_id, workspace)\n            launcher = instance.run_launcher\n            assert launcher.terminate(dagster_run.run_id)"
        ]
    },
    {
        "func_name": "test_server_down",
        "original": "def test_server_down():\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='nope', python_file=file_relative_path(__file__, 'test_default_run_launcher.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, force_port=True, wait_on_exit=True) as server_process:\n            api_client = server_process.create_client()\n            with WorkspaceProcessContext(instance, GrpcServerTarget(location_name='test', port=api_client.port, socket=api_client.socket, host=api_client.host)) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('sleepy_job')\n                dagster_run = instance.create_run_for_job(job_def=sleepy_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n                instance.launch_run(dagster_run.run_id, workspace)\n                poll_for_step_start(instance, dagster_run.run_id)\n                launcher = instance.run_launcher\n                original_run_tags = instance.get_run_by_id(dagster_run.run_id).tags[GRPC_INFO_TAG]\n                instance.add_run_tags(dagster_run.run_id, {GRPC_INFO_TAG: _seven.json.dumps(merge_dicts({'host': 'localhost'}, {'port': find_free_port()}))})\n                instance.add_run_tags(dagster_run.run_id, {GRPC_INFO_TAG: original_run_tags})\n                assert launcher.terminate(dagster_run.run_id)",
        "mutated": [
            "def test_server_down():\n    if False:\n        i = 10\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='nope', python_file=file_relative_path(__file__, 'test_default_run_launcher.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, force_port=True, wait_on_exit=True) as server_process:\n            api_client = server_process.create_client()\n            with WorkspaceProcessContext(instance, GrpcServerTarget(location_name='test', port=api_client.port, socket=api_client.socket, host=api_client.host)) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('sleepy_job')\n                dagster_run = instance.create_run_for_job(job_def=sleepy_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n                instance.launch_run(dagster_run.run_id, workspace)\n                poll_for_step_start(instance, dagster_run.run_id)\n                launcher = instance.run_launcher\n                original_run_tags = instance.get_run_by_id(dagster_run.run_id).tags[GRPC_INFO_TAG]\n                instance.add_run_tags(dagster_run.run_id, {GRPC_INFO_TAG: _seven.json.dumps(merge_dicts({'host': 'localhost'}, {'port': find_free_port()}))})\n                instance.add_run_tags(dagster_run.run_id, {GRPC_INFO_TAG: original_run_tags})\n                assert launcher.terminate(dagster_run.run_id)",
            "def test_server_down():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='nope', python_file=file_relative_path(__file__, 'test_default_run_launcher.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, force_port=True, wait_on_exit=True) as server_process:\n            api_client = server_process.create_client()\n            with WorkspaceProcessContext(instance, GrpcServerTarget(location_name='test', port=api_client.port, socket=api_client.socket, host=api_client.host)) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('sleepy_job')\n                dagster_run = instance.create_run_for_job(job_def=sleepy_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n                instance.launch_run(dagster_run.run_id, workspace)\n                poll_for_step_start(instance, dagster_run.run_id)\n                launcher = instance.run_launcher\n                original_run_tags = instance.get_run_by_id(dagster_run.run_id).tags[GRPC_INFO_TAG]\n                instance.add_run_tags(dagster_run.run_id, {GRPC_INFO_TAG: _seven.json.dumps(merge_dicts({'host': 'localhost'}, {'port': find_free_port()}))})\n                instance.add_run_tags(dagster_run.run_id, {GRPC_INFO_TAG: original_run_tags})\n                assert launcher.terminate(dagster_run.run_id)",
            "def test_server_down():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='nope', python_file=file_relative_path(__file__, 'test_default_run_launcher.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, force_port=True, wait_on_exit=True) as server_process:\n            api_client = server_process.create_client()\n            with WorkspaceProcessContext(instance, GrpcServerTarget(location_name='test', port=api_client.port, socket=api_client.socket, host=api_client.host)) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('sleepy_job')\n                dagster_run = instance.create_run_for_job(job_def=sleepy_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n                instance.launch_run(dagster_run.run_id, workspace)\n                poll_for_step_start(instance, dagster_run.run_id)\n                launcher = instance.run_launcher\n                original_run_tags = instance.get_run_by_id(dagster_run.run_id).tags[GRPC_INFO_TAG]\n                instance.add_run_tags(dagster_run.run_id, {GRPC_INFO_TAG: _seven.json.dumps(merge_dicts({'host': 'localhost'}, {'port': find_free_port()}))})\n                instance.add_run_tags(dagster_run.run_id, {GRPC_INFO_TAG: original_run_tags})\n                assert launcher.terminate(dagster_run.run_id)",
            "def test_server_down():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='nope', python_file=file_relative_path(__file__, 'test_default_run_launcher.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, force_port=True, wait_on_exit=True) as server_process:\n            api_client = server_process.create_client()\n            with WorkspaceProcessContext(instance, GrpcServerTarget(location_name='test', port=api_client.port, socket=api_client.socket, host=api_client.host)) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('sleepy_job')\n                dagster_run = instance.create_run_for_job(job_def=sleepy_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n                instance.launch_run(dagster_run.run_id, workspace)\n                poll_for_step_start(instance, dagster_run.run_id)\n                launcher = instance.run_launcher\n                original_run_tags = instance.get_run_by_id(dagster_run.run_id).tags[GRPC_INFO_TAG]\n                instance.add_run_tags(dagster_run.run_id, {GRPC_INFO_TAG: _seven.json.dumps(merge_dicts({'host': 'localhost'}, {'port': find_free_port()}))})\n                instance.add_run_tags(dagster_run.run_id, {GRPC_INFO_TAG: original_run_tags})\n                assert launcher.terminate(dagster_run.run_id)",
            "def test_server_down():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with instance_for_test() as instance:\n        loadable_target_origin = LoadableTargetOrigin(executable_path=sys.executable, attribute='nope', python_file=file_relative_path(__file__, 'test_default_run_launcher.py'))\n        with GrpcServerProcess(instance_ref=instance.get_ref(), loadable_target_origin=loadable_target_origin, max_workers=4, force_port=True, wait_on_exit=True) as server_process:\n            api_client = server_process.create_client()\n            with WorkspaceProcessContext(instance, GrpcServerTarget(location_name='test', port=api_client.port, socket=api_client.socket, host=api_client.host)) as workspace_process_context:\n                workspace = workspace_process_context.create_request_context()\n                external_job = workspace.get_code_location('test').get_repository('nope').get_full_external_job('sleepy_job')\n                dagster_run = instance.create_run_for_job(job_def=sleepy_job, run_config=None, external_job_origin=external_job.get_external_origin(), job_code_origin=external_job.get_python_origin())\n                instance.launch_run(dagster_run.run_id, workspace)\n                poll_for_step_start(instance, dagster_run.run_id)\n                launcher = instance.run_launcher\n                original_run_tags = instance.get_run_by_id(dagster_run.run_id).tags[GRPC_INFO_TAG]\n                instance.add_run_tags(dagster_run.run_id, {GRPC_INFO_TAG: _seven.json.dumps(merge_dicts({'host': 'localhost'}, {'port': find_free_port()}))})\n                instance.add_run_tags(dagster_run.run_id, {GRPC_INFO_TAG: original_run_tags})\n                assert launcher.terminate(dagster_run.run_id)"
        ]
    }
]