[
    {
        "func_name": "__init__",
        "original": "def __init__(self, step_handler: StepHandler, retries: RetryMode, sleep_seconds: Optional[float]=None, check_step_health_interval_seconds: Optional[int]=None, max_concurrent: Optional[int]=None, tag_concurrency_limits: Optional[List[Dict[str, Any]]]=None, should_verify_step: bool=False):\n    self._step_handler = step_handler\n    self._retries = retries\n    self._max_concurrent = check.opt_int_param(max_concurrent, 'max_concurrent')\n    self._tag_concurrency_limits = check.opt_list_param(tag_concurrency_limits, 'tag_concurrency_limits')\n    if self._max_concurrent is not None:\n        check.invariant(self._max_concurrent > 0, 'max_concurrent must be > 0')\n    self._sleep_seconds = cast(float, check.opt_float_param(sleep_seconds, 'sleep_seconds', default=DEFAULT_SLEEP_SECONDS))\n    self._check_step_health_interval_seconds = cast(int, check.opt_int_param(check_step_health_interval_seconds, 'check_step_health_interval_seconds', default=20))\n    self._should_verify_step = should_verify_step\n    self._event_cursor: Optional[str] = None",
        "mutated": [
            "def __init__(self, step_handler: StepHandler, retries: RetryMode, sleep_seconds: Optional[float]=None, check_step_health_interval_seconds: Optional[int]=None, max_concurrent: Optional[int]=None, tag_concurrency_limits: Optional[List[Dict[str, Any]]]=None, should_verify_step: bool=False):\n    if False:\n        i = 10\n    self._step_handler = step_handler\n    self._retries = retries\n    self._max_concurrent = check.opt_int_param(max_concurrent, 'max_concurrent')\n    self._tag_concurrency_limits = check.opt_list_param(tag_concurrency_limits, 'tag_concurrency_limits')\n    if self._max_concurrent is not None:\n        check.invariant(self._max_concurrent > 0, 'max_concurrent must be > 0')\n    self._sleep_seconds = cast(float, check.opt_float_param(sleep_seconds, 'sleep_seconds', default=DEFAULT_SLEEP_SECONDS))\n    self._check_step_health_interval_seconds = cast(int, check.opt_int_param(check_step_health_interval_seconds, 'check_step_health_interval_seconds', default=20))\n    self._should_verify_step = should_verify_step\n    self._event_cursor: Optional[str] = None",
            "def __init__(self, step_handler: StepHandler, retries: RetryMode, sleep_seconds: Optional[float]=None, check_step_health_interval_seconds: Optional[int]=None, max_concurrent: Optional[int]=None, tag_concurrency_limits: Optional[List[Dict[str, Any]]]=None, should_verify_step: bool=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self._step_handler = step_handler\n    self._retries = retries\n    self._max_concurrent = check.opt_int_param(max_concurrent, 'max_concurrent')\n    self._tag_concurrency_limits = check.opt_list_param(tag_concurrency_limits, 'tag_concurrency_limits')\n    if self._max_concurrent is not None:\n        check.invariant(self._max_concurrent > 0, 'max_concurrent must be > 0')\n    self._sleep_seconds = cast(float, check.opt_float_param(sleep_seconds, 'sleep_seconds', default=DEFAULT_SLEEP_SECONDS))\n    self._check_step_health_interval_seconds = cast(int, check.opt_int_param(check_step_health_interval_seconds, 'check_step_health_interval_seconds', default=20))\n    self._should_verify_step = should_verify_step\n    self._event_cursor: Optional[str] = None",
            "def __init__(self, step_handler: StepHandler, retries: RetryMode, sleep_seconds: Optional[float]=None, check_step_health_interval_seconds: Optional[int]=None, max_concurrent: Optional[int]=None, tag_concurrency_limits: Optional[List[Dict[str, Any]]]=None, should_verify_step: bool=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self._step_handler = step_handler\n    self._retries = retries\n    self._max_concurrent = check.opt_int_param(max_concurrent, 'max_concurrent')\n    self._tag_concurrency_limits = check.opt_list_param(tag_concurrency_limits, 'tag_concurrency_limits')\n    if self._max_concurrent is not None:\n        check.invariant(self._max_concurrent > 0, 'max_concurrent must be > 0')\n    self._sleep_seconds = cast(float, check.opt_float_param(sleep_seconds, 'sleep_seconds', default=DEFAULT_SLEEP_SECONDS))\n    self._check_step_health_interval_seconds = cast(int, check.opt_int_param(check_step_health_interval_seconds, 'check_step_health_interval_seconds', default=20))\n    self._should_verify_step = should_verify_step\n    self._event_cursor: Optional[str] = None",
            "def __init__(self, step_handler: StepHandler, retries: RetryMode, sleep_seconds: Optional[float]=None, check_step_health_interval_seconds: Optional[int]=None, max_concurrent: Optional[int]=None, tag_concurrency_limits: Optional[List[Dict[str, Any]]]=None, should_verify_step: bool=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self._step_handler = step_handler\n    self._retries = retries\n    self._max_concurrent = check.opt_int_param(max_concurrent, 'max_concurrent')\n    self._tag_concurrency_limits = check.opt_list_param(tag_concurrency_limits, 'tag_concurrency_limits')\n    if self._max_concurrent is not None:\n        check.invariant(self._max_concurrent > 0, 'max_concurrent must be > 0')\n    self._sleep_seconds = cast(float, check.opt_float_param(sleep_seconds, 'sleep_seconds', default=DEFAULT_SLEEP_SECONDS))\n    self._check_step_health_interval_seconds = cast(int, check.opt_int_param(check_step_health_interval_seconds, 'check_step_health_interval_seconds', default=20))\n    self._should_verify_step = should_verify_step\n    self._event_cursor: Optional[str] = None",
            "def __init__(self, step_handler: StepHandler, retries: RetryMode, sleep_seconds: Optional[float]=None, check_step_health_interval_seconds: Optional[int]=None, max_concurrent: Optional[int]=None, tag_concurrency_limits: Optional[List[Dict[str, Any]]]=None, should_verify_step: bool=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self._step_handler = step_handler\n    self._retries = retries\n    self._max_concurrent = check.opt_int_param(max_concurrent, 'max_concurrent')\n    self._tag_concurrency_limits = check.opt_list_param(tag_concurrency_limits, 'tag_concurrency_limits')\n    if self._max_concurrent is not None:\n        check.invariant(self._max_concurrent > 0, 'max_concurrent must be > 0')\n    self._sleep_seconds = cast(float, check.opt_float_param(sleep_seconds, 'sleep_seconds', default=DEFAULT_SLEEP_SECONDS))\n    self._check_step_health_interval_seconds = cast(int, check.opt_int_param(check_step_health_interval_seconds, 'check_step_health_interval_seconds', default=20))\n    self._should_verify_step = should_verify_step\n    self._event_cursor: Optional[str] = None"
        ]
    },
    {
        "func_name": "retries",
        "original": "@property\ndef retries(self):\n    return self._retries",
        "mutated": [
            "@property\ndef retries(self):\n    if False:\n        i = 10\n    return self._retries",
            "@property\ndef retries(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return self._retries",
            "@property\ndef retries(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return self._retries",
            "@property\ndef retries(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return self._retries",
            "@property\ndef retries(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return self._retries"
        ]
    },
    {
        "func_name": "_pop_events",
        "original": "def _pop_events(self, instance: DagsterInstance, run_id: str) -> Sequence[DagsterEvent]:\n    conn = instance.get_records_for_run(run_id, self._event_cursor, of_type=set(DagsterEventType))\n    self._event_cursor = conn.cursor\n    dagster_events = [record.event_log_entry.dagster_event for record in conn.records if record.event_log_entry.dagster_event]\n    return dagster_events",
        "mutated": [
            "def _pop_events(self, instance: DagsterInstance, run_id: str) -> Sequence[DagsterEvent]:\n    if False:\n        i = 10\n    conn = instance.get_records_for_run(run_id, self._event_cursor, of_type=set(DagsterEventType))\n    self._event_cursor = conn.cursor\n    dagster_events = [record.event_log_entry.dagster_event for record in conn.records if record.event_log_entry.dagster_event]\n    return dagster_events",
            "def _pop_events(self, instance: DagsterInstance, run_id: str) -> Sequence[DagsterEvent]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    conn = instance.get_records_for_run(run_id, self._event_cursor, of_type=set(DagsterEventType))\n    self._event_cursor = conn.cursor\n    dagster_events = [record.event_log_entry.dagster_event for record in conn.records if record.event_log_entry.dagster_event]\n    return dagster_events",
            "def _pop_events(self, instance: DagsterInstance, run_id: str) -> Sequence[DagsterEvent]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    conn = instance.get_records_for_run(run_id, self._event_cursor, of_type=set(DagsterEventType))\n    self._event_cursor = conn.cursor\n    dagster_events = [record.event_log_entry.dagster_event for record in conn.records if record.event_log_entry.dagster_event]\n    return dagster_events",
            "def _pop_events(self, instance: DagsterInstance, run_id: str) -> Sequence[DagsterEvent]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    conn = instance.get_records_for_run(run_id, self._event_cursor, of_type=set(DagsterEventType))\n    self._event_cursor = conn.cursor\n    dagster_events = [record.event_log_entry.dagster_event for record in conn.records if record.event_log_entry.dagster_event]\n    return dagster_events",
            "def _pop_events(self, instance: DagsterInstance, run_id: str) -> Sequence[DagsterEvent]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    conn = instance.get_records_for_run(run_id, self._event_cursor, of_type=set(DagsterEventType))\n    self._event_cursor = conn.cursor\n    dagster_events = [record.event_log_entry.dagster_event for record in conn.records if record.event_log_entry.dagster_event]\n    return dagster_events"
        ]
    },
    {
        "func_name": "_get_step_handler_context",
        "original": "def _get_step_handler_context(self, plan_context, steps, active_execution) -> StepHandlerContext:\n    return StepHandlerContext(instance=plan_context.plan_data.instance, plan_context=plan_context, steps=steps, execute_step_args=ExecuteStepArgs(job_origin=plan_context.reconstructable_job.get_python_origin(), run_id=plan_context.dagster_run.run_id, step_keys_to_execute=[step.key for step in steps], instance_ref=plan_context.plan_data.instance.get_ref(), retry_mode=self.retries.for_inner_plan(), known_state=active_execution.get_known_state(), should_verify_step=self._should_verify_step, print_serialized_events=False), dagster_run=plan_context.dagster_run)",
        "mutated": [
            "def _get_step_handler_context(self, plan_context, steps, active_execution) -> StepHandlerContext:\n    if False:\n        i = 10\n    return StepHandlerContext(instance=plan_context.plan_data.instance, plan_context=plan_context, steps=steps, execute_step_args=ExecuteStepArgs(job_origin=plan_context.reconstructable_job.get_python_origin(), run_id=plan_context.dagster_run.run_id, step_keys_to_execute=[step.key for step in steps], instance_ref=plan_context.plan_data.instance.get_ref(), retry_mode=self.retries.for_inner_plan(), known_state=active_execution.get_known_state(), should_verify_step=self._should_verify_step, print_serialized_events=False), dagster_run=plan_context.dagster_run)",
            "def _get_step_handler_context(self, plan_context, steps, active_execution) -> StepHandlerContext:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return StepHandlerContext(instance=plan_context.plan_data.instance, plan_context=plan_context, steps=steps, execute_step_args=ExecuteStepArgs(job_origin=plan_context.reconstructable_job.get_python_origin(), run_id=plan_context.dagster_run.run_id, step_keys_to_execute=[step.key for step in steps], instance_ref=plan_context.plan_data.instance.get_ref(), retry_mode=self.retries.for_inner_plan(), known_state=active_execution.get_known_state(), should_verify_step=self._should_verify_step, print_serialized_events=False), dagster_run=plan_context.dagster_run)",
            "def _get_step_handler_context(self, plan_context, steps, active_execution) -> StepHandlerContext:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return StepHandlerContext(instance=plan_context.plan_data.instance, plan_context=plan_context, steps=steps, execute_step_args=ExecuteStepArgs(job_origin=plan_context.reconstructable_job.get_python_origin(), run_id=plan_context.dagster_run.run_id, step_keys_to_execute=[step.key for step in steps], instance_ref=plan_context.plan_data.instance.get_ref(), retry_mode=self.retries.for_inner_plan(), known_state=active_execution.get_known_state(), should_verify_step=self._should_verify_step, print_serialized_events=False), dagster_run=plan_context.dagster_run)",
            "def _get_step_handler_context(self, plan_context, steps, active_execution) -> StepHandlerContext:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return StepHandlerContext(instance=plan_context.plan_data.instance, plan_context=plan_context, steps=steps, execute_step_args=ExecuteStepArgs(job_origin=plan_context.reconstructable_job.get_python_origin(), run_id=plan_context.dagster_run.run_id, step_keys_to_execute=[step.key for step in steps], instance_ref=plan_context.plan_data.instance.get_ref(), retry_mode=self.retries.for_inner_plan(), known_state=active_execution.get_known_state(), should_verify_step=self._should_verify_step, print_serialized_events=False), dagster_run=plan_context.dagster_run)",
            "def _get_step_handler_context(self, plan_context, steps, active_execution) -> StepHandlerContext:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return StepHandlerContext(instance=plan_context.plan_data.instance, plan_context=plan_context, steps=steps, execute_step_args=ExecuteStepArgs(job_origin=plan_context.reconstructable_job.get_python_origin(), run_id=plan_context.dagster_run.run_id, step_keys_to_execute=[step.key for step in steps], instance_ref=plan_context.plan_data.instance.get_ref(), retry_mode=self.retries.for_inner_plan(), known_state=active_execution.get_known_state(), should_verify_step=self._should_verify_step, print_serialized_events=False), dagster_run=plan_context.dagster_run)"
        ]
    },
    {
        "func_name": "execute",
        "original": "def execute(self, plan_context: PlanOrchestrationContext, execution_plan: ExecutionPlan):\n    check.inst_param(plan_context, 'plan_context', PlanOrchestrationContext)\n    check.inst_param(execution_plan, 'execution_plan', ExecutionPlan)\n    DagsterEvent.engine_event(plan_context, f'Starting execution with step handler {self._step_handler.name}.', EngineEventData())\n    with InstanceConcurrencyContext(plan_context.instance, plan_context.run_id) as instance_concurrency_context:\n        with ActiveExecution(execution_plan, retry_mode=self.retries, max_concurrent=self._max_concurrent, tag_concurrency_limits=self._tag_concurrency_limits, instance_concurrency_context=instance_concurrency_context) as active_execution:\n            running_steps: Dict[str, ExecutionStep] = {}\n            if plan_context.resume_from_failure:\n                DagsterEvent.engine_event(plan_context, 'Resuming execution from failure', EngineEventData())\n                prior_events = self._pop_events(plan_context.instance, plan_context.run_id)\n                for dagster_event in prior_events:\n                    yield dagster_event\n                possibly_in_flight_steps = active_execution.rebuild_from_events(prior_events)\n                for step in possibly_in_flight_steps:\n                    step_handler_context = self._get_step_handler_context(plan_context, [step], active_execution)\n                    DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Checking on status of in-progress step {step.key} from previous run', EngineEventData())\n                    should_retry_step = False\n                    health_check = None\n                    try:\n                        health_check = self._step_handler.check_step_health(step_handler_context)\n                    except Exception:\n                        DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Including {step.key} in the new run since it raised an error when checking whether it was running', EngineEventData(error=serializable_error_info_from_exc_info(sys.exc_info())))\n                        should_retry_step = True\n                    else:\n                        if not health_check.is_healthy:\n                            DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Including step {step.key} in the new run since it is not currently running: {health_check.unhealthy_reason}')\n                            should_retry_step = True\n                    if should_retry_step:\n                        list(self._step_handler.launch_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                    running_steps[step.key] = step\n            last_check_step_health_time = pendulum.now('UTC')\n            while not active_execution.is_complete:\n                if active_execution.check_for_interrupts():\n                    active_execution.mark_interrupted()\n                    if not plan_context.instance.run_will_resume(plan_context.run_id):\n                        DagsterEvent.engine_event(plan_context, 'Executor received termination signal, forwarding to steps', EngineEventData.interrupted(list(running_steps.keys())))\n                        for step in running_steps.values():\n                            list(self._step_handler.terminate_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                    else:\n                        DagsterEvent.engine_event(plan_context, 'Executor received termination signal, not forwarding to steps because run will be resumed', EngineEventData(metadata={'steps_in_flight': MetadataValue.text(str(running_steps.keys()))}))\n                    return\n                for dagster_event in self._pop_events(plan_context.instance, plan_context.run_id):\n                    yield dagster_event\n                    if dagster_event.is_step_skipped:\n                        assert isinstance(dagster_event.step_key, str)\n                        active_execution.verify_complete(plan_context, dagster_event.step_key)\n                    else:\n                        active_execution.handle_event(dagster_event)\n                        if dagster_event.is_step_success or dagster_event.is_step_failure or dagster_event.is_resource_init_failure or dagster_event.is_step_up_for_retry:\n                            assert isinstance(dagster_event.step_key, str)\n                            del running_steps[dagster_event.step_key]\n                            if not dagster_event.is_step_up_for_retry:\n                                active_execution.verify_complete(plan_context, dagster_event.step_key)\n                list(active_execution.plan_events_iterator(plan_context))\n                curr_time = pendulum.now('UTC')\n                if (curr_time - last_check_step_health_time).total_seconds() >= self._check_step_health_interval_seconds:\n                    last_check_step_health_time = curr_time\n                    for step in running_steps.values():\n                        step_context = plan_context.for_step(step)\n                        try:\n                            health_check_result = self._step_handler.check_step_health(self._get_step_handler_context(plan_context, [step], active_execution))\n                            if not health_check_result.is_healthy:\n                                DagsterEvent.step_failure_event(step_context=step_context, step_failure_data=StepFailureData(error=None, user_failure_data=None), message=f'Step {step.key} failed health check: {health_check_result.unhealthy_reason}')\n                        except Exception:\n                            serializable_error = serializable_error_info_from_exc_info(sys.exc_info())\n                            DagsterEvent.step_failure_event(step_context=plan_context.for_step(step), step_failure_data=StepFailureData(error=serializable_error, user_failure_data=None))\n                if self._max_concurrent is not None:\n                    max_steps_to_run = self._max_concurrent - len(running_steps)\n                    check.invariant(max_steps_to_run >= 0, 'More steps are active than max_concurrent')\n                else:\n                    max_steps_to_run = None\n                list(active_execution.concurrency_event_iterator(plan_context))\n                for step in active_execution.get_steps_to_execute(max_steps_to_run):\n                    running_steps[step.key] = step\n                    list(self._step_handler.launch_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                time.sleep(self._sleep_seconds)",
        "mutated": [
            "def execute(self, plan_context: PlanOrchestrationContext, execution_plan: ExecutionPlan):\n    if False:\n        i = 10\n    check.inst_param(plan_context, 'plan_context', PlanOrchestrationContext)\n    check.inst_param(execution_plan, 'execution_plan', ExecutionPlan)\n    DagsterEvent.engine_event(plan_context, f'Starting execution with step handler {self._step_handler.name}.', EngineEventData())\n    with InstanceConcurrencyContext(plan_context.instance, plan_context.run_id) as instance_concurrency_context:\n        with ActiveExecution(execution_plan, retry_mode=self.retries, max_concurrent=self._max_concurrent, tag_concurrency_limits=self._tag_concurrency_limits, instance_concurrency_context=instance_concurrency_context) as active_execution:\n            running_steps: Dict[str, ExecutionStep] = {}\n            if plan_context.resume_from_failure:\n                DagsterEvent.engine_event(plan_context, 'Resuming execution from failure', EngineEventData())\n                prior_events = self._pop_events(plan_context.instance, plan_context.run_id)\n                for dagster_event in prior_events:\n                    yield dagster_event\n                possibly_in_flight_steps = active_execution.rebuild_from_events(prior_events)\n                for step in possibly_in_flight_steps:\n                    step_handler_context = self._get_step_handler_context(plan_context, [step], active_execution)\n                    DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Checking on status of in-progress step {step.key} from previous run', EngineEventData())\n                    should_retry_step = False\n                    health_check = None\n                    try:\n                        health_check = self._step_handler.check_step_health(step_handler_context)\n                    except Exception:\n                        DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Including {step.key} in the new run since it raised an error when checking whether it was running', EngineEventData(error=serializable_error_info_from_exc_info(sys.exc_info())))\n                        should_retry_step = True\n                    else:\n                        if not health_check.is_healthy:\n                            DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Including step {step.key} in the new run since it is not currently running: {health_check.unhealthy_reason}')\n                            should_retry_step = True\n                    if should_retry_step:\n                        list(self._step_handler.launch_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                    running_steps[step.key] = step\n            last_check_step_health_time = pendulum.now('UTC')\n            while not active_execution.is_complete:\n                if active_execution.check_for_interrupts():\n                    active_execution.mark_interrupted()\n                    if not plan_context.instance.run_will_resume(plan_context.run_id):\n                        DagsterEvent.engine_event(plan_context, 'Executor received termination signal, forwarding to steps', EngineEventData.interrupted(list(running_steps.keys())))\n                        for step in running_steps.values():\n                            list(self._step_handler.terminate_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                    else:\n                        DagsterEvent.engine_event(plan_context, 'Executor received termination signal, not forwarding to steps because run will be resumed', EngineEventData(metadata={'steps_in_flight': MetadataValue.text(str(running_steps.keys()))}))\n                    return\n                for dagster_event in self._pop_events(plan_context.instance, plan_context.run_id):\n                    yield dagster_event\n                    if dagster_event.is_step_skipped:\n                        assert isinstance(dagster_event.step_key, str)\n                        active_execution.verify_complete(plan_context, dagster_event.step_key)\n                    else:\n                        active_execution.handle_event(dagster_event)\n                        if dagster_event.is_step_success or dagster_event.is_step_failure or dagster_event.is_resource_init_failure or dagster_event.is_step_up_for_retry:\n                            assert isinstance(dagster_event.step_key, str)\n                            del running_steps[dagster_event.step_key]\n                            if not dagster_event.is_step_up_for_retry:\n                                active_execution.verify_complete(plan_context, dagster_event.step_key)\n                list(active_execution.plan_events_iterator(plan_context))\n                curr_time = pendulum.now('UTC')\n                if (curr_time - last_check_step_health_time).total_seconds() >= self._check_step_health_interval_seconds:\n                    last_check_step_health_time = curr_time\n                    for step in running_steps.values():\n                        step_context = plan_context.for_step(step)\n                        try:\n                            health_check_result = self._step_handler.check_step_health(self._get_step_handler_context(plan_context, [step], active_execution))\n                            if not health_check_result.is_healthy:\n                                DagsterEvent.step_failure_event(step_context=step_context, step_failure_data=StepFailureData(error=None, user_failure_data=None), message=f'Step {step.key} failed health check: {health_check_result.unhealthy_reason}')\n                        except Exception:\n                            serializable_error = serializable_error_info_from_exc_info(sys.exc_info())\n                            DagsterEvent.step_failure_event(step_context=plan_context.for_step(step), step_failure_data=StepFailureData(error=serializable_error, user_failure_data=None))\n                if self._max_concurrent is not None:\n                    max_steps_to_run = self._max_concurrent - len(running_steps)\n                    check.invariant(max_steps_to_run >= 0, 'More steps are active than max_concurrent')\n                else:\n                    max_steps_to_run = None\n                list(active_execution.concurrency_event_iterator(plan_context))\n                for step in active_execution.get_steps_to_execute(max_steps_to_run):\n                    running_steps[step.key] = step\n                    list(self._step_handler.launch_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                time.sleep(self._sleep_seconds)",
            "def execute(self, plan_context: PlanOrchestrationContext, execution_plan: ExecutionPlan):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    check.inst_param(plan_context, 'plan_context', PlanOrchestrationContext)\n    check.inst_param(execution_plan, 'execution_plan', ExecutionPlan)\n    DagsterEvent.engine_event(plan_context, f'Starting execution with step handler {self._step_handler.name}.', EngineEventData())\n    with InstanceConcurrencyContext(plan_context.instance, plan_context.run_id) as instance_concurrency_context:\n        with ActiveExecution(execution_plan, retry_mode=self.retries, max_concurrent=self._max_concurrent, tag_concurrency_limits=self._tag_concurrency_limits, instance_concurrency_context=instance_concurrency_context) as active_execution:\n            running_steps: Dict[str, ExecutionStep] = {}\n            if plan_context.resume_from_failure:\n                DagsterEvent.engine_event(plan_context, 'Resuming execution from failure', EngineEventData())\n                prior_events = self._pop_events(plan_context.instance, plan_context.run_id)\n                for dagster_event in prior_events:\n                    yield dagster_event\n                possibly_in_flight_steps = active_execution.rebuild_from_events(prior_events)\n                for step in possibly_in_flight_steps:\n                    step_handler_context = self._get_step_handler_context(plan_context, [step], active_execution)\n                    DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Checking on status of in-progress step {step.key} from previous run', EngineEventData())\n                    should_retry_step = False\n                    health_check = None\n                    try:\n                        health_check = self._step_handler.check_step_health(step_handler_context)\n                    except Exception:\n                        DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Including {step.key} in the new run since it raised an error when checking whether it was running', EngineEventData(error=serializable_error_info_from_exc_info(sys.exc_info())))\n                        should_retry_step = True\n                    else:\n                        if not health_check.is_healthy:\n                            DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Including step {step.key} in the new run since it is not currently running: {health_check.unhealthy_reason}')\n                            should_retry_step = True\n                    if should_retry_step:\n                        list(self._step_handler.launch_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                    running_steps[step.key] = step\n            last_check_step_health_time = pendulum.now('UTC')\n            while not active_execution.is_complete:\n                if active_execution.check_for_interrupts():\n                    active_execution.mark_interrupted()\n                    if not plan_context.instance.run_will_resume(plan_context.run_id):\n                        DagsterEvent.engine_event(plan_context, 'Executor received termination signal, forwarding to steps', EngineEventData.interrupted(list(running_steps.keys())))\n                        for step in running_steps.values():\n                            list(self._step_handler.terminate_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                    else:\n                        DagsterEvent.engine_event(plan_context, 'Executor received termination signal, not forwarding to steps because run will be resumed', EngineEventData(metadata={'steps_in_flight': MetadataValue.text(str(running_steps.keys()))}))\n                    return\n                for dagster_event in self._pop_events(plan_context.instance, plan_context.run_id):\n                    yield dagster_event\n                    if dagster_event.is_step_skipped:\n                        assert isinstance(dagster_event.step_key, str)\n                        active_execution.verify_complete(plan_context, dagster_event.step_key)\n                    else:\n                        active_execution.handle_event(dagster_event)\n                        if dagster_event.is_step_success or dagster_event.is_step_failure or dagster_event.is_resource_init_failure or dagster_event.is_step_up_for_retry:\n                            assert isinstance(dagster_event.step_key, str)\n                            del running_steps[dagster_event.step_key]\n                            if not dagster_event.is_step_up_for_retry:\n                                active_execution.verify_complete(plan_context, dagster_event.step_key)\n                list(active_execution.plan_events_iterator(plan_context))\n                curr_time = pendulum.now('UTC')\n                if (curr_time - last_check_step_health_time).total_seconds() >= self._check_step_health_interval_seconds:\n                    last_check_step_health_time = curr_time\n                    for step in running_steps.values():\n                        step_context = plan_context.for_step(step)\n                        try:\n                            health_check_result = self._step_handler.check_step_health(self._get_step_handler_context(plan_context, [step], active_execution))\n                            if not health_check_result.is_healthy:\n                                DagsterEvent.step_failure_event(step_context=step_context, step_failure_data=StepFailureData(error=None, user_failure_data=None), message=f'Step {step.key} failed health check: {health_check_result.unhealthy_reason}')\n                        except Exception:\n                            serializable_error = serializable_error_info_from_exc_info(sys.exc_info())\n                            DagsterEvent.step_failure_event(step_context=plan_context.for_step(step), step_failure_data=StepFailureData(error=serializable_error, user_failure_data=None))\n                if self._max_concurrent is not None:\n                    max_steps_to_run = self._max_concurrent - len(running_steps)\n                    check.invariant(max_steps_to_run >= 0, 'More steps are active than max_concurrent')\n                else:\n                    max_steps_to_run = None\n                list(active_execution.concurrency_event_iterator(plan_context))\n                for step in active_execution.get_steps_to_execute(max_steps_to_run):\n                    running_steps[step.key] = step\n                    list(self._step_handler.launch_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                time.sleep(self._sleep_seconds)",
            "def execute(self, plan_context: PlanOrchestrationContext, execution_plan: ExecutionPlan):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    check.inst_param(plan_context, 'plan_context', PlanOrchestrationContext)\n    check.inst_param(execution_plan, 'execution_plan', ExecutionPlan)\n    DagsterEvent.engine_event(plan_context, f'Starting execution with step handler {self._step_handler.name}.', EngineEventData())\n    with InstanceConcurrencyContext(plan_context.instance, plan_context.run_id) as instance_concurrency_context:\n        with ActiveExecution(execution_plan, retry_mode=self.retries, max_concurrent=self._max_concurrent, tag_concurrency_limits=self._tag_concurrency_limits, instance_concurrency_context=instance_concurrency_context) as active_execution:\n            running_steps: Dict[str, ExecutionStep] = {}\n            if plan_context.resume_from_failure:\n                DagsterEvent.engine_event(plan_context, 'Resuming execution from failure', EngineEventData())\n                prior_events = self._pop_events(plan_context.instance, plan_context.run_id)\n                for dagster_event in prior_events:\n                    yield dagster_event\n                possibly_in_flight_steps = active_execution.rebuild_from_events(prior_events)\n                for step in possibly_in_flight_steps:\n                    step_handler_context = self._get_step_handler_context(plan_context, [step], active_execution)\n                    DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Checking on status of in-progress step {step.key} from previous run', EngineEventData())\n                    should_retry_step = False\n                    health_check = None\n                    try:\n                        health_check = self._step_handler.check_step_health(step_handler_context)\n                    except Exception:\n                        DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Including {step.key} in the new run since it raised an error when checking whether it was running', EngineEventData(error=serializable_error_info_from_exc_info(sys.exc_info())))\n                        should_retry_step = True\n                    else:\n                        if not health_check.is_healthy:\n                            DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Including step {step.key} in the new run since it is not currently running: {health_check.unhealthy_reason}')\n                            should_retry_step = True\n                    if should_retry_step:\n                        list(self._step_handler.launch_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                    running_steps[step.key] = step\n            last_check_step_health_time = pendulum.now('UTC')\n            while not active_execution.is_complete:\n                if active_execution.check_for_interrupts():\n                    active_execution.mark_interrupted()\n                    if not plan_context.instance.run_will_resume(plan_context.run_id):\n                        DagsterEvent.engine_event(plan_context, 'Executor received termination signal, forwarding to steps', EngineEventData.interrupted(list(running_steps.keys())))\n                        for step in running_steps.values():\n                            list(self._step_handler.terminate_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                    else:\n                        DagsterEvent.engine_event(plan_context, 'Executor received termination signal, not forwarding to steps because run will be resumed', EngineEventData(metadata={'steps_in_flight': MetadataValue.text(str(running_steps.keys()))}))\n                    return\n                for dagster_event in self._pop_events(plan_context.instance, plan_context.run_id):\n                    yield dagster_event\n                    if dagster_event.is_step_skipped:\n                        assert isinstance(dagster_event.step_key, str)\n                        active_execution.verify_complete(plan_context, dagster_event.step_key)\n                    else:\n                        active_execution.handle_event(dagster_event)\n                        if dagster_event.is_step_success or dagster_event.is_step_failure or dagster_event.is_resource_init_failure or dagster_event.is_step_up_for_retry:\n                            assert isinstance(dagster_event.step_key, str)\n                            del running_steps[dagster_event.step_key]\n                            if not dagster_event.is_step_up_for_retry:\n                                active_execution.verify_complete(plan_context, dagster_event.step_key)\n                list(active_execution.plan_events_iterator(plan_context))\n                curr_time = pendulum.now('UTC')\n                if (curr_time - last_check_step_health_time).total_seconds() >= self._check_step_health_interval_seconds:\n                    last_check_step_health_time = curr_time\n                    for step in running_steps.values():\n                        step_context = plan_context.for_step(step)\n                        try:\n                            health_check_result = self._step_handler.check_step_health(self._get_step_handler_context(plan_context, [step], active_execution))\n                            if not health_check_result.is_healthy:\n                                DagsterEvent.step_failure_event(step_context=step_context, step_failure_data=StepFailureData(error=None, user_failure_data=None), message=f'Step {step.key} failed health check: {health_check_result.unhealthy_reason}')\n                        except Exception:\n                            serializable_error = serializable_error_info_from_exc_info(sys.exc_info())\n                            DagsterEvent.step_failure_event(step_context=plan_context.for_step(step), step_failure_data=StepFailureData(error=serializable_error, user_failure_data=None))\n                if self._max_concurrent is not None:\n                    max_steps_to_run = self._max_concurrent - len(running_steps)\n                    check.invariant(max_steps_to_run >= 0, 'More steps are active than max_concurrent')\n                else:\n                    max_steps_to_run = None\n                list(active_execution.concurrency_event_iterator(plan_context))\n                for step in active_execution.get_steps_to_execute(max_steps_to_run):\n                    running_steps[step.key] = step\n                    list(self._step_handler.launch_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                time.sleep(self._sleep_seconds)",
            "def execute(self, plan_context: PlanOrchestrationContext, execution_plan: ExecutionPlan):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    check.inst_param(plan_context, 'plan_context', PlanOrchestrationContext)\n    check.inst_param(execution_plan, 'execution_plan', ExecutionPlan)\n    DagsterEvent.engine_event(plan_context, f'Starting execution with step handler {self._step_handler.name}.', EngineEventData())\n    with InstanceConcurrencyContext(plan_context.instance, plan_context.run_id) as instance_concurrency_context:\n        with ActiveExecution(execution_plan, retry_mode=self.retries, max_concurrent=self._max_concurrent, tag_concurrency_limits=self._tag_concurrency_limits, instance_concurrency_context=instance_concurrency_context) as active_execution:\n            running_steps: Dict[str, ExecutionStep] = {}\n            if plan_context.resume_from_failure:\n                DagsterEvent.engine_event(plan_context, 'Resuming execution from failure', EngineEventData())\n                prior_events = self._pop_events(plan_context.instance, plan_context.run_id)\n                for dagster_event in prior_events:\n                    yield dagster_event\n                possibly_in_flight_steps = active_execution.rebuild_from_events(prior_events)\n                for step in possibly_in_flight_steps:\n                    step_handler_context = self._get_step_handler_context(plan_context, [step], active_execution)\n                    DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Checking on status of in-progress step {step.key} from previous run', EngineEventData())\n                    should_retry_step = False\n                    health_check = None\n                    try:\n                        health_check = self._step_handler.check_step_health(step_handler_context)\n                    except Exception:\n                        DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Including {step.key} in the new run since it raised an error when checking whether it was running', EngineEventData(error=serializable_error_info_from_exc_info(sys.exc_info())))\n                        should_retry_step = True\n                    else:\n                        if not health_check.is_healthy:\n                            DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Including step {step.key} in the new run since it is not currently running: {health_check.unhealthy_reason}')\n                            should_retry_step = True\n                    if should_retry_step:\n                        list(self._step_handler.launch_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                    running_steps[step.key] = step\n            last_check_step_health_time = pendulum.now('UTC')\n            while not active_execution.is_complete:\n                if active_execution.check_for_interrupts():\n                    active_execution.mark_interrupted()\n                    if not plan_context.instance.run_will_resume(plan_context.run_id):\n                        DagsterEvent.engine_event(plan_context, 'Executor received termination signal, forwarding to steps', EngineEventData.interrupted(list(running_steps.keys())))\n                        for step in running_steps.values():\n                            list(self._step_handler.terminate_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                    else:\n                        DagsterEvent.engine_event(plan_context, 'Executor received termination signal, not forwarding to steps because run will be resumed', EngineEventData(metadata={'steps_in_flight': MetadataValue.text(str(running_steps.keys()))}))\n                    return\n                for dagster_event in self._pop_events(plan_context.instance, plan_context.run_id):\n                    yield dagster_event\n                    if dagster_event.is_step_skipped:\n                        assert isinstance(dagster_event.step_key, str)\n                        active_execution.verify_complete(plan_context, dagster_event.step_key)\n                    else:\n                        active_execution.handle_event(dagster_event)\n                        if dagster_event.is_step_success or dagster_event.is_step_failure or dagster_event.is_resource_init_failure or dagster_event.is_step_up_for_retry:\n                            assert isinstance(dagster_event.step_key, str)\n                            del running_steps[dagster_event.step_key]\n                            if not dagster_event.is_step_up_for_retry:\n                                active_execution.verify_complete(plan_context, dagster_event.step_key)\n                list(active_execution.plan_events_iterator(plan_context))\n                curr_time = pendulum.now('UTC')\n                if (curr_time - last_check_step_health_time).total_seconds() >= self._check_step_health_interval_seconds:\n                    last_check_step_health_time = curr_time\n                    for step in running_steps.values():\n                        step_context = plan_context.for_step(step)\n                        try:\n                            health_check_result = self._step_handler.check_step_health(self._get_step_handler_context(plan_context, [step], active_execution))\n                            if not health_check_result.is_healthy:\n                                DagsterEvent.step_failure_event(step_context=step_context, step_failure_data=StepFailureData(error=None, user_failure_data=None), message=f'Step {step.key} failed health check: {health_check_result.unhealthy_reason}')\n                        except Exception:\n                            serializable_error = serializable_error_info_from_exc_info(sys.exc_info())\n                            DagsterEvent.step_failure_event(step_context=plan_context.for_step(step), step_failure_data=StepFailureData(error=serializable_error, user_failure_data=None))\n                if self._max_concurrent is not None:\n                    max_steps_to_run = self._max_concurrent - len(running_steps)\n                    check.invariant(max_steps_to_run >= 0, 'More steps are active than max_concurrent')\n                else:\n                    max_steps_to_run = None\n                list(active_execution.concurrency_event_iterator(plan_context))\n                for step in active_execution.get_steps_to_execute(max_steps_to_run):\n                    running_steps[step.key] = step\n                    list(self._step_handler.launch_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                time.sleep(self._sleep_seconds)",
            "def execute(self, plan_context: PlanOrchestrationContext, execution_plan: ExecutionPlan):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    check.inst_param(plan_context, 'plan_context', PlanOrchestrationContext)\n    check.inst_param(execution_plan, 'execution_plan', ExecutionPlan)\n    DagsterEvent.engine_event(plan_context, f'Starting execution with step handler {self._step_handler.name}.', EngineEventData())\n    with InstanceConcurrencyContext(plan_context.instance, plan_context.run_id) as instance_concurrency_context:\n        with ActiveExecution(execution_plan, retry_mode=self.retries, max_concurrent=self._max_concurrent, tag_concurrency_limits=self._tag_concurrency_limits, instance_concurrency_context=instance_concurrency_context) as active_execution:\n            running_steps: Dict[str, ExecutionStep] = {}\n            if plan_context.resume_from_failure:\n                DagsterEvent.engine_event(plan_context, 'Resuming execution from failure', EngineEventData())\n                prior_events = self._pop_events(plan_context.instance, plan_context.run_id)\n                for dagster_event in prior_events:\n                    yield dagster_event\n                possibly_in_flight_steps = active_execution.rebuild_from_events(prior_events)\n                for step in possibly_in_flight_steps:\n                    step_handler_context = self._get_step_handler_context(plan_context, [step], active_execution)\n                    DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Checking on status of in-progress step {step.key} from previous run', EngineEventData())\n                    should_retry_step = False\n                    health_check = None\n                    try:\n                        health_check = self._step_handler.check_step_health(step_handler_context)\n                    except Exception:\n                        DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Including {step.key} in the new run since it raised an error when checking whether it was running', EngineEventData(error=serializable_error_info_from_exc_info(sys.exc_info())))\n                        should_retry_step = True\n                    else:\n                        if not health_check.is_healthy:\n                            DagsterEvent.engine_event(step_handler_context.get_step_context(step.key), f'Including step {step.key} in the new run since it is not currently running: {health_check.unhealthy_reason}')\n                            should_retry_step = True\n                    if should_retry_step:\n                        list(self._step_handler.launch_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                    running_steps[step.key] = step\n            last_check_step_health_time = pendulum.now('UTC')\n            while not active_execution.is_complete:\n                if active_execution.check_for_interrupts():\n                    active_execution.mark_interrupted()\n                    if not plan_context.instance.run_will_resume(plan_context.run_id):\n                        DagsterEvent.engine_event(plan_context, 'Executor received termination signal, forwarding to steps', EngineEventData.interrupted(list(running_steps.keys())))\n                        for step in running_steps.values():\n                            list(self._step_handler.terminate_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                    else:\n                        DagsterEvent.engine_event(plan_context, 'Executor received termination signal, not forwarding to steps because run will be resumed', EngineEventData(metadata={'steps_in_flight': MetadataValue.text(str(running_steps.keys()))}))\n                    return\n                for dagster_event in self._pop_events(plan_context.instance, plan_context.run_id):\n                    yield dagster_event\n                    if dagster_event.is_step_skipped:\n                        assert isinstance(dagster_event.step_key, str)\n                        active_execution.verify_complete(plan_context, dagster_event.step_key)\n                    else:\n                        active_execution.handle_event(dagster_event)\n                        if dagster_event.is_step_success or dagster_event.is_step_failure or dagster_event.is_resource_init_failure or dagster_event.is_step_up_for_retry:\n                            assert isinstance(dagster_event.step_key, str)\n                            del running_steps[dagster_event.step_key]\n                            if not dagster_event.is_step_up_for_retry:\n                                active_execution.verify_complete(plan_context, dagster_event.step_key)\n                list(active_execution.plan_events_iterator(plan_context))\n                curr_time = pendulum.now('UTC')\n                if (curr_time - last_check_step_health_time).total_seconds() >= self._check_step_health_interval_seconds:\n                    last_check_step_health_time = curr_time\n                    for step in running_steps.values():\n                        step_context = plan_context.for_step(step)\n                        try:\n                            health_check_result = self._step_handler.check_step_health(self._get_step_handler_context(plan_context, [step], active_execution))\n                            if not health_check_result.is_healthy:\n                                DagsterEvent.step_failure_event(step_context=step_context, step_failure_data=StepFailureData(error=None, user_failure_data=None), message=f'Step {step.key} failed health check: {health_check_result.unhealthy_reason}')\n                        except Exception:\n                            serializable_error = serializable_error_info_from_exc_info(sys.exc_info())\n                            DagsterEvent.step_failure_event(step_context=plan_context.for_step(step), step_failure_data=StepFailureData(error=serializable_error, user_failure_data=None))\n                if self._max_concurrent is not None:\n                    max_steps_to_run = self._max_concurrent - len(running_steps)\n                    check.invariant(max_steps_to_run >= 0, 'More steps are active than max_concurrent')\n                else:\n                    max_steps_to_run = None\n                list(active_execution.concurrency_event_iterator(plan_context))\n                for step in active_execution.get_steps_to_execute(max_steps_to_run):\n                    running_steps[step.key] = step\n                    list(self._step_handler.launch_step(self._get_step_handler_context(plan_context, [step], active_execution)))\n                time.sleep(self._sleep_seconds)"
        ]
    }
]