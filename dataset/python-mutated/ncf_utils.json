[
    {
        "func_name": "compute_test_results",
        "original": "def compute_test_results(model, train, test, rating_metrics, ranking_metrics, k=DEFAULT_K):\n    \"\"\"Compute the test results using a trained NCF model.\n\n    Args:\n        model (object): TF model.\n        train (pandas.DataFrame): Train set.\n        test (pandas.DataFrame): Test set.\n        rating_metrics (list): List of rating metrics.\n        ranking_metrics (list): List of ranking metrics.\n        k (int): top K recommendations\n\n    Returns:\n        dict: Test results.\n\n    \"\"\"\n    test_results = {}\n    predictions = [[row.userID, row.itemID, model.predict(row.userID, row.itemID)] for (_, row) in test.iterrows()]\n    predictions = pd.DataFrame(predictions, columns=['userID', 'itemID', 'prediction'])\n    predictions = predictions.astype({'userID': 'int64', 'itemID': 'int64', 'prediction': 'float64'})\n    for metric in rating_metrics:\n        test_results[metric] = eval(metric)(test, predictions)\n    (users, items, preds) = ([], [], [])\n    item = list(train.itemID.unique())\n    for user in train.userID.unique():\n        user = [user] * len(item)\n        users.extend(user)\n        items.extend(item)\n        preds.extend(list(model.predict(user, item, is_list=True)))\n    all_predictions = pd.DataFrame(data={'userID': users, 'itemID': items, 'prediction': preds})\n    merged = pd.merge(train, all_predictions, on=['userID', 'itemID'], how='outer')\n    all_predictions = merged[merged.rating.isnull()].drop('rating', axis=1)\n    for metric in ranking_metrics:\n        test_results[metric] = eval(metric)(test, all_predictions, col_prediction='prediction', k=k)\n    return test_results",
        "mutated": [
            "def compute_test_results(model, train, test, rating_metrics, ranking_metrics, k=DEFAULT_K):\n    if False:\n        i = 10\n    'Compute the test results using a trained NCF model.\\n\\n    Args:\\n        model (object): TF model.\\n        train (pandas.DataFrame): Train set.\\n        test (pandas.DataFrame): Test set.\\n        rating_metrics (list): List of rating metrics.\\n        ranking_metrics (list): List of ranking metrics.\\n        k (int): top K recommendations\\n\\n    Returns:\\n        dict: Test results.\\n\\n    '\n    test_results = {}\n    predictions = [[row.userID, row.itemID, model.predict(row.userID, row.itemID)] for (_, row) in test.iterrows()]\n    predictions = pd.DataFrame(predictions, columns=['userID', 'itemID', 'prediction'])\n    predictions = predictions.astype({'userID': 'int64', 'itemID': 'int64', 'prediction': 'float64'})\n    for metric in rating_metrics:\n        test_results[metric] = eval(metric)(test, predictions)\n    (users, items, preds) = ([], [], [])\n    item = list(train.itemID.unique())\n    for user in train.userID.unique():\n        user = [user] * len(item)\n        users.extend(user)\n        items.extend(item)\n        preds.extend(list(model.predict(user, item, is_list=True)))\n    all_predictions = pd.DataFrame(data={'userID': users, 'itemID': items, 'prediction': preds})\n    merged = pd.merge(train, all_predictions, on=['userID', 'itemID'], how='outer')\n    all_predictions = merged[merged.rating.isnull()].drop('rating', axis=1)\n    for metric in ranking_metrics:\n        test_results[metric] = eval(metric)(test, all_predictions, col_prediction='prediction', k=k)\n    return test_results",
            "def compute_test_results(model, train, test, rating_metrics, ranking_metrics, k=DEFAULT_K):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Compute the test results using a trained NCF model.\\n\\n    Args:\\n        model (object): TF model.\\n        train (pandas.DataFrame): Train set.\\n        test (pandas.DataFrame): Test set.\\n        rating_metrics (list): List of rating metrics.\\n        ranking_metrics (list): List of ranking metrics.\\n        k (int): top K recommendations\\n\\n    Returns:\\n        dict: Test results.\\n\\n    '\n    test_results = {}\n    predictions = [[row.userID, row.itemID, model.predict(row.userID, row.itemID)] for (_, row) in test.iterrows()]\n    predictions = pd.DataFrame(predictions, columns=['userID', 'itemID', 'prediction'])\n    predictions = predictions.astype({'userID': 'int64', 'itemID': 'int64', 'prediction': 'float64'})\n    for metric in rating_metrics:\n        test_results[metric] = eval(metric)(test, predictions)\n    (users, items, preds) = ([], [], [])\n    item = list(train.itemID.unique())\n    for user in train.userID.unique():\n        user = [user] * len(item)\n        users.extend(user)\n        items.extend(item)\n        preds.extend(list(model.predict(user, item, is_list=True)))\n    all_predictions = pd.DataFrame(data={'userID': users, 'itemID': items, 'prediction': preds})\n    merged = pd.merge(train, all_predictions, on=['userID', 'itemID'], how='outer')\n    all_predictions = merged[merged.rating.isnull()].drop('rating', axis=1)\n    for metric in ranking_metrics:\n        test_results[metric] = eval(metric)(test, all_predictions, col_prediction='prediction', k=k)\n    return test_results",
            "def compute_test_results(model, train, test, rating_metrics, ranking_metrics, k=DEFAULT_K):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Compute the test results using a trained NCF model.\\n\\n    Args:\\n        model (object): TF model.\\n        train (pandas.DataFrame): Train set.\\n        test (pandas.DataFrame): Test set.\\n        rating_metrics (list): List of rating metrics.\\n        ranking_metrics (list): List of ranking metrics.\\n        k (int): top K recommendations\\n\\n    Returns:\\n        dict: Test results.\\n\\n    '\n    test_results = {}\n    predictions = [[row.userID, row.itemID, model.predict(row.userID, row.itemID)] for (_, row) in test.iterrows()]\n    predictions = pd.DataFrame(predictions, columns=['userID', 'itemID', 'prediction'])\n    predictions = predictions.astype({'userID': 'int64', 'itemID': 'int64', 'prediction': 'float64'})\n    for metric in rating_metrics:\n        test_results[metric] = eval(metric)(test, predictions)\n    (users, items, preds) = ([], [], [])\n    item = list(train.itemID.unique())\n    for user in train.userID.unique():\n        user = [user] * len(item)\n        users.extend(user)\n        items.extend(item)\n        preds.extend(list(model.predict(user, item, is_list=True)))\n    all_predictions = pd.DataFrame(data={'userID': users, 'itemID': items, 'prediction': preds})\n    merged = pd.merge(train, all_predictions, on=['userID', 'itemID'], how='outer')\n    all_predictions = merged[merged.rating.isnull()].drop('rating', axis=1)\n    for metric in ranking_metrics:\n        test_results[metric] = eval(metric)(test, all_predictions, col_prediction='prediction', k=k)\n    return test_results",
            "def compute_test_results(model, train, test, rating_metrics, ranking_metrics, k=DEFAULT_K):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Compute the test results using a trained NCF model.\\n\\n    Args:\\n        model (object): TF model.\\n        train (pandas.DataFrame): Train set.\\n        test (pandas.DataFrame): Test set.\\n        rating_metrics (list): List of rating metrics.\\n        ranking_metrics (list): List of ranking metrics.\\n        k (int): top K recommendations\\n\\n    Returns:\\n        dict: Test results.\\n\\n    '\n    test_results = {}\n    predictions = [[row.userID, row.itemID, model.predict(row.userID, row.itemID)] for (_, row) in test.iterrows()]\n    predictions = pd.DataFrame(predictions, columns=['userID', 'itemID', 'prediction'])\n    predictions = predictions.astype({'userID': 'int64', 'itemID': 'int64', 'prediction': 'float64'})\n    for metric in rating_metrics:\n        test_results[metric] = eval(metric)(test, predictions)\n    (users, items, preds) = ([], [], [])\n    item = list(train.itemID.unique())\n    for user in train.userID.unique():\n        user = [user] * len(item)\n        users.extend(user)\n        items.extend(item)\n        preds.extend(list(model.predict(user, item, is_list=True)))\n    all_predictions = pd.DataFrame(data={'userID': users, 'itemID': items, 'prediction': preds})\n    merged = pd.merge(train, all_predictions, on=['userID', 'itemID'], how='outer')\n    all_predictions = merged[merged.rating.isnull()].drop('rating', axis=1)\n    for metric in ranking_metrics:\n        test_results[metric] = eval(metric)(test, all_predictions, col_prediction='prediction', k=k)\n    return test_results",
            "def compute_test_results(model, train, test, rating_metrics, ranking_metrics, k=DEFAULT_K):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Compute the test results using a trained NCF model.\\n\\n    Args:\\n        model (object): TF model.\\n        train (pandas.DataFrame): Train set.\\n        test (pandas.DataFrame): Test set.\\n        rating_metrics (list): List of rating metrics.\\n        ranking_metrics (list): List of ranking metrics.\\n        k (int): top K recommendations\\n\\n    Returns:\\n        dict: Test results.\\n\\n    '\n    test_results = {}\n    predictions = [[row.userID, row.itemID, model.predict(row.userID, row.itemID)] for (_, row) in test.iterrows()]\n    predictions = pd.DataFrame(predictions, columns=['userID', 'itemID', 'prediction'])\n    predictions = predictions.astype({'userID': 'int64', 'itemID': 'int64', 'prediction': 'float64'})\n    for metric in rating_metrics:\n        test_results[metric] = eval(metric)(test, predictions)\n    (users, items, preds) = ([], [], [])\n    item = list(train.itemID.unique())\n    for user in train.userID.unique():\n        user = [user] * len(item)\n        users.extend(user)\n        items.extend(item)\n        preds.extend(list(model.predict(user, item, is_list=True)))\n    all_predictions = pd.DataFrame(data={'userID': users, 'itemID': items, 'prediction': preds})\n    merged = pd.merge(train, all_predictions, on=['userID', 'itemID'], how='outer')\n    all_predictions = merged[merged.rating.isnull()].drop('rating', axis=1)\n    for metric in ranking_metrics:\n        test_results[metric] = eval(metric)(test, all_predictions, col_prediction='prediction', k=k)\n    return test_results"
        ]
    },
    {
        "func_name": "combine_metrics_dicts",
        "original": "def combine_metrics_dicts(*metrics):\n    \"\"\"Combine metrics from dicts.\n\n    Args:\n        metrics (dict): Metrics\n\n    Returns:\n        pandas.DataFrame: Dataframe with metrics combined.\n    \"\"\"\n    df = pd.DataFrame(metrics[0], index=[0])\n    for metric in metrics[1:]:\n        df = df.append(pd.DataFrame(metric, index=[0]), sort=False)\n    return df",
        "mutated": [
            "def combine_metrics_dicts(*metrics):\n    if False:\n        i = 10\n    'Combine metrics from dicts.\\n\\n    Args:\\n        metrics (dict): Metrics\\n\\n    Returns:\\n        pandas.DataFrame: Dataframe with metrics combined.\\n    '\n    df = pd.DataFrame(metrics[0], index=[0])\n    for metric in metrics[1:]:\n        df = df.append(pd.DataFrame(metric, index=[0]), sort=False)\n    return df",
            "def combine_metrics_dicts(*metrics):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Combine metrics from dicts.\\n\\n    Args:\\n        metrics (dict): Metrics\\n\\n    Returns:\\n        pandas.DataFrame: Dataframe with metrics combined.\\n    '\n    df = pd.DataFrame(metrics[0], index=[0])\n    for metric in metrics[1:]:\n        df = df.append(pd.DataFrame(metric, index=[0]), sort=False)\n    return df",
            "def combine_metrics_dicts(*metrics):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Combine metrics from dicts.\\n\\n    Args:\\n        metrics (dict): Metrics\\n\\n    Returns:\\n        pandas.DataFrame: Dataframe with metrics combined.\\n    '\n    df = pd.DataFrame(metrics[0], index=[0])\n    for metric in metrics[1:]:\n        df = df.append(pd.DataFrame(metric, index=[0]), sort=False)\n    return df",
            "def combine_metrics_dicts(*metrics):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Combine metrics from dicts.\\n\\n    Args:\\n        metrics (dict): Metrics\\n\\n    Returns:\\n        pandas.DataFrame: Dataframe with metrics combined.\\n    '\n    df = pd.DataFrame(metrics[0], index=[0])\n    for metric in metrics[1:]:\n        df = df.append(pd.DataFrame(metric, index=[0]), sort=False)\n    return df",
            "def combine_metrics_dicts(*metrics):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Combine metrics from dicts.\\n\\n    Args:\\n        metrics (dict): Metrics\\n\\n    Returns:\\n        pandas.DataFrame: Dataframe with metrics combined.\\n    '\n    df = pd.DataFrame(metrics[0], index=[0])\n    for metric in metrics[1:]:\n        df = df.append(pd.DataFrame(metric, index=[0]), sort=False)\n    return df"
        ]
    }
]