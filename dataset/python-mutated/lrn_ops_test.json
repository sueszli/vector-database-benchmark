[
    {
        "func_name": "_LRN",
        "original": "def _LRN(self, input_image, lrn_depth_radius=5, bias=1.0, alpha=1.0, beta=0.5):\n    \"\"\"Compute expected result.\"\"\"\n    output = copy.deepcopy(input_image)\n    batch_size = input_image.shape[0]\n    rows = input_image.shape[1]\n    cols = input_image.shape[2]\n    depth = input_image.shape[3]\n    for b in range(batch_size):\n        for r in range(rows):\n            for c in range(cols):\n                for d in range(depth):\n                    begin = max(0, d - lrn_depth_radius)\n                    end = min(depth, d + lrn_depth_radius + 1)\n                    patch = input_image[b, r, c, begin:end]\n                    output[b, r, c, d] /= np.power(bias + alpha * np.sum(patch * patch), beta)\n    return output",
        "mutated": [
            "def _LRN(self, input_image, lrn_depth_radius=5, bias=1.0, alpha=1.0, beta=0.5):\n    if False:\n        i = 10\n    'Compute expected result.'\n    output = copy.deepcopy(input_image)\n    batch_size = input_image.shape[0]\n    rows = input_image.shape[1]\n    cols = input_image.shape[2]\n    depth = input_image.shape[3]\n    for b in range(batch_size):\n        for r in range(rows):\n            for c in range(cols):\n                for d in range(depth):\n                    begin = max(0, d - lrn_depth_radius)\n                    end = min(depth, d + lrn_depth_radius + 1)\n                    patch = input_image[b, r, c, begin:end]\n                    output[b, r, c, d] /= np.power(bias + alpha * np.sum(patch * patch), beta)\n    return output",
            "def _LRN(self, input_image, lrn_depth_radius=5, bias=1.0, alpha=1.0, beta=0.5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Compute expected result.'\n    output = copy.deepcopy(input_image)\n    batch_size = input_image.shape[0]\n    rows = input_image.shape[1]\n    cols = input_image.shape[2]\n    depth = input_image.shape[3]\n    for b in range(batch_size):\n        for r in range(rows):\n            for c in range(cols):\n                for d in range(depth):\n                    begin = max(0, d - lrn_depth_radius)\n                    end = min(depth, d + lrn_depth_radius + 1)\n                    patch = input_image[b, r, c, begin:end]\n                    output[b, r, c, d] /= np.power(bias + alpha * np.sum(patch * patch), beta)\n    return output",
            "def _LRN(self, input_image, lrn_depth_radius=5, bias=1.0, alpha=1.0, beta=0.5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Compute expected result.'\n    output = copy.deepcopy(input_image)\n    batch_size = input_image.shape[0]\n    rows = input_image.shape[1]\n    cols = input_image.shape[2]\n    depth = input_image.shape[3]\n    for b in range(batch_size):\n        for r in range(rows):\n            for c in range(cols):\n                for d in range(depth):\n                    begin = max(0, d - lrn_depth_radius)\n                    end = min(depth, d + lrn_depth_radius + 1)\n                    patch = input_image[b, r, c, begin:end]\n                    output[b, r, c, d] /= np.power(bias + alpha * np.sum(patch * patch), beta)\n    return output",
            "def _LRN(self, input_image, lrn_depth_radius=5, bias=1.0, alpha=1.0, beta=0.5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Compute expected result.'\n    output = copy.deepcopy(input_image)\n    batch_size = input_image.shape[0]\n    rows = input_image.shape[1]\n    cols = input_image.shape[2]\n    depth = input_image.shape[3]\n    for b in range(batch_size):\n        for r in range(rows):\n            for c in range(cols):\n                for d in range(depth):\n                    begin = max(0, d - lrn_depth_radius)\n                    end = min(depth, d + lrn_depth_radius + 1)\n                    patch = input_image[b, r, c, begin:end]\n                    output[b, r, c, d] /= np.power(bias + alpha * np.sum(patch * patch), beta)\n    return output",
            "def _LRN(self, input_image, lrn_depth_radius=5, bias=1.0, alpha=1.0, beta=0.5):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Compute expected result.'\n    output = copy.deepcopy(input_image)\n    batch_size = input_image.shape[0]\n    rows = input_image.shape[1]\n    cols = input_image.shape[2]\n    depth = input_image.shape[3]\n    for b in range(batch_size):\n        for r in range(rows):\n            for c in range(cols):\n                for d in range(depth):\n                    begin = max(0, d - lrn_depth_radius)\n                    end = min(depth, d + lrn_depth_radius + 1)\n                    patch = input_image[b, r, c, begin:end]\n                    output[b, r, c, d] /= np.power(bias + alpha * np.sum(patch * patch), beta)\n    return output"
        ]
    },
    {
        "func_name": "_RunAndVerify",
        "original": "def _RunAndVerify(self, dtype):\n    with self.session():\n        shape = np.random.randint(1, 16, size=4)\n        shape[3] += 1\n        p = array_ops.placeholder(dtype, shape=shape)\n        lrn_depth_radius = np.random.randint(1, shape[3])\n        bias = 1.0 + np.random.rand()\n        alpha = 2.0 * np.random.rand()\n        beta = 2.0 * np.random.rand()\n        with self.test_scope():\n            lrn_t = nn.local_response_normalization(p, name='lrn', depth_radius=lrn_depth_radius, bias=bias, alpha=alpha, beta=beta)\n        params = {p: np.random.rand(*shape).astype('f')}\n        result = lrn_t.eval(feed_dict=params)\n    expected = self._LRN(params[p], lrn_depth_radius=lrn_depth_radius, bias=bias, alpha=alpha, beta=beta)\n    err = np.amax(np.abs(result - expected))\n    print('LRN error for bias ', bias, 'alpha ', alpha, ' beta ', beta, ' is ', err)\n    if dtype == dtypes.float32:\n        self.assertTrue(err < 0.0001)\n    else:\n        self.assertTrue(err < 0.01)\n    self.assertShapeEqual(expected, lrn_t)",
        "mutated": [
            "def _RunAndVerify(self, dtype):\n    if False:\n        i = 10\n    with self.session():\n        shape = np.random.randint(1, 16, size=4)\n        shape[3] += 1\n        p = array_ops.placeholder(dtype, shape=shape)\n        lrn_depth_radius = np.random.randint(1, shape[3])\n        bias = 1.0 + np.random.rand()\n        alpha = 2.0 * np.random.rand()\n        beta = 2.0 * np.random.rand()\n        with self.test_scope():\n            lrn_t = nn.local_response_normalization(p, name='lrn', depth_radius=lrn_depth_radius, bias=bias, alpha=alpha, beta=beta)\n        params = {p: np.random.rand(*shape).astype('f')}\n        result = lrn_t.eval(feed_dict=params)\n    expected = self._LRN(params[p], lrn_depth_radius=lrn_depth_radius, bias=bias, alpha=alpha, beta=beta)\n    err = np.amax(np.abs(result - expected))\n    print('LRN error for bias ', bias, 'alpha ', alpha, ' beta ', beta, ' is ', err)\n    if dtype == dtypes.float32:\n        self.assertTrue(err < 0.0001)\n    else:\n        self.assertTrue(err < 0.01)\n    self.assertShapeEqual(expected, lrn_t)",
            "def _RunAndVerify(self, dtype):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with self.session():\n        shape = np.random.randint(1, 16, size=4)\n        shape[3] += 1\n        p = array_ops.placeholder(dtype, shape=shape)\n        lrn_depth_radius = np.random.randint(1, shape[3])\n        bias = 1.0 + np.random.rand()\n        alpha = 2.0 * np.random.rand()\n        beta = 2.0 * np.random.rand()\n        with self.test_scope():\n            lrn_t = nn.local_response_normalization(p, name='lrn', depth_radius=lrn_depth_radius, bias=bias, alpha=alpha, beta=beta)\n        params = {p: np.random.rand(*shape).astype('f')}\n        result = lrn_t.eval(feed_dict=params)\n    expected = self._LRN(params[p], lrn_depth_radius=lrn_depth_radius, bias=bias, alpha=alpha, beta=beta)\n    err = np.amax(np.abs(result - expected))\n    print('LRN error for bias ', bias, 'alpha ', alpha, ' beta ', beta, ' is ', err)\n    if dtype == dtypes.float32:\n        self.assertTrue(err < 0.0001)\n    else:\n        self.assertTrue(err < 0.01)\n    self.assertShapeEqual(expected, lrn_t)",
            "def _RunAndVerify(self, dtype):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with self.session():\n        shape = np.random.randint(1, 16, size=4)\n        shape[3] += 1\n        p = array_ops.placeholder(dtype, shape=shape)\n        lrn_depth_radius = np.random.randint(1, shape[3])\n        bias = 1.0 + np.random.rand()\n        alpha = 2.0 * np.random.rand()\n        beta = 2.0 * np.random.rand()\n        with self.test_scope():\n            lrn_t = nn.local_response_normalization(p, name='lrn', depth_radius=lrn_depth_radius, bias=bias, alpha=alpha, beta=beta)\n        params = {p: np.random.rand(*shape).astype('f')}\n        result = lrn_t.eval(feed_dict=params)\n    expected = self._LRN(params[p], lrn_depth_radius=lrn_depth_radius, bias=bias, alpha=alpha, beta=beta)\n    err = np.amax(np.abs(result - expected))\n    print('LRN error for bias ', bias, 'alpha ', alpha, ' beta ', beta, ' is ', err)\n    if dtype == dtypes.float32:\n        self.assertTrue(err < 0.0001)\n    else:\n        self.assertTrue(err < 0.01)\n    self.assertShapeEqual(expected, lrn_t)",
            "def _RunAndVerify(self, dtype):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with self.session():\n        shape = np.random.randint(1, 16, size=4)\n        shape[3] += 1\n        p = array_ops.placeholder(dtype, shape=shape)\n        lrn_depth_radius = np.random.randint(1, shape[3])\n        bias = 1.0 + np.random.rand()\n        alpha = 2.0 * np.random.rand()\n        beta = 2.0 * np.random.rand()\n        with self.test_scope():\n            lrn_t = nn.local_response_normalization(p, name='lrn', depth_radius=lrn_depth_radius, bias=bias, alpha=alpha, beta=beta)\n        params = {p: np.random.rand(*shape).astype('f')}\n        result = lrn_t.eval(feed_dict=params)\n    expected = self._LRN(params[p], lrn_depth_radius=lrn_depth_radius, bias=bias, alpha=alpha, beta=beta)\n    err = np.amax(np.abs(result - expected))\n    print('LRN error for bias ', bias, 'alpha ', alpha, ' beta ', beta, ' is ', err)\n    if dtype == dtypes.float32:\n        self.assertTrue(err < 0.0001)\n    else:\n        self.assertTrue(err < 0.01)\n    self.assertShapeEqual(expected, lrn_t)",
            "def _RunAndVerify(self, dtype):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with self.session():\n        shape = np.random.randint(1, 16, size=4)\n        shape[3] += 1\n        p = array_ops.placeholder(dtype, shape=shape)\n        lrn_depth_radius = np.random.randint(1, shape[3])\n        bias = 1.0 + np.random.rand()\n        alpha = 2.0 * np.random.rand()\n        beta = 2.0 * np.random.rand()\n        with self.test_scope():\n            lrn_t = nn.local_response_normalization(p, name='lrn', depth_radius=lrn_depth_radius, bias=bias, alpha=alpha, beta=beta)\n        params = {p: np.random.rand(*shape).astype('f')}\n        result = lrn_t.eval(feed_dict=params)\n    expected = self._LRN(params[p], lrn_depth_radius=lrn_depth_radius, bias=bias, alpha=alpha, beta=beta)\n    err = np.amax(np.abs(result - expected))\n    print('LRN error for bias ', bias, 'alpha ', alpha, ' beta ', beta, ' is ', err)\n    if dtype == dtypes.float32:\n        self.assertTrue(err < 0.0001)\n    else:\n        self.assertTrue(err < 0.01)\n    self.assertShapeEqual(expected, lrn_t)"
        ]
    },
    {
        "func_name": "testCompute",
        "original": "def testCompute(self):\n    for _ in range(2):\n        self._RunAndVerify(dtypes.float32)",
        "mutated": [
            "def testCompute(self):\n    if False:\n        i = 10\n    for _ in range(2):\n        self._RunAndVerify(dtypes.float32)",
            "def testCompute(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    for _ in range(2):\n        self._RunAndVerify(dtypes.float32)",
            "def testCompute(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    for _ in range(2):\n        self._RunAndVerify(dtypes.float32)",
            "def testCompute(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    for _ in range(2):\n        self._RunAndVerify(dtypes.float32)",
            "def testCompute(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    for _ in range(2):\n        self._RunAndVerify(dtypes.float32)"
        ]
    },
    {
        "func_name": "testLrnGrad",
        "original": "def testLrnGrad(self):\n    shape = [1, 2, 3, 4]\n    total_size = np.prod(shape)\n    in_image_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    out_image_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    out_grads_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    depth_radius = np.random.randint(1, shape[3])\n    bias = 1.0 + np.random.rand()\n    alpha = 1.0 * np.random.rand()\n    beta = 1.0 * np.random.rand()\n    with self.session():\n        in_image = constant_op.constant(in_image_vals, shape=shape)\n        out_image = constant_op.constant(out_image_vals, shape=shape)\n        out_grads = constant_op.constant(out_grads_vals, shape=shape)\n        with ops.device(CPU_DEVICE):\n            expected = gen_nn_ops.lrn_grad(out_grads, in_image, out_image, depth_radius, bias, alpha, beta)\n        with self.test_scope():\n            actual = gen_nn_ops.lrn_grad(out_grads, in_image, out_image, depth_radius, bias, alpha, beta)\n        expected_val = self.evaluate(expected)\n        actual_val = self.evaluate(actual)\n    self.assertAllClose(actual_val, expected_val, rtol=0.001)",
        "mutated": [
            "def testLrnGrad(self):\n    if False:\n        i = 10\n    shape = [1, 2, 3, 4]\n    total_size = np.prod(shape)\n    in_image_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    out_image_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    out_grads_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    depth_radius = np.random.randint(1, shape[3])\n    bias = 1.0 + np.random.rand()\n    alpha = 1.0 * np.random.rand()\n    beta = 1.0 * np.random.rand()\n    with self.session():\n        in_image = constant_op.constant(in_image_vals, shape=shape)\n        out_image = constant_op.constant(out_image_vals, shape=shape)\n        out_grads = constant_op.constant(out_grads_vals, shape=shape)\n        with ops.device(CPU_DEVICE):\n            expected = gen_nn_ops.lrn_grad(out_grads, in_image, out_image, depth_radius, bias, alpha, beta)\n        with self.test_scope():\n            actual = gen_nn_ops.lrn_grad(out_grads, in_image, out_image, depth_radius, bias, alpha, beta)\n        expected_val = self.evaluate(expected)\n        actual_val = self.evaluate(actual)\n    self.assertAllClose(actual_val, expected_val, rtol=0.001)",
            "def testLrnGrad(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    shape = [1, 2, 3, 4]\n    total_size = np.prod(shape)\n    in_image_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    out_image_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    out_grads_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    depth_radius = np.random.randint(1, shape[3])\n    bias = 1.0 + np.random.rand()\n    alpha = 1.0 * np.random.rand()\n    beta = 1.0 * np.random.rand()\n    with self.session():\n        in_image = constant_op.constant(in_image_vals, shape=shape)\n        out_image = constant_op.constant(out_image_vals, shape=shape)\n        out_grads = constant_op.constant(out_grads_vals, shape=shape)\n        with ops.device(CPU_DEVICE):\n            expected = gen_nn_ops.lrn_grad(out_grads, in_image, out_image, depth_radius, bias, alpha, beta)\n        with self.test_scope():\n            actual = gen_nn_ops.lrn_grad(out_grads, in_image, out_image, depth_radius, bias, alpha, beta)\n        expected_val = self.evaluate(expected)\n        actual_val = self.evaluate(actual)\n    self.assertAllClose(actual_val, expected_val, rtol=0.001)",
            "def testLrnGrad(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    shape = [1, 2, 3, 4]\n    total_size = np.prod(shape)\n    in_image_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    out_image_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    out_grads_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    depth_radius = np.random.randint(1, shape[3])\n    bias = 1.0 + np.random.rand()\n    alpha = 1.0 * np.random.rand()\n    beta = 1.0 * np.random.rand()\n    with self.session():\n        in_image = constant_op.constant(in_image_vals, shape=shape)\n        out_image = constant_op.constant(out_image_vals, shape=shape)\n        out_grads = constant_op.constant(out_grads_vals, shape=shape)\n        with ops.device(CPU_DEVICE):\n            expected = gen_nn_ops.lrn_grad(out_grads, in_image, out_image, depth_radius, bias, alpha, beta)\n        with self.test_scope():\n            actual = gen_nn_ops.lrn_grad(out_grads, in_image, out_image, depth_radius, bias, alpha, beta)\n        expected_val = self.evaluate(expected)\n        actual_val = self.evaluate(actual)\n    self.assertAllClose(actual_val, expected_val, rtol=0.001)",
            "def testLrnGrad(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    shape = [1, 2, 3, 4]\n    total_size = np.prod(shape)\n    in_image_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    out_image_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    out_grads_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    depth_radius = np.random.randint(1, shape[3])\n    bias = 1.0 + np.random.rand()\n    alpha = 1.0 * np.random.rand()\n    beta = 1.0 * np.random.rand()\n    with self.session():\n        in_image = constant_op.constant(in_image_vals, shape=shape)\n        out_image = constant_op.constant(out_image_vals, shape=shape)\n        out_grads = constant_op.constant(out_grads_vals, shape=shape)\n        with ops.device(CPU_DEVICE):\n            expected = gen_nn_ops.lrn_grad(out_grads, in_image, out_image, depth_radius, bias, alpha, beta)\n        with self.test_scope():\n            actual = gen_nn_ops.lrn_grad(out_grads, in_image, out_image, depth_radius, bias, alpha, beta)\n        expected_val = self.evaluate(expected)\n        actual_val = self.evaluate(actual)\n    self.assertAllClose(actual_val, expected_val, rtol=0.001)",
            "def testLrnGrad(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    shape = [1, 2, 3, 4]\n    total_size = np.prod(shape)\n    in_image_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    out_image_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    out_grads_vals = np.arange(1, total_size + 1, dtype=np.float32)\n    depth_radius = np.random.randint(1, shape[3])\n    bias = 1.0 + np.random.rand()\n    alpha = 1.0 * np.random.rand()\n    beta = 1.0 * np.random.rand()\n    with self.session():\n        in_image = constant_op.constant(in_image_vals, shape=shape)\n        out_image = constant_op.constant(out_image_vals, shape=shape)\n        out_grads = constant_op.constant(out_grads_vals, shape=shape)\n        with ops.device(CPU_DEVICE):\n            expected = gen_nn_ops.lrn_grad(out_grads, in_image, out_image, depth_radius, bias, alpha, beta)\n        with self.test_scope():\n            actual = gen_nn_ops.lrn_grad(out_grads, in_image, out_image, depth_radius, bias, alpha, beta)\n        expected_val = self.evaluate(expected)\n        actual_val = self.evaluate(actual)\n    self.assertAllClose(actual_val, expected_val, rtol=0.001)"
        ]
    }
]