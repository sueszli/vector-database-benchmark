from pyspark.sql import SparkSession, Catalog

def sql_catalog_example(spark):
    if False:
        for i in range(10):
            print('nop')
    catalog = Catalog(spark)
    table_df = catalog.createTable('table', '/ppml/spark-3.1.3/examples/src/main/resources/people.txt', 'text')
    table_df.show()
    print('createTable API finished')
    cur_db = catalog.currentDatabase()
    print('current database: {}'.format(cur_db))
    print('currentDatabase API finished')
    catalog.createTable('table3', '/ppml/spark-3.1.3/examples/src/main/resources/people.txt', 'text')
    spark.sql('select * from table3').show()
    print('createTable API finished')
    catalog.listColumns('table3')
    print('listColumns API finished')
    catalog.listTables()
    catalog.listTables(dbName='default')
    print('listTables API finished')
    spark.createDataFrame([(1, 1)]).createTempView('my_table')
    spark.table('my_table').show()
    catalog.dropTempView('my_table')
    print('dropTempView API finished')
    spark.createDataFrame([(1, 1)]).createGlobalTempView('my_table')
    spark.table('global_temp.my_table').show()
    catalog.dropGlobalTempView('my_table')
    print('dropGlobalTempView API finished')
    print('table3 is cached: {}'.format(catalog.isCached('table3')))
    catalog.cacheTable('table3')
    print('table3 is cached: {}'.format(catalog.isCached('table3')))
    print('cacheTable & isCached API finished')
    catalog.uncacheTable('table3')
    print('table3 is cached: {}'.format(catalog.isCached('table3')))
    print('uncacheTable API finished')
    catalog.cacheTable('table')
    catalog.cacheTable('table3')
    catalog.clearCache()
    print('table is cached: {}'.format(catalog.isCached('table')))
    print('table3 is cached: {}'.format(catalog.isCached('table3')))
    print('clearCache API finished')
    funs = catalog.listFunctions()
    funs1 = catalog.listFunctions('default')
    print('there are {} functions registed on this db'.format(funs1))
    print('listFunctions API finished')
    catalog.setCurrentDatabase('default')
    print('setCurrentDatabase API finished')
    spark.stop()
    print('Finish running Catalog API')
if __name__ == '__main__':
    spark = SparkSession.builder.appName('Python Spark SQL Catalog example').config('spark.some.config.option', 'some-value').getOrCreate()
    sql_catalog_example(spark)