[
    {
        "func_name": "init_query_builder",
        "original": "def init_query_builder(params, transaction, regression_breakpoint, limit, span_score_threshold):\n    before_minutes = int((regression_breakpoint - params['start']).total_seconds() // 60)\n    after_minutes = int((params['end'] - regression_breakpoint).total_seconds() // 60)\n    selected_columns = ['percentileArray(spans_exclusive_time, 0.95) as p95_self_time', 'array_join(spans_op) as span_op', 'array_join(spans_group) as span_group', 'any(id) as sample_event_id']\n    builder = QueryBuilder(dataset=Dataset.Discover, params=params, selected_columns=selected_columns, equations=[], query=f'event.type:transaction transaction:\"{transaction}\"', limit=limit, config=QueryBuilderConfig(auto_aggregations=True, use_aggregate_conditions=True, functions_acl=['array_join', 'percentileArray']))\n    p95_before_function = Function('quantileIf(0.95)', [Function('tupleElement', [Column('snuba_all_spans'), 3]), Function('less', [Column('timestamp'), regression_breakpoint])])\n    builder.columns.append(Function('if', [Function('isNaN', [p95_before_function]), 0, p95_before_function], 'p95_before'))\n    p95_after_function = Function('quantileIf(0.95)', [Function('tupleElement', [Column('snuba_all_spans'), 3]), Function('greater', [Column('timestamp'), regression_breakpoint])])\n    builder.columns.append(Function('if', [Function('isNaN', [p95_after_function]), 0, p95_after_function], 'p95_after'))\n    builder.columns.append(Function('divide', [Function('countIf', [Function('less', [Column('timestamp'), regression_breakpoint])]), before_minutes], 'spm_before'))\n    builder.columns.append(Function('divide', [Function('countIf', [Function('greater', [Column('timestamp'), regression_breakpoint])]), after_minutes], 'spm_after'))\n    builder.columns.append(Function('minus', [Function('multiply', [Column('spm_after'), Column('p95_after')]), Function('multiply', [Column('spm_before'), Column('p95_before')])], 'score'))\n    builder.where.append(Or([Condition(Column('timestamp'), Op.LT, regression_breakpoint - BUFFER), Condition(Column('timestamp'), Op.GT, regression_breakpoint + BUFFER)]))\n    builder.having.append(Condition(Column('score'), Op.GTE, span_score_threshold))\n    builder.orderby = [OrderBy(Column('score'), Direction.DESC)]\n    return builder",
        "mutated": [
            "def init_query_builder(params, transaction, regression_breakpoint, limit, span_score_threshold):\n    if False:\n        i = 10\n    before_minutes = int((regression_breakpoint - params['start']).total_seconds() // 60)\n    after_minutes = int((params['end'] - regression_breakpoint).total_seconds() // 60)\n    selected_columns = ['percentileArray(spans_exclusive_time, 0.95) as p95_self_time', 'array_join(spans_op) as span_op', 'array_join(spans_group) as span_group', 'any(id) as sample_event_id']\n    builder = QueryBuilder(dataset=Dataset.Discover, params=params, selected_columns=selected_columns, equations=[], query=f'event.type:transaction transaction:\"{transaction}\"', limit=limit, config=QueryBuilderConfig(auto_aggregations=True, use_aggregate_conditions=True, functions_acl=['array_join', 'percentileArray']))\n    p95_before_function = Function('quantileIf(0.95)', [Function('tupleElement', [Column('snuba_all_spans'), 3]), Function('less', [Column('timestamp'), regression_breakpoint])])\n    builder.columns.append(Function('if', [Function('isNaN', [p95_before_function]), 0, p95_before_function], 'p95_before'))\n    p95_after_function = Function('quantileIf(0.95)', [Function('tupleElement', [Column('snuba_all_spans'), 3]), Function('greater', [Column('timestamp'), regression_breakpoint])])\n    builder.columns.append(Function('if', [Function('isNaN', [p95_after_function]), 0, p95_after_function], 'p95_after'))\n    builder.columns.append(Function('divide', [Function('countIf', [Function('less', [Column('timestamp'), regression_breakpoint])]), before_minutes], 'spm_before'))\n    builder.columns.append(Function('divide', [Function('countIf', [Function('greater', [Column('timestamp'), regression_breakpoint])]), after_minutes], 'spm_after'))\n    builder.columns.append(Function('minus', [Function('multiply', [Column('spm_after'), Column('p95_after')]), Function('multiply', [Column('spm_before'), Column('p95_before')])], 'score'))\n    builder.where.append(Or([Condition(Column('timestamp'), Op.LT, regression_breakpoint - BUFFER), Condition(Column('timestamp'), Op.GT, regression_breakpoint + BUFFER)]))\n    builder.having.append(Condition(Column('score'), Op.GTE, span_score_threshold))\n    builder.orderby = [OrderBy(Column('score'), Direction.DESC)]\n    return builder",
            "def init_query_builder(params, transaction, regression_breakpoint, limit, span_score_threshold):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    before_minutes = int((regression_breakpoint - params['start']).total_seconds() // 60)\n    after_minutes = int((params['end'] - regression_breakpoint).total_seconds() // 60)\n    selected_columns = ['percentileArray(spans_exclusive_time, 0.95) as p95_self_time', 'array_join(spans_op) as span_op', 'array_join(spans_group) as span_group', 'any(id) as sample_event_id']\n    builder = QueryBuilder(dataset=Dataset.Discover, params=params, selected_columns=selected_columns, equations=[], query=f'event.type:transaction transaction:\"{transaction}\"', limit=limit, config=QueryBuilderConfig(auto_aggregations=True, use_aggregate_conditions=True, functions_acl=['array_join', 'percentileArray']))\n    p95_before_function = Function('quantileIf(0.95)', [Function('tupleElement', [Column('snuba_all_spans'), 3]), Function('less', [Column('timestamp'), regression_breakpoint])])\n    builder.columns.append(Function('if', [Function('isNaN', [p95_before_function]), 0, p95_before_function], 'p95_before'))\n    p95_after_function = Function('quantileIf(0.95)', [Function('tupleElement', [Column('snuba_all_spans'), 3]), Function('greater', [Column('timestamp'), regression_breakpoint])])\n    builder.columns.append(Function('if', [Function('isNaN', [p95_after_function]), 0, p95_after_function], 'p95_after'))\n    builder.columns.append(Function('divide', [Function('countIf', [Function('less', [Column('timestamp'), regression_breakpoint])]), before_minutes], 'spm_before'))\n    builder.columns.append(Function('divide', [Function('countIf', [Function('greater', [Column('timestamp'), regression_breakpoint])]), after_minutes], 'spm_after'))\n    builder.columns.append(Function('minus', [Function('multiply', [Column('spm_after'), Column('p95_after')]), Function('multiply', [Column('spm_before'), Column('p95_before')])], 'score'))\n    builder.where.append(Or([Condition(Column('timestamp'), Op.LT, regression_breakpoint - BUFFER), Condition(Column('timestamp'), Op.GT, regression_breakpoint + BUFFER)]))\n    builder.having.append(Condition(Column('score'), Op.GTE, span_score_threshold))\n    builder.orderby = [OrderBy(Column('score'), Direction.DESC)]\n    return builder",
            "def init_query_builder(params, transaction, regression_breakpoint, limit, span_score_threshold):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    before_minutes = int((regression_breakpoint - params['start']).total_seconds() // 60)\n    after_minutes = int((params['end'] - regression_breakpoint).total_seconds() // 60)\n    selected_columns = ['percentileArray(spans_exclusive_time, 0.95) as p95_self_time', 'array_join(spans_op) as span_op', 'array_join(spans_group) as span_group', 'any(id) as sample_event_id']\n    builder = QueryBuilder(dataset=Dataset.Discover, params=params, selected_columns=selected_columns, equations=[], query=f'event.type:transaction transaction:\"{transaction}\"', limit=limit, config=QueryBuilderConfig(auto_aggregations=True, use_aggregate_conditions=True, functions_acl=['array_join', 'percentileArray']))\n    p95_before_function = Function('quantileIf(0.95)', [Function('tupleElement', [Column('snuba_all_spans'), 3]), Function('less', [Column('timestamp'), regression_breakpoint])])\n    builder.columns.append(Function('if', [Function('isNaN', [p95_before_function]), 0, p95_before_function], 'p95_before'))\n    p95_after_function = Function('quantileIf(0.95)', [Function('tupleElement', [Column('snuba_all_spans'), 3]), Function('greater', [Column('timestamp'), regression_breakpoint])])\n    builder.columns.append(Function('if', [Function('isNaN', [p95_after_function]), 0, p95_after_function], 'p95_after'))\n    builder.columns.append(Function('divide', [Function('countIf', [Function('less', [Column('timestamp'), regression_breakpoint])]), before_minutes], 'spm_before'))\n    builder.columns.append(Function('divide', [Function('countIf', [Function('greater', [Column('timestamp'), regression_breakpoint])]), after_minutes], 'spm_after'))\n    builder.columns.append(Function('minus', [Function('multiply', [Column('spm_after'), Column('p95_after')]), Function('multiply', [Column('spm_before'), Column('p95_before')])], 'score'))\n    builder.where.append(Or([Condition(Column('timestamp'), Op.LT, regression_breakpoint - BUFFER), Condition(Column('timestamp'), Op.GT, regression_breakpoint + BUFFER)]))\n    builder.having.append(Condition(Column('score'), Op.GTE, span_score_threshold))\n    builder.orderby = [OrderBy(Column('score'), Direction.DESC)]\n    return builder",
            "def init_query_builder(params, transaction, regression_breakpoint, limit, span_score_threshold):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    before_minutes = int((regression_breakpoint - params['start']).total_seconds() // 60)\n    after_minutes = int((params['end'] - regression_breakpoint).total_seconds() // 60)\n    selected_columns = ['percentileArray(spans_exclusive_time, 0.95) as p95_self_time', 'array_join(spans_op) as span_op', 'array_join(spans_group) as span_group', 'any(id) as sample_event_id']\n    builder = QueryBuilder(dataset=Dataset.Discover, params=params, selected_columns=selected_columns, equations=[], query=f'event.type:transaction transaction:\"{transaction}\"', limit=limit, config=QueryBuilderConfig(auto_aggregations=True, use_aggregate_conditions=True, functions_acl=['array_join', 'percentileArray']))\n    p95_before_function = Function('quantileIf(0.95)', [Function('tupleElement', [Column('snuba_all_spans'), 3]), Function('less', [Column('timestamp'), regression_breakpoint])])\n    builder.columns.append(Function('if', [Function('isNaN', [p95_before_function]), 0, p95_before_function], 'p95_before'))\n    p95_after_function = Function('quantileIf(0.95)', [Function('tupleElement', [Column('snuba_all_spans'), 3]), Function('greater', [Column('timestamp'), regression_breakpoint])])\n    builder.columns.append(Function('if', [Function('isNaN', [p95_after_function]), 0, p95_after_function], 'p95_after'))\n    builder.columns.append(Function('divide', [Function('countIf', [Function('less', [Column('timestamp'), regression_breakpoint])]), before_minutes], 'spm_before'))\n    builder.columns.append(Function('divide', [Function('countIf', [Function('greater', [Column('timestamp'), regression_breakpoint])]), after_minutes], 'spm_after'))\n    builder.columns.append(Function('minus', [Function('multiply', [Column('spm_after'), Column('p95_after')]), Function('multiply', [Column('spm_before'), Column('p95_before')])], 'score'))\n    builder.where.append(Or([Condition(Column('timestamp'), Op.LT, regression_breakpoint - BUFFER), Condition(Column('timestamp'), Op.GT, regression_breakpoint + BUFFER)]))\n    builder.having.append(Condition(Column('score'), Op.GTE, span_score_threshold))\n    builder.orderby = [OrderBy(Column('score'), Direction.DESC)]\n    return builder",
            "def init_query_builder(params, transaction, regression_breakpoint, limit, span_score_threshold):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    before_minutes = int((regression_breakpoint - params['start']).total_seconds() // 60)\n    after_minutes = int((params['end'] - regression_breakpoint).total_seconds() // 60)\n    selected_columns = ['percentileArray(spans_exclusive_time, 0.95) as p95_self_time', 'array_join(spans_op) as span_op', 'array_join(spans_group) as span_group', 'any(id) as sample_event_id']\n    builder = QueryBuilder(dataset=Dataset.Discover, params=params, selected_columns=selected_columns, equations=[], query=f'event.type:transaction transaction:\"{transaction}\"', limit=limit, config=QueryBuilderConfig(auto_aggregations=True, use_aggregate_conditions=True, functions_acl=['array_join', 'percentileArray']))\n    p95_before_function = Function('quantileIf(0.95)', [Function('tupleElement', [Column('snuba_all_spans'), 3]), Function('less', [Column('timestamp'), regression_breakpoint])])\n    builder.columns.append(Function('if', [Function('isNaN', [p95_before_function]), 0, p95_before_function], 'p95_before'))\n    p95_after_function = Function('quantileIf(0.95)', [Function('tupleElement', [Column('snuba_all_spans'), 3]), Function('greater', [Column('timestamp'), regression_breakpoint])])\n    builder.columns.append(Function('if', [Function('isNaN', [p95_after_function]), 0, p95_after_function], 'p95_after'))\n    builder.columns.append(Function('divide', [Function('countIf', [Function('less', [Column('timestamp'), regression_breakpoint])]), before_minutes], 'spm_before'))\n    builder.columns.append(Function('divide', [Function('countIf', [Function('greater', [Column('timestamp'), regression_breakpoint])]), after_minutes], 'spm_after'))\n    builder.columns.append(Function('minus', [Function('multiply', [Column('spm_after'), Column('p95_after')]), Function('multiply', [Column('spm_before'), Column('p95_before')])], 'score'))\n    builder.where.append(Or([Condition(Column('timestamp'), Op.LT, regression_breakpoint - BUFFER), Condition(Column('timestamp'), Op.GT, regression_breakpoint + BUFFER)]))\n    builder.having.append(Condition(Column('score'), Op.GTE, span_score_threshold))\n    builder.orderby = [OrderBy(Column('score'), Direction.DESC)]\n    return builder"
        ]
    },
    {
        "func_name": "query_spans",
        "original": "def query_spans(transaction, regression_breakpoint, params, limit, span_score_threshold):\n    referrer = f'{BASE_REFERRER}-{SPAN_ANALYSIS}'\n    snuba_results = raw_snql_query(init_query_builder(params, transaction, regression_breakpoint, limit, span_score_threshold).get_snql_query(), referrer)\n    return snuba_results.get('data')",
        "mutated": [
            "def query_spans(transaction, regression_breakpoint, params, limit, span_score_threshold):\n    if False:\n        i = 10\n    referrer = f'{BASE_REFERRER}-{SPAN_ANALYSIS}'\n    snuba_results = raw_snql_query(init_query_builder(params, transaction, regression_breakpoint, limit, span_score_threshold).get_snql_query(), referrer)\n    return snuba_results.get('data')",
            "def query_spans(transaction, regression_breakpoint, params, limit, span_score_threshold):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    referrer = f'{BASE_REFERRER}-{SPAN_ANALYSIS}'\n    snuba_results = raw_snql_query(init_query_builder(params, transaction, regression_breakpoint, limit, span_score_threshold).get_snql_query(), referrer)\n    return snuba_results.get('data')",
            "def query_spans(transaction, regression_breakpoint, params, limit, span_score_threshold):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    referrer = f'{BASE_REFERRER}-{SPAN_ANALYSIS}'\n    snuba_results = raw_snql_query(init_query_builder(params, transaction, regression_breakpoint, limit, span_score_threshold).get_snql_query(), referrer)\n    return snuba_results.get('data')",
            "def query_spans(transaction, regression_breakpoint, params, limit, span_score_threshold):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    referrer = f'{BASE_REFERRER}-{SPAN_ANALYSIS}'\n    snuba_results = raw_snql_query(init_query_builder(params, transaction, regression_breakpoint, limit, span_score_threshold).get_snql_query(), referrer)\n    return snuba_results.get('data')",
            "def query_spans(transaction, regression_breakpoint, params, limit, span_score_threshold):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    referrer = f'{BASE_REFERRER}-{SPAN_ANALYSIS}'\n    snuba_results = raw_snql_query(init_query_builder(params, transaction, regression_breakpoint, limit, span_score_threshold).get_snql_query(), referrer)\n    return snuba_results.get('data')"
        ]
    },
    {
        "func_name": "fetch_span_analysis_results",
        "original": "def fetch_span_analysis_results(transaction_name, regression_breakpoint, params, project_id, limit, span_score_threshold):\n    span_data = query_spans(transaction=transaction_name, regression_breakpoint=regression_breakpoint, params=params, limit=limit, span_score_threshold=span_score_threshold)\n    for result in span_data:\n        result['span_description'] = get_span_description(EventID(project_id, result['sample_event_id']), result['span_op'], result['span_group'])\n    return [{key: row[key] for key in RESPONSE_KEYS} for row in span_data]",
        "mutated": [
            "def fetch_span_analysis_results(transaction_name, regression_breakpoint, params, project_id, limit, span_score_threshold):\n    if False:\n        i = 10\n    span_data = query_spans(transaction=transaction_name, regression_breakpoint=regression_breakpoint, params=params, limit=limit, span_score_threshold=span_score_threshold)\n    for result in span_data:\n        result['span_description'] = get_span_description(EventID(project_id, result['sample_event_id']), result['span_op'], result['span_group'])\n    return [{key: row[key] for key in RESPONSE_KEYS} for row in span_data]",
            "def fetch_span_analysis_results(transaction_name, regression_breakpoint, params, project_id, limit, span_score_threshold):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    span_data = query_spans(transaction=transaction_name, regression_breakpoint=regression_breakpoint, params=params, limit=limit, span_score_threshold=span_score_threshold)\n    for result in span_data:\n        result['span_description'] = get_span_description(EventID(project_id, result['sample_event_id']), result['span_op'], result['span_group'])\n    return [{key: row[key] for key in RESPONSE_KEYS} for row in span_data]",
            "def fetch_span_analysis_results(transaction_name, regression_breakpoint, params, project_id, limit, span_score_threshold):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    span_data = query_spans(transaction=transaction_name, regression_breakpoint=regression_breakpoint, params=params, limit=limit, span_score_threshold=span_score_threshold)\n    for result in span_data:\n        result['span_description'] = get_span_description(EventID(project_id, result['sample_event_id']), result['span_op'], result['span_group'])\n    return [{key: row[key] for key in RESPONSE_KEYS} for row in span_data]",
            "def fetch_span_analysis_results(transaction_name, regression_breakpoint, params, project_id, limit, span_score_threshold):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    span_data = query_spans(transaction=transaction_name, regression_breakpoint=regression_breakpoint, params=params, limit=limit, span_score_threshold=span_score_threshold)\n    for result in span_data:\n        result['span_description'] = get_span_description(EventID(project_id, result['sample_event_id']), result['span_op'], result['span_group'])\n    return [{key: row[key] for key in RESPONSE_KEYS} for row in span_data]",
            "def fetch_span_analysis_results(transaction_name, regression_breakpoint, params, project_id, limit, span_score_threshold):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    span_data = query_spans(transaction=transaction_name, regression_breakpoint=regression_breakpoint, params=params, limit=limit, span_score_threshold=span_score_threshold)\n    for result in span_data:\n        result['span_description'] = get_span_description(EventID(project_id, result['sample_event_id']), result['span_op'], result['span_group'])\n    return [{key: row[key] for key in RESPONSE_KEYS} for row in span_data]"
        ]
    },
    {
        "func_name": "get_geo_data",
        "original": "def get_geo_data(period):\n    adjusted_params = {**params}\n    if period == 'before':\n        adjusted_params['end'] = regression_breakpoint - BUFFER\n    else:\n        adjusted_params['start'] = regression_breakpoint + BUFFER\n    geo_code_durations = metrics_query(['p95(transaction.duration)', 'geo.country_code', 'tpm()'], f'event.type:transaction transaction:{transaction_name}', adjusted_params, referrer=f'{BASE_REFERRER}-{GEO_ANALYSIS}', limit=METRICS_MAX_LIMIT, orderby=['-tpm()'])\n    return geo_code_durations",
        "mutated": [
            "def get_geo_data(period):\n    if False:\n        i = 10\n    adjusted_params = {**params}\n    if period == 'before':\n        adjusted_params['end'] = regression_breakpoint - BUFFER\n    else:\n        adjusted_params['start'] = regression_breakpoint + BUFFER\n    geo_code_durations = metrics_query(['p95(transaction.duration)', 'geo.country_code', 'tpm()'], f'event.type:transaction transaction:{transaction_name}', adjusted_params, referrer=f'{BASE_REFERRER}-{GEO_ANALYSIS}', limit=METRICS_MAX_LIMIT, orderby=['-tpm()'])\n    return geo_code_durations",
            "def get_geo_data(period):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    adjusted_params = {**params}\n    if period == 'before':\n        adjusted_params['end'] = regression_breakpoint - BUFFER\n    else:\n        adjusted_params['start'] = regression_breakpoint + BUFFER\n    geo_code_durations = metrics_query(['p95(transaction.duration)', 'geo.country_code', 'tpm()'], f'event.type:transaction transaction:{transaction_name}', adjusted_params, referrer=f'{BASE_REFERRER}-{GEO_ANALYSIS}', limit=METRICS_MAX_LIMIT, orderby=['-tpm()'])\n    return geo_code_durations",
            "def get_geo_data(period):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    adjusted_params = {**params}\n    if period == 'before':\n        adjusted_params['end'] = regression_breakpoint - BUFFER\n    else:\n        adjusted_params['start'] = regression_breakpoint + BUFFER\n    geo_code_durations = metrics_query(['p95(transaction.duration)', 'geo.country_code', 'tpm()'], f'event.type:transaction transaction:{transaction_name}', adjusted_params, referrer=f'{BASE_REFERRER}-{GEO_ANALYSIS}', limit=METRICS_MAX_LIMIT, orderby=['-tpm()'])\n    return geo_code_durations",
            "def get_geo_data(period):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    adjusted_params = {**params}\n    if period == 'before':\n        adjusted_params['end'] = regression_breakpoint - BUFFER\n    else:\n        adjusted_params['start'] = regression_breakpoint + BUFFER\n    geo_code_durations = metrics_query(['p95(transaction.duration)', 'geo.country_code', 'tpm()'], f'event.type:transaction transaction:{transaction_name}', adjusted_params, referrer=f'{BASE_REFERRER}-{GEO_ANALYSIS}', limit=METRICS_MAX_LIMIT, orderby=['-tpm()'])\n    return geo_code_durations",
            "def get_geo_data(period):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    adjusted_params = {**params}\n    if period == 'before':\n        adjusted_params['end'] = regression_breakpoint - BUFFER\n    else:\n        adjusted_params['start'] = regression_breakpoint + BUFFER\n    geo_code_durations = metrics_query(['p95(transaction.duration)', 'geo.country_code', 'tpm()'], f'event.type:transaction transaction:{transaction_name}', adjusted_params, referrer=f'{BASE_REFERRER}-{GEO_ANALYSIS}', limit=METRICS_MAX_LIMIT, orderby=['-tpm()'])\n    return geo_code_durations"
        ]
    },
    {
        "func_name": "fetch_geo_analysis_results",
        "original": "def fetch_geo_analysis_results(transaction_name, regression_breakpoint, params, limit):\n\n    def get_geo_data(period):\n        adjusted_params = {**params}\n        if period == 'before':\n            adjusted_params['end'] = regression_breakpoint - BUFFER\n        else:\n            adjusted_params['start'] = regression_breakpoint + BUFFER\n        geo_code_durations = metrics_query(['p95(transaction.duration)', 'geo.country_code', 'tpm()'], f'event.type:transaction transaction:{transaction_name}', adjusted_params, referrer=f'{BASE_REFERRER}-{GEO_ANALYSIS}', limit=METRICS_MAX_LIMIT, orderby=['-tpm()'])\n        return geo_code_durations\n    geo_results = [get_geo_data('before'), get_geo_data('after')]\n    for (index, result) in enumerate(geo_results):\n        geo_results[index] = {f\"{data.get('geo.country_code')}\": data for data in result.get('data')}\n    (before_results, after_results) = geo_results\n    changed_keys = set(before_results.keys()) & set(after_results.keys())\n    new_keys = set(after_results.keys()) - set(before_results.keys())\n    analysis_results = []\n    for key in changed_keys | new_keys:\n        if key == '':\n            continue\n        duration_before = before_results[key]['p95_transaction_duration'] if before_results.get(key) else 0.0\n        duration_after = after_results[key]['p95_transaction_duration']\n        if duration_after > duration_before:\n            duration_delta = duration_after - duration_before\n            analysis_results.append({'geo.country_code': key, 'duration_before': duration_before, 'duration_after': duration_after, 'duration_delta': duration_delta, 'score': duration_delta * after_results[key]['tpm']})\n    analysis_results.sort(key=lambda x: x['score'], reverse=True)\n    return analysis_results[:limit]",
        "mutated": [
            "def fetch_geo_analysis_results(transaction_name, regression_breakpoint, params, limit):\n    if False:\n        i = 10\n\n    def get_geo_data(period):\n        adjusted_params = {**params}\n        if period == 'before':\n            adjusted_params['end'] = regression_breakpoint - BUFFER\n        else:\n            adjusted_params['start'] = regression_breakpoint + BUFFER\n        geo_code_durations = metrics_query(['p95(transaction.duration)', 'geo.country_code', 'tpm()'], f'event.type:transaction transaction:{transaction_name}', adjusted_params, referrer=f'{BASE_REFERRER}-{GEO_ANALYSIS}', limit=METRICS_MAX_LIMIT, orderby=['-tpm()'])\n        return geo_code_durations\n    geo_results = [get_geo_data('before'), get_geo_data('after')]\n    for (index, result) in enumerate(geo_results):\n        geo_results[index] = {f\"{data.get('geo.country_code')}\": data for data in result.get('data')}\n    (before_results, after_results) = geo_results\n    changed_keys = set(before_results.keys()) & set(after_results.keys())\n    new_keys = set(after_results.keys()) - set(before_results.keys())\n    analysis_results = []\n    for key in changed_keys | new_keys:\n        if key == '':\n            continue\n        duration_before = before_results[key]['p95_transaction_duration'] if before_results.get(key) else 0.0\n        duration_after = after_results[key]['p95_transaction_duration']\n        if duration_after > duration_before:\n            duration_delta = duration_after - duration_before\n            analysis_results.append({'geo.country_code': key, 'duration_before': duration_before, 'duration_after': duration_after, 'duration_delta': duration_delta, 'score': duration_delta * after_results[key]['tpm']})\n    analysis_results.sort(key=lambda x: x['score'], reverse=True)\n    return analysis_results[:limit]",
            "def fetch_geo_analysis_results(transaction_name, regression_breakpoint, params, limit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n\n    def get_geo_data(period):\n        adjusted_params = {**params}\n        if period == 'before':\n            adjusted_params['end'] = regression_breakpoint - BUFFER\n        else:\n            adjusted_params['start'] = regression_breakpoint + BUFFER\n        geo_code_durations = metrics_query(['p95(transaction.duration)', 'geo.country_code', 'tpm()'], f'event.type:transaction transaction:{transaction_name}', adjusted_params, referrer=f'{BASE_REFERRER}-{GEO_ANALYSIS}', limit=METRICS_MAX_LIMIT, orderby=['-tpm()'])\n        return geo_code_durations\n    geo_results = [get_geo_data('before'), get_geo_data('after')]\n    for (index, result) in enumerate(geo_results):\n        geo_results[index] = {f\"{data.get('geo.country_code')}\": data for data in result.get('data')}\n    (before_results, after_results) = geo_results\n    changed_keys = set(before_results.keys()) & set(after_results.keys())\n    new_keys = set(after_results.keys()) - set(before_results.keys())\n    analysis_results = []\n    for key in changed_keys | new_keys:\n        if key == '':\n            continue\n        duration_before = before_results[key]['p95_transaction_duration'] if before_results.get(key) else 0.0\n        duration_after = after_results[key]['p95_transaction_duration']\n        if duration_after > duration_before:\n            duration_delta = duration_after - duration_before\n            analysis_results.append({'geo.country_code': key, 'duration_before': duration_before, 'duration_after': duration_after, 'duration_delta': duration_delta, 'score': duration_delta * after_results[key]['tpm']})\n    analysis_results.sort(key=lambda x: x['score'], reverse=True)\n    return analysis_results[:limit]",
            "def fetch_geo_analysis_results(transaction_name, regression_breakpoint, params, limit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n    def get_geo_data(period):\n        adjusted_params = {**params}\n        if period == 'before':\n            adjusted_params['end'] = regression_breakpoint - BUFFER\n        else:\n            adjusted_params['start'] = regression_breakpoint + BUFFER\n        geo_code_durations = metrics_query(['p95(transaction.duration)', 'geo.country_code', 'tpm()'], f'event.type:transaction transaction:{transaction_name}', adjusted_params, referrer=f'{BASE_REFERRER}-{GEO_ANALYSIS}', limit=METRICS_MAX_LIMIT, orderby=['-tpm()'])\n        return geo_code_durations\n    geo_results = [get_geo_data('before'), get_geo_data('after')]\n    for (index, result) in enumerate(geo_results):\n        geo_results[index] = {f\"{data.get('geo.country_code')}\": data for data in result.get('data')}\n    (before_results, after_results) = geo_results\n    changed_keys = set(before_results.keys()) & set(after_results.keys())\n    new_keys = set(after_results.keys()) - set(before_results.keys())\n    analysis_results = []\n    for key in changed_keys | new_keys:\n        if key == '':\n            continue\n        duration_before = before_results[key]['p95_transaction_duration'] if before_results.get(key) else 0.0\n        duration_after = after_results[key]['p95_transaction_duration']\n        if duration_after > duration_before:\n            duration_delta = duration_after - duration_before\n            analysis_results.append({'geo.country_code': key, 'duration_before': duration_before, 'duration_after': duration_after, 'duration_delta': duration_delta, 'score': duration_delta * after_results[key]['tpm']})\n    analysis_results.sort(key=lambda x: x['score'], reverse=True)\n    return analysis_results[:limit]",
            "def fetch_geo_analysis_results(transaction_name, regression_breakpoint, params, limit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n\n    def get_geo_data(period):\n        adjusted_params = {**params}\n        if period == 'before':\n            adjusted_params['end'] = regression_breakpoint - BUFFER\n        else:\n            adjusted_params['start'] = regression_breakpoint + BUFFER\n        geo_code_durations = metrics_query(['p95(transaction.duration)', 'geo.country_code', 'tpm()'], f'event.type:transaction transaction:{transaction_name}', adjusted_params, referrer=f'{BASE_REFERRER}-{GEO_ANALYSIS}', limit=METRICS_MAX_LIMIT, orderby=['-tpm()'])\n        return geo_code_durations\n    geo_results = [get_geo_data('before'), get_geo_data('after')]\n    for (index, result) in enumerate(geo_results):\n        geo_results[index] = {f\"{data.get('geo.country_code')}\": data for data in result.get('data')}\n    (before_results, after_results) = geo_results\n    changed_keys = set(before_results.keys()) & set(after_results.keys())\n    new_keys = set(after_results.keys()) - set(before_results.keys())\n    analysis_results = []\n    for key in changed_keys | new_keys:\n        if key == '':\n            continue\n        duration_before = before_results[key]['p95_transaction_duration'] if before_results.get(key) else 0.0\n        duration_after = after_results[key]['p95_transaction_duration']\n        if duration_after > duration_before:\n            duration_delta = duration_after - duration_before\n            analysis_results.append({'geo.country_code': key, 'duration_before': duration_before, 'duration_after': duration_after, 'duration_delta': duration_delta, 'score': duration_delta * after_results[key]['tpm']})\n    analysis_results.sort(key=lambda x: x['score'], reverse=True)\n    return analysis_results[:limit]",
            "def fetch_geo_analysis_results(transaction_name, regression_breakpoint, params, limit):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n\n    def get_geo_data(period):\n        adjusted_params = {**params}\n        if period == 'before':\n            adjusted_params['end'] = regression_breakpoint - BUFFER\n        else:\n            adjusted_params['start'] = regression_breakpoint + BUFFER\n        geo_code_durations = metrics_query(['p95(transaction.duration)', 'geo.country_code', 'tpm()'], f'event.type:transaction transaction:{transaction_name}', adjusted_params, referrer=f'{BASE_REFERRER}-{GEO_ANALYSIS}', limit=METRICS_MAX_LIMIT, orderby=['-tpm()'])\n        return geo_code_durations\n    geo_results = [get_geo_data('before'), get_geo_data('after')]\n    for (index, result) in enumerate(geo_results):\n        geo_results[index] = {f\"{data.get('geo.country_code')}\": data for data in result.get('data')}\n    (before_results, after_results) = geo_results\n    changed_keys = set(before_results.keys()) & set(after_results.keys())\n    new_keys = set(after_results.keys()) - set(before_results.keys())\n    analysis_results = []\n    for key in changed_keys | new_keys:\n        if key == '':\n            continue\n        duration_before = before_results[key]['p95_transaction_duration'] if before_results.get(key) else 0.0\n        duration_after = after_results[key]['p95_transaction_duration']\n        if duration_after > duration_before:\n            duration_delta = duration_after - duration_before\n            analysis_results.append({'geo.country_code': key, 'duration_before': duration_before, 'duration_after': duration_after, 'duration_delta': duration_delta, 'score': duration_delta * after_results[key]['tpm']})\n    analysis_results.sort(key=lambda x: x['score'], reverse=True)\n    return analysis_results[:limit]"
        ]
    },
    {
        "func_name": "get",
        "original": "def get(self, request, organization):\n    if not features.has('organizations:performance-duration-regression-visible', organization, actor=request.user):\n        return Response(status=404)\n    transaction_name = request.GET.get('transaction')\n    project_id = request.GET.get('project')\n    regression_breakpoint = request.GET.get('breakpoint')\n    analysis_type = request.GET.get('type', SPAN_ANALYSIS)\n    limit = int(request.GET.get('per_page', DEFAULT_LIMIT))\n    span_score_threshold = int(request.GET.get('span_score_threshold', SPAN_ANALYSIS_SCORE_THRESHOLD))\n    if not transaction_name or not project_id or (not regression_breakpoint):\n        return Response(status=400)\n    regression_breakpoint = parse_datetime_string(regression_breakpoint)\n    params = self.get_snuba_params(request, organization)\n    with self.handle_query_errors():\n        transaction_count_query = metrics_query(['count()'], f'event.type:transaction transaction:\"{transaction_name}\"', params, referrer=f'{BASE_REFERRER}-{analysis_type}')\n    if transaction_count_query['data'][0]['count'] == 0:\n        return Response(status=400, data='Transaction not found')\n    sentry_sdk.set_tag('analysis_type', analysis_type)\n    results = []\n    if analysis_type == SPAN_ANALYSIS:\n        results = fetch_span_analysis_results(transaction_name, regression_breakpoint, params, project_id, limit, span_score_threshold)\n    elif analysis_type == GEO_ANALYSIS:\n        results = fetch_geo_analysis_results(transaction_name, regression_breakpoint, params, limit)\n    return Response(results, status=200)",
        "mutated": [
            "def get(self, request, organization):\n    if False:\n        i = 10\n    if not features.has('organizations:performance-duration-regression-visible', organization, actor=request.user):\n        return Response(status=404)\n    transaction_name = request.GET.get('transaction')\n    project_id = request.GET.get('project')\n    regression_breakpoint = request.GET.get('breakpoint')\n    analysis_type = request.GET.get('type', SPAN_ANALYSIS)\n    limit = int(request.GET.get('per_page', DEFAULT_LIMIT))\n    span_score_threshold = int(request.GET.get('span_score_threshold', SPAN_ANALYSIS_SCORE_THRESHOLD))\n    if not transaction_name or not project_id or (not regression_breakpoint):\n        return Response(status=400)\n    regression_breakpoint = parse_datetime_string(regression_breakpoint)\n    params = self.get_snuba_params(request, organization)\n    with self.handle_query_errors():\n        transaction_count_query = metrics_query(['count()'], f'event.type:transaction transaction:\"{transaction_name}\"', params, referrer=f'{BASE_REFERRER}-{analysis_type}')\n    if transaction_count_query['data'][0]['count'] == 0:\n        return Response(status=400, data='Transaction not found')\n    sentry_sdk.set_tag('analysis_type', analysis_type)\n    results = []\n    if analysis_type == SPAN_ANALYSIS:\n        results = fetch_span_analysis_results(transaction_name, regression_breakpoint, params, project_id, limit, span_score_threshold)\n    elif analysis_type == GEO_ANALYSIS:\n        results = fetch_geo_analysis_results(transaction_name, regression_breakpoint, params, limit)\n    return Response(results, status=200)",
            "def get(self, request, organization):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not features.has('organizations:performance-duration-regression-visible', organization, actor=request.user):\n        return Response(status=404)\n    transaction_name = request.GET.get('transaction')\n    project_id = request.GET.get('project')\n    regression_breakpoint = request.GET.get('breakpoint')\n    analysis_type = request.GET.get('type', SPAN_ANALYSIS)\n    limit = int(request.GET.get('per_page', DEFAULT_LIMIT))\n    span_score_threshold = int(request.GET.get('span_score_threshold', SPAN_ANALYSIS_SCORE_THRESHOLD))\n    if not transaction_name or not project_id or (not regression_breakpoint):\n        return Response(status=400)\n    regression_breakpoint = parse_datetime_string(regression_breakpoint)\n    params = self.get_snuba_params(request, organization)\n    with self.handle_query_errors():\n        transaction_count_query = metrics_query(['count()'], f'event.type:transaction transaction:\"{transaction_name}\"', params, referrer=f'{BASE_REFERRER}-{analysis_type}')\n    if transaction_count_query['data'][0]['count'] == 0:\n        return Response(status=400, data='Transaction not found')\n    sentry_sdk.set_tag('analysis_type', analysis_type)\n    results = []\n    if analysis_type == SPAN_ANALYSIS:\n        results = fetch_span_analysis_results(transaction_name, regression_breakpoint, params, project_id, limit, span_score_threshold)\n    elif analysis_type == GEO_ANALYSIS:\n        results = fetch_geo_analysis_results(transaction_name, regression_breakpoint, params, limit)\n    return Response(results, status=200)",
            "def get(self, request, organization):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not features.has('organizations:performance-duration-regression-visible', organization, actor=request.user):\n        return Response(status=404)\n    transaction_name = request.GET.get('transaction')\n    project_id = request.GET.get('project')\n    regression_breakpoint = request.GET.get('breakpoint')\n    analysis_type = request.GET.get('type', SPAN_ANALYSIS)\n    limit = int(request.GET.get('per_page', DEFAULT_LIMIT))\n    span_score_threshold = int(request.GET.get('span_score_threshold', SPAN_ANALYSIS_SCORE_THRESHOLD))\n    if not transaction_name or not project_id or (not regression_breakpoint):\n        return Response(status=400)\n    regression_breakpoint = parse_datetime_string(regression_breakpoint)\n    params = self.get_snuba_params(request, organization)\n    with self.handle_query_errors():\n        transaction_count_query = metrics_query(['count()'], f'event.type:transaction transaction:\"{transaction_name}\"', params, referrer=f'{BASE_REFERRER}-{analysis_type}')\n    if transaction_count_query['data'][0]['count'] == 0:\n        return Response(status=400, data='Transaction not found')\n    sentry_sdk.set_tag('analysis_type', analysis_type)\n    results = []\n    if analysis_type == SPAN_ANALYSIS:\n        results = fetch_span_analysis_results(transaction_name, regression_breakpoint, params, project_id, limit, span_score_threshold)\n    elif analysis_type == GEO_ANALYSIS:\n        results = fetch_geo_analysis_results(transaction_name, regression_breakpoint, params, limit)\n    return Response(results, status=200)",
            "def get(self, request, organization):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not features.has('organizations:performance-duration-regression-visible', organization, actor=request.user):\n        return Response(status=404)\n    transaction_name = request.GET.get('transaction')\n    project_id = request.GET.get('project')\n    regression_breakpoint = request.GET.get('breakpoint')\n    analysis_type = request.GET.get('type', SPAN_ANALYSIS)\n    limit = int(request.GET.get('per_page', DEFAULT_LIMIT))\n    span_score_threshold = int(request.GET.get('span_score_threshold', SPAN_ANALYSIS_SCORE_THRESHOLD))\n    if not transaction_name or not project_id or (not regression_breakpoint):\n        return Response(status=400)\n    regression_breakpoint = parse_datetime_string(regression_breakpoint)\n    params = self.get_snuba_params(request, organization)\n    with self.handle_query_errors():\n        transaction_count_query = metrics_query(['count()'], f'event.type:transaction transaction:\"{transaction_name}\"', params, referrer=f'{BASE_REFERRER}-{analysis_type}')\n    if transaction_count_query['data'][0]['count'] == 0:\n        return Response(status=400, data='Transaction not found')\n    sentry_sdk.set_tag('analysis_type', analysis_type)\n    results = []\n    if analysis_type == SPAN_ANALYSIS:\n        results = fetch_span_analysis_results(transaction_name, regression_breakpoint, params, project_id, limit, span_score_threshold)\n    elif analysis_type == GEO_ANALYSIS:\n        results = fetch_geo_analysis_results(transaction_name, regression_breakpoint, params, limit)\n    return Response(results, status=200)",
            "def get(self, request, organization):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not features.has('organizations:performance-duration-regression-visible', organization, actor=request.user):\n        return Response(status=404)\n    transaction_name = request.GET.get('transaction')\n    project_id = request.GET.get('project')\n    regression_breakpoint = request.GET.get('breakpoint')\n    analysis_type = request.GET.get('type', SPAN_ANALYSIS)\n    limit = int(request.GET.get('per_page', DEFAULT_LIMIT))\n    span_score_threshold = int(request.GET.get('span_score_threshold', SPAN_ANALYSIS_SCORE_THRESHOLD))\n    if not transaction_name or not project_id or (not regression_breakpoint):\n        return Response(status=400)\n    regression_breakpoint = parse_datetime_string(regression_breakpoint)\n    params = self.get_snuba_params(request, organization)\n    with self.handle_query_errors():\n        transaction_count_query = metrics_query(['count()'], f'event.type:transaction transaction:\"{transaction_name}\"', params, referrer=f'{BASE_REFERRER}-{analysis_type}')\n    if transaction_count_query['data'][0]['count'] == 0:\n        return Response(status=400, data='Transaction not found')\n    sentry_sdk.set_tag('analysis_type', analysis_type)\n    results = []\n    if analysis_type == SPAN_ANALYSIS:\n        results = fetch_span_analysis_results(transaction_name, regression_breakpoint, params, project_id, limit, span_score_threshold)\n    elif analysis_type == GEO_ANALYSIS:\n        results = fetch_geo_analysis_results(transaction_name, regression_breakpoint, params, limit)\n    return Response(results, status=200)"
        ]
    }
]