[
    {
        "func_name": "setup",
        "original": "def setup(self, sfc, userOpts=dict()):\n    self.sf = sfc\n    self.results = self.tempStorage()\n    for opt in list(userOpts.keys()):\n        self.opts[opt] = userOpts[opt]",
        "mutated": [
            "def setup(self, sfc, userOpts=dict()):\n    if False:\n        i = 10\n    self.sf = sfc\n    self.results = self.tempStorage()\n    for opt in list(userOpts.keys()):\n        self.opts[opt] = userOpts[opt]",
            "def setup(self, sfc, userOpts=dict()):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.sf = sfc\n    self.results = self.tempStorage()\n    for opt in list(userOpts.keys()):\n        self.opts[opt] = userOpts[opt]",
            "def setup(self, sfc, userOpts=dict()):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.sf = sfc\n    self.results = self.tempStorage()\n    for opt in list(userOpts.keys()):\n        self.opts[opt] = userOpts[opt]",
            "def setup(self, sfc, userOpts=dict()):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.sf = sfc\n    self.results = self.tempStorage()\n    for opt in list(userOpts.keys()):\n        self.opts[opt] = userOpts[opt]",
            "def setup(self, sfc, userOpts=dict()):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.sf = sfc\n    self.results = self.tempStorage()\n    for opt in list(userOpts.keys()):\n        self.opts[opt] = userOpts[opt]"
        ]
    },
    {
        "func_name": "watchedEvents",
        "original": "def watchedEvents(self):\n    return ['DOMAIN_NAME', 'HUMAN_NAME', 'EMAILADDR']",
        "mutated": [
            "def watchedEvents(self):\n    if False:\n        i = 10\n    return ['DOMAIN_NAME', 'HUMAN_NAME', 'EMAILADDR']",
            "def watchedEvents(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return ['DOMAIN_NAME', 'HUMAN_NAME', 'EMAILADDR']",
            "def watchedEvents(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return ['DOMAIN_NAME', 'HUMAN_NAME', 'EMAILADDR']",
            "def watchedEvents(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return ['DOMAIN_NAME', 'HUMAN_NAME', 'EMAILADDR']",
            "def watchedEvents(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return ['DOMAIN_NAME', 'HUMAN_NAME', 'EMAILADDR']"
        ]
    },
    {
        "func_name": "producedEvents",
        "original": "def producedEvents(self):\n    return ['DARKNET_MENTION_URL', 'DARKNET_MENTION_CONTENT']",
        "mutated": [
            "def producedEvents(self):\n    if False:\n        i = 10\n    return ['DARKNET_MENTION_URL', 'DARKNET_MENTION_CONTENT']",
            "def producedEvents(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return ['DARKNET_MENTION_URL', 'DARKNET_MENTION_CONTENT']",
            "def producedEvents(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return ['DARKNET_MENTION_URL', 'DARKNET_MENTION_CONTENT']",
            "def producedEvents(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return ['DARKNET_MENTION_URL', 'DARKNET_MENTION_CONTENT']",
            "def producedEvents(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return ['DARKNET_MENTION_URL', 'DARKNET_MENTION_CONTENT']"
        ]
    },
    {
        "func_name": "handleEvent",
        "original": "def handleEvent(self, event):\n    eventName = event.eventType\n    eventData = event.data\n    if not self.opts['fullnames'] and eventName == 'HUMAN_NAME':\n        return\n    if eventData in self.results:\n        self.debug('Already did a search for ' + eventData + ', skipping.')\n        return\n    self.results[eventData] = True\n    keepGoing = True\n    page = 1\n    while keepGoing and page <= int(self.opts['max_pages']):\n        if self.checkForStop():\n            return\n        params = {'search': '\"' + eventData.encode('raw_unicode_escape').decode('ascii', errors='replace') + '\"', 'submit': 'Search', 'page': str(page)}\n        data = self.sf.fetchUrl('https://onionsearchengine.com/search.php?' + urllib.parse.urlencode(params), useragent=self.opts['_useragent'], timeout=self.opts['timeout'])\n        if data is None or not data.get('content'):\n            self.info('No results returned from onionsearchengine.com.')\n            return\n        page += 1\n        if 'url.php?u=' not in data['content']:\n            if \"you didn't submit a keyword\" in data['content']:\n                continue\n            return\n        if 'forward >' not in data['content']:\n            keepGoing = False\n        links = re.findall('url\\\\.php\\\\?u=(.[^\\\\\"\\\\\\']+)[\\\\\"\\\\\\']', data['content'], re.IGNORECASE | re.DOTALL)\n        for link in links:\n            if self.checkForStop():\n                return\n            if link in self.results:\n                continue\n            self.results[link] = True\n            blacklist = False\n            for r in self.opts['blacklist']:\n                if re.match(r, link, re.IGNORECASE):\n                    self.debug('Skipping ' + link + ' as it matches blacklist ' + r)\n                    blacklist = True\n            if blacklist:\n                continue\n            self.debug('Found a darknet mention: ' + link)\n            if not self.sf.urlFQDN(link).endswith('.onion'):\n                continue\n            if not self.opts['fetchlinks']:\n                evt = SpiderFootEvent('DARKNET_MENTION_URL', link, self.__name__, event)\n                self.notifyListeners(evt)\n                continue\n            res = self.sf.fetchUrl(link, timeout=self.opts['_fetchtimeout'], useragent=self.opts['_useragent'], verify=False)\n            if res['content'] is None:\n                self.debug('Ignoring ' + link + ' as no data returned')\n                continue\n            if eventData not in res['content']:\n                self.debug('Ignoring ' + link + ' as no mention of ' + eventData)\n                continue\n            evt = SpiderFootEvent('DARKNET_MENTION_URL', link, self.__name__, event)\n            self.notifyListeners(evt)\n            try:\n                startIndex = res['content'].index(eventData) - 120\n                endIndex = startIndex + len(eventData) + 240\n            except Exception:\n                self.debug('String \"' + eventData + '\" not found in content.')\n                continue\n            data = res['content'][startIndex:endIndex]\n            evt = SpiderFootEvent('DARKNET_MENTION_CONTENT', '...' + data + '...', self.__name__, evt)\n            self.notifyListeners(evt)",
        "mutated": [
            "def handleEvent(self, event):\n    if False:\n        i = 10\n    eventName = event.eventType\n    eventData = event.data\n    if not self.opts['fullnames'] and eventName == 'HUMAN_NAME':\n        return\n    if eventData in self.results:\n        self.debug('Already did a search for ' + eventData + ', skipping.')\n        return\n    self.results[eventData] = True\n    keepGoing = True\n    page = 1\n    while keepGoing and page <= int(self.opts['max_pages']):\n        if self.checkForStop():\n            return\n        params = {'search': '\"' + eventData.encode('raw_unicode_escape').decode('ascii', errors='replace') + '\"', 'submit': 'Search', 'page': str(page)}\n        data = self.sf.fetchUrl('https://onionsearchengine.com/search.php?' + urllib.parse.urlencode(params), useragent=self.opts['_useragent'], timeout=self.opts['timeout'])\n        if data is None or not data.get('content'):\n            self.info('No results returned from onionsearchengine.com.')\n            return\n        page += 1\n        if 'url.php?u=' not in data['content']:\n            if \"you didn't submit a keyword\" in data['content']:\n                continue\n            return\n        if 'forward >' not in data['content']:\n            keepGoing = False\n        links = re.findall('url\\\\.php\\\\?u=(.[^\\\\\"\\\\\\']+)[\\\\\"\\\\\\']', data['content'], re.IGNORECASE | re.DOTALL)\n        for link in links:\n            if self.checkForStop():\n                return\n            if link in self.results:\n                continue\n            self.results[link] = True\n            blacklist = False\n            for r in self.opts['blacklist']:\n                if re.match(r, link, re.IGNORECASE):\n                    self.debug('Skipping ' + link + ' as it matches blacklist ' + r)\n                    blacklist = True\n            if blacklist:\n                continue\n            self.debug('Found a darknet mention: ' + link)\n            if not self.sf.urlFQDN(link).endswith('.onion'):\n                continue\n            if not self.opts['fetchlinks']:\n                evt = SpiderFootEvent('DARKNET_MENTION_URL', link, self.__name__, event)\n                self.notifyListeners(evt)\n                continue\n            res = self.sf.fetchUrl(link, timeout=self.opts['_fetchtimeout'], useragent=self.opts['_useragent'], verify=False)\n            if res['content'] is None:\n                self.debug('Ignoring ' + link + ' as no data returned')\n                continue\n            if eventData not in res['content']:\n                self.debug('Ignoring ' + link + ' as no mention of ' + eventData)\n                continue\n            evt = SpiderFootEvent('DARKNET_MENTION_URL', link, self.__name__, event)\n            self.notifyListeners(evt)\n            try:\n                startIndex = res['content'].index(eventData) - 120\n                endIndex = startIndex + len(eventData) + 240\n            except Exception:\n                self.debug('String \"' + eventData + '\" not found in content.')\n                continue\n            data = res['content'][startIndex:endIndex]\n            evt = SpiderFootEvent('DARKNET_MENTION_CONTENT', '...' + data + '...', self.__name__, evt)\n            self.notifyListeners(evt)",
            "def handleEvent(self, event):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    eventName = event.eventType\n    eventData = event.data\n    if not self.opts['fullnames'] and eventName == 'HUMAN_NAME':\n        return\n    if eventData in self.results:\n        self.debug('Already did a search for ' + eventData + ', skipping.')\n        return\n    self.results[eventData] = True\n    keepGoing = True\n    page = 1\n    while keepGoing and page <= int(self.opts['max_pages']):\n        if self.checkForStop():\n            return\n        params = {'search': '\"' + eventData.encode('raw_unicode_escape').decode('ascii', errors='replace') + '\"', 'submit': 'Search', 'page': str(page)}\n        data = self.sf.fetchUrl('https://onionsearchengine.com/search.php?' + urllib.parse.urlencode(params), useragent=self.opts['_useragent'], timeout=self.opts['timeout'])\n        if data is None or not data.get('content'):\n            self.info('No results returned from onionsearchengine.com.')\n            return\n        page += 1\n        if 'url.php?u=' not in data['content']:\n            if \"you didn't submit a keyword\" in data['content']:\n                continue\n            return\n        if 'forward >' not in data['content']:\n            keepGoing = False\n        links = re.findall('url\\\\.php\\\\?u=(.[^\\\\\"\\\\\\']+)[\\\\\"\\\\\\']', data['content'], re.IGNORECASE | re.DOTALL)\n        for link in links:\n            if self.checkForStop():\n                return\n            if link in self.results:\n                continue\n            self.results[link] = True\n            blacklist = False\n            for r in self.opts['blacklist']:\n                if re.match(r, link, re.IGNORECASE):\n                    self.debug('Skipping ' + link + ' as it matches blacklist ' + r)\n                    blacklist = True\n            if blacklist:\n                continue\n            self.debug('Found a darknet mention: ' + link)\n            if not self.sf.urlFQDN(link).endswith('.onion'):\n                continue\n            if not self.opts['fetchlinks']:\n                evt = SpiderFootEvent('DARKNET_MENTION_URL', link, self.__name__, event)\n                self.notifyListeners(evt)\n                continue\n            res = self.sf.fetchUrl(link, timeout=self.opts['_fetchtimeout'], useragent=self.opts['_useragent'], verify=False)\n            if res['content'] is None:\n                self.debug('Ignoring ' + link + ' as no data returned')\n                continue\n            if eventData not in res['content']:\n                self.debug('Ignoring ' + link + ' as no mention of ' + eventData)\n                continue\n            evt = SpiderFootEvent('DARKNET_MENTION_URL', link, self.__name__, event)\n            self.notifyListeners(evt)\n            try:\n                startIndex = res['content'].index(eventData) - 120\n                endIndex = startIndex + len(eventData) + 240\n            except Exception:\n                self.debug('String \"' + eventData + '\" not found in content.')\n                continue\n            data = res['content'][startIndex:endIndex]\n            evt = SpiderFootEvent('DARKNET_MENTION_CONTENT', '...' + data + '...', self.__name__, evt)\n            self.notifyListeners(evt)",
            "def handleEvent(self, event):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    eventName = event.eventType\n    eventData = event.data\n    if not self.opts['fullnames'] and eventName == 'HUMAN_NAME':\n        return\n    if eventData in self.results:\n        self.debug('Already did a search for ' + eventData + ', skipping.')\n        return\n    self.results[eventData] = True\n    keepGoing = True\n    page = 1\n    while keepGoing and page <= int(self.opts['max_pages']):\n        if self.checkForStop():\n            return\n        params = {'search': '\"' + eventData.encode('raw_unicode_escape').decode('ascii', errors='replace') + '\"', 'submit': 'Search', 'page': str(page)}\n        data = self.sf.fetchUrl('https://onionsearchengine.com/search.php?' + urllib.parse.urlencode(params), useragent=self.opts['_useragent'], timeout=self.opts['timeout'])\n        if data is None or not data.get('content'):\n            self.info('No results returned from onionsearchengine.com.')\n            return\n        page += 1\n        if 'url.php?u=' not in data['content']:\n            if \"you didn't submit a keyword\" in data['content']:\n                continue\n            return\n        if 'forward >' not in data['content']:\n            keepGoing = False\n        links = re.findall('url\\\\.php\\\\?u=(.[^\\\\\"\\\\\\']+)[\\\\\"\\\\\\']', data['content'], re.IGNORECASE | re.DOTALL)\n        for link in links:\n            if self.checkForStop():\n                return\n            if link in self.results:\n                continue\n            self.results[link] = True\n            blacklist = False\n            for r in self.opts['blacklist']:\n                if re.match(r, link, re.IGNORECASE):\n                    self.debug('Skipping ' + link + ' as it matches blacklist ' + r)\n                    blacklist = True\n            if blacklist:\n                continue\n            self.debug('Found a darknet mention: ' + link)\n            if not self.sf.urlFQDN(link).endswith('.onion'):\n                continue\n            if not self.opts['fetchlinks']:\n                evt = SpiderFootEvent('DARKNET_MENTION_URL', link, self.__name__, event)\n                self.notifyListeners(evt)\n                continue\n            res = self.sf.fetchUrl(link, timeout=self.opts['_fetchtimeout'], useragent=self.opts['_useragent'], verify=False)\n            if res['content'] is None:\n                self.debug('Ignoring ' + link + ' as no data returned')\n                continue\n            if eventData not in res['content']:\n                self.debug('Ignoring ' + link + ' as no mention of ' + eventData)\n                continue\n            evt = SpiderFootEvent('DARKNET_MENTION_URL', link, self.__name__, event)\n            self.notifyListeners(evt)\n            try:\n                startIndex = res['content'].index(eventData) - 120\n                endIndex = startIndex + len(eventData) + 240\n            except Exception:\n                self.debug('String \"' + eventData + '\" not found in content.')\n                continue\n            data = res['content'][startIndex:endIndex]\n            evt = SpiderFootEvent('DARKNET_MENTION_CONTENT', '...' + data + '...', self.__name__, evt)\n            self.notifyListeners(evt)",
            "def handleEvent(self, event):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    eventName = event.eventType\n    eventData = event.data\n    if not self.opts['fullnames'] and eventName == 'HUMAN_NAME':\n        return\n    if eventData in self.results:\n        self.debug('Already did a search for ' + eventData + ', skipping.')\n        return\n    self.results[eventData] = True\n    keepGoing = True\n    page = 1\n    while keepGoing and page <= int(self.opts['max_pages']):\n        if self.checkForStop():\n            return\n        params = {'search': '\"' + eventData.encode('raw_unicode_escape').decode('ascii', errors='replace') + '\"', 'submit': 'Search', 'page': str(page)}\n        data = self.sf.fetchUrl('https://onionsearchengine.com/search.php?' + urllib.parse.urlencode(params), useragent=self.opts['_useragent'], timeout=self.opts['timeout'])\n        if data is None or not data.get('content'):\n            self.info('No results returned from onionsearchengine.com.')\n            return\n        page += 1\n        if 'url.php?u=' not in data['content']:\n            if \"you didn't submit a keyword\" in data['content']:\n                continue\n            return\n        if 'forward >' not in data['content']:\n            keepGoing = False\n        links = re.findall('url\\\\.php\\\\?u=(.[^\\\\\"\\\\\\']+)[\\\\\"\\\\\\']', data['content'], re.IGNORECASE | re.DOTALL)\n        for link in links:\n            if self.checkForStop():\n                return\n            if link in self.results:\n                continue\n            self.results[link] = True\n            blacklist = False\n            for r in self.opts['blacklist']:\n                if re.match(r, link, re.IGNORECASE):\n                    self.debug('Skipping ' + link + ' as it matches blacklist ' + r)\n                    blacklist = True\n            if blacklist:\n                continue\n            self.debug('Found a darknet mention: ' + link)\n            if not self.sf.urlFQDN(link).endswith('.onion'):\n                continue\n            if not self.opts['fetchlinks']:\n                evt = SpiderFootEvent('DARKNET_MENTION_URL', link, self.__name__, event)\n                self.notifyListeners(evt)\n                continue\n            res = self.sf.fetchUrl(link, timeout=self.opts['_fetchtimeout'], useragent=self.opts['_useragent'], verify=False)\n            if res['content'] is None:\n                self.debug('Ignoring ' + link + ' as no data returned')\n                continue\n            if eventData not in res['content']:\n                self.debug('Ignoring ' + link + ' as no mention of ' + eventData)\n                continue\n            evt = SpiderFootEvent('DARKNET_MENTION_URL', link, self.__name__, event)\n            self.notifyListeners(evt)\n            try:\n                startIndex = res['content'].index(eventData) - 120\n                endIndex = startIndex + len(eventData) + 240\n            except Exception:\n                self.debug('String \"' + eventData + '\" not found in content.')\n                continue\n            data = res['content'][startIndex:endIndex]\n            evt = SpiderFootEvent('DARKNET_MENTION_CONTENT', '...' + data + '...', self.__name__, evt)\n            self.notifyListeners(evt)",
            "def handleEvent(self, event):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    eventName = event.eventType\n    eventData = event.data\n    if not self.opts['fullnames'] and eventName == 'HUMAN_NAME':\n        return\n    if eventData in self.results:\n        self.debug('Already did a search for ' + eventData + ', skipping.')\n        return\n    self.results[eventData] = True\n    keepGoing = True\n    page = 1\n    while keepGoing and page <= int(self.opts['max_pages']):\n        if self.checkForStop():\n            return\n        params = {'search': '\"' + eventData.encode('raw_unicode_escape').decode('ascii', errors='replace') + '\"', 'submit': 'Search', 'page': str(page)}\n        data = self.sf.fetchUrl('https://onionsearchengine.com/search.php?' + urllib.parse.urlencode(params), useragent=self.opts['_useragent'], timeout=self.opts['timeout'])\n        if data is None or not data.get('content'):\n            self.info('No results returned from onionsearchengine.com.')\n            return\n        page += 1\n        if 'url.php?u=' not in data['content']:\n            if \"you didn't submit a keyword\" in data['content']:\n                continue\n            return\n        if 'forward >' not in data['content']:\n            keepGoing = False\n        links = re.findall('url\\\\.php\\\\?u=(.[^\\\\\"\\\\\\']+)[\\\\\"\\\\\\']', data['content'], re.IGNORECASE | re.DOTALL)\n        for link in links:\n            if self.checkForStop():\n                return\n            if link in self.results:\n                continue\n            self.results[link] = True\n            blacklist = False\n            for r in self.opts['blacklist']:\n                if re.match(r, link, re.IGNORECASE):\n                    self.debug('Skipping ' + link + ' as it matches blacklist ' + r)\n                    blacklist = True\n            if blacklist:\n                continue\n            self.debug('Found a darknet mention: ' + link)\n            if not self.sf.urlFQDN(link).endswith('.onion'):\n                continue\n            if not self.opts['fetchlinks']:\n                evt = SpiderFootEvent('DARKNET_MENTION_URL', link, self.__name__, event)\n                self.notifyListeners(evt)\n                continue\n            res = self.sf.fetchUrl(link, timeout=self.opts['_fetchtimeout'], useragent=self.opts['_useragent'], verify=False)\n            if res['content'] is None:\n                self.debug('Ignoring ' + link + ' as no data returned')\n                continue\n            if eventData not in res['content']:\n                self.debug('Ignoring ' + link + ' as no mention of ' + eventData)\n                continue\n            evt = SpiderFootEvent('DARKNET_MENTION_URL', link, self.__name__, event)\n            self.notifyListeners(evt)\n            try:\n                startIndex = res['content'].index(eventData) - 120\n                endIndex = startIndex + len(eventData) + 240\n            except Exception:\n                self.debug('String \"' + eventData + '\" not found in content.')\n                continue\n            data = res['content'][startIndex:endIndex]\n            evt = SpiderFootEvent('DARKNET_MENTION_CONTENT', '...' + data + '...', self.__name__, evt)\n            self.notifyListeners(evt)"
        ]
    }
]