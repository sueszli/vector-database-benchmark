[
    {
        "func_name": "get_addr_argument",
        "original": "def get_addr_argument(field: str, value: str) -> Tuple[str, str]:\n    addr_field = addr_fields[field]\n    op = '='\n    if '/' in value:\n        op = '=~'\n    return (addr_field['type'], '%s %s %s' % (addr_field['field'], op, value))",
        "mutated": [
            "def get_addr_argument(field: str, value: str) -> Tuple[str, str]:\n    if False:\n        i = 10\n    addr_field = addr_fields[field]\n    op = '='\n    if '/' in value:\n        op = '=~'\n    return (addr_field['type'], '%s %s %s' % (addr_field['field'], op, value))",
            "def get_addr_argument(field: str, value: str) -> Tuple[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    addr_field = addr_fields[field]\n    op = '='\n    if '/' in value:\n        op = '=~'\n    return (addr_field['type'], '%s %s %s' % (addr_field['field'], op, value))",
            "def get_addr_argument(field: str, value: str) -> Tuple[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    addr_field = addr_fields[field]\n    op = '='\n    if '/' in value:\n        op = '=~'\n    return (addr_field['type'], '%s %s %s' % (addr_field['field'], op, value))",
            "def get_addr_argument(field: str, value: str) -> Tuple[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    addr_field = addr_fields[field]\n    op = '='\n    if '/' in value:\n        op = '=~'\n    return (addr_field['type'], '%s %s %s' % (addr_field['field'], op, value))",
            "def get_addr_argument(field: str, value: str) -> Tuple[str, str]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    addr_field = addr_fields[field]\n    op = '='\n    if '/' in value:\n        op = '=~'\n    return (addr_field['type'], '%s %s %s' % (addr_field['field'], op, value))"
        ]
    },
    {
        "func_name": "print_fields",
        "original": "def print_fields() -> None:\n    equals = '=' * 7\n    title = 'General'\n    sys.stdout.write('{0} {1:^10} {0}\\n'.format(equals, title))\n    sys.stdout.writelines(('%-12s: %s\\n' % (field, name) for (field, name) in ivre.flow.FIELDS.items()))\n    for (proto, configs) in ivre.flow.META_DESC.items():\n        sys.stdout.write('{0} {1:^10} {0}\\n'.format(equals, proto))\n        sys.stdout.writelines(('meta.%s.%s (list)\\n' % (proto, name) for name in configs['keys']))\n        sys.stdout.writelines(('meta.%s.%s\\n' % (proto, name) for name in configs.get('counters', [])))",
        "mutated": [
            "def print_fields() -> None:\n    if False:\n        i = 10\n    equals = '=' * 7\n    title = 'General'\n    sys.stdout.write('{0} {1:^10} {0}\\n'.format(equals, title))\n    sys.stdout.writelines(('%-12s: %s\\n' % (field, name) for (field, name) in ivre.flow.FIELDS.items()))\n    for (proto, configs) in ivre.flow.META_DESC.items():\n        sys.stdout.write('{0} {1:^10} {0}\\n'.format(equals, proto))\n        sys.stdout.writelines(('meta.%s.%s (list)\\n' % (proto, name) for name in configs['keys']))\n        sys.stdout.writelines(('meta.%s.%s\\n' % (proto, name) for name in configs.get('counters', [])))",
            "def print_fields() -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    equals = '=' * 7\n    title = 'General'\n    sys.stdout.write('{0} {1:^10} {0}\\n'.format(equals, title))\n    sys.stdout.writelines(('%-12s: %s\\n' % (field, name) for (field, name) in ivre.flow.FIELDS.items()))\n    for (proto, configs) in ivre.flow.META_DESC.items():\n        sys.stdout.write('{0} {1:^10} {0}\\n'.format(equals, proto))\n        sys.stdout.writelines(('meta.%s.%s (list)\\n' % (proto, name) for name in configs['keys']))\n        sys.stdout.writelines(('meta.%s.%s\\n' % (proto, name) for name in configs.get('counters', [])))",
            "def print_fields() -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    equals = '=' * 7\n    title = 'General'\n    sys.stdout.write('{0} {1:^10} {0}\\n'.format(equals, title))\n    sys.stdout.writelines(('%-12s: %s\\n' % (field, name) for (field, name) in ivre.flow.FIELDS.items()))\n    for (proto, configs) in ivre.flow.META_DESC.items():\n        sys.stdout.write('{0} {1:^10} {0}\\n'.format(equals, proto))\n        sys.stdout.writelines(('meta.%s.%s (list)\\n' % (proto, name) for name in configs['keys']))\n        sys.stdout.writelines(('meta.%s.%s\\n' % (proto, name) for name in configs.get('counters', [])))",
            "def print_fields() -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    equals = '=' * 7\n    title = 'General'\n    sys.stdout.write('{0} {1:^10} {0}\\n'.format(equals, title))\n    sys.stdout.writelines(('%-12s: %s\\n' % (field, name) for (field, name) in ivre.flow.FIELDS.items()))\n    for (proto, configs) in ivre.flow.META_DESC.items():\n        sys.stdout.write('{0} {1:^10} {0}\\n'.format(equals, proto))\n        sys.stdout.writelines(('meta.%s.%s (list)\\n' % (proto, name) for name in configs['keys']))\n        sys.stdout.writelines(('meta.%s.%s\\n' % (proto, name) for name in configs.get('counters', [])))",
            "def print_fields() -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    equals = '=' * 7\n    title = 'General'\n    sys.stdout.write('{0} {1:^10} {0}\\n'.format(equals, title))\n    sys.stdout.writelines(('%-12s: %s\\n' % (field, name) for (field, name) in ivre.flow.FIELDS.items()))\n    for (proto, configs) in ivre.flow.META_DESC.items():\n        sys.stdout.write('{0} {1:^10} {0}\\n'.format(equals, proto))\n        sys.stdout.writelines(('meta.%s.%s (list)\\n' % (proto, name) for name in configs['keys']))\n        sys.stdout.writelines(('meta.%s.%s\\n' % (proto, name) for name in configs.get('counters', [])))"
        ]
    },
    {
        "func_name": "main",
        "original": "def main() -> None:\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument('--init', '--purgedb', action='store_true', help='Purge or create and initialize the database.')\n    parser.add_argument('--ensure-indexes', action='store_true', help='Create missing indexes (will lock the database).')\n    parser.add_argument('--node-filters', '-n', nargs='+', metavar='FILTER', help='Filter the results with a list of ivre specific node textual filters (see WebUI doc in FLOW.md).')\n    parser.add_argument('--flow-filters', '-f', nargs='+', metavar='FILTER', help='Filter the results with a list of ivre specific flow textual filters (see WebUI doc in FLOW.md).')\n    parser.add_argument('--json', '-j', action='store_true', help='Outputs the full json records of results.')\n    parser.add_argument('--count', '-c', action='store_true', help='Only return the count of the results.')\n    parser.add_argument('--limit', '-l', type=int, default=None, help='Output at most LIMIT results.')\n    parser.add_argument('--skip', type=int, default=0, help='Skip first SKIP results.')\n    parser.add_argument('--orderby', '-o', help='Order of results (\"src\", \"dst\" or \"flow\")')\n    parser.add_argument('--separator', '-s', help='Separator string.')\n    parser.add_argument('--top', '-t', nargs='+', help='Top flows for a given set of fields, e.g. \"--top src.addr dport\".')\n    parser.add_argument('--collect', '-C', nargs='+', help='When using --top, also collect these properties.', default=[])\n    parser.add_argument('--sum', '-S', nargs='+', help='When using --top, sum on these properties to order the result.', default=[])\n    parser.add_argument('--least', '-L', action='store_true', help='When using --top, sort records by least')\n    parser.add_argument('--mode', '-m', help='Query special mode (flow_map, talk_map...)')\n    parser.add_argument('--timeline', '-T', action='store_true', help='Retrieves the timeline of each flow')\n    parser.add_argument('--flow-daily', action='store_true', help='Flow count per times of the day. If --precision is absent, it will be based on FLOW_TIME_PRECISION (%d)' % config.FLOW_TIME_PRECISION)\n    parser.add_argument('--plot', action='store_true', help='Plot data when possible (requires matplotlib).')\n    parser.add_argument('--fields', nargs='*', help='Without values, gives the list of available fields. Otherwise, display these fields for each entry.')\n    parser.add_argument('--reduce-precision', type=int, metavar='NEW_PRECISION', help='Only with MongoDB backend. Reduce precision to NEW_PRECISION for flows timeslots. Uses precision, before, after and filters.')\n    parser.add_argument('--after', '-a', type=str, help='Only with MongoDB backend. Get only flows seen after this date. Date format: YEAR-MONTH-DAY HOUR:MINUTE. Based on timeslots precision. If the given date is in the middle of a timeslot, flows start at the next timeslot.')\n    parser.add_argument('--before', '-b', type=str, help='Only with MongoDB backend. Get only flows seen before this date. Date format: YEAR-MONTH-DAY HOUR:MINUTE. Based on timeslots precision. If the given date is in the middle of a timeslot, the whole period is kept even if theoretically some flows may have been seen after the given date.')\n    parser.add_argument('--precision', nargs='?', default=None, const=0, help='Only With MongoDB backend. If PRECISION is specified, get only flows with one timeslot of the given precision. Otherwise, list precisions.', type=int)\n    parser.add_argument('--host', type=str, metavar='HOST', help='Filter on source OR destination IP. Accepts IP address or CIDR.')\n    parser.add_argument('--src', type=str, metavar='SRC', help='Filter on source IP. Accepts IP address or CIDR.')\n    parser.add_argument('--dst', type=str, metavar='DST', help='Filter on destination IP. Accepts IP address or CIDR.')\n    parser.add_argument('--proto', type=str, metavar='PROTO', help='Filter on transport protocol.')\n    parser.add_argument('--tcp', action='store_true', help='Alias to --proto tcp')\n    parser.add_argument('--udp', action='store_true', help='Alias to --proto udp')\n    parser.add_argument('--port', type=int, metavar='PORT', help='Alias to --dport')\n    parser.add_argument('--dport', type=int, metavar='DPORT', help='Filter on destination port.')\n    parser.add_argument('--sport', type=int, metavar='SPORT', help='Filter on source port.')\n    args = parser.parse_args()\n    out = sys.stdout\n    if args.plot and plt is None:\n        utils.LOGGER.critical('Matplotlib is required for --plot')\n        sys.exit(-1)\n    if args.init:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will remove any flow result in your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        db.flow.init()\n        sys.exit(0)\n    if args.ensure_indexes:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will lock your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        db.flow.ensure_indexes()\n        sys.exit(0)\n    if args.fields is not None and (not args.fields):\n        print_fields()\n        sys.exit(0)\n    elif args.fields is not None:\n        for field in args.fields:\n            ivre.flow.validate_field(field)\n    if args.precision == 0:\n        out.writelines(('%d\\n' % precision for precision in db.flow.list_precisions()))\n        sys.exit(0)\n    filters = {'nodes': args.node_filters or [], 'edges': args.flow_filters or []}\n    args_dict = vars(args)\n    for key in addr_fields:\n        if args_dict[key] is not None:\n            (flt_t, flt_v) = get_addr_argument(key, args_dict[key])\n            filters[flt_t].append(flt_v)\n    if args.proto is not None:\n        filters['edges'].append('proto = %s' % args.proto)\n    for key in ['tcp', 'udp']:\n        if args_dict[key]:\n            filters['edges'].append('proto = %s' % key)\n    for key in ['port', 'dport']:\n        if args_dict[key] is not None:\n            filters['edges'].append('dport = %d' % args_dict[key])\n    if args.sport is not None:\n        filters['edges'].append('ANY sports = %d' % args.sport)\n    time_args = ['before', 'after']\n    time_values = {}\n    for arg in time_args:\n        time_values[arg] = datetime.datetime.strptime(args_dict[arg], '%Y-%m-%d %H:%M') if args_dict[arg] is not None else None\n    query = db.flow.from_filters(filters, limit=args.limit, skip=args.skip, orderby=args.orderby, mode=args.mode, timeline=args.timeline, after=time_values['after'], before=time_values['before'], precision=args.precision)\n    if args.reduce_precision:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will permanently reduce the precision of your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        new_precision = args.reduce_precision\n        db.flow.reduce_precision(new_precision, flt=query, before=time_values['before'], after=time_values['after'], current_precision=args.precision)\n        sys.exit(0)\n    sep = args.separator or ' | '\n    coma = ' ;' if args.separator else ' ; '\n    coma2 = ',' if args.separator else ', '\n    if args.count:\n        count = db.flow.count(query)\n        out.write('%(clients)d clients\\n%(servers)d servers\\n%(flows)d flows\\n' % count)\n    elif args.top:\n        top = db.flow.topvalues(query, args.top, collect_fields=args.collect, sum_fields=args.sum, topnbr=args.limit, skip=args.skip, least=args.least)\n        for rec in top:\n            sys.stdout.write('%s%s%s%s%s\\n' % ('(' + coma2.join((str(val) for val in rec['fields'])) + ')', sep, rec['count'], sep, coma.join((str('(' + coma2.join((str(val) for val in collected)) + ')') for collected in rec['collected'])) if rec['collected'] else ''))\n    elif args.flow_daily:\n        precision = args.precision if args.precision is not None else config.FLOW_TIME_PRECISION\n        plot_data: Dict[str, Dict[datetime.datetime, int]] = {}\n        for rec in db.flow.flow_daily(precision, query, after=time_values['after'], before=time_values['before']):\n            out.write(sep.join([rec['time_in_day'].strftime('%T.%f'), ' ; '.join(['(' + x[0] + ', ' + str(x[1]) + ')' for x in rec['flows']])]))\n            out.write('\\n')\n            if args.plot:\n                for flw in rec['flows']:\n                    t = rec['time_in_day']\n                    dt = datetime.datetime(1970, 1, 1, hour=t.hour, minute=t.minute, second=t.second)\n                    plot_data.setdefault(flw[0], {})\n                    plot_data[flw[0]][dt] = flw[1]\n        if args.plot and plot_data:\n            t = datetime.datetime(1970, 1, 1, 0, 0, 0)\n            t += datetime.timedelta(seconds=config.FLOW_TIME_BASE % precision)\n            times = []\n            while t < datetime.datetime(1970, 1, 2):\n                times.append(t)\n                t = t + datetime.timedelta(seconds=precision)\n            ax = plt.subplots()[1]\n            fmt = matplotlib.dates.DateFormatter('%H:%M:%S')\n            for (flow, data) in plot_data.items():\n                values = [data[ti] if ti in data else 0 for ti in times]\n                plt.step(times, values, '.-', where='post', label=flow)\n            plt.legend(loc='best')\n            ax.xaxis.set_major_formatter(fmt)\n            plt.gcf().autofmt_xdate()\n            plt.show()\n    else:\n        fmt = '%%s%s%%s%s%%s' % (sep, sep)\n        node_width = len('XXXX:XXXX:XXXX:XXXX:XXXX:XXXX')\n        flow_width = len('tcp/XXXXX')\n        for res in db.flow.to_iter(query, limit=args.limit, skip=args.skip, orderby=args.orderby, mode=args.mode, timeline=args.timeline):\n            if args.json:\n                out.write('%s\\n' % res)\n            else:\n                elts = {}\n                for elt in ['src', 'flow', 'dst']:\n                    elts[elt] = res[elt]['label']\n                    if args.fields:\n                        elts[elt] = '%s%s%s' % (elts[elt], coma, coma.join((str(res[elt]['data'].get(field, '')) for field in args.fields)))\n                (src, flow, dst) = (elts['src'], elts['flow'], elts['dst'])\n                node_width = max(node_width, len(src), len(dst))\n                flow_width = max(flow_width, len(flow))\n                if not args.separator:\n                    fmt = '%%-%ds%s%%-%ds%s%%-%ds' % (node_width, sep, flow_width, sep, node_width)\n                out.write(fmt % (src, flow, dst))\n                if args.timeline:\n                    out.write(sep)\n                    try:\n                        out.write(coma.join((str(elt) for elt in sorted(res['flow']['data']['meta']['times']))))\n                    except KeyError:\n                        out.write('?')\n                out.write('\\n')",
        "mutated": [
            "def main() -> None:\n    if False:\n        i = 10\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument('--init', '--purgedb', action='store_true', help='Purge or create and initialize the database.')\n    parser.add_argument('--ensure-indexes', action='store_true', help='Create missing indexes (will lock the database).')\n    parser.add_argument('--node-filters', '-n', nargs='+', metavar='FILTER', help='Filter the results with a list of ivre specific node textual filters (see WebUI doc in FLOW.md).')\n    parser.add_argument('--flow-filters', '-f', nargs='+', metavar='FILTER', help='Filter the results with a list of ivre specific flow textual filters (see WebUI doc in FLOW.md).')\n    parser.add_argument('--json', '-j', action='store_true', help='Outputs the full json records of results.')\n    parser.add_argument('--count', '-c', action='store_true', help='Only return the count of the results.')\n    parser.add_argument('--limit', '-l', type=int, default=None, help='Output at most LIMIT results.')\n    parser.add_argument('--skip', type=int, default=0, help='Skip first SKIP results.')\n    parser.add_argument('--orderby', '-o', help='Order of results (\"src\", \"dst\" or \"flow\")')\n    parser.add_argument('--separator', '-s', help='Separator string.')\n    parser.add_argument('--top', '-t', nargs='+', help='Top flows for a given set of fields, e.g. \"--top src.addr dport\".')\n    parser.add_argument('--collect', '-C', nargs='+', help='When using --top, also collect these properties.', default=[])\n    parser.add_argument('--sum', '-S', nargs='+', help='When using --top, sum on these properties to order the result.', default=[])\n    parser.add_argument('--least', '-L', action='store_true', help='When using --top, sort records by least')\n    parser.add_argument('--mode', '-m', help='Query special mode (flow_map, talk_map...)')\n    parser.add_argument('--timeline', '-T', action='store_true', help='Retrieves the timeline of each flow')\n    parser.add_argument('--flow-daily', action='store_true', help='Flow count per times of the day. If --precision is absent, it will be based on FLOW_TIME_PRECISION (%d)' % config.FLOW_TIME_PRECISION)\n    parser.add_argument('--plot', action='store_true', help='Plot data when possible (requires matplotlib).')\n    parser.add_argument('--fields', nargs='*', help='Without values, gives the list of available fields. Otherwise, display these fields for each entry.')\n    parser.add_argument('--reduce-precision', type=int, metavar='NEW_PRECISION', help='Only with MongoDB backend. Reduce precision to NEW_PRECISION for flows timeslots. Uses precision, before, after and filters.')\n    parser.add_argument('--after', '-a', type=str, help='Only with MongoDB backend. Get only flows seen after this date. Date format: YEAR-MONTH-DAY HOUR:MINUTE. Based on timeslots precision. If the given date is in the middle of a timeslot, flows start at the next timeslot.')\n    parser.add_argument('--before', '-b', type=str, help='Only with MongoDB backend. Get only flows seen before this date. Date format: YEAR-MONTH-DAY HOUR:MINUTE. Based on timeslots precision. If the given date is in the middle of a timeslot, the whole period is kept even if theoretically some flows may have been seen after the given date.')\n    parser.add_argument('--precision', nargs='?', default=None, const=0, help='Only With MongoDB backend. If PRECISION is specified, get only flows with one timeslot of the given precision. Otherwise, list precisions.', type=int)\n    parser.add_argument('--host', type=str, metavar='HOST', help='Filter on source OR destination IP. Accepts IP address or CIDR.')\n    parser.add_argument('--src', type=str, metavar='SRC', help='Filter on source IP. Accepts IP address or CIDR.')\n    parser.add_argument('--dst', type=str, metavar='DST', help='Filter on destination IP. Accepts IP address or CIDR.')\n    parser.add_argument('--proto', type=str, metavar='PROTO', help='Filter on transport protocol.')\n    parser.add_argument('--tcp', action='store_true', help='Alias to --proto tcp')\n    parser.add_argument('--udp', action='store_true', help='Alias to --proto udp')\n    parser.add_argument('--port', type=int, metavar='PORT', help='Alias to --dport')\n    parser.add_argument('--dport', type=int, metavar='DPORT', help='Filter on destination port.')\n    parser.add_argument('--sport', type=int, metavar='SPORT', help='Filter on source port.')\n    args = parser.parse_args()\n    out = sys.stdout\n    if args.plot and plt is None:\n        utils.LOGGER.critical('Matplotlib is required for --plot')\n        sys.exit(-1)\n    if args.init:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will remove any flow result in your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        db.flow.init()\n        sys.exit(0)\n    if args.ensure_indexes:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will lock your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        db.flow.ensure_indexes()\n        sys.exit(0)\n    if args.fields is not None and (not args.fields):\n        print_fields()\n        sys.exit(0)\n    elif args.fields is not None:\n        for field in args.fields:\n            ivre.flow.validate_field(field)\n    if args.precision == 0:\n        out.writelines(('%d\\n' % precision for precision in db.flow.list_precisions()))\n        sys.exit(0)\n    filters = {'nodes': args.node_filters or [], 'edges': args.flow_filters or []}\n    args_dict = vars(args)\n    for key in addr_fields:\n        if args_dict[key] is not None:\n            (flt_t, flt_v) = get_addr_argument(key, args_dict[key])\n            filters[flt_t].append(flt_v)\n    if args.proto is not None:\n        filters['edges'].append('proto = %s' % args.proto)\n    for key in ['tcp', 'udp']:\n        if args_dict[key]:\n            filters['edges'].append('proto = %s' % key)\n    for key in ['port', 'dport']:\n        if args_dict[key] is not None:\n            filters['edges'].append('dport = %d' % args_dict[key])\n    if args.sport is not None:\n        filters['edges'].append('ANY sports = %d' % args.sport)\n    time_args = ['before', 'after']\n    time_values = {}\n    for arg in time_args:\n        time_values[arg] = datetime.datetime.strptime(args_dict[arg], '%Y-%m-%d %H:%M') if args_dict[arg] is not None else None\n    query = db.flow.from_filters(filters, limit=args.limit, skip=args.skip, orderby=args.orderby, mode=args.mode, timeline=args.timeline, after=time_values['after'], before=time_values['before'], precision=args.precision)\n    if args.reduce_precision:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will permanently reduce the precision of your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        new_precision = args.reduce_precision\n        db.flow.reduce_precision(new_precision, flt=query, before=time_values['before'], after=time_values['after'], current_precision=args.precision)\n        sys.exit(0)\n    sep = args.separator or ' | '\n    coma = ' ;' if args.separator else ' ; '\n    coma2 = ',' if args.separator else ', '\n    if args.count:\n        count = db.flow.count(query)\n        out.write('%(clients)d clients\\n%(servers)d servers\\n%(flows)d flows\\n' % count)\n    elif args.top:\n        top = db.flow.topvalues(query, args.top, collect_fields=args.collect, sum_fields=args.sum, topnbr=args.limit, skip=args.skip, least=args.least)\n        for rec in top:\n            sys.stdout.write('%s%s%s%s%s\\n' % ('(' + coma2.join((str(val) for val in rec['fields'])) + ')', sep, rec['count'], sep, coma.join((str('(' + coma2.join((str(val) for val in collected)) + ')') for collected in rec['collected'])) if rec['collected'] else ''))\n    elif args.flow_daily:\n        precision = args.precision if args.precision is not None else config.FLOW_TIME_PRECISION\n        plot_data: Dict[str, Dict[datetime.datetime, int]] = {}\n        for rec in db.flow.flow_daily(precision, query, after=time_values['after'], before=time_values['before']):\n            out.write(sep.join([rec['time_in_day'].strftime('%T.%f'), ' ; '.join(['(' + x[0] + ', ' + str(x[1]) + ')' for x in rec['flows']])]))\n            out.write('\\n')\n            if args.plot:\n                for flw in rec['flows']:\n                    t = rec['time_in_day']\n                    dt = datetime.datetime(1970, 1, 1, hour=t.hour, minute=t.minute, second=t.second)\n                    plot_data.setdefault(flw[0], {})\n                    plot_data[flw[0]][dt] = flw[1]\n        if args.plot and plot_data:\n            t = datetime.datetime(1970, 1, 1, 0, 0, 0)\n            t += datetime.timedelta(seconds=config.FLOW_TIME_BASE % precision)\n            times = []\n            while t < datetime.datetime(1970, 1, 2):\n                times.append(t)\n                t = t + datetime.timedelta(seconds=precision)\n            ax = plt.subplots()[1]\n            fmt = matplotlib.dates.DateFormatter('%H:%M:%S')\n            for (flow, data) in plot_data.items():\n                values = [data[ti] if ti in data else 0 for ti in times]\n                plt.step(times, values, '.-', where='post', label=flow)\n            plt.legend(loc='best')\n            ax.xaxis.set_major_formatter(fmt)\n            plt.gcf().autofmt_xdate()\n            plt.show()\n    else:\n        fmt = '%%s%s%%s%s%%s' % (sep, sep)\n        node_width = len('XXXX:XXXX:XXXX:XXXX:XXXX:XXXX')\n        flow_width = len('tcp/XXXXX')\n        for res in db.flow.to_iter(query, limit=args.limit, skip=args.skip, orderby=args.orderby, mode=args.mode, timeline=args.timeline):\n            if args.json:\n                out.write('%s\\n' % res)\n            else:\n                elts = {}\n                for elt in ['src', 'flow', 'dst']:\n                    elts[elt] = res[elt]['label']\n                    if args.fields:\n                        elts[elt] = '%s%s%s' % (elts[elt], coma, coma.join((str(res[elt]['data'].get(field, '')) for field in args.fields)))\n                (src, flow, dst) = (elts['src'], elts['flow'], elts['dst'])\n                node_width = max(node_width, len(src), len(dst))\n                flow_width = max(flow_width, len(flow))\n                if not args.separator:\n                    fmt = '%%-%ds%s%%-%ds%s%%-%ds' % (node_width, sep, flow_width, sep, node_width)\n                out.write(fmt % (src, flow, dst))\n                if args.timeline:\n                    out.write(sep)\n                    try:\n                        out.write(coma.join((str(elt) for elt in sorted(res['flow']['data']['meta']['times']))))\n                    except KeyError:\n                        out.write('?')\n                out.write('\\n')",
            "def main() -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument('--init', '--purgedb', action='store_true', help='Purge or create and initialize the database.')\n    parser.add_argument('--ensure-indexes', action='store_true', help='Create missing indexes (will lock the database).')\n    parser.add_argument('--node-filters', '-n', nargs='+', metavar='FILTER', help='Filter the results with a list of ivre specific node textual filters (see WebUI doc in FLOW.md).')\n    parser.add_argument('--flow-filters', '-f', nargs='+', metavar='FILTER', help='Filter the results with a list of ivre specific flow textual filters (see WebUI doc in FLOW.md).')\n    parser.add_argument('--json', '-j', action='store_true', help='Outputs the full json records of results.')\n    parser.add_argument('--count', '-c', action='store_true', help='Only return the count of the results.')\n    parser.add_argument('--limit', '-l', type=int, default=None, help='Output at most LIMIT results.')\n    parser.add_argument('--skip', type=int, default=0, help='Skip first SKIP results.')\n    parser.add_argument('--orderby', '-o', help='Order of results (\"src\", \"dst\" or \"flow\")')\n    parser.add_argument('--separator', '-s', help='Separator string.')\n    parser.add_argument('--top', '-t', nargs='+', help='Top flows for a given set of fields, e.g. \"--top src.addr dport\".')\n    parser.add_argument('--collect', '-C', nargs='+', help='When using --top, also collect these properties.', default=[])\n    parser.add_argument('--sum', '-S', nargs='+', help='When using --top, sum on these properties to order the result.', default=[])\n    parser.add_argument('--least', '-L', action='store_true', help='When using --top, sort records by least')\n    parser.add_argument('--mode', '-m', help='Query special mode (flow_map, talk_map...)')\n    parser.add_argument('--timeline', '-T', action='store_true', help='Retrieves the timeline of each flow')\n    parser.add_argument('--flow-daily', action='store_true', help='Flow count per times of the day. If --precision is absent, it will be based on FLOW_TIME_PRECISION (%d)' % config.FLOW_TIME_PRECISION)\n    parser.add_argument('--plot', action='store_true', help='Plot data when possible (requires matplotlib).')\n    parser.add_argument('--fields', nargs='*', help='Without values, gives the list of available fields. Otherwise, display these fields for each entry.')\n    parser.add_argument('--reduce-precision', type=int, metavar='NEW_PRECISION', help='Only with MongoDB backend. Reduce precision to NEW_PRECISION for flows timeslots. Uses precision, before, after and filters.')\n    parser.add_argument('--after', '-a', type=str, help='Only with MongoDB backend. Get only flows seen after this date. Date format: YEAR-MONTH-DAY HOUR:MINUTE. Based on timeslots precision. If the given date is in the middle of a timeslot, flows start at the next timeslot.')\n    parser.add_argument('--before', '-b', type=str, help='Only with MongoDB backend. Get only flows seen before this date. Date format: YEAR-MONTH-DAY HOUR:MINUTE. Based on timeslots precision. If the given date is in the middle of a timeslot, the whole period is kept even if theoretically some flows may have been seen after the given date.')\n    parser.add_argument('--precision', nargs='?', default=None, const=0, help='Only With MongoDB backend. If PRECISION is specified, get only flows with one timeslot of the given precision. Otherwise, list precisions.', type=int)\n    parser.add_argument('--host', type=str, metavar='HOST', help='Filter on source OR destination IP. Accepts IP address or CIDR.')\n    parser.add_argument('--src', type=str, metavar='SRC', help='Filter on source IP. Accepts IP address or CIDR.')\n    parser.add_argument('--dst', type=str, metavar='DST', help='Filter on destination IP. Accepts IP address or CIDR.')\n    parser.add_argument('--proto', type=str, metavar='PROTO', help='Filter on transport protocol.')\n    parser.add_argument('--tcp', action='store_true', help='Alias to --proto tcp')\n    parser.add_argument('--udp', action='store_true', help='Alias to --proto udp')\n    parser.add_argument('--port', type=int, metavar='PORT', help='Alias to --dport')\n    parser.add_argument('--dport', type=int, metavar='DPORT', help='Filter on destination port.')\n    parser.add_argument('--sport', type=int, metavar='SPORT', help='Filter on source port.')\n    args = parser.parse_args()\n    out = sys.stdout\n    if args.plot and plt is None:\n        utils.LOGGER.critical('Matplotlib is required for --plot')\n        sys.exit(-1)\n    if args.init:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will remove any flow result in your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        db.flow.init()\n        sys.exit(0)\n    if args.ensure_indexes:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will lock your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        db.flow.ensure_indexes()\n        sys.exit(0)\n    if args.fields is not None and (not args.fields):\n        print_fields()\n        sys.exit(0)\n    elif args.fields is not None:\n        for field in args.fields:\n            ivre.flow.validate_field(field)\n    if args.precision == 0:\n        out.writelines(('%d\\n' % precision for precision in db.flow.list_precisions()))\n        sys.exit(0)\n    filters = {'nodes': args.node_filters or [], 'edges': args.flow_filters or []}\n    args_dict = vars(args)\n    for key in addr_fields:\n        if args_dict[key] is not None:\n            (flt_t, flt_v) = get_addr_argument(key, args_dict[key])\n            filters[flt_t].append(flt_v)\n    if args.proto is not None:\n        filters['edges'].append('proto = %s' % args.proto)\n    for key in ['tcp', 'udp']:\n        if args_dict[key]:\n            filters['edges'].append('proto = %s' % key)\n    for key in ['port', 'dport']:\n        if args_dict[key] is not None:\n            filters['edges'].append('dport = %d' % args_dict[key])\n    if args.sport is not None:\n        filters['edges'].append('ANY sports = %d' % args.sport)\n    time_args = ['before', 'after']\n    time_values = {}\n    for arg in time_args:\n        time_values[arg] = datetime.datetime.strptime(args_dict[arg], '%Y-%m-%d %H:%M') if args_dict[arg] is not None else None\n    query = db.flow.from_filters(filters, limit=args.limit, skip=args.skip, orderby=args.orderby, mode=args.mode, timeline=args.timeline, after=time_values['after'], before=time_values['before'], precision=args.precision)\n    if args.reduce_precision:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will permanently reduce the precision of your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        new_precision = args.reduce_precision\n        db.flow.reduce_precision(new_precision, flt=query, before=time_values['before'], after=time_values['after'], current_precision=args.precision)\n        sys.exit(0)\n    sep = args.separator or ' | '\n    coma = ' ;' if args.separator else ' ; '\n    coma2 = ',' if args.separator else ', '\n    if args.count:\n        count = db.flow.count(query)\n        out.write('%(clients)d clients\\n%(servers)d servers\\n%(flows)d flows\\n' % count)\n    elif args.top:\n        top = db.flow.topvalues(query, args.top, collect_fields=args.collect, sum_fields=args.sum, topnbr=args.limit, skip=args.skip, least=args.least)\n        for rec in top:\n            sys.stdout.write('%s%s%s%s%s\\n' % ('(' + coma2.join((str(val) for val in rec['fields'])) + ')', sep, rec['count'], sep, coma.join((str('(' + coma2.join((str(val) for val in collected)) + ')') for collected in rec['collected'])) if rec['collected'] else ''))\n    elif args.flow_daily:\n        precision = args.precision if args.precision is not None else config.FLOW_TIME_PRECISION\n        plot_data: Dict[str, Dict[datetime.datetime, int]] = {}\n        for rec in db.flow.flow_daily(precision, query, after=time_values['after'], before=time_values['before']):\n            out.write(sep.join([rec['time_in_day'].strftime('%T.%f'), ' ; '.join(['(' + x[0] + ', ' + str(x[1]) + ')' for x in rec['flows']])]))\n            out.write('\\n')\n            if args.plot:\n                for flw in rec['flows']:\n                    t = rec['time_in_day']\n                    dt = datetime.datetime(1970, 1, 1, hour=t.hour, minute=t.minute, second=t.second)\n                    plot_data.setdefault(flw[0], {})\n                    plot_data[flw[0]][dt] = flw[1]\n        if args.plot and plot_data:\n            t = datetime.datetime(1970, 1, 1, 0, 0, 0)\n            t += datetime.timedelta(seconds=config.FLOW_TIME_BASE % precision)\n            times = []\n            while t < datetime.datetime(1970, 1, 2):\n                times.append(t)\n                t = t + datetime.timedelta(seconds=precision)\n            ax = plt.subplots()[1]\n            fmt = matplotlib.dates.DateFormatter('%H:%M:%S')\n            for (flow, data) in plot_data.items():\n                values = [data[ti] if ti in data else 0 for ti in times]\n                plt.step(times, values, '.-', where='post', label=flow)\n            plt.legend(loc='best')\n            ax.xaxis.set_major_formatter(fmt)\n            plt.gcf().autofmt_xdate()\n            plt.show()\n    else:\n        fmt = '%%s%s%%s%s%%s' % (sep, sep)\n        node_width = len('XXXX:XXXX:XXXX:XXXX:XXXX:XXXX')\n        flow_width = len('tcp/XXXXX')\n        for res in db.flow.to_iter(query, limit=args.limit, skip=args.skip, orderby=args.orderby, mode=args.mode, timeline=args.timeline):\n            if args.json:\n                out.write('%s\\n' % res)\n            else:\n                elts = {}\n                for elt in ['src', 'flow', 'dst']:\n                    elts[elt] = res[elt]['label']\n                    if args.fields:\n                        elts[elt] = '%s%s%s' % (elts[elt], coma, coma.join((str(res[elt]['data'].get(field, '')) for field in args.fields)))\n                (src, flow, dst) = (elts['src'], elts['flow'], elts['dst'])\n                node_width = max(node_width, len(src), len(dst))\n                flow_width = max(flow_width, len(flow))\n                if not args.separator:\n                    fmt = '%%-%ds%s%%-%ds%s%%-%ds' % (node_width, sep, flow_width, sep, node_width)\n                out.write(fmt % (src, flow, dst))\n                if args.timeline:\n                    out.write(sep)\n                    try:\n                        out.write(coma.join((str(elt) for elt in sorted(res['flow']['data']['meta']['times']))))\n                    except KeyError:\n                        out.write('?')\n                out.write('\\n')",
            "def main() -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument('--init', '--purgedb', action='store_true', help='Purge or create and initialize the database.')\n    parser.add_argument('--ensure-indexes', action='store_true', help='Create missing indexes (will lock the database).')\n    parser.add_argument('--node-filters', '-n', nargs='+', metavar='FILTER', help='Filter the results with a list of ivre specific node textual filters (see WebUI doc in FLOW.md).')\n    parser.add_argument('--flow-filters', '-f', nargs='+', metavar='FILTER', help='Filter the results with a list of ivre specific flow textual filters (see WebUI doc in FLOW.md).')\n    parser.add_argument('--json', '-j', action='store_true', help='Outputs the full json records of results.')\n    parser.add_argument('--count', '-c', action='store_true', help='Only return the count of the results.')\n    parser.add_argument('--limit', '-l', type=int, default=None, help='Output at most LIMIT results.')\n    parser.add_argument('--skip', type=int, default=0, help='Skip first SKIP results.')\n    parser.add_argument('--orderby', '-o', help='Order of results (\"src\", \"dst\" or \"flow\")')\n    parser.add_argument('--separator', '-s', help='Separator string.')\n    parser.add_argument('--top', '-t', nargs='+', help='Top flows for a given set of fields, e.g. \"--top src.addr dport\".')\n    parser.add_argument('--collect', '-C', nargs='+', help='When using --top, also collect these properties.', default=[])\n    parser.add_argument('--sum', '-S', nargs='+', help='When using --top, sum on these properties to order the result.', default=[])\n    parser.add_argument('--least', '-L', action='store_true', help='When using --top, sort records by least')\n    parser.add_argument('--mode', '-m', help='Query special mode (flow_map, talk_map...)')\n    parser.add_argument('--timeline', '-T', action='store_true', help='Retrieves the timeline of each flow')\n    parser.add_argument('--flow-daily', action='store_true', help='Flow count per times of the day. If --precision is absent, it will be based on FLOW_TIME_PRECISION (%d)' % config.FLOW_TIME_PRECISION)\n    parser.add_argument('--plot', action='store_true', help='Plot data when possible (requires matplotlib).')\n    parser.add_argument('--fields', nargs='*', help='Without values, gives the list of available fields. Otherwise, display these fields for each entry.')\n    parser.add_argument('--reduce-precision', type=int, metavar='NEW_PRECISION', help='Only with MongoDB backend. Reduce precision to NEW_PRECISION for flows timeslots. Uses precision, before, after and filters.')\n    parser.add_argument('--after', '-a', type=str, help='Only with MongoDB backend. Get only flows seen after this date. Date format: YEAR-MONTH-DAY HOUR:MINUTE. Based on timeslots precision. If the given date is in the middle of a timeslot, flows start at the next timeslot.')\n    parser.add_argument('--before', '-b', type=str, help='Only with MongoDB backend. Get only flows seen before this date. Date format: YEAR-MONTH-DAY HOUR:MINUTE. Based on timeslots precision. If the given date is in the middle of a timeslot, the whole period is kept even if theoretically some flows may have been seen after the given date.')\n    parser.add_argument('--precision', nargs='?', default=None, const=0, help='Only With MongoDB backend. If PRECISION is specified, get only flows with one timeslot of the given precision. Otherwise, list precisions.', type=int)\n    parser.add_argument('--host', type=str, metavar='HOST', help='Filter on source OR destination IP. Accepts IP address or CIDR.')\n    parser.add_argument('--src', type=str, metavar='SRC', help='Filter on source IP. Accepts IP address or CIDR.')\n    parser.add_argument('--dst', type=str, metavar='DST', help='Filter on destination IP. Accepts IP address or CIDR.')\n    parser.add_argument('--proto', type=str, metavar='PROTO', help='Filter on transport protocol.')\n    parser.add_argument('--tcp', action='store_true', help='Alias to --proto tcp')\n    parser.add_argument('--udp', action='store_true', help='Alias to --proto udp')\n    parser.add_argument('--port', type=int, metavar='PORT', help='Alias to --dport')\n    parser.add_argument('--dport', type=int, metavar='DPORT', help='Filter on destination port.')\n    parser.add_argument('--sport', type=int, metavar='SPORT', help='Filter on source port.')\n    args = parser.parse_args()\n    out = sys.stdout\n    if args.plot and plt is None:\n        utils.LOGGER.critical('Matplotlib is required for --plot')\n        sys.exit(-1)\n    if args.init:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will remove any flow result in your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        db.flow.init()\n        sys.exit(0)\n    if args.ensure_indexes:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will lock your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        db.flow.ensure_indexes()\n        sys.exit(0)\n    if args.fields is not None and (not args.fields):\n        print_fields()\n        sys.exit(0)\n    elif args.fields is not None:\n        for field in args.fields:\n            ivre.flow.validate_field(field)\n    if args.precision == 0:\n        out.writelines(('%d\\n' % precision for precision in db.flow.list_precisions()))\n        sys.exit(0)\n    filters = {'nodes': args.node_filters or [], 'edges': args.flow_filters or []}\n    args_dict = vars(args)\n    for key in addr_fields:\n        if args_dict[key] is not None:\n            (flt_t, flt_v) = get_addr_argument(key, args_dict[key])\n            filters[flt_t].append(flt_v)\n    if args.proto is not None:\n        filters['edges'].append('proto = %s' % args.proto)\n    for key in ['tcp', 'udp']:\n        if args_dict[key]:\n            filters['edges'].append('proto = %s' % key)\n    for key in ['port', 'dport']:\n        if args_dict[key] is not None:\n            filters['edges'].append('dport = %d' % args_dict[key])\n    if args.sport is not None:\n        filters['edges'].append('ANY sports = %d' % args.sport)\n    time_args = ['before', 'after']\n    time_values = {}\n    for arg in time_args:\n        time_values[arg] = datetime.datetime.strptime(args_dict[arg], '%Y-%m-%d %H:%M') if args_dict[arg] is not None else None\n    query = db.flow.from_filters(filters, limit=args.limit, skip=args.skip, orderby=args.orderby, mode=args.mode, timeline=args.timeline, after=time_values['after'], before=time_values['before'], precision=args.precision)\n    if args.reduce_precision:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will permanently reduce the precision of your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        new_precision = args.reduce_precision\n        db.flow.reduce_precision(new_precision, flt=query, before=time_values['before'], after=time_values['after'], current_precision=args.precision)\n        sys.exit(0)\n    sep = args.separator or ' | '\n    coma = ' ;' if args.separator else ' ; '\n    coma2 = ',' if args.separator else ', '\n    if args.count:\n        count = db.flow.count(query)\n        out.write('%(clients)d clients\\n%(servers)d servers\\n%(flows)d flows\\n' % count)\n    elif args.top:\n        top = db.flow.topvalues(query, args.top, collect_fields=args.collect, sum_fields=args.sum, topnbr=args.limit, skip=args.skip, least=args.least)\n        for rec in top:\n            sys.stdout.write('%s%s%s%s%s\\n' % ('(' + coma2.join((str(val) for val in rec['fields'])) + ')', sep, rec['count'], sep, coma.join((str('(' + coma2.join((str(val) for val in collected)) + ')') for collected in rec['collected'])) if rec['collected'] else ''))\n    elif args.flow_daily:\n        precision = args.precision if args.precision is not None else config.FLOW_TIME_PRECISION\n        plot_data: Dict[str, Dict[datetime.datetime, int]] = {}\n        for rec in db.flow.flow_daily(precision, query, after=time_values['after'], before=time_values['before']):\n            out.write(sep.join([rec['time_in_day'].strftime('%T.%f'), ' ; '.join(['(' + x[0] + ', ' + str(x[1]) + ')' for x in rec['flows']])]))\n            out.write('\\n')\n            if args.plot:\n                for flw in rec['flows']:\n                    t = rec['time_in_day']\n                    dt = datetime.datetime(1970, 1, 1, hour=t.hour, minute=t.minute, second=t.second)\n                    plot_data.setdefault(flw[0], {})\n                    plot_data[flw[0]][dt] = flw[1]\n        if args.plot and plot_data:\n            t = datetime.datetime(1970, 1, 1, 0, 0, 0)\n            t += datetime.timedelta(seconds=config.FLOW_TIME_BASE % precision)\n            times = []\n            while t < datetime.datetime(1970, 1, 2):\n                times.append(t)\n                t = t + datetime.timedelta(seconds=precision)\n            ax = plt.subplots()[1]\n            fmt = matplotlib.dates.DateFormatter('%H:%M:%S')\n            for (flow, data) in plot_data.items():\n                values = [data[ti] if ti in data else 0 for ti in times]\n                plt.step(times, values, '.-', where='post', label=flow)\n            plt.legend(loc='best')\n            ax.xaxis.set_major_formatter(fmt)\n            plt.gcf().autofmt_xdate()\n            plt.show()\n    else:\n        fmt = '%%s%s%%s%s%%s' % (sep, sep)\n        node_width = len('XXXX:XXXX:XXXX:XXXX:XXXX:XXXX')\n        flow_width = len('tcp/XXXXX')\n        for res in db.flow.to_iter(query, limit=args.limit, skip=args.skip, orderby=args.orderby, mode=args.mode, timeline=args.timeline):\n            if args.json:\n                out.write('%s\\n' % res)\n            else:\n                elts = {}\n                for elt in ['src', 'flow', 'dst']:\n                    elts[elt] = res[elt]['label']\n                    if args.fields:\n                        elts[elt] = '%s%s%s' % (elts[elt], coma, coma.join((str(res[elt]['data'].get(field, '')) for field in args.fields)))\n                (src, flow, dst) = (elts['src'], elts['flow'], elts['dst'])\n                node_width = max(node_width, len(src), len(dst))\n                flow_width = max(flow_width, len(flow))\n                if not args.separator:\n                    fmt = '%%-%ds%s%%-%ds%s%%-%ds' % (node_width, sep, flow_width, sep, node_width)\n                out.write(fmt % (src, flow, dst))\n                if args.timeline:\n                    out.write(sep)\n                    try:\n                        out.write(coma.join((str(elt) for elt in sorted(res['flow']['data']['meta']['times']))))\n                    except KeyError:\n                        out.write('?')\n                out.write('\\n')",
            "def main() -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument('--init', '--purgedb', action='store_true', help='Purge or create and initialize the database.')\n    parser.add_argument('--ensure-indexes', action='store_true', help='Create missing indexes (will lock the database).')\n    parser.add_argument('--node-filters', '-n', nargs='+', metavar='FILTER', help='Filter the results with a list of ivre specific node textual filters (see WebUI doc in FLOW.md).')\n    parser.add_argument('--flow-filters', '-f', nargs='+', metavar='FILTER', help='Filter the results with a list of ivre specific flow textual filters (see WebUI doc in FLOW.md).')\n    parser.add_argument('--json', '-j', action='store_true', help='Outputs the full json records of results.')\n    parser.add_argument('--count', '-c', action='store_true', help='Only return the count of the results.')\n    parser.add_argument('--limit', '-l', type=int, default=None, help='Output at most LIMIT results.')\n    parser.add_argument('--skip', type=int, default=0, help='Skip first SKIP results.')\n    parser.add_argument('--orderby', '-o', help='Order of results (\"src\", \"dst\" or \"flow\")')\n    parser.add_argument('--separator', '-s', help='Separator string.')\n    parser.add_argument('--top', '-t', nargs='+', help='Top flows for a given set of fields, e.g. \"--top src.addr dport\".')\n    parser.add_argument('--collect', '-C', nargs='+', help='When using --top, also collect these properties.', default=[])\n    parser.add_argument('--sum', '-S', nargs='+', help='When using --top, sum on these properties to order the result.', default=[])\n    parser.add_argument('--least', '-L', action='store_true', help='When using --top, sort records by least')\n    parser.add_argument('--mode', '-m', help='Query special mode (flow_map, talk_map...)')\n    parser.add_argument('--timeline', '-T', action='store_true', help='Retrieves the timeline of each flow')\n    parser.add_argument('--flow-daily', action='store_true', help='Flow count per times of the day. If --precision is absent, it will be based on FLOW_TIME_PRECISION (%d)' % config.FLOW_TIME_PRECISION)\n    parser.add_argument('--plot', action='store_true', help='Plot data when possible (requires matplotlib).')\n    parser.add_argument('--fields', nargs='*', help='Without values, gives the list of available fields. Otherwise, display these fields for each entry.')\n    parser.add_argument('--reduce-precision', type=int, metavar='NEW_PRECISION', help='Only with MongoDB backend. Reduce precision to NEW_PRECISION for flows timeslots. Uses precision, before, after and filters.')\n    parser.add_argument('--after', '-a', type=str, help='Only with MongoDB backend. Get only flows seen after this date. Date format: YEAR-MONTH-DAY HOUR:MINUTE. Based on timeslots precision. If the given date is in the middle of a timeslot, flows start at the next timeslot.')\n    parser.add_argument('--before', '-b', type=str, help='Only with MongoDB backend. Get only flows seen before this date. Date format: YEAR-MONTH-DAY HOUR:MINUTE. Based on timeslots precision. If the given date is in the middle of a timeslot, the whole period is kept even if theoretically some flows may have been seen after the given date.')\n    parser.add_argument('--precision', nargs='?', default=None, const=0, help='Only With MongoDB backend. If PRECISION is specified, get only flows with one timeslot of the given precision. Otherwise, list precisions.', type=int)\n    parser.add_argument('--host', type=str, metavar='HOST', help='Filter on source OR destination IP. Accepts IP address or CIDR.')\n    parser.add_argument('--src', type=str, metavar='SRC', help='Filter on source IP. Accepts IP address or CIDR.')\n    parser.add_argument('--dst', type=str, metavar='DST', help='Filter on destination IP. Accepts IP address or CIDR.')\n    parser.add_argument('--proto', type=str, metavar='PROTO', help='Filter on transport protocol.')\n    parser.add_argument('--tcp', action='store_true', help='Alias to --proto tcp')\n    parser.add_argument('--udp', action='store_true', help='Alias to --proto udp')\n    parser.add_argument('--port', type=int, metavar='PORT', help='Alias to --dport')\n    parser.add_argument('--dport', type=int, metavar='DPORT', help='Filter on destination port.')\n    parser.add_argument('--sport', type=int, metavar='SPORT', help='Filter on source port.')\n    args = parser.parse_args()\n    out = sys.stdout\n    if args.plot and plt is None:\n        utils.LOGGER.critical('Matplotlib is required for --plot')\n        sys.exit(-1)\n    if args.init:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will remove any flow result in your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        db.flow.init()\n        sys.exit(0)\n    if args.ensure_indexes:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will lock your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        db.flow.ensure_indexes()\n        sys.exit(0)\n    if args.fields is not None and (not args.fields):\n        print_fields()\n        sys.exit(0)\n    elif args.fields is not None:\n        for field in args.fields:\n            ivre.flow.validate_field(field)\n    if args.precision == 0:\n        out.writelines(('%d\\n' % precision for precision in db.flow.list_precisions()))\n        sys.exit(0)\n    filters = {'nodes': args.node_filters or [], 'edges': args.flow_filters or []}\n    args_dict = vars(args)\n    for key in addr_fields:\n        if args_dict[key] is not None:\n            (flt_t, flt_v) = get_addr_argument(key, args_dict[key])\n            filters[flt_t].append(flt_v)\n    if args.proto is not None:\n        filters['edges'].append('proto = %s' % args.proto)\n    for key in ['tcp', 'udp']:\n        if args_dict[key]:\n            filters['edges'].append('proto = %s' % key)\n    for key in ['port', 'dport']:\n        if args_dict[key] is not None:\n            filters['edges'].append('dport = %d' % args_dict[key])\n    if args.sport is not None:\n        filters['edges'].append('ANY sports = %d' % args.sport)\n    time_args = ['before', 'after']\n    time_values = {}\n    for arg in time_args:\n        time_values[arg] = datetime.datetime.strptime(args_dict[arg], '%Y-%m-%d %H:%M') if args_dict[arg] is not None else None\n    query = db.flow.from_filters(filters, limit=args.limit, skip=args.skip, orderby=args.orderby, mode=args.mode, timeline=args.timeline, after=time_values['after'], before=time_values['before'], precision=args.precision)\n    if args.reduce_precision:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will permanently reduce the precision of your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        new_precision = args.reduce_precision\n        db.flow.reduce_precision(new_precision, flt=query, before=time_values['before'], after=time_values['after'], current_precision=args.precision)\n        sys.exit(0)\n    sep = args.separator or ' | '\n    coma = ' ;' if args.separator else ' ; '\n    coma2 = ',' if args.separator else ', '\n    if args.count:\n        count = db.flow.count(query)\n        out.write('%(clients)d clients\\n%(servers)d servers\\n%(flows)d flows\\n' % count)\n    elif args.top:\n        top = db.flow.topvalues(query, args.top, collect_fields=args.collect, sum_fields=args.sum, topnbr=args.limit, skip=args.skip, least=args.least)\n        for rec in top:\n            sys.stdout.write('%s%s%s%s%s\\n' % ('(' + coma2.join((str(val) for val in rec['fields'])) + ')', sep, rec['count'], sep, coma.join((str('(' + coma2.join((str(val) for val in collected)) + ')') for collected in rec['collected'])) if rec['collected'] else ''))\n    elif args.flow_daily:\n        precision = args.precision if args.precision is not None else config.FLOW_TIME_PRECISION\n        plot_data: Dict[str, Dict[datetime.datetime, int]] = {}\n        for rec in db.flow.flow_daily(precision, query, after=time_values['after'], before=time_values['before']):\n            out.write(sep.join([rec['time_in_day'].strftime('%T.%f'), ' ; '.join(['(' + x[0] + ', ' + str(x[1]) + ')' for x in rec['flows']])]))\n            out.write('\\n')\n            if args.plot:\n                for flw in rec['flows']:\n                    t = rec['time_in_day']\n                    dt = datetime.datetime(1970, 1, 1, hour=t.hour, minute=t.minute, second=t.second)\n                    plot_data.setdefault(flw[0], {})\n                    plot_data[flw[0]][dt] = flw[1]\n        if args.plot and plot_data:\n            t = datetime.datetime(1970, 1, 1, 0, 0, 0)\n            t += datetime.timedelta(seconds=config.FLOW_TIME_BASE % precision)\n            times = []\n            while t < datetime.datetime(1970, 1, 2):\n                times.append(t)\n                t = t + datetime.timedelta(seconds=precision)\n            ax = plt.subplots()[1]\n            fmt = matplotlib.dates.DateFormatter('%H:%M:%S')\n            for (flow, data) in plot_data.items():\n                values = [data[ti] if ti in data else 0 for ti in times]\n                plt.step(times, values, '.-', where='post', label=flow)\n            plt.legend(loc='best')\n            ax.xaxis.set_major_formatter(fmt)\n            plt.gcf().autofmt_xdate()\n            plt.show()\n    else:\n        fmt = '%%s%s%%s%s%%s' % (sep, sep)\n        node_width = len('XXXX:XXXX:XXXX:XXXX:XXXX:XXXX')\n        flow_width = len('tcp/XXXXX')\n        for res in db.flow.to_iter(query, limit=args.limit, skip=args.skip, orderby=args.orderby, mode=args.mode, timeline=args.timeline):\n            if args.json:\n                out.write('%s\\n' % res)\n            else:\n                elts = {}\n                for elt in ['src', 'flow', 'dst']:\n                    elts[elt] = res[elt]['label']\n                    if args.fields:\n                        elts[elt] = '%s%s%s' % (elts[elt], coma, coma.join((str(res[elt]['data'].get(field, '')) for field in args.fields)))\n                (src, flow, dst) = (elts['src'], elts['flow'], elts['dst'])\n                node_width = max(node_width, len(src), len(dst))\n                flow_width = max(flow_width, len(flow))\n                if not args.separator:\n                    fmt = '%%-%ds%s%%-%ds%s%%-%ds' % (node_width, sep, flow_width, sep, node_width)\n                out.write(fmt % (src, flow, dst))\n                if args.timeline:\n                    out.write(sep)\n                    try:\n                        out.write(coma.join((str(elt) for elt in sorted(res['flow']['data']['meta']['times']))))\n                    except KeyError:\n                        out.write('?')\n                out.write('\\n')",
            "def main() -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument('--init', '--purgedb', action='store_true', help='Purge or create and initialize the database.')\n    parser.add_argument('--ensure-indexes', action='store_true', help='Create missing indexes (will lock the database).')\n    parser.add_argument('--node-filters', '-n', nargs='+', metavar='FILTER', help='Filter the results with a list of ivre specific node textual filters (see WebUI doc in FLOW.md).')\n    parser.add_argument('--flow-filters', '-f', nargs='+', metavar='FILTER', help='Filter the results with a list of ivre specific flow textual filters (see WebUI doc in FLOW.md).')\n    parser.add_argument('--json', '-j', action='store_true', help='Outputs the full json records of results.')\n    parser.add_argument('--count', '-c', action='store_true', help='Only return the count of the results.')\n    parser.add_argument('--limit', '-l', type=int, default=None, help='Output at most LIMIT results.')\n    parser.add_argument('--skip', type=int, default=0, help='Skip first SKIP results.')\n    parser.add_argument('--orderby', '-o', help='Order of results (\"src\", \"dst\" or \"flow\")')\n    parser.add_argument('--separator', '-s', help='Separator string.')\n    parser.add_argument('--top', '-t', nargs='+', help='Top flows for a given set of fields, e.g. \"--top src.addr dport\".')\n    parser.add_argument('--collect', '-C', nargs='+', help='When using --top, also collect these properties.', default=[])\n    parser.add_argument('--sum', '-S', nargs='+', help='When using --top, sum on these properties to order the result.', default=[])\n    parser.add_argument('--least', '-L', action='store_true', help='When using --top, sort records by least')\n    parser.add_argument('--mode', '-m', help='Query special mode (flow_map, talk_map...)')\n    parser.add_argument('--timeline', '-T', action='store_true', help='Retrieves the timeline of each flow')\n    parser.add_argument('--flow-daily', action='store_true', help='Flow count per times of the day. If --precision is absent, it will be based on FLOW_TIME_PRECISION (%d)' % config.FLOW_TIME_PRECISION)\n    parser.add_argument('--plot', action='store_true', help='Plot data when possible (requires matplotlib).')\n    parser.add_argument('--fields', nargs='*', help='Without values, gives the list of available fields. Otherwise, display these fields for each entry.')\n    parser.add_argument('--reduce-precision', type=int, metavar='NEW_PRECISION', help='Only with MongoDB backend. Reduce precision to NEW_PRECISION for flows timeslots. Uses precision, before, after and filters.')\n    parser.add_argument('--after', '-a', type=str, help='Only with MongoDB backend. Get only flows seen after this date. Date format: YEAR-MONTH-DAY HOUR:MINUTE. Based on timeslots precision. If the given date is in the middle of a timeslot, flows start at the next timeslot.')\n    parser.add_argument('--before', '-b', type=str, help='Only with MongoDB backend. Get only flows seen before this date. Date format: YEAR-MONTH-DAY HOUR:MINUTE. Based on timeslots precision. If the given date is in the middle of a timeslot, the whole period is kept even if theoretically some flows may have been seen after the given date.')\n    parser.add_argument('--precision', nargs='?', default=None, const=0, help='Only With MongoDB backend. If PRECISION is specified, get only flows with one timeslot of the given precision. Otherwise, list precisions.', type=int)\n    parser.add_argument('--host', type=str, metavar='HOST', help='Filter on source OR destination IP. Accepts IP address or CIDR.')\n    parser.add_argument('--src', type=str, metavar='SRC', help='Filter on source IP. Accepts IP address or CIDR.')\n    parser.add_argument('--dst', type=str, metavar='DST', help='Filter on destination IP. Accepts IP address or CIDR.')\n    parser.add_argument('--proto', type=str, metavar='PROTO', help='Filter on transport protocol.')\n    parser.add_argument('--tcp', action='store_true', help='Alias to --proto tcp')\n    parser.add_argument('--udp', action='store_true', help='Alias to --proto udp')\n    parser.add_argument('--port', type=int, metavar='PORT', help='Alias to --dport')\n    parser.add_argument('--dport', type=int, metavar='DPORT', help='Filter on destination port.')\n    parser.add_argument('--sport', type=int, metavar='SPORT', help='Filter on source port.')\n    args = parser.parse_args()\n    out = sys.stdout\n    if args.plot and plt is None:\n        utils.LOGGER.critical('Matplotlib is required for --plot')\n        sys.exit(-1)\n    if args.init:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will remove any flow result in your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        db.flow.init()\n        sys.exit(0)\n    if args.ensure_indexes:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will lock your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        db.flow.ensure_indexes()\n        sys.exit(0)\n    if args.fields is not None and (not args.fields):\n        print_fields()\n        sys.exit(0)\n    elif args.fields is not None:\n        for field in args.fields:\n            ivre.flow.validate_field(field)\n    if args.precision == 0:\n        out.writelines(('%d\\n' % precision for precision in db.flow.list_precisions()))\n        sys.exit(0)\n    filters = {'nodes': args.node_filters or [], 'edges': args.flow_filters or []}\n    args_dict = vars(args)\n    for key in addr_fields:\n        if args_dict[key] is not None:\n            (flt_t, flt_v) = get_addr_argument(key, args_dict[key])\n            filters[flt_t].append(flt_v)\n    if args.proto is not None:\n        filters['edges'].append('proto = %s' % args.proto)\n    for key in ['tcp', 'udp']:\n        if args_dict[key]:\n            filters['edges'].append('proto = %s' % key)\n    for key in ['port', 'dport']:\n        if args_dict[key] is not None:\n            filters['edges'].append('dport = %d' % args_dict[key])\n    if args.sport is not None:\n        filters['edges'].append('ANY sports = %d' % args.sport)\n    time_args = ['before', 'after']\n    time_values = {}\n    for arg in time_args:\n        time_values[arg] = datetime.datetime.strptime(args_dict[arg], '%Y-%m-%d %H:%M') if args_dict[arg] is not None else None\n    query = db.flow.from_filters(filters, limit=args.limit, skip=args.skip, orderby=args.orderby, mode=args.mode, timeline=args.timeline, after=time_values['after'], before=time_values['before'], precision=args.precision)\n    if args.reduce_precision:\n        if os.isatty(sys.stdin.fileno()):\n            out.write('This will permanently reduce the precision of your database. Process ? [y/N] ')\n            ans = input()\n            if ans.lower() != 'y':\n                sys.exit(-1)\n        new_precision = args.reduce_precision\n        db.flow.reduce_precision(new_precision, flt=query, before=time_values['before'], after=time_values['after'], current_precision=args.precision)\n        sys.exit(0)\n    sep = args.separator or ' | '\n    coma = ' ;' if args.separator else ' ; '\n    coma2 = ',' if args.separator else ', '\n    if args.count:\n        count = db.flow.count(query)\n        out.write('%(clients)d clients\\n%(servers)d servers\\n%(flows)d flows\\n' % count)\n    elif args.top:\n        top = db.flow.topvalues(query, args.top, collect_fields=args.collect, sum_fields=args.sum, topnbr=args.limit, skip=args.skip, least=args.least)\n        for rec in top:\n            sys.stdout.write('%s%s%s%s%s\\n' % ('(' + coma2.join((str(val) for val in rec['fields'])) + ')', sep, rec['count'], sep, coma.join((str('(' + coma2.join((str(val) for val in collected)) + ')') for collected in rec['collected'])) if rec['collected'] else ''))\n    elif args.flow_daily:\n        precision = args.precision if args.precision is not None else config.FLOW_TIME_PRECISION\n        plot_data: Dict[str, Dict[datetime.datetime, int]] = {}\n        for rec in db.flow.flow_daily(precision, query, after=time_values['after'], before=time_values['before']):\n            out.write(sep.join([rec['time_in_day'].strftime('%T.%f'), ' ; '.join(['(' + x[0] + ', ' + str(x[1]) + ')' for x in rec['flows']])]))\n            out.write('\\n')\n            if args.plot:\n                for flw in rec['flows']:\n                    t = rec['time_in_day']\n                    dt = datetime.datetime(1970, 1, 1, hour=t.hour, minute=t.minute, second=t.second)\n                    plot_data.setdefault(flw[0], {})\n                    plot_data[flw[0]][dt] = flw[1]\n        if args.plot and plot_data:\n            t = datetime.datetime(1970, 1, 1, 0, 0, 0)\n            t += datetime.timedelta(seconds=config.FLOW_TIME_BASE % precision)\n            times = []\n            while t < datetime.datetime(1970, 1, 2):\n                times.append(t)\n                t = t + datetime.timedelta(seconds=precision)\n            ax = plt.subplots()[1]\n            fmt = matplotlib.dates.DateFormatter('%H:%M:%S')\n            for (flow, data) in plot_data.items():\n                values = [data[ti] if ti in data else 0 for ti in times]\n                plt.step(times, values, '.-', where='post', label=flow)\n            plt.legend(loc='best')\n            ax.xaxis.set_major_formatter(fmt)\n            plt.gcf().autofmt_xdate()\n            plt.show()\n    else:\n        fmt = '%%s%s%%s%s%%s' % (sep, sep)\n        node_width = len('XXXX:XXXX:XXXX:XXXX:XXXX:XXXX')\n        flow_width = len('tcp/XXXXX')\n        for res in db.flow.to_iter(query, limit=args.limit, skip=args.skip, orderby=args.orderby, mode=args.mode, timeline=args.timeline):\n            if args.json:\n                out.write('%s\\n' % res)\n            else:\n                elts = {}\n                for elt in ['src', 'flow', 'dst']:\n                    elts[elt] = res[elt]['label']\n                    if args.fields:\n                        elts[elt] = '%s%s%s' % (elts[elt], coma, coma.join((str(res[elt]['data'].get(field, '')) for field in args.fields)))\n                (src, flow, dst) = (elts['src'], elts['flow'], elts['dst'])\n                node_width = max(node_width, len(src), len(dst))\n                flow_width = max(flow_width, len(flow))\n                if not args.separator:\n                    fmt = '%%-%ds%s%%-%ds%s%%-%ds' % (node_width, sep, flow_width, sep, node_width)\n                out.write(fmt % (src, flow, dst))\n                if args.timeline:\n                    out.write(sep)\n                    try:\n                        out.write(coma.join((str(elt) for elt in sorted(res['flow']['data']['meta']['times']))))\n                    except KeyError:\n                        out.write('?')\n                out.write('\\n')"
        ]
    }
]