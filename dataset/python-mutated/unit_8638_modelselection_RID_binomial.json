[
    {
        "func_name": "test_modelselection_binomial_RID",
        "original": "def test_modelselection_binomial_RID():\n    \"\"\"\n        In this test, I use model selection backward mode to generate GLM models with influence = dfbetas.  Next, I\n        run GLM model with influence = dfbetas with the same predictor subsets as in model selection.  The rid frame\n        generated from both methods should equal.\n    \"\"\"\n    d = h2o.import_file(path=pyunit_utils.locate('smalldata/logreg/prostate.csv'))\n    my_y = 'CAPSULE'\n    my_x = ['AGE', 'RACE', 'DCAPS', 'PSA', 'VOL', 'DPROS', 'GLEASON']\n    d['CAPSULE'] = d['CAPSULE'].asfactor()\n    model_backward = modelSelection(seed=12345, max_predictor_number=3, mode='backward', influence='dfbetas', standardize=False, family='binomial')\n    model_backward.train(training_frame=d, x=my_x, y=my_y)\n    backward_rid = model_backward.get_regression_influence_diagnostics(())\n    best_predictor_subsets = model_backward.get_best_model_predictors()\n    for ind in range(0, len(backward_rid)):\n        glm = H2OGeneralizedLinearEstimator(family='binomial', seed=1234, influence='dfbetas', standardize=False, lambda_=0.0)\n        glm.train(x=best_predictor_subsets[ind], y=my_y, training_frame=d)\n        glm_rid = glm.get_regression_influence_diagnostics()\n        colnames = glm_rid.names\n        for ind2 in range(0, len(colnames)):\n            if 'DFBETA' in colnames[ind2]:\n                pyunit_utils.compare_frames_local(glm_rid[colnames[ind2]], backward_rid[ind][colnames[ind2]], prob=1.0, tol=1e-06)\n    print('Pass test!')",
        "mutated": [
            "def test_modelselection_binomial_RID():\n    if False:\n        i = 10\n    '\\n        In this test, I use model selection backward mode to generate GLM models with influence = dfbetas.  Next, I\\n        run GLM model with influence = dfbetas with the same predictor subsets as in model selection.  The rid frame\\n        generated from both methods should equal.\\n    '\n    d = h2o.import_file(path=pyunit_utils.locate('smalldata/logreg/prostate.csv'))\n    my_y = 'CAPSULE'\n    my_x = ['AGE', 'RACE', 'DCAPS', 'PSA', 'VOL', 'DPROS', 'GLEASON']\n    d['CAPSULE'] = d['CAPSULE'].asfactor()\n    model_backward = modelSelection(seed=12345, max_predictor_number=3, mode='backward', influence='dfbetas', standardize=False, family='binomial')\n    model_backward.train(training_frame=d, x=my_x, y=my_y)\n    backward_rid = model_backward.get_regression_influence_diagnostics(())\n    best_predictor_subsets = model_backward.get_best_model_predictors()\n    for ind in range(0, len(backward_rid)):\n        glm = H2OGeneralizedLinearEstimator(family='binomial', seed=1234, influence='dfbetas', standardize=False, lambda_=0.0)\n        glm.train(x=best_predictor_subsets[ind], y=my_y, training_frame=d)\n        glm_rid = glm.get_regression_influence_diagnostics()\n        colnames = glm_rid.names\n        for ind2 in range(0, len(colnames)):\n            if 'DFBETA' in colnames[ind2]:\n                pyunit_utils.compare_frames_local(glm_rid[colnames[ind2]], backward_rid[ind][colnames[ind2]], prob=1.0, tol=1e-06)\n    print('Pass test!')",
            "def test_modelselection_binomial_RID():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        In this test, I use model selection backward mode to generate GLM models with influence = dfbetas.  Next, I\\n        run GLM model with influence = dfbetas with the same predictor subsets as in model selection.  The rid frame\\n        generated from both methods should equal.\\n    '\n    d = h2o.import_file(path=pyunit_utils.locate('smalldata/logreg/prostate.csv'))\n    my_y = 'CAPSULE'\n    my_x = ['AGE', 'RACE', 'DCAPS', 'PSA', 'VOL', 'DPROS', 'GLEASON']\n    d['CAPSULE'] = d['CAPSULE'].asfactor()\n    model_backward = modelSelection(seed=12345, max_predictor_number=3, mode='backward', influence='dfbetas', standardize=False, family='binomial')\n    model_backward.train(training_frame=d, x=my_x, y=my_y)\n    backward_rid = model_backward.get_regression_influence_diagnostics(())\n    best_predictor_subsets = model_backward.get_best_model_predictors()\n    for ind in range(0, len(backward_rid)):\n        glm = H2OGeneralizedLinearEstimator(family='binomial', seed=1234, influence='dfbetas', standardize=False, lambda_=0.0)\n        glm.train(x=best_predictor_subsets[ind], y=my_y, training_frame=d)\n        glm_rid = glm.get_regression_influence_diagnostics()\n        colnames = glm_rid.names\n        for ind2 in range(0, len(colnames)):\n            if 'DFBETA' in colnames[ind2]:\n                pyunit_utils.compare_frames_local(glm_rid[colnames[ind2]], backward_rid[ind][colnames[ind2]], prob=1.0, tol=1e-06)\n    print('Pass test!')",
            "def test_modelselection_binomial_RID():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        In this test, I use model selection backward mode to generate GLM models with influence = dfbetas.  Next, I\\n        run GLM model with influence = dfbetas with the same predictor subsets as in model selection.  The rid frame\\n        generated from both methods should equal.\\n    '\n    d = h2o.import_file(path=pyunit_utils.locate('smalldata/logreg/prostate.csv'))\n    my_y = 'CAPSULE'\n    my_x = ['AGE', 'RACE', 'DCAPS', 'PSA', 'VOL', 'DPROS', 'GLEASON']\n    d['CAPSULE'] = d['CAPSULE'].asfactor()\n    model_backward = modelSelection(seed=12345, max_predictor_number=3, mode='backward', influence='dfbetas', standardize=False, family='binomial')\n    model_backward.train(training_frame=d, x=my_x, y=my_y)\n    backward_rid = model_backward.get_regression_influence_diagnostics(())\n    best_predictor_subsets = model_backward.get_best_model_predictors()\n    for ind in range(0, len(backward_rid)):\n        glm = H2OGeneralizedLinearEstimator(family='binomial', seed=1234, influence='dfbetas', standardize=False, lambda_=0.0)\n        glm.train(x=best_predictor_subsets[ind], y=my_y, training_frame=d)\n        glm_rid = glm.get_regression_influence_diagnostics()\n        colnames = glm_rid.names\n        for ind2 in range(0, len(colnames)):\n            if 'DFBETA' in colnames[ind2]:\n                pyunit_utils.compare_frames_local(glm_rid[colnames[ind2]], backward_rid[ind][colnames[ind2]], prob=1.0, tol=1e-06)\n    print('Pass test!')",
            "def test_modelselection_binomial_RID():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        In this test, I use model selection backward mode to generate GLM models with influence = dfbetas.  Next, I\\n        run GLM model with influence = dfbetas with the same predictor subsets as in model selection.  The rid frame\\n        generated from both methods should equal.\\n    '\n    d = h2o.import_file(path=pyunit_utils.locate('smalldata/logreg/prostate.csv'))\n    my_y = 'CAPSULE'\n    my_x = ['AGE', 'RACE', 'DCAPS', 'PSA', 'VOL', 'DPROS', 'GLEASON']\n    d['CAPSULE'] = d['CAPSULE'].asfactor()\n    model_backward = modelSelection(seed=12345, max_predictor_number=3, mode='backward', influence='dfbetas', standardize=False, family='binomial')\n    model_backward.train(training_frame=d, x=my_x, y=my_y)\n    backward_rid = model_backward.get_regression_influence_diagnostics(())\n    best_predictor_subsets = model_backward.get_best_model_predictors()\n    for ind in range(0, len(backward_rid)):\n        glm = H2OGeneralizedLinearEstimator(family='binomial', seed=1234, influence='dfbetas', standardize=False, lambda_=0.0)\n        glm.train(x=best_predictor_subsets[ind], y=my_y, training_frame=d)\n        glm_rid = glm.get_regression_influence_diagnostics()\n        colnames = glm_rid.names\n        for ind2 in range(0, len(colnames)):\n            if 'DFBETA' in colnames[ind2]:\n                pyunit_utils.compare_frames_local(glm_rid[colnames[ind2]], backward_rid[ind][colnames[ind2]], prob=1.0, tol=1e-06)\n    print('Pass test!')",
            "def test_modelselection_binomial_RID():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        In this test, I use model selection backward mode to generate GLM models with influence = dfbetas.  Next, I\\n        run GLM model with influence = dfbetas with the same predictor subsets as in model selection.  The rid frame\\n        generated from both methods should equal.\\n    '\n    d = h2o.import_file(path=pyunit_utils.locate('smalldata/logreg/prostate.csv'))\n    my_y = 'CAPSULE'\n    my_x = ['AGE', 'RACE', 'DCAPS', 'PSA', 'VOL', 'DPROS', 'GLEASON']\n    d['CAPSULE'] = d['CAPSULE'].asfactor()\n    model_backward = modelSelection(seed=12345, max_predictor_number=3, mode='backward', influence='dfbetas', standardize=False, family='binomial')\n    model_backward.train(training_frame=d, x=my_x, y=my_y)\n    backward_rid = model_backward.get_regression_influence_diagnostics(())\n    best_predictor_subsets = model_backward.get_best_model_predictors()\n    for ind in range(0, len(backward_rid)):\n        glm = H2OGeneralizedLinearEstimator(family='binomial', seed=1234, influence='dfbetas', standardize=False, lambda_=0.0)\n        glm.train(x=best_predictor_subsets[ind], y=my_y, training_frame=d)\n        glm_rid = glm.get_regression_influence_diagnostics()\n        colnames = glm_rid.names\n        for ind2 in range(0, len(colnames)):\n            if 'DFBETA' in colnames[ind2]:\n                pyunit_utils.compare_frames_local(glm_rid[colnames[ind2]], backward_rid[ind][colnames[ind2]], prob=1.0, tol=1e-06)\n    print('Pass test!')"
        ]
    }
]