[
    {
        "func_name": "encode",
        "original": "def encode(x):\n    (Z, _) = model.encode(x, layer_count - 1, 1)\n    Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n    return Z",
        "mutated": [
            "def encode(x):\n    if False:\n        i = 10\n    (Z, _) = model.encode(x, layer_count - 1, 1)\n    Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n    return Z",
            "def encode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (Z, _) = model.encode(x, layer_count - 1, 1)\n    Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n    return Z",
            "def encode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (Z, _) = model.encode(x, layer_count - 1, 1)\n    Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n    return Z",
            "def encode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (Z, _) = model.encode(x, layer_count - 1, 1)\n    Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n    return Z",
            "def encode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (Z, _) = model.encode(x, layer_count - 1, 1)\n    Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n    return Z"
        ]
    },
    {
        "func_name": "decode",
        "original": "def decode(x):\n    layer_idx = torch.arange(2 * cfg.MODEL.LAYER_COUNT)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    return model.decoder(x, layer_count - 1, 1, noise=True)",
        "mutated": [
            "def decode(x):\n    if False:\n        i = 10\n    layer_idx = torch.arange(2 * cfg.MODEL.LAYER_COUNT)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    return model.decoder(x, layer_count - 1, 1, noise=True)",
            "def decode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    layer_idx = torch.arange(2 * cfg.MODEL.LAYER_COUNT)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    return model.decoder(x, layer_count - 1, 1, noise=True)",
            "def decode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    layer_idx = torch.arange(2 * cfg.MODEL.LAYER_COUNT)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    return model.decoder(x, layer_count - 1, 1, noise=True)",
            "def decode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    layer_idx = torch.arange(2 * cfg.MODEL.LAYER_COUNT)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    return model.decoder(x, layer_count - 1, 1, noise=True)",
            "def decode(x):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    layer_idx = torch.arange(2 * cfg.MODEL.LAYER_COUNT)[np.newaxis, :, np.newaxis]\n    ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n    coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n    return model.decoder(x, layer_count - 1, 1, noise=True)"
        ]
    },
    {
        "func_name": "update_image",
        "original": "def update_image(w):\n    with torch.no_grad():\n        w = w + model.dlatent_avg.buff.data[0]\n        w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n        layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n        cur_layers = (7 + 1) * 2\n        mixing_cutoff = cur_layers\n        styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n        x_rec = decode(styles)\n        return x_rec",
        "mutated": [
            "def update_image(w):\n    if False:\n        i = 10\n    with torch.no_grad():\n        w = w + model.dlatent_avg.buff.data[0]\n        w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n        layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n        cur_layers = (7 + 1) * 2\n        mixing_cutoff = cur_layers\n        styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n        x_rec = decode(styles)\n        return x_rec",
            "def update_image(w):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with torch.no_grad():\n        w = w + model.dlatent_avg.buff.data[0]\n        w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n        layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n        cur_layers = (7 + 1) * 2\n        mixing_cutoff = cur_layers\n        styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n        x_rec = decode(styles)\n        return x_rec",
            "def update_image(w):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with torch.no_grad():\n        w = w + model.dlatent_avg.buff.data[0]\n        w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n        layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n        cur_layers = (7 + 1) * 2\n        mixing_cutoff = cur_layers\n        styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n        x_rec = decode(styles)\n        return x_rec",
            "def update_image(w):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with torch.no_grad():\n        w = w + model.dlatent_avg.buff.data[0]\n        w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n        layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n        cur_layers = (7 + 1) * 2\n        mixing_cutoff = cur_layers\n        styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n        x_rec = decode(styles)\n        return x_rec",
            "def update_image(w):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with torch.no_grad():\n        w = w + model.dlatent_avg.buff.data[0]\n        w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n        layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n        cur_layers = (7 + 1) * 2\n        mixing_cutoff = cur_layers\n        styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n        x_rec = decode(styles)\n        return x_rec"
        ]
    },
    {
        "func_name": "do_attribute_traversal",
        "original": "def do_attribute_traversal(path, attrib_idx, start, end):\n    img = np.asarray(Image.open(path))\n    if img.shape[2] == 4:\n        img = img[:, :, :3]\n    im = img.transpose((2, 0, 1))\n    x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n    if x.shape[0] == 4:\n        x = x[:3]\n    factor = x.shape[2] // im_size\n    if factor != 1:\n        x = torch.nn.functional.avg_pool2d(x[None, ...], factor, factor)[0]\n    assert x.shape[2] == im_size\n    _latents = encode(x[None, ...].cuda())\n    latents = _latents[0, 0]\n    latents -= model.dlatent_avg.buff.data[0]\n    w0 = torch.tensor(np.load('principal_directions/direction_%d.npy' % attrib_idx), dtype=torch.float32)\n    attr0 = (latents * w0).sum()\n    latents = latents - attr0 * w0\n\n    def update_image(w):\n        with torch.no_grad():\n            w = w + model.dlatent_avg.buff.data[0]\n            w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n            layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n            cur_layers = (7 + 1) * 2\n            mixing_cutoff = cur_layers\n            styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n            x_rec = decode(styles)\n            return x_rec\n    traversal = []\n    r = 7\n    inc = (end - start) / (r - 1)\n    for i in range(r):\n        W = latents + w0 * (attr0 + start)\n        im = update_image(W)\n        traversal.append(im)\n        attr0 += inc\n    res = torch.cat(traversal)\n    indices = [0, 1, 2, 3, 4, 10, 11, 17, 19]\n    labels = ['gender', 'smile', 'attractive', 'wavy-hair', 'young', 'big_lips', 'big_nose', 'chubby', 'glasses']\n    save_image(res * 0.5 + 0.5, 'make_figures/output/%s/traversal_%s.jpg' % (cfg.NAME, labels[indices.index(attrib_idx)]), pad_value=1)",
        "mutated": [
            "def do_attribute_traversal(path, attrib_idx, start, end):\n    if False:\n        i = 10\n    img = np.asarray(Image.open(path))\n    if img.shape[2] == 4:\n        img = img[:, :, :3]\n    im = img.transpose((2, 0, 1))\n    x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n    if x.shape[0] == 4:\n        x = x[:3]\n    factor = x.shape[2] // im_size\n    if factor != 1:\n        x = torch.nn.functional.avg_pool2d(x[None, ...], factor, factor)[0]\n    assert x.shape[2] == im_size\n    _latents = encode(x[None, ...].cuda())\n    latents = _latents[0, 0]\n    latents -= model.dlatent_avg.buff.data[0]\n    w0 = torch.tensor(np.load('principal_directions/direction_%d.npy' % attrib_idx), dtype=torch.float32)\n    attr0 = (latents * w0).sum()\n    latents = latents - attr0 * w0\n\n    def update_image(w):\n        with torch.no_grad():\n            w = w + model.dlatent_avg.buff.data[0]\n            w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n            layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n            cur_layers = (7 + 1) * 2\n            mixing_cutoff = cur_layers\n            styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n            x_rec = decode(styles)\n            return x_rec\n    traversal = []\n    r = 7\n    inc = (end - start) / (r - 1)\n    for i in range(r):\n        W = latents + w0 * (attr0 + start)\n        im = update_image(W)\n        traversal.append(im)\n        attr0 += inc\n    res = torch.cat(traversal)\n    indices = [0, 1, 2, 3, 4, 10, 11, 17, 19]\n    labels = ['gender', 'smile', 'attractive', 'wavy-hair', 'young', 'big_lips', 'big_nose', 'chubby', 'glasses']\n    save_image(res * 0.5 + 0.5, 'make_figures/output/%s/traversal_%s.jpg' % (cfg.NAME, labels[indices.index(attrib_idx)]), pad_value=1)",
            "def do_attribute_traversal(path, attrib_idx, start, end):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    img = np.asarray(Image.open(path))\n    if img.shape[2] == 4:\n        img = img[:, :, :3]\n    im = img.transpose((2, 0, 1))\n    x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n    if x.shape[0] == 4:\n        x = x[:3]\n    factor = x.shape[2] // im_size\n    if factor != 1:\n        x = torch.nn.functional.avg_pool2d(x[None, ...], factor, factor)[0]\n    assert x.shape[2] == im_size\n    _latents = encode(x[None, ...].cuda())\n    latents = _latents[0, 0]\n    latents -= model.dlatent_avg.buff.data[0]\n    w0 = torch.tensor(np.load('principal_directions/direction_%d.npy' % attrib_idx), dtype=torch.float32)\n    attr0 = (latents * w0).sum()\n    latents = latents - attr0 * w0\n\n    def update_image(w):\n        with torch.no_grad():\n            w = w + model.dlatent_avg.buff.data[0]\n            w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n            layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n            cur_layers = (7 + 1) * 2\n            mixing_cutoff = cur_layers\n            styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n            x_rec = decode(styles)\n            return x_rec\n    traversal = []\n    r = 7\n    inc = (end - start) / (r - 1)\n    for i in range(r):\n        W = latents + w0 * (attr0 + start)\n        im = update_image(W)\n        traversal.append(im)\n        attr0 += inc\n    res = torch.cat(traversal)\n    indices = [0, 1, 2, 3, 4, 10, 11, 17, 19]\n    labels = ['gender', 'smile', 'attractive', 'wavy-hair', 'young', 'big_lips', 'big_nose', 'chubby', 'glasses']\n    save_image(res * 0.5 + 0.5, 'make_figures/output/%s/traversal_%s.jpg' % (cfg.NAME, labels[indices.index(attrib_idx)]), pad_value=1)",
            "def do_attribute_traversal(path, attrib_idx, start, end):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    img = np.asarray(Image.open(path))\n    if img.shape[2] == 4:\n        img = img[:, :, :3]\n    im = img.transpose((2, 0, 1))\n    x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n    if x.shape[0] == 4:\n        x = x[:3]\n    factor = x.shape[2] // im_size\n    if factor != 1:\n        x = torch.nn.functional.avg_pool2d(x[None, ...], factor, factor)[0]\n    assert x.shape[2] == im_size\n    _latents = encode(x[None, ...].cuda())\n    latents = _latents[0, 0]\n    latents -= model.dlatent_avg.buff.data[0]\n    w0 = torch.tensor(np.load('principal_directions/direction_%d.npy' % attrib_idx), dtype=torch.float32)\n    attr0 = (latents * w0).sum()\n    latents = latents - attr0 * w0\n\n    def update_image(w):\n        with torch.no_grad():\n            w = w + model.dlatent_avg.buff.data[0]\n            w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n            layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n            cur_layers = (7 + 1) * 2\n            mixing_cutoff = cur_layers\n            styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n            x_rec = decode(styles)\n            return x_rec\n    traversal = []\n    r = 7\n    inc = (end - start) / (r - 1)\n    for i in range(r):\n        W = latents + w0 * (attr0 + start)\n        im = update_image(W)\n        traversal.append(im)\n        attr0 += inc\n    res = torch.cat(traversal)\n    indices = [0, 1, 2, 3, 4, 10, 11, 17, 19]\n    labels = ['gender', 'smile', 'attractive', 'wavy-hair', 'young', 'big_lips', 'big_nose', 'chubby', 'glasses']\n    save_image(res * 0.5 + 0.5, 'make_figures/output/%s/traversal_%s.jpg' % (cfg.NAME, labels[indices.index(attrib_idx)]), pad_value=1)",
            "def do_attribute_traversal(path, attrib_idx, start, end):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    img = np.asarray(Image.open(path))\n    if img.shape[2] == 4:\n        img = img[:, :, :3]\n    im = img.transpose((2, 0, 1))\n    x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n    if x.shape[0] == 4:\n        x = x[:3]\n    factor = x.shape[2] // im_size\n    if factor != 1:\n        x = torch.nn.functional.avg_pool2d(x[None, ...], factor, factor)[0]\n    assert x.shape[2] == im_size\n    _latents = encode(x[None, ...].cuda())\n    latents = _latents[0, 0]\n    latents -= model.dlatent_avg.buff.data[0]\n    w0 = torch.tensor(np.load('principal_directions/direction_%d.npy' % attrib_idx), dtype=torch.float32)\n    attr0 = (latents * w0).sum()\n    latents = latents - attr0 * w0\n\n    def update_image(w):\n        with torch.no_grad():\n            w = w + model.dlatent_avg.buff.data[0]\n            w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n            layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n            cur_layers = (7 + 1) * 2\n            mixing_cutoff = cur_layers\n            styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n            x_rec = decode(styles)\n            return x_rec\n    traversal = []\n    r = 7\n    inc = (end - start) / (r - 1)\n    for i in range(r):\n        W = latents + w0 * (attr0 + start)\n        im = update_image(W)\n        traversal.append(im)\n        attr0 += inc\n    res = torch.cat(traversal)\n    indices = [0, 1, 2, 3, 4, 10, 11, 17, 19]\n    labels = ['gender', 'smile', 'attractive', 'wavy-hair', 'young', 'big_lips', 'big_nose', 'chubby', 'glasses']\n    save_image(res * 0.5 + 0.5, 'make_figures/output/%s/traversal_%s.jpg' % (cfg.NAME, labels[indices.index(attrib_idx)]), pad_value=1)",
            "def do_attribute_traversal(path, attrib_idx, start, end):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    img = np.asarray(Image.open(path))\n    if img.shape[2] == 4:\n        img = img[:, :, :3]\n    im = img.transpose((2, 0, 1))\n    x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n    if x.shape[0] == 4:\n        x = x[:3]\n    factor = x.shape[2] // im_size\n    if factor != 1:\n        x = torch.nn.functional.avg_pool2d(x[None, ...], factor, factor)[0]\n    assert x.shape[2] == im_size\n    _latents = encode(x[None, ...].cuda())\n    latents = _latents[0, 0]\n    latents -= model.dlatent_avg.buff.data[0]\n    w0 = torch.tensor(np.load('principal_directions/direction_%d.npy' % attrib_idx), dtype=torch.float32)\n    attr0 = (latents * w0).sum()\n    latents = latents - attr0 * w0\n\n    def update_image(w):\n        with torch.no_grad():\n            w = w + model.dlatent_avg.buff.data[0]\n            w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n            layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n            cur_layers = (7 + 1) * 2\n            mixing_cutoff = cur_layers\n            styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n            x_rec = decode(styles)\n            return x_rec\n    traversal = []\n    r = 7\n    inc = (end - start) / (r - 1)\n    for i in range(r):\n        W = latents + w0 * (attr0 + start)\n        im = update_image(W)\n        traversal.append(im)\n        attr0 += inc\n    res = torch.cat(traversal)\n    indices = [0, 1, 2, 3, 4, 10, 11, 17, 19]\n    labels = ['gender', 'smile', 'attractive', 'wavy-hair', 'young', 'big_lips', 'big_nose', 'chubby', 'glasses']\n    save_image(res * 0.5 + 0.5, 'make_figures/output/%s/traversal_%s.jpg' % (cfg.NAME, labels[indices.index(attrib_idx)]), pad_value=1)"
        ]
    },
    {
        "func_name": "sample",
        "original": "def sample(cfg, logger):\n    torch.cuda.set_device(0)\n    model = Model(startf=cfg.MODEL.START_CHANNEL_COUNT, layer_count=cfg.MODEL.LAYER_COUNT, maxf=cfg.MODEL.MAX_CHANNEL_COUNT, latent_size=cfg.MODEL.LATENT_SPACE_SIZE, truncation_psi=cfg.MODEL.TRUNCATIOM_PSI, truncation_cutoff=cfg.MODEL.TRUNCATIOM_CUTOFF, mapping_layers=cfg.MODEL.MAPPING_LAYERS, channels=cfg.MODEL.CHANNELS, generator=cfg.MODEL.GENERATOR, encoder=cfg.MODEL.ENCODER)\n    model.cuda(0)\n    model.eval()\n    model.requires_grad_(False)\n    decoder = model.decoder\n    encoder = model.encoder\n    mapping_tl = model.mapping_d\n    mapping_fl = model.mapping_f\n    dlatent_avg = model.dlatent_avg\n    logger.info('Trainable parameters generator:')\n    count_parameters(decoder)\n    logger.info('Trainable parameters discriminator:')\n    count_parameters(encoder)\n    arguments = dict()\n    arguments['iteration'] = 0\n    model_dict = {'discriminator_s': encoder, 'generator_s': decoder, 'mapping_tl_s': mapping_tl, 'mapping_fl_s': mapping_fl, 'dlatent_avg': dlatent_avg}\n    checkpointer = Checkpointer(cfg, model_dict, {}, logger=logger, save=False)\n    extra_checkpoint_data = checkpointer.load()\n    model.eval()\n    layer_count = cfg.MODEL.LAYER_COUNT\n\n    def encode(x):\n        (Z, _) = model.encode(x, layer_count - 1, 1)\n        Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n        return Z\n\n    def decode(x):\n        layer_idx = torch.arange(2 * cfg.MODEL.LAYER_COUNT)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        return model.decoder(x, layer_count - 1, 1, noise=True)\n    path = cfg.DATASET.SAMPLES_PATH\n    im_size = 2 ** (cfg.MODEL.LAYER_COUNT + 1)\n\n    def do_attribute_traversal(path, attrib_idx, start, end):\n        img = np.asarray(Image.open(path))\n        if img.shape[2] == 4:\n            img = img[:, :, :3]\n        im = img.transpose((2, 0, 1))\n        x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n        if x.shape[0] == 4:\n            x = x[:3]\n        factor = x.shape[2] // im_size\n        if factor != 1:\n            x = torch.nn.functional.avg_pool2d(x[None, ...], factor, factor)[0]\n        assert x.shape[2] == im_size\n        _latents = encode(x[None, ...].cuda())\n        latents = _latents[0, 0]\n        latents -= model.dlatent_avg.buff.data[0]\n        w0 = torch.tensor(np.load('principal_directions/direction_%d.npy' % attrib_idx), dtype=torch.float32)\n        attr0 = (latents * w0).sum()\n        latents = latents - attr0 * w0\n\n        def update_image(w):\n            with torch.no_grad():\n                w = w + model.dlatent_avg.buff.data[0]\n                w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n                layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n                cur_layers = (7 + 1) * 2\n                mixing_cutoff = cur_layers\n                styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n                x_rec = decode(styles)\n                return x_rec\n        traversal = []\n        r = 7\n        inc = (end - start) / (r - 1)\n        for i in range(r):\n            W = latents + w0 * (attr0 + start)\n            im = update_image(W)\n            traversal.append(im)\n            attr0 += inc\n        res = torch.cat(traversal)\n        indices = [0, 1, 2, 3, 4, 10, 11, 17, 19]\n        labels = ['gender', 'smile', 'attractive', 'wavy-hair', 'young', 'big_lips', 'big_nose', 'chubby', 'glasses']\n        save_image(res * 0.5 + 0.5, 'make_figures/output/%s/traversal_%s.jpg' % (cfg.NAME, labels[indices.index(attrib_idx)]), pad_value=1)\n    do_attribute_traversal(path + '/00049.png', 0, 0.6, -34)\n    do_attribute_traversal(path + '/00125.png', 1, -3, 15.0)\n    do_attribute_traversal(path + '/00057.png', 3, -2, 30.0)\n    do_attribute_traversal(path + '/00031.png', 4, -10, 30.0)\n    do_attribute_traversal(path + '/00088.png', 10, -0.3, 30.0)\n    do_attribute_traversal(path + '/00004.png', 11, -25, 20.0)\n    do_attribute_traversal(path + '/00012.png', 17, -40, 40.0)\n    do_attribute_traversal(path + '/00017.png', 19, 0, 30.0)",
        "mutated": [
            "def sample(cfg, logger):\n    if False:\n        i = 10\n    torch.cuda.set_device(0)\n    model = Model(startf=cfg.MODEL.START_CHANNEL_COUNT, layer_count=cfg.MODEL.LAYER_COUNT, maxf=cfg.MODEL.MAX_CHANNEL_COUNT, latent_size=cfg.MODEL.LATENT_SPACE_SIZE, truncation_psi=cfg.MODEL.TRUNCATIOM_PSI, truncation_cutoff=cfg.MODEL.TRUNCATIOM_CUTOFF, mapping_layers=cfg.MODEL.MAPPING_LAYERS, channels=cfg.MODEL.CHANNELS, generator=cfg.MODEL.GENERATOR, encoder=cfg.MODEL.ENCODER)\n    model.cuda(0)\n    model.eval()\n    model.requires_grad_(False)\n    decoder = model.decoder\n    encoder = model.encoder\n    mapping_tl = model.mapping_d\n    mapping_fl = model.mapping_f\n    dlatent_avg = model.dlatent_avg\n    logger.info('Trainable parameters generator:')\n    count_parameters(decoder)\n    logger.info('Trainable parameters discriminator:')\n    count_parameters(encoder)\n    arguments = dict()\n    arguments['iteration'] = 0\n    model_dict = {'discriminator_s': encoder, 'generator_s': decoder, 'mapping_tl_s': mapping_tl, 'mapping_fl_s': mapping_fl, 'dlatent_avg': dlatent_avg}\n    checkpointer = Checkpointer(cfg, model_dict, {}, logger=logger, save=False)\n    extra_checkpoint_data = checkpointer.load()\n    model.eval()\n    layer_count = cfg.MODEL.LAYER_COUNT\n\n    def encode(x):\n        (Z, _) = model.encode(x, layer_count - 1, 1)\n        Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n        return Z\n\n    def decode(x):\n        layer_idx = torch.arange(2 * cfg.MODEL.LAYER_COUNT)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        return model.decoder(x, layer_count - 1, 1, noise=True)\n    path = cfg.DATASET.SAMPLES_PATH\n    im_size = 2 ** (cfg.MODEL.LAYER_COUNT + 1)\n\n    def do_attribute_traversal(path, attrib_idx, start, end):\n        img = np.asarray(Image.open(path))\n        if img.shape[2] == 4:\n            img = img[:, :, :3]\n        im = img.transpose((2, 0, 1))\n        x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n        if x.shape[0] == 4:\n            x = x[:3]\n        factor = x.shape[2] // im_size\n        if factor != 1:\n            x = torch.nn.functional.avg_pool2d(x[None, ...], factor, factor)[0]\n        assert x.shape[2] == im_size\n        _latents = encode(x[None, ...].cuda())\n        latents = _latents[0, 0]\n        latents -= model.dlatent_avg.buff.data[0]\n        w0 = torch.tensor(np.load('principal_directions/direction_%d.npy' % attrib_idx), dtype=torch.float32)\n        attr0 = (latents * w0).sum()\n        latents = latents - attr0 * w0\n\n        def update_image(w):\n            with torch.no_grad():\n                w = w + model.dlatent_avg.buff.data[0]\n                w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n                layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n                cur_layers = (7 + 1) * 2\n                mixing_cutoff = cur_layers\n                styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n                x_rec = decode(styles)\n                return x_rec\n        traversal = []\n        r = 7\n        inc = (end - start) / (r - 1)\n        for i in range(r):\n            W = latents + w0 * (attr0 + start)\n            im = update_image(W)\n            traversal.append(im)\n            attr0 += inc\n        res = torch.cat(traversal)\n        indices = [0, 1, 2, 3, 4, 10, 11, 17, 19]\n        labels = ['gender', 'smile', 'attractive', 'wavy-hair', 'young', 'big_lips', 'big_nose', 'chubby', 'glasses']\n        save_image(res * 0.5 + 0.5, 'make_figures/output/%s/traversal_%s.jpg' % (cfg.NAME, labels[indices.index(attrib_idx)]), pad_value=1)\n    do_attribute_traversal(path + '/00049.png', 0, 0.6, -34)\n    do_attribute_traversal(path + '/00125.png', 1, -3, 15.0)\n    do_attribute_traversal(path + '/00057.png', 3, -2, 30.0)\n    do_attribute_traversal(path + '/00031.png', 4, -10, 30.0)\n    do_attribute_traversal(path + '/00088.png', 10, -0.3, 30.0)\n    do_attribute_traversal(path + '/00004.png', 11, -25, 20.0)\n    do_attribute_traversal(path + '/00012.png', 17, -40, 40.0)\n    do_attribute_traversal(path + '/00017.png', 19, 0, 30.0)",
            "def sample(cfg, logger):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    torch.cuda.set_device(0)\n    model = Model(startf=cfg.MODEL.START_CHANNEL_COUNT, layer_count=cfg.MODEL.LAYER_COUNT, maxf=cfg.MODEL.MAX_CHANNEL_COUNT, latent_size=cfg.MODEL.LATENT_SPACE_SIZE, truncation_psi=cfg.MODEL.TRUNCATIOM_PSI, truncation_cutoff=cfg.MODEL.TRUNCATIOM_CUTOFF, mapping_layers=cfg.MODEL.MAPPING_LAYERS, channels=cfg.MODEL.CHANNELS, generator=cfg.MODEL.GENERATOR, encoder=cfg.MODEL.ENCODER)\n    model.cuda(0)\n    model.eval()\n    model.requires_grad_(False)\n    decoder = model.decoder\n    encoder = model.encoder\n    mapping_tl = model.mapping_d\n    mapping_fl = model.mapping_f\n    dlatent_avg = model.dlatent_avg\n    logger.info('Trainable parameters generator:')\n    count_parameters(decoder)\n    logger.info('Trainable parameters discriminator:')\n    count_parameters(encoder)\n    arguments = dict()\n    arguments['iteration'] = 0\n    model_dict = {'discriminator_s': encoder, 'generator_s': decoder, 'mapping_tl_s': mapping_tl, 'mapping_fl_s': mapping_fl, 'dlatent_avg': dlatent_avg}\n    checkpointer = Checkpointer(cfg, model_dict, {}, logger=logger, save=False)\n    extra_checkpoint_data = checkpointer.load()\n    model.eval()\n    layer_count = cfg.MODEL.LAYER_COUNT\n\n    def encode(x):\n        (Z, _) = model.encode(x, layer_count - 1, 1)\n        Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n        return Z\n\n    def decode(x):\n        layer_idx = torch.arange(2 * cfg.MODEL.LAYER_COUNT)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        return model.decoder(x, layer_count - 1, 1, noise=True)\n    path = cfg.DATASET.SAMPLES_PATH\n    im_size = 2 ** (cfg.MODEL.LAYER_COUNT + 1)\n\n    def do_attribute_traversal(path, attrib_idx, start, end):\n        img = np.asarray(Image.open(path))\n        if img.shape[2] == 4:\n            img = img[:, :, :3]\n        im = img.transpose((2, 0, 1))\n        x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n        if x.shape[0] == 4:\n            x = x[:3]\n        factor = x.shape[2] // im_size\n        if factor != 1:\n            x = torch.nn.functional.avg_pool2d(x[None, ...], factor, factor)[0]\n        assert x.shape[2] == im_size\n        _latents = encode(x[None, ...].cuda())\n        latents = _latents[0, 0]\n        latents -= model.dlatent_avg.buff.data[0]\n        w0 = torch.tensor(np.load('principal_directions/direction_%d.npy' % attrib_idx), dtype=torch.float32)\n        attr0 = (latents * w0).sum()\n        latents = latents - attr0 * w0\n\n        def update_image(w):\n            with torch.no_grad():\n                w = w + model.dlatent_avg.buff.data[0]\n                w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n                layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n                cur_layers = (7 + 1) * 2\n                mixing_cutoff = cur_layers\n                styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n                x_rec = decode(styles)\n                return x_rec\n        traversal = []\n        r = 7\n        inc = (end - start) / (r - 1)\n        for i in range(r):\n            W = latents + w0 * (attr0 + start)\n            im = update_image(W)\n            traversal.append(im)\n            attr0 += inc\n        res = torch.cat(traversal)\n        indices = [0, 1, 2, 3, 4, 10, 11, 17, 19]\n        labels = ['gender', 'smile', 'attractive', 'wavy-hair', 'young', 'big_lips', 'big_nose', 'chubby', 'glasses']\n        save_image(res * 0.5 + 0.5, 'make_figures/output/%s/traversal_%s.jpg' % (cfg.NAME, labels[indices.index(attrib_idx)]), pad_value=1)\n    do_attribute_traversal(path + '/00049.png', 0, 0.6, -34)\n    do_attribute_traversal(path + '/00125.png', 1, -3, 15.0)\n    do_attribute_traversal(path + '/00057.png', 3, -2, 30.0)\n    do_attribute_traversal(path + '/00031.png', 4, -10, 30.0)\n    do_attribute_traversal(path + '/00088.png', 10, -0.3, 30.0)\n    do_attribute_traversal(path + '/00004.png', 11, -25, 20.0)\n    do_attribute_traversal(path + '/00012.png', 17, -40, 40.0)\n    do_attribute_traversal(path + '/00017.png', 19, 0, 30.0)",
            "def sample(cfg, logger):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    torch.cuda.set_device(0)\n    model = Model(startf=cfg.MODEL.START_CHANNEL_COUNT, layer_count=cfg.MODEL.LAYER_COUNT, maxf=cfg.MODEL.MAX_CHANNEL_COUNT, latent_size=cfg.MODEL.LATENT_SPACE_SIZE, truncation_psi=cfg.MODEL.TRUNCATIOM_PSI, truncation_cutoff=cfg.MODEL.TRUNCATIOM_CUTOFF, mapping_layers=cfg.MODEL.MAPPING_LAYERS, channels=cfg.MODEL.CHANNELS, generator=cfg.MODEL.GENERATOR, encoder=cfg.MODEL.ENCODER)\n    model.cuda(0)\n    model.eval()\n    model.requires_grad_(False)\n    decoder = model.decoder\n    encoder = model.encoder\n    mapping_tl = model.mapping_d\n    mapping_fl = model.mapping_f\n    dlatent_avg = model.dlatent_avg\n    logger.info('Trainable parameters generator:')\n    count_parameters(decoder)\n    logger.info('Trainable parameters discriminator:')\n    count_parameters(encoder)\n    arguments = dict()\n    arguments['iteration'] = 0\n    model_dict = {'discriminator_s': encoder, 'generator_s': decoder, 'mapping_tl_s': mapping_tl, 'mapping_fl_s': mapping_fl, 'dlatent_avg': dlatent_avg}\n    checkpointer = Checkpointer(cfg, model_dict, {}, logger=logger, save=False)\n    extra_checkpoint_data = checkpointer.load()\n    model.eval()\n    layer_count = cfg.MODEL.LAYER_COUNT\n\n    def encode(x):\n        (Z, _) = model.encode(x, layer_count - 1, 1)\n        Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n        return Z\n\n    def decode(x):\n        layer_idx = torch.arange(2 * cfg.MODEL.LAYER_COUNT)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        return model.decoder(x, layer_count - 1, 1, noise=True)\n    path = cfg.DATASET.SAMPLES_PATH\n    im_size = 2 ** (cfg.MODEL.LAYER_COUNT + 1)\n\n    def do_attribute_traversal(path, attrib_idx, start, end):\n        img = np.asarray(Image.open(path))\n        if img.shape[2] == 4:\n            img = img[:, :, :3]\n        im = img.transpose((2, 0, 1))\n        x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n        if x.shape[0] == 4:\n            x = x[:3]\n        factor = x.shape[2] // im_size\n        if factor != 1:\n            x = torch.nn.functional.avg_pool2d(x[None, ...], factor, factor)[0]\n        assert x.shape[2] == im_size\n        _latents = encode(x[None, ...].cuda())\n        latents = _latents[0, 0]\n        latents -= model.dlatent_avg.buff.data[0]\n        w0 = torch.tensor(np.load('principal_directions/direction_%d.npy' % attrib_idx), dtype=torch.float32)\n        attr0 = (latents * w0).sum()\n        latents = latents - attr0 * w0\n\n        def update_image(w):\n            with torch.no_grad():\n                w = w + model.dlatent_avg.buff.data[0]\n                w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n                layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n                cur_layers = (7 + 1) * 2\n                mixing_cutoff = cur_layers\n                styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n                x_rec = decode(styles)\n                return x_rec\n        traversal = []\n        r = 7\n        inc = (end - start) / (r - 1)\n        for i in range(r):\n            W = latents + w0 * (attr0 + start)\n            im = update_image(W)\n            traversal.append(im)\n            attr0 += inc\n        res = torch.cat(traversal)\n        indices = [0, 1, 2, 3, 4, 10, 11, 17, 19]\n        labels = ['gender', 'smile', 'attractive', 'wavy-hair', 'young', 'big_lips', 'big_nose', 'chubby', 'glasses']\n        save_image(res * 0.5 + 0.5, 'make_figures/output/%s/traversal_%s.jpg' % (cfg.NAME, labels[indices.index(attrib_idx)]), pad_value=1)\n    do_attribute_traversal(path + '/00049.png', 0, 0.6, -34)\n    do_attribute_traversal(path + '/00125.png', 1, -3, 15.0)\n    do_attribute_traversal(path + '/00057.png', 3, -2, 30.0)\n    do_attribute_traversal(path + '/00031.png', 4, -10, 30.0)\n    do_attribute_traversal(path + '/00088.png', 10, -0.3, 30.0)\n    do_attribute_traversal(path + '/00004.png', 11, -25, 20.0)\n    do_attribute_traversal(path + '/00012.png', 17, -40, 40.0)\n    do_attribute_traversal(path + '/00017.png', 19, 0, 30.0)",
            "def sample(cfg, logger):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    torch.cuda.set_device(0)\n    model = Model(startf=cfg.MODEL.START_CHANNEL_COUNT, layer_count=cfg.MODEL.LAYER_COUNT, maxf=cfg.MODEL.MAX_CHANNEL_COUNT, latent_size=cfg.MODEL.LATENT_SPACE_SIZE, truncation_psi=cfg.MODEL.TRUNCATIOM_PSI, truncation_cutoff=cfg.MODEL.TRUNCATIOM_CUTOFF, mapping_layers=cfg.MODEL.MAPPING_LAYERS, channels=cfg.MODEL.CHANNELS, generator=cfg.MODEL.GENERATOR, encoder=cfg.MODEL.ENCODER)\n    model.cuda(0)\n    model.eval()\n    model.requires_grad_(False)\n    decoder = model.decoder\n    encoder = model.encoder\n    mapping_tl = model.mapping_d\n    mapping_fl = model.mapping_f\n    dlatent_avg = model.dlatent_avg\n    logger.info('Trainable parameters generator:')\n    count_parameters(decoder)\n    logger.info('Trainable parameters discriminator:')\n    count_parameters(encoder)\n    arguments = dict()\n    arguments['iteration'] = 0\n    model_dict = {'discriminator_s': encoder, 'generator_s': decoder, 'mapping_tl_s': mapping_tl, 'mapping_fl_s': mapping_fl, 'dlatent_avg': dlatent_avg}\n    checkpointer = Checkpointer(cfg, model_dict, {}, logger=logger, save=False)\n    extra_checkpoint_data = checkpointer.load()\n    model.eval()\n    layer_count = cfg.MODEL.LAYER_COUNT\n\n    def encode(x):\n        (Z, _) = model.encode(x, layer_count - 1, 1)\n        Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n        return Z\n\n    def decode(x):\n        layer_idx = torch.arange(2 * cfg.MODEL.LAYER_COUNT)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        return model.decoder(x, layer_count - 1, 1, noise=True)\n    path = cfg.DATASET.SAMPLES_PATH\n    im_size = 2 ** (cfg.MODEL.LAYER_COUNT + 1)\n\n    def do_attribute_traversal(path, attrib_idx, start, end):\n        img = np.asarray(Image.open(path))\n        if img.shape[2] == 4:\n            img = img[:, :, :3]\n        im = img.transpose((2, 0, 1))\n        x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n        if x.shape[0] == 4:\n            x = x[:3]\n        factor = x.shape[2] // im_size\n        if factor != 1:\n            x = torch.nn.functional.avg_pool2d(x[None, ...], factor, factor)[0]\n        assert x.shape[2] == im_size\n        _latents = encode(x[None, ...].cuda())\n        latents = _latents[0, 0]\n        latents -= model.dlatent_avg.buff.data[0]\n        w0 = torch.tensor(np.load('principal_directions/direction_%d.npy' % attrib_idx), dtype=torch.float32)\n        attr0 = (latents * w0).sum()\n        latents = latents - attr0 * w0\n\n        def update_image(w):\n            with torch.no_grad():\n                w = w + model.dlatent_avg.buff.data[0]\n                w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n                layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n                cur_layers = (7 + 1) * 2\n                mixing_cutoff = cur_layers\n                styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n                x_rec = decode(styles)\n                return x_rec\n        traversal = []\n        r = 7\n        inc = (end - start) / (r - 1)\n        for i in range(r):\n            W = latents + w0 * (attr0 + start)\n            im = update_image(W)\n            traversal.append(im)\n            attr0 += inc\n        res = torch.cat(traversal)\n        indices = [0, 1, 2, 3, 4, 10, 11, 17, 19]\n        labels = ['gender', 'smile', 'attractive', 'wavy-hair', 'young', 'big_lips', 'big_nose', 'chubby', 'glasses']\n        save_image(res * 0.5 + 0.5, 'make_figures/output/%s/traversal_%s.jpg' % (cfg.NAME, labels[indices.index(attrib_idx)]), pad_value=1)\n    do_attribute_traversal(path + '/00049.png', 0, 0.6, -34)\n    do_attribute_traversal(path + '/00125.png', 1, -3, 15.0)\n    do_attribute_traversal(path + '/00057.png', 3, -2, 30.0)\n    do_attribute_traversal(path + '/00031.png', 4, -10, 30.0)\n    do_attribute_traversal(path + '/00088.png', 10, -0.3, 30.0)\n    do_attribute_traversal(path + '/00004.png', 11, -25, 20.0)\n    do_attribute_traversal(path + '/00012.png', 17, -40, 40.0)\n    do_attribute_traversal(path + '/00017.png', 19, 0, 30.0)",
            "def sample(cfg, logger):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    torch.cuda.set_device(0)\n    model = Model(startf=cfg.MODEL.START_CHANNEL_COUNT, layer_count=cfg.MODEL.LAYER_COUNT, maxf=cfg.MODEL.MAX_CHANNEL_COUNT, latent_size=cfg.MODEL.LATENT_SPACE_SIZE, truncation_psi=cfg.MODEL.TRUNCATIOM_PSI, truncation_cutoff=cfg.MODEL.TRUNCATIOM_CUTOFF, mapping_layers=cfg.MODEL.MAPPING_LAYERS, channels=cfg.MODEL.CHANNELS, generator=cfg.MODEL.GENERATOR, encoder=cfg.MODEL.ENCODER)\n    model.cuda(0)\n    model.eval()\n    model.requires_grad_(False)\n    decoder = model.decoder\n    encoder = model.encoder\n    mapping_tl = model.mapping_d\n    mapping_fl = model.mapping_f\n    dlatent_avg = model.dlatent_avg\n    logger.info('Trainable parameters generator:')\n    count_parameters(decoder)\n    logger.info('Trainable parameters discriminator:')\n    count_parameters(encoder)\n    arguments = dict()\n    arguments['iteration'] = 0\n    model_dict = {'discriminator_s': encoder, 'generator_s': decoder, 'mapping_tl_s': mapping_tl, 'mapping_fl_s': mapping_fl, 'dlatent_avg': dlatent_avg}\n    checkpointer = Checkpointer(cfg, model_dict, {}, logger=logger, save=False)\n    extra_checkpoint_data = checkpointer.load()\n    model.eval()\n    layer_count = cfg.MODEL.LAYER_COUNT\n\n    def encode(x):\n        (Z, _) = model.encode(x, layer_count - 1, 1)\n        Z = Z.repeat(1, model.mapping_f.num_layers, 1)\n        return Z\n\n    def decode(x):\n        layer_idx = torch.arange(2 * cfg.MODEL.LAYER_COUNT)[np.newaxis, :, np.newaxis]\n        ones = torch.ones(layer_idx.shape, dtype=torch.float32)\n        coefs = torch.where(layer_idx < model.truncation_cutoff, ones, ones)\n        return model.decoder(x, layer_count - 1, 1, noise=True)\n    path = cfg.DATASET.SAMPLES_PATH\n    im_size = 2 ** (cfg.MODEL.LAYER_COUNT + 1)\n\n    def do_attribute_traversal(path, attrib_idx, start, end):\n        img = np.asarray(Image.open(path))\n        if img.shape[2] == 4:\n            img = img[:, :, :3]\n        im = img.transpose((2, 0, 1))\n        x = torch.tensor(np.asarray(im, dtype=np.float32), device='cpu', requires_grad=True).cuda() / 127.5 - 1.0\n        if x.shape[0] == 4:\n            x = x[:3]\n        factor = x.shape[2] // im_size\n        if factor != 1:\n            x = torch.nn.functional.avg_pool2d(x[None, ...], factor, factor)[0]\n        assert x.shape[2] == im_size\n        _latents = encode(x[None, ...].cuda())\n        latents = _latents[0, 0]\n        latents -= model.dlatent_avg.buff.data[0]\n        w0 = torch.tensor(np.load('principal_directions/direction_%d.npy' % attrib_idx), dtype=torch.float32)\n        attr0 = (latents * w0).sum()\n        latents = latents - attr0 * w0\n\n        def update_image(w):\n            with torch.no_grad():\n                w = w + model.dlatent_avg.buff.data[0]\n                w = w[None, None, ...].repeat(1, model.mapping_f.num_layers, 1)\n                layer_idx = torch.arange(model.mapping_f.num_layers)[np.newaxis, :, np.newaxis]\n                cur_layers = (7 + 1) * 2\n                mixing_cutoff = cur_layers\n                styles = torch.where(layer_idx < mixing_cutoff, w, _latents[0])\n                x_rec = decode(styles)\n                return x_rec\n        traversal = []\n        r = 7\n        inc = (end - start) / (r - 1)\n        for i in range(r):\n            W = latents + w0 * (attr0 + start)\n            im = update_image(W)\n            traversal.append(im)\n            attr0 += inc\n        res = torch.cat(traversal)\n        indices = [0, 1, 2, 3, 4, 10, 11, 17, 19]\n        labels = ['gender', 'smile', 'attractive', 'wavy-hair', 'young', 'big_lips', 'big_nose', 'chubby', 'glasses']\n        save_image(res * 0.5 + 0.5, 'make_figures/output/%s/traversal_%s.jpg' % (cfg.NAME, labels[indices.index(attrib_idx)]), pad_value=1)\n    do_attribute_traversal(path + '/00049.png', 0, 0.6, -34)\n    do_attribute_traversal(path + '/00125.png', 1, -3, 15.0)\n    do_attribute_traversal(path + '/00057.png', 3, -2, 30.0)\n    do_attribute_traversal(path + '/00031.png', 4, -10, 30.0)\n    do_attribute_traversal(path + '/00088.png', 10, -0.3, 30.0)\n    do_attribute_traversal(path + '/00004.png', 11, -25, 20.0)\n    do_attribute_traversal(path + '/00012.png', 17, -40, 40.0)\n    do_attribute_traversal(path + '/00017.png', 19, 0, 30.0)"
        ]
    }
]