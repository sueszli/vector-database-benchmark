[
    {
        "func_name": "betweenness_centrality",
        "original": "@py_random_state(5)\n@nx._dispatch(edge_attrs='weight')\ndef betweenness_centrality(G, k=None, normalized=True, weight=None, endpoints=False, seed=None):\n    \"\"\"Compute the shortest-path betweenness centrality for nodes.\n\n    Betweenness centrality of a node $v$ is the sum of the\n    fraction of all-pairs shortest paths that pass through $v$\n\n    .. math::\n\n       c_B(v) =\\\\sum_{s,t \\\\in V} \\\\frac{\\\\sigma(s, t|v)}{\\\\sigma(s, t)}\n\n    where $V$ is the set of nodes, $\\\\sigma(s, t)$ is the number of\n    shortest $(s, t)$-paths,  and $\\\\sigma(s, t|v)$ is the number of\n    those paths  passing through some  node $v$ other than $s, t$.\n    If $s = t$, $\\\\sigma(s, t) = 1$, and if $v \\\\in {s, t}$,\n    $\\\\sigma(s, t|v) = 0$ [2]_.\n\n    Parameters\n    ----------\n    G : graph\n      A NetworkX graph.\n\n    k : int, optional (default=None)\n      If k is not None use k node samples to estimate betweenness.\n      The value of k <= n where n is the number of nodes in the graph.\n      Higher values give better approximation.\n\n    normalized : bool, optional\n      If True the betweenness values are normalized by `2/((n-1)(n-2))`\n      for graphs, and `1/((n-1)(n-2))` for directed graphs where `n`\n      is the number of nodes in G.\n\n    weight : None or string, optional (default=None)\n      If None, all edge weights are considered equal.\n      Otherwise holds the name of the edge attribute used as weight.\n      Weights are used to calculate weighted shortest paths, so they are\n      interpreted as distances.\n\n    endpoints : bool, optional\n      If True include the endpoints in the shortest path counts.\n\n    seed : integer, random_state, or None (default)\n        Indicator of random number generation state.\n        See :ref:`Randomness<randomness>`.\n        Note that this is only used if k is not None.\n\n    Returns\n    -------\n    nodes : dictionary\n       Dictionary of nodes with betweenness centrality as the value.\n\n    See Also\n    --------\n    edge_betweenness_centrality\n    load_centrality\n\n    Notes\n    -----\n    The algorithm is from Ulrik Brandes [1]_.\n    See [4]_ for the original first published version and [2]_ for details on\n    algorithms for variations and related metrics.\n\n    For approximate betweenness calculations set k=#samples to use\n    k nodes (\"pivots\") to estimate the betweenness values. For an estimate\n    of the number of pivots needed see [3]_.\n\n    For weighted graphs the edge weights must be greater than zero.\n    Zero edge weights can produce an infinite number of equal length\n    paths between pairs of nodes.\n\n    The total number of paths between source and target is counted\n    differently for directed and undirected graphs. Directed paths\n    are easy to count. Undirected paths are tricky: should a path\n    from \"u\" to \"v\" count as 1 undirected path or as 2 directed paths?\n\n    For betweenness_centrality we report the number of undirected\n    paths when G is undirected.\n\n    For betweenness_centrality_subset the reporting is different.\n    If the source and target subsets are the same, then we want\n    to count undirected paths. But if the source and target subsets\n    differ -- for example, if sources is {0} and targets is {1},\n    then we are only counting the paths in one direction. They are\n    undirected paths but we are counting them in a directed way.\n    To count them as undirected paths, each should count as half a path.\n\n    This algorithm is not guaranteed to be correct if edge weights\n    are floating point numbers. As a workaround you can use integer\n    numbers by multiplying the relevant edge attributes by a convenient\n    constant factor (eg 100) and converting to integers.\n\n    References\n    ----------\n    .. [1] Ulrik Brandes:\n       A Faster Algorithm for Betweenness Centrality.\n       Journal of Mathematical Sociology 25(2):163-177, 2001.\n       https://doi.org/10.1080/0022250X.2001.9990249\n    .. [2] Ulrik Brandes:\n       On Variants of Shortest-Path Betweenness\n       Centrality and their Generic Computation.\n       Social Networks 30(2):136-145, 2008.\n       https://doi.org/10.1016/j.socnet.2007.11.001\n    .. [3] Ulrik Brandes and Christian Pich:\n       Centrality Estimation in Large Networks.\n       International Journal of Bifurcation and Chaos 17(7):2303-2318, 2007.\n       https://dx.doi.org/10.1142/S0218127407018403\n    .. [4] Linton C. Freeman:\n       A set of measures of centrality based on betweenness.\n       Sociometry 40: 35\u201341, 1977\n       https://doi.org/10.2307/3033543\n    \"\"\"\n    betweenness = dict.fromkeys(G, 0.0)\n    if k is None:\n        nodes = G\n    else:\n        nodes = seed.sample(list(G.nodes()), k)\n    for s in nodes:\n        if weight is None:\n            (S, P, sigma, _) = _single_source_shortest_path_basic(G, s)\n        else:\n            (S, P, sigma, _) = _single_source_dijkstra_path_basic(G, s, weight)\n        if endpoints:\n            (betweenness, _) = _accumulate_endpoints(betweenness, S, P, sigma, s)\n        else:\n            (betweenness, _) = _accumulate_basic(betweenness, S, P, sigma, s)\n    betweenness = _rescale(betweenness, len(G), normalized=normalized, directed=G.is_directed(), k=k, endpoints=endpoints)\n    return betweenness",
        "mutated": [
            "@py_random_state(5)\n@nx._dispatch(edge_attrs='weight')\ndef betweenness_centrality(G, k=None, normalized=True, weight=None, endpoints=False, seed=None):\n    if False:\n        i = 10\n    'Compute the shortest-path betweenness centrality for nodes.\\n\\n    Betweenness centrality of a node $v$ is the sum of the\\n    fraction of all-pairs shortest paths that pass through $v$\\n\\n    .. math::\\n\\n       c_B(v) =\\\\sum_{s,t \\\\in V} \\\\frac{\\\\sigma(s, t|v)}{\\\\sigma(s, t)}\\n\\n    where $V$ is the set of nodes, $\\\\sigma(s, t)$ is the number of\\n    shortest $(s, t)$-paths,  and $\\\\sigma(s, t|v)$ is the number of\\n    those paths  passing through some  node $v$ other than $s, t$.\\n    If $s = t$, $\\\\sigma(s, t) = 1$, and if $v \\\\in {s, t}$,\\n    $\\\\sigma(s, t|v) = 0$ [2]_.\\n\\n    Parameters\\n    ----------\\n    G : graph\\n      A NetworkX graph.\\n\\n    k : int, optional (default=None)\\n      If k is not None use k node samples to estimate betweenness.\\n      The value of k <= n where n is the number of nodes in the graph.\\n      Higher values give better approximation.\\n\\n    normalized : bool, optional\\n      If True the betweenness values are normalized by `2/((n-1)(n-2))`\\n      for graphs, and `1/((n-1)(n-2))` for directed graphs where `n`\\n      is the number of nodes in G.\\n\\n    weight : None or string, optional (default=None)\\n      If None, all edge weights are considered equal.\\n      Otherwise holds the name of the edge attribute used as weight.\\n      Weights are used to calculate weighted shortest paths, so they are\\n      interpreted as distances.\\n\\n    endpoints : bool, optional\\n      If True include the endpoints in the shortest path counts.\\n\\n    seed : integer, random_state, or None (default)\\n        Indicator of random number generation state.\\n        See :ref:`Randomness<randomness>`.\\n        Note that this is only used if k is not None.\\n\\n    Returns\\n    -------\\n    nodes : dictionary\\n       Dictionary of nodes with betweenness centrality as the value.\\n\\n    See Also\\n    --------\\n    edge_betweenness_centrality\\n    load_centrality\\n\\n    Notes\\n    -----\\n    The algorithm is from Ulrik Brandes [1]_.\\n    See [4]_ for the original first published version and [2]_ for details on\\n    algorithms for variations and related metrics.\\n\\n    For approximate betweenness calculations set k=#samples to use\\n    k nodes (\"pivots\") to estimate the betweenness values. For an estimate\\n    of the number of pivots needed see [3]_.\\n\\n    For weighted graphs the edge weights must be greater than zero.\\n    Zero edge weights can produce an infinite number of equal length\\n    paths between pairs of nodes.\\n\\n    The total number of paths between source and target is counted\\n    differently for directed and undirected graphs. Directed paths\\n    are easy to count. Undirected paths are tricky: should a path\\n    from \"u\" to \"v\" count as 1 undirected path or as 2 directed paths?\\n\\n    For betweenness_centrality we report the number of undirected\\n    paths when G is undirected.\\n\\n    For betweenness_centrality_subset the reporting is different.\\n    If the source and target subsets are the same, then we want\\n    to count undirected paths. But if the source and target subsets\\n    differ -- for example, if sources is {0} and targets is {1},\\n    then we are only counting the paths in one direction. They are\\n    undirected paths but we are counting them in a directed way.\\n    To count them as undirected paths, each should count as half a path.\\n\\n    This algorithm is not guaranteed to be correct if edge weights\\n    are floating point numbers. As a workaround you can use integer\\n    numbers by multiplying the relevant edge attributes by a convenient\\n    constant factor (eg 100) and converting to integers.\\n\\n    References\\n    ----------\\n    .. [1] Ulrik Brandes:\\n       A Faster Algorithm for Betweenness Centrality.\\n       Journal of Mathematical Sociology 25(2):163-177, 2001.\\n       https://doi.org/10.1080/0022250X.2001.9990249\\n    .. [2] Ulrik Brandes:\\n       On Variants of Shortest-Path Betweenness\\n       Centrality and their Generic Computation.\\n       Social Networks 30(2):136-145, 2008.\\n       https://doi.org/10.1016/j.socnet.2007.11.001\\n    .. [3] Ulrik Brandes and Christian Pich:\\n       Centrality Estimation in Large Networks.\\n       International Journal of Bifurcation and Chaos 17(7):2303-2318, 2007.\\n       https://dx.doi.org/10.1142/S0218127407018403\\n    .. [4] Linton C. Freeman:\\n       A set of measures of centrality based on betweenness.\\n       Sociometry 40: 35\u201341, 1977\\n       https://doi.org/10.2307/3033543\\n    '\n    betweenness = dict.fromkeys(G, 0.0)\n    if k is None:\n        nodes = G\n    else:\n        nodes = seed.sample(list(G.nodes()), k)\n    for s in nodes:\n        if weight is None:\n            (S, P, sigma, _) = _single_source_shortest_path_basic(G, s)\n        else:\n            (S, P, sigma, _) = _single_source_dijkstra_path_basic(G, s, weight)\n        if endpoints:\n            (betweenness, _) = _accumulate_endpoints(betweenness, S, P, sigma, s)\n        else:\n            (betweenness, _) = _accumulate_basic(betweenness, S, P, sigma, s)\n    betweenness = _rescale(betweenness, len(G), normalized=normalized, directed=G.is_directed(), k=k, endpoints=endpoints)\n    return betweenness",
            "@py_random_state(5)\n@nx._dispatch(edge_attrs='weight')\ndef betweenness_centrality(G, k=None, normalized=True, weight=None, endpoints=False, seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Compute the shortest-path betweenness centrality for nodes.\\n\\n    Betweenness centrality of a node $v$ is the sum of the\\n    fraction of all-pairs shortest paths that pass through $v$\\n\\n    .. math::\\n\\n       c_B(v) =\\\\sum_{s,t \\\\in V} \\\\frac{\\\\sigma(s, t|v)}{\\\\sigma(s, t)}\\n\\n    where $V$ is the set of nodes, $\\\\sigma(s, t)$ is the number of\\n    shortest $(s, t)$-paths,  and $\\\\sigma(s, t|v)$ is the number of\\n    those paths  passing through some  node $v$ other than $s, t$.\\n    If $s = t$, $\\\\sigma(s, t) = 1$, and if $v \\\\in {s, t}$,\\n    $\\\\sigma(s, t|v) = 0$ [2]_.\\n\\n    Parameters\\n    ----------\\n    G : graph\\n      A NetworkX graph.\\n\\n    k : int, optional (default=None)\\n      If k is not None use k node samples to estimate betweenness.\\n      The value of k <= n where n is the number of nodes in the graph.\\n      Higher values give better approximation.\\n\\n    normalized : bool, optional\\n      If True the betweenness values are normalized by `2/((n-1)(n-2))`\\n      for graphs, and `1/((n-1)(n-2))` for directed graphs where `n`\\n      is the number of nodes in G.\\n\\n    weight : None or string, optional (default=None)\\n      If None, all edge weights are considered equal.\\n      Otherwise holds the name of the edge attribute used as weight.\\n      Weights are used to calculate weighted shortest paths, so they are\\n      interpreted as distances.\\n\\n    endpoints : bool, optional\\n      If True include the endpoints in the shortest path counts.\\n\\n    seed : integer, random_state, or None (default)\\n        Indicator of random number generation state.\\n        See :ref:`Randomness<randomness>`.\\n        Note that this is only used if k is not None.\\n\\n    Returns\\n    -------\\n    nodes : dictionary\\n       Dictionary of nodes with betweenness centrality as the value.\\n\\n    See Also\\n    --------\\n    edge_betweenness_centrality\\n    load_centrality\\n\\n    Notes\\n    -----\\n    The algorithm is from Ulrik Brandes [1]_.\\n    See [4]_ for the original first published version and [2]_ for details on\\n    algorithms for variations and related metrics.\\n\\n    For approximate betweenness calculations set k=#samples to use\\n    k nodes (\"pivots\") to estimate the betweenness values. For an estimate\\n    of the number of pivots needed see [3]_.\\n\\n    For weighted graphs the edge weights must be greater than zero.\\n    Zero edge weights can produce an infinite number of equal length\\n    paths between pairs of nodes.\\n\\n    The total number of paths between source and target is counted\\n    differently for directed and undirected graphs. Directed paths\\n    are easy to count. Undirected paths are tricky: should a path\\n    from \"u\" to \"v\" count as 1 undirected path or as 2 directed paths?\\n\\n    For betweenness_centrality we report the number of undirected\\n    paths when G is undirected.\\n\\n    For betweenness_centrality_subset the reporting is different.\\n    If the source and target subsets are the same, then we want\\n    to count undirected paths. But if the source and target subsets\\n    differ -- for example, if sources is {0} and targets is {1},\\n    then we are only counting the paths in one direction. They are\\n    undirected paths but we are counting them in a directed way.\\n    To count them as undirected paths, each should count as half a path.\\n\\n    This algorithm is not guaranteed to be correct if edge weights\\n    are floating point numbers. As a workaround you can use integer\\n    numbers by multiplying the relevant edge attributes by a convenient\\n    constant factor (eg 100) and converting to integers.\\n\\n    References\\n    ----------\\n    .. [1] Ulrik Brandes:\\n       A Faster Algorithm for Betweenness Centrality.\\n       Journal of Mathematical Sociology 25(2):163-177, 2001.\\n       https://doi.org/10.1080/0022250X.2001.9990249\\n    .. [2] Ulrik Brandes:\\n       On Variants of Shortest-Path Betweenness\\n       Centrality and their Generic Computation.\\n       Social Networks 30(2):136-145, 2008.\\n       https://doi.org/10.1016/j.socnet.2007.11.001\\n    .. [3] Ulrik Brandes and Christian Pich:\\n       Centrality Estimation in Large Networks.\\n       International Journal of Bifurcation and Chaos 17(7):2303-2318, 2007.\\n       https://dx.doi.org/10.1142/S0218127407018403\\n    .. [4] Linton C. Freeman:\\n       A set of measures of centrality based on betweenness.\\n       Sociometry 40: 35\u201341, 1977\\n       https://doi.org/10.2307/3033543\\n    '\n    betweenness = dict.fromkeys(G, 0.0)\n    if k is None:\n        nodes = G\n    else:\n        nodes = seed.sample(list(G.nodes()), k)\n    for s in nodes:\n        if weight is None:\n            (S, P, sigma, _) = _single_source_shortest_path_basic(G, s)\n        else:\n            (S, P, sigma, _) = _single_source_dijkstra_path_basic(G, s, weight)\n        if endpoints:\n            (betweenness, _) = _accumulate_endpoints(betweenness, S, P, sigma, s)\n        else:\n            (betweenness, _) = _accumulate_basic(betweenness, S, P, sigma, s)\n    betweenness = _rescale(betweenness, len(G), normalized=normalized, directed=G.is_directed(), k=k, endpoints=endpoints)\n    return betweenness",
            "@py_random_state(5)\n@nx._dispatch(edge_attrs='weight')\ndef betweenness_centrality(G, k=None, normalized=True, weight=None, endpoints=False, seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Compute the shortest-path betweenness centrality for nodes.\\n\\n    Betweenness centrality of a node $v$ is the sum of the\\n    fraction of all-pairs shortest paths that pass through $v$\\n\\n    .. math::\\n\\n       c_B(v) =\\\\sum_{s,t \\\\in V} \\\\frac{\\\\sigma(s, t|v)}{\\\\sigma(s, t)}\\n\\n    where $V$ is the set of nodes, $\\\\sigma(s, t)$ is the number of\\n    shortest $(s, t)$-paths,  and $\\\\sigma(s, t|v)$ is the number of\\n    those paths  passing through some  node $v$ other than $s, t$.\\n    If $s = t$, $\\\\sigma(s, t) = 1$, and if $v \\\\in {s, t}$,\\n    $\\\\sigma(s, t|v) = 0$ [2]_.\\n\\n    Parameters\\n    ----------\\n    G : graph\\n      A NetworkX graph.\\n\\n    k : int, optional (default=None)\\n      If k is not None use k node samples to estimate betweenness.\\n      The value of k <= n where n is the number of nodes in the graph.\\n      Higher values give better approximation.\\n\\n    normalized : bool, optional\\n      If True the betweenness values are normalized by `2/((n-1)(n-2))`\\n      for graphs, and `1/((n-1)(n-2))` for directed graphs where `n`\\n      is the number of nodes in G.\\n\\n    weight : None or string, optional (default=None)\\n      If None, all edge weights are considered equal.\\n      Otherwise holds the name of the edge attribute used as weight.\\n      Weights are used to calculate weighted shortest paths, so they are\\n      interpreted as distances.\\n\\n    endpoints : bool, optional\\n      If True include the endpoints in the shortest path counts.\\n\\n    seed : integer, random_state, or None (default)\\n        Indicator of random number generation state.\\n        See :ref:`Randomness<randomness>`.\\n        Note that this is only used if k is not None.\\n\\n    Returns\\n    -------\\n    nodes : dictionary\\n       Dictionary of nodes with betweenness centrality as the value.\\n\\n    See Also\\n    --------\\n    edge_betweenness_centrality\\n    load_centrality\\n\\n    Notes\\n    -----\\n    The algorithm is from Ulrik Brandes [1]_.\\n    See [4]_ for the original first published version and [2]_ for details on\\n    algorithms for variations and related metrics.\\n\\n    For approximate betweenness calculations set k=#samples to use\\n    k nodes (\"pivots\") to estimate the betweenness values. For an estimate\\n    of the number of pivots needed see [3]_.\\n\\n    For weighted graphs the edge weights must be greater than zero.\\n    Zero edge weights can produce an infinite number of equal length\\n    paths between pairs of nodes.\\n\\n    The total number of paths between source and target is counted\\n    differently for directed and undirected graphs. Directed paths\\n    are easy to count. Undirected paths are tricky: should a path\\n    from \"u\" to \"v\" count as 1 undirected path or as 2 directed paths?\\n\\n    For betweenness_centrality we report the number of undirected\\n    paths when G is undirected.\\n\\n    For betweenness_centrality_subset the reporting is different.\\n    If the source and target subsets are the same, then we want\\n    to count undirected paths. But if the source and target subsets\\n    differ -- for example, if sources is {0} and targets is {1},\\n    then we are only counting the paths in one direction. They are\\n    undirected paths but we are counting them in a directed way.\\n    To count them as undirected paths, each should count as half a path.\\n\\n    This algorithm is not guaranteed to be correct if edge weights\\n    are floating point numbers. As a workaround you can use integer\\n    numbers by multiplying the relevant edge attributes by a convenient\\n    constant factor (eg 100) and converting to integers.\\n\\n    References\\n    ----------\\n    .. [1] Ulrik Brandes:\\n       A Faster Algorithm for Betweenness Centrality.\\n       Journal of Mathematical Sociology 25(2):163-177, 2001.\\n       https://doi.org/10.1080/0022250X.2001.9990249\\n    .. [2] Ulrik Brandes:\\n       On Variants of Shortest-Path Betweenness\\n       Centrality and their Generic Computation.\\n       Social Networks 30(2):136-145, 2008.\\n       https://doi.org/10.1016/j.socnet.2007.11.001\\n    .. [3] Ulrik Brandes and Christian Pich:\\n       Centrality Estimation in Large Networks.\\n       International Journal of Bifurcation and Chaos 17(7):2303-2318, 2007.\\n       https://dx.doi.org/10.1142/S0218127407018403\\n    .. [4] Linton C. Freeman:\\n       A set of measures of centrality based on betweenness.\\n       Sociometry 40: 35\u201341, 1977\\n       https://doi.org/10.2307/3033543\\n    '\n    betweenness = dict.fromkeys(G, 0.0)\n    if k is None:\n        nodes = G\n    else:\n        nodes = seed.sample(list(G.nodes()), k)\n    for s in nodes:\n        if weight is None:\n            (S, P, sigma, _) = _single_source_shortest_path_basic(G, s)\n        else:\n            (S, P, sigma, _) = _single_source_dijkstra_path_basic(G, s, weight)\n        if endpoints:\n            (betweenness, _) = _accumulate_endpoints(betweenness, S, P, sigma, s)\n        else:\n            (betweenness, _) = _accumulate_basic(betweenness, S, P, sigma, s)\n    betweenness = _rescale(betweenness, len(G), normalized=normalized, directed=G.is_directed(), k=k, endpoints=endpoints)\n    return betweenness",
            "@py_random_state(5)\n@nx._dispatch(edge_attrs='weight')\ndef betweenness_centrality(G, k=None, normalized=True, weight=None, endpoints=False, seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Compute the shortest-path betweenness centrality for nodes.\\n\\n    Betweenness centrality of a node $v$ is the sum of the\\n    fraction of all-pairs shortest paths that pass through $v$\\n\\n    .. math::\\n\\n       c_B(v) =\\\\sum_{s,t \\\\in V} \\\\frac{\\\\sigma(s, t|v)}{\\\\sigma(s, t)}\\n\\n    where $V$ is the set of nodes, $\\\\sigma(s, t)$ is the number of\\n    shortest $(s, t)$-paths,  and $\\\\sigma(s, t|v)$ is the number of\\n    those paths  passing through some  node $v$ other than $s, t$.\\n    If $s = t$, $\\\\sigma(s, t) = 1$, and if $v \\\\in {s, t}$,\\n    $\\\\sigma(s, t|v) = 0$ [2]_.\\n\\n    Parameters\\n    ----------\\n    G : graph\\n      A NetworkX graph.\\n\\n    k : int, optional (default=None)\\n      If k is not None use k node samples to estimate betweenness.\\n      The value of k <= n where n is the number of nodes in the graph.\\n      Higher values give better approximation.\\n\\n    normalized : bool, optional\\n      If True the betweenness values are normalized by `2/((n-1)(n-2))`\\n      for graphs, and `1/((n-1)(n-2))` for directed graphs where `n`\\n      is the number of nodes in G.\\n\\n    weight : None or string, optional (default=None)\\n      If None, all edge weights are considered equal.\\n      Otherwise holds the name of the edge attribute used as weight.\\n      Weights are used to calculate weighted shortest paths, so they are\\n      interpreted as distances.\\n\\n    endpoints : bool, optional\\n      If True include the endpoints in the shortest path counts.\\n\\n    seed : integer, random_state, or None (default)\\n        Indicator of random number generation state.\\n        See :ref:`Randomness<randomness>`.\\n        Note that this is only used if k is not None.\\n\\n    Returns\\n    -------\\n    nodes : dictionary\\n       Dictionary of nodes with betweenness centrality as the value.\\n\\n    See Also\\n    --------\\n    edge_betweenness_centrality\\n    load_centrality\\n\\n    Notes\\n    -----\\n    The algorithm is from Ulrik Brandes [1]_.\\n    See [4]_ for the original first published version and [2]_ for details on\\n    algorithms for variations and related metrics.\\n\\n    For approximate betweenness calculations set k=#samples to use\\n    k nodes (\"pivots\") to estimate the betweenness values. For an estimate\\n    of the number of pivots needed see [3]_.\\n\\n    For weighted graphs the edge weights must be greater than zero.\\n    Zero edge weights can produce an infinite number of equal length\\n    paths between pairs of nodes.\\n\\n    The total number of paths between source and target is counted\\n    differently for directed and undirected graphs. Directed paths\\n    are easy to count. Undirected paths are tricky: should a path\\n    from \"u\" to \"v\" count as 1 undirected path or as 2 directed paths?\\n\\n    For betweenness_centrality we report the number of undirected\\n    paths when G is undirected.\\n\\n    For betweenness_centrality_subset the reporting is different.\\n    If the source and target subsets are the same, then we want\\n    to count undirected paths. But if the source and target subsets\\n    differ -- for example, if sources is {0} and targets is {1},\\n    then we are only counting the paths in one direction. They are\\n    undirected paths but we are counting them in a directed way.\\n    To count them as undirected paths, each should count as half a path.\\n\\n    This algorithm is not guaranteed to be correct if edge weights\\n    are floating point numbers. As a workaround you can use integer\\n    numbers by multiplying the relevant edge attributes by a convenient\\n    constant factor (eg 100) and converting to integers.\\n\\n    References\\n    ----------\\n    .. [1] Ulrik Brandes:\\n       A Faster Algorithm for Betweenness Centrality.\\n       Journal of Mathematical Sociology 25(2):163-177, 2001.\\n       https://doi.org/10.1080/0022250X.2001.9990249\\n    .. [2] Ulrik Brandes:\\n       On Variants of Shortest-Path Betweenness\\n       Centrality and their Generic Computation.\\n       Social Networks 30(2):136-145, 2008.\\n       https://doi.org/10.1016/j.socnet.2007.11.001\\n    .. [3] Ulrik Brandes and Christian Pich:\\n       Centrality Estimation in Large Networks.\\n       International Journal of Bifurcation and Chaos 17(7):2303-2318, 2007.\\n       https://dx.doi.org/10.1142/S0218127407018403\\n    .. [4] Linton C. Freeman:\\n       A set of measures of centrality based on betweenness.\\n       Sociometry 40: 35\u201341, 1977\\n       https://doi.org/10.2307/3033543\\n    '\n    betweenness = dict.fromkeys(G, 0.0)\n    if k is None:\n        nodes = G\n    else:\n        nodes = seed.sample(list(G.nodes()), k)\n    for s in nodes:\n        if weight is None:\n            (S, P, sigma, _) = _single_source_shortest_path_basic(G, s)\n        else:\n            (S, P, sigma, _) = _single_source_dijkstra_path_basic(G, s, weight)\n        if endpoints:\n            (betweenness, _) = _accumulate_endpoints(betweenness, S, P, sigma, s)\n        else:\n            (betweenness, _) = _accumulate_basic(betweenness, S, P, sigma, s)\n    betweenness = _rescale(betweenness, len(G), normalized=normalized, directed=G.is_directed(), k=k, endpoints=endpoints)\n    return betweenness",
            "@py_random_state(5)\n@nx._dispatch(edge_attrs='weight')\ndef betweenness_centrality(G, k=None, normalized=True, weight=None, endpoints=False, seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Compute the shortest-path betweenness centrality for nodes.\\n\\n    Betweenness centrality of a node $v$ is the sum of the\\n    fraction of all-pairs shortest paths that pass through $v$\\n\\n    .. math::\\n\\n       c_B(v) =\\\\sum_{s,t \\\\in V} \\\\frac{\\\\sigma(s, t|v)}{\\\\sigma(s, t)}\\n\\n    where $V$ is the set of nodes, $\\\\sigma(s, t)$ is the number of\\n    shortest $(s, t)$-paths,  and $\\\\sigma(s, t|v)$ is the number of\\n    those paths  passing through some  node $v$ other than $s, t$.\\n    If $s = t$, $\\\\sigma(s, t) = 1$, and if $v \\\\in {s, t}$,\\n    $\\\\sigma(s, t|v) = 0$ [2]_.\\n\\n    Parameters\\n    ----------\\n    G : graph\\n      A NetworkX graph.\\n\\n    k : int, optional (default=None)\\n      If k is not None use k node samples to estimate betweenness.\\n      The value of k <= n where n is the number of nodes in the graph.\\n      Higher values give better approximation.\\n\\n    normalized : bool, optional\\n      If True the betweenness values are normalized by `2/((n-1)(n-2))`\\n      for graphs, and `1/((n-1)(n-2))` for directed graphs where `n`\\n      is the number of nodes in G.\\n\\n    weight : None or string, optional (default=None)\\n      If None, all edge weights are considered equal.\\n      Otherwise holds the name of the edge attribute used as weight.\\n      Weights are used to calculate weighted shortest paths, so they are\\n      interpreted as distances.\\n\\n    endpoints : bool, optional\\n      If True include the endpoints in the shortest path counts.\\n\\n    seed : integer, random_state, or None (default)\\n        Indicator of random number generation state.\\n        See :ref:`Randomness<randomness>`.\\n        Note that this is only used if k is not None.\\n\\n    Returns\\n    -------\\n    nodes : dictionary\\n       Dictionary of nodes with betweenness centrality as the value.\\n\\n    See Also\\n    --------\\n    edge_betweenness_centrality\\n    load_centrality\\n\\n    Notes\\n    -----\\n    The algorithm is from Ulrik Brandes [1]_.\\n    See [4]_ for the original first published version and [2]_ for details on\\n    algorithms for variations and related metrics.\\n\\n    For approximate betweenness calculations set k=#samples to use\\n    k nodes (\"pivots\") to estimate the betweenness values. For an estimate\\n    of the number of pivots needed see [3]_.\\n\\n    For weighted graphs the edge weights must be greater than zero.\\n    Zero edge weights can produce an infinite number of equal length\\n    paths between pairs of nodes.\\n\\n    The total number of paths between source and target is counted\\n    differently for directed and undirected graphs. Directed paths\\n    are easy to count. Undirected paths are tricky: should a path\\n    from \"u\" to \"v\" count as 1 undirected path or as 2 directed paths?\\n\\n    For betweenness_centrality we report the number of undirected\\n    paths when G is undirected.\\n\\n    For betweenness_centrality_subset the reporting is different.\\n    If the source and target subsets are the same, then we want\\n    to count undirected paths. But if the source and target subsets\\n    differ -- for example, if sources is {0} and targets is {1},\\n    then we are only counting the paths in one direction. They are\\n    undirected paths but we are counting them in a directed way.\\n    To count them as undirected paths, each should count as half a path.\\n\\n    This algorithm is not guaranteed to be correct if edge weights\\n    are floating point numbers. As a workaround you can use integer\\n    numbers by multiplying the relevant edge attributes by a convenient\\n    constant factor (eg 100) and converting to integers.\\n\\n    References\\n    ----------\\n    .. [1] Ulrik Brandes:\\n       A Faster Algorithm for Betweenness Centrality.\\n       Journal of Mathematical Sociology 25(2):163-177, 2001.\\n       https://doi.org/10.1080/0022250X.2001.9990249\\n    .. [2] Ulrik Brandes:\\n       On Variants of Shortest-Path Betweenness\\n       Centrality and their Generic Computation.\\n       Social Networks 30(2):136-145, 2008.\\n       https://doi.org/10.1016/j.socnet.2007.11.001\\n    .. [3] Ulrik Brandes and Christian Pich:\\n       Centrality Estimation in Large Networks.\\n       International Journal of Bifurcation and Chaos 17(7):2303-2318, 2007.\\n       https://dx.doi.org/10.1142/S0218127407018403\\n    .. [4] Linton C. Freeman:\\n       A set of measures of centrality based on betweenness.\\n       Sociometry 40: 35\u201341, 1977\\n       https://doi.org/10.2307/3033543\\n    '\n    betweenness = dict.fromkeys(G, 0.0)\n    if k is None:\n        nodes = G\n    else:\n        nodes = seed.sample(list(G.nodes()), k)\n    for s in nodes:\n        if weight is None:\n            (S, P, sigma, _) = _single_source_shortest_path_basic(G, s)\n        else:\n            (S, P, sigma, _) = _single_source_dijkstra_path_basic(G, s, weight)\n        if endpoints:\n            (betweenness, _) = _accumulate_endpoints(betweenness, S, P, sigma, s)\n        else:\n            (betweenness, _) = _accumulate_basic(betweenness, S, P, sigma, s)\n    betweenness = _rescale(betweenness, len(G), normalized=normalized, directed=G.is_directed(), k=k, endpoints=endpoints)\n    return betweenness"
        ]
    },
    {
        "func_name": "edge_betweenness_centrality",
        "original": "@py_random_state(4)\n@nx._dispatch(edge_attrs='weight')\ndef edge_betweenness_centrality(G, k=None, normalized=True, weight=None, seed=None):\n    \"\"\"Compute betweenness centrality for edges.\n\n    Betweenness centrality of an edge $e$ is the sum of the\n    fraction of all-pairs shortest paths that pass through $e$\n\n    .. math::\n\n       c_B(e) =\\\\sum_{s,t \\\\in V} \\\\frac{\\\\sigma(s, t|e)}{\\\\sigma(s, t)}\n\n    where $V$ is the set of nodes, $\\\\sigma(s, t)$ is the number of\n    shortest $(s, t)$-paths, and $\\\\sigma(s, t|e)$ is the number of\n    those paths passing through edge $e$ [2]_.\n\n    Parameters\n    ----------\n    G : graph\n      A NetworkX graph.\n\n    k : int, optional (default=None)\n      If k is not None use k node samples to estimate betweenness.\n      The value of k <= n where n is the number of nodes in the graph.\n      Higher values give better approximation.\n\n    normalized : bool, optional\n      If True the betweenness values are normalized by $2/(n(n-1))$\n      for graphs, and $1/(n(n-1))$ for directed graphs where $n$\n      is the number of nodes in G.\n\n    weight : None or string, optional (default=None)\n      If None, all edge weights are considered equal.\n      Otherwise holds the name of the edge attribute used as weight.\n      Weights are used to calculate weighted shortest paths, so they are\n      interpreted as distances.\n\n    seed : integer, random_state, or None (default)\n        Indicator of random number generation state.\n        See :ref:`Randomness<randomness>`.\n        Note that this is only used if k is not None.\n\n    Returns\n    -------\n    edges : dictionary\n       Dictionary of edges with betweenness centrality as the value.\n\n    See Also\n    --------\n    betweenness_centrality\n    edge_load\n\n    Notes\n    -----\n    The algorithm is from Ulrik Brandes [1]_.\n\n    For weighted graphs the edge weights must be greater than zero.\n    Zero edge weights can produce an infinite number of equal length\n    paths between pairs of nodes.\n\n    References\n    ----------\n    .. [1]  A Faster Algorithm for Betweenness Centrality. Ulrik Brandes,\n       Journal of Mathematical Sociology 25(2):163-177, 2001.\n       https://doi.org/10.1080/0022250X.2001.9990249\n    .. [2] Ulrik Brandes: On Variants of Shortest-Path Betweenness\n       Centrality and their Generic Computation.\n       Social Networks 30(2):136-145, 2008.\n       https://doi.org/10.1016/j.socnet.2007.11.001\n    \"\"\"\n    betweenness = dict.fromkeys(G, 0.0)\n    betweenness.update(dict.fromkeys(G.edges(), 0.0))\n    if k is None:\n        nodes = G\n    else:\n        nodes = seed.sample(list(G.nodes()), k)\n    for s in nodes:\n        if weight is None:\n            (S, P, sigma, _) = _single_source_shortest_path_basic(G, s)\n        else:\n            (S, P, sigma, _) = _single_source_dijkstra_path_basic(G, s, weight)\n        betweenness = _accumulate_edges(betweenness, S, P, sigma, s)\n    for n in G:\n        del betweenness[n]\n    betweenness = _rescale_e(betweenness, len(G), normalized=normalized, directed=G.is_directed())\n    if G.is_multigraph():\n        betweenness = _add_edge_keys(G, betweenness, weight=weight)\n    return betweenness",
        "mutated": [
            "@py_random_state(4)\n@nx._dispatch(edge_attrs='weight')\ndef edge_betweenness_centrality(G, k=None, normalized=True, weight=None, seed=None):\n    if False:\n        i = 10\n    'Compute betweenness centrality for edges.\\n\\n    Betweenness centrality of an edge $e$ is the sum of the\\n    fraction of all-pairs shortest paths that pass through $e$\\n\\n    .. math::\\n\\n       c_B(e) =\\\\sum_{s,t \\\\in V} \\\\frac{\\\\sigma(s, t|e)}{\\\\sigma(s, t)}\\n\\n    where $V$ is the set of nodes, $\\\\sigma(s, t)$ is the number of\\n    shortest $(s, t)$-paths, and $\\\\sigma(s, t|e)$ is the number of\\n    those paths passing through edge $e$ [2]_.\\n\\n    Parameters\\n    ----------\\n    G : graph\\n      A NetworkX graph.\\n\\n    k : int, optional (default=None)\\n      If k is not None use k node samples to estimate betweenness.\\n      The value of k <= n where n is the number of nodes in the graph.\\n      Higher values give better approximation.\\n\\n    normalized : bool, optional\\n      If True the betweenness values are normalized by $2/(n(n-1))$\\n      for graphs, and $1/(n(n-1))$ for directed graphs where $n$\\n      is the number of nodes in G.\\n\\n    weight : None or string, optional (default=None)\\n      If None, all edge weights are considered equal.\\n      Otherwise holds the name of the edge attribute used as weight.\\n      Weights are used to calculate weighted shortest paths, so they are\\n      interpreted as distances.\\n\\n    seed : integer, random_state, or None (default)\\n        Indicator of random number generation state.\\n        See :ref:`Randomness<randomness>`.\\n        Note that this is only used if k is not None.\\n\\n    Returns\\n    -------\\n    edges : dictionary\\n       Dictionary of edges with betweenness centrality as the value.\\n\\n    See Also\\n    --------\\n    betweenness_centrality\\n    edge_load\\n\\n    Notes\\n    -----\\n    The algorithm is from Ulrik Brandes [1]_.\\n\\n    For weighted graphs the edge weights must be greater than zero.\\n    Zero edge weights can produce an infinite number of equal length\\n    paths between pairs of nodes.\\n\\n    References\\n    ----------\\n    .. [1]  A Faster Algorithm for Betweenness Centrality. Ulrik Brandes,\\n       Journal of Mathematical Sociology 25(2):163-177, 2001.\\n       https://doi.org/10.1080/0022250X.2001.9990249\\n    .. [2] Ulrik Brandes: On Variants of Shortest-Path Betweenness\\n       Centrality and their Generic Computation.\\n       Social Networks 30(2):136-145, 2008.\\n       https://doi.org/10.1016/j.socnet.2007.11.001\\n    '\n    betweenness = dict.fromkeys(G, 0.0)\n    betweenness.update(dict.fromkeys(G.edges(), 0.0))\n    if k is None:\n        nodes = G\n    else:\n        nodes = seed.sample(list(G.nodes()), k)\n    for s in nodes:\n        if weight is None:\n            (S, P, sigma, _) = _single_source_shortest_path_basic(G, s)\n        else:\n            (S, P, sigma, _) = _single_source_dijkstra_path_basic(G, s, weight)\n        betweenness = _accumulate_edges(betweenness, S, P, sigma, s)\n    for n in G:\n        del betweenness[n]\n    betweenness = _rescale_e(betweenness, len(G), normalized=normalized, directed=G.is_directed())\n    if G.is_multigraph():\n        betweenness = _add_edge_keys(G, betweenness, weight=weight)\n    return betweenness",
            "@py_random_state(4)\n@nx._dispatch(edge_attrs='weight')\ndef edge_betweenness_centrality(G, k=None, normalized=True, weight=None, seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Compute betweenness centrality for edges.\\n\\n    Betweenness centrality of an edge $e$ is the sum of the\\n    fraction of all-pairs shortest paths that pass through $e$\\n\\n    .. math::\\n\\n       c_B(e) =\\\\sum_{s,t \\\\in V} \\\\frac{\\\\sigma(s, t|e)}{\\\\sigma(s, t)}\\n\\n    where $V$ is the set of nodes, $\\\\sigma(s, t)$ is the number of\\n    shortest $(s, t)$-paths, and $\\\\sigma(s, t|e)$ is the number of\\n    those paths passing through edge $e$ [2]_.\\n\\n    Parameters\\n    ----------\\n    G : graph\\n      A NetworkX graph.\\n\\n    k : int, optional (default=None)\\n      If k is not None use k node samples to estimate betweenness.\\n      The value of k <= n where n is the number of nodes in the graph.\\n      Higher values give better approximation.\\n\\n    normalized : bool, optional\\n      If True the betweenness values are normalized by $2/(n(n-1))$\\n      for graphs, and $1/(n(n-1))$ for directed graphs where $n$\\n      is the number of nodes in G.\\n\\n    weight : None or string, optional (default=None)\\n      If None, all edge weights are considered equal.\\n      Otherwise holds the name of the edge attribute used as weight.\\n      Weights are used to calculate weighted shortest paths, so they are\\n      interpreted as distances.\\n\\n    seed : integer, random_state, or None (default)\\n        Indicator of random number generation state.\\n        See :ref:`Randomness<randomness>`.\\n        Note that this is only used if k is not None.\\n\\n    Returns\\n    -------\\n    edges : dictionary\\n       Dictionary of edges with betweenness centrality as the value.\\n\\n    See Also\\n    --------\\n    betweenness_centrality\\n    edge_load\\n\\n    Notes\\n    -----\\n    The algorithm is from Ulrik Brandes [1]_.\\n\\n    For weighted graphs the edge weights must be greater than zero.\\n    Zero edge weights can produce an infinite number of equal length\\n    paths between pairs of nodes.\\n\\n    References\\n    ----------\\n    .. [1]  A Faster Algorithm for Betweenness Centrality. Ulrik Brandes,\\n       Journal of Mathematical Sociology 25(2):163-177, 2001.\\n       https://doi.org/10.1080/0022250X.2001.9990249\\n    .. [2] Ulrik Brandes: On Variants of Shortest-Path Betweenness\\n       Centrality and their Generic Computation.\\n       Social Networks 30(2):136-145, 2008.\\n       https://doi.org/10.1016/j.socnet.2007.11.001\\n    '\n    betweenness = dict.fromkeys(G, 0.0)\n    betweenness.update(dict.fromkeys(G.edges(), 0.0))\n    if k is None:\n        nodes = G\n    else:\n        nodes = seed.sample(list(G.nodes()), k)\n    for s in nodes:\n        if weight is None:\n            (S, P, sigma, _) = _single_source_shortest_path_basic(G, s)\n        else:\n            (S, P, sigma, _) = _single_source_dijkstra_path_basic(G, s, weight)\n        betweenness = _accumulate_edges(betweenness, S, P, sigma, s)\n    for n in G:\n        del betweenness[n]\n    betweenness = _rescale_e(betweenness, len(G), normalized=normalized, directed=G.is_directed())\n    if G.is_multigraph():\n        betweenness = _add_edge_keys(G, betweenness, weight=weight)\n    return betweenness",
            "@py_random_state(4)\n@nx._dispatch(edge_attrs='weight')\ndef edge_betweenness_centrality(G, k=None, normalized=True, weight=None, seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Compute betweenness centrality for edges.\\n\\n    Betweenness centrality of an edge $e$ is the sum of the\\n    fraction of all-pairs shortest paths that pass through $e$\\n\\n    .. math::\\n\\n       c_B(e) =\\\\sum_{s,t \\\\in V} \\\\frac{\\\\sigma(s, t|e)}{\\\\sigma(s, t)}\\n\\n    where $V$ is the set of nodes, $\\\\sigma(s, t)$ is the number of\\n    shortest $(s, t)$-paths, and $\\\\sigma(s, t|e)$ is the number of\\n    those paths passing through edge $e$ [2]_.\\n\\n    Parameters\\n    ----------\\n    G : graph\\n      A NetworkX graph.\\n\\n    k : int, optional (default=None)\\n      If k is not None use k node samples to estimate betweenness.\\n      The value of k <= n where n is the number of nodes in the graph.\\n      Higher values give better approximation.\\n\\n    normalized : bool, optional\\n      If True the betweenness values are normalized by $2/(n(n-1))$\\n      for graphs, and $1/(n(n-1))$ for directed graphs where $n$\\n      is the number of nodes in G.\\n\\n    weight : None or string, optional (default=None)\\n      If None, all edge weights are considered equal.\\n      Otherwise holds the name of the edge attribute used as weight.\\n      Weights are used to calculate weighted shortest paths, so they are\\n      interpreted as distances.\\n\\n    seed : integer, random_state, or None (default)\\n        Indicator of random number generation state.\\n        See :ref:`Randomness<randomness>`.\\n        Note that this is only used if k is not None.\\n\\n    Returns\\n    -------\\n    edges : dictionary\\n       Dictionary of edges with betweenness centrality as the value.\\n\\n    See Also\\n    --------\\n    betweenness_centrality\\n    edge_load\\n\\n    Notes\\n    -----\\n    The algorithm is from Ulrik Brandes [1]_.\\n\\n    For weighted graphs the edge weights must be greater than zero.\\n    Zero edge weights can produce an infinite number of equal length\\n    paths between pairs of nodes.\\n\\n    References\\n    ----------\\n    .. [1]  A Faster Algorithm for Betweenness Centrality. Ulrik Brandes,\\n       Journal of Mathematical Sociology 25(2):163-177, 2001.\\n       https://doi.org/10.1080/0022250X.2001.9990249\\n    .. [2] Ulrik Brandes: On Variants of Shortest-Path Betweenness\\n       Centrality and their Generic Computation.\\n       Social Networks 30(2):136-145, 2008.\\n       https://doi.org/10.1016/j.socnet.2007.11.001\\n    '\n    betweenness = dict.fromkeys(G, 0.0)\n    betweenness.update(dict.fromkeys(G.edges(), 0.0))\n    if k is None:\n        nodes = G\n    else:\n        nodes = seed.sample(list(G.nodes()), k)\n    for s in nodes:\n        if weight is None:\n            (S, P, sigma, _) = _single_source_shortest_path_basic(G, s)\n        else:\n            (S, P, sigma, _) = _single_source_dijkstra_path_basic(G, s, weight)\n        betweenness = _accumulate_edges(betweenness, S, P, sigma, s)\n    for n in G:\n        del betweenness[n]\n    betweenness = _rescale_e(betweenness, len(G), normalized=normalized, directed=G.is_directed())\n    if G.is_multigraph():\n        betweenness = _add_edge_keys(G, betweenness, weight=weight)\n    return betweenness",
            "@py_random_state(4)\n@nx._dispatch(edge_attrs='weight')\ndef edge_betweenness_centrality(G, k=None, normalized=True, weight=None, seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Compute betweenness centrality for edges.\\n\\n    Betweenness centrality of an edge $e$ is the sum of the\\n    fraction of all-pairs shortest paths that pass through $e$\\n\\n    .. math::\\n\\n       c_B(e) =\\\\sum_{s,t \\\\in V} \\\\frac{\\\\sigma(s, t|e)}{\\\\sigma(s, t)}\\n\\n    where $V$ is the set of nodes, $\\\\sigma(s, t)$ is the number of\\n    shortest $(s, t)$-paths, and $\\\\sigma(s, t|e)$ is the number of\\n    those paths passing through edge $e$ [2]_.\\n\\n    Parameters\\n    ----------\\n    G : graph\\n      A NetworkX graph.\\n\\n    k : int, optional (default=None)\\n      If k is not None use k node samples to estimate betweenness.\\n      The value of k <= n where n is the number of nodes in the graph.\\n      Higher values give better approximation.\\n\\n    normalized : bool, optional\\n      If True the betweenness values are normalized by $2/(n(n-1))$\\n      for graphs, and $1/(n(n-1))$ for directed graphs where $n$\\n      is the number of nodes in G.\\n\\n    weight : None or string, optional (default=None)\\n      If None, all edge weights are considered equal.\\n      Otherwise holds the name of the edge attribute used as weight.\\n      Weights are used to calculate weighted shortest paths, so they are\\n      interpreted as distances.\\n\\n    seed : integer, random_state, or None (default)\\n        Indicator of random number generation state.\\n        See :ref:`Randomness<randomness>`.\\n        Note that this is only used if k is not None.\\n\\n    Returns\\n    -------\\n    edges : dictionary\\n       Dictionary of edges with betweenness centrality as the value.\\n\\n    See Also\\n    --------\\n    betweenness_centrality\\n    edge_load\\n\\n    Notes\\n    -----\\n    The algorithm is from Ulrik Brandes [1]_.\\n\\n    For weighted graphs the edge weights must be greater than zero.\\n    Zero edge weights can produce an infinite number of equal length\\n    paths between pairs of nodes.\\n\\n    References\\n    ----------\\n    .. [1]  A Faster Algorithm for Betweenness Centrality. Ulrik Brandes,\\n       Journal of Mathematical Sociology 25(2):163-177, 2001.\\n       https://doi.org/10.1080/0022250X.2001.9990249\\n    .. [2] Ulrik Brandes: On Variants of Shortest-Path Betweenness\\n       Centrality and their Generic Computation.\\n       Social Networks 30(2):136-145, 2008.\\n       https://doi.org/10.1016/j.socnet.2007.11.001\\n    '\n    betweenness = dict.fromkeys(G, 0.0)\n    betweenness.update(dict.fromkeys(G.edges(), 0.0))\n    if k is None:\n        nodes = G\n    else:\n        nodes = seed.sample(list(G.nodes()), k)\n    for s in nodes:\n        if weight is None:\n            (S, P, sigma, _) = _single_source_shortest_path_basic(G, s)\n        else:\n            (S, P, sigma, _) = _single_source_dijkstra_path_basic(G, s, weight)\n        betweenness = _accumulate_edges(betweenness, S, P, sigma, s)\n    for n in G:\n        del betweenness[n]\n    betweenness = _rescale_e(betweenness, len(G), normalized=normalized, directed=G.is_directed())\n    if G.is_multigraph():\n        betweenness = _add_edge_keys(G, betweenness, weight=weight)\n    return betweenness",
            "@py_random_state(4)\n@nx._dispatch(edge_attrs='weight')\ndef edge_betweenness_centrality(G, k=None, normalized=True, weight=None, seed=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Compute betweenness centrality for edges.\\n\\n    Betweenness centrality of an edge $e$ is the sum of the\\n    fraction of all-pairs shortest paths that pass through $e$\\n\\n    .. math::\\n\\n       c_B(e) =\\\\sum_{s,t \\\\in V} \\\\frac{\\\\sigma(s, t|e)}{\\\\sigma(s, t)}\\n\\n    where $V$ is the set of nodes, $\\\\sigma(s, t)$ is the number of\\n    shortest $(s, t)$-paths, and $\\\\sigma(s, t|e)$ is the number of\\n    those paths passing through edge $e$ [2]_.\\n\\n    Parameters\\n    ----------\\n    G : graph\\n      A NetworkX graph.\\n\\n    k : int, optional (default=None)\\n      If k is not None use k node samples to estimate betweenness.\\n      The value of k <= n where n is the number of nodes in the graph.\\n      Higher values give better approximation.\\n\\n    normalized : bool, optional\\n      If True the betweenness values are normalized by $2/(n(n-1))$\\n      for graphs, and $1/(n(n-1))$ for directed graphs where $n$\\n      is the number of nodes in G.\\n\\n    weight : None or string, optional (default=None)\\n      If None, all edge weights are considered equal.\\n      Otherwise holds the name of the edge attribute used as weight.\\n      Weights are used to calculate weighted shortest paths, so they are\\n      interpreted as distances.\\n\\n    seed : integer, random_state, or None (default)\\n        Indicator of random number generation state.\\n        See :ref:`Randomness<randomness>`.\\n        Note that this is only used if k is not None.\\n\\n    Returns\\n    -------\\n    edges : dictionary\\n       Dictionary of edges with betweenness centrality as the value.\\n\\n    See Also\\n    --------\\n    betweenness_centrality\\n    edge_load\\n\\n    Notes\\n    -----\\n    The algorithm is from Ulrik Brandes [1]_.\\n\\n    For weighted graphs the edge weights must be greater than zero.\\n    Zero edge weights can produce an infinite number of equal length\\n    paths between pairs of nodes.\\n\\n    References\\n    ----------\\n    .. [1]  A Faster Algorithm for Betweenness Centrality. Ulrik Brandes,\\n       Journal of Mathematical Sociology 25(2):163-177, 2001.\\n       https://doi.org/10.1080/0022250X.2001.9990249\\n    .. [2] Ulrik Brandes: On Variants of Shortest-Path Betweenness\\n       Centrality and their Generic Computation.\\n       Social Networks 30(2):136-145, 2008.\\n       https://doi.org/10.1016/j.socnet.2007.11.001\\n    '\n    betweenness = dict.fromkeys(G, 0.0)\n    betweenness.update(dict.fromkeys(G.edges(), 0.0))\n    if k is None:\n        nodes = G\n    else:\n        nodes = seed.sample(list(G.nodes()), k)\n    for s in nodes:\n        if weight is None:\n            (S, P, sigma, _) = _single_source_shortest_path_basic(G, s)\n        else:\n            (S, P, sigma, _) = _single_source_dijkstra_path_basic(G, s, weight)\n        betweenness = _accumulate_edges(betweenness, S, P, sigma, s)\n    for n in G:\n        del betweenness[n]\n    betweenness = _rescale_e(betweenness, len(G), normalized=normalized, directed=G.is_directed())\n    if G.is_multigraph():\n        betweenness = _add_edge_keys(G, betweenness, weight=weight)\n    return betweenness"
        ]
    },
    {
        "func_name": "_single_source_shortest_path_basic",
        "original": "def _single_source_shortest_path_basic(G, s):\n    S = []\n    P = {}\n    for v in G:\n        P[v] = []\n    sigma = dict.fromkeys(G, 0.0)\n    D = {}\n    sigma[s] = 1.0\n    D[s] = 0\n    Q = deque([s])\n    while Q:\n        v = Q.popleft()\n        S.append(v)\n        Dv = D[v]\n        sigmav = sigma[v]\n        for w in G[v]:\n            if w not in D:\n                Q.append(w)\n                D[w] = Dv + 1\n            if D[w] == Dv + 1:\n                sigma[w] += sigmav\n                P[w].append(v)\n    return (S, P, sigma, D)",
        "mutated": [
            "def _single_source_shortest_path_basic(G, s):\n    if False:\n        i = 10\n    S = []\n    P = {}\n    for v in G:\n        P[v] = []\n    sigma = dict.fromkeys(G, 0.0)\n    D = {}\n    sigma[s] = 1.0\n    D[s] = 0\n    Q = deque([s])\n    while Q:\n        v = Q.popleft()\n        S.append(v)\n        Dv = D[v]\n        sigmav = sigma[v]\n        for w in G[v]:\n            if w not in D:\n                Q.append(w)\n                D[w] = Dv + 1\n            if D[w] == Dv + 1:\n                sigma[w] += sigmav\n                P[w].append(v)\n    return (S, P, sigma, D)",
            "def _single_source_shortest_path_basic(G, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    S = []\n    P = {}\n    for v in G:\n        P[v] = []\n    sigma = dict.fromkeys(G, 0.0)\n    D = {}\n    sigma[s] = 1.0\n    D[s] = 0\n    Q = deque([s])\n    while Q:\n        v = Q.popleft()\n        S.append(v)\n        Dv = D[v]\n        sigmav = sigma[v]\n        for w in G[v]:\n            if w not in D:\n                Q.append(w)\n                D[w] = Dv + 1\n            if D[w] == Dv + 1:\n                sigma[w] += sigmav\n                P[w].append(v)\n    return (S, P, sigma, D)",
            "def _single_source_shortest_path_basic(G, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    S = []\n    P = {}\n    for v in G:\n        P[v] = []\n    sigma = dict.fromkeys(G, 0.0)\n    D = {}\n    sigma[s] = 1.0\n    D[s] = 0\n    Q = deque([s])\n    while Q:\n        v = Q.popleft()\n        S.append(v)\n        Dv = D[v]\n        sigmav = sigma[v]\n        for w in G[v]:\n            if w not in D:\n                Q.append(w)\n                D[w] = Dv + 1\n            if D[w] == Dv + 1:\n                sigma[w] += sigmav\n                P[w].append(v)\n    return (S, P, sigma, D)",
            "def _single_source_shortest_path_basic(G, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    S = []\n    P = {}\n    for v in G:\n        P[v] = []\n    sigma = dict.fromkeys(G, 0.0)\n    D = {}\n    sigma[s] = 1.0\n    D[s] = 0\n    Q = deque([s])\n    while Q:\n        v = Q.popleft()\n        S.append(v)\n        Dv = D[v]\n        sigmav = sigma[v]\n        for w in G[v]:\n            if w not in D:\n                Q.append(w)\n                D[w] = Dv + 1\n            if D[w] == Dv + 1:\n                sigma[w] += sigmav\n                P[w].append(v)\n    return (S, P, sigma, D)",
            "def _single_source_shortest_path_basic(G, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    S = []\n    P = {}\n    for v in G:\n        P[v] = []\n    sigma = dict.fromkeys(G, 0.0)\n    D = {}\n    sigma[s] = 1.0\n    D[s] = 0\n    Q = deque([s])\n    while Q:\n        v = Q.popleft()\n        S.append(v)\n        Dv = D[v]\n        sigmav = sigma[v]\n        for w in G[v]:\n            if w not in D:\n                Q.append(w)\n                D[w] = Dv + 1\n            if D[w] == Dv + 1:\n                sigma[w] += sigmav\n                P[w].append(v)\n    return (S, P, sigma, D)"
        ]
    },
    {
        "func_name": "_single_source_dijkstra_path_basic",
        "original": "def _single_source_dijkstra_path_basic(G, s, weight):\n    weight = _weight_function(G, weight)\n    S = []\n    P = {}\n    for v in G:\n        P[v] = []\n    sigma = dict.fromkeys(G, 0.0)\n    D = {}\n    sigma[s] = 1.0\n    push = heappush\n    pop = heappop\n    seen = {s: 0}\n    c = count()\n    Q = []\n    push(Q, (0, next(c), s, s))\n    while Q:\n        (dist, _, pred, v) = pop(Q)\n        if v in D:\n            continue\n        sigma[v] += sigma[pred]\n        S.append(v)\n        D[v] = dist\n        for (w, edgedata) in G[v].items():\n            vw_dist = dist + weight(v, w, edgedata)\n            if w not in D and (w not in seen or vw_dist < seen[w]):\n                seen[w] = vw_dist\n                push(Q, (vw_dist, next(c), v, w))\n                sigma[w] = 0.0\n                P[w] = [v]\n            elif vw_dist == seen[w]:\n                sigma[w] += sigma[v]\n                P[w].append(v)\n    return (S, P, sigma, D)",
        "mutated": [
            "def _single_source_dijkstra_path_basic(G, s, weight):\n    if False:\n        i = 10\n    weight = _weight_function(G, weight)\n    S = []\n    P = {}\n    for v in G:\n        P[v] = []\n    sigma = dict.fromkeys(G, 0.0)\n    D = {}\n    sigma[s] = 1.0\n    push = heappush\n    pop = heappop\n    seen = {s: 0}\n    c = count()\n    Q = []\n    push(Q, (0, next(c), s, s))\n    while Q:\n        (dist, _, pred, v) = pop(Q)\n        if v in D:\n            continue\n        sigma[v] += sigma[pred]\n        S.append(v)\n        D[v] = dist\n        for (w, edgedata) in G[v].items():\n            vw_dist = dist + weight(v, w, edgedata)\n            if w not in D and (w not in seen or vw_dist < seen[w]):\n                seen[w] = vw_dist\n                push(Q, (vw_dist, next(c), v, w))\n                sigma[w] = 0.0\n                P[w] = [v]\n            elif vw_dist == seen[w]:\n                sigma[w] += sigma[v]\n                P[w].append(v)\n    return (S, P, sigma, D)",
            "def _single_source_dijkstra_path_basic(G, s, weight):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    weight = _weight_function(G, weight)\n    S = []\n    P = {}\n    for v in G:\n        P[v] = []\n    sigma = dict.fromkeys(G, 0.0)\n    D = {}\n    sigma[s] = 1.0\n    push = heappush\n    pop = heappop\n    seen = {s: 0}\n    c = count()\n    Q = []\n    push(Q, (0, next(c), s, s))\n    while Q:\n        (dist, _, pred, v) = pop(Q)\n        if v in D:\n            continue\n        sigma[v] += sigma[pred]\n        S.append(v)\n        D[v] = dist\n        for (w, edgedata) in G[v].items():\n            vw_dist = dist + weight(v, w, edgedata)\n            if w not in D and (w not in seen or vw_dist < seen[w]):\n                seen[w] = vw_dist\n                push(Q, (vw_dist, next(c), v, w))\n                sigma[w] = 0.0\n                P[w] = [v]\n            elif vw_dist == seen[w]:\n                sigma[w] += sigma[v]\n                P[w].append(v)\n    return (S, P, sigma, D)",
            "def _single_source_dijkstra_path_basic(G, s, weight):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    weight = _weight_function(G, weight)\n    S = []\n    P = {}\n    for v in G:\n        P[v] = []\n    sigma = dict.fromkeys(G, 0.0)\n    D = {}\n    sigma[s] = 1.0\n    push = heappush\n    pop = heappop\n    seen = {s: 0}\n    c = count()\n    Q = []\n    push(Q, (0, next(c), s, s))\n    while Q:\n        (dist, _, pred, v) = pop(Q)\n        if v in D:\n            continue\n        sigma[v] += sigma[pred]\n        S.append(v)\n        D[v] = dist\n        for (w, edgedata) in G[v].items():\n            vw_dist = dist + weight(v, w, edgedata)\n            if w not in D and (w not in seen or vw_dist < seen[w]):\n                seen[w] = vw_dist\n                push(Q, (vw_dist, next(c), v, w))\n                sigma[w] = 0.0\n                P[w] = [v]\n            elif vw_dist == seen[w]:\n                sigma[w] += sigma[v]\n                P[w].append(v)\n    return (S, P, sigma, D)",
            "def _single_source_dijkstra_path_basic(G, s, weight):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    weight = _weight_function(G, weight)\n    S = []\n    P = {}\n    for v in G:\n        P[v] = []\n    sigma = dict.fromkeys(G, 0.0)\n    D = {}\n    sigma[s] = 1.0\n    push = heappush\n    pop = heappop\n    seen = {s: 0}\n    c = count()\n    Q = []\n    push(Q, (0, next(c), s, s))\n    while Q:\n        (dist, _, pred, v) = pop(Q)\n        if v in D:\n            continue\n        sigma[v] += sigma[pred]\n        S.append(v)\n        D[v] = dist\n        for (w, edgedata) in G[v].items():\n            vw_dist = dist + weight(v, w, edgedata)\n            if w not in D and (w not in seen or vw_dist < seen[w]):\n                seen[w] = vw_dist\n                push(Q, (vw_dist, next(c), v, w))\n                sigma[w] = 0.0\n                P[w] = [v]\n            elif vw_dist == seen[w]:\n                sigma[w] += sigma[v]\n                P[w].append(v)\n    return (S, P, sigma, D)",
            "def _single_source_dijkstra_path_basic(G, s, weight):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    weight = _weight_function(G, weight)\n    S = []\n    P = {}\n    for v in G:\n        P[v] = []\n    sigma = dict.fromkeys(G, 0.0)\n    D = {}\n    sigma[s] = 1.0\n    push = heappush\n    pop = heappop\n    seen = {s: 0}\n    c = count()\n    Q = []\n    push(Q, (0, next(c), s, s))\n    while Q:\n        (dist, _, pred, v) = pop(Q)\n        if v in D:\n            continue\n        sigma[v] += sigma[pred]\n        S.append(v)\n        D[v] = dist\n        for (w, edgedata) in G[v].items():\n            vw_dist = dist + weight(v, w, edgedata)\n            if w not in D and (w not in seen or vw_dist < seen[w]):\n                seen[w] = vw_dist\n                push(Q, (vw_dist, next(c), v, w))\n                sigma[w] = 0.0\n                P[w] = [v]\n            elif vw_dist == seen[w]:\n                sigma[w] += sigma[v]\n                P[w].append(v)\n    return (S, P, sigma, D)"
        ]
    },
    {
        "func_name": "_accumulate_basic",
        "original": "def _accumulate_basic(betweenness, S, P, sigma, s):\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            delta[v] += sigma[v] * coeff\n        if w != s:\n            betweenness[w] += delta[w]\n    return (betweenness, delta)",
        "mutated": [
            "def _accumulate_basic(betweenness, S, P, sigma, s):\n    if False:\n        i = 10\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            delta[v] += sigma[v] * coeff\n        if w != s:\n            betweenness[w] += delta[w]\n    return (betweenness, delta)",
            "def _accumulate_basic(betweenness, S, P, sigma, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            delta[v] += sigma[v] * coeff\n        if w != s:\n            betweenness[w] += delta[w]\n    return (betweenness, delta)",
            "def _accumulate_basic(betweenness, S, P, sigma, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            delta[v] += sigma[v] * coeff\n        if w != s:\n            betweenness[w] += delta[w]\n    return (betweenness, delta)",
            "def _accumulate_basic(betweenness, S, P, sigma, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            delta[v] += sigma[v] * coeff\n        if w != s:\n            betweenness[w] += delta[w]\n    return (betweenness, delta)",
            "def _accumulate_basic(betweenness, S, P, sigma, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            delta[v] += sigma[v] * coeff\n        if w != s:\n            betweenness[w] += delta[w]\n    return (betweenness, delta)"
        ]
    },
    {
        "func_name": "_accumulate_endpoints",
        "original": "def _accumulate_endpoints(betweenness, S, P, sigma, s):\n    betweenness[s] += len(S) - 1\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            delta[v] += sigma[v] * coeff\n        if w != s:\n            betweenness[w] += delta[w] + 1\n    return (betweenness, delta)",
        "mutated": [
            "def _accumulate_endpoints(betweenness, S, P, sigma, s):\n    if False:\n        i = 10\n    betweenness[s] += len(S) - 1\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            delta[v] += sigma[v] * coeff\n        if w != s:\n            betweenness[w] += delta[w] + 1\n    return (betweenness, delta)",
            "def _accumulate_endpoints(betweenness, S, P, sigma, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    betweenness[s] += len(S) - 1\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            delta[v] += sigma[v] * coeff\n        if w != s:\n            betweenness[w] += delta[w] + 1\n    return (betweenness, delta)",
            "def _accumulate_endpoints(betweenness, S, P, sigma, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    betweenness[s] += len(S) - 1\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            delta[v] += sigma[v] * coeff\n        if w != s:\n            betweenness[w] += delta[w] + 1\n    return (betweenness, delta)",
            "def _accumulate_endpoints(betweenness, S, P, sigma, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    betweenness[s] += len(S) - 1\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            delta[v] += sigma[v] * coeff\n        if w != s:\n            betweenness[w] += delta[w] + 1\n    return (betweenness, delta)",
            "def _accumulate_endpoints(betweenness, S, P, sigma, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    betweenness[s] += len(S) - 1\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            delta[v] += sigma[v] * coeff\n        if w != s:\n            betweenness[w] += delta[w] + 1\n    return (betweenness, delta)"
        ]
    },
    {
        "func_name": "_accumulate_edges",
        "original": "def _accumulate_edges(betweenness, S, P, sigma, s):\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            c = sigma[v] * coeff\n            if (v, w) not in betweenness:\n                betweenness[w, v] += c\n            else:\n                betweenness[v, w] += c\n            delta[v] += c\n        if w != s:\n            betweenness[w] += delta[w]\n    return betweenness",
        "mutated": [
            "def _accumulate_edges(betweenness, S, P, sigma, s):\n    if False:\n        i = 10\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            c = sigma[v] * coeff\n            if (v, w) not in betweenness:\n                betweenness[w, v] += c\n            else:\n                betweenness[v, w] += c\n            delta[v] += c\n        if w != s:\n            betweenness[w] += delta[w]\n    return betweenness",
            "def _accumulate_edges(betweenness, S, P, sigma, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            c = sigma[v] * coeff\n            if (v, w) not in betweenness:\n                betweenness[w, v] += c\n            else:\n                betweenness[v, w] += c\n            delta[v] += c\n        if w != s:\n            betweenness[w] += delta[w]\n    return betweenness",
            "def _accumulate_edges(betweenness, S, P, sigma, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            c = sigma[v] * coeff\n            if (v, w) not in betweenness:\n                betweenness[w, v] += c\n            else:\n                betweenness[v, w] += c\n            delta[v] += c\n        if w != s:\n            betweenness[w] += delta[w]\n    return betweenness",
            "def _accumulate_edges(betweenness, S, P, sigma, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            c = sigma[v] * coeff\n            if (v, w) not in betweenness:\n                betweenness[w, v] += c\n            else:\n                betweenness[v, w] += c\n            delta[v] += c\n        if w != s:\n            betweenness[w] += delta[w]\n    return betweenness",
            "def _accumulate_edges(betweenness, S, P, sigma, s):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    delta = dict.fromkeys(S, 0)\n    while S:\n        w = S.pop()\n        coeff = (1 + delta[w]) / sigma[w]\n        for v in P[w]:\n            c = sigma[v] * coeff\n            if (v, w) not in betweenness:\n                betweenness[w, v] += c\n            else:\n                betweenness[v, w] += c\n            delta[v] += c\n        if w != s:\n            betweenness[w] += delta[w]\n    return betweenness"
        ]
    },
    {
        "func_name": "_rescale",
        "original": "def _rescale(betweenness, n, normalized, directed=False, k=None, endpoints=False):\n    if normalized:\n        if endpoints:\n            if n < 2:\n                scale = None\n            else:\n                scale = 1 / (n * (n - 1))\n        elif n <= 2:\n            scale = None\n        else:\n            scale = 1 / ((n - 1) * (n - 2))\n    elif not directed:\n        scale = 0.5\n    else:\n        scale = None\n    if scale is not None:\n        if k is not None:\n            scale = scale * n / k\n        for v in betweenness:\n            betweenness[v] *= scale\n    return betweenness",
        "mutated": [
            "def _rescale(betweenness, n, normalized, directed=False, k=None, endpoints=False):\n    if False:\n        i = 10\n    if normalized:\n        if endpoints:\n            if n < 2:\n                scale = None\n            else:\n                scale = 1 / (n * (n - 1))\n        elif n <= 2:\n            scale = None\n        else:\n            scale = 1 / ((n - 1) * (n - 2))\n    elif not directed:\n        scale = 0.5\n    else:\n        scale = None\n    if scale is not None:\n        if k is not None:\n            scale = scale * n / k\n        for v in betweenness:\n            betweenness[v] *= scale\n    return betweenness",
            "def _rescale(betweenness, n, normalized, directed=False, k=None, endpoints=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if normalized:\n        if endpoints:\n            if n < 2:\n                scale = None\n            else:\n                scale = 1 / (n * (n - 1))\n        elif n <= 2:\n            scale = None\n        else:\n            scale = 1 / ((n - 1) * (n - 2))\n    elif not directed:\n        scale = 0.5\n    else:\n        scale = None\n    if scale is not None:\n        if k is not None:\n            scale = scale * n / k\n        for v in betweenness:\n            betweenness[v] *= scale\n    return betweenness",
            "def _rescale(betweenness, n, normalized, directed=False, k=None, endpoints=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if normalized:\n        if endpoints:\n            if n < 2:\n                scale = None\n            else:\n                scale = 1 / (n * (n - 1))\n        elif n <= 2:\n            scale = None\n        else:\n            scale = 1 / ((n - 1) * (n - 2))\n    elif not directed:\n        scale = 0.5\n    else:\n        scale = None\n    if scale is not None:\n        if k is not None:\n            scale = scale * n / k\n        for v in betweenness:\n            betweenness[v] *= scale\n    return betweenness",
            "def _rescale(betweenness, n, normalized, directed=False, k=None, endpoints=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if normalized:\n        if endpoints:\n            if n < 2:\n                scale = None\n            else:\n                scale = 1 / (n * (n - 1))\n        elif n <= 2:\n            scale = None\n        else:\n            scale = 1 / ((n - 1) * (n - 2))\n    elif not directed:\n        scale = 0.5\n    else:\n        scale = None\n    if scale is not None:\n        if k is not None:\n            scale = scale * n / k\n        for v in betweenness:\n            betweenness[v] *= scale\n    return betweenness",
            "def _rescale(betweenness, n, normalized, directed=False, k=None, endpoints=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if normalized:\n        if endpoints:\n            if n < 2:\n                scale = None\n            else:\n                scale = 1 / (n * (n - 1))\n        elif n <= 2:\n            scale = None\n        else:\n            scale = 1 / ((n - 1) * (n - 2))\n    elif not directed:\n        scale = 0.5\n    else:\n        scale = None\n    if scale is not None:\n        if k is not None:\n            scale = scale * n / k\n        for v in betweenness:\n            betweenness[v] *= scale\n    return betweenness"
        ]
    },
    {
        "func_name": "_rescale_e",
        "original": "def _rescale_e(betweenness, n, normalized, directed=False, k=None):\n    if normalized:\n        if n <= 1:\n            scale = None\n        else:\n            scale = 1 / (n * (n - 1))\n    elif not directed:\n        scale = 0.5\n    else:\n        scale = None\n    if scale is not None:\n        if k is not None:\n            scale = scale * n / k\n        for v in betweenness:\n            betweenness[v] *= scale\n    return betweenness",
        "mutated": [
            "def _rescale_e(betweenness, n, normalized, directed=False, k=None):\n    if False:\n        i = 10\n    if normalized:\n        if n <= 1:\n            scale = None\n        else:\n            scale = 1 / (n * (n - 1))\n    elif not directed:\n        scale = 0.5\n    else:\n        scale = None\n    if scale is not None:\n        if k is not None:\n            scale = scale * n / k\n        for v in betweenness:\n            betweenness[v] *= scale\n    return betweenness",
            "def _rescale_e(betweenness, n, normalized, directed=False, k=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if normalized:\n        if n <= 1:\n            scale = None\n        else:\n            scale = 1 / (n * (n - 1))\n    elif not directed:\n        scale = 0.5\n    else:\n        scale = None\n    if scale is not None:\n        if k is not None:\n            scale = scale * n / k\n        for v in betweenness:\n            betweenness[v] *= scale\n    return betweenness",
            "def _rescale_e(betweenness, n, normalized, directed=False, k=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if normalized:\n        if n <= 1:\n            scale = None\n        else:\n            scale = 1 / (n * (n - 1))\n    elif not directed:\n        scale = 0.5\n    else:\n        scale = None\n    if scale is not None:\n        if k is not None:\n            scale = scale * n / k\n        for v in betweenness:\n            betweenness[v] *= scale\n    return betweenness",
            "def _rescale_e(betweenness, n, normalized, directed=False, k=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if normalized:\n        if n <= 1:\n            scale = None\n        else:\n            scale = 1 / (n * (n - 1))\n    elif not directed:\n        scale = 0.5\n    else:\n        scale = None\n    if scale is not None:\n        if k is not None:\n            scale = scale * n / k\n        for v in betweenness:\n            betweenness[v] *= scale\n    return betweenness",
            "def _rescale_e(betweenness, n, normalized, directed=False, k=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if normalized:\n        if n <= 1:\n            scale = None\n        else:\n            scale = 1 / (n * (n - 1))\n    elif not directed:\n        scale = 0.5\n    else:\n        scale = None\n    if scale is not None:\n        if k is not None:\n            scale = scale * n / k\n        for v in betweenness:\n            betweenness[v] *= scale\n    return betweenness"
        ]
    },
    {
        "func_name": "_add_edge_keys",
        "original": "@not_implemented_for('graph')\ndef _add_edge_keys(G, betweenness, weight=None):\n    \"\"\"Adds the corrected betweenness centrality (BC) values for multigraphs.\n\n    Parameters\n    ----------\n    G : NetworkX graph.\n\n    betweenness : dictionary\n        Dictionary mapping adjacent node tuples to betweenness centrality values.\n\n    weight : string or function\n        See `_weight_function` for details. Defaults to `None`.\n\n    Returns\n    -------\n    edges : dictionary\n        The parameter `betweenness` including edges with keys and their\n        betweenness centrality values.\n\n    The BC value is divided among edges of equal weight.\n    \"\"\"\n    _weight = _weight_function(G, weight)\n    edge_bc = dict.fromkeys(G.edges, 0.0)\n    for (u, v) in betweenness:\n        d = G[u][v]\n        wt = _weight(u, v, d)\n        keys = [k for k in d if _weight(u, v, {k: d[k]}) == wt]\n        bc = betweenness[u, v] / len(keys)\n        for k in keys:\n            edge_bc[u, v, k] = bc\n    return edge_bc",
        "mutated": [
            "@not_implemented_for('graph')\ndef _add_edge_keys(G, betweenness, weight=None):\n    if False:\n        i = 10\n    'Adds the corrected betweenness centrality (BC) values for multigraphs.\\n\\n    Parameters\\n    ----------\\n    G : NetworkX graph.\\n\\n    betweenness : dictionary\\n        Dictionary mapping adjacent node tuples to betweenness centrality values.\\n\\n    weight : string or function\\n        See `_weight_function` for details. Defaults to `None`.\\n\\n    Returns\\n    -------\\n    edges : dictionary\\n        The parameter `betweenness` including edges with keys and their\\n        betweenness centrality values.\\n\\n    The BC value is divided among edges of equal weight.\\n    '\n    _weight = _weight_function(G, weight)\n    edge_bc = dict.fromkeys(G.edges, 0.0)\n    for (u, v) in betweenness:\n        d = G[u][v]\n        wt = _weight(u, v, d)\n        keys = [k for k in d if _weight(u, v, {k: d[k]}) == wt]\n        bc = betweenness[u, v] / len(keys)\n        for k in keys:\n            edge_bc[u, v, k] = bc\n    return edge_bc",
            "@not_implemented_for('graph')\ndef _add_edge_keys(G, betweenness, weight=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Adds the corrected betweenness centrality (BC) values for multigraphs.\\n\\n    Parameters\\n    ----------\\n    G : NetworkX graph.\\n\\n    betweenness : dictionary\\n        Dictionary mapping adjacent node tuples to betweenness centrality values.\\n\\n    weight : string or function\\n        See `_weight_function` for details. Defaults to `None`.\\n\\n    Returns\\n    -------\\n    edges : dictionary\\n        The parameter `betweenness` including edges with keys and their\\n        betweenness centrality values.\\n\\n    The BC value is divided among edges of equal weight.\\n    '\n    _weight = _weight_function(G, weight)\n    edge_bc = dict.fromkeys(G.edges, 0.0)\n    for (u, v) in betweenness:\n        d = G[u][v]\n        wt = _weight(u, v, d)\n        keys = [k for k in d if _weight(u, v, {k: d[k]}) == wt]\n        bc = betweenness[u, v] / len(keys)\n        for k in keys:\n            edge_bc[u, v, k] = bc\n    return edge_bc",
            "@not_implemented_for('graph')\ndef _add_edge_keys(G, betweenness, weight=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Adds the corrected betweenness centrality (BC) values for multigraphs.\\n\\n    Parameters\\n    ----------\\n    G : NetworkX graph.\\n\\n    betweenness : dictionary\\n        Dictionary mapping adjacent node tuples to betweenness centrality values.\\n\\n    weight : string or function\\n        See `_weight_function` for details. Defaults to `None`.\\n\\n    Returns\\n    -------\\n    edges : dictionary\\n        The parameter `betweenness` including edges with keys and their\\n        betweenness centrality values.\\n\\n    The BC value is divided among edges of equal weight.\\n    '\n    _weight = _weight_function(G, weight)\n    edge_bc = dict.fromkeys(G.edges, 0.0)\n    for (u, v) in betweenness:\n        d = G[u][v]\n        wt = _weight(u, v, d)\n        keys = [k for k in d if _weight(u, v, {k: d[k]}) == wt]\n        bc = betweenness[u, v] / len(keys)\n        for k in keys:\n            edge_bc[u, v, k] = bc\n    return edge_bc",
            "@not_implemented_for('graph')\ndef _add_edge_keys(G, betweenness, weight=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Adds the corrected betweenness centrality (BC) values for multigraphs.\\n\\n    Parameters\\n    ----------\\n    G : NetworkX graph.\\n\\n    betweenness : dictionary\\n        Dictionary mapping adjacent node tuples to betweenness centrality values.\\n\\n    weight : string or function\\n        See `_weight_function` for details. Defaults to `None`.\\n\\n    Returns\\n    -------\\n    edges : dictionary\\n        The parameter `betweenness` including edges with keys and their\\n        betweenness centrality values.\\n\\n    The BC value is divided among edges of equal weight.\\n    '\n    _weight = _weight_function(G, weight)\n    edge_bc = dict.fromkeys(G.edges, 0.0)\n    for (u, v) in betweenness:\n        d = G[u][v]\n        wt = _weight(u, v, d)\n        keys = [k for k in d if _weight(u, v, {k: d[k]}) == wt]\n        bc = betweenness[u, v] / len(keys)\n        for k in keys:\n            edge_bc[u, v, k] = bc\n    return edge_bc",
            "@not_implemented_for('graph')\ndef _add_edge_keys(G, betweenness, weight=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Adds the corrected betweenness centrality (BC) values for multigraphs.\\n\\n    Parameters\\n    ----------\\n    G : NetworkX graph.\\n\\n    betweenness : dictionary\\n        Dictionary mapping adjacent node tuples to betweenness centrality values.\\n\\n    weight : string or function\\n        See `_weight_function` for details. Defaults to `None`.\\n\\n    Returns\\n    -------\\n    edges : dictionary\\n        The parameter `betweenness` including edges with keys and their\\n        betweenness centrality values.\\n\\n    The BC value is divided among edges of equal weight.\\n    '\n    _weight = _weight_function(G, weight)\n    edge_bc = dict.fromkeys(G.edges, 0.0)\n    for (u, v) in betweenness:\n        d = G[u][v]\n        wt = _weight(u, v, d)\n        keys = [k for k in d if _weight(u, v, {k: d[k]}) == wt]\n        bc = betweenness[u, v] / len(keys)\n        for k in keys:\n            edge_bc[u, v, k] = bc\n    return edge_bc"
        ]
    }
]