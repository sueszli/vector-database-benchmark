[
    {
        "func_name": "setUpClass",
        "original": "@classmethod\ndef setUpClass(cls) -> None:\n    ray.init()",
        "mutated": [
            "@classmethod\ndef setUpClass(cls) -> None:\n    if False:\n        i = 10\n    ray.init()",
            "@classmethod\ndef setUpClass(cls) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    ray.init()",
            "@classmethod\ndef setUpClass(cls) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    ray.init()",
            "@classmethod\ndef setUpClass(cls) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    ray.init()",
            "@classmethod\ndef setUpClass(cls) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    ray.init()"
        ]
    },
    {
        "func_name": "tearDownClass",
        "original": "@classmethod\ndef tearDownClass(cls) -> None:\n    ray.shutdown()",
        "mutated": [
            "@classmethod\ndef tearDownClass(cls) -> None:\n    if False:\n        i = 10\n    ray.shutdown()",
            "@classmethod\ndef tearDownClass(cls) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    ray.shutdown()",
            "@classmethod\ndef tearDownClass(cls) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    ray.shutdown()",
            "@classmethod\ndef tearDownClass(cls) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    ray.shutdown()",
            "@classmethod\ndef tearDownClass(cls) -> None:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    ray.shutdown()"
        ]
    },
    {
        "func_name": "test_dqn_compilation",
        "original": "def test_dqn_compilation(self):\n    \"\"\"Test whether DQN can be built on all frameworks.\"\"\"\n    num_iterations = 1\n    config = dqn.dqn.DQNConfig().environment('CartPole-v1').rollouts(num_rollout_workers=2).training(num_steps_sampled_before_learning_starts=0)\n    for _ in framework_iterator(config):\n        print('Double-dueling')\n        algo = config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()\n        print('Rainbow')\n        rainbow_config = deepcopy(config).training(num_atoms=10, noisy=True, double_q=True, dueling=True, n_step=5)\n        algo = rainbow_config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()",
        "mutated": [
            "def test_dqn_compilation(self):\n    if False:\n        i = 10\n    'Test whether DQN can be built on all frameworks.'\n    num_iterations = 1\n    config = dqn.dqn.DQNConfig().environment('CartPole-v1').rollouts(num_rollout_workers=2).training(num_steps_sampled_before_learning_starts=0)\n    for _ in framework_iterator(config):\n        print('Double-dueling')\n        algo = config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()\n        print('Rainbow')\n        rainbow_config = deepcopy(config).training(num_atoms=10, noisy=True, double_q=True, dueling=True, n_step=5)\n        algo = rainbow_config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()",
            "def test_dqn_compilation(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Test whether DQN can be built on all frameworks.'\n    num_iterations = 1\n    config = dqn.dqn.DQNConfig().environment('CartPole-v1').rollouts(num_rollout_workers=2).training(num_steps_sampled_before_learning_starts=0)\n    for _ in framework_iterator(config):\n        print('Double-dueling')\n        algo = config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()\n        print('Rainbow')\n        rainbow_config = deepcopy(config).training(num_atoms=10, noisy=True, double_q=True, dueling=True, n_step=5)\n        algo = rainbow_config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()",
            "def test_dqn_compilation(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Test whether DQN can be built on all frameworks.'\n    num_iterations = 1\n    config = dqn.dqn.DQNConfig().environment('CartPole-v1').rollouts(num_rollout_workers=2).training(num_steps_sampled_before_learning_starts=0)\n    for _ in framework_iterator(config):\n        print('Double-dueling')\n        algo = config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()\n        print('Rainbow')\n        rainbow_config = deepcopy(config).training(num_atoms=10, noisy=True, double_q=True, dueling=True, n_step=5)\n        algo = rainbow_config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()",
            "def test_dqn_compilation(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Test whether DQN can be built on all frameworks.'\n    num_iterations = 1\n    config = dqn.dqn.DQNConfig().environment('CartPole-v1').rollouts(num_rollout_workers=2).training(num_steps_sampled_before_learning_starts=0)\n    for _ in framework_iterator(config):\n        print('Double-dueling')\n        algo = config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()\n        print('Rainbow')\n        rainbow_config = deepcopy(config).training(num_atoms=10, noisy=True, double_q=True, dueling=True, n_step=5)\n        algo = rainbow_config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()",
            "def test_dqn_compilation(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Test whether DQN can be built on all frameworks.'\n    num_iterations = 1\n    config = dqn.dqn.DQNConfig().environment('CartPole-v1').rollouts(num_rollout_workers=2).training(num_steps_sampled_before_learning_starts=0)\n    for _ in framework_iterator(config):\n        print('Double-dueling')\n        algo = config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()\n        print('Rainbow')\n        rainbow_config = deepcopy(config).training(num_atoms=10, noisy=True, double_q=True, dueling=True, n_step=5)\n        algo = rainbow_config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()"
        ]
    },
    {
        "func_name": "test_dqn_compilation_integer_rewards",
        "original": "def test_dqn_compilation_integer_rewards(self):\n    \"\"\"Test whether DQN can be built on all frameworks.\n        Unlike the previous test, this uses an environment with integer rewards\n        in order to test that type conversions are working correctly.\"\"\"\n    num_iterations = 1\n    config = dqn.dqn.DQNConfig().environment('Taxi-v3').rollouts(num_rollout_workers=2).training(num_steps_sampled_before_learning_starts=0)\n    for _ in framework_iterator(config):\n        print('Double-dueling')\n        algo = config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()\n        print('Rainbow')\n        rainbow_config = deepcopy(config).training(num_atoms=10, noisy=True, double_q=True, dueling=True, n_step=5)\n        algo = rainbow_config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()",
        "mutated": [
            "def test_dqn_compilation_integer_rewards(self):\n    if False:\n        i = 10\n    'Test whether DQN can be built on all frameworks.\\n        Unlike the previous test, this uses an environment with integer rewards\\n        in order to test that type conversions are working correctly.'\n    num_iterations = 1\n    config = dqn.dqn.DQNConfig().environment('Taxi-v3').rollouts(num_rollout_workers=2).training(num_steps_sampled_before_learning_starts=0)\n    for _ in framework_iterator(config):\n        print('Double-dueling')\n        algo = config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()\n        print('Rainbow')\n        rainbow_config = deepcopy(config).training(num_atoms=10, noisy=True, double_q=True, dueling=True, n_step=5)\n        algo = rainbow_config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()",
            "def test_dqn_compilation_integer_rewards(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Test whether DQN can be built on all frameworks.\\n        Unlike the previous test, this uses an environment with integer rewards\\n        in order to test that type conversions are working correctly.'\n    num_iterations = 1\n    config = dqn.dqn.DQNConfig().environment('Taxi-v3').rollouts(num_rollout_workers=2).training(num_steps_sampled_before_learning_starts=0)\n    for _ in framework_iterator(config):\n        print('Double-dueling')\n        algo = config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()\n        print('Rainbow')\n        rainbow_config = deepcopy(config).training(num_atoms=10, noisy=True, double_q=True, dueling=True, n_step=5)\n        algo = rainbow_config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()",
            "def test_dqn_compilation_integer_rewards(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Test whether DQN can be built on all frameworks.\\n        Unlike the previous test, this uses an environment with integer rewards\\n        in order to test that type conversions are working correctly.'\n    num_iterations = 1\n    config = dqn.dqn.DQNConfig().environment('Taxi-v3').rollouts(num_rollout_workers=2).training(num_steps_sampled_before_learning_starts=0)\n    for _ in framework_iterator(config):\n        print('Double-dueling')\n        algo = config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()\n        print('Rainbow')\n        rainbow_config = deepcopy(config).training(num_atoms=10, noisy=True, double_q=True, dueling=True, n_step=5)\n        algo = rainbow_config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()",
            "def test_dqn_compilation_integer_rewards(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Test whether DQN can be built on all frameworks.\\n        Unlike the previous test, this uses an environment with integer rewards\\n        in order to test that type conversions are working correctly.'\n    num_iterations = 1\n    config = dqn.dqn.DQNConfig().environment('Taxi-v3').rollouts(num_rollout_workers=2).training(num_steps_sampled_before_learning_starts=0)\n    for _ in framework_iterator(config):\n        print('Double-dueling')\n        algo = config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()\n        print('Rainbow')\n        rainbow_config = deepcopy(config).training(num_atoms=10, noisy=True, double_q=True, dueling=True, n_step=5)\n        algo = rainbow_config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()",
            "def test_dqn_compilation_integer_rewards(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Test whether DQN can be built on all frameworks.\\n        Unlike the previous test, this uses an environment with integer rewards\\n        in order to test that type conversions are working correctly.'\n    num_iterations = 1\n    config = dqn.dqn.DQNConfig().environment('Taxi-v3').rollouts(num_rollout_workers=2).training(num_steps_sampled_before_learning_starts=0)\n    for _ in framework_iterator(config):\n        print('Double-dueling')\n        algo = config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()\n        print('Rainbow')\n        rainbow_config = deepcopy(config).training(num_atoms=10, noisy=True, double_q=True, dueling=True, n_step=5)\n        algo = rainbow_config.build()\n        for i in range(num_iterations):\n            results = algo.train()\n            check_train_results(results)\n            print(results)\n        check_compute_single_action(algo)\n        algo.stop()"
        ]
    },
    {
        "func_name": "test_dqn_exploration_and_soft_q_config",
        "original": "def test_dqn_exploration_and_soft_q_config(self):\n    \"\"\"Tests, whether a DQN Agent outputs exploration/softmaxed actions.\"\"\"\n    config = dqn.dqn.DQNConfig().environment('FrozenLake-v1').rollouts(num_rollout_workers=0).environment(env_config={'is_slippery': False, 'map_name': '4x4'}).training(num_steps_sampled_before_learning_starts=0)\n    obs = np.array(0)\n    for _ in framework_iterator(config):\n        algo = config.build()\n        a_ = algo.compute_single_action(obs, explore=False)\n        for _ in range(50):\n            a = algo.compute_single_action(obs, explore=False)\n            check(a, a_)\n        actions = []\n        for _ in range(50):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()\n        config.exploration(exploration_config={'type': 'SoftQ', 'temperature': 1e-06})\n        algo = config.build()\n        actions = [algo.compute_single_action(obs)]\n        for _ in range(50):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, decimals=3)\n        algo.stop()\n        config.exploration_config['temperature'] = 1.0\n        algo = config.build()\n        a_ = algo.compute_single_action(obs, explore=False)\n        for _ in range(50):\n            a = algo.compute_single_action(obs, explore=False)\n            check(a, a_)\n        actions = []\n        for _ in range(300):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()\n        config.exploration(exploration_config={'type': 'Random'}, explore=True)\n        algo = config.build()\n        actions = []\n        for _ in range(300):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()",
        "mutated": [
            "def test_dqn_exploration_and_soft_q_config(self):\n    if False:\n        i = 10\n    'Tests, whether a DQN Agent outputs exploration/softmaxed actions.'\n    config = dqn.dqn.DQNConfig().environment('FrozenLake-v1').rollouts(num_rollout_workers=0).environment(env_config={'is_slippery': False, 'map_name': '4x4'}).training(num_steps_sampled_before_learning_starts=0)\n    obs = np.array(0)\n    for _ in framework_iterator(config):\n        algo = config.build()\n        a_ = algo.compute_single_action(obs, explore=False)\n        for _ in range(50):\n            a = algo.compute_single_action(obs, explore=False)\n            check(a, a_)\n        actions = []\n        for _ in range(50):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()\n        config.exploration(exploration_config={'type': 'SoftQ', 'temperature': 1e-06})\n        algo = config.build()\n        actions = [algo.compute_single_action(obs)]\n        for _ in range(50):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, decimals=3)\n        algo.stop()\n        config.exploration_config['temperature'] = 1.0\n        algo = config.build()\n        a_ = algo.compute_single_action(obs, explore=False)\n        for _ in range(50):\n            a = algo.compute_single_action(obs, explore=False)\n            check(a, a_)\n        actions = []\n        for _ in range(300):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()\n        config.exploration(exploration_config={'type': 'Random'}, explore=True)\n        algo = config.build()\n        actions = []\n        for _ in range(300):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()",
            "def test_dqn_exploration_and_soft_q_config(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Tests, whether a DQN Agent outputs exploration/softmaxed actions.'\n    config = dqn.dqn.DQNConfig().environment('FrozenLake-v1').rollouts(num_rollout_workers=0).environment(env_config={'is_slippery': False, 'map_name': '4x4'}).training(num_steps_sampled_before_learning_starts=0)\n    obs = np.array(0)\n    for _ in framework_iterator(config):\n        algo = config.build()\n        a_ = algo.compute_single_action(obs, explore=False)\n        for _ in range(50):\n            a = algo.compute_single_action(obs, explore=False)\n            check(a, a_)\n        actions = []\n        for _ in range(50):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()\n        config.exploration(exploration_config={'type': 'SoftQ', 'temperature': 1e-06})\n        algo = config.build()\n        actions = [algo.compute_single_action(obs)]\n        for _ in range(50):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, decimals=3)\n        algo.stop()\n        config.exploration_config['temperature'] = 1.0\n        algo = config.build()\n        a_ = algo.compute_single_action(obs, explore=False)\n        for _ in range(50):\n            a = algo.compute_single_action(obs, explore=False)\n            check(a, a_)\n        actions = []\n        for _ in range(300):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()\n        config.exploration(exploration_config={'type': 'Random'}, explore=True)\n        algo = config.build()\n        actions = []\n        for _ in range(300):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()",
            "def test_dqn_exploration_and_soft_q_config(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Tests, whether a DQN Agent outputs exploration/softmaxed actions.'\n    config = dqn.dqn.DQNConfig().environment('FrozenLake-v1').rollouts(num_rollout_workers=0).environment(env_config={'is_slippery': False, 'map_name': '4x4'}).training(num_steps_sampled_before_learning_starts=0)\n    obs = np.array(0)\n    for _ in framework_iterator(config):\n        algo = config.build()\n        a_ = algo.compute_single_action(obs, explore=False)\n        for _ in range(50):\n            a = algo.compute_single_action(obs, explore=False)\n            check(a, a_)\n        actions = []\n        for _ in range(50):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()\n        config.exploration(exploration_config={'type': 'SoftQ', 'temperature': 1e-06})\n        algo = config.build()\n        actions = [algo.compute_single_action(obs)]\n        for _ in range(50):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, decimals=3)\n        algo.stop()\n        config.exploration_config['temperature'] = 1.0\n        algo = config.build()\n        a_ = algo.compute_single_action(obs, explore=False)\n        for _ in range(50):\n            a = algo.compute_single_action(obs, explore=False)\n            check(a, a_)\n        actions = []\n        for _ in range(300):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()\n        config.exploration(exploration_config={'type': 'Random'}, explore=True)\n        algo = config.build()\n        actions = []\n        for _ in range(300):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()",
            "def test_dqn_exploration_and_soft_q_config(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Tests, whether a DQN Agent outputs exploration/softmaxed actions.'\n    config = dqn.dqn.DQNConfig().environment('FrozenLake-v1').rollouts(num_rollout_workers=0).environment(env_config={'is_slippery': False, 'map_name': '4x4'}).training(num_steps_sampled_before_learning_starts=0)\n    obs = np.array(0)\n    for _ in framework_iterator(config):\n        algo = config.build()\n        a_ = algo.compute_single_action(obs, explore=False)\n        for _ in range(50):\n            a = algo.compute_single_action(obs, explore=False)\n            check(a, a_)\n        actions = []\n        for _ in range(50):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()\n        config.exploration(exploration_config={'type': 'SoftQ', 'temperature': 1e-06})\n        algo = config.build()\n        actions = [algo.compute_single_action(obs)]\n        for _ in range(50):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, decimals=3)\n        algo.stop()\n        config.exploration_config['temperature'] = 1.0\n        algo = config.build()\n        a_ = algo.compute_single_action(obs, explore=False)\n        for _ in range(50):\n            a = algo.compute_single_action(obs, explore=False)\n            check(a, a_)\n        actions = []\n        for _ in range(300):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()\n        config.exploration(exploration_config={'type': 'Random'}, explore=True)\n        algo = config.build()\n        actions = []\n        for _ in range(300):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()",
            "def test_dqn_exploration_and_soft_q_config(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Tests, whether a DQN Agent outputs exploration/softmaxed actions.'\n    config = dqn.dqn.DQNConfig().environment('FrozenLake-v1').rollouts(num_rollout_workers=0).environment(env_config={'is_slippery': False, 'map_name': '4x4'}).training(num_steps_sampled_before_learning_starts=0)\n    obs = np.array(0)\n    for _ in framework_iterator(config):\n        algo = config.build()\n        a_ = algo.compute_single_action(obs, explore=False)\n        for _ in range(50):\n            a = algo.compute_single_action(obs, explore=False)\n            check(a, a_)\n        actions = []\n        for _ in range(50):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()\n        config.exploration(exploration_config={'type': 'SoftQ', 'temperature': 1e-06})\n        algo = config.build()\n        actions = [algo.compute_single_action(obs)]\n        for _ in range(50):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, decimals=3)\n        algo.stop()\n        config.exploration_config['temperature'] = 1.0\n        algo = config.build()\n        a_ = algo.compute_single_action(obs, explore=False)\n        for _ in range(50):\n            a = algo.compute_single_action(obs, explore=False)\n            check(a, a_)\n        actions = []\n        for _ in range(300):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()\n        config.exploration(exploration_config={'type': 'Random'}, explore=True)\n        algo = config.build()\n        actions = []\n        for _ in range(300):\n            actions.append(algo.compute_single_action(obs))\n        check(np.std(actions), 0.0, false=True)\n        algo.stop()"
        ]
    }
]