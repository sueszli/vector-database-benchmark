[
    {
        "func_name": "test_multi_scale_flip_aug_3D",
        "original": "def test_multi_scale_flip_aug_3D():\n    np.random.seed(0)\n    transforms = [{'type': 'GlobalRotScaleTrans', 'rot_range': [-0.1, 0.1], 'scale_ratio_range': [0.9, 1.1], 'translation_std': [0, 0, 0]}, {'type': 'RandomFlip3D', 'sync_2d': False, 'flip_ratio_bev_horizontal': 0.5}, {'type': 'PointSample', 'num_points': 5}, {'type': 'DefaultFormatBundle3D', 'class_names': ('bed', 'table', 'sofa', 'chair', 'toilet', 'desk', 'dresser', 'night_stand', 'bookshelf', 'bathtub'), 'with_label': False}, {'type': 'Collect3D', 'keys': ['points']}]\n    img_scale = (1333, 800)\n    pts_scale_ratio = 1\n    multi_scale_flip_aug_3D = MultiScaleFlipAug3D(transforms, img_scale, pts_scale_ratio)\n    pts_file_name = 'tests/data/sunrgbd/points/000001.bin'\n    sample_idx = 4\n    file_name = 'tests/data/sunrgbd/points/000001.bin'\n    bbox3d_fields = []\n    points = np.array([[0.20397437, 1.4267826, -1.0503972, 0.16195858], [-2.2095256, 3.3159535, -0.7706928, 0.4416629], [1.5090443, 3.2764456, -1.1913797, 0.02097607], [-1.373904, 3.8711405, 0.8524302, 2.064786], [-1.8139812, 3.538856, -1.0056694, 0.20668638]])\n    points = DepthPoints(points, points_dim=4, attribute_dims=dict(height=3))\n    results = dict(points=points, pts_file_name=pts_file_name, sample_idx=sample_idx, file_name=file_name, bbox3d_fields=bbox3d_fields)\n    results = multi_scale_flip_aug_3D(results)\n    expected_points = torch.tensor([[-2.2418, 3.2942, -0.7707, 0.4417], [-1.4116, 3.8575, 0.8524, 2.0648], [-1.8484, 3.521, -1.0057, 0.2067], [0.19, 1.4287, -1.0504, 0.162], [1.477, 3.291, -1.1914, 0.021]], dtype=torch.float32)\n    assert torch.allclose(results['points'][0]._data, expected_points, atol=0.0001)",
        "mutated": [
            "def test_multi_scale_flip_aug_3D():\n    if False:\n        i = 10\n    np.random.seed(0)\n    transforms = [{'type': 'GlobalRotScaleTrans', 'rot_range': [-0.1, 0.1], 'scale_ratio_range': [0.9, 1.1], 'translation_std': [0, 0, 0]}, {'type': 'RandomFlip3D', 'sync_2d': False, 'flip_ratio_bev_horizontal': 0.5}, {'type': 'PointSample', 'num_points': 5}, {'type': 'DefaultFormatBundle3D', 'class_names': ('bed', 'table', 'sofa', 'chair', 'toilet', 'desk', 'dresser', 'night_stand', 'bookshelf', 'bathtub'), 'with_label': False}, {'type': 'Collect3D', 'keys': ['points']}]\n    img_scale = (1333, 800)\n    pts_scale_ratio = 1\n    multi_scale_flip_aug_3D = MultiScaleFlipAug3D(transforms, img_scale, pts_scale_ratio)\n    pts_file_name = 'tests/data/sunrgbd/points/000001.bin'\n    sample_idx = 4\n    file_name = 'tests/data/sunrgbd/points/000001.bin'\n    bbox3d_fields = []\n    points = np.array([[0.20397437, 1.4267826, -1.0503972, 0.16195858], [-2.2095256, 3.3159535, -0.7706928, 0.4416629], [1.5090443, 3.2764456, -1.1913797, 0.02097607], [-1.373904, 3.8711405, 0.8524302, 2.064786], [-1.8139812, 3.538856, -1.0056694, 0.20668638]])\n    points = DepthPoints(points, points_dim=4, attribute_dims=dict(height=3))\n    results = dict(points=points, pts_file_name=pts_file_name, sample_idx=sample_idx, file_name=file_name, bbox3d_fields=bbox3d_fields)\n    results = multi_scale_flip_aug_3D(results)\n    expected_points = torch.tensor([[-2.2418, 3.2942, -0.7707, 0.4417], [-1.4116, 3.8575, 0.8524, 2.0648], [-1.8484, 3.521, -1.0057, 0.2067], [0.19, 1.4287, -1.0504, 0.162], [1.477, 3.291, -1.1914, 0.021]], dtype=torch.float32)\n    assert torch.allclose(results['points'][0]._data, expected_points, atol=0.0001)",
            "def test_multi_scale_flip_aug_3D():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    np.random.seed(0)\n    transforms = [{'type': 'GlobalRotScaleTrans', 'rot_range': [-0.1, 0.1], 'scale_ratio_range': [0.9, 1.1], 'translation_std': [0, 0, 0]}, {'type': 'RandomFlip3D', 'sync_2d': False, 'flip_ratio_bev_horizontal': 0.5}, {'type': 'PointSample', 'num_points': 5}, {'type': 'DefaultFormatBundle3D', 'class_names': ('bed', 'table', 'sofa', 'chair', 'toilet', 'desk', 'dresser', 'night_stand', 'bookshelf', 'bathtub'), 'with_label': False}, {'type': 'Collect3D', 'keys': ['points']}]\n    img_scale = (1333, 800)\n    pts_scale_ratio = 1\n    multi_scale_flip_aug_3D = MultiScaleFlipAug3D(transforms, img_scale, pts_scale_ratio)\n    pts_file_name = 'tests/data/sunrgbd/points/000001.bin'\n    sample_idx = 4\n    file_name = 'tests/data/sunrgbd/points/000001.bin'\n    bbox3d_fields = []\n    points = np.array([[0.20397437, 1.4267826, -1.0503972, 0.16195858], [-2.2095256, 3.3159535, -0.7706928, 0.4416629], [1.5090443, 3.2764456, -1.1913797, 0.02097607], [-1.373904, 3.8711405, 0.8524302, 2.064786], [-1.8139812, 3.538856, -1.0056694, 0.20668638]])\n    points = DepthPoints(points, points_dim=4, attribute_dims=dict(height=3))\n    results = dict(points=points, pts_file_name=pts_file_name, sample_idx=sample_idx, file_name=file_name, bbox3d_fields=bbox3d_fields)\n    results = multi_scale_flip_aug_3D(results)\n    expected_points = torch.tensor([[-2.2418, 3.2942, -0.7707, 0.4417], [-1.4116, 3.8575, 0.8524, 2.0648], [-1.8484, 3.521, -1.0057, 0.2067], [0.19, 1.4287, -1.0504, 0.162], [1.477, 3.291, -1.1914, 0.021]], dtype=torch.float32)\n    assert torch.allclose(results['points'][0]._data, expected_points, atol=0.0001)",
            "def test_multi_scale_flip_aug_3D():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    np.random.seed(0)\n    transforms = [{'type': 'GlobalRotScaleTrans', 'rot_range': [-0.1, 0.1], 'scale_ratio_range': [0.9, 1.1], 'translation_std': [0, 0, 0]}, {'type': 'RandomFlip3D', 'sync_2d': False, 'flip_ratio_bev_horizontal': 0.5}, {'type': 'PointSample', 'num_points': 5}, {'type': 'DefaultFormatBundle3D', 'class_names': ('bed', 'table', 'sofa', 'chair', 'toilet', 'desk', 'dresser', 'night_stand', 'bookshelf', 'bathtub'), 'with_label': False}, {'type': 'Collect3D', 'keys': ['points']}]\n    img_scale = (1333, 800)\n    pts_scale_ratio = 1\n    multi_scale_flip_aug_3D = MultiScaleFlipAug3D(transforms, img_scale, pts_scale_ratio)\n    pts_file_name = 'tests/data/sunrgbd/points/000001.bin'\n    sample_idx = 4\n    file_name = 'tests/data/sunrgbd/points/000001.bin'\n    bbox3d_fields = []\n    points = np.array([[0.20397437, 1.4267826, -1.0503972, 0.16195858], [-2.2095256, 3.3159535, -0.7706928, 0.4416629], [1.5090443, 3.2764456, -1.1913797, 0.02097607], [-1.373904, 3.8711405, 0.8524302, 2.064786], [-1.8139812, 3.538856, -1.0056694, 0.20668638]])\n    points = DepthPoints(points, points_dim=4, attribute_dims=dict(height=3))\n    results = dict(points=points, pts_file_name=pts_file_name, sample_idx=sample_idx, file_name=file_name, bbox3d_fields=bbox3d_fields)\n    results = multi_scale_flip_aug_3D(results)\n    expected_points = torch.tensor([[-2.2418, 3.2942, -0.7707, 0.4417], [-1.4116, 3.8575, 0.8524, 2.0648], [-1.8484, 3.521, -1.0057, 0.2067], [0.19, 1.4287, -1.0504, 0.162], [1.477, 3.291, -1.1914, 0.021]], dtype=torch.float32)\n    assert torch.allclose(results['points'][0]._data, expected_points, atol=0.0001)",
            "def test_multi_scale_flip_aug_3D():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    np.random.seed(0)\n    transforms = [{'type': 'GlobalRotScaleTrans', 'rot_range': [-0.1, 0.1], 'scale_ratio_range': [0.9, 1.1], 'translation_std': [0, 0, 0]}, {'type': 'RandomFlip3D', 'sync_2d': False, 'flip_ratio_bev_horizontal': 0.5}, {'type': 'PointSample', 'num_points': 5}, {'type': 'DefaultFormatBundle3D', 'class_names': ('bed', 'table', 'sofa', 'chair', 'toilet', 'desk', 'dresser', 'night_stand', 'bookshelf', 'bathtub'), 'with_label': False}, {'type': 'Collect3D', 'keys': ['points']}]\n    img_scale = (1333, 800)\n    pts_scale_ratio = 1\n    multi_scale_flip_aug_3D = MultiScaleFlipAug3D(transforms, img_scale, pts_scale_ratio)\n    pts_file_name = 'tests/data/sunrgbd/points/000001.bin'\n    sample_idx = 4\n    file_name = 'tests/data/sunrgbd/points/000001.bin'\n    bbox3d_fields = []\n    points = np.array([[0.20397437, 1.4267826, -1.0503972, 0.16195858], [-2.2095256, 3.3159535, -0.7706928, 0.4416629], [1.5090443, 3.2764456, -1.1913797, 0.02097607], [-1.373904, 3.8711405, 0.8524302, 2.064786], [-1.8139812, 3.538856, -1.0056694, 0.20668638]])\n    points = DepthPoints(points, points_dim=4, attribute_dims=dict(height=3))\n    results = dict(points=points, pts_file_name=pts_file_name, sample_idx=sample_idx, file_name=file_name, bbox3d_fields=bbox3d_fields)\n    results = multi_scale_flip_aug_3D(results)\n    expected_points = torch.tensor([[-2.2418, 3.2942, -0.7707, 0.4417], [-1.4116, 3.8575, 0.8524, 2.0648], [-1.8484, 3.521, -1.0057, 0.2067], [0.19, 1.4287, -1.0504, 0.162], [1.477, 3.291, -1.1914, 0.021]], dtype=torch.float32)\n    assert torch.allclose(results['points'][0]._data, expected_points, atol=0.0001)",
            "def test_multi_scale_flip_aug_3D():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    np.random.seed(0)\n    transforms = [{'type': 'GlobalRotScaleTrans', 'rot_range': [-0.1, 0.1], 'scale_ratio_range': [0.9, 1.1], 'translation_std': [0, 0, 0]}, {'type': 'RandomFlip3D', 'sync_2d': False, 'flip_ratio_bev_horizontal': 0.5}, {'type': 'PointSample', 'num_points': 5}, {'type': 'DefaultFormatBundle3D', 'class_names': ('bed', 'table', 'sofa', 'chair', 'toilet', 'desk', 'dresser', 'night_stand', 'bookshelf', 'bathtub'), 'with_label': False}, {'type': 'Collect3D', 'keys': ['points']}]\n    img_scale = (1333, 800)\n    pts_scale_ratio = 1\n    multi_scale_flip_aug_3D = MultiScaleFlipAug3D(transforms, img_scale, pts_scale_ratio)\n    pts_file_name = 'tests/data/sunrgbd/points/000001.bin'\n    sample_idx = 4\n    file_name = 'tests/data/sunrgbd/points/000001.bin'\n    bbox3d_fields = []\n    points = np.array([[0.20397437, 1.4267826, -1.0503972, 0.16195858], [-2.2095256, 3.3159535, -0.7706928, 0.4416629], [1.5090443, 3.2764456, -1.1913797, 0.02097607], [-1.373904, 3.8711405, 0.8524302, 2.064786], [-1.8139812, 3.538856, -1.0056694, 0.20668638]])\n    points = DepthPoints(points, points_dim=4, attribute_dims=dict(height=3))\n    results = dict(points=points, pts_file_name=pts_file_name, sample_idx=sample_idx, file_name=file_name, bbox3d_fields=bbox3d_fields)\n    results = multi_scale_flip_aug_3D(results)\n    expected_points = torch.tensor([[-2.2418, 3.2942, -0.7707, 0.4417], [-1.4116, 3.8575, 0.8524, 2.0648], [-1.8484, 3.521, -1.0057, 0.2067], [0.19, 1.4287, -1.0504, 0.162], [1.477, 3.291, -1.1914, 0.021]], dtype=torch.float32)\n    assert torch.allclose(results['points'][0]._data, expected_points, atol=0.0001)"
        ]
    }
]