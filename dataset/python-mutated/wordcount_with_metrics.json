[
    {
        "func_name": "__init__",
        "original": "def __init__(self):\n    beam.DoFn.__init__(self)\n    self.words_counter = Metrics.counter(self.__class__, 'words')\n    self.word_lengths_counter = Metrics.counter(self.__class__, 'word_lengths')\n    self.word_lengths_dist = Metrics.distribution(self.__class__, 'word_len_dist')\n    self.empty_line_counter = Metrics.counter(self.__class__, 'empty_lines')",
        "mutated": [
            "def __init__(self):\n    if False:\n        i = 10\n    beam.DoFn.__init__(self)\n    self.words_counter = Metrics.counter(self.__class__, 'words')\n    self.word_lengths_counter = Metrics.counter(self.__class__, 'word_lengths')\n    self.word_lengths_dist = Metrics.distribution(self.__class__, 'word_len_dist')\n    self.empty_line_counter = Metrics.counter(self.__class__, 'empty_lines')",
            "def __init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    beam.DoFn.__init__(self)\n    self.words_counter = Metrics.counter(self.__class__, 'words')\n    self.word_lengths_counter = Metrics.counter(self.__class__, 'word_lengths')\n    self.word_lengths_dist = Metrics.distribution(self.__class__, 'word_len_dist')\n    self.empty_line_counter = Metrics.counter(self.__class__, 'empty_lines')",
            "def __init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    beam.DoFn.__init__(self)\n    self.words_counter = Metrics.counter(self.__class__, 'words')\n    self.word_lengths_counter = Metrics.counter(self.__class__, 'word_lengths')\n    self.word_lengths_dist = Metrics.distribution(self.__class__, 'word_len_dist')\n    self.empty_line_counter = Metrics.counter(self.__class__, 'empty_lines')",
            "def __init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    beam.DoFn.__init__(self)\n    self.words_counter = Metrics.counter(self.__class__, 'words')\n    self.word_lengths_counter = Metrics.counter(self.__class__, 'word_lengths')\n    self.word_lengths_dist = Metrics.distribution(self.__class__, 'word_len_dist')\n    self.empty_line_counter = Metrics.counter(self.__class__, 'empty_lines')",
            "def __init__(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    beam.DoFn.__init__(self)\n    self.words_counter = Metrics.counter(self.__class__, 'words')\n    self.word_lengths_counter = Metrics.counter(self.__class__, 'word_lengths')\n    self.word_lengths_dist = Metrics.distribution(self.__class__, 'word_len_dist')\n    self.empty_line_counter = Metrics.counter(self.__class__, 'empty_lines')"
        ]
    },
    {
        "func_name": "process",
        "original": "def process(self, element):\n    \"\"\"Returns an iterator over the words of this element.\n\n    The element is a line of text.  If the line is blank, note that, too.\n\n    Args:\n      element: the element being processed\n\n    Returns:\n      The processed element.\n    \"\"\"\n    text_line = element.strip()\n    if not text_line:\n        self.empty_line_counter.inc(1)\n    words = re.findall(\"[\\\\w\\\\']+\", text_line, re.UNICODE)\n    for w in words:\n        self.words_counter.inc()\n        self.word_lengths_counter.inc(len(w))\n        self.word_lengths_dist.update(len(w))\n    return words",
        "mutated": [
            "def process(self, element):\n    if False:\n        i = 10\n    'Returns an iterator over the words of this element.\\n\\n    The element is a line of text.  If the line is blank, note that, too.\\n\\n    Args:\\n      element: the element being processed\\n\\n    Returns:\\n      The processed element.\\n    '\n    text_line = element.strip()\n    if not text_line:\n        self.empty_line_counter.inc(1)\n    words = re.findall(\"[\\\\w\\\\']+\", text_line, re.UNICODE)\n    for w in words:\n        self.words_counter.inc()\n        self.word_lengths_counter.inc(len(w))\n        self.word_lengths_dist.update(len(w))\n    return words",
            "def process(self, element):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Returns an iterator over the words of this element.\\n\\n    The element is a line of text.  If the line is blank, note that, too.\\n\\n    Args:\\n      element: the element being processed\\n\\n    Returns:\\n      The processed element.\\n    '\n    text_line = element.strip()\n    if not text_line:\n        self.empty_line_counter.inc(1)\n    words = re.findall(\"[\\\\w\\\\']+\", text_line, re.UNICODE)\n    for w in words:\n        self.words_counter.inc()\n        self.word_lengths_counter.inc(len(w))\n        self.word_lengths_dist.update(len(w))\n    return words",
            "def process(self, element):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Returns an iterator over the words of this element.\\n\\n    The element is a line of text.  If the line is blank, note that, too.\\n\\n    Args:\\n      element: the element being processed\\n\\n    Returns:\\n      The processed element.\\n    '\n    text_line = element.strip()\n    if not text_line:\n        self.empty_line_counter.inc(1)\n    words = re.findall(\"[\\\\w\\\\']+\", text_line, re.UNICODE)\n    for w in words:\n        self.words_counter.inc()\n        self.word_lengths_counter.inc(len(w))\n        self.word_lengths_dist.update(len(w))\n    return words",
            "def process(self, element):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Returns an iterator over the words of this element.\\n\\n    The element is a line of text.  If the line is blank, note that, too.\\n\\n    Args:\\n      element: the element being processed\\n\\n    Returns:\\n      The processed element.\\n    '\n    text_line = element.strip()\n    if not text_line:\n        self.empty_line_counter.inc(1)\n    words = re.findall(\"[\\\\w\\\\']+\", text_line, re.UNICODE)\n    for w in words:\n        self.words_counter.inc()\n        self.word_lengths_counter.inc(len(w))\n        self.word_lengths_dist.update(len(w))\n    return words",
            "def process(self, element):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Returns an iterator over the words of this element.\\n\\n    The element is a line of text.  If the line is blank, note that, too.\\n\\n    Args:\\n      element: the element being processed\\n\\n    Returns:\\n      The processed element.\\n    '\n    text_line = element.strip()\n    if not text_line:\n        self.empty_line_counter.inc(1)\n    words = re.findall(\"[\\\\w\\\\']+\", text_line, re.UNICODE)\n    for w in words:\n        self.words_counter.inc()\n        self.word_lengths_counter.inc(len(w))\n        self.word_lengths_dist.update(len(w))\n    return words"
        ]
    },
    {
        "func_name": "count_ones",
        "original": "def count_ones(word_ones):\n    (word, ones) = word_ones\n    return (word, sum(ones))",
        "mutated": [
            "def count_ones(word_ones):\n    if False:\n        i = 10\n    (word, ones) = word_ones\n    return (word, sum(ones))",
            "def count_ones(word_ones):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (word, ones) = word_ones\n    return (word, sum(ones))",
            "def count_ones(word_ones):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (word, ones) = word_ones\n    return (word, sum(ones))",
            "def count_ones(word_ones):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (word, ones) = word_ones\n    return (word, sum(ones))",
            "def count_ones(word_ones):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (word, ones) = word_ones\n    return (word, sum(ones))"
        ]
    },
    {
        "func_name": "format_result",
        "original": "def format_result(word_count):\n    (word, count) = word_count\n    return '%s: %d' % (word, count)",
        "mutated": [
            "def format_result(word_count):\n    if False:\n        i = 10\n    (word, count) = word_count\n    return '%s: %d' % (word, count)",
            "def format_result(word_count):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (word, count) = word_count\n    return '%s: %d' % (word, count)",
            "def format_result(word_count):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (word, count) = word_count\n    return '%s: %d' % (word, count)",
            "def format_result(word_count):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (word, count) = word_count\n    return '%s: %d' % (word, count)",
            "def format_result(word_count):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (word, count) = word_count\n    return '%s: %d' % (word, count)"
        ]
    },
    {
        "func_name": "main",
        "original": "def main(argv=None, save_main_session=True):\n    \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--input', dest='input', default='gs://dataflow-samples/shakespeare/kinglear.txt', help='Input file to process.')\n    parser.add_argument('--output', dest='output', required=True, help='Output file to write results to.')\n    (known_args, pipeline_args) = parser.parse_known_args(argv)\n    pipeline_options = PipelineOptions(pipeline_args)\n    pipeline_options.view_as(SetupOptions).save_main_session = save_main_session\n    p = beam.Pipeline(options=pipeline_options)\n    lines = p | 'read' >> ReadFromText(known_args.input)\n\n    def count_ones(word_ones):\n        (word, ones) = word_ones\n        return (word, sum(ones))\n    counts = lines | 'split' >> beam.ParDo(WordExtractingDoFn()).with_output_types(str) | 'pair_with_one' >> beam.Map(lambda x: (x, 1)) | 'group' >> beam.GroupByKey() | 'count' >> beam.Map(count_ones)\n\n    def format_result(word_count):\n        (word, count) = word_count\n        return '%s: %d' % (word, count)\n    output = counts | 'format' >> beam.Map(format_result)\n    output | 'write' >> WriteToText(known_args.output)\n    result = p.run()\n    result.wait_until_finish()\n    if not hasattr(result, 'has_job') or result.has_job:\n        empty_lines_filter = MetricsFilter().with_name('empty_lines')\n        query_result = result.metrics().query(empty_lines_filter)\n        if query_result['counters']:\n            empty_lines_counter = query_result['counters'][0]\n            logging.info('number of empty lines: %d', empty_lines_counter.result)\n        word_lengths_filter = MetricsFilter().with_name('word_len_dist')\n        query_result = result.metrics().query(word_lengths_filter)\n        if query_result['distributions']:\n            word_lengths_dist = query_result['distributions'][0]\n            logging.info('average word length: %d', word_lengths_dist.result.mean)",
        "mutated": [
            "def main(argv=None, save_main_session=True):\n    if False:\n        i = 10\n    'Main entry point; defines and runs the wordcount pipeline.'\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--input', dest='input', default='gs://dataflow-samples/shakespeare/kinglear.txt', help='Input file to process.')\n    parser.add_argument('--output', dest='output', required=True, help='Output file to write results to.')\n    (known_args, pipeline_args) = parser.parse_known_args(argv)\n    pipeline_options = PipelineOptions(pipeline_args)\n    pipeline_options.view_as(SetupOptions).save_main_session = save_main_session\n    p = beam.Pipeline(options=pipeline_options)\n    lines = p | 'read' >> ReadFromText(known_args.input)\n\n    def count_ones(word_ones):\n        (word, ones) = word_ones\n        return (word, sum(ones))\n    counts = lines | 'split' >> beam.ParDo(WordExtractingDoFn()).with_output_types(str) | 'pair_with_one' >> beam.Map(lambda x: (x, 1)) | 'group' >> beam.GroupByKey() | 'count' >> beam.Map(count_ones)\n\n    def format_result(word_count):\n        (word, count) = word_count\n        return '%s: %d' % (word, count)\n    output = counts | 'format' >> beam.Map(format_result)\n    output | 'write' >> WriteToText(known_args.output)\n    result = p.run()\n    result.wait_until_finish()\n    if not hasattr(result, 'has_job') or result.has_job:\n        empty_lines_filter = MetricsFilter().with_name('empty_lines')\n        query_result = result.metrics().query(empty_lines_filter)\n        if query_result['counters']:\n            empty_lines_counter = query_result['counters'][0]\n            logging.info('number of empty lines: %d', empty_lines_counter.result)\n        word_lengths_filter = MetricsFilter().with_name('word_len_dist')\n        query_result = result.metrics().query(word_lengths_filter)\n        if query_result['distributions']:\n            word_lengths_dist = query_result['distributions'][0]\n            logging.info('average word length: %d', word_lengths_dist.result.mean)",
            "def main(argv=None, save_main_session=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Main entry point; defines and runs the wordcount pipeline.'\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--input', dest='input', default='gs://dataflow-samples/shakespeare/kinglear.txt', help='Input file to process.')\n    parser.add_argument('--output', dest='output', required=True, help='Output file to write results to.')\n    (known_args, pipeline_args) = parser.parse_known_args(argv)\n    pipeline_options = PipelineOptions(pipeline_args)\n    pipeline_options.view_as(SetupOptions).save_main_session = save_main_session\n    p = beam.Pipeline(options=pipeline_options)\n    lines = p | 'read' >> ReadFromText(known_args.input)\n\n    def count_ones(word_ones):\n        (word, ones) = word_ones\n        return (word, sum(ones))\n    counts = lines | 'split' >> beam.ParDo(WordExtractingDoFn()).with_output_types(str) | 'pair_with_one' >> beam.Map(lambda x: (x, 1)) | 'group' >> beam.GroupByKey() | 'count' >> beam.Map(count_ones)\n\n    def format_result(word_count):\n        (word, count) = word_count\n        return '%s: %d' % (word, count)\n    output = counts | 'format' >> beam.Map(format_result)\n    output | 'write' >> WriteToText(known_args.output)\n    result = p.run()\n    result.wait_until_finish()\n    if not hasattr(result, 'has_job') or result.has_job:\n        empty_lines_filter = MetricsFilter().with_name('empty_lines')\n        query_result = result.metrics().query(empty_lines_filter)\n        if query_result['counters']:\n            empty_lines_counter = query_result['counters'][0]\n            logging.info('number of empty lines: %d', empty_lines_counter.result)\n        word_lengths_filter = MetricsFilter().with_name('word_len_dist')\n        query_result = result.metrics().query(word_lengths_filter)\n        if query_result['distributions']:\n            word_lengths_dist = query_result['distributions'][0]\n            logging.info('average word length: %d', word_lengths_dist.result.mean)",
            "def main(argv=None, save_main_session=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Main entry point; defines and runs the wordcount pipeline.'\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--input', dest='input', default='gs://dataflow-samples/shakespeare/kinglear.txt', help='Input file to process.')\n    parser.add_argument('--output', dest='output', required=True, help='Output file to write results to.')\n    (known_args, pipeline_args) = parser.parse_known_args(argv)\n    pipeline_options = PipelineOptions(pipeline_args)\n    pipeline_options.view_as(SetupOptions).save_main_session = save_main_session\n    p = beam.Pipeline(options=pipeline_options)\n    lines = p | 'read' >> ReadFromText(known_args.input)\n\n    def count_ones(word_ones):\n        (word, ones) = word_ones\n        return (word, sum(ones))\n    counts = lines | 'split' >> beam.ParDo(WordExtractingDoFn()).with_output_types(str) | 'pair_with_one' >> beam.Map(lambda x: (x, 1)) | 'group' >> beam.GroupByKey() | 'count' >> beam.Map(count_ones)\n\n    def format_result(word_count):\n        (word, count) = word_count\n        return '%s: %d' % (word, count)\n    output = counts | 'format' >> beam.Map(format_result)\n    output | 'write' >> WriteToText(known_args.output)\n    result = p.run()\n    result.wait_until_finish()\n    if not hasattr(result, 'has_job') or result.has_job:\n        empty_lines_filter = MetricsFilter().with_name('empty_lines')\n        query_result = result.metrics().query(empty_lines_filter)\n        if query_result['counters']:\n            empty_lines_counter = query_result['counters'][0]\n            logging.info('number of empty lines: %d', empty_lines_counter.result)\n        word_lengths_filter = MetricsFilter().with_name('word_len_dist')\n        query_result = result.metrics().query(word_lengths_filter)\n        if query_result['distributions']:\n            word_lengths_dist = query_result['distributions'][0]\n            logging.info('average word length: %d', word_lengths_dist.result.mean)",
            "def main(argv=None, save_main_session=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Main entry point; defines and runs the wordcount pipeline.'\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--input', dest='input', default='gs://dataflow-samples/shakespeare/kinglear.txt', help='Input file to process.')\n    parser.add_argument('--output', dest='output', required=True, help='Output file to write results to.')\n    (known_args, pipeline_args) = parser.parse_known_args(argv)\n    pipeline_options = PipelineOptions(pipeline_args)\n    pipeline_options.view_as(SetupOptions).save_main_session = save_main_session\n    p = beam.Pipeline(options=pipeline_options)\n    lines = p | 'read' >> ReadFromText(known_args.input)\n\n    def count_ones(word_ones):\n        (word, ones) = word_ones\n        return (word, sum(ones))\n    counts = lines | 'split' >> beam.ParDo(WordExtractingDoFn()).with_output_types(str) | 'pair_with_one' >> beam.Map(lambda x: (x, 1)) | 'group' >> beam.GroupByKey() | 'count' >> beam.Map(count_ones)\n\n    def format_result(word_count):\n        (word, count) = word_count\n        return '%s: %d' % (word, count)\n    output = counts | 'format' >> beam.Map(format_result)\n    output | 'write' >> WriteToText(known_args.output)\n    result = p.run()\n    result.wait_until_finish()\n    if not hasattr(result, 'has_job') or result.has_job:\n        empty_lines_filter = MetricsFilter().with_name('empty_lines')\n        query_result = result.metrics().query(empty_lines_filter)\n        if query_result['counters']:\n            empty_lines_counter = query_result['counters'][0]\n            logging.info('number of empty lines: %d', empty_lines_counter.result)\n        word_lengths_filter = MetricsFilter().with_name('word_len_dist')\n        query_result = result.metrics().query(word_lengths_filter)\n        if query_result['distributions']:\n            word_lengths_dist = query_result['distributions'][0]\n            logging.info('average word length: %d', word_lengths_dist.result.mean)",
            "def main(argv=None, save_main_session=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Main entry point; defines and runs the wordcount pipeline.'\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--input', dest='input', default='gs://dataflow-samples/shakespeare/kinglear.txt', help='Input file to process.')\n    parser.add_argument('--output', dest='output', required=True, help='Output file to write results to.')\n    (known_args, pipeline_args) = parser.parse_known_args(argv)\n    pipeline_options = PipelineOptions(pipeline_args)\n    pipeline_options.view_as(SetupOptions).save_main_session = save_main_session\n    p = beam.Pipeline(options=pipeline_options)\n    lines = p | 'read' >> ReadFromText(known_args.input)\n\n    def count_ones(word_ones):\n        (word, ones) = word_ones\n        return (word, sum(ones))\n    counts = lines | 'split' >> beam.ParDo(WordExtractingDoFn()).with_output_types(str) | 'pair_with_one' >> beam.Map(lambda x: (x, 1)) | 'group' >> beam.GroupByKey() | 'count' >> beam.Map(count_ones)\n\n    def format_result(word_count):\n        (word, count) = word_count\n        return '%s: %d' % (word, count)\n    output = counts | 'format' >> beam.Map(format_result)\n    output | 'write' >> WriteToText(known_args.output)\n    result = p.run()\n    result.wait_until_finish()\n    if not hasattr(result, 'has_job') or result.has_job:\n        empty_lines_filter = MetricsFilter().with_name('empty_lines')\n        query_result = result.metrics().query(empty_lines_filter)\n        if query_result['counters']:\n            empty_lines_counter = query_result['counters'][0]\n            logging.info('number of empty lines: %d', empty_lines_counter.result)\n        word_lengths_filter = MetricsFilter().with_name('word_len_dist')\n        query_result = result.metrics().query(word_lengths_filter)\n        if query_result['distributions']:\n            word_lengths_dist = query_result['distributions'][0]\n            logging.info('average word length: %d', word_lengths_dist.result.mean)"
        ]
    }
]