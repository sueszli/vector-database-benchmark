[
    {
        "func_name": "compress",
        "original": "def compress(self, *, jpeg_quality: int=95) -> ImageEncoded | Image:\n    \"\"\"\n        Converts an `Image` to an [`rerun.ImageEncoded`][] using JPEG compression.\n\n        JPEG compression works best for photographs. Only RGB or Mono images are\n        supported, not RGBA. Note that compressing to JPEG costs a bit of CPU time,\n        both when logging and later when viewing them.\n\n        Parameters\n        ----------\n        jpeg_quality:\n            Higher quality = larger file size. A quality of 95 still saves a lot\n            of space, but is visually very similar.\n        \"\"\"\n    from PIL import Image as PILImage\n    from .._image import ImageEncoded\n    from . import Image\n    self = cast(Image, self)\n    with catch_and_log_exceptions(context='Image compression'):\n        tensor_data_arrow = self.data.as_arrow_array()\n        if tensor_data_arrow[0].value['buffer'].type_code == self.JPEG_TYPE_ID:\n            _send_warning_or_raise('Image is already compressed as JPEG. Ignoring compression request.', 1, recording=None)\n            return self\n        shape_dims = tensor_data_arrow[0].value['shape'].values.field(0).to_numpy()\n        non_empty_dims = find_non_empty_dim_indices(shape_dims)\n        filtered_shape = shape_dims[non_empty_dims]\n        if len(filtered_shape) == 2:\n            mode = 'L'\n        elif len(filtered_shape) == 3 and filtered_shape[-1] == 3:\n            mode = 'RGB'\n        else:\n            raise ValueError('Only RGB or Mono images are supported for JPEG compression')\n        image_array = tensor_data_arrow[0].value['buffer'].value.values.to_numpy().reshape(filtered_shape)\n        if image_array.dtype not in ['uint8', 'sint32', 'float32']:\n            image_array = image_array.astype('float32')\n        pil_image = PILImage.fromarray(image_array, mode=mode)\n        output = BytesIO()\n        pil_image.save(output, format='JPEG', quality=jpeg_quality)\n        jpeg_bytes = output.getvalue()\n        output.close()\n        return ImageEncoded(contents=jpeg_bytes)\n    return self",
        "mutated": [
            "def compress(self, *, jpeg_quality: int=95) -> ImageEncoded | Image:\n    if False:\n        i = 10\n    '\\n        Converts an `Image` to an [`rerun.ImageEncoded`][] using JPEG compression.\\n\\n        JPEG compression works best for photographs. Only RGB or Mono images are\\n        supported, not RGBA. Note that compressing to JPEG costs a bit of CPU time,\\n        both when logging and later when viewing them.\\n\\n        Parameters\\n        ----------\\n        jpeg_quality:\\n            Higher quality = larger file size. A quality of 95 still saves a lot\\n            of space, but is visually very similar.\\n        '\n    from PIL import Image as PILImage\n    from .._image import ImageEncoded\n    from . import Image\n    self = cast(Image, self)\n    with catch_and_log_exceptions(context='Image compression'):\n        tensor_data_arrow = self.data.as_arrow_array()\n        if tensor_data_arrow[0].value['buffer'].type_code == self.JPEG_TYPE_ID:\n            _send_warning_or_raise('Image is already compressed as JPEG. Ignoring compression request.', 1, recording=None)\n            return self\n        shape_dims = tensor_data_arrow[0].value['shape'].values.field(0).to_numpy()\n        non_empty_dims = find_non_empty_dim_indices(shape_dims)\n        filtered_shape = shape_dims[non_empty_dims]\n        if len(filtered_shape) == 2:\n            mode = 'L'\n        elif len(filtered_shape) == 3 and filtered_shape[-1] == 3:\n            mode = 'RGB'\n        else:\n            raise ValueError('Only RGB or Mono images are supported for JPEG compression')\n        image_array = tensor_data_arrow[0].value['buffer'].value.values.to_numpy().reshape(filtered_shape)\n        if image_array.dtype not in ['uint8', 'sint32', 'float32']:\n            image_array = image_array.astype('float32')\n        pil_image = PILImage.fromarray(image_array, mode=mode)\n        output = BytesIO()\n        pil_image.save(output, format='JPEG', quality=jpeg_quality)\n        jpeg_bytes = output.getvalue()\n        output.close()\n        return ImageEncoded(contents=jpeg_bytes)\n    return self",
            "def compress(self, *, jpeg_quality: int=95) -> ImageEncoded | Image:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Converts an `Image` to an [`rerun.ImageEncoded`][] using JPEG compression.\\n\\n        JPEG compression works best for photographs. Only RGB or Mono images are\\n        supported, not RGBA. Note that compressing to JPEG costs a bit of CPU time,\\n        both when logging and later when viewing them.\\n\\n        Parameters\\n        ----------\\n        jpeg_quality:\\n            Higher quality = larger file size. A quality of 95 still saves a lot\\n            of space, but is visually very similar.\\n        '\n    from PIL import Image as PILImage\n    from .._image import ImageEncoded\n    from . import Image\n    self = cast(Image, self)\n    with catch_and_log_exceptions(context='Image compression'):\n        tensor_data_arrow = self.data.as_arrow_array()\n        if tensor_data_arrow[0].value['buffer'].type_code == self.JPEG_TYPE_ID:\n            _send_warning_or_raise('Image is already compressed as JPEG. Ignoring compression request.', 1, recording=None)\n            return self\n        shape_dims = tensor_data_arrow[0].value['shape'].values.field(0).to_numpy()\n        non_empty_dims = find_non_empty_dim_indices(shape_dims)\n        filtered_shape = shape_dims[non_empty_dims]\n        if len(filtered_shape) == 2:\n            mode = 'L'\n        elif len(filtered_shape) == 3 and filtered_shape[-1] == 3:\n            mode = 'RGB'\n        else:\n            raise ValueError('Only RGB or Mono images are supported for JPEG compression')\n        image_array = tensor_data_arrow[0].value['buffer'].value.values.to_numpy().reshape(filtered_shape)\n        if image_array.dtype not in ['uint8', 'sint32', 'float32']:\n            image_array = image_array.astype('float32')\n        pil_image = PILImage.fromarray(image_array, mode=mode)\n        output = BytesIO()\n        pil_image.save(output, format='JPEG', quality=jpeg_quality)\n        jpeg_bytes = output.getvalue()\n        output.close()\n        return ImageEncoded(contents=jpeg_bytes)\n    return self",
            "def compress(self, *, jpeg_quality: int=95) -> ImageEncoded | Image:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Converts an `Image` to an [`rerun.ImageEncoded`][] using JPEG compression.\\n\\n        JPEG compression works best for photographs. Only RGB or Mono images are\\n        supported, not RGBA. Note that compressing to JPEG costs a bit of CPU time,\\n        both when logging and later when viewing them.\\n\\n        Parameters\\n        ----------\\n        jpeg_quality:\\n            Higher quality = larger file size. A quality of 95 still saves a lot\\n            of space, but is visually very similar.\\n        '\n    from PIL import Image as PILImage\n    from .._image import ImageEncoded\n    from . import Image\n    self = cast(Image, self)\n    with catch_and_log_exceptions(context='Image compression'):\n        tensor_data_arrow = self.data.as_arrow_array()\n        if tensor_data_arrow[0].value['buffer'].type_code == self.JPEG_TYPE_ID:\n            _send_warning_or_raise('Image is already compressed as JPEG. Ignoring compression request.', 1, recording=None)\n            return self\n        shape_dims = tensor_data_arrow[0].value['shape'].values.field(0).to_numpy()\n        non_empty_dims = find_non_empty_dim_indices(shape_dims)\n        filtered_shape = shape_dims[non_empty_dims]\n        if len(filtered_shape) == 2:\n            mode = 'L'\n        elif len(filtered_shape) == 3 and filtered_shape[-1] == 3:\n            mode = 'RGB'\n        else:\n            raise ValueError('Only RGB or Mono images are supported for JPEG compression')\n        image_array = tensor_data_arrow[0].value['buffer'].value.values.to_numpy().reshape(filtered_shape)\n        if image_array.dtype not in ['uint8', 'sint32', 'float32']:\n            image_array = image_array.astype('float32')\n        pil_image = PILImage.fromarray(image_array, mode=mode)\n        output = BytesIO()\n        pil_image.save(output, format='JPEG', quality=jpeg_quality)\n        jpeg_bytes = output.getvalue()\n        output.close()\n        return ImageEncoded(contents=jpeg_bytes)\n    return self",
            "def compress(self, *, jpeg_quality: int=95) -> ImageEncoded | Image:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Converts an `Image` to an [`rerun.ImageEncoded`][] using JPEG compression.\\n\\n        JPEG compression works best for photographs. Only RGB or Mono images are\\n        supported, not RGBA. Note that compressing to JPEG costs a bit of CPU time,\\n        both when logging and later when viewing them.\\n\\n        Parameters\\n        ----------\\n        jpeg_quality:\\n            Higher quality = larger file size. A quality of 95 still saves a lot\\n            of space, but is visually very similar.\\n        '\n    from PIL import Image as PILImage\n    from .._image import ImageEncoded\n    from . import Image\n    self = cast(Image, self)\n    with catch_and_log_exceptions(context='Image compression'):\n        tensor_data_arrow = self.data.as_arrow_array()\n        if tensor_data_arrow[0].value['buffer'].type_code == self.JPEG_TYPE_ID:\n            _send_warning_or_raise('Image is already compressed as JPEG. Ignoring compression request.', 1, recording=None)\n            return self\n        shape_dims = tensor_data_arrow[0].value['shape'].values.field(0).to_numpy()\n        non_empty_dims = find_non_empty_dim_indices(shape_dims)\n        filtered_shape = shape_dims[non_empty_dims]\n        if len(filtered_shape) == 2:\n            mode = 'L'\n        elif len(filtered_shape) == 3 and filtered_shape[-1] == 3:\n            mode = 'RGB'\n        else:\n            raise ValueError('Only RGB or Mono images are supported for JPEG compression')\n        image_array = tensor_data_arrow[0].value['buffer'].value.values.to_numpy().reshape(filtered_shape)\n        if image_array.dtype not in ['uint8', 'sint32', 'float32']:\n            image_array = image_array.astype('float32')\n        pil_image = PILImage.fromarray(image_array, mode=mode)\n        output = BytesIO()\n        pil_image.save(output, format='JPEG', quality=jpeg_quality)\n        jpeg_bytes = output.getvalue()\n        output.close()\n        return ImageEncoded(contents=jpeg_bytes)\n    return self",
            "def compress(self, *, jpeg_quality: int=95) -> ImageEncoded | Image:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Converts an `Image` to an [`rerun.ImageEncoded`][] using JPEG compression.\\n\\n        JPEG compression works best for photographs. Only RGB or Mono images are\\n        supported, not RGBA. Note that compressing to JPEG costs a bit of CPU time,\\n        both when logging and later when viewing them.\\n\\n        Parameters\\n        ----------\\n        jpeg_quality:\\n            Higher quality = larger file size. A quality of 95 still saves a lot\\n            of space, but is visually very similar.\\n        '\n    from PIL import Image as PILImage\n    from .._image import ImageEncoded\n    from . import Image\n    self = cast(Image, self)\n    with catch_and_log_exceptions(context='Image compression'):\n        tensor_data_arrow = self.data.as_arrow_array()\n        if tensor_data_arrow[0].value['buffer'].type_code == self.JPEG_TYPE_ID:\n            _send_warning_or_raise('Image is already compressed as JPEG. Ignoring compression request.', 1, recording=None)\n            return self\n        shape_dims = tensor_data_arrow[0].value['shape'].values.field(0).to_numpy()\n        non_empty_dims = find_non_empty_dim_indices(shape_dims)\n        filtered_shape = shape_dims[non_empty_dims]\n        if len(filtered_shape) == 2:\n            mode = 'L'\n        elif len(filtered_shape) == 3 and filtered_shape[-1] == 3:\n            mode = 'RGB'\n        else:\n            raise ValueError('Only RGB or Mono images are supported for JPEG compression')\n        image_array = tensor_data_arrow[0].value['buffer'].value.values.to_numpy().reshape(filtered_shape)\n        if image_array.dtype not in ['uint8', 'sint32', 'float32']:\n            image_array = image_array.astype('float32')\n        pil_image = PILImage.fromarray(image_array, mode=mode)\n        output = BytesIO()\n        pil_image.save(output, format='JPEG', quality=jpeg_quality)\n        jpeg_bytes = output.getvalue()\n        output.close()\n        return ImageEncoded(contents=jpeg_bytes)\n    return self"
        ]
    },
    {
        "func_name": "data__field_converter_override",
        "original": "@staticmethod\n@catch_and_log_exceptions('Image converter')\ndef data__field_converter_override(data: TensorDataArrayLike) -> TensorDataBatch:\n    from ..components import TensorDataBatch\n    from ..datatypes import TensorDataType, TensorDimensionType\n    tensor_data = TensorDataBatch(data)\n    tensor_data_arrow = tensor_data.as_arrow_array()\n    tensor_data_type = TensorDataType().storage_type\n    shape_data_type = TensorDimensionType().storage_type\n    shape_dims = tensor_data_arrow[0].value['shape'].values.field(0).to_numpy()\n    shape_names = tensor_data_arrow[0].value['shape'].values.field(1).to_numpy(zero_copy_only=False)\n    non_empty_dims = find_non_empty_dim_indices(shape_dims)\n    num_non_empty_dims = len(non_empty_dims)\n    if num_non_empty_dims < 2 or 3 < num_non_empty_dims:\n        _send_warning_or_raise(f'Expected image, got array of shape {shape_dims}', 1, recording=None)\n    if num_non_empty_dims == 3:\n        depth = shape_dims[non_empty_dims[-1]]\n        if depth not in (3, 4):\n            _send_warning_or_raise(f'Expected image 3 (RGB) or 4 (RGBA). Instead got array of shape {shape_dims}', 1, recording=None)\n    if all((label is None for label in shape_names)):\n        for (ind, label) in zip(non_empty_dims, ['height', 'width', 'depth']):\n            shape_names[ind] = label\n        tensor_data_type = TensorDataType().storage_type\n        shape_data_type = TensorDimensionType().storage_type\n        shape_names = pa.array(shape_names, mask=np.array([n is None for n in shape_names]), type=shape_data_type.field('name').type)\n        new_shape = pa.ListArray.from_arrays(offsets=[0, len(shape_dims)], values=pa.StructArray.from_arrays([tensor_data_arrow[0].value['shape'].values.field(0), shape_names], fields=[shape_data_type.field('size'), shape_data_type.field('name')])).cast(tensor_data_type.field('shape').type)\n        return TensorDataBatch(pa.StructArray.from_arrays([new_shape, tensor_data_arrow.storage.field(1)], fields=[tensor_data_type.field('shape'), tensor_data_type.field('buffer')]).cast(tensor_data_arrow.storage.type))\n    return tensor_data",
        "mutated": [
            "@staticmethod\n@catch_and_log_exceptions('Image converter')\ndef data__field_converter_override(data: TensorDataArrayLike) -> TensorDataBatch:\n    if False:\n        i = 10\n    from ..components import TensorDataBatch\n    from ..datatypes import TensorDataType, TensorDimensionType\n    tensor_data = TensorDataBatch(data)\n    tensor_data_arrow = tensor_data.as_arrow_array()\n    tensor_data_type = TensorDataType().storage_type\n    shape_data_type = TensorDimensionType().storage_type\n    shape_dims = tensor_data_arrow[0].value['shape'].values.field(0).to_numpy()\n    shape_names = tensor_data_arrow[0].value['shape'].values.field(1).to_numpy(zero_copy_only=False)\n    non_empty_dims = find_non_empty_dim_indices(shape_dims)\n    num_non_empty_dims = len(non_empty_dims)\n    if num_non_empty_dims < 2 or 3 < num_non_empty_dims:\n        _send_warning_or_raise(f'Expected image, got array of shape {shape_dims}', 1, recording=None)\n    if num_non_empty_dims == 3:\n        depth = shape_dims[non_empty_dims[-1]]\n        if depth not in (3, 4):\n            _send_warning_or_raise(f'Expected image 3 (RGB) or 4 (RGBA). Instead got array of shape {shape_dims}', 1, recording=None)\n    if all((label is None for label in shape_names)):\n        for (ind, label) in zip(non_empty_dims, ['height', 'width', 'depth']):\n            shape_names[ind] = label\n        tensor_data_type = TensorDataType().storage_type\n        shape_data_type = TensorDimensionType().storage_type\n        shape_names = pa.array(shape_names, mask=np.array([n is None for n in shape_names]), type=shape_data_type.field('name').type)\n        new_shape = pa.ListArray.from_arrays(offsets=[0, len(shape_dims)], values=pa.StructArray.from_arrays([tensor_data_arrow[0].value['shape'].values.field(0), shape_names], fields=[shape_data_type.field('size'), shape_data_type.field('name')])).cast(tensor_data_type.field('shape').type)\n        return TensorDataBatch(pa.StructArray.from_arrays([new_shape, tensor_data_arrow.storage.field(1)], fields=[tensor_data_type.field('shape'), tensor_data_type.field('buffer')]).cast(tensor_data_arrow.storage.type))\n    return tensor_data",
            "@staticmethod\n@catch_and_log_exceptions('Image converter')\ndef data__field_converter_override(data: TensorDataArrayLike) -> TensorDataBatch:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    from ..components import TensorDataBatch\n    from ..datatypes import TensorDataType, TensorDimensionType\n    tensor_data = TensorDataBatch(data)\n    tensor_data_arrow = tensor_data.as_arrow_array()\n    tensor_data_type = TensorDataType().storage_type\n    shape_data_type = TensorDimensionType().storage_type\n    shape_dims = tensor_data_arrow[0].value['shape'].values.field(0).to_numpy()\n    shape_names = tensor_data_arrow[0].value['shape'].values.field(1).to_numpy(zero_copy_only=False)\n    non_empty_dims = find_non_empty_dim_indices(shape_dims)\n    num_non_empty_dims = len(non_empty_dims)\n    if num_non_empty_dims < 2 or 3 < num_non_empty_dims:\n        _send_warning_or_raise(f'Expected image, got array of shape {shape_dims}', 1, recording=None)\n    if num_non_empty_dims == 3:\n        depth = shape_dims[non_empty_dims[-1]]\n        if depth not in (3, 4):\n            _send_warning_or_raise(f'Expected image 3 (RGB) or 4 (RGBA). Instead got array of shape {shape_dims}', 1, recording=None)\n    if all((label is None for label in shape_names)):\n        for (ind, label) in zip(non_empty_dims, ['height', 'width', 'depth']):\n            shape_names[ind] = label\n        tensor_data_type = TensorDataType().storage_type\n        shape_data_type = TensorDimensionType().storage_type\n        shape_names = pa.array(shape_names, mask=np.array([n is None for n in shape_names]), type=shape_data_type.field('name').type)\n        new_shape = pa.ListArray.from_arrays(offsets=[0, len(shape_dims)], values=pa.StructArray.from_arrays([tensor_data_arrow[0].value['shape'].values.field(0), shape_names], fields=[shape_data_type.field('size'), shape_data_type.field('name')])).cast(tensor_data_type.field('shape').type)\n        return TensorDataBatch(pa.StructArray.from_arrays([new_shape, tensor_data_arrow.storage.field(1)], fields=[tensor_data_type.field('shape'), tensor_data_type.field('buffer')]).cast(tensor_data_arrow.storage.type))\n    return tensor_data",
            "@staticmethod\n@catch_and_log_exceptions('Image converter')\ndef data__field_converter_override(data: TensorDataArrayLike) -> TensorDataBatch:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    from ..components import TensorDataBatch\n    from ..datatypes import TensorDataType, TensorDimensionType\n    tensor_data = TensorDataBatch(data)\n    tensor_data_arrow = tensor_data.as_arrow_array()\n    tensor_data_type = TensorDataType().storage_type\n    shape_data_type = TensorDimensionType().storage_type\n    shape_dims = tensor_data_arrow[0].value['shape'].values.field(0).to_numpy()\n    shape_names = tensor_data_arrow[0].value['shape'].values.field(1).to_numpy(zero_copy_only=False)\n    non_empty_dims = find_non_empty_dim_indices(shape_dims)\n    num_non_empty_dims = len(non_empty_dims)\n    if num_non_empty_dims < 2 or 3 < num_non_empty_dims:\n        _send_warning_or_raise(f'Expected image, got array of shape {shape_dims}', 1, recording=None)\n    if num_non_empty_dims == 3:\n        depth = shape_dims[non_empty_dims[-1]]\n        if depth not in (3, 4):\n            _send_warning_or_raise(f'Expected image 3 (RGB) or 4 (RGBA). Instead got array of shape {shape_dims}', 1, recording=None)\n    if all((label is None for label in shape_names)):\n        for (ind, label) in zip(non_empty_dims, ['height', 'width', 'depth']):\n            shape_names[ind] = label\n        tensor_data_type = TensorDataType().storage_type\n        shape_data_type = TensorDimensionType().storage_type\n        shape_names = pa.array(shape_names, mask=np.array([n is None for n in shape_names]), type=shape_data_type.field('name').type)\n        new_shape = pa.ListArray.from_arrays(offsets=[0, len(shape_dims)], values=pa.StructArray.from_arrays([tensor_data_arrow[0].value['shape'].values.field(0), shape_names], fields=[shape_data_type.field('size'), shape_data_type.field('name')])).cast(tensor_data_type.field('shape').type)\n        return TensorDataBatch(pa.StructArray.from_arrays([new_shape, tensor_data_arrow.storage.field(1)], fields=[tensor_data_type.field('shape'), tensor_data_type.field('buffer')]).cast(tensor_data_arrow.storage.type))\n    return tensor_data",
            "@staticmethod\n@catch_and_log_exceptions('Image converter')\ndef data__field_converter_override(data: TensorDataArrayLike) -> TensorDataBatch:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    from ..components import TensorDataBatch\n    from ..datatypes import TensorDataType, TensorDimensionType\n    tensor_data = TensorDataBatch(data)\n    tensor_data_arrow = tensor_data.as_arrow_array()\n    tensor_data_type = TensorDataType().storage_type\n    shape_data_type = TensorDimensionType().storage_type\n    shape_dims = tensor_data_arrow[0].value['shape'].values.field(0).to_numpy()\n    shape_names = tensor_data_arrow[0].value['shape'].values.field(1).to_numpy(zero_copy_only=False)\n    non_empty_dims = find_non_empty_dim_indices(shape_dims)\n    num_non_empty_dims = len(non_empty_dims)\n    if num_non_empty_dims < 2 or 3 < num_non_empty_dims:\n        _send_warning_or_raise(f'Expected image, got array of shape {shape_dims}', 1, recording=None)\n    if num_non_empty_dims == 3:\n        depth = shape_dims[non_empty_dims[-1]]\n        if depth not in (3, 4):\n            _send_warning_or_raise(f'Expected image 3 (RGB) or 4 (RGBA). Instead got array of shape {shape_dims}', 1, recording=None)\n    if all((label is None for label in shape_names)):\n        for (ind, label) in zip(non_empty_dims, ['height', 'width', 'depth']):\n            shape_names[ind] = label\n        tensor_data_type = TensorDataType().storage_type\n        shape_data_type = TensorDimensionType().storage_type\n        shape_names = pa.array(shape_names, mask=np.array([n is None for n in shape_names]), type=shape_data_type.field('name').type)\n        new_shape = pa.ListArray.from_arrays(offsets=[0, len(shape_dims)], values=pa.StructArray.from_arrays([tensor_data_arrow[0].value['shape'].values.field(0), shape_names], fields=[shape_data_type.field('size'), shape_data_type.field('name')])).cast(tensor_data_type.field('shape').type)\n        return TensorDataBatch(pa.StructArray.from_arrays([new_shape, tensor_data_arrow.storage.field(1)], fields=[tensor_data_type.field('shape'), tensor_data_type.field('buffer')]).cast(tensor_data_arrow.storage.type))\n    return tensor_data",
            "@staticmethod\n@catch_and_log_exceptions('Image converter')\ndef data__field_converter_override(data: TensorDataArrayLike) -> TensorDataBatch:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    from ..components import TensorDataBatch\n    from ..datatypes import TensorDataType, TensorDimensionType\n    tensor_data = TensorDataBatch(data)\n    tensor_data_arrow = tensor_data.as_arrow_array()\n    tensor_data_type = TensorDataType().storage_type\n    shape_data_type = TensorDimensionType().storage_type\n    shape_dims = tensor_data_arrow[0].value['shape'].values.field(0).to_numpy()\n    shape_names = tensor_data_arrow[0].value['shape'].values.field(1).to_numpy(zero_copy_only=False)\n    non_empty_dims = find_non_empty_dim_indices(shape_dims)\n    num_non_empty_dims = len(non_empty_dims)\n    if num_non_empty_dims < 2 or 3 < num_non_empty_dims:\n        _send_warning_or_raise(f'Expected image, got array of shape {shape_dims}', 1, recording=None)\n    if num_non_empty_dims == 3:\n        depth = shape_dims[non_empty_dims[-1]]\n        if depth not in (3, 4):\n            _send_warning_or_raise(f'Expected image 3 (RGB) or 4 (RGBA). Instead got array of shape {shape_dims}', 1, recording=None)\n    if all((label is None for label in shape_names)):\n        for (ind, label) in zip(non_empty_dims, ['height', 'width', 'depth']):\n            shape_names[ind] = label\n        tensor_data_type = TensorDataType().storage_type\n        shape_data_type = TensorDimensionType().storage_type\n        shape_names = pa.array(shape_names, mask=np.array([n is None for n in shape_names]), type=shape_data_type.field('name').type)\n        new_shape = pa.ListArray.from_arrays(offsets=[0, len(shape_dims)], values=pa.StructArray.from_arrays([tensor_data_arrow[0].value['shape'].values.field(0), shape_names], fields=[shape_data_type.field('size'), shape_data_type.field('name')])).cast(tensor_data_type.field('shape').type)\n        return TensorDataBatch(pa.StructArray.from_arrays([new_shape, tensor_data_arrow.storage.field(1)], fields=[tensor_data_type.field('shape'), tensor_data_type.field('buffer')]).cast(tensor_data_arrow.storage.type))\n    return tensor_data"
        ]
    }
]