[
    {
        "func_name": "test_getitem",
        "original": "def test_getitem():\n    np.random.seed(0)\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    img_norm_cfg = dict(mean=[102.9801, 115.9465, 122.7717], std=[1.0, 1.0, 1.0], to_rgb=False)\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=True, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1600, 900), keep_ratio=True), dict(type='RandomFlip3D', flip_ratio_bev_horizontal=1.0), dict(type='Normalize', **img_norm_cfg), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'attr_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    nus_dataset = NuScenesMonoDataset(ann_file='tests/data/nuscenes/nus_infos_mono3d.coco.json', pipeline=pipeline, data_root='tests/data/nuscenes/', img_prefix='tests/data/nuscenes/', test_mode=False)\n    data = nus_dataset[0]\n    img_metas = data['img_metas']._data\n    filename = img_metas['filename']\n    img_shape = img_metas['img_shape']\n    pad_shape = img_metas['pad_shape']\n    flip = img_metas['flip']\n    bboxes = data['gt_bboxes']._data\n    attrs = data['attr_labels']._data\n    labels3d = data['gt_labels_3d']._data\n    labels = data['gt_labels']._data\n    centers2d = data['centers2d']._data\n    depths = data['depths']._data\n    expected_filename = 'tests/data/nuscenes/samples/CAM_BACK_LEFT/' + 'n015-2018-07-18-11-07-57+0800__CAM_BACK_LEFT__1531883530447423.jpg'\n    expected_img_shape = (900, 1600, 3)\n    expected_pad_shape = (928, 1600, 3)\n    expected_flip = True\n    expected_bboxes = torch.tensor([[485.4207, 513.7568, 515.4637, 576.1393], [748.9482, 512.0452, 776.4941, 571.631], [432.1318, 427.8805, 508.429, 578.1468], [367.3779, 427.7682, 439.4244, 578.8904], [592.8713, 515.004, 623.4984, 575.0945]])\n    expected_attr_labels = torch.tensor([8, 8, 4, 4, 8])\n    expected_labels = torch.tensor([8, 8, 7, 7, 8])\n    expected_centers2d = torch.tensor([[500.609, 544.6358], [762.8789, 541.528], [471.1633, 502.2295], [404.1957, 502.5908], [608.3627, 544.7317]])\n    expected_depths = torch.tensor([15.3193, 15.6073, 14.7567, 14.8803, 15.4923])\n    assert filename == expected_filename\n    assert img_shape == expected_img_shape\n    assert pad_shape == expected_pad_shape\n    assert flip == expected_flip\n    assert torch.allclose(bboxes, expected_bboxes, 1e-05)\n    assert torch.all(attrs == expected_attr_labels)\n    assert torch.all(labels == expected_labels)\n    assert torch.all(labels3d == expected_labels)\n    assert torch.allclose(centers2d, expected_centers2d, 1e-05)\n    assert torch.allclose(depths, expected_depths, 1e-05)",
        "mutated": [
            "def test_getitem():\n    if False:\n        i = 10\n    np.random.seed(0)\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    img_norm_cfg = dict(mean=[102.9801, 115.9465, 122.7717], std=[1.0, 1.0, 1.0], to_rgb=False)\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=True, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1600, 900), keep_ratio=True), dict(type='RandomFlip3D', flip_ratio_bev_horizontal=1.0), dict(type='Normalize', **img_norm_cfg), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'attr_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    nus_dataset = NuScenesMonoDataset(ann_file='tests/data/nuscenes/nus_infos_mono3d.coco.json', pipeline=pipeline, data_root='tests/data/nuscenes/', img_prefix='tests/data/nuscenes/', test_mode=False)\n    data = nus_dataset[0]\n    img_metas = data['img_metas']._data\n    filename = img_metas['filename']\n    img_shape = img_metas['img_shape']\n    pad_shape = img_metas['pad_shape']\n    flip = img_metas['flip']\n    bboxes = data['gt_bboxes']._data\n    attrs = data['attr_labels']._data\n    labels3d = data['gt_labels_3d']._data\n    labels = data['gt_labels']._data\n    centers2d = data['centers2d']._data\n    depths = data['depths']._data\n    expected_filename = 'tests/data/nuscenes/samples/CAM_BACK_LEFT/' + 'n015-2018-07-18-11-07-57+0800__CAM_BACK_LEFT__1531883530447423.jpg'\n    expected_img_shape = (900, 1600, 3)\n    expected_pad_shape = (928, 1600, 3)\n    expected_flip = True\n    expected_bboxes = torch.tensor([[485.4207, 513.7568, 515.4637, 576.1393], [748.9482, 512.0452, 776.4941, 571.631], [432.1318, 427.8805, 508.429, 578.1468], [367.3779, 427.7682, 439.4244, 578.8904], [592.8713, 515.004, 623.4984, 575.0945]])\n    expected_attr_labels = torch.tensor([8, 8, 4, 4, 8])\n    expected_labels = torch.tensor([8, 8, 7, 7, 8])\n    expected_centers2d = torch.tensor([[500.609, 544.6358], [762.8789, 541.528], [471.1633, 502.2295], [404.1957, 502.5908], [608.3627, 544.7317]])\n    expected_depths = torch.tensor([15.3193, 15.6073, 14.7567, 14.8803, 15.4923])\n    assert filename == expected_filename\n    assert img_shape == expected_img_shape\n    assert pad_shape == expected_pad_shape\n    assert flip == expected_flip\n    assert torch.allclose(bboxes, expected_bboxes, 1e-05)\n    assert torch.all(attrs == expected_attr_labels)\n    assert torch.all(labels == expected_labels)\n    assert torch.all(labels3d == expected_labels)\n    assert torch.allclose(centers2d, expected_centers2d, 1e-05)\n    assert torch.allclose(depths, expected_depths, 1e-05)",
            "def test_getitem():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    np.random.seed(0)\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    img_norm_cfg = dict(mean=[102.9801, 115.9465, 122.7717], std=[1.0, 1.0, 1.0], to_rgb=False)\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=True, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1600, 900), keep_ratio=True), dict(type='RandomFlip3D', flip_ratio_bev_horizontal=1.0), dict(type='Normalize', **img_norm_cfg), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'attr_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    nus_dataset = NuScenesMonoDataset(ann_file='tests/data/nuscenes/nus_infos_mono3d.coco.json', pipeline=pipeline, data_root='tests/data/nuscenes/', img_prefix='tests/data/nuscenes/', test_mode=False)\n    data = nus_dataset[0]\n    img_metas = data['img_metas']._data\n    filename = img_metas['filename']\n    img_shape = img_metas['img_shape']\n    pad_shape = img_metas['pad_shape']\n    flip = img_metas['flip']\n    bboxes = data['gt_bboxes']._data\n    attrs = data['attr_labels']._data\n    labels3d = data['gt_labels_3d']._data\n    labels = data['gt_labels']._data\n    centers2d = data['centers2d']._data\n    depths = data['depths']._data\n    expected_filename = 'tests/data/nuscenes/samples/CAM_BACK_LEFT/' + 'n015-2018-07-18-11-07-57+0800__CAM_BACK_LEFT__1531883530447423.jpg'\n    expected_img_shape = (900, 1600, 3)\n    expected_pad_shape = (928, 1600, 3)\n    expected_flip = True\n    expected_bboxes = torch.tensor([[485.4207, 513.7568, 515.4637, 576.1393], [748.9482, 512.0452, 776.4941, 571.631], [432.1318, 427.8805, 508.429, 578.1468], [367.3779, 427.7682, 439.4244, 578.8904], [592.8713, 515.004, 623.4984, 575.0945]])\n    expected_attr_labels = torch.tensor([8, 8, 4, 4, 8])\n    expected_labels = torch.tensor([8, 8, 7, 7, 8])\n    expected_centers2d = torch.tensor([[500.609, 544.6358], [762.8789, 541.528], [471.1633, 502.2295], [404.1957, 502.5908], [608.3627, 544.7317]])\n    expected_depths = torch.tensor([15.3193, 15.6073, 14.7567, 14.8803, 15.4923])\n    assert filename == expected_filename\n    assert img_shape == expected_img_shape\n    assert pad_shape == expected_pad_shape\n    assert flip == expected_flip\n    assert torch.allclose(bboxes, expected_bboxes, 1e-05)\n    assert torch.all(attrs == expected_attr_labels)\n    assert torch.all(labels == expected_labels)\n    assert torch.all(labels3d == expected_labels)\n    assert torch.allclose(centers2d, expected_centers2d, 1e-05)\n    assert torch.allclose(depths, expected_depths, 1e-05)",
            "def test_getitem():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    np.random.seed(0)\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    img_norm_cfg = dict(mean=[102.9801, 115.9465, 122.7717], std=[1.0, 1.0, 1.0], to_rgb=False)\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=True, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1600, 900), keep_ratio=True), dict(type='RandomFlip3D', flip_ratio_bev_horizontal=1.0), dict(type='Normalize', **img_norm_cfg), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'attr_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    nus_dataset = NuScenesMonoDataset(ann_file='tests/data/nuscenes/nus_infos_mono3d.coco.json', pipeline=pipeline, data_root='tests/data/nuscenes/', img_prefix='tests/data/nuscenes/', test_mode=False)\n    data = nus_dataset[0]\n    img_metas = data['img_metas']._data\n    filename = img_metas['filename']\n    img_shape = img_metas['img_shape']\n    pad_shape = img_metas['pad_shape']\n    flip = img_metas['flip']\n    bboxes = data['gt_bboxes']._data\n    attrs = data['attr_labels']._data\n    labels3d = data['gt_labels_3d']._data\n    labels = data['gt_labels']._data\n    centers2d = data['centers2d']._data\n    depths = data['depths']._data\n    expected_filename = 'tests/data/nuscenes/samples/CAM_BACK_LEFT/' + 'n015-2018-07-18-11-07-57+0800__CAM_BACK_LEFT__1531883530447423.jpg'\n    expected_img_shape = (900, 1600, 3)\n    expected_pad_shape = (928, 1600, 3)\n    expected_flip = True\n    expected_bboxes = torch.tensor([[485.4207, 513.7568, 515.4637, 576.1393], [748.9482, 512.0452, 776.4941, 571.631], [432.1318, 427.8805, 508.429, 578.1468], [367.3779, 427.7682, 439.4244, 578.8904], [592.8713, 515.004, 623.4984, 575.0945]])\n    expected_attr_labels = torch.tensor([8, 8, 4, 4, 8])\n    expected_labels = torch.tensor([8, 8, 7, 7, 8])\n    expected_centers2d = torch.tensor([[500.609, 544.6358], [762.8789, 541.528], [471.1633, 502.2295], [404.1957, 502.5908], [608.3627, 544.7317]])\n    expected_depths = torch.tensor([15.3193, 15.6073, 14.7567, 14.8803, 15.4923])\n    assert filename == expected_filename\n    assert img_shape == expected_img_shape\n    assert pad_shape == expected_pad_shape\n    assert flip == expected_flip\n    assert torch.allclose(bboxes, expected_bboxes, 1e-05)\n    assert torch.all(attrs == expected_attr_labels)\n    assert torch.all(labels == expected_labels)\n    assert torch.all(labels3d == expected_labels)\n    assert torch.allclose(centers2d, expected_centers2d, 1e-05)\n    assert torch.allclose(depths, expected_depths, 1e-05)",
            "def test_getitem():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    np.random.seed(0)\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    img_norm_cfg = dict(mean=[102.9801, 115.9465, 122.7717], std=[1.0, 1.0, 1.0], to_rgb=False)\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=True, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1600, 900), keep_ratio=True), dict(type='RandomFlip3D', flip_ratio_bev_horizontal=1.0), dict(type='Normalize', **img_norm_cfg), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'attr_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    nus_dataset = NuScenesMonoDataset(ann_file='tests/data/nuscenes/nus_infos_mono3d.coco.json', pipeline=pipeline, data_root='tests/data/nuscenes/', img_prefix='tests/data/nuscenes/', test_mode=False)\n    data = nus_dataset[0]\n    img_metas = data['img_metas']._data\n    filename = img_metas['filename']\n    img_shape = img_metas['img_shape']\n    pad_shape = img_metas['pad_shape']\n    flip = img_metas['flip']\n    bboxes = data['gt_bboxes']._data\n    attrs = data['attr_labels']._data\n    labels3d = data['gt_labels_3d']._data\n    labels = data['gt_labels']._data\n    centers2d = data['centers2d']._data\n    depths = data['depths']._data\n    expected_filename = 'tests/data/nuscenes/samples/CAM_BACK_LEFT/' + 'n015-2018-07-18-11-07-57+0800__CAM_BACK_LEFT__1531883530447423.jpg'\n    expected_img_shape = (900, 1600, 3)\n    expected_pad_shape = (928, 1600, 3)\n    expected_flip = True\n    expected_bboxes = torch.tensor([[485.4207, 513.7568, 515.4637, 576.1393], [748.9482, 512.0452, 776.4941, 571.631], [432.1318, 427.8805, 508.429, 578.1468], [367.3779, 427.7682, 439.4244, 578.8904], [592.8713, 515.004, 623.4984, 575.0945]])\n    expected_attr_labels = torch.tensor([8, 8, 4, 4, 8])\n    expected_labels = torch.tensor([8, 8, 7, 7, 8])\n    expected_centers2d = torch.tensor([[500.609, 544.6358], [762.8789, 541.528], [471.1633, 502.2295], [404.1957, 502.5908], [608.3627, 544.7317]])\n    expected_depths = torch.tensor([15.3193, 15.6073, 14.7567, 14.8803, 15.4923])\n    assert filename == expected_filename\n    assert img_shape == expected_img_shape\n    assert pad_shape == expected_pad_shape\n    assert flip == expected_flip\n    assert torch.allclose(bboxes, expected_bboxes, 1e-05)\n    assert torch.all(attrs == expected_attr_labels)\n    assert torch.all(labels == expected_labels)\n    assert torch.all(labels3d == expected_labels)\n    assert torch.allclose(centers2d, expected_centers2d, 1e-05)\n    assert torch.allclose(depths, expected_depths, 1e-05)",
            "def test_getitem():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    np.random.seed(0)\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    img_norm_cfg = dict(mean=[102.9801, 115.9465, 122.7717], std=[1.0, 1.0, 1.0], to_rgb=False)\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=True, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1600, 900), keep_ratio=True), dict(type='RandomFlip3D', flip_ratio_bev_horizontal=1.0), dict(type='Normalize', **img_norm_cfg), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'attr_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    nus_dataset = NuScenesMonoDataset(ann_file='tests/data/nuscenes/nus_infos_mono3d.coco.json', pipeline=pipeline, data_root='tests/data/nuscenes/', img_prefix='tests/data/nuscenes/', test_mode=False)\n    data = nus_dataset[0]\n    img_metas = data['img_metas']._data\n    filename = img_metas['filename']\n    img_shape = img_metas['img_shape']\n    pad_shape = img_metas['pad_shape']\n    flip = img_metas['flip']\n    bboxes = data['gt_bboxes']._data\n    attrs = data['attr_labels']._data\n    labels3d = data['gt_labels_3d']._data\n    labels = data['gt_labels']._data\n    centers2d = data['centers2d']._data\n    depths = data['depths']._data\n    expected_filename = 'tests/data/nuscenes/samples/CAM_BACK_LEFT/' + 'n015-2018-07-18-11-07-57+0800__CAM_BACK_LEFT__1531883530447423.jpg'\n    expected_img_shape = (900, 1600, 3)\n    expected_pad_shape = (928, 1600, 3)\n    expected_flip = True\n    expected_bboxes = torch.tensor([[485.4207, 513.7568, 515.4637, 576.1393], [748.9482, 512.0452, 776.4941, 571.631], [432.1318, 427.8805, 508.429, 578.1468], [367.3779, 427.7682, 439.4244, 578.8904], [592.8713, 515.004, 623.4984, 575.0945]])\n    expected_attr_labels = torch.tensor([8, 8, 4, 4, 8])\n    expected_labels = torch.tensor([8, 8, 7, 7, 8])\n    expected_centers2d = torch.tensor([[500.609, 544.6358], [762.8789, 541.528], [471.1633, 502.2295], [404.1957, 502.5908], [608.3627, 544.7317]])\n    expected_depths = torch.tensor([15.3193, 15.6073, 14.7567, 14.8803, 15.4923])\n    assert filename == expected_filename\n    assert img_shape == expected_img_shape\n    assert pad_shape == expected_pad_shape\n    assert flip == expected_flip\n    assert torch.allclose(bboxes, expected_bboxes, 1e-05)\n    assert torch.all(attrs == expected_attr_labels)\n    assert torch.all(labels == expected_labels)\n    assert torch.all(labels3d == expected_labels)\n    assert torch.allclose(centers2d, expected_centers2d, 1e-05)\n    assert torch.allclose(depths, expected_depths, 1e-05)"
        ]
    },
    {
        "func_name": "test_format_results",
        "original": "def test_format_results():\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    root_path = 'tests/data/nuscenes/'\n    ann_file = 'tests/data/nuscenes/nus_infos_mono3d.coco.json'\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=True, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1600, 900), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'attr_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    nus_dataset = NuScenesMonoDataset(ann_file=ann_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/nuscenes/mono3d_sample_results.pkl')\n    (result_files, tmp_dir) = nus_dataset.format_results(results)\n    result_data = mmcv.load(result_files['img_bbox'])\n    assert len(result_data['results'].keys()) == 1\n    assert len(result_data['results']['e93e98b63d3b40209056d129dc53ceee']) == 8\n    det = result_data['results']['e93e98b63d3b40209056d129dc53ceee'][0]\n    expected_token = 'e93e98b63d3b40209056d129dc53ceee'\n    expected_trans = torch.tensor([1018.753821915645, 605.190386124652, 0.7266818822266328])\n    expected_size = torch.tensor([1.440000057220459, 1.6380000114440918, 4.25])\n    expected_rotation = torch.tensor([-0.5717, -0.0014, 0.017, -0.8203])\n    expected_detname = 'car'\n    expected_attr = 'vehicle.moving'\n    assert det['sample_token'] == expected_token\n    assert torch.allclose(torch.tensor(det['translation']), expected_trans, 1e-05)\n    assert torch.allclose(torch.tensor(det['size']), expected_size, 1e-05)\n    assert torch.allclose(torch.tensor(det['rotation']), expected_rotation, atol=0.0001)\n    assert det['detection_name'] == expected_detname\n    assert det['attribute_name'] == expected_attr",
        "mutated": [
            "def test_format_results():\n    if False:\n        i = 10\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    root_path = 'tests/data/nuscenes/'\n    ann_file = 'tests/data/nuscenes/nus_infos_mono3d.coco.json'\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=True, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1600, 900), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'attr_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    nus_dataset = NuScenesMonoDataset(ann_file=ann_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/nuscenes/mono3d_sample_results.pkl')\n    (result_files, tmp_dir) = nus_dataset.format_results(results)\n    result_data = mmcv.load(result_files['img_bbox'])\n    assert len(result_data['results'].keys()) == 1\n    assert len(result_data['results']['e93e98b63d3b40209056d129dc53ceee']) == 8\n    det = result_data['results']['e93e98b63d3b40209056d129dc53ceee'][0]\n    expected_token = 'e93e98b63d3b40209056d129dc53ceee'\n    expected_trans = torch.tensor([1018.753821915645, 605.190386124652, 0.7266818822266328])\n    expected_size = torch.tensor([1.440000057220459, 1.6380000114440918, 4.25])\n    expected_rotation = torch.tensor([-0.5717, -0.0014, 0.017, -0.8203])\n    expected_detname = 'car'\n    expected_attr = 'vehicle.moving'\n    assert det['sample_token'] == expected_token\n    assert torch.allclose(torch.tensor(det['translation']), expected_trans, 1e-05)\n    assert torch.allclose(torch.tensor(det['size']), expected_size, 1e-05)\n    assert torch.allclose(torch.tensor(det['rotation']), expected_rotation, atol=0.0001)\n    assert det['detection_name'] == expected_detname\n    assert det['attribute_name'] == expected_attr",
            "def test_format_results():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    root_path = 'tests/data/nuscenes/'\n    ann_file = 'tests/data/nuscenes/nus_infos_mono3d.coco.json'\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=True, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1600, 900), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'attr_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    nus_dataset = NuScenesMonoDataset(ann_file=ann_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/nuscenes/mono3d_sample_results.pkl')\n    (result_files, tmp_dir) = nus_dataset.format_results(results)\n    result_data = mmcv.load(result_files['img_bbox'])\n    assert len(result_data['results'].keys()) == 1\n    assert len(result_data['results']['e93e98b63d3b40209056d129dc53ceee']) == 8\n    det = result_data['results']['e93e98b63d3b40209056d129dc53ceee'][0]\n    expected_token = 'e93e98b63d3b40209056d129dc53ceee'\n    expected_trans = torch.tensor([1018.753821915645, 605.190386124652, 0.7266818822266328])\n    expected_size = torch.tensor([1.440000057220459, 1.6380000114440918, 4.25])\n    expected_rotation = torch.tensor([-0.5717, -0.0014, 0.017, -0.8203])\n    expected_detname = 'car'\n    expected_attr = 'vehicle.moving'\n    assert det['sample_token'] == expected_token\n    assert torch.allclose(torch.tensor(det['translation']), expected_trans, 1e-05)\n    assert torch.allclose(torch.tensor(det['size']), expected_size, 1e-05)\n    assert torch.allclose(torch.tensor(det['rotation']), expected_rotation, atol=0.0001)\n    assert det['detection_name'] == expected_detname\n    assert det['attribute_name'] == expected_attr",
            "def test_format_results():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    root_path = 'tests/data/nuscenes/'\n    ann_file = 'tests/data/nuscenes/nus_infos_mono3d.coco.json'\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=True, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1600, 900), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'attr_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    nus_dataset = NuScenesMonoDataset(ann_file=ann_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/nuscenes/mono3d_sample_results.pkl')\n    (result_files, tmp_dir) = nus_dataset.format_results(results)\n    result_data = mmcv.load(result_files['img_bbox'])\n    assert len(result_data['results'].keys()) == 1\n    assert len(result_data['results']['e93e98b63d3b40209056d129dc53ceee']) == 8\n    det = result_data['results']['e93e98b63d3b40209056d129dc53ceee'][0]\n    expected_token = 'e93e98b63d3b40209056d129dc53ceee'\n    expected_trans = torch.tensor([1018.753821915645, 605.190386124652, 0.7266818822266328])\n    expected_size = torch.tensor([1.440000057220459, 1.6380000114440918, 4.25])\n    expected_rotation = torch.tensor([-0.5717, -0.0014, 0.017, -0.8203])\n    expected_detname = 'car'\n    expected_attr = 'vehicle.moving'\n    assert det['sample_token'] == expected_token\n    assert torch.allclose(torch.tensor(det['translation']), expected_trans, 1e-05)\n    assert torch.allclose(torch.tensor(det['size']), expected_size, 1e-05)\n    assert torch.allclose(torch.tensor(det['rotation']), expected_rotation, atol=0.0001)\n    assert det['detection_name'] == expected_detname\n    assert det['attribute_name'] == expected_attr",
            "def test_format_results():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    root_path = 'tests/data/nuscenes/'\n    ann_file = 'tests/data/nuscenes/nus_infos_mono3d.coco.json'\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=True, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1600, 900), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'attr_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    nus_dataset = NuScenesMonoDataset(ann_file=ann_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/nuscenes/mono3d_sample_results.pkl')\n    (result_files, tmp_dir) = nus_dataset.format_results(results)\n    result_data = mmcv.load(result_files['img_bbox'])\n    assert len(result_data['results'].keys()) == 1\n    assert len(result_data['results']['e93e98b63d3b40209056d129dc53ceee']) == 8\n    det = result_data['results']['e93e98b63d3b40209056d129dc53ceee'][0]\n    expected_token = 'e93e98b63d3b40209056d129dc53ceee'\n    expected_trans = torch.tensor([1018.753821915645, 605.190386124652, 0.7266818822266328])\n    expected_size = torch.tensor([1.440000057220459, 1.6380000114440918, 4.25])\n    expected_rotation = torch.tensor([-0.5717, -0.0014, 0.017, -0.8203])\n    expected_detname = 'car'\n    expected_attr = 'vehicle.moving'\n    assert det['sample_token'] == expected_token\n    assert torch.allclose(torch.tensor(det['translation']), expected_trans, 1e-05)\n    assert torch.allclose(torch.tensor(det['size']), expected_size, 1e-05)\n    assert torch.allclose(torch.tensor(det['rotation']), expected_rotation, atol=0.0001)\n    assert det['detection_name'] == expected_detname\n    assert det['attribute_name'] == expected_attr",
            "def test_format_results():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    root_path = 'tests/data/nuscenes/'\n    ann_file = 'tests/data/nuscenes/nus_infos_mono3d.coco.json'\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=True, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1600, 900), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'attr_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    nus_dataset = NuScenesMonoDataset(ann_file=ann_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/nuscenes/mono3d_sample_results.pkl')\n    (result_files, tmp_dir) = nus_dataset.format_results(results)\n    result_data = mmcv.load(result_files['img_bbox'])\n    assert len(result_data['results'].keys()) == 1\n    assert len(result_data['results']['e93e98b63d3b40209056d129dc53ceee']) == 8\n    det = result_data['results']['e93e98b63d3b40209056d129dc53ceee'][0]\n    expected_token = 'e93e98b63d3b40209056d129dc53ceee'\n    expected_trans = torch.tensor([1018.753821915645, 605.190386124652, 0.7266818822266328])\n    expected_size = torch.tensor([1.440000057220459, 1.6380000114440918, 4.25])\n    expected_rotation = torch.tensor([-0.5717, -0.0014, 0.017, -0.8203])\n    expected_detname = 'car'\n    expected_attr = 'vehicle.moving'\n    assert det['sample_token'] == expected_token\n    assert torch.allclose(torch.tensor(det['translation']), expected_trans, 1e-05)\n    assert torch.allclose(torch.tensor(det['size']), expected_size, 1e-05)\n    assert torch.allclose(torch.tensor(det['rotation']), expected_rotation, atol=0.0001)\n    assert det['detection_name'] == expected_detname\n    assert det['attribute_name'] == expected_attr"
        ]
    },
    {
        "func_name": "test_show",
        "original": "def test_show():\n    root_path = 'tests/data/nuscenes/'\n    ann_file = 'tests/data/nuscenes/nus_infos_mono3d.coco.json'\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    eval_pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='DefaultFormatBundle3D', class_names=class_names, with_label=False), dict(type='Collect3D', keys=['img'])]\n    nus_dataset = NuScenesMonoDataset(data_root=root_path, ann_file=ann_file, img_prefix='tests/data/nuscenes/', test_mode=True, pipeline=eval_pipeline)\n    results = mmcv.load('tests/data/nuscenes/mono3d_sample_results.pkl')\n    results = [results[0]]\n    tmp_dir = tempfile.TemporaryDirectory()\n    temp_dir = tmp_dir.name\n    nus_dataset.show(results, temp_dir, show=False)\n    file_name = 'n015-2018-07-18-11-07-57+0800__CAM_BACK_LEFT__1531883530447423'\n    img_file_path = osp.join(temp_dir, file_name, f'{file_name}_img.png')\n    gt_file_path = osp.join(temp_dir, file_name, f'{file_name}_gt.png')\n    pred_file_path = osp.join(temp_dir, file_name, f'{file_name}_pred.png')\n    mmcv.check_file_exist(img_file_path)\n    mmcv.check_file_exist(gt_file_path)\n    mmcv.check_file_exist(pred_file_path)\n    tmp_dir.cleanup()",
        "mutated": [
            "def test_show():\n    if False:\n        i = 10\n    root_path = 'tests/data/nuscenes/'\n    ann_file = 'tests/data/nuscenes/nus_infos_mono3d.coco.json'\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    eval_pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='DefaultFormatBundle3D', class_names=class_names, with_label=False), dict(type='Collect3D', keys=['img'])]\n    nus_dataset = NuScenesMonoDataset(data_root=root_path, ann_file=ann_file, img_prefix='tests/data/nuscenes/', test_mode=True, pipeline=eval_pipeline)\n    results = mmcv.load('tests/data/nuscenes/mono3d_sample_results.pkl')\n    results = [results[0]]\n    tmp_dir = tempfile.TemporaryDirectory()\n    temp_dir = tmp_dir.name\n    nus_dataset.show(results, temp_dir, show=False)\n    file_name = 'n015-2018-07-18-11-07-57+0800__CAM_BACK_LEFT__1531883530447423'\n    img_file_path = osp.join(temp_dir, file_name, f'{file_name}_img.png')\n    gt_file_path = osp.join(temp_dir, file_name, f'{file_name}_gt.png')\n    pred_file_path = osp.join(temp_dir, file_name, f'{file_name}_pred.png')\n    mmcv.check_file_exist(img_file_path)\n    mmcv.check_file_exist(gt_file_path)\n    mmcv.check_file_exist(pred_file_path)\n    tmp_dir.cleanup()",
            "def test_show():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    root_path = 'tests/data/nuscenes/'\n    ann_file = 'tests/data/nuscenes/nus_infos_mono3d.coco.json'\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    eval_pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='DefaultFormatBundle3D', class_names=class_names, with_label=False), dict(type='Collect3D', keys=['img'])]\n    nus_dataset = NuScenesMonoDataset(data_root=root_path, ann_file=ann_file, img_prefix='tests/data/nuscenes/', test_mode=True, pipeline=eval_pipeline)\n    results = mmcv.load('tests/data/nuscenes/mono3d_sample_results.pkl')\n    results = [results[0]]\n    tmp_dir = tempfile.TemporaryDirectory()\n    temp_dir = tmp_dir.name\n    nus_dataset.show(results, temp_dir, show=False)\n    file_name = 'n015-2018-07-18-11-07-57+0800__CAM_BACK_LEFT__1531883530447423'\n    img_file_path = osp.join(temp_dir, file_name, f'{file_name}_img.png')\n    gt_file_path = osp.join(temp_dir, file_name, f'{file_name}_gt.png')\n    pred_file_path = osp.join(temp_dir, file_name, f'{file_name}_pred.png')\n    mmcv.check_file_exist(img_file_path)\n    mmcv.check_file_exist(gt_file_path)\n    mmcv.check_file_exist(pred_file_path)\n    tmp_dir.cleanup()",
            "def test_show():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    root_path = 'tests/data/nuscenes/'\n    ann_file = 'tests/data/nuscenes/nus_infos_mono3d.coco.json'\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    eval_pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='DefaultFormatBundle3D', class_names=class_names, with_label=False), dict(type='Collect3D', keys=['img'])]\n    nus_dataset = NuScenesMonoDataset(data_root=root_path, ann_file=ann_file, img_prefix='tests/data/nuscenes/', test_mode=True, pipeline=eval_pipeline)\n    results = mmcv.load('tests/data/nuscenes/mono3d_sample_results.pkl')\n    results = [results[0]]\n    tmp_dir = tempfile.TemporaryDirectory()\n    temp_dir = tmp_dir.name\n    nus_dataset.show(results, temp_dir, show=False)\n    file_name = 'n015-2018-07-18-11-07-57+0800__CAM_BACK_LEFT__1531883530447423'\n    img_file_path = osp.join(temp_dir, file_name, f'{file_name}_img.png')\n    gt_file_path = osp.join(temp_dir, file_name, f'{file_name}_gt.png')\n    pred_file_path = osp.join(temp_dir, file_name, f'{file_name}_pred.png')\n    mmcv.check_file_exist(img_file_path)\n    mmcv.check_file_exist(gt_file_path)\n    mmcv.check_file_exist(pred_file_path)\n    tmp_dir.cleanup()",
            "def test_show():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    root_path = 'tests/data/nuscenes/'\n    ann_file = 'tests/data/nuscenes/nus_infos_mono3d.coco.json'\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    eval_pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='DefaultFormatBundle3D', class_names=class_names, with_label=False), dict(type='Collect3D', keys=['img'])]\n    nus_dataset = NuScenesMonoDataset(data_root=root_path, ann_file=ann_file, img_prefix='tests/data/nuscenes/', test_mode=True, pipeline=eval_pipeline)\n    results = mmcv.load('tests/data/nuscenes/mono3d_sample_results.pkl')\n    results = [results[0]]\n    tmp_dir = tempfile.TemporaryDirectory()\n    temp_dir = tmp_dir.name\n    nus_dataset.show(results, temp_dir, show=False)\n    file_name = 'n015-2018-07-18-11-07-57+0800__CAM_BACK_LEFT__1531883530447423'\n    img_file_path = osp.join(temp_dir, file_name, f'{file_name}_img.png')\n    gt_file_path = osp.join(temp_dir, file_name, f'{file_name}_gt.png')\n    pred_file_path = osp.join(temp_dir, file_name, f'{file_name}_pred.png')\n    mmcv.check_file_exist(img_file_path)\n    mmcv.check_file_exist(gt_file_path)\n    mmcv.check_file_exist(pred_file_path)\n    tmp_dir.cleanup()",
            "def test_show():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    root_path = 'tests/data/nuscenes/'\n    ann_file = 'tests/data/nuscenes/nus_infos_mono3d.coco.json'\n    class_names = ['car', 'truck', 'trailer', 'bus', 'construction_vehicle', 'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier']\n    eval_pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='DefaultFormatBundle3D', class_names=class_names, with_label=False), dict(type='Collect3D', keys=['img'])]\n    nus_dataset = NuScenesMonoDataset(data_root=root_path, ann_file=ann_file, img_prefix='tests/data/nuscenes/', test_mode=True, pipeline=eval_pipeline)\n    results = mmcv.load('tests/data/nuscenes/mono3d_sample_results.pkl')\n    results = [results[0]]\n    tmp_dir = tempfile.TemporaryDirectory()\n    temp_dir = tmp_dir.name\n    nus_dataset.show(results, temp_dir, show=False)\n    file_name = 'n015-2018-07-18-11-07-57+0800__CAM_BACK_LEFT__1531883530447423'\n    img_file_path = osp.join(temp_dir, file_name, f'{file_name}_img.png')\n    gt_file_path = osp.join(temp_dir, file_name, f'{file_name}_gt.png')\n    pred_file_path = osp.join(temp_dir, file_name, f'{file_name}_pred.png')\n    mmcv.check_file_exist(img_file_path)\n    mmcv.check_file_exist(gt_file_path)\n    mmcv.check_file_exist(pred_file_path)\n    tmp_dir.cleanup()"
        ]
    }
]