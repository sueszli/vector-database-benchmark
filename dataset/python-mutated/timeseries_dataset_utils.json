[
    {
        "func_name": "timeseries_dataset_from_array",
        "original": "@keras_export(['keras.utils.timeseries_dataset_from_array', 'keras.preprocessing.timeseries_dataset_from_array'])\ndef timeseries_dataset_from_array(data, targets, sequence_length, sequence_stride=1, sampling_rate=1, batch_size=128, shuffle=False, seed=None, start_index=None, end_index=None):\n    \"\"\"Creates a dataset of sliding windows over a timeseries provided as array.\n\n    This function takes in a sequence of data-points gathered at\n    equal intervals, along with time series parameters such as\n    length of the sequences/windows, spacing between two sequence/windows, etc.,\n    to produce batches of timeseries inputs and targets.\n\n    Args:\n        data: Numpy array or eager tensor\n            containing consecutive data points (timesteps).\n            Axis 0 is expected to be the time dimension.\n        targets: Targets corresponding to timesteps in `data`.\n            `targets[i]` should be the target\n            corresponding to the window that starts at index `i`\n            (see example 2 below).\n            Pass `None` if you don't have target data (in this case the dataset\n            will only yield the input data).\n        sequence_length: Length of the output sequences\n            (in number of timesteps).\n        sequence_stride: Period between successive output sequences.\n            For stride `s`, output samples would\n            start at index `data[i]`, `data[i + s]`, `data[i + 2 * s]`, etc.\n        sampling_rate: Period between successive individual timesteps\n            within sequences. For rate `r`, timesteps\n            `data[i], data[i + r], ... data[i + sequence_length]`\n            are used for creating a sample sequence.\n        batch_size: Number of timeseries samples in each batch\n            (except maybe the last one). If `None`, the data will not be batched\n            (the dataset will yield individual samples).\n        shuffle: Whether to shuffle output samples,\n            or instead draw them in chronological order.\n        seed: Optional int; random seed for shuffling.\n        start_index: Optional int; data points earlier (exclusive)\n            than `start_index` will not be used\n            in the output sequences. This is useful to reserve part of the\n            data for test or validation.\n        end_index: Optional int; data points later (exclusive) than `end_index`\n            will not be used in the output sequences.\n            This is useful to reserve part of the data for test or validation.\n\n    Returns:\n\n    A `tf.data.Dataset` instance. If `targets` was passed, the dataset yields\n    tuple `(batch_of_sequences, batch_of_targets)`. If not, the dataset yields\n    only `batch_of_sequences`.\n\n    Example 1:\n\n    Consider indices `[0, 1, ... 98]`.\n    With `sequence_length=10,  sampling_rate=2, sequence_stride=3`,\n    `shuffle=False`, the dataset will yield batches of sequences\n    composed of the following indices:\n\n    ```\n    First sequence:  [0  2  4  6  8 10 12 14 16 18]\n    Second sequence: [3  5  7  9 11 13 15 17 19 21]\n    Third sequence:  [6  8 10 12 14 16 18 20 22 24]\n    ...\n    Last sequence:   [78 80 82 84 86 88 90 92 94 96]\n    ```\n\n    In this case the last 2 data points are discarded since no full sequence\n    can be generated to include them (the next sequence would have started\n    at index 81, and thus its last step would have gone over 98).\n\n    Example 2: Temporal regression.\n\n    Consider an array `data` of scalar values, of shape `(steps,)`.\n    To generate a dataset that uses the past 10\n    timesteps to predict the next timestep, you would use:\n\n    ```python\n    input_data = data[:-10]\n    targets = data[10:]\n    dataset = timeseries_dataset_from_array(\n        input_data, targets, sequence_length=10)\n    for batch in dataset:\n      inputs, targets = batch\n      assert np.array_equal(inputs[0], data[:10])  # First sequence: steps [0-9]\n      # Corresponding target: step 10\n      assert np.array_equal(targets[0], data[10])\n      break\n    ```\n\n    Example 3: Temporal regression for many-to-many architectures.\n\n    Consider two arrays of scalar values `X` and `Y`,\n    both of shape `(100,)`. The resulting dataset should consist samples with\n    20 timestamps each. The samples should not overlap.\n    To generate a dataset that uses the current timestamp\n    to predict the corresponding target timestep, you would use:\n\n    ```python\n    X = np.arange(100)\n    Y = X*2\n\n    sample_length = 20\n    input_dataset = timeseries_dataset_from_array(\n        X, None, sequence_length=sample_length, sequence_stride=sample_length)\n    target_dataset = timeseries_dataset_from_array(\n        Y, None, sequence_length=sample_length, sequence_stride=sample_length)\n\n    for batch in zip(input_dataset, target_dataset):\n        inputs, targets = batch\n        assert np.array_equal(inputs[0], X[:sample_length])\n\n        # second sample equals output timestamps 20-40\n        assert np.array_equal(targets[1], Y[sample_length:2*sample_length])\n        break\n    ```\n    \"\"\"\n    if start_index:\n        if start_index < 0:\n            raise ValueError(f'`start_index` must be 0 or greater. Received: start_index={start_index}')\n        if start_index >= len(data):\n            raise ValueError(f'`start_index` must be lower than the length of the data. Received: start_index={start_index}, for data of length {len(data)}')\n    if end_index:\n        if start_index and end_index <= start_index:\n            raise ValueError(f'`end_index` must be higher than `start_index`. Received: start_index={start_index}, and end_index={end_index} ')\n        if end_index >= len(data):\n            raise ValueError(f'`end_index` must be lower than the length of the data. Received: end_index={end_index}, for data of length {len(data)}')\n        if end_index <= 0:\n            raise ValueError(f'`end_index` must be higher than 0. Received: end_index={end_index}')\n    if sampling_rate <= 0:\n        raise ValueError(f'`sampling_rate` must be higher than 0. Received: sampling_rate={sampling_rate}')\n    if sampling_rate >= len(data):\n        raise ValueError(f'`sampling_rate` must be lower than the length of the data. Received: sampling_rate={sampling_rate}, for data of length {len(data)}')\n    if sequence_stride <= 0:\n        raise ValueError(f'`sequence_stride` must be higher than 0. Received: sequence_stride={sequence_stride}')\n    if sequence_stride >= len(data):\n        raise ValueError(f'`sequence_stride` must be lower than the length of the data. Received: sequence_stride={sequence_stride}, for data of length {len(data)}')\n    if start_index is None:\n        start_index = 0\n    if end_index is None:\n        end_index = len(data)\n    num_seqs = end_index - start_index - (sequence_length - 1) * sampling_rate\n    if targets is not None:\n        num_seqs = min(num_seqs, len(targets))\n    if num_seqs < 2147483647:\n        index_dtype = 'int32'\n    else:\n        index_dtype = 'int64'\n    start_positions = np.arange(0, num_seqs, sequence_stride, dtype=index_dtype)\n    if shuffle:\n        if seed is None:\n            seed = np.random.randint(1000000.0)\n        rng = np.random.RandomState(seed)\n        rng.shuffle(start_positions)\n    sequence_length = tf.cast(sequence_length, dtype=index_dtype)\n    sampling_rate = tf.cast(sampling_rate, dtype=index_dtype)\n    positions_ds = tf.data.Dataset.from_tensors(start_positions).repeat()\n    indices = tf.data.Dataset.zip((tf.data.Dataset.range(len(start_positions)), positions_ds)).map(lambda i, positions: tf.range(positions[i], positions[i] + sequence_length * sampling_rate, sampling_rate), num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = sequences_from_indices(data, indices, start_index, end_index)\n    if targets is not None:\n        indices = tf.data.Dataset.zip((tf.data.Dataset.range(len(start_positions)), positions_ds)).map(lambda i, positions: positions[i], num_parallel_calls=tf.data.AUTOTUNE)\n        target_ds = sequences_from_indices(targets, indices, start_index, end_index)\n        dataset = tf.data.Dataset.zip((dataset, target_ds))\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    if batch_size is not None:\n        if shuffle:\n            dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)\n        dataset = dataset.batch(batch_size)\n    elif shuffle:\n        dataset = dataset.shuffle(buffer_size=1024, seed=seed)\n    return dataset",
        "mutated": [
            "@keras_export(['keras.utils.timeseries_dataset_from_array', 'keras.preprocessing.timeseries_dataset_from_array'])\ndef timeseries_dataset_from_array(data, targets, sequence_length, sequence_stride=1, sampling_rate=1, batch_size=128, shuffle=False, seed=None, start_index=None, end_index=None):\n    if False:\n        i = 10\n    \"Creates a dataset of sliding windows over a timeseries provided as array.\\n\\n    This function takes in a sequence of data-points gathered at\\n    equal intervals, along with time series parameters such as\\n    length of the sequences/windows, spacing between two sequence/windows, etc.,\\n    to produce batches of timeseries inputs and targets.\\n\\n    Args:\\n        data: Numpy array or eager tensor\\n            containing consecutive data points (timesteps).\\n            Axis 0 is expected to be the time dimension.\\n        targets: Targets corresponding to timesteps in `data`.\\n            `targets[i]` should be the target\\n            corresponding to the window that starts at index `i`\\n            (see example 2 below).\\n            Pass `None` if you don't have target data (in this case the dataset\\n            will only yield the input data).\\n        sequence_length: Length of the output sequences\\n            (in number of timesteps).\\n        sequence_stride: Period between successive output sequences.\\n            For stride `s`, output samples would\\n            start at index `data[i]`, `data[i + s]`, `data[i + 2 * s]`, etc.\\n        sampling_rate: Period between successive individual timesteps\\n            within sequences. For rate `r`, timesteps\\n            `data[i], data[i + r], ... data[i + sequence_length]`\\n            are used for creating a sample sequence.\\n        batch_size: Number of timeseries samples in each batch\\n            (except maybe the last one). If `None`, the data will not be batched\\n            (the dataset will yield individual samples).\\n        shuffle: Whether to shuffle output samples,\\n            or instead draw them in chronological order.\\n        seed: Optional int; random seed for shuffling.\\n        start_index: Optional int; data points earlier (exclusive)\\n            than `start_index` will not be used\\n            in the output sequences. This is useful to reserve part of the\\n            data for test or validation.\\n        end_index: Optional int; data points later (exclusive) than `end_index`\\n            will not be used in the output sequences.\\n            This is useful to reserve part of the data for test or validation.\\n\\n    Returns:\\n\\n    A `tf.data.Dataset` instance. If `targets` was passed, the dataset yields\\n    tuple `(batch_of_sequences, batch_of_targets)`. If not, the dataset yields\\n    only `batch_of_sequences`.\\n\\n    Example 1:\\n\\n    Consider indices `[0, 1, ... 98]`.\\n    With `sequence_length=10,  sampling_rate=2, sequence_stride=3`,\\n    `shuffle=False`, the dataset will yield batches of sequences\\n    composed of the following indices:\\n\\n    ```\\n    First sequence:  [0  2  4  6  8 10 12 14 16 18]\\n    Second sequence: [3  5  7  9 11 13 15 17 19 21]\\n    Third sequence:  [6  8 10 12 14 16 18 20 22 24]\\n    ...\\n    Last sequence:   [78 80 82 84 86 88 90 92 94 96]\\n    ```\\n\\n    In this case the last 2 data points are discarded since no full sequence\\n    can be generated to include them (the next sequence would have started\\n    at index 81, and thus its last step would have gone over 98).\\n\\n    Example 2: Temporal regression.\\n\\n    Consider an array `data` of scalar values, of shape `(steps,)`.\\n    To generate a dataset that uses the past 10\\n    timesteps to predict the next timestep, you would use:\\n\\n    ```python\\n    input_data = data[:-10]\\n    targets = data[10:]\\n    dataset = timeseries_dataset_from_array(\\n        input_data, targets, sequence_length=10)\\n    for batch in dataset:\\n      inputs, targets = batch\\n      assert np.array_equal(inputs[0], data[:10])  # First sequence: steps [0-9]\\n      # Corresponding target: step 10\\n      assert np.array_equal(targets[0], data[10])\\n      break\\n    ```\\n\\n    Example 3: Temporal regression for many-to-many architectures.\\n\\n    Consider two arrays of scalar values `X` and `Y`,\\n    both of shape `(100,)`. The resulting dataset should consist samples with\\n    20 timestamps each. The samples should not overlap.\\n    To generate a dataset that uses the current timestamp\\n    to predict the corresponding target timestep, you would use:\\n\\n    ```python\\n    X = np.arange(100)\\n    Y = X*2\\n\\n    sample_length = 20\\n    input_dataset = timeseries_dataset_from_array(\\n        X, None, sequence_length=sample_length, sequence_stride=sample_length)\\n    target_dataset = timeseries_dataset_from_array(\\n        Y, None, sequence_length=sample_length, sequence_stride=sample_length)\\n\\n    for batch in zip(input_dataset, target_dataset):\\n        inputs, targets = batch\\n        assert np.array_equal(inputs[0], X[:sample_length])\\n\\n        # second sample equals output timestamps 20-40\\n        assert np.array_equal(targets[1], Y[sample_length:2*sample_length])\\n        break\\n    ```\\n    \"\n    if start_index:\n        if start_index < 0:\n            raise ValueError(f'`start_index` must be 0 or greater. Received: start_index={start_index}')\n        if start_index >= len(data):\n            raise ValueError(f'`start_index` must be lower than the length of the data. Received: start_index={start_index}, for data of length {len(data)}')\n    if end_index:\n        if start_index and end_index <= start_index:\n            raise ValueError(f'`end_index` must be higher than `start_index`. Received: start_index={start_index}, and end_index={end_index} ')\n        if end_index >= len(data):\n            raise ValueError(f'`end_index` must be lower than the length of the data. Received: end_index={end_index}, for data of length {len(data)}')\n        if end_index <= 0:\n            raise ValueError(f'`end_index` must be higher than 0. Received: end_index={end_index}')\n    if sampling_rate <= 0:\n        raise ValueError(f'`sampling_rate` must be higher than 0. Received: sampling_rate={sampling_rate}')\n    if sampling_rate >= len(data):\n        raise ValueError(f'`sampling_rate` must be lower than the length of the data. Received: sampling_rate={sampling_rate}, for data of length {len(data)}')\n    if sequence_stride <= 0:\n        raise ValueError(f'`sequence_stride` must be higher than 0. Received: sequence_stride={sequence_stride}')\n    if sequence_stride >= len(data):\n        raise ValueError(f'`sequence_stride` must be lower than the length of the data. Received: sequence_stride={sequence_stride}, for data of length {len(data)}')\n    if start_index is None:\n        start_index = 0\n    if end_index is None:\n        end_index = len(data)\n    num_seqs = end_index - start_index - (sequence_length - 1) * sampling_rate\n    if targets is not None:\n        num_seqs = min(num_seqs, len(targets))\n    if num_seqs < 2147483647:\n        index_dtype = 'int32'\n    else:\n        index_dtype = 'int64'\n    start_positions = np.arange(0, num_seqs, sequence_stride, dtype=index_dtype)\n    if shuffle:\n        if seed is None:\n            seed = np.random.randint(1000000.0)\n        rng = np.random.RandomState(seed)\n        rng.shuffle(start_positions)\n    sequence_length = tf.cast(sequence_length, dtype=index_dtype)\n    sampling_rate = tf.cast(sampling_rate, dtype=index_dtype)\n    positions_ds = tf.data.Dataset.from_tensors(start_positions).repeat()\n    indices = tf.data.Dataset.zip((tf.data.Dataset.range(len(start_positions)), positions_ds)).map(lambda i, positions: tf.range(positions[i], positions[i] + sequence_length * sampling_rate, sampling_rate), num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = sequences_from_indices(data, indices, start_index, end_index)\n    if targets is not None:\n        indices = tf.data.Dataset.zip((tf.data.Dataset.range(len(start_positions)), positions_ds)).map(lambda i, positions: positions[i], num_parallel_calls=tf.data.AUTOTUNE)\n        target_ds = sequences_from_indices(targets, indices, start_index, end_index)\n        dataset = tf.data.Dataset.zip((dataset, target_ds))\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    if batch_size is not None:\n        if shuffle:\n            dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)\n        dataset = dataset.batch(batch_size)\n    elif shuffle:\n        dataset = dataset.shuffle(buffer_size=1024, seed=seed)\n    return dataset",
            "@keras_export(['keras.utils.timeseries_dataset_from_array', 'keras.preprocessing.timeseries_dataset_from_array'])\ndef timeseries_dataset_from_array(data, targets, sequence_length, sequence_stride=1, sampling_rate=1, batch_size=128, shuffle=False, seed=None, start_index=None, end_index=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Creates a dataset of sliding windows over a timeseries provided as array.\\n\\n    This function takes in a sequence of data-points gathered at\\n    equal intervals, along with time series parameters such as\\n    length of the sequences/windows, spacing between two sequence/windows, etc.,\\n    to produce batches of timeseries inputs and targets.\\n\\n    Args:\\n        data: Numpy array or eager tensor\\n            containing consecutive data points (timesteps).\\n            Axis 0 is expected to be the time dimension.\\n        targets: Targets corresponding to timesteps in `data`.\\n            `targets[i]` should be the target\\n            corresponding to the window that starts at index `i`\\n            (see example 2 below).\\n            Pass `None` if you don't have target data (in this case the dataset\\n            will only yield the input data).\\n        sequence_length: Length of the output sequences\\n            (in number of timesteps).\\n        sequence_stride: Period between successive output sequences.\\n            For stride `s`, output samples would\\n            start at index `data[i]`, `data[i + s]`, `data[i + 2 * s]`, etc.\\n        sampling_rate: Period between successive individual timesteps\\n            within sequences. For rate `r`, timesteps\\n            `data[i], data[i + r], ... data[i + sequence_length]`\\n            are used for creating a sample sequence.\\n        batch_size: Number of timeseries samples in each batch\\n            (except maybe the last one). If `None`, the data will not be batched\\n            (the dataset will yield individual samples).\\n        shuffle: Whether to shuffle output samples,\\n            or instead draw them in chronological order.\\n        seed: Optional int; random seed for shuffling.\\n        start_index: Optional int; data points earlier (exclusive)\\n            than `start_index` will not be used\\n            in the output sequences. This is useful to reserve part of the\\n            data for test or validation.\\n        end_index: Optional int; data points later (exclusive) than `end_index`\\n            will not be used in the output sequences.\\n            This is useful to reserve part of the data for test or validation.\\n\\n    Returns:\\n\\n    A `tf.data.Dataset` instance. If `targets` was passed, the dataset yields\\n    tuple `(batch_of_sequences, batch_of_targets)`. If not, the dataset yields\\n    only `batch_of_sequences`.\\n\\n    Example 1:\\n\\n    Consider indices `[0, 1, ... 98]`.\\n    With `sequence_length=10,  sampling_rate=2, sequence_stride=3`,\\n    `shuffle=False`, the dataset will yield batches of sequences\\n    composed of the following indices:\\n\\n    ```\\n    First sequence:  [0  2  4  6  8 10 12 14 16 18]\\n    Second sequence: [3  5  7  9 11 13 15 17 19 21]\\n    Third sequence:  [6  8 10 12 14 16 18 20 22 24]\\n    ...\\n    Last sequence:   [78 80 82 84 86 88 90 92 94 96]\\n    ```\\n\\n    In this case the last 2 data points are discarded since no full sequence\\n    can be generated to include them (the next sequence would have started\\n    at index 81, and thus its last step would have gone over 98).\\n\\n    Example 2: Temporal regression.\\n\\n    Consider an array `data` of scalar values, of shape `(steps,)`.\\n    To generate a dataset that uses the past 10\\n    timesteps to predict the next timestep, you would use:\\n\\n    ```python\\n    input_data = data[:-10]\\n    targets = data[10:]\\n    dataset = timeseries_dataset_from_array(\\n        input_data, targets, sequence_length=10)\\n    for batch in dataset:\\n      inputs, targets = batch\\n      assert np.array_equal(inputs[0], data[:10])  # First sequence: steps [0-9]\\n      # Corresponding target: step 10\\n      assert np.array_equal(targets[0], data[10])\\n      break\\n    ```\\n\\n    Example 3: Temporal regression for many-to-many architectures.\\n\\n    Consider two arrays of scalar values `X` and `Y`,\\n    both of shape `(100,)`. The resulting dataset should consist samples with\\n    20 timestamps each. The samples should not overlap.\\n    To generate a dataset that uses the current timestamp\\n    to predict the corresponding target timestep, you would use:\\n\\n    ```python\\n    X = np.arange(100)\\n    Y = X*2\\n\\n    sample_length = 20\\n    input_dataset = timeseries_dataset_from_array(\\n        X, None, sequence_length=sample_length, sequence_stride=sample_length)\\n    target_dataset = timeseries_dataset_from_array(\\n        Y, None, sequence_length=sample_length, sequence_stride=sample_length)\\n\\n    for batch in zip(input_dataset, target_dataset):\\n        inputs, targets = batch\\n        assert np.array_equal(inputs[0], X[:sample_length])\\n\\n        # second sample equals output timestamps 20-40\\n        assert np.array_equal(targets[1], Y[sample_length:2*sample_length])\\n        break\\n    ```\\n    \"\n    if start_index:\n        if start_index < 0:\n            raise ValueError(f'`start_index` must be 0 or greater. Received: start_index={start_index}')\n        if start_index >= len(data):\n            raise ValueError(f'`start_index` must be lower than the length of the data. Received: start_index={start_index}, for data of length {len(data)}')\n    if end_index:\n        if start_index and end_index <= start_index:\n            raise ValueError(f'`end_index` must be higher than `start_index`. Received: start_index={start_index}, and end_index={end_index} ')\n        if end_index >= len(data):\n            raise ValueError(f'`end_index` must be lower than the length of the data. Received: end_index={end_index}, for data of length {len(data)}')\n        if end_index <= 0:\n            raise ValueError(f'`end_index` must be higher than 0. Received: end_index={end_index}')\n    if sampling_rate <= 0:\n        raise ValueError(f'`sampling_rate` must be higher than 0. Received: sampling_rate={sampling_rate}')\n    if sampling_rate >= len(data):\n        raise ValueError(f'`sampling_rate` must be lower than the length of the data. Received: sampling_rate={sampling_rate}, for data of length {len(data)}')\n    if sequence_stride <= 0:\n        raise ValueError(f'`sequence_stride` must be higher than 0. Received: sequence_stride={sequence_stride}')\n    if sequence_stride >= len(data):\n        raise ValueError(f'`sequence_stride` must be lower than the length of the data. Received: sequence_stride={sequence_stride}, for data of length {len(data)}')\n    if start_index is None:\n        start_index = 0\n    if end_index is None:\n        end_index = len(data)\n    num_seqs = end_index - start_index - (sequence_length - 1) * sampling_rate\n    if targets is not None:\n        num_seqs = min(num_seqs, len(targets))\n    if num_seqs < 2147483647:\n        index_dtype = 'int32'\n    else:\n        index_dtype = 'int64'\n    start_positions = np.arange(0, num_seqs, sequence_stride, dtype=index_dtype)\n    if shuffle:\n        if seed is None:\n            seed = np.random.randint(1000000.0)\n        rng = np.random.RandomState(seed)\n        rng.shuffle(start_positions)\n    sequence_length = tf.cast(sequence_length, dtype=index_dtype)\n    sampling_rate = tf.cast(sampling_rate, dtype=index_dtype)\n    positions_ds = tf.data.Dataset.from_tensors(start_positions).repeat()\n    indices = tf.data.Dataset.zip((tf.data.Dataset.range(len(start_positions)), positions_ds)).map(lambda i, positions: tf.range(positions[i], positions[i] + sequence_length * sampling_rate, sampling_rate), num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = sequences_from_indices(data, indices, start_index, end_index)\n    if targets is not None:\n        indices = tf.data.Dataset.zip((tf.data.Dataset.range(len(start_positions)), positions_ds)).map(lambda i, positions: positions[i], num_parallel_calls=tf.data.AUTOTUNE)\n        target_ds = sequences_from_indices(targets, indices, start_index, end_index)\n        dataset = tf.data.Dataset.zip((dataset, target_ds))\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    if batch_size is not None:\n        if shuffle:\n            dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)\n        dataset = dataset.batch(batch_size)\n    elif shuffle:\n        dataset = dataset.shuffle(buffer_size=1024, seed=seed)\n    return dataset",
            "@keras_export(['keras.utils.timeseries_dataset_from_array', 'keras.preprocessing.timeseries_dataset_from_array'])\ndef timeseries_dataset_from_array(data, targets, sequence_length, sequence_stride=1, sampling_rate=1, batch_size=128, shuffle=False, seed=None, start_index=None, end_index=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Creates a dataset of sliding windows over a timeseries provided as array.\\n\\n    This function takes in a sequence of data-points gathered at\\n    equal intervals, along with time series parameters such as\\n    length of the sequences/windows, spacing between two sequence/windows, etc.,\\n    to produce batches of timeseries inputs and targets.\\n\\n    Args:\\n        data: Numpy array or eager tensor\\n            containing consecutive data points (timesteps).\\n            Axis 0 is expected to be the time dimension.\\n        targets: Targets corresponding to timesteps in `data`.\\n            `targets[i]` should be the target\\n            corresponding to the window that starts at index `i`\\n            (see example 2 below).\\n            Pass `None` if you don't have target data (in this case the dataset\\n            will only yield the input data).\\n        sequence_length: Length of the output sequences\\n            (in number of timesteps).\\n        sequence_stride: Period between successive output sequences.\\n            For stride `s`, output samples would\\n            start at index `data[i]`, `data[i + s]`, `data[i + 2 * s]`, etc.\\n        sampling_rate: Period between successive individual timesteps\\n            within sequences. For rate `r`, timesteps\\n            `data[i], data[i + r], ... data[i + sequence_length]`\\n            are used for creating a sample sequence.\\n        batch_size: Number of timeseries samples in each batch\\n            (except maybe the last one). If `None`, the data will not be batched\\n            (the dataset will yield individual samples).\\n        shuffle: Whether to shuffle output samples,\\n            or instead draw them in chronological order.\\n        seed: Optional int; random seed for shuffling.\\n        start_index: Optional int; data points earlier (exclusive)\\n            than `start_index` will not be used\\n            in the output sequences. This is useful to reserve part of the\\n            data for test or validation.\\n        end_index: Optional int; data points later (exclusive) than `end_index`\\n            will not be used in the output sequences.\\n            This is useful to reserve part of the data for test or validation.\\n\\n    Returns:\\n\\n    A `tf.data.Dataset` instance. If `targets` was passed, the dataset yields\\n    tuple `(batch_of_sequences, batch_of_targets)`. If not, the dataset yields\\n    only `batch_of_sequences`.\\n\\n    Example 1:\\n\\n    Consider indices `[0, 1, ... 98]`.\\n    With `sequence_length=10,  sampling_rate=2, sequence_stride=3`,\\n    `shuffle=False`, the dataset will yield batches of sequences\\n    composed of the following indices:\\n\\n    ```\\n    First sequence:  [0  2  4  6  8 10 12 14 16 18]\\n    Second sequence: [3  5  7  9 11 13 15 17 19 21]\\n    Third sequence:  [6  8 10 12 14 16 18 20 22 24]\\n    ...\\n    Last sequence:   [78 80 82 84 86 88 90 92 94 96]\\n    ```\\n\\n    In this case the last 2 data points are discarded since no full sequence\\n    can be generated to include them (the next sequence would have started\\n    at index 81, and thus its last step would have gone over 98).\\n\\n    Example 2: Temporal regression.\\n\\n    Consider an array `data` of scalar values, of shape `(steps,)`.\\n    To generate a dataset that uses the past 10\\n    timesteps to predict the next timestep, you would use:\\n\\n    ```python\\n    input_data = data[:-10]\\n    targets = data[10:]\\n    dataset = timeseries_dataset_from_array(\\n        input_data, targets, sequence_length=10)\\n    for batch in dataset:\\n      inputs, targets = batch\\n      assert np.array_equal(inputs[0], data[:10])  # First sequence: steps [0-9]\\n      # Corresponding target: step 10\\n      assert np.array_equal(targets[0], data[10])\\n      break\\n    ```\\n\\n    Example 3: Temporal regression for many-to-many architectures.\\n\\n    Consider two arrays of scalar values `X` and `Y`,\\n    both of shape `(100,)`. The resulting dataset should consist samples with\\n    20 timestamps each. The samples should not overlap.\\n    To generate a dataset that uses the current timestamp\\n    to predict the corresponding target timestep, you would use:\\n\\n    ```python\\n    X = np.arange(100)\\n    Y = X*2\\n\\n    sample_length = 20\\n    input_dataset = timeseries_dataset_from_array(\\n        X, None, sequence_length=sample_length, sequence_stride=sample_length)\\n    target_dataset = timeseries_dataset_from_array(\\n        Y, None, sequence_length=sample_length, sequence_stride=sample_length)\\n\\n    for batch in zip(input_dataset, target_dataset):\\n        inputs, targets = batch\\n        assert np.array_equal(inputs[0], X[:sample_length])\\n\\n        # second sample equals output timestamps 20-40\\n        assert np.array_equal(targets[1], Y[sample_length:2*sample_length])\\n        break\\n    ```\\n    \"\n    if start_index:\n        if start_index < 0:\n            raise ValueError(f'`start_index` must be 0 or greater. Received: start_index={start_index}')\n        if start_index >= len(data):\n            raise ValueError(f'`start_index` must be lower than the length of the data. Received: start_index={start_index}, for data of length {len(data)}')\n    if end_index:\n        if start_index and end_index <= start_index:\n            raise ValueError(f'`end_index` must be higher than `start_index`. Received: start_index={start_index}, and end_index={end_index} ')\n        if end_index >= len(data):\n            raise ValueError(f'`end_index` must be lower than the length of the data. Received: end_index={end_index}, for data of length {len(data)}')\n        if end_index <= 0:\n            raise ValueError(f'`end_index` must be higher than 0. Received: end_index={end_index}')\n    if sampling_rate <= 0:\n        raise ValueError(f'`sampling_rate` must be higher than 0. Received: sampling_rate={sampling_rate}')\n    if sampling_rate >= len(data):\n        raise ValueError(f'`sampling_rate` must be lower than the length of the data. Received: sampling_rate={sampling_rate}, for data of length {len(data)}')\n    if sequence_stride <= 0:\n        raise ValueError(f'`sequence_stride` must be higher than 0. Received: sequence_stride={sequence_stride}')\n    if sequence_stride >= len(data):\n        raise ValueError(f'`sequence_stride` must be lower than the length of the data. Received: sequence_stride={sequence_stride}, for data of length {len(data)}')\n    if start_index is None:\n        start_index = 0\n    if end_index is None:\n        end_index = len(data)\n    num_seqs = end_index - start_index - (sequence_length - 1) * sampling_rate\n    if targets is not None:\n        num_seqs = min(num_seqs, len(targets))\n    if num_seqs < 2147483647:\n        index_dtype = 'int32'\n    else:\n        index_dtype = 'int64'\n    start_positions = np.arange(0, num_seqs, sequence_stride, dtype=index_dtype)\n    if shuffle:\n        if seed is None:\n            seed = np.random.randint(1000000.0)\n        rng = np.random.RandomState(seed)\n        rng.shuffle(start_positions)\n    sequence_length = tf.cast(sequence_length, dtype=index_dtype)\n    sampling_rate = tf.cast(sampling_rate, dtype=index_dtype)\n    positions_ds = tf.data.Dataset.from_tensors(start_positions).repeat()\n    indices = tf.data.Dataset.zip((tf.data.Dataset.range(len(start_positions)), positions_ds)).map(lambda i, positions: tf.range(positions[i], positions[i] + sequence_length * sampling_rate, sampling_rate), num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = sequences_from_indices(data, indices, start_index, end_index)\n    if targets is not None:\n        indices = tf.data.Dataset.zip((tf.data.Dataset.range(len(start_positions)), positions_ds)).map(lambda i, positions: positions[i], num_parallel_calls=tf.data.AUTOTUNE)\n        target_ds = sequences_from_indices(targets, indices, start_index, end_index)\n        dataset = tf.data.Dataset.zip((dataset, target_ds))\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    if batch_size is not None:\n        if shuffle:\n            dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)\n        dataset = dataset.batch(batch_size)\n    elif shuffle:\n        dataset = dataset.shuffle(buffer_size=1024, seed=seed)\n    return dataset",
            "@keras_export(['keras.utils.timeseries_dataset_from_array', 'keras.preprocessing.timeseries_dataset_from_array'])\ndef timeseries_dataset_from_array(data, targets, sequence_length, sequence_stride=1, sampling_rate=1, batch_size=128, shuffle=False, seed=None, start_index=None, end_index=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Creates a dataset of sliding windows over a timeseries provided as array.\\n\\n    This function takes in a sequence of data-points gathered at\\n    equal intervals, along with time series parameters such as\\n    length of the sequences/windows, spacing between two sequence/windows, etc.,\\n    to produce batches of timeseries inputs and targets.\\n\\n    Args:\\n        data: Numpy array or eager tensor\\n            containing consecutive data points (timesteps).\\n            Axis 0 is expected to be the time dimension.\\n        targets: Targets corresponding to timesteps in `data`.\\n            `targets[i]` should be the target\\n            corresponding to the window that starts at index `i`\\n            (see example 2 below).\\n            Pass `None` if you don't have target data (in this case the dataset\\n            will only yield the input data).\\n        sequence_length: Length of the output sequences\\n            (in number of timesteps).\\n        sequence_stride: Period between successive output sequences.\\n            For stride `s`, output samples would\\n            start at index `data[i]`, `data[i + s]`, `data[i + 2 * s]`, etc.\\n        sampling_rate: Period between successive individual timesteps\\n            within sequences. For rate `r`, timesteps\\n            `data[i], data[i + r], ... data[i + sequence_length]`\\n            are used for creating a sample sequence.\\n        batch_size: Number of timeseries samples in each batch\\n            (except maybe the last one). If `None`, the data will not be batched\\n            (the dataset will yield individual samples).\\n        shuffle: Whether to shuffle output samples,\\n            or instead draw them in chronological order.\\n        seed: Optional int; random seed for shuffling.\\n        start_index: Optional int; data points earlier (exclusive)\\n            than `start_index` will not be used\\n            in the output sequences. This is useful to reserve part of the\\n            data for test or validation.\\n        end_index: Optional int; data points later (exclusive) than `end_index`\\n            will not be used in the output sequences.\\n            This is useful to reserve part of the data for test or validation.\\n\\n    Returns:\\n\\n    A `tf.data.Dataset` instance. If `targets` was passed, the dataset yields\\n    tuple `(batch_of_sequences, batch_of_targets)`. If not, the dataset yields\\n    only `batch_of_sequences`.\\n\\n    Example 1:\\n\\n    Consider indices `[0, 1, ... 98]`.\\n    With `sequence_length=10,  sampling_rate=2, sequence_stride=3`,\\n    `shuffle=False`, the dataset will yield batches of sequences\\n    composed of the following indices:\\n\\n    ```\\n    First sequence:  [0  2  4  6  8 10 12 14 16 18]\\n    Second sequence: [3  5  7  9 11 13 15 17 19 21]\\n    Third sequence:  [6  8 10 12 14 16 18 20 22 24]\\n    ...\\n    Last sequence:   [78 80 82 84 86 88 90 92 94 96]\\n    ```\\n\\n    In this case the last 2 data points are discarded since no full sequence\\n    can be generated to include them (the next sequence would have started\\n    at index 81, and thus its last step would have gone over 98).\\n\\n    Example 2: Temporal regression.\\n\\n    Consider an array `data` of scalar values, of shape `(steps,)`.\\n    To generate a dataset that uses the past 10\\n    timesteps to predict the next timestep, you would use:\\n\\n    ```python\\n    input_data = data[:-10]\\n    targets = data[10:]\\n    dataset = timeseries_dataset_from_array(\\n        input_data, targets, sequence_length=10)\\n    for batch in dataset:\\n      inputs, targets = batch\\n      assert np.array_equal(inputs[0], data[:10])  # First sequence: steps [0-9]\\n      # Corresponding target: step 10\\n      assert np.array_equal(targets[0], data[10])\\n      break\\n    ```\\n\\n    Example 3: Temporal regression for many-to-many architectures.\\n\\n    Consider two arrays of scalar values `X` and `Y`,\\n    both of shape `(100,)`. The resulting dataset should consist samples with\\n    20 timestamps each. The samples should not overlap.\\n    To generate a dataset that uses the current timestamp\\n    to predict the corresponding target timestep, you would use:\\n\\n    ```python\\n    X = np.arange(100)\\n    Y = X*2\\n\\n    sample_length = 20\\n    input_dataset = timeseries_dataset_from_array(\\n        X, None, sequence_length=sample_length, sequence_stride=sample_length)\\n    target_dataset = timeseries_dataset_from_array(\\n        Y, None, sequence_length=sample_length, sequence_stride=sample_length)\\n\\n    for batch in zip(input_dataset, target_dataset):\\n        inputs, targets = batch\\n        assert np.array_equal(inputs[0], X[:sample_length])\\n\\n        # second sample equals output timestamps 20-40\\n        assert np.array_equal(targets[1], Y[sample_length:2*sample_length])\\n        break\\n    ```\\n    \"\n    if start_index:\n        if start_index < 0:\n            raise ValueError(f'`start_index` must be 0 or greater. Received: start_index={start_index}')\n        if start_index >= len(data):\n            raise ValueError(f'`start_index` must be lower than the length of the data. Received: start_index={start_index}, for data of length {len(data)}')\n    if end_index:\n        if start_index and end_index <= start_index:\n            raise ValueError(f'`end_index` must be higher than `start_index`. Received: start_index={start_index}, and end_index={end_index} ')\n        if end_index >= len(data):\n            raise ValueError(f'`end_index` must be lower than the length of the data. Received: end_index={end_index}, for data of length {len(data)}')\n        if end_index <= 0:\n            raise ValueError(f'`end_index` must be higher than 0. Received: end_index={end_index}')\n    if sampling_rate <= 0:\n        raise ValueError(f'`sampling_rate` must be higher than 0. Received: sampling_rate={sampling_rate}')\n    if sampling_rate >= len(data):\n        raise ValueError(f'`sampling_rate` must be lower than the length of the data. Received: sampling_rate={sampling_rate}, for data of length {len(data)}')\n    if sequence_stride <= 0:\n        raise ValueError(f'`sequence_stride` must be higher than 0. Received: sequence_stride={sequence_stride}')\n    if sequence_stride >= len(data):\n        raise ValueError(f'`sequence_stride` must be lower than the length of the data. Received: sequence_stride={sequence_stride}, for data of length {len(data)}')\n    if start_index is None:\n        start_index = 0\n    if end_index is None:\n        end_index = len(data)\n    num_seqs = end_index - start_index - (sequence_length - 1) * sampling_rate\n    if targets is not None:\n        num_seqs = min(num_seqs, len(targets))\n    if num_seqs < 2147483647:\n        index_dtype = 'int32'\n    else:\n        index_dtype = 'int64'\n    start_positions = np.arange(0, num_seqs, sequence_stride, dtype=index_dtype)\n    if shuffle:\n        if seed is None:\n            seed = np.random.randint(1000000.0)\n        rng = np.random.RandomState(seed)\n        rng.shuffle(start_positions)\n    sequence_length = tf.cast(sequence_length, dtype=index_dtype)\n    sampling_rate = tf.cast(sampling_rate, dtype=index_dtype)\n    positions_ds = tf.data.Dataset.from_tensors(start_positions).repeat()\n    indices = tf.data.Dataset.zip((tf.data.Dataset.range(len(start_positions)), positions_ds)).map(lambda i, positions: tf.range(positions[i], positions[i] + sequence_length * sampling_rate, sampling_rate), num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = sequences_from_indices(data, indices, start_index, end_index)\n    if targets is not None:\n        indices = tf.data.Dataset.zip((tf.data.Dataset.range(len(start_positions)), positions_ds)).map(lambda i, positions: positions[i], num_parallel_calls=tf.data.AUTOTUNE)\n        target_ds = sequences_from_indices(targets, indices, start_index, end_index)\n        dataset = tf.data.Dataset.zip((dataset, target_ds))\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    if batch_size is not None:\n        if shuffle:\n            dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)\n        dataset = dataset.batch(batch_size)\n    elif shuffle:\n        dataset = dataset.shuffle(buffer_size=1024, seed=seed)\n    return dataset",
            "@keras_export(['keras.utils.timeseries_dataset_from_array', 'keras.preprocessing.timeseries_dataset_from_array'])\ndef timeseries_dataset_from_array(data, targets, sequence_length, sequence_stride=1, sampling_rate=1, batch_size=128, shuffle=False, seed=None, start_index=None, end_index=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Creates a dataset of sliding windows over a timeseries provided as array.\\n\\n    This function takes in a sequence of data-points gathered at\\n    equal intervals, along with time series parameters such as\\n    length of the sequences/windows, spacing between two sequence/windows, etc.,\\n    to produce batches of timeseries inputs and targets.\\n\\n    Args:\\n        data: Numpy array or eager tensor\\n            containing consecutive data points (timesteps).\\n            Axis 0 is expected to be the time dimension.\\n        targets: Targets corresponding to timesteps in `data`.\\n            `targets[i]` should be the target\\n            corresponding to the window that starts at index `i`\\n            (see example 2 below).\\n            Pass `None` if you don't have target data (in this case the dataset\\n            will only yield the input data).\\n        sequence_length: Length of the output sequences\\n            (in number of timesteps).\\n        sequence_stride: Period between successive output sequences.\\n            For stride `s`, output samples would\\n            start at index `data[i]`, `data[i + s]`, `data[i + 2 * s]`, etc.\\n        sampling_rate: Period between successive individual timesteps\\n            within sequences. For rate `r`, timesteps\\n            `data[i], data[i + r], ... data[i + sequence_length]`\\n            are used for creating a sample sequence.\\n        batch_size: Number of timeseries samples in each batch\\n            (except maybe the last one). If `None`, the data will not be batched\\n            (the dataset will yield individual samples).\\n        shuffle: Whether to shuffle output samples,\\n            or instead draw them in chronological order.\\n        seed: Optional int; random seed for shuffling.\\n        start_index: Optional int; data points earlier (exclusive)\\n            than `start_index` will not be used\\n            in the output sequences. This is useful to reserve part of the\\n            data for test or validation.\\n        end_index: Optional int; data points later (exclusive) than `end_index`\\n            will not be used in the output sequences.\\n            This is useful to reserve part of the data for test or validation.\\n\\n    Returns:\\n\\n    A `tf.data.Dataset` instance. If `targets` was passed, the dataset yields\\n    tuple `(batch_of_sequences, batch_of_targets)`. If not, the dataset yields\\n    only `batch_of_sequences`.\\n\\n    Example 1:\\n\\n    Consider indices `[0, 1, ... 98]`.\\n    With `sequence_length=10,  sampling_rate=2, sequence_stride=3`,\\n    `shuffle=False`, the dataset will yield batches of sequences\\n    composed of the following indices:\\n\\n    ```\\n    First sequence:  [0  2  4  6  8 10 12 14 16 18]\\n    Second sequence: [3  5  7  9 11 13 15 17 19 21]\\n    Third sequence:  [6  8 10 12 14 16 18 20 22 24]\\n    ...\\n    Last sequence:   [78 80 82 84 86 88 90 92 94 96]\\n    ```\\n\\n    In this case the last 2 data points are discarded since no full sequence\\n    can be generated to include them (the next sequence would have started\\n    at index 81, and thus its last step would have gone over 98).\\n\\n    Example 2: Temporal regression.\\n\\n    Consider an array `data` of scalar values, of shape `(steps,)`.\\n    To generate a dataset that uses the past 10\\n    timesteps to predict the next timestep, you would use:\\n\\n    ```python\\n    input_data = data[:-10]\\n    targets = data[10:]\\n    dataset = timeseries_dataset_from_array(\\n        input_data, targets, sequence_length=10)\\n    for batch in dataset:\\n      inputs, targets = batch\\n      assert np.array_equal(inputs[0], data[:10])  # First sequence: steps [0-9]\\n      # Corresponding target: step 10\\n      assert np.array_equal(targets[0], data[10])\\n      break\\n    ```\\n\\n    Example 3: Temporal regression for many-to-many architectures.\\n\\n    Consider two arrays of scalar values `X` and `Y`,\\n    both of shape `(100,)`. The resulting dataset should consist samples with\\n    20 timestamps each. The samples should not overlap.\\n    To generate a dataset that uses the current timestamp\\n    to predict the corresponding target timestep, you would use:\\n\\n    ```python\\n    X = np.arange(100)\\n    Y = X*2\\n\\n    sample_length = 20\\n    input_dataset = timeseries_dataset_from_array(\\n        X, None, sequence_length=sample_length, sequence_stride=sample_length)\\n    target_dataset = timeseries_dataset_from_array(\\n        Y, None, sequence_length=sample_length, sequence_stride=sample_length)\\n\\n    for batch in zip(input_dataset, target_dataset):\\n        inputs, targets = batch\\n        assert np.array_equal(inputs[0], X[:sample_length])\\n\\n        # second sample equals output timestamps 20-40\\n        assert np.array_equal(targets[1], Y[sample_length:2*sample_length])\\n        break\\n    ```\\n    \"\n    if start_index:\n        if start_index < 0:\n            raise ValueError(f'`start_index` must be 0 or greater. Received: start_index={start_index}')\n        if start_index >= len(data):\n            raise ValueError(f'`start_index` must be lower than the length of the data. Received: start_index={start_index}, for data of length {len(data)}')\n    if end_index:\n        if start_index and end_index <= start_index:\n            raise ValueError(f'`end_index` must be higher than `start_index`. Received: start_index={start_index}, and end_index={end_index} ')\n        if end_index >= len(data):\n            raise ValueError(f'`end_index` must be lower than the length of the data. Received: end_index={end_index}, for data of length {len(data)}')\n        if end_index <= 0:\n            raise ValueError(f'`end_index` must be higher than 0. Received: end_index={end_index}')\n    if sampling_rate <= 0:\n        raise ValueError(f'`sampling_rate` must be higher than 0. Received: sampling_rate={sampling_rate}')\n    if sampling_rate >= len(data):\n        raise ValueError(f'`sampling_rate` must be lower than the length of the data. Received: sampling_rate={sampling_rate}, for data of length {len(data)}')\n    if sequence_stride <= 0:\n        raise ValueError(f'`sequence_stride` must be higher than 0. Received: sequence_stride={sequence_stride}')\n    if sequence_stride >= len(data):\n        raise ValueError(f'`sequence_stride` must be lower than the length of the data. Received: sequence_stride={sequence_stride}, for data of length {len(data)}')\n    if start_index is None:\n        start_index = 0\n    if end_index is None:\n        end_index = len(data)\n    num_seqs = end_index - start_index - (sequence_length - 1) * sampling_rate\n    if targets is not None:\n        num_seqs = min(num_seqs, len(targets))\n    if num_seqs < 2147483647:\n        index_dtype = 'int32'\n    else:\n        index_dtype = 'int64'\n    start_positions = np.arange(0, num_seqs, sequence_stride, dtype=index_dtype)\n    if shuffle:\n        if seed is None:\n            seed = np.random.randint(1000000.0)\n        rng = np.random.RandomState(seed)\n        rng.shuffle(start_positions)\n    sequence_length = tf.cast(sequence_length, dtype=index_dtype)\n    sampling_rate = tf.cast(sampling_rate, dtype=index_dtype)\n    positions_ds = tf.data.Dataset.from_tensors(start_positions).repeat()\n    indices = tf.data.Dataset.zip((tf.data.Dataset.range(len(start_positions)), positions_ds)).map(lambda i, positions: tf.range(positions[i], positions[i] + sequence_length * sampling_rate, sampling_rate), num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = sequences_from_indices(data, indices, start_index, end_index)\n    if targets is not None:\n        indices = tf.data.Dataset.zip((tf.data.Dataset.range(len(start_positions)), positions_ds)).map(lambda i, positions: positions[i], num_parallel_calls=tf.data.AUTOTUNE)\n        target_ds = sequences_from_indices(targets, indices, start_index, end_index)\n        dataset = tf.data.Dataset.zip((dataset, target_ds))\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    if batch_size is not None:\n        if shuffle:\n            dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)\n        dataset = dataset.batch(batch_size)\n    elif shuffle:\n        dataset = dataset.shuffle(buffer_size=1024, seed=seed)\n    return dataset"
        ]
    },
    {
        "func_name": "sequences_from_indices",
        "original": "def sequences_from_indices(array, indices_ds, start_index, end_index):\n    dataset = tf.data.Dataset.from_tensors(array[start_index:end_index])\n    dataset = tf.data.Dataset.zip((dataset.repeat(), indices_ds)).map(lambda steps, inds: tf.gather(steps, inds), num_parallel_calls=tf.data.AUTOTUNE)\n    return dataset",
        "mutated": [
            "def sequences_from_indices(array, indices_ds, start_index, end_index):\n    if False:\n        i = 10\n    dataset = tf.data.Dataset.from_tensors(array[start_index:end_index])\n    dataset = tf.data.Dataset.zip((dataset.repeat(), indices_ds)).map(lambda steps, inds: tf.gather(steps, inds), num_parallel_calls=tf.data.AUTOTUNE)\n    return dataset",
            "def sequences_from_indices(array, indices_ds, start_index, end_index):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    dataset = tf.data.Dataset.from_tensors(array[start_index:end_index])\n    dataset = tf.data.Dataset.zip((dataset.repeat(), indices_ds)).map(lambda steps, inds: tf.gather(steps, inds), num_parallel_calls=tf.data.AUTOTUNE)\n    return dataset",
            "def sequences_from_indices(array, indices_ds, start_index, end_index):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    dataset = tf.data.Dataset.from_tensors(array[start_index:end_index])\n    dataset = tf.data.Dataset.zip((dataset.repeat(), indices_ds)).map(lambda steps, inds: tf.gather(steps, inds), num_parallel_calls=tf.data.AUTOTUNE)\n    return dataset",
            "def sequences_from_indices(array, indices_ds, start_index, end_index):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    dataset = tf.data.Dataset.from_tensors(array[start_index:end_index])\n    dataset = tf.data.Dataset.zip((dataset.repeat(), indices_ds)).map(lambda steps, inds: tf.gather(steps, inds), num_parallel_calls=tf.data.AUTOTUNE)\n    return dataset",
            "def sequences_from_indices(array, indices_ds, start_index, end_index):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    dataset = tf.data.Dataset.from_tensors(array[start_index:end_index])\n    dataset = tf.data.Dataset.zip((dataset.repeat(), indices_ds)).map(lambda steps, inds: tf.gather(steps, inds), num_parallel_calls=tf.data.AUTOTUNE)\n    return dataset"
        ]
    }
]