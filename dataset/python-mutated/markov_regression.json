[
    {
        "func_name": "__init__",
        "original": "def __init__(self, endog, k_regimes, trend='c', exog=None, order=0, exog_tvtp=None, switching_trend=True, switching_exog=True, switching_variance=False, dates=None, freq=None, missing='none'):\n    from statsmodels.tools.validation import string_like\n    self.trend = string_like(trend, 'trend', options=('n', 'c', 'ct', 't'))\n    self.switching_trend = switching_trend\n    self.switching_exog = switching_exog\n    self.switching_variance = switching_variance\n    (self.k_exog, exog) = markov_switching.prepare_exog(exog)\n    nobs = len(endog)\n    self.k_trend = 0\n    self._k_exog = self.k_exog\n    trend_exog = None\n    if trend == 'c':\n        trend_exog = np.ones((nobs, 1))\n        self.k_trend = 1\n    elif trend == 't':\n        trend_exog = (np.arange(nobs) + 1)[:, np.newaxis]\n        self.k_trend = 1\n    elif trend == 'ct':\n        trend_exog = np.c_[np.ones((nobs, 1)), (np.arange(nobs) + 1)[:, np.newaxis]]\n        self.k_trend = 2\n    if trend_exog is not None:\n        exog = trend_exog if exog is None else np.c_[trend_exog, exog]\n        self._k_exog += self.k_trend\n    super(MarkovRegression, self).__init__(endog, k_regimes, order=order, exog_tvtp=exog_tvtp, exog=exog, dates=dates, freq=freq, missing=missing)\n    if self.switching_trend is True or self.switching_trend is False:\n        self.switching_trend = [self.switching_trend] * self.k_trend\n    elif not len(self.switching_trend) == self.k_trend:\n        raise ValueError('Invalid iterable passed to `switching_trend`.')\n    if self.switching_exog is True or self.switching_exog is False:\n        self.switching_exog = [self.switching_exog] * self.k_exog\n    elif not len(self.switching_exog) == self.k_exog:\n        raise ValueError('Invalid iterable passed to `switching_exog`.')\n    self.switching_coeffs = np.r_[self.switching_trend, self.switching_exog].astype(bool).tolist()\n    self.parameters['exog'] = self.switching_coeffs\n    self.parameters['variance'] = [1] if self.switching_variance else [0]",
        "mutated": [
            "def __init__(self, endog, k_regimes, trend='c', exog=None, order=0, exog_tvtp=None, switching_trend=True, switching_exog=True, switching_variance=False, dates=None, freq=None, missing='none'):\n    if False:\n        i = 10\n    from statsmodels.tools.validation import string_like\n    self.trend = string_like(trend, 'trend', options=('n', 'c', 'ct', 't'))\n    self.switching_trend = switching_trend\n    self.switching_exog = switching_exog\n    self.switching_variance = switching_variance\n    (self.k_exog, exog) = markov_switching.prepare_exog(exog)\n    nobs = len(endog)\n    self.k_trend = 0\n    self._k_exog = self.k_exog\n    trend_exog = None\n    if trend == 'c':\n        trend_exog = np.ones((nobs, 1))\n        self.k_trend = 1\n    elif trend == 't':\n        trend_exog = (np.arange(nobs) + 1)[:, np.newaxis]\n        self.k_trend = 1\n    elif trend == 'ct':\n        trend_exog = np.c_[np.ones((nobs, 1)), (np.arange(nobs) + 1)[:, np.newaxis]]\n        self.k_trend = 2\n    if trend_exog is not None:\n        exog = trend_exog if exog is None else np.c_[trend_exog, exog]\n        self._k_exog += self.k_trend\n    super(MarkovRegression, self).__init__(endog, k_regimes, order=order, exog_tvtp=exog_tvtp, exog=exog, dates=dates, freq=freq, missing=missing)\n    if self.switching_trend is True or self.switching_trend is False:\n        self.switching_trend = [self.switching_trend] * self.k_trend\n    elif not len(self.switching_trend) == self.k_trend:\n        raise ValueError('Invalid iterable passed to `switching_trend`.')\n    if self.switching_exog is True or self.switching_exog is False:\n        self.switching_exog = [self.switching_exog] * self.k_exog\n    elif not len(self.switching_exog) == self.k_exog:\n        raise ValueError('Invalid iterable passed to `switching_exog`.')\n    self.switching_coeffs = np.r_[self.switching_trend, self.switching_exog].astype(bool).tolist()\n    self.parameters['exog'] = self.switching_coeffs\n    self.parameters['variance'] = [1] if self.switching_variance else [0]",
            "def __init__(self, endog, k_regimes, trend='c', exog=None, order=0, exog_tvtp=None, switching_trend=True, switching_exog=True, switching_variance=False, dates=None, freq=None, missing='none'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    from statsmodels.tools.validation import string_like\n    self.trend = string_like(trend, 'trend', options=('n', 'c', 'ct', 't'))\n    self.switching_trend = switching_trend\n    self.switching_exog = switching_exog\n    self.switching_variance = switching_variance\n    (self.k_exog, exog) = markov_switching.prepare_exog(exog)\n    nobs = len(endog)\n    self.k_trend = 0\n    self._k_exog = self.k_exog\n    trend_exog = None\n    if trend == 'c':\n        trend_exog = np.ones((nobs, 1))\n        self.k_trend = 1\n    elif trend == 't':\n        trend_exog = (np.arange(nobs) + 1)[:, np.newaxis]\n        self.k_trend = 1\n    elif trend == 'ct':\n        trend_exog = np.c_[np.ones((nobs, 1)), (np.arange(nobs) + 1)[:, np.newaxis]]\n        self.k_trend = 2\n    if trend_exog is not None:\n        exog = trend_exog if exog is None else np.c_[trend_exog, exog]\n        self._k_exog += self.k_trend\n    super(MarkovRegression, self).__init__(endog, k_regimes, order=order, exog_tvtp=exog_tvtp, exog=exog, dates=dates, freq=freq, missing=missing)\n    if self.switching_trend is True or self.switching_trend is False:\n        self.switching_trend = [self.switching_trend] * self.k_trend\n    elif not len(self.switching_trend) == self.k_trend:\n        raise ValueError('Invalid iterable passed to `switching_trend`.')\n    if self.switching_exog is True or self.switching_exog is False:\n        self.switching_exog = [self.switching_exog] * self.k_exog\n    elif not len(self.switching_exog) == self.k_exog:\n        raise ValueError('Invalid iterable passed to `switching_exog`.')\n    self.switching_coeffs = np.r_[self.switching_trend, self.switching_exog].astype(bool).tolist()\n    self.parameters['exog'] = self.switching_coeffs\n    self.parameters['variance'] = [1] if self.switching_variance else [0]",
            "def __init__(self, endog, k_regimes, trend='c', exog=None, order=0, exog_tvtp=None, switching_trend=True, switching_exog=True, switching_variance=False, dates=None, freq=None, missing='none'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    from statsmodels.tools.validation import string_like\n    self.trend = string_like(trend, 'trend', options=('n', 'c', 'ct', 't'))\n    self.switching_trend = switching_trend\n    self.switching_exog = switching_exog\n    self.switching_variance = switching_variance\n    (self.k_exog, exog) = markov_switching.prepare_exog(exog)\n    nobs = len(endog)\n    self.k_trend = 0\n    self._k_exog = self.k_exog\n    trend_exog = None\n    if trend == 'c':\n        trend_exog = np.ones((nobs, 1))\n        self.k_trend = 1\n    elif trend == 't':\n        trend_exog = (np.arange(nobs) + 1)[:, np.newaxis]\n        self.k_trend = 1\n    elif trend == 'ct':\n        trend_exog = np.c_[np.ones((nobs, 1)), (np.arange(nobs) + 1)[:, np.newaxis]]\n        self.k_trend = 2\n    if trend_exog is not None:\n        exog = trend_exog if exog is None else np.c_[trend_exog, exog]\n        self._k_exog += self.k_trend\n    super(MarkovRegression, self).__init__(endog, k_regimes, order=order, exog_tvtp=exog_tvtp, exog=exog, dates=dates, freq=freq, missing=missing)\n    if self.switching_trend is True or self.switching_trend is False:\n        self.switching_trend = [self.switching_trend] * self.k_trend\n    elif not len(self.switching_trend) == self.k_trend:\n        raise ValueError('Invalid iterable passed to `switching_trend`.')\n    if self.switching_exog is True or self.switching_exog is False:\n        self.switching_exog = [self.switching_exog] * self.k_exog\n    elif not len(self.switching_exog) == self.k_exog:\n        raise ValueError('Invalid iterable passed to `switching_exog`.')\n    self.switching_coeffs = np.r_[self.switching_trend, self.switching_exog].astype(bool).tolist()\n    self.parameters['exog'] = self.switching_coeffs\n    self.parameters['variance'] = [1] if self.switching_variance else [0]",
            "def __init__(self, endog, k_regimes, trend='c', exog=None, order=0, exog_tvtp=None, switching_trend=True, switching_exog=True, switching_variance=False, dates=None, freq=None, missing='none'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    from statsmodels.tools.validation import string_like\n    self.trend = string_like(trend, 'trend', options=('n', 'c', 'ct', 't'))\n    self.switching_trend = switching_trend\n    self.switching_exog = switching_exog\n    self.switching_variance = switching_variance\n    (self.k_exog, exog) = markov_switching.prepare_exog(exog)\n    nobs = len(endog)\n    self.k_trend = 0\n    self._k_exog = self.k_exog\n    trend_exog = None\n    if trend == 'c':\n        trend_exog = np.ones((nobs, 1))\n        self.k_trend = 1\n    elif trend == 't':\n        trend_exog = (np.arange(nobs) + 1)[:, np.newaxis]\n        self.k_trend = 1\n    elif trend == 'ct':\n        trend_exog = np.c_[np.ones((nobs, 1)), (np.arange(nobs) + 1)[:, np.newaxis]]\n        self.k_trend = 2\n    if trend_exog is not None:\n        exog = trend_exog if exog is None else np.c_[trend_exog, exog]\n        self._k_exog += self.k_trend\n    super(MarkovRegression, self).__init__(endog, k_regimes, order=order, exog_tvtp=exog_tvtp, exog=exog, dates=dates, freq=freq, missing=missing)\n    if self.switching_trend is True or self.switching_trend is False:\n        self.switching_trend = [self.switching_trend] * self.k_trend\n    elif not len(self.switching_trend) == self.k_trend:\n        raise ValueError('Invalid iterable passed to `switching_trend`.')\n    if self.switching_exog is True or self.switching_exog is False:\n        self.switching_exog = [self.switching_exog] * self.k_exog\n    elif not len(self.switching_exog) == self.k_exog:\n        raise ValueError('Invalid iterable passed to `switching_exog`.')\n    self.switching_coeffs = np.r_[self.switching_trend, self.switching_exog].astype(bool).tolist()\n    self.parameters['exog'] = self.switching_coeffs\n    self.parameters['variance'] = [1] if self.switching_variance else [0]",
            "def __init__(self, endog, k_regimes, trend='c', exog=None, order=0, exog_tvtp=None, switching_trend=True, switching_exog=True, switching_variance=False, dates=None, freq=None, missing='none'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    from statsmodels.tools.validation import string_like\n    self.trend = string_like(trend, 'trend', options=('n', 'c', 'ct', 't'))\n    self.switching_trend = switching_trend\n    self.switching_exog = switching_exog\n    self.switching_variance = switching_variance\n    (self.k_exog, exog) = markov_switching.prepare_exog(exog)\n    nobs = len(endog)\n    self.k_trend = 0\n    self._k_exog = self.k_exog\n    trend_exog = None\n    if trend == 'c':\n        trend_exog = np.ones((nobs, 1))\n        self.k_trend = 1\n    elif trend == 't':\n        trend_exog = (np.arange(nobs) + 1)[:, np.newaxis]\n        self.k_trend = 1\n    elif trend == 'ct':\n        trend_exog = np.c_[np.ones((nobs, 1)), (np.arange(nobs) + 1)[:, np.newaxis]]\n        self.k_trend = 2\n    if trend_exog is not None:\n        exog = trend_exog if exog is None else np.c_[trend_exog, exog]\n        self._k_exog += self.k_trend\n    super(MarkovRegression, self).__init__(endog, k_regimes, order=order, exog_tvtp=exog_tvtp, exog=exog, dates=dates, freq=freq, missing=missing)\n    if self.switching_trend is True or self.switching_trend is False:\n        self.switching_trend = [self.switching_trend] * self.k_trend\n    elif not len(self.switching_trend) == self.k_trend:\n        raise ValueError('Invalid iterable passed to `switching_trend`.')\n    if self.switching_exog is True or self.switching_exog is False:\n        self.switching_exog = [self.switching_exog] * self.k_exog\n    elif not len(self.switching_exog) == self.k_exog:\n        raise ValueError('Invalid iterable passed to `switching_exog`.')\n    self.switching_coeffs = np.r_[self.switching_trend, self.switching_exog].astype(bool).tolist()\n    self.parameters['exog'] = self.switching_coeffs\n    self.parameters['variance'] = [1] if self.switching_variance else [0]"
        ]
    },
    {
        "func_name": "predict_conditional",
        "original": "def predict_conditional(self, params):\n    \"\"\"\n        In-sample prediction, conditional on the current regime\n\n        Parameters\n        ----------\n        params : array_like\n            Array of parameters at which to perform prediction.\n\n        Returns\n        -------\n        predict : array_like\n            Array of predictions conditional on current, and possibly past,\n            regimes\n        \"\"\"\n    params = np.array(params, ndmin=1)\n    predict = np.zeros((self.k_regimes, self.nobs), dtype=params.dtype)\n    for i in range(self.k_regimes):\n        if self._k_exog > 0:\n            coeffs = params[self.parameters[i, 'exog']]\n            predict[i] = np.dot(self.exog, coeffs)\n    return predict[:, None, :]",
        "mutated": [
            "def predict_conditional(self, params):\n    if False:\n        i = 10\n    '\\n        In-sample prediction, conditional on the current regime\\n\\n        Parameters\\n        ----------\\n        params : array_like\\n            Array of parameters at which to perform prediction.\\n\\n        Returns\\n        -------\\n        predict : array_like\\n            Array of predictions conditional on current, and possibly past,\\n            regimes\\n        '\n    params = np.array(params, ndmin=1)\n    predict = np.zeros((self.k_regimes, self.nobs), dtype=params.dtype)\n    for i in range(self.k_regimes):\n        if self._k_exog > 0:\n            coeffs = params[self.parameters[i, 'exog']]\n            predict[i] = np.dot(self.exog, coeffs)\n    return predict[:, None, :]",
            "def predict_conditional(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        In-sample prediction, conditional on the current regime\\n\\n        Parameters\\n        ----------\\n        params : array_like\\n            Array of parameters at which to perform prediction.\\n\\n        Returns\\n        -------\\n        predict : array_like\\n            Array of predictions conditional on current, and possibly past,\\n            regimes\\n        '\n    params = np.array(params, ndmin=1)\n    predict = np.zeros((self.k_regimes, self.nobs), dtype=params.dtype)\n    for i in range(self.k_regimes):\n        if self._k_exog > 0:\n            coeffs = params[self.parameters[i, 'exog']]\n            predict[i] = np.dot(self.exog, coeffs)\n    return predict[:, None, :]",
            "def predict_conditional(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        In-sample prediction, conditional on the current regime\\n\\n        Parameters\\n        ----------\\n        params : array_like\\n            Array of parameters at which to perform prediction.\\n\\n        Returns\\n        -------\\n        predict : array_like\\n            Array of predictions conditional on current, and possibly past,\\n            regimes\\n        '\n    params = np.array(params, ndmin=1)\n    predict = np.zeros((self.k_regimes, self.nobs), dtype=params.dtype)\n    for i in range(self.k_regimes):\n        if self._k_exog > 0:\n            coeffs = params[self.parameters[i, 'exog']]\n            predict[i] = np.dot(self.exog, coeffs)\n    return predict[:, None, :]",
            "def predict_conditional(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        In-sample prediction, conditional on the current regime\\n\\n        Parameters\\n        ----------\\n        params : array_like\\n            Array of parameters at which to perform prediction.\\n\\n        Returns\\n        -------\\n        predict : array_like\\n            Array of predictions conditional on current, and possibly past,\\n            regimes\\n        '\n    params = np.array(params, ndmin=1)\n    predict = np.zeros((self.k_regimes, self.nobs), dtype=params.dtype)\n    for i in range(self.k_regimes):\n        if self._k_exog > 0:\n            coeffs = params[self.parameters[i, 'exog']]\n            predict[i] = np.dot(self.exog, coeffs)\n    return predict[:, None, :]",
            "def predict_conditional(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        In-sample prediction, conditional on the current regime\\n\\n        Parameters\\n        ----------\\n        params : array_like\\n            Array of parameters at which to perform prediction.\\n\\n        Returns\\n        -------\\n        predict : array_like\\n            Array of predictions conditional on current, and possibly past,\\n            regimes\\n        '\n    params = np.array(params, ndmin=1)\n    predict = np.zeros((self.k_regimes, self.nobs), dtype=params.dtype)\n    for i in range(self.k_regimes):\n        if self._k_exog > 0:\n            coeffs = params[self.parameters[i, 'exog']]\n            predict[i] = np.dot(self.exog, coeffs)\n    return predict[:, None, :]"
        ]
    },
    {
        "func_name": "_resid",
        "original": "def _resid(self, params):\n    predict = np.repeat(self.predict_conditional(params), self.k_regimes, axis=1)\n    return self.endog - predict",
        "mutated": [
            "def _resid(self, params):\n    if False:\n        i = 10\n    predict = np.repeat(self.predict_conditional(params), self.k_regimes, axis=1)\n    return self.endog - predict",
            "def _resid(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    predict = np.repeat(self.predict_conditional(params), self.k_regimes, axis=1)\n    return self.endog - predict",
            "def _resid(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    predict = np.repeat(self.predict_conditional(params), self.k_regimes, axis=1)\n    return self.endog - predict",
            "def _resid(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    predict = np.repeat(self.predict_conditional(params), self.k_regimes, axis=1)\n    return self.endog - predict",
            "def _resid(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    predict = np.repeat(self.predict_conditional(params), self.k_regimes, axis=1)\n    return self.endog - predict"
        ]
    },
    {
        "func_name": "_conditional_loglikelihoods",
        "original": "def _conditional_loglikelihoods(self, params):\n    \"\"\"\n        Compute loglikelihoods conditional on the current period's regime\n        \"\"\"\n    resid = self._resid(params)\n    variance = params[self.parameters['variance']].squeeze()\n    if self.switching_variance:\n        variance = np.reshape(variance, (self.k_regimes, 1, 1))\n    conditional_loglikelihoods = -0.5 * resid ** 2 / variance - 0.5 * np.log(2 * np.pi * variance)\n    return conditional_loglikelihoods",
        "mutated": [
            "def _conditional_loglikelihoods(self, params):\n    if False:\n        i = 10\n    \"\\n        Compute loglikelihoods conditional on the current period's regime\\n        \"\n    resid = self._resid(params)\n    variance = params[self.parameters['variance']].squeeze()\n    if self.switching_variance:\n        variance = np.reshape(variance, (self.k_regimes, 1, 1))\n    conditional_loglikelihoods = -0.5 * resid ** 2 / variance - 0.5 * np.log(2 * np.pi * variance)\n    return conditional_loglikelihoods",
            "def _conditional_loglikelihoods(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n        Compute loglikelihoods conditional on the current period's regime\\n        \"\n    resid = self._resid(params)\n    variance = params[self.parameters['variance']].squeeze()\n    if self.switching_variance:\n        variance = np.reshape(variance, (self.k_regimes, 1, 1))\n    conditional_loglikelihoods = -0.5 * resid ** 2 / variance - 0.5 * np.log(2 * np.pi * variance)\n    return conditional_loglikelihoods",
            "def _conditional_loglikelihoods(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n        Compute loglikelihoods conditional on the current period's regime\\n        \"\n    resid = self._resid(params)\n    variance = params[self.parameters['variance']].squeeze()\n    if self.switching_variance:\n        variance = np.reshape(variance, (self.k_regimes, 1, 1))\n    conditional_loglikelihoods = -0.5 * resid ** 2 / variance - 0.5 * np.log(2 * np.pi * variance)\n    return conditional_loglikelihoods",
            "def _conditional_loglikelihoods(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n        Compute loglikelihoods conditional on the current period's regime\\n        \"\n    resid = self._resid(params)\n    variance = params[self.parameters['variance']].squeeze()\n    if self.switching_variance:\n        variance = np.reshape(variance, (self.k_regimes, 1, 1))\n    conditional_loglikelihoods = -0.5 * resid ** 2 / variance - 0.5 * np.log(2 * np.pi * variance)\n    return conditional_loglikelihoods",
            "def _conditional_loglikelihoods(self, params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n        Compute loglikelihoods conditional on the current period's regime\\n        \"\n    resid = self._resid(params)\n    variance = params[self.parameters['variance']].squeeze()\n    if self.switching_variance:\n        variance = np.reshape(variance, (self.k_regimes, 1, 1))\n    conditional_loglikelihoods = -0.5 * resid ** 2 / variance - 0.5 * np.log(2 * np.pi * variance)\n    return conditional_loglikelihoods"
        ]
    },
    {
        "func_name": "_res_classes",
        "original": "@property\ndef _res_classes(self):\n    return {'fit': (MarkovRegressionResults, MarkovRegressionResultsWrapper)}",
        "mutated": [
            "@property\ndef _res_classes(self):\n    if False:\n        i = 10\n    return {'fit': (MarkovRegressionResults, MarkovRegressionResultsWrapper)}",
            "@property\ndef _res_classes(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return {'fit': (MarkovRegressionResults, MarkovRegressionResultsWrapper)}",
            "@property\ndef _res_classes(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return {'fit': (MarkovRegressionResults, MarkovRegressionResultsWrapper)}",
            "@property\ndef _res_classes(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return {'fit': (MarkovRegressionResults, MarkovRegressionResultsWrapper)}",
            "@property\ndef _res_classes(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return {'fit': (MarkovRegressionResults, MarkovRegressionResultsWrapper)}"
        ]
    },
    {
        "func_name": "_em_iteration",
        "original": "def _em_iteration(self, params0):\n    \"\"\"\n        EM iteration\n\n        Notes\n        -----\n        This uses the inherited _em_iteration method for computing the\n        non-TVTP transition probabilities and then performs the EM step for\n        regression coefficients and variances.\n        \"\"\"\n    (result, params1) = super(MarkovRegression, self)._em_iteration(params0)\n    tmp = np.sqrt(result.smoothed_marginal_probabilities)\n    coeffs = None\n    if self._k_exog > 0:\n        coeffs = self._em_exog(result, self.endog, self.exog, self.parameters.switching['exog'], tmp)\n        for i in range(self.k_regimes):\n            params1[self.parameters[i, 'exog']] = coeffs[i]\n    params1[self.parameters['variance']] = self._em_variance(result, self.endog, self.exog, coeffs, tmp)\n    return (result, params1)",
        "mutated": [
            "def _em_iteration(self, params0):\n    if False:\n        i = 10\n    '\\n        EM iteration\\n\\n        Notes\\n        -----\\n        This uses the inherited _em_iteration method for computing the\\n        non-TVTP transition probabilities and then performs the EM step for\\n        regression coefficients and variances.\\n        '\n    (result, params1) = super(MarkovRegression, self)._em_iteration(params0)\n    tmp = np.sqrt(result.smoothed_marginal_probabilities)\n    coeffs = None\n    if self._k_exog > 0:\n        coeffs = self._em_exog(result, self.endog, self.exog, self.parameters.switching['exog'], tmp)\n        for i in range(self.k_regimes):\n            params1[self.parameters[i, 'exog']] = coeffs[i]\n    params1[self.parameters['variance']] = self._em_variance(result, self.endog, self.exog, coeffs, tmp)\n    return (result, params1)",
            "def _em_iteration(self, params0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        EM iteration\\n\\n        Notes\\n        -----\\n        This uses the inherited _em_iteration method for computing the\\n        non-TVTP transition probabilities and then performs the EM step for\\n        regression coefficients and variances.\\n        '\n    (result, params1) = super(MarkovRegression, self)._em_iteration(params0)\n    tmp = np.sqrt(result.smoothed_marginal_probabilities)\n    coeffs = None\n    if self._k_exog > 0:\n        coeffs = self._em_exog(result, self.endog, self.exog, self.parameters.switching['exog'], tmp)\n        for i in range(self.k_regimes):\n            params1[self.parameters[i, 'exog']] = coeffs[i]\n    params1[self.parameters['variance']] = self._em_variance(result, self.endog, self.exog, coeffs, tmp)\n    return (result, params1)",
            "def _em_iteration(self, params0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        EM iteration\\n\\n        Notes\\n        -----\\n        This uses the inherited _em_iteration method for computing the\\n        non-TVTP transition probabilities and then performs the EM step for\\n        regression coefficients and variances.\\n        '\n    (result, params1) = super(MarkovRegression, self)._em_iteration(params0)\n    tmp = np.sqrt(result.smoothed_marginal_probabilities)\n    coeffs = None\n    if self._k_exog > 0:\n        coeffs = self._em_exog(result, self.endog, self.exog, self.parameters.switching['exog'], tmp)\n        for i in range(self.k_regimes):\n            params1[self.parameters[i, 'exog']] = coeffs[i]\n    params1[self.parameters['variance']] = self._em_variance(result, self.endog, self.exog, coeffs, tmp)\n    return (result, params1)",
            "def _em_iteration(self, params0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        EM iteration\\n\\n        Notes\\n        -----\\n        This uses the inherited _em_iteration method for computing the\\n        non-TVTP transition probabilities and then performs the EM step for\\n        regression coefficients and variances.\\n        '\n    (result, params1) = super(MarkovRegression, self)._em_iteration(params0)\n    tmp = np.sqrt(result.smoothed_marginal_probabilities)\n    coeffs = None\n    if self._k_exog > 0:\n        coeffs = self._em_exog(result, self.endog, self.exog, self.parameters.switching['exog'], tmp)\n        for i in range(self.k_regimes):\n            params1[self.parameters[i, 'exog']] = coeffs[i]\n    params1[self.parameters['variance']] = self._em_variance(result, self.endog, self.exog, coeffs, tmp)\n    return (result, params1)",
            "def _em_iteration(self, params0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        EM iteration\\n\\n        Notes\\n        -----\\n        This uses the inherited _em_iteration method for computing the\\n        non-TVTP transition probabilities and then performs the EM step for\\n        regression coefficients and variances.\\n        '\n    (result, params1) = super(MarkovRegression, self)._em_iteration(params0)\n    tmp = np.sqrt(result.smoothed_marginal_probabilities)\n    coeffs = None\n    if self._k_exog > 0:\n        coeffs = self._em_exog(result, self.endog, self.exog, self.parameters.switching['exog'], tmp)\n        for i in range(self.k_regimes):\n            params1[self.parameters[i, 'exog']] = coeffs[i]\n    params1[self.parameters['variance']] = self._em_variance(result, self.endog, self.exog, coeffs, tmp)\n    return (result, params1)"
        ]
    },
    {
        "func_name": "_em_exog",
        "original": "def _em_exog(self, result, endog, exog, switching, tmp=None):\n    \"\"\"\n        EM step for regression coefficients\n        \"\"\"\n    k_exog = exog.shape[1]\n    coeffs = np.zeros((self.k_regimes, k_exog))\n    if not np.all(switching):\n        nonswitching_exog = exog[:, ~switching]\n        nonswitching_coeffs = np.dot(np.linalg.pinv(nonswitching_exog), endog)\n        coeffs[:, ~switching] = nonswitching_coeffs\n        endog = endog - np.dot(nonswitching_exog, nonswitching_coeffs)\n    if np.any(switching):\n        switching_exog = exog[:, switching]\n        if tmp is None:\n            tmp = np.sqrt(result.smoothed_marginal_probabilities)\n        for i in range(self.k_regimes):\n            tmp_endog = tmp[i] * endog\n            tmp_exog = tmp[i][:, np.newaxis] * switching_exog\n            coeffs[i, switching] = np.dot(np.linalg.pinv(tmp_exog), tmp_endog)\n    return coeffs",
        "mutated": [
            "def _em_exog(self, result, endog, exog, switching, tmp=None):\n    if False:\n        i = 10\n    '\\n        EM step for regression coefficients\\n        '\n    k_exog = exog.shape[1]\n    coeffs = np.zeros((self.k_regimes, k_exog))\n    if not np.all(switching):\n        nonswitching_exog = exog[:, ~switching]\n        nonswitching_coeffs = np.dot(np.linalg.pinv(nonswitching_exog), endog)\n        coeffs[:, ~switching] = nonswitching_coeffs\n        endog = endog - np.dot(nonswitching_exog, nonswitching_coeffs)\n    if np.any(switching):\n        switching_exog = exog[:, switching]\n        if tmp is None:\n            tmp = np.sqrt(result.smoothed_marginal_probabilities)\n        for i in range(self.k_regimes):\n            tmp_endog = tmp[i] * endog\n            tmp_exog = tmp[i][:, np.newaxis] * switching_exog\n            coeffs[i, switching] = np.dot(np.linalg.pinv(tmp_exog), tmp_endog)\n    return coeffs",
            "def _em_exog(self, result, endog, exog, switching, tmp=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        EM step for regression coefficients\\n        '\n    k_exog = exog.shape[1]\n    coeffs = np.zeros((self.k_regimes, k_exog))\n    if not np.all(switching):\n        nonswitching_exog = exog[:, ~switching]\n        nonswitching_coeffs = np.dot(np.linalg.pinv(nonswitching_exog), endog)\n        coeffs[:, ~switching] = nonswitching_coeffs\n        endog = endog - np.dot(nonswitching_exog, nonswitching_coeffs)\n    if np.any(switching):\n        switching_exog = exog[:, switching]\n        if tmp is None:\n            tmp = np.sqrt(result.smoothed_marginal_probabilities)\n        for i in range(self.k_regimes):\n            tmp_endog = tmp[i] * endog\n            tmp_exog = tmp[i][:, np.newaxis] * switching_exog\n            coeffs[i, switching] = np.dot(np.linalg.pinv(tmp_exog), tmp_endog)\n    return coeffs",
            "def _em_exog(self, result, endog, exog, switching, tmp=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        EM step for regression coefficients\\n        '\n    k_exog = exog.shape[1]\n    coeffs = np.zeros((self.k_regimes, k_exog))\n    if not np.all(switching):\n        nonswitching_exog = exog[:, ~switching]\n        nonswitching_coeffs = np.dot(np.linalg.pinv(nonswitching_exog), endog)\n        coeffs[:, ~switching] = nonswitching_coeffs\n        endog = endog - np.dot(nonswitching_exog, nonswitching_coeffs)\n    if np.any(switching):\n        switching_exog = exog[:, switching]\n        if tmp is None:\n            tmp = np.sqrt(result.smoothed_marginal_probabilities)\n        for i in range(self.k_regimes):\n            tmp_endog = tmp[i] * endog\n            tmp_exog = tmp[i][:, np.newaxis] * switching_exog\n            coeffs[i, switching] = np.dot(np.linalg.pinv(tmp_exog), tmp_endog)\n    return coeffs",
            "def _em_exog(self, result, endog, exog, switching, tmp=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        EM step for regression coefficients\\n        '\n    k_exog = exog.shape[1]\n    coeffs = np.zeros((self.k_regimes, k_exog))\n    if not np.all(switching):\n        nonswitching_exog = exog[:, ~switching]\n        nonswitching_coeffs = np.dot(np.linalg.pinv(nonswitching_exog), endog)\n        coeffs[:, ~switching] = nonswitching_coeffs\n        endog = endog - np.dot(nonswitching_exog, nonswitching_coeffs)\n    if np.any(switching):\n        switching_exog = exog[:, switching]\n        if tmp is None:\n            tmp = np.sqrt(result.smoothed_marginal_probabilities)\n        for i in range(self.k_regimes):\n            tmp_endog = tmp[i] * endog\n            tmp_exog = tmp[i][:, np.newaxis] * switching_exog\n            coeffs[i, switching] = np.dot(np.linalg.pinv(tmp_exog), tmp_endog)\n    return coeffs",
            "def _em_exog(self, result, endog, exog, switching, tmp=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        EM step for regression coefficients\\n        '\n    k_exog = exog.shape[1]\n    coeffs = np.zeros((self.k_regimes, k_exog))\n    if not np.all(switching):\n        nonswitching_exog = exog[:, ~switching]\n        nonswitching_coeffs = np.dot(np.linalg.pinv(nonswitching_exog), endog)\n        coeffs[:, ~switching] = nonswitching_coeffs\n        endog = endog - np.dot(nonswitching_exog, nonswitching_coeffs)\n    if np.any(switching):\n        switching_exog = exog[:, switching]\n        if tmp is None:\n            tmp = np.sqrt(result.smoothed_marginal_probabilities)\n        for i in range(self.k_regimes):\n            tmp_endog = tmp[i] * endog\n            tmp_exog = tmp[i][:, np.newaxis] * switching_exog\n            coeffs[i, switching] = np.dot(np.linalg.pinv(tmp_exog), tmp_endog)\n    return coeffs"
        ]
    },
    {
        "func_name": "_em_variance",
        "original": "def _em_variance(self, result, endog, exog, betas, tmp=None):\n    \"\"\"\n        EM step for variances\n        \"\"\"\n    k_exog = 0 if exog is None else exog.shape[1]\n    if self.switching_variance:\n        variance = np.zeros(self.k_regimes)\n        for i in range(self.k_regimes):\n            if k_exog > 0:\n                resid = endog - np.dot(exog, betas[i])\n            else:\n                resid = endog\n            variance[i] = np.sum(resid ** 2 * result.smoothed_marginal_probabilities[i]) / np.sum(result.smoothed_marginal_probabilities[i])\n    else:\n        variance = 0\n        if tmp is None:\n            tmp = np.sqrt(result.smoothed_marginal_probabilities)\n        for i in range(self.k_regimes):\n            tmp_endog = tmp[i] * endog\n            if k_exog > 0:\n                tmp_exog = tmp[i][:, np.newaxis] * exog\n                resid = tmp_endog - np.dot(tmp_exog, betas[i])\n            else:\n                resid = tmp_endog\n            variance += np.sum(resid ** 2)\n        variance /= self.nobs\n    return variance",
        "mutated": [
            "def _em_variance(self, result, endog, exog, betas, tmp=None):\n    if False:\n        i = 10\n    '\\n        EM step for variances\\n        '\n    k_exog = 0 if exog is None else exog.shape[1]\n    if self.switching_variance:\n        variance = np.zeros(self.k_regimes)\n        for i in range(self.k_regimes):\n            if k_exog > 0:\n                resid = endog - np.dot(exog, betas[i])\n            else:\n                resid = endog\n            variance[i] = np.sum(resid ** 2 * result.smoothed_marginal_probabilities[i]) / np.sum(result.smoothed_marginal_probabilities[i])\n    else:\n        variance = 0\n        if tmp is None:\n            tmp = np.sqrt(result.smoothed_marginal_probabilities)\n        for i in range(self.k_regimes):\n            tmp_endog = tmp[i] * endog\n            if k_exog > 0:\n                tmp_exog = tmp[i][:, np.newaxis] * exog\n                resid = tmp_endog - np.dot(tmp_exog, betas[i])\n            else:\n                resid = tmp_endog\n            variance += np.sum(resid ** 2)\n        variance /= self.nobs\n    return variance",
            "def _em_variance(self, result, endog, exog, betas, tmp=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        EM step for variances\\n        '\n    k_exog = 0 if exog is None else exog.shape[1]\n    if self.switching_variance:\n        variance = np.zeros(self.k_regimes)\n        for i in range(self.k_regimes):\n            if k_exog > 0:\n                resid = endog - np.dot(exog, betas[i])\n            else:\n                resid = endog\n            variance[i] = np.sum(resid ** 2 * result.smoothed_marginal_probabilities[i]) / np.sum(result.smoothed_marginal_probabilities[i])\n    else:\n        variance = 0\n        if tmp is None:\n            tmp = np.sqrt(result.smoothed_marginal_probabilities)\n        for i in range(self.k_regimes):\n            tmp_endog = tmp[i] * endog\n            if k_exog > 0:\n                tmp_exog = tmp[i][:, np.newaxis] * exog\n                resid = tmp_endog - np.dot(tmp_exog, betas[i])\n            else:\n                resid = tmp_endog\n            variance += np.sum(resid ** 2)\n        variance /= self.nobs\n    return variance",
            "def _em_variance(self, result, endog, exog, betas, tmp=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        EM step for variances\\n        '\n    k_exog = 0 if exog is None else exog.shape[1]\n    if self.switching_variance:\n        variance = np.zeros(self.k_regimes)\n        for i in range(self.k_regimes):\n            if k_exog > 0:\n                resid = endog - np.dot(exog, betas[i])\n            else:\n                resid = endog\n            variance[i] = np.sum(resid ** 2 * result.smoothed_marginal_probabilities[i]) / np.sum(result.smoothed_marginal_probabilities[i])\n    else:\n        variance = 0\n        if tmp is None:\n            tmp = np.sqrt(result.smoothed_marginal_probabilities)\n        for i in range(self.k_regimes):\n            tmp_endog = tmp[i] * endog\n            if k_exog > 0:\n                tmp_exog = tmp[i][:, np.newaxis] * exog\n                resid = tmp_endog - np.dot(tmp_exog, betas[i])\n            else:\n                resid = tmp_endog\n            variance += np.sum(resid ** 2)\n        variance /= self.nobs\n    return variance",
            "def _em_variance(self, result, endog, exog, betas, tmp=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        EM step for variances\\n        '\n    k_exog = 0 if exog is None else exog.shape[1]\n    if self.switching_variance:\n        variance = np.zeros(self.k_regimes)\n        for i in range(self.k_regimes):\n            if k_exog > 0:\n                resid = endog - np.dot(exog, betas[i])\n            else:\n                resid = endog\n            variance[i] = np.sum(resid ** 2 * result.smoothed_marginal_probabilities[i]) / np.sum(result.smoothed_marginal_probabilities[i])\n    else:\n        variance = 0\n        if tmp is None:\n            tmp = np.sqrt(result.smoothed_marginal_probabilities)\n        for i in range(self.k_regimes):\n            tmp_endog = tmp[i] * endog\n            if k_exog > 0:\n                tmp_exog = tmp[i][:, np.newaxis] * exog\n                resid = tmp_endog - np.dot(tmp_exog, betas[i])\n            else:\n                resid = tmp_endog\n            variance += np.sum(resid ** 2)\n        variance /= self.nobs\n    return variance",
            "def _em_variance(self, result, endog, exog, betas, tmp=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        EM step for variances\\n        '\n    k_exog = 0 if exog is None else exog.shape[1]\n    if self.switching_variance:\n        variance = np.zeros(self.k_regimes)\n        for i in range(self.k_regimes):\n            if k_exog > 0:\n                resid = endog - np.dot(exog, betas[i])\n            else:\n                resid = endog\n            variance[i] = np.sum(resid ** 2 * result.smoothed_marginal_probabilities[i]) / np.sum(result.smoothed_marginal_probabilities[i])\n    else:\n        variance = 0\n        if tmp is None:\n            tmp = np.sqrt(result.smoothed_marginal_probabilities)\n        for i in range(self.k_regimes):\n            tmp_endog = tmp[i] * endog\n            if k_exog > 0:\n                tmp_exog = tmp[i][:, np.newaxis] * exog\n                resid = tmp_endog - np.dot(tmp_exog, betas[i])\n            else:\n                resid = tmp_endog\n            variance += np.sum(resid ** 2)\n        variance /= self.nobs\n    return variance"
        ]
    },
    {
        "func_name": "start_params",
        "original": "@property\ndef start_params(self):\n    \"\"\"\n        (array) Starting parameters for maximum likelihood estimation.\n\n        Notes\n        -----\n        These are not very sophisticated and / or good. We set equal transition\n        probabilities and interpolate regression coefficients between zero and\n        the OLS estimates, where the interpolation is based on the regime\n        number. We rely heavily on the EM algorithm to quickly find much better\n        starting parameters, which are then used by the typical scoring\n        approach.\n        \"\"\"\n    params = markov_switching.MarkovSwitching.start_params.fget(self)\n    if self._k_exog > 0:\n        beta = np.dot(np.linalg.pinv(self.exog), self.endog)\n        variance = np.var(self.endog - np.dot(self.exog, beta))\n        if np.any(self.switching_coeffs):\n            for i in range(self.k_regimes):\n                params[self.parameters[i, 'exog']] = beta * (i / self.k_regimes)\n        else:\n            params[self.parameters['exog']] = beta\n    else:\n        variance = np.var(self.endog)\n    if self.switching_variance:\n        params[self.parameters['variance']] = np.linspace(variance / 10.0, variance, num=self.k_regimes)\n    else:\n        params[self.parameters['variance']] = variance\n    return params",
        "mutated": [
            "@property\ndef start_params(self):\n    if False:\n        i = 10\n    '\\n        (array) Starting parameters for maximum likelihood estimation.\\n\\n        Notes\\n        -----\\n        These are not very sophisticated and / or good. We set equal transition\\n        probabilities and interpolate regression coefficients between zero and\\n        the OLS estimates, where the interpolation is based on the regime\\n        number. We rely heavily on the EM algorithm to quickly find much better\\n        starting parameters, which are then used by the typical scoring\\n        approach.\\n        '\n    params = markov_switching.MarkovSwitching.start_params.fget(self)\n    if self._k_exog > 0:\n        beta = np.dot(np.linalg.pinv(self.exog), self.endog)\n        variance = np.var(self.endog - np.dot(self.exog, beta))\n        if np.any(self.switching_coeffs):\n            for i in range(self.k_regimes):\n                params[self.parameters[i, 'exog']] = beta * (i / self.k_regimes)\n        else:\n            params[self.parameters['exog']] = beta\n    else:\n        variance = np.var(self.endog)\n    if self.switching_variance:\n        params[self.parameters['variance']] = np.linspace(variance / 10.0, variance, num=self.k_regimes)\n    else:\n        params[self.parameters['variance']] = variance\n    return params",
            "@property\ndef start_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        (array) Starting parameters for maximum likelihood estimation.\\n\\n        Notes\\n        -----\\n        These are not very sophisticated and / or good. We set equal transition\\n        probabilities and interpolate regression coefficients between zero and\\n        the OLS estimates, where the interpolation is based on the regime\\n        number. We rely heavily on the EM algorithm to quickly find much better\\n        starting parameters, which are then used by the typical scoring\\n        approach.\\n        '\n    params = markov_switching.MarkovSwitching.start_params.fget(self)\n    if self._k_exog > 0:\n        beta = np.dot(np.linalg.pinv(self.exog), self.endog)\n        variance = np.var(self.endog - np.dot(self.exog, beta))\n        if np.any(self.switching_coeffs):\n            for i in range(self.k_regimes):\n                params[self.parameters[i, 'exog']] = beta * (i / self.k_regimes)\n        else:\n            params[self.parameters['exog']] = beta\n    else:\n        variance = np.var(self.endog)\n    if self.switching_variance:\n        params[self.parameters['variance']] = np.linspace(variance / 10.0, variance, num=self.k_regimes)\n    else:\n        params[self.parameters['variance']] = variance\n    return params",
            "@property\ndef start_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        (array) Starting parameters for maximum likelihood estimation.\\n\\n        Notes\\n        -----\\n        These are not very sophisticated and / or good. We set equal transition\\n        probabilities and interpolate regression coefficients between zero and\\n        the OLS estimates, where the interpolation is based on the regime\\n        number. We rely heavily on the EM algorithm to quickly find much better\\n        starting parameters, which are then used by the typical scoring\\n        approach.\\n        '\n    params = markov_switching.MarkovSwitching.start_params.fget(self)\n    if self._k_exog > 0:\n        beta = np.dot(np.linalg.pinv(self.exog), self.endog)\n        variance = np.var(self.endog - np.dot(self.exog, beta))\n        if np.any(self.switching_coeffs):\n            for i in range(self.k_regimes):\n                params[self.parameters[i, 'exog']] = beta * (i / self.k_regimes)\n        else:\n            params[self.parameters['exog']] = beta\n    else:\n        variance = np.var(self.endog)\n    if self.switching_variance:\n        params[self.parameters['variance']] = np.linspace(variance / 10.0, variance, num=self.k_regimes)\n    else:\n        params[self.parameters['variance']] = variance\n    return params",
            "@property\ndef start_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        (array) Starting parameters for maximum likelihood estimation.\\n\\n        Notes\\n        -----\\n        These are not very sophisticated and / or good. We set equal transition\\n        probabilities and interpolate regression coefficients between zero and\\n        the OLS estimates, where the interpolation is based on the regime\\n        number. We rely heavily on the EM algorithm to quickly find much better\\n        starting parameters, which are then used by the typical scoring\\n        approach.\\n        '\n    params = markov_switching.MarkovSwitching.start_params.fget(self)\n    if self._k_exog > 0:\n        beta = np.dot(np.linalg.pinv(self.exog), self.endog)\n        variance = np.var(self.endog - np.dot(self.exog, beta))\n        if np.any(self.switching_coeffs):\n            for i in range(self.k_regimes):\n                params[self.parameters[i, 'exog']] = beta * (i / self.k_regimes)\n        else:\n            params[self.parameters['exog']] = beta\n    else:\n        variance = np.var(self.endog)\n    if self.switching_variance:\n        params[self.parameters['variance']] = np.linspace(variance / 10.0, variance, num=self.k_regimes)\n    else:\n        params[self.parameters['variance']] = variance\n    return params",
            "@property\ndef start_params(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        (array) Starting parameters for maximum likelihood estimation.\\n\\n        Notes\\n        -----\\n        These are not very sophisticated and / or good. We set equal transition\\n        probabilities and interpolate regression coefficients between zero and\\n        the OLS estimates, where the interpolation is based on the regime\\n        number. We rely heavily on the EM algorithm to quickly find much better\\n        starting parameters, which are then used by the typical scoring\\n        approach.\\n        '\n    params = markov_switching.MarkovSwitching.start_params.fget(self)\n    if self._k_exog > 0:\n        beta = np.dot(np.linalg.pinv(self.exog), self.endog)\n        variance = np.var(self.endog - np.dot(self.exog, beta))\n        if np.any(self.switching_coeffs):\n            for i in range(self.k_regimes):\n                params[self.parameters[i, 'exog']] = beta * (i / self.k_regimes)\n        else:\n            params[self.parameters['exog']] = beta\n    else:\n        variance = np.var(self.endog)\n    if self.switching_variance:\n        params[self.parameters['variance']] = np.linspace(variance / 10.0, variance, num=self.k_regimes)\n    else:\n        params[self.parameters['variance']] = variance\n    return params"
        ]
    },
    {
        "func_name": "param_names",
        "original": "@property\ndef param_names(self):\n    \"\"\"\n        (list of str) List of human readable parameter names (for parameters\n        actually included in the model).\n        \"\"\"\n    param_names = np.array(markov_switching.MarkovSwitching.param_names.fget(self), dtype=object)\n    if np.any(self.switching_coeffs):\n        for i in range(self.k_regimes):\n            param_names[self.parameters[i, 'exog']] = ['%s[%d]' % (exog_name, i) for exog_name in self.exog_names]\n    else:\n        param_names[self.parameters['exog']] = self.exog_names\n    if self.switching_variance:\n        for i in range(self.k_regimes):\n            param_names[self.parameters[i, 'variance']] = 'sigma2[%d]' % i\n    else:\n        param_names[self.parameters['variance']] = 'sigma2'\n    return param_names.tolist()",
        "mutated": [
            "@property\ndef param_names(self):\n    if False:\n        i = 10\n    '\\n        (list of str) List of human readable parameter names (for parameters\\n        actually included in the model).\\n        '\n    param_names = np.array(markov_switching.MarkovSwitching.param_names.fget(self), dtype=object)\n    if np.any(self.switching_coeffs):\n        for i in range(self.k_regimes):\n            param_names[self.parameters[i, 'exog']] = ['%s[%d]' % (exog_name, i) for exog_name in self.exog_names]\n    else:\n        param_names[self.parameters['exog']] = self.exog_names\n    if self.switching_variance:\n        for i in range(self.k_regimes):\n            param_names[self.parameters[i, 'variance']] = 'sigma2[%d]' % i\n    else:\n        param_names[self.parameters['variance']] = 'sigma2'\n    return param_names.tolist()",
            "@property\ndef param_names(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        (list of str) List of human readable parameter names (for parameters\\n        actually included in the model).\\n        '\n    param_names = np.array(markov_switching.MarkovSwitching.param_names.fget(self), dtype=object)\n    if np.any(self.switching_coeffs):\n        for i in range(self.k_regimes):\n            param_names[self.parameters[i, 'exog']] = ['%s[%d]' % (exog_name, i) for exog_name in self.exog_names]\n    else:\n        param_names[self.parameters['exog']] = self.exog_names\n    if self.switching_variance:\n        for i in range(self.k_regimes):\n            param_names[self.parameters[i, 'variance']] = 'sigma2[%d]' % i\n    else:\n        param_names[self.parameters['variance']] = 'sigma2'\n    return param_names.tolist()",
            "@property\ndef param_names(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        (list of str) List of human readable parameter names (for parameters\\n        actually included in the model).\\n        '\n    param_names = np.array(markov_switching.MarkovSwitching.param_names.fget(self), dtype=object)\n    if np.any(self.switching_coeffs):\n        for i in range(self.k_regimes):\n            param_names[self.parameters[i, 'exog']] = ['%s[%d]' % (exog_name, i) for exog_name in self.exog_names]\n    else:\n        param_names[self.parameters['exog']] = self.exog_names\n    if self.switching_variance:\n        for i in range(self.k_regimes):\n            param_names[self.parameters[i, 'variance']] = 'sigma2[%d]' % i\n    else:\n        param_names[self.parameters['variance']] = 'sigma2'\n    return param_names.tolist()",
            "@property\ndef param_names(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        (list of str) List of human readable parameter names (for parameters\\n        actually included in the model).\\n        '\n    param_names = np.array(markov_switching.MarkovSwitching.param_names.fget(self), dtype=object)\n    if np.any(self.switching_coeffs):\n        for i in range(self.k_regimes):\n            param_names[self.parameters[i, 'exog']] = ['%s[%d]' % (exog_name, i) for exog_name in self.exog_names]\n    else:\n        param_names[self.parameters['exog']] = self.exog_names\n    if self.switching_variance:\n        for i in range(self.k_regimes):\n            param_names[self.parameters[i, 'variance']] = 'sigma2[%d]' % i\n    else:\n        param_names[self.parameters['variance']] = 'sigma2'\n    return param_names.tolist()",
            "@property\ndef param_names(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        (list of str) List of human readable parameter names (for parameters\\n        actually included in the model).\\n        '\n    param_names = np.array(markov_switching.MarkovSwitching.param_names.fget(self), dtype=object)\n    if np.any(self.switching_coeffs):\n        for i in range(self.k_regimes):\n            param_names[self.parameters[i, 'exog']] = ['%s[%d]' % (exog_name, i) for exog_name in self.exog_names]\n    else:\n        param_names[self.parameters['exog']] = self.exog_names\n    if self.switching_variance:\n        for i in range(self.k_regimes):\n            param_names[self.parameters[i, 'variance']] = 'sigma2[%d]' % i\n    else:\n        param_names[self.parameters['variance']] = 'sigma2'\n    return param_names.tolist()"
        ]
    },
    {
        "func_name": "transform_params",
        "original": "def transform_params(self, unconstrained):\n    \"\"\"\n        Transform unconstrained parameters used by the optimizer to constrained\n        parameters used in likelihood evaluation\n\n        Parameters\n        ----------\n        unconstrained : array_like\n            Array of unconstrained parameters used by the optimizer, to be\n            transformed.\n\n        Returns\n        -------\n        constrained : array_like\n            Array of constrained parameters which may be used in likelihood\n            evaluation.\n        \"\"\"\n    constrained = super(MarkovRegression, self).transform_params(unconstrained)\n    constrained[self.parameters['exog']] = unconstrained[self.parameters['exog']]\n    constrained[self.parameters['variance']] = unconstrained[self.parameters['variance']] ** 2\n    return constrained",
        "mutated": [
            "def transform_params(self, unconstrained):\n    if False:\n        i = 10\n    '\\n        Transform unconstrained parameters used by the optimizer to constrained\\n        parameters used in likelihood evaluation\\n\\n        Parameters\\n        ----------\\n        unconstrained : array_like\\n            Array of unconstrained parameters used by the optimizer, to be\\n            transformed.\\n\\n        Returns\\n        -------\\n        constrained : array_like\\n            Array of constrained parameters which may be used in likelihood\\n            evaluation.\\n        '\n    constrained = super(MarkovRegression, self).transform_params(unconstrained)\n    constrained[self.parameters['exog']] = unconstrained[self.parameters['exog']]\n    constrained[self.parameters['variance']] = unconstrained[self.parameters['variance']] ** 2\n    return constrained",
            "def transform_params(self, unconstrained):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Transform unconstrained parameters used by the optimizer to constrained\\n        parameters used in likelihood evaluation\\n\\n        Parameters\\n        ----------\\n        unconstrained : array_like\\n            Array of unconstrained parameters used by the optimizer, to be\\n            transformed.\\n\\n        Returns\\n        -------\\n        constrained : array_like\\n            Array of constrained parameters which may be used in likelihood\\n            evaluation.\\n        '\n    constrained = super(MarkovRegression, self).transform_params(unconstrained)\n    constrained[self.parameters['exog']] = unconstrained[self.parameters['exog']]\n    constrained[self.parameters['variance']] = unconstrained[self.parameters['variance']] ** 2\n    return constrained",
            "def transform_params(self, unconstrained):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Transform unconstrained parameters used by the optimizer to constrained\\n        parameters used in likelihood evaluation\\n\\n        Parameters\\n        ----------\\n        unconstrained : array_like\\n            Array of unconstrained parameters used by the optimizer, to be\\n            transformed.\\n\\n        Returns\\n        -------\\n        constrained : array_like\\n            Array of constrained parameters which may be used in likelihood\\n            evaluation.\\n        '\n    constrained = super(MarkovRegression, self).transform_params(unconstrained)\n    constrained[self.parameters['exog']] = unconstrained[self.parameters['exog']]\n    constrained[self.parameters['variance']] = unconstrained[self.parameters['variance']] ** 2\n    return constrained",
            "def transform_params(self, unconstrained):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Transform unconstrained parameters used by the optimizer to constrained\\n        parameters used in likelihood evaluation\\n\\n        Parameters\\n        ----------\\n        unconstrained : array_like\\n            Array of unconstrained parameters used by the optimizer, to be\\n            transformed.\\n\\n        Returns\\n        -------\\n        constrained : array_like\\n            Array of constrained parameters which may be used in likelihood\\n            evaluation.\\n        '\n    constrained = super(MarkovRegression, self).transform_params(unconstrained)\n    constrained[self.parameters['exog']] = unconstrained[self.parameters['exog']]\n    constrained[self.parameters['variance']] = unconstrained[self.parameters['variance']] ** 2\n    return constrained",
            "def transform_params(self, unconstrained):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Transform unconstrained parameters used by the optimizer to constrained\\n        parameters used in likelihood evaluation\\n\\n        Parameters\\n        ----------\\n        unconstrained : array_like\\n            Array of unconstrained parameters used by the optimizer, to be\\n            transformed.\\n\\n        Returns\\n        -------\\n        constrained : array_like\\n            Array of constrained parameters which may be used in likelihood\\n            evaluation.\\n        '\n    constrained = super(MarkovRegression, self).transform_params(unconstrained)\n    constrained[self.parameters['exog']] = unconstrained[self.parameters['exog']]\n    constrained[self.parameters['variance']] = unconstrained[self.parameters['variance']] ** 2\n    return constrained"
        ]
    },
    {
        "func_name": "untransform_params",
        "original": "def untransform_params(self, constrained):\n    \"\"\"\n        Transform constrained parameters used in likelihood evaluation\n        to unconstrained parameters used by the optimizer\n\n        Parameters\n        ----------\n        constrained : array_like\n            Array of constrained parameters used in likelihood evaluation, to\n            be transformed.\n\n        Returns\n        -------\n        unconstrained : array_like\n            Array of unconstrained parameters used by the optimizer.\n        \"\"\"\n    unconstrained = super(MarkovRegression, self).untransform_params(constrained)\n    unconstrained[self.parameters['exog']] = constrained[self.parameters['exog']]\n    unconstrained[self.parameters['variance']] = constrained[self.parameters['variance']] ** 0.5\n    return unconstrained",
        "mutated": [
            "def untransform_params(self, constrained):\n    if False:\n        i = 10\n    '\\n        Transform constrained parameters used in likelihood evaluation\\n        to unconstrained parameters used by the optimizer\\n\\n        Parameters\\n        ----------\\n        constrained : array_like\\n            Array of constrained parameters used in likelihood evaluation, to\\n            be transformed.\\n\\n        Returns\\n        -------\\n        unconstrained : array_like\\n            Array of unconstrained parameters used by the optimizer.\\n        '\n    unconstrained = super(MarkovRegression, self).untransform_params(constrained)\n    unconstrained[self.parameters['exog']] = constrained[self.parameters['exog']]\n    unconstrained[self.parameters['variance']] = constrained[self.parameters['variance']] ** 0.5\n    return unconstrained",
            "def untransform_params(self, constrained):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Transform constrained parameters used in likelihood evaluation\\n        to unconstrained parameters used by the optimizer\\n\\n        Parameters\\n        ----------\\n        constrained : array_like\\n            Array of constrained parameters used in likelihood evaluation, to\\n            be transformed.\\n\\n        Returns\\n        -------\\n        unconstrained : array_like\\n            Array of unconstrained parameters used by the optimizer.\\n        '\n    unconstrained = super(MarkovRegression, self).untransform_params(constrained)\n    unconstrained[self.parameters['exog']] = constrained[self.parameters['exog']]\n    unconstrained[self.parameters['variance']] = constrained[self.parameters['variance']] ** 0.5\n    return unconstrained",
            "def untransform_params(self, constrained):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Transform constrained parameters used in likelihood evaluation\\n        to unconstrained parameters used by the optimizer\\n\\n        Parameters\\n        ----------\\n        constrained : array_like\\n            Array of constrained parameters used in likelihood evaluation, to\\n            be transformed.\\n\\n        Returns\\n        -------\\n        unconstrained : array_like\\n            Array of unconstrained parameters used by the optimizer.\\n        '\n    unconstrained = super(MarkovRegression, self).untransform_params(constrained)\n    unconstrained[self.parameters['exog']] = constrained[self.parameters['exog']]\n    unconstrained[self.parameters['variance']] = constrained[self.parameters['variance']] ** 0.5\n    return unconstrained",
            "def untransform_params(self, constrained):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Transform constrained parameters used in likelihood evaluation\\n        to unconstrained parameters used by the optimizer\\n\\n        Parameters\\n        ----------\\n        constrained : array_like\\n            Array of constrained parameters used in likelihood evaluation, to\\n            be transformed.\\n\\n        Returns\\n        -------\\n        unconstrained : array_like\\n            Array of unconstrained parameters used by the optimizer.\\n        '\n    unconstrained = super(MarkovRegression, self).untransform_params(constrained)\n    unconstrained[self.parameters['exog']] = constrained[self.parameters['exog']]\n    unconstrained[self.parameters['variance']] = constrained[self.parameters['variance']] ** 0.5\n    return unconstrained",
            "def untransform_params(self, constrained):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Transform constrained parameters used in likelihood evaluation\\n        to unconstrained parameters used by the optimizer\\n\\n        Parameters\\n        ----------\\n        constrained : array_like\\n            Array of constrained parameters used in likelihood evaluation, to\\n            be transformed.\\n\\n        Returns\\n        -------\\n        unconstrained : array_like\\n            Array of unconstrained parameters used by the optimizer.\\n        '\n    unconstrained = super(MarkovRegression, self).untransform_params(constrained)\n    unconstrained[self.parameters['exog']] = constrained[self.parameters['exog']]\n    unconstrained[self.parameters['variance']] = constrained[self.parameters['variance']] ** 0.5\n    return unconstrained"
        ]
    }
]