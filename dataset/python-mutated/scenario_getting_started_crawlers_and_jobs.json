[
    {
        "func_name": "__init__",
        "original": "def __init__(self, glue_client, glue_service_role, glue_bucket):\n    \"\"\"\n        :param glue_client: A Boto3 AWS Glue client.\n        :param glue_service_role: An AWS Identity and Access Management (IAM) role\n                                  that AWS Glue can assume to gain access to the\n                                  resources it requires.\n        :param glue_bucket: An S3 bucket that can hold a job script and output data\n                            from AWS Glue job runs.\n        \"\"\"\n    self.glue_client = glue_client\n    self.glue_service_role = glue_service_role\n    self.glue_bucket = glue_bucket",
        "mutated": [
            "def __init__(self, glue_client, glue_service_role, glue_bucket):\n    if False:\n        i = 10\n    '\\n        :param glue_client: A Boto3 AWS Glue client.\\n        :param glue_service_role: An AWS Identity and Access Management (IAM) role\\n                                  that AWS Glue can assume to gain access to the\\n                                  resources it requires.\\n        :param glue_bucket: An S3 bucket that can hold a job script and output data\\n                            from AWS Glue job runs.\\n        '\n    self.glue_client = glue_client\n    self.glue_service_role = glue_service_role\n    self.glue_bucket = glue_bucket",
            "def __init__(self, glue_client, glue_service_role, glue_bucket):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        :param glue_client: A Boto3 AWS Glue client.\\n        :param glue_service_role: An AWS Identity and Access Management (IAM) role\\n                                  that AWS Glue can assume to gain access to the\\n                                  resources it requires.\\n        :param glue_bucket: An S3 bucket that can hold a job script and output data\\n                            from AWS Glue job runs.\\n        '\n    self.glue_client = glue_client\n    self.glue_service_role = glue_service_role\n    self.glue_bucket = glue_bucket",
            "def __init__(self, glue_client, glue_service_role, glue_bucket):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        :param glue_client: A Boto3 AWS Glue client.\\n        :param glue_service_role: An AWS Identity and Access Management (IAM) role\\n                                  that AWS Glue can assume to gain access to the\\n                                  resources it requires.\\n        :param glue_bucket: An S3 bucket that can hold a job script and output data\\n                            from AWS Glue job runs.\\n        '\n    self.glue_client = glue_client\n    self.glue_service_role = glue_service_role\n    self.glue_bucket = glue_bucket",
            "def __init__(self, glue_client, glue_service_role, glue_bucket):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        :param glue_client: A Boto3 AWS Glue client.\\n        :param glue_service_role: An AWS Identity and Access Management (IAM) role\\n                                  that AWS Glue can assume to gain access to the\\n                                  resources it requires.\\n        :param glue_bucket: An S3 bucket that can hold a job script and output data\\n                            from AWS Glue job runs.\\n        '\n    self.glue_client = glue_client\n    self.glue_service_role = glue_service_role\n    self.glue_bucket = glue_bucket",
            "def __init__(self, glue_client, glue_service_role, glue_bucket):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        :param glue_client: A Boto3 AWS Glue client.\\n        :param glue_service_role: An AWS Identity and Access Management (IAM) role\\n                                  that AWS Glue can assume to gain access to the\\n                                  resources it requires.\\n        :param glue_bucket: An S3 bucket that can hold a job script and output data\\n                            from AWS Glue job runs.\\n        '\n    self.glue_client = glue_client\n    self.glue_service_role = glue_service_role\n    self.glue_bucket = glue_bucket"
        ]
    },
    {
        "func_name": "wait",
        "original": "@staticmethod\ndef wait(seconds, tick=12):\n    \"\"\"\n        Waits for a specified number of seconds, while also displaying an animated\n        spinner.\n\n        :param seconds: The number of seconds to wait.\n        :param tick: The number of frames per second used to animate the spinner.\n        \"\"\"\n    progress = '|/-\\\\'\n    waited = 0\n    while waited < seconds:\n        for frame in range(tick):\n            sys.stdout.write(f'\\r{progress[frame % len(progress)]}')\n            sys.stdout.flush()\n            time.sleep(1 / tick)\n        waited += 1",
        "mutated": [
            "@staticmethod\ndef wait(seconds, tick=12):\n    if False:\n        i = 10\n    '\\n        Waits for a specified number of seconds, while also displaying an animated\\n        spinner.\\n\\n        :param seconds: The number of seconds to wait.\\n        :param tick: The number of frames per second used to animate the spinner.\\n        '\n    progress = '|/-\\\\'\n    waited = 0\n    while waited < seconds:\n        for frame in range(tick):\n            sys.stdout.write(f'\\r{progress[frame % len(progress)]}')\n            sys.stdout.flush()\n            time.sleep(1 / tick)\n        waited += 1",
            "@staticmethod\ndef wait(seconds, tick=12):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Waits for a specified number of seconds, while also displaying an animated\\n        spinner.\\n\\n        :param seconds: The number of seconds to wait.\\n        :param tick: The number of frames per second used to animate the spinner.\\n        '\n    progress = '|/-\\\\'\n    waited = 0\n    while waited < seconds:\n        for frame in range(tick):\n            sys.stdout.write(f'\\r{progress[frame % len(progress)]}')\n            sys.stdout.flush()\n            time.sleep(1 / tick)\n        waited += 1",
            "@staticmethod\ndef wait(seconds, tick=12):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Waits for a specified number of seconds, while also displaying an animated\\n        spinner.\\n\\n        :param seconds: The number of seconds to wait.\\n        :param tick: The number of frames per second used to animate the spinner.\\n        '\n    progress = '|/-\\\\'\n    waited = 0\n    while waited < seconds:\n        for frame in range(tick):\n            sys.stdout.write(f'\\r{progress[frame % len(progress)]}')\n            sys.stdout.flush()\n            time.sleep(1 / tick)\n        waited += 1",
            "@staticmethod\ndef wait(seconds, tick=12):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Waits for a specified number of seconds, while also displaying an animated\\n        spinner.\\n\\n        :param seconds: The number of seconds to wait.\\n        :param tick: The number of frames per second used to animate the spinner.\\n        '\n    progress = '|/-\\\\'\n    waited = 0\n    while waited < seconds:\n        for frame in range(tick):\n            sys.stdout.write(f'\\r{progress[frame % len(progress)]}')\n            sys.stdout.flush()\n            time.sleep(1 / tick)\n        waited += 1",
            "@staticmethod\ndef wait(seconds, tick=12):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Waits for a specified number of seconds, while also displaying an animated\\n        spinner.\\n\\n        :param seconds: The number of seconds to wait.\\n        :param tick: The number of frames per second used to animate the spinner.\\n        '\n    progress = '|/-\\\\'\n    waited = 0\n    while waited < seconds:\n        for frame in range(tick):\n            sys.stdout.write(f'\\r{progress[frame % len(progress)]}')\n            sys.stdout.flush()\n            time.sleep(1 / tick)\n        waited += 1"
        ]
    },
    {
        "func_name": "upload_job_script",
        "original": "def upload_job_script(self, job_script):\n    \"\"\"\n        Uploads a Python ETL script to an S3 bucket. The script is used by the AWS Glue\n        job to transform data.\n\n        :param job_script: The relative path to the job script.\n        \"\"\"\n    try:\n        self.glue_bucket.upload_file(Filename=job_script, Key=job_script)\n        print(f\"Uploaded job script '{job_script}' to the example bucket.\")\n    except S3UploadFailedError as err:\n        logger.error(\"Couldn't upload job script. Here's why: %s\", err)\n        raise",
        "mutated": [
            "def upload_job_script(self, job_script):\n    if False:\n        i = 10\n    '\\n        Uploads a Python ETL script to an S3 bucket. The script is used by the AWS Glue\\n        job to transform data.\\n\\n        :param job_script: The relative path to the job script.\\n        '\n    try:\n        self.glue_bucket.upload_file(Filename=job_script, Key=job_script)\n        print(f\"Uploaded job script '{job_script}' to the example bucket.\")\n    except S3UploadFailedError as err:\n        logger.error(\"Couldn't upload job script. Here's why: %s\", err)\n        raise",
            "def upload_job_script(self, job_script):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Uploads a Python ETL script to an S3 bucket. The script is used by the AWS Glue\\n        job to transform data.\\n\\n        :param job_script: The relative path to the job script.\\n        '\n    try:\n        self.glue_bucket.upload_file(Filename=job_script, Key=job_script)\n        print(f\"Uploaded job script '{job_script}' to the example bucket.\")\n    except S3UploadFailedError as err:\n        logger.error(\"Couldn't upload job script. Here's why: %s\", err)\n        raise",
            "def upload_job_script(self, job_script):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Uploads a Python ETL script to an S3 bucket. The script is used by the AWS Glue\\n        job to transform data.\\n\\n        :param job_script: The relative path to the job script.\\n        '\n    try:\n        self.glue_bucket.upload_file(Filename=job_script, Key=job_script)\n        print(f\"Uploaded job script '{job_script}' to the example bucket.\")\n    except S3UploadFailedError as err:\n        logger.error(\"Couldn't upload job script. Here's why: %s\", err)\n        raise",
            "def upload_job_script(self, job_script):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Uploads a Python ETL script to an S3 bucket. The script is used by the AWS Glue\\n        job to transform data.\\n\\n        :param job_script: The relative path to the job script.\\n        '\n    try:\n        self.glue_bucket.upload_file(Filename=job_script, Key=job_script)\n        print(f\"Uploaded job script '{job_script}' to the example bucket.\")\n    except S3UploadFailedError as err:\n        logger.error(\"Couldn't upload job script. Here's why: %s\", err)\n        raise",
            "def upload_job_script(self, job_script):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Uploads a Python ETL script to an S3 bucket. The script is used by the AWS Glue\\n        job to transform data.\\n\\n        :param job_script: The relative path to the job script.\\n        '\n    try:\n        self.glue_bucket.upload_file(Filename=job_script, Key=job_script)\n        print(f\"Uploaded job script '{job_script}' to the example bucket.\")\n    except S3UploadFailedError as err:\n        logger.error(\"Couldn't upload job script. Here's why: %s\", err)\n        raise"
        ]
    },
    {
        "func_name": "run",
        "original": "def run(self, crawler_name, db_name, db_prefix, data_source, job_script, job_name):\n    \"\"\"\n        Runs the scenario. This is an interactive experience that runs at a command\n        prompt and asks you for input throughout.\n\n        :param crawler_name: The name of the crawler used in the scenario. If the\n                             crawler does not exist, it is created.\n        :param db_name: The name to give the metadata database created by the crawler.\n        :param db_prefix: The prefix to give tables added to the database by the\n                          crawler.\n        :param data_source: The location of the data source that is targeted by the\n                            crawler and extracted during job runs.\n        :param job_script: The job script that is used to transform data during job\n                           runs.\n        :param job_name: The name to give the job definition that is created during the\n                         scenario.\n        \"\"\"\n    wrapper = GlueWrapper(self.glue_client)\n    print(f'Checking for crawler {crawler_name}.')\n    crawler = wrapper.get_crawler(crawler_name)\n    if crawler is None:\n        print(f'Creating crawler {crawler_name}.')\n        wrapper.create_crawler(crawler_name, self.glue_service_role.arn, db_name, db_prefix, data_source)\n        print(f'Created crawler {crawler_name}.')\n        crawler = wrapper.get_crawler(crawler_name)\n    pprint(crawler)\n    print('-' * 88)\n    print(f'When you run the crawler, it crawls data stored in {data_source} and creates a metadata database in the AWS Glue Data Catalog that describes the data in the data source.')\n    print('In this example, the source data is in CSV format.')\n    ready = False\n    while not ready:\n        ready = Question.ask_question('Ready to start the crawler? (y/n) ', Question.is_yesno)\n    wrapper.start_crawler(crawler_name)\n    print(\"Let's wait for the crawler to run. This typically takes a few minutes.\")\n    crawler_state = None\n    while crawler_state != 'READY':\n        self.wait(10)\n        crawler = wrapper.get_crawler(crawler_name)\n        crawler_state = crawler['State']\n        print(f\"Crawler is {crawler['State']}.\")\n    print('-' * 88)\n    database = wrapper.get_database(db_name)\n    print(f'The crawler created database {db_name}:')\n    pprint(database)\n    print(f'The database contains these tables:')\n    tables = wrapper.get_tables(db_name)\n    for (index, table) in enumerate(tables):\n        print(f\"\\t{index + 1}. {table['Name']}\")\n    table_index = Question.ask_question(f'Enter the number of a table to see more detail: ', Question.is_int, Question.in_range(1, len(tables)))\n    pprint(tables[table_index - 1])\n    print('-' * 88)\n    print(f'Creating job definition {job_name}.')\n    wrapper.create_job(job_name, 'Getting started example job.', self.glue_service_role.arn, f's3://{self.glue_bucket.name}/{job_script}')\n    print('Created job definition.')\n    print(f'When you run the job, it extracts data from {data_source}, transforms it by using the {job_script} script, and loads the output into S3 bucket {self.glue_bucket.name}.')\n    print('In this example, the data is transformed from CSV to JSON, and only a few fields are included in the output.')\n    job_run_status = None\n    if Question.ask_question(f'Ready to run? (y/n) ', Question.is_yesno):\n        job_run_id = wrapper.start_job_run(job_name, db_name, tables[0]['Name'], self.glue_bucket.name)\n        print(f\"Job {job_name} started. Let's wait for it to run.\")\n        while job_run_status not in ['SUCCEEDED', 'STOPPED', 'FAILED', 'TIMEOUT']:\n            self.wait(10)\n            job_run = wrapper.get_job_run(job_name, job_run_id)\n            job_run_status = job_run['JobRunState']\n            print(f'Job {job_name}/{job_run_id} is {job_run_status}.')\n    print('-' * 88)\n    if job_run_status == 'SUCCEEDED':\n        print(f\"Data from your job run is stored in your S3 bucket '{self.glue_bucket.name}':\")\n        try:\n            keys = [obj.key for obj in self.glue_bucket.objects.filter(Prefix='run-')]\n            for (index, key) in enumerate(keys):\n                print(f'\\t{index + 1}: {key}')\n            lines = 4\n            key_index = Question.ask_question(f'Enter the number of a block to download it and see the first {lines} lines of JSON output in the block: ', Question.is_int, Question.in_range(1, len(keys)))\n            job_data = io.BytesIO()\n            self.glue_bucket.download_fileobj(keys[key_index - 1], job_data)\n            job_data.seek(0)\n            for _ in range(lines):\n                print(job_data.readline().decode('utf-8'))\n        except ClientError as err:\n            logger.error(\"Couldn't get job run data. Here's why: %s: %s\", err.response['Error']['Code'], err.response['Error']['Message'])\n            raise\n        print('-' * 88)\n    job_names = wrapper.list_jobs()\n    if job_names:\n        print(f'Your account has {len(job_names)} jobs defined:')\n        for (index, job_name) in enumerate(job_names):\n            print(f'\\t{index + 1}. {job_name}')\n        job_index = Question.ask_question(f'Enter a number between 1 and {len(job_names)} to see the list of runs for a job: ', Question.is_int, Question.in_range(1, len(job_names)))\n        job_runs = wrapper.get_job_runs(job_names[job_index - 1])\n        if job_runs:\n            print(f'Found {len(job_runs)} runs for job {job_names[job_index - 1]}:')\n            for (index, job_run) in enumerate(job_runs):\n                print(f\"\\t{index + 1}. {job_run['JobRunState']} on {job_run['CompletedOn']:%Y-%m-%d %H:%M:%S}\")\n            run_index = Question.ask_question(f'Enter a number between 1 and {len(job_runs)} to see details for a run: ', Question.is_int, Question.in_range(1, len(job_runs)))\n            pprint(job_runs[run_index - 1])\n        else:\n            print(f'No runs found for job {job_names[job_index - 1]}')\n    else:\n        print(\"Your account doesn't have any jobs defined.\")\n    print('-' * 88)\n    print(f\"Let's clean up. During this example we created job definition '{job_name}'.\")\n    if Question.ask_question('Do you want to delete the definition and all runs? (y/n) ', Question.is_yesno):\n        wrapper.delete_job(job_name)\n        print(f\"Job definition '{job_name}' deleted.\")\n    tables = wrapper.get_tables(db_name)\n    print(f\"We also created database '{db_name}' that contains these tables:\")\n    for table in tables:\n        print(f\"\\t{table['Name']}\")\n    if Question.ask_question('Do you want to delete the tables and the database? (y/n) ', Question.is_yesno):\n        for table in tables:\n            wrapper.delete_table(db_name, table['Name'])\n            print(f\"Deleted table {table['Name']}.\")\n        wrapper.delete_database(db_name)\n        print(f'Deleted database {db_name}.')\n    print(f\"We also created crawler '{crawler_name}'.\")\n    if Question.ask_question('Do you want to delete the crawler? (y/n) ', Question.is_yesno):\n        wrapper.delete_crawler(crawler_name)\n        print(f'Deleted crawler {crawler_name}.')\n    print('-' * 88)",
        "mutated": [
            "def run(self, crawler_name, db_name, db_prefix, data_source, job_script, job_name):\n    if False:\n        i = 10\n    '\\n        Runs the scenario. This is an interactive experience that runs at a command\\n        prompt and asks you for input throughout.\\n\\n        :param crawler_name: The name of the crawler used in the scenario. If the\\n                             crawler does not exist, it is created.\\n        :param db_name: The name to give the metadata database created by the crawler.\\n        :param db_prefix: The prefix to give tables added to the database by the\\n                          crawler.\\n        :param data_source: The location of the data source that is targeted by the\\n                            crawler and extracted during job runs.\\n        :param job_script: The job script that is used to transform data during job\\n                           runs.\\n        :param job_name: The name to give the job definition that is created during the\\n                         scenario.\\n        '\n    wrapper = GlueWrapper(self.glue_client)\n    print(f'Checking for crawler {crawler_name}.')\n    crawler = wrapper.get_crawler(crawler_name)\n    if crawler is None:\n        print(f'Creating crawler {crawler_name}.')\n        wrapper.create_crawler(crawler_name, self.glue_service_role.arn, db_name, db_prefix, data_source)\n        print(f'Created crawler {crawler_name}.')\n        crawler = wrapper.get_crawler(crawler_name)\n    pprint(crawler)\n    print('-' * 88)\n    print(f'When you run the crawler, it crawls data stored in {data_source} and creates a metadata database in the AWS Glue Data Catalog that describes the data in the data source.')\n    print('In this example, the source data is in CSV format.')\n    ready = False\n    while not ready:\n        ready = Question.ask_question('Ready to start the crawler? (y/n) ', Question.is_yesno)\n    wrapper.start_crawler(crawler_name)\n    print(\"Let's wait for the crawler to run. This typically takes a few minutes.\")\n    crawler_state = None\n    while crawler_state != 'READY':\n        self.wait(10)\n        crawler = wrapper.get_crawler(crawler_name)\n        crawler_state = crawler['State']\n        print(f\"Crawler is {crawler['State']}.\")\n    print('-' * 88)\n    database = wrapper.get_database(db_name)\n    print(f'The crawler created database {db_name}:')\n    pprint(database)\n    print(f'The database contains these tables:')\n    tables = wrapper.get_tables(db_name)\n    for (index, table) in enumerate(tables):\n        print(f\"\\t{index + 1}. {table['Name']}\")\n    table_index = Question.ask_question(f'Enter the number of a table to see more detail: ', Question.is_int, Question.in_range(1, len(tables)))\n    pprint(tables[table_index - 1])\n    print('-' * 88)\n    print(f'Creating job definition {job_name}.')\n    wrapper.create_job(job_name, 'Getting started example job.', self.glue_service_role.arn, f's3://{self.glue_bucket.name}/{job_script}')\n    print('Created job definition.')\n    print(f'When you run the job, it extracts data from {data_source}, transforms it by using the {job_script} script, and loads the output into S3 bucket {self.glue_bucket.name}.')\n    print('In this example, the data is transformed from CSV to JSON, and only a few fields are included in the output.')\n    job_run_status = None\n    if Question.ask_question(f'Ready to run? (y/n) ', Question.is_yesno):\n        job_run_id = wrapper.start_job_run(job_name, db_name, tables[0]['Name'], self.glue_bucket.name)\n        print(f\"Job {job_name} started. Let's wait for it to run.\")\n        while job_run_status not in ['SUCCEEDED', 'STOPPED', 'FAILED', 'TIMEOUT']:\n            self.wait(10)\n            job_run = wrapper.get_job_run(job_name, job_run_id)\n            job_run_status = job_run['JobRunState']\n            print(f'Job {job_name}/{job_run_id} is {job_run_status}.')\n    print('-' * 88)\n    if job_run_status == 'SUCCEEDED':\n        print(f\"Data from your job run is stored in your S3 bucket '{self.glue_bucket.name}':\")\n        try:\n            keys = [obj.key for obj in self.glue_bucket.objects.filter(Prefix='run-')]\n            for (index, key) in enumerate(keys):\n                print(f'\\t{index + 1}: {key}')\n            lines = 4\n            key_index = Question.ask_question(f'Enter the number of a block to download it and see the first {lines} lines of JSON output in the block: ', Question.is_int, Question.in_range(1, len(keys)))\n            job_data = io.BytesIO()\n            self.glue_bucket.download_fileobj(keys[key_index - 1], job_data)\n            job_data.seek(0)\n            for _ in range(lines):\n                print(job_data.readline().decode('utf-8'))\n        except ClientError as err:\n            logger.error(\"Couldn't get job run data. Here's why: %s: %s\", err.response['Error']['Code'], err.response['Error']['Message'])\n            raise\n        print('-' * 88)\n    job_names = wrapper.list_jobs()\n    if job_names:\n        print(f'Your account has {len(job_names)} jobs defined:')\n        for (index, job_name) in enumerate(job_names):\n            print(f'\\t{index + 1}. {job_name}')\n        job_index = Question.ask_question(f'Enter a number between 1 and {len(job_names)} to see the list of runs for a job: ', Question.is_int, Question.in_range(1, len(job_names)))\n        job_runs = wrapper.get_job_runs(job_names[job_index - 1])\n        if job_runs:\n            print(f'Found {len(job_runs)} runs for job {job_names[job_index - 1]}:')\n            for (index, job_run) in enumerate(job_runs):\n                print(f\"\\t{index + 1}. {job_run['JobRunState']} on {job_run['CompletedOn']:%Y-%m-%d %H:%M:%S}\")\n            run_index = Question.ask_question(f'Enter a number between 1 and {len(job_runs)} to see details for a run: ', Question.is_int, Question.in_range(1, len(job_runs)))\n            pprint(job_runs[run_index - 1])\n        else:\n            print(f'No runs found for job {job_names[job_index - 1]}')\n    else:\n        print(\"Your account doesn't have any jobs defined.\")\n    print('-' * 88)\n    print(f\"Let's clean up. During this example we created job definition '{job_name}'.\")\n    if Question.ask_question('Do you want to delete the definition and all runs? (y/n) ', Question.is_yesno):\n        wrapper.delete_job(job_name)\n        print(f\"Job definition '{job_name}' deleted.\")\n    tables = wrapper.get_tables(db_name)\n    print(f\"We also created database '{db_name}' that contains these tables:\")\n    for table in tables:\n        print(f\"\\t{table['Name']}\")\n    if Question.ask_question('Do you want to delete the tables and the database? (y/n) ', Question.is_yesno):\n        for table in tables:\n            wrapper.delete_table(db_name, table['Name'])\n            print(f\"Deleted table {table['Name']}.\")\n        wrapper.delete_database(db_name)\n        print(f'Deleted database {db_name}.')\n    print(f\"We also created crawler '{crawler_name}'.\")\n    if Question.ask_question('Do you want to delete the crawler? (y/n) ', Question.is_yesno):\n        wrapper.delete_crawler(crawler_name)\n        print(f'Deleted crawler {crawler_name}.')\n    print('-' * 88)",
            "def run(self, crawler_name, db_name, db_prefix, data_source, job_script, job_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Runs the scenario. This is an interactive experience that runs at a command\\n        prompt and asks you for input throughout.\\n\\n        :param crawler_name: The name of the crawler used in the scenario. If the\\n                             crawler does not exist, it is created.\\n        :param db_name: The name to give the metadata database created by the crawler.\\n        :param db_prefix: The prefix to give tables added to the database by the\\n                          crawler.\\n        :param data_source: The location of the data source that is targeted by the\\n                            crawler and extracted during job runs.\\n        :param job_script: The job script that is used to transform data during job\\n                           runs.\\n        :param job_name: The name to give the job definition that is created during the\\n                         scenario.\\n        '\n    wrapper = GlueWrapper(self.glue_client)\n    print(f'Checking for crawler {crawler_name}.')\n    crawler = wrapper.get_crawler(crawler_name)\n    if crawler is None:\n        print(f'Creating crawler {crawler_name}.')\n        wrapper.create_crawler(crawler_name, self.glue_service_role.arn, db_name, db_prefix, data_source)\n        print(f'Created crawler {crawler_name}.')\n        crawler = wrapper.get_crawler(crawler_name)\n    pprint(crawler)\n    print('-' * 88)\n    print(f'When you run the crawler, it crawls data stored in {data_source} and creates a metadata database in the AWS Glue Data Catalog that describes the data in the data source.')\n    print('In this example, the source data is in CSV format.')\n    ready = False\n    while not ready:\n        ready = Question.ask_question('Ready to start the crawler? (y/n) ', Question.is_yesno)\n    wrapper.start_crawler(crawler_name)\n    print(\"Let's wait for the crawler to run. This typically takes a few minutes.\")\n    crawler_state = None\n    while crawler_state != 'READY':\n        self.wait(10)\n        crawler = wrapper.get_crawler(crawler_name)\n        crawler_state = crawler['State']\n        print(f\"Crawler is {crawler['State']}.\")\n    print('-' * 88)\n    database = wrapper.get_database(db_name)\n    print(f'The crawler created database {db_name}:')\n    pprint(database)\n    print(f'The database contains these tables:')\n    tables = wrapper.get_tables(db_name)\n    for (index, table) in enumerate(tables):\n        print(f\"\\t{index + 1}. {table['Name']}\")\n    table_index = Question.ask_question(f'Enter the number of a table to see more detail: ', Question.is_int, Question.in_range(1, len(tables)))\n    pprint(tables[table_index - 1])\n    print('-' * 88)\n    print(f'Creating job definition {job_name}.')\n    wrapper.create_job(job_name, 'Getting started example job.', self.glue_service_role.arn, f's3://{self.glue_bucket.name}/{job_script}')\n    print('Created job definition.')\n    print(f'When you run the job, it extracts data from {data_source}, transforms it by using the {job_script} script, and loads the output into S3 bucket {self.glue_bucket.name}.')\n    print('In this example, the data is transformed from CSV to JSON, and only a few fields are included in the output.')\n    job_run_status = None\n    if Question.ask_question(f'Ready to run? (y/n) ', Question.is_yesno):\n        job_run_id = wrapper.start_job_run(job_name, db_name, tables[0]['Name'], self.glue_bucket.name)\n        print(f\"Job {job_name} started. Let's wait for it to run.\")\n        while job_run_status not in ['SUCCEEDED', 'STOPPED', 'FAILED', 'TIMEOUT']:\n            self.wait(10)\n            job_run = wrapper.get_job_run(job_name, job_run_id)\n            job_run_status = job_run['JobRunState']\n            print(f'Job {job_name}/{job_run_id} is {job_run_status}.')\n    print('-' * 88)\n    if job_run_status == 'SUCCEEDED':\n        print(f\"Data from your job run is stored in your S3 bucket '{self.glue_bucket.name}':\")\n        try:\n            keys = [obj.key for obj in self.glue_bucket.objects.filter(Prefix='run-')]\n            for (index, key) in enumerate(keys):\n                print(f'\\t{index + 1}: {key}')\n            lines = 4\n            key_index = Question.ask_question(f'Enter the number of a block to download it and see the first {lines} lines of JSON output in the block: ', Question.is_int, Question.in_range(1, len(keys)))\n            job_data = io.BytesIO()\n            self.glue_bucket.download_fileobj(keys[key_index - 1], job_data)\n            job_data.seek(0)\n            for _ in range(lines):\n                print(job_data.readline().decode('utf-8'))\n        except ClientError as err:\n            logger.error(\"Couldn't get job run data. Here's why: %s: %s\", err.response['Error']['Code'], err.response['Error']['Message'])\n            raise\n        print('-' * 88)\n    job_names = wrapper.list_jobs()\n    if job_names:\n        print(f'Your account has {len(job_names)} jobs defined:')\n        for (index, job_name) in enumerate(job_names):\n            print(f'\\t{index + 1}. {job_name}')\n        job_index = Question.ask_question(f'Enter a number between 1 and {len(job_names)} to see the list of runs for a job: ', Question.is_int, Question.in_range(1, len(job_names)))\n        job_runs = wrapper.get_job_runs(job_names[job_index - 1])\n        if job_runs:\n            print(f'Found {len(job_runs)} runs for job {job_names[job_index - 1]}:')\n            for (index, job_run) in enumerate(job_runs):\n                print(f\"\\t{index + 1}. {job_run['JobRunState']} on {job_run['CompletedOn']:%Y-%m-%d %H:%M:%S}\")\n            run_index = Question.ask_question(f'Enter a number between 1 and {len(job_runs)} to see details for a run: ', Question.is_int, Question.in_range(1, len(job_runs)))\n            pprint(job_runs[run_index - 1])\n        else:\n            print(f'No runs found for job {job_names[job_index - 1]}')\n    else:\n        print(\"Your account doesn't have any jobs defined.\")\n    print('-' * 88)\n    print(f\"Let's clean up. During this example we created job definition '{job_name}'.\")\n    if Question.ask_question('Do you want to delete the definition and all runs? (y/n) ', Question.is_yesno):\n        wrapper.delete_job(job_name)\n        print(f\"Job definition '{job_name}' deleted.\")\n    tables = wrapper.get_tables(db_name)\n    print(f\"We also created database '{db_name}' that contains these tables:\")\n    for table in tables:\n        print(f\"\\t{table['Name']}\")\n    if Question.ask_question('Do you want to delete the tables and the database? (y/n) ', Question.is_yesno):\n        for table in tables:\n            wrapper.delete_table(db_name, table['Name'])\n            print(f\"Deleted table {table['Name']}.\")\n        wrapper.delete_database(db_name)\n        print(f'Deleted database {db_name}.')\n    print(f\"We also created crawler '{crawler_name}'.\")\n    if Question.ask_question('Do you want to delete the crawler? (y/n) ', Question.is_yesno):\n        wrapper.delete_crawler(crawler_name)\n        print(f'Deleted crawler {crawler_name}.')\n    print('-' * 88)",
            "def run(self, crawler_name, db_name, db_prefix, data_source, job_script, job_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Runs the scenario. This is an interactive experience that runs at a command\\n        prompt and asks you for input throughout.\\n\\n        :param crawler_name: The name of the crawler used in the scenario. If the\\n                             crawler does not exist, it is created.\\n        :param db_name: The name to give the metadata database created by the crawler.\\n        :param db_prefix: The prefix to give tables added to the database by the\\n                          crawler.\\n        :param data_source: The location of the data source that is targeted by the\\n                            crawler and extracted during job runs.\\n        :param job_script: The job script that is used to transform data during job\\n                           runs.\\n        :param job_name: The name to give the job definition that is created during the\\n                         scenario.\\n        '\n    wrapper = GlueWrapper(self.glue_client)\n    print(f'Checking for crawler {crawler_name}.')\n    crawler = wrapper.get_crawler(crawler_name)\n    if crawler is None:\n        print(f'Creating crawler {crawler_name}.')\n        wrapper.create_crawler(crawler_name, self.glue_service_role.arn, db_name, db_prefix, data_source)\n        print(f'Created crawler {crawler_name}.')\n        crawler = wrapper.get_crawler(crawler_name)\n    pprint(crawler)\n    print('-' * 88)\n    print(f'When you run the crawler, it crawls data stored in {data_source} and creates a metadata database in the AWS Glue Data Catalog that describes the data in the data source.')\n    print('In this example, the source data is in CSV format.')\n    ready = False\n    while not ready:\n        ready = Question.ask_question('Ready to start the crawler? (y/n) ', Question.is_yesno)\n    wrapper.start_crawler(crawler_name)\n    print(\"Let's wait for the crawler to run. This typically takes a few minutes.\")\n    crawler_state = None\n    while crawler_state != 'READY':\n        self.wait(10)\n        crawler = wrapper.get_crawler(crawler_name)\n        crawler_state = crawler['State']\n        print(f\"Crawler is {crawler['State']}.\")\n    print('-' * 88)\n    database = wrapper.get_database(db_name)\n    print(f'The crawler created database {db_name}:')\n    pprint(database)\n    print(f'The database contains these tables:')\n    tables = wrapper.get_tables(db_name)\n    for (index, table) in enumerate(tables):\n        print(f\"\\t{index + 1}. {table['Name']}\")\n    table_index = Question.ask_question(f'Enter the number of a table to see more detail: ', Question.is_int, Question.in_range(1, len(tables)))\n    pprint(tables[table_index - 1])\n    print('-' * 88)\n    print(f'Creating job definition {job_name}.')\n    wrapper.create_job(job_name, 'Getting started example job.', self.glue_service_role.arn, f's3://{self.glue_bucket.name}/{job_script}')\n    print('Created job definition.')\n    print(f'When you run the job, it extracts data from {data_source}, transforms it by using the {job_script} script, and loads the output into S3 bucket {self.glue_bucket.name}.')\n    print('In this example, the data is transformed from CSV to JSON, and only a few fields are included in the output.')\n    job_run_status = None\n    if Question.ask_question(f'Ready to run? (y/n) ', Question.is_yesno):\n        job_run_id = wrapper.start_job_run(job_name, db_name, tables[0]['Name'], self.glue_bucket.name)\n        print(f\"Job {job_name} started. Let's wait for it to run.\")\n        while job_run_status not in ['SUCCEEDED', 'STOPPED', 'FAILED', 'TIMEOUT']:\n            self.wait(10)\n            job_run = wrapper.get_job_run(job_name, job_run_id)\n            job_run_status = job_run['JobRunState']\n            print(f'Job {job_name}/{job_run_id} is {job_run_status}.')\n    print('-' * 88)\n    if job_run_status == 'SUCCEEDED':\n        print(f\"Data from your job run is stored in your S3 bucket '{self.glue_bucket.name}':\")\n        try:\n            keys = [obj.key for obj in self.glue_bucket.objects.filter(Prefix='run-')]\n            for (index, key) in enumerate(keys):\n                print(f'\\t{index + 1}: {key}')\n            lines = 4\n            key_index = Question.ask_question(f'Enter the number of a block to download it and see the first {lines} lines of JSON output in the block: ', Question.is_int, Question.in_range(1, len(keys)))\n            job_data = io.BytesIO()\n            self.glue_bucket.download_fileobj(keys[key_index - 1], job_data)\n            job_data.seek(0)\n            for _ in range(lines):\n                print(job_data.readline().decode('utf-8'))\n        except ClientError as err:\n            logger.error(\"Couldn't get job run data. Here's why: %s: %s\", err.response['Error']['Code'], err.response['Error']['Message'])\n            raise\n        print('-' * 88)\n    job_names = wrapper.list_jobs()\n    if job_names:\n        print(f'Your account has {len(job_names)} jobs defined:')\n        for (index, job_name) in enumerate(job_names):\n            print(f'\\t{index + 1}. {job_name}')\n        job_index = Question.ask_question(f'Enter a number between 1 and {len(job_names)} to see the list of runs for a job: ', Question.is_int, Question.in_range(1, len(job_names)))\n        job_runs = wrapper.get_job_runs(job_names[job_index - 1])\n        if job_runs:\n            print(f'Found {len(job_runs)} runs for job {job_names[job_index - 1]}:')\n            for (index, job_run) in enumerate(job_runs):\n                print(f\"\\t{index + 1}. {job_run['JobRunState']} on {job_run['CompletedOn']:%Y-%m-%d %H:%M:%S}\")\n            run_index = Question.ask_question(f'Enter a number between 1 and {len(job_runs)} to see details for a run: ', Question.is_int, Question.in_range(1, len(job_runs)))\n            pprint(job_runs[run_index - 1])\n        else:\n            print(f'No runs found for job {job_names[job_index - 1]}')\n    else:\n        print(\"Your account doesn't have any jobs defined.\")\n    print('-' * 88)\n    print(f\"Let's clean up. During this example we created job definition '{job_name}'.\")\n    if Question.ask_question('Do you want to delete the definition and all runs? (y/n) ', Question.is_yesno):\n        wrapper.delete_job(job_name)\n        print(f\"Job definition '{job_name}' deleted.\")\n    tables = wrapper.get_tables(db_name)\n    print(f\"We also created database '{db_name}' that contains these tables:\")\n    for table in tables:\n        print(f\"\\t{table['Name']}\")\n    if Question.ask_question('Do you want to delete the tables and the database? (y/n) ', Question.is_yesno):\n        for table in tables:\n            wrapper.delete_table(db_name, table['Name'])\n            print(f\"Deleted table {table['Name']}.\")\n        wrapper.delete_database(db_name)\n        print(f'Deleted database {db_name}.')\n    print(f\"We also created crawler '{crawler_name}'.\")\n    if Question.ask_question('Do you want to delete the crawler? (y/n) ', Question.is_yesno):\n        wrapper.delete_crawler(crawler_name)\n        print(f'Deleted crawler {crawler_name}.')\n    print('-' * 88)",
            "def run(self, crawler_name, db_name, db_prefix, data_source, job_script, job_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Runs the scenario. This is an interactive experience that runs at a command\\n        prompt and asks you for input throughout.\\n\\n        :param crawler_name: The name of the crawler used in the scenario. If the\\n                             crawler does not exist, it is created.\\n        :param db_name: The name to give the metadata database created by the crawler.\\n        :param db_prefix: The prefix to give tables added to the database by the\\n                          crawler.\\n        :param data_source: The location of the data source that is targeted by the\\n                            crawler and extracted during job runs.\\n        :param job_script: The job script that is used to transform data during job\\n                           runs.\\n        :param job_name: The name to give the job definition that is created during the\\n                         scenario.\\n        '\n    wrapper = GlueWrapper(self.glue_client)\n    print(f'Checking for crawler {crawler_name}.')\n    crawler = wrapper.get_crawler(crawler_name)\n    if crawler is None:\n        print(f'Creating crawler {crawler_name}.')\n        wrapper.create_crawler(crawler_name, self.glue_service_role.arn, db_name, db_prefix, data_source)\n        print(f'Created crawler {crawler_name}.')\n        crawler = wrapper.get_crawler(crawler_name)\n    pprint(crawler)\n    print('-' * 88)\n    print(f'When you run the crawler, it crawls data stored in {data_source} and creates a metadata database in the AWS Glue Data Catalog that describes the data in the data source.')\n    print('In this example, the source data is in CSV format.')\n    ready = False\n    while not ready:\n        ready = Question.ask_question('Ready to start the crawler? (y/n) ', Question.is_yesno)\n    wrapper.start_crawler(crawler_name)\n    print(\"Let's wait for the crawler to run. This typically takes a few minutes.\")\n    crawler_state = None\n    while crawler_state != 'READY':\n        self.wait(10)\n        crawler = wrapper.get_crawler(crawler_name)\n        crawler_state = crawler['State']\n        print(f\"Crawler is {crawler['State']}.\")\n    print('-' * 88)\n    database = wrapper.get_database(db_name)\n    print(f'The crawler created database {db_name}:')\n    pprint(database)\n    print(f'The database contains these tables:')\n    tables = wrapper.get_tables(db_name)\n    for (index, table) in enumerate(tables):\n        print(f\"\\t{index + 1}. {table['Name']}\")\n    table_index = Question.ask_question(f'Enter the number of a table to see more detail: ', Question.is_int, Question.in_range(1, len(tables)))\n    pprint(tables[table_index - 1])\n    print('-' * 88)\n    print(f'Creating job definition {job_name}.')\n    wrapper.create_job(job_name, 'Getting started example job.', self.glue_service_role.arn, f's3://{self.glue_bucket.name}/{job_script}')\n    print('Created job definition.')\n    print(f'When you run the job, it extracts data from {data_source}, transforms it by using the {job_script} script, and loads the output into S3 bucket {self.glue_bucket.name}.')\n    print('In this example, the data is transformed from CSV to JSON, and only a few fields are included in the output.')\n    job_run_status = None\n    if Question.ask_question(f'Ready to run? (y/n) ', Question.is_yesno):\n        job_run_id = wrapper.start_job_run(job_name, db_name, tables[0]['Name'], self.glue_bucket.name)\n        print(f\"Job {job_name} started. Let's wait for it to run.\")\n        while job_run_status not in ['SUCCEEDED', 'STOPPED', 'FAILED', 'TIMEOUT']:\n            self.wait(10)\n            job_run = wrapper.get_job_run(job_name, job_run_id)\n            job_run_status = job_run['JobRunState']\n            print(f'Job {job_name}/{job_run_id} is {job_run_status}.')\n    print('-' * 88)\n    if job_run_status == 'SUCCEEDED':\n        print(f\"Data from your job run is stored in your S3 bucket '{self.glue_bucket.name}':\")\n        try:\n            keys = [obj.key for obj in self.glue_bucket.objects.filter(Prefix='run-')]\n            for (index, key) in enumerate(keys):\n                print(f'\\t{index + 1}: {key}')\n            lines = 4\n            key_index = Question.ask_question(f'Enter the number of a block to download it and see the first {lines} lines of JSON output in the block: ', Question.is_int, Question.in_range(1, len(keys)))\n            job_data = io.BytesIO()\n            self.glue_bucket.download_fileobj(keys[key_index - 1], job_data)\n            job_data.seek(0)\n            for _ in range(lines):\n                print(job_data.readline().decode('utf-8'))\n        except ClientError as err:\n            logger.error(\"Couldn't get job run data. Here's why: %s: %s\", err.response['Error']['Code'], err.response['Error']['Message'])\n            raise\n        print('-' * 88)\n    job_names = wrapper.list_jobs()\n    if job_names:\n        print(f'Your account has {len(job_names)} jobs defined:')\n        for (index, job_name) in enumerate(job_names):\n            print(f'\\t{index + 1}. {job_name}')\n        job_index = Question.ask_question(f'Enter a number between 1 and {len(job_names)} to see the list of runs for a job: ', Question.is_int, Question.in_range(1, len(job_names)))\n        job_runs = wrapper.get_job_runs(job_names[job_index - 1])\n        if job_runs:\n            print(f'Found {len(job_runs)} runs for job {job_names[job_index - 1]}:')\n            for (index, job_run) in enumerate(job_runs):\n                print(f\"\\t{index + 1}. {job_run['JobRunState']} on {job_run['CompletedOn']:%Y-%m-%d %H:%M:%S}\")\n            run_index = Question.ask_question(f'Enter a number between 1 and {len(job_runs)} to see details for a run: ', Question.is_int, Question.in_range(1, len(job_runs)))\n            pprint(job_runs[run_index - 1])\n        else:\n            print(f'No runs found for job {job_names[job_index - 1]}')\n    else:\n        print(\"Your account doesn't have any jobs defined.\")\n    print('-' * 88)\n    print(f\"Let's clean up. During this example we created job definition '{job_name}'.\")\n    if Question.ask_question('Do you want to delete the definition and all runs? (y/n) ', Question.is_yesno):\n        wrapper.delete_job(job_name)\n        print(f\"Job definition '{job_name}' deleted.\")\n    tables = wrapper.get_tables(db_name)\n    print(f\"We also created database '{db_name}' that contains these tables:\")\n    for table in tables:\n        print(f\"\\t{table['Name']}\")\n    if Question.ask_question('Do you want to delete the tables and the database? (y/n) ', Question.is_yesno):\n        for table in tables:\n            wrapper.delete_table(db_name, table['Name'])\n            print(f\"Deleted table {table['Name']}.\")\n        wrapper.delete_database(db_name)\n        print(f'Deleted database {db_name}.')\n    print(f\"We also created crawler '{crawler_name}'.\")\n    if Question.ask_question('Do you want to delete the crawler? (y/n) ', Question.is_yesno):\n        wrapper.delete_crawler(crawler_name)\n        print(f'Deleted crawler {crawler_name}.')\n    print('-' * 88)",
            "def run(self, crawler_name, db_name, db_prefix, data_source, job_script, job_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Runs the scenario. This is an interactive experience that runs at a command\\n        prompt and asks you for input throughout.\\n\\n        :param crawler_name: The name of the crawler used in the scenario. If the\\n                             crawler does not exist, it is created.\\n        :param db_name: The name to give the metadata database created by the crawler.\\n        :param db_prefix: The prefix to give tables added to the database by the\\n                          crawler.\\n        :param data_source: The location of the data source that is targeted by the\\n                            crawler and extracted during job runs.\\n        :param job_script: The job script that is used to transform data during job\\n                           runs.\\n        :param job_name: The name to give the job definition that is created during the\\n                         scenario.\\n        '\n    wrapper = GlueWrapper(self.glue_client)\n    print(f'Checking for crawler {crawler_name}.')\n    crawler = wrapper.get_crawler(crawler_name)\n    if crawler is None:\n        print(f'Creating crawler {crawler_name}.')\n        wrapper.create_crawler(crawler_name, self.glue_service_role.arn, db_name, db_prefix, data_source)\n        print(f'Created crawler {crawler_name}.')\n        crawler = wrapper.get_crawler(crawler_name)\n    pprint(crawler)\n    print('-' * 88)\n    print(f'When you run the crawler, it crawls data stored in {data_source} and creates a metadata database in the AWS Glue Data Catalog that describes the data in the data source.')\n    print('In this example, the source data is in CSV format.')\n    ready = False\n    while not ready:\n        ready = Question.ask_question('Ready to start the crawler? (y/n) ', Question.is_yesno)\n    wrapper.start_crawler(crawler_name)\n    print(\"Let's wait for the crawler to run. This typically takes a few minutes.\")\n    crawler_state = None\n    while crawler_state != 'READY':\n        self.wait(10)\n        crawler = wrapper.get_crawler(crawler_name)\n        crawler_state = crawler['State']\n        print(f\"Crawler is {crawler['State']}.\")\n    print('-' * 88)\n    database = wrapper.get_database(db_name)\n    print(f'The crawler created database {db_name}:')\n    pprint(database)\n    print(f'The database contains these tables:')\n    tables = wrapper.get_tables(db_name)\n    for (index, table) in enumerate(tables):\n        print(f\"\\t{index + 1}. {table['Name']}\")\n    table_index = Question.ask_question(f'Enter the number of a table to see more detail: ', Question.is_int, Question.in_range(1, len(tables)))\n    pprint(tables[table_index - 1])\n    print('-' * 88)\n    print(f'Creating job definition {job_name}.')\n    wrapper.create_job(job_name, 'Getting started example job.', self.glue_service_role.arn, f's3://{self.glue_bucket.name}/{job_script}')\n    print('Created job definition.')\n    print(f'When you run the job, it extracts data from {data_source}, transforms it by using the {job_script} script, and loads the output into S3 bucket {self.glue_bucket.name}.')\n    print('In this example, the data is transformed from CSV to JSON, and only a few fields are included in the output.')\n    job_run_status = None\n    if Question.ask_question(f'Ready to run? (y/n) ', Question.is_yesno):\n        job_run_id = wrapper.start_job_run(job_name, db_name, tables[0]['Name'], self.glue_bucket.name)\n        print(f\"Job {job_name} started. Let's wait for it to run.\")\n        while job_run_status not in ['SUCCEEDED', 'STOPPED', 'FAILED', 'TIMEOUT']:\n            self.wait(10)\n            job_run = wrapper.get_job_run(job_name, job_run_id)\n            job_run_status = job_run['JobRunState']\n            print(f'Job {job_name}/{job_run_id} is {job_run_status}.')\n    print('-' * 88)\n    if job_run_status == 'SUCCEEDED':\n        print(f\"Data from your job run is stored in your S3 bucket '{self.glue_bucket.name}':\")\n        try:\n            keys = [obj.key for obj in self.glue_bucket.objects.filter(Prefix='run-')]\n            for (index, key) in enumerate(keys):\n                print(f'\\t{index + 1}: {key}')\n            lines = 4\n            key_index = Question.ask_question(f'Enter the number of a block to download it and see the first {lines} lines of JSON output in the block: ', Question.is_int, Question.in_range(1, len(keys)))\n            job_data = io.BytesIO()\n            self.glue_bucket.download_fileobj(keys[key_index - 1], job_data)\n            job_data.seek(0)\n            for _ in range(lines):\n                print(job_data.readline().decode('utf-8'))\n        except ClientError as err:\n            logger.error(\"Couldn't get job run data. Here's why: %s: %s\", err.response['Error']['Code'], err.response['Error']['Message'])\n            raise\n        print('-' * 88)\n    job_names = wrapper.list_jobs()\n    if job_names:\n        print(f'Your account has {len(job_names)} jobs defined:')\n        for (index, job_name) in enumerate(job_names):\n            print(f'\\t{index + 1}. {job_name}')\n        job_index = Question.ask_question(f'Enter a number between 1 and {len(job_names)} to see the list of runs for a job: ', Question.is_int, Question.in_range(1, len(job_names)))\n        job_runs = wrapper.get_job_runs(job_names[job_index - 1])\n        if job_runs:\n            print(f'Found {len(job_runs)} runs for job {job_names[job_index - 1]}:')\n            for (index, job_run) in enumerate(job_runs):\n                print(f\"\\t{index + 1}. {job_run['JobRunState']} on {job_run['CompletedOn']:%Y-%m-%d %H:%M:%S}\")\n            run_index = Question.ask_question(f'Enter a number between 1 and {len(job_runs)} to see details for a run: ', Question.is_int, Question.in_range(1, len(job_runs)))\n            pprint(job_runs[run_index - 1])\n        else:\n            print(f'No runs found for job {job_names[job_index - 1]}')\n    else:\n        print(\"Your account doesn't have any jobs defined.\")\n    print('-' * 88)\n    print(f\"Let's clean up. During this example we created job definition '{job_name}'.\")\n    if Question.ask_question('Do you want to delete the definition and all runs? (y/n) ', Question.is_yesno):\n        wrapper.delete_job(job_name)\n        print(f\"Job definition '{job_name}' deleted.\")\n    tables = wrapper.get_tables(db_name)\n    print(f\"We also created database '{db_name}' that contains these tables:\")\n    for table in tables:\n        print(f\"\\t{table['Name']}\")\n    if Question.ask_question('Do you want to delete the tables and the database? (y/n) ', Question.is_yesno):\n        for table in tables:\n            wrapper.delete_table(db_name, table['Name'])\n            print(f\"Deleted table {table['Name']}.\")\n        wrapper.delete_database(db_name)\n        print(f'Deleted database {db_name}.')\n    print(f\"We also created crawler '{crawler_name}'.\")\n    if Question.ask_question('Do you want to delete the crawler? (y/n) ', Question.is_yesno):\n        wrapper.delete_crawler(crawler_name)\n        print(f'Deleted crawler {crawler_name}.')\n    print('-' * 88)"
        ]
    },
    {
        "func_name": "parse_args",
        "original": "def parse_args(args):\n    \"\"\"\n    Parse command line arguments.\n\n    :param args: The command line arguments.\n    :return: The parsed arguments.\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"Runs the AWS Glue getting started with crawlers and jobs scenario. Before you run this scenario, set up scaffold resources by running 'python scaffold.py deploy'.\")\n    parser.add_argument('role_name', help='The name of an IAM role that AWS Glue can assume. This role must grant access to Amazon S3 and to the permissions granted by the AWSGlueServiceRole managed policy.')\n    parser.add_argument('bucket_name', help='The name of an S3 bucket that AWS Glue can access to get the job script and put job results.')\n    parser.add_argument('--job_script', default='flight_etl_job_script.py', help='The name of the job script file that is used in the scenario.')\n    return parser.parse_args(args)",
        "mutated": [
            "def parse_args(args):\n    if False:\n        i = 10\n    '\\n    Parse command line arguments.\\n\\n    :param args: The command line arguments.\\n    :return: The parsed arguments.\\n    '\n    parser = argparse.ArgumentParser(description=\"Runs the AWS Glue getting started with crawlers and jobs scenario. Before you run this scenario, set up scaffold resources by running 'python scaffold.py deploy'.\")\n    parser.add_argument('role_name', help='The name of an IAM role that AWS Glue can assume. This role must grant access to Amazon S3 and to the permissions granted by the AWSGlueServiceRole managed policy.')\n    parser.add_argument('bucket_name', help='The name of an S3 bucket that AWS Glue can access to get the job script and put job results.')\n    parser.add_argument('--job_script', default='flight_etl_job_script.py', help='The name of the job script file that is used in the scenario.')\n    return parser.parse_args(args)",
            "def parse_args(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Parse command line arguments.\\n\\n    :param args: The command line arguments.\\n    :return: The parsed arguments.\\n    '\n    parser = argparse.ArgumentParser(description=\"Runs the AWS Glue getting started with crawlers and jobs scenario. Before you run this scenario, set up scaffold resources by running 'python scaffold.py deploy'.\")\n    parser.add_argument('role_name', help='The name of an IAM role that AWS Glue can assume. This role must grant access to Amazon S3 and to the permissions granted by the AWSGlueServiceRole managed policy.')\n    parser.add_argument('bucket_name', help='The name of an S3 bucket that AWS Glue can access to get the job script and put job results.')\n    parser.add_argument('--job_script', default='flight_etl_job_script.py', help='The name of the job script file that is used in the scenario.')\n    return parser.parse_args(args)",
            "def parse_args(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Parse command line arguments.\\n\\n    :param args: The command line arguments.\\n    :return: The parsed arguments.\\n    '\n    parser = argparse.ArgumentParser(description=\"Runs the AWS Glue getting started with crawlers and jobs scenario. Before you run this scenario, set up scaffold resources by running 'python scaffold.py deploy'.\")\n    parser.add_argument('role_name', help='The name of an IAM role that AWS Glue can assume. This role must grant access to Amazon S3 and to the permissions granted by the AWSGlueServiceRole managed policy.')\n    parser.add_argument('bucket_name', help='The name of an S3 bucket that AWS Glue can access to get the job script and put job results.')\n    parser.add_argument('--job_script', default='flight_etl_job_script.py', help='The name of the job script file that is used in the scenario.')\n    return parser.parse_args(args)",
            "def parse_args(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Parse command line arguments.\\n\\n    :param args: The command line arguments.\\n    :return: The parsed arguments.\\n    '\n    parser = argparse.ArgumentParser(description=\"Runs the AWS Glue getting started with crawlers and jobs scenario. Before you run this scenario, set up scaffold resources by running 'python scaffold.py deploy'.\")\n    parser.add_argument('role_name', help='The name of an IAM role that AWS Glue can assume. This role must grant access to Amazon S3 and to the permissions granted by the AWSGlueServiceRole managed policy.')\n    parser.add_argument('bucket_name', help='The name of an S3 bucket that AWS Glue can access to get the job script and put job results.')\n    parser.add_argument('--job_script', default='flight_etl_job_script.py', help='The name of the job script file that is used in the scenario.')\n    return parser.parse_args(args)",
            "def parse_args(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Parse command line arguments.\\n\\n    :param args: The command line arguments.\\n    :return: The parsed arguments.\\n    '\n    parser = argparse.ArgumentParser(description=\"Runs the AWS Glue getting started with crawlers and jobs scenario. Before you run this scenario, set up scaffold resources by running 'python scaffold.py deploy'.\")\n    parser.add_argument('role_name', help='The name of an IAM role that AWS Glue can assume. This role must grant access to Amazon S3 and to the permissions granted by the AWSGlueServiceRole managed policy.')\n    parser.add_argument('bucket_name', help='The name of an S3 bucket that AWS Glue can access to get the job script and put job results.')\n    parser.add_argument('--job_script', default='flight_etl_job_script.py', help='The name of the job script file that is used in the scenario.')\n    return parser.parse_args(args)"
        ]
    },
    {
        "func_name": "main",
        "original": "def main():\n    args = parse_args(sys.argv[1:])\n    try:\n        print('-' * 88)\n        print('Welcome to the AWS Glue getting started with crawlers and jobs scenario.')\n        print('-' * 88)\n        scenario = GlueCrawlerJobScenario(boto3.client('glue'), boto3.resource('iam').Role(args.role_name), boto3.resource('s3').Bucket(args.bucket_name))\n        scenario.upload_job_script(args.job_script)\n        scenario.run('doc-example-crawler', 'doc-example-database', 'doc-example-', 's3://crawler-public-us-east-1/flight/2016/csv', args.job_script, 'doc-example-job')\n        print('-' * 88)\n        print(\"To destroy scaffold resources, including the IAM role and S3 bucket used in this scenario, run 'python scaffold.py destroy'.\")\n        print('\\nThanks for watching!')\n        print('-' * 88)\n    except Exception:\n        logging.exception('Something went wrong with the example.')",
        "mutated": [
            "def main():\n    if False:\n        i = 10\n    args = parse_args(sys.argv[1:])\n    try:\n        print('-' * 88)\n        print('Welcome to the AWS Glue getting started with crawlers and jobs scenario.')\n        print('-' * 88)\n        scenario = GlueCrawlerJobScenario(boto3.client('glue'), boto3.resource('iam').Role(args.role_name), boto3.resource('s3').Bucket(args.bucket_name))\n        scenario.upload_job_script(args.job_script)\n        scenario.run('doc-example-crawler', 'doc-example-database', 'doc-example-', 's3://crawler-public-us-east-1/flight/2016/csv', args.job_script, 'doc-example-job')\n        print('-' * 88)\n        print(\"To destroy scaffold resources, including the IAM role and S3 bucket used in this scenario, run 'python scaffold.py destroy'.\")\n        print('\\nThanks for watching!')\n        print('-' * 88)\n    except Exception:\n        logging.exception('Something went wrong with the example.')",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    args = parse_args(sys.argv[1:])\n    try:\n        print('-' * 88)\n        print('Welcome to the AWS Glue getting started with crawlers and jobs scenario.')\n        print('-' * 88)\n        scenario = GlueCrawlerJobScenario(boto3.client('glue'), boto3.resource('iam').Role(args.role_name), boto3.resource('s3').Bucket(args.bucket_name))\n        scenario.upload_job_script(args.job_script)\n        scenario.run('doc-example-crawler', 'doc-example-database', 'doc-example-', 's3://crawler-public-us-east-1/flight/2016/csv', args.job_script, 'doc-example-job')\n        print('-' * 88)\n        print(\"To destroy scaffold resources, including the IAM role and S3 bucket used in this scenario, run 'python scaffold.py destroy'.\")\n        print('\\nThanks for watching!')\n        print('-' * 88)\n    except Exception:\n        logging.exception('Something went wrong with the example.')",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    args = parse_args(sys.argv[1:])\n    try:\n        print('-' * 88)\n        print('Welcome to the AWS Glue getting started with crawlers and jobs scenario.')\n        print('-' * 88)\n        scenario = GlueCrawlerJobScenario(boto3.client('glue'), boto3.resource('iam').Role(args.role_name), boto3.resource('s3').Bucket(args.bucket_name))\n        scenario.upload_job_script(args.job_script)\n        scenario.run('doc-example-crawler', 'doc-example-database', 'doc-example-', 's3://crawler-public-us-east-1/flight/2016/csv', args.job_script, 'doc-example-job')\n        print('-' * 88)\n        print(\"To destroy scaffold resources, including the IAM role and S3 bucket used in this scenario, run 'python scaffold.py destroy'.\")\n        print('\\nThanks for watching!')\n        print('-' * 88)\n    except Exception:\n        logging.exception('Something went wrong with the example.')",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    args = parse_args(sys.argv[1:])\n    try:\n        print('-' * 88)\n        print('Welcome to the AWS Glue getting started with crawlers and jobs scenario.')\n        print('-' * 88)\n        scenario = GlueCrawlerJobScenario(boto3.client('glue'), boto3.resource('iam').Role(args.role_name), boto3.resource('s3').Bucket(args.bucket_name))\n        scenario.upload_job_script(args.job_script)\n        scenario.run('doc-example-crawler', 'doc-example-database', 'doc-example-', 's3://crawler-public-us-east-1/flight/2016/csv', args.job_script, 'doc-example-job')\n        print('-' * 88)\n        print(\"To destroy scaffold resources, including the IAM role and S3 bucket used in this scenario, run 'python scaffold.py destroy'.\")\n        print('\\nThanks for watching!')\n        print('-' * 88)\n    except Exception:\n        logging.exception('Something went wrong with the example.')",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    args = parse_args(sys.argv[1:])\n    try:\n        print('-' * 88)\n        print('Welcome to the AWS Glue getting started with crawlers and jobs scenario.')\n        print('-' * 88)\n        scenario = GlueCrawlerJobScenario(boto3.client('glue'), boto3.resource('iam').Role(args.role_name), boto3.resource('s3').Bucket(args.bucket_name))\n        scenario.upload_job_script(args.job_script)\n        scenario.run('doc-example-crawler', 'doc-example-database', 'doc-example-', 's3://crawler-public-us-east-1/flight/2016/csv', args.job_script, 'doc-example-job')\n        print('-' * 88)\n        print(\"To destroy scaffold resources, including the IAM role and S3 bucket used in this scenario, run 'python scaffold.py destroy'.\")\n        print('\\nThanks for watching!')\n        print('-' * 88)\n    except Exception:\n        logging.exception('Something went wrong with the example.')"
        ]
    }
]