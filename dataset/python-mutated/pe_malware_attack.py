"""
This module implements the following white-box attacks related to PE malware crafting:
    1) Append based attacks (example paper link: https://arxiv.org/abs/1810.08280)
    2) Section insertion attacks (example paper link: https://arxiv.org/abs/2008.07125)
    3) Slack manipulation attacks (example paper link: https://arxiv.org/abs/1810.08280)
    4) DOS Header Attacks (example paper link: https://arxiv.org/abs/1901.03583)
"""
import json
import random
import logging
from typing import Optional, Union, Tuple, List, Dict, TYPE_CHECKING
from tqdm.auto import trange
import numpy as np
from art.estimators.estimator import BaseEstimator, NeuralNetworkMixin
from art.estimators.classification.classifier import ClassifierMixin
from art.attacks.attack import EvasionAttack
if TYPE_CHECKING:
    import tensorflow as tf
    from art.utils import CLASSIFIER_NEURALNETWORK_TYPE
logger = logging.getLogger(__name__)

class MalwareGDTensorFlow(EvasionAttack):
    """
    Implementation of the following white-box attacks related to PE malware crafting:
        1) Append based attacks (example paper link: https://arxiv.org/abs/1810.08280)
        2) Section insertion attacks (example paper link: https://arxiv.org/abs/2008.07125)
        3) Slack manipulation attacks (example paper link: https://arxiv.org/abs/1810.08280)
        4) DOS Header Attacks (example paper link: https://arxiv.org/abs/1901.03583)
    """
    attack_params = EvasionAttack.attack_params + ['embedding_weights', 'param_dic', 'num_of_iterations', 'l_0', 'l_r', 'use_sign', 'verbose']
    _estimator_requirements = (BaseEstimator, NeuralNetworkMixin, ClassifierMixin)

    def __init__(self, classifier: 'CLASSIFIER_NEURALNETWORK_TYPE', embedding_weights: np.ndarray, param_dic: Dict[str, int], num_of_iterations: int=10, l_0: Union[float, int]=0.1, l_r: float=1.0, use_sign: bool=False, verbose: bool=False) -> None:
        if False:
            print('Hello World!')
        "\n        :param classifier: A trained classifier that takes in the PE embeddings to make a prediction.\n        :param embedding_weights: Weights for the embedding layer\n        :param param_dic: A dictionary specifying some MalConv parameters.\n                          'maxlen': the input size to the MalConv model\n                          'input_dim': the number of discrete values, normally 257.\n                          'embedding_size': size of the embedding layer. Default 8.\n        :param num_of_iterations: The number of iterations to apply.\n        :param l_0: l_0 bound for the attack. If less then 1 it is interpreted as a fraction of the file size.\n                    If larger than 1 it is interpreted as the total number of permissible features to change.\n        :param l_r: Learning rate for the optimisation\n        :param use_sign: If we want to use the sign of the gradient, rather then the gradient itself.\n        :param verbose: Show progress bars.\n        "
        super().__init__(estimator=classifier)
        self.param_dic = param_dic
        self.embedding_weights = embedding_weights
        self.l_0 = l_0
        self.l_r = l_r
        self.use_sign = use_sign
        self.total_perturbation: np.ndarray = np.zeros(shape=(1, 1))
        self.num_of_iterations = num_of_iterations
        self.verbose = verbose
        self._check_params()
        self.embedding_weights = self.embedding_weights.astype('float32')

    def _check_params(self) -> None:
        if False:
            i = 10
            return i + 15
        if not isinstance(self.param_dic, dict):
            raise ValueError("A param_dic should be provided with the following keys/value pairs: 'maxlen': the input size to the MalConv model'input_dim': the number of discrete values. Normally 257.'embedding_size': size of the embedding layer. Normally 8.")
        if not isinstance(self.embedding_weights, np.ndarray):
            raise ValueError('The weights for the embedding layer should be given as a numpy array.')
        if not isinstance(self.l_0, (int, float)) or self.l_0 < 0:
            raise ValueError('The l0 bound should be greater or equal to 0. Further, it should be provided as an integer specifying the total number of features to perturb, or a a float representing the fraction of the total number of features of the original file we can perturb.')
        if not isinstance(self.l_r, (int, float)) or self.l_r < 0:
            raise ValueError('The learning rate should be a float or integer greater than zero.')
        if not isinstance(self.use_sign, bool):
            raise ValueError('Whether to use the sign of the gradient should be a True/False bool.')
        if not isinstance(self.num_of_iterations, int) or self.num_of_iterations < 0:
            raise ValueError('The number of iterations must be an integer greater than zero.')
        if not isinstance(self.verbose, bool):
            raise ValueError('The verbosity level should be a True/False bool.')

    @staticmethod
    def initialise_sample(x: np.ndarray, y: np.ndarray, sample_sizes: np.ndarray, perturbation_size: np.ndarray, perturb_sizes: Optional[List[List[int]]], perturb_starts: Optional[List[List[int]]]) -> np.ndarray:
        if False:
            return 10
        '\n        Randomly append bytes at the end of the malware to initialise it, or if perturbation regions are provided,\n        perturb those.\n\n        :param x: Array with input data.\n        :param y: Labels, after having been adjusted to account for malware which cannot support the full l0 budget.\n        :param sample_sizes: The size of the original file, before it was padded to the input size required by MalConv\n        :param perturbation_size: Size of the perturbations in L0 terms to put at end of file\n        :param perturb_sizes: List of length batch size, each element is in itself a list containing the size\n                              of the allowable perturbation region\n        :param perturb_starts: List of length batch size, each element is in itself a list containing the start\n                               of perturbation region.\n        :return x: Array with features to be perturbed set to a random value.\n        '
        for j in range(len(x)):
            if y[j] == 1:
                if perturb_sizes is not None and perturb_starts is not None:
                    for (size, start) in zip(perturb_sizes[j], perturb_starts[j]):
                        x[j, start:start + size] = np.random.randint(low=0, high=256, size=(1, size))
                x[j, sample_sizes[j]:sample_sizes[j] + perturbation_size[j]] = np.random.randint(low=0, high=256, size=(1, perturbation_size[j]))
        return x

    def check_valid_size(self, y: np.ndarray, sample_sizes: np.ndarray, append_perturbation_size: np.ndarray) -> np.ndarray:
        if False:
            for i in range(10):
                print('nop')
        '\n        Checks that we can append the l0 perturbation to the malware sample and not exceed the\n        maximum file size. A new label vector with just the valid files indicated is created.\n\n        :param y: Labels.\n        :param sample_sizes: The size of the original file, before it was padded to the input size required by MalConv.\n        :param append_perturbation_size: Size of the perturbations in L0 terms to put at end of file.\n        :return adv_label_vector: Labels which indicate which malware samples have enough free features to\n                                  accommodate all the adversarial perturbation.\n        '
        adv_label_vector = np.zeros_like(y)
        for (i, label) in enumerate(y):
            if label == 1:
                if sample_sizes[i] + append_perturbation_size[i] <= self.param_dic['maxlen']:
                    adv_label_vector[i] = 1
                    logger.info('size to append on sample %d is %d', i, append_perturbation_size[i])
        return adv_label_vector

    def generate_mask(self, x: np.ndarray, y: np.ndarray, sample_sizes: np.ndarray, perturbation_size: np.ndarray, perturb_sizes: Optional[List[List[int]]], perturb_starts: Optional[List[List[int]]]) -> 'tf.Tensor':
        if False:
            while True:
                i = 10
        '\n        Makes a mask to apply to the gradients to control which samples in the batch are perturbed.\n\n        :param x: Array with input data.\n        :param y: Labels to make sure the benign files are zero masked.\n        :param sample_sizes: The size of the original file, before it was padded to the input size required by MalConv\n        :param perturbation_size: Size of the perturbations in L0 terms to put at end of file\n        :param perturb_sizes: List of length batch size, each element is in itself a list containing the size\n                              of the allowable perturbation region\n        :param perturb_starts: List of length batch size, each element is in itself a list containing the start\n                               of perturbation region.\n        :return mask: Array with 1s on the features we will modify on this batch and 0s elsewhere.\n        '
        import tensorflow as tf
        mask = np.zeros_like(x)
        for i in range(len(x)):
            if y[i] == 1:
                if perturb_sizes is None and perturb_starts is None:
                    mask[i, sample_sizes[i]:sample_sizes[i] + perturbation_size[i]] = 1
                elif perturb_sizes is not None and perturb_starts is not None:
                    sample_perturb_sizes = perturb_sizes[i]
                    sample_perturb_starts = perturb_starts[i]
                    for (size, start) in zip(sample_perturb_sizes, sample_perturb_starts):
                        mask[i, start:start + size] = 1
                    mask[i, sample_sizes[i]:sample_sizes[i] + perturbation_size[i]] = 1
                else:
                    raise ValueError('either both start and size of perturbation regions are supplied or neither is supplied')
                assert np.sum(mask[i]) == self.total_perturbation[i]
        mask = np.expand_dims(mask, axis=-1)
        expanded_masks = []
        for _ in range(self.param_dic['embedding_size']):
            expanded_masks.append(mask)
        expanded_masks = np.concatenate(expanded_masks, axis=-1)
        expanded_masks = tf.convert_to_tensor(expanded_masks)
        expanded_masks = tf.cast(expanded_masks, dtype='float32')
        return expanded_masks

    def update_embeddings(self, embeddings: 'tf.Tensor', gradients: 'tf.Tensor', mask: 'tf.Tensor') -> 'tf.Tensor':
        if False:
            return 10
        '\n        Update embeddings.\n\n        :param embeddings: Embeddings produced by the data from passing it through the first embedding layer of MalConv\n        :param gradients: Gradients to update the embeddings\n        :param mask: Tensor with 1s on the embeddings we modify, 0s elsewhere.\n        :return embeddings: Updated embeddings wrt the adversarial objective.\n        '
        import tensorflow as tf
        if self.use_sign:
            gradients = tf.sign(gradients)
        embeddings = embeddings + self.l_r * gradients * mask
        return embeddings

    def get_adv_malware(self, embeddings: 'tf.Tensor', data: np.ndarray, labels: np.ndarray, fsize: np.ndarray, perturbation_size: np.ndarray, perturb_sizes: Optional[List[List[int]]]=None, perturb_starts: Optional[List[List[int]]]=None) -> np.ndarray:
        if False:
            i = 10
            return i + 15
        '\n        Project the adversarial example back though the closest l2 vector.\n\n        :embeddings: Adversarially optimised embeddings\n        :labels: Labels for the data\n        :fsize: Size of the original malware\n        :data: Original data in the feature space\n        :perturbation_size: Size of the l0 attack to append (if any).\n        :perturb_sizes: List, with each element itself being a list of the start positions of a\n                        perturbation regions in a sample\n        :perturb_starts: List, with each element itself being a list of the start positions of a\n                         start of the perturbation regions in a sample\n\n        :return data: Numpy array with valid data samples.\n        '
        import tensorflow as tf
        for (i, label) in enumerate(labels):
            if label == 1:
                total_diff = 0
                m = tf.constant([1, self.param_dic['input_dim'], 1], tf.int32)
                if perturb_sizes is not None and perturb_starts is not None:
                    for (size, start) in zip(perturb_sizes[i], perturb_starts[i]):
                        expanded = tf.tile(tf.expand_dims(embeddings[i, start:start + size, :], axis=1), m)
                        diff = tf.norm(expanded - self.embedding_weights, axis=-1)
                        diff = tf.math.argmin(diff, axis=-1)
                        data[i, start:start + size] = diff
                        total_diff += len(diff)
                expanded = tf.tile(tf.expand_dims(embeddings[i, fsize[i]:fsize[i] + perturbation_size[i], :], axis=1), m)
                diff = tf.norm(expanded - self.embedding_weights, axis=-1)
                diff = tf.math.argmin(diff, axis=-1)
                data[i, fsize[i]:fsize[i] + perturbation_size[i]] = diff
                total_diff += len(diff)
                assert total_diff == self.total_perturbation[i]
        return data

    @staticmethod
    def pull_out_adversarial_malware(x: np.ndarray, y: np.ndarray, sample_sizes: np.ndarray, initial_dtype: np.dtype, input_perturb_sizes: Optional[List[List[int]]]=None, input_perturb_starts: Optional[List[List[int]]]=None) -> Union[Tuple[np.ndarray, np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray, np.ndarray, List[List[int]], List[List[int]]]]:
        if False:
            i = 10
            return i + 15
        '\n        Fetches the malware from the data\n\n        :param x: Batch of data which will contain a mix of adversarial examples and unperturbed data.\n        :param y: Labels indicating which are valid adversarial examples or not.\n        :param initial_dtype: Data can be given in a few formats (uin16, float, etc) so use initial_dtype\n                              to make the returned sample match the original.\n        :param sample_sizes: Size of the original data files\n        :param input_perturb_sizes: List of length batch size, each element is in itself a list containing\n                                    the size of the allowable perturbation region\n        :param input_perturb_starts: List of length batch size, each element is in itself a list containing\n                                     the start of perturbation region.\n\n        :return adv_x: array composed of only the data that we can make valid adversarial examples from.\n        :return adv_y: labels, all ones.\n        '
        num_of_malware_samples = int(np.sum(y))
        adv_x = np.zeros((num_of_malware_samples, x.shape[1]), dtype=initial_dtype)
        adv_y = np.ones((num_of_malware_samples, 1))
        adv_sample_sizes = np.zeros((num_of_malware_samples,), dtype=int)
        perturb_sizes = []
        perturb_starts = []
        j = 0
        for (i, label) in enumerate(y):
            if label == 1:
                adv_x[j] = x[i]
                adv_sample_sizes[j] = int(sample_sizes[i])
                j += 1
                if input_perturb_sizes is not None and input_perturb_starts is not None:
                    perturb_sizes.append(input_perturb_sizes[i])
                    perturb_starts.append(input_perturb_starts[i])
        if input_perturb_sizes is not None and input_perturb_starts is not None:
            return (adv_x, adv_y, adv_sample_sizes, perturb_starts, perturb_sizes)
        return (adv_x, adv_y, adv_sample_sizes)

    def compute_perturbation_regions(self, input_perturbation_size: np.ndarray, input_perturb_sizes: List[List[int]], automatically_append: bool) -> Tuple[np.ndarray, List[List[int]]]:
        if False:
            return 10
        '\n        Based on the l0 budget and the provided allowable perturbation regions we iteratively mark regions of the PE\n        file for modification until we exhaust our budget.\n\n        :param input_perturb_sizes: The size of the regions we can perturb.\n        :param input_perturbation_size: The total amount of perturbation allowed on a specific sample.\n        :param automatically_append: If we want to automatically append unused perturbation on the end of the malware.\n        :return perturbation_size: Remaining perturbation (if any)\n        :return perturb_sizes: Potentially adjusted sizes of the locations in the PE file we can perturb.\n        '
        perturb_sizes = input_perturb_sizes.copy()
        perturbation_size = input_perturbation_size.copy()
        for (i, section_sizes) in enumerate(perturb_sizes):
            for (j, size) in enumerate(section_sizes):
                if perturbation_size[i] - size >= 0:
                    logger.info('on sample %d allocate %d in perturb region', i, size)
                    perturbation_size[i] = perturbation_size[i] - size
                else:
                    excess = np.abs(perturbation_size[i] - size)
                    perturbation_size[i] = perturbation_size[i] - size
                    section_sizes[j] = size - excess
                    logger.info('on sample %d ran out of l0, update to %d from %d', i, section_sizes[j], size)
                    perturb_sizes[i] = section_sizes
                    perturbation_size[i] = 0
        perturbation_size = np.where(perturbation_size < 0, 0, perturbation_size)
        if not automatically_append:
            perturbation_size = np.zeros_like(perturbation_size)
            total_perturbation = np.zeros_like(perturbation_size)
            for i in range(len(perturbation_size)):
                total_perturbation[i] = np.sum(perturb_sizes[i])
            self.total_perturbation = total_perturbation
        return (perturbation_size, perturb_sizes)

    def pull_out_valid_samples(self, x: np.ndarray, y: np.ndarray, sample_sizes: np.ndarray, automatically_append: bool=True, perturb_sizes: Optional[List[List[int]]]=None, perturb_starts: Optional[List[List[int]]]=None) -> Union[Tuple[np.ndarray, np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray, np.ndarray, List[List[int]], List[List[int]]]]:
        if False:
            for i in range(10):
                print('nop')
        '\n        Filters the input data for samples that can be made adversarial.\n\n        :param x: Array with input data.\n        :param y: Labels to make sure the benign files are zero masked.\n        :param sample_sizes: The size of the original file, before it was padded to the input size required by MalConv\n        :param automatically_append: Whether to automatically append extra spare perturbation at the end of the file.\n        :param perturb_sizes: List of length batch size, each element is in itself a list containing\n                              the size of the allowable perturbation region\n        :param perturb_starts: List of length batch size, each element is in itself a list containing\n                               the start of perturbation region.\n\n        '
        initial_dtype = x.dtype
        perturbation_size = np.zeros(len(sample_sizes), dtype=int)
        for (i, sample_size) in enumerate(sample_sizes):
            if self.l_0 < 1:
                perturbation_size[i] = int(sample_size * self.l_0)
            else:
                perturbation_size[i] = int(self.l_0)
        if perturb_sizes is not None and perturb_starts is not None:
            (perturbation_size, perturb_sizes) = self.compute_perturbation_regions(perturbation_size, perturb_sizes, automatically_append)
        y = self.check_valid_size(y, sample_sizes, perturbation_size)
        if perturb_sizes is not None and perturb_starts is not None:
            return self.pull_out_adversarial_malware(x, y, sample_sizes, initial_dtype, perturb_sizes, perturb_starts)
        return self.pull_out_adversarial_malware(x, y, sample_sizes, initial_dtype)

    def generate(self, x: np.ndarray, y: Optional[np.ndarray]=None, sample_sizes: Optional[np.ndarray]=None, automatically_append: bool=True, verify_input_data: bool=True, perturb_sizes: Optional[List[List[int]]]=None, perturb_starts: Optional[List[List[int]]]=None, **kwargs) -> np.ndarray:
        if False:
            i = 10
            return i + 15
        '\n        Generates the adversarial examples. x needs to be composed of valid files by default which can support the\n        adversarial perturbation and so are malicious and can support the assigned L0 budget. They can obtained by\n        using `pull_out_valid_samples` on the data.\n\n        This check on the input data can be over-ridden by toggling the flag verify_input_data\n        This will result in only the data which can be made adversarial being perturbed and so the resulting batch will\n        be a mixture of adversarial and unperturbed data.\n\n        To assign the L0 budget we go through each list in perturb_sizes and perturb_starts in order, and\n        assign the budget based on the sizes given until the l0 budget is exhausted.\n\n        After all the regions marked in perturb_sizes and perturb_starts have been assigned and automatically_append is\n        set to true and remaining l0 perturbation the extra perturbation is added at the end in an append style attack.\n\n        :param x: A array with input data.\n        :param y: (N, 1) binary labels to make sure the benign files are zero masked.\n        :param sample_sizes: The size of the original file, before it was padded to the input size required by MalConv\n        :param automatically_append: Whether to automatically append extra spare perturbation at the end of the file.\n        :param verify_input_data: If to check that all the data supplied is valid for adversarial perturbations.\n        :param perturb_sizes: A list of length batch size, each element is in itself a list containing\n                              the size of the allowable perturbation region\n        :param perturb_starts: A list of length batch size, each element is in itself a list containing\n                               the start of perturbation region.\n        :return x: our adversarial examples.\n        '
        import tensorflow as tf
        adv_x = x.copy()
        if sample_sizes is None:
            raise ValueError('The size of the original files needs to be supplied')
        if y is None:
            raise ValueError('Labels need to be provided so we only modify the malware')
        assert len(adv_x) == len(y)
        assert len(y) == len(sample_sizes)
        if perturb_sizes is not None:
            assert len(y) == len(perturb_sizes)
        if perturb_starts is not None:
            assert len(y) == len(perturb_starts)
        if perturb_starts is not None:
            assert perturb_sizes is not None
        if perturb_sizes is not None:
            assert perturb_starts is not None
        if not automatically_append:
            assert perturb_sizes is not None
            assert perturb_starts is not None
        perturbation_size = np.zeros(len(sample_sizes), dtype=int)
        for (i, sample_size) in enumerate(sample_sizes):
            if self.l_0 < 1:
                perturbation_size[i] = int(sample_size * self.l_0)
            else:
                perturbation_size[i] = int(self.l_0)
        self.total_perturbation = np.copy(perturbation_size)
        if perturb_sizes is not None and perturb_starts is not None:
            (perturbation_size, perturb_sizes) = self.compute_perturbation_regions(perturbation_size, perturb_sizes, automatically_append)
        y = self.check_valid_size(y, sample_sizes, perturbation_size)
        if verify_input_data:
            if np.sum(y) != len(y):
                raise ValueError(f'{len(y) - np.sum(y)} invalid samples found in batch which cannot support the assigned perturbation or are benign To filter for samples that can be processed use pull_out_valid_samples on the samples. Checking can be disabled by using verify_input_data')
        adv_x = self.initialise_sample(adv_x, y, sample_sizes, perturbation_size, perturb_sizes=perturb_sizes, perturb_starts=perturb_starts)
        mask = self.generate_mask(adv_x, y, sample_sizes, perturbation_size, perturb_sizes=perturb_sizes, perturb_starts=perturb_starts)
        embeddings = tf.nn.embedding_lookup(params=self.embedding_weights, ids=adv_x.astype('int32'))
        for _ in trange(self.num_of_iterations, desc='PE Adv. Malware', disable=not self.verbose):
            gradients = self.estimator.class_gradient(embeddings, label=0)
            gradients = gradients[:, 0, :, :]
            gradients = -1 * gradients
            embeddings = self.update_embeddings(embeddings, gradients, mask)
        adv_x = self.get_adv_malware(embeddings=embeddings, data=adv_x, labels=y, fsize=sample_sizes, perturbation_size=perturbation_size, perturb_sizes=perturb_sizes, perturb_starts=perturb_starts)
        return adv_x

    @staticmethod
    def process_file(filepath: str, padding_char: int=256, maxlen: int=2 ** 20) -> Tuple[np.ndarray, int]:
        if False:
            print('Hello World!')
        '\n        Go from raw file to numpy array.\n\n        :param filepath: Path to the file we convert to a numpy array\n        :param padding_char: The char to use to pad the input if it is shorter then maxlen\n        :param maxlen: Maximum size of the file processed by the model. Currently set to 1MB\n        :return data: A numpy array of the PE file\n        :return size_of_original_file: Size of the PE file\n        '
        with open(filepath, 'rb') as file:
            open_file = file.read()
        size_of_original_file = len(open_file)
        data = np.ones((maxlen,), dtype=np.uint16) * padding_char
        selected_bytes = np.frombuffer(open_file[:maxlen], dtype=np.uint8)
        data[:len(selected_bytes)] = selected_bytes
        return (data, size_of_original_file)

    @staticmethod
    def get_peinfo(filepath: str, save_to_json_path: Optional[str]=None) -> Tuple[List[int], List[int]]:
        if False:
            print('Hello World!')
        '\n        Given a PE file we extract out the section information to determine the slack regions in the file.\n        We return two lists 1) with the start location of the slack regions and 2) with the size of the slack region.\n        We are using the lief library (https://github.com/lief-project/LIEF) to manipulate the PE file.\n\n        :param filepath: Path to file we want to analyse with pedump and get the section information.\n        :param save_to_json_path: (Optional) if we want to save the results of pedump to a json file, provide the path.\n        :return start_of_slack: A list with the slack starts\n        :return size_of_slack: A list with the slack start positions\n        '
        import lief
        start_of_slack = []
        size_of_slack = []
        cleaned_dump = {}
        binary = lief.parse(filepath)
        for section in binary.sections:
            section_info = {}
            slack = section.sizeof_raw_data - section.virtual_size
            section_info['PointerToRawData'] = section.pointerto_raw_data
            section_info['VirtualAddress'] = section.virtual_size
            section_info['SizeOfRawData'] = section.sizeof_raw_data
            cleaned_dump[section.name] = section_info
            if slack > 0:
                size_of_slack.append(slack)
                start_of_slack.append(section.pointerto_raw_data + section.virtual_size)
        if save_to_json_path is not None:
            with open(save_to_json_path, 'w', encoding='utf8') as outfile:
                json.dump(cleaned_dump, outfile, indent=4, sort_keys=True)
        return (start_of_slack, size_of_slack)

    def insert_section(self, datapoint: Union[List[int], str], sample_size: Optional[int]=None, padding_char: int=256, maxlen: int=2 ** 20, bytes_to_assign: Optional[int]=None, verbose: bool=False) -> Union[Tuple[np.ndarray, int, int, int, List[int], List[int]], Tuple[None, None, None, None, None, None]]:
        if False:
            i = 10
            return i + 15
        "\n        Create a new section in a PE file that the attacker can perturb to create an adversarial example.\n        we are using the lief library (https://github.com/lief-project/LIEF) to manipulate the PE file.\n\n        :param datapoint: either 1) path to file we want to analyse with lief and get the section information.\n                          or 2) list of ints that can be processed by lief.\n\n                          If we have already pre-processed the file into a numpy array, we convert it to a form\n                          that can be read by lief.\n                          eg, if we have it as a numpy array this could be done by:\n\n                          datapoint = datapoint[0:size]  # size is the original size of the malware file\n                          datapoint = datapoint.astype('uint8')\n                          datapoint = datapoint.tolist()\n        :param sample_size: Size of the original datapoint. Only if it is an array and the l0 budget is fractional\n        :param padding_char: The char to use to pad the file to be of length maxlen\n        :param maxlen: Maximum length of the data that the MalConv model can process\n        :param bytes_to_assign: (Optional) how many bytes we wish to specify when inserting a new section.\n                                If unspecified the whole l0 budget will be used on a single section.\n        :param verbose: lief outputs a lot to the console, particularly if we are processing many files.\n                        By default suppress printing of messages. Can be toggled on/off by True/False\n        :return manipulated_data: Executable with section inserted and turned into a numpy array of\n                                  the appropriate size\n        :return len(manipulated_file): Size of original file\n        :return information_on_section.pointerto_raw_data: The start of the inserted section\n        :return information_on_section.virtual_size: Size of the inserted section\n        :return size_of_slack: Size of slack regions in this executable (including from the section we just inserted)\n        :return start_of_slack: Start of slack regions in this executable (including from the section we just inserted)\n        "
        import lief
        if not verbose:
            lief.logging.disable()
        binary = lief.PE.parse(datapoint)
        name_in_use = True
        while name_in_use:
            new_section_name = '.' + ''.join((chr(random.randrange(ord('a'), ord('z'))) for _ in range(5)))
            name_in_use = False
            for section in binary.sections:
                if new_section_name == section.name:
                    name_in_use = True
        new_section = lief.PE.Section(new_section_name)
        if bytes_to_assign is None:
            if self.l_0 < 1:
                if isinstance(datapoint, str):
                    with open(datapoint, 'rb') as file:
                        open_file = file.read()
                    sample_size = len(open_file)
                elif sample_size is None:
                    raise ValueError('if the data is an array and the l0 budget is fractional the sample size must be provided')
                perturbation_size = int(sample_size * self.l_0)
            else:
                perturbation_size = int(self.l_0)
            new_section.content = [random.randint(0, 255) for _ in range(perturbation_size)]
        else:
            new_section.content = [random.randint(0, 255) for _ in range(bytes_to_assign)]
        section_end_points = []
        for section in binary.sections:
            section_end_points.append(section.virtual_address + section.size)
        new_section.virtual_address = max(section_end_points)
        binary.add_section(new_section, random.choice([lief.PE.SECTION_TYPES.BSS, lief.PE.SECTION_TYPES.DATA, lief.PE.SECTION_TYPES.EXPORT, lief.PE.SECTION_TYPES.IDATA, lief.PE.SECTION_TYPES.RELOCATION, lief.PE.SECTION_TYPES.RESOURCE, lief.PE.SECTION_TYPES.TEXT, lief.PE.SECTION_TYPES.TLS_, lief.PE.SECTION_TYPES.UNKNOWN]))
        information_on_section = binary.get_section(new_section_name)
        size_of_slack = []
        start_of_slack = []
        for section in binary.sections:
            slack = section.sizeof_raw_data - section.virtual_size
            if slack > 0:
                size_of_slack.append(slack)
                start_of_slack.append(section.pointerto_raw_data + section.virtual_size)
        builder = lief.PE.Builder(binary)
        builder.build()
        manipulated_file = np.array(builder.get_build(), dtype=np.uint8)
        manipulated_data = np.ones((maxlen,), dtype=np.uint16) * padding_char
        if len(manipulated_file) < maxlen:
            manipulated_data[:len(manipulated_file)] = manipulated_file[:maxlen]
            return (manipulated_data, len(manipulated_file), information_on_section.pointerto_raw_data, information_on_section.virtual_size, size_of_slack, start_of_slack)
        return (None, None, None, None, None, None)

    @staticmethod
    def get_dos_locations(x: np.ndarray) -> Tuple[List[List[int]], List[List[int]]]:
        if False:
            i = 10
            return i + 15
        '\n        We identify the regions in the DOS header which we can perturb adversarially.\n\n        There are a series of "magic numbers" in this method which relate to the structure of the PE file.\n        1) mz_offset = 2: the first two bytes of a PE are fixed as MZ.\n        2) 0x3C: offset to the pointer to the PE header. The pointer is 4 bytes long.\n        3) 0x40: end of the pointer to the PE header.\n\n        :return batch_of_starts: A list of start locations we can perturb.\n                                 This will always have the same value of 2 and 64.\n        :return batch_of_sizes: Size of the perturbations we can carry out.\n        :return batch_of_starts: Start locations which we can perturb.\n        '
        batch_of_starts = []
        batch_of_sizes = []
        mz_offset = 2
        for i in range(len(x)):
            size = []
            start = []
            pointer_to_pe_header = x[i, int(60):int(64)].astype(np.uint8)
            pointer_to_pe_header = pointer_to_pe_header[3] << 24 | pointer_to_pe_header[2] << 16 | pointer_to_pe_header[1] << 8 | pointer_to_pe_header[0]
            size.append(int(60) - mz_offset)
            start.append(mz_offset)
            size.append(pointer_to_pe_header - int(64) - 1)
            start.append(int(64))
            batch_of_starts.append(start)
            batch_of_sizes.append(size)
        return (batch_of_starts, batch_of_sizes)