[
    {
        "func_name": "test_policy_aggregation_random",
        "original": "@parameterized.named_parameters({'testcase_name': 'kuhn_poker', 'game_name': 'kuhn_poker'}, {'testcase_name': 'leduc_poker', 'game_name': 'leduc_poker'})\ndef test_policy_aggregation_random(self, game_name):\n    env = rl_environment.Environment(game_name)\n    policies = [[policy.UniformRandomPolicy(env.game) for _ in range(2)] for _ in range(2)]\n    probabilities = [list(np.ones(len(policies)) / len(policies)) for _ in range(2)]\n    pol_ag = policy_aggregator.PolicyAggregator(env.game)\n    aggr_policy = pol_ag.aggregate([0], policies, probabilities)\n    for item in aggr_policy.policy[0].items():\n        (_, probs) = zip(*item[1].items())\n        const_probs = tuple([probs[0]] * len(probs))\n        self.assertEqual(probs, const_probs)",
        "mutated": [
            "@parameterized.named_parameters({'testcase_name': 'kuhn_poker', 'game_name': 'kuhn_poker'}, {'testcase_name': 'leduc_poker', 'game_name': 'leduc_poker'})\ndef test_policy_aggregation_random(self, game_name):\n    if False:\n        i = 10\n    env = rl_environment.Environment(game_name)\n    policies = [[policy.UniformRandomPolicy(env.game) for _ in range(2)] for _ in range(2)]\n    probabilities = [list(np.ones(len(policies)) / len(policies)) for _ in range(2)]\n    pol_ag = policy_aggregator.PolicyAggregator(env.game)\n    aggr_policy = pol_ag.aggregate([0], policies, probabilities)\n    for item in aggr_policy.policy[0].items():\n        (_, probs) = zip(*item[1].items())\n        const_probs = tuple([probs[0]] * len(probs))\n        self.assertEqual(probs, const_probs)",
            "@parameterized.named_parameters({'testcase_name': 'kuhn_poker', 'game_name': 'kuhn_poker'}, {'testcase_name': 'leduc_poker', 'game_name': 'leduc_poker'})\ndef test_policy_aggregation_random(self, game_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    env = rl_environment.Environment(game_name)\n    policies = [[policy.UniformRandomPolicy(env.game) for _ in range(2)] for _ in range(2)]\n    probabilities = [list(np.ones(len(policies)) / len(policies)) for _ in range(2)]\n    pol_ag = policy_aggregator.PolicyAggregator(env.game)\n    aggr_policy = pol_ag.aggregate([0], policies, probabilities)\n    for item in aggr_policy.policy[0].items():\n        (_, probs) = zip(*item[1].items())\n        const_probs = tuple([probs[0]] * len(probs))\n        self.assertEqual(probs, const_probs)",
            "@parameterized.named_parameters({'testcase_name': 'kuhn_poker', 'game_name': 'kuhn_poker'}, {'testcase_name': 'leduc_poker', 'game_name': 'leduc_poker'})\ndef test_policy_aggregation_random(self, game_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    env = rl_environment.Environment(game_name)\n    policies = [[policy.UniformRandomPolicy(env.game) for _ in range(2)] for _ in range(2)]\n    probabilities = [list(np.ones(len(policies)) / len(policies)) for _ in range(2)]\n    pol_ag = policy_aggregator.PolicyAggregator(env.game)\n    aggr_policy = pol_ag.aggregate([0], policies, probabilities)\n    for item in aggr_policy.policy[0].items():\n        (_, probs) = zip(*item[1].items())\n        const_probs = tuple([probs[0]] * len(probs))\n        self.assertEqual(probs, const_probs)",
            "@parameterized.named_parameters({'testcase_name': 'kuhn_poker', 'game_name': 'kuhn_poker'}, {'testcase_name': 'leduc_poker', 'game_name': 'leduc_poker'})\ndef test_policy_aggregation_random(self, game_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    env = rl_environment.Environment(game_name)\n    policies = [[policy.UniformRandomPolicy(env.game) for _ in range(2)] for _ in range(2)]\n    probabilities = [list(np.ones(len(policies)) / len(policies)) for _ in range(2)]\n    pol_ag = policy_aggregator.PolicyAggregator(env.game)\n    aggr_policy = pol_ag.aggregate([0], policies, probabilities)\n    for item in aggr_policy.policy[0].items():\n        (_, probs) = zip(*item[1].items())\n        const_probs = tuple([probs[0]] * len(probs))\n        self.assertEqual(probs, const_probs)",
            "@parameterized.named_parameters({'testcase_name': 'kuhn_poker', 'game_name': 'kuhn_poker'}, {'testcase_name': 'leduc_poker', 'game_name': 'leduc_poker'})\ndef test_policy_aggregation_random(self, game_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    env = rl_environment.Environment(game_name)\n    policies = [[policy.UniformRandomPolicy(env.game) for _ in range(2)] for _ in range(2)]\n    probabilities = [list(np.ones(len(policies)) / len(policies)) for _ in range(2)]\n    pol_ag = policy_aggregator.PolicyAggregator(env.game)\n    aggr_policy = pol_ag.aggregate([0], policies, probabilities)\n    for item in aggr_policy.policy[0].items():\n        (_, probs) = zip(*item[1].items())\n        const_probs = tuple([probs[0]] * len(probs))\n        self.assertEqual(probs, const_probs)"
        ]
    },
    {
        "func_name": "test_policy_aggregation_tabular_randinit",
        "original": "@parameterized.named_parameters({'testcase_name': 'kuhn_poker', 'game_name': 'kuhn_poker'}, {'testcase_name': 'leduc_poker', 'game_name': 'leduc_poker'})\ndef test_policy_aggregation_tabular_randinit(self, game_name):\n    env = rl_environment.Environment(game_name)\n    mother_policy = policy.TabularPolicy(env.game).copy_with_noise(1, 10, np.random.RandomState(0))\n    policies = [[mother_policy.__copy__() for _ in range(2)] for _ in range(2)]\n    probabilities = [list(np.ones(len(policies)) / len(policies)) for _ in range(2)]\n    pol_ag = policy_aggregator.PolicyAggregator(env.game)\n    aggr_policy = pol_ag.aggregate([0], policies, probabilities)\n    for (state, value) in aggr_policy.policy[0].items():\n        polici = mother_policy.policy_for_key(state)\n        value_normal = {action: probability for (action, probability) in enumerate(polici) if probability > 0}\n        for key in value_normal.keys():\n            self.assertAlmostEqual(value[key], value_normal[key], 8)",
        "mutated": [
            "@parameterized.named_parameters({'testcase_name': 'kuhn_poker', 'game_name': 'kuhn_poker'}, {'testcase_name': 'leduc_poker', 'game_name': 'leduc_poker'})\ndef test_policy_aggregation_tabular_randinit(self, game_name):\n    if False:\n        i = 10\n    env = rl_environment.Environment(game_name)\n    mother_policy = policy.TabularPolicy(env.game).copy_with_noise(1, 10, np.random.RandomState(0))\n    policies = [[mother_policy.__copy__() for _ in range(2)] for _ in range(2)]\n    probabilities = [list(np.ones(len(policies)) / len(policies)) for _ in range(2)]\n    pol_ag = policy_aggregator.PolicyAggregator(env.game)\n    aggr_policy = pol_ag.aggregate([0], policies, probabilities)\n    for (state, value) in aggr_policy.policy[0].items():\n        polici = mother_policy.policy_for_key(state)\n        value_normal = {action: probability for (action, probability) in enumerate(polici) if probability > 0}\n        for key in value_normal.keys():\n            self.assertAlmostEqual(value[key], value_normal[key], 8)",
            "@parameterized.named_parameters({'testcase_name': 'kuhn_poker', 'game_name': 'kuhn_poker'}, {'testcase_name': 'leduc_poker', 'game_name': 'leduc_poker'})\ndef test_policy_aggregation_tabular_randinit(self, game_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    env = rl_environment.Environment(game_name)\n    mother_policy = policy.TabularPolicy(env.game).copy_with_noise(1, 10, np.random.RandomState(0))\n    policies = [[mother_policy.__copy__() for _ in range(2)] for _ in range(2)]\n    probabilities = [list(np.ones(len(policies)) / len(policies)) for _ in range(2)]\n    pol_ag = policy_aggregator.PolicyAggregator(env.game)\n    aggr_policy = pol_ag.aggregate([0], policies, probabilities)\n    for (state, value) in aggr_policy.policy[0].items():\n        polici = mother_policy.policy_for_key(state)\n        value_normal = {action: probability for (action, probability) in enumerate(polici) if probability > 0}\n        for key in value_normal.keys():\n            self.assertAlmostEqual(value[key], value_normal[key], 8)",
            "@parameterized.named_parameters({'testcase_name': 'kuhn_poker', 'game_name': 'kuhn_poker'}, {'testcase_name': 'leduc_poker', 'game_name': 'leduc_poker'})\ndef test_policy_aggregation_tabular_randinit(self, game_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    env = rl_environment.Environment(game_name)\n    mother_policy = policy.TabularPolicy(env.game).copy_with_noise(1, 10, np.random.RandomState(0))\n    policies = [[mother_policy.__copy__() for _ in range(2)] for _ in range(2)]\n    probabilities = [list(np.ones(len(policies)) / len(policies)) for _ in range(2)]\n    pol_ag = policy_aggregator.PolicyAggregator(env.game)\n    aggr_policy = pol_ag.aggregate([0], policies, probabilities)\n    for (state, value) in aggr_policy.policy[0].items():\n        polici = mother_policy.policy_for_key(state)\n        value_normal = {action: probability for (action, probability) in enumerate(polici) if probability > 0}\n        for key in value_normal.keys():\n            self.assertAlmostEqual(value[key], value_normal[key], 8)",
            "@parameterized.named_parameters({'testcase_name': 'kuhn_poker', 'game_name': 'kuhn_poker'}, {'testcase_name': 'leduc_poker', 'game_name': 'leduc_poker'})\ndef test_policy_aggregation_tabular_randinit(self, game_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    env = rl_environment.Environment(game_name)\n    mother_policy = policy.TabularPolicy(env.game).copy_with_noise(1, 10, np.random.RandomState(0))\n    policies = [[mother_policy.__copy__() for _ in range(2)] for _ in range(2)]\n    probabilities = [list(np.ones(len(policies)) / len(policies)) for _ in range(2)]\n    pol_ag = policy_aggregator.PolicyAggregator(env.game)\n    aggr_policy = pol_ag.aggregate([0], policies, probabilities)\n    for (state, value) in aggr_policy.policy[0].items():\n        polici = mother_policy.policy_for_key(state)\n        value_normal = {action: probability for (action, probability) in enumerate(polici) if probability > 0}\n        for key in value_normal.keys():\n            self.assertAlmostEqual(value[key], value_normal[key], 8)",
            "@parameterized.named_parameters({'testcase_name': 'kuhn_poker', 'game_name': 'kuhn_poker'}, {'testcase_name': 'leduc_poker', 'game_name': 'leduc_poker'})\ndef test_policy_aggregation_tabular_randinit(self, game_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    env = rl_environment.Environment(game_name)\n    mother_policy = policy.TabularPolicy(env.game).copy_with_noise(1, 10, np.random.RandomState(0))\n    policies = [[mother_policy.__copy__() for _ in range(2)] for _ in range(2)]\n    probabilities = [list(np.ones(len(policies)) / len(policies)) for _ in range(2)]\n    pol_ag = policy_aggregator.PolicyAggregator(env.game)\n    aggr_policy = pol_ag.aggregate([0], policies, probabilities)\n    for (state, value) in aggr_policy.policy[0].items():\n        polici = mother_policy.policy_for_key(state)\n        value_normal = {action: probability for (action, probability) in enumerate(polici) if probability > 0}\n        for key in value_normal.keys():\n            self.assertAlmostEqual(value[key], value_normal[key], 8)"
        ]
    },
    {
        "func_name": "test_policy_aggregation_variadic",
        "original": "@parameterized.named_parameters({'testcase_name': 'tic_tac_toe', 'game_name': 'tic_tac_toe'})\ndef test_policy_aggregation_variadic(self, game_name):\n    game = pyspiel.load_game(game_name)\n    uniform_policy = policy.UniformRandomPolicy(game)\n    first_action_policy = policy.FirstActionPolicy(game)\n    pol_ag = policy_aggregator.PolicyAggregator(game)\n    weights0 = [1.0, 0.0]\n    player0 = pol_ag.aggregate(list(range(game.num_players())), [[uniform_policy, first_action_policy]] + [[uniform_policy]] * (game.num_players() - 1), [weights0] + [[1.0]] * (game.num_players() - 1))\n    state = game.new_initial_state()\n    action_prob = player0.action_probabilities(state)\n    for action in action_prob:\n        if action_prob[action] > 0:\n            self.assertAlmostEqual(action_prob[action], 1.0 / len(state.legal_actions()))",
        "mutated": [
            "@parameterized.named_parameters({'testcase_name': 'tic_tac_toe', 'game_name': 'tic_tac_toe'})\ndef test_policy_aggregation_variadic(self, game_name):\n    if False:\n        i = 10\n    game = pyspiel.load_game(game_name)\n    uniform_policy = policy.UniformRandomPolicy(game)\n    first_action_policy = policy.FirstActionPolicy(game)\n    pol_ag = policy_aggregator.PolicyAggregator(game)\n    weights0 = [1.0, 0.0]\n    player0 = pol_ag.aggregate(list(range(game.num_players())), [[uniform_policy, first_action_policy]] + [[uniform_policy]] * (game.num_players() - 1), [weights0] + [[1.0]] * (game.num_players() - 1))\n    state = game.new_initial_state()\n    action_prob = player0.action_probabilities(state)\n    for action in action_prob:\n        if action_prob[action] > 0:\n            self.assertAlmostEqual(action_prob[action], 1.0 / len(state.legal_actions()))",
            "@parameterized.named_parameters({'testcase_name': 'tic_tac_toe', 'game_name': 'tic_tac_toe'})\ndef test_policy_aggregation_variadic(self, game_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    game = pyspiel.load_game(game_name)\n    uniform_policy = policy.UniformRandomPolicy(game)\n    first_action_policy = policy.FirstActionPolicy(game)\n    pol_ag = policy_aggregator.PolicyAggregator(game)\n    weights0 = [1.0, 0.0]\n    player0 = pol_ag.aggregate(list(range(game.num_players())), [[uniform_policy, first_action_policy]] + [[uniform_policy]] * (game.num_players() - 1), [weights0] + [[1.0]] * (game.num_players() - 1))\n    state = game.new_initial_state()\n    action_prob = player0.action_probabilities(state)\n    for action in action_prob:\n        if action_prob[action] > 0:\n            self.assertAlmostEqual(action_prob[action], 1.0 / len(state.legal_actions()))",
            "@parameterized.named_parameters({'testcase_name': 'tic_tac_toe', 'game_name': 'tic_tac_toe'})\ndef test_policy_aggregation_variadic(self, game_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    game = pyspiel.load_game(game_name)\n    uniform_policy = policy.UniformRandomPolicy(game)\n    first_action_policy = policy.FirstActionPolicy(game)\n    pol_ag = policy_aggregator.PolicyAggregator(game)\n    weights0 = [1.0, 0.0]\n    player0 = pol_ag.aggregate(list(range(game.num_players())), [[uniform_policy, first_action_policy]] + [[uniform_policy]] * (game.num_players() - 1), [weights0] + [[1.0]] * (game.num_players() - 1))\n    state = game.new_initial_state()\n    action_prob = player0.action_probabilities(state)\n    for action in action_prob:\n        if action_prob[action] > 0:\n            self.assertAlmostEqual(action_prob[action], 1.0 / len(state.legal_actions()))",
            "@parameterized.named_parameters({'testcase_name': 'tic_tac_toe', 'game_name': 'tic_tac_toe'})\ndef test_policy_aggregation_variadic(self, game_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    game = pyspiel.load_game(game_name)\n    uniform_policy = policy.UniformRandomPolicy(game)\n    first_action_policy = policy.FirstActionPolicy(game)\n    pol_ag = policy_aggregator.PolicyAggregator(game)\n    weights0 = [1.0, 0.0]\n    player0 = pol_ag.aggregate(list(range(game.num_players())), [[uniform_policy, first_action_policy]] + [[uniform_policy]] * (game.num_players() - 1), [weights0] + [[1.0]] * (game.num_players() - 1))\n    state = game.new_initial_state()\n    action_prob = player0.action_probabilities(state)\n    for action in action_prob:\n        if action_prob[action] > 0:\n            self.assertAlmostEqual(action_prob[action], 1.0 / len(state.legal_actions()))",
            "@parameterized.named_parameters({'testcase_name': 'tic_tac_toe', 'game_name': 'tic_tac_toe'})\ndef test_policy_aggregation_variadic(self, game_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    game = pyspiel.load_game(game_name)\n    uniform_policy = policy.UniformRandomPolicy(game)\n    first_action_policy = policy.FirstActionPolicy(game)\n    pol_ag = policy_aggregator.PolicyAggregator(game)\n    weights0 = [1.0, 0.0]\n    player0 = pol_ag.aggregate(list(range(game.num_players())), [[uniform_policy, first_action_policy]] + [[uniform_policy]] * (game.num_players() - 1), [weights0] + [[1.0]] * (game.num_players() - 1))\n    state = game.new_initial_state()\n    action_prob = player0.action_probabilities(state)\n    for action in action_prob:\n        if action_prob[action] > 0:\n            self.assertAlmostEqual(action_prob[action], 1.0 / len(state.legal_actions()))"
        ]
    }
]