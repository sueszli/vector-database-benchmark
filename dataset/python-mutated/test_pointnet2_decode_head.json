[
    {
        "func_name": "test_pn2_decode_head_loss",
        "original": "def test_pn2_decode_head_loss():\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    pn2_decode_head_cfg = dict(type='PointNet2Head', fp_channels=((768, 256, 256), (384, 256, 256), (320, 256, 128), (128, 128, 128, 128)), channels=128, num_classes=20, dropout_ratio=0.5, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), act_cfg=dict(type='ReLU'), loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=False, class_weight=None, loss_weight=1.0), ignore_index=20)\n    self = build_head(pn2_decode_head_cfg)\n    self.cuda()\n    assert isinstance(self.conv_seg, torch.nn.Conv1d)\n    assert self.conv_seg.in_channels == 128\n    assert self.conv_seg.out_channels == 20\n    assert self.conv_seg.kernel_size == (1,)\n    assert isinstance(self.pre_seg_conv, ConvModule)\n    assert isinstance(self.pre_seg_conv.conv, torch.nn.Conv1d)\n    assert self.pre_seg_conv.conv.in_channels == 128\n    assert self.pre_seg_conv.conv.out_channels == 128\n    assert self.pre_seg_conv.conv.kernel_size == (1,)\n    assert isinstance(self.pre_seg_conv.bn, torch.nn.BatchNorm1d)\n    assert self.pre_seg_conv.bn.num_features == 128\n    assert isinstance(self.pre_seg_conv.activate, torch.nn.ReLU)\n    sa_xyz = [torch.rand(2, 4096, 3).float().cuda(), torch.rand(2, 1024, 3).float().cuda(), torch.rand(2, 256, 3).float().cuda(), torch.rand(2, 64, 3).float().cuda(), torch.rand(2, 16, 3).float().cuda()]\n    sa_features = [torch.rand(2, 6, 4096).float().cuda(), torch.rand(2, 64, 1024).float().cuda(), torch.rand(2, 128, 256).float().cuda(), torch.rand(2, 256, 64).float().cuda(), torch.rand(2, 512, 16).float().cuda()]\n    input_dict = dict(sa_xyz=sa_xyz, sa_features=sa_features)\n    seg_logits = self(input_dict)\n    assert seg_logits.shape == torch.Size([2, 20, 4096])\n    pts_semantic_mask = torch.randint(0, 20, (2, 4096)).long().cuda()\n    losses = self.losses(seg_logits, pts_semantic_mask)\n    assert losses['loss_sem_seg'].item() > 0\n    ignore_index_mask = torch.ones_like(pts_semantic_mask) * 20\n    losses = self.losses(seg_logits, ignore_index_mask)\n    assert losses['loss_sem_seg'].item() == 0\n    pn2_decode_head_cfg['loss_decode'] = dict(type='CrossEntropyLoss', use_sigmoid=False, class_weight=np.random.rand(20), loss_weight=1.0)\n    self = build_head(pn2_decode_head_cfg)\n    self.cuda()\n    losses = self.losses(seg_logits, pts_semantic_mask)\n    assert losses['loss_sem_seg'].item() > 0",
        "mutated": [
            "def test_pn2_decode_head_loss():\n    if False:\n        i = 10\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    pn2_decode_head_cfg = dict(type='PointNet2Head', fp_channels=((768, 256, 256), (384, 256, 256), (320, 256, 128), (128, 128, 128, 128)), channels=128, num_classes=20, dropout_ratio=0.5, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), act_cfg=dict(type='ReLU'), loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=False, class_weight=None, loss_weight=1.0), ignore_index=20)\n    self = build_head(pn2_decode_head_cfg)\n    self.cuda()\n    assert isinstance(self.conv_seg, torch.nn.Conv1d)\n    assert self.conv_seg.in_channels == 128\n    assert self.conv_seg.out_channels == 20\n    assert self.conv_seg.kernel_size == (1,)\n    assert isinstance(self.pre_seg_conv, ConvModule)\n    assert isinstance(self.pre_seg_conv.conv, torch.nn.Conv1d)\n    assert self.pre_seg_conv.conv.in_channels == 128\n    assert self.pre_seg_conv.conv.out_channels == 128\n    assert self.pre_seg_conv.conv.kernel_size == (1,)\n    assert isinstance(self.pre_seg_conv.bn, torch.nn.BatchNorm1d)\n    assert self.pre_seg_conv.bn.num_features == 128\n    assert isinstance(self.pre_seg_conv.activate, torch.nn.ReLU)\n    sa_xyz = [torch.rand(2, 4096, 3).float().cuda(), torch.rand(2, 1024, 3).float().cuda(), torch.rand(2, 256, 3).float().cuda(), torch.rand(2, 64, 3).float().cuda(), torch.rand(2, 16, 3).float().cuda()]\n    sa_features = [torch.rand(2, 6, 4096).float().cuda(), torch.rand(2, 64, 1024).float().cuda(), torch.rand(2, 128, 256).float().cuda(), torch.rand(2, 256, 64).float().cuda(), torch.rand(2, 512, 16).float().cuda()]\n    input_dict = dict(sa_xyz=sa_xyz, sa_features=sa_features)\n    seg_logits = self(input_dict)\n    assert seg_logits.shape == torch.Size([2, 20, 4096])\n    pts_semantic_mask = torch.randint(0, 20, (2, 4096)).long().cuda()\n    losses = self.losses(seg_logits, pts_semantic_mask)\n    assert losses['loss_sem_seg'].item() > 0\n    ignore_index_mask = torch.ones_like(pts_semantic_mask) * 20\n    losses = self.losses(seg_logits, ignore_index_mask)\n    assert losses['loss_sem_seg'].item() == 0\n    pn2_decode_head_cfg['loss_decode'] = dict(type='CrossEntropyLoss', use_sigmoid=False, class_weight=np.random.rand(20), loss_weight=1.0)\n    self = build_head(pn2_decode_head_cfg)\n    self.cuda()\n    losses = self.losses(seg_logits, pts_semantic_mask)\n    assert losses['loss_sem_seg'].item() > 0",
            "def test_pn2_decode_head_loss():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    pn2_decode_head_cfg = dict(type='PointNet2Head', fp_channels=((768, 256, 256), (384, 256, 256), (320, 256, 128), (128, 128, 128, 128)), channels=128, num_classes=20, dropout_ratio=0.5, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), act_cfg=dict(type='ReLU'), loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=False, class_weight=None, loss_weight=1.0), ignore_index=20)\n    self = build_head(pn2_decode_head_cfg)\n    self.cuda()\n    assert isinstance(self.conv_seg, torch.nn.Conv1d)\n    assert self.conv_seg.in_channels == 128\n    assert self.conv_seg.out_channels == 20\n    assert self.conv_seg.kernel_size == (1,)\n    assert isinstance(self.pre_seg_conv, ConvModule)\n    assert isinstance(self.pre_seg_conv.conv, torch.nn.Conv1d)\n    assert self.pre_seg_conv.conv.in_channels == 128\n    assert self.pre_seg_conv.conv.out_channels == 128\n    assert self.pre_seg_conv.conv.kernel_size == (1,)\n    assert isinstance(self.pre_seg_conv.bn, torch.nn.BatchNorm1d)\n    assert self.pre_seg_conv.bn.num_features == 128\n    assert isinstance(self.pre_seg_conv.activate, torch.nn.ReLU)\n    sa_xyz = [torch.rand(2, 4096, 3).float().cuda(), torch.rand(2, 1024, 3).float().cuda(), torch.rand(2, 256, 3).float().cuda(), torch.rand(2, 64, 3).float().cuda(), torch.rand(2, 16, 3).float().cuda()]\n    sa_features = [torch.rand(2, 6, 4096).float().cuda(), torch.rand(2, 64, 1024).float().cuda(), torch.rand(2, 128, 256).float().cuda(), torch.rand(2, 256, 64).float().cuda(), torch.rand(2, 512, 16).float().cuda()]\n    input_dict = dict(sa_xyz=sa_xyz, sa_features=sa_features)\n    seg_logits = self(input_dict)\n    assert seg_logits.shape == torch.Size([2, 20, 4096])\n    pts_semantic_mask = torch.randint(0, 20, (2, 4096)).long().cuda()\n    losses = self.losses(seg_logits, pts_semantic_mask)\n    assert losses['loss_sem_seg'].item() > 0\n    ignore_index_mask = torch.ones_like(pts_semantic_mask) * 20\n    losses = self.losses(seg_logits, ignore_index_mask)\n    assert losses['loss_sem_seg'].item() == 0\n    pn2_decode_head_cfg['loss_decode'] = dict(type='CrossEntropyLoss', use_sigmoid=False, class_weight=np.random.rand(20), loss_weight=1.0)\n    self = build_head(pn2_decode_head_cfg)\n    self.cuda()\n    losses = self.losses(seg_logits, pts_semantic_mask)\n    assert losses['loss_sem_seg'].item() > 0",
            "def test_pn2_decode_head_loss():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    pn2_decode_head_cfg = dict(type='PointNet2Head', fp_channels=((768, 256, 256), (384, 256, 256), (320, 256, 128), (128, 128, 128, 128)), channels=128, num_classes=20, dropout_ratio=0.5, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), act_cfg=dict(type='ReLU'), loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=False, class_weight=None, loss_weight=1.0), ignore_index=20)\n    self = build_head(pn2_decode_head_cfg)\n    self.cuda()\n    assert isinstance(self.conv_seg, torch.nn.Conv1d)\n    assert self.conv_seg.in_channels == 128\n    assert self.conv_seg.out_channels == 20\n    assert self.conv_seg.kernel_size == (1,)\n    assert isinstance(self.pre_seg_conv, ConvModule)\n    assert isinstance(self.pre_seg_conv.conv, torch.nn.Conv1d)\n    assert self.pre_seg_conv.conv.in_channels == 128\n    assert self.pre_seg_conv.conv.out_channels == 128\n    assert self.pre_seg_conv.conv.kernel_size == (1,)\n    assert isinstance(self.pre_seg_conv.bn, torch.nn.BatchNorm1d)\n    assert self.pre_seg_conv.bn.num_features == 128\n    assert isinstance(self.pre_seg_conv.activate, torch.nn.ReLU)\n    sa_xyz = [torch.rand(2, 4096, 3).float().cuda(), torch.rand(2, 1024, 3).float().cuda(), torch.rand(2, 256, 3).float().cuda(), torch.rand(2, 64, 3).float().cuda(), torch.rand(2, 16, 3).float().cuda()]\n    sa_features = [torch.rand(2, 6, 4096).float().cuda(), torch.rand(2, 64, 1024).float().cuda(), torch.rand(2, 128, 256).float().cuda(), torch.rand(2, 256, 64).float().cuda(), torch.rand(2, 512, 16).float().cuda()]\n    input_dict = dict(sa_xyz=sa_xyz, sa_features=sa_features)\n    seg_logits = self(input_dict)\n    assert seg_logits.shape == torch.Size([2, 20, 4096])\n    pts_semantic_mask = torch.randint(0, 20, (2, 4096)).long().cuda()\n    losses = self.losses(seg_logits, pts_semantic_mask)\n    assert losses['loss_sem_seg'].item() > 0\n    ignore_index_mask = torch.ones_like(pts_semantic_mask) * 20\n    losses = self.losses(seg_logits, ignore_index_mask)\n    assert losses['loss_sem_seg'].item() == 0\n    pn2_decode_head_cfg['loss_decode'] = dict(type='CrossEntropyLoss', use_sigmoid=False, class_weight=np.random.rand(20), loss_weight=1.0)\n    self = build_head(pn2_decode_head_cfg)\n    self.cuda()\n    losses = self.losses(seg_logits, pts_semantic_mask)\n    assert losses['loss_sem_seg'].item() > 0",
            "def test_pn2_decode_head_loss():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    pn2_decode_head_cfg = dict(type='PointNet2Head', fp_channels=((768, 256, 256), (384, 256, 256), (320, 256, 128), (128, 128, 128, 128)), channels=128, num_classes=20, dropout_ratio=0.5, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), act_cfg=dict(type='ReLU'), loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=False, class_weight=None, loss_weight=1.0), ignore_index=20)\n    self = build_head(pn2_decode_head_cfg)\n    self.cuda()\n    assert isinstance(self.conv_seg, torch.nn.Conv1d)\n    assert self.conv_seg.in_channels == 128\n    assert self.conv_seg.out_channels == 20\n    assert self.conv_seg.kernel_size == (1,)\n    assert isinstance(self.pre_seg_conv, ConvModule)\n    assert isinstance(self.pre_seg_conv.conv, torch.nn.Conv1d)\n    assert self.pre_seg_conv.conv.in_channels == 128\n    assert self.pre_seg_conv.conv.out_channels == 128\n    assert self.pre_seg_conv.conv.kernel_size == (1,)\n    assert isinstance(self.pre_seg_conv.bn, torch.nn.BatchNorm1d)\n    assert self.pre_seg_conv.bn.num_features == 128\n    assert isinstance(self.pre_seg_conv.activate, torch.nn.ReLU)\n    sa_xyz = [torch.rand(2, 4096, 3).float().cuda(), torch.rand(2, 1024, 3).float().cuda(), torch.rand(2, 256, 3).float().cuda(), torch.rand(2, 64, 3).float().cuda(), torch.rand(2, 16, 3).float().cuda()]\n    sa_features = [torch.rand(2, 6, 4096).float().cuda(), torch.rand(2, 64, 1024).float().cuda(), torch.rand(2, 128, 256).float().cuda(), torch.rand(2, 256, 64).float().cuda(), torch.rand(2, 512, 16).float().cuda()]\n    input_dict = dict(sa_xyz=sa_xyz, sa_features=sa_features)\n    seg_logits = self(input_dict)\n    assert seg_logits.shape == torch.Size([2, 20, 4096])\n    pts_semantic_mask = torch.randint(0, 20, (2, 4096)).long().cuda()\n    losses = self.losses(seg_logits, pts_semantic_mask)\n    assert losses['loss_sem_seg'].item() > 0\n    ignore_index_mask = torch.ones_like(pts_semantic_mask) * 20\n    losses = self.losses(seg_logits, ignore_index_mask)\n    assert losses['loss_sem_seg'].item() == 0\n    pn2_decode_head_cfg['loss_decode'] = dict(type='CrossEntropyLoss', use_sigmoid=False, class_weight=np.random.rand(20), loss_weight=1.0)\n    self = build_head(pn2_decode_head_cfg)\n    self.cuda()\n    losses = self.losses(seg_logits, pts_semantic_mask)\n    assert losses['loss_sem_seg'].item() > 0",
            "def test_pn2_decode_head_loss():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    pn2_decode_head_cfg = dict(type='PointNet2Head', fp_channels=((768, 256, 256), (384, 256, 256), (320, 256, 128), (128, 128, 128, 128)), channels=128, num_classes=20, dropout_ratio=0.5, conv_cfg=dict(type='Conv1d'), norm_cfg=dict(type='BN1d'), act_cfg=dict(type='ReLU'), loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=False, class_weight=None, loss_weight=1.0), ignore_index=20)\n    self = build_head(pn2_decode_head_cfg)\n    self.cuda()\n    assert isinstance(self.conv_seg, torch.nn.Conv1d)\n    assert self.conv_seg.in_channels == 128\n    assert self.conv_seg.out_channels == 20\n    assert self.conv_seg.kernel_size == (1,)\n    assert isinstance(self.pre_seg_conv, ConvModule)\n    assert isinstance(self.pre_seg_conv.conv, torch.nn.Conv1d)\n    assert self.pre_seg_conv.conv.in_channels == 128\n    assert self.pre_seg_conv.conv.out_channels == 128\n    assert self.pre_seg_conv.conv.kernel_size == (1,)\n    assert isinstance(self.pre_seg_conv.bn, torch.nn.BatchNorm1d)\n    assert self.pre_seg_conv.bn.num_features == 128\n    assert isinstance(self.pre_seg_conv.activate, torch.nn.ReLU)\n    sa_xyz = [torch.rand(2, 4096, 3).float().cuda(), torch.rand(2, 1024, 3).float().cuda(), torch.rand(2, 256, 3).float().cuda(), torch.rand(2, 64, 3).float().cuda(), torch.rand(2, 16, 3).float().cuda()]\n    sa_features = [torch.rand(2, 6, 4096).float().cuda(), torch.rand(2, 64, 1024).float().cuda(), torch.rand(2, 128, 256).float().cuda(), torch.rand(2, 256, 64).float().cuda(), torch.rand(2, 512, 16).float().cuda()]\n    input_dict = dict(sa_xyz=sa_xyz, sa_features=sa_features)\n    seg_logits = self(input_dict)\n    assert seg_logits.shape == torch.Size([2, 20, 4096])\n    pts_semantic_mask = torch.randint(0, 20, (2, 4096)).long().cuda()\n    losses = self.losses(seg_logits, pts_semantic_mask)\n    assert losses['loss_sem_seg'].item() > 0\n    ignore_index_mask = torch.ones_like(pts_semantic_mask) * 20\n    losses = self.losses(seg_logits, ignore_index_mask)\n    assert losses['loss_sem_seg'].item() == 0\n    pn2_decode_head_cfg['loss_decode'] = dict(type='CrossEntropyLoss', use_sigmoid=False, class_weight=np.random.rand(20), loss_weight=1.0)\n    self = build_head(pn2_decode_head_cfg)\n    self.cuda()\n    losses = self.losses(seg_logits, pts_semantic_mask)\n    assert losses['loss_sem_seg'].item() > 0"
        ]
    }
]