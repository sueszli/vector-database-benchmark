[
    {
        "func_name": "__init__",
        "original": "def __init__(self, num_classes=80, num_ffn_fcs=2, num_heads=8, num_cls_fcs=1, num_mask_fcs=3, feedforward_channels=2048, in_channels=256, out_channels=256, dropout=0.0, mask_thr=0.5, act_cfg=dict(type='ReLU', inplace=True), ffn_act_cfg=dict(type='ReLU', inplace=True), conv_kernel_size=3, feat_transform_cfg=None, hard_mask_thr=0.5, kernel_init=False, with_ffn=True, mask_out_stride=4, relative_coors=False, relative_coors_off=False, feat_gather_stride=1, mask_transform_stride=1, mask_upsample_stride=1, num_thing_classes=80, num_stuff_classes=53, mask_assign_stride=4, ignore_label=255, thing_label_in_seg=0, previous=None, previous_x_feat=None, previous_link=None, previous_type=None, previous_detach=False, previous_detach_link=False, previous_link_detach=False, kernel_updator_cfg=dict(type='DynamicConv', in_channels=256, feat_channels=64, out_channels=256, input_feat_shape=1, act_cfg=dict(type='ReLU', inplace=True), norm_cfg=dict(type='LN')), loss_rank=None, loss_mask=dict(type='CrossEntropyLoss', use_mask=True, loss_weight=1.0), loss_dice=dict(type='DiceLoss', loss_weight=3.0), loss_cls=dict(type='FocalLoss', use_sigmoid=True, gamma=2.0, alpha=0.25, loss_weight=2.0)):\n    super(VideoKernelUpdateHead, self).__init__()\n    self.num_classes = num_classes\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_mask = build_loss(loss_mask)\n    self.loss_dice = build_loss(loss_dice)\n    if loss_rank is not None:\n        self.loss_rank = build_loss(loss_rank)\n    else:\n        self.loss_rank = loss_rank\n    self.in_channels = in_channels\n    self.out_channels = out_channels\n    self.mask_thr = mask_thr\n    self.fp16_enabled = False\n    self.dropout = dropout\n    self.num_heads = num_heads\n    self.hard_mask_thr = hard_mask_thr\n    self.kernel_init = kernel_init\n    self.with_ffn = with_ffn\n    self.mask_out_stride = mask_out_stride\n    self.relative_coors = relative_coors\n    self.relative_coors_off = relative_coors_off\n    self.conv_kernel_size = conv_kernel_size\n    self.feat_gather_stride = feat_gather_stride\n    self.mask_transform_stride = mask_transform_stride\n    self.mask_upsample_stride = mask_upsample_stride\n    self.num_thing_classes = num_thing_classes\n    self.num_stuff_classes = num_stuff_classes\n    self.mask_assign_stride = mask_assign_stride\n    self.ignore_label = ignore_label\n    self.thing_label_in_seg = thing_label_in_seg\n    self.attention = MultiheadAttention(in_channels * conv_kernel_size ** 2, num_heads, dropout)\n    self.attention_norm = build_norm_layer(dict(type='LN'), in_channels * conv_kernel_size ** 2)[1]\n    self.kernel_update_conv = build_transformer_layer(kernel_updator_cfg)\n    if feat_transform_cfg is not None:\n        kernel_size = feat_transform_cfg.pop('kernel_size', 1)\n        self.feat_transform = ConvModule(in_channels, in_channels, kernel_size, stride=feat_gather_stride, padding=int(feat_gather_stride // 2), **feat_transform_cfg)\n    else:\n        self.feat_transform = None\n    if self.with_ffn:\n        self.ffn = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n        self.ffn_norm = build_norm_layer(dict(type='LN'), in_channels)[1]\n    self.cls_fcs = nn.ModuleList()\n    for _ in range(num_cls_fcs):\n        self.cls_fcs.append(nn.Linear(in_channels, in_channels, bias=False))\n        self.cls_fcs.append(build_norm_layer(dict(type='LN'), in_channels)[1])\n        self.cls_fcs.append(build_activation_layer(act_cfg))\n    if self.loss_cls.use_sigmoid:\n        self.fc_cls = nn.Linear(in_channels, self.num_classes)\n    else:\n        self.fc_cls = nn.Linear(in_channels, self.num_classes + 1)\n    self.mask_fcs = nn.ModuleList()\n    for _ in range(num_mask_fcs):\n        self.mask_fcs.append(nn.Linear(in_channels, in_channels, bias=False))\n        self.mask_fcs.append(build_norm_layer(dict(type='LN'), in_channels)[1])\n        self.mask_fcs.append(build_activation_layer(act_cfg))\n    self.fc_mask = nn.Linear(in_channels, out_channels)\n    self.previous = previous\n    self.previous_type = previous_type\n    self.previous_link = previous_link\n    self.previous_x_feat = previous_x_feat\n    self.previous_detach = previous_detach\n    self.previous_detach_link = previous_detach_link\n    self.previous_link_detach = previous_link_detach\n    if self.previous is not None:\n        _in_channels = self.in_channels\n        _conv_kernel_size = self.conv_kernel_size\n        _num_head = 8\n        _dropout = 0.0\n        if self.previous_type == 'ffn':\n            self.attention_previous = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm = build_norm_layer(dict(type='LN'), in_channels)[1]\n        elif self.previous_type == 'update' or self.previous_type == 'update_obj':\n            self.attention_previous_update_track = build_transformer_layer(kernel_updator_cfg)\n            self.attention_previous_track = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_track) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_track = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_track = build_norm_layer(dict(type='LN'), in_channels)[1]\n        if self.previous_link == 'update_dynamic_cov':\n            _in_channels = self.in_channels\n            _conv_kernel_size = self.conv_kernel_size\n            _num_head = 8\n            _dropout = 0.0\n            self.attention_previous_update_link = build_transformer_layer(kernel_updator_cfg)\n            self.attention_previous_link = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_link) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_link = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_link = build_norm_layer(dict(type='LN'), in_channels)[1]\n        elif self.previous_link == 'link_atten':\n            _in_channels = self.in_channels\n            _conv_kernel_size = self.conv_kernel_size\n            _num_head = 8\n            _dropout = 0.0\n            self.attention_previous_link = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_link) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_link = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_link = build_norm_layer(dict(type='LN'), in_channels)[1]",
        "mutated": [
            "def __init__(self, num_classes=80, num_ffn_fcs=2, num_heads=8, num_cls_fcs=1, num_mask_fcs=3, feedforward_channels=2048, in_channels=256, out_channels=256, dropout=0.0, mask_thr=0.5, act_cfg=dict(type='ReLU', inplace=True), ffn_act_cfg=dict(type='ReLU', inplace=True), conv_kernel_size=3, feat_transform_cfg=None, hard_mask_thr=0.5, kernel_init=False, with_ffn=True, mask_out_stride=4, relative_coors=False, relative_coors_off=False, feat_gather_stride=1, mask_transform_stride=1, mask_upsample_stride=1, num_thing_classes=80, num_stuff_classes=53, mask_assign_stride=4, ignore_label=255, thing_label_in_seg=0, previous=None, previous_x_feat=None, previous_link=None, previous_type=None, previous_detach=False, previous_detach_link=False, previous_link_detach=False, kernel_updator_cfg=dict(type='DynamicConv', in_channels=256, feat_channels=64, out_channels=256, input_feat_shape=1, act_cfg=dict(type='ReLU', inplace=True), norm_cfg=dict(type='LN')), loss_rank=None, loss_mask=dict(type='CrossEntropyLoss', use_mask=True, loss_weight=1.0), loss_dice=dict(type='DiceLoss', loss_weight=3.0), loss_cls=dict(type='FocalLoss', use_sigmoid=True, gamma=2.0, alpha=0.25, loss_weight=2.0)):\n    if False:\n        i = 10\n    super(VideoKernelUpdateHead, self).__init__()\n    self.num_classes = num_classes\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_mask = build_loss(loss_mask)\n    self.loss_dice = build_loss(loss_dice)\n    if loss_rank is not None:\n        self.loss_rank = build_loss(loss_rank)\n    else:\n        self.loss_rank = loss_rank\n    self.in_channels = in_channels\n    self.out_channels = out_channels\n    self.mask_thr = mask_thr\n    self.fp16_enabled = False\n    self.dropout = dropout\n    self.num_heads = num_heads\n    self.hard_mask_thr = hard_mask_thr\n    self.kernel_init = kernel_init\n    self.with_ffn = with_ffn\n    self.mask_out_stride = mask_out_stride\n    self.relative_coors = relative_coors\n    self.relative_coors_off = relative_coors_off\n    self.conv_kernel_size = conv_kernel_size\n    self.feat_gather_stride = feat_gather_stride\n    self.mask_transform_stride = mask_transform_stride\n    self.mask_upsample_stride = mask_upsample_stride\n    self.num_thing_classes = num_thing_classes\n    self.num_stuff_classes = num_stuff_classes\n    self.mask_assign_stride = mask_assign_stride\n    self.ignore_label = ignore_label\n    self.thing_label_in_seg = thing_label_in_seg\n    self.attention = MultiheadAttention(in_channels * conv_kernel_size ** 2, num_heads, dropout)\n    self.attention_norm = build_norm_layer(dict(type='LN'), in_channels * conv_kernel_size ** 2)[1]\n    self.kernel_update_conv = build_transformer_layer(kernel_updator_cfg)\n    if feat_transform_cfg is not None:\n        kernel_size = feat_transform_cfg.pop('kernel_size', 1)\n        self.feat_transform = ConvModule(in_channels, in_channels, kernel_size, stride=feat_gather_stride, padding=int(feat_gather_stride // 2), **feat_transform_cfg)\n    else:\n        self.feat_transform = None\n    if self.with_ffn:\n        self.ffn = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n        self.ffn_norm = build_norm_layer(dict(type='LN'), in_channels)[1]\n    self.cls_fcs = nn.ModuleList()\n    for _ in range(num_cls_fcs):\n        self.cls_fcs.append(nn.Linear(in_channels, in_channels, bias=False))\n        self.cls_fcs.append(build_norm_layer(dict(type='LN'), in_channels)[1])\n        self.cls_fcs.append(build_activation_layer(act_cfg))\n    if self.loss_cls.use_sigmoid:\n        self.fc_cls = nn.Linear(in_channels, self.num_classes)\n    else:\n        self.fc_cls = nn.Linear(in_channels, self.num_classes + 1)\n    self.mask_fcs = nn.ModuleList()\n    for _ in range(num_mask_fcs):\n        self.mask_fcs.append(nn.Linear(in_channels, in_channels, bias=False))\n        self.mask_fcs.append(build_norm_layer(dict(type='LN'), in_channels)[1])\n        self.mask_fcs.append(build_activation_layer(act_cfg))\n    self.fc_mask = nn.Linear(in_channels, out_channels)\n    self.previous = previous\n    self.previous_type = previous_type\n    self.previous_link = previous_link\n    self.previous_x_feat = previous_x_feat\n    self.previous_detach = previous_detach\n    self.previous_detach_link = previous_detach_link\n    self.previous_link_detach = previous_link_detach\n    if self.previous is not None:\n        _in_channels = self.in_channels\n        _conv_kernel_size = self.conv_kernel_size\n        _num_head = 8\n        _dropout = 0.0\n        if self.previous_type == 'ffn':\n            self.attention_previous = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm = build_norm_layer(dict(type='LN'), in_channels)[1]\n        elif self.previous_type == 'update' or self.previous_type == 'update_obj':\n            self.attention_previous_update_track = build_transformer_layer(kernel_updator_cfg)\n            self.attention_previous_track = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_track) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_track = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_track = build_norm_layer(dict(type='LN'), in_channels)[1]\n        if self.previous_link == 'update_dynamic_cov':\n            _in_channels = self.in_channels\n            _conv_kernel_size = self.conv_kernel_size\n            _num_head = 8\n            _dropout = 0.0\n            self.attention_previous_update_link = build_transformer_layer(kernel_updator_cfg)\n            self.attention_previous_link = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_link) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_link = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_link = build_norm_layer(dict(type='LN'), in_channels)[1]\n        elif self.previous_link == 'link_atten':\n            _in_channels = self.in_channels\n            _conv_kernel_size = self.conv_kernel_size\n            _num_head = 8\n            _dropout = 0.0\n            self.attention_previous_link = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_link) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_link = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_link = build_norm_layer(dict(type='LN'), in_channels)[1]",
            "def __init__(self, num_classes=80, num_ffn_fcs=2, num_heads=8, num_cls_fcs=1, num_mask_fcs=3, feedforward_channels=2048, in_channels=256, out_channels=256, dropout=0.0, mask_thr=0.5, act_cfg=dict(type='ReLU', inplace=True), ffn_act_cfg=dict(type='ReLU', inplace=True), conv_kernel_size=3, feat_transform_cfg=None, hard_mask_thr=0.5, kernel_init=False, with_ffn=True, mask_out_stride=4, relative_coors=False, relative_coors_off=False, feat_gather_stride=1, mask_transform_stride=1, mask_upsample_stride=1, num_thing_classes=80, num_stuff_classes=53, mask_assign_stride=4, ignore_label=255, thing_label_in_seg=0, previous=None, previous_x_feat=None, previous_link=None, previous_type=None, previous_detach=False, previous_detach_link=False, previous_link_detach=False, kernel_updator_cfg=dict(type='DynamicConv', in_channels=256, feat_channels=64, out_channels=256, input_feat_shape=1, act_cfg=dict(type='ReLU', inplace=True), norm_cfg=dict(type='LN')), loss_rank=None, loss_mask=dict(type='CrossEntropyLoss', use_mask=True, loss_weight=1.0), loss_dice=dict(type='DiceLoss', loss_weight=3.0), loss_cls=dict(type='FocalLoss', use_sigmoid=True, gamma=2.0, alpha=0.25, loss_weight=2.0)):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super(VideoKernelUpdateHead, self).__init__()\n    self.num_classes = num_classes\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_mask = build_loss(loss_mask)\n    self.loss_dice = build_loss(loss_dice)\n    if loss_rank is not None:\n        self.loss_rank = build_loss(loss_rank)\n    else:\n        self.loss_rank = loss_rank\n    self.in_channels = in_channels\n    self.out_channels = out_channels\n    self.mask_thr = mask_thr\n    self.fp16_enabled = False\n    self.dropout = dropout\n    self.num_heads = num_heads\n    self.hard_mask_thr = hard_mask_thr\n    self.kernel_init = kernel_init\n    self.with_ffn = with_ffn\n    self.mask_out_stride = mask_out_stride\n    self.relative_coors = relative_coors\n    self.relative_coors_off = relative_coors_off\n    self.conv_kernel_size = conv_kernel_size\n    self.feat_gather_stride = feat_gather_stride\n    self.mask_transform_stride = mask_transform_stride\n    self.mask_upsample_stride = mask_upsample_stride\n    self.num_thing_classes = num_thing_classes\n    self.num_stuff_classes = num_stuff_classes\n    self.mask_assign_stride = mask_assign_stride\n    self.ignore_label = ignore_label\n    self.thing_label_in_seg = thing_label_in_seg\n    self.attention = MultiheadAttention(in_channels * conv_kernel_size ** 2, num_heads, dropout)\n    self.attention_norm = build_norm_layer(dict(type='LN'), in_channels * conv_kernel_size ** 2)[1]\n    self.kernel_update_conv = build_transformer_layer(kernel_updator_cfg)\n    if feat_transform_cfg is not None:\n        kernel_size = feat_transform_cfg.pop('kernel_size', 1)\n        self.feat_transform = ConvModule(in_channels, in_channels, kernel_size, stride=feat_gather_stride, padding=int(feat_gather_stride // 2), **feat_transform_cfg)\n    else:\n        self.feat_transform = None\n    if self.with_ffn:\n        self.ffn = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n        self.ffn_norm = build_norm_layer(dict(type='LN'), in_channels)[1]\n    self.cls_fcs = nn.ModuleList()\n    for _ in range(num_cls_fcs):\n        self.cls_fcs.append(nn.Linear(in_channels, in_channels, bias=False))\n        self.cls_fcs.append(build_norm_layer(dict(type='LN'), in_channels)[1])\n        self.cls_fcs.append(build_activation_layer(act_cfg))\n    if self.loss_cls.use_sigmoid:\n        self.fc_cls = nn.Linear(in_channels, self.num_classes)\n    else:\n        self.fc_cls = nn.Linear(in_channels, self.num_classes + 1)\n    self.mask_fcs = nn.ModuleList()\n    for _ in range(num_mask_fcs):\n        self.mask_fcs.append(nn.Linear(in_channels, in_channels, bias=False))\n        self.mask_fcs.append(build_norm_layer(dict(type='LN'), in_channels)[1])\n        self.mask_fcs.append(build_activation_layer(act_cfg))\n    self.fc_mask = nn.Linear(in_channels, out_channels)\n    self.previous = previous\n    self.previous_type = previous_type\n    self.previous_link = previous_link\n    self.previous_x_feat = previous_x_feat\n    self.previous_detach = previous_detach\n    self.previous_detach_link = previous_detach_link\n    self.previous_link_detach = previous_link_detach\n    if self.previous is not None:\n        _in_channels = self.in_channels\n        _conv_kernel_size = self.conv_kernel_size\n        _num_head = 8\n        _dropout = 0.0\n        if self.previous_type == 'ffn':\n            self.attention_previous = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm = build_norm_layer(dict(type='LN'), in_channels)[1]\n        elif self.previous_type == 'update' or self.previous_type == 'update_obj':\n            self.attention_previous_update_track = build_transformer_layer(kernel_updator_cfg)\n            self.attention_previous_track = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_track) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_track = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_track = build_norm_layer(dict(type='LN'), in_channels)[1]\n        if self.previous_link == 'update_dynamic_cov':\n            _in_channels = self.in_channels\n            _conv_kernel_size = self.conv_kernel_size\n            _num_head = 8\n            _dropout = 0.0\n            self.attention_previous_update_link = build_transformer_layer(kernel_updator_cfg)\n            self.attention_previous_link = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_link) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_link = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_link = build_norm_layer(dict(type='LN'), in_channels)[1]\n        elif self.previous_link == 'link_atten':\n            _in_channels = self.in_channels\n            _conv_kernel_size = self.conv_kernel_size\n            _num_head = 8\n            _dropout = 0.0\n            self.attention_previous_link = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_link) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_link = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_link = build_norm_layer(dict(type='LN'), in_channels)[1]",
            "def __init__(self, num_classes=80, num_ffn_fcs=2, num_heads=8, num_cls_fcs=1, num_mask_fcs=3, feedforward_channels=2048, in_channels=256, out_channels=256, dropout=0.0, mask_thr=0.5, act_cfg=dict(type='ReLU', inplace=True), ffn_act_cfg=dict(type='ReLU', inplace=True), conv_kernel_size=3, feat_transform_cfg=None, hard_mask_thr=0.5, kernel_init=False, with_ffn=True, mask_out_stride=4, relative_coors=False, relative_coors_off=False, feat_gather_stride=1, mask_transform_stride=1, mask_upsample_stride=1, num_thing_classes=80, num_stuff_classes=53, mask_assign_stride=4, ignore_label=255, thing_label_in_seg=0, previous=None, previous_x_feat=None, previous_link=None, previous_type=None, previous_detach=False, previous_detach_link=False, previous_link_detach=False, kernel_updator_cfg=dict(type='DynamicConv', in_channels=256, feat_channels=64, out_channels=256, input_feat_shape=1, act_cfg=dict(type='ReLU', inplace=True), norm_cfg=dict(type='LN')), loss_rank=None, loss_mask=dict(type='CrossEntropyLoss', use_mask=True, loss_weight=1.0), loss_dice=dict(type='DiceLoss', loss_weight=3.0), loss_cls=dict(type='FocalLoss', use_sigmoid=True, gamma=2.0, alpha=0.25, loss_weight=2.0)):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super(VideoKernelUpdateHead, self).__init__()\n    self.num_classes = num_classes\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_mask = build_loss(loss_mask)\n    self.loss_dice = build_loss(loss_dice)\n    if loss_rank is not None:\n        self.loss_rank = build_loss(loss_rank)\n    else:\n        self.loss_rank = loss_rank\n    self.in_channels = in_channels\n    self.out_channels = out_channels\n    self.mask_thr = mask_thr\n    self.fp16_enabled = False\n    self.dropout = dropout\n    self.num_heads = num_heads\n    self.hard_mask_thr = hard_mask_thr\n    self.kernel_init = kernel_init\n    self.with_ffn = with_ffn\n    self.mask_out_stride = mask_out_stride\n    self.relative_coors = relative_coors\n    self.relative_coors_off = relative_coors_off\n    self.conv_kernel_size = conv_kernel_size\n    self.feat_gather_stride = feat_gather_stride\n    self.mask_transform_stride = mask_transform_stride\n    self.mask_upsample_stride = mask_upsample_stride\n    self.num_thing_classes = num_thing_classes\n    self.num_stuff_classes = num_stuff_classes\n    self.mask_assign_stride = mask_assign_stride\n    self.ignore_label = ignore_label\n    self.thing_label_in_seg = thing_label_in_seg\n    self.attention = MultiheadAttention(in_channels * conv_kernel_size ** 2, num_heads, dropout)\n    self.attention_norm = build_norm_layer(dict(type='LN'), in_channels * conv_kernel_size ** 2)[1]\n    self.kernel_update_conv = build_transformer_layer(kernel_updator_cfg)\n    if feat_transform_cfg is not None:\n        kernel_size = feat_transform_cfg.pop('kernel_size', 1)\n        self.feat_transform = ConvModule(in_channels, in_channels, kernel_size, stride=feat_gather_stride, padding=int(feat_gather_stride // 2), **feat_transform_cfg)\n    else:\n        self.feat_transform = None\n    if self.with_ffn:\n        self.ffn = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n        self.ffn_norm = build_norm_layer(dict(type='LN'), in_channels)[1]\n    self.cls_fcs = nn.ModuleList()\n    for _ in range(num_cls_fcs):\n        self.cls_fcs.append(nn.Linear(in_channels, in_channels, bias=False))\n        self.cls_fcs.append(build_norm_layer(dict(type='LN'), in_channels)[1])\n        self.cls_fcs.append(build_activation_layer(act_cfg))\n    if self.loss_cls.use_sigmoid:\n        self.fc_cls = nn.Linear(in_channels, self.num_classes)\n    else:\n        self.fc_cls = nn.Linear(in_channels, self.num_classes + 1)\n    self.mask_fcs = nn.ModuleList()\n    for _ in range(num_mask_fcs):\n        self.mask_fcs.append(nn.Linear(in_channels, in_channels, bias=False))\n        self.mask_fcs.append(build_norm_layer(dict(type='LN'), in_channels)[1])\n        self.mask_fcs.append(build_activation_layer(act_cfg))\n    self.fc_mask = nn.Linear(in_channels, out_channels)\n    self.previous = previous\n    self.previous_type = previous_type\n    self.previous_link = previous_link\n    self.previous_x_feat = previous_x_feat\n    self.previous_detach = previous_detach\n    self.previous_detach_link = previous_detach_link\n    self.previous_link_detach = previous_link_detach\n    if self.previous is not None:\n        _in_channels = self.in_channels\n        _conv_kernel_size = self.conv_kernel_size\n        _num_head = 8\n        _dropout = 0.0\n        if self.previous_type == 'ffn':\n            self.attention_previous = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm = build_norm_layer(dict(type='LN'), in_channels)[1]\n        elif self.previous_type == 'update' or self.previous_type == 'update_obj':\n            self.attention_previous_update_track = build_transformer_layer(kernel_updator_cfg)\n            self.attention_previous_track = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_track) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_track = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_track = build_norm_layer(dict(type='LN'), in_channels)[1]\n        if self.previous_link == 'update_dynamic_cov':\n            _in_channels = self.in_channels\n            _conv_kernel_size = self.conv_kernel_size\n            _num_head = 8\n            _dropout = 0.0\n            self.attention_previous_update_link = build_transformer_layer(kernel_updator_cfg)\n            self.attention_previous_link = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_link) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_link = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_link = build_norm_layer(dict(type='LN'), in_channels)[1]\n        elif self.previous_link == 'link_atten':\n            _in_channels = self.in_channels\n            _conv_kernel_size = self.conv_kernel_size\n            _num_head = 8\n            _dropout = 0.0\n            self.attention_previous_link = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_link) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_link = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_link = build_norm_layer(dict(type='LN'), in_channels)[1]",
            "def __init__(self, num_classes=80, num_ffn_fcs=2, num_heads=8, num_cls_fcs=1, num_mask_fcs=3, feedforward_channels=2048, in_channels=256, out_channels=256, dropout=0.0, mask_thr=0.5, act_cfg=dict(type='ReLU', inplace=True), ffn_act_cfg=dict(type='ReLU', inplace=True), conv_kernel_size=3, feat_transform_cfg=None, hard_mask_thr=0.5, kernel_init=False, with_ffn=True, mask_out_stride=4, relative_coors=False, relative_coors_off=False, feat_gather_stride=1, mask_transform_stride=1, mask_upsample_stride=1, num_thing_classes=80, num_stuff_classes=53, mask_assign_stride=4, ignore_label=255, thing_label_in_seg=0, previous=None, previous_x_feat=None, previous_link=None, previous_type=None, previous_detach=False, previous_detach_link=False, previous_link_detach=False, kernel_updator_cfg=dict(type='DynamicConv', in_channels=256, feat_channels=64, out_channels=256, input_feat_shape=1, act_cfg=dict(type='ReLU', inplace=True), norm_cfg=dict(type='LN')), loss_rank=None, loss_mask=dict(type='CrossEntropyLoss', use_mask=True, loss_weight=1.0), loss_dice=dict(type='DiceLoss', loss_weight=3.0), loss_cls=dict(type='FocalLoss', use_sigmoid=True, gamma=2.0, alpha=0.25, loss_weight=2.0)):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super(VideoKernelUpdateHead, self).__init__()\n    self.num_classes = num_classes\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_mask = build_loss(loss_mask)\n    self.loss_dice = build_loss(loss_dice)\n    if loss_rank is not None:\n        self.loss_rank = build_loss(loss_rank)\n    else:\n        self.loss_rank = loss_rank\n    self.in_channels = in_channels\n    self.out_channels = out_channels\n    self.mask_thr = mask_thr\n    self.fp16_enabled = False\n    self.dropout = dropout\n    self.num_heads = num_heads\n    self.hard_mask_thr = hard_mask_thr\n    self.kernel_init = kernel_init\n    self.with_ffn = with_ffn\n    self.mask_out_stride = mask_out_stride\n    self.relative_coors = relative_coors\n    self.relative_coors_off = relative_coors_off\n    self.conv_kernel_size = conv_kernel_size\n    self.feat_gather_stride = feat_gather_stride\n    self.mask_transform_stride = mask_transform_stride\n    self.mask_upsample_stride = mask_upsample_stride\n    self.num_thing_classes = num_thing_classes\n    self.num_stuff_classes = num_stuff_classes\n    self.mask_assign_stride = mask_assign_stride\n    self.ignore_label = ignore_label\n    self.thing_label_in_seg = thing_label_in_seg\n    self.attention = MultiheadAttention(in_channels * conv_kernel_size ** 2, num_heads, dropout)\n    self.attention_norm = build_norm_layer(dict(type='LN'), in_channels * conv_kernel_size ** 2)[1]\n    self.kernel_update_conv = build_transformer_layer(kernel_updator_cfg)\n    if feat_transform_cfg is not None:\n        kernel_size = feat_transform_cfg.pop('kernel_size', 1)\n        self.feat_transform = ConvModule(in_channels, in_channels, kernel_size, stride=feat_gather_stride, padding=int(feat_gather_stride // 2), **feat_transform_cfg)\n    else:\n        self.feat_transform = None\n    if self.with_ffn:\n        self.ffn = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n        self.ffn_norm = build_norm_layer(dict(type='LN'), in_channels)[1]\n    self.cls_fcs = nn.ModuleList()\n    for _ in range(num_cls_fcs):\n        self.cls_fcs.append(nn.Linear(in_channels, in_channels, bias=False))\n        self.cls_fcs.append(build_norm_layer(dict(type='LN'), in_channels)[1])\n        self.cls_fcs.append(build_activation_layer(act_cfg))\n    if self.loss_cls.use_sigmoid:\n        self.fc_cls = nn.Linear(in_channels, self.num_classes)\n    else:\n        self.fc_cls = nn.Linear(in_channels, self.num_classes + 1)\n    self.mask_fcs = nn.ModuleList()\n    for _ in range(num_mask_fcs):\n        self.mask_fcs.append(nn.Linear(in_channels, in_channels, bias=False))\n        self.mask_fcs.append(build_norm_layer(dict(type='LN'), in_channels)[1])\n        self.mask_fcs.append(build_activation_layer(act_cfg))\n    self.fc_mask = nn.Linear(in_channels, out_channels)\n    self.previous = previous\n    self.previous_type = previous_type\n    self.previous_link = previous_link\n    self.previous_x_feat = previous_x_feat\n    self.previous_detach = previous_detach\n    self.previous_detach_link = previous_detach_link\n    self.previous_link_detach = previous_link_detach\n    if self.previous is not None:\n        _in_channels = self.in_channels\n        _conv_kernel_size = self.conv_kernel_size\n        _num_head = 8\n        _dropout = 0.0\n        if self.previous_type == 'ffn':\n            self.attention_previous = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm = build_norm_layer(dict(type='LN'), in_channels)[1]\n        elif self.previous_type == 'update' or self.previous_type == 'update_obj':\n            self.attention_previous_update_track = build_transformer_layer(kernel_updator_cfg)\n            self.attention_previous_track = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_track) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_track = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_track = build_norm_layer(dict(type='LN'), in_channels)[1]\n        if self.previous_link == 'update_dynamic_cov':\n            _in_channels = self.in_channels\n            _conv_kernel_size = self.conv_kernel_size\n            _num_head = 8\n            _dropout = 0.0\n            self.attention_previous_update_link = build_transformer_layer(kernel_updator_cfg)\n            self.attention_previous_link = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_link) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_link = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_link = build_norm_layer(dict(type='LN'), in_channels)[1]\n        elif self.previous_link == 'link_atten':\n            _in_channels = self.in_channels\n            _conv_kernel_size = self.conv_kernel_size\n            _num_head = 8\n            _dropout = 0.0\n            self.attention_previous_link = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_link) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_link = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_link = build_norm_layer(dict(type='LN'), in_channels)[1]",
            "def __init__(self, num_classes=80, num_ffn_fcs=2, num_heads=8, num_cls_fcs=1, num_mask_fcs=3, feedforward_channels=2048, in_channels=256, out_channels=256, dropout=0.0, mask_thr=0.5, act_cfg=dict(type='ReLU', inplace=True), ffn_act_cfg=dict(type='ReLU', inplace=True), conv_kernel_size=3, feat_transform_cfg=None, hard_mask_thr=0.5, kernel_init=False, with_ffn=True, mask_out_stride=4, relative_coors=False, relative_coors_off=False, feat_gather_stride=1, mask_transform_stride=1, mask_upsample_stride=1, num_thing_classes=80, num_stuff_classes=53, mask_assign_stride=4, ignore_label=255, thing_label_in_seg=0, previous=None, previous_x_feat=None, previous_link=None, previous_type=None, previous_detach=False, previous_detach_link=False, previous_link_detach=False, kernel_updator_cfg=dict(type='DynamicConv', in_channels=256, feat_channels=64, out_channels=256, input_feat_shape=1, act_cfg=dict(type='ReLU', inplace=True), norm_cfg=dict(type='LN')), loss_rank=None, loss_mask=dict(type='CrossEntropyLoss', use_mask=True, loss_weight=1.0), loss_dice=dict(type='DiceLoss', loss_weight=3.0), loss_cls=dict(type='FocalLoss', use_sigmoid=True, gamma=2.0, alpha=0.25, loss_weight=2.0)):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super(VideoKernelUpdateHead, self).__init__()\n    self.num_classes = num_classes\n    self.loss_cls = build_loss(loss_cls)\n    self.loss_mask = build_loss(loss_mask)\n    self.loss_dice = build_loss(loss_dice)\n    if loss_rank is not None:\n        self.loss_rank = build_loss(loss_rank)\n    else:\n        self.loss_rank = loss_rank\n    self.in_channels = in_channels\n    self.out_channels = out_channels\n    self.mask_thr = mask_thr\n    self.fp16_enabled = False\n    self.dropout = dropout\n    self.num_heads = num_heads\n    self.hard_mask_thr = hard_mask_thr\n    self.kernel_init = kernel_init\n    self.with_ffn = with_ffn\n    self.mask_out_stride = mask_out_stride\n    self.relative_coors = relative_coors\n    self.relative_coors_off = relative_coors_off\n    self.conv_kernel_size = conv_kernel_size\n    self.feat_gather_stride = feat_gather_stride\n    self.mask_transform_stride = mask_transform_stride\n    self.mask_upsample_stride = mask_upsample_stride\n    self.num_thing_classes = num_thing_classes\n    self.num_stuff_classes = num_stuff_classes\n    self.mask_assign_stride = mask_assign_stride\n    self.ignore_label = ignore_label\n    self.thing_label_in_seg = thing_label_in_seg\n    self.attention = MultiheadAttention(in_channels * conv_kernel_size ** 2, num_heads, dropout)\n    self.attention_norm = build_norm_layer(dict(type='LN'), in_channels * conv_kernel_size ** 2)[1]\n    self.kernel_update_conv = build_transformer_layer(kernel_updator_cfg)\n    if feat_transform_cfg is not None:\n        kernel_size = feat_transform_cfg.pop('kernel_size', 1)\n        self.feat_transform = ConvModule(in_channels, in_channels, kernel_size, stride=feat_gather_stride, padding=int(feat_gather_stride // 2), **feat_transform_cfg)\n    else:\n        self.feat_transform = None\n    if self.with_ffn:\n        self.ffn = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n        self.ffn_norm = build_norm_layer(dict(type='LN'), in_channels)[1]\n    self.cls_fcs = nn.ModuleList()\n    for _ in range(num_cls_fcs):\n        self.cls_fcs.append(nn.Linear(in_channels, in_channels, bias=False))\n        self.cls_fcs.append(build_norm_layer(dict(type='LN'), in_channels)[1])\n        self.cls_fcs.append(build_activation_layer(act_cfg))\n    if self.loss_cls.use_sigmoid:\n        self.fc_cls = nn.Linear(in_channels, self.num_classes)\n    else:\n        self.fc_cls = nn.Linear(in_channels, self.num_classes + 1)\n    self.mask_fcs = nn.ModuleList()\n    for _ in range(num_mask_fcs):\n        self.mask_fcs.append(nn.Linear(in_channels, in_channels, bias=False))\n        self.mask_fcs.append(build_norm_layer(dict(type='LN'), in_channels)[1])\n        self.mask_fcs.append(build_activation_layer(act_cfg))\n    self.fc_mask = nn.Linear(in_channels, out_channels)\n    self.previous = previous\n    self.previous_type = previous_type\n    self.previous_link = previous_link\n    self.previous_x_feat = previous_x_feat\n    self.previous_detach = previous_detach\n    self.previous_detach_link = previous_detach_link\n    self.previous_link_detach = previous_link_detach\n    if self.previous is not None:\n        _in_channels = self.in_channels\n        _conv_kernel_size = self.conv_kernel_size\n        _num_head = 8\n        _dropout = 0.0\n        if self.previous_type == 'ffn':\n            self.attention_previous = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm = build_norm_layer(dict(type='LN'), in_channels)[1]\n        elif self.previous_type == 'update' or self.previous_type == 'update_obj':\n            self.attention_previous_update_track = build_transformer_layer(kernel_updator_cfg)\n            self.attention_previous_track = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_track) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_track = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_track = build_norm_layer(dict(type='LN'), in_channels)[1]\n        if self.previous_link == 'update_dynamic_cov':\n            _in_channels = self.in_channels\n            _conv_kernel_size = self.conv_kernel_size\n            _num_head = 8\n            _dropout = 0.0\n            self.attention_previous_update_link = build_transformer_layer(kernel_updator_cfg)\n            self.attention_previous_link = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_link) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_link = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_link = build_norm_layer(dict(type='LN'), in_channels)[1]\n        elif self.previous_link == 'link_atten':\n            _in_channels = self.in_channels\n            _conv_kernel_size = self.conv_kernel_size\n            _num_head = 8\n            _dropout = 0.0\n            self.attention_previous_link = MultiheadAttention(_in_channels * _conv_kernel_size ** 2, _num_head, _dropout)\n            (_, self.attention_previous_norm_link) = build_norm_layer(dict(type='LN'), _in_channels * _conv_kernel_size ** 2)\n            self.link_ffn_link = FFN(in_channels, feedforward_channels, num_ffn_fcs, act_cfg=ffn_act_cfg, dropout=dropout)\n            self.link_ffn_norm_link = build_norm_layer(dict(type='LN'), in_channels)[1]"
        ]
    },
    {
        "func_name": "forward",
        "original": "def forward(self, x, proposal_feat, mask_preds, prev_cls_score=None, mask_shape=None, img_metas=None, previous_obj_feats=None, previous_mask_preds=None, previous_x_feats=None):\n    (N, num_proposals) = proposal_feat.shape[:2]\n    if self.feat_transform is not None:\n        x = self.feat_transform(x)\n        if previous_x_feats is not None:\n            previous_x_feats = self.feat_transform(previous_x_feats)\n    (C, H, W) = x.shape[-3:]\n    (mask_h, mask_w) = mask_preds.shape[-2:]\n    if mask_h != H or mask_w != W:\n        gather_mask = F.interpolate(mask_preds, (H, W), align_corners=False, mode='bilinear')\n    else:\n        gather_mask = mask_preds\n    sigmoid_masks = gather_mask.sigmoid()\n    nonzero_inds = sigmoid_masks > self.hard_mask_thr\n    sigmoid_masks = nonzero_inds.float()\n    x_feat = torch.einsum('bnhw,bchw->bnc', sigmoid_masks, x)\n    proposal_feat = proposal_feat.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n    if self.training and self.previous_detach:\n        previous_obj_feats = previous_obj_feats.detach()\n    if previous_obj_feats is not None and self.previous_link == 'update_dynamic_cov':\n        previous_obj_feats_link = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n        if self.training and self.previous_detach_link:\n            previous_obj_feats_link = previous_obj_feats_link.detach()\n        previous_obj_feats_update = self.attention_previous_update_link(x_feat, previous_obj_feats_link)\n        previous_obj_feats_update = previous_obj_feats_update.reshape(N, num_proposals, -1).permute(1, 0, 2)\n        cur_obj_feat = proposal_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n        cur_obj_feat = self.attention_previous_norm_link(self.attention_previous_link(query=cur_obj_feat, key=previous_obj_feats_update, value=previous_obj_feats_update, identity=cur_obj_feat))\n        cur_obj_feat = cur_obj_feat.permute(1, 0, 2)\n        cur_obj_feat = cur_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n        proposal_feat = self.link_ffn_norm_link(self.link_ffn_link(cur_obj_feat))\n    if previous_obj_feats is not None and self.previous_link == 'link_atten':\n        previous_obj_feats_link = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n        previous_obj_feats_update = previous_obj_feats_link.reshape(N, num_proposals, -1).permute(1, 0, 2)\n        cur_obj_feat = proposal_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n        cur_obj_feat = self.attention_previous_norm_link(self.attention_previous_link(query=cur_obj_feat, key=previous_obj_feats_update, value=previous_obj_feats_update, identity=cur_obj_feat))\n        cur_obj_feat = cur_obj_feat.permute(1, 0, 2)\n        cur_obj_feat = cur_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n        proposal_feat = self.link_ffn_norm_link(self.link_ffn_link(cur_obj_feat))\n    obj_feat = self.kernel_update_conv(x_feat, proposal_feat)\n    obj_feat = obj_feat.reshape(N, num_proposals, -1).permute(1, 0, 2)\n    obj_feat = self.attention_norm(self.attention(obj_feat))\n    obj_feat = obj_feat.permute(1, 0, 2)\n    obj_feat = obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n    if self.with_ffn:\n        obj_feat = self.ffn_norm(self.ffn(obj_feat))\n    if previous_obj_feats is not None:\n        if self.previous_type == 'ffn':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feat = self.attention_previous_norm(self.attention_previous(query=cur_obj_feat, key=previous_obj_feats, value=previous_obj_feats, identity=cur_obj_feat))\n            previous_obj_feat = previous_obj_feat.permute(1, 0, 2)\n            previous_obj_feat_track = previous_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm(self.link_ffn(previous_obj_feat_track))\n        elif self.previous_type == 'update':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            previous_obj_feats_track = self.attention_previous_update_track(x_feat, previous_obj_feats)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = self.attention_previous_norm_track(self.attention_previous_track(query=cur_obj_feat, key=previous_obj_feats_track, value=previous_obj_feats_track, identity=cur_obj_feat))\n            previous_obj_feats_track = previous_obj_feats_track.permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm_track(self.link_ffn_track(previous_obj_feats_track))\n        elif self.previous_type == 'update_obj':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            previous_obj_feats_track = self.attention_previous_update_track(obj_feat.squeeze(2), previous_obj_feats)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = self.attention_previous_norm_track(self.attention_previous_track(query=cur_obj_feat, key=previous_obj_feats_track, value=previous_obj_feats_track, identity=cur_obj_feat))\n            previous_obj_feats_track = previous_obj_feats_track.permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm_track(self.link_ffn_track(previous_obj_feats_track))\n        else:\n            previous_obj_feat_track = None\n    cls_feat = obj_feat.sum(-2)\n    mask_feat = obj_feat\n    for cls_layer in self.cls_fcs:\n        cls_feat = cls_layer(cls_feat)\n    for reg_layer in self.mask_fcs:\n        mask_feat = reg_layer(mask_feat)\n    cls_score = self.fc_cls(cls_feat).view(N, num_proposals, -1)\n    mask_feat = self.fc_mask(mask_feat).permute(0, 1, 3, 2)\n    if self.mask_transform_stride == 2 and self.feat_gather_stride == 1:\n        mask_x = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n        (H, W) = mask_x.shape[-2:]\n    else:\n        mask_x = x\n    mask_feat = mask_feat.reshape(N, num_proposals, C, self.conv_kernel_size, self.conv_kernel_size)\n    new_mask_preds = []\n    for i in range(N):\n        new_mask_preds.append(F.conv2d(mask_x[i:i + 1], mask_feat[i], padding=int(self.conv_kernel_size // 2)))\n    new_mask_preds = torch.cat(new_mask_preds, dim=0)\n    new_mask_preds = new_mask_preds.reshape(N, num_proposals, H, W)\n    if self.mask_transform_stride == 2:\n        new_mask_preds = F.interpolate(new_mask_preds, scale_factor=2, mode='bilinear', align_corners=False)\n    if mask_shape is not None and mask_shape[0] != H:\n        new_mask_preds = F.interpolate(new_mask_preds, mask_shape, align_corners=False, mode='bilinear')\n    if previous_obj_feats is not None and previous_obj_feat_track is not None:\n        obj_feat = obj_feat.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size)\n        previous_obj_feat_track = previous_obj_feat_track.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size)\n        return (cls_score, new_mask_preds, obj_feat, x_feat, previous_obj_feat_track)\n    else:\n        return (cls_score, new_mask_preds, obj_feat.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size), x_feat, None)",
        "mutated": [
            "def forward(self, x, proposal_feat, mask_preds, prev_cls_score=None, mask_shape=None, img_metas=None, previous_obj_feats=None, previous_mask_preds=None, previous_x_feats=None):\n    if False:\n        i = 10\n    (N, num_proposals) = proposal_feat.shape[:2]\n    if self.feat_transform is not None:\n        x = self.feat_transform(x)\n        if previous_x_feats is not None:\n            previous_x_feats = self.feat_transform(previous_x_feats)\n    (C, H, W) = x.shape[-3:]\n    (mask_h, mask_w) = mask_preds.shape[-2:]\n    if mask_h != H or mask_w != W:\n        gather_mask = F.interpolate(mask_preds, (H, W), align_corners=False, mode='bilinear')\n    else:\n        gather_mask = mask_preds\n    sigmoid_masks = gather_mask.sigmoid()\n    nonzero_inds = sigmoid_masks > self.hard_mask_thr\n    sigmoid_masks = nonzero_inds.float()\n    x_feat = torch.einsum('bnhw,bchw->bnc', sigmoid_masks, x)\n    proposal_feat = proposal_feat.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n    if self.training and self.previous_detach:\n        previous_obj_feats = previous_obj_feats.detach()\n    if previous_obj_feats is not None and self.previous_link == 'update_dynamic_cov':\n        previous_obj_feats_link = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n        if self.training and self.previous_detach_link:\n            previous_obj_feats_link = previous_obj_feats_link.detach()\n        previous_obj_feats_update = self.attention_previous_update_link(x_feat, previous_obj_feats_link)\n        previous_obj_feats_update = previous_obj_feats_update.reshape(N, num_proposals, -1).permute(1, 0, 2)\n        cur_obj_feat = proposal_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n        cur_obj_feat = self.attention_previous_norm_link(self.attention_previous_link(query=cur_obj_feat, key=previous_obj_feats_update, value=previous_obj_feats_update, identity=cur_obj_feat))\n        cur_obj_feat = cur_obj_feat.permute(1, 0, 2)\n        cur_obj_feat = cur_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n        proposal_feat = self.link_ffn_norm_link(self.link_ffn_link(cur_obj_feat))\n    if previous_obj_feats is not None and self.previous_link == 'link_atten':\n        previous_obj_feats_link = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n        previous_obj_feats_update = previous_obj_feats_link.reshape(N, num_proposals, -1).permute(1, 0, 2)\n        cur_obj_feat = proposal_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n        cur_obj_feat = self.attention_previous_norm_link(self.attention_previous_link(query=cur_obj_feat, key=previous_obj_feats_update, value=previous_obj_feats_update, identity=cur_obj_feat))\n        cur_obj_feat = cur_obj_feat.permute(1, 0, 2)\n        cur_obj_feat = cur_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n        proposal_feat = self.link_ffn_norm_link(self.link_ffn_link(cur_obj_feat))\n    obj_feat = self.kernel_update_conv(x_feat, proposal_feat)\n    obj_feat = obj_feat.reshape(N, num_proposals, -1).permute(1, 0, 2)\n    obj_feat = self.attention_norm(self.attention(obj_feat))\n    obj_feat = obj_feat.permute(1, 0, 2)\n    obj_feat = obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n    if self.with_ffn:\n        obj_feat = self.ffn_norm(self.ffn(obj_feat))\n    if previous_obj_feats is not None:\n        if self.previous_type == 'ffn':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feat = self.attention_previous_norm(self.attention_previous(query=cur_obj_feat, key=previous_obj_feats, value=previous_obj_feats, identity=cur_obj_feat))\n            previous_obj_feat = previous_obj_feat.permute(1, 0, 2)\n            previous_obj_feat_track = previous_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm(self.link_ffn(previous_obj_feat_track))\n        elif self.previous_type == 'update':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            previous_obj_feats_track = self.attention_previous_update_track(x_feat, previous_obj_feats)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = self.attention_previous_norm_track(self.attention_previous_track(query=cur_obj_feat, key=previous_obj_feats_track, value=previous_obj_feats_track, identity=cur_obj_feat))\n            previous_obj_feats_track = previous_obj_feats_track.permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm_track(self.link_ffn_track(previous_obj_feats_track))\n        elif self.previous_type == 'update_obj':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            previous_obj_feats_track = self.attention_previous_update_track(obj_feat.squeeze(2), previous_obj_feats)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = self.attention_previous_norm_track(self.attention_previous_track(query=cur_obj_feat, key=previous_obj_feats_track, value=previous_obj_feats_track, identity=cur_obj_feat))\n            previous_obj_feats_track = previous_obj_feats_track.permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm_track(self.link_ffn_track(previous_obj_feats_track))\n        else:\n            previous_obj_feat_track = None\n    cls_feat = obj_feat.sum(-2)\n    mask_feat = obj_feat\n    for cls_layer in self.cls_fcs:\n        cls_feat = cls_layer(cls_feat)\n    for reg_layer in self.mask_fcs:\n        mask_feat = reg_layer(mask_feat)\n    cls_score = self.fc_cls(cls_feat).view(N, num_proposals, -1)\n    mask_feat = self.fc_mask(mask_feat).permute(0, 1, 3, 2)\n    if self.mask_transform_stride == 2 and self.feat_gather_stride == 1:\n        mask_x = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n        (H, W) = mask_x.shape[-2:]\n    else:\n        mask_x = x\n    mask_feat = mask_feat.reshape(N, num_proposals, C, self.conv_kernel_size, self.conv_kernel_size)\n    new_mask_preds = []\n    for i in range(N):\n        new_mask_preds.append(F.conv2d(mask_x[i:i + 1], mask_feat[i], padding=int(self.conv_kernel_size // 2)))\n    new_mask_preds = torch.cat(new_mask_preds, dim=0)\n    new_mask_preds = new_mask_preds.reshape(N, num_proposals, H, W)\n    if self.mask_transform_stride == 2:\n        new_mask_preds = F.interpolate(new_mask_preds, scale_factor=2, mode='bilinear', align_corners=False)\n    if mask_shape is not None and mask_shape[0] != H:\n        new_mask_preds = F.interpolate(new_mask_preds, mask_shape, align_corners=False, mode='bilinear')\n    if previous_obj_feats is not None and previous_obj_feat_track is not None:\n        obj_feat = obj_feat.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size)\n        previous_obj_feat_track = previous_obj_feat_track.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size)\n        return (cls_score, new_mask_preds, obj_feat, x_feat, previous_obj_feat_track)\n    else:\n        return (cls_score, new_mask_preds, obj_feat.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size), x_feat, None)",
            "def forward(self, x, proposal_feat, mask_preds, prev_cls_score=None, mask_shape=None, img_metas=None, previous_obj_feats=None, previous_mask_preds=None, previous_x_feats=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (N, num_proposals) = proposal_feat.shape[:2]\n    if self.feat_transform is not None:\n        x = self.feat_transform(x)\n        if previous_x_feats is not None:\n            previous_x_feats = self.feat_transform(previous_x_feats)\n    (C, H, W) = x.shape[-3:]\n    (mask_h, mask_w) = mask_preds.shape[-2:]\n    if mask_h != H or mask_w != W:\n        gather_mask = F.interpolate(mask_preds, (H, W), align_corners=False, mode='bilinear')\n    else:\n        gather_mask = mask_preds\n    sigmoid_masks = gather_mask.sigmoid()\n    nonzero_inds = sigmoid_masks > self.hard_mask_thr\n    sigmoid_masks = nonzero_inds.float()\n    x_feat = torch.einsum('bnhw,bchw->bnc', sigmoid_masks, x)\n    proposal_feat = proposal_feat.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n    if self.training and self.previous_detach:\n        previous_obj_feats = previous_obj_feats.detach()\n    if previous_obj_feats is not None and self.previous_link == 'update_dynamic_cov':\n        previous_obj_feats_link = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n        if self.training and self.previous_detach_link:\n            previous_obj_feats_link = previous_obj_feats_link.detach()\n        previous_obj_feats_update = self.attention_previous_update_link(x_feat, previous_obj_feats_link)\n        previous_obj_feats_update = previous_obj_feats_update.reshape(N, num_proposals, -1).permute(1, 0, 2)\n        cur_obj_feat = proposal_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n        cur_obj_feat = self.attention_previous_norm_link(self.attention_previous_link(query=cur_obj_feat, key=previous_obj_feats_update, value=previous_obj_feats_update, identity=cur_obj_feat))\n        cur_obj_feat = cur_obj_feat.permute(1, 0, 2)\n        cur_obj_feat = cur_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n        proposal_feat = self.link_ffn_norm_link(self.link_ffn_link(cur_obj_feat))\n    if previous_obj_feats is not None and self.previous_link == 'link_atten':\n        previous_obj_feats_link = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n        previous_obj_feats_update = previous_obj_feats_link.reshape(N, num_proposals, -1).permute(1, 0, 2)\n        cur_obj_feat = proposal_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n        cur_obj_feat = self.attention_previous_norm_link(self.attention_previous_link(query=cur_obj_feat, key=previous_obj_feats_update, value=previous_obj_feats_update, identity=cur_obj_feat))\n        cur_obj_feat = cur_obj_feat.permute(1, 0, 2)\n        cur_obj_feat = cur_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n        proposal_feat = self.link_ffn_norm_link(self.link_ffn_link(cur_obj_feat))\n    obj_feat = self.kernel_update_conv(x_feat, proposal_feat)\n    obj_feat = obj_feat.reshape(N, num_proposals, -1).permute(1, 0, 2)\n    obj_feat = self.attention_norm(self.attention(obj_feat))\n    obj_feat = obj_feat.permute(1, 0, 2)\n    obj_feat = obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n    if self.with_ffn:\n        obj_feat = self.ffn_norm(self.ffn(obj_feat))\n    if previous_obj_feats is not None:\n        if self.previous_type == 'ffn':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feat = self.attention_previous_norm(self.attention_previous(query=cur_obj_feat, key=previous_obj_feats, value=previous_obj_feats, identity=cur_obj_feat))\n            previous_obj_feat = previous_obj_feat.permute(1, 0, 2)\n            previous_obj_feat_track = previous_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm(self.link_ffn(previous_obj_feat_track))\n        elif self.previous_type == 'update':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            previous_obj_feats_track = self.attention_previous_update_track(x_feat, previous_obj_feats)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = self.attention_previous_norm_track(self.attention_previous_track(query=cur_obj_feat, key=previous_obj_feats_track, value=previous_obj_feats_track, identity=cur_obj_feat))\n            previous_obj_feats_track = previous_obj_feats_track.permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm_track(self.link_ffn_track(previous_obj_feats_track))\n        elif self.previous_type == 'update_obj':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            previous_obj_feats_track = self.attention_previous_update_track(obj_feat.squeeze(2), previous_obj_feats)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = self.attention_previous_norm_track(self.attention_previous_track(query=cur_obj_feat, key=previous_obj_feats_track, value=previous_obj_feats_track, identity=cur_obj_feat))\n            previous_obj_feats_track = previous_obj_feats_track.permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm_track(self.link_ffn_track(previous_obj_feats_track))\n        else:\n            previous_obj_feat_track = None\n    cls_feat = obj_feat.sum(-2)\n    mask_feat = obj_feat\n    for cls_layer in self.cls_fcs:\n        cls_feat = cls_layer(cls_feat)\n    for reg_layer in self.mask_fcs:\n        mask_feat = reg_layer(mask_feat)\n    cls_score = self.fc_cls(cls_feat).view(N, num_proposals, -1)\n    mask_feat = self.fc_mask(mask_feat).permute(0, 1, 3, 2)\n    if self.mask_transform_stride == 2 and self.feat_gather_stride == 1:\n        mask_x = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n        (H, W) = mask_x.shape[-2:]\n    else:\n        mask_x = x\n    mask_feat = mask_feat.reshape(N, num_proposals, C, self.conv_kernel_size, self.conv_kernel_size)\n    new_mask_preds = []\n    for i in range(N):\n        new_mask_preds.append(F.conv2d(mask_x[i:i + 1], mask_feat[i], padding=int(self.conv_kernel_size // 2)))\n    new_mask_preds = torch.cat(new_mask_preds, dim=0)\n    new_mask_preds = new_mask_preds.reshape(N, num_proposals, H, W)\n    if self.mask_transform_stride == 2:\n        new_mask_preds = F.interpolate(new_mask_preds, scale_factor=2, mode='bilinear', align_corners=False)\n    if mask_shape is not None and mask_shape[0] != H:\n        new_mask_preds = F.interpolate(new_mask_preds, mask_shape, align_corners=False, mode='bilinear')\n    if previous_obj_feats is not None and previous_obj_feat_track is not None:\n        obj_feat = obj_feat.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size)\n        previous_obj_feat_track = previous_obj_feat_track.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size)\n        return (cls_score, new_mask_preds, obj_feat, x_feat, previous_obj_feat_track)\n    else:\n        return (cls_score, new_mask_preds, obj_feat.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size), x_feat, None)",
            "def forward(self, x, proposal_feat, mask_preds, prev_cls_score=None, mask_shape=None, img_metas=None, previous_obj_feats=None, previous_mask_preds=None, previous_x_feats=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (N, num_proposals) = proposal_feat.shape[:2]\n    if self.feat_transform is not None:\n        x = self.feat_transform(x)\n        if previous_x_feats is not None:\n            previous_x_feats = self.feat_transform(previous_x_feats)\n    (C, H, W) = x.shape[-3:]\n    (mask_h, mask_w) = mask_preds.shape[-2:]\n    if mask_h != H or mask_w != W:\n        gather_mask = F.interpolate(mask_preds, (H, W), align_corners=False, mode='bilinear')\n    else:\n        gather_mask = mask_preds\n    sigmoid_masks = gather_mask.sigmoid()\n    nonzero_inds = sigmoid_masks > self.hard_mask_thr\n    sigmoid_masks = nonzero_inds.float()\n    x_feat = torch.einsum('bnhw,bchw->bnc', sigmoid_masks, x)\n    proposal_feat = proposal_feat.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n    if self.training and self.previous_detach:\n        previous_obj_feats = previous_obj_feats.detach()\n    if previous_obj_feats is not None and self.previous_link == 'update_dynamic_cov':\n        previous_obj_feats_link = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n        if self.training and self.previous_detach_link:\n            previous_obj_feats_link = previous_obj_feats_link.detach()\n        previous_obj_feats_update = self.attention_previous_update_link(x_feat, previous_obj_feats_link)\n        previous_obj_feats_update = previous_obj_feats_update.reshape(N, num_proposals, -1).permute(1, 0, 2)\n        cur_obj_feat = proposal_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n        cur_obj_feat = self.attention_previous_norm_link(self.attention_previous_link(query=cur_obj_feat, key=previous_obj_feats_update, value=previous_obj_feats_update, identity=cur_obj_feat))\n        cur_obj_feat = cur_obj_feat.permute(1, 0, 2)\n        cur_obj_feat = cur_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n        proposal_feat = self.link_ffn_norm_link(self.link_ffn_link(cur_obj_feat))\n    if previous_obj_feats is not None and self.previous_link == 'link_atten':\n        previous_obj_feats_link = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n        previous_obj_feats_update = previous_obj_feats_link.reshape(N, num_proposals, -1).permute(1, 0, 2)\n        cur_obj_feat = proposal_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n        cur_obj_feat = self.attention_previous_norm_link(self.attention_previous_link(query=cur_obj_feat, key=previous_obj_feats_update, value=previous_obj_feats_update, identity=cur_obj_feat))\n        cur_obj_feat = cur_obj_feat.permute(1, 0, 2)\n        cur_obj_feat = cur_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n        proposal_feat = self.link_ffn_norm_link(self.link_ffn_link(cur_obj_feat))\n    obj_feat = self.kernel_update_conv(x_feat, proposal_feat)\n    obj_feat = obj_feat.reshape(N, num_proposals, -1).permute(1, 0, 2)\n    obj_feat = self.attention_norm(self.attention(obj_feat))\n    obj_feat = obj_feat.permute(1, 0, 2)\n    obj_feat = obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n    if self.with_ffn:\n        obj_feat = self.ffn_norm(self.ffn(obj_feat))\n    if previous_obj_feats is not None:\n        if self.previous_type == 'ffn':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feat = self.attention_previous_norm(self.attention_previous(query=cur_obj_feat, key=previous_obj_feats, value=previous_obj_feats, identity=cur_obj_feat))\n            previous_obj_feat = previous_obj_feat.permute(1, 0, 2)\n            previous_obj_feat_track = previous_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm(self.link_ffn(previous_obj_feat_track))\n        elif self.previous_type == 'update':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            previous_obj_feats_track = self.attention_previous_update_track(x_feat, previous_obj_feats)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = self.attention_previous_norm_track(self.attention_previous_track(query=cur_obj_feat, key=previous_obj_feats_track, value=previous_obj_feats_track, identity=cur_obj_feat))\n            previous_obj_feats_track = previous_obj_feats_track.permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm_track(self.link_ffn_track(previous_obj_feats_track))\n        elif self.previous_type == 'update_obj':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            previous_obj_feats_track = self.attention_previous_update_track(obj_feat.squeeze(2), previous_obj_feats)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = self.attention_previous_norm_track(self.attention_previous_track(query=cur_obj_feat, key=previous_obj_feats_track, value=previous_obj_feats_track, identity=cur_obj_feat))\n            previous_obj_feats_track = previous_obj_feats_track.permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm_track(self.link_ffn_track(previous_obj_feats_track))\n        else:\n            previous_obj_feat_track = None\n    cls_feat = obj_feat.sum(-2)\n    mask_feat = obj_feat\n    for cls_layer in self.cls_fcs:\n        cls_feat = cls_layer(cls_feat)\n    for reg_layer in self.mask_fcs:\n        mask_feat = reg_layer(mask_feat)\n    cls_score = self.fc_cls(cls_feat).view(N, num_proposals, -1)\n    mask_feat = self.fc_mask(mask_feat).permute(0, 1, 3, 2)\n    if self.mask_transform_stride == 2 and self.feat_gather_stride == 1:\n        mask_x = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n        (H, W) = mask_x.shape[-2:]\n    else:\n        mask_x = x\n    mask_feat = mask_feat.reshape(N, num_proposals, C, self.conv_kernel_size, self.conv_kernel_size)\n    new_mask_preds = []\n    for i in range(N):\n        new_mask_preds.append(F.conv2d(mask_x[i:i + 1], mask_feat[i], padding=int(self.conv_kernel_size // 2)))\n    new_mask_preds = torch.cat(new_mask_preds, dim=0)\n    new_mask_preds = new_mask_preds.reshape(N, num_proposals, H, W)\n    if self.mask_transform_stride == 2:\n        new_mask_preds = F.interpolate(new_mask_preds, scale_factor=2, mode='bilinear', align_corners=False)\n    if mask_shape is not None and mask_shape[0] != H:\n        new_mask_preds = F.interpolate(new_mask_preds, mask_shape, align_corners=False, mode='bilinear')\n    if previous_obj_feats is not None and previous_obj_feat_track is not None:\n        obj_feat = obj_feat.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size)\n        previous_obj_feat_track = previous_obj_feat_track.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size)\n        return (cls_score, new_mask_preds, obj_feat, x_feat, previous_obj_feat_track)\n    else:\n        return (cls_score, new_mask_preds, obj_feat.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size), x_feat, None)",
            "def forward(self, x, proposal_feat, mask_preds, prev_cls_score=None, mask_shape=None, img_metas=None, previous_obj_feats=None, previous_mask_preds=None, previous_x_feats=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (N, num_proposals) = proposal_feat.shape[:2]\n    if self.feat_transform is not None:\n        x = self.feat_transform(x)\n        if previous_x_feats is not None:\n            previous_x_feats = self.feat_transform(previous_x_feats)\n    (C, H, W) = x.shape[-3:]\n    (mask_h, mask_w) = mask_preds.shape[-2:]\n    if mask_h != H or mask_w != W:\n        gather_mask = F.interpolate(mask_preds, (H, W), align_corners=False, mode='bilinear')\n    else:\n        gather_mask = mask_preds\n    sigmoid_masks = gather_mask.sigmoid()\n    nonzero_inds = sigmoid_masks > self.hard_mask_thr\n    sigmoid_masks = nonzero_inds.float()\n    x_feat = torch.einsum('bnhw,bchw->bnc', sigmoid_masks, x)\n    proposal_feat = proposal_feat.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n    if self.training and self.previous_detach:\n        previous_obj_feats = previous_obj_feats.detach()\n    if previous_obj_feats is not None and self.previous_link == 'update_dynamic_cov':\n        previous_obj_feats_link = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n        if self.training and self.previous_detach_link:\n            previous_obj_feats_link = previous_obj_feats_link.detach()\n        previous_obj_feats_update = self.attention_previous_update_link(x_feat, previous_obj_feats_link)\n        previous_obj_feats_update = previous_obj_feats_update.reshape(N, num_proposals, -1).permute(1, 0, 2)\n        cur_obj_feat = proposal_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n        cur_obj_feat = self.attention_previous_norm_link(self.attention_previous_link(query=cur_obj_feat, key=previous_obj_feats_update, value=previous_obj_feats_update, identity=cur_obj_feat))\n        cur_obj_feat = cur_obj_feat.permute(1, 0, 2)\n        cur_obj_feat = cur_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n        proposal_feat = self.link_ffn_norm_link(self.link_ffn_link(cur_obj_feat))\n    if previous_obj_feats is not None and self.previous_link == 'link_atten':\n        previous_obj_feats_link = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n        previous_obj_feats_update = previous_obj_feats_link.reshape(N, num_proposals, -1).permute(1, 0, 2)\n        cur_obj_feat = proposal_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n        cur_obj_feat = self.attention_previous_norm_link(self.attention_previous_link(query=cur_obj_feat, key=previous_obj_feats_update, value=previous_obj_feats_update, identity=cur_obj_feat))\n        cur_obj_feat = cur_obj_feat.permute(1, 0, 2)\n        cur_obj_feat = cur_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n        proposal_feat = self.link_ffn_norm_link(self.link_ffn_link(cur_obj_feat))\n    obj_feat = self.kernel_update_conv(x_feat, proposal_feat)\n    obj_feat = obj_feat.reshape(N, num_proposals, -1).permute(1, 0, 2)\n    obj_feat = self.attention_norm(self.attention(obj_feat))\n    obj_feat = obj_feat.permute(1, 0, 2)\n    obj_feat = obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n    if self.with_ffn:\n        obj_feat = self.ffn_norm(self.ffn(obj_feat))\n    if previous_obj_feats is not None:\n        if self.previous_type == 'ffn':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feat = self.attention_previous_norm(self.attention_previous(query=cur_obj_feat, key=previous_obj_feats, value=previous_obj_feats, identity=cur_obj_feat))\n            previous_obj_feat = previous_obj_feat.permute(1, 0, 2)\n            previous_obj_feat_track = previous_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm(self.link_ffn(previous_obj_feat_track))\n        elif self.previous_type == 'update':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            previous_obj_feats_track = self.attention_previous_update_track(x_feat, previous_obj_feats)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = self.attention_previous_norm_track(self.attention_previous_track(query=cur_obj_feat, key=previous_obj_feats_track, value=previous_obj_feats_track, identity=cur_obj_feat))\n            previous_obj_feats_track = previous_obj_feats_track.permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm_track(self.link_ffn_track(previous_obj_feats_track))\n        elif self.previous_type == 'update_obj':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            previous_obj_feats_track = self.attention_previous_update_track(obj_feat.squeeze(2), previous_obj_feats)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = self.attention_previous_norm_track(self.attention_previous_track(query=cur_obj_feat, key=previous_obj_feats_track, value=previous_obj_feats_track, identity=cur_obj_feat))\n            previous_obj_feats_track = previous_obj_feats_track.permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm_track(self.link_ffn_track(previous_obj_feats_track))\n        else:\n            previous_obj_feat_track = None\n    cls_feat = obj_feat.sum(-2)\n    mask_feat = obj_feat\n    for cls_layer in self.cls_fcs:\n        cls_feat = cls_layer(cls_feat)\n    for reg_layer in self.mask_fcs:\n        mask_feat = reg_layer(mask_feat)\n    cls_score = self.fc_cls(cls_feat).view(N, num_proposals, -1)\n    mask_feat = self.fc_mask(mask_feat).permute(0, 1, 3, 2)\n    if self.mask_transform_stride == 2 and self.feat_gather_stride == 1:\n        mask_x = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n        (H, W) = mask_x.shape[-2:]\n    else:\n        mask_x = x\n    mask_feat = mask_feat.reshape(N, num_proposals, C, self.conv_kernel_size, self.conv_kernel_size)\n    new_mask_preds = []\n    for i in range(N):\n        new_mask_preds.append(F.conv2d(mask_x[i:i + 1], mask_feat[i], padding=int(self.conv_kernel_size // 2)))\n    new_mask_preds = torch.cat(new_mask_preds, dim=0)\n    new_mask_preds = new_mask_preds.reshape(N, num_proposals, H, W)\n    if self.mask_transform_stride == 2:\n        new_mask_preds = F.interpolate(new_mask_preds, scale_factor=2, mode='bilinear', align_corners=False)\n    if mask_shape is not None and mask_shape[0] != H:\n        new_mask_preds = F.interpolate(new_mask_preds, mask_shape, align_corners=False, mode='bilinear')\n    if previous_obj_feats is not None and previous_obj_feat_track is not None:\n        obj_feat = obj_feat.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size)\n        previous_obj_feat_track = previous_obj_feat_track.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size)\n        return (cls_score, new_mask_preds, obj_feat, x_feat, previous_obj_feat_track)\n    else:\n        return (cls_score, new_mask_preds, obj_feat.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size), x_feat, None)",
            "def forward(self, x, proposal_feat, mask_preds, prev_cls_score=None, mask_shape=None, img_metas=None, previous_obj_feats=None, previous_mask_preds=None, previous_x_feats=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (N, num_proposals) = proposal_feat.shape[:2]\n    if self.feat_transform is not None:\n        x = self.feat_transform(x)\n        if previous_x_feats is not None:\n            previous_x_feats = self.feat_transform(previous_x_feats)\n    (C, H, W) = x.shape[-3:]\n    (mask_h, mask_w) = mask_preds.shape[-2:]\n    if mask_h != H or mask_w != W:\n        gather_mask = F.interpolate(mask_preds, (H, W), align_corners=False, mode='bilinear')\n    else:\n        gather_mask = mask_preds\n    sigmoid_masks = gather_mask.sigmoid()\n    nonzero_inds = sigmoid_masks > self.hard_mask_thr\n    sigmoid_masks = nonzero_inds.float()\n    x_feat = torch.einsum('bnhw,bchw->bnc', sigmoid_masks, x)\n    proposal_feat = proposal_feat.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n    if self.training and self.previous_detach:\n        previous_obj_feats = previous_obj_feats.detach()\n    if previous_obj_feats is not None and self.previous_link == 'update_dynamic_cov':\n        previous_obj_feats_link = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n        if self.training and self.previous_detach_link:\n            previous_obj_feats_link = previous_obj_feats_link.detach()\n        previous_obj_feats_update = self.attention_previous_update_link(x_feat, previous_obj_feats_link)\n        previous_obj_feats_update = previous_obj_feats_update.reshape(N, num_proposals, -1).permute(1, 0, 2)\n        cur_obj_feat = proposal_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n        cur_obj_feat = self.attention_previous_norm_link(self.attention_previous_link(query=cur_obj_feat, key=previous_obj_feats_update, value=previous_obj_feats_update, identity=cur_obj_feat))\n        cur_obj_feat = cur_obj_feat.permute(1, 0, 2)\n        cur_obj_feat = cur_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n        proposal_feat = self.link_ffn_norm_link(self.link_ffn_link(cur_obj_feat))\n    if previous_obj_feats is not None and self.previous_link == 'link_atten':\n        previous_obj_feats_link = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n        previous_obj_feats_update = previous_obj_feats_link.reshape(N, num_proposals, -1).permute(1, 0, 2)\n        cur_obj_feat = proposal_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n        cur_obj_feat = self.attention_previous_norm_link(self.attention_previous_link(query=cur_obj_feat, key=previous_obj_feats_update, value=previous_obj_feats_update, identity=cur_obj_feat))\n        cur_obj_feat = cur_obj_feat.permute(1, 0, 2)\n        cur_obj_feat = cur_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n        proposal_feat = self.link_ffn_norm_link(self.link_ffn_link(cur_obj_feat))\n    obj_feat = self.kernel_update_conv(x_feat, proposal_feat)\n    obj_feat = obj_feat.reshape(N, num_proposals, -1).permute(1, 0, 2)\n    obj_feat = self.attention_norm(self.attention(obj_feat))\n    obj_feat = obj_feat.permute(1, 0, 2)\n    obj_feat = obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n    if self.with_ffn:\n        obj_feat = self.ffn_norm(self.ffn(obj_feat))\n    if previous_obj_feats is not None:\n        if self.previous_type == 'ffn':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feat = self.attention_previous_norm(self.attention_previous(query=cur_obj_feat, key=previous_obj_feats, value=previous_obj_feats, identity=cur_obj_feat))\n            previous_obj_feat = previous_obj_feat.permute(1, 0, 2)\n            previous_obj_feat_track = previous_obj_feat.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm(self.link_ffn(previous_obj_feat_track))\n        elif self.previous_type == 'update':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            previous_obj_feats_track = self.attention_previous_update_track(x_feat, previous_obj_feats)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = self.attention_previous_norm_track(self.attention_previous_track(query=cur_obj_feat, key=previous_obj_feats_track, value=previous_obj_feats_track, identity=cur_obj_feat))\n            previous_obj_feats_track = previous_obj_feats_track.permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm_track(self.link_ffn_track(previous_obj_feats_track))\n        elif self.previous_type == 'update_obj':\n            previous_obj_feats = previous_obj_feats.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            previous_obj_feats_track = self.attention_previous_update_track(obj_feat.squeeze(2), previous_obj_feats)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels, -1).permute(0, 1, 3, 2)\n            cur_obj_feat = obj_feat.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, self.in_channels * self.conv_kernel_size ** 2).permute(1, 0, 2)\n            previous_obj_feats_track = self.attention_previous_norm_track(self.attention_previous_track(query=cur_obj_feat, key=previous_obj_feats_track, value=previous_obj_feats_track, identity=cur_obj_feat))\n            previous_obj_feats_track = previous_obj_feats_track.permute(1, 0, 2)\n            previous_obj_feats_track = previous_obj_feats_track.reshape(N, num_proposals, -1, self.in_channels)\n            previous_obj_feat_track = self.link_ffn_norm_track(self.link_ffn_track(previous_obj_feats_track))\n        else:\n            previous_obj_feat_track = None\n    cls_feat = obj_feat.sum(-2)\n    mask_feat = obj_feat\n    for cls_layer in self.cls_fcs:\n        cls_feat = cls_layer(cls_feat)\n    for reg_layer in self.mask_fcs:\n        mask_feat = reg_layer(mask_feat)\n    cls_score = self.fc_cls(cls_feat).view(N, num_proposals, -1)\n    mask_feat = self.fc_mask(mask_feat).permute(0, 1, 3, 2)\n    if self.mask_transform_stride == 2 and self.feat_gather_stride == 1:\n        mask_x = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n        (H, W) = mask_x.shape[-2:]\n    else:\n        mask_x = x\n    mask_feat = mask_feat.reshape(N, num_proposals, C, self.conv_kernel_size, self.conv_kernel_size)\n    new_mask_preds = []\n    for i in range(N):\n        new_mask_preds.append(F.conv2d(mask_x[i:i + 1], mask_feat[i], padding=int(self.conv_kernel_size // 2)))\n    new_mask_preds = torch.cat(new_mask_preds, dim=0)\n    new_mask_preds = new_mask_preds.reshape(N, num_proposals, H, W)\n    if self.mask_transform_stride == 2:\n        new_mask_preds = F.interpolate(new_mask_preds, scale_factor=2, mode='bilinear', align_corners=False)\n    if mask_shape is not None and mask_shape[0] != H:\n        new_mask_preds = F.interpolate(new_mask_preds, mask_shape, align_corners=False, mode='bilinear')\n    if previous_obj_feats is not None and previous_obj_feat_track is not None:\n        obj_feat = obj_feat.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size)\n        previous_obj_feat_track = previous_obj_feat_track.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size)\n        return (cls_score, new_mask_preds, obj_feat, x_feat, previous_obj_feat_track)\n    else:\n        return (cls_score, new_mask_preds, obj_feat.permute(0, 1, 3, 2).reshape(N, num_proposals, self.in_channels, self.conv_kernel_size, self.conv_kernel_size), x_feat, None)"
        ]
    },
    {
        "func_name": "_get_target_single",
        "original": "def _get_target_single(self, pos_inds, neg_inds, pos_mask, neg_mask, pos_gt_mask, pos_gt_labels, gt_sem_seg, gt_sem_cls, cfg):\n    num_pos = pos_mask.size(0)\n    num_neg = neg_mask.size(0)\n    num_samples = num_pos + num_neg\n    (H, W) = pos_mask.shape[-2:]\n    labels = pos_mask.new_full((num_samples,), self.num_classes, dtype=torch.long)\n    label_weights = pos_mask.new_zeros((num_samples, self.num_classes))\n    mask_targets = pos_mask.new_zeros(num_samples, H, W)\n    mask_weights = pos_mask.new_zeros(num_samples, H, W)\n    if num_pos > 0:\n        labels[pos_inds] = pos_gt_labels\n        pos_weight = 1.0 if cfg.pos_weight <= 0 else cfg.pos_weight\n        label_weights[pos_inds] = pos_weight\n        pos_mask_targets = pos_gt_mask\n        mask_targets[pos_inds, ...] = pos_mask_targets\n        mask_weights[pos_inds, ...] = 1\n    if num_neg > 0:\n        label_weights[neg_inds] = 1.0\n    if gt_sem_cls is not None and gt_sem_seg is not None:\n        sem_labels = pos_mask.new_full((self.num_stuff_classes,), self.num_classes, dtype=torch.long)\n        sem_targets = pos_mask.new_zeros(self.num_stuff_classes, H, W)\n        sem_weights = pos_mask.new_zeros(self.num_stuff_classes, H, W)\n        sem_stuff_weights = torch.eye(self.num_stuff_classes, device=pos_mask.device)\n        sem_thing_weights = pos_mask.new_zeros((self.num_stuff_classes, self.num_thing_classes))\n        sem_label_weights = torch.cat([sem_thing_weights, sem_stuff_weights], dim=-1)\n        if len(gt_sem_cls > 0):\n            sem_inds = gt_sem_cls - self.num_thing_classes\n            sem_inds = sem_inds.long()\n            sem_labels[sem_inds] = gt_sem_cls.long()\n            sem_targets[sem_inds] = gt_sem_seg\n            sem_weights[sem_inds] = 1\n        label_weights[:, self.num_thing_classes:] = 0\n        labels = torch.cat([labels, sem_labels])\n        label_weights = torch.cat([label_weights, sem_label_weights])\n        mask_targets = torch.cat([mask_targets, sem_targets])\n        mask_weights = torch.cat([mask_weights, sem_weights])\n    return (labels, label_weights, mask_targets, mask_weights)",
        "mutated": [
            "def _get_target_single(self, pos_inds, neg_inds, pos_mask, neg_mask, pos_gt_mask, pos_gt_labels, gt_sem_seg, gt_sem_cls, cfg):\n    if False:\n        i = 10\n    num_pos = pos_mask.size(0)\n    num_neg = neg_mask.size(0)\n    num_samples = num_pos + num_neg\n    (H, W) = pos_mask.shape[-2:]\n    labels = pos_mask.new_full((num_samples,), self.num_classes, dtype=torch.long)\n    label_weights = pos_mask.new_zeros((num_samples, self.num_classes))\n    mask_targets = pos_mask.new_zeros(num_samples, H, W)\n    mask_weights = pos_mask.new_zeros(num_samples, H, W)\n    if num_pos > 0:\n        labels[pos_inds] = pos_gt_labels\n        pos_weight = 1.0 if cfg.pos_weight <= 0 else cfg.pos_weight\n        label_weights[pos_inds] = pos_weight\n        pos_mask_targets = pos_gt_mask\n        mask_targets[pos_inds, ...] = pos_mask_targets\n        mask_weights[pos_inds, ...] = 1\n    if num_neg > 0:\n        label_weights[neg_inds] = 1.0\n    if gt_sem_cls is not None and gt_sem_seg is not None:\n        sem_labels = pos_mask.new_full((self.num_stuff_classes,), self.num_classes, dtype=torch.long)\n        sem_targets = pos_mask.new_zeros(self.num_stuff_classes, H, W)\n        sem_weights = pos_mask.new_zeros(self.num_stuff_classes, H, W)\n        sem_stuff_weights = torch.eye(self.num_stuff_classes, device=pos_mask.device)\n        sem_thing_weights = pos_mask.new_zeros((self.num_stuff_classes, self.num_thing_classes))\n        sem_label_weights = torch.cat([sem_thing_weights, sem_stuff_weights], dim=-1)\n        if len(gt_sem_cls > 0):\n            sem_inds = gt_sem_cls - self.num_thing_classes\n            sem_inds = sem_inds.long()\n            sem_labels[sem_inds] = gt_sem_cls.long()\n            sem_targets[sem_inds] = gt_sem_seg\n            sem_weights[sem_inds] = 1\n        label_weights[:, self.num_thing_classes:] = 0\n        labels = torch.cat([labels, sem_labels])\n        label_weights = torch.cat([label_weights, sem_label_weights])\n        mask_targets = torch.cat([mask_targets, sem_targets])\n        mask_weights = torch.cat([mask_weights, sem_weights])\n    return (labels, label_weights, mask_targets, mask_weights)",
            "def _get_target_single(self, pos_inds, neg_inds, pos_mask, neg_mask, pos_gt_mask, pos_gt_labels, gt_sem_seg, gt_sem_cls, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    num_pos = pos_mask.size(0)\n    num_neg = neg_mask.size(0)\n    num_samples = num_pos + num_neg\n    (H, W) = pos_mask.shape[-2:]\n    labels = pos_mask.new_full((num_samples,), self.num_classes, dtype=torch.long)\n    label_weights = pos_mask.new_zeros((num_samples, self.num_classes))\n    mask_targets = pos_mask.new_zeros(num_samples, H, W)\n    mask_weights = pos_mask.new_zeros(num_samples, H, W)\n    if num_pos > 0:\n        labels[pos_inds] = pos_gt_labels\n        pos_weight = 1.0 if cfg.pos_weight <= 0 else cfg.pos_weight\n        label_weights[pos_inds] = pos_weight\n        pos_mask_targets = pos_gt_mask\n        mask_targets[pos_inds, ...] = pos_mask_targets\n        mask_weights[pos_inds, ...] = 1\n    if num_neg > 0:\n        label_weights[neg_inds] = 1.0\n    if gt_sem_cls is not None and gt_sem_seg is not None:\n        sem_labels = pos_mask.new_full((self.num_stuff_classes,), self.num_classes, dtype=torch.long)\n        sem_targets = pos_mask.new_zeros(self.num_stuff_classes, H, W)\n        sem_weights = pos_mask.new_zeros(self.num_stuff_classes, H, W)\n        sem_stuff_weights = torch.eye(self.num_stuff_classes, device=pos_mask.device)\n        sem_thing_weights = pos_mask.new_zeros((self.num_stuff_classes, self.num_thing_classes))\n        sem_label_weights = torch.cat([sem_thing_weights, sem_stuff_weights], dim=-1)\n        if len(gt_sem_cls > 0):\n            sem_inds = gt_sem_cls - self.num_thing_classes\n            sem_inds = sem_inds.long()\n            sem_labels[sem_inds] = gt_sem_cls.long()\n            sem_targets[sem_inds] = gt_sem_seg\n            sem_weights[sem_inds] = 1\n        label_weights[:, self.num_thing_classes:] = 0\n        labels = torch.cat([labels, sem_labels])\n        label_weights = torch.cat([label_weights, sem_label_weights])\n        mask_targets = torch.cat([mask_targets, sem_targets])\n        mask_weights = torch.cat([mask_weights, sem_weights])\n    return (labels, label_weights, mask_targets, mask_weights)",
            "def _get_target_single(self, pos_inds, neg_inds, pos_mask, neg_mask, pos_gt_mask, pos_gt_labels, gt_sem_seg, gt_sem_cls, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    num_pos = pos_mask.size(0)\n    num_neg = neg_mask.size(0)\n    num_samples = num_pos + num_neg\n    (H, W) = pos_mask.shape[-2:]\n    labels = pos_mask.new_full((num_samples,), self.num_classes, dtype=torch.long)\n    label_weights = pos_mask.new_zeros((num_samples, self.num_classes))\n    mask_targets = pos_mask.new_zeros(num_samples, H, W)\n    mask_weights = pos_mask.new_zeros(num_samples, H, W)\n    if num_pos > 0:\n        labels[pos_inds] = pos_gt_labels\n        pos_weight = 1.0 if cfg.pos_weight <= 0 else cfg.pos_weight\n        label_weights[pos_inds] = pos_weight\n        pos_mask_targets = pos_gt_mask\n        mask_targets[pos_inds, ...] = pos_mask_targets\n        mask_weights[pos_inds, ...] = 1\n    if num_neg > 0:\n        label_weights[neg_inds] = 1.0\n    if gt_sem_cls is not None and gt_sem_seg is not None:\n        sem_labels = pos_mask.new_full((self.num_stuff_classes,), self.num_classes, dtype=torch.long)\n        sem_targets = pos_mask.new_zeros(self.num_stuff_classes, H, W)\n        sem_weights = pos_mask.new_zeros(self.num_stuff_classes, H, W)\n        sem_stuff_weights = torch.eye(self.num_stuff_classes, device=pos_mask.device)\n        sem_thing_weights = pos_mask.new_zeros((self.num_stuff_classes, self.num_thing_classes))\n        sem_label_weights = torch.cat([sem_thing_weights, sem_stuff_weights], dim=-1)\n        if len(gt_sem_cls > 0):\n            sem_inds = gt_sem_cls - self.num_thing_classes\n            sem_inds = sem_inds.long()\n            sem_labels[sem_inds] = gt_sem_cls.long()\n            sem_targets[sem_inds] = gt_sem_seg\n            sem_weights[sem_inds] = 1\n        label_weights[:, self.num_thing_classes:] = 0\n        labels = torch.cat([labels, sem_labels])\n        label_weights = torch.cat([label_weights, sem_label_weights])\n        mask_targets = torch.cat([mask_targets, sem_targets])\n        mask_weights = torch.cat([mask_weights, sem_weights])\n    return (labels, label_weights, mask_targets, mask_weights)",
            "def _get_target_single(self, pos_inds, neg_inds, pos_mask, neg_mask, pos_gt_mask, pos_gt_labels, gt_sem_seg, gt_sem_cls, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    num_pos = pos_mask.size(0)\n    num_neg = neg_mask.size(0)\n    num_samples = num_pos + num_neg\n    (H, W) = pos_mask.shape[-2:]\n    labels = pos_mask.new_full((num_samples,), self.num_classes, dtype=torch.long)\n    label_weights = pos_mask.new_zeros((num_samples, self.num_classes))\n    mask_targets = pos_mask.new_zeros(num_samples, H, W)\n    mask_weights = pos_mask.new_zeros(num_samples, H, W)\n    if num_pos > 0:\n        labels[pos_inds] = pos_gt_labels\n        pos_weight = 1.0 if cfg.pos_weight <= 0 else cfg.pos_weight\n        label_weights[pos_inds] = pos_weight\n        pos_mask_targets = pos_gt_mask\n        mask_targets[pos_inds, ...] = pos_mask_targets\n        mask_weights[pos_inds, ...] = 1\n    if num_neg > 0:\n        label_weights[neg_inds] = 1.0\n    if gt_sem_cls is not None and gt_sem_seg is not None:\n        sem_labels = pos_mask.new_full((self.num_stuff_classes,), self.num_classes, dtype=torch.long)\n        sem_targets = pos_mask.new_zeros(self.num_stuff_classes, H, W)\n        sem_weights = pos_mask.new_zeros(self.num_stuff_classes, H, W)\n        sem_stuff_weights = torch.eye(self.num_stuff_classes, device=pos_mask.device)\n        sem_thing_weights = pos_mask.new_zeros((self.num_stuff_classes, self.num_thing_classes))\n        sem_label_weights = torch.cat([sem_thing_weights, sem_stuff_weights], dim=-1)\n        if len(gt_sem_cls > 0):\n            sem_inds = gt_sem_cls - self.num_thing_classes\n            sem_inds = sem_inds.long()\n            sem_labels[sem_inds] = gt_sem_cls.long()\n            sem_targets[sem_inds] = gt_sem_seg\n            sem_weights[sem_inds] = 1\n        label_weights[:, self.num_thing_classes:] = 0\n        labels = torch.cat([labels, sem_labels])\n        label_weights = torch.cat([label_weights, sem_label_weights])\n        mask_targets = torch.cat([mask_targets, sem_targets])\n        mask_weights = torch.cat([mask_weights, sem_weights])\n    return (labels, label_weights, mask_targets, mask_weights)",
            "def _get_target_single(self, pos_inds, neg_inds, pos_mask, neg_mask, pos_gt_mask, pos_gt_labels, gt_sem_seg, gt_sem_cls, cfg):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    num_pos = pos_mask.size(0)\n    num_neg = neg_mask.size(0)\n    num_samples = num_pos + num_neg\n    (H, W) = pos_mask.shape[-2:]\n    labels = pos_mask.new_full((num_samples,), self.num_classes, dtype=torch.long)\n    label_weights = pos_mask.new_zeros((num_samples, self.num_classes))\n    mask_targets = pos_mask.new_zeros(num_samples, H, W)\n    mask_weights = pos_mask.new_zeros(num_samples, H, W)\n    if num_pos > 0:\n        labels[pos_inds] = pos_gt_labels\n        pos_weight = 1.0 if cfg.pos_weight <= 0 else cfg.pos_weight\n        label_weights[pos_inds] = pos_weight\n        pos_mask_targets = pos_gt_mask\n        mask_targets[pos_inds, ...] = pos_mask_targets\n        mask_weights[pos_inds, ...] = 1\n    if num_neg > 0:\n        label_weights[neg_inds] = 1.0\n    if gt_sem_cls is not None and gt_sem_seg is not None:\n        sem_labels = pos_mask.new_full((self.num_stuff_classes,), self.num_classes, dtype=torch.long)\n        sem_targets = pos_mask.new_zeros(self.num_stuff_classes, H, W)\n        sem_weights = pos_mask.new_zeros(self.num_stuff_classes, H, W)\n        sem_stuff_weights = torch.eye(self.num_stuff_classes, device=pos_mask.device)\n        sem_thing_weights = pos_mask.new_zeros((self.num_stuff_classes, self.num_thing_classes))\n        sem_label_weights = torch.cat([sem_thing_weights, sem_stuff_weights], dim=-1)\n        if len(gt_sem_cls > 0):\n            sem_inds = gt_sem_cls - self.num_thing_classes\n            sem_inds = sem_inds.long()\n            sem_labels[sem_inds] = gt_sem_cls.long()\n            sem_targets[sem_inds] = gt_sem_seg\n            sem_weights[sem_inds] = 1\n        label_weights[:, self.num_thing_classes:] = 0\n        labels = torch.cat([labels, sem_labels])\n        label_weights = torch.cat([label_weights, sem_label_weights])\n        mask_targets = torch.cat([mask_targets, sem_targets])\n        mask_weights = torch.cat([mask_weights, sem_weights])\n    return (labels, label_weights, mask_targets, mask_weights)"
        ]
    },
    {
        "func_name": "get_targets",
        "original": "def get_targets(self, sampling_results, gt_mask, gt_labels, rcnn_train_cfg, concat=True, gt_sem_seg=None, gt_sem_cls=None):\n    pos_inds_list = [res.pos_inds for res in sampling_results]\n    neg_inds_list = [res.neg_inds for res in sampling_results]\n    pos_mask_list = [res.pos_masks for res in sampling_results]\n    neg_mask_list = [res.neg_masks for res in sampling_results]\n    pos_gt_mask_list = [res.pos_gt_masks for res in sampling_results]\n    pos_gt_labels_list = [res.pos_gt_labels for res in sampling_results]\n    if gt_sem_seg is None:\n        gt_sem_seg = [None] * 2\n        gt_sem_cls = [None] * 2\n    (labels, label_weights, mask_targets, mask_weights) = multi_apply(self._get_target_single, pos_inds_list, neg_inds_list, pos_mask_list, neg_mask_list, pos_gt_mask_list, pos_gt_labels_list, gt_sem_seg, gt_sem_cls, cfg=rcnn_train_cfg)\n    if concat:\n        labels = torch.cat(labels, 0)\n        label_weights = torch.cat(label_weights, 0)\n        mask_targets = torch.cat(mask_targets, 0)\n        mask_weights = torch.cat(mask_weights, 0)\n    return (labels, label_weights, mask_targets, mask_weights)",
        "mutated": [
            "def get_targets(self, sampling_results, gt_mask, gt_labels, rcnn_train_cfg, concat=True, gt_sem_seg=None, gt_sem_cls=None):\n    if False:\n        i = 10\n    pos_inds_list = [res.pos_inds for res in sampling_results]\n    neg_inds_list = [res.neg_inds for res in sampling_results]\n    pos_mask_list = [res.pos_masks for res in sampling_results]\n    neg_mask_list = [res.neg_masks for res in sampling_results]\n    pos_gt_mask_list = [res.pos_gt_masks for res in sampling_results]\n    pos_gt_labels_list = [res.pos_gt_labels for res in sampling_results]\n    if gt_sem_seg is None:\n        gt_sem_seg = [None] * 2\n        gt_sem_cls = [None] * 2\n    (labels, label_weights, mask_targets, mask_weights) = multi_apply(self._get_target_single, pos_inds_list, neg_inds_list, pos_mask_list, neg_mask_list, pos_gt_mask_list, pos_gt_labels_list, gt_sem_seg, gt_sem_cls, cfg=rcnn_train_cfg)\n    if concat:\n        labels = torch.cat(labels, 0)\n        label_weights = torch.cat(label_weights, 0)\n        mask_targets = torch.cat(mask_targets, 0)\n        mask_weights = torch.cat(mask_weights, 0)\n    return (labels, label_weights, mask_targets, mask_weights)",
            "def get_targets(self, sampling_results, gt_mask, gt_labels, rcnn_train_cfg, concat=True, gt_sem_seg=None, gt_sem_cls=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    pos_inds_list = [res.pos_inds for res in sampling_results]\n    neg_inds_list = [res.neg_inds for res in sampling_results]\n    pos_mask_list = [res.pos_masks for res in sampling_results]\n    neg_mask_list = [res.neg_masks for res in sampling_results]\n    pos_gt_mask_list = [res.pos_gt_masks for res in sampling_results]\n    pos_gt_labels_list = [res.pos_gt_labels for res in sampling_results]\n    if gt_sem_seg is None:\n        gt_sem_seg = [None] * 2\n        gt_sem_cls = [None] * 2\n    (labels, label_weights, mask_targets, mask_weights) = multi_apply(self._get_target_single, pos_inds_list, neg_inds_list, pos_mask_list, neg_mask_list, pos_gt_mask_list, pos_gt_labels_list, gt_sem_seg, gt_sem_cls, cfg=rcnn_train_cfg)\n    if concat:\n        labels = torch.cat(labels, 0)\n        label_weights = torch.cat(label_weights, 0)\n        mask_targets = torch.cat(mask_targets, 0)\n        mask_weights = torch.cat(mask_weights, 0)\n    return (labels, label_weights, mask_targets, mask_weights)",
            "def get_targets(self, sampling_results, gt_mask, gt_labels, rcnn_train_cfg, concat=True, gt_sem_seg=None, gt_sem_cls=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    pos_inds_list = [res.pos_inds for res in sampling_results]\n    neg_inds_list = [res.neg_inds for res in sampling_results]\n    pos_mask_list = [res.pos_masks for res in sampling_results]\n    neg_mask_list = [res.neg_masks for res in sampling_results]\n    pos_gt_mask_list = [res.pos_gt_masks for res in sampling_results]\n    pos_gt_labels_list = [res.pos_gt_labels for res in sampling_results]\n    if gt_sem_seg is None:\n        gt_sem_seg = [None] * 2\n        gt_sem_cls = [None] * 2\n    (labels, label_weights, mask_targets, mask_weights) = multi_apply(self._get_target_single, pos_inds_list, neg_inds_list, pos_mask_list, neg_mask_list, pos_gt_mask_list, pos_gt_labels_list, gt_sem_seg, gt_sem_cls, cfg=rcnn_train_cfg)\n    if concat:\n        labels = torch.cat(labels, 0)\n        label_weights = torch.cat(label_weights, 0)\n        mask_targets = torch.cat(mask_targets, 0)\n        mask_weights = torch.cat(mask_weights, 0)\n    return (labels, label_weights, mask_targets, mask_weights)",
            "def get_targets(self, sampling_results, gt_mask, gt_labels, rcnn_train_cfg, concat=True, gt_sem_seg=None, gt_sem_cls=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    pos_inds_list = [res.pos_inds for res in sampling_results]\n    neg_inds_list = [res.neg_inds for res in sampling_results]\n    pos_mask_list = [res.pos_masks for res in sampling_results]\n    neg_mask_list = [res.neg_masks for res in sampling_results]\n    pos_gt_mask_list = [res.pos_gt_masks for res in sampling_results]\n    pos_gt_labels_list = [res.pos_gt_labels for res in sampling_results]\n    if gt_sem_seg is None:\n        gt_sem_seg = [None] * 2\n        gt_sem_cls = [None] * 2\n    (labels, label_weights, mask_targets, mask_weights) = multi_apply(self._get_target_single, pos_inds_list, neg_inds_list, pos_mask_list, neg_mask_list, pos_gt_mask_list, pos_gt_labels_list, gt_sem_seg, gt_sem_cls, cfg=rcnn_train_cfg)\n    if concat:\n        labels = torch.cat(labels, 0)\n        label_weights = torch.cat(label_weights, 0)\n        mask_targets = torch.cat(mask_targets, 0)\n        mask_weights = torch.cat(mask_weights, 0)\n    return (labels, label_weights, mask_targets, mask_weights)",
            "def get_targets(self, sampling_results, gt_mask, gt_labels, rcnn_train_cfg, concat=True, gt_sem_seg=None, gt_sem_cls=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    pos_inds_list = [res.pos_inds for res in sampling_results]\n    neg_inds_list = [res.neg_inds for res in sampling_results]\n    pos_mask_list = [res.pos_masks for res in sampling_results]\n    neg_mask_list = [res.neg_masks for res in sampling_results]\n    pos_gt_mask_list = [res.pos_gt_masks for res in sampling_results]\n    pos_gt_labels_list = [res.pos_gt_labels for res in sampling_results]\n    if gt_sem_seg is None:\n        gt_sem_seg = [None] * 2\n        gt_sem_cls = [None] * 2\n    (labels, label_weights, mask_targets, mask_weights) = multi_apply(self._get_target_single, pos_inds_list, neg_inds_list, pos_mask_list, neg_mask_list, pos_gt_mask_list, pos_gt_labels_list, gt_sem_seg, gt_sem_cls, cfg=rcnn_train_cfg)\n    if concat:\n        labels = torch.cat(labels, 0)\n        label_weights = torch.cat(label_weights, 0)\n        mask_targets = torch.cat(mask_targets, 0)\n        mask_weights = torch.cat(mask_weights, 0)\n    return (labels, label_weights, mask_targets, mask_weights)"
        ]
    },
    {
        "func_name": "rescale_masks",
        "original": "def rescale_masks(self, masks_per_img, img_meta):\n    (h, w, _) = img_meta['img_shape']\n    masks_per_img = F.interpolate(masks_per_img.unsqueeze(0).sigmoid(), size=img_meta['batch_input_shape'], mode='bilinear', align_corners=False)\n    masks_per_img = masks_per_img[:, :, :h, :w]\n    ori_shape = img_meta['ori_shape']\n    seg_masks = F.interpolate(masks_per_img, size=ori_shape[:2], mode='bilinear', align_corners=False).squeeze(0)\n    return seg_masks",
        "mutated": [
            "def rescale_masks(self, masks_per_img, img_meta):\n    if False:\n        i = 10\n    (h, w, _) = img_meta['img_shape']\n    masks_per_img = F.interpolate(masks_per_img.unsqueeze(0).sigmoid(), size=img_meta['batch_input_shape'], mode='bilinear', align_corners=False)\n    masks_per_img = masks_per_img[:, :, :h, :w]\n    ori_shape = img_meta['ori_shape']\n    seg_masks = F.interpolate(masks_per_img, size=ori_shape[:2], mode='bilinear', align_corners=False).squeeze(0)\n    return seg_masks",
            "def rescale_masks(self, masks_per_img, img_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    (h, w, _) = img_meta['img_shape']\n    masks_per_img = F.interpolate(masks_per_img.unsqueeze(0).sigmoid(), size=img_meta['batch_input_shape'], mode='bilinear', align_corners=False)\n    masks_per_img = masks_per_img[:, :, :h, :w]\n    ori_shape = img_meta['ori_shape']\n    seg_masks = F.interpolate(masks_per_img, size=ori_shape[:2], mode='bilinear', align_corners=False).squeeze(0)\n    return seg_masks",
            "def rescale_masks(self, masks_per_img, img_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    (h, w, _) = img_meta['img_shape']\n    masks_per_img = F.interpolate(masks_per_img.unsqueeze(0).sigmoid(), size=img_meta['batch_input_shape'], mode='bilinear', align_corners=False)\n    masks_per_img = masks_per_img[:, :, :h, :w]\n    ori_shape = img_meta['ori_shape']\n    seg_masks = F.interpolate(masks_per_img, size=ori_shape[:2], mode='bilinear', align_corners=False).squeeze(0)\n    return seg_masks",
            "def rescale_masks(self, masks_per_img, img_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    (h, w, _) = img_meta['img_shape']\n    masks_per_img = F.interpolate(masks_per_img.unsqueeze(0).sigmoid(), size=img_meta['batch_input_shape'], mode='bilinear', align_corners=False)\n    masks_per_img = masks_per_img[:, :, :h, :w]\n    ori_shape = img_meta['ori_shape']\n    seg_masks = F.interpolate(masks_per_img, size=ori_shape[:2], mode='bilinear', align_corners=False).squeeze(0)\n    return seg_masks",
            "def rescale_masks(self, masks_per_img, img_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    (h, w, _) = img_meta['img_shape']\n    masks_per_img = F.interpolate(masks_per_img.unsqueeze(0).sigmoid(), size=img_meta['batch_input_shape'], mode='bilinear', align_corners=False)\n    masks_per_img = masks_per_img[:, :, :h, :w]\n    ori_shape = img_meta['ori_shape']\n    seg_masks = F.interpolate(masks_per_img, size=ori_shape[:2], mode='bilinear', align_corners=False).squeeze(0)\n    return seg_masks"
        ]
    },
    {
        "func_name": "get_seg_masks",
        "original": "def get_seg_masks(self, masks_per_img, labels_per_img, scores_per_img, test_cfg, img_meta):\n    seg_masks = self.rescale_masks(masks_per_img, img_meta)\n    seg_masks = seg_masks > test_cfg.mask_thr\n    (bbox_result, segm_result, mask_preds) = self.segm2result(seg_masks, labels_per_img, scores_per_img)\n    return (bbox_result, segm_result, mask_preds)",
        "mutated": [
            "def get_seg_masks(self, masks_per_img, labels_per_img, scores_per_img, test_cfg, img_meta):\n    if False:\n        i = 10\n    seg_masks = self.rescale_masks(masks_per_img, img_meta)\n    seg_masks = seg_masks > test_cfg.mask_thr\n    (bbox_result, segm_result, mask_preds) = self.segm2result(seg_masks, labels_per_img, scores_per_img)\n    return (bbox_result, segm_result, mask_preds)",
            "def get_seg_masks(self, masks_per_img, labels_per_img, scores_per_img, test_cfg, img_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    seg_masks = self.rescale_masks(masks_per_img, img_meta)\n    seg_masks = seg_masks > test_cfg.mask_thr\n    (bbox_result, segm_result, mask_preds) = self.segm2result(seg_masks, labels_per_img, scores_per_img)\n    return (bbox_result, segm_result, mask_preds)",
            "def get_seg_masks(self, masks_per_img, labels_per_img, scores_per_img, test_cfg, img_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    seg_masks = self.rescale_masks(masks_per_img, img_meta)\n    seg_masks = seg_masks > test_cfg.mask_thr\n    (bbox_result, segm_result, mask_preds) = self.segm2result(seg_masks, labels_per_img, scores_per_img)\n    return (bbox_result, segm_result, mask_preds)",
            "def get_seg_masks(self, masks_per_img, labels_per_img, scores_per_img, test_cfg, img_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    seg_masks = self.rescale_masks(masks_per_img, img_meta)\n    seg_masks = seg_masks > test_cfg.mask_thr\n    (bbox_result, segm_result, mask_preds) = self.segm2result(seg_masks, labels_per_img, scores_per_img)\n    return (bbox_result, segm_result, mask_preds)",
            "def get_seg_masks(self, masks_per_img, labels_per_img, scores_per_img, test_cfg, img_meta):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    seg_masks = self.rescale_masks(masks_per_img, img_meta)\n    seg_masks = seg_masks > test_cfg.mask_thr\n    (bbox_result, segm_result, mask_preds) = self.segm2result(seg_masks, labels_per_img, scores_per_img)\n    return (bbox_result, segm_result, mask_preds)"
        ]
    },
    {
        "func_name": "segm2result",
        "original": "def segm2result(self, mask_preds, det_labels, cls_scores):\n    num_classes = self.num_classes\n    segm_result = [[] for _ in range(num_classes)]\n    det_labels = det_labels.cpu().numpy()\n    cls_scores = cls_scores.cpu().numpy()\n    num_ins = mask_preds.shape[0]\n    bboxes = np.zeros((num_ins, 5), dtype=np.float32)\n    bboxes[:, -1] = cls_scores\n    bboxes[:, :4] = np.array(tensor_mask2box(mask_preds).clip(min=0))\n    for idx in range(num_ins):\n        segm_result[det_labels[idx]].append(mask_preds[idx])\n    return (bboxes, segm_result, mask_preds)",
        "mutated": [
            "def segm2result(self, mask_preds, det_labels, cls_scores):\n    if False:\n        i = 10\n    num_classes = self.num_classes\n    segm_result = [[] for _ in range(num_classes)]\n    det_labels = det_labels.cpu().numpy()\n    cls_scores = cls_scores.cpu().numpy()\n    num_ins = mask_preds.shape[0]\n    bboxes = np.zeros((num_ins, 5), dtype=np.float32)\n    bboxes[:, -1] = cls_scores\n    bboxes[:, :4] = np.array(tensor_mask2box(mask_preds).clip(min=0))\n    for idx in range(num_ins):\n        segm_result[det_labels[idx]].append(mask_preds[idx])\n    return (bboxes, segm_result, mask_preds)",
            "def segm2result(self, mask_preds, det_labels, cls_scores):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    num_classes = self.num_classes\n    segm_result = [[] for _ in range(num_classes)]\n    det_labels = det_labels.cpu().numpy()\n    cls_scores = cls_scores.cpu().numpy()\n    num_ins = mask_preds.shape[0]\n    bboxes = np.zeros((num_ins, 5), dtype=np.float32)\n    bboxes[:, -1] = cls_scores\n    bboxes[:, :4] = np.array(tensor_mask2box(mask_preds).clip(min=0))\n    for idx in range(num_ins):\n        segm_result[det_labels[idx]].append(mask_preds[idx])\n    return (bboxes, segm_result, mask_preds)",
            "def segm2result(self, mask_preds, det_labels, cls_scores):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    num_classes = self.num_classes\n    segm_result = [[] for _ in range(num_classes)]\n    det_labels = det_labels.cpu().numpy()\n    cls_scores = cls_scores.cpu().numpy()\n    num_ins = mask_preds.shape[0]\n    bboxes = np.zeros((num_ins, 5), dtype=np.float32)\n    bboxes[:, -1] = cls_scores\n    bboxes[:, :4] = np.array(tensor_mask2box(mask_preds).clip(min=0))\n    for idx in range(num_ins):\n        segm_result[det_labels[idx]].append(mask_preds[idx])\n    return (bboxes, segm_result, mask_preds)",
            "def segm2result(self, mask_preds, det_labels, cls_scores):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    num_classes = self.num_classes\n    segm_result = [[] for _ in range(num_classes)]\n    det_labels = det_labels.cpu().numpy()\n    cls_scores = cls_scores.cpu().numpy()\n    num_ins = mask_preds.shape[0]\n    bboxes = np.zeros((num_ins, 5), dtype=np.float32)\n    bboxes[:, -1] = cls_scores\n    bboxes[:, :4] = np.array(tensor_mask2box(mask_preds).clip(min=0))\n    for idx in range(num_ins):\n        segm_result[det_labels[idx]].append(mask_preds[idx])\n    return (bboxes, segm_result, mask_preds)",
            "def segm2result(self, mask_preds, det_labels, cls_scores):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    num_classes = self.num_classes\n    segm_result = [[] for _ in range(num_classes)]\n    det_labels = det_labels.cpu().numpy()\n    cls_scores = cls_scores.cpu().numpy()\n    num_ins = mask_preds.shape[0]\n    bboxes = np.zeros((num_ins, 5), dtype=np.float32)\n    bboxes[:, -1] = cls_scores\n    bboxes[:, :4] = np.array(tensor_mask2box(mask_preds).clip(min=0))\n    for idx in range(num_ins):\n        segm_result[det_labels[idx]].append(mask_preds[idx])\n    return (bboxes, segm_result, mask_preds)"
        ]
    }
]