[
    {
        "func_name": "_brute_force_compute_downstream_costs",
        "original": "def _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes):\n    guide_nodes = [x for x in guide_trace.nodes if guide_trace.nodes[x]['type'] == 'sample']\n    (downstream_costs, downstream_guide_cost_nodes) = ({}, {})\n    stacks = get_plate_stacks(model_trace)\n    for node in guide_nodes:\n        downstream_costs[node] = MultiFrameTensor((stacks[node], model_trace.nodes[node]['log_prob'] - guide_trace.nodes[node]['log_prob']))\n        downstream_guide_cost_nodes[node] = set([node])\n        descendants = guide_trace.successors(node)\n        for desc in descendants:\n            desc_mft = MultiFrameTensor((stacks[desc], model_trace.nodes[desc]['log_prob'] - guide_trace.nodes[desc]['log_prob']))\n            downstream_costs[node].add(*desc_mft.items())\n            downstream_guide_cost_nodes[node].update([desc])\n    for site in non_reparam_nodes:\n        children_in_model = set()\n        for node in downstream_guide_cost_nodes[site]:\n            children_in_model.update(model_trace.successors(node))\n        children_in_model.difference_update(downstream_guide_cost_nodes[site])\n        for child in children_in_model:\n            assert model_trace.nodes[child]['type'] == 'sample'\n            child_mft = MultiFrameTensor((stacks[child], model_trace.nodes[child]['log_prob']))\n            downstream_costs[site].add(*child_mft.items())\n            downstream_guide_cost_nodes[site].update([child])\n    for k in non_reparam_nodes:\n        downstream_costs[k] = downstream_costs[k].sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n    return (downstream_costs, downstream_guide_cost_nodes)",
        "mutated": [
            "def _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes):\n    if False:\n        i = 10\n    guide_nodes = [x for x in guide_trace.nodes if guide_trace.nodes[x]['type'] == 'sample']\n    (downstream_costs, downstream_guide_cost_nodes) = ({}, {})\n    stacks = get_plate_stacks(model_trace)\n    for node in guide_nodes:\n        downstream_costs[node] = MultiFrameTensor((stacks[node], model_trace.nodes[node]['log_prob'] - guide_trace.nodes[node]['log_prob']))\n        downstream_guide_cost_nodes[node] = set([node])\n        descendants = guide_trace.successors(node)\n        for desc in descendants:\n            desc_mft = MultiFrameTensor((stacks[desc], model_trace.nodes[desc]['log_prob'] - guide_trace.nodes[desc]['log_prob']))\n            downstream_costs[node].add(*desc_mft.items())\n            downstream_guide_cost_nodes[node].update([desc])\n    for site in non_reparam_nodes:\n        children_in_model = set()\n        for node in downstream_guide_cost_nodes[site]:\n            children_in_model.update(model_trace.successors(node))\n        children_in_model.difference_update(downstream_guide_cost_nodes[site])\n        for child in children_in_model:\n            assert model_trace.nodes[child]['type'] == 'sample'\n            child_mft = MultiFrameTensor((stacks[child], model_trace.nodes[child]['log_prob']))\n            downstream_costs[site].add(*child_mft.items())\n            downstream_guide_cost_nodes[site].update([child])\n    for k in non_reparam_nodes:\n        downstream_costs[k] = downstream_costs[k].sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n    return (downstream_costs, downstream_guide_cost_nodes)",
            "def _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    guide_nodes = [x for x in guide_trace.nodes if guide_trace.nodes[x]['type'] == 'sample']\n    (downstream_costs, downstream_guide_cost_nodes) = ({}, {})\n    stacks = get_plate_stacks(model_trace)\n    for node in guide_nodes:\n        downstream_costs[node] = MultiFrameTensor((stacks[node], model_trace.nodes[node]['log_prob'] - guide_trace.nodes[node]['log_prob']))\n        downstream_guide_cost_nodes[node] = set([node])\n        descendants = guide_trace.successors(node)\n        for desc in descendants:\n            desc_mft = MultiFrameTensor((stacks[desc], model_trace.nodes[desc]['log_prob'] - guide_trace.nodes[desc]['log_prob']))\n            downstream_costs[node].add(*desc_mft.items())\n            downstream_guide_cost_nodes[node].update([desc])\n    for site in non_reparam_nodes:\n        children_in_model = set()\n        for node in downstream_guide_cost_nodes[site]:\n            children_in_model.update(model_trace.successors(node))\n        children_in_model.difference_update(downstream_guide_cost_nodes[site])\n        for child in children_in_model:\n            assert model_trace.nodes[child]['type'] == 'sample'\n            child_mft = MultiFrameTensor((stacks[child], model_trace.nodes[child]['log_prob']))\n            downstream_costs[site].add(*child_mft.items())\n            downstream_guide_cost_nodes[site].update([child])\n    for k in non_reparam_nodes:\n        downstream_costs[k] = downstream_costs[k].sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n    return (downstream_costs, downstream_guide_cost_nodes)",
            "def _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    guide_nodes = [x for x in guide_trace.nodes if guide_trace.nodes[x]['type'] == 'sample']\n    (downstream_costs, downstream_guide_cost_nodes) = ({}, {})\n    stacks = get_plate_stacks(model_trace)\n    for node in guide_nodes:\n        downstream_costs[node] = MultiFrameTensor((stacks[node], model_trace.nodes[node]['log_prob'] - guide_trace.nodes[node]['log_prob']))\n        downstream_guide_cost_nodes[node] = set([node])\n        descendants = guide_trace.successors(node)\n        for desc in descendants:\n            desc_mft = MultiFrameTensor((stacks[desc], model_trace.nodes[desc]['log_prob'] - guide_trace.nodes[desc]['log_prob']))\n            downstream_costs[node].add(*desc_mft.items())\n            downstream_guide_cost_nodes[node].update([desc])\n    for site in non_reparam_nodes:\n        children_in_model = set()\n        for node in downstream_guide_cost_nodes[site]:\n            children_in_model.update(model_trace.successors(node))\n        children_in_model.difference_update(downstream_guide_cost_nodes[site])\n        for child in children_in_model:\n            assert model_trace.nodes[child]['type'] == 'sample'\n            child_mft = MultiFrameTensor((stacks[child], model_trace.nodes[child]['log_prob']))\n            downstream_costs[site].add(*child_mft.items())\n            downstream_guide_cost_nodes[site].update([child])\n    for k in non_reparam_nodes:\n        downstream_costs[k] = downstream_costs[k].sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n    return (downstream_costs, downstream_guide_cost_nodes)",
            "def _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    guide_nodes = [x for x in guide_trace.nodes if guide_trace.nodes[x]['type'] == 'sample']\n    (downstream_costs, downstream_guide_cost_nodes) = ({}, {})\n    stacks = get_plate_stacks(model_trace)\n    for node in guide_nodes:\n        downstream_costs[node] = MultiFrameTensor((stacks[node], model_trace.nodes[node]['log_prob'] - guide_trace.nodes[node]['log_prob']))\n        downstream_guide_cost_nodes[node] = set([node])\n        descendants = guide_trace.successors(node)\n        for desc in descendants:\n            desc_mft = MultiFrameTensor((stacks[desc], model_trace.nodes[desc]['log_prob'] - guide_trace.nodes[desc]['log_prob']))\n            downstream_costs[node].add(*desc_mft.items())\n            downstream_guide_cost_nodes[node].update([desc])\n    for site in non_reparam_nodes:\n        children_in_model = set()\n        for node in downstream_guide_cost_nodes[site]:\n            children_in_model.update(model_trace.successors(node))\n        children_in_model.difference_update(downstream_guide_cost_nodes[site])\n        for child in children_in_model:\n            assert model_trace.nodes[child]['type'] == 'sample'\n            child_mft = MultiFrameTensor((stacks[child], model_trace.nodes[child]['log_prob']))\n            downstream_costs[site].add(*child_mft.items())\n            downstream_guide_cost_nodes[site].update([child])\n    for k in non_reparam_nodes:\n        downstream_costs[k] = downstream_costs[k].sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n    return (downstream_costs, downstream_guide_cost_nodes)",
            "def _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    guide_nodes = [x for x in guide_trace.nodes if guide_trace.nodes[x]['type'] == 'sample']\n    (downstream_costs, downstream_guide_cost_nodes) = ({}, {})\n    stacks = get_plate_stacks(model_trace)\n    for node in guide_nodes:\n        downstream_costs[node] = MultiFrameTensor((stacks[node], model_trace.nodes[node]['log_prob'] - guide_trace.nodes[node]['log_prob']))\n        downstream_guide_cost_nodes[node] = set([node])\n        descendants = guide_trace.successors(node)\n        for desc in descendants:\n            desc_mft = MultiFrameTensor((stacks[desc], model_trace.nodes[desc]['log_prob'] - guide_trace.nodes[desc]['log_prob']))\n            downstream_costs[node].add(*desc_mft.items())\n            downstream_guide_cost_nodes[node].update([desc])\n    for site in non_reparam_nodes:\n        children_in_model = set()\n        for node in downstream_guide_cost_nodes[site]:\n            children_in_model.update(model_trace.successors(node))\n        children_in_model.difference_update(downstream_guide_cost_nodes[site])\n        for child in children_in_model:\n            assert model_trace.nodes[child]['type'] == 'sample'\n            child_mft = MultiFrameTensor((stacks[child], model_trace.nodes[child]['log_prob']))\n            downstream_costs[site].add(*child_mft.items())\n            downstream_guide_cost_nodes[site].update([child])\n    for k in non_reparam_nodes:\n        downstream_costs[k] = downstream_costs[k].sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n    return (downstream_costs, downstream_guide_cost_nodes)"
        ]
    },
    {
        "func_name": "_provenance_compute_downstream_costs",
        "original": "def _provenance_compute_downstream_costs(model_trace, guide_trace):\n    downstream_costs = defaultdict(lambda : MultiFrameTensor())\n    downstream_guide_cost_nodes = defaultdict(lambda : set())\n    for (name, site) in model_trace.nodes.items():\n        if site['type'] == 'sample':\n            for key in get_provenance(site['log_prob_sum']):\n                downstream_costs[key].add((site['cond_indep_stack'], site['log_prob']))\n                downstream_guide_cost_nodes[key] |= {name}\n    for (name, site) in guide_trace.nodes.items():\n        if site['type'] == 'sample':\n            for key in get_provenance(site['log_prob_sum']):\n                downstream_costs[key].add((site['cond_indep_stack'], -site['log_prob']))\n                downstream_guide_cost_nodes[key] |= {name}\n    for (node, downstream_cost) in downstream_costs.items():\n        guide_site = guide_trace.nodes[node]\n        downstream_costs[node] = downstream_cost.sum_to(guide_site['cond_indep_stack'])\n    return (downstream_costs, downstream_guide_cost_nodes)",
        "mutated": [
            "def _provenance_compute_downstream_costs(model_trace, guide_trace):\n    if False:\n        i = 10\n    downstream_costs = defaultdict(lambda : MultiFrameTensor())\n    downstream_guide_cost_nodes = defaultdict(lambda : set())\n    for (name, site) in model_trace.nodes.items():\n        if site['type'] == 'sample':\n            for key in get_provenance(site['log_prob_sum']):\n                downstream_costs[key].add((site['cond_indep_stack'], site['log_prob']))\n                downstream_guide_cost_nodes[key] |= {name}\n    for (name, site) in guide_trace.nodes.items():\n        if site['type'] == 'sample':\n            for key in get_provenance(site['log_prob_sum']):\n                downstream_costs[key].add((site['cond_indep_stack'], -site['log_prob']))\n                downstream_guide_cost_nodes[key] |= {name}\n    for (node, downstream_cost) in downstream_costs.items():\n        guide_site = guide_trace.nodes[node]\n        downstream_costs[node] = downstream_cost.sum_to(guide_site['cond_indep_stack'])\n    return (downstream_costs, downstream_guide_cost_nodes)",
            "def _provenance_compute_downstream_costs(model_trace, guide_trace):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    downstream_costs = defaultdict(lambda : MultiFrameTensor())\n    downstream_guide_cost_nodes = defaultdict(lambda : set())\n    for (name, site) in model_trace.nodes.items():\n        if site['type'] == 'sample':\n            for key in get_provenance(site['log_prob_sum']):\n                downstream_costs[key].add((site['cond_indep_stack'], site['log_prob']))\n                downstream_guide_cost_nodes[key] |= {name}\n    for (name, site) in guide_trace.nodes.items():\n        if site['type'] == 'sample':\n            for key in get_provenance(site['log_prob_sum']):\n                downstream_costs[key].add((site['cond_indep_stack'], -site['log_prob']))\n                downstream_guide_cost_nodes[key] |= {name}\n    for (node, downstream_cost) in downstream_costs.items():\n        guide_site = guide_trace.nodes[node]\n        downstream_costs[node] = downstream_cost.sum_to(guide_site['cond_indep_stack'])\n    return (downstream_costs, downstream_guide_cost_nodes)",
            "def _provenance_compute_downstream_costs(model_trace, guide_trace):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    downstream_costs = defaultdict(lambda : MultiFrameTensor())\n    downstream_guide_cost_nodes = defaultdict(lambda : set())\n    for (name, site) in model_trace.nodes.items():\n        if site['type'] == 'sample':\n            for key in get_provenance(site['log_prob_sum']):\n                downstream_costs[key].add((site['cond_indep_stack'], site['log_prob']))\n                downstream_guide_cost_nodes[key] |= {name}\n    for (name, site) in guide_trace.nodes.items():\n        if site['type'] == 'sample':\n            for key in get_provenance(site['log_prob_sum']):\n                downstream_costs[key].add((site['cond_indep_stack'], -site['log_prob']))\n                downstream_guide_cost_nodes[key] |= {name}\n    for (node, downstream_cost) in downstream_costs.items():\n        guide_site = guide_trace.nodes[node]\n        downstream_costs[node] = downstream_cost.sum_to(guide_site['cond_indep_stack'])\n    return (downstream_costs, downstream_guide_cost_nodes)",
            "def _provenance_compute_downstream_costs(model_trace, guide_trace):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    downstream_costs = defaultdict(lambda : MultiFrameTensor())\n    downstream_guide_cost_nodes = defaultdict(lambda : set())\n    for (name, site) in model_trace.nodes.items():\n        if site['type'] == 'sample':\n            for key in get_provenance(site['log_prob_sum']):\n                downstream_costs[key].add((site['cond_indep_stack'], site['log_prob']))\n                downstream_guide_cost_nodes[key] |= {name}\n    for (name, site) in guide_trace.nodes.items():\n        if site['type'] == 'sample':\n            for key in get_provenance(site['log_prob_sum']):\n                downstream_costs[key].add((site['cond_indep_stack'], -site['log_prob']))\n                downstream_guide_cost_nodes[key] |= {name}\n    for (node, downstream_cost) in downstream_costs.items():\n        guide_site = guide_trace.nodes[node]\n        downstream_costs[node] = downstream_cost.sum_to(guide_site['cond_indep_stack'])\n    return (downstream_costs, downstream_guide_cost_nodes)",
            "def _provenance_compute_downstream_costs(model_trace, guide_trace):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    downstream_costs = defaultdict(lambda : MultiFrameTensor())\n    downstream_guide_cost_nodes = defaultdict(lambda : set())\n    for (name, site) in model_trace.nodes.items():\n        if site['type'] == 'sample':\n            for key in get_provenance(site['log_prob_sum']):\n                downstream_costs[key].add((site['cond_indep_stack'], site['log_prob']))\n                downstream_guide_cost_nodes[key] |= {name}\n    for (name, site) in guide_trace.nodes.items():\n        if site['type'] == 'sample':\n            for key in get_provenance(site['log_prob_sum']):\n                downstream_costs[key].add((site['cond_indep_stack'], -site['log_prob']))\n                downstream_guide_cost_nodes[key] |= {name}\n    for (node, downstream_cost) in downstream_costs.items():\n        guide_site = guide_trace.nodes[node]\n        downstream_costs[node] = downstream_cost.sum_to(guide_site['cond_indep_stack'])\n    return (downstream_costs, downstream_guide_cost_nodes)"
        ]
    },
    {
        "func_name": "big_model_guide",
        "original": "def big_model_guide(include_obs=True, include_single=False, include_inner_1=False, flip_c23=False, include_triple=False, include_z1=False):\n    p0 = torch.tensor(math.exp(-0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33), requires_grad=True)\n    p2 = torch.tensor(math.exp(-0.7), requires_grad=True)\n    if include_triple:\n        with pyro.plate('plate_triple1', 6) as ind_triple1:\n            with pyro.plate('plate_triple2', 7) as ind_triple2:\n                if include_z1:\n                    pyro.sample('z1', dist.Bernoulli(p2).expand_by([len(ind_triple2), len(ind_triple1)]))\n                with pyro.plate('plate_triple3', 9) as ind_triple3:\n                    pyro.sample('z0', dist.Bernoulli(p2).expand_by([len(ind_triple3), len(ind_triple2), len(ind_triple1)]))\n    pyro.sample('a1', dist.Bernoulli(p0))\n    if include_single:\n        with pyro.plate('plate_single', 5) as ind_single:\n            b0 = pyro.sample('b0', dist.Bernoulli(p0).expand_by([len(ind_single)]))\n            assert b0.shape == (5,)\n    with pyro.plate('plate_outer', 2) as ind_outer:\n        pyro.sample('b1', dist.Bernoulli(p0).expand_by([len(ind_outer)]))\n        if include_inner_1:\n            with pyro.plate('plate_inner_1', 3) as ind_inner:\n                pyro.sample('c1', dist.Bernoulli(p1).expand_by([len(ind_inner), len(ind_outer)]))\n                if flip_c23 and (not include_obs):\n                    pyro.sample('c3', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n                    pyro.sample('c2', dist.Bernoulli(p1).expand_by([len(ind_inner), len(ind_outer)]))\n                else:\n                    pyro.sample('c2', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n                    pyro.sample('c3', dist.Bernoulli(p2).expand_by([len(ind_inner), len(ind_outer)]))\n        with pyro.plate('plate_inner_2', 4) as ind_inner:\n            pyro.sample('d1', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n            d2 = pyro.sample('d2', dist.Bernoulli(p2).expand_by([len(ind_inner), len(ind_outer)]))\n            assert d2.shape == (4, 2)\n            if include_obs:\n                pyro.sample('obs', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]), obs=torch.ones(d2.size()))",
        "mutated": [
            "def big_model_guide(include_obs=True, include_single=False, include_inner_1=False, flip_c23=False, include_triple=False, include_z1=False):\n    if False:\n        i = 10\n    p0 = torch.tensor(math.exp(-0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33), requires_grad=True)\n    p2 = torch.tensor(math.exp(-0.7), requires_grad=True)\n    if include_triple:\n        with pyro.plate('plate_triple1', 6) as ind_triple1:\n            with pyro.plate('plate_triple2', 7) as ind_triple2:\n                if include_z1:\n                    pyro.sample('z1', dist.Bernoulli(p2).expand_by([len(ind_triple2), len(ind_triple1)]))\n                with pyro.plate('plate_triple3', 9) as ind_triple3:\n                    pyro.sample('z0', dist.Bernoulli(p2).expand_by([len(ind_triple3), len(ind_triple2), len(ind_triple1)]))\n    pyro.sample('a1', dist.Bernoulli(p0))\n    if include_single:\n        with pyro.plate('plate_single', 5) as ind_single:\n            b0 = pyro.sample('b0', dist.Bernoulli(p0).expand_by([len(ind_single)]))\n            assert b0.shape == (5,)\n    with pyro.plate('plate_outer', 2) as ind_outer:\n        pyro.sample('b1', dist.Bernoulli(p0).expand_by([len(ind_outer)]))\n        if include_inner_1:\n            with pyro.plate('plate_inner_1', 3) as ind_inner:\n                pyro.sample('c1', dist.Bernoulli(p1).expand_by([len(ind_inner), len(ind_outer)]))\n                if flip_c23 and (not include_obs):\n                    pyro.sample('c3', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n                    pyro.sample('c2', dist.Bernoulli(p1).expand_by([len(ind_inner), len(ind_outer)]))\n                else:\n                    pyro.sample('c2', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n                    pyro.sample('c3', dist.Bernoulli(p2).expand_by([len(ind_inner), len(ind_outer)]))\n        with pyro.plate('plate_inner_2', 4) as ind_inner:\n            pyro.sample('d1', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n            d2 = pyro.sample('d2', dist.Bernoulli(p2).expand_by([len(ind_inner), len(ind_outer)]))\n            assert d2.shape == (4, 2)\n            if include_obs:\n                pyro.sample('obs', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]), obs=torch.ones(d2.size()))",
            "def big_model_guide(include_obs=True, include_single=False, include_inner_1=False, flip_c23=False, include_triple=False, include_z1=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    p0 = torch.tensor(math.exp(-0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33), requires_grad=True)\n    p2 = torch.tensor(math.exp(-0.7), requires_grad=True)\n    if include_triple:\n        with pyro.plate('plate_triple1', 6) as ind_triple1:\n            with pyro.plate('plate_triple2', 7) as ind_triple2:\n                if include_z1:\n                    pyro.sample('z1', dist.Bernoulli(p2).expand_by([len(ind_triple2), len(ind_triple1)]))\n                with pyro.plate('plate_triple3', 9) as ind_triple3:\n                    pyro.sample('z0', dist.Bernoulli(p2).expand_by([len(ind_triple3), len(ind_triple2), len(ind_triple1)]))\n    pyro.sample('a1', dist.Bernoulli(p0))\n    if include_single:\n        with pyro.plate('plate_single', 5) as ind_single:\n            b0 = pyro.sample('b0', dist.Bernoulli(p0).expand_by([len(ind_single)]))\n            assert b0.shape == (5,)\n    with pyro.plate('plate_outer', 2) as ind_outer:\n        pyro.sample('b1', dist.Bernoulli(p0).expand_by([len(ind_outer)]))\n        if include_inner_1:\n            with pyro.plate('plate_inner_1', 3) as ind_inner:\n                pyro.sample('c1', dist.Bernoulli(p1).expand_by([len(ind_inner), len(ind_outer)]))\n                if flip_c23 and (not include_obs):\n                    pyro.sample('c3', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n                    pyro.sample('c2', dist.Bernoulli(p1).expand_by([len(ind_inner), len(ind_outer)]))\n                else:\n                    pyro.sample('c2', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n                    pyro.sample('c3', dist.Bernoulli(p2).expand_by([len(ind_inner), len(ind_outer)]))\n        with pyro.plate('plate_inner_2', 4) as ind_inner:\n            pyro.sample('d1', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n            d2 = pyro.sample('d2', dist.Bernoulli(p2).expand_by([len(ind_inner), len(ind_outer)]))\n            assert d2.shape == (4, 2)\n            if include_obs:\n                pyro.sample('obs', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]), obs=torch.ones(d2.size()))",
            "def big_model_guide(include_obs=True, include_single=False, include_inner_1=False, flip_c23=False, include_triple=False, include_z1=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    p0 = torch.tensor(math.exp(-0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33), requires_grad=True)\n    p2 = torch.tensor(math.exp(-0.7), requires_grad=True)\n    if include_triple:\n        with pyro.plate('plate_triple1', 6) as ind_triple1:\n            with pyro.plate('plate_triple2', 7) as ind_triple2:\n                if include_z1:\n                    pyro.sample('z1', dist.Bernoulli(p2).expand_by([len(ind_triple2), len(ind_triple1)]))\n                with pyro.plate('plate_triple3', 9) as ind_triple3:\n                    pyro.sample('z0', dist.Bernoulli(p2).expand_by([len(ind_triple3), len(ind_triple2), len(ind_triple1)]))\n    pyro.sample('a1', dist.Bernoulli(p0))\n    if include_single:\n        with pyro.plate('plate_single', 5) as ind_single:\n            b0 = pyro.sample('b0', dist.Bernoulli(p0).expand_by([len(ind_single)]))\n            assert b0.shape == (5,)\n    with pyro.plate('plate_outer', 2) as ind_outer:\n        pyro.sample('b1', dist.Bernoulli(p0).expand_by([len(ind_outer)]))\n        if include_inner_1:\n            with pyro.plate('plate_inner_1', 3) as ind_inner:\n                pyro.sample('c1', dist.Bernoulli(p1).expand_by([len(ind_inner), len(ind_outer)]))\n                if flip_c23 and (not include_obs):\n                    pyro.sample('c3', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n                    pyro.sample('c2', dist.Bernoulli(p1).expand_by([len(ind_inner), len(ind_outer)]))\n                else:\n                    pyro.sample('c2', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n                    pyro.sample('c3', dist.Bernoulli(p2).expand_by([len(ind_inner), len(ind_outer)]))\n        with pyro.plate('plate_inner_2', 4) as ind_inner:\n            pyro.sample('d1', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n            d2 = pyro.sample('d2', dist.Bernoulli(p2).expand_by([len(ind_inner), len(ind_outer)]))\n            assert d2.shape == (4, 2)\n            if include_obs:\n                pyro.sample('obs', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]), obs=torch.ones(d2.size()))",
            "def big_model_guide(include_obs=True, include_single=False, include_inner_1=False, flip_c23=False, include_triple=False, include_z1=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    p0 = torch.tensor(math.exp(-0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33), requires_grad=True)\n    p2 = torch.tensor(math.exp(-0.7), requires_grad=True)\n    if include_triple:\n        with pyro.plate('plate_triple1', 6) as ind_triple1:\n            with pyro.plate('plate_triple2', 7) as ind_triple2:\n                if include_z1:\n                    pyro.sample('z1', dist.Bernoulli(p2).expand_by([len(ind_triple2), len(ind_triple1)]))\n                with pyro.plate('plate_triple3', 9) as ind_triple3:\n                    pyro.sample('z0', dist.Bernoulli(p2).expand_by([len(ind_triple3), len(ind_triple2), len(ind_triple1)]))\n    pyro.sample('a1', dist.Bernoulli(p0))\n    if include_single:\n        with pyro.plate('plate_single', 5) as ind_single:\n            b0 = pyro.sample('b0', dist.Bernoulli(p0).expand_by([len(ind_single)]))\n            assert b0.shape == (5,)\n    with pyro.plate('plate_outer', 2) as ind_outer:\n        pyro.sample('b1', dist.Bernoulli(p0).expand_by([len(ind_outer)]))\n        if include_inner_1:\n            with pyro.plate('plate_inner_1', 3) as ind_inner:\n                pyro.sample('c1', dist.Bernoulli(p1).expand_by([len(ind_inner), len(ind_outer)]))\n                if flip_c23 and (not include_obs):\n                    pyro.sample('c3', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n                    pyro.sample('c2', dist.Bernoulli(p1).expand_by([len(ind_inner), len(ind_outer)]))\n                else:\n                    pyro.sample('c2', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n                    pyro.sample('c3', dist.Bernoulli(p2).expand_by([len(ind_inner), len(ind_outer)]))\n        with pyro.plate('plate_inner_2', 4) as ind_inner:\n            pyro.sample('d1', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n            d2 = pyro.sample('d2', dist.Bernoulli(p2).expand_by([len(ind_inner), len(ind_outer)]))\n            assert d2.shape == (4, 2)\n            if include_obs:\n                pyro.sample('obs', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]), obs=torch.ones(d2.size()))",
            "def big_model_guide(include_obs=True, include_single=False, include_inner_1=False, flip_c23=False, include_triple=False, include_z1=False):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    p0 = torch.tensor(math.exp(-0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33), requires_grad=True)\n    p2 = torch.tensor(math.exp(-0.7), requires_grad=True)\n    if include_triple:\n        with pyro.plate('plate_triple1', 6) as ind_triple1:\n            with pyro.plate('plate_triple2', 7) as ind_triple2:\n                if include_z1:\n                    pyro.sample('z1', dist.Bernoulli(p2).expand_by([len(ind_triple2), len(ind_triple1)]))\n                with pyro.plate('plate_triple3', 9) as ind_triple3:\n                    pyro.sample('z0', dist.Bernoulli(p2).expand_by([len(ind_triple3), len(ind_triple2), len(ind_triple1)]))\n    pyro.sample('a1', dist.Bernoulli(p0))\n    if include_single:\n        with pyro.plate('plate_single', 5) as ind_single:\n            b0 = pyro.sample('b0', dist.Bernoulli(p0).expand_by([len(ind_single)]))\n            assert b0.shape == (5,)\n    with pyro.plate('plate_outer', 2) as ind_outer:\n        pyro.sample('b1', dist.Bernoulli(p0).expand_by([len(ind_outer)]))\n        if include_inner_1:\n            with pyro.plate('plate_inner_1', 3) as ind_inner:\n                pyro.sample('c1', dist.Bernoulli(p1).expand_by([len(ind_inner), len(ind_outer)]))\n                if flip_c23 and (not include_obs):\n                    pyro.sample('c3', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n                    pyro.sample('c2', dist.Bernoulli(p1).expand_by([len(ind_inner), len(ind_outer)]))\n                else:\n                    pyro.sample('c2', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n                    pyro.sample('c3', dist.Bernoulli(p2).expand_by([len(ind_inner), len(ind_outer)]))\n        with pyro.plate('plate_inner_2', 4) as ind_inner:\n            pyro.sample('d1', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]))\n            d2 = pyro.sample('d2', dist.Bernoulli(p2).expand_by([len(ind_inner), len(ind_outer)]))\n            assert d2.shape == (4, 2)\n            if include_obs:\n                pyro.sample('obs', dist.Bernoulli(p0).expand_by([len(ind_inner), len(ind_outer)]), obs=torch.ones(d2.size()))"
        ]
    },
    {
        "func_name": "test_compute_downstream_costs_big_model_guide_pair",
        "original": "@pytest.mark.parametrize('include_inner_1', [True, False])\n@pytest.mark.parametrize('include_single', [True, False])\n@pytest.mark.parametrize('flip_c23', [True, False])\n@pytest.mark.parametrize('include_triple', [True, False])\n@pytest.mark.parametrize('include_z1', [True, False])\ndef test_compute_downstream_costs_big_model_guide_pair(include_inner_1, include_single, flip_c23, include_triple, include_z1):\n    with TrackNonReparam():\n        guide_trace = poutine.trace(big_model_guide, graph_type='dense').get_trace(include_obs=False, include_inner_1=include_inner_1, include_single=include_single, flip_c23=flip_c23, include_triple=include_triple, include_z1=include_z1)\n        model_trace = poutine.trace(poutine.replay(big_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, include_inner_1=include_inner_1, include_single=include_single, flip_c23=flip_c23, include_triple=include_triple, include_z1=include_z1)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        assert nodes == {name}\n    expected_nodes_full_model = {'a1': {'c2', 'a1', 'd1', 'c1', 'obs', 'b1', 'd2', 'c3', 'b0'}, 'd2': {'obs', 'd2'}, 'd1': {'obs', 'd1', 'd2'}, 'c3': {'d2', 'obs', 'd1', 'c3'}, 'b0': {'b0', 'd1', 'c1', 'obs', 'b1', 'd2', 'c3', 'c2'}, 'b1': {'obs', 'b1', 'd1', 'd2', 'c3', 'c1', 'c2'}, 'c1': {'d1', 'c1', 'obs', 'd2', 'c3', 'c2'}, 'c2': {'obs', 'd1', 'c3', 'd2', 'c2'}}\n    if not include_triple and include_inner_1 and include_single and (not flip_c23):\n        assert dc_nodes == expected_nodes_full_model\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n    expected_b1 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n    expected_b1 += model_trace.nodes['obs']['log_prob'].sum(0, keepdim=False)\n    if include_inner_1:\n        expected_b1 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum(0)\n        expected_b1 += (model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']).sum(0)\n        expected_b1 += (model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']).sum(0)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    if include_single:\n        expected_b0 = model_trace.nodes['b0']['log_prob'] - guide_trace.nodes['b0']['log_prob']\n        expected_b0 += (model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']).sum()\n        expected_b0 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum()\n        expected_b0 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum()\n        expected_b0 += model_trace.nodes['obs']['log_prob'].sum()\n        if include_inner_1:\n            expected_b0 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum()\n            expected_b0 += (model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']).sum()\n            expected_b0 += (model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']).sum()\n        assert_equal(expected_b0, dc['b0'], prec=1e-06)\n        assert dc['b0'].size() == (5,)\n    if include_inner_1:\n        expected_c3 = model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']\n        expected_c3 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n        expected_c3 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n        expected_c3 += model_trace.nodes['obs']['log_prob'].sum(0)\n        expected_c2 = model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n        expected_c2 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n        expected_c2 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n        expected_c2 += model_trace.nodes['obs']['log_prob'].sum(0)\n        expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n        if flip_c23:\n            expected_c3 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n            expected_c2 += model_trace.nodes['c3']['log_prob']\n        else:\n            expected_c2 += model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']\n            expected_c2 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n        expected_c1 += expected_c3\n        assert_equal(expected_c1, dc['c1'], prec=1e-06)\n        assert_equal(expected_c2, dc['c2'], prec=1e-06)\n        assert_equal(expected_c3, dc['c3'], prec=1e-06)\n    expected_d1 = model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']\n    expected_d1 += model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']\n    expected_d1 += model_trace.nodes['obs']['log_prob']\n    expected_d2 = model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']\n    expected_d2 += model_trace.nodes['obs']['log_prob']\n    if include_triple:\n        expected_z0 = dc['a1'] + model_trace.nodes['z0']['log_prob'] - guide_trace.nodes['z0']['log_prob']\n        assert_equal(expected_z0, dc['z0'], prec=1e-06)\n    assert_equal(expected_d2, dc['d2'], prec=1e-06)\n    assert_equal(expected_d1, dc['d1'], prec=1e-06)\n    assert dc['b1'].size() == (2,)\n    assert dc['d2'].size() == (4, 2)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob'])).sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)",
        "mutated": [
            "@pytest.mark.parametrize('include_inner_1', [True, False])\n@pytest.mark.parametrize('include_single', [True, False])\n@pytest.mark.parametrize('flip_c23', [True, False])\n@pytest.mark.parametrize('include_triple', [True, False])\n@pytest.mark.parametrize('include_z1', [True, False])\ndef test_compute_downstream_costs_big_model_guide_pair(include_inner_1, include_single, flip_c23, include_triple, include_z1):\n    if False:\n        i = 10\n    with TrackNonReparam():\n        guide_trace = poutine.trace(big_model_guide, graph_type='dense').get_trace(include_obs=False, include_inner_1=include_inner_1, include_single=include_single, flip_c23=flip_c23, include_triple=include_triple, include_z1=include_z1)\n        model_trace = poutine.trace(poutine.replay(big_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, include_inner_1=include_inner_1, include_single=include_single, flip_c23=flip_c23, include_triple=include_triple, include_z1=include_z1)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        assert nodes == {name}\n    expected_nodes_full_model = {'a1': {'c2', 'a1', 'd1', 'c1', 'obs', 'b1', 'd2', 'c3', 'b0'}, 'd2': {'obs', 'd2'}, 'd1': {'obs', 'd1', 'd2'}, 'c3': {'d2', 'obs', 'd1', 'c3'}, 'b0': {'b0', 'd1', 'c1', 'obs', 'b1', 'd2', 'c3', 'c2'}, 'b1': {'obs', 'b1', 'd1', 'd2', 'c3', 'c1', 'c2'}, 'c1': {'d1', 'c1', 'obs', 'd2', 'c3', 'c2'}, 'c2': {'obs', 'd1', 'c3', 'd2', 'c2'}}\n    if not include_triple and include_inner_1 and include_single and (not flip_c23):\n        assert dc_nodes == expected_nodes_full_model\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n    expected_b1 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n    expected_b1 += model_trace.nodes['obs']['log_prob'].sum(0, keepdim=False)\n    if include_inner_1:\n        expected_b1 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum(0)\n        expected_b1 += (model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']).sum(0)\n        expected_b1 += (model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']).sum(0)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    if include_single:\n        expected_b0 = model_trace.nodes['b0']['log_prob'] - guide_trace.nodes['b0']['log_prob']\n        expected_b0 += (model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']).sum()\n        expected_b0 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum()\n        expected_b0 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum()\n        expected_b0 += model_trace.nodes['obs']['log_prob'].sum()\n        if include_inner_1:\n            expected_b0 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum()\n            expected_b0 += (model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']).sum()\n            expected_b0 += (model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']).sum()\n        assert_equal(expected_b0, dc['b0'], prec=1e-06)\n        assert dc['b0'].size() == (5,)\n    if include_inner_1:\n        expected_c3 = model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']\n        expected_c3 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n        expected_c3 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n        expected_c3 += model_trace.nodes['obs']['log_prob'].sum(0)\n        expected_c2 = model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n        expected_c2 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n        expected_c2 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n        expected_c2 += model_trace.nodes['obs']['log_prob'].sum(0)\n        expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n        if flip_c23:\n            expected_c3 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n            expected_c2 += model_trace.nodes['c3']['log_prob']\n        else:\n            expected_c2 += model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']\n            expected_c2 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n        expected_c1 += expected_c3\n        assert_equal(expected_c1, dc['c1'], prec=1e-06)\n        assert_equal(expected_c2, dc['c2'], prec=1e-06)\n        assert_equal(expected_c3, dc['c3'], prec=1e-06)\n    expected_d1 = model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']\n    expected_d1 += model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']\n    expected_d1 += model_trace.nodes['obs']['log_prob']\n    expected_d2 = model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']\n    expected_d2 += model_trace.nodes['obs']['log_prob']\n    if include_triple:\n        expected_z0 = dc['a1'] + model_trace.nodes['z0']['log_prob'] - guide_trace.nodes['z0']['log_prob']\n        assert_equal(expected_z0, dc['z0'], prec=1e-06)\n    assert_equal(expected_d2, dc['d2'], prec=1e-06)\n    assert_equal(expected_d1, dc['d1'], prec=1e-06)\n    assert dc['b1'].size() == (2,)\n    assert dc['d2'].size() == (4, 2)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob'])).sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)",
            "@pytest.mark.parametrize('include_inner_1', [True, False])\n@pytest.mark.parametrize('include_single', [True, False])\n@pytest.mark.parametrize('flip_c23', [True, False])\n@pytest.mark.parametrize('include_triple', [True, False])\n@pytest.mark.parametrize('include_z1', [True, False])\ndef test_compute_downstream_costs_big_model_guide_pair(include_inner_1, include_single, flip_c23, include_triple, include_z1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with TrackNonReparam():\n        guide_trace = poutine.trace(big_model_guide, graph_type='dense').get_trace(include_obs=False, include_inner_1=include_inner_1, include_single=include_single, flip_c23=flip_c23, include_triple=include_triple, include_z1=include_z1)\n        model_trace = poutine.trace(poutine.replay(big_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, include_inner_1=include_inner_1, include_single=include_single, flip_c23=flip_c23, include_triple=include_triple, include_z1=include_z1)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        assert nodes == {name}\n    expected_nodes_full_model = {'a1': {'c2', 'a1', 'd1', 'c1', 'obs', 'b1', 'd2', 'c3', 'b0'}, 'd2': {'obs', 'd2'}, 'd1': {'obs', 'd1', 'd2'}, 'c3': {'d2', 'obs', 'd1', 'c3'}, 'b0': {'b0', 'd1', 'c1', 'obs', 'b1', 'd2', 'c3', 'c2'}, 'b1': {'obs', 'b1', 'd1', 'd2', 'c3', 'c1', 'c2'}, 'c1': {'d1', 'c1', 'obs', 'd2', 'c3', 'c2'}, 'c2': {'obs', 'd1', 'c3', 'd2', 'c2'}}\n    if not include_triple and include_inner_1 and include_single and (not flip_c23):\n        assert dc_nodes == expected_nodes_full_model\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n    expected_b1 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n    expected_b1 += model_trace.nodes['obs']['log_prob'].sum(0, keepdim=False)\n    if include_inner_1:\n        expected_b1 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum(0)\n        expected_b1 += (model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']).sum(0)\n        expected_b1 += (model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']).sum(0)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    if include_single:\n        expected_b0 = model_trace.nodes['b0']['log_prob'] - guide_trace.nodes['b0']['log_prob']\n        expected_b0 += (model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']).sum()\n        expected_b0 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum()\n        expected_b0 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum()\n        expected_b0 += model_trace.nodes['obs']['log_prob'].sum()\n        if include_inner_1:\n            expected_b0 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum()\n            expected_b0 += (model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']).sum()\n            expected_b0 += (model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']).sum()\n        assert_equal(expected_b0, dc['b0'], prec=1e-06)\n        assert dc['b0'].size() == (5,)\n    if include_inner_1:\n        expected_c3 = model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']\n        expected_c3 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n        expected_c3 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n        expected_c3 += model_trace.nodes['obs']['log_prob'].sum(0)\n        expected_c2 = model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n        expected_c2 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n        expected_c2 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n        expected_c2 += model_trace.nodes['obs']['log_prob'].sum(0)\n        expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n        if flip_c23:\n            expected_c3 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n            expected_c2 += model_trace.nodes['c3']['log_prob']\n        else:\n            expected_c2 += model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']\n            expected_c2 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n        expected_c1 += expected_c3\n        assert_equal(expected_c1, dc['c1'], prec=1e-06)\n        assert_equal(expected_c2, dc['c2'], prec=1e-06)\n        assert_equal(expected_c3, dc['c3'], prec=1e-06)\n    expected_d1 = model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']\n    expected_d1 += model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']\n    expected_d1 += model_trace.nodes['obs']['log_prob']\n    expected_d2 = model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']\n    expected_d2 += model_trace.nodes['obs']['log_prob']\n    if include_triple:\n        expected_z0 = dc['a1'] + model_trace.nodes['z0']['log_prob'] - guide_trace.nodes['z0']['log_prob']\n        assert_equal(expected_z0, dc['z0'], prec=1e-06)\n    assert_equal(expected_d2, dc['d2'], prec=1e-06)\n    assert_equal(expected_d1, dc['d1'], prec=1e-06)\n    assert dc['b1'].size() == (2,)\n    assert dc['d2'].size() == (4, 2)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob'])).sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)",
            "@pytest.mark.parametrize('include_inner_1', [True, False])\n@pytest.mark.parametrize('include_single', [True, False])\n@pytest.mark.parametrize('flip_c23', [True, False])\n@pytest.mark.parametrize('include_triple', [True, False])\n@pytest.mark.parametrize('include_z1', [True, False])\ndef test_compute_downstream_costs_big_model_guide_pair(include_inner_1, include_single, flip_c23, include_triple, include_z1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with TrackNonReparam():\n        guide_trace = poutine.trace(big_model_guide, graph_type='dense').get_trace(include_obs=False, include_inner_1=include_inner_1, include_single=include_single, flip_c23=flip_c23, include_triple=include_triple, include_z1=include_z1)\n        model_trace = poutine.trace(poutine.replay(big_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, include_inner_1=include_inner_1, include_single=include_single, flip_c23=flip_c23, include_triple=include_triple, include_z1=include_z1)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        assert nodes == {name}\n    expected_nodes_full_model = {'a1': {'c2', 'a1', 'd1', 'c1', 'obs', 'b1', 'd2', 'c3', 'b0'}, 'd2': {'obs', 'd2'}, 'd1': {'obs', 'd1', 'd2'}, 'c3': {'d2', 'obs', 'd1', 'c3'}, 'b0': {'b0', 'd1', 'c1', 'obs', 'b1', 'd2', 'c3', 'c2'}, 'b1': {'obs', 'b1', 'd1', 'd2', 'c3', 'c1', 'c2'}, 'c1': {'d1', 'c1', 'obs', 'd2', 'c3', 'c2'}, 'c2': {'obs', 'd1', 'c3', 'd2', 'c2'}}\n    if not include_triple and include_inner_1 and include_single and (not flip_c23):\n        assert dc_nodes == expected_nodes_full_model\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n    expected_b1 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n    expected_b1 += model_trace.nodes['obs']['log_prob'].sum(0, keepdim=False)\n    if include_inner_1:\n        expected_b1 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum(0)\n        expected_b1 += (model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']).sum(0)\n        expected_b1 += (model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']).sum(0)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    if include_single:\n        expected_b0 = model_trace.nodes['b0']['log_prob'] - guide_trace.nodes['b0']['log_prob']\n        expected_b0 += (model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']).sum()\n        expected_b0 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum()\n        expected_b0 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum()\n        expected_b0 += model_trace.nodes['obs']['log_prob'].sum()\n        if include_inner_1:\n            expected_b0 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum()\n            expected_b0 += (model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']).sum()\n            expected_b0 += (model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']).sum()\n        assert_equal(expected_b0, dc['b0'], prec=1e-06)\n        assert dc['b0'].size() == (5,)\n    if include_inner_1:\n        expected_c3 = model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']\n        expected_c3 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n        expected_c3 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n        expected_c3 += model_trace.nodes['obs']['log_prob'].sum(0)\n        expected_c2 = model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n        expected_c2 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n        expected_c2 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n        expected_c2 += model_trace.nodes['obs']['log_prob'].sum(0)\n        expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n        if flip_c23:\n            expected_c3 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n            expected_c2 += model_trace.nodes['c3']['log_prob']\n        else:\n            expected_c2 += model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']\n            expected_c2 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n        expected_c1 += expected_c3\n        assert_equal(expected_c1, dc['c1'], prec=1e-06)\n        assert_equal(expected_c2, dc['c2'], prec=1e-06)\n        assert_equal(expected_c3, dc['c3'], prec=1e-06)\n    expected_d1 = model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']\n    expected_d1 += model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']\n    expected_d1 += model_trace.nodes['obs']['log_prob']\n    expected_d2 = model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']\n    expected_d2 += model_trace.nodes['obs']['log_prob']\n    if include_triple:\n        expected_z0 = dc['a1'] + model_trace.nodes['z0']['log_prob'] - guide_trace.nodes['z0']['log_prob']\n        assert_equal(expected_z0, dc['z0'], prec=1e-06)\n    assert_equal(expected_d2, dc['d2'], prec=1e-06)\n    assert_equal(expected_d1, dc['d1'], prec=1e-06)\n    assert dc['b1'].size() == (2,)\n    assert dc['d2'].size() == (4, 2)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob'])).sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)",
            "@pytest.mark.parametrize('include_inner_1', [True, False])\n@pytest.mark.parametrize('include_single', [True, False])\n@pytest.mark.parametrize('flip_c23', [True, False])\n@pytest.mark.parametrize('include_triple', [True, False])\n@pytest.mark.parametrize('include_z1', [True, False])\ndef test_compute_downstream_costs_big_model_guide_pair(include_inner_1, include_single, flip_c23, include_triple, include_z1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with TrackNonReparam():\n        guide_trace = poutine.trace(big_model_guide, graph_type='dense').get_trace(include_obs=False, include_inner_1=include_inner_1, include_single=include_single, flip_c23=flip_c23, include_triple=include_triple, include_z1=include_z1)\n        model_trace = poutine.trace(poutine.replay(big_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, include_inner_1=include_inner_1, include_single=include_single, flip_c23=flip_c23, include_triple=include_triple, include_z1=include_z1)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        assert nodes == {name}\n    expected_nodes_full_model = {'a1': {'c2', 'a1', 'd1', 'c1', 'obs', 'b1', 'd2', 'c3', 'b0'}, 'd2': {'obs', 'd2'}, 'd1': {'obs', 'd1', 'd2'}, 'c3': {'d2', 'obs', 'd1', 'c3'}, 'b0': {'b0', 'd1', 'c1', 'obs', 'b1', 'd2', 'c3', 'c2'}, 'b1': {'obs', 'b1', 'd1', 'd2', 'c3', 'c1', 'c2'}, 'c1': {'d1', 'c1', 'obs', 'd2', 'c3', 'c2'}, 'c2': {'obs', 'd1', 'c3', 'd2', 'c2'}}\n    if not include_triple and include_inner_1 and include_single and (not flip_c23):\n        assert dc_nodes == expected_nodes_full_model\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n    expected_b1 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n    expected_b1 += model_trace.nodes['obs']['log_prob'].sum(0, keepdim=False)\n    if include_inner_1:\n        expected_b1 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum(0)\n        expected_b1 += (model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']).sum(0)\n        expected_b1 += (model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']).sum(0)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    if include_single:\n        expected_b0 = model_trace.nodes['b0']['log_prob'] - guide_trace.nodes['b0']['log_prob']\n        expected_b0 += (model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']).sum()\n        expected_b0 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum()\n        expected_b0 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum()\n        expected_b0 += model_trace.nodes['obs']['log_prob'].sum()\n        if include_inner_1:\n            expected_b0 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum()\n            expected_b0 += (model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']).sum()\n            expected_b0 += (model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']).sum()\n        assert_equal(expected_b0, dc['b0'], prec=1e-06)\n        assert dc['b0'].size() == (5,)\n    if include_inner_1:\n        expected_c3 = model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']\n        expected_c3 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n        expected_c3 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n        expected_c3 += model_trace.nodes['obs']['log_prob'].sum(0)\n        expected_c2 = model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n        expected_c2 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n        expected_c2 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n        expected_c2 += model_trace.nodes['obs']['log_prob'].sum(0)\n        expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n        if flip_c23:\n            expected_c3 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n            expected_c2 += model_trace.nodes['c3']['log_prob']\n        else:\n            expected_c2 += model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']\n            expected_c2 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n        expected_c1 += expected_c3\n        assert_equal(expected_c1, dc['c1'], prec=1e-06)\n        assert_equal(expected_c2, dc['c2'], prec=1e-06)\n        assert_equal(expected_c3, dc['c3'], prec=1e-06)\n    expected_d1 = model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']\n    expected_d1 += model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']\n    expected_d1 += model_trace.nodes['obs']['log_prob']\n    expected_d2 = model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']\n    expected_d2 += model_trace.nodes['obs']['log_prob']\n    if include_triple:\n        expected_z0 = dc['a1'] + model_trace.nodes['z0']['log_prob'] - guide_trace.nodes['z0']['log_prob']\n        assert_equal(expected_z0, dc['z0'], prec=1e-06)\n    assert_equal(expected_d2, dc['d2'], prec=1e-06)\n    assert_equal(expected_d1, dc['d1'], prec=1e-06)\n    assert dc['b1'].size() == (2,)\n    assert dc['d2'].size() == (4, 2)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob'])).sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)",
            "@pytest.mark.parametrize('include_inner_1', [True, False])\n@pytest.mark.parametrize('include_single', [True, False])\n@pytest.mark.parametrize('flip_c23', [True, False])\n@pytest.mark.parametrize('include_triple', [True, False])\n@pytest.mark.parametrize('include_z1', [True, False])\ndef test_compute_downstream_costs_big_model_guide_pair(include_inner_1, include_single, flip_c23, include_triple, include_z1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with TrackNonReparam():\n        guide_trace = poutine.trace(big_model_guide, graph_type='dense').get_trace(include_obs=False, include_inner_1=include_inner_1, include_single=include_single, flip_c23=flip_c23, include_triple=include_triple, include_z1=include_z1)\n        model_trace = poutine.trace(poutine.replay(big_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, include_inner_1=include_inner_1, include_single=include_single, flip_c23=flip_c23, include_triple=include_triple, include_z1=include_z1)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        assert nodes == {name}\n    expected_nodes_full_model = {'a1': {'c2', 'a1', 'd1', 'c1', 'obs', 'b1', 'd2', 'c3', 'b0'}, 'd2': {'obs', 'd2'}, 'd1': {'obs', 'd1', 'd2'}, 'c3': {'d2', 'obs', 'd1', 'c3'}, 'b0': {'b0', 'd1', 'c1', 'obs', 'b1', 'd2', 'c3', 'c2'}, 'b1': {'obs', 'b1', 'd1', 'd2', 'c3', 'c1', 'c2'}, 'c1': {'d1', 'c1', 'obs', 'd2', 'c3', 'c2'}, 'c2': {'obs', 'd1', 'c3', 'd2', 'c2'}}\n    if not include_triple and include_inner_1 and include_single and (not flip_c23):\n        assert dc_nodes == expected_nodes_full_model\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n    expected_b1 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n    expected_b1 += model_trace.nodes['obs']['log_prob'].sum(0, keepdim=False)\n    if include_inner_1:\n        expected_b1 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum(0)\n        expected_b1 += (model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']).sum(0)\n        expected_b1 += (model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']).sum(0)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    if include_single:\n        expected_b0 = model_trace.nodes['b0']['log_prob'] - guide_trace.nodes['b0']['log_prob']\n        expected_b0 += (model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']).sum()\n        expected_b0 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum()\n        expected_b0 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum()\n        expected_b0 += model_trace.nodes['obs']['log_prob'].sum()\n        if include_inner_1:\n            expected_b0 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum()\n            expected_b0 += (model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']).sum()\n            expected_b0 += (model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']).sum()\n        assert_equal(expected_b0, dc['b0'], prec=1e-06)\n        assert dc['b0'].size() == (5,)\n    if include_inner_1:\n        expected_c3 = model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']\n        expected_c3 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n        expected_c3 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n        expected_c3 += model_trace.nodes['obs']['log_prob'].sum(0)\n        expected_c2 = model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n        expected_c2 += (model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']).sum(0)\n        expected_c2 += (model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']).sum(0)\n        expected_c2 += model_trace.nodes['obs']['log_prob'].sum(0)\n        expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n        if flip_c23:\n            expected_c3 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n            expected_c2 += model_trace.nodes['c3']['log_prob']\n        else:\n            expected_c2 += model_trace.nodes['c3']['log_prob'] - guide_trace.nodes['c3']['log_prob']\n            expected_c2 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n        expected_c1 += expected_c3\n        assert_equal(expected_c1, dc['c1'], prec=1e-06)\n        assert_equal(expected_c2, dc['c2'], prec=1e-06)\n        assert_equal(expected_c3, dc['c3'], prec=1e-06)\n    expected_d1 = model_trace.nodes['d1']['log_prob'] - guide_trace.nodes['d1']['log_prob']\n    expected_d1 += model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']\n    expected_d1 += model_trace.nodes['obs']['log_prob']\n    expected_d2 = model_trace.nodes['d2']['log_prob'] - guide_trace.nodes['d2']['log_prob']\n    expected_d2 += model_trace.nodes['obs']['log_prob']\n    if include_triple:\n        expected_z0 = dc['a1'] + model_trace.nodes['z0']['log_prob'] - guide_trace.nodes['z0']['log_prob']\n        assert_equal(expected_z0, dc['z0'], prec=1e-06)\n    assert_equal(expected_d2, dc['d2'], prec=1e-06)\n    assert_equal(expected_d1, dc['d1'], prec=1e-06)\n    assert dc['b1'].size() == (2,)\n    assert dc['d2'].size() == (4, 2)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob'])).sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)"
        ]
    },
    {
        "func_name": "diamond_model",
        "original": "def diamond_model(dim):\n    p0 = torch.tensor(math.exp(-0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0))\n    pyro.sample('c1', dist.Bernoulli(p1))\n    for i in pyro.plate('plate', 2):\n        b_i = pyro.sample('b{}'.format(i), dist.Bernoulli(p0 * p1))\n        assert b_i.shape == ()\n    pyro.sample('obs', dist.Bernoulli(p0), obs=torch.tensor(1.0))",
        "mutated": [
            "def diamond_model(dim):\n    if False:\n        i = 10\n    p0 = torch.tensor(math.exp(-0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0))\n    pyro.sample('c1', dist.Bernoulli(p1))\n    for i in pyro.plate('plate', 2):\n        b_i = pyro.sample('b{}'.format(i), dist.Bernoulli(p0 * p1))\n        assert b_i.shape == ()\n    pyro.sample('obs', dist.Bernoulli(p0), obs=torch.tensor(1.0))",
            "def diamond_model(dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    p0 = torch.tensor(math.exp(-0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0))\n    pyro.sample('c1', dist.Bernoulli(p1))\n    for i in pyro.plate('plate', 2):\n        b_i = pyro.sample('b{}'.format(i), dist.Bernoulli(p0 * p1))\n        assert b_i.shape == ()\n    pyro.sample('obs', dist.Bernoulli(p0), obs=torch.tensor(1.0))",
            "def diamond_model(dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    p0 = torch.tensor(math.exp(-0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0))\n    pyro.sample('c1', dist.Bernoulli(p1))\n    for i in pyro.plate('plate', 2):\n        b_i = pyro.sample('b{}'.format(i), dist.Bernoulli(p0 * p1))\n        assert b_i.shape == ()\n    pyro.sample('obs', dist.Bernoulli(p0), obs=torch.tensor(1.0))",
            "def diamond_model(dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    p0 = torch.tensor(math.exp(-0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0))\n    pyro.sample('c1', dist.Bernoulli(p1))\n    for i in pyro.plate('plate', 2):\n        b_i = pyro.sample('b{}'.format(i), dist.Bernoulli(p0 * p1))\n        assert b_i.shape == ()\n    pyro.sample('obs', dist.Bernoulli(p0), obs=torch.tensor(1.0))",
            "def diamond_model(dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    p0 = torch.tensor(math.exp(-0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0))\n    pyro.sample('c1', dist.Bernoulli(p1))\n    for i in pyro.plate('plate', 2):\n        b_i = pyro.sample('b{}'.format(i), dist.Bernoulli(p0 * p1))\n        assert b_i.shape == ()\n    pyro.sample('obs', dist.Bernoulli(p0), obs=torch.tensor(1.0))"
        ]
    },
    {
        "func_name": "diamond_guide",
        "original": "def diamond_guide(dim):\n    p0 = torch.tensor(math.exp(-0.7), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.43), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0))\n    for i in pyro.plate('plate', dim):\n        pyro.sample('b{}'.format(i), dist.Bernoulli(p1))\n    pyro.sample('c1', dist.Bernoulli(p0))",
        "mutated": [
            "def diamond_guide(dim):\n    if False:\n        i = 10\n    p0 = torch.tensor(math.exp(-0.7), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.43), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0))\n    for i in pyro.plate('plate', dim):\n        pyro.sample('b{}'.format(i), dist.Bernoulli(p1))\n    pyro.sample('c1', dist.Bernoulli(p0))",
            "def diamond_guide(dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    p0 = torch.tensor(math.exp(-0.7), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.43), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0))\n    for i in pyro.plate('plate', dim):\n        pyro.sample('b{}'.format(i), dist.Bernoulli(p1))\n    pyro.sample('c1', dist.Bernoulli(p0))",
            "def diamond_guide(dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    p0 = torch.tensor(math.exp(-0.7), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.43), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0))\n    for i in pyro.plate('plate', dim):\n        pyro.sample('b{}'.format(i), dist.Bernoulli(p1))\n    pyro.sample('c1', dist.Bernoulli(p0))",
            "def diamond_guide(dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    p0 = torch.tensor(math.exp(-0.7), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.43), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0))\n    for i in pyro.plate('plate', dim):\n        pyro.sample('b{}'.format(i), dist.Bernoulli(p1))\n    pyro.sample('c1', dist.Bernoulli(p0))",
            "def diamond_guide(dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    p0 = torch.tensor(math.exp(-0.7), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.43), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0))\n    for i in pyro.plate('plate', dim):\n        pyro.sample('b{}'.format(i), dist.Bernoulli(p1))\n    pyro.sample('c1', dist.Bernoulli(p0))"
        ]
    },
    {
        "func_name": "test_compute_downstream_costs_duplicates",
        "original": "@pytest.mark.parametrize('dim', [2, 3, 7, 11])\ndef test_compute_downstream_costs_duplicates(dim):\n    with TrackNonReparam():\n        guide_trace = poutine.trace(diamond_guide, graph_type='dense').get_trace(dim=dim)\n        model_trace = poutine.trace(poutine.replay(diamond_model, trace=guide_trace), graph_type='dense').get_trace(dim=dim)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        assert nodes == {name}\n    expected_a1 = model_trace.nodes['a1']['log_prob'] - guide_trace.nodes['a1']['log_prob']\n    for d in range(dim):\n        expected_a1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n        expected_a1 -= guide_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_a1 += model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_a1 += model_trace.nodes['obs']['log_prob']\n    expected_b1 = -guide_trace.nodes['b1']['log_prob']\n    for d in range(dim):\n        expected_b1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_b1 += model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_b1 += model_trace.nodes['obs']['log_prob']\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    for d in range(dim):\n        expected_c1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_c1 += model_trace.nodes['obs']['log_prob']\n    assert_equal(expected_a1, dc['a1'], prec=1e-06)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    assert_equal(expected_c1, dc['c1'], prec=1e-06)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob'])).sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)",
        "mutated": [
            "@pytest.mark.parametrize('dim', [2, 3, 7, 11])\ndef test_compute_downstream_costs_duplicates(dim):\n    if False:\n        i = 10\n    with TrackNonReparam():\n        guide_trace = poutine.trace(diamond_guide, graph_type='dense').get_trace(dim=dim)\n        model_trace = poutine.trace(poutine.replay(diamond_model, trace=guide_trace), graph_type='dense').get_trace(dim=dim)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        assert nodes == {name}\n    expected_a1 = model_trace.nodes['a1']['log_prob'] - guide_trace.nodes['a1']['log_prob']\n    for d in range(dim):\n        expected_a1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n        expected_a1 -= guide_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_a1 += model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_a1 += model_trace.nodes['obs']['log_prob']\n    expected_b1 = -guide_trace.nodes['b1']['log_prob']\n    for d in range(dim):\n        expected_b1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_b1 += model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_b1 += model_trace.nodes['obs']['log_prob']\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    for d in range(dim):\n        expected_c1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_c1 += model_trace.nodes['obs']['log_prob']\n    assert_equal(expected_a1, dc['a1'], prec=1e-06)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    assert_equal(expected_c1, dc['c1'], prec=1e-06)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob'])).sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)",
            "@pytest.mark.parametrize('dim', [2, 3, 7, 11])\ndef test_compute_downstream_costs_duplicates(dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with TrackNonReparam():\n        guide_trace = poutine.trace(diamond_guide, graph_type='dense').get_trace(dim=dim)\n        model_trace = poutine.trace(poutine.replay(diamond_model, trace=guide_trace), graph_type='dense').get_trace(dim=dim)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        assert nodes == {name}\n    expected_a1 = model_trace.nodes['a1']['log_prob'] - guide_trace.nodes['a1']['log_prob']\n    for d in range(dim):\n        expected_a1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n        expected_a1 -= guide_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_a1 += model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_a1 += model_trace.nodes['obs']['log_prob']\n    expected_b1 = -guide_trace.nodes['b1']['log_prob']\n    for d in range(dim):\n        expected_b1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_b1 += model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_b1 += model_trace.nodes['obs']['log_prob']\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    for d in range(dim):\n        expected_c1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_c1 += model_trace.nodes['obs']['log_prob']\n    assert_equal(expected_a1, dc['a1'], prec=1e-06)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    assert_equal(expected_c1, dc['c1'], prec=1e-06)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob'])).sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)",
            "@pytest.mark.parametrize('dim', [2, 3, 7, 11])\ndef test_compute_downstream_costs_duplicates(dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with TrackNonReparam():\n        guide_trace = poutine.trace(diamond_guide, graph_type='dense').get_trace(dim=dim)\n        model_trace = poutine.trace(poutine.replay(diamond_model, trace=guide_trace), graph_type='dense').get_trace(dim=dim)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        assert nodes == {name}\n    expected_a1 = model_trace.nodes['a1']['log_prob'] - guide_trace.nodes['a1']['log_prob']\n    for d in range(dim):\n        expected_a1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n        expected_a1 -= guide_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_a1 += model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_a1 += model_trace.nodes['obs']['log_prob']\n    expected_b1 = -guide_trace.nodes['b1']['log_prob']\n    for d in range(dim):\n        expected_b1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_b1 += model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_b1 += model_trace.nodes['obs']['log_prob']\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    for d in range(dim):\n        expected_c1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_c1 += model_trace.nodes['obs']['log_prob']\n    assert_equal(expected_a1, dc['a1'], prec=1e-06)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    assert_equal(expected_c1, dc['c1'], prec=1e-06)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob'])).sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)",
            "@pytest.mark.parametrize('dim', [2, 3, 7, 11])\ndef test_compute_downstream_costs_duplicates(dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with TrackNonReparam():\n        guide_trace = poutine.trace(diamond_guide, graph_type='dense').get_trace(dim=dim)\n        model_trace = poutine.trace(poutine.replay(diamond_model, trace=guide_trace), graph_type='dense').get_trace(dim=dim)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        assert nodes == {name}\n    expected_a1 = model_trace.nodes['a1']['log_prob'] - guide_trace.nodes['a1']['log_prob']\n    for d in range(dim):\n        expected_a1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n        expected_a1 -= guide_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_a1 += model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_a1 += model_trace.nodes['obs']['log_prob']\n    expected_b1 = -guide_trace.nodes['b1']['log_prob']\n    for d in range(dim):\n        expected_b1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_b1 += model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_b1 += model_trace.nodes['obs']['log_prob']\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    for d in range(dim):\n        expected_c1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_c1 += model_trace.nodes['obs']['log_prob']\n    assert_equal(expected_a1, dc['a1'], prec=1e-06)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    assert_equal(expected_c1, dc['c1'], prec=1e-06)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob'])).sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)",
            "@pytest.mark.parametrize('dim', [2, 3, 7, 11])\ndef test_compute_downstream_costs_duplicates(dim):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with TrackNonReparam():\n        guide_trace = poutine.trace(diamond_guide, graph_type='dense').get_trace(dim=dim)\n        model_trace = poutine.trace(poutine.replay(diamond_model, trace=guide_trace), graph_type='dense').get_trace(dim=dim)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        assert nodes == {name}\n    expected_a1 = model_trace.nodes['a1']['log_prob'] - guide_trace.nodes['a1']['log_prob']\n    for d in range(dim):\n        expected_a1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n        expected_a1 -= guide_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_a1 += model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_a1 += model_trace.nodes['obs']['log_prob']\n    expected_b1 = -guide_trace.nodes['b1']['log_prob']\n    for d in range(dim):\n        expected_b1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_b1 += model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_b1 += model_trace.nodes['obs']['log_prob']\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    for d in range(dim):\n        expected_c1 += model_trace.nodes['b{}'.format(d)]['log_prob']\n    expected_c1 += model_trace.nodes['obs']['log_prob']\n    assert_equal(expected_a1, dc['a1'], prec=1e-06)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    assert_equal(expected_c1, dc['c1'], prec=1e-06)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob'])).sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)"
        ]
    },
    {
        "func_name": "nested_model_guide",
        "original": "def nested_model_guide(include_obs=True, dim1=11, dim2=7):\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    for i in pyro.plate('plate', dim1):\n        pyro.sample('b{}'.format(i), dist.Bernoulli(p0))\n        with pyro.plate('plate_{}'.format(i), dim2 + i) as ind:\n            c_i = pyro.sample('c{}'.format(i), dist.Bernoulli(p1).expand_by([len(ind)]))\n            assert c_i.shape == (dim2 + i,)\n            if include_obs:\n                obs_i = pyro.sample('obs{}'.format(i), dist.Bernoulli(c_i), obs=torch.ones(c_i.size()))\n                assert obs_i.shape == (dim2 + i,)",
        "mutated": [
            "def nested_model_guide(include_obs=True, dim1=11, dim2=7):\n    if False:\n        i = 10\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    for i in pyro.plate('plate', dim1):\n        pyro.sample('b{}'.format(i), dist.Bernoulli(p0))\n        with pyro.plate('plate_{}'.format(i), dim2 + i) as ind:\n            c_i = pyro.sample('c{}'.format(i), dist.Bernoulli(p1).expand_by([len(ind)]))\n            assert c_i.shape == (dim2 + i,)\n            if include_obs:\n                obs_i = pyro.sample('obs{}'.format(i), dist.Bernoulli(c_i), obs=torch.ones(c_i.size()))\n                assert obs_i.shape == (dim2 + i,)",
            "def nested_model_guide(include_obs=True, dim1=11, dim2=7):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    for i in pyro.plate('plate', dim1):\n        pyro.sample('b{}'.format(i), dist.Bernoulli(p0))\n        with pyro.plate('plate_{}'.format(i), dim2 + i) as ind:\n            c_i = pyro.sample('c{}'.format(i), dist.Bernoulli(p1).expand_by([len(ind)]))\n            assert c_i.shape == (dim2 + i,)\n            if include_obs:\n                obs_i = pyro.sample('obs{}'.format(i), dist.Bernoulli(c_i), obs=torch.ones(c_i.size()))\n                assert obs_i.shape == (dim2 + i,)",
            "def nested_model_guide(include_obs=True, dim1=11, dim2=7):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    for i in pyro.plate('plate', dim1):\n        pyro.sample('b{}'.format(i), dist.Bernoulli(p0))\n        with pyro.plate('plate_{}'.format(i), dim2 + i) as ind:\n            c_i = pyro.sample('c{}'.format(i), dist.Bernoulli(p1).expand_by([len(ind)]))\n            assert c_i.shape == (dim2 + i,)\n            if include_obs:\n                obs_i = pyro.sample('obs{}'.format(i), dist.Bernoulli(c_i), obs=torch.ones(c_i.size()))\n                assert obs_i.shape == (dim2 + i,)",
            "def nested_model_guide(include_obs=True, dim1=11, dim2=7):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    for i in pyro.plate('plate', dim1):\n        pyro.sample('b{}'.format(i), dist.Bernoulli(p0))\n        with pyro.plate('plate_{}'.format(i), dim2 + i) as ind:\n            c_i = pyro.sample('c{}'.format(i), dist.Bernoulli(p1).expand_by([len(ind)]))\n            assert c_i.shape == (dim2 + i,)\n            if include_obs:\n                obs_i = pyro.sample('obs{}'.format(i), dist.Bernoulli(c_i), obs=torch.ones(c_i.size()))\n                assert obs_i.shape == (dim2 + i,)",
            "def nested_model_guide(include_obs=True, dim1=11, dim2=7):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    for i in pyro.plate('plate', dim1):\n        pyro.sample('b{}'.format(i), dist.Bernoulli(p0))\n        with pyro.plate('plate_{}'.format(i), dim2 + i) as ind:\n            c_i = pyro.sample('c{}'.format(i), dist.Bernoulli(p1).expand_by([len(ind)]))\n            assert c_i.shape == (dim2 + i,)\n            if include_obs:\n                obs_i = pyro.sample('obs{}'.format(i), dist.Bernoulli(c_i), obs=torch.ones(c_i.size()))\n                assert obs_i.shape == (dim2 + i,)"
        ]
    },
    {
        "func_name": "test_compute_downstream_costs_plate_in_iplate",
        "original": "@pytest.mark.parametrize('dim1', [2, 5, 9])\ndef test_compute_downstream_costs_plate_in_iplate(dim1):\n    with TrackNonReparam():\n        guide_trace = poutine.trace(nested_model_guide, graph_type='dense').get_trace(include_obs=False, dim1=dim1)\n        model_trace = poutine.trace(poutine.replay(nested_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name.startswith('c'):\n            i = int(name[1:])\n            assert nodes == {name, f'obs{i}'}\n        else:\n            assert nodes == {name}\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_c1 += model_trace.nodes['obs1']['log_prob']\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum()\n    expected_b1 += model_trace.nodes['obs1']['log_prob'].sum()\n    expected_c0 = model_trace.nodes['c0']['log_prob'] - guide_trace.nodes['c0']['log_prob']\n    expected_c0 += model_trace.nodes['obs0']['log_prob']\n    expected_b0 = model_trace.nodes['b0']['log_prob'] - guide_trace.nodes['b0']['log_prob']\n    expected_b0 += (model_trace.nodes['c0']['log_prob'] - guide_trace.nodes['c0']['log_prob']).sum()\n    expected_b0 += model_trace.nodes['obs0']['log_prob'].sum()\n    assert_equal(expected_c1, dc['c1'], prec=1e-06)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    assert_equal(expected_c0, dc['c0'], prec=1e-06)\n    assert_equal(expected_b0, dc['b0'], prec=1e-06)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k.startswith('c'):\n            i = int(k[1:])\n            expected_dc_provenance.add((model_trace.nodes[f'obs{i}']['cond_indep_stack'], model_trace.nodes[f'obs{i}']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)",
        "mutated": [
            "@pytest.mark.parametrize('dim1', [2, 5, 9])\ndef test_compute_downstream_costs_plate_in_iplate(dim1):\n    if False:\n        i = 10\n    with TrackNonReparam():\n        guide_trace = poutine.trace(nested_model_guide, graph_type='dense').get_trace(include_obs=False, dim1=dim1)\n        model_trace = poutine.trace(poutine.replay(nested_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name.startswith('c'):\n            i = int(name[1:])\n            assert nodes == {name, f'obs{i}'}\n        else:\n            assert nodes == {name}\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_c1 += model_trace.nodes['obs1']['log_prob']\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum()\n    expected_b1 += model_trace.nodes['obs1']['log_prob'].sum()\n    expected_c0 = model_trace.nodes['c0']['log_prob'] - guide_trace.nodes['c0']['log_prob']\n    expected_c0 += model_trace.nodes['obs0']['log_prob']\n    expected_b0 = model_trace.nodes['b0']['log_prob'] - guide_trace.nodes['b0']['log_prob']\n    expected_b0 += (model_trace.nodes['c0']['log_prob'] - guide_trace.nodes['c0']['log_prob']).sum()\n    expected_b0 += model_trace.nodes['obs0']['log_prob'].sum()\n    assert_equal(expected_c1, dc['c1'], prec=1e-06)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    assert_equal(expected_c0, dc['c0'], prec=1e-06)\n    assert_equal(expected_b0, dc['b0'], prec=1e-06)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k.startswith('c'):\n            i = int(k[1:])\n            expected_dc_provenance.add((model_trace.nodes[f'obs{i}']['cond_indep_stack'], model_trace.nodes[f'obs{i}']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)",
            "@pytest.mark.parametrize('dim1', [2, 5, 9])\ndef test_compute_downstream_costs_plate_in_iplate(dim1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with TrackNonReparam():\n        guide_trace = poutine.trace(nested_model_guide, graph_type='dense').get_trace(include_obs=False, dim1=dim1)\n        model_trace = poutine.trace(poutine.replay(nested_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name.startswith('c'):\n            i = int(name[1:])\n            assert nodes == {name, f'obs{i}'}\n        else:\n            assert nodes == {name}\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_c1 += model_trace.nodes['obs1']['log_prob']\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum()\n    expected_b1 += model_trace.nodes['obs1']['log_prob'].sum()\n    expected_c0 = model_trace.nodes['c0']['log_prob'] - guide_trace.nodes['c0']['log_prob']\n    expected_c0 += model_trace.nodes['obs0']['log_prob']\n    expected_b0 = model_trace.nodes['b0']['log_prob'] - guide_trace.nodes['b0']['log_prob']\n    expected_b0 += (model_trace.nodes['c0']['log_prob'] - guide_trace.nodes['c0']['log_prob']).sum()\n    expected_b0 += model_trace.nodes['obs0']['log_prob'].sum()\n    assert_equal(expected_c1, dc['c1'], prec=1e-06)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    assert_equal(expected_c0, dc['c0'], prec=1e-06)\n    assert_equal(expected_b0, dc['b0'], prec=1e-06)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k.startswith('c'):\n            i = int(k[1:])\n            expected_dc_provenance.add((model_trace.nodes[f'obs{i}']['cond_indep_stack'], model_trace.nodes[f'obs{i}']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)",
            "@pytest.mark.parametrize('dim1', [2, 5, 9])\ndef test_compute_downstream_costs_plate_in_iplate(dim1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with TrackNonReparam():\n        guide_trace = poutine.trace(nested_model_guide, graph_type='dense').get_trace(include_obs=False, dim1=dim1)\n        model_trace = poutine.trace(poutine.replay(nested_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name.startswith('c'):\n            i = int(name[1:])\n            assert nodes == {name, f'obs{i}'}\n        else:\n            assert nodes == {name}\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_c1 += model_trace.nodes['obs1']['log_prob']\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum()\n    expected_b1 += model_trace.nodes['obs1']['log_prob'].sum()\n    expected_c0 = model_trace.nodes['c0']['log_prob'] - guide_trace.nodes['c0']['log_prob']\n    expected_c0 += model_trace.nodes['obs0']['log_prob']\n    expected_b0 = model_trace.nodes['b0']['log_prob'] - guide_trace.nodes['b0']['log_prob']\n    expected_b0 += (model_trace.nodes['c0']['log_prob'] - guide_trace.nodes['c0']['log_prob']).sum()\n    expected_b0 += model_trace.nodes['obs0']['log_prob'].sum()\n    assert_equal(expected_c1, dc['c1'], prec=1e-06)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    assert_equal(expected_c0, dc['c0'], prec=1e-06)\n    assert_equal(expected_b0, dc['b0'], prec=1e-06)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k.startswith('c'):\n            i = int(k[1:])\n            expected_dc_provenance.add((model_trace.nodes[f'obs{i}']['cond_indep_stack'], model_trace.nodes[f'obs{i}']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)",
            "@pytest.mark.parametrize('dim1', [2, 5, 9])\ndef test_compute_downstream_costs_plate_in_iplate(dim1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with TrackNonReparam():\n        guide_trace = poutine.trace(nested_model_guide, graph_type='dense').get_trace(include_obs=False, dim1=dim1)\n        model_trace = poutine.trace(poutine.replay(nested_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name.startswith('c'):\n            i = int(name[1:])\n            assert nodes == {name, f'obs{i}'}\n        else:\n            assert nodes == {name}\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_c1 += model_trace.nodes['obs1']['log_prob']\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum()\n    expected_b1 += model_trace.nodes['obs1']['log_prob'].sum()\n    expected_c0 = model_trace.nodes['c0']['log_prob'] - guide_trace.nodes['c0']['log_prob']\n    expected_c0 += model_trace.nodes['obs0']['log_prob']\n    expected_b0 = model_trace.nodes['b0']['log_prob'] - guide_trace.nodes['b0']['log_prob']\n    expected_b0 += (model_trace.nodes['c0']['log_prob'] - guide_trace.nodes['c0']['log_prob']).sum()\n    expected_b0 += model_trace.nodes['obs0']['log_prob'].sum()\n    assert_equal(expected_c1, dc['c1'], prec=1e-06)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    assert_equal(expected_c0, dc['c0'], prec=1e-06)\n    assert_equal(expected_b0, dc['b0'], prec=1e-06)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k.startswith('c'):\n            i = int(k[1:])\n            expected_dc_provenance.add((model_trace.nodes[f'obs{i}']['cond_indep_stack'], model_trace.nodes[f'obs{i}']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)",
            "@pytest.mark.parametrize('dim1', [2, 5, 9])\ndef test_compute_downstream_costs_plate_in_iplate(dim1):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with TrackNonReparam():\n        guide_trace = poutine.trace(nested_model_guide, graph_type='dense').get_trace(include_obs=False, dim1=dim1)\n        model_trace = poutine.trace(poutine.replay(nested_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name.startswith('c'):\n            i = int(name[1:])\n            assert nodes == {name, f'obs{i}'}\n        else:\n            assert nodes == {name}\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_c1 += model_trace.nodes['obs1']['log_prob']\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += (model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']).sum()\n    expected_b1 += model_trace.nodes['obs1']['log_prob'].sum()\n    expected_c0 = model_trace.nodes['c0']['log_prob'] - guide_trace.nodes['c0']['log_prob']\n    expected_c0 += model_trace.nodes['obs0']['log_prob']\n    expected_b0 = model_trace.nodes['b0']['log_prob'] - guide_trace.nodes['b0']['log_prob']\n    expected_b0 += (model_trace.nodes['c0']['log_prob'] - guide_trace.nodes['c0']['log_prob']).sum()\n    expected_b0 += model_trace.nodes['obs0']['log_prob'].sum()\n    assert_equal(expected_c1, dc['c1'], prec=1e-06)\n    assert_equal(expected_b1, dc['b1'], prec=1e-06)\n    assert_equal(expected_c0, dc['c0'], prec=1e-06)\n    assert_equal(expected_b0, dc['b0'], prec=1e-06)\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k.startswith('c'):\n            i = int(k[1:])\n            expected_dc_provenance.add((model_trace.nodes[f'obs{i}']['cond_indep_stack'], model_trace.nodes[f'obs{i}']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)"
        ]
    },
    {
        "func_name": "nested_model_guide2",
        "original": "def nested_model_guide2(include_obs=True, dim1=3, dim2=2):\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    with pyro.plate('plate1', dim1) as ind:\n        c = pyro.sample('c', dist.Bernoulli(p1).expand_by([len(ind)]))\n        assert c.shape == (dim1,)\n        for i in pyro.plate('plate2', dim2):\n            b_i = pyro.sample('b{}'.format(i), dist.Bernoulli(p0).expand_by([len(ind)]))\n            assert b_i.shape == (dim1,)\n            if include_obs:\n                obs_i = pyro.sample('obs{}'.format(i), dist.Bernoulli(b_i), obs=torch.ones(b_i.size()))\n                assert obs_i.shape == (dim1,)",
        "mutated": [
            "def nested_model_guide2(include_obs=True, dim1=3, dim2=2):\n    if False:\n        i = 10\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    with pyro.plate('plate1', dim1) as ind:\n        c = pyro.sample('c', dist.Bernoulli(p1).expand_by([len(ind)]))\n        assert c.shape == (dim1,)\n        for i in pyro.plate('plate2', dim2):\n            b_i = pyro.sample('b{}'.format(i), dist.Bernoulli(p0).expand_by([len(ind)]))\n            assert b_i.shape == (dim1,)\n            if include_obs:\n                obs_i = pyro.sample('obs{}'.format(i), dist.Bernoulli(b_i), obs=torch.ones(b_i.size()))\n                assert obs_i.shape == (dim1,)",
            "def nested_model_guide2(include_obs=True, dim1=3, dim2=2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    with pyro.plate('plate1', dim1) as ind:\n        c = pyro.sample('c', dist.Bernoulli(p1).expand_by([len(ind)]))\n        assert c.shape == (dim1,)\n        for i in pyro.plate('plate2', dim2):\n            b_i = pyro.sample('b{}'.format(i), dist.Bernoulli(p0).expand_by([len(ind)]))\n            assert b_i.shape == (dim1,)\n            if include_obs:\n                obs_i = pyro.sample('obs{}'.format(i), dist.Bernoulli(b_i), obs=torch.ones(b_i.size()))\n                assert obs_i.shape == (dim1,)",
            "def nested_model_guide2(include_obs=True, dim1=3, dim2=2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    with pyro.plate('plate1', dim1) as ind:\n        c = pyro.sample('c', dist.Bernoulli(p1).expand_by([len(ind)]))\n        assert c.shape == (dim1,)\n        for i in pyro.plate('plate2', dim2):\n            b_i = pyro.sample('b{}'.format(i), dist.Bernoulli(p0).expand_by([len(ind)]))\n            assert b_i.shape == (dim1,)\n            if include_obs:\n                obs_i = pyro.sample('obs{}'.format(i), dist.Bernoulli(b_i), obs=torch.ones(b_i.size()))\n                assert obs_i.shape == (dim1,)",
            "def nested_model_guide2(include_obs=True, dim1=3, dim2=2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    with pyro.plate('plate1', dim1) as ind:\n        c = pyro.sample('c', dist.Bernoulli(p1).expand_by([len(ind)]))\n        assert c.shape == (dim1,)\n        for i in pyro.plate('plate2', dim2):\n            b_i = pyro.sample('b{}'.format(i), dist.Bernoulli(p0).expand_by([len(ind)]))\n            assert b_i.shape == (dim1,)\n            if include_obs:\n                obs_i = pyro.sample('obs{}'.format(i), dist.Bernoulli(b_i), obs=torch.ones(b_i.size()))\n                assert obs_i.shape == (dim1,)",
            "def nested_model_guide2(include_obs=True, dim1=3, dim2=2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    with pyro.plate('plate1', dim1) as ind:\n        c = pyro.sample('c', dist.Bernoulli(p1).expand_by([len(ind)]))\n        assert c.shape == (dim1,)\n        for i in pyro.plate('plate2', dim2):\n            b_i = pyro.sample('b{}'.format(i), dist.Bernoulli(p0).expand_by([len(ind)]))\n            assert b_i.shape == (dim1,)\n            if include_obs:\n                obs_i = pyro.sample('obs{}'.format(i), dist.Bernoulli(b_i), obs=torch.ones(b_i.size()))\n                assert obs_i.shape == (dim1,)"
        ]
    },
    {
        "func_name": "test_compute_downstream_costs_iplate_in_plate",
        "original": "@pytest.mark.parametrize('dim1', [2, 5])\n@pytest.mark.parametrize('dim2', [3, 4])\ndef test_compute_downstream_costs_iplate_in_plate(dim1, dim2):\n    with TrackNonReparam():\n        guide_trace = poutine.trace(nested_model_guide2, graph_type='dense').get_trace(include_obs=False, dim1=dim1, dim2=dim2)\n        model_trace = poutine.trace(poutine.replay(nested_model_guide2, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1, dim2=dim2)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name.startswith('b'):\n            i = int(name[1:])\n            assert nodes == {name, f'obs{i}'}\n        else:\n            assert nodes == {name}\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k.startswith('b'):\n            i = int(k[1:])\n            expected_dc_provenance.add((model_trace.nodes[f'obs{i}']['cond_indep_stack'], model_trace.nodes[f'obs{i}']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += model_trace.nodes['obs1']['log_prob']\n    assert_equal(expected_b1, dc['b1'])\n    expected_c = model_trace.nodes['c']['log_prob'] - guide_trace.nodes['c']['log_prob']\n    for i in range(dim2):\n        expected_c += model_trace.nodes['b{}'.format(i)]['log_prob'] - guide_trace.nodes['b{}'.format(i)]['log_prob']\n        expected_c += model_trace.nodes['obs{}'.format(i)]['log_prob']\n    assert_equal(expected_c, dc['c'])\n    expected_a1 = model_trace.nodes['a1']['log_prob'] - guide_trace.nodes['a1']['log_prob']\n    expected_a1 += expected_c.sum()\n    assert_equal(expected_a1, dc['a1'])",
        "mutated": [
            "@pytest.mark.parametrize('dim1', [2, 5])\n@pytest.mark.parametrize('dim2', [3, 4])\ndef test_compute_downstream_costs_iplate_in_plate(dim1, dim2):\n    if False:\n        i = 10\n    with TrackNonReparam():\n        guide_trace = poutine.trace(nested_model_guide2, graph_type='dense').get_trace(include_obs=False, dim1=dim1, dim2=dim2)\n        model_trace = poutine.trace(poutine.replay(nested_model_guide2, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1, dim2=dim2)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name.startswith('b'):\n            i = int(name[1:])\n            assert nodes == {name, f'obs{i}'}\n        else:\n            assert nodes == {name}\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k.startswith('b'):\n            i = int(k[1:])\n            expected_dc_provenance.add((model_trace.nodes[f'obs{i}']['cond_indep_stack'], model_trace.nodes[f'obs{i}']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += model_trace.nodes['obs1']['log_prob']\n    assert_equal(expected_b1, dc['b1'])\n    expected_c = model_trace.nodes['c']['log_prob'] - guide_trace.nodes['c']['log_prob']\n    for i in range(dim2):\n        expected_c += model_trace.nodes['b{}'.format(i)]['log_prob'] - guide_trace.nodes['b{}'.format(i)]['log_prob']\n        expected_c += model_trace.nodes['obs{}'.format(i)]['log_prob']\n    assert_equal(expected_c, dc['c'])\n    expected_a1 = model_trace.nodes['a1']['log_prob'] - guide_trace.nodes['a1']['log_prob']\n    expected_a1 += expected_c.sum()\n    assert_equal(expected_a1, dc['a1'])",
            "@pytest.mark.parametrize('dim1', [2, 5])\n@pytest.mark.parametrize('dim2', [3, 4])\ndef test_compute_downstream_costs_iplate_in_plate(dim1, dim2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with TrackNonReparam():\n        guide_trace = poutine.trace(nested_model_guide2, graph_type='dense').get_trace(include_obs=False, dim1=dim1, dim2=dim2)\n        model_trace = poutine.trace(poutine.replay(nested_model_guide2, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1, dim2=dim2)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name.startswith('b'):\n            i = int(name[1:])\n            assert nodes == {name, f'obs{i}'}\n        else:\n            assert nodes == {name}\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k.startswith('b'):\n            i = int(k[1:])\n            expected_dc_provenance.add((model_trace.nodes[f'obs{i}']['cond_indep_stack'], model_trace.nodes[f'obs{i}']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += model_trace.nodes['obs1']['log_prob']\n    assert_equal(expected_b1, dc['b1'])\n    expected_c = model_trace.nodes['c']['log_prob'] - guide_trace.nodes['c']['log_prob']\n    for i in range(dim2):\n        expected_c += model_trace.nodes['b{}'.format(i)]['log_prob'] - guide_trace.nodes['b{}'.format(i)]['log_prob']\n        expected_c += model_trace.nodes['obs{}'.format(i)]['log_prob']\n    assert_equal(expected_c, dc['c'])\n    expected_a1 = model_trace.nodes['a1']['log_prob'] - guide_trace.nodes['a1']['log_prob']\n    expected_a1 += expected_c.sum()\n    assert_equal(expected_a1, dc['a1'])",
            "@pytest.mark.parametrize('dim1', [2, 5])\n@pytest.mark.parametrize('dim2', [3, 4])\ndef test_compute_downstream_costs_iplate_in_plate(dim1, dim2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with TrackNonReparam():\n        guide_trace = poutine.trace(nested_model_guide2, graph_type='dense').get_trace(include_obs=False, dim1=dim1, dim2=dim2)\n        model_trace = poutine.trace(poutine.replay(nested_model_guide2, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1, dim2=dim2)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name.startswith('b'):\n            i = int(name[1:])\n            assert nodes == {name, f'obs{i}'}\n        else:\n            assert nodes == {name}\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k.startswith('b'):\n            i = int(k[1:])\n            expected_dc_provenance.add((model_trace.nodes[f'obs{i}']['cond_indep_stack'], model_trace.nodes[f'obs{i}']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += model_trace.nodes['obs1']['log_prob']\n    assert_equal(expected_b1, dc['b1'])\n    expected_c = model_trace.nodes['c']['log_prob'] - guide_trace.nodes['c']['log_prob']\n    for i in range(dim2):\n        expected_c += model_trace.nodes['b{}'.format(i)]['log_prob'] - guide_trace.nodes['b{}'.format(i)]['log_prob']\n        expected_c += model_trace.nodes['obs{}'.format(i)]['log_prob']\n    assert_equal(expected_c, dc['c'])\n    expected_a1 = model_trace.nodes['a1']['log_prob'] - guide_trace.nodes['a1']['log_prob']\n    expected_a1 += expected_c.sum()\n    assert_equal(expected_a1, dc['a1'])",
            "@pytest.mark.parametrize('dim1', [2, 5])\n@pytest.mark.parametrize('dim2', [3, 4])\ndef test_compute_downstream_costs_iplate_in_plate(dim1, dim2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with TrackNonReparam():\n        guide_trace = poutine.trace(nested_model_guide2, graph_type='dense').get_trace(include_obs=False, dim1=dim1, dim2=dim2)\n        model_trace = poutine.trace(poutine.replay(nested_model_guide2, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1, dim2=dim2)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name.startswith('b'):\n            i = int(name[1:])\n            assert nodes == {name, f'obs{i}'}\n        else:\n            assert nodes == {name}\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k.startswith('b'):\n            i = int(k[1:])\n            expected_dc_provenance.add((model_trace.nodes[f'obs{i}']['cond_indep_stack'], model_trace.nodes[f'obs{i}']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += model_trace.nodes['obs1']['log_prob']\n    assert_equal(expected_b1, dc['b1'])\n    expected_c = model_trace.nodes['c']['log_prob'] - guide_trace.nodes['c']['log_prob']\n    for i in range(dim2):\n        expected_c += model_trace.nodes['b{}'.format(i)]['log_prob'] - guide_trace.nodes['b{}'.format(i)]['log_prob']\n        expected_c += model_trace.nodes['obs{}'.format(i)]['log_prob']\n    assert_equal(expected_c, dc['c'])\n    expected_a1 = model_trace.nodes['a1']['log_prob'] - guide_trace.nodes['a1']['log_prob']\n    expected_a1 += expected_c.sum()\n    assert_equal(expected_a1, dc['a1'])",
            "@pytest.mark.parametrize('dim1', [2, 5])\n@pytest.mark.parametrize('dim2', [3, 4])\ndef test_compute_downstream_costs_iplate_in_plate(dim1, dim2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with TrackNonReparam():\n        guide_trace = poutine.trace(nested_model_guide2, graph_type='dense').get_trace(include_obs=False, dim1=dim1, dim2=dim2)\n        model_trace = poutine.trace(poutine.replay(nested_model_guide2, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1, dim2=dim2)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name.startswith('b'):\n            i = int(name[1:])\n            assert nodes == {name, f'obs{i}'}\n        else:\n            assert nodes == {name}\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k.startswith('b'):\n            i = int(k[1:])\n            expected_dc_provenance.add((model_trace.nodes[f'obs{i}']['cond_indep_stack'], model_trace.nodes[f'obs{i}']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)\n    expected_b1 = model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']\n    expected_b1 += model_trace.nodes['obs1']['log_prob']\n    assert_equal(expected_b1, dc['b1'])\n    expected_c = model_trace.nodes['c']['log_prob'] - guide_trace.nodes['c']['log_prob']\n    for i in range(dim2):\n        expected_c += model_trace.nodes['b{}'.format(i)]['log_prob'] - guide_trace.nodes['b{}'.format(i)]['log_prob']\n        expected_c += model_trace.nodes['obs{}'.format(i)]['log_prob']\n    assert_equal(expected_c, dc['c'])\n    expected_a1 = model_trace.nodes['a1']['log_prob'] - guide_trace.nodes['a1']['log_prob']\n    expected_a1 += expected_c.sum()\n    assert_equal(expected_a1, dc['a1'])"
        ]
    },
    {
        "func_name": "plate_reuse_model_guide",
        "original": "def plate_reuse_model_guide(include_obs=True, dim1=3, dim2=2):\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    my_plate1 = pyro.plate('plate1', dim1)\n    my_plate2 = pyro.plate('plate2', dim2)\n    with my_plate1 as ind1:\n        with my_plate2 as ind2:\n            pyro.sample('c1', dist.Bernoulli(p1).expand_by([len(ind2), len(ind1)]))\n    pyro.sample('b1', dist.Bernoulli(p0 * p1))\n    with my_plate2 as ind2:\n        with my_plate1 as ind1:\n            c2 = pyro.sample('c2', dist.Bernoulli(p1).expand_by([len(ind2), len(ind1)]))\n            if include_obs:\n                pyro.sample('obs', dist.Bernoulli(c2), obs=torch.ones(c2.size()))",
        "mutated": [
            "def plate_reuse_model_guide(include_obs=True, dim1=3, dim2=2):\n    if False:\n        i = 10\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    my_plate1 = pyro.plate('plate1', dim1)\n    my_plate2 = pyro.plate('plate2', dim2)\n    with my_plate1 as ind1:\n        with my_plate2 as ind2:\n            pyro.sample('c1', dist.Bernoulli(p1).expand_by([len(ind2), len(ind1)]))\n    pyro.sample('b1', dist.Bernoulli(p0 * p1))\n    with my_plate2 as ind2:\n        with my_plate1 as ind1:\n            c2 = pyro.sample('c2', dist.Bernoulli(p1).expand_by([len(ind2), len(ind1)]))\n            if include_obs:\n                pyro.sample('obs', dist.Bernoulli(c2), obs=torch.ones(c2.size()))",
            "def plate_reuse_model_guide(include_obs=True, dim1=3, dim2=2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    my_plate1 = pyro.plate('plate1', dim1)\n    my_plate2 = pyro.plate('plate2', dim2)\n    with my_plate1 as ind1:\n        with my_plate2 as ind2:\n            pyro.sample('c1', dist.Bernoulli(p1).expand_by([len(ind2), len(ind1)]))\n    pyro.sample('b1', dist.Bernoulli(p0 * p1))\n    with my_plate2 as ind2:\n        with my_plate1 as ind1:\n            c2 = pyro.sample('c2', dist.Bernoulli(p1).expand_by([len(ind2), len(ind1)]))\n            if include_obs:\n                pyro.sample('obs', dist.Bernoulli(c2), obs=torch.ones(c2.size()))",
            "def plate_reuse_model_guide(include_obs=True, dim1=3, dim2=2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    my_plate1 = pyro.plate('plate1', dim1)\n    my_plate2 = pyro.plate('plate2', dim2)\n    with my_plate1 as ind1:\n        with my_plate2 as ind2:\n            pyro.sample('c1', dist.Bernoulli(p1).expand_by([len(ind2), len(ind1)]))\n    pyro.sample('b1', dist.Bernoulli(p0 * p1))\n    with my_plate2 as ind2:\n        with my_plate1 as ind1:\n            c2 = pyro.sample('c2', dist.Bernoulli(p1).expand_by([len(ind2), len(ind1)]))\n            if include_obs:\n                pyro.sample('obs', dist.Bernoulli(c2), obs=torch.ones(c2.size()))",
            "def plate_reuse_model_guide(include_obs=True, dim1=3, dim2=2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    my_plate1 = pyro.plate('plate1', dim1)\n    my_plate2 = pyro.plate('plate2', dim2)\n    with my_plate1 as ind1:\n        with my_plate2 as ind2:\n            pyro.sample('c1', dist.Bernoulli(p1).expand_by([len(ind2), len(ind1)]))\n    pyro.sample('b1', dist.Bernoulli(p0 * p1))\n    with my_plate2 as ind2:\n        with my_plate1 as ind1:\n            c2 = pyro.sample('c2', dist.Bernoulli(p1).expand_by([len(ind2), len(ind1)]))\n            if include_obs:\n                pyro.sample('obs', dist.Bernoulli(c2), obs=torch.ones(c2.size()))",
            "def plate_reuse_model_guide(include_obs=True, dim1=3, dim2=2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    p0 = torch.tensor(math.exp(-0.4 - include_obs * 0.2), requires_grad=True)\n    p1 = torch.tensor(math.exp(-0.33 - include_obs * 0.1), requires_grad=True)\n    pyro.sample('a1', dist.Bernoulli(p0 * p1))\n    my_plate1 = pyro.plate('plate1', dim1)\n    my_plate2 = pyro.plate('plate2', dim2)\n    with my_plate1 as ind1:\n        with my_plate2 as ind2:\n            pyro.sample('c1', dist.Bernoulli(p1).expand_by([len(ind2), len(ind1)]))\n    pyro.sample('b1', dist.Bernoulli(p0 * p1))\n    with my_plate2 as ind2:\n        with my_plate1 as ind1:\n            c2 = pyro.sample('c2', dist.Bernoulli(p1).expand_by([len(ind2), len(ind1)]))\n            if include_obs:\n                pyro.sample('obs', dist.Bernoulli(c2), obs=torch.ones(c2.size()))"
        ]
    },
    {
        "func_name": "test_compute_downstream_costs_plate_reuse",
        "original": "@pytest.mark.parametrize('dim1', [2, 5])\n@pytest.mark.parametrize('dim2', [3, 4])\ndef test_compute_downstream_costs_plate_reuse(dim1, dim2):\n    with TrackNonReparam():\n        guide_trace = poutine.trace(plate_reuse_model_guide, graph_type='dense').get_trace(include_obs=False, dim1=dim1, dim2=dim2)\n        model_trace = poutine.trace(poutine.replay(plate_reuse_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1, dim2=dim2)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name == 'c2':\n            assert nodes == {'c2', 'obs'}\n        else:\n            assert nodes == {name}\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k == 'c2':\n            expected_dc_provenance.add((model_trace.nodes['obs']['cond_indep_stack'], model_trace.nodes['obs']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_c1 += (model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']).sum()\n    expected_c1 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n    expected_c1 += model_trace.nodes['obs']['log_prob']\n    assert_equal(expected_c1, dc['c1'])",
        "mutated": [
            "@pytest.mark.parametrize('dim1', [2, 5])\n@pytest.mark.parametrize('dim2', [3, 4])\ndef test_compute_downstream_costs_plate_reuse(dim1, dim2):\n    if False:\n        i = 10\n    with TrackNonReparam():\n        guide_trace = poutine.trace(plate_reuse_model_guide, graph_type='dense').get_trace(include_obs=False, dim1=dim1, dim2=dim2)\n        model_trace = poutine.trace(poutine.replay(plate_reuse_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1, dim2=dim2)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name == 'c2':\n            assert nodes == {'c2', 'obs'}\n        else:\n            assert nodes == {name}\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k == 'c2':\n            expected_dc_provenance.add((model_trace.nodes['obs']['cond_indep_stack'], model_trace.nodes['obs']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_c1 += (model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']).sum()\n    expected_c1 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n    expected_c1 += model_trace.nodes['obs']['log_prob']\n    assert_equal(expected_c1, dc['c1'])",
            "@pytest.mark.parametrize('dim1', [2, 5])\n@pytest.mark.parametrize('dim2', [3, 4])\ndef test_compute_downstream_costs_plate_reuse(dim1, dim2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    with TrackNonReparam():\n        guide_trace = poutine.trace(plate_reuse_model_guide, graph_type='dense').get_trace(include_obs=False, dim1=dim1, dim2=dim2)\n        model_trace = poutine.trace(poutine.replay(plate_reuse_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1, dim2=dim2)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name == 'c2':\n            assert nodes == {'c2', 'obs'}\n        else:\n            assert nodes == {name}\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k == 'c2':\n            expected_dc_provenance.add((model_trace.nodes['obs']['cond_indep_stack'], model_trace.nodes['obs']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_c1 += (model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']).sum()\n    expected_c1 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n    expected_c1 += model_trace.nodes['obs']['log_prob']\n    assert_equal(expected_c1, dc['c1'])",
            "@pytest.mark.parametrize('dim1', [2, 5])\n@pytest.mark.parametrize('dim2', [3, 4])\ndef test_compute_downstream_costs_plate_reuse(dim1, dim2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    with TrackNonReparam():\n        guide_trace = poutine.trace(plate_reuse_model_guide, graph_type='dense').get_trace(include_obs=False, dim1=dim1, dim2=dim2)\n        model_trace = poutine.trace(poutine.replay(plate_reuse_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1, dim2=dim2)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name == 'c2':\n            assert nodes == {'c2', 'obs'}\n        else:\n            assert nodes == {name}\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k == 'c2':\n            expected_dc_provenance.add((model_trace.nodes['obs']['cond_indep_stack'], model_trace.nodes['obs']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_c1 += (model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']).sum()\n    expected_c1 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n    expected_c1 += model_trace.nodes['obs']['log_prob']\n    assert_equal(expected_c1, dc['c1'])",
            "@pytest.mark.parametrize('dim1', [2, 5])\n@pytest.mark.parametrize('dim2', [3, 4])\ndef test_compute_downstream_costs_plate_reuse(dim1, dim2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    with TrackNonReparam():\n        guide_trace = poutine.trace(plate_reuse_model_guide, graph_type='dense').get_trace(include_obs=False, dim1=dim1, dim2=dim2)\n        model_trace = poutine.trace(poutine.replay(plate_reuse_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1, dim2=dim2)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name == 'c2':\n            assert nodes == {'c2', 'obs'}\n        else:\n            assert nodes == {name}\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k == 'c2':\n            expected_dc_provenance.add((model_trace.nodes['obs']['cond_indep_stack'], model_trace.nodes['obs']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_c1 += (model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']).sum()\n    expected_c1 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n    expected_c1 += model_trace.nodes['obs']['log_prob']\n    assert_equal(expected_c1, dc['c1'])",
            "@pytest.mark.parametrize('dim1', [2, 5])\n@pytest.mark.parametrize('dim2', [3, 4])\ndef test_compute_downstream_costs_plate_reuse(dim1, dim2):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    with TrackNonReparam():\n        guide_trace = poutine.trace(plate_reuse_model_guide, graph_type='dense').get_trace(include_obs=False, dim1=dim1, dim2=dim2)\n        model_trace = poutine.trace(poutine.replay(plate_reuse_model_guide, trace=guide_trace), graph_type='dense').get_trace(include_obs=True, dim1=dim1, dim2=dim2)\n    guide_trace = prune_subsample_sites(guide_trace)\n    model_trace = prune_subsample_sites(model_trace)\n    model_trace.compute_log_prob()\n    guide_trace.compute_log_prob()\n    non_reparam_nodes = set(guide_trace.nonreparam_stochastic_nodes)\n    (dc, dc_nodes) = _compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_brute, dc_nodes_brute) = _brute_force_compute_downstream_costs(model_trace, guide_trace, non_reparam_nodes)\n    (dc_provenance, dc_nodes_provenance) = _provenance_compute_downstream_costs(model_trace, guide_trace)\n    assert dc_nodes == dc_nodes_brute\n    for (name, nodes) in dc_nodes_provenance.items():\n        assert nodes.issubset(dc_nodes[name])\n        if name == 'c2':\n            assert nodes == {'c2', 'obs'}\n        else:\n            assert nodes == {name}\n    for k in dc:\n        assert guide_trace.nodes[k]['log_prob'].size() == dc[k].size()\n        assert_equal(dc[k], dc_brute[k])\n        expected_dc_provenance = MultiFrameTensor((model_trace.nodes[k]['cond_indep_stack'], model_trace.nodes[k]['log_prob']), (guide_trace.nodes[k]['cond_indep_stack'], -guide_trace.nodes[k]['log_prob']))\n        if k == 'c2':\n            expected_dc_provenance.add((model_trace.nodes['obs']['cond_indep_stack'], model_trace.nodes['obs']['log_prob']))\n        expected_dc_provenance = expected_dc_provenance.sum_to(guide_trace.nodes[k]['cond_indep_stack'])\n        assert_equal(dc_provenance[k], expected_dc_provenance)\n    expected_c1 = model_trace.nodes['c1']['log_prob'] - guide_trace.nodes['c1']['log_prob']\n    expected_c1 += (model_trace.nodes['b1']['log_prob'] - guide_trace.nodes['b1']['log_prob']).sum()\n    expected_c1 += model_trace.nodes['c2']['log_prob'] - guide_trace.nodes['c2']['log_prob']\n    expected_c1 += model_trace.nodes['obs']['log_prob']\n    assert_equal(expected_c1, dc['c1'])"
        ]
    }
]