[
    {
        "func_name": "sql_column_api",
        "original": "def sql_column_api(spark):\n    print('Start running SQL column API')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.age.alias('age2')).show()\n    print('alias API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.asc()).show()\n    df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.asc_nulls_first()).show()\n    df.select(df.name).orderBy(df.name.asc_nulls_last()).show()\n    print('asc API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, df.age.between(2, 4)).show()\n    print('between API finished')\n    df = spark.createDataFrame([Row(a=170, b=75)])\n    df.select(df.a.bitwiseAND(df.b)).show()\n    df.select(df.a.bitwiseOR(df.b)).show()\n    df.select(df.a.bitwiseXOR(df.b)).show()\n    print('bitwise API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.age.cast('string').alias('ages')).show()\n    df.filter(df.name.contains('o')).show()\n    print('cast and contains API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.desc()).show()\n    df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.desc_nulls_first()).show()\n    df.select(df.name).orderBy(df.name.desc_nulls_last()).show()\n    print('desc API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.filter(df.name.endswith('ice')).show()\n    df.filter(df.name.startswith('Al')).show()\n    print('with API finished')\n    df1 = spark.createDataFrame([Row(id=1, value='foo'), Row(id=2, value=None)])\n    df1.select(df1['value'] == 'foo', df1['value'].eqNullSafe('foo'), df1['value'].eqNullSafe(None)).show()\n    print('eqNullSafe API finished')\n    df = spark.createDataFrame([Row(r=Row(a=1, b='b'))])\n    df.select(df.r.getField('b')).show()\n    df = spark.createDataFrame([([1, 2], {'key': 'value'})], ['l', 'd'])\n    df.select(df.l.getItem(0), df.d.getItem('key')).show()\n    print('get API finished')\n    df = spark.createDataFrame([Row(name='Tom', height=80), Row(name='Alice', height=None)])\n    df.filter(df.height.isNotNull()).show()\n    df.filter(df.height.isNull()).show()\n    df[df.name.isin('Tom', 'Mike')].show()\n    print('is API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    res = df.filter(df.name.like('Al%')).collect()\n    print(res)\n    res = df.filter(df.name.rlike('ice$')).collect()\n    print(res)\n    print('like API is finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, F.when(df.age > 3, 1).otherwise(0)).show()\n    print('otherwise API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    window = Window.partitionBy('name').orderBy('age').rowsBetween(Window.unboundedPreceding, Window.currentRow)\n    df.withColumn('rank', rank().over(window)).withColumn('min', min('age').over(window)).show()\n    print('over API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    res = df.select(df.name.substr(1, 3).alias('col')).collect()\n    print(res)\n    print('substr API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, F.when(df.age > 4, 1).when(df.age < 3, -1).otherwise(0)).show()\n    print('when API finished')\n    print('Finish running SQL Column API')",
        "mutated": [
            "def sql_column_api(spark):\n    if False:\n        i = 10\n    print('Start running SQL column API')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.age.alias('age2')).show()\n    print('alias API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.asc()).show()\n    df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.asc_nulls_first()).show()\n    df.select(df.name).orderBy(df.name.asc_nulls_last()).show()\n    print('asc API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, df.age.between(2, 4)).show()\n    print('between API finished')\n    df = spark.createDataFrame([Row(a=170, b=75)])\n    df.select(df.a.bitwiseAND(df.b)).show()\n    df.select(df.a.bitwiseOR(df.b)).show()\n    df.select(df.a.bitwiseXOR(df.b)).show()\n    print('bitwise API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.age.cast('string').alias('ages')).show()\n    df.filter(df.name.contains('o')).show()\n    print('cast and contains API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.desc()).show()\n    df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.desc_nulls_first()).show()\n    df.select(df.name).orderBy(df.name.desc_nulls_last()).show()\n    print('desc API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.filter(df.name.endswith('ice')).show()\n    df.filter(df.name.startswith('Al')).show()\n    print('with API finished')\n    df1 = spark.createDataFrame([Row(id=1, value='foo'), Row(id=2, value=None)])\n    df1.select(df1['value'] == 'foo', df1['value'].eqNullSafe('foo'), df1['value'].eqNullSafe(None)).show()\n    print('eqNullSafe API finished')\n    df = spark.createDataFrame([Row(r=Row(a=1, b='b'))])\n    df.select(df.r.getField('b')).show()\n    df = spark.createDataFrame([([1, 2], {'key': 'value'})], ['l', 'd'])\n    df.select(df.l.getItem(0), df.d.getItem('key')).show()\n    print('get API finished')\n    df = spark.createDataFrame([Row(name='Tom', height=80), Row(name='Alice', height=None)])\n    df.filter(df.height.isNotNull()).show()\n    df.filter(df.height.isNull()).show()\n    df[df.name.isin('Tom', 'Mike')].show()\n    print('is API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    res = df.filter(df.name.like('Al%')).collect()\n    print(res)\n    res = df.filter(df.name.rlike('ice$')).collect()\n    print(res)\n    print('like API is finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, F.when(df.age > 3, 1).otherwise(0)).show()\n    print('otherwise API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    window = Window.partitionBy('name').orderBy('age').rowsBetween(Window.unboundedPreceding, Window.currentRow)\n    df.withColumn('rank', rank().over(window)).withColumn('min', min('age').over(window)).show()\n    print('over API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    res = df.select(df.name.substr(1, 3).alias('col')).collect()\n    print(res)\n    print('substr API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, F.when(df.age > 4, 1).when(df.age < 3, -1).otherwise(0)).show()\n    print('when API finished')\n    print('Finish running SQL Column API')",
            "def sql_column_api(spark):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    print('Start running SQL column API')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.age.alias('age2')).show()\n    print('alias API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.asc()).show()\n    df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.asc_nulls_first()).show()\n    df.select(df.name).orderBy(df.name.asc_nulls_last()).show()\n    print('asc API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, df.age.between(2, 4)).show()\n    print('between API finished')\n    df = spark.createDataFrame([Row(a=170, b=75)])\n    df.select(df.a.bitwiseAND(df.b)).show()\n    df.select(df.a.bitwiseOR(df.b)).show()\n    df.select(df.a.bitwiseXOR(df.b)).show()\n    print('bitwise API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.age.cast('string').alias('ages')).show()\n    df.filter(df.name.contains('o')).show()\n    print('cast and contains API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.desc()).show()\n    df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.desc_nulls_first()).show()\n    df.select(df.name).orderBy(df.name.desc_nulls_last()).show()\n    print('desc API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.filter(df.name.endswith('ice')).show()\n    df.filter(df.name.startswith('Al')).show()\n    print('with API finished')\n    df1 = spark.createDataFrame([Row(id=1, value='foo'), Row(id=2, value=None)])\n    df1.select(df1['value'] == 'foo', df1['value'].eqNullSafe('foo'), df1['value'].eqNullSafe(None)).show()\n    print('eqNullSafe API finished')\n    df = spark.createDataFrame([Row(r=Row(a=1, b='b'))])\n    df.select(df.r.getField('b')).show()\n    df = spark.createDataFrame([([1, 2], {'key': 'value'})], ['l', 'd'])\n    df.select(df.l.getItem(0), df.d.getItem('key')).show()\n    print('get API finished')\n    df = spark.createDataFrame([Row(name='Tom', height=80), Row(name='Alice', height=None)])\n    df.filter(df.height.isNotNull()).show()\n    df.filter(df.height.isNull()).show()\n    df[df.name.isin('Tom', 'Mike')].show()\n    print('is API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    res = df.filter(df.name.like('Al%')).collect()\n    print(res)\n    res = df.filter(df.name.rlike('ice$')).collect()\n    print(res)\n    print('like API is finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, F.when(df.age > 3, 1).otherwise(0)).show()\n    print('otherwise API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    window = Window.partitionBy('name').orderBy('age').rowsBetween(Window.unboundedPreceding, Window.currentRow)\n    df.withColumn('rank', rank().over(window)).withColumn('min', min('age').over(window)).show()\n    print('over API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    res = df.select(df.name.substr(1, 3).alias('col')).collect()\n    print(res)\n    print('substr API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, F.when(df.age > 4, 1).when(df.age < 3, -1).otherwise(0)).show()\n    print('when API finished')\n    print('Finish running SQL Column API')",
            "def sql_column_api(spark):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    print('Start running SQL column API')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.age.alias('age2')).show()\n    print('alias API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.asc()).show()\n    df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.asc_nulls_first()).show()\n    df.select(df.name).orderBy(df.name.asc_nulls_last()).show()\n    print('asc API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, df.age.between(2, 4)).show()\n    print('between API finished')\n    df = spark.createDataFrame([Row(a=170, b=75)])\n    df.select(df.a.bitwiseAND(df.b)).show()\n    df.select(df.a.bitwiseOR(df.b)).show()\n    df.select(df.a.bitwiseXOR(df.b)).show()\n    print('bitwise API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.age.cast('string').alias('ages')).show()\n    df.filter(df.name.contains('o')).show()\n    print('cast and contains API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.desc()).show()\n    df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.desc_nulls_first()).show()\n    df.select(df.name).orderBy(df.name.desc_nulls_last()).show()\n    print('desc API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.filter(df.name.endswith('ice')).show()\n    df.filter(df.name.startswith('Al')).show()\n    print('with API finished')\n    df1 = spark.createDataFrame([Row(id=1, value='foo'), Row(id=2, value=None)])\n    df1.select(df1['value'] == 'foo', df1['value'].eqNullSafe('foo'), df1['value'].eqNullSafe(None)).show()\n    print('eqNullSafe API finished')\n    df = spark.createDataFrame([Row(r=Row(a=1, b='b'))])\n    df.select(df.r.getField('b')).show()\n    df = spark.createDataFrame([([1, 2], {'key': 'value'})], ['l', 'd'])\n    df.select(df.l.getItem(0), df.d.getItem('key')).show()\n    print('get API finished')\n    df = spark.createDataFrame([Row(name='Tom', height=80), Row(name='Alice', height=None)])\n    df.filter(df.height.isNotNull()).show()\n    df.filter(df.height.isNull()).show()\n    df[df.name.isin('Tom', 'Mike')].show()\n    print('is API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    res = df.filter(df.name.like('Al%')).collect()\n    print(res)\n    res = df.filter(df.name.rlike('ice$')).collect()\n    print(res)\n    print('like API is finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, F.when(df.age > 3, 1).otherwise(0)).show()\n    print('otherwise API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    window = Window.partitionBy('name').orderBy('age').rowsBetween(Window.unboundedPreceding, Window.currentRow)\n    df.withColumn('rank', rank().over(window)).withColumn('min', min('age').over(window)).show()\n    print('over API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    res = df.select(df.name.substr(1, 3).alias('col')).collect()\n    print(res)\n    print('substr API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, F.when(df.age > 4, 1).when(df.age < 3, -1).otherwise(0)).show()\n    print('when API finished')\n    print('Finish running SQL Column API')",
            "def sql_column_api(spark):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    print('Start running SQL column API')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.age.alias('age2')).show()\n    print('alias API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.asc()).show()\n    df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.asc_nulls_first()).show()\n    df.select(df.name).orderBy(df.name.asc_nulls_last()).show()\n    print('asc API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, df.age.between(2, 4)).show()\n    print('between API finished')\n    df = spark.createDataFrame([Row(a=170, b=75)])\n    df.select(df.a.bitwiseAND(df.b)).show()\n    df.select(df.a.bitwiseOR(df.b)).show()\n    df.select(df.a.bitwiseXOR(df.b)).show()\n    print('bitwise API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.age.cast('string').alias('ages')).show()\n    df.filter(df.name.contains('o')).show()\n    print('cast and contains API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.desc()).show()\n    df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.desc_nulls_first()).show()\n    df.select(df.name).orderBy(df.name.desc_nulls_last()).show()\n    print('desc API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.filter(df.name.endswith('ice')).show()\n    df.filter(df.name.startswith('Al')).show()\n    print('with API finished')\n    df1 = spark.createDataFrame([Row(id=1, value='foo'), Row(id=2, value=None)])\n    df1.select(df1['value'] == 'foo', df1['value'].eqNullSafe('foo'), df1['value'].eqNullSafe(None)).show()\n    print('eqNullSafe API finished')\n    df = spark.createDataFrame([Row(r=Row(a=1, b='b'))])\n    df.select(df.r.getField('b')).show()\n    df = spark.createDataFrame([([1, 2], {'key': 'value'})], ['l', 'd'])\n    df.select(df.l.getItem(0), df.d.getItem('key')).show()\n    print('get API finished')\n    df = spark.createDataFrame([Row(name='Tom', height=80), Row(name='Alice', height=None)])\n    df.filter(df.height.isNotNull()).show()\n    df.filter(df.height.isNull()).show()\n    df[df.name.isin('Tom', 'Mike')].show()\n    print('is API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    res = df.filter(df.name.like('Al%')).collect()\n    print(res)\n    res = df.filter(df.name.rlike('ice$')).collect()\n    print(res)\n    print('like API is finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, F.when(df.age > 3, 1).otherwise(0)).show()\n    print('otherwise API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    window = Window.partitionBy('name').orderBy('age').rowsBetween(Window.unboundedPreceding, Window.currentRow)\n    df.withColumn('rank', rank().over(window)).withColumn('min', min('age').over(window)).show()\n    print('over API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    res = df.select(df.name.substr(1, 3).alias('col')).collect()\n    print(res)\n    print('substr API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, F.when(df.age > 4, 1).when(df.age < 3, -1).otherwise(0)).show()\n    print('when API finished')\n    print('Finish running SQL Column API')",
            "def sql_column_api(spark):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    print('Start running SQL column API')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.age.alias('age2')).show()\n    print('alias API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.asc()).show()\n    df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.asc_nulls_first()).show()\n    df.select(df.name).orderBy(df.name.asc_nulls_last()).show()\n    print('asc API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, df.age.between(2, 4)).show()\n    print('between API finished')\n    df = spark.createDataFrame([Row(a=170, b=75)])\n    df.select(df.a.bitwiseAND(df.b)).show()\n    df.select(df.a.bitwiseOR(df.b)).show()\n    df.select(df.a.bitwiseXOR(df.b)).show()\n    print('bitwise API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.age.cast('string').alias('ages')).show()\n    df.filter(df.name.contains('o')).show()\n    print('cast and contains API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.desc()).show()\n    df = spark.createDataFrame([('Tom', 80), (None, 60), ('Alice', None)], ['name', 'height'])\n    df.select(df.name).orderBy(df.name.desc_nulls_first()).show()\n    df.select(df.name).orderBy(df.name.desc_nulls_last()).show()\n    print('desc API finished')\n    df = spark.createDataFrame([('Tom', 80), ('Alice', None)], ['name', 'height'])\n    df.filter(df.name.endswith('ice')).show()\n    df.filter(df.name.startswith('Al')).show()\n    print('with API finished')\n    df1 = spark.createDataFrame([Row(id=1, value='foo'), Row(id=2, value=None)])\n    df1.select(df1['value'] == 'foo', df1['value'].eqNullSafe('foo'), df1['value'].eqNullSafe(None)).show()\n    print('eqNullSafe API finished')\n    df = spark.createDataFrame([Row(r=Row(a=1, b='b'))])\n    df.select(df.r.getField('b')).show()\n    df = spark.createDataFrame([([1, 2], {'key': 'value'})], ['l', 'd'])\n    df.select(df.l.getItem(0), df.d.getItem('key')).show()\n    print('get API finished')\n    df = spark.createDataFrame([Row(name='Tom', height=80), Row(name='Alice', height=None)])\n    df.filter(df.height.isNotNull()).show()\n    df.filter(df.height.isNull()).show()\n    df[df.name.isin('Tom', 'Mike')].show()\n    print('is API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    res = df.filter(df.name.like('Al%')).collect()\n    print(res)\n    res = df.filter(df.name.rlike('ice$')).collect()\n    print(res)\n    print('like API is finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, F.when(df.age > 3, 1).otherwise(0)).show()\n    print('otherwise API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    window = Window.partitionBy('name').orderBy('age').rowsBetween(Window.unboundedPreceding, Window.currentRow)\n    df.withColumn('rank', rank().over(window)).withColumn('min', min('age').over(window)).show()\n    print('over API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    res = df.select(df.name.substr(1, 3).alias('col')).collect()\n    print(res)\n    print('substr API finished')\n    df = spark.createDataFrame([(2, 'Alice'), (5, 'Bob')], ['age', 'name'])\n    df.select(df.name, F.when(df.age > 4, 1).when(df.age < 3, -1).otherwise(0)).show()\n    print('when API finished')\n    print('Finish running SQL Column API')"
        ]
    }
]