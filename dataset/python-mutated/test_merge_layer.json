[
    {
        "func_name": "pytest_generate_tests",
        "original": "def pytest_generate_tests(metafunc):\n    fargs = []\n    eps = np.finfo(np.float32).eps\n    w_rng = [[-1.0, 1.0]]\n    rng_max = [eps]\n    fargs = itt.product(w_rng, rng_max)\n    metafunc.parametrize('allrand_args', fargs)",
        "mutated": [
            "def pytest_generate_tests(metafunc):\n    if False:\n        i = 10\n    fargs = []\n    eps = np.finfo(np.float32).eps\n    w_rng = [[-1.0, 1.0]]\n    rng_max = [eps]\n    fargs = itt.product(w_rng, rng_max)\n    metafunc.parametrize('allrand_args', fargs)",
            "def pytest_generate_tests(metafunc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    fargs = []\n    eps = np.finfo(np.float32).eps\n    w_rng = [[-1.0, 1.0]]\n    rng_max = [eps]\n    fargs = itt.product(w_rng, rng_max)\n    metafunc.parametrize('allrand_args', fargs)",
            "def pytest_generate_tests(metafunc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    fargs = []\n    eps = np.finfo(np.float32).eps\n    w_rng = [[-1.0, 1.0]]\n    rng_max = [eps]\n    fargs = itt.product(w_rng, rng_max)\n    metafunc.parametrize('allrand_args', fargs)",
            "def pytest_generate_tests(metafunc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    fargs = []\n    eps = np.finfo(np.float32).eps\n    w_rng = [[-1.0, 1.0]]\n    rng_max = [eps]\n    fargs = itt.product(w_rng, rng_max)\n    metafunc.parametrize('allrand_args', fargs)",
            "def pytest_generate_tests(metafunc):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    fargs = []\n    eps = np.finfo(np.float32).eps\n    w_rng = [[-1.0, 1.0]]\n    rng_max = [eps]\n    fargs = itt.product(w_rng, rng_max)\n    metafunc.parametrize('allrand_args', fargs)"
        ]
    },
    {
        "func_name": "test_concat_l1_l1",
        "original": "def test_concat_l1_l1(backend_default, allrand_args, deltas_buffer):\n    dtypeu = np.float32\n    (w_rng, rngmax) = allrand_args\n    nins = [128, 1024]\n    nouts = [64, 2048]\n    batch_size = 16\n    NervanaObject.be.bsz = batch_size\n    be = NervanaObject.be\n    init_unif = Uniform(low=w_rng[0], high=w_rng[1])\n    layers = [Sequential(Affine(nout=nout, init=init_unif)) for nout in nouts]\n    inputs = [be.array(dtypeu(np.random.random((nin, batch_size)))) for nin in nins]\n    merge = MergeMultistream(layers, merge='stack')\n    assert len(inputs) == len(layers)\n    merge.configure(inputs)\n    merge.allocate()\n    merge.allocate_deltas(deltas_buffer)\n    deltas_buffer.allocate_buffers()\n    merge.set_deltas(deltas_buffer)\n    out = merge.fprop(inputs).get()\n    sublayers = [s.layers[0] for s in layers]\n    weights = [layer.W.get() for layer in sublayers]\n    out_exp = np.concatenate([np.dot(w, inp.get()) for (w, inp) in zip(weights, inputs)])\n    assert allclose_with_out(out, out_exp, atol=0.001)\n    err_lst = [dtypeu(np.random.random((nout, batch_size))) for nout in nouts]\n    err_concat = np.concatenate(err_lst)\n    merge.bprop(be.array(err_concat))\n    dW_exp_lst = [np.dot(err, inp.get().T) for (err, inp) in zip(err_lst, inputs)]\n    for (layer, dW_exp) in zip(sublayers, dW_exp_lst):\n        assert allclose_with_out(layer.dW.get(), dW_exp)\n    return",
        "mutated": [
            "def test_concat_l1_l1(backend_default, allrand_args, deltas_buffer):\n    if False:\n        i = 10\n    dtypeu = np.float32\n    (w_rng, rngmax) = allrand_args\n    nins = [128, 1024]\n    nouts = [64, 2048]\n    batch_size = 16\n    NervanaObject.be.bsz = batch_size\n    be = NervanaObject.be\n    init_unif = Uniform(low=w_rng[0], high=w_rng[1])\n    layers = [Sequential(Affine(nout=nout, init=init_unif)) for nout in nouts]\n    inputs = [be.array(dtypeu(np.random.random((nin, batch_size)))) for nin in nins]\n    merge = MergeMultistream(layers, merge='stack')\n    assert len(inputs) == len(layers)\n    merge.configure(inputs)\n    merge.allocate()\n    merge.allocate_deltas(deltas_buffer)\n    deltas_buffer.allocate_buffers()\n    merge.set_deltas(deltas_buffer)\n    out = merge.fprop(inputs).get()\n    sublayers = [s.layers[0] for s in layers]\n    weights = [layer.W.get() for layer in sublayers]\n    out_exp = np.concatenate([np.dot(w, inp.get()) for (w, inp) in zip(weights, inputs)])\n    assert allclose_with_out(out, out_exp, atol=0.001)\n    err_lst = [dtypeu(np.random.random((nout, batch_size))) for nout in nouts]\n    err_concat = np.concatenate(err_lst)\n    merge.bprop(be.array(err_concat))\n    dW_exp_lst = [np.dot(err, inp.get().T) for (err, inp) in zip(err_lst, inputs)]\n    for (layer, dW_exp) in zip(sublayers, dW_exp_lst):\n        assert allclose_with_out(layer.dW.get(), dW_exp)\n    return",
            "def test_concat_l1_l1(backend_default, allrand_args, deltas_buffer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    dtypeu = np.float32\n    (w_rng, rngmax) = allrand_args\n    nins = [128, 1024]\n    nouts = [64, 2048]\n    batch_size = 16\n    NervanaObject.be.bsz = batch_size\n    be = NervanaObject.be\n    init_unif = Uniform(low=w_rng[0], high=w_rng[1])\n    layers = [Sequential(Affine(nout=nout, init=init_unif)) for nout in nouts]\n    inputs = [be.array(dtypeu(np.random.random((nin, batch_size)))) for nin in nins]\n    merge = MergeMultistream(layers, merge='stack')\n    assert len(inputs) == len(layers)\n    merge.configure(inputs)\n    merge.allocate()\n    merge.allocate_deltas(deltas_buffer)\n    deltas_buffer.allocate_buffers()\n    merge.set_deltas(deltas_buffer)\n    out = merge.fprop(inputs).get()\n    sublayers = [s.layers[0] for s in layers]\n    weights = [layer.W.get() for layer in sublayers]\n    out_exp = np.concatenate([np.dot(w, inp.get()) for (w, inp) in zip(weights, inputs)])\n    assert allclose_with_out(out, out_exp, atol=0.001)\n    err_lst = [dtypeu(np.random.random((nout, batch_size))) for nout in nouts]\n    err_concat = np.concatenate(err_lst)\n    merge.bprop(be.array(err_concat))\n    dW_exp_lst = [np.dot(err, inp.get().T) for (err, inp) in zip(err_lst, inputs)]\n    for (layer, dW_exp) in zip(sublayers, dW_exp_lst):\n        assert allclose_with_out(layer.dW.get(), dW_exp)\n    return",
            "def test_concat_l1_l1(backend_default, allrand_args, deltas_buffer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    dtypeu = np.float32\n    (w_rng, rngmax) = allrand_args\n    nins = [128, 1024]\n    nouts = [64, 2048]\n    batch_size = 16\n    NervanaObject.be.bsz = batch_size\n    be = NervanaObject.be\n    init_unif = Uniform(low=w_rng[0], high=w_rng[1])\n    layers = [Sequential(Affine(nout=nout, init=init_unif)) for nout in nouts]\n    inputs = [be.array(dtypeu(np.random.random((nin, batch_size)))) for nin in nins]\n    merge = MergeMultistream(layers, merge='stack')\n    assert len(inputs) == len(layers)\n    merge.configure(inputs)\n    merge.allocate()\n    merge.allocate_deltas(deltas_buffer)\n    deltas_buffer.allocate_buffers()\n    merge.set_deltas(deltas_buffer)\n    out = merge.fprop(inputs).get()\n    sublayers = [s.layers[0] for s in layers]\n    weights = [layer.W.get() for layer in sublayers]\n    out_exp = np.concatenate([np.dot(w, inp.get()) for (w, inp) in zip(weights, inputs)])\n    assert allclose_with_out(out, out_exp, atol=0.001)\n    err_lst = [dtypeu(np.random.random((nout, batch_size))) for nout in nouts]\n    err_concat = np.concatenate(err_lst)\n    merge.bprop(be.array(err_concat))\n    dW_exp_lst = [np.dot(err, inp.get().T) for (err, inp) in zip(err_lst, inputs)]\n    for (layer, dW_exp) in zip(sublayers, dW_exp_lst):\n        assert allclose_with_out(layer.dW.get(), dW_exp)\n    return",
            "def test_concat_l1_l1(backend_default, allrand_args, deltas_buffer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    dtypeu = np.float32\n    (w_rng, rngmax) = allrand_args\n    nins = [128, 1024]\n    nouts = [64, 2048]\n    batch_size = 16\n    NervanaObject.be.bsz = batch_size\n    be = NervanaObject.be\n    init_unif = Uniform(low=w_rng[0], high=w_rng[1])\n    layers = [Sequential(Affine(nout=nout, init=init_unif)) for nout in nouts]\n    inputs = [be.array(dtypeu(np.random.random((nin, batch_size)))) for nin in nins]\n    merge = MergeMultistream(layers, merge='stack')\n    assert len(inputs) == len(layers)\n    merge.configure(inputs)\n    merge.allocate()\n    merge.allocate_deltas(deltas_buffer)\n    deltas_buffer.allocate_buffers()\n    merge.set_deltas(deltas_buffer)\n    out = merge.fprop(inputs).get()\n    sublayers = [s.layers[0] for s in layers]\n    weights = [layer.W.get() for layer in sublayers]\n    out_exp = np.concatenate([np.dot(w, inp.get()) for (w, inp) in zip(weights, inputs)])\n    assert allclose_with_out(out, out_exp, atol=0.001)\n    err_lst = [dtypeu(np.random.random((nout, batch_size))) for nout in nouts]\n    err_concat = np.concatenate(err_lst)\n    merge.bprop(be.array(err_concat))\n    dW_exp_lst = [np.dot(err, inp.get().T) for (err, inp) in zip(err_lst, inputs)]\n    for (layer, dW_exp) in zip(sublayers, dW_exp_lst):\n        assert allclose_with_out(layer.dW.get(), dW_exp)\n    return",
            "def test_concat_l1_l1(backend_default, allrand_args, deltas_buffer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    dtypeu = np.float32\n    (w_rng, rngmax) = allrand_args\n    nins = [128, 1024]\n    nouts = [64, 2048]\n    batch_size = 16\n    NervanaObject.be.bsz = batch_size\n    be = NervanaObject.be\n    init_unif = Uniform(low=w_rng[0], high=w_rng[1])\n    layers = [Sequential(Affine(nout=nout, init=init_unif)) for nout in nouts]\n    inputs = [be.array(dtypeu(np.random.random((nin, batch_size)))) for nin in nins]\n    merge = MergeMultistream(layers, merge='stack')\n    assert len(inputs) == len(layers)\n    merge.configure(inputs)\n    merge.allocate()\n    merge.allocate_deltas(deltas_buffer)\n    deltas_buffer.allocate_buffers()\n    merge.set_deltas(deltas_buffer)\n    out = merge.fprop(inputs).get()\n    sublayers = [s.layers[0] for s in layers]\n    weights = [layer.W.get() for layer in sublayers]\n    out_exp = np.concatenate([np.dot(w, inp.get()) for (w, inp) in zip(weights, inputs)])\n    assert allclose_with_out(out, out_exp, atol=0.001)\n    err_lst = [dtypeu(np.random.random((nout, batch_size))) for nout in nouts]\n    err_concat = np.concatenate(err_lst)\n    merge.bprop(be.array(err_concat))\n    dW_exp_lst = [np.dot(err, inp.get().T) for (err, inp) in zip(err_lst, inputs)]\n    for (layer, dW_exp) in zip(sublayers, dW_exp_lst):\n        assert allclose_with_out(layer.dW.get(), dW_exp)\n    return"
        ]
    },
    {
        "func_name": "test_concat_sequence_l1_l1",
        "original": "def test_concat_sequence_l1_l1(backend_default, allrand_args, deltas_buffer):\n    dtypeu = np.float32\n    (w_rng, rngmax) = allrand_args\n    nin = 128\n    steps = [32, 64]\n    nout = 256\n    batch_size = 16\n    NervanaObject.be.bsz = batch_size\n    be = NervanaObject.be\n    init_unif = Uniform(low=w_rng[0], high=w_rng[1])\n    layers = [Sequential(Affine(nout=nout, init=init_unif)) for _ in (0, 1)]\n    inputs = [be.array(dtypeu(np.random.random((nin, batch_size * step)))) for step in steps]\n    merge = MergeMultistream(layers, merge='recurrent')\n    assert len(inputs) == len(layers)\n    merge.configure(inputs)\n    merge.allocate()\n    merge.allocate_deltas(deltas_buffer)\n    deltas_buffer.allocate_buffers()\n    merge.set_deltas(deltas_buffer)\n    out = merge.fprop(inputs).get()\n    sublayers = [s.layers[0] for s in layers]\n    weights = [layer.W.get() for layer in sublayers]\n    out_exp = np.concatenate([np.dot(w, inp.get()) for (w, inp) in zip(weights, inputs)], axis=1)\n    assert allclose_with_out(out, out_exp, atol=0.001)\n    err_lst = [dtypeu(np.random.random((nout, batch_size * step))) for step in steps]\n    err_concat = be.array(np.concatenate(err_lst, axis=1))\n    merge.bprop(err_concat)\n    dW_exp_lst = [np.dot(err, inp.get().T) for (err, inp) in zip(err_lst, inputs)]\n    for (layer, dW_exp) in zip(sublayers, dW_exp_lst):\n        assert allclose_with_out(layer.dW.get(), dW_exp)\n    return",
        "mutated": [
            "def test_concat_sequence_l1_l1(backend_default, allrand_args, deltas_buffer):\n    if False:\n        i = 10\n    dtypeu = np.float32\n    (w_rng, rngmax) = allrand_args\n    nin = 128\n    steps = [32, 64]\n    nout = 256\n    batch_size = 16\n    NervanaObject.be.bsz = batch_size\n    be = NervanaObject.be\n    init_unif = Uniform(low=w_rng[0], high=w_rng[1])\n    layers = [Sequential(Affine(nout=nout, init=init_unif)) for _ in (0, 1)]\n    inputs = [be.array(dtypeu(np.random.random((nin, batch_size * step)))) for step in steps]\n    merge = MergeMultistream(layers, merge='recurrent')\n    assert len(inputs) == len(layers)\n    merge.configure(inputs)\n    merge.allocate()\n    merge.allocate_deltas(deltas_buffer)\n    deltas_buffer.allocate_buffers()\n    merge.set_deltas(deltas_buffer)\n    out = merge.fprop(inputs).get()\n    sublayers = [s.layers[0] for s in layers]\n    weights = [layer.W.get() for layer in sublayers]\n    out_exp = np.concatenate([np.dot(w, inp.get()) for (w, inp) in zip(weights, inputs)], axis=1)\n    assert allclose_with_out(out, out_exp, atol=0.001)\n    err_lst = [dtypeu(np.random.random((nout, batch_size * step))) for step in steps]\n    err_concat = be.array(np.concatenate(err_lst, axis=1))\n    merge.bprop(err_concat)\n    dW_exp_lst = [np.dot(err, inp.get().T) for (err, inp) in zip(err_lst, inputs)]\n    for (layer, dW_exp) in zip(sublayers, dW_exp_lst):\n        assert allclose_with_out(layer.dW.get(), dW_exp)\n    return",
            "def test_concat_sequence_l1_l1(backend_default, allrand_args, deltas_buffer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    dtypeu = np.float32\n    (w_rng, rngmax) = allrand_args\n    nin = 128\n    steps = [32, 64]\n    nout = 256\n    batch_size = 16\n    NervanaObject.be.bsz = batch_size\n    be = NervanaObject.be\n    init_unif = Uniform(low=w_rng[0], high=w_rng[1])\n    layers = [Sequential(Affine(nout=nout, init=init_unif)) for _ in (0, 1)]\n    inputs = [be.array(dtypeu(np.random.random((nin, batch_size * step)))) for step in steps]\n    merge = MergeMultistream(layers, merge='recurrent')\n    assert len(inputs) == len(layers)\n    merge.configure(inputs)\n    merge.allocate()\n    merge.allocate_deltas(deltas_buffer)\n    deltas_buffer.allocate_buffers()\n    merge.set_deltas(deltas_buffer)\n    out = merge.fprop(inputs).get()\n    sublayers = [s.layers[0] for s in layers]\n    weights = [layer.W.get() for layer in sublayers]\n    out_exp = np.concatenate([np.dot(w, inp.get()) for (w, inp) in zip(weights, inputs)], axis=1)\n    assert allclose_with_out(out, out_exp, atol=0.001)\n    err_lst = [dtypeu(np.random.random((nout, batch_size * step))) for step in steps]\n    err_concat = be.array(np.concatenate(err_lst, axis=1))\n    merge.bprop(err_concat)\n    dW_exp_lst = [np.dot(err, inp.get().T) for (err, inp) in zip(err_lst, inputs)]\n    for (layer, dW_exp) in zip(sublayers, dW_exp_lst):\n        assert allclose_with_out(layer.dW.get(), dW_exp)\n    return",
            "def test_concat_sequence_l1_l1(backend_default, allrand_args, deltas_buffer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    dtypeu = np.float32\n    (w_rng, rngmax) = allrand_args\n    nin = 128\n    steps = [32, 64]\n    nout = 256\n    batch_size = 16\n    NervanaObject.be.bsz = batch_size\n    be = NervanaObject.be\n    init_unif = Uniform(low=w_rng[0], high=w_rng[1])\n    layers = [Sequential(Affine(nout=nout, init=init_unif)) for _ in (0, 1)]\n    inputs = [be.array(dtypeu(np.random.random((nin, batch_size * step)))) for step in steps]\n    merge = MergeMultistream(layers, merge='recurrent')\n    assert len(inputs) == len(layers)\n    merge.configure(inputs)\n    merge.allocate()\n    merge.allocate_deltas(deltas_buffer)\n    deltas_buffer.allocate_buffers()\n    merge.set_deltas(deltas_buffer)\n    out = merge.fprop(inputs).get()\n    sublayers = [s.layers[0] for s in layers]\n    weights = [layer.W.get() for layer in sublayers]\n    out_exp = np.concatenate([np.dot(w, inp.get()) for (w, inp) in zip(weights, inputs)], axis=1)\n    assert allclose_with_out(out, out_exp, atol=0.001)\n    err_lst = [dtypeu(np.random.random((nout, batch_size * step))) for step in steps]\n    err_concat = be.array(np.concatenate(err_lst, axis=1))\n    merge.bprop(err_concat)\n    dW_exp_lst = [np.dot(err, inp.get().T) for (err, inp) in zip(err_lst, inputs)]\n    for (layer, dW_exp) in zip(sublayers, dW_exp_lst):\n        assert allclose_with_out(layer.dW.get(), dW_exp)\n    return",
            "def test_concat_sequence_l1_l1(backend_default, allrand_args, deltas_buffer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    dtypeu = np.float32\n    (w_rng, rngmax) = allrand_args\n    nin = 128\n    steps = [32, 64]\n    nout = 256\n    batch_size = 16\n    NervanaObject.be.bsz = batch_size\n    be = NervanaObject.be\n    init_unif = Uniform(low=w_rng[0], high=w_rng[1])\n    layers = [Sequential(Affine(nout=nout, init=init_unif)) for _ in (0, 1)]\n    inputs = [be.array(dtypeu(np.random.random((nin, batch_size * step)))) for step in steps]\n    merge = MergeMultistream(layers, merge='recurrent')\n    assert len(inputs) == len(layers)\n    merge.configure(inputs)\n    merge.allocate()\n    merge.allocate_deltas(deltas_buffer)\n    deltas_buffer.allocate_buffers()\n    merge.set_deltas(deltas_buffer)\n    out = merge.fprop(inputs).get()\n    sublayers = [s.layers[0] for s in layers]\n    weights = [layer.W.get() for layer in sublayers]\n    out_exp = np.concatenate([np.dot(w, inp.get()) for (w, inp) in zip(weights, inputs)], axis=1)\n    assert allclose_with_out(out, out_exp, atol=0.001)\n    err_lst = [dtypeu(np.random.random((nout, batch_size * step))) for step in steps]\n    err_concat = be.array(np.concatenate(err_lst, axis=1))\n    merge.bprop(err_concat)\n    dW_exp_lst = [np.dot(err, inp.get().T) for (err, inp) in zip(err_lst, inputs)]\n    for (layer, dW_exp) in zip(sublayers, dW_exp_lst):\n        assert allclose_with_out(layer.dW.get(), dW_exp)\n    return",
            "def test_concat_sequence_l1_l1(backend_default, allrand_args, deltas_buffer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    dtypeu = np.float32\n    (w_rng, rngmax) = allrand_args\n    nin = 128\n    steps = [32, 64]\n    nout = 256\n    batch_size = 16\n    NervanaObject.be.bsz = batch_size\n    be = NervanaObject.be\n    init_unif = Uniform(low=w_rng[0], high=w_rng[1])\n    layers = [Sequential(Affine(nout=nout, init=init_unif)) for _ in (0, 1)]\n    inputs = [be.array(dtypeu(np.random.random((nin, batch_size * step)))) for step in steps]\n    merge = MergeMultistream(layers, merge='recurrent')\n    assert len(inputs) == len(layers)\n    merge.configure(inputs)\n    merge.allocate()\n    merge.allocate_deltas(deltas_buffer)\n    deltas_buffer.allocate_buffers()\n    merge.set_deltas(deltas_buffer)\n    out = merge.fprop(inputs).get()\n    sublayers = [s.layers[0] for s in layers]\n    weights = [layer.W.get() for layer in sublayers]\n    out_exp = np.concatenate([np.dot(w, inp.get()) for (w, inp) in zip(weights, inputs)], axis=1)\n    assert allclose_with_out(out, out_exp, atol=0.001)\n    err_lst = [dtypeu(np.random.random((nout, batch_size * step))) for step in steps]\n    err_concat = be.array(np.concatenate(err_lst, axis=1))\n    merge.bprop(err_concat)\n    dW_exp_lst = [np.dot(err, inp.get().T) for (err, inp) in zip(err_lst, inputs)]\n    for (layer, dW_exp) in zip(sublayers, dW_exp_lst):\n        assert allclose_with_out(layer.dW.get(), dW_exp)\n    return"
        ]
    }
]