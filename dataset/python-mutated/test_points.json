[
    {
        "func_name": "test_base_points",
        "original": "def test_base_points():\n    empty_boxes = []\n    points = BasePoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    base_points = BasePoints(points_np, points_dim=3)\n    assert base_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    base_points = BasePoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], base_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], base_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], base_points.color)\n    assert torch.allclose(expected_tensor[:, 6], base_points.height)\n    new_base_points = base_points.clone()\n    assert torch.allclose(new_base_points.tensor, base_points.tensor)\n    new_base_points.shuffle()\n    assert new_base_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    base_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.001)\n    new_base_points = base_points.clone()\n    new_base_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_base_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    base_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = base_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    base_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, base_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, base_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, base_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, base_points[:, 3].tensor, 0.0001)\n    assert len(base_points) == 4\n    expected_repr = 'BasePoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(base_points)\n    base_points_clone = base_points.clone()\n    cat_points = BasePoints.cat([base_points, base_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(base_points)], base_points.tensor)\n    for (i, point) in enumerate(base_points):\n        assert torch.allclose(point, base_points.tensor[i])\n    new_points = base_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=base_points.tensor.dtype))\n    base_points = BasePoints(points_np, points_dim=7, attribute_dims=dict(height=3, color=[4, 5, 6]))\n    assert torch.all(base_points[:, 3:].tensor == torch.tensor(points_np[:, 3:]))\n    base_points = BasePoints(points_np[:, :3])\n    assert base_points.attribute_dims is None\n    base_points.height = points_np[:, 3]\n    assert base_points.attribute_dims == dict(height=3)\n    base_points.color = points_np[:, 4:]\n    assert base_points.attribute_dims == dict(height=3, color=[4, 5, 6])\n    assert torch.allclose(base_points.height, torch.tensor([0.6666, 0.1502, 0.6565, 0.2803]))\n    assert torch.allclose(base_points.color, torch.tensor([[0.1956, 0.4974, 0.9409], [0.3707, 0.1086, 0.6297], [0.6248, 0.6954, 0.2538], [0.0258, 0.4896, 0.3269]]))\n    with pytest.raises(ValueError):\n        base_points.coord = np.random.rand(5, 3)\n    with pytest.raises(ValueError):\n        base_points.height = np.random.rand(3)\n    with pytest.raises(ValueError):\n        base_points.color = np.random.rand(4, 2)\n    base_points.coord = points_np[:, [1, 2, 3]]\n    base_points.height = points_np[:, 0]\n    base_points.color = points_np[:, [4, 5, 6]]\n    assert np.allclose(base_points.coord, points_np[:, 1:4])\n    assert np.allclose(base_points.height, points_np[:, 0])\n    assert np.allclose(base_points.color, points_np[:, 4:])",
        "mutated": [
            "def test_base_points():\n    if False:\n        i = 10\n    empty_boxes = []\n    points = BasePoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    base_points = BasePoints(points_np, points_dim=3)\n    assert base_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    base_points = BasePoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], base_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], base_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], base_points.color)\n    assert torch.allclose(expected_tensor[:, 6], base_points.height)\n    new_base_points = base_points.clone()\n    assert torch.allclose(new_base_points.tensor, base_points.tensor)\n    new_base_points.shuffle()\n    assert new_base_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    base_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.001)\n    new_base_points = base_points.clone()\n    new_base_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_base_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    base_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = base_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    base_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, base_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, base_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, base_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, base_points[:, 3].tensor, 0.0001)\n    assert len(base_points) == 4\n    expected_repr = 'BasePoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(base_points)\n    base_points_clone = base_points.clone()\n    cat_points = BasePoints.cat([base_points, base_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(base_points)], base_points.tensor)\n    for (i, point) in enumerate(base_points):\n        assert torch.allclose(point, base_points.tensor[i])\n    new_points = base_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=base_points.tensor.dtype))\n    base_points = BasePoints(points_np, points_dim=7, attribute_dims=dict(height=3, color=[4, 5, 6]))\n    assert torch.all(base_points[:, 3:].tensor == torch.tensor(points_np[:, 3:]))\n    base_points = BasePoints(points_np[:, :3])\n    assert base_points.attribute_dims is None\n    base_points.height = points_np[:, 3]\n    assert base_points.attribute_dims == dict(height=3)\n    base_points.color = points_np[:, 4:]\n    assert base_points.attribute_dims == dict(height=3, color=[4, 5, 6])\n    assert torch.allclose(base_points.height, torch.tensor([0.6666, 0.1502, 0.6565, 0.2803]))\n    assert torch.allclose(base_points.color, torch.tensor([[0.1956, 0.4974, 0.9409], [0.3707, 0.1086, 0.6297], [0.6248, 0.6954, 0.2538], [0.0258, 0.4896, 0.3269]]))\n    with pytest.raises(ValueError):\n        base_points.coord = np.random.rand(5, 3)\n    with pytest.raises(ValueError):\n        base_points.height = np.random.rand(3)\n    with pytest.raises(ValueError):\n        base_points.color = np.random.rand(4, 2)\n    base_points.coord = points_np[:, [1, 2, 3]]\n    base_points.height = points_np[:, 0]\n    base_points.color = points_np[:, [4, 5, 6]]\n    assert np.allclose(base_points.coord, points_np[:, 1:4])\n    assert np.allclose(base_points.height, points_np[:, 0])\n    assert np.allclose(base_points.color, points_np[:, 4:])",
            "def test_base_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    empty_boxes = []\n    points = BasePoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    base_points = BasePoints(points_np, points_dim=3)\n    assert base_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    base_points = BasePoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], base_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], base_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], base_points.color)\n    assert torch.allclose(expected_tensor[:, 6], base_points.height)\n    new_base_points = base_points.clone()\n    assert torch.allclose(new_base_points.tensor, base_points.tensor)\n    new_base_points.shuffle()\n    assert new_base_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    base_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.001)\n    new_base_points = base_points.clone()\n    new_base_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_base_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    base_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = base_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    base_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, base_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, base_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, base_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, base_points[:, 3].tensor, 0.0001)\n    assert len(base_points) == 4\n    expected_repr = 'BasePoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(base_points)\n    base_points_clone = base_points.clone()\n    cat_points = BasePoints.cat([base_points, base_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(base_points)], base_points.tensor)\n    for (i, point) in enumerate(base_points):\n        assert torch.allclose(point, base_points.tensor[i])\n    new_points = base_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=base_points.tensor.dtype))\n    base_points = BasePoints(points_np, points_dim=7, attribute_dims=dict(height=3, color=[4, 5, 6]))\n    assert torch.all(base_points[:, 3:].tensor == torch.tensor(points_np[:, 3:]))\n    base_points = BasePoints(points_np[:, :3])\n    assert base_points.attribute_dims is None\n    base_points.height = points_np[:, 3]\n    assert base_points.attribute_dims == dict(height=3)\n    base_points.color = points_np[:, 4:]\n    assert base_points.attribute_dims == dict(height=3, color=[4, 5, 6])\n    assert torch.allclose(base_points.height, torch.tensor([0.6666, 0.1502, 0.6565, 0.2803]))\n    assert torch.allclose(base_points.color, torch.tensor([[0.1956, 0.4974, 0.9409], [0.3707, 0.1086, 0.6297], [0.6248, 0.6954, 0.2538], [0.0258, 0.4896, 0.3269]]))\n    with pytest.raises(ValueError):\n        base_points.coord = np.random.rand(5, 3)\n    with pytest.raises(ValueError):\n        base_points.height = np.random.rand(3)\n    with pytest.raises(ValueError):\n        base_points.color = np.random.rand(4, 2)\n    base_points.coord = points_np[:, [1, 2, 3]]\n    base_points.height = points_np[:, 0]\n    base_points.color = points_np[:, [4, 5, 6]]\n    assert np.allclose(base_points.coord, points_np[:, 1:4])\n    assert np.allclose(base_points.height, points_np[:, 0])\n    assert np.allclose(base_points.color, points_np[:, 4:])",
            "def test_base_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    empty_boxes = []\n    points = BasePoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    base_points = BasePoints(points_np, points_dim=3)\n    assert base_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    base_points = BasePoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], base_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], base_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], base_points.color)\n    assert torch.allclose(expected_tensor[:, 6], base_points.height)\n    new_base_points = base_points.clone()\n    assert torch.allclose(new_base_points.tensor, base_points.tensor)\n    new_base_points.shuffle()\n    assert new_base_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    base_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.001)\n    new_base_points = base_points.clone()\n    new_base_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_base_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    base_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = base_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    base_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, base_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, base_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, base_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, base_points[:, 3].tensor, 0.0001)\n    assert len(base_points) == 4\n    expected_repr = 'BasePoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(base_points)\n    base_points_clone = base_points.clone()\n    cat_points = BasePoints.cat([base_points, base_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(base_points)], base_points.tensor)\n    for (i, point) in enumerate(base_points):\n        assert torch.allclose(point, base_points.tensor[i])\n    new_points = base_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=base_points.tensor.dtype))\n    base_points = BasePoints(points_np, points_dim=7, attribute_dims=dict(height=3, color=[4, 5, 6]))\n    assert torch.all(base_points[:, 3:].tensor == torch.tensor(points_np[:, 3:]))\n    base_points = BasePoints(points_np[:, :3])\n    assert base_points.attribute_dims is None\n    base_points.height = points_np[:, 3]\n    assert base_points.attribute_dims == dict(height=3)\n    base_points.color = points_np[:, 4:]\n    assert base_points.attribute_dims == dict(height=3, color=[4, 5, 6])\n    assert torch.allclose(base_points.height, torch.tensor([0.6666, 0.1502, 0.6565, 0.2803]))\n    assert torch.allclose(base_points.color, torch.tensor([[0.1956, 0.4974, 0.9409], [0.3707, 0.1086, 0.6297], [0.6248, 0.6954, 0.2538], [0.0258, 0.4896, 0.3269]]))\n    with pytest.raises(ValueError):\n        base_points.coord = np.random.rand(5, 3)\n    with pytest.raises(ValueError):\n        base_points.height = np.random.rand(3)\n    with pytest.raises(ValueError):\n        base_points.color = np.random.rand(4, 2)\n    base_points.coord = points_np[:, [1, 2, 3]]\n    base_points.height = points_np[:, 0]\n    base_points.color = points_np[:, [4, 5, 6]]\n    assert np.allclose(base_points.coord, points_np[:, 1:4])\n    assert np.allclose(base_points.height, points_np[:, 0])\n    assert np.allclose(base_points.color, points_np[:, 4:])",
            "def test_base_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    empty_boxes = []\n    points = BasePoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    base_points = BasePoints(points_np, points_dim=3)\n    assert base_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    base_points = BasePoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], base_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], base_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], base_points.color)\n    assert torch.allclose(expected_tensor[:, 6], base_points.height)\n    new_base_points = base_points.clone()\n    assert torch.allclose(new_base_points.tensor, base_points.tensor)\n    new_base_points.shuffle()\n    assert new_base_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    base_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.001)\n    new_base_points = base_points.clone()\n    new_base_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_base_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    base_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = base_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    base_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, base_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, base_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, base_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, base_points[:, 3].tensor, 0.0001)\n    assert len(base_points) == 4\n    expected_repr = 'BasePoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(base_points)\n    base_points_clone = base_points.clone()\n    cat_points = BasePoints.cat([base_points, base_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(base_points)], base_points.tensor)\n    for (i, point) in enumerate(base_points):\n        assert torch.allclose(point, base_points.tensor[i])\n    new_points = base_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=base_points.tensor.dtype))\n    base_points = BasePoints(points_np, points_dim=7, attribute_dims=dict(height=3, color=[4, 5, 6]))\n    assert torch.all(base_points[:, 3:].tensor == torch.tensor(points_np[:, 3:]))\n    base_points = BasePoints(points_np[:, :3])\n    assert base_points.attribute_dims is None\n    base_points.height = points_np[:, 3]\n    assert base_points.attribute_dims == dict(height=3)\n    base_points.color = points_np[:, 4:]\n    assert base_points.attribute_dims == dict(height=3, color=[4, 5, 6])\n    assert torch.allclose(base_points.height, torch.tensor([0.6666, 0.1502, 0.6565, 0.2803]))\n    assert torch.allclose(base_points.color, torch.tensor([[0.1956, 0.4974, 0.9409], [0.3707, 0.1086, 0.6297], [0.6248, 0.6954, 0.2538], [0.0258, 0.4896, 0.3269]]))\n    with pytest.raises(ValueError):\n        base_points.coord = np.random.rand(5, 3)\n    with pytest.raises(ValueError):\n        base_points.height = np.random.rand(3)\n    with pytest.raises(ValueError):\n        base_points.color = np.random.rand(4, 2)\n    base_points.coord = points_np[:, [1, 2, 3]]\n    base_points.height = points_np[:, 0]\n    base_points.color = points_np[:, [4, 5, 6]]\n    assert np.allclose(base_points.coord, points_np[:, 1:4])\n    assert np.allclose(base_points.height, points_np[:, 0])\n    assert np.allclose(base_points.color, points_np[:, 4:])",
            "def test_base_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    empty_boxes = []\n    points = BasePoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    base_points = BasePoints(points_np, points_dim=3)\n    assert base_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    base_points = BasePoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], base_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], base_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], base_points.color)\n    assert torch.allclose(expected_tensor[:, 6], base_points.height)\n    new_base_points = base_points.clone()\n    assert torch.allclose(new_base_points.tensor, base_points.tensor)\n    new_base_points.shuffle()\n    assert new_base_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    base_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.001)\n    new_base_points = base_points.clone()\n    new_base_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_base_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    base_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = base_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    base_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, base_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, base_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, base_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, base_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, base_points[:, 3].tensor, 0.0001)\n    assert len(base_points) == 4\n    expected_repr = 'BasePoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(base_points)\n    base_points_clone = base_points.clone()\n    cat_points = BasePoints.cat([base_points, base_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(base_points)], base_points.tensor)\n    for (i, point) in enumerate(base_points):\n        assert torch.allclose(point, base_points.tensor[i])\n    new_points = base_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=base_points.tensor.dtype))\n    base_points = BasePoints(points_np, points_dim=7, attribute_dims=dict(height=3, color=[4, 5, 6]))\n    assert torch.all(base_points[:, 3:].tensor == torch.tensor(points_np[:, 3:]))\n    base_points = BasePoints(points_np[:, :3])\n    assert base_points.attribute_dims is None\n    base_points.height = points_np[:, 3]\n    assert base_points.attribute_dims == dict(height=3)\n    base_points.color = points_np[:, 4:]\n    assert base_points.attribute_dims == dict(height=3, color=[4, 5, 6])\n    assert torch.allclose(base_points.height, torch.tensor([0.6666, 0.1502, 0.6565, 0.2803]))\n    assert torch.allclose(base_points.color, torch.tensor([[0.1956, 0.4974, 0.9409], [0.3707, 0.1086, 0.6297], [0.6248, 0.6954, 0.2538], [0.0258, 0.4896, 0.3269]]))\n    with pytest.raises(ValueError):\n        base_points.coord = np.random.rand(5, 3)\n    with pytest.raises(ValueError):\n        base_points.height = np.random.rand(3)\n    with pytest.raises(ValueError):\n        base_points.color = np.random.rand(4, 2)\n    base_points.coord = points_np[:, [1, 2, 3]]\n    base_points.height = points_np[:, 0]\n    base_points.color = points_np[:, [4, 5, 6]]\n    assert np.allclose(base_points.coord, points_np[:, 1:4])\n    assert np.allclose(base_points.height, points_np[:, 0])\n    assert np.allclose(base_points.color, points_np[:, 4:])"
        ]
    },
    {
        "func_name": "test_cam_points",
        "original": "def test_cam_points():\n    empty_boxes = []\n    points = CameraPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    cam_points = CameraPoints(points_np, points_dim=3)\n    assert cam_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    cam_points = CameraPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor)\n    assert torch.allclose(expected_tensor[:, [0, 2]], cam_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], cam_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], cam_points.color)\n    assert torch.allclose(expected_tensor[:, 6], cam_points.height)\n    new_cam_points = cam_points.clone()\n    assert torch.allclose(new_cam_points.tensor, cam_points.tensor)\n    new_cam_points.shuffle()\n    assert new_cam_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    cam_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.001)\n    new_cam_points = cam_points.clone()\n    new_cam_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_cam_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    cam_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = cam_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    cam_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, cam_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, cam_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, cam_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, cam_points[:, 3].tensor, 0.0001)\n    assert len(cam_points) == 4\n    expected_repr = 'CameraPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(cam_points)\n    cam_points_clone = cam_points.clone()\n    cat_points = CameraPoints.cat([cam_points, cam_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(cam_points)], cam_points.tensor)\n    for (i, point) in enumerate(cam_points):\n        assert torch.allclose(point, cam_points.tensor[i])\n    new_points = cam_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=cam_points.tensor.dtype))\n    point_bev_range = [-10, -10, 10, 10]\n    in_range_flags = cam_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    cam_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)\n    cam_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, 2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, 8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, 2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, 8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)",
        "mutated": [
            "def test_cam_points():\n    if False:\n        i = 10\n    empty_boxes = []\n    points = CameraPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    cam_points = CameraPoints(points_np, points_dim=3)\n    assert cam_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    cam_points = CameraPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor)\n    assert torch.allclose(expected_tensor[:, [0, 2]], cam_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], cam_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], cam_points.color)\n    assert torch.allclose(expected_tensor[:, 6], cam_points.height)\n    new_cam_points = cam_points.clone()\n    assert torch.allclose(new_cam_points.tensor, cam_points.tensor)\n    new_cam_points.shuffle()\n    assert new_cam_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    cam_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.001)\n    new_cam_points = cam_points.clone()\n    new_cam_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_cam_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    cam_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = cam_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    cam_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, cam_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, cam_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, cam_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, cam_points[:, 3].tensor, 0.0001)\n    assert len(cam_points) == 4\n    expected_repr = 'CameraPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(cam_points)\n    cam_points_clone = cam_points.clone()\n    cat_points = CameraPoints.cat([cam_points, cam_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(cam_points)], cam_points.tensor)\n    for (i, point) in enumerate(cam_points):\n        assert torch.allclose(point, cam_points.tensor[i])\n    new_points = cam_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=cam_points.tensor.dtype))\n    point_bev_range = [-10, -10, 10, 10]\n    in_range_flags = cam_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    cam_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)\n    cam_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, 2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, 8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, 2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, 8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)",
            "def test_cam_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    empty_boxes = []\n    points = CameraPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    cam_points = CameraPoints(points_np, points_dim=3)\n    assert cam_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    cam_points = CameraPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor)\n    assert torch.allclose(expected_tensor[:, [0, 2]], cam_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], cam_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], cam_points.color)\n    assert torch.allclose(expected_tensor[:, 6], cam_points.height)\n    new_cam_points = cam_points.clone()\n    assert torch.allclose(new_cam_points.tensor, cam_points.tensor)\n    new_cam_points.shuffle()\n    assert new_cam_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    cam_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.001)\n    new_cam_points = cam_points.clone()\n    new_cam_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_cam_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    cam_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = cam_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    cam_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, cam_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, cam_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, cam_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, cam_points[:, 3].tensor, 0.0001)\n    assert len(cam_points) == 4\n    expected_repr = 'CameraPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(cam_points)\n    cam_points_clone = cam_points.clone()\n    cat_points = CameraPoints.cat([cam_points, cam_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(cam_points)], cam_points.tensor)\n    for (i, point) in enumerate(cam_points):\n        assert torch.allclose(point, cam_points.tensor[i])\n    new_points = cam_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=cam_points.tensor.dtype))\n    point_bev_range = [-10, -10, 10, 10]\n    in_range_flags = cam_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    cam_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)\n    cam_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, 2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, 8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, 2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, 8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)",
            "def test_cam_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    empty_boxes = []\n    points = CameraPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    cam_points = CameraPoints(points_np, points_dim=3)\n    assert cam_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    cam_points = CameraPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor)\n    assert torch.allclose(expected_tensor[:, [0, 2]], cam_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], cam_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], cam_points.color)\n    assert torch.allclose(expected_tensor[:, 6], cam_points.height)\n    new_cam_points = cam_points.clone()\n    assert torch.allclose(new_cam_points.tensor, cam_points.tensor)\n    new_cam_points.shuffle()\n    assert new_cam_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    cam_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.001)\n    new_cam_points = cam_points.clone()\n    new_cam_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_cam_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    cam_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = cam_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    cam_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, cam_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, cam_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, cam_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, cam_points[:, 3].tensor, 0.0001)\n    assert len(cam_points) == 4\n    expected_repr = 'CameraPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(cam_points)\n    cam_points_clone = cam_points.clone()\n    cat_points = CameraPoints.cat([cam_points, cam_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(cam_points)], cam_points.tensor)\n    for (i, point) in enumerate(cam_points):\n        assert torch.allclose(point, cam_points.tensor[i])\n    new_points = cam_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=cam_points.tensor.dtype))\n    point_bev_range = [-10, -10, 10, 10]\n    in_range_flags = cam_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    cam_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)\n    cam_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, 2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, 8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, 2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, 8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)",
            "def test_cam_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    empty_boxes = []\n    points = CameraPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    cam_points = CameraPoints(points_np, points_dim=3)\n    assert cam_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    cam_points = CameraPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor)\n    assert torch.allclose(expected_tensor[:, [0, 2]], cam_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], cam_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], cam_points.color)\n    assert torch.allclose(expected_tensor[:, 6], cam_points.height)\n    new_cam_points = cam_points.clone()\n    assert torch.allclose(new_cam_points.tensor, cam_points.tensor)\n    new_cam_points.shuffle()\n    assert new_cam_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    cam_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.001)\n    new_cam_points = cam_points.clone()\n    new_cam_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_cam_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    cam_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = cam_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    cam_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, cam_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, cam_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, cam_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, cam_points[:, 3].tensor, 0.0001)\n    assert len(cam_points) == 4\n    expected_repr = 'CameraPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(cam_points)\n    cam_points_clone = cam_points.clone()\n    cat_points = CameraPoints.cat([cam_points, cam_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(cam_points)], cam_points.tensor)\n    for (i, point) in enumerate(cam_points):\n        assert torch.allclose(point, cam_points.tensor[i])\n    new_points = cam_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=cam_points.tensor.dtype))\n    point_bev_range = [-10, -10, 10, 10]\n    in_range_flags = cam_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    cam_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)\n    cam_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, 2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, 8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, 2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, 8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)",
            "def test_cam_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    empty_boxes = []\n    points = CameraPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    cam_points = CameraPoints(points_np, points_dim=3)\n    assert cam_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    cam_points = CameraPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor)\n    assert torch.allclose(expected_tensor[:, [0, 2]], cam_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], cam_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], cam_points.color)\n    assert torch.allclose(expected_tensor[:, 6], cam_points.height)\n    new_cam_points = cam_points.clone()\n    assert torch.allclose(new_cam_points.tensor, cam_points.tensor)\n    new_cam_points.shuffle()\n    assert new_cam_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    cam_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.001)\n    new_cam_points = cam_points.clone()\n    new_cam_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_cam_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    cam_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = cam_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    cam_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, cam_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, cam_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, cam_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, cam_points[:, 3].tensor, 0.0001)\n    assert len(cam_points) == 4\n    expected_repr = 'CameraPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(cam_points)\n    cam_points_clone = cam_points.clone()\n    cat_points = CameraPoints.cat([cam_points, cam_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(cam_points)], cam_points.tensor)\n    for (i, point) in enumerate(cam_points):\n        assert torch.allclose(point, cam_points.tensor[i])\n    new_points = cam_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=cam_points.tensor.dtype))\n    point_bev_range = [-10, -10, 10, 10]\n    in_range_flags = cam_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    cam_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)\n    cam_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, 2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, 8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, 2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, 8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, cam_points.tensor, 0.0001)"
        ]
    },
    {
        "func_name": "test_lidar_points",
        "original": "def test_lidar_points():\n    empty_boxes = []\n    points = LiDARPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    lidar_points = LiDARPoints(points_np, points_dim=3)\n    assert lidar_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    lidar_points = LiDARPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], lidar_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], lidar_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], lidar_points.color)\n    assert torch.allclose(expected_tensor[:, 6], lidar_points.height)\n    new_lidar_points = lidar_points.clone()\n    assert torch.allclose(new_lidar_points.tensor, lidar_points.tensor)\n    new_lidar_points.shuffle()\n    assert new_lidar_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    lidar_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.001)\n    new_lidar_points = lidar_points.clone()\n    new_lidar_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_lidar_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    lidar_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = lidar_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    lidar_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, lidar_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, lidar_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, lidar_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, lidar_points[:, 3].tensor, 0.0001)\n    assert len(lidar_points) == 4\n    expected_repr = 'LiDARPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(lidar_points)\n    lidar_points_clone = lidar_points.clone()\n    cat_points = LiDARPoints.cat([lidar_points, lidar_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(lidar_points)], lidar_points.tensor)\n    for (i, point) in enumerate(lidar_points):\n        assert torch.allclose(point, lidar_points.tensor[i])\n    new_points = lidar_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=lidar_points.tensor.dtype))\n    point_bev_range = [-30, -40, 30, 40]\n    in_range_flags = lidar_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([False, True, False, False])\n    assert torch.all(in_range_flags == expected_flags)\n    lidar_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)\n    lidar_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)",
        "mutated": [
            "def test_lidar_points():\n    if False:\n        i = 10\n    empty_boxes = []\n    points = LiDARPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    lidar_points = LiDARPoints(points_np, points_dim=3)\n    assert lidar_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    lidar_points = LiDARPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], lidar_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], lidar_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], lidar_points.color)\n    assert torch.allclose(expected_tensor[:, 6], lidar_points.height)\n    new_lidar_points = lidar_points.clone()\n    assert torch.allclose(new_lidar_points.tensor, lidar_points.tensor)\n    new_lidar_points.shuffle()\n    assert new_lidar_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    lidar_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.001)\n    new_lidar_points = lidar_points.clone()\n    new_lidar_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_lidar_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    lidar_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = lidar_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    lidar_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, lidar_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, lidar_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, lidar_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, lidar_points[:, 3].tensor, 0.0001)\n    assert len(lidar_points) == 4\n    expected_repr = 'LiDARPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(lidar_points)\n    lidar_points_clone = lidar_points.clone()\n    cat_points = LiDARPoints.cat([lidar_points, lidar_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(lidar_points)], lidar_points.tensor)\n    for (i, point) in enumerate(lidar_points):\n        assert torch.allclose(point, lidar_points.tensor[i])\n    new_points = lidar_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=lidar_points.tensor.dtype))\n    point_bev_range = [-30, -40, 30, 40]\n    in_range_flags = lidar_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([False, True, False, False])\n    assert torch.all(in_range_flags == expected_flags)\n    lidar_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)\n    lidar_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)",
            "def test_lidar_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    empty_boxes = []\n    points = LiDARPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    lidar_points = LiDARPoints(points_np, points_dim=3)\n    assert lidar_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    lidar_points = LiDARPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], lidar_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], lidar_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], lidar_points.color)\n    assert torch.allclose(expected_tensor[:, 6], lidar_points.height)\n    new_lidar_points = lidar_points.clone()\n    assert torch.allclose(new_lidar_points.tensor, lidar_points.tensor)\n    new_lidar_points.shuffle()\n    assert new_lidar_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    lidar_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.001)\n    new_lidar_points = lidar_points.clone()\n    new_lidar_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_lidar_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    lidar_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = lidar_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    lidar_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, lidar_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, lidar_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, lidar_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, lidar_points[:, 3].tensor, 0.0001)\n    assert len(lidar_points) == 4\n    expected_repr = 'LiDARPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(lidar_points)\n    lidar_points_clone = lidar_points.clone()\n    cat_points = LiDARPoints.cat([lidar_points, lidar_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(lidar_points)], lidar_points.tensor)\n    for (i, point) in enumerate(lidar_points):\n        assert torch.allclose(point, lidar_points.tensor[i])\n    new_points = lidar_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=lidar_points.tensor.dtype))\n    point_bev_range = [-30, -40, 30, 40]\n    in_range_flags = lidar_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([False, True, False, False])\n    assert torch.all(in_range_flags == expected_flags)\n    lidar_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)\n    lidar_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)",
            "def test_lidar_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    empty_boxes = []\n    points = LiDARPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    lidar_points = LiDARPoints(points_np, points_dim=3)\n    assert lidar_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    lidar_points = LiDARPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], lidar_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], lidar_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], lidar_points.color)\n    assert torch.allclose(expected_tensor[:, 6], lidar_points.height)\n    new_lidar_points = lidar_points.clone()\n    assert torch.allclose(new_lidar_points.tensor, lidar_points.tensor)\n    new_lidar_points.shuffle()\n    assert new_lidar_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    lidar_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.001)\n    new_lidar_points = lidar_points.clone()\n    new_lidar_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_lidar_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    lidar_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = lidar_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    lidar_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, lidar_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, lidar_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, lidar_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, lidar_points[:, 3].tensor, 0.0001)\n    assert len(lidar_points) == 4\n    expected_repr = 'LiDARPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(lidar_points)\n    lidar_points_clone = lidar_points.clone()\n    cat_points = LiDARPoints.cat([lidar_points, lidar_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(lidar_points)], lidar_points.tensor)\n    for (i, point) in enumerate(lidar_points):\n        assert torch.allclose(point, lidar_points.tensor[i])\n    new_points = lidar_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=lidar_points.tensor.dtype))\n    point_bev_range = [-30, -40, 30, 40]\n    in_range_flags = lidar_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([False, True, False, False])\n    assert torch.all(in_range_flags == expected_flags)\n    lidar_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)\n    lidar_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)",
            "def test_lidar_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    empty_boxes = []\n    points = LiDARPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    lidar_points = LiDARPoints(points_np, points_dim=3)\n    assert lidar_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    lidar_points = LiDARPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], lidar_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], lidar_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], lidar_points.color)\n    assert torch.allclose(expected_tensor[:, 6], lidar_points.height)\n    new_lidar_points = lidar_points.clone()\n    assert torch.allclose(new_lidar_points.tensor, lidar_points.tensor)\n    new_lidar_points.shuffle()\n    assert new_lidar_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    lidar_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.001)\n    new_lidar_points = lidar_points.clone()\n    new_lidar_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_lidar_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    lidar_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = lidar_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    lidar_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, lidar_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, lidar_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, lidar_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, lidar_points[:, 3].tensor, 0.0001)\n    assert len(lidar_points) == 4\n    expected_repr = 'LiDARPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(lidar_points)\n    lidar_points_clone = lidar_points.clone()\n    cat_points = LiDARPoints.cat([lidar_points, lidar_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(lidar_points)], lidar_points.tensor)\n    for (i, point) in enumerate(lidar_points):\n        assert torch.allclose(point, lidar_points.tensor[i])\n    new_points = lidar_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=lidar_points.tensor.dtype))\n    point_bev_range = [-30, -40, 30, 40]\n    in_range_flags = lidar_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([False, True, False, False])\n    assert torch.all(in_range_flags == expected_flags)\n    lidar_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)\n    lidar_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)",
            "def test_lidar_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    empty_boxes = []\n    points = LiDARPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    lidar_points = LiDARPoints(points_np, points_dim=3)\n    assert lidar_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    lidar_points = LiDARPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], lidar_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], lidar_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], lidar_points.color)\n    assert torch.allclose(expected_tensor[:, 6], lidar_points.height)\n    new_lidar_points = lidar_points.clone()\n    assert torch.allclose(new_lidar_points.tensor, lidar_points.tensor)\n    new_lidar_points.shuffle()\n    assert new_lidar_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    lidar_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.001)\n    new_lidar_points = lidar_points.clone()\n    new_lidar_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_lidar_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    lidar_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = lidar_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    lidar_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, lidar_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, lidar_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, lidar_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, lidar_points[:, 3].tensor, 0.0001)\n    assert len(lidar_points) == 4\n    expected_repr = 'LiDARPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(lidar_points)\n    lidar_points_clone = lidar_points.clone()\n    cat_points = LiDARPoints.cat([lidar_points, lidar_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(lidar_points)], lidar_points.tensor)\n    for (i, point) in enumerate(lidar_points):\n        assert torch.allclose(point, lidar_points.tensor[i])\n    new_points = lidar_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=lidar_points.tensor.dtype))\n    point_bev_range = [-30, -40, 30, 40]\n    in_range_flags = lidar_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([False, True, False, False])\n    assert torch.all(in_range_flags == expected_flags)\n    lidar_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)\n    lidar_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, lidar_points.tensor, 0.0001)"
        ]
    },
    {
        "func_name": "test_depth_points",
        "original": "def test_depth_points():\n    empty_boxes = []\n    points = DepthPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    depth_points = DepthPoints(points_np, points_dim=3)\n    assert depth_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    depth_points = DepthPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], depth_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], depth_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], depth_points.color)\n    assert torch.allclose(expected_tensor[:, 6], depth_points.height)\n    new_depth_points = depth_points.clone()\n    assert torch.allclose(new_depth_points.tensor, depth_points.tensor)\n    new_depth_points.shuffle()\n    assert new_depth_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    depth_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.001)\n    new_depth_points = depth_points.clone()\n    new_depth_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_depth_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    depth_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = depth_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    depth_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, depth_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, depth_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, depth_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, depth_points[:, 3].tensor, 0.0001)\n    assert len(depth_points) == 4\n    expected_repr = 'DepthPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(depth_points)\n    depth_points_clone = depth_points.clone()\n    cat_points = DepthPoints.cat([depth_points, depth_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(depth_points)], depth_points.tensor)\n    for (i, point) in enumerate(depth_points):\n        assert torch.allclose(point, depth_points.tensor[i])\n    new_points = depth_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=depth_points.tensor.dtype))\n    point_bev_range = [-30, -40, 30, 40]\n    in_range_flags = depth_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([False, True, False, False])\n    assert torch.all(in_range_flags == expected_flags)\n    depth_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)\n    depth_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)",
        "mutated": [
            "def test_depth_points():\n    if False:\n        i = 10\n    empty_boxes = []\n    points = DepthPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    depth_points = DepthPoints(points_np, points_dim=3)\n    assert depth_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    depth_points = DepthPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], depth_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], depth_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], depth_points.color)\n    assert torch.allclose(expected_tensor[:, 6], depth_points.height)\n    new_depth_points = depth_points.clone()\n    assert torch.allclose(new_depth_points.tensor, depth_points.tensor)\n    new_depth_points.shuffle()\n    assert new_depth_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    depth_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.001)\n    new_depth_points = depth_points.clone()\n    new_depth_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_depth_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    depth_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = depth_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    depth_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, depth_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, depth_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, depth_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, depth_points[:, 3].tensor, 0.0001)\n    assert len(depth_points) == 4\n    expected_repr = 'DepthPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(depth_points)\n    depth_points_clone = depth_points.clone()\n    cat_points = DepthPoints.cat([depth_points, depth_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(depth_points)], depth_points.tensor)\n    for (i, point) in enumerate(depth_points):\n        assert torch.allclose(point, depth_points.tensor[i])\n    new_points = depth_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=depth_points.tensor.dtype))\n    point_bev_range = [-30, -40, 30, 40]\n    in_range_flags = depth_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([False, True, False, False])\n    assert torch.all(in_range_flags == expected_flags)\n    depth_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)\n    depth_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)",
            "def test_depth_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    empty_boxes = []\n    points = DepthPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    depth_points = DepthPoints(points_np, points_dim=3)\n    assert depth_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    depth_points = DepthPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], depth_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], depth_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], depth_points.color)\n    assert torch.allclose(expected_tensor[:, 6], depth_points.height)\n    new_depth_points = depth_points.clone()\n    assert torch.allclose(new_depth_points.tensor, depth_points.tensor)\n    new_depth_points.shuffle()\n    assert new_depth_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    depth_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.001)\n    new_depth_points = depth_points.clone()\n    new_depth_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_depth_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    depth_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = depth_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    depth_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, depth_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, depth_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, depth_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, depth_points[:, 3].tensor, 0.0001)\n    assert len(depth_points) == 4\n    expected_repr = 'DepthPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(depth_points)\n    depth_points_clone = depth_points.clone()\n    cat_points = DepthPoints.cat([depth_points, depth_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(depth_points)], depth_points.tensor)\n    for (i, point) in enumerate(depth_points):\n        assert torch.allclose(point, depth_points.tensor[i])\n    new_points = depth_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=depth_points.tensor.dtype))\n    point_bev_range = [-30, -40, 30, 40]\n    in_range_flags = depth_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([False, True, False, False])\n    assert torch.all(in_range_flags == expected_flags)\n    depth_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)\n    depth_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)",
            "def test_depth_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    empty_boxes = []\n    points = DepthPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    depth_points = DepthPoints(points_np, points_dim=3)\n    assert depth_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    depth_points = DepthPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], depth_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], depth_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], depth_points.color)\n    assert torch.allclose(expected_tensor[:, 6], depth_points.height)\n    new_depth_points = depth_points.clone()\n    assert torch.allclose(new_depth_points.tensor, depth_points.tensor)\n    new_depth_points.shuffle()\n    assert new_depth_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    depth_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.001)\n    new_depth_points = depth_points.clone()\n    new_depth_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_depth_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    depth_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = depth_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    depth_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, depth_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, depth_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, depth_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, depth_points[:, 3].tensor, 0.0001)\n    assert len(depth_points) == 4\n    expected_repr = 'DepthPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(depth_points)\n    depth_points_clone = depth_points.clone()\n    cat_points = DepthPoints.cat([depth_points, depth_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(depth_points)], depth_points.tensor)\n    for (i, point) in enumerate(depth_points):\n        assert torch.allclose(point, depth_points.tensor[i])\n    new_points = depth_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=depth_points.tensor.dtype))\n    point_bev_range = [-30, -40, 30, 40]\n    in_range_flags = depth_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([False, True, False, False])\n    assert torch.all(in_range_flags == expected_flags)\n    depth_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)\n    depth_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)",
            "def test_depth_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    empty_boxes = []\n    points = DepthPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    depth_points = DepthPoints(points_np, points_dim=3)\n    assert depth_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    depth_points = DepthPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], depth_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], depth_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], depth_points.color)\n    assert torch.allclose(expected_tensor[:, 6], depth_points.height)\n    new_depth_points = depth_points.clone()\n    assert torch.allclose(new_depth_points.tensor, depth_points.tensor)\n    new_depth_points.shuffle()\n    assert new_depth_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    depth_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.001)\n    new_depth_points = depth_points.clone()\n    new_depth_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_depth_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    depth_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = depth_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    depth_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, depth_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, depth_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, depth_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, depth_points[:, 3].tensor, 0.0001)\n    assert len(depth_points) == 4\n    expected_repr = 'DepthPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(depth_points)\n    depth_points_clone = depth_points.clone()\n    cat_points = DepthPoints.cat([depth_points, depth_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(depth_points)], depth_points.tensor)\n    for (i, point) in enumerate(depth_points):\n        assert torch.allclose(point, depth_points.tensor[i])\n    new_points = depth_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=depth_points.tensor.dtype))\n    point_bev_range = [-30, -40, 30, 40]\n    in_range_flags = depth_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([False, True, False, False])\n    assert torch.all(in_range_flags == expected_flags)\n    depth_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)\n    depth_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)",
            "def test_depth_points():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    empty_boxes = []\n    points = DepthPoints(empty_boxes)\n    assert points.tensor.shape[0] == 0\n    assert points.tensor.shape[1] == 3\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381], [-26.6751588, 5.59499564, -0.91434586], [-5.80979675, 35.4092357, 0.200889888], [-31.3086877, 1.09007628, -0.194612112]], dtype=np.float32)\n    depth_points = DepthPoints(points_np, points_dim=3)\n    assert depth_points.tensor.shape[0] == 4\n    points_np = np.array([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]], dtype=np.float32)\n    depth_points = DepthPoints(points_np, points_dim=7, attribute_dims=dict(color=[3, 4, 5], height=6))\n    expected_tensor = torch.tensor([[-5.24223238, 40.0209696, 0.297570381, 0.6666, 0.1956, 0.4974, 0.9409], [-26.6751588, 5.59499564, -0.91434586, 0.1502, 0.3707, 0.1086, 0.6297], [-5.80979675, 35.4092357, 0.200889888, 0.6565, 0.6248, 0.6954, 0.2538], [-31.3086877, 1.09007628, -0.194612112, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor)\n    assert torch.allclose(expected_tensor[:, :2], depth_points.bev)\n    assert torch.allclose(expected_tensor[:, :3], depth_points.coord)\n    assert torch.allclose(expected_tensor[:, 3:6], depth_points.color)\n    assert torch.allclose(expected_tensor[:, 6], depth_points.height)\n    new_depth_points = depth_points.clone()\n    assert torch.allclose(new_depth_points.tensor, depth_points.tensor)\n    new_depth_points.shuffle()\n    assert new_depth_points.tensor.shape == torch.Size([4, 7])\n    rot_mat = torch.tensor([[0.93629336, -0.27509585, 0.21835066], [0.28962948, 0.95642509, -0.03695701], [-0.19866933, 0.0978434, 0.97517033]])\n    depth_points.rotate(rot_mat)\n    expected_tensor = torch.tensor([[6.6239, 39.748, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-23.174, 12.6, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [4.776, 35.484, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-28.96, 9.6364, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.001)\n    new_depth_points = depth_points.clone()\n    new_depth_points.rotate(0.1, axis=2)\n    expected_tensor = torch.tensor([[2.6226, 40.211, -2.3335, 0.6666, 0.1956, 0.4974, 0.9409], [-24.316, 10.224, -6.923, 0.1502, 0.3707, 0.1086, 0.6297], [1.2096, 35.784, -2.3813, 0.6565, 0.6248, 0.6954, 0.2538], [-29.777, 6.6971, -7.0663, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, new_depth_points.tensor, 0.001)\n    translation_vector = torch.tensor([0.93629336, -0.27509585, 0.21835066])\n    depth_points.translate(translation_vector)\n    expected_tensor = torch.tensor([[7.5602, 39.473, -2.1152, 0.6666, 0.1956, 0.4974, 0.9409], [-22.237, 12.325, -6.7046, 0.1502, 0.3707, 0.1086, 0.6297], [5.7123, 35.209, -2.1629, 0.6565, 0.6248, 0.6954, 0.2538], [-28.023, 9.3613, -6.848, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)\n    point_range = [-10, -40, -10, 10, 40, 10]\n    in_range_flags = depth_points.in_range_3d(point_range)\n    expected_flags = torch.tensor([True, False, True, False])\n    assert torch.all(in_range_flags == expected_flags)\n    depth_points.scale(1.2)\n    expected_tensor = torch.tensor([[9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [-26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [-33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297]])\n    assert torch.allclose(expected_tensor, depth_points[1].tensor, 0.0001)\n    expected_tensor = torch.tensor([[-26.6848, 14.7898, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, depth_points[1:3].tensor, 0.0001)\n    mask = torch.tensor([True, False, True, False])\n    expected_tensor = torch.tensor([[9.0722, 47.3678, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [6.8547, 42.2509, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538]])\n    assert torch.allclose(expected_tensor, depth_points[mask].tensor, 0.0001)\n    expected_tensor = torch.tensor([[0.6666], [0.1502], [0.6565], [0.2803]])\n    assert torch.allclose(expected_tensor, depth_points[:, 3].tensor, 0.0001)\n    assert len(depth_points) == 4\n    expected_repr = 'DepthPoints(\\n    tensor([[ 9.0722e+00,  4.7368e+01, -2.5382e+00,  6.6660e-01,  1.9560e-01,\\n          4.9740e-01,  9.4090e-01],\\n        [-2.6685e+01,  1.4790e+01, -8.0455e+00,  1.5020e-01,  3.7070e-01,\\n          1.0860e-01,  6.2970e-01],\\n        [ 6.8547e+00,  4.2251e+01, -2.5955e+00,  6.5650e-01,  6.2480e-01,\\n          6.9540e-01,  2.5380e-01],\\n        [-3.3628e+01,  1.1234e+01, -8.2176e+00,  2.8030e-01,  2.5800e-02,\\n          4.8960e-01,  3.2690e-01]]))'\n    assert expected_repr == str(depth_points)\n    depth_points_clone = depth_points.clone()\n    cat_points = DepthPoints.cat([depth_points, depth_points_clone])\n    assert torch.allclose(cat_points.tensor[:len(depth_points)], depth_points.tensor)\n    for (i, point) in enumerate(depth_points):\n        assert torch.allclose(point, depth_points.tensor[i])\n    new_points = depth_points.new_point([[1, 2, 3, 4, 5, 6, 7]])\n    assert torch.allclose(new_points.tensor, torch.tensor([[1, 2, 3, 4, 5, 6, 7]], dtype=depth_points.tensor.dtype))\n    point_bev_range = [-30, -40, 30, 40]\n    in_range_flags = depth_points.in_range_bev(point_bev_range)\n    expected_flags = torch.tensor([False, True, False, False])\n    assert torch.all(in_range_flags == expected_flags)\n    depth_points.flip(bev_direction='horizontal')\n    expected_tensor = torch.tensor([[-9.0722, 47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, 14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, 42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, 11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)\n    depth_points.flip(bev_direction='vertical')\n    expected_tensor = torch.tensor([[-9.0722, -47.368, -2.5382, 0.6666, 0.1956, 0.4974, 0.9409], [26.685, -14.79, -8.0455, 0.1502, 0.3707, 0.1086, 0.6297], [-6.8547, -42.251, -2.5955, 0.6565, 0.6248, 0.6954, 0.2538], [33.628, -11.234, -8.2176, 0.2803, 0.0258, 0.4896, 0.3269]])\n    assert torch.allclose(expected_tensor, depth_points.tensor, 0.0001)"
        ]
    }
]