[
    {
        "func_name": "_ReadMappingBasenameToBoxNames",
        "original": "def _ReadMappingBasenameToBoxNames(input_path, index_image_names):\n    \"\"\"Reads mapping from image name to DELF file names for each box.\n\n  Args:\n    input_path: Path to CSV file containing mapping.\n    index_image_names: List containing index image names, in order, for the\n      dataset under consideration.\n\n  Returns:\n    images_to_box_feature_files: Dict. key=string (image name); value=list of\n      strings (file names containing DELF features for boxes).\n  \"\"\"\n    images_to_box_feature_files = {}\n    with tf.gfile.GFile(input_path, 'r') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            index_image_name = index_image_names[int(row['index_image_id'])]\n            if index_image_name not in images_to_box_feature_files:\n                images_to_box_feature_files[index_image_name] = []\n            images_to_box_feature_files[index_image_name].append(row['name'])\n    return images_to_box_feature_files",
        "mutated": [
            "def _ReadMappingBasenameToBoxNames(input_path, index_image_names):\n    if False:\n        i = 10\n    'Reads mapping from image name to DELF file names for each box.\\n\\n  Args:\\n    input_path: Path to CSV file containing mapping.\\n    index_image_names: List containing index image names, in order, for the\\n      dataset under consideration.\\n\\n  Returns:\\n    images_to_box_feature_files: Dict. key=string (image name); value=list of\\n      strings (file names containing DELF features for boxes).\\n  '\n    images_to_box_feature_files = {}\n    with tf.gfile.GFile(input_path, 'r') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            index_image_name = index_image_names[int(row['index_image_id'])]\n            if index_image_name not in images_to_box_feature_files:\n                images_to_box_feature_files[index_image_name] = []\n            images_to_box_feature_files[index_image_name].append(row['name'])\n    return images_to_box_feature_files",
            "def _ReadMappingBasenameToBoxNames(input_path, index_image_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Reads mapping from image name to DELF file names for each box.\\n\\n  Args:\\n    input_path: Path to CSV file containing mapping.\\n    index_image_names: List containing index image names, in order, for the\\n      dataset under consideration.\\n\\n  Returns:\\n    images_to_box_feature_files: Dict. key=string (image name); value=list of\\n      strings (file names containing DELF features for boxes).\\n  '\n    images_to_box_feature_files = {}\n    with tf.gfile.GFile(input_path, 'r') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            index_image_name = index_image_names[int(row['index_image_id'])]\n            if index_image_name not in images_to_box_feature_files:\n                images_to_box_feature_files[index_image_name] = []\n            images_to_box_feature_files[index_image_name].append(row['name'])\n    return images_to_box_feature_files",
            "def _ReadMappingBasenameToBoxNames(input_path, index_image_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Reads mapping from image name to DELF file names for each box.\\n\\n  Args:\\n    input_path: Path to CSV file containing mapping.\\n    index_image_names: List containing index image names, in order, for the\\n      dataset under consideration.\\n\\n  Returns:\\n    images_to_box_feature_files: Dict. key=string (image name); value=list of\\n      strings (file names containing DELF features for boxes).\\n  '\n    images_to_box_feature_files = {}\n    with tf.gfile.GFile(input_path, 'r') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            index_image_name = index_image_names[int(row['index_image_id'])]\n            if index_image_name not in images_to_box_feature_files:\n                images_to_box_feature_files[index_image_name] = []\n            images_to_box_feature_files[index_image_name].append(row['name'])\n    return images_to_box_feature_files",
            "def _ReadMappingBasenameToBoxNames(input_path, index_image_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Reads mapping from image name to DELF file names for each box.\\n\\n  Args:\\n    input_path: Path to CSV file containing mapping.\\n    index_image_names: List containing index image names, in order, for the\\n      dataset under consideration.\\n\\n  Returns:\\n    images_to_box_feature_files: Dict. key=string (image name); value=list of\\n      strings (file names containing DELF features for boxes).\\n  '\n    images_to_box_feature_files = {}\n    with tf.gfile.GFile(input_path, 'r') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            index_image_name = index_image_names[int(row['index_image_id'])]\n            if index_image_name not in images_to_box_feature_files:\n                images_to_box_feature_files[index_image_name] = []\n            images_to_box_feature_files[index_image_name].append(row['name'])\n    return images_to_box_feature_files",
            "def _ReadMappingBasenameToBoxNames(input_path, index_image_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Reads mapping from image name to DELF file names for each box.\\n\\n  Args:\\n    input_path: Path to CSV file containing mapping.\\n    index_image_names: List containing index image names, in order, for the\\n      dataset under consideration.\\n\\n  Returns:\\n    images_to_box_feature_files: Dict. key=string (image name); value=list of\\n      strings (file names containing DELF features for boxes).\\n  '\n    images_to_box_feature_files = {}\n    with tf.gfile.GFile(input_path, 'r') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            index_image_name = index_image_names[int(row['index_image_id'])]\n            if index_image_name not in images_to_box_feature_files:\n                images_to_box_feature_files[index_image_name] = []\n            images_to_box_feature_files[index_image_name].append(row['name'])\n    return images_to_box_feature_files"
        ]
    },
    {
        "func_name": "ExtractAggregatedRepresentationsToFiles",
        "original": "def ExtractAggregatedRepresentationsToFiles(image_names, features_dir, aggregation_config_path, mapping_path, output_aggregation_dir):\n    \"\"\"Extracts aggregated feature representations, saving them to files.\n\n  It checks if the aggregated representation for an image already exists,\n  and skips computation for those.\n\n  Args:\n    image_names: List of image names. These are used to compose input file names\n      for the feature files, and the output file names for aggregated\n      representations.\n    features_dir: Directory where DELF features are located.\n    aggregation_config_path: Path to AggregationConfig proto text file with\n      configuration to be used for extraction.\n    mapping_path: Optional CSV file which maps each .delf file name to the index\n      image ID and detected box ID. If regional aggregation is performed, this\n      should be set. Otherwise, this is ignored.\n    output_aggregation_dir: Directory where aggregation output will be written\n      to.\n\n  Raises:\n    ValueError: If AggregationConfig is malformed, or `mapping_path` is\n      missing.\n  \"\"\"\n    num_images = len(image_names)\n    config = aggregation_config_pb2.AggregationConfig()\n    with tf.gfile.GFile(aggregation_config_path, 'r') as f:\n        text_format.Merge(f.read(), config)\n    output_extension = '.'\n    if config.use_regional_aggregation:\n        output_extension += 'r'\n    if config.aggregation_type == _VLAD:\n        output_extension += _VLAD_EXTENSION_SUFFIX\n    elif config.aggregation_type == _ASMK:\n        output_extension += _ASMK_EXTENSION_SUFFIX\n    elif config.aggregation_type == _ASMK_STAR:\n        output_extension += _ASMK_STAR_EXTENSION_SUFFIX\n    else:\n        raise ValueError('Invalid aggregation type: %d' % config.aggregation_type)\n    if mapping_path:\n        images_to_box_feature_files = _ReadMappingBasenameToBoxNames(mapping_path, image_names)\n    if not tf.gfile.Exists(output_aggregation_dir):\n        tf.gfile.MakeDirs(output_aggregation_dir)\n    with tf.Session() as sess:\n        extractor = feature_aggregation_extractor.ExtractAggregatedRepresentation(sess, config)\n        start = time.clock()\n        for i in range(num_images):\n            if i == 0:\n                print('Starting to extract aggregation from images...')\n            elif i % _STATUS_CHECK_ITERATIONS == 0:\n                elapsed = time.clock() - start\n                print('Processing image %d out of %d, last %d images took %f seconds' % (i, num_images, _STATUS_CHECK_ITERATIONS, elapsed))\n                start = time.clock()\n            image_name = image_names[i]\n            output_aggregation_filename = os.path.join(output_aggregation_dir, image_name + output_extension)\n            if tf.io.gfile.exists(output_aggregation_filename):\n                print('Skipping %s' % image_name)\n                continue\n            if config.use_regional_aggregation:\n                if not mapping_path:\n                    raise ValueError('Requested regional aggregation, but mapping_path was not provided')\n                descriptors_list = []\n                num_features_per_box = []\n                for box_feature_file in images_to_box_feature_files[image_name]:\n                    delf_filename = os.path.join(features_dir, box_feature_file + _DELF_EXTENSION)\n                    (_, _, box_descriptors, _, _) = feature_io.ReadFromFile(delf_filename)\n                    if not box_descriptors.shape[0]:\n                        box_descriptors = np.reshape(box_descriptors, [0, config.feature_dimensionality])\n                    descriptors_list.append(box_descriptors)\n                    num_features_per_box.append(box_descriptors.shape[0])\n                descriptors = np.concatenate(descriptors_list)\n            else:\n                input_delf_filename = os.path.join(features_dir, image_name + _DELF_EXTENSION)\n                (_, _, descriptors, _, _) = feature_io.ReadFromFile(input_delf_filename)\n                if not descriptors.shape[0]:\n                    descriptors = np.reshape(descriptors, [0, config.feature_dimensionality])\n                num_features_per_box = None\n            (aggregated_descriptors, feature_visual_words) = extractor.Extract(descriptors, num_features_per_box)\n            if config.aggregation_type == _VLAD:\n                datum_io.WriteToFile(aggregated_descriptors, output_aggregation_filename)\n            else:\n                datum_io.WritePairToFile(aggregated_descriptors, feature_visual_words.astype('uint32'), output_aggregation_filename)",
        "mutated": [
            "def ExtractAggregatedRepresentationsToFiles(image_names, features_dir, aggregation_config_path, mapping_path, output_aggregation_dir):\n    if False:\n        i = 10\n    'Extracts aggregated feature representations, saving them to files.\\n\\n  It checks if the aggregated representation for an image already exists,\\n  and skips computation for those.\\n\\n  Args:\\n    image_names: List of image names. These are used to compose input file names\\n      for the feature files, and the output file names for aggregated\\n      representations.\\n    features_dir: Directory where DELF features are located.\\n    aggregation_config_path: Path to AggregationConfig proto text file with\\n      configuration to be used for extraction.\\n    mapping_path: Optional CSV file which maps each .delf file name to the index\\n      image ID and detected box ID. If regional aggregation is performed, this\\n      should be set. Otherwise, this is ignored.\\n    output_aggregation_dir: Directory where aggregation output will be written\\n      to.\\n\\n  Raises:\\n    ValueError: If AggregationConfig is malformed, or `mapping_path` is\\n      missing.\\n  '\n    num_images = len(image_names)\n    config = aggregation_config_pb2.AggregationConfig()\n    with tf.gfile.GFile(aggregation_config_path, 'r') as f:\n        text_format.Merge(f.read(), config)\n    output_extension = '.'\n    if config.use_regional_aggregation:\n        output_extension += 'r'\n    if config.aggregation_type == _VLAD:\n        output_extension += _VLAD_EXTENSION_SUFFIX\n    elif config.aggregation_type == _ASMK:\n        output_extension += _ASMK_EXTENSION_SUFFIX\n    elif config.aggregation_type == _ASMK_STAR:\n        output_extension += _ASMK_STAR_EXTENSION_SUFFIX\n    else:\n        raise ValueError('Invalid aggregation type: %d' % config.aggregation_type)\n    if mapping_path:\n        images_to_box_feature_files = _ReadMappingBasenameToBoxNames(mapping_path, image_names)\n    if not tf.gfile.Exists(output_aggregation_dir):\n        tf.gfile.MakeDirs(output_aggregation_dir)\n    with tf.Session() as sess:\n        extractor = feature_aggregation_extractor.ExtractAggregatedRepresentation(sess, config)\n        start = time.clock()\n        for i in range(num_images):\n            if i == 0:\n                print('Starting to extract aggregation from images...')\n            elif i % _STATUS_CHECK_ITERATIONS == 0:\n                elapsed = time.clock() - start\n                print('Processing image %d out of %d, last %d images took %f seconds' % (i, num_images, _STATUS_CHECK_ITERATIONS, elapsed))\n                start = time.clock()\n            image_name = image_names[i]\n            output_aggregation_filename = os.path.join(output_aggregation_dir, image_name + output_extension)\n            if tf.io.gfile.exists(output_aggregation_filename):\n                print('Skipping %s' % image_name)\n                continue\n            if config.use_regional_aggregation:\n                if not mapping_path:\n                    raise ValueError('Requested regional aggregation, but mapping_path was not provided')\n                descriptors_list = []\n                num_features_per_box = []\n                for box_feature_file in images_to_box_feature_files[image_name]:\n                    delf_filename = os.path.join(features_dir, box_feature_file + _DELF_EXTENSION)\n                    (_, _, box_descriptors, _, _) = feature_io.ReadFromFile(delf_filename)\n                    if not box_descriptors.shape[0]:\n                        box_descriptors = np.reshape(box_descriptors, [0, config.feature_dimensionality])\n                    descriptors_list.append(box_descriptors)\n                    num_features_per_box.append(box_descriptors.shape[0])\n                descriptors = np.concatenate(descriptors_list)\n            else:\n                input_delf_filename = os.path.join(features_dir, image_name + _DELF_EXTENSION)\n                (_, _, descriptors, _, _) = feature_io.ReadFromFile(input_delf_filename)\n                if not descriptors.shape[0]:\n                    descriptors = np.reshape(descriptors, [0, config.feature_dimensionality])\n                num_features_per_box = None\n            (aggregated_descriptors, feature_visual_words) = extractor.Extract(descriptors, num_features_per_box)\n            if config.aggregation_type == _VLAD:\n                datum_io.WriteToFile(aggregated_descriptors, output_aggregation_filename)\n            else:\n                datum_io.WritePairToFile(aggregated_descriptors, feature_visual_words.astype('uint32'), output_aggregation_filename)",
            "def ExtractAggregatedRepresentationsToFiles(image_names, features_dir, aggregation_config_path, mapping_path, output_aggregation_dir):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Extracts aggregated feature representations, saving them to files.\\n\\n  It checks if the aggregated representation for an image already exists,\\n  and skips computation for those.\\n\\n  Args:\\n    image_names: List of image names. These are used to compose input file names\\n      for the feature files, and the output file names for aggregated\\n      representations.\\n    features_dir: Directory where DELF features are located.\\n    aggregation_config_path: Path to AggregationConfig proto text file with\\n      configuration to be used for extraction.\\n    mapping_path: Optional CSV file which maps each .delf file name to the index\\n      image ID and detected box ID. If regional aggregation is performed, this\\n      should be set. Otherwise, this is ignored.\\n    output_aggregation_dir: Directory where aggregation output will be written\\n      to.\\n\\n  Raises:\\n    ValueError: If AggregationConfig is malformed, or `mapping_path` is\\n      missing.\\n  '\n    num_images = len(image_names)\n    config = aggregation_config_pb2.AggregationConfig()\n    with tf.gfile.GFile(aggregation_config_path, 'r') as f:\n        text_format.Merge(f.read(), config)\n    output_extension = '.'\n    if config.use_regional_aggregation:\n        output_extension += 'r'\n    if config.aggregation_type == _VLAD:\n        output_extension += _VLAD_EXTENSION_SUFFIX\n    elif config.aggregation_type == _ASMK:\n        output_extension += _ASMK_EXTENSION_SUFFIX\n    elif config.aggregation_type == _ASMK_STAR:\n        output_extension += _ASMK_STAR_EXTENSION_SUFFIX\n    else:\n        raise ValueError('Invalid aggregation type: %d' % config.aggregation_type)\n    if mapping_path:\n        images_to_box_feature_files = _ReadMappingBasenameToBoxNames(mapping_path, image_names)\n    if not tf.gfile.Exists(output_aggregation_dir):\n        tf.gfile.MakeDirs(output_aggregation_dir)\n    with tf.Session() as sess:\n        extractor = feature_aggregation_extractor.ExtractAggregatedRepresentation(sess, config)\n        start = time.clock()\n        for i in range(num_images):\n            if i == 0:\n                print('Starting to extract aggregation from images...')\n            elif i % _STATUS_CHECK_ITERATIONS == 0:\n                elapsed = time.clock() - start\n                print('Processing image %d out of %d, last %d images took %f seconds' % (i, num_images, _STATUS_CHECK_ITERATIONS, elapsed))\n                start = time.clock()\n            image_name = image_names[i]\n            output_aggregation_filename = os.path.join(output_aggregation_dir, image_name + output_extension)\n            if tf.io.gfile.exists(output_aggregation_filename):\n                print('Skipping %s' % image_name)\n                continue\n            if config.use_regional_aggregation:\n                if not mapping_path:\n                    raise ValueError('Requested regional aggregation, but mapping_path was not provided')\n                descriptors_list = []\n                num_features_per_box = []\n                for box_feature_file in images_to_box_feature_files[image_name]:\n                    delf_filename = os.path.join(features_dir, box_feature_file + _DELF_EXTENSION)\n                    (_, _, box_descriptors, _, _) = feature_io.ReadFromFile(delf_filename)\n                    if not box_descriptors.shape[0]:\n                        box_descriptors = np.reshape(box_descriptors, [0, config.feature_dimensionality])\n                    descriptors_list.append(box_descriptors)\n                    num_features_per_box.append(box_descriptors.shape[0])\n                descriptors = np.concatenate(descriptors_list)\n            else:\n                input_delf_filename = os.path.join(features_dir, image_name + _DELF_EXTENSION)\n                (_, _, descriptors, _, _) = feature_io.ReadFromFile(input_delf_filename)\n                if not descriptors.shape[0]:\n                    descriptors = np.reshape(descriptors, [0, config.feature_dimensionality])\n                num_features_per_box = None\n            (aggregated_descriptors, feature_visual_words) = extractor.Extract(descriptors, num_features_per_box)\n            if config.aggregation_type == _VLAD:\n                datum_io.WriteToFile(aggregated_descriptors, output_aggregation_filename)\n            else:\n                datum_io.WritePairToFile(aggregated_descriptors, feature_visual_words.astype('uint32'), output_aggregation_filename)",
            "def ExtractAggregatedRepresentationsToFiles(image_names, features_dir, aggregation_config_path, mapping_path, output_aggregation_dir):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Extracts aggregated feature representations, saving them to files.\\n\\n  It checks if the aggregated representation for an image already exists,\\n  and skips computation for those.\\n\\n  Args:\\n    image_names: List of image names. These are used to compose input file names\\n      for the feature files, and the output file names for aggregated\\n      representations.\\n    features_dir: Directory where DELF features are located.\\n    aggregation_config_path: Path to AggregationConfig proto text file with\\n      configuration to be used for extraction.\\n    mapping_path: Optional CSV file which maps each .delf file name to the index\\n      image ID and detected box ID. If regional aggregation is performed, this\\n      should be set. Otherwise, this is ignored.\\n    output_aggregation_dir: Directory where aggregation output will be written\\n      to.\\n\\n  Raises:\\n    ValueError: If AggregationConfig is malformed, or `mapping_path` is\\n      missing.\\n  '\n    num_images = len(image_names)\n    config = aggregation_config_pb2.AggregationConfig()\n    with tf.gfile.GFile(aggregation_config_path, 'r') as f:\n        text_format.Merge(f.read(), config)\n    output_extension = '.'\n    if config.use_regional_aggregation:\n        output_extension += 'r'\n    if config.aggregation_type == _VLAD:\n        output_extension += _VLAD_EXTENSION_SUFFIX\n    elif config.aggregation_type == _ASMK:\n        output_extension += _ASMK_EXTENSION_SUFFIX\n    elif config.aggregation_type == _ASMK_STAR:\n        output_extension += _ASMK_STAR_EXTENSION_SUFFIX\n    else:\n        raise ValueError('Invalid aggregation type: %d' % config.aggregation_type)\n    if mapping_path:\n        images_to_box_feature_files = _ReadMappingBasenameToBoxNames(mapping_path, image_names)\n    if not tf.gfile.Exists(output_aggregation_dir):\n        tf.gfile.MakeDirs(output_aggregation_dir)\n    with tf.Session() as sess:\n        extractor = feature_aggregation_extractor.ExtractAggregatedRepresentation(sess, config)\n        start = time.clock()\n        for i in range(num_images):\n            if i == 0:\n                print('Starting to extract aggregation from images...')\n            elif i % _STATUS_CHECK_ITERATIONS == 0:\n                elapsed = time.clock() - start\n                print('Processing image %d out of %d, last %d images took %f seconds' % (i, num_images, _STATUS_CHECK_ITERATIONS, elapsed))\n                start = time.clock()\n            image_name = image_names[i]\n            output_aggregation_filename = os.path.join(output_aggregation_dir, image_name + output_extension)\n            if tf.io.gfile.exists(output_aggregation_filename):\n                print('Skipping %s' % image_name)\n                continue\n            if config.use_regional_aggregation:\n                if not mapping_path:\n                    raise ValueError('Requested regional aggregation, but mapping_path was not provided')\n                descriptors_list = []\n                num_features_per_box = []\n                for box_feature_file in images_to_box_feature_files[image_name]:\n                    delf_filename = os.path.join(features_dir, box_feature_file + _DELF_EXTENSION)\n                    (_, _, box_descriptors, _, _) = feature_io.ReadFromFile(delf_filename)\n                    if not box_descriptors.shape[0]:\n                        box_descriptors = np.reshape(box_descriptors, [0, config.feature_dimensionality])\n                    descriptors_list.append(box_descriptors)\n                    num_features_per_box.append(box_descriptors.shape[0])\n                descriptors = np.concatenate(descriptors_list)\n            else:\n                input_delf_filename = os.path.join(features_dir, image_name + _DELF_EXTENSION)\n                (_, _, descriptors, _, _) = feature_io.ReadFromFile(input_delf_filename)\n                if not descriptors.shape[0]:\n                    descriptors = np.reshape(descriptors, [0, config.feature_dimensionality])\n                num_features_per_box = None\n            (aggregated_descriptors, feature_visual_words) = extractor.Extract(descriptors, num_features_per_box)\n            if config.aggregation_type == _VLAD:\n                datum_io.WriteToFile(aggregated_descriptors, output_aggregation_filename)\n            else:\n                datum_io.WritePairToFile(aggregated_descriptors, feature_visual_words.astype('uint32'), output_aggregation_filename)",
            "def ExtractAggregatedRepresentationsToFiles(image_names, features_dir, aggregation_config_path, mapping_path, output_aggregation_dir):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Extracts aggregated feature representations, saving them to files.\\n\\n  It checks if the aggregated representation for an image already exists,\\n  and skips computation for those.\\n\\n  Args:\\n    image_names: List of image names. These are used to compose input file names\\n      for the feature files, and the output file names for aggregated\\n      representations.\\n    features_dir: Directory where DELF features are located.\\n    aggregation_config_path: Path to AggregationConfig proto text file with\\n      configuration to be used for extraction.\\n    mapping_path: Optional CSV file which maps each .delf file name to the index\\n      image ID and detected box ID. If regional aggregation is performed, this\\n      should be set. Otherwise, this is ignored.\\n    output_aggregation_dir: Directory where aggregation output will be written\\n      to.\\n\\n  Raises:\\n    ValueError: If AggregationConfig is malformed, or `mapping_path` is\\n      missing.\\n  '\n    num_images = len(image_names)\n    config = aggregation_config_pb2.AggregationConfig()\n    with tf.gfile.GFile(aggregation_config_path, 'r') as f:\n        text_format.Merge(f.read(), config)\n    output_extension = '.'\n    if config.use_regional_aggregation:\n        output_extension += 'r'\n    if config.aggregation_type == _VLAD:\n        output_extension += _VLAD_EXTENSION_SUFFIX\n    elif config.aggregation_type == _ASMK:\n        output_extension += _ASMK_EXTENSION_SUFFIX\n    elif config.aggregation_type == _ASMK_STAR:\n        output_extension += _ASMK_STAR_EXTENSION_SUFFIX\n    else:\n        raise ValueError('Invalid aggregation type: %d' % config.aggregation_type)\n    if mapping_path:\n        images_to_box_feature_files = _ReadMappingBasenameToBoxNames(mapping_path, image_names)\n    if not tf.gfile.Exists(output_aggregation_dir):\n        tf.gfile.MakeDirs(output_aggregation_dir)\n    with tf.Session() as sess:\n        extractor = feature_aggregation_extractor.ExtractAggregatedRepresentation(sess, config)\n        start = time.clock()\n        for i in range(num_images):\n            if i == 0:\n                print('Starting to extract aggregation from images...')\n            elif i % _STATUS_CHECK_ITERATIONS == 0:\n                elapsed = time.clock() - start\n                print('Processing image %d out of %d, last %d images took %f seconds' % (i, num_images, _STATUS_CHECK_ITERATIONS, elapsed))\n                start = time.clock()\n            image_name = image_names[i]\n            output_aggregation_filename = os.path.join(output_aggregation_dir, image_name + output_extension)\n            if tf.io.gfile.exists(output_aggregation_filename):\n                print('Skipping %s' % image_name)\n                continue\n            if config.use_regional_aggregation:\n                if not mapping_path:\n                    raise ValueError('Requested regional aggregation, but mapping_path was not provided')\n                descriptors_list = []\n                num_features_per_box = []\n                for box_feature_file in images_to_box_feature_files[image_name]:\n                    delf_filename = os.path.join(features_dir, box_feature_file + _DELF_EXTENSION)\n                    (_, _, box_descriptors, _, _) = feature_io.ReadFromFile(delf_filename)\n                    if not box_descriptors.shape[0]:\n                        box_descriptors = np.reshape(box_descriptors, [0, config.feature_dimensionality])\n                    descriptors_list.append(box_descriptors)\n                    num_features_per_box.append(box_descriptors.shape[0])\n                descriptors = np.concatenate(descriptors_list)\n            else:\n                input_delf_filename = os.path.join(features_dir, image_name + _DELF_EXTENSION)\n                (_, _, descriptors, _, _) = feature_io.ReadFromFile(input_delf_filename)\n                if not descriptors.shape[0]:\n                    descriptors = np.reshape(descriptors, [0, config.feature_dimensionality])\n                num_features_per_box = None\n            (aggregated_descriptors, feature_visual_words) = extractor.Extract(descriptors, num_features_per_box)\n            if config.aggregation_type == _VLAD:\n                datum_io.WriteToFile(aggregated_descriptors, output_aggregation_filename)\n            else:\n                datum_io.WritePairToFile(aggregated_descriptors, feature_visual_words.astype('uint32'), output_aggregation_filename)",
            "def ExtractAggregatedRepresentationsToFiles(image_names, features_dir, aggregation_config_path, mapping_path, output_aggregation_dir):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Extracts aggregated feature representations, saving them to files.\\n\\n  It checks if the aggregated representation for an image already exists,\\n  and skips computation for those.\\n\\n  Args:\\n    image_names: List of image names. These are used to compose input file names\\n      for the feature files, and the output file names for aggregated\\n      representations.\\n    features_dir: Directory where DELF features are located.\\n    aggregation_config_path: Path to AggregationConfig proto text file with\\n      configuration to be used for extraction.\\n    mapping_path: Optional CSV file which maps each .delf file name to the index\\n      image ID and detected box ID. If regional aggregation is performed, this\\n      should be set. Otherwise, this is ignored.\\n    output_aggregation_dir: Directory where aggregation output will be written\\n      to.\\n\\n  Raises:\\n    ValueError: If AggregationConfig is malformed, or `mapping_path` is\\n      missing.\\n  '\n    num_images = len(image_names)\n    config = aggregation_config_pb2.AggregationConfig()\n    with tf.gfile.GFile(aggregation_config_path, 'r') as f:\n        text_format.Merge(f.read(), config)\n    output_extension = '.'\n    if config.use_regional_aggregation:\n        output_extension += 'r'\n    if config.aggregation_type == _VLAD:\n        output_extension += _VLAD_EXTENSION_SUFFIX\n    elif config.aggregation_type == _ASMK:\n        output_extension += _ASMK_EXTENSION_SUFFIX\n    elif config.aggregation_type == _ASMK_STAR:\n        output_extension += _ASMK_STAR_EXTENSION_SUFFIX\n    else:\n        raise ValueError('Invalid aggregation type: %d' % config.aggregation_type)\n    if mapping_path:\n        images_to_box_feature_files = _ReadMappingBasenameToBoxNames(mapping_path, image_names)\n    if not tf.gfile.Exists(output_aggregation_dir):\n        tf.gfile.MakeDirs(output_aggregation_dir)\n    with tf.Session() as sess:\n        extractor = feature_aggregation_extractor.ExtractAggregatedRepresentation(sess, config)\n        start = time.clock()\n        for i in range(num_images):\n            if i == 0:\n                print('Starting to extract aggregation from images...')\n            elif i % _STATUS_CHECK_ITERATIONS == 0:\n                elapsed = time.clock() - start\n                print('Processing image %d out of %d, last %d images took %f seconds' % (i, num_images, _STATUS_CHECK_ITERATIONS, elapsed))\n                start = time.clock()\n            image_name = image_names[i]\n            output_aggregation_filename = os.path.join(output_aggregation_dir, image_name + output_extension)\n            if tf.io.gfile.exists(output_aggregation_filename):\n                print('Skipping %s' % image_name)\n                continue\n            if config.use_regional_aggregation:\n                if not mapping_path:\n                    raise ValueError('Requested regional aggregation, but mapping_path was not provided')\n                descriptors_list = []\n                num_features_per_box = []\n                for box_feature_file in images_to_box_feature_files[image_name]:\n                    delf_filename = os.path.join(features_dir, box_feature_file + _DELF_EXTENSION)\n                    (_, _, box_descriptors, _, _) = feature_io.ReadFromFile(delf_filename)\n                    if not box_descriptors.shape[0]:\n                        box_descriptors = np.reshape(box_descriptors, [0, config.feature_dimensionality])\n                    descriptors_list.append(box_descriptors)\n                    num_features_per_box.append(box_descriptors.shape[0])\n                descriptors = np.concatenate(descriptors_list)\n            else:\n                input_delf_filename = os.path.join(features_dir, image_name + _DELF_EXTENSION)\n                (_, _, descriptors, _, _) = feature_io.ReadFromFile(input_delf_filename)\n                if not descriptors.shape[0]:\n                    descriptors = np.reshape(descriptors, [0, config.feature_dimensionality])\n                num_features_per_box = None\n            (aggregated_descriptors, feature_visual_words) = extractor.Extract(descriptors, num_features_per_box)\n            if config.aggregation_type == _VLAD:\n                datum_io.WriteToFile(aggregated_descriptors, output_aggregation_filename)\n            else:\n                datum_io.WritePairToFile(aggregated_descriptors, feature_visual_words.astype('uint32'), output_aggregation_filename)"
        ]
    }
]