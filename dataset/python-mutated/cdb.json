[
    {
        "func_name": "cdb_run",
        "original": "@endpoint('/cdb/cmd/{which}/{version=0}', postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_run(ctx, rd, which, version):\n    try:\n        m = module_for_cmd(which)\n    except ImportError:\n        raise HTTPNotFound(f'No module named: {which}')\n    if not getattr(m, 'readonly', False):\n        ctx.check_for_write_access(rd)\n    if getattr(m, 'version', 0) != int(version):\n        raise HTTPNotFound('The module {} is not available in version: {}.Make sure the version of calibre used for the server and calibredb match'.format(which, version))\n    db = get_library_data(ctx, rd, strict_library_id=True)[0]\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the command-line db interface with a user who has per library restrictions')\n    raw = rd.read()\n    ct = rd.inheaders.get('Content-Type', all=True)\n    ct = {x.lower().partition(';')[0] for x in ct}\n    try:\n        if MSGPACK_MIME in ct:\n            args = msgpack_loads(raw)\n        elif 'application/json' in ct:\n            args = json_loads(raw)\n        else:\n            raise HTTPBadRequest('Only JSON or msgpack requests are supported')\n    except Exception:\n        raise HTTPBadRequest('args are not valid encoded data')\n    if getattr(m, 'needs_srv_ctx', False):\n        args = [ctx] + list(args)\n    try:\n        result = m.implementation(db, partial(ctx.notify_changes, db.backend.library_path), *args)\n    except Exception as err:\n        tb = ''\n        if not getattr(err, 'suppress_traceback', False):\n            import traceback\n            tb = traceback.format_exc()\n        return {'err': as_unicode(err), 'tb': tb}\n    return {'result': result}",
        "mutated": [
            "@endpoint('/cdb/cmd/{which}/{version=0}', postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_run(ctx, rd, which, version):\n    if False:\n        i = 10\n    try:\n        m = module_for_cmd(which)\n    except ImportError:\n        raise HTTPNotFound(f'No module named: {which}')\n    if not getattr(m, 'readonly', False):\n        ctx.check_for_write_access(rd)\n    if getattr(m, 'version', 0) != int(version):\n        raise HTTPNotFound('The module {} is not available in version: {}.Make sure the version of calibre used for the server and calibredb match'.format(which, version))\n    db = get_library_data(ctx, rd, strict_library_id=True)[0]\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the command-line db interface with a user who has per library restrictions')\n    raw = rd.read()\n    ct = rd.inheaders.get('Content-Type', all=True)\n    ct = {x.lower().partition(';')[0] for x in ct}\n    try:\n        if MSGPACK_MIME in ct:\n            args = msgpack_loads(raw)\n        elif 'application/json' in ct:\n            args = json_loads(raw)\n        else:\n            raise HTTPBadRequest('Only JSON or msgpack requests are supported')\n    except Exception:\n        raise HTTPBadRequest('args are not valid encoded data')\n    if getattr(m, 'needs_srv_ctx', False):\n        args = [ctx] + list(args)\n    try:\n        result = m.implementation(db, partial(ctx.notify_changes, db.backend.library_path), *args)\n    except Exception as err:\n        tb = ''\n        if not getattr(err, 'suppress_traceback', False):\n            import traceback\n            tb = traceback.format_exc()\n        return {'err': as_unicode(err), 'tb': tb}\n    return {'result': result}",
            "@endpoint('/cdb/cmd/{which}/{version=0}', postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_run(ctx, rd, which, version):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    try:\n        m = module_for_cmd(which)\n    except ImportError:\n        raise HTTPNotFound(f'No module named: {which}')\n    if not getattr(m, 'readonly', False):\n        ctx.check_for_write_access(rd)\n    if getattr(m, 'version', 0) != int(version):\n        raise HTTPNotFound('The module {} is not available in version: {}.Make sure the version of calibre used for the server and calibredb match'.format(which, version))\n    db = get_library_data(ctx, rd, strict_library_id=True)[0]\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the command-line db interface with a user who has per library restrictions')\n    raw = rd.read()\n    ct = rd.inheaders.get('Content-Type', all=True)\n    ct = {x.lower().partition(';')[0] for x in ct}\n    try:\n        if MSGPACK_MIME in ct:\n            args = msgpack_loads(raw)\n        elif 'application/json' in ct:\n            args = json_loads(raw)\n        else:\n            raise HTTPBadRequest('Only JSON or msgpack requests are supported')\n    except Exception:\n        raise HTTPBadRequest('args are not valid encoded data')\n    if getattr(m, 'needs_srv_ctx', False):\n        args = [ctx] + list(args)\n    try:\n        result = m.implementation(db, partial(ctx.notify_changes, db.backend.library_path), *args)\n    except Exception as err:\n        tb = ''\n        if not getattr(err, 'suppress_traceback', False):\n            import traceback\n            tb = traceback.format_exc()\n        return {'err': as_unicode(err), 'tb': tb}\n    return {'result': result}",
            "@endpoint('/cdb/cmd/{which}/{version=0}', postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_run(ctx, rd, which, version):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    try:\n        m = module_for_cmd(which)\n    except ImportError:\n        raise HTTPNotFound(f'No module named: {which}')\n    if not getattr(m, 'readonly', False):\n        ctx.check_for_write_access(rd)\n    if getattr(m, 'version', 0) != int(version):\n        raise HTTPNotFound('The module {} is not available in version: {}.Make sure the version of calibre used for the server and calibredb match'.format(which, version))\n    db = get_library_data(ctx, rd, strict_library_id=True)[0]\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the command-line db interface with a user who has per library restrictions')\n    raw = rd.read()\n    ct = rd.inheaders.get('Content-Type', all=True)\n    ct = {x.lower().partition(';')[0] for x in ct}\n    try:\n        if MSGPACK_MIME in ct:\n            args = msgpack_loads(raw)\n        elif 'application/json' in ct:\n            args = json_loads(raw)\n        else:\n            raise HTTPBadRequest('Only JSON or msgpack requests are supported')\n    except Exception:\n        raise HTTPBadRequest('args are not valid encoded data')\n    if getattr(m, 'needs_srv_ctx', False):\n        args = [ctx] + list(args)\n    try:\n        result = m.implementation(db, partial(ctx.notify_changes, db.backend.library_path), *args)\n    except Exception as err:\n        tb = ''\n        if not getattr(err, 'suppress_traceback', False):\n            import traceback\n            tb = traceback.format_exc()\n        return {'err': as_unicode(err), 'tb': tb}\n    return {'result': result}",
            "@endpoint('/cdb/cmd/{which}/{version=0}', postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_run(ctx, rd, which, version):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    try:\n        m = module_for_cmd(which)\n    except ImportError:\n        raise HTTPNotFound(f'No module named: {which}')\n    if not getattr(m, 'readonly', False):\n        ctx.check_for_write_access(rd)\n    if getattr(m, 'version', 0) != int(version):\n        raise HTTPNotFound('The module {} is not available in version: {}.Make sure the version of calibre used for the server and calibredb match'.format(which, version))\n    db = get_library_data(ctx, rd, strict_library_id=True)[0]\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the command-line db interface with a user who has per library restrictions')\n    raw = rd.read()\n    ct = rd.inheaders.get('Content-Type', all=True)\n    ct = {x.lower().partition(';')[0] for x in ct}\n    try:\n        if MSGPACK_MIME in ct:\n            args = msgpack_loads(raw)\n        elif 'application/json' in ct:\n            args = json_loads(raw)\n        else:\n            raise HTTPBadRequest('Only JSON or msgpack requests are supported')\n    except Exception:\n        raise HTTPBadRequest('args are not valid encoded data')\n    if getattr(m, 'needs_srv_ctx', False):\n        args = [ctx] + list(args)\n    try:\n        result = m.implementation(db, partial(ctx.notify_changes, db.backend.library_path), *args)\n    except Exception as err:\n        tb = ''\n        if not getattr(err, 'suppress_traceback', False):\n            import traceback\n            tb = traceback.format_exc()\n        return {'err': as_unicode(err), 'tb': tb}\n    return {'result': result}",
            "@endpoint('/cdb/cmd/{which}/{version=0}', postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_run(ctx, rd, which, version):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    try:\n        m = module_for_cmd(which)\n    except ImportError:\n        raise HTTPNotFound(f'No module named: {which}')\n    if not getattr(m, 'readonly', False):\n        ctx.check_for_write_access(rd)\n    if getattr(m, 'version', 0) != int(version):\n        raise HTTPNotFound('The module {} is not available in version: {}.Make sure the version of calibre used for the server and calibredb match'.format(which, version))\n    db = get_library_data(ctx, rd, strict_library_id=True)[0]\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the command-line db interface with a user who has per library restrictions')\n    raw = rd.read()\n    ct = rd.inheaders.get('Content-Type', all=True)\n    ct = {x.lower().partition(';')[0] for x in ct}\n    try:\n        if MSGPACK_MIME in ct:\n            args = msgpack_loads(raw)\n        elif 'application/json' in ct:\n            args = json_loads(raw)\n        else:\n            raise HTTPBadRequest('Only JSON or msgpack requests are supported')\n    except Exception:\n        raise HTTPBadRequest('args are not valid encoded data')\n    if getattr(m, 'needs_srv_ctx', False):\n        args = [ctx] + list(args)\n    try:\n        result = m.implementation(db, partial(ctx.notify_changes, db.backend.library_path), *args)\n    except Exception as err:\n        tb = ''\n        if not getattr(err, 'suppress_traceback', False):\n            import traceback\n            tb = traceback.format_exc()\n        return {'err': as_unicode(err), 'tb': tb}\n    return {'result': result}"
        ]
    },
    {
        "func_name": "cdb_add_book",
        "original": "@endpoint('/cdb/add-book/{job_id}/{add_duplicates}/{filename}/{library_id=None}', needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_add_book(ctx, rd, job_id, add_duplicates, filename, library_id):\n    \"\"\"\n    Add a file as a new book. The file contents must be in the body of the request.\n\n    The response will also have the title/authors/languages read from the\n    metadata of the file/filename. It will contain a `book_id` field specifying\n    the id of the newly added book, or if add_duplicates is not specified and a\n    duplicate was found, no book_id will be present, instead there will be a\n    `duplicates` field specifying the title and authors for all duplicate\n    matches. It will also return the value of `job_id` as the `id` field and\n    `filename` as the `filename` field.\n    \"\"\"\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the add book interface with a user who has per library restrictions')\n    if not filename:\n        raise HTTPBadRequest('An empty filename is not allowed')\n    sfilename = sanitize_file_name(filename)\n    fmt = os.path.splitext(sfilename)[1]\n    fmt = fmt[1:] if fmt else None\n    if not fmt:\n        raise HTTPBadRequest('An filename with no extension is not allowed')\n    if isinstance(rd.request_body_file, BytesIO):\n        raise HTTPBadRequest('A request body containing the file data must be specified')\n    add_duplicates = add_duplicates in ('y', '1')\n    path = os.path.join(rd.tdir, sfilename)\n    rd.request_body_file.seek(0)\n    with open(path, 'wb') as f:\n        shutil.copyfileobj(rd.request_body_file, f)\n    from calibre.ebooks.metadata.worker import run_import_plugins\n    path = run_import_plugins((path,), time.monotonic_ns(), rd.tdir)[0]\n    with open(path, 'rb') as f:\n        mi = get_metadata(f, stream_type=os.path.splitext(path)[1][1:], use_libprs_metadata=True)\n        f.seek(0)\n        nfmt = os.path.splitext(path)[1]\n        fmt = nfmt[1:] if nfmt else fmt\n        (ids, duplicates) = db.add_books([(mi, {fmt: f})], add_duplicates=add_duplicates)\n    ans = {'title': mi.title, 'authors': mi.authors, 'languages': mi.languages, 'filename': filename, 'id': job_id}\n    if ids:\n        ans['book_id'] = ids[0]\n        ctx.notify_changes(db.backend.library_path, books_added(ids))\n    else:\n        ans['duplicates'] = [{'title': m.title, 'authors': m.authors} for (m, _) in duplicates]\n    return ans",
        "mutated": [
            "@endpoint('/cdb/add-book/{job_id}/{add_duplicates}/{filename}/{library_id=None}', needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_add_book(ctx, rd, job_id, add_duplicates, filename, library_id):\n    if False:\n        i = 10\n    '\\n    Add a file as a new book. The file contents must be in the body of the request.\\n\\n    The response will also have the title/authors/languages read from the\\n    metadata of the file/filename. It will contain a `book_id` field specifying\\n    the id of the newly added book, or if add_duplicates is not specified and a\\n    duplicate was found, no book_id will be present, instead there will be a\\n    `duplicates` field specifying the title and authors for all duplicate\\n    matches. It will also return the value of `job_id` as the `id` field and\\n    `filename` as the `filename` field.\\n    '\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the add book interface with a user who has per library restrictions')\n    if not filename:\n        raise HTTPBadRequest('An empty filename is not allowed')\n    sfilename = sanitize_file_name(filename)\n    fmt = os.path.splitext(sfilename)[1]\n    fmt = fmt[1:] if fmt else None\n    if not fmt:\n        raise HTTPBadRequest('An filename with no extension is not allowed')\n    if isinstance(rd.request_body_file, BytesIO):\n        raise HTTPBadRequest('A request body containing the file data must be specified')\n    add_duplicates = add_duplicates in ('y', '1')\n    path = os.path.join(rd.tdir, sfilename)\n    rd.request_body_file.seek(0)\n    with open(path, 'wb') as f:\n        shutil.copyfileobj(rd.request_body_file, f)\n    from calibre.ebooks.metadata.worker import run_import_plugins\n    path = run_import_plugins((path,), time.monotonic_ns(), rd.tdir)[0]\n    with open(path, 'rb') as f:\n        mi = get_metadata(f, stream_type=os.path.splitext(path)[1][1:], use_libprs_metadata=True)\n        f.seek(0)\n        nfmt = os.path.splitext(path)[1]\n        fmt = nfmt[1:] if nfmt else fmt\n        (ids, duplicates) = db.add_books([(mi, {fmt: f})], add_duplicates=add_duplicates)\n    ans = {'title': mi.title, 'authors': mi.authors, 'languages': mi.languages, 'filename': filename, 'id': job_id}\n    if ids:\n        ans['book_id'] = ids[0]\n        ctx.notify_changes(db.backend.library_path, books_added(ids))\n    else:\n        ans['duplicates'] = [{'title': m.title, 'authors': m.authors} for (m, _) in duplicates]\n    return ans",
            "@endpoint('/cdb/add-book/{job_id}/{add_duplicates}/{filename}/{library_id=None}', needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_add_book(ctx, rd, job_id, add_duplicates, filename, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Add a file as a new book. The file contents must be in the body of the request.\\n\\n    The response will also have the title/authors/languages read from the\\n    metadata of the file/filename. It will contain a `book_id` field specifying\\n    the id of the newly added book, or if add_duplicates is not specified and a\\n    duplicate was found, no book_id will be present, instead there will be a\\n    `duplicates` field specifying the title and authors for all duplicate\\n    matches. It will also return the value of `job_id` as the `id` field and\\n    `filename` as the `filename` field.\\n    '\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the add book interface with a user who has per library restrictions')\n    if not filename:\n        raise HTTPBadRequest('An empty filename is not allowed')\n    sfilename = sanitize_file_name(filename)\n    fmt = os.path.splitext(sfilename)[1]\n    fmt = fmt[1:] if fmt else None\n    if not fmt:\n        raise HTTPBadRequest('An filename with no extension is not allowed')\n    if isinstance(rd.request_body_file, BytesIO):\n        raise HTTPBadRequest('A request body containing the file data must be specified')\n    add_duplicates = add_duplicates in ('y', '1')\n    path = os.path.join(rd.tdir, sfilename)\n    rd.request_body_file.seek(0)\n    with open(path, 'wb') as f:\n        shutil.copyfileobj(rd.request_body_file, f)\n    from calibre.ebooks.metadata.worker import run_import_plugins\n    path = run_import_plugins((path,), time.monotonic_ns(), rd.tdir)[0]\n    with open(path, 'rb') as f:\n        mi = get_metadata(f, stream_type=os.path.splitext(path)[1][1:], use_libprs_metadata=True)\n        f.seek(0)\n        nfmt = os.path.splitext(path)[1]\n        fmt = nfmt[1:] if nfmt else fmt\n        (ids, duplicates) = db.add_books([(mi, {fmt: f})], add_duplicates=add_duplicates)\n    ans = {'title': mi.title, 'authors': mi.authors, 'languages': mi.languages, 'filename': filename, 'id': job_id}\n    if ids:\n        ans['book_id'] = ids[0]\n        ctx.notify_changes(db.backend.library_path, books_added(ids))\n    else:\n        ans['duplicates'] = [{'title': m.title, 'authors': m.authors} for (m, _) in duplicates]\n    return ans",
            "@endpoint('/cdb/add-book/{job_id}/{add_duplicates}/{filename}/{library_id=None}', needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_add_book(ctx, rd, job_id, add_duplicates, filename, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Add a file as a new book. The file contents must be in the body of the request.\\n\\n    The response will also have the title/authors/languages read from the\\n    metadata of the file/filename. It will contain a `book_id` field specifying\\n    the id of the newly added book, or if add_duplicates is not specified and a\\n    duplicate was found, no book_id will be present, instead there will be a\\n    `duplicates` field specifying the title and authors for all duplicate\\n    matches. It will also return the value of `job_id` as the `id` field and\\n    `filename` as the `filename` field.\\n    '\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the add book interface with a user who has per library restrictions')\n    if not filename:\n        raise HTTPBadRequest('An empty filename is not allowed')\n    sfilename = sanitize_file_name(filename)\n    fmt = os.path.splitext(sfilename)[1]\n    fmt = fmt[1:] if fmt else None\n    if not fmt:\n        raise HTTPBadRequest('An filename with no extension is not allowed')\n    if isinstance(rd.request_body_file, BytesIO):\n        raise HTTPBadRequest('A request body containing the file data must be specified')\n    add_duplicates = add_duplicates in ('y', '1')\n    path = os.path.join(rd.tdir, sfilename)\n    rd.request_body_file.seek(0)\n    with open(path, 'wb') as f:\n        shutil.copyfileobj(rd.request_body_file, f)\n    from calibre.ebooks.metadata.worker import run_import_plugins\n    path = run_import_plugins((path,), time.monotonic_ns(), rd.tdir)[0]\n    with open(path, 'rb') as f:\n        mi = get_metadata(f, stream_type=os.path.splitext(path)[1][1:], use_libprs_metadata=True)\n        f.seek(0)\n        nfmt = os.path.splitext(path)[1]\n        fmt = nfmt[1:] if nfmt else fmt\n        (ids, duplicates) = db.add_books([(mi, {fmt: f})], add_duplicates=add_duplicates)\n    ans = {'title': mi.title, 'authors': mi.authors, 'languages': mi.languages, 'filename': filename, 'id': job_id}\n    if ids:\n        ans['book_id'] = ids[0]\n        ctx.notify_changes(db.backend.library_path, books_added(ids))\n    else:\n        ans['duplicates'] = [{'title': m.title, 'authors': m.authors} for (m, _) in duplicates]\n    return ans",
            "@endpoint('/cdb/add-book/{job_id}/{add_duplicates}/{filename}/{library_id=None}', needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_add_book(ctx, rd, job_id, add_duplicates, filename, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Add a file as a new book. The file contents must be in the body of the request.\\n\\n    The response will also have the title/authors/languages read from the\\n    metadata of the file/filename. It will contain a `book_id` field specifying\\n    the id of the newly added book, or if add_duplicates is not specified and a\\n    duplicate was found, no book_id will be present, instead there will be a\\n    `duplicates` field specifying the title and authors for all duplicate\\n    matches. It will also return the value of `job_id` as the `id` field and\\n    `filename` as the `filename` field.\\n    '\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the add book interface with a user who has per library restrictions')\n    if not filename:\n        raise HTTPBadRequest('An empty filename is not allowed')\n    sfilename = sanitize_file_name(filename)\n    fmt = os.path.splitext(sfilename)[1]\n    fmt = fmt[1:] if fmt else None\n    if not fmt:\n        raise HTTPBadRequest('An filename with no extension is not allowed')\n    if isinstance(rd.request_body_file, BytesIO):\n        raise HTTPBadRequest('A request body containing the file data must be specified')\n    add_duplicates = add_duplicates in ('y', '1')\n    path = os.path.join(rd.tdir, sfilename)\n    rd.request_body_file.seek(0)\n    with open(path, 'wb') as f:\n        shutil.copyfileobj(rd.request_body_file, f)\n    from calibre.ebooks.metadata.worker import run_import_plugins\n    path = run_import_plugins((path,), time.monotonic_ns(), rd.tdir)[0]\n    with open(path, 'rb') as f:\n        mi = get_metadata(f, stream_type=os.path.splitext(path)[1][1:], use_libprs_metadata=True)\n        f.seek(0)\n        nfmt = os.path.splitext(path)[1]\n        fmt = nfmt[1:] if nfmt else fmt\n        (ids, duplicates) = db.add_books([(mi, {fmt: f})], add_duplicates=add_duplicates)\n    ans = {'title': mi.title, 'authors': mi.authors, 'languages': mi.languages, 'filename': filename, 'id': job_id}\n    if ids:\n        ans['book_id'] = ids[0]\n        ctx.notify_changes(db.backend.library_path, books_added(ids))\n    else:\n        ans['duplicates'] = [{'title': m.title, 'authors': m.authors} for (m, _) in duplicates]\n    return ans",
            "@endpoint('/cdb/add-book/{job_id}/{add_duplicates}/{filename}/{library_id=None}', needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_add_book(ctx, rd, job_id, add_duplicates, filename, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Add a file as a new book. The file contents must be in the body of the request.\\n\\n    The response will also have the title/authors/languages read from the\\n    metadata of the file/filename. It will contain a `book_id` field specifying\\n    the id of the newly added book, or if add_duplicates is not specified and a\\n    duplicate was found, no book_id will be present, instead there will be a\\n    `duplicates` field specifying the title and authors for all duplicate\\n    matches. It will also return the value of `job_id` as the `id` field and\\n    `filename` as the `filename` field.\\n    '\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the add book interface with a user who has per library restrictions')\n    if not filename:\n        raise HTTPBadRequest('An empty filename is not allowed')\n    sfilename = sanitize_file_name(filename)\n    fmt = os.path.splitext(sfilename)[1]\n    fmt = fmt[1:] if fmt else None\n    if not fmt:\n        raise HTTPBadRequest('An filename with no extension is not allowed')\n    if isinstance(rd.request_body_file, BytesIO):\n        raise HTTPBadRequest('A request body containing the file data must be specified')\n    add_duplicates = add_duplicates in ('y', '1')\n    path = os.path.join(rd.tdir, sfilename)\n    rd.request_body_file.seek(0)\n    with open(path, 'wb') as f:\n        shutil.copyfileobj(rd.request_body_file, f)\n    from calibre.ebooks.metadata.worker import run_import_plugins\n    path = run_import_plugins((path,), time.monotonic_ns(), rd.tdir)[0]\n    with open(path, 'rb') as f:\n        mi = get_metadata(f, stream_type=os.path.splitext(path)[1][1:], use_libprs_metadata=True)\n        f.seek(0)\n        nfmt = os.path.splitext(path)[1]\n        fmt = nfmt[1:] if nfmt else fmt\n        (ids, duplicates) = db.add_books([(mi, {fmt: f})], add_duplicates=add_duplicates)\n    ans = {'title': mi.title, 'authors': mi.authors, 'languages': mi.languages, 'filename': filename, 'id': job_id}\n    if ids:\n        ans['book_id'] = ids[0]\n        ctx.notify_changes(db.backend.library_path, books_added(ids))\n    else:\n        ans['duplicates'] = [{'title': m.title, 'authors': m.authors} for (m, _) in duplicates]\n    return ans"
        ]
    },
    {
        "func_name": "cdb_delete_book",
        "original": "@endpoint('/cdb/delete-books/{book_ids}/{library_id=None}', needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_delete_book(ctx, rd, book_ids, library_id):\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the delete book interface with a user who has per library restrictions')\n    try:\n        ids = {int(x) for x in book_ids.split(',')}\n    except Exception:\n        raise HTTPBadRequest(f'invalid book_ids: {book_ids}')\n    db.remove_books(ids)\n    ctx.notify_changes(db.backend.library_path, books_deleted(ids))\n    return {}",
        "mutated": [
            "@endpoint('/cdb/delete-books/{book_ids}/{library_id=None}', needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_delete_book(ctx, rd, book_ids, library_id):\n    if False:\n        i = 10\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the delete book interface with a user who has per library restrictions')\n    try:\n        ids = {int(x) for x in book_ids.split(',')}\n    except Exception:\n        raise HTTPBadRequest(f'invalid book_ids: {book_ids}')\n    db.remove_books(ids)\n    ctx.notify_changes(db.backend.library_path, books_deleted(ids))\n    return {}",
            "@endpoint('/cdb/delete-books/{book_ids}/{library_id=None}', needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_delete_book(ctx, rd, book_ids, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the delete book interface with a user who has per library restrictions')\n    try:\n        ids = {int(x) for x in book_ids.split(',')}\n    except Exception:\n        raise HTTPBadRequest(f'invalid book_ids: {book_ids}')\n    db.remove_books(ids)\n    ctx.notify_changes(db.backend.library_path, books_deleted(ids))\n    return {}",
            "@endpoint('/cdb/delete-books/{book_ids}/{library_id=None}', needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_delete_book(ctx, rd, book_ids, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the delete book interface with a user who has per library restrictions')\n    try:\n        ids = {int(x) for x in book_ids.split(',')}\n    except Exception:\n        raise HTTPBadRequest(f'invalid book_ids: {book_ids}')\n    db.remove_books(ids)\n    ctx.notify_changes(db.backend.library_path, books_deleted(ids))\n    return {}",
            "@endpoint('/cdb/delete-books/{book_ids}/{library_id=None}', needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_delete_book(ctx, rd, book_ids, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the delete book interface with a user who has per library restrictions')\n    try:\n        ids = {int(x) for x in book_ids.split(',')}\n    except Exception:\n        raise HTTPBadRequest(f'invalid book_ids: {book_ids}')\n    db.remove_books(ids)\n    ctx.notify_changes(db.backend.library_path, books_deleted(ids))\n    return {}",
            "@endpoint('/cdb/delete-books/{book_ids}/{library_id=None}', needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_delete_book(ctx, rd, book_ids, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the delete book interface with a user who has per library restrictions')\n    try:\n        ids = {int(x) for x in book_ids.split(',')}\n    except Exception:\n        raise HTTPBadRequest(f'invalid book_ids: {book_ids}')\n    db.remove_books(ids)\n    ctx.notify_changes(db.backend.library_path, books_deleted(ids))\n    return {}"
        ]
    },
    {
        "func_name": "cdb_set_cover",
        "original": "@endpoint('/cdb/set-cover/{book_id}/{library_id=None}', types={'book_id': int}, needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_set_cover(ctx, rd, book_id, library_id):\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the add book interface with a user who has per library restrictions')\n    rd.request_body_file.seek(0)\n    dirtied = db.set_cover({book_id: rd.request_body_file})\n    ctx.notify_changes(db.backend.library_path, metadata(dirtied))\n    return tuple(dirtied)",
        "mutated": [
            "@endpoint('/cdb/set-cover/{book_id}/{library_id=None}', types={'book_id': int}, needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_set_cover(ctx, rd, book_id, library_id):\n    if False:\n        i = 10\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the add book interface with a user who has per library restrictions')\n    rd.request_body_file.seek(0)\n    dirtied = db.set_cover({book_id: rd.request_body_file})\n    ctx.notify_changes(db.backend.library_path, metadata(dirtied))\n    return tuple(dirtied)",
            "@endpoint('/cdb/set-cover/{book_id}/{library_id=None}', types={'book_id': int}, needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_set_cover(ctx, rd, book_id, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the add book interface with a user who has per library restrictions')\n    rd.request_body_file.seek(0)\n    dirtied = db.set_cover({book_id: rd.request_body_file})\n    ctx.notify_changes(db.backend.library_path, metadata(dirtied))\n    return tuple(dirtied)",
            "@endpoint('/cdb/set-cover/{book_id}/{library_id=None}', types={'book_id': int}, needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_set_cover(ctx, rd, book_id, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the add book interface with a user who has per library restrictions')\n    rd.request_body_file.seek(0)\n    dirtied = db.set_cover({book_id: rd.request_body_file})\n    ctx.notify_changes(db.backend.library_path, metadata(dirtied))\n    return tuple(dirtied)",
            "@endpoint('/cdb/set-cover/{book_id}/{library_id=None}', types={'book_id': int}, needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_set_cover(ctx, rd, book_id, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the add book interface with a user who has per library restrictions')\n    rd.request_body_file.seek(0)\n    dirtied = db.set_cover({book_id: rd.request_body_file})\n    ctx.notify_changes(db.backend.library_path, metadata(dirtied))\n    return tuple(dirtied)",
            "@endpoint('/cdb/set-cover/{book_id}/{library_id=None}', types={'book_id': int}, needs_db_write=True, postprocess=json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_set_cover(ctx, rd, book_id, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the add book interface with a user who has per library restrictions')\n    rd.request_body_file.seek(0)\n    dirtied = db.set_cover({book_id: rd.request_body_file})\n    ctx.notify_changes(db.backend.library_path, metadata(dirtied))\n    return tuple(dirtied)"
        ]
    },
    {
        "func_name": "load_payload_data",
        "original": "def load_payload_data(rd):\n    raw = rd.read()\n    ct = rd.inheaders.get('Content-Type', all=True)\n    ct = {x.lower().partition(';')[0] for x in ct}\n    try:\n        if MSGPACK_MIME in ct:\n            return msgpack_loads(raw)\n        elif 'application/json' in ct:\n            return json_loads(raw)\n        else:\n            raise HTTPBadRequest('Only JSON or msgpack requests are supported')\n    except Exception:\n        raise HTTPBadRequest('Invalid encoded data')",
        "mutated": [
            "def load_payload_data(rd):\n    if False:\n        i = 10\n    raw = rd.read()\n    ct = rd.inheaders.get('Content-Type', all=True)\n    ct = {x.lower().partition(';')[0] for x in ct}\n    try:\n        if MSGPACK_MIME in ct:\n            return msgpack_loads(raw)\n        elif 'application/json' in ct:\n            return json_loads(raw)\n        else:\n            raise HTTPBadRequest('Only JSON or msgpack requests are supported')\n    except Exception:\n        raise HTTPBadRequest('Invalid encoded data')",
            "def load_payload_data(rd):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    raw = rd.read()\n    ct = rd.inheaders.get('Content-Type', all=True)\n    ct = {x.lower().partition(';')[0] for x in ct}\n    try:\n        if MSGPACK_MIME in ct:\n            return msgpack_loads(raw)\n        elif 'application/json' in ct:\n            return json_loads(raw)\n        else:\n            raise HTTPBadRequest('Only JSON or msgpack requests are supported')\n    except Exception:\n        raise HTTPBadRequest('Invalid encoded data')",
            "def load_payload_data(rd):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    raw = rd.read()\n    ct = rd.inheaders.get('Content-Type', all=True)\n    ct = {x.lower().partition(';')[0] for x in ct}\n    try:\n        if MSGPACK_MIME in ct:\n            return msgpack_loads(raw)\n        elif 'application/json' in ct:\n            return json_loads(raw)\n        else:\n            raise HTTPBadRequest('Only JSON or msgpack requests are supported')\n    except Exception:\n        raise HTTPBadRequest('Invalid encoded data')",
            "def load_payload_data(rd):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    raw = rd.read()\n    ct = rd.inheaders.get('Content-Type', all=True)\n    ct = {x.lower().partition(';')[0] for x in ct}\n    try:\n        if MSGPACK_MIME in ct:\n            return msgpack_loads(raw)\n        elif 'application/json' in ct:\n            return json_loads(raw)\n        else:\n            raise HTTPBadRequest('Only JSON or msgpack requests are supported')\n    except Exception:\n        raise HTTPBadRequest('Invalid encoded data')",
            "def load_payload_data(rd):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    raw = rd.read()\n    ct = rd.inheaders.get('Content-Type', all=True)\n    ct = {x.lower().partition(';')[0] for x in ct}\n    try:\n        if MSGPACK_MIME in ct:\n            return msgpack_loads(raw)\n        elif 'application/json' in ct:\n            return json_loads(raw)\n        else:\n            raise HTTPBadRequest('Only JSON or msgpack requests are supported')\n    except Exception:\n        raise HTTPBadRequest('Invalid encoded data')"
        ]
    },
    {
        "func_name": "cdb_set_fields",
        "original": "@endpoint('/cdb/set-fields/{book_id}/{library_id=None}', types={'book_id': int}, needs_db_write=True, postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_set_fields(ctx, rd, book_id, library_id):\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the set fields interface with a user who has per library restrictions')\n    data = load_payload_data(rd)\n    try:\n        (changes, loaded_book_ids) = (data['changes'], frozenset(map(int, data.get('loaded_book_ids', ()))))\n        all_dirtied = bool(data.get('all_dirtied'))\n        if not isinstance(changes, dict):\n            raise TypeError('changes must be a dict')\n    except Exception:\n        raise HTTPBadRequest(\"Data must be of the form {'changes': {'title': 'New Title', ...}, 'loaded_book_ids':[book_id1, book_id2, ...]'}\")\n    dirtied = set()\n    cdata = changes.pop('cover', False)\n    if cdata is not False:\n        if cdata is not None:\n            try:\n                cdata = from_base64_bytes(cdata.split(',', 1)[-1])\n            except Exception:\n                raise HTTPBadRequest('Cover data is not valid base64 encoded data')\n            try:\n                fmt = what(None, cdata)\n            except Exception:\n                fmt = None\n            if fmt not in ('jpeg', 'png'):\n                raise HTTPBadRequest('Cover data must be either JPEG or PNG')\n        dirtied |= db.set_cover({book_id: cdata})\n    added_formats = changes.pop('added_formats', False)\n    if added_formats:\n        for data in added_formats:\n            try:\n                fmt = data['ext'].upper()\n            except Exception:\n                raise HTTPBadRequest('Format has no extension')\n            if fmt:\n                try:\n                    fmt_data = from_base64_bytes(data['data_url'].split(',', 1)[-1])\n                except Exception:\n                    raise HTTPBadRequest('Format data is not valid base64 encoded data')\n                if db.add_format(book_id, fmt, ReadOnlyFileBuffer(fmt_data)):\n                    dirtied.add(book_id)\n    removed_formats = changes.pop('removed_formats', False)\n    if removed_formats:\n        db.remove_formats({book_id: list(removed_formats)})\n        dirtied.add(book_id)\n    for (field, value) in iteritems(changes):\n        dirtied |= db.set_field(field, {book_id: value})\n    ctx.notify_changes(db.backend.library_path, metadata(dirtied))\n    all_ids = dirtied if all_dirtied else dirtied & loaded_book_ids\n    all_ids |= {book_id}\n    return {bid: book_as_json(db, bid) for bid in all_ids}",
        "mutated": [
            "@endpoint('/cdb/set-fields/{book_id}/{library_id=None}', types={'book_id': int}, needs_db_write=True, postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_set_fields(ctx, rd, book_id, library_id):\n    if False:\n        i = 10\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the set fields interface with a user who has per library restrictions')\n    data = load_payload_data(rd)\n    try:\n        (changes, loaded_book_ids) = (data['changes'], frozenset(map(int, data.get('loaded_book_ids', ()))))\n        all_dirtied = bool(data.get('all_dirtied'))\n        if not isinstance(changes, dict):\n            raise TypeError('changes must be a dict')\n    except Exception:\n        raise HTTPBadRequest(\"Data must be of the form {'changes': {'title': 'New Title', ...}, 'loaded_book_ids':[book_id1, book_id2, ...]'}\")\n    dirtied = set()\n    cdata = changes.pop('cover', False)\n    if cdata is not False:\n        if cdata is not None:\n            try:\n                cdata = from_base64_bytes(cdata.split(',', 1)[-1])\n            except Exception:\n                raise HTTPBadRequest('Cover data is not valid base64 encoded data')\n            try:\n                fmt = what(None, cdata)\n            except Exception:\n                fmt = None\n            if fmt not in ('jpeg', 'png'):\n                raise HTTPBadRequest('Cover data must be either JPEG or PNG')\n        dirtied |= db.set_cover({book_id: cdata})\n    added_formats = changes.pop('added_formats', False)\n    if added_formats:\n        for data in added_formats:\n            try:\n                fmt = data['ext'].upper()\n            except Exception:\n                raise HTTPBadRequest('Format has no extension')\n            if fmt:\n                try:\n                    fmt_data = from_base64_bytes(data['data_url'].split(',', 1)[-1])\n                except Exception:\n                    raise HTTPBadRequest('Format data is not valid base64 encoded data')\n                if db.add_format(book_id, fmt, ReadOnlyFileBuffer(fmt_data)):\n                    dirtied.add(book_id)\n    removed_formats = changes.pop('removed_formats', False)\n    if removed_formats:\n        db.remove_formats({book_id: list(removed_formats)})\n        dirtied.add(book_id)\n    for (field, value) in iteritems(changes):\n        dirtied |= db.set_field(field, {book_id: value})\n    ctx.notify_changes(db.backend.library_path, metadata(dirtied))\n    all_ids = dirtied if all_dirtied else dirtied & loaded_book_ids\n    all_ids |= {book_id}\n    return {bid: book_as_json(db, bid) for bid in all_ids}",
            "@endpoint('/cdb/set-fields/{book_id}/{library_id=None}', types={'book_id': int}, needs_db_write=True, postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_set_fields(ctx, rd, book_id, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the set fields interface with a user who has per library restrictions')\n    data = load_payload_data(rd)\n    try:\n        (changes, loaded_book_ids) = (data['changes'], frozenset(map(int, data.get('loaded_book_ids', ()))))\n        all_dirtied = bool(data.get('all_dirtied'))\n        if not isinstance(changes, dict):\n            raise TypeError('changes must be a dict')\n    except Exception:\n        raise HTTPBadRequest(\"Data must be of the form {'changes': {'title': 'New Title', ...}, 'loaded_book_ids':[book_id1, book_id2, ...]'}\")\n    dirtied = set()\n    cdata = changes.pop('cover', False)\n    if cdata is not False:\n        if cdata is not None:\n            try:\n                cdata = from_base64_bytes(cdata.split(',', 1)[-1])\n            except Exception:\n                raise HTTPBadRequest('Cover data is not valid base64 encoded data')\n            try:\n                fmt = what(None, cdata)\n            except Exception:\n                fmt = None\n            if fmt not in ('jpeg', 'png'):\n                raise HTTPBadRequest('Cover data must be either JPEG or PNG')\n        dirtied |= db.set_cover({book_id: cdata})\n    added_formats = changes.pop('added_formats', False)\n    if added_formats:\n        for data in added_formats:\n            try:\n                fmt = data['ext'].upper()\n            except Exception:\n                raise HTTPBadRequest('Format has no extension')\n            if fmt:\n                try:\n                    fmt_data = from_base64_bytes(data['data_url'].split(',', 1)[-1])\n                except Exception:\n                    raise HTTPBadRequest('Format data is not valid base64 encoded data')\n                if db.add_format(book_id, fmt, ReadOnlyFileBuffer(fmt_data)):\n                    dirtied.add(book_id)\n    removed_formats = changes.pop('removed_formats', False)\n    if removed_formats:\n        db.remove_formats({book_id: list(removed_formats)})\n        dirtied.add(book_id)\n    for (field, value) in iteritems(changes):\n        dirtied |= db.set_field(field, {book_id: value})\n    ctx.notify_changes(db.backend.library_path, metadata(dirtied))\n    all_ids = dirtied if all_dirtied else dirtied & loaded_book_ids\n    all_ids |= {book_id}\n    return {bid: book_as_json(db, bid) for bid in all_ids}",
            "@endpoint('/cdb/set-fields/{book_id}/{library_id=None}', types={'book_id': int}, needs_db_write=True, postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_set_fields(ctx, rd, book_id, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the set fields interface with a user who has per library restrictions')\n    data = load_payload_data(rd)\n    try:\n        (changes, loaded_book_ids) = (data['changes'], frozenset(map(int, data.get('loaded_book_ids', ()))))\n        all_dirtied = bool(data.get('all_dirtied'))\n        if not isinstance(changes, dict):\n            raise TypeError('changes must be a dict')\n    except Exception:\n        raise HTTPBadRequest(\"Data must be of the form {'changes': {'title': 'New Title', ...}, 'loaded_book_ids':[book_id1, book_id2, ...]'}\")\n    dirtied = set()\n    cdata = changes.pop('cover', False)\n    if cdata is not False:\n        if cdata is not None:\n            try:\n                cdata = from_base64_bytes(cdata.split(',', 1)[-1])\n            except Exception:\n                raise HTTPBadRequest('Cover data is not valid base64 encoded data')\n            try:\n                fmt = what(None, cdata)\n            except Exception:\n                fmt = None\n            if fmt not in ('jpeg', 'png'):\n                raise HTTPBadRequest('Cover data must be either JPEG or PNG')\n        dirtied |= db.set_cover({book_id: cdata})\n    added_formats = changes.pop('added_formats', False)\n    if added_formats:\n        for data in added_formats:\n            try:\n                fmt = data['ext'].upper()\n            except Exception:\n                raise HTTPBadRequest('Format has no extension')\n            if fmt:\n                try:\n                    fmt_data = from_base64_bytes(data['data_url'].split(',', 1)[-1])\n                except Exception:\n                    raise HTTPBadRequest('Format data is not valid base64 encoded data')\n                if db.add_format(book_id, fmt, ReadOnlyFileBuffer(fmt_data)):\n                    dirtied.add(book_id)\n    removed_formats = changes.pop('removed_formats', False)\n    if removed_formats:\n        db.remove_formats({book_id: list(removed_formats)})\n        dirtied.add(book_id)\n    for (field, value) in iteritems(changes):\n        dirtied |= db.set_field(field, {book_id: value})\n    ctx.notify_changes(db.backend.library_path, metadata(dirtied))\n    all_ids = dirtied if all_dirtied else dirtied & loaded_book_ids\n    all_ids |= {book_id}\n    return {bid: book_as_json(db, bid) for bid in all_ids}",
            "@endpoint('/cdb/set-fields/{book_id}/{library_id=None}', types={'book_id': int}, needs_db_write=True, postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_set_fields(ctx, rd, book_id, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the set fields interface with a user who has per library restrictions')\n    data = load_payload_data(rd)\n    try:\n        (changes, loaded_book_ids) = (data['changes'], frozenset(map(int, data.get('loaded_book_ids', ()))))\n        all_dirtied = bool(data.get('all_dirtied'))\n        if not isinstance(changes, dict):\n            raise TypeError('changes must be a dict')\n    except Exception:\n        raise HTTPBadRequest(\"Data must be of the form {'changes': {'title': 'New Title', ...}, 'loaded_book_ids':[book_id1, book_id2, ...]'}\")\n    dirtied = set()\n    cdata = changes.pop('cover', False)\n    if cdata is not False:\n        if cdata is not None:\n            try:\n                cdata = from_base64_bytes(cdata.split(',', 1)[-1])\n            except Exception:\n                raise HTTPBadRequest('Cover data is not valid base64 encoded data')\n            try:\n                fmt = what(None, cdata)\n            except Exception:\n                fmt = None\n            if fmt not in ('jpeg', 'png'):\n                raise HTTPBadRequest('Cover data must be either JPEG or PNG')\n        dirtied |= db.set_cover({book_id: cdata})\n    added_formats = changes.pop('added_formats', False)\n    if added_formats:\n        for data in added_formats:\n            try:\n                fmt = data['ext'].upper()\n            except Exception:\n                raise HTTPBadRequest('Format has no extension')\n            if fmt:\n                try:\n                    fmt_data = from_base64_bytes(data['data_url'].split(',', 1)[-1])\n                except Exception:\n                    raise HTTPBadRequest('Format data is not valid base64 encoded data')\n                if db.add_format(book_id, fmt, ReadOnlyFileBuffer(fmt_data)):\n                    dirtied.add(book_id)\n    removed_formats = changes.pop('removed_formats', False)\n    if removed_formats:\n        db.remove_formats({book_id: list(removed_formats)})\n        dirtied.add(book_id)\n    for (field, value) in iteritems(changes):\n        dirtied |= db.set_field(field, {book_id: value})\n    ctx.notify_changes(db.backend.library_path, metadata(dirtied))\n    all_ids = dirtied if all_dirtied else dirtied & loaded_book_ids\n    all_ids |= {book_id}\n    return {bid: book_as_json(db, bid) for bid in all_ids}",
            "@endpoint('/cdb/set-fields/{book_id}/{library_id=None}', types={'book_id': int}, needs_db_write=True, postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_set_fields(ctx, rd, book_id, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    db = get_db(ctx, rd, library_id)\n    if ctx.restriction_for(rd, db):\n        raise HTTPForbidden('Cannot use the set fields interface with a user who has per library restrictions')\n    data = load_payload_data(rd)\n    try:\n        (changes, loaded_book_ids) = (data['changes'], frozenset(map(int, data.get('loaded_book_ids', ()))))\n        all_dirtied = bool(data.get('all_dirtied'))\n        if not isinstance(changes, dict):\n            raise TypeError('changes must be a dict')\n    except Exception:\n        raise HTTPBadRequest(\"Data must be of the form {'changes': {'title': 'New Title', ...}, 'loaded_book_ids':[book_id1, book_id2, ...]'}\")\n    dirtied = set()\n    cdata = changes.pop('cover', False)\n    if cdata is not False:\n        if cdata is not None:\n            try:\n                cdata = from_base64_bytes(cdata.split(',', 1)[-1])\n            except Exception:\n                raise HTTPBadRequest('Cover data is not valid base64 encoded data')\n            try:\n                fmt = what(None, cdata)\n            except Exception:\n                fmt = None\n            if fmt not in ('jpeg', 'png'):\n                raise HTTPBadRequest('Cover data must be either JPEG or PNG')\n        dirtied |= db.set_cover({book_id: cdata})\n    added_formats = changes.pop('added_formats', False)\n    if added_formats:\n        for data in added_formats:\n            try:\n                fmt = data['ext'].upper()\n            except Exception:\n                raise HTTPBadRequest('Format has no extension')\n            if fmt:\n                try:\n                    fmt_data = from_base64_bytes(data['data_url'].split(',', 1)[-1])\n                except Exception:\n                    raise HTTPBadRequest('Format data is not valid base64 encoded data')\n                if db.add_format(book_id, fmt, ReadOnlyFileBuffer(fmt_data)):\n                    dirtied.add(book_id)\n    removed_formats = changes.pop('removed_formats', False)\n    if removed_formats:\n        db.remove_formats({book_id: list(removed_formats)})\n        dirtied.add(book_id)\n    for (field, value) in iteritems(changes):\n        dirtied |= db.set_field(field, {book_id: value})\n    ctx.notify_changes(db.backend.library_path, metadata(dirtied))\n    all_ids = dirtied if all_dirtied else dirtied & loaded_book_ids\n    all_ids |= {book_id}\n    return {bid: book_as_json(db, bid) for bid in all_ids}"
        ]
    },
    {
        "func_name": "cdb_copy_to_library",
        "original": "@endpoint('/cdb/copy-to-library/{target_library_id}/{library_id=None}', needs_db_write=True, postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_copy_to_library(ctx, rd, target_library_id, library_id):\n    db_src = get_db(ctx, rd, library_id)\n    db_dest = get_db(ctx, rd, target_library_id)\n    if ctx.restriction_for(rd, db_src) or ctx.restriction_for(rd, db_dest):\n        raise HTTPForbidden('Cannot use the copy to library interface with a user who has per library restrictions')\n    data = load_payload_data(rd)\n    try:\n        book_ids = {int(x) for x in data['book_ids']}\n        move_books = bool(data.get('move', False))\n        preserve_date = bool(data.get('preserve_date', True))\n        duplicate_action = data.get('duplicate_action') or 'add'\n        automerge_action = data.get('automerge_action') or 'overwrite'\n    except Exception:\n        raise HTTPBadRequest('Invalid encoded data, must be of the form: {book_ids: [id1, id2, ..]}')\n    if duplicate_action not in ('add', 'add_formats_to_existing', 'ignore'):\n        raise HTTPBadRequest('duplicate_action must be one of: add, add_formats_to_existing, ignore')\n    if automerge_action not in ('overwrite', 'ignore', 'new record'):\n        raise HTTPBadRequest('automerge_action must be one of: overwrite, ignore, new record')\n    response = {}\n    identical_books_data = None\n    if duplicate_action != 'add':\n        identical_books_data = db_dest.data_for_find_identical_books()\n    to_remove = set()\n    from calibre.db.copy_to_library import copy_one_book\n    for book_id in book_ids:\n        try:\n            rdata = copy_one_book(book_id, db_src, db_dest, duplicate_action=duplicate_action, automerge_action=automerge_action, preserve_uuid=move_books, preserve_date=preserve_date, identical_books_data=identical_books_data)\n            if move_books:\n                to_remove.add(book_id)\n            response[book_id] = {'ok': True, 'payload': rdata}\n        except Exception:\n            import traceback\n            response[book_id] = {'ok': False, 'payload': traceback.format_exc()}\n    if to_remove:\n        db_src.remove_books(to_remove, permanent=True)\n    return response",
        "mutated": [
            "@endpoint('/cdb/copy-to-library/{target_library_id}/{library_id=None}', needs_db_write=True, postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_copy_to_library(ctx, rd, target_library_id, library_id):\n    if False:\n        i = 10\n    db_src = get_db(ctx, rd, library_id)\n    db_dest = get_db(ctx, rd, target_library_id)\n    if ctx.restriction_for(rd, db_src) or ctx.restriction_for(rd, db_dest):\n        raise HTTPForbidden('Cannot use the copy to library interface with a user who has per library restrictions')\n    data = load_payload_data(rd)\n    try:\n        book_ids = {int(x) for x in data['book_ids']}\n        move_books = bool(data.get('move', False))\n        preserve_date = bool(data.get('preserve_date', True))\n        duplicate_action = data.get('duplicate_action') or 'add'\n        automerge_action = data.get('automerge_action') or 'overwrite'\n    except Exception:\n        raise HTTPBadRequest('Invalid encoded data, must be of the form: {book_ids: [id1, id2, ..]}')\n    if duplicate_action not in ('add', 'add_formats_to_existing', 'ignore'):\n        raise HTTPBadRequest('duplicate_action must be one of: add, add_formats_to_existing, ignore')\n    if automerge_action not in ('overwrite', 'ignore', 'new record'):\n        raise HTTPBadRequest('automerge_action must be one of: overwrite, ignore, new record')\n    response = {}\n    identical_books_data = None\n    if duplicate_action != 'add':\n        identical_books_data = db_dest.data_for_find_identical_books()\n    to_remove = set()\n    from calibre.db.copy_to_library import copy_one_book\n    for book_id in book_ids:\n        try:\n            rdata = copy_one_book(book_id, db_src, db_dest, duplicate_action=duplicate_action, automerge_action=automerge_action, preserve_uuid=move_books, preserve_date=preserve_date, identical_books_data=identical_books_data)\n            if move_books:\n                to_remove.add(book_id)\n            response[book_id] = {'ok': True, 'payload': rdata}\n        except Exception:\n            import traceback\n            response[book_id] = {'ok': False, 'payload': traceback.format_exc()}\n    if to_remove:\n        db_src.remove_books(to_remove, permanent=True)\n    return response",
            "@endpoint('/cdb/copy-to-library/{target_library_id}/{library_id=None}', needs_db_write=True, postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_copy_to_library(ctx, rd, target_library_id, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    db_src = get_db(ctx, rd, library_id)\n    db_dest = get_db(ctx, rd, target_library_id)\n    if ctx.restriction_for(rd, db_src) or ctx.restriction_for(rd, db_dest):\n        raise HTTPForbidden('Cannot use the copy to library interface with a user who has per library restrictions')\n    data = load_payload_data(rd)\n    try:\n        book_ids = {int(x) for x in data['book_ids']}\n        move_books = bool(data.get('move', False))\n        preserve_date = bool(data.get('preserve_date', True))\n        duplicate_action = data.get('duplicate_action') or 'add'\n        automerge_action = data.get('automerge_action') or 'overwrite'\n    except Exception:\n        raise HTTPBadRequest('Invalid encoded data, must be of the form: {book_ids: [id1, id2, ..]}')\n    if duplicate_action not in ('add', 'add_formats_to_existing', 'ignore'):\n        raise HTTPBadRequest('duplicate_action must be one of: add, add_formats_to_existing, ignore')\n    if automerge_action not in ('overwrite', 'ignore', 'new record'):\n        raise HTTPBadRequest('automerge_action must be one of: overwrite, ignore, new record')\n    response = {}\n    identical_books_data = None\n    if duplicate_action != 'add':\n        identical_books_data = db_dest.data_for_find_identical_books()\n    to_remove = set()\n    from calibre.db.copy_to_library import copy_one_book\n    for book_id in book_ids:\n        try:\n            rdata = copy_one_book(book_id, db_src, db_dest, duplicate_action=duplicate_action, automerge_action=automerge_action, preserve_uuid=move_books, preserve_date=preserve_date, identical_books_data=identical_books_data)\n            if move_books:\n                to_remove.add(book_id)\n            response[book_id] = {'ok': True, 'payload': rdata}\n        except Exception:\n            import traceback\n            response[book_id] = {'ok': False, 'payload': traceback.format_exc()}\n    if to_remove:\n        db_src.remove_books(to_remove, permanent=True)\n    return response",
            "@endpoint('/cdb/copy-to-library/{target_library_id}/{library_id=None}', needs_db_write=True, postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_copy_to_library(ctx, rd, target_library_id, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    db_src = get_db(ctx, rd, library_id)\n    db_dest = get_db(ctx, rd, target_library_id)\n    if ctx.restriction_for(rd, db_src) or ctx.restriction_for(rd, db_dest):\n        raise HTTPForbidden('Cannot use the copy to library interface with a user who has per library restrictions')\n    data = load_payload_data(rd)\n    try:\n        book_ids = {int(x) for x in data['book_ids']}\n        move_books = bool(data.get('move', False))\n        preserve_date = bool(data.get('preserve_date', True))\n        duplicate_action = data.get('duplicate_action') or 'add'\n        automerge_action = data.get('automerge_action') or 'overwrite'\n    except Exception:\n        raise HTTPBadRequest('Invalid encoded data, must be of the form: {book_ids: [id1, id2, ..]}')\n    if duplicate_action not in ('add', 'add_formats_to_existing', 'ignore'):\n        raise HTTPBadRequest('duplicate_action must be one of: add, add_formats_to_existing, ignore')\n    if automerge_action not in ('overwrite', 'ignore', 'new record'):\n        raise HTTPBadRequest('automerge_action must be one of: overwrite, ignore, new record')\n    response = {}\n    identical_books_data = None\n    if duplicate_action != 'add':\n        identical_books_data = db_dest.data_for_find_identical_books()\n    to_remove = set()\n    from calibre.db.copy_to_library import copy_one_book\n    for book_id in book_ids:\n        try:\n            rdata = copy_one_book(book_id, db_src, db_dest, duplicate_action=duplicate_action, automerge_action=automerge_action, preserve_uuid=move_books, preserve_date=preserve_date, identical_books_data=identical_books_data)\n            if move_books:\n                to_remove.add(book_id)\n            response[book_id] = {'ok': True, 'payload': rdata}\n        except Exception:\n            import traceback\n            response[book_id] = {'ok': False, 'payload': traceback.format_exc()}\n    if to_remove:\n        db_src.remove_books(to_remove, permanent=True)\n    return response",
            "@endpoint('/cdb/copy-to-library/{target_library_id}/{library_id=None}', needs_db_write=True, postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_copy_to_library(ctx, rd, target_library_id, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    db_src = get_db(ctx, rd, library_id)\n    db_dest = get_db(ctx, rd, target_library_id)\n    if ctx.restriction_for(rd, db_src) or ctx.restriction_for(rd, db_dest):\n        raise HTTPForbidden('Cannot use the copy to library interface with a user who has per library restrictions')\n    data = load_payload_data(rd)\n    try:\n        book_ids = {int(x) for x in data['book_ids']}\n        move_books = bool(data.get('move', False))\n        preserve_date = bool(data.get('preserve_date', True))\n        duplicate_action = data.get('duplicate_action') or 'add'\n        automerge_action = data.get('automerge_action') or 'overwrite'\n    except Exception:\n        raise HTTPBadRequest('Invalid encoded data, must be of the form: {book_ids: [id1, id2, ..]}')\n    if duplicate_action not in ('add', 'add_formats_to_existing', 'ignore'):\n        raise HTTPBadRequest('duplicate_action must be one of: add, add_formats_to_existing, ignore')\n    if automerge_action not in ('overwrite', 'ignore', 'new record'):\n        raise HTTPBadRequest('automerge_action must be one of: overwrite, ignore, new record')\n    response = {}\n    identical_books_data = None\n    if duplicate_action != 'add':\n        identical_books_data = db_dest.data_for_find_identical_books()\n    to_remove = set()\n    from calibre.db.copy_to_library import copy_one_book\n    for book_id in book_ids:\n        try:\n            rdata = copy_one_book(book_id, db_src, db_dest, duplicate_action=duplicate_action, automerge_action=automerge_action, preserve_uuid=move_books, preserve_date=preserve_date, identical_books_data=identical_books_data)\n            if move_books:\n                to_remove.add(book_id)\n            response[book_id] = {'ok': True, 'payload': rdata}\n        except Exception:\n            import traceback\n            response[book_id] = {'ok': False, 'payload': traceback.format_exc()}\n    if to_remove:\n        db_src.remove_books(to_remove, permanent=True)\n    return response",
            "@endpoint('/cdb/copy-to-library/{target_library_id}/{library_id=None}', needs_db_write=True, postprocess=msgpack_or_json, methods=receive_data_methods, cache_control='no-cache')\ndef cdb_copy_to_library(ctx, rd, target_library_id, library_id):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    db_src = get_db(ctx, rd, library_id)\n    db_dest = get_db(ctx, rd, target_library_id)\n    if ctx.restriction_for(rd, db_src) or ctx.restriction_for(rd, db_dest):\n        raise HTTPForbidden('Cannot use the copy to library interface with a user who has per library restrictions')\n    data = load_payload_data(rd)\n    try:\n        book_ids = {int(x) for x in data['book_ids']}\n        move_books = bool(data.get('move', False))\n        preserve_date = bool(data.get('preserve_date', True))\n        duplicate_action = data.get('duplicate_action') or 'add'\n        automerge_action = data.get('automerge_action') or 'overwrite'\n    except Exception:\n        raise HTTPBadRequest('Invalid encoded data, must be of the form: {book_ids: [id1, id2, ..]}')\n    if duplicate_action not in ('add', 'add_formats_to_existing', 'ignore'):\n        raise HTTPBadRequest('duplicate_action must be one of: add, add_formats_to_existing, ignore')\n    if automerge_action not in ('overwrite', 'ignore', 'new record'):\n        raise HTTPBadRequest('automerge_action must be one of: overwrite, ignore, new record')\n    response = {}\n    identical_books_data = None\n    if duplicate_action != 'add':\n        identical_books_data = db_dest.data_for_find_identical_books()\n    to_remove = set()\n    from calibre.db.copy_to_library import copy_one_book\n    for book_id in book_ids:\n        try:\n            rdata = copy_one_book(book_id, db_src, db_dest, duplicate_action=duplicate_action, automerge_action=automerge_action, preserve_uuid=move_books, preserve_date=preserve_date, identical_books_data=identical_books_data)\n            if move_books:\n                to_remove.add(book_id)\n            response[book_id] = {'ok': True, 'payload': rdata}\n        except Exception:\n            import traceback\n            response[book_id] = {'ok': False, 'payload': traceback.format_exc()}\n    if to_remove:\n        db_src.remove_books(to_remove, permanent=True)\n    return response"
        ]
    }
]