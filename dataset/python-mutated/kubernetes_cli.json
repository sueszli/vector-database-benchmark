[
    {
        "func_name": "cli",
        "original": "@click.group()\ndef cli():\n    pass",
        "mutated": [
            "@click.group()\ndef cli():\n    if False:\n        i = 10\n    pass",
            "@click.group()\ndef cli():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    pass",
            "@click.group()\ndef cli():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    pass",
            "@click.group()\ndef cli():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    pass",
            "@click.group()\ndef cli():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    pass"
        ]
    },
    {
        "func_name": "kubernetes",
        "original": "@cli.group(help='Commands related to Kubernetes.')\ndef kubernetes():\n    pass",
        "mutated": [
            "@cli.group(help='Commands related to Kubernetes.')\ndef kubernetes():\n    if False:\n        i = 10\n    pass",
            "@cli.group(help='Commands related to Kubernetes.')\ndef kubernetes():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    pass",
            "@cli.group(help='Commands related to Kubernetes.')\ndef kubernetes():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    pass",
            "@cli.group(help='Commands related to Kubernetes.')\ndef kubernetes():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    pass",
            "@cli.group(help='Commands related to Kubernetes.')\ndef kubernetes():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    pass"
        ]
    },
    {
        "func_name": "echo",
        "original": "def echo(msg, stream='stderr', job_id=None, **kwargs):\n    msg = util.to_unicode(msg)\n    if job_id:\n        msg = '[%s] %s' % (job_id, msg)\n    ctx.obj.echo_always(msg, err=stream == sys.stderr, **kwargs)",
        "mutated": [
            "def echo(msg, stream='stderr', job_id=None, **kwargs):\n    if False:\n        i = 10\n    msg = util.to_unicode(msg)\n    if job_id:\n        msg = '[%s] %s' % (job_id, msg)\n    ctx.obj.echo_always(msg, err=stream == sys.stderr, **kwargs)",
            "def echo(msg, stream='stderr', job_id=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    msg = util.to_unicode(msg)\n    if job_id:\n        msg = '[%s] %s' % (job_id, msg)\n    ctx.obj.echo_always(msg, err=stream == sys.stderr, **kwargs)",
            "def echo(msg, stream='stderr', job_id=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    msg = util.to_unicode(msg)\n    if job_id:\n        msg = '[%s] %s' % (job_id, msg)\n    ctx.obj.echo_always(msg, err=stream == sys.stderr, **kwargs)",
            "def echo(msg, stream='stderr', job_id=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    msg = util.to_unicode(msg)\n    if job_id:\n        msg = '[%s] %s' % (job_id, msg)\n    ctx.obj.echo_always(msg, err=stream == sys.stderr, **kwargs)",
            "def echo(msg, stream='stderr', job_id=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    msg = util.to_unicode(msg)\n    if job_id:\n        msg = '[%s] %s' % (job_id, msg)\n    ctx.obj.echo_always(msg, err=stream == sys.stderr, **kwargs)"
        ]
    },
    {
        "func_name": "_sync_metadata",
        "original": "def _sync_metadata():\n    if ctx.obj.metadata.TYPE == 'local':\n        sync_local_metadata_from_datastore(DATASTORE_LOCAL_DIR, ctx.obj.flow_datastore.get_task_datastore(kwargs['run_id'], step_name, kwargs['task_id']))",
        "mutated": [
            "def _sync_metadata():\n    if False:\n        i = 10\n    if ctx.obj.metadata.TYPE == 'local':\n        sync_local_metadata_from_datastore(DATASTORE_LOCAL_DIR, ctx.obj.flow_datastore.get_task_datastore(kwargs['run_id'], step_name, kwargs['task_id']))",
            "def _sync_metadata():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if ctx.obj.metadata.TYPE == 'local':\n        sync_local_metadata_from_datastore(DATASTORE_LOCAL_DIR, ctx.obj.flow_datastore.get_task_datastore(kwargs['run_id'], step_name, kwargs['task_id']))",
            "def _sync_metadata():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if ctx.obj.metadata.TYPE == 'local':\n        sync_local_metadata_from_datastore(DATASTORE_LOCAL_DIR, ctx.obj.flow_datastore.get_task_datastore(kwargs['run_id'], step_name, kwargs['task_id']))",
            "def _sync_metadata():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if ctx.obj.metadata.TYPE == 'local':\n        sync_local_metadata_from_datastore(DATASTORE_LOCAL_DIR, ctx.obj.flow_datastore.get_task_datastore(kwargs['run_id'], step_name, kwargs['task_id']))",
            "def _sync_metadata():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if ctx.obj.metadata.TYPE == 'local':\n        sync_local_metadata_from_datastore(DATASTORE_LOCAL_DIR, ctx.obj.flow_datastore.get_task_datastore(kwargs['run_id'], step_name, kwargs['task_id']))"
        ]
    },
    {
        "func_name": "step",
        "original": "@tracing.cli_entrypoint('kubernetes/step')\n@kubernetes.command(help='Execute a single task on Kubernetes. This command calls the top-level step command inside a Kubernetes pod with the given options. Typically you do not call this command directly; it is used internally by Metaflow.')\n@click.argument('step-name')\n@click.argument('code-package-sha')\n@click.argument('code-package-url')\n@click.option('--executable', help='Executable requirement for Kubernetes pod.')\n@click.option('--image', help='Docker image requirement for Kubernetes pod.')\n@click.option('--image-pull-policy', default=None, help='Optional Docker Image Pull Policy for Kubernetes pod.')\n@click.option('--service-account', help='IRSA requirement for Kubernetes pod.')\n@click.option('--secrets', multiple=True, default=None, help='Secrets for Kubernetes pod.')\n@click.option('--node-selector', multiple=True, default=None, help='NodeSelector for Kubernetes pod.')\n@click.option('--k8s-namespace', default=None, help='Namespace for Kubernetes job.')\n@click.option('--cpu', help='CPU requirement for Kubernetes pod.')\n@click.option('--disk', help='Disk requirement for Kubernetes pod.')\n@click.option('--memory', help='Memory requirement for Kubernetes pod.')\n@click.option('--gpu', help='GPU requirement for Kubernetes pod.')\n@click.option('--gpu-vendor', help='GPU vendor requirement for Kubernetes pod.')\n@click.option('--run-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--task-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--input-paths', help=\"Passed to the top-level 'step'.\")\n@click.option('--split-index', help=\"Passed to the top-level 'step'.\")\n@click.option('--clone-path', help=\"Passed to the top-level 'step'.\")\n@click.option('--clone-run-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--tag', multiple=True, default=None, help=\"Passed to the top-level 'step'.\")\n@click.option('--namespace', default=None, help=\"Passed to the top-level 'step'.\")\n@click.option('--retry-count', default=0, help=\"Passed to the top-level 'step'.\")\n@click.option('--max-user-code-retries', default=0, help=\"Passed to the top-level 'step'.\")\n@click.option('--use-tmpfs', is_flag=True, help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-tempdir', is_flag=True, help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-size', help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-path', help='tmpfs requirement for Kubernetes pod.')\n@click.option('--run-time-limit', default=5 * 24 * 60 * 60, help='Run time limit in seconds for Kubernetes pod.')\n@click.option('--persistent-volume-claims', type=JSONTypeClass(), default=None, multiple=False)\n@click.option('--tolerations', default=None, type=JSONTypeClass(), multiple=False)\n@click.pass_context\ndef step(ctx, step_name, code_package_sha, code_package_url, executable=None, image=None, image_pull_policy=None, service_account=None, secrets=None, node_selector=None, k8s_namespace=None, cpu=None, disk=None, memory=None, gpu=None, gpu_vendor=None, use_tmpfs=None, tmpfs_tempdir=None, tmpfs_size=None, tmpfs_path=None, run_time_limit=None, persistent_volume_claims=None, tolerations=None, **kwargs):\n\n    def echo(msg, stream='stderr', job_id=None, **kwargs):\n        msg = util.to_unicode(msg)\n        if job_id:\n            msg = '[%s] %s' % (job_id, msg)\n        ctx.obj.echo_always(msg, err=stream == sys.stderr, **kwargs)\n    node = ctx.obj.graph[step_name]\n    executable = ctx.obj.environment.executable(step_name, executable)\n    env = {}\n    env_deco = [deco for deco in node.decorators if deco.name == 'environment']\n    if env_deco:\n        env = env_deco[0].attributes['vars']\n    input_paths = kwargs.get('input_paths')\n    split_vars = None\n    if input_paths:\n        max_size = 30 * 1024\n        split_vars = {'METAFLOW_INPUT_PATHS_%d' % (i // max_size): input_paths[i:i + max_size] for i in range(0, len(input_paths), max_size)}\n        kwargs['input_paths'] = ''.join(('${%s}' % s for s in split_vars.keys()))\n        env.update(split_vars)\n    retry_count = int(kwargs.get('retry_count', 0))\n    retry_deco = [deco for deco in node.decorators if deco.name == 'retry']\n    minutes_between_retries = None\n    if retry_deco:\n        minutes_between_retries = int(retry_deco[0].attributes.get('minutes_between_retries', 2))\n    if retry_count:\n        ctx.obj.echo_always('Sleeping %d minutes before the next retry' % minutes_between_retries)\n        time.sleep(minutes_between_retries * 60)\n    step_cli = '{entrypoint} {top_args} step {step} {step_args}'.format(entrypoint='%s -u %s' % (executable, os.path.basename(sys.argv[0])), top_args=' '.join(util.dict_to_cli_options(ctx.parent.parent.params)), step=step_name, step_args=' '.join(util.dict_to_cli_options(kwargs)))\n    ds = ctx.obj.flow_datastore.get_task_datastore(mode='w', run_id=kwargs['run_id'], step_name=step_name, task_id=kwargs['task_id'], attempt=int(retry_count))\n    stdout_location = ds.get_log_location(TASK_LOG_SOURCE, 'stdout')\n    stderr_location = ds.get_log_location(TASK_LOG_SOURCE, 'stderr')\n    node_selector = parse_kube_keyvalue_list(node_selector)\n\n    def _sync_metadata():\n        if ctx.obj.metadata.TYPE == 'local':\n            sync_local_metadata_from_datastore(DATASTORE_LOCAL_DIR, ctx.obj.flow_datastore.get_task_datastore(kwargs['run_id'], step_name, kwargs['task_id']))\n    try:\n        kubernetes = Kubernetes(datastore=ctx.obj.flow_datastore, metadata=ctx.obj.metadata, environment=ctx.obj.environment)\n        with ctx.obj.monitor.measure('metaflow.kubernetes.launch_job'):\n            kubernetes.launch_job(flow_name=ctx.obj.flow.name, run_id=kwargs['run_id'], step_name=step_name, task_id=kwargs['task_id'], attempt=str(retry_count), user=util.get_username(), code_package_sha=code_package_sha, code_package_url=code_package_url, code_package_ds=ctx.obj.flow_datastore.TYPE, step_cli=step_cli, docker_image=image, docker_image_pull_policy=image_pull_policy, service_account=service_account, secrets=secrets, node_selector=node_selector, namespace=k8s_namespace, cpu=cpu, disk=disk, memory=memory, gpu=gpu, gpu_vendor=gpu_vendor, use_tmpfs=use_tmpfs, tmpfs_tempdir=tmpfs_tempdir, tmpfs_size=tmpfs_size, tmpfs_path=tmpfs_path, run_time_limit=run_time_limit, env=env, persistent_volume_claims=persistent_volume_claims, tolerations=tolerations)\n    except Exception as e:\n        traceback.print_exc(chain=False)\n        _sync_metadata()\n        sys.exit(METAFLOW_EXIT_DISALLOW_RETRY)\n    try:\n        kubernetes.wait(stdout_location, stderr_location, echo=echo)\n    except KubernetesKilledException:\n        traceback.print_exc()\n        sys.exit(METAFLOW_EXIT_DISALLOW_RETRY)\n    finally:\n        _sync_metadata()",
        "mutated": [
            "@tracing.cli_entrypoint('kubernetes/step')\n@kubernetes.command(help='Execute a single task on Kubernetes. This command calls the top-level step command inside a Kubernetes pod with the given options. Typically you do not call this command directly; it is used internally by Metaflow.')\n@click.argument('step-name')\n@click.argument('code-package-sha')\n@click.argument('code-package-url')\n@click.option('--executable', help='Executable requirement for Kubernetes pod.')\n@click.option('--image', help='Docker image requirement for Kubernetes pod.')\n@click.option('--image-pull-policy', default=None, help='Optional Docker Image Pull Policy for Kubernetes pod.')\n@click.option('--service-account', help='IRSA requirement for Kubernetes pod.')\n@click.option('--secrets', multiple=True, default=None, help='Secrets for Kubernetes pod.')\n@click.option('--node-selector', multiple=True, default=None, help='NodeSelector for Kubernetes pod.')\n@click.option('--k8s-namespace', default=None, help='Namespace for Kubernetes job.')\n@click.option('--cpu', help='CPU requirement for Kubernetes pod.')\n@click.option('--disk', help='Disk requirement for Kubernetes pod.')\n@click.option('--memory', help='Memory requirement for Kubernetes pod.')\n@click.option('--gpu', help='GPU requirement for Kubernetes pod.')\n@click.option('--gpu-vendor', help='GPU vendor requirement for Kubernetes pod.')\n@click.option('--run-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--task-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--input-paths', help=\"Passed to the top-level 'step'.\")\n@click.option('--split-index', help=\"Passed to the top-level 'step'.\")\n@click.option('--clone-path', help=\"Passed to the top-level 'step'.\")\n@click.option('--clone-run-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--tag', multiple=True, default=None, help=\"Passed to the top-level 'step'.\")\n@click.option('--namespace', default=None, help=\"Passed to the top-level 'step'.\")\n@click.option('--retry-count', default=0, help=\"Passed to the top-level 'step'.\")\n@click.option('--max-user-code-retries', default=0, help=\"Passed to the top-level 'step'.\")\n@click.option('--use-tmpfs', is_flag=True, help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-tempdir', is_flag=True, help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-size', help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-path', help='tmpfs requirement for Kubernetes pod.')\n@click.option('--run-time-limit', default=5 * 24 * 60 * 60, help='Run time limit in seconds for Kubernetes pod.')\n@click.option('--persistent-volume-claims', type=JSONTypeClass(), default=None, multiple=False)\n@click.option('--tolerations', default=None, type=JSONTypeClass(), multiple=False)\n@click.pass_context\ndef step(ctx, step_name, code_package_sha, code_package_url, executable=None, image=None, image_pull_policy=None, service_account=None, secrets=None, node_selector=None, k8s_namespace=None, cpu=None, disk=None, memory=None, gpu=None, gpu_vendor=None, use_tmpfs=None, tmpfs_tempdir=None, tmpfs_size=None, tmpfs_path=None, run_time_limit=None, persistent_volume_claims=None, tolerations=None, **kwargs):\n    if False:\n        i = 10\n\n    def echo(msg, stream='stderr', job_id=None, **kwargs):\n        msg = util.to_unicode(msg)\n        if job_id:\n            msg = '[%s] %s' % (job_id, msg)\n        ctx.obj.echo_always(msg, err=stream == sys.stderr, **kwargs)\n    node = ctx.obj.graph[step_name]\n    executable = ctx.obj.environment.executable(step_name, executable)\n    env = {}\n    env_deco = [deco for deco in node.decorators if deco.name == 'environment']\n    if env_deco:\n        env = env_deco[0].attributes['vars']\n    input_paths = kwargs.get('input_paths')\n    split_vars = None\n    if input_paths:\n        max_size = 30 * 1024\n        split_vars = {'METAFLOW_INPUT_PATHS_%d' % (i // max_size): input_paths[i:i + max_size] for i in range(0, len(input_paths), max_size)}\n        kwargs['input_paths'] = ''.join(('${%s}' % s for s in split_vars.keys()))\n        env.update(split_vars)\n    retry_count = int(kwargs.get('retry_count', 0))\n    retry_deco = [deco for deco in node.decorators if deco.name == 'retry']\n    minutes_between_retries = None\n    if retry_deco:\n        minutes_between_retries = int(retry_deco[0].attributes.get('minutes_between_retries', 2))\n    if retry_count:\n        ctx.obj.echo_always('Sleeping %d minutes before the next retry' % minutes_between_retries)\n        time.sleep(minutes_between_retries * 60)\n    step_cli = '{entrypoint} {top_args} step {step} {step_args}'.format(entrypoint='%s -u %s' % (executable, os.path.basename(sys.argv[0])), top_args=' '.join(util.dict_to_cli_options(ctx.parent.parent.params)), step=step_name, step_args=' '.join(util.dict_to_cli_options(kwargs)))\n    ds = ctx.obj.flow_datastore.get_task_datastore(mode='w', run_id=kwargs['run_id'], step_name=step_name, task_id=kwargs['task_id'], attempt=int(retry_count))\n    stdout_location = ds.get_log_location(TASK_LOG_SOURCE, 'stdout')\n    stderr_location = ds.get_log_location(TASK_LOG_SOURCE, 'stderr')\n    node_selector = parse_kube_keyvalue_list(node_selector)\n\n    def _sync_metadata():\n        if ctx.obj.metadata.TYPE == 'local':\n            sync_local_metadata_from_datastore(DATASTORE_LOCAL_DIR, ctx.obj.flow_datastore.get_task_datastore(kwargs['run_id'], step_name, kwargs['task_id']))\n    try:\n        kubernetes = Kubernetes(datastore=ctx.obj.flow_datastore, metadata=ctx.obj.metadata, environment=ctx.obj.environment)\n        with ctx.obj.monitor.measure('metaflow.kubernetes.launch_job'):\n            kubernetes.launch_job(flow_name=ctx.obj.flow.name, run_id=kwargs['run_id'], step_name=step_name, task_id=kwargs['task_id'], attempt=str(retry_count), user=util.get_username(), code_package_sha=code_package_sha, code_package_url=code_package_url, code_package_ds=ctx.obj.flow_datastore.TYPE, step_cli=step_cli, docker_image=image, docker_image_pull_policy=image_pull_policy, service_account=service_account, secrets=secrets, node_selector=node_selector, namespace=k8s_namespace, cpu=cpu, disk=disk, memory=memory, gpu=gpu, gpu_vendor=gpu_vendor, use_tmpfs=use_tmpfs, tmpfs_tempdir=tmpfs_tempdir, tmpfs_size=tmpfs_size, tmpfs_path=tmpfs_path, run_time_limit=run_time_limit, env=env, persistent_volume_claims=persistent_volume_claims, tolerations=tolerations)\n    except Exception as e:\n        traceback.print_exc(chain=False)\n        _sync_metadata()\n        sys.exit(METAFLOW_EXIT_DISALLOW_RETRY)\n    try:\n        kubernetes.wait(stdout_location, stderr_location, echo=echo)\n    except KubernetesKilledException:\n        traceback.print_exc()\n        sys.exit(METAFLOW_EXIT_DISALLOW_RETRY)\n    finally:\n        _sync_metadata()",
            "@tracing.cli_entrypoint('kubernetes/step')\n@kubernetes.command(help='Execute a single task on Kubernetes. This command calls the top-level step command inside a Kubernetes pod with the given options. Typically you do not call this command directly; it is used internally by Metaflow.')\n@click.argument('step-name')\n@click.argument('code-package-sha')\n@click.argument('code-package-url')\n@click.option('--executable', help='Executable requirement for Kubernetes pod.')\n@click.option('--image', help='Docker image requirement for Kubernetes pod.')\n@click.option('--image-pull-policy', default=None, help='Optional Docker Image Pull Policy for Kubernetes pod.')\n@click.option('--service-account', help='IRSA requirement for Kubernetes pod.')\n@click.option('--secrets', multiple=True, default=None, help='Secrets for Kubernetes pod.')\n@click.option('--node-selector', multiple=True, default=None, help='NodeSelector for Kubernetes pod.')\n@click.option('--k8s-namespace', default=None, help='Namespace for Kubernetes job.')\n@click.option('--cpu', help='CPU requirement for Kubernetes pod.')\n@click.option('--disk', help='Disk requirement for Kubernetes pod.')\n@click.option('--memory', help='Memory requirement for Kubernetes pod.')\n@click.option('--gpu', help='GPU requirement for Kubernetes pod.')\n@click.option('--gpu-vendor', help='GPU vendor requirement for Kubernetes pod.')\n@click.option('--run-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--task-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--input-paths', help=\"Passed to the top-level 'step'.\")\n@click.option('--split-index', help=\"Passed to the top-level 'step'.\")\n@click.option('--clone-path', help=\"Passed to the top-level 'step'.\")\n@click.option('--clone-run-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--tag', multiple=True, default=None, help=\"Passed to the top-level 'step'.\")\n@click.option('--namespace', default=None, help=\"Passed to the top-level 'step'.\")\n@click.option('--retry-count', default=0, help=\"Passed to the top-level 'step'.\")\n@click.option('--max-user-code-retries', default=0, help=\"Passed to the top-level 'step'.\")\n@click.option('--use-tmpfs', is_flag=True, help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-tempdir', is_flag=True, help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-size', help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-path', help='tmpfs requirement for Kubernetes pod.')\n@click.option('--run-time-limit', default=5 * 24 * 60 * 60, help='Run time limit in seconds for Kubernetes pod.')\n@click.option('--persistent-volume-claims', type=JSONTypeClass(), default=None, multiple=False)\n@click.option('--tolerations', default=None, type=JSONTypeClass(), multiple=False)\n@click.pass_context\ndef step(ctx, step_name, code_package_sha, code_package_url, executable=None, image=None, image_pull_policy=None, service_account=None, secrets=None, node_selector=None, k8s_namespace=None, cpu=None, disk=None, memory=None, gpu=None, gpu_vendor=None, use_tmpfs=None, tmpfs_tempdir=None, tmpfs_size=None, tmpfs_path=None, run_time_limit=None, persistent_volume_claims=None, tolerations=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n\n    def echo(msg, stream='stderr', job_id=None, **kwargs):\n        msg = util.to_unicode(msg)\n        if job_id:\n            msg = '[%s] %s' % (job_id, msg)\n        ctx.obj.echo_always(msg, err=stream == sys.stderr, **kwargs)\n    node = ctx.obj.graph[step_name]\n    executable = ctx.obj.environment.executable(step_name, executable)\n    env = {}\n    env_deco = [deco for deco in node.decorators if deco.name == 'environment']\n    if env_deco:\n        env = env_deco[0].attributes['vars']\n    input_paths = kwargs.get('input_paths')\n    split_vars = None\n    if input_paths:\n        max_size = 30 * 1024\n        split_vars = {'METAFLOW_INPUT_PATHS_%d' % (i // max_size): input_paths[i:i + max_size] for i in range(0, len(input_paths), max_size)}\n        kwargs['input_paths'] = ''.join(('${%s}' % s for s in split_vars.keys()))\n        env.update(split_vars)\n    retry_count = int(kwargs.get('retry_count', 0))\n    retry_deco = [deco for deco in node.decorators if deco.name == 'retry']\n    minutes_between_retries = None\n    if retry_deco:\n        minutes_between_retries = int(retry_deco[0].attributes.get('minutes_between_retries', 2))\n    if retry_count:\n        ctx.obj.echo_always('Sleeping %d minutes before the next retry' % minutes_between_retries)\n        time.sleep(minutes_between_retries * 60)\n    step_cli = '{entrypoint} {top_args} step {step} {step_args}'.format(entrypoint='%s -u %s' % (executable, os.path.basename(sys.argv[0])), top_args=' '.join(util.dict_to_cli_options(ctx.parent.parent.params)), step=step_name, step_args=' '.join(util.dict_to_cli_options(kwargs)))\n    ds = ctx.obj.flow_datastore.get_task_datastore(mode='w', run_id=kwargs['run_id'], step_name=step_name, task_id=kwargs['task_id'], attempt=int(retry_count))\n    stdout_location = ds.get_log_location(TASK_LOG_SOURCE, 'stdout')\n    stderr_location = ds.get_log_location(TASK_LOG_SOURCE, 'stderr')\n    node_selector = parse_kube_keyvalue_list(node_selector)\n\n    def _sync_metadata():\n        if ctx.obj.metadata.TYPE == 'local':\n            sync_local_metadata_from_datastore(DATASTORE_LOCAL_DIR, ctx.obj.flow_datastore.get_task_datastore(kwargs['run_id'], step_name, kwargs['task_id']))\n    try:\n        kubernetes = Kubernetes(datastore=ctx.obj.flow_datastore, metadata=ctx.obj.metadata, environment=ctx.obj.environment)\n        with ctx.obj.monitor.measure('metaflow.kubernetes.launch_job'):\n            kubernetes.launch_job(flow_name=ctx.obj.flow.name, run_id=kwargs['run_id'], step_name=step_name, task_id=kwargs['task_id'], attempt=str(retry_count), user=util.get_username(), code_package_sha=code_package_sha, code_package_url=code_package_url, code_package_ds=ctx.obj.flow_datastore.TYPE, step_cli=step_cli, docker_image=image, docker_image_pull_policy=image_pull_policy, service_account=service_account, secrets=secrets, node_selector=node_selector, namespace=k8s_namespace, cpu=cpu, disk=disk, memory=memory, gpu=gpu, gpu_vendor=gpu_vendor, use_tmpfs=use_tmpfs, tmpfs_tempdir=tmpfs_tempdir, tmpfs_size=tmpfs_size, tmpfs_path=tmpfs_path, run_time_limit=run_time_limit, env=env, persistent_volume_claims=persistent_volume_claims, tolerations=tolerations)\n    except Exception as e:\n        traceback.print_exc(chain=False)\n        _sync_metadata()\n        sys.exit(METAFLOW_EXIT_DISALLOW_RETRY)\n    try:\n        kubernetes.wait(stdout_location, stderr_location, echo=echo)\n    except KubernetesKilledException:\n        traceback.print_exc()\n        sys.exit(METAFLOW_EXIT_DISALLOW_RETRY)\n    finally:\n        _sync_metadata()",
            "@tracing.cli_entrypoint('kubernetes/step')\n@kubernetes.command(help='Execute a single task on Kubernetes. This command calls the top-level step command inside a Kubernetes pod with the given options. Typically you do not call this command directly; it is used internally by Metaflow.')\n@click.argument('step-name')\n@click.argument('code-package-sha')\n@click.argument('code-package-url')\n@click.option('--executable', help='Executable requirement for Kubernetes pod.')\n@click.option('--image', help='Docker image requirement for Kubernetes pod.')\n@click.option('--image-pull-policy', default=None, help='Optional Docker Image Pull Policy for Kubernetes pod.')\n@click.option('--service-account', help='IRSA requirement for Kubernetes pod.')\n@click.option('--secrets', multiple=True, default=None, help='Secrets for Kubernetes pod.')\n@click.option('--node-selector', multiple=True, default=None, help='NodeSelector for Kubernetes pod.')\n@click.option('--k8s-namespace', default=None, help='Namespace for Kubernetes job.')\n@click.option('--cpu', help='CPU requirement for Kubernetes pod.')\n@click.option('--disk', help='Disk requirement for Kubernetes pod.')\n@click.option('--memory', help='Memory requirement for Kubernetes pod.')\n@click.option('--gpu', help='GPU requirement for Kubernetes pod.')\n@click.option('--gpu-vendor', help='GPU vendor requirement for Kubernetes pod.')\n@click.option('--run-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--task-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--input-paths', help=\"Passed to the top-level 'step'.\")\n@click.option('--split-index', help=\"Passed to the top-level 'step'.\")\n@click.option('--clone-path', help=\"Passed to the top-level 'step'.\")\n@click.option('--clone-run-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--tag', multiple=True, default=None, help=\"Passed to the top-level 'step'.\")\n@click.option('--namespace', default=None, help=\"Passed to the top-level 'step'.\")\n@click.option('--retry-count', default=0, help=\"Passed to the top-level 'step'.\")\n@click.option('--max-user-code-retries', default=0, help=\"Passed to the top-level 'step'.\")\n@click.option('--use-tmpfs', is_flag=True, help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-tempdir', is_flag=True, help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-size', help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-path', help='tmpfs requirement for Kubernetes pod.')\n@click.option('--run-time-limit', default=5 * 24 * 60 * 60, help='Run time limit in seconds for Kubernetes pod.')\n@click.option('--persistent-volume-claims', type=JSONTypeClass(), default=None, multiple=False)\n@click.option('--tolerations', default=None, type=JSONTypeClass(), multiple=False)\n@click.pass_context\ndef step(ctx, step_name, code_package_sha, code_package_url, executable=None, image=None, image_pull_policy=None, service_account=None, secrets=None, node_selector=None, k8s_namespace=None, cpu=None, disk=None, memory=None, gpu=None, gpu_vendor=None, use_tmpfs=None, tmpfs_tempdir=None, tmpfs_size=None, tmpfs_path=None, run_time_limit=None, persistent_volume_claims=None, tolerations=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n    def echo(msg, stream='stderr', job_id=None, **kwargs):\n        msg = util.to_unicode(msg)\n        if job_id:\n            msg = '[%s] %s' % (job_id, msg)\n        ctx.obj.echo_always(msg, err=stream == sys.stderr, **kwargs)\n    node = ctx.obj.graph[step_name]\n    executable = ctx.obj.environment.executable(step_name, executable)\n    env = {}\n    env_deco = [deco for deco in node.decorators if deco.name == 'environment']\n    if env_deco:\n        env = env_deco[0].attributes['vars']\n    input_paths = kwargs.get('input_paths')\n    split_vars = None\n    if input_paths:\n        max_size = 30 * 1024\n        split_vars = {'METAFLOW_INPUT_PATHS_%d' % (i // max_size): input_paths[i:i + max_size] for i in range(0, len(input_paths), max_size)}\n        kwargs['input_paths'] = ''.join(('${%s}' % s for s in split_vars.keys()))\n        env.update(split_vars)\n    retry_count = int(kwargs.get('retry_count', 0))\n    retry_deco = [deco for deco in node.decorators if deco.name == 'retry']\n    minutes_between_retries = None\n    if retry_deco:\n        minutes_between_retries = int(retry_deco[0].attributes.get('minutes_between_retries', 2))\n    if retry_count:\n        ctx.obj.echo_always('Sleeping %d minutes before the next retry' % minutes_between_retries)\n        time.sleep(minutes_between_retries * 60)\n    step_cli = '{entrypoint} {top_args} step {step} {step_args}'.format(entrypoint='%s -u %s' % (executable, os.path.basename(sys.argv[0])), top_args=' '.join(util.dict_to_cli_options(ctx.parent.parent.params)), step=step_name, step_args=' '.join(util.dict_to_cli_options(kwargs)))\n    ds = ctx.obj.flow_datastore.get_task_datastore(mode='w', run_id=kwargs['run_id'], step_name=step_name, task_id=kwargs['task_id'], attempt=int(retry_count))\n    stdout_location = ds.get_log_location(TASK_LOG_SOURCE, 'stdout')\n    stderr_location = ds.get_log_location(TASK_LOG_SOURCE, 'stderr')\n    node_selector = parse_kube_keyvalue_list(node_selector)\n\n    def _sync_metadata():\n        if ctx.obj.metadata.TYPE == 'local':\n            sync_local_metadata_from_datastore(DATASTORE_LOCAL_DIR, ctx.obj.flow_datastore.get_task_datastore(kwargs['run_id'], step_name, kwargs['task_id']))\n    try:\n        kubernetes = Kubernetes(datastore=ctx.obj.flow_datastore, metadata=ctx.obj.metadata, environment=ctx.obj.environment)\n        with ctx.obj.monitor.measure('metaflow.kubernetes.launch_job'):\n            kubernetes.launch_job(flow_name=ctx.obj.flow.name, run_id=kwargs['run_id'], step_name=step_name, task_id=kwargs['task_id'], attempt=str(retry_count), user=util.get_username(), code_package_sha=code_package_sha, code_package_url=code_package_url, code_package_ds=ctx.obj.flow_datastore.TYPE, step_cli=step_cli, docker_image=image, docker_image_pull_policy=image_pull_policy, service_account=service_account, secrets=secrets, node_selector=node_selector, namespace=k8s_namespace, cpu=cpu, disk=disk, memory=memory, gpu=gpu, gpu_vendor=gpu_vendor, use_tmpfs=use_tmpfs, tmpfs_tempdir=tmpfs_tempdir, tmpfs_size=tmpfs_size, tmpfs_path=tmpfs_path, run_time_limit=run_time_limit, env=env, persistent_volume_claims=persistent_volume_claims, tolerations=tolerations)\n    except Exception as e:\n        traceback.print_exc(chain=False)\n        _sync_metadata()\n        sys.exit(METAFLOW_EXIT_DISALLOW_RETRY)\n    try:\n        kubernetes.wait(stdout_location, stderr_location, echo=echo)\n    except KubernetesKilledException:\n        traceback.print_exc()\n        sys.exit(METAFLOW_EXIT_DISALLOW_RETRY)\n    finally:\n        _sync_metadata()",
            "@tracing.cli_entrypoint('kubernetes/step')\n@kubernetes.command(help='Execute a single task on Kubernetes. This command calls the top-level step command inside a Kubernetes pod with the given options. Typically you do not call this command directly; it is used internally by Metaflow.')\n@click.argument('step-name')\n@click.argument('code-package-sha')\n@click.argument('code-package-url')\n@click.option('--executable', help='Executable requirement for Kubernetes pod.')\n@click.option('--image', help='Docker image requirement for Kubernetes pod.')\n@click.option('--image-pull-policy', default=None, help='Optional Docker Image Pull Policy for Kubernetes pod.')\n@click.option('--service-account', help='IRSA requirement for Kubernetes pod.')\n@click.option('--secrets', multiple=True, default=None, help='Secrets for Kubernetes pod.')\n@click.option('--node-selector', multiple=True, default=None, help='NodeSelector for Kubernetes pod.')\n@click.option('--k8s-namespace', default=None, help='Namespace for Kubernetes job.')\n@click.option('--cpu', help='CPU requirement for Kubernetes pod.')\n@click.option('--disk', help='Disk requirement for Kubernetes pod.')\n@click.option('--memory', help='Memory requirement for Kubernetes pod.')\n@click.option('--gpu', help='GPU requirement for Kubernetes pod.')\n@click.option('--gpu-vendor', help='GPU vendor requirement for Kubernetes pod.')\n@click.option('--run-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--task-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--input-paths', help=\"Passed to the top-level 'step'.\")\n@click.option('--split-index', help=\"Passed to the top-level 'step'.\")\n@click.option('--clone-path', help=\"Passed to the top-level 'step'.\")\n@click.option('--clone-run-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--tag', multiple=True, default=None, help=\"Passed to the top-level 'step'.\")\n@click.option('--namespace', default=None, help=\"Passed to the top-level 'step'.\")\n@click.option('--retry-count', default=0, help=\"Passed to the top-level 'step'.\")\n@click.option('--max-user-code-retries', default=0, help=\"Passed to the top-level 'step'.\")\n@click.option('--use-tmpfs', is_flag=True, help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-tempdir', is_flag=True, help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-size', help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-path', help='tmpfs requirement for Kubernetes pod.')\n@click.option('--run-time-limit', default=5 * 24 * 60 * 60, help='Run time limit in seconds for Kubernetes pod.')\n@click.option('--persistent-volume-claims', type=JSONTypeClass(), default=None, multiple=False)\n@click.option('--tolerations', default=None, type=JSONTypeClass(), multiple=False)\n@click.pass_context\ndef step(ctx, step_name, code_package_sha, code_package_url, executable=None, image=None, image_pull_policy=None, service_account=None, secrets=None, node_selector=None, k8s_namespace=None, cpu=None, disk=None, memory=None, gpu=None, gpu_vendor=None, use_tmpfs=None, tmpfs_tempdir=None, tmpfs_size=None, tmpfs_path=None, run_time_limit=None, persistent_volume_claims=None, tolerations=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n\n    def echo(msg, stream='stderr', job_id=None, **kwargs):\n        msg = util.to_unicode(msg)\n        if job_id:\n            msg = '[%s] %s' % (job_id, msg)\n        ctx.obj.echo_always(msg, err=stream == sys.stderr, **kwargs)\n    node = ctx.obj.graph[step_name]\n    executable = ctx.obj.environment.executable(step_name, executable)\n    env = {}\n    env_deco = [deco for deco in node.decorators if deco.name == 'environment']\n    if env_deco:\n        env = env_deco[0].attributes['vars']\n    input_paths = kwargs.get('input_paths')\n    split_vars = None\n    if input_paths:\n        max_size = 30 * 1024\n        split_vars = {'METAFLOW_INPUT_PATHS_%d' % (i // max_size): input_paths[i:i + max_size] for i in range(0, len(input_paths), max_size)}\n        kwargs['input_paths'] = ''.join(('${%s}' % s for s in split_vars.keys()))\n        env.update(split_vars)\n    retry_count = int(kwargs.get('retry_count', 0))\n    retry_deco = [deco for deco in node.decorators if deco.name == 'retry']\n    minutes_between_retries = None\n    if retry_deco:\n        minutes_between_retries = int(retry_deco[0].attributes.get('minutes_between_retries', 2))\n    if retry_count:\n        ctx.obj.echo_always('Sleeping %d minutes before the next retry' % minutes_between_retries)\n        time.sleep(minutes_between_retries * 60)\n    step_cli = '{entrypoint} {top_args} step {step} {step_args}'.format(entrypoint='%s -u %s' % (executable, os.path.basename(sys.argv[0])), top_args=' '.join(util.dict_to_cli_options(ctx.parent.parent.params)), step=step_name, step_args=' '.join(util.dict_to_cli_options(kwargs)))\n    ds = ctx.obj.flow_datastore.get_task_datastore(mode='w', run_id=kwargs['run_id'], step_name=step_name, task_id=kwargs['task_id'], attempt=int(retry_count))\n    stdout_location = ds.get_log_location(TASK_LOG_SOURCE, 'stdout')\n    stderr_location = ds.get_log_location(TASK_LOG_SOURCE, 'stderr')\n    node_selector = parse_kube_keyvalue_list(node_selector)\n\n    def _sync_metadata():\n        if ctx.obj.metadata.TYPE == 'local':\n            sync_local_metadata_from_datastore(DATASTORE_LOCAL_DIR, ctx.obj.flow_datastore.get_task_datastore(kwargs['run_id'], step_name, kwargs['task_id']))\n    try:\n        kubernetes = Kubernetes(datastore=ctx.obj.flow_datastore, metadata=ctx.obj.metadata, environment=ctx.obj.environment)\n        with ctx.obj.monitor.measure('metaflow.kubernetes.launch_job'):\n            kubernetes.launch_job(flow_name=ctx.obj.flow.name, run_id=kwargs['run_id'], step_name=step_name, task_id=kwargs['task_id'], attempt=str(retry_count), user=util.get_username(), code_package_sha=code_package_sha, code_package_url=code_package_url, code_package_ds=ctx.obj.flow_datastore.TYPE, step_cli=step_cli, docker_image=image, docker_image_pull_policy=image_pull_policy, service_account=service_account, secrets=secrets, node_selector=node_selector, namespace=k8s_namespace, cpu=cpu, disk=disk, memory=memory, gpu=gpu, gpu_vendor=gpu_vendor, use_tmpfs=use_tmpfs, tmpfs_tempdir=tmpfs_tempdir, tmpfs_size=tmpfs_size, tmpfs_path=tmpfs_path, run_time_limit=run_time_limit, env=env, persistent_volume_claims=persistent_volume_claims, tolerations=tolerations)\n    except Exception as e:\n        traceback.print_exc(chain=False)\n        _sync_metadata()\n        sys.exit(METAFLOW_EXIT_DISALLOW_RETRY)\n    try:\n        kubernetes.wait(stdout_location, stderr_location, echo=echo)\n    except KubernetesKilledException:\n        traceback.print_exc()\n        sys.exit(METAFLOW_EXIT_DISALLOW_RETRY)\n    finally:\n        _sync_metadata()",
            "@tracing.cli_entrypoint('kubernetes/step')\n@kubernetes.command(help='Execute a single task on Kubernetes. This command calls the top-level step command inside a Kubernetes pod with the given options. Typically you do not call this command directly; it is used internally by Metaflow.')\n@click.argument('step-name')\n@click.argument('code-package-sha')\n@click.argument('code-package-url')\n@click.option('--executable', help='Executable requirement for Kubernetes pod.')\n@click.option('--image', help='Docker image requirement for Kubernetes pod.')\n@click.option('--image-pull-policy', default=None, help='Optional Docker Image Pull Policy for Kubernetes pod.')\n@click.option('--service-account', help='IRSA requirement for Kubernetes pod.')\n@click.option('--secrets', multiple=True, default=None, help='Secrets for Kubernetes pod.')\n@click.option('--node-selector', multiple=True, default=None, help='NodeSelector for Kubernetes pod.')\n@click.option('--k8s-namespace', default=None, help='Namespace for Kubernetes job.')\n@click.option('--cpu', help='CPU requirement for Kubernetes pod.')\n@click.option('--disk', help='Disk requirement for Kubernetes pod.')\n@click.option('--memory', help='Memory requirement for Kubernetes pod.')\n@click.option('--gpu', help='GPU requirement for Kubernetes pod.')\n@click.option('--gpu-vendor', help='GPU vendor requirement for Kubernetes pod.')\n@click.option('--run-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--task-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--input-paths', help=\"Passed to the top-level 'step'.\")\n@click.option('--split-index', help=\"Passed to the top-level 'step'.\")\n@click.option('--clone-path', help=\"Passed to the top-level 'step'.\")\n@click.option('--clone-run-id', help=\"Passed to the top-level 'step'.\")\n@click.option('--tag', multiple=True, default=None, help=\"Passed to the top-level 'step'.\")\n@click.option('--namespace', default=None, help=\"Passed to the top-level 'step'.\")\n@click.option('--retry-count', default=0, help=\"Passed to the top-level 'step'.\")\n@click.option('--max-user-code-retries', default=0, help=\"Passed to the top-level 'step'.\")\n@click.option('--use-tmpfs', is_flag=True, help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-tempdir', is_flag=True, help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-size', help='tmpfs requirement for Kubernetes pod.')\n@click.option('--tmpfs-path', help='tmpfs requirement for Kubernetes pod.')\n@click.option('--run-time-limit', default=5 * 24 * 60 * 60, help='Run time limit in seconds for Kubernetes pod.')\n@click.option('--persistent-volume-claims', type=JSONTypeClass(), default=None, multiple=False)\n@click.option('--tolerations', default=None, type=JSONTypeClass(), multiple=False)\n@click.pass_context\ndef step(ctx, step_name, code_package_sha, code_package_url, executable=None, image=None, image_pull_policy=None, service_account=None, secrets=None, node_selector=None, k8s_namespace=None, cpu=None, disk=None, memory=None, gpu=None, gpu_vendor=None, use_tmpfs=None, tmpfs_tempdir=None, tmpfs_size=None, tmpfs_path=None, run_time_limit=None, persistent_volume_claims=None, tolerations=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n\n    def echo(msg, stream='stderr', job_id=None, **kwargs):\n        msg = util.to_unicode(msg)\n        if job_id:\n            msg = '[%s] %s' % (job_id, msg)\n        ctx.obj.echo_always(msg, err=stream == sys.stderr, **kwargs)\n    node = ctx.obj.graph[step_name]\n    executable = ctx.obj.environment.executable(step_name, executable)\n    env = {}\n    env_deco = [deco for deco in node.decorators if deco.name == 'environment']\n    if env_deco:\n        env = env_deco[0].attributes['vars']\n    input_paths = kwargs.get('input_paths')\n    split_vars = None\n    if input_paths:\n        max_size = 30 * 1024\n        split_vars = {'METAFLOW_INPUT_PATHS_%d' % (i // max_size): input_paths[i:i + max_size] for i in range(0, len(input_paths), max_size)}\n        kwargs['input_paths'] = ''.join(('${%s}' % s for s in split_vars.keys()))\n        env.update(split_vars)\n    retry_count = int(kwargs.get('retry_count', 0))\n    retry_deco = [deco for deco in node.decorators if deco.name == 'retry']\n    minutes_between_retries = None\n    if retry_deco:\n        minutes_between_retries = int(retry_deco[0].attributes.get('minutes_between_retries', 2))\n    if retry_count:\n        ctx.obj.echo_always('Sleeping %d minutes before the next retry' % minutes_between_retries)\n        time.sleep(minutes_between_retries * 60)\n    step_cli = '{entrypoint} {top_args} step {step} {step_args}'.format(entrypoint='%s -u %s' % (executable, os.path.basename(sys.argv[0])), top_args=' '.join(util.dict_to_cli_options(ctx.parent.parent.params)), step=step_name, step_args=' '.join(util.dict_to_cli_options(kwargs)))\n    ds = ctx.obj.flow_datastore.get_task_datastore(mode='w', run_id=kwargs['run_id'], step_name=step_name, task_id=kwargs['task_id'], attempt=int(retry_count))\n    stdout_location = ds.get_log_location(TASK_LOG_SOURCE, 'stdout')\n    stderr_location = ds.get_log_location(TASK_LOG_SOURCE, 'stderr')\n    node_selector = parse_kube_keyvalue_list(node_selector)\n\n    def _sync_metadata():\n        if ctx.obj.metadata.TYPE == 'local':\n            sync_local_metadata_from_datastore(DATASTORE_LOCAL_DIR, ctx.obj.flow_datastore.get_task_datastore(kwargs['run_id'], step_name, kwargs['task_id']))\n    try:\n        kubernetes = Kubernetes(datastore=ctx.obj.flow_datastore, metadata=ctx.obj.metadata, environment=ctx.obj.environment)\n        with ctx.obj.monitor.measure('metaflow.kubernetes.launch_job'):\n            kubernetes.launch_job(flow_name=ctx.obj.flow.name, run_id=kwargs['run_id'], step_name=step_name, task_id=kwargs['task_id'], attempt=str(retry_count), user=util.get_username(), code_package_sha=code_package_sha, code_package_url=code_package_url, code_package_ds=ctx.obj.flow_datastore.TYPE, step_cli=step_cli, docker_image=image, docker_image_pull_policy=image_pull_policy, service_account=service_account, secrets=secrets, node_selector=node_selector, namespace=k8s_namespace, cpu=cpu, disk=disk, memory=memory, gpu=gpu, gpu_vendor=gpu_vendor, use_tmpfs=use_tmpfs, tmpfs_tempdir=tmpfs_tempdir, tmpfs_size=tmpfs_size, tmpfs_path=tmpfs_path, run_time_limit=run_time_limit, env=env, persistent_volume_claims=persistent_volume_claims, tolerations=tolerations)\n    except Exception as e:\n        traceback.print_exc(chain=False)\n        _sync_metadata()\n        sys.exit(METAFLOW_EXIT_DISALLOW_RETRY)\n    try:\n        kubernetes.wait(stdout_location, stderr_location, echo=echo)\n    except KubernetesKilledException:\n        traceback.print_exc()\n        sys.exit(METAFLOW_EXIT_DISALLOW_RETRY)\n    finally:\n        _sync_metadata()"
        ]
    }
]