[
    {
        "func_name": "__init__",
        "original": "def __init__(self, sample_size: int=10000, random_state: int=42, test_size: float=0.3, dimension_reduction_method: str='auto', num_samples_in_display: int=500, **kwargs):\n    super().__init__(**kwargs)\n    self.sample_size = sample_size\n    self.random_state = random_state\n    self.test_size = test_size\n    if dimension_reduction_method is None:\n        dimension_reduction_method = 'none'\n    if dimension_reduction_method.lower() not in ['auto', 'umap', 'pca', 'none']:\n        raise ValueError(f'dimension_reduction_method must be one of \"auto\", \"umap\", \"pca\" or \"none\". Got {dimension_reduction_method} instead')\n    self.dimension_reduction_method = dimension_reduction_method.lower()\n    self.num_samples_in_display = num_samples_in_display",
        "mutated": [
            "def __init__(self, sample_size: int=10000, random_state: int=42, test_size: float=0.3, dimension_reduction_method: str='auto', num_samples_in_display: int=500, **kwargs):\n    if False:\n        i = 10\n    super().__init__(**kwargs)\n    self.sample_size = sample_size\n    self.random_state = random_state\n    self.test_size = test_size\n    if dimension_reduction_method is None:\n        dimension_reduction_method = 'none'\n    if dimension_reduction_method.lower() not in ['auto', 'umap', 'pca', 'none']:\n        raise ValueError(f'dimension_reduction_method must be one of \"auto\", \"umap\", \"pca\" or \"none\". Got {dimension_reduction_method} instead')\n    self.dimension_reduction_method = dimension_reduction_method.lower()\n    self.num_samples_in_display = num_samples_in_display",
            "def __init__(self, sample_size: int=10000, random_state: int=42, test_size: float=0.3, dimension_reduction_method: str='auto', num_samples_in_display: int=500, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super().__init__(**kwargs)\n    self.sample_size = sample_size\n    self.random_state = random_state\n    self.test_size = test_size\n    if dimension_reduction_method is None:\n        dimension_reduction_method = 'none'\n    if dimension_reduction_method.lower() not in ['auto', 'umap', 'pca', 'none']:\n        raise ValueError(f'dimension_reduction_method must be one of \"auto\", \"umap\", \"pca\" or \"none\". Got {dimension_reduction_method} instead')\n    self.dimension_reduction_method = dimension_reduction_method.lower()\n    self.num_samples_in_display = num_samples_in_display",
            "def __init__(self, sample_size: int=10000, random_state: int=42, test_size: float=0.3, dimension_reduction_method: str='auto', num_samples_in_display: int=500, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super().__init__(**kwargs)\n    self.sample_size = sample_size\n    self.random_state = random_state\n    self.test_size = test_size\n    if dimension_reduction_method is None:\n        dimension_reduction_method = 'none'\n    if dimension_reduction_method.lower() not in ['auto', 'umap', 'pca', 'none']:\n        raise ValueError(f'dimension_reduction_method must be one of \"auto\", \"umap\", \"pca\" or \"none\". Got {dimension_reduction_method} instead')\n    self.dimension_reduction_method = dimension_reduction_method.lower()\n    self.num_samples_in_display = num_samples_in_display",
            "def __init__(self, sample_size: int=10000, random_state: int=42, test_size: float=0.3, dimension_reduction_method: str='auto', num_samples_in_display: int=500, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super().__init__(**kwargs)\n    self.sample_size = sample_size\n    self.random_state = random_state\n    self.test_size = test_size\n    if dimension_reduction_method is None:\n        dimension_reduction_method = 'none'\n    if dimension_reduction_method.lower() not in ['auto', 'umap', 'pca', 'none']:\n        raise ValueError(f'dimension_reduction_method must be one of \"auto\", \"umap\", \"pca\" or \"none\". Got {dimension_reduction_method} instead')\n    self.dimension_reduction_method = dimension_reduction_method.lower()\n    self.num_samples_in_display = num_samples_in_display",
            "def __init__(self, sample_size: int=10000, random_state: int=42, test_size: float=0.3, dimension_reduction_method: str='auto', num_samples_in_display: int=500, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super().__init__(**kwargs)\n    self.sample_size = sample_size\n    self.random_state = random_state\n    self.test_size = test_size\n    if dimension_reduction_method is None:\n        dimension_reduction_method = 'none'\n    if dimension_reduction_method.lower() not in ['auto', 'umap', 'pca', 'none']:\n        raise ValueError(f'dimension_reduction_method must be one of \"auto\", \"umap\", \"pca\" or \"none\". Got {dimension_reduction_method} instead')\n    self.dimension_reduction_method = dimension_reduction_method.lower()\n    self.num_samples_in_display = num_samples_in_display"
        ]
    },
    {
        "func_name": "run_logic",
        "original": "def run_logic(self, context: Context) -> CheckResult:\n    \"\"\"Run check.\n\n        Returns\n        -------\n        CheckResult\n            value: dictionary containing the domain classifier auc and a dict of column name to its feature\n            importance as calculated for the domain classifier model.\n            display: distribution graph for each column for the columns most explaining the dataset difference,\n            comparing the train and test distributions.\n\n        Raises\n        ------\n        DeepchecksValueError\n            If the object is not a Dataset or DataFrame instance\n        \"\"\"\n    train_dataset = context.train\n    test_dataset = context.test\n    sample_size = min(self.sample_size, train_dataset.n_samples, test_dataset.n_samples)\n    (values_dict, displays) = run_multivariable_drift_for_embeddings(train_dataset=train_dataset, test_dataset=test_dataset, sample_size=sample_size, random_state=self.random_state, test_size=self.test_size, num_samples_in_display=self.num_samples_in_display, dimension_reduction_method=self.dimension_reduction_method, with_display=context.with_display, model_classes=context.model_classes)\n    return CheckResult(value=values_dict, display=displays, header='Embeddings Drift')",
        "mutated": [
            "def run_logic(self, context: Context) -> CheckResult:\n    if False:\n        i = 10\n    'Run check.\\n\\n        Returns\\n        -------\\n        CheckResult\\n            value: dictionary containing the domain classifier auc and a dict of column name to its feature\\n            importance as calculated for the domain classifier model.\\n            display: distribution graph for each column for the columns most explaining the dataset difference,\\n            comparing the train and test distributions.\\n\\n        Raises\\n        ------\\n        DeepchecksValueError\\n            If the object is not a Dataset or DataFrame instance\\n        '\n    train_dataset = context.train\n    test_dataset = context.test\n    sample_size = min(self.sample_size, train_dataset.n_samples, test_dataset.n_samples)\n    (values_dict, displays) = run_multivariable_drift_for_embeddings(train_dataset=train_dataset, test_dataset=test_dataset, sample_size=sample_size, random_state=self.random_state, test_size=self.test_size, num_samples_in_display=self.num_samples_in_display, dimension_reduction_method=self.dimension_reduction_method, with_display=context.with_display, model_classes=context.model_classes)\n    return CheckResult(value=values_dict, display=displays, header='Embeddings Drift')",
            "def run_logic(self, context: Context) -> CheckResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Run check.\\n\\n        Returns\\n        -------\\n        CheckResult\\n            value: dictionary containing the domain classifier auc and a dict of column name to its feature\\n            importance as calculated for the domain classifier model.\\n            display: distribution graph for each column for the columns most explaining the dataset difference,\\n            comparing the train and test distributions.\\n\\n        Raises\\n        ------\\n        DeepchecksValueError\\n            If the object is not a Dataset or DataFrame instance\\n        '\n    train_dataset = context.train\n    test_dataset = context.test\n    sample_size = min(self.sample_size, train_dataset.n_samples, test_dataset.n_samples)\n    (values_dict, displays) = run_multivariable_drift_for_embeddings(train_dataset=train_dataset, test_dataset=test_dataset, sample_size=sample_size, random_state=self.random_state, test_size=self.test_size, num_samples_in_display=self.num_samples_in_display, dimension_reduction_method=self.dimension_reduction_method, with_display=context.with_display, model_classes=context.model_classes)\n    return CheckResult(value=values_dict, display=displays, header='Embeddings Drift')",
            "def run_logic(self, context: Context) -> CheckResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Run check.\\n\\n        Returns\\n        -------\\n        CheckResult\\n            value: dictionary containing the domain classifier auc and a dict of column name to its feature\\n            importance as calculated for the domain classifier model.\\n            display: distribution graph for each column for the columns most explaining the dataset difference,\\n            comparing the train and test distributions.\\n\\n        Raises\\n        ------\\n        DeepchecksValueError\\n            If the object is not a Dataset or DataFrame instance\\n        '\n    train_dataset = context.train\n    test_dataset = context.test\n    sample_size = min(self.sample_size, train_dataset.n_samples, test_dataset.n_samples)\n    (values_dict, displays) = run_multivariable_drift_for_embeddings(train_dataset=train_dataset, test_dataset=test_dataset, sample_size=sample_size, random_state=self.random_state, test_size=self.test_size, num_samples_in_display=self.num_samples_in_display, dimension_reduction_method=self.dimension_reduction_method, with_display=context.with_display, model_classes=context.model_classes)\n    return CheckResult(value=values_dict, display=displays, header='Embeddings Drift')",
            "def run_logic(self, context: Context) -> CheckResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Run check.\\n\\n        Returns\\n        -------\\n        CheckResult\\n            value: dictionary containing the domain classifier auc and a dict of column name to its feature\\n            importance as calculated for the domain classifier model.\\n            display: distribution graph for each column for the columns most explaining the dataset difference,\\n            comparing the train and test distributions.\\n\\n        Raises\\n        ------\\n        DeepchecksValueError\\n            If the object is not a Dataset or DataFrame instance\\n        '\n    train_dataset = context.train\n    test_dataset = context.test\n    sample_size = min(self.sample_size, train_dataset.n_samples, test_dataset.n_samples)\n    (values_dict, displays) = run_multivariable_drift_for_embeddings(train_dataset=train_dataset, test_dataset=test_dataset, sample_size=sample_size, random_state=self.random_state, test_size=self.test_size, num_samples_in_display=self.num_samples_in_display, dimension_reduction_method=self.dimension_reduction_method, with_display=context.with_display, model_classes=context.model_classes)\n    return CheckResult(value=values_dict, display=displays, header='Embeddings Drift')",
            "def run_logic(self, context: Context) -> CheckResult:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Run check.\\n\\n        Returns\\n        -------\\n        CheckResult\\n            value: dictionary containing the domain classifier auc and a dict of column name to its feature\\n            importance as calculated for the domain classifier model.\\n            display: distribution graph for each column for the columns most explaining the dataset difference,\\n            comparing the train and test distributions.\\n\\n        Raises\\n        ------\\n        DeepchecksValueError\\n            If the object is not a Dataset or DataFrame instance\\n        '\n    train_dataset = context.train\n    test_dataset = context.test\n    sample_size = min(self.sample_size, train_dataset.n_samples, test_dataset.n_samples)\n    (values_dict, displays) = run_multivariable_drift_for_embeddings(train_dataset=train_dataset, test_dataset=test_dataset, sample_size=sample_size, random_state=self.random_state, test_size=self.test_size, num_samples_in_display=self.num_samples_in_display, dimension_reduction_method=self.dimension_reduction_method, with_display=context.with_display, model_classes=context.model_classes)\n    return CheckResult(value=values_dict, display=displays, header='Embeddings Drift')"
        ]
    },
    {
        "func_name": "condition",
        "original": "def condition(result: dict):\n    drift_score = result['domain_classifier_drift_score']\n    details = f\"Found drift value of: {format_number(drift_score)}, corresponding to a domain classifier AUC of: {format_number(result['domain_classifier_auc'])}\"\n    category = ConditionCategory.PASS if drift_score < max_drift_value else ConditionCategory.FAIL\n    return ConditionResult(category, details)",
        "mutated": [
            "def condition(result: dict):\n    if False:\n        i = 10\n    drift_score = result['domain_classifier_drift_score']\n    details = f\"Found drift value of: {format_number(drift_score)}, corresponding to a domain classifier AUC of: {format_number(result['domain_classifier_auc'])}\"\n    category = ConditionCategory.PASS if drift_score < max_drift_value else ConditionCategory.FAIL\n    return ConditionResult(category, details)",
            "def condition(result: dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    drift_score = result['domain_classifier_drift_score']\n    details = f\"Found drift value of: {format_number(drift_score)}, corresponding to a domain classifier AUC of: {format_number(result['domain_classifier_auc'])}\"\n    category = ConditionCategory.PASS if drift_score < max_drift_value else ConditionCategory.FAIL\n    return ConditionResult(category, details)",
            "def condition(result: dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    drift_score = result['domain_classifier_drift_score']\n    details = f\"Found drift value of: {format_number(drift_score)}, corresponding to a domain classifier AUC of: {format_number(result['domain_classifier_auc'])}\"\n    category = ConditionCategory.PASS if drift_score < max_drift_value else ConditionCategory.FAIL\n    return ConditionResult(category, details)",
            "def condition(result: dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    drift_score = result['domain_classifier_drift_score']\n    details = f\"Found drift value of: {format_number(drift_score)}, corresponding to a domain classifier AUC of: {format_number(result['domain_classifier_auc'])}\"\n    category = ConditionCategory.PASS if drift_score < max_drift_value else ConditionCategory.FAIL\n    return ConditionResult(category, details)",
            "def condition(result: dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    drift_score = result['domain_classifier_drift_score']\n    details = f\"Found drift value of: {format_number(drift_score)}, corresponding to a domain classifier AUC of: {format_number(result['domain_classifier_auc'])}\"\n    category = ConditionCategory.PASS if drift_score < max_drift_value else ConditionCategory.FAIL\n    return ConditionResult(category, details)"
        ]
    },
    {
        "func_name": "add_condition_overall_drift_value_less_than",
        "original": "def add_condition_overall_drift_value_less_than(self, max_drift_value: float=0.25):\n    \"\"\"Add condition.\n\n        Overall drift score, calculated as (2 * AUC - 1) for the AUC of the dataset discriminator model, is less\n        than the specified value. This value is used as it scales the AUC value to the range [0, 1], where 0 indicates\n        a random model (and no drift) and 1 indicates a perfect model (and completely distinguishable datasets).\n\n        Parameters\n        ----------\n        max_drift_value : float , default: 0.25\n            Maximal drift value allowed (value 0 and above)\n        \"\"\"\n\n    def condition(result: dict):\n        drift_score = result['domain_classifier_drift_score']\n        details = f\"Found drift value of: {format_number(drift_score)}, corresponding to a domain classifier AUC of: {format_number(result['domain_classifier_auc'])}\"\n        category = ConditionCategory.PASS if drift_score < max_drift_value else ConditionCategory.FAIL\n        return ConditionResult(category, details)\n    return self.add_condition(f'Drift value is less than {format_number(max_drift_value)}', condition)",
        "mutated": [
            "def add_condition_overall_drift_value_less_than(self, max_drift_value: float=0.25):\n    if False:\n        i = 10\n    'Add condition.\\n\\n        Overall drift score, calculated as (2 * AUC - 1) for the AUC of the dataset discriminator model, is less\\n        than the specified value. This value is used as it scales the AUC value to the range [0, 1], where 0 indicates\\n        a random model (and no drift) and 1 indicates a perfect model (and completely distinguishable datasets).\\n\\n        Parameters\\n        ----------\\n        max_drift_value : float , default: 0.25\\n            Maximal drift value allowed (value 0 and above)\\n        '\n\n    def condition(result: dict):\n        drift_score = result['domain_classifier_drift_score']\n        details = f\"Found drift value of: {format_number(drift_score)}, corresponding to a domain classifier AUC of: {format_number(result['domain_classifier_auc'])}\"\n        category = ConditionCategory.PASS if drift_score < max_drift_value else ConditionCategory.FAIL\n        return ConditionResult(category, details)\n    return self.add_condition(f'Drift value is less than {format_number(max_drift_value)}', condition)",
            "def add_condition_overall_drift_value_less_than(self, max_drift_value: float=0.25):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Add condition.\\n\\n        Overall drift score, calculated as (2 * AUC - 1) for the AUC of the dataset discriminator model, is less\\n        than the specified value. This value is used as it scales the AUC value to the range [0, 1], where 0 indicates\\n        a random model (and no drift) and 1 indicates a perfect model (and completely distinguishable datasets).\\n\\n        Parameters\\n        ----------\\n        max_drift_value : float , default: 0.25\\n            Maximal drift value allowed (value 0 and above)\\n        '\n\n    def condition(result: dict):\n        drift_score = result['domain_classifier_drift_score']\n        details = f\"Found drift value of: {format_number(drift_score)}, corresponding to a domain classifier AUC of: {format_number(result['domain_classifier_auc'])}\"\n        category = ConditionCategory.PASS if drift_score < max_drift_value else ConditionCategory.FAIL\n        return ConditionResult(category, details)\n    return self.add_condition(f'Drift value is less than {format_number(max_drift_value)}', condition)",
            "def add_condition_overall_drift_value_less_than(self, max_drift_value: float=0.25):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Add condition.\\n\\n        Overall drift score, calculated as (2 * AUC - 1) for the AUC of the dataset discriminator model, is less\\n        than the specified value. This value is used as it scales the AUC value to the range [0, 1], where 0 indicates\\n        a random model (and no drift) and 1 indicates a perfect model (and completely distinguishable datasets).\\n\\n        Parameters\\n        ----------\\n        max_drift_value : float , default: 0.25\\n            Maximal drift value allowed (value 0 and above)\\n        '\n\n    def condition(result: dict):\n        drift_score = result['domain_classifier_drift_score']\n        details = f\"Found drift value of: {format_number(drift_score)}, corresponding to a domain classifier AUC of: {format_number(result['domain_classifier_auc'])}\"\n        category = ConditionCategory.PASS if drift_score < max_drift_value else ConditionCategory.FAIL\n        return ConditionResult(category, details)\n    return self.add_condition(f'Drift value is less than {format_number(max_drift_value)}', condition)",
            "def add_condition_overall_drift_value_less_than(self, max_drift_value: float=0.25):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Add condition.\\n\\n        Overall drift score, calculated as (2 * AUC - 1) for the AUC of the dataset discriminator model, is less\\n        than the specified value. This value is used as it scales the AUC value to the range [0, 1], where 0 indicates\\n        a random model (and no drift) and 1 indicates a perfect model (and completely distinguishable datasets).\\n\\n        Parameters\\n        ----------\\n        max_drift_value : float , default: 0.25\\n            Maximal drift value allowed (value 0 and above)\\n        '\n\n    def condition(result: dict):\n        drift_score = result['domain_classifier_drift_score']\n        details = f\"Found drift value of: {format_number(drift_score)}, corresponding to a domain classifier AUC of: {format_number(result['domain_classifier_auc'])}\"\n        category = ConditionCategory.PASS if drift_score < max_drift_value else ConditionCategory.FAIL\n        return ConditionResult(category, details)\n    return self.add_condition(f'Drift value is less than {format_number(max_drift_value)}', condition)",
            "def add_condition_overall_drift_value_less_than(self, max_drift_value: float=0.25):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Add condition.\\n\\n        Overall drift score, calculated as (2 * AUC - 1) for the AUC of the dataset discriminator model, is less\\n        than the specified value. This value is used as it scales the AUC value to the range [0, 1], where 0 indicates\\n        a random model (and no drift) and 1 indicates a perfect model (and completely distinguishable datasets).\\n\\n        Parameters\\n        ----------\\n        max_drift_value : float , default: 0.25\\n            Maximal drift value allowed (value 0 and above)\\n        '\n\n    def condition(result: dict):\n        drift_score = result['domain_classifier_drift_score']\n        details = f\"Found drift value of: {format_number(drift_score)}, corresponding to a domain classifier AUC of: {format_number(result['domain_classifier_auc'])}\"\n        category = ConditionCategory.PASS if drift_score < max_drift_value else ConditionCategory.FAIL\n        return ConditionResult(category, details)\n    return self.add_condition(f'Drift value is less than {format_number(max_drift_value)}', condition)"
        ]
    }
]