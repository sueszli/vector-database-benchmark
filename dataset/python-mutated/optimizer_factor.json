[
    {
        "func_name": "__init__",
        "original": "def __init__(self, optimizer):\n    self._optimizer = optimizer\n    self._learning_rate = optimizer._learning_rate\n    self._regularization = optimizer.regularization",
        "mutated": [
            "def __init__(self, optimizer):\n    if False:\n        i = 10\n    self._optimizer = optimizer\n    self._learning_rate = optimizer._learning_rate\n    self._regularization = optimizer.regularization",
            "def __init__(self, optimizer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self._optimizer = optimizer\n    self._learning_rate = optimizer._learning_rate\n    self._regularization = optimizer.regularization",
            "def __init__(self, optimizer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self._optimizer = optimizer\n    self._learning_rate = optimizer._learning_rate\n    self._regularization = optimizer.regularization",
            "def __init__(self, optimizer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self._optimizer = optimizer\n    self._learning_rate = optimizer._learning_rate\n    self._regularization = optimizer.regularization",
            "def __init__(self, optimizer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self._optimizer = optimizer\n    self._learning_rate = optimizer._learning_rate\n    self._regularization = optimizer.regularization"
        ]
    },
    {
        "func_name": "minimize",
        "original": "def minimize(self, losses, startup_program=None, parameter_list=None, no_grad_set=None):\n    \"\"\"\n        Args:\n            losses(Variable): loss variable defined by user\n            startup_program(Program): startup program that defined by user\n            parameter_list(str list): parameter names defined by users\n            no_grad_set(set): a set of variables that is defined by users\n                so that these variables do not need gradient computation\n        \"\"\"\n    pass",
        "mutated": [
            "def minimize(self, losses, startup_program=None, parameter_list=None, no_grad_set=None):\n    if False:\n        i = 10\n    '\\n        Args:\\n            losses(Variable): loss variable defined by user\\n            startup_program(Program): startup program that defined by user\\n            parameter_list(str list): parameter names defined by users\\n            no_grad_set(set): a set of variables that is defined by users\\n                so that these variables do not need gradient computation\\n        '\n    pass",
            "def minimize(self, losses, startup_program=None, parameter_list=None, no_grad_set=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Args:\\n            losses(Variable): loss variable defined by user\\n            startup_program(Program): startup program that defined by user\\n            parameter_list(str list): parameter names defined by users\\n            no_grad_set(set): a set of variables that is defined by users\\n                so that these variables do not need gradient computation\\n        '\n    pass",
            "def minimize(self, losses, startup_program=None, parameter_list=None, no_grad_set=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Args:\\n            losses(Variable): loss variable defined by user\\n            startup_program(Program): startup program that defined by user\\n            parameter_list(str list): parameter names defined by users\\n            no_grad_set(set): a set of variables that is defined by users\\n                so that these variables do not need gradient computation\\n        '\n    pass",
            "def minimize(self, losses, startup_program=None, parameter_list=None, no_grad_set=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Args:\\n            losses(Variable): loss variable defined by user\\n            startup_program(Program): startup program that defined by user\\n            parameter_list(str list): parameter names defined by users\\n            no_grad_set(set): a set of variables that is defined by users\\n                so that these variables do not need gradient computation\\n        '\n    pass",
            "def minimize(self, losses, startup_program=None, parameter_list=None, no_grad_set=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Args:\\n            losses(Variable): loss variable defined by user\\n            startup_program(Program): startup program that defined by user\\n            parameter_list(str list): parameter names defined by users\\n            no_grad_set(set): a set of variables that is defined by users\\n                so that these variables do not need gradient computation\\n        '\n    pass"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, optimizer):\n    super().__init__(optimizer)\n    self._window = 1\n    self.type = 'downpour'\n    self.data_norm_name = ['.batch_size', '.batch_square_sum', '.batch_sum', '.batch_size@GRAD', '.batch_square_sum@GRAD', '.batch_sum@GRAD']\n    self.supported_embedding_types = ['lookup_table', 'pull_sparse', 'pull_sparse_v2', 'pull_box_sparse', 'pull_gpups_sparse']\n    self.supported_embedding_grad_types = ['lookup_table_grad', 'push_sparse', 'push_sparse_v2']\n    op_maker = core.op_proto_and_checker_maker\n    self.op_role_key = op_maker.kOpRoleAttrName()",
        "mutated": [
            "def __init__(self, optimizer):\n    if False:\n        i = 10\n    super().__init__(optimizer)\n    self._window = 1\n    self.type = 'downpour'\n    self.data_norm_name = ['.batch_size', '.batch_square_sum', '.batch_sum', '.batch_size@GRAD', '.batch_square_sum@GRAD', '.batch_sum@GRAD']\n    self.supported_embedding_types = ['lookup_table', 'pull_sparse', 'pull_sparse_v2', 'pull_box_sparse', 'pull_gpups_sparse']\n    self.supported_embedding_grad_types = ['lookup_table_grad', 'push_sparse', 'push_sparse_v2']\n    op_maker = core.op_proto_and_checker_maker\n    self.op_role_key = op_maker.kOpRoleAttrName()",
            "def __init__(self, optimizer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    super().__init__(optimizer)\n    self._window = 1\n    self.type = 'downpour'\n    self.data_norm_name = ['.batch_size', '.batch_square_sum', '.batch_sum', '.batch_size@GRAD', '.batch_square_sum@GRAD', '.batch_sum@GRAD']\n    self.supported_embedding_types = ['lookup_table', 'pull_sparse', 'pull_sparse_v2', 'pull_box_sparse', 'pull_gpups_sparse']\n    self.supported_embedding_grad_types = ['lookup_table_grad', 'push_sparse', 'push_sparse_v2']\n    op_maker = core.op_proto_and_checker_maker\n    self.op_role_key = op_maker.kOpRoleAttrName()",
            "def __init__(self, optimizer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    super().__init__(optimizer)\n    self._window = 1\n    self.type = 'downpour'\n    self.data_norm_name = ['.batch_size', '.batch_square_sum', '.batch_sum', '.batch_size@GRAD', '.batch_square_sum@GRAD', '.batch_sum@GRAD']\n    self.supported_embedding_types = ['lookup_table', 'pull_sparse', 'pull_sparse_v2', 'pull_box_sparse', 'pull_gpups_sparse']\n    self.supported_embedding_grad_types = ['lookup_table_grad', 'push_sparse', 'push_sparse_v2']\n    op_maker = core.op_proto_and_checker_maker\n    self.op_role_key = op_maker.kOpRoleAttrName()",
            "def __init__(self, optimizer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    super().__init__(optimizer)\n    self._window = 1\n    self.type = 'downpour'\n    self.data_norm_name = ['.batch_size', '.batch_square_sum', '.batch_sum', '.batch_size@GRAD', '.batch_square_sum@GRAD', '.batch_sum@GRAD']\n    self.supported_embedding_types = ['lookup_table', 'pull_sparse', 'pull_sparse_v2', 'pull_box_sparse', 'pull_gpups_sparse']\n    self.supported_embedding_grad_types = ['lookup_table_grad', 'push_sparse', 'push_sparse_v2']\n    op_maker = core.op_proto_and_checker_maker\n    self.op_role_key = op_maker.kOpRoleAttrName()",
            "def __init__(self, optimizer):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    super().__init__(optimizer)\n    self._window = 1\n    self.type = 'downpour'\n    self.data_norm_name = ['.batch_size', '.batch_square_sum', '.batch_sum', '.batch_size@GRAD', '.batch_square_sum@GRAD', '.batch_sum@GRAD']\n    self.supported_embedding_types = ['lookup_table', 'pull_sparse', 'pull_sparse_v2', 'pull_box_sparse', 'pull_gpups_sparse']\n    self.supported_embedding_grad_types = ['lookup_table_grad', 'push_sparse', 'push_sparse_v2']\n    op_maker = core.op_proto_and_checker_maker\n    self.op_role_key = op_maker.kOpRoleAttrName()"
        ]
    },
    {
        "func_name": "_find_distributed_lookup_table_inputs",
        "original": "def _find_distributed_lookup_table_inputs(self, program, table_names):\n    \"\"\"\n        Find input variable of distribute lookup table in program.\n        We could support multi-distribute table now.\n        Args:\n            program(Program): given program, locate distributed lookup table\n            table_name(str): given table names that is found beforehand\n        Returns:\n            inputs\n        \"\"\"\n    local_vars = program.current_block().vars\n    inputs_dict = {}\n    for table_name in table_names:\n        inputs_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.input('W')[0] in table_names:\n                inputs_dict[op.input('W')[0]].extend([local_vars[name] for name in op.input('Ids')])\n    return inputs_dict",
        "mutated": [
            "def _find_distributed_lookup_table_inputs(self, program, table_names):\n    if False:\n        i = 10\n    '\\n        Find input variable of distribute lookup table in program.\\n        We could support multi-distribute table now.\\n        Args:\\n            program(Program): given program, locate distributed lookup table\\n            table_name(str): given table names that is found beforehand\\n        Returns:\\n            inputs\\n        '\n    local_vars = program.current_block().vars\n    inputs_dict = {}\n    for table_name in table_names:\n        inputs_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.input('W')[0] in table_names:\n                inputs_dict[op.input('W')[0]].extend([local_vars[name] for name in op.input('Ids')])\n    return inputs_dict",
            "def _find_distributed_lookup_table_inputs(self, program, table_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Find input variable of distribute lookup table in program.\\n        We could support multi-distribute table now.\\n        Args:\\n            program(Program): given program, locate distributed lookup table\\n            table_name(str): given table names that is found beforehand\\n        Returns:\\n            inputs\\n        '\n    local_vars = program.current_block().vars\n    inputs_dict = {}\n    for table_name in table_names:\n        inputs_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.input('W')[0] in table_names:\n                inputs_dict[op.input('W')[0]].extend([local_vars[name] for name in op.input('Ids')])\n    return inputs_dict",
            "def _find_distributed_lookup_table_inputs(self, program, table_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Find input variable of distribute lookup table in program.\\n        We could support multi-distribute table now.\\n        Args:\\n            program(Program): given program, locate distributed lookup table\\n            table_name(str): given table names that is found beforehand\\n        Returns:\\n            inputs\\n        '\n    local_vars = program.current_block().vars\n    inputs_dict = {}\n    for table_name in table_names:\n        inputs_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.input('W')[0] in table_names:\n                inputs_dict[op.input('W')[0]].extend([local_vars[name] for name in op.input('Ids')])\n    return inputs_dict",
            "def _find_distributed_lookup_table_inputs(self, program, table_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Find input variable of distribute lookup table in program.\\n        We could support multi-distribute table now.\\n        Args:\\n            program(Program): given program, locate distributed lookup table\\n            table_name(str): given table names that is found beforehand\\n        Returns:\\n            inputs\\n        '\n    local_vars = program.current_block().vars\n    inputs_dict = {}\n    for table_name in table_names:\n        inputs_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.input('W')[0] in table_names:\n                inputs_dict[op.input('W')[0]].extend([local_vars[name] for name in op.input('Ids')])\n    return inputs_dict",
            "def _find_distributed_lookup_table_inputs(self, program, table_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Find input variable of distribute lookup table in program.\\n        We could support multi-distribute table now.\\n        Args:\\n            program(Program): given program, locate distributed lookup table\\n            table_name(str): given table names that is found beforehand\\n        Returns:\\n            inputs\\n        '\n    local_vars = program.current_block().vars\n    inputs_dict = {}\n    for table_name in table_names:\n        inputs_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.input('W')[0] in table_names:\n                inputs_dict[op.input('W')[0]].extend([local_vars[name] for name in op.input('Ids')])\n    return inputs_dict"
        ]
    },
    {
        "func_name": "_find_distributed_lookup_table_outputs",
        "original": "def _find_distributed_lookup_table_outputs(self, program, table_names):\n    \"\"\"\n        Find output variable of distribute lookup table in program.\n        We could support multi-distribute table now.\n        Args:\n            programs(Program): given program, locate distributed lookup table\n            table_name(str): given table name that is found beforehand\n        Returns:\n            outputs\n        \"\"\"\n    local_vars = program.current_block().vars\n    outputs_dict = {}\n    for table_name in table_names:\n        outputs_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.input('W')[0] in table_names:\n                outputs_dict[op.input('W')[0]].extend([local_vars[name] for name in op.output('Out')])\n    return outputs_dict",
        "mutated": [
            "def _find_distributed_lookup_table_outputs(self, program, table_names):\n    if False:\n        i = 10\n    '\\n        Find output variable of distribute lookup table in program.\\n        We could support multi-distribute table now.\\n        Args:\\n            programs(Program): given program, locate distributed lookup table\\n            table_name(str): given table name that is found beforehand\\n        Returns:\\n            outputs\\n        '\n    local_vars = program.current_block().vars\n    outputs_dict = {}\n    for table_name in table_names:\n        outputs_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.input('W')[0] in table_names:\n                outputs_dict[op.input('W')[0]].extend([local_vars[name] for name in op.output('Out')])\n    return outputs_dict",
            "def _find_distributed_lookup_table_outputs(self, program, table_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Find output variable of distribute lookup table in program.\\n        We could support multi-distribute table now.\\n        Args:\\n            programs(Program): given program, locate distributed lookup table\\n            table_name(str): given table name that is found beforehand\\n        Returns:\\n            outputs\\n        '\n    local_vars = program.current_block().vars\n    outputs_dict = {}\n    for table_name in table_names:\n        outputs_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.input('W')[0] in table_names:\n                outputs_dict[op.input('W')[0]].extend([local_vars[name] for name in op.output('Out')])\n    return outputs_dict",
            "def _find_distributed_lookup_table_outputs(self, program, table_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Find output variable of distribute lookup table in program.\\n        We could support multi-distribute table now.\\n        Args:\\n            programs(Program): given program, locate distributed lookup table\\n            table_name(str): given table name that is found beforehand\\n        Returns:\\n            outputs\\n        '\n    local_vars = program.current_block().vars\n    outputs_dict = {}\n    for table_name in table_names:\n        outputs_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.input('W')[0] in table_names:\n                outputs_dict[op.input('W')[0]].extend([local_vars[name] for name in op.output('Out')])\n    return outputs_dict",
            "def _find_distributed_lookup_table_outputs(self, program, table_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Find output variable of distribute lookup table in program.\\n        We could support multi-distribute table now.\\n        Args:\\n            programs(Program): given program, locate distributed lookup table\\n            table_name(str): given table name that is found beforehand\\n        Returns:\\n            outputs\\n        '\n    local_vars = program.current_block().vars\n    outputs_dict = {}\n    for table_name in table_names:\n        outputs_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.input('W')[0] in table_names:\n                outputs_dict[op.input('W')[0]].extend([local_vars[name] for name in op.output('Out')])\n    return outputs_dict",
            "def _find_distributed_lookup_table_outputs(self, program, table_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Find output variable of distribute lookup table in program.\\n        We could support multi-distribute table now.\\n        Args:\\n            programs(Program): given program, locate distributed lookup table\\n            table_name(str): given table name that is found beforehand\\n        Returns:\\n            outputs\\n        '\n    local_vars = program.current_block().vars\n    outputs_dict = {}\n    for table_name in table_names:\n        outputs_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.input('W')[0] in table_names:\n                outputs_dict[op.input('W')[0]].extend([local_vars[name] for name in op.output('Out')])\n    return outputs_dict"
        ]
    },
    {
        "func_name": "_find_distributed_lookup_table_grads",
        "original": "def _find_distributed_lookup_table_grads(self, program, table_names):\n    local_vars = program.current_block().vars\n    grads_dict = {}\n    for table_name in table_names:\n        grads_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_grad_types:\n            if op.input('W')[0] in table_names:\n                grads_dict[op.input('W')[0]].extend([local_vars[name] for name in op.input('Out@GRAD')])\n    return grads_dict",
        "mutated": [
            "def _find_distributed_lookup_table_grads(self, program, table_names):\n    if False:\n        i = 10\n    local_vars = program.current_block().vars\n    grads_dict = {}\n    for table_name in table_names:\n        grads_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_grad_types:\n            if op.input('W')[0] in table_names:\n                grads_dict[op.input('W')[0]].extend([local_vars[name] for name in op.input('Out@GRAD')])\n    return grads_dict",
            "def _find_distributed_lookup_table_grads(self, program, table_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    local_vars = program.current_block().vars\n    grads_dict = {}\n    for table_name in table_names:\n        grads_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_grad_types:\n            if op.input('W')[0] in table_names:\n                grads_dict[op.input('W')[0]].extend([local_vars[name] for name in op.input('Out@GRAD')])\n    return grads_dict",
            "def _find_distributed_lookup_table_grads(self, program, table_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    local_vars = program.current_block().vars\n    grads_dict = {}\n    for table_name in table_names:\n        grads_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_grad_types:\n            if op.input('W')[0] in table_names:\n                grads_dict[op.input('W')[0]].extend([local_vars[name] for name in op.input('Out@GRAD')])\n    return grads_dict",
            "def _find_distributed_lookup_table_grads(self, program, table_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    local_vars = program.current_block().vars\n    grads_dict = {}\n    for table_name in table_names:\n        grads_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_grad_types:\n            if op.input('W')[0] in table_names:\n                grads_dict[op.input('W')[0]].extend([local_vars[name] for name in op.input('Out@GRAD')])\n    return grads_dict",
            "def _find_distributed_lookup_table_grads(self, program, table_names):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    local_vars = program.current_block().vars\n    grads_dict = {}\n    for table_name in table_names:\n        grads_dict[table_name] = []\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_grad_types:\n            if op.input('W')[0] in table_names:\n                grads_dict[op.input('W')[0]].extend([local_vars[name] for name in op.input('Out@GRAD')])\n    return grads_dict"
        ]
    },
    {
        "func_name": "_is_optimizer_op",
        "original": "def _is_optimizer_op(self, op):\n    return self.op_role_key in op.attr_names and int(op.all_attrs()[self.op_role_key]) & int(OpRole.Optimize)",
        "mutated": [
            "def _is_optimizer_op(self, op):\n    if False:\n        i = 10\n    return self.op_role_key in op.attr_names and int(op.all_attrs()[self.op_role_key]) & int(OpRole.Optimize)",
            "def _is_optimizer_op(self, op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return self.op_role_key in op.attr_names and int(op.all_attrs()[self.op_role_key]) & int(OpRole.Optimize)",
            "def _is_optimizer_op(self, op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return self.op_role_key in op.attr_names and int(op.all_attrs()[self.op_role_key]) & int(OpRole.Optimize)",
            "def _is_optimizer_op(self, op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return self.op_role_key in op.attr_names and int(op.all_attrs()[self.op_role_key]) & int(OpRole.Optimize)",
            "def _is_optimizer_op(self, op):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return self.op_role_key in op.attr_names and int(op.all_attrs()[self.op_role_key]) & int(OpRole.Optimize)"
        ]
    },
    {
        "func_name": "_remove_optimize_op_for_embedding",
        "original": "def _remove_optimize_op_for_embedding(self, loss, table_name):\n    \"\"\"\n        find multi-sparse-table\n        \"\"\"\n    table_name = [name + '@GRAD' for name in table_name]\n    need_remove_op_index = []\n    block = loss.block.program.global_block()\n    for (ids, op) in list(enumerate(block.ops)):\n        if self._is_optimizer_op(op):\n            if op.input('Grad')[0] in table_name:\n                need_remove_op_index.append(ids)\n    need_remove_op_index.sort(reverse=True)\n    for index in need_remove_op_index:\n        block._remove_op(index)",
        "mutated": [
            "def _remove_optimize_op_for_embedding(self, loss, table_name):\n    if False:\n        i = 10\n    '\\n        find multi-sparse-table\\n        '\n    table_name = [name + '@GRAD' for name in table_name]\n    need_remove_op_index = []\n    block = loss.block.program.global_block()\n    for (ids, op) in list(enumerate(block.ops)):\n        if self._is_optimizer_op(op):\n            if op.input('Grad')[0] in table_name:\n                need_remove_op_index.append(ids)\n    need_remove_op_index.sort(reverse=True)\n    for index in need_remove_op_index:\n        block._remove_op(index)",
            "def _remove_optimize_op_for_embedding(self, loss, table_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        find multi-sparse-table\\n        '\n    table_name = [name + '@GRAD' for name in table_name]\n    need_remove_op_index = []\n    block = loss.block.program.global_block()\n    for (ids, op) in list(enumerate(block.ops)):\n        if self._is_optimizer_op(op):\n            if op.input('Grad')[0] in table_name:\n                need_remove_op_index.append(ids)\n    need_remove_op_index.sort(reverse=True)\n    for index in need_remove_op_index:\n        block._remove_op(index)",
            "def _remove_optimize_op_for_embedding(self, loss, table_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        find multi-sparse-table\\n        '\n    table_name = [name + '@GRAD' for name in table_name]\n    need_remove_op_index = []\n    block = loss.block.program.global_block()\n    for (ids, op) in list(enumerate(block.ops)):\n        if self._is_optimizer_op(op):\n            if op.input('Grad')[0] in table_name:\n                need_remove_op_index.append(ids)\n    need_remove_op_index.sort(reverse=True)\n    for index in need_remove_op_index:\n        block._remove_op(index)",
            "def _remove_optimize_op_for_embedding(self, loss, table_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        find multi-sparse-table\\n        '\n    table_name = [name + '@GRAD' for name in table_name]\n    need_remove_op_index = []\n    block = loss.block.program.global_block()\n    for (ids, op) in list(enumerate(block.ops)):\n        if self._is_optimizer_op(op):\n            if op.input('Grad')[0] in table_name:\n                need_remove_op_index.append(ids)\n    need_remove_op_index.sort(reverse=True)\n    for index in need_remove_op_index:\n        block._remove_op(index)",
            "def _remove_optimize_op_for_embedding(self, loss, table_name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        find multi-sparse-table\\n        '\n    table_name = [name + '@GRAD' for name in table_name]\n    need_remove_op_index = []\n    block = loss.block.program.global_block()\n    for (ids, op) in list(enumerate(block.ops)):\n        if self._is_optimizer_op(op):\n            if op.input('Grad')[0] in table_name:\n                need_remove_op_index.append(ids)\n    need_remove_op_index.sort(reverse=True)\n    for index in need_remove_op_index:\n        block._remove_op(index)"
        ]
    },
    {
        "func_name": "_find_multi_distributed_lookup_table",
        "original": "def _find_multi_distributed_lookup_table(self, losses):\n    \"\"\"\n        find multi-sparse-table\n        \"\"\"\n    table_names = set()\n    cnt = 0\n    tmp_list = []\n    ret_list = []\n    for loss in losses:\n        for op in loss.block.program.global_block().ops:\n            if op.type in self.supported_embedding_types:\n                if op.attr('is_distributed') is True:\n                    table_name = op.input('W')[0]\n                    if table_name not in table_names:\n                        table_names.add(table_name)\n                        tmp_list.append([table_name, cnt])\n                        cnt += 1\n    tmp_list.sort(key=lambda k: k[1])\n    for x in tmp_list:\n        ret_list.append(x[0])\n    return ret_list",
        "mutated": [
            "def _find_multi_distributed_lookup_table(self, losses):\n    if False:\n        i = 10\n    '\\n        find multi-sparse-table\\n        '\n    table_names = set()\n    cnt = 0\n    tmp_list = []\n    ret_list = []\n    for loss in losses:\n        for op in loss.block.program.global_block().ops:\n            if op.type in self.supported_embedding_types:\n                if op.attr('is_distributed') is True:\n                    table_name = op.input('W')[0]\n                    if table_name not in table_names:\n                        table_names.add(table_name)\n                        tmp_list.append([table_name, cnt])\n                        cnt += 1\n    tmp_list.sort(key=lambda k: k[1])\n    for x in tmp_list:\n        ret_list.append(x[0])\n    return ret_list",
            "def _find_multi_distributed_lookup_table(self, losses):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        find multi-sparse-table\\n        '\n    table_names = set()\n    cnt = 0\n    tmp_list = []\n    ret_list = []\n    for loss in losses:\n        for op in loss.block.program.global_block().ops:\n            if op.type in self.supported_embedding_types:\n                if op.attr('is_distributed') is True:\n                    table_name = op.input('W')[0]\n                    if table_name not in table_names:\n                        table_names.add(table_name)\n                        tmp_list.append([table_name, cnt])\n                        cnt += 1\n    tmp_list.sort(key=lambda k: k[1])\n    for x in tmp_list:\n        ret_list.append(x[0])\n    return ret_list",
            "def _find_multi_distributed_lookup_table(self, losses):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        find multi-sparse-table\\n        '\n    table_names = set()\n    cnt = 0\n    tmp_list = []\n    ret_list = []\n    for loss in losses:\n        for op in loss.block.program.global_block().ops:\n            if op.type in self.supported_embedding_types:\n                if op.attr('is_distributed') is True:\n                    table_name = op.input('W')[0]\n                    if table_name not in table_names:\n                        table_names.add(table_name)\n                        tmp_list.append([table_name, cnt])\n                        cnt += 1\n    tmp_list.sort(key=lambda k: k[1])\n    for x in tmp_list:\n        ret_list.append(x[0])\n    return ret_list",
            "def _find_multi_distributed_lookup_table(self, losses):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        find multi-sparse-table\\n        '\n    table_names = set()\n    cnt = 0\n    tmp_list = []\n    ret_list = []\n    for loss in losses:\n        for op in loss.block.program.global_block().ops:\n            if op.type in self.supported_embedding_types:\n                if op.attr('is_distributed') is True:\n                    table_name = op.input('W')[0]\n                    if table_name not in table_names:\n                        table_names.add(table_name)\n                        tmp_list.append([table_name, cnt])\n                        cnt += 1\n    tmp_list.sort(key=lambda k: k[1])\n    for x in tmp_list:\n        ret_list.append(x[0])\n    return ret_list",
            "def _find_multi_distributed_lookup_table(self, losses):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        find multi-sparse-table\\n        '\n    table_names = set()\n    cnt = 0\n    tmp_list = []\n    ret_list = []\n    for loss in losses:\n        for op in loss.block.program.global_block().ops:\n            if op.type in self.supported_embedding_types:\n                if op.attr('is_distributed') is True:\n                    table_name = op.input('W')[0]\n                    if table_name not in table_names:\n                        table_names.add(table_name)\n                        tmp_list.append([table_name, cnt])\n                        cnt += 1\n    tmp_list.sort(key=lambda k: k[1])\n    for x in tmp_list:\n        ret_list.append(x[0])\n    return ret_list"
        ]
    },
    {
        "func_name": "_if_last_block",
        "original": "def _if_last_block(self, op, _equal_dict):\n    cond_str = op.input('Cond')[0]\n    bool_test = False\n    if cond_str.startswith('equal'):\n        bool_test = True\n    vars_ = op.input('Input')\n    equal_keys = _equal_dict.keys()\n    for var_cond in vars_:\n        if var_cond in equal_keys:\n            if bool_test:\n                print('the conditional block is error')\n            return False\n    return True",
        "mutated": [
            "def _if_last_block(self, op, _equal_dict):\n    if False:\n        i = 10\n    cond_str = op.input('Cond')[0]\n    bool_test = False\n    if cond_str.startswith('equal'):\n        bool_test = True\n    vars_ = op.input('Input')\n    equal_keys = _equal_dict.keys()\n    for var_cond in vars_:\n        if var_cond in equal_keys:\n            if bool_test:\n                print('the conditional block is error')\n            return False\n    return True",
            "def _if_last_block(self, op, _equal_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    cond_str = op.input('Cond')[0]\n    bool_test = False\n    if cond_str.startswith('equal'):\n        bool_test = True\n    vars_ = op.input('Input')\n    equal_keys = _equal_dict.keys()\n    for var_cond in vars_:\n        if var_cond in equal_keys:\n            if bool_test:\n                print('the conditional block is error')\n            return False\n    return True",
            "def _if_last_block(self, op, _equal_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    cond_str = op.input('Cond')[0]\n    bool_test = False\n    if cond_str.startswith('equal'):\n        bool_test = True\n    vars_ = op.input('Input')\n    equal_keys = _equal_dict.keys()\n    for var_cond in vars_:\n        if var_cond in equal_keys:\n            if bool_test:\n                print('the conditional block is error')\n            return False\n    return True",
            "def _if_last_block(self, op, _equal_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    cond_str = op.input('Cond')[0]\n    bool_test = False\n    if cond_str.startswith('equal'):\n        bool_test = True\n    vars_ = op.input('Input')\n    equal_keys = _equal_dict.keys()\n    for var_cond in vars_:\n        if var_cond in equal_keys:\n            if bool_test:\n                print('the conditional block is error')\n            return False\n    return True",
            "def _if_last_block(self, op, _equal_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    cond_str = op.input('Cond')[0]\n    bool_test = False\n    if cond_str.startswith('equal'):\n        bool_test = True\n    vars_ = op.input('Input')\n    equal_keys = _equal_dict.keys()\n    for var_cond in vars_:\n        if var_cond in equal_keys:\n            if bool_test:\n                print('the conditional block is error')\n            return False\n    return True"
        ]
    },
    {
        "func_name": "_generte_cond_para_map",
        "original": "def _generte_cond_para_map(self, op, _fill_value_dict, _equal_fill_dict, _now_program, _all_params):\n    cond_str = op.input('Cond')[0]\n    vars_ = op.input('Input')\n    if self._if_last_block(op, _equal_fill_dict):\n        vars_ = op.input('Input')\n        cond_key = ''\n        if cond_str.startswith('equal'):\n            cond_key = int(_fill_value_dict[_equal_fill_dict[cond_str]])\n        else:\n            cond_key = -1\n        p_list = []\n        for var_cond in vars_:\n            if var_cond in _all_params:\n                p_list.append(var_cond)\n        self._cond_params[cond_key] = p_list\n        self._other_params.extend(p_list)\n    else:\n        ops_cond = _now_program.block(int(op.attr('sub_block').id)).ops\n        for op in ops_cond:\n            if op.type == 'conditional_block':\n                self._generte_cond_para_map(op, _fill_value_dict, _equal_fill_dict, _now_program, _all_params)",
        "mutated": [
            "def _generte_cond_para_map(self, op, _fill_value_dict, _equal_fill_dict, _now_program, _all_params):\n    if False:\n        i = 10\n    cond_str = op.input('Cond')[0]\n    vars_ = op.input('Input')\n    if self._if_last_block(op, _equal_fill_dict):\n        vars_ = op.input('Input')\n        cond_key = ''\n        if cond_str.startswith('equal'):\n            cond_key = int(_fill_value_dict[_equal_fill_dict[cond_str]])\n        else:\n            cond_key = -1\n        p_list = []\n        for var_cond in vars_:\n            if var_cond in _all_params:\n                p_list.append(var_cond)\n        self._cond_params[cond_key] = p_list\n        self._other_params.extend(p_list)\n    else:\n        ops_cond = _now_program.block(int(op.attr('sub_block').id)).ops\n        for op in ops_cond:\n            if op.type == 'conditional_block':\n                self._generte_cond_para_map(op, _fill_value_dict, _equal_fill_dict, _now_program, _all_params)",
            "def _generte_cond_para_map(self, op, _fill_value_dict, _equal_fill_dict, _now_program, _all_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    cond_str = op.input('Cond')[0]\n    vars_ = op.input('Input')\n    if self._if_last_block(op, _equal_fill_dict):\n        vars_ = op.input('Input')\n        cond_key = ''\n        if cond_str.startswith('equal'):\n            cond_key = int(_fill_value_dict[_equal_fill_dict[cond_str]])\n        else:\n            cond_key = -1\n        p_list = []\n        for var_cond in vars_:\n            if var_cond in _all_params:\n                p_list.append(var_cond)\n        self._cond_params[cond_key] = p_list\n        self._other_params.extend(p_list)\n    else:\n        ops_cond = _now_program.block(int(op.attr('sub_block').id)).ops\n        for op in ops_cond:\n            if op.type == 'conditional_block':\n                self._generte_cond_para_map(op, _fill_value_dict, _equal_fill_dict, _now_program, _all_params)",
            "def _generte_cond_para_map(self, op, _fill_value_dict, _equal_fill_dict, _now_program, _all_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    cond_str = op.input('Cond')[0]\n    vars_ = op.input('Input')\n    if self._if_last_block(op, _equal_fill_dict):\n        vars_ = op.input('Input')\n        cond_key = ''\n        if cond_str.startswith('equal'):\n            cond_key = int(_fill_value_dict[_equal_fill_dict[cond_str]])\n        else:\n            cond_key = -1\n        p_list = []\n        for var_cond in vars_:\n            if var_cond in _all_params:\n                p_list.append(var_cond)\n        self._cond_params[cond_key] = p_list\n        self._other_params.extend(p_list)\n    else:\n        ops_cond = _now_program.block(int(op.attr('sub_block').id)).ops\n        for op in ops_cond:\n            if op.type == 'conditional_block':\n                self._generte_cond_para_map(op, _fill_value_dict, _equal_fill_dict, _now_program, _all_params)",
            "def _generte_cond_para_map(self, op, _fill_value_dict, _equal_fill_dict, _now_program, _all_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    cond_str = op.input('Cond')[0]\n    vars_ = op.input('Input')\n    if self._if_last_block(op, _equal_fill_dict):\n        vars_ = op.input('Input')\n        cond_key = ''\n        if cond_str.startswith('equal'):\n            cond_key = int(_fill_value_dict[_equal_fill_dict[cond_str]])\n        else:\n            cond_key = -1\n        p_list = []\n        for var_cond in vars_:\n            if var_cond in _all_params:\n                p_list.append(var_cond)\n        self._cond_params[cond_key] = p_list\n        self._other_params.extend(p_list)\n    else:\n        ops_cond = _now_program.block(int(op.attr('sub_block').id)).ops\n        for op in ops_cond:\n            if op.type == 'conditional_block':\n                self._generte_cond_para_map(op, _fill_value_dict, _equal_fill_dict, _now_program, _all_params)",
            "def _generte_cond_para_map(self, op, _fill_value_dict, _equal_fill_dict, _now_program, _all_params):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    cond_str = op.input('Cond')[0]\n    vars_ = op.input('Input')\n    if self._if_last_block(op, _equal_fill_dict):\n        vars_ = op.input('Input')\n        cond_key = ''\n        if cond_str.startswith('equal'):\n            cond_key = int(_fill_value_dict[_equal_fill_dict[cond_str]])\n        else:\n            cond_key = -1\n        p_list = []\n        for var_cond in vars_:\n            if var_cond in _all_params:\n                p_list.append(var_cond)\n        self._cond_params[cond_key] = p_list\n        self._other_params.extend(p_list)\n    else:\n        ops_cond = _now_program.block(int(op.attr('sub_block').id)).ops\n        for op in ops_cond:\n            if op.type == 'conditional_block':\n                self._generte_cond_para_map(op, _fill_value_dict, _equal_fill_dict, _now_program, _all_params)"
        ]
    },
    {
        "func_name": "_has_conditional_block",
        "original": "def _has_conditional_block(self, loss):\n    now_program = loss.block.program\n    root_block = now_program.block(0)\n    ops_ = root_block.ops\n    for op in ops_:\n        if op.type == 'conditional_block':\n            return True\n    return False",
        "mutated": [
            "def _has_conditional_block(self, loss):\n    if False:\n        i = 10\n    now_program = loss.block.program\n    root_block = now_program.block(0)\n    ops_ = root_block.ops\n    for op in ops_:\n        if op.type == 'conditional_block':\n            return True\n    return False",
            "def _has_conditional_block(self, loss):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    now_program = loss.block.program\n    root_block = now_program.block(0)\n    ops_ = root_block.ops\n    for op in ops_:\n        if op.type == 'conditional_block':\n            return True\n    return False",
            "def _has_conditional_block(self, loss):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    now_program = loss.block.program\n    root_block = now_program.block(0)\n    ops_ = root_block.ops\n    for op in ops_:\n        if op.type == 'conditional_block':\n            return True\n    return False",
            "def _has_conditional_block(self, loss):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    now_program = loss.block.program\n    root_block = now_program.block(0)\n    ops_ = root_block.ops\n    for op in ops_:\n        if op.type == 'conditional_block':\n            return True\n    return False",
            "def _has_conditional_block(self, loss):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    now_program = loss.block.program\n    root_block = now_program.block(0)\n    ops_ = root_block.ops\n    for op in ops_:\n        if op.type == 'conditional_block':\n            return True\n    return False"
        ]
    },
    {
        "func_name": "_check_params_grads",
        "original": "def _check_params_grads(self, params, grads):\n    if len(params) != len(grads):\n        raise ValueError(f'params size != grads size, {len(params)} vs {len(grads)}')\n    pname2grad = {}\n    for i in range(len(params)):\n        pname = params[i].name\n        gname = grads[i].name\n        if pname != gname[:-5]:\n            raise ValueError(f' params != grads , {pname} vs {gname}')\n        pname2grad[pname] = grads[i]\n    return pname2grad",
        "mutated": [
            "def _check_params_grads(self, params, grads):\n    if False:\n        i = 10\n    if len(params) != len(grads):\n        raise ValueError(f'params size != grads size, {len(params)} vs {len(grads)}')\n    pname2grad = {}\n    for i in range(len(params)):\n        pname = params[i].name\n        gname = grads[i].name\n        if pname != gname[:-5]:\n            raise ValueError(f' params != grads , {pname} vs {gname}')\n        pname2grad[pname] = grads[i]\n    return pname2grad",
            "def _check_params_grads(self, params, grads):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if len(params) != len(grads):\n        raise ValueError(f'params size != grads size, {len(params)} vs {len(grads)}')\n    pname2grad = {}\n    for i in range(len(params)):\n        pname = params[i].name\n        gname = grads[i].name\n        if pname != gname[:-5]:\n            raise ValueError(f' params != grads , {pname} vs {gname}')\n        pname2grad[pname] = grads[i]\n    return pname2grad",
            "def _check_params_grads(self, params, grads):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if len(params) != len(grads):\n        raise ValueError(f'params size != grads size, {len(params)} vs {len(grads)}')\n    pname2grad = {}\n    for i in range(len(params)):\n        pname = params[i].name\n        gname = grads[i].name\n        if pname != gname[:-5]:\n            raise ValueError(f' params != grads , {pname} vs {gname}')\n        pname2grad[pname] = grads[i]\n    return pname2grad",
            "def _check_params_grads(self, params, grads):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if len(params) != len(grads):\n        raise ValueError(f'params size != grads size, {len(params)} vs {len(grads)}')\n    pname2grad = {}\n    for i in range(len(params)):\n        pname = params[i].name\n        gname = grads[i].name\n        if pname != gname[:-5]:\n            raise ValueError(f' params != grads , {pname} vs {gname}')\n        pname2grad[pname] = grads[i]\n    return pname2grad",
            "def _check_params_grads(self, params, grads):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if len(params) != len(grads):\n        raise ValueError(f'params size != grads size, {len(params)} vs {len(grads)}')\n    pname2grad = {}\n    for i in range(len(params)):\n        pname = params[i].name\n        gname = grads[i].name\n        if pname != gname[:-5]:\n            raise ValueError(f' params != grads , {pname} vs {gname}')\n        pname2grad[pname] = grads[i]\n    return pname2grad"
        ]
    },
    {
        "func_name": "_generate_multi_dense_table",
        "original": "def _generate_multi_dense_table(self, params, grads, cond_params, other_params, sparse_table_names, dense_table_id=0):\n    pname2grad = self._check_params_grads(params, grads)\n    root_params_list = []\n    root_grads_list = []\n    dense_tables = []\n    for (i, p) in enumerate(params):\n        if p.name not in other_params and p.name not in sparse_table_names:\n            root_params_list.append(p)\n            root_grads_list.append(grads[i])\n    if len(root_params_list) > 0:\n        dense_tables.append(dense_table_id)\n        dense_table_id += 1\n    lists_params = [[] for i in range(len(cond_params.keys()))]\n    lists_grads = [[] for i in range(len(cond_params.keys()))]\n    key_id = 0\n    name2key = {}\n    cond2denseid = {}\n    for (key, value) in cond_params.items():\n        cond2denseid[key] = dense_table_id\n        dense_tables.append(dense_table_id)\n        dense_table_id += 1\n        for v in value:\n            name2key[v] = key_id\n        key_id += 1\n    for p in params:\n        if p.name in other_params:\n            lists_params[name2key[p.name]].append(p)\n            lists_grads[name2key[p.name]].append(pname2grad[p.name])\n    return (dense_tables, cond2denseid, lists_params, lists_grads, root_params_list, root_grads_list)",
        "mutated": [
            "def _generate_multi_dense_table(self, params, grads, cond_params, other_params, sparse_table_names, dense_table_id=0):\n    if False:\n        i = 10\n    pname2grad = self._check_params_grads(params, grads)\n    root_params_list = []\n    root_grads_list = []\n    dense_tables = []\n    for (i, p) in enumerate(params):\n        if p.name not in other_params and p.name not in sparse_table_names:\n            root_params_list.append(p)\n            root_grads_list.append(grads[i])\n    if len(root_params_list) > 0:\n        dense_tables.append(dense_table_id)\n        dense_table_id += 1\n    lists_params = [[] for i in range(len(cond_params.keys()))]\n    lists_grads = [[] for i in range(len(cond_params.keys()))]\n    key_id = 0\n    name2key = {}\n    cond2denseid = {}\n    for (key, value) in cond_params.items():\n        cond2denseid[key] = dense_table_id\n        dense_tables.append(dense_table_id)\n        dense_table_id += 1\n        for v in value:\n            name2key[v] = key_id\n        key_id += 1\n    for p in params:\n        if p.name in other_params:\n            lists_params[name2key[p.name]].append(p)\n            lists_grads[name2key[p.name]].append(pname2grad[p.name])\n    return (dense_tables, cond2denseid, lists_params, lists_grads, root_params_list, root_grads_list)",
            "def _generate_multi_dense_table(self, params, grads, cond_params, other_params, sparse_table_names, dense_table_id=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    pname2grad = self._check_params_grads(params, grads)\n    root_params_list = []\n    root_grads_list = []\n    dense_tables = []\n    for (i, p) in enumerate(params):\n        if p.name not in other_params and p.name not in sparse_table_names:\n            root_params_list.append(p)\n            root_grads_list.append(grads[i])\n    if len(root_params_list) > 0:\n        dense_tables.append(dense_table_id)\n        dense_table_id += 1\n    lists_params = [[] for i in range(len(cond_params.keys()))]\n    lists_grads = [[] for i in range(len(cond_params.keys()))]\n    key_id = 0\n    name2key = {}\n    cond2denseid = {}\n    for (key, value) in cond_params.items():\n        cond2denseid[key] = dense_table_id\n        dense_tables.append(dense_table_id)\n        dense_table_id += 1\n        for v in value:\n            name2key[v] = key_id\n        key_id += 1\n    for p in params:\n        if p.name in other_params:\n            lists_params[name2key[p.name]].append(p)\n            lists_grads[name2key[p.name]].append(pname2grad[p.name])\n    return (dense_tables, cond2denseid, lists_params, lists_grads, root_params_list, root_grads_list)",
            "def _generate_multi_dense_table(self, params, grads, cond_params, other_params, sparse_table_names, dense_table_id=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    pname2grad = self._check_params_grads(params, grads)\n    root_params_list = []\n    root_grads_list = []\n    dense_tables = []\n    for (i, p) in enumerate(params):\n        if p.name not in other_params and p.name not in sparse_table_names:\n            root_params_list.append(p)\n            root_grads_list.append(grads[i])\n    if len(root_params_list) > 0:\n        dense_tables.append(dense_table_id)\n        dense_table_id += 1\n    lists_params = [[] for i in range(len(cond_params.keys()))]\n    lists_grads = [[] for i in range(len(cond_params.keys()))]\n    key_id = 0\n    name2key = {}\n    cond2denseid = {}\n    for (key, value) in cond_params.items():\n        cond2denseid[key] = dense_table_id\n        dense_tables.append(dense_table_id)\n        dense_table_id += 1\n        for v in value:\n            name2key[v] = key_id\n        key_id += 1\n    for p in params:\n        if p.name in other_params:\n            lists_params[name2key[p.name]].append(p)\n            lists_grads[name2key[p.name]].append(pname2grad[p.name])\n    return (dense_tables, cond2denseid, lists_params, lists_grads, root_params_list, root_grads_list)",
            "def _generate_multi_dense_table(self, params, grads, cond_params, other_params, sparse_table_names, dense_table_id=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    pname2grad = self._check_params_grads(params, grads)\n    root_params_list = []\n    root_grads_list = []\n    dense_tables = []\n    for (i, p) in enumerate(params):\n        if p.name not in other_params and p.name not in sparse_table_names:\n            root_params_list.append(p)\n            root_grads_list.append(grads[i])\n    if len(root_params_list) > 0:\n        dense_tables.append(dense_table_id)\n        dense_table_id += 1\n    lists_params = [[] for i in range(len(cond_params.keys()))]\n    lists_grads = [[] for i in range(len(cond_params.keys()))]\n    key_id = 0\n    name2key = {}\n    cond2denseid = {}\n    for (key, value) in cond_params.items():\n        cond2denseid[key] = dense_table_id\n        dense_tables.append(dense_table_id)\n        dense_table_id += 1\n        for v in value:\n            name2key[v] = key_id\n        key_id += 1\n    for p in params:\n        if p.name in other_params:\n            lists_params[name2key[p.name]].append(p)\n            lists_grads[name2key[p.name]].append(pname2grad[p.name])\n    return (dense_tables, cond2denseid, lists_params, lists_grads, root_params_list, root_grads_list)",
            "def _generate_multi_dense_table(self, params, grads, cond_params, other_params, sparse_table_names, dense_table_id=0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    pname2grad = self._check_params_grads(params, grads)\n    root_params_list = []\n    root_grads_list = []\n    dense_tables = []\n    for (i, p) in enumerate(params):\n        if p.name not in other_params and p.name not in sparse_table_names:\n            root_params_list.append(p)\n            root_grads_list.append(grads[i])\n    if len(root_params_list) > 0:\n        dense_tables.append(dense_table_id)\n        dense_table_id += 1\n    lists_params = [[] for i in range(len(cond_params.keys()))]\n    lists_grads = [[] for i in range(len(cond_params.keys()))]\n    key_id = 0\n    name2key = {}\n    cond2denseid = {}\n    for (key, value) in cond_params.items():\n        cond2denseid[key] = dense_table_id\n        dense_tables.append(dense_table_id)\n        dense_table_id += 1\n        for v in value:\n            name2key[v] = key_id\n        key_id += 1\n    for p in params:\n        if p.name in other_params:\n            lists_params[name2key[p.name]].append(p)\n            lists_grads[name2key[p.name]].append(pname2grad[p.name])\n    return (dense_tables, cond2denseid, lists_params, lists_grads, root_params_list, root_grads_list)"
        ]
    },
    {
        "func_name": "_gen_distributed_emb_to_size_dict",
        "original": "def _gen_distributed_emb_to_size_dict(self, program):\n    d_size = {}\n    local_vars = program.current_block().vars\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.attr('is_distributed') is True:\n                table_name = op.input('W')[0]\n                emb_size = local_vars[table_name].shape[-1]\n                if d_size.get(table_name) is None:\n                    d_size[table_name] = emb_size\n                elif d_size[table_name] != emb_size:\n                    raise ValueError(f'embedding size error: {emb_size} vs {d_size[table_name]}')\n    return d_size",
        "mutated": [
            "def _gen_distributed_emb_to_size_dict(self, program):\n    if False:\n        i = 10\n    d_size = {}\n    local_vars = program.current_block().vars\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.attr('is_distributed') is True:\n                table_name = op.input('W')[0]\n                emb_size = local_vars[table_name].shape[-1]\n                if d_size.get(table_name) is None:\n                    d_size[table_name] = emb_size\n                elif d_size[table_name] != emb_size:\n                    raise ValueError(f'embedding size error: {emb_size} vs {d_size[table_name]}')\n    return d_size",
            "def _gen_distributed_emb_to_size_dict(self, program):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    d_size = {}\n    local_vars = program.current_block().vars\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.attr('is_distributed') is True:\n                table_name = op.input('W')[0]\n                emb_size = local_vars[table_name].shape[-1]\n                if d_size.get(table_name) is None:\n                    d_size[table_name] = emb_size\n                elif d_size[table_name] != emb_size:\n                    raise ValueError(f'embedding size error: {emb_size} vs {d_size[table_name]}')\n    return d_size",
            "def _gen_distributed_emb_to_size_dict(self, program):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    d_size = {}\n    local_vars = program.current_block().vars\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.attr('is_distributed') is True:\n                table_name = op.input('W')[0]\n                emb_size = local_vars[table_name].shape[-1]\n                if d_size.get(table_name) is None:\n                    d_size[table_name] = emb_size\n                elif d_size[table_name] != emb_size:\n                    raise ValueError(f'embedding size error: {emb_size} vs {d_size[table_name]}')\n    return d_size",
            "def _gen_distributed_emb_to_size_dict(self, program):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    d_size = {}\n    local_vars = program.current_block().vars\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.attr('is_distributed') is True:\n                table_name = op.input('W')[0]\n                emb_size = local_vars[table_name].shape[-1]\n                if d_size.get(table_name) is None:\n                    d_size[table_name] = emb_size\n                elif d_size[table_name] != emb_size:\n                    raise ValueError(f'embedding size error: {emb_size} vs {d_size[table_name]}')\n    return d_size",
            "def _gen_distributed_emb_to_size_dict(self, program):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    d_size = {}\n    local_vars = program.current_block().vars\n    for op in program.global_block().ops:\n        if op.type in self.supported_embedding_types:\n            if op.attr('is_distributed') is True:\n                table_name = op.input('W')[0]\n                emb_size = local_vars[table_name].shape[-1]\n                if d_size.get(table_name) is None:\n                    d_size[table_name] = emb_size\n                elif d_size[table_name] != emb_size:\n                    raise ValueError(f'embedding size error: {emb_size} vs {d_size[table_name]}')\n    return d_size"
        ]
    },
    {
        "func_name": "_check_config_fleet_with_program_op",
        "original": "def _check_config_fleet_with_program_op(self, strategy, table_name, emb_to_size):\n    if strategy.get(table_name) is None:\n        strategy[table_name] = {}\n    st = strategy[table_name]\n    accessor = 'DownpourCtrAccessor'\n    if st.get('sparse_accessor_class') is not None:\n        accessor = st['sparse_accessor_class']\n    if accessor == 'DownpourFeatureValueAccessor' or accessor == 'DownpourCtrAccessor' or accessor == 'DownpourCtrDymfAccessor' or (accessor == 'DownpourDoubleUnitAccessor') or (accessor == 'DownpourUnitAccessor'):\n        if st.get('sparse_embedx_dim') is not None and strategy.get('use_cvm') is True and (st['sparse_embedx_dim'] != emb_to_size[table_name] - 3):\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim - 3 = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name] - 3))\n        if st.get('sparse_embedx_dim') is not None and strategy.get('use_cvm') is False and (st['sparse_embedx_dim'] != emb_to_size[table_name] - 1):\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim - 1 = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name] - 1))\n        if st.get('sparse_embedx_dim') is None and strategy.get('use_cvm') is True:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {} - 3.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name] - 3\n        if st.get('sparse_embedx_dim') is None and strategy.get('use_cvm') is False:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {} - 1.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name] - 1\n    elif accessor == 'DownpourSparseValueAccessor':\n        if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[table_name]:\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name]))\n        if st.get('sparse_embedx_dim') is None:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {}.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name]\n    return strategy",
        "mutated": [
            "def _check_config_fleet_with_program_op(self, strategy, table_name, emb_to_size):\n    if False:\n        i = 10\n    if strategy.get(table_name) is None:\n        strategy[table_name] = {}\n    st = strategy[table_name]\n    accessor = 'DownpourCtrAccessor'\n    if st.get('sparse_accessor_class') is not None:\n        accessor = st['sparse_accessor_class']\n    if accessor == 'DownpourFeatureValueAccessor' or accessor == 'DownpourCtrAccessor' or accessor == 'DownpourCtrDymfAccessor' or (accessor == 'DownpourDoubleUnitAccessor') or (accessor == 'DownpourUnitAccessor'):\n        if st.get('sparse_embedx_dim') is not None and strategy.get('use_cvm') is True and (st['sparse_embedx_dim'] != emb_to_size[table_name] - 3):\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim - 3 = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name] - 3))\n        if st.get('sparse_embedx_dim') is not None and strategy.get('use_cvm') is False and (st['sparse_embedx_dim'] != emb_to_size[table_name] - 1):\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim - 1 = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name] - 1))\n        if st.get('sparse_embedx_dim') is None and strategy.get('use_cvm') is True:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {} - 3.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name] - 3\n        if st.get('sparse_embedx_dim') is None and strategy.get('use_cvm') is False:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {} - 1.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name] - 1\n    elif accessor == 'DownpourSparseValueAccessor':\n        if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[table_name]:\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name]))\n        if st.get('sparse_embedx_dim') is None:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {}.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name]\n    return strategy",
            "def _check_config_fleet_with_program_op(self, strategy, table_name, emb_to_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if strategy.get(table_name) is None:\n        strategy[table_name] = {}\n    st = strategy[table_name]\n    accessor = 'DownpourCtrAccessor'\n    if st.get('sparse_accessor_class') is not None:\n        accessor = st['sparse_accessor_class']\n    if accessor == 'DownpourFeatureValueAccessor' or accessor == 'DownpourCtrAccessor' or accessor == 'DownpourCtrDymfAccessor' or (accessor == 'DownpourDoubleUnitAccessor') or (accessor == 'DownpourUnitAccessor'):\n        if st.get('sparse_embedx_dim') is not None and strategy.get('use_cvm') is True and (st['sparse_embedx_dim'] != emb_to_size[table_name] - 3):\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim - 3 = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name] - 3))\n        if st.get('sparse_embedx_dim') is not None and strategy.get('use_cvm') is False and (st['sparse_embedx_dim'] != emb_to_size[table_name] - 1):\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim - 1 = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name] - 1))\n        if st.get('sparse_embedx_dim') is None and strategy.get('use_cvm') is True:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {} - 3.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name] - 3\n        if st.get('sparse_embedx_dim') is None and strategy.get('use_cvm') is False:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {} - 1.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name] - 1\n    elif accessor == 'DownpourSparseValueAccessor':\n        if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[table_name]:\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name]))\n        if st.get('sparse_embedx_dim') is None:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {}.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name]\n    return strategy",
            "def _check_config_fleet_with_program_op(self, strategy, table_name, emb_to_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if strategy.get(table_name) is None:\n        strategy[table_name] = {}\n    st = strategy[table_name]\n    accessor = 'DownpourCtrAccessor'\n    if st.get('sparse_accessor_class') is not None:\n        accessor = st['sparse_accessor_class']\n    if accessor == 'DownpourFeatureValueAccessor' or accessor == 'DownpourCtrAccessor' or accessor == 'DownpourCtrDymfAccessor' or (accessor == 'DownpourDoubleUnitAccessor') or (accessor == 'DownpourUnitAccessor'):\n        if st.get('sparse_embedx_dim') is not None and strategy.get('use_cvm') is True and (st['sparse_embedx_dim'] != emb_to_size[table_name] - 3):\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim - 3 = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name] - 3))\n        if st.get('sparse_embedx_dim') is not None and strategy.get('use_cvm') is False and (st['sparse_embedx_dim'] != emb_to_size[table_name] - 1):\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim - 1 = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name] - 1))\n        if st.get('sparse_embedx_dim') is None and strategy.get('use_cvm') is True:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {} - 3.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name] - 3\n        if st.get('sparse_embedx_dim') is None and strategy.get('use_cvm') is False:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {} - 1.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name] - 1\n    elif accessor == 'DownpourSparseValueAccessor':\n        if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[table_name]:\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name]))\n        if st.get('sparse_embedx_dim') is None:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {}.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name]\n    return strategy",
            "def _check_config_fleet_with_program_op(self, strategy, table_name, emb_to_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if strategy.get(table_name) is None:\n        strategy[table_name] = {}\n    st = strategy[table_name]\n    accessor = 'DownpourCtrAccessor'\n    if st.get('sparse_accessor_class') is not None:\n        accessor = st['sparse_accessor_class']\n    if accessor == 'DownpourFeatureValueAccessor' or accessor == 'DownpourCtrAccessor' or accessor == 'DownpourCtrDymfAccessor' or (accessor == 'DownpourDoubleUnitAccessor') or (accessor == 'DownpourUnitAccessor'):\n        if st.get('sparse_embedx_dim') is not None and strategy.get('use_cvm') is True and (st['sparse_embedx_dim'] != emb_to_size[table_name] - 3):\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim - 3 = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name] - 3))\n        if st.get('sparse_embedx_dim') is not None and strategy.get('use_cvm') is False and (st['sparse_embedx_dim'] != emb_to_size[table_name] - 1):\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim - 1 = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name] - 1))\n        if st.get('sparse_embedx_dim') is None and strategy.get('use_cvm') is True:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {} - 3.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name] - 3\n        if st.get('sparse_embedx_dim') is None and strategy.get('use_cvm') is False:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {} - 1.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name] - 1\n    elif accessor == 'DownpourSparseValueAccessor':\n        if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[table_name]:\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name]))\n        if st.get('sparse_embedx_dim') is None:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {}.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name]\n    return strategy",
            "def _check_config_fleet_with_program_op(self, strategy, table_name, emb_to_size):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if strategy.get(table_name) is None:\n        strategy[table_name] = {}\n    st = strategy[table_name]\n    accessor = 'DownpourCtrAccessor'\n    if st.get('sparse_accessor_class') is not None:\n        accessor = st['sparse_accessor_class']\n    if accessor == 'DownpourFeatureValueAccessor' or accessor == 'DownpourCtrAccessor' or accessor == 'DownpourCtrDymfAccessor' or (accessor == 'DownpourDoubleUnitAccessor') or (accessor == 'DownpourUnitAccessor'):\n        if st.get('sparse_embedx_dim') is not None and strategy.get('use_cvm') is True and (st['sparse_embedx_dim'] != emb_to_size[table_name] - 3):\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim - 3 = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name] - 3))\n        if st.get('sparse_embedx_dim') is not None and strategy.get('use_cvm') is False and (st['sparse_embedx_dim'] != emb_to_size[table_name] - 1):\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim - 1 = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name] - 1))\n        if st.get('sparse_embedx_dim') is None and strategy.get('use_cvm') is True:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {} - 3.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name] - 3\n        if st.get('sparse_embedx_dim') is None and strategy.get('use_cvm') is False:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {} - 1.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name] - 1\n    elif accessor == 'DownpourSparseValueAccessor':\n        if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[table_name]:\n            raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding dim = {}'.format(st['sparse_embedx_dim'], emb_to_size[table_name]))\n        if st.get('sparse_embedx_dim') is None:\n            logger.warning(\"sparse embedding dim for table name '{}' is: {}, while sparse_embedx_dim with same sparse table name is not set in config_fleet.py. Hence automatically set sparse_embedx_dim = {}.\".format(table_name, emb_to_size[table_name], emb_to_size[table_name]))\n            st['sparse_embedx_dim'] = emb_to_size[table_name]\n    return strategy"
        ]
    },
    {
        "func_name": "_minimize",
        "original": "def _minimize(self, losses, startup_program=None, parameter_list=None, no_grad_set=None, strategy={}):\n    \"\"\"\n        DownpounSGD is a distributed optimizer so\n        that user can call minimize to generate backward\n        operators and optimization operators within minimize function\n        Args:\n            loss(Variable): loss variable defined by user\n            startup_program(Program): startup program that defined by user\n            parameter_list(str list): parameter names defined by users\n            no_grad_set(set): a set of variables that is defined by users\n            so that these variables do not need gradient computation\n            strategy(dict): user-defined properties\n        Returns:\n            [optimize_ops, grads_and_weights]\n        \"\"\"\n    prog_id_to_sparse_table = OrderedDict()\n    prog_id_to_inputs_dict = OrderedDict()\n    prog_id_to_outputs_dict = OrderedDict()\n    ps_param = pslib.PSParameter()\n    server = DownpourServer()\n    prog_id_to_worker = OrderedDict()\n    prog_id_to_param_grads = OrderedDict()\n    prog_id_to_sparse_grads = OrderedDict()\n    program_id_set = set()\n    sparse_table_to_index = OrderedDict()\n    sparse_table_index = 0\n    for num in range(len(losses)):\n        loss = losses[num]\n        parameters = None\n        if parameter_list is not None:\n            parameters = parameter_list[num]\n        prog_id = str(id(loss.block.program))\n        params_grads = sorted(paddle.static.append_backward(loss, parameters, no_grad_set), key=lambda x: x[0].name)\n        flag_use_ps_gpu = strategy.get('use_ps_gpu', False)\n        if flag_use_ps_gpu:\n            if not isinstance(startup_program, list):\n                startup_program = [startup_program]\n            optimizer = copy.deepcopy(self._optimizer)\n            optimize_ops = optimizer.apply_optimize(loss, startup_program=startup_program[num], params_grads=params_grads)\n            embedding_table = self._find_multi_distributed_lookup_table([loss])\n            self._remove_optimize_op_for_embedding(loss, embedding_table)\n        flag_multi_task = self._has_conditional_block(loss)\n        if flag_multi_task:\n            self._cond_params = {}\n            self._other_params = []\n            now_program = loss.block.program\n            root_block = now_program.block(0)\n            all_params = []\n            for par in root_block.all_parameters():\n                all_params.append(par.name)\n            ops_ = root_block.ops\n            fill_value_dict = {}\n            equal_fill_dict = {}\n            for op in ops_:\n                if op.type == 'fill_constant':\n                    fill_value_dict[op.output('Out')[0]] = op.attr('value')\n                if op.type == 'equal':\n                    equal_fill_dict[op.output('Out')[0]] = op.input('Y')[0]\n                if op.type == 'conditional_block':\n                    self._generte_cond_para_map(op, fill_value_dict, equal_fill_dict, now_program, all_params)\n        if prog_id not in program_id_set:\n            program_id_set.add(prog_id)\n            sparse_table = self._find_multi_distributed_lookup_table([loss])\n            prog_id_to_sparse_table[prog_id] = sparse_table\n            for tn in sparse_table:\n                if sparse_table_to_index.get(tn) is None:\n                    sparse_table_to_index[tn] = sparse_table_index\n                    sparse_table_index += 1\n            emb_to_size = self._gen_distributed_emb_to_size_dict(loss.block.program)\n            inputs_dict = self._find_distributed_lookup_table_inputs(loss.block.program, sparse_table)\n            prog_id_to_inputs_dict[prog_id] = inputs_dict\n            outputs_dict = self._find_distributed_lookup_table_outputs(loss.block.program, sparse_table)\n            prog_id_to_outputs_dict[prog_id] = outputs_dict\n            prog_id_to_worker[prog_id] = DownpourWorker(self._window)\n            grads_dict = self._find_distributed_lookup_table_grads(loss.block.program, sparse_table)\n            prog_id_to_sparse_grads[prog_id] = grads_dict\n        if prog_id not in prog_id_to_param_grads:\n            prog_id_to_param_grads[prog_id] = []\n        prog_id_to_param_grads[prog_id].append(params_grads)\n    if strategy.get('fleet_desc_file') is not None:\n        fleet_desc_file = strategy['fleet_desc_file']\n        with open(fleet_desc_file) as f:\n            text_format.Merge(f.read(), ps_param)\n        server.get_desc().CopyFrom(ps_param.server_param)\n        if len(ps_param.trainer_param) == 1:\n            for k in prog_id_to_worker:\n                prog_id_to_worker[k].get_desc().CopyFrom(ps_param.trainer_param[0])\n        else:\n            if len(ps_param.trainer_param) != len(prog_id_to_worker):\n                raise ValueError(f'trainer param size != program size, {len(ps_param.trainer_param)} vs {len(prog_id_to_worker)}')\n            idx = 0\n            for k in prog_id_to_worker:\n                prog_id_to_worker[k].get_desc().CopyFrom(ps_param.trainer_param[idx])\n                idx += 1\n    if FLEET_GLOBAL_DICT['enable']:\n        one_slot = None\n        strategy['device_worker'] = 'Hogwild'\n        emb_to_table = FLEET_GLOBAL_DICT['emb_to_table']\n        emb_to_accessor = FLEET_GLOBAL_DICT['emb_to_accessor']\n        emb_to_size = FLEET_GLOBAL_DICT['emb_to_size']\n        if len(sparse_table_to_index) != len(emb_to_table):\n            raise ValueError('sparse tables from  program != sparse tables from op: {} vs {}'.format(len(sparse_table_to_index), len(emb_to_table)))\n        for key in sparse_table_to_index:\n            if key not in emb_to_table or sparse_table_to_index[key] != emb_to_table[key]:\n                print('sparse_table_to_index ', sparse_table_to_index)\n                print('emb_to_table ', emb_to_table)\n                raise ValueError('key error: %s' % key)\n            if strategy.get(key) is None:\n                strategy[key] = {}\n            st = strategy[key]\n            accessor = None\n            if st.get('sparse_accessor_class') is not None:\n                accessor = st['sparse_accessor_class']\n            tables = server.get_desc().downpour_server_param.downpour_table_param\n            for table in tables:\n                if table.table_id == sparse_table_to_index[key]:\n                    accessor = table.accessor.accessor_class\n                    break\n            for loss in losses:\n                for op in loss.block.program.global_block().ops:\n                    if op.type in self.supported_embedding_types:\n                        if accessor is not None and op.has_attr('AccessorClass'):\n                            op._set_attr('AccessorClass', accessor)\n                        if one_slot is None:\n                            one_slot = loss.block.program.global_block().var(op.input('Ids')[0])\n            if accessor is None:\n                accessor = emb_to_accessor[key]\n            if accessor == 'DownpourFeatureValueAccessor' or accessor == 'DownpourCtrDymfAccessor' or accessor == 'DownpourCtrAccessor' or (accessor == 'DownpourDoubleUnitAccessor') or (accessor == 'DownpourUnitAccessor'):\n                if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[key] - 3:\n                    raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding size - 3 = {}'.format(st['sparse_embedx_dim'], emb_to_size[key] - 3))\n                st['sparse_embedx_dim'] = emb_to_size[key] - 3\n            elif accessor == 'DownpourSparseValueAccessor':\n                if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[key]:\n                    raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding size = {}'.format(st['sparse_embedx_dim'], emb_to_size[key]))\n                st['sparse_embedx_dim'] = emb_to_size[key]\n    for tn in sparse_table_to_index:\n        sparse_table_index = sparse_table_to_index[tn]\n        st = self._check_config_fleet_with_program_op(strategy, tn, emb_to_size)\n        if st.get(tn) is not None:\n            server.add_sparse_table(sparse_table_index, st[tn])\n        else:\n            server.add_sparse_table(sparse_table_index, None)\n    program_id_set.clear()\n    for loss in losses:\n        prog_id = str(id(loss.block.program))\n        if prog_id not in program_id_set:\n            program_id_set.add(prog_id)\n            worker = prog_id_to_worker[prog_id]\n            inputs_dict = prog_id_to_inputs_dict[prog_id]\n            outputs_dict = prog_id_to_outputs_dict[prog_id]\n            for tn in prog_id_to_sparse_table[prog_id]:\n                sparse_table_index = sparse_table_to_index[tn]\n                grads_dict = prog_id_to_sparse_grads[prog_id]\n                worker.add_sparse_table(sparse_table_index, inputs_dict[tn], outputs_dict[tn], grads_dict[tn])\n    dense_start_table_id = len(sparse_table_to_index)\n    dense_table_index = len(sparse_table_to_index)\n    program_configs = {}\n    program_id_set.clear()\n    for loss_index in range(len(losses)):\n        program_id = str(id(losses[loss_index].block.program))\n        if program_id not in program_id_set:\n            program_id_set.add(program_id)\n            worker = prog_id_to_worker[program_id]\n            sparse_table_names = prog_id_to_sparse_table[program_id]\n            sparse_table_index = [sparse_table_to_index[i] for i in sparse_table_names]\n            program_configs[program_id] = {'pull_sparse': list(sparse_table_index), 'push_sparse': list(sparse_table_index)}\n            params_grads = prog_id_to_param_grads[program_id]\n            for pg in params_grads:\n                params = []\n                grads = []\n                data_norm_params = []\n                data_norm_grads = []\n                for i in pg:\n                    is_data_norm_data = False\n                    for data_norm_name in self.data_norm_name:\n                        if i[0].name.endswith(data_norm_name):\n                            is_data_norm_data = True\n                            data_norm_params.append(i[0])\n                    if not is_data_norm_data:\n                        params.append(i[0])\n                for i in pg:\n                    is_data_norm_data = False\n                    for data_norm_grad in self.data_norm_name:\n                        if i[0].name.endswith(data_norm_grad):\n                            is_data_norm_data = True\n                            data_norm_grads.append(i[1])\n                    if not is_data_norm_data:\n                        grads.append(i[1])\n                multi_task_dense_tables_push = []\n                multi_task_dense_tables_pull = []\n                if flag_multi_task:\n                    (dense_tables, cond2denseid, lists_params, lists_grads, root_params_list, root_grads_list) = self._generate_multi_dense_table(params, grads, self._cond_params, self._other_params, sparse_table_names, dense_table_index)\n                    program_configs[program_id]['cond2denseid'] = cond2denseid\n                    multi_task_dense_tables_push = dense_tables\n                    multi_task_dense_tables_pull = dense_tables[:]\n                if strategy.get('dense_table') is not None:\n                    if flag_multi_task:\n                        server_dense_table_index = dense_table_index\n                        if len(root_params_list) > 0:\n                            server.add_dense_table(server_dense_table_index, root_params_list, root_grads_list, strategy['dense_table'], sparse_table_names)\n                            server_dense_table_index += 1\n                        for i in range(len(lists_params)):\n                            server.add_dense_table(server_dense_table_index, lists_params[i], lists_grads[i], strategy['dense_table'], sparse_table_names)\n                            server_dense_table_index += 1\n                    else:\n                        server.add_dense_table(dense_table_index, params, grads, strategy['dense_table'], sparse_table_names)\n                else:\n                    server.add_dense_table(dense_table_index, params, grads, None, sparse_table_names)\n                if flag_multi_task:\n                    if len(root_params_list) > 0:\n                        worker.add_dense_table(dense_table_index, self._learning_rate, root_params_list, root_grads_list, dense_start_table_id, sparse_table_names)\n                        dense_table_index += 1\n                    for i in range(len(lists_params)):\n                        worker.add_dense_table(dense_table_index, self._learning_rate, lists_params[i], lists_grads[i], dense_start_table_id, sparse_table_names)\n                        dense_table_index += 1\n                    dense_table_index -= 1\n                else:\n                    worker.add_dense_table(dense_table_index, self._learning_rate, params, grads, dense_start_table_id, sparse_table_names)\n                if FLEET_GLOBAL_DICT['enable']:\n                    cur_prog = losses[loss_index].block.program\n                    cur_prog.global_block().append_op(type='push_dense', inputs={'Ids': one_slot}, attrs={'InputNames': [i.name for i in grads], 'TableId': dense_table_index, 'ScaleDataNorm': strategy.get('scale_datanorm', -1)})\n                if 'pull_dense' in program_configs[program_id] and 'push_dense' in program_configs[program_id] and (len(program_configs[program_id]['pull_dense']) > 0):\n                    if flag_multi_task:\n                        program_configs[program_id]['pull_dense'].extend(multi_task_dense_tables_pull)\n                        program_configs[program_id]['push_dense'].extend(multi_task_dense_tables_push)\n                    else:\n                        program_configs[program_id]['pull_dense'].extend([dense_table_index])\n                        program_configs[program_id]['push_dense'].extend([dense_table_index])\n                elif flag_multi_task:\n                    program_configs[program_id]['pull_dense'] = multi_task_dense_tables_pull\n                    program_configs[program_id]['push_dense'] = multi_task_dense_tables_push\n                else:\n                    program_configs[program_id]['pull_dense'] = [dense_table_index]\n                    program_configs[program_id]['push_dense'] = [dense_table_index]\n                if len(data_norm_params) != 0 and len(data_norm_grads) != 0:\n                    dense_table_index += 1\n                    if strategy.get('datanorm_table') is not None:\n                        server.add_data_norm_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, strategy['datanorm_table'], sparse_table_names)\n                    else:\n                        server.add_data_norm_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, None, sparse_table_names)\n                    worker.add_dense_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, dense_start_table_id, sparse_table_names)\n                    if FLEET_GLOBAL_DICT['enable']:\n                        cur_prog = losses[loss_index].block.program\n                        cur_prog.global_block().append_op(type='push_dense', inputs={'Ids': one_slot}, attrs={'InputNames': [i.name for i in data_norm_grads], 'TableId': dense_table_index, 'ScaleDataNorm': strategy.get('scale_datanorm', -1)})\n                    program_configs[program_id]['pull_dense'].extend([dense_table_index])\n                    program_configs[program_id]['push_dense'].extend([dense_table_index])\n                dense_table_index += 1\n        worker_skipped_ops = ['lookup_table', 'lookup_table_grad']\n        if len(worker.get_desc().skip_op) == 0:\n            worker.get_desc().skip_op.extend(worker_skipped_ops)\n    ps_param.server_param.CopyFrom(server.get_desc())\n    if len(ps_param.trainer_param) == 0:\n        for k in prog_id_to_worker:\n            tp = ps_param.trainer_param.add()\n            tp.CopyFrom(prog_id_to_worker[k].get_desc())\n    if strategy.get('fs_uri') is not None:\n        ps_param.fs_client_param.uri = strategy['fs_uri']\n    elif ps_param.fs_client_param.uri == '':\n        ps_param.fs_client_param.uri = 'hdfs://your_hdfs_uri'\n    if strategy.get('fs_user') is not None:\n        ps_param.fs_client_param.user = strategy['fs_user']\n    elif ps_param.fs_client_param.user == '':\n        ps_param.fs_client_param.user = 'your_hdfs_user'\n    if strategy.get('fs_passwd') is not None:\n        ps_param.fs_client_param.passwd = strategy['fs_passwd']\n    elif ps_param.fs_client_param.passwd == '':\n        ps_param.fs_client_param.passwd = 'your_hdfs_passwd'\n    if strategy.get('fs_hadoop_bin') is not None:\n        ps_param.fs_client_param.hadoop_bin = strategy['fs_hadoop_bin']\n    elif ps_param.fs_client_param.hadoop_bin == '':\n        ps_param.fs_client_param.hadoop_bin = '$HADOOP_HOME/bin/hadoop'\n    opt_info = {}\n    opt_info['program_id_to_worker'] = prog_id_to_worker\n    opt_info['program_configs'] = program_configs\n    opt_info['trainer'] = strategy.get('trainer', 'DistMultiTrainer')\n    opt_info['device_worker'] = strategy.get('device_worker', 'DownpourSGD')\n    opt_info['optimizer'] = 'DownpourSGD'\n    opt_info['fleet_desc'] = ps_param\n    opt_info['worker_skipped_ops'] = worker_skipped_ops\n    opt_info['use_cvm'] = strategy.get('use_cvm', False)\n    opt_info['no_cvm'] = strategy.get('no_cvm', False)\n    opt_info['scale_sparse_gradient_with_batch_size'] = strategy.get('scale_sparse_gradient_with_batch_size', True)\n    opt_info['worker_class'] = strategy.get('worker_class', 'DownpourWorker')\n    opt_info['stat_var_names'] = strategy.get('stat_var_names', [])\n    opt_info['local_tables'] = strategy.get('local_tables', [])\n    opt_info['async_tables'] = strategy.get('async_tables', [])\n    opt_info['async_tables'] = strategy.get('async_tables', [])\n    opt_info['scale_datanorm'] = strategy.get('scale_datanorm', -1)\n    opt_info['check_nan_var_names'] = strategy.get('check_nan_var_names', [])\n    opt_info['dump_slot'] = False\n    opt_info['dump_converter'] = ''\n    opt_info['dump_fields'] = strategy.get('dump_fields', [])\n    opt_info['dump_file_num'] = strategy.get('dump_file_num', 16)\n    opt_info['user_define_dump_filename'] = strategy.get('user_define_dump_filename', '')\n    opt_info['dump_fields_path'] = strategy.get('dump_fields_path', '')\n    opt_info['dump_param'] = strategy.get('dump_param', [])\n    gpus_env = os.getenv('FLAGS_selected_gpus', '0')\n    opt_info['worker_places'] = [int(s) for s in gpus_env.split(',')]\n    opt_info['use_ps_gpu'] = strategy.get('use_ps_gpu', False)\n    if server._server.downpour_server_param.downpour_table_param[0].accessor.accessor_class in ['DownpourCtrAccessor', 'DownpourCtrDoubleAccessor', 'DownpourUnitAccessor', 'DownpourDoubleUnitAccessor', 'DownpourCtrDymfAccessor']:\n        opt_info['dump_slot'] = True\n    elif server._server.downpour_server_param.downpour_table_param[0].accessor.accessor_class == 'DownpourSparseValueAccessor':\n        opt_info['no_cvm'] = True\n    opt_info['adjust_ins_weight'] = strategy.get('adjust_ins_weight', {})\n    opt_info['copy_table'] = strategy.get('copy_table', {})\n    opt_info['loss_names'] = strategy.get('loss_names', [])\n    for loss in losses:\n        loss.block.program._fleet_opt = opt_info\n    param_grads_list = []\n    for loss in losses:\n        prog_id = str(id(loss.block.program))\n        param_grads_list.append(prog_id_to_param_grads[prog_id])\n    return (None, param_grads_list, opt_info)",
        "mutated": [
            "def _minimize(self, losses, startup_program=None, parameter_list=None, no_grad_set=None, strategy={}):\n    if False:\n        i = 10\n    '\\n        DownpounSGD is a distributed optimizer so\\n        that user can call minimize to generate backward\\n        operators and optimization operators within minimize function\\n        Args:\\n            loss(Variable): loss variable defined by user\\n            startup_program(Program): startup program that defined by user\\n            parameter_list(str list): parameter names defined by users\\n            no_grad_set(set): a set of variables that is defined by users\\n            so that these variables do not need gradient computation\\n            strategy(dict): user-defined properties\\n        Returns:\\n            [optimize_ops, grads_and_weights]\\n        '\n    prog_id_to_sparse_table = OrderedDict()\n    prog_id_to_inputs_dict = OrderedDict()\n    prog_id_to_outputs_dict = OrderedDict()\n    ps_param = pslib.PSParameter()\n    server = DownpourServer()\n    prog_id_to_worker = OrderedDict()\n    prog_id_to_param_grads = OrderedDict()\n    prog_id_to_sparse_grads = OrderedDict()\n    program_id_set = set()\n    sparse_table_to_index = OrderedDict()\n    sparse_table_index = 0\n    for num in range(len(losses)):\n        loss = losses[num]\n        parameters = None\n        if parameter_list is not None:\n            parameters = parameter_list[num]\n        prog_id = str(id(loss.block.program))\n        params_grads = sorted(paddle.static.append_backward(loss, parameters, no_grad_set), key=lambda x: x[0].name)\n        flag_use_ps_gpu = strategy.get('use_ps_gpu', False)\n        if flag_use_ps_gpu:\n            if not isinstance(startup_program, list):\n                startup_program = [startup_program]\n            optimizer = copy.deepcopy(self._optimizer)\n            optimize_ops = optimizer.apply_optimize(loss, startup_program=startup_program[num], params_grads=params_grads)\n            embedding_table = self._find_multi_distributed_lookup_table([loss])\n            self._remove_optimize_op_for_embedding(loss, embedding_table)\n        flag_multi_task = self._has_conditional_block(loss)\n        if flag_multi_task:\n            self._cond_params = {}\n            self._other_params = []\n            now_program = loss.block.program\n            root_block = now_program.block(0)\n            all_params = []\n            for par in root_block.all_parameters():\n                all_params.append(par.name)\n            ops_ = root_block.ops\n            fill_value_dict = {}\n            equal_fill_dict = {}\n            for op in ops_:\n                if op.type == 'fill_constant':\n                    fill_value_dict[op.output('Out')[0]] = op.attr('value')\n                if op.type == 'equal':\n                    equal_fill_dict[op.output('Out')[0]] = op.input('Y')[0]\n                if op.type == 'conditional_block':\n                    self._generte_cond_para_map(op, fill_value_dict, equal_fill_dict, now_program, all_params)\n        if prog_id not in program_id_set:\n            program_id_set.add(prog_id)\n            sparse_table = self._find_multi_distributed_lookup_table([loss])\n            prog_id_to_sparse_table[prog_id] = sparse_table\n            for tn in sparse_table:\n                if sparse_table_to_index.get(tn) is None:\n                    sparse_table_to_index[tn] = sparse_table_index\n                    sparse_table_index += 1\n            emb_to_size = self._gen_distributed_emb_to_size_dict(loss.block.program)\n            inputs_dict = self._find_distributed_lookup_table_inputs(loss.block.program, sparse_table)\n            prog_id_to_inputs_dict[prog_id] = inputs_dict\n            outputs_dict = self._find_distributed_lookup_table_outputs(loss.block.program, sparse_table)\n            prog_id_to_outputs_dict[prog_id] = outputs_dict\n            prog_id_to_worker[prog_id] = DownpourWorker(self._window)\n            grads_dict = self._find_distributed_lookup_table_grads(loss.block.program, sparse_table)\n            prog_id_to_sparse_grads[prog_id] = grads_dict\n        if prog_id not in prog_id_to_param_grads:\n            prog_id_to_param_grads[prog_id] = []\n        prog_id_to_param_grads[prog_id].append(params_grads)\n    if strategy.get('fleet_desc_file') is not None:\n        fleet_desc_file = strategy['fleet_desc_file']\n        with open(fleet_desc_file) as f:\n            text_format.Merge(f.read(), ps_param)\n        server.get_desc().CopyFrom(ps_param.server_param)\n        if len(ps_param.trainer_param) == 1:\n            for k in prog_id_to_worker:\n                prog_id_to_worker[k].get_desc().CopyFrom(ps_param.trainer_param[0])\n        else:\n            if len(ps_param.trainer_param) != len(prog_id_to_worker):\n                raise ValueError(f'trainer param size != program size, {len(ps_param.trainer_param)} vs {len(prog_id_to_worker)}')\n            idx = 0\n            for k in prog_id_to_worker:\n                prog_id_to_worker[k].get_desc().CopyFrom(ps_param.trainer_param[idx])\n                idx += 1\n    if FLEET_GLOBAL_DICT['enable']:\n        one_slot = None\n        strategy['device_worker'] = 'Hogwild'\n        emb_to_table = FLEET_GLOBAL_DICT['emb_to_table']\n        emb_to_accessor = FLEET_GLOBAL_DICT['emb_to_accessor']\n        emb_to_size = FLEET_GLOBAL_DICT['emb_to_size']\n        if len(sparse_table_to_index) != len(emb_to_table):\n            raise ValueError('sparse tables from  program != sparse tables from op: {} vs {}'.format(len(sparse_table_to_index), len(emb_to_table)))\n        for key in sparse_table_to_index:\n            if key not in emb_to_table or sparse_table_to_index[key] != emb_to_table[key]:\n                print('sparse_table_to_index ', sparse_table_to_index)\n                print('emb_to_table ', emb_to_table)\n                raise ValueError('key error: %s' % key)\n            if strategy.get(key) is None:\n                strategy[key] = {}\n            st = strategy[key]\n            accessor = None\n            if st.get('sparse_accessor_class') is not None:\n                accessor = st['sparse_accessor_class']\n            tables = server.get_desc().downpour_server_param.downpour_table_param\n            for table in tables:\n                if table.table_id == sparse_table_to_index[key]:\n                    accessor = table.accessor.accessor_class\n                    break\n            for loss in losses:\n                for op in loss.block.program.global_block().ops:\n                    if op.type in self.supported_embedding_types:\n                        if accessor is not None and op.has_attr('AccessorClass'):\n                            op._set_attr('AccessorClass', accessor)\n                        if one_slot is None:\n                            one_slot = loss.block.program.global_block().var(op.input('Ids')[0])\n            if accessor is None:\n                accessor = emb_to_accessor[key]\n            if accessor == 'DownpourFeatureValueAccessor' or accessor == 'DownpourCtrDymfAccessor' or accessor == 'DownpourCtrAccessor' or (accessor == 'DownpourDoubleUnitAccessor') or (accessor == 'DownpourUnitAccessor'):\n                if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[key] - 3:\n                    raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding size - 3 = {}'.format(st['sparse_embedx_dim'], emb_to_size[key] - 3))\n                st['sparse_embedx_dim'] = emb_to_size[key] - 3\n            elif accessor == 'DownpourSparseValueAccessor':\n                if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[key]:\n                    raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding size = {}'.format(st['sparse_embedx_dim'], emb_to_size[key]))\n                st['sparse_embedx_dim'] = emb_to_size[key]\n    for tn in sparse_table_to_index:\n        sparse_table_index = sparse_table_to_index[tn]\n        st = self._check_config_fleet_with_program_op(strategy, tn, emb_to_size)\n        if st.get(tn) is not None:\n            server.add_sparse_table(sparse_table_index, st[tn])\n        else:\n            server.add_sparse_table(sparse_table_index, None)\n    program_id_set.clear()\n    for loss in losses:\n        prog_id = str(id(loss.block.program))\n        if prog_id not in program_id_set:\n            program_id_set.add(prog_id)\n            worker = prog_id_to_worker[prog_id]\n            inputs_dict = prog_id_to_inputs_dict[prog_id]\n            outputs_dict = prog_id_to_outputs_dict[prog_id]\n            for tn in prog_id_to_sparse_table[prog_id]:\n                sparse_table_index = sparse_table_to_index[tn]\n                grads_dict = prog_id_to_sparse_grads[prog_id]\n                worker.add_sparse_table(sparse_table_index, inputs_dict[tn], outputs_dict[tn], grads_dict[tn])\n    dense_start_table_id = len(sparse_table_to_index)\n    dense_table_index = len(sparse_table_to_index)\n    program_configs = {}\n    program_id_set.clear()\n    for loss_index in range(len(losses)):\n        program_id = str(id(losses[loss_index].block.program))\n        if program_id not in program_id_set:\n            program_id_set.add(program_id)\n            worker = prog_id_to_worker[program_id]\n            sparse_table_names = prog_id_to_sparse_table[program_id]\n            sparse_table_index = [sparse_table_to_index[i] for i in sparse_table_names]\n            program_configs[program_id] = {'pull_sparse': list(sparse_table_index), 'push_sparse': list(sparse_table_index)}\n            params_grads = prog_id_to_param_grads[program_id]\n            for pg in params_grads:\n                params = []\n                grads = []\n                data_norm_params = []\n                data_norm_grads = []\n                for i in pg:\n                    is_data_norm_data = False\n                    for data_norm_name in self.data_norm_name:\n                        if i[0].name.endswith(data_norm_name):\n                            is_data_norm_data = True\n                            data_norm_params.append(i[0])\n                    if not is_data_norm_data:\n                        params.append(i[0])\n                for i in pg:\n                    is_data_norm_data = False\n                    for data_norm_grad in self.data_norm_name:\n                        if i[0].name.endswith(data_norm_grad):\n                            is_data_norm_data = True\n                            data_norm_grads.append(i[1])\n                    if not is_data_norm_data:\n                        grads.append(i[1])\n                multi_task_dense_tables_push = []\n                multi_task_dense_tables_pull = []\n                if flag_multi_task:\n                    (dense_tables, cond2denseid, lists_params, lists_grads, root_params_list, root_grads_list) = self._generate_multi_dense_table(params, grads, self._cond_params, self._other_params, sparse_table_names, dense_table_index)\n                    program_configs[program_id]['cond2denseid'] = cond2denseid\n                    multi_task_dense_tables_push = dense_tables\n                    multi_task_dense_tables_pull = dense_tables[:]\n                if strategy.get('dense_table') is not None:\n                    if flag_multi_task:\n                        server_dense_table_index = dense_table_index\n                        if len(root_params_list) > 0:\n                            server.add_dense_table(server_dense_table_index, root_params_list, root_grads_list, strategy['dense_table'], sparse_table_names)\n                            server_dense_table_index += 1\n                        for i in range(len(lists_params)):\n                            server.add_dense_table(server_dense_table_index, lists_params[i], lists_grads[i], strategy['dense_table'], sparse_table_names)\n                            server_dense_table_index += 1\n                    else:\n                        server.add_dense_table(dense_table_index, params, grads, strategy['dense_table'], sparse_table_names)\n                else:\n                    server.add_dense_table(dense_table_index, params, grads, None, sparse_table_names)\n                if flag_multi_task:\n                    if len(root_params_list) > 0:\n                        worker.add_dense_table(dense_table_index, self._learning_rate, root_params_list, root_grads_list, dense_start_table_id, sparse_table_names)\n                        dense_table_index += 1\n                    for i in range(len(lists_params)):\n                        worker.add_dense_table(dense_table_index, self._learning_rate, lists_params[i], lists_grads[i], dense_start_table_id, sparse_table_names)\n                        dense_table_index += 1\n                    dense_table_index -= 1\n                else:\n                    worker.add_dense_table(dense_table_index, self._learning_rate, params, grads, dense_start_table_id, sparse_table_names)\n                if FLEET_GLOBAL_DICT['enable']:\n                    cur_prog = losses[loss_index].block.program\n                    cur_prog.global_block().append_op(type='push_dense', inputs={'Ids': one_slot}, attrs={'InputNames': [i.name for i in grads], 'TableId': dense_table_index, 'ScaleDataNorm': strategy.get('scale_datanorm', -1)})\n                if 'pull_dense' in program_configs[program_id] and 'push_dense' in program_configs[program_id] and (len(program_configs[program_id]['pull_dense']) > 0):\n                    if flag_multi_task:\n                        program_configs[program_id]['pull_dense'].extend(multi_task_dense_tables_pull)\n                        program_configs[program_id]['push_dense'].extend(multi_task_dense_tables_push)\n                    else:\n                        program_configs[program_id]['pull_dense'].extend([dense_table_index])\n                        program_configs[program_id]['push_dense'].extend([dense_table_index])\n                elif flag_multi_task:\n                    program_configs[program_id]['pull_dense'] = multi_task_dense_tables_pull\n                    program_configs[program_id]['push_dense'] = multi_task_dense_tables_push\n                else:\n                    program_configs[program_id]['pull_dense'] = [dense_table_index]\n                    program_configs[program_id]['push_dense'] = [dense_table_index]\n                if len(data_norm_params) != 0 and len(data_norm_grads) != 0:\n                    dense_table_index += 1\n                    if strategy.get('datanorm_table') is not None:\n                        server.add_data_norm_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, strategy['datanorm_table'], sparse_table_names)\n                    else:\n                        server.add_data_norm_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, None, sparse_table_names)\n                    worker.add_dense_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, dense_start_table_id, sparse_table_names)\n                    if FLEET_GLOBAL_DICT['enable']:\n                        cur_prog = losses[loss_index].block.program\n                        cur_prog.global_block().append_op(type='push_dense', inputs={'Ids': one_slot}, attrs={'InputNames': [i.name for i in data_norm_grads], 'TableId': dense_table_index, 'ScaleDataNorm': strategy.get('scale_datanorm', -1)})\n                    program_configs[program_id]['pull_dense'].extend([dense_table_index])\n                    program_configs[program_id]['push_dense'].extend([dense_table_index])\n                dense_table_index += 1\n        worker_skipped_ops = ['lookup_table', 'lookup_table_grad']\n        if len(worker.get_desc().skip_op) == 0:\n            worker.get_desc().skip_op.extend(worker_skipped_ops)\n    ps_param.server_param.CopyFrom(server.get_desc())\n    if len(ps_param.trainer_param) == 0:\n        for k in prog_id_to_worker:\n            tp = ps_param.trainer_param.add()\n            tp.CopyFrom(prog_id_to_worker[k].get_desc())\n    if strategy.get('fs_uri') is not None:\n        ps_param.fs_client_param.uri = strategy['fs_uri']\n    elif ps_param.fs_client_param.uri == '':\n        ps_param.fs_client_param.uri = 'hdfs://your_hdfs_uri'\n    if strategy.get('fs_user') is not None:\n        ps_param.fs_client_param.user = strategy['fs_user']\n    elif ps_param.fs_client_param.user == '':\n        ps_param.fs_client_param.user = 'your_hdfs_user'\n    if strategy.get('fs_passwd') is not None:\n        ps_param.fs_client_param.passwd = strategy['fs_passwd']\n    elif ps_param.fs_client_param.passwd == '':\n        ps_param.fs_client_param.passwd = 'your_hdfs_passwd'\n    if strategy.get('fs_hadoop_bin') is not None:\n        ps_param.fs_client_param.hadoop_bin = strategy['fs_hadoop_bin']\n    elif ps_param.fs_client_param.hadoop_bin == '':\n        ps_param.fs_client_param.hadoop_bin = '$HADOOP_HOME/bin/hadoop'\n    opt_info = {}\n    opt_info['program_id_to_worker'] = prog_id_to_worker\n    opt_info['program_configs'] = program_configs\n    opt_info['trainer'] = strategy.get('trainer', 'DistMultiTrainer')\n    opt_info['device_worker'] = strategy.get('device_worker', 'DownpourSGD')\n    opt_info['optimizer'] = 'DownpourSGD'\n    opt_info['fleet_desc'] = ps_param\n    opt_info['worker_skipped_ops'] = worker_skipped_ops\n    opt_info['use_cvm'] = strategy.get('use_cvm', False)\n    opt_info['no_cvm'] = strategy.get('no_cvm', False)\n    opt_info['scale_sparse_gradient_with_batch_size'] = strategy.get('scale_sparse_gradient_with_batch_size', True)\n    opt_info['worker_class'] = strategy.get('worker_class', 'DownpourWorker')\n    opt_info['stat_var_names'] = strategy.get('stat_var_names', [])\n    opt_info['local_tables'] = strategy.get('local_tables', [])\n    opt_info['async_tables'] = strategy.get('async_tables', [])\n    opt_info['async_tables'] = strategy.get('async_tables', [])\n    opt_info['scale_datanorm'] = strategy.get('scale_datanorm', -1)\n    opt_info['check_nan_var_names'] = strategy.get('check_nan_var_names', [])\n    opt_info['dump_slot'] = False\n    opt_info['dump_converter'] = ''\n    opt_info['dump_fields'] = strategy.get('dump_fields', [])\n    opt_info['dump_file_num'] = strategy.get('dump_file_num', 16)\n    opt_info['user_define_dump_filename'] = strategy.get('user_define_dump_filename', '')\n    opt_info['dump_fields_path'] = strategy.get('dump_fields_path', '')\n    opt_info['dump_param'] = strategy.get('dump_param', [])\n    gpus_env = os.getenv('FLAGS_selected_gpus', '0')\n    opt_info['worker_places'] = [int(s) for s in gpus_env.split(',')]\n    opt_info['use_ps_gpu'] = strategy.get('use_ps_gpu', False)\n    if server._server.downpour_server_param.downpour_table_param[0].accessor.accessor_class in ['DownpourCtrAccessor', 'DownpourCtrDoubleAccessor', 'DownpourUnitAccessor', 'DownpourDoubleUnitAccessor', 'DownpourCtrDymfAccessor']:\n        opt_info['dump_slot'] = True\n    elif server._server.downpour_server_param.downpour_table_param[0].accessor.accessor_class == 'DownpourSparseValueAccessor':\n        opt_info['no_cvm'] = True\n    opt_info['adjust_ins_weight'] = strategy.get('adjust_ins_weight', {})\n    opt_info['copy_table'] = strategy.get('copy_table', {})\n    opt_info['loss_names'] = strategy.get('loss_names', [])\n    for loss in losses:\n        loss.block.program._fleet_opt = opt_info\n    param_grads_list = []\n    for loss in losses:\n        prog_id = str(id(loss.block.program))\n        param_grads_list.append(prog_id_to_param_grads[prog_id])\n    return (None, param_grads_list, opt_info)",
            "def _minimize(self, losses, startup_program=None, parameter_list=None, no_grad_set=None, strategy={}):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        DownpounSGD is a distributed optimizer so\\n        that user can call minimize to generate backward\\n        operators and optimization operators within minimize function\\n        Args:\\n            loss(Variable): loss variable defined by user\\n            startup_program(Program): startup program that defined by user\\n            parameter_list(str list): parameter names defined by users\\n            no_grad_set(set): a set of variables that is defined by users\\n            so that these variables do not need gradient computation\\n            strategy(dict): user-defined properties\\n        Returns:\\n            [optimize_ops, grads_and_weights]\\n        '\n    prog_id_to_sparse_table = OrderedDict()\n    prog_id_to_inputs_dict = OrderedDict()\n    prog_id_to_outputs_dict = OrderedDict()\n    ps_param = pslib.PSParameter()\n    server = DownpourServer()\n    prog_id_to_worker = OrderedDict()\n    prog_id_to_param_grads = OrderedDict()\n    prog_id_to_sparse_grads = OrderedDict()\n    program_id_set = set()\n    sparse_table_to_index = OrderedDict()\n    sparse_table_index = 0\n    for num in range(len(losses)):\n        loss = losses[num]\n        parameters = None\n        if parameter_list is not None:\n            parameters = parameter_list[num]\n        prog_id = str(id(loss.block.program))\n        params_grads = sorted(paddle.static.append_backward(loss, parameters, no_grad_set), key=lambda x: x[0].name)\n        flag_use_ps_gpu = strategy.get('use_ps_gpu', False)\n        if flag_use_ps_gpu:\n            if not isinstance(startup_program, list):\n                startup_program = [startup_program]\n            optimizer = copy.deepcopy(self._optimizer)\n            optimize_ops = optimizer.apply_optimize(loss, startup_program=startup_program[num], params_grads=params_grads)\n            embedding_table = self._find_multi_distributed_lookup_table([loss])\n            self._remove_optimize_op_for_embedding(loss, embedding_table)\n        flag_multi_task = self._has_conditional_block(loss)\n        if flag_multi_task:\n            self._cond_params = {}\n            self._other_params = []\n            now_program = loss.block.program\n            root_block = now_program.block(0)\n            all_params = []\n            for par in root_block.all_parameters():\n                all_params.append(par.name)\n            ops_ = root_block.ops\n            fill_value_dict = {}\n            equal_fill_dict = {}\n            for op in ops_:\n                if op.type == 'fill_constant':\n                    fill_value_dict[op.output('Out')[0]] = op.attr('value')\n                if op.type == 'equal':\n                    equal_fill_dict[op.output('Out')[0]] = op.input('Y')[0]\n                if op.type == 'conditional_block':\n                    self._generte_cond_para_map(op, fill_value_dict, equal_fill_dict, now_program, all_params)\n        if prog_id not in program_id_set:\n            program_id_set.add(prog_id)\n            sparse_table = self._find_multi_distributed_lookup_table([loss])\n            prog_id_to_sparse_table[prog_id] = sparse_table\n            for tn in sparse_table:\n                if sparse_table_to_index.get(tn) is None:\n                    sparse_table_to_index[tn] = sparse_table_index\n                    sparse_table_index += 1\n            emb_to_size = self._gen_distributed_emb_to_size_dict(loss.block.program)\n            inputs_dict = self._find_distributed_lookup_table_inputs(loss.block.program, sparse_table)\n            prog_id_to_inputs_dict[prog_id] = inputs_dict\n            outputs_dict = self._find_distributed_lookup_table_outputs(loss.block.program, sparse_table)\n            prog_id_to_outputs_dict[prog_id] = outputs_dict\n            prog_id_to_worker[prog_id] = DownpourWorker(self._window)\n            grads_dict = self._find_distributed_lookup_table_grads(loss.block.program, sparse_table)\n            prog_id_to_sparse_grads[prog_id] = grads_dict\n        if prog_id not in prog_id_to_param_grads:\n            prog_id_to_param_grads[prog_id] = []\n        prog_id_to_param_grads[prog_id].append(params_grads)\n    if strategy.get('fleet_desc_file') is not None:\n        fleet_desc_file = strategy['fleet_desc_file']\n        with open(fleet_desc_file) as f:\n            text_format.Merge(f.read(), ps_param)\n        server.get_desc().CopyFrom(ps_param.server_param)\n        if len(ps_param.trainer_param) == 1:\n            for k in prog_id_to_worker:\n                prog_id_to_worker[k].get_desc().CopyFrom(ps_param.trainer_param[0])\n        else:\n            if len(ps_param.trainer_param) != len(prog_id_to_worker):\n                raise ValueError(f'trainer param size != program size, {len(ps_param.trainer_param)} vs {len(prog_id_to_worker)}')\n            idx = 0\n            for k in prog_id_to_worker:\n                prog_id_to_worker[k].get_desc().CopyFrom(ps_param.trainer_param[idx])\n                idx += 1\n    if FLEET_GLOBAL_DICT['enable']:\n        one_slot = None\n        strategy['device_worker'] = 'Hogwild'\n        emb_to_table = FLEET_GLOBAL_DICT['emb_to_table']\n        emb_to_accessor = FLEET_GLOBAL_DICT['emb_to_accessor']\n        emb_to_size = FLEET_GLOBAL_DICT['emb_to_size']\n        if len(sparse_table_to_index) != len(emb_to_table):\n            raise ValueError('sparse tables from  program != sparse tables from op: {} vs {}'.format(len(sparse_table_to_index), len(emb_to_table)))\n        for key in sparse_table_to_index:\n            if key not in emb_to_table or sparse_table_to_index[key] != emb_to_table[key]:\n                print('sparse_table_to_index ', sparse_table_to_index)\n                print('emb_to_table ', emb_to_table)\n                raise ValueError('key error: %s' % key)\n            if strategy.get(key) is None:\n                strategy[key] = {}\n            st = strategy[key]\n            accessor = None\n            if st.get('sparse_accessor_class') is not None:\n                accessor = st['sparse_accessor_class']\n            tables = server.get_desc().downpour_server_param.downpour_table_param\n            for table in tables:\n                if table.table_id == sparse_table_to_index[key]:\n                    accessor = table.accessor.accessor_class\n                    break\n            for loss in losses:\n                for op in loss.block.program.global_block().ops:\n                    if op.type in self.supported_embedding_types:\n                        if accessor is not None and op.has_attr('AccessorClass'):\n                            op._set_attr('AccessorClass', accessor)\n                        if one_slot is None:\n                            one_slot = loss.block.program.global_block().var(op.input('Ids')[0])\n            if accessor is None:\n                accessor = emb_to_accessor[key]\n            if accessor == 'DownpourFeatureValueAccessor' or accessor == 'DownpourCtrDymfAccessor' or accessor == 'DownpourCtrAccessor' or (accessor == 'DownpourDoubleUnitAccessor') or (accessor == 'DownpourUnitAccessor'):\n                if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[key] - 3:\n                    raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding size - 3 = {}'.format(st['sparse_embedx_dim'], emb_to_size[key] - 3))\n                st['sparse_embedx_dim'] = emb_to_size[key] - 3\n            elif accessor == 'DownpourSparseValueAccessor':\n                if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[key]:\n                    raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding size = {}'.format(st['sparse_embedx_dim'], emb_to_size[key]))\n                st['sparse_embedx_dim'] = emb_to_size[key]\n    for tn in sparse_table_to_index:\n        sparse_table_index = sparse_table_to_index[tn]\n        st = self._check_config_fleet_with_program_op(strategy, tn, emb_to_size)\n        if st.get(tn) is not None:\n            server.add_sparse_table(sparse_table_index, st[tn])\n        else:\n            server.add_sparse_table(sparse_table_index, None)\n    program_id_set.clear()\n    for loss in losses:\n        prog_id = str(id(loss.block.program))\n        if prog_id not in program_id_set:\n            program_id_set.add(prog_id)\n            worker = prog_id_to_worker[prog_id]\n            inputs_dict = prog_id_to_inputs_dict[prog_id]\n            outputs_dict = prog_id_to_outputs_dict[prog_id]\n            for tn in prog_id_to_sparse_table[prog_id]:\n                sparse_table_index = sparse_table_to_index[tn]\n                grads_dict = prog_id_to_sparse_grads[prog_id]\n                worker.add_sparse_table(sparse_table_index, inputs_dict[tn], outputs_dict[tn], grads_dict[tn])\n    dense_start_table_id = len(sparse_table_to_index)\n    dense_table_index = len(sparse_table_to_index)\n    program_configs = {}\n    program_id_set.clear()\n    for loss_index in range(len(losses)):\n        program_id = str(id(losses[loss_index].block.program))\n        if program_id not in program_id_set:\n            program_id_set.add(program_id)\n            worker = prog_id_to_worker[program_id]\n            sparse_table_names = prog_id_to_sparse_table[program_id]\n            sparse_table_index = [sparse_table_to_index[i] for i in sparse_table_names]\n            program_configs[program_id] = {'pull_sparse': list(sparse_table_index), 'push_sparse': list(sparse_table_index)}\n            params_grads = prog_id_to_param_grads[program_id]\n            for pg in params_grads:\n                params = []\n                grads = []\n                data_norm_params = []\n                data_norm_grads = []\n                for i in pg:\n                    is_data_norm_data = False\n                    for data_norm_name in self.data_norm_name:\n                        if i[0].name.endswith(data_norm_name):\n                            is_data_norm_data = True\n                            data_norm_params.append(i[0])\n                    if not is_data_norm_data:\n                        params.append(i[0])\n                for i in pg:\n                    is_data_norm_data = False\n                    for data_norm_grad in self.data_norm_name:\n                        if i[0].name.endswith(data_norm_grad):\n                            is_data_norm_data = True\n                            data_norm_grads.append(i[1])\n                    if not is_data_norm_data:\n                        grads.append(i[1])\n                multi_task_dense_tables_push = []\n                multi_task_dense_tables_pull = []\n                if flag_multi_task:\n                    (dense_tables, cond2denseid, lists_params, lists_grads, root_params_list, root_grads_list) = self._generate_multi_dense_table(params, grads, self._cond_params, self._other_params, sparse_table_names, dense_table_index)\n                    program_configs[program_id]['cond2denseid'] = cond2denseid\n                    multi_task_dense_tables_push = dense_tables\n                    multi_task_dense_tables_pull = dense_tables[:]\n                if strategy.get('dense_table') is not None:\n                    if flag_multi_task:\n                        server_dense_table_index = dense_table_index\n                        if len(root_params_list) > 0:\n                            server.add_dense_table(server_dense_table_index, root_params_list, root_grads_list, strategy['dense_table'], sparse_table_names)\n                            server_dense_table_index += 1\n                        for i in range(len(lists_params)):\n                            server.add_dense_table(server_dense_table_index, lists_params[i], lists_grads[i], strategy['dense_table'], sparse_table_names)\n                            server_dense_table_index += 1\n                    else:\n                        server.add_dense_table(dense_table_index, params, grads, strategy['dense_table'], sparse_table_names)\n                else:\n                    server.add_dense_table(dense_table_index, params, grads, None, sparse_table_names)\n                if flag_multi_task:\n                    if len(root_params_list) > 0:\n                        worker.add_dense_table(dense_table_index, self._learning_rate, root_params_list, root_grads_list, dense_start_table_id, sparse_table_names)\n                        dense_table_index += 1\n                    for i in range(len(lists_params)):\n                        worker.add_dense_table(dense_table_index, self._learning_rate, lists_params[i], lists_grads[i], dense_start_table_id, sparse_table_names)\n                        dense_table_index += 1\n                    dense_table_index -= 1\n                else:\n                    worker.add_dense_table(dense_table_index, self._learning_rate, params, grads, dense_start_table_id, sparse_table_names)\n                if FLEET_GLOBAL_DICT['enable']:\n                    cur_prog = losses[loss_index].block.program\n                    cur_prog.global_block().append_op(type='push_dense', inputs={'Ids': one_slot}, attrs={'InputNames': [i.name for i in grads], 'TableId': dense_table_index, 'ScaleDataNorm': strategy.get('scale_datanorm', -1)})\n                if 'pull_dense' in program_configs[program_id] and 'push_dense' in program_configs[program_id] and (len(program_configs[program_id]['pull_dense']) > 0):\n                    if flag_multi_task:\n                        program_configs[program_id]['pull_dense'].extend(multi_task_dense_tables_pull)\n                        program_configs[program_id]['push_dense'].extend(multi_task_dense_tables_push)\n                    else:\n                        program_configs[program_id]['pull_dense'].extend([dense_table_index])\n                        program_configs[program_id]['push_dense'].extend([dense_table_index])\n                elif flag_multi_task:\n                    program_configs[program_id]['pull_dense'] = multi_task_dense_tables_pull\n                    program_configs[program_id]['push_dense'] = multi_task_dense_tables_push\n                else:\n                    program_configs[program_id]['pull_dense'] = [dense_table_index]\n                    program_configs[program_id]['push_dense'] = [dense_table_index]\n                if len(data_norm_params) != 0 and len(data_norm_grads) != 0:\n                    dense_table_index += 1\n                    if strategy.get('datanorm_table') is not None:\n                        server.add_data_norm_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, strategy['datanorm_table'], sparse_table_names)\n                    else:\n                        server.add_data_norm_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, None, sparse_table_names)\n                    worker.add_dense_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, dense_start_table_id, sparse_table_names)\n                    if FLEET_GLOBAL_DICT['enable']:\n                        cur_prog = losses[loss_index].block.program\n                        cur_prog.global_block().append_op(type='push_dense', inputs={'Ids': one_slot}, attrs={'InputNames': [i.name for i in data_norm_grads], 'TableId': dense_table_index, 'ScaleDataNorm': strategy.get('scale_datanorm', -1)})\n                    program_configs[program_id]['pull_dense'].extend([dense_table_index])\n                    program_configs[program_id]['push_dense'].extend([dense_table_index])\n                dense_table_index += 1\n        worker_skipped_ops = ['lookup_table', 'lookup_table_grad']\n        if len(worker.get_desc().skip_op) == 0:\n            worker.get_desc().skip_op.extend(worker_skipped_ops)\n    ps_param.server_param.CopyFrom(server.get_desc())\n    if len(ps_param.trainer_param) == 0:\n        for k in prog_id_to_worker:\n            tp = ps_param.trainer_param.add()\n            tp.CopyFrom(prog_id_to_worker[k].get_desc())\n    if strategy.get('fs_uri') is not None:\n        ps_param.fs_client_param.uri = strategy['fs_uri']\n    elif ps_param.fs_client_param.uri == '':\n        ps_param.fs_client_param.uri = 'hdfs://your_hdfs_uri'\n    if strategy.get('fs_user') is not None:\n        ps_param.fs_client_param.user = strategy['fs_user']\n    elif ps_param.fs_client_param.user == '':\n        ps_param.fs_client_param.user = 'your_hdfs_user'\n    if strategy.get('fs_passwd') is not None:\n        ps_param.fs_client_param.passwd = strategy['fs_passwd']\n    elif ps_param.fs_client_param.passwd == '':\n        ps_param.fs_client_param.passwd = 'your_hdfs_passwd'\n    if strategy.get('fs_hadoop_bin') is not None:\n        ps_param.fs_client_param.hadoop_bin = strategy['fs_hadoop_bin']\n    elif ps_param.fs_client_param.hadoop_bin == '':\n        ps_param.fs_client_param.hadoop_bin = '$HADOOP_HOME/bin/hadoop'\n    opt_info = {}\n    opt_info['program_id_to_worker'] = prog_id_to_worker\n    opt_info['program_configs'] = program_configs\n    opt_info['trainer'] = strategy.get('trainer', 'DistMultiTrainer')\n    opt_info['device_worker'] = strategy.get('device_worker', 'DownpourSGD')\n    opt_info['optimizer'] = 'DownpourSGD'\n    opt_info['fleet_desc'] = ps_param\n    opt_info['worker_skipped_ops'] = worker_skipped_ops\n    opt_info['use_cvm'] = strategy.get('use_cvm', False)\n    opt_info['no_cvm'] = strategy.get('no_cvm', False)\n    opt_info['scale_sparse_gradient_with_batch_size'] = strategy.get('scale_sparse_gradient_with_batch_size', True)\n    opt_info['worker_class'] = strategy.get('worker_class', 'DownpourWorker')\n    opt_info['stat_var_names'] = strategy.get('stat_var_names', [])\n    opt_info['local_tables'] = strategy.get('local_tables', [])\n    opt_info['async_tables'] = strategy.get('async_tables', [])\n    opt_info['async_tables'] = strategy.get('async_tables', [])\n    opt_info['scale_datanorm'] = strategy.get('scale_datanorm', -1)\n    opt_info['check_nan_var_names'] = strategy.get('check_nan_var_names', [])\n    opt_info['dump_slot'] = False\n    opt_info['dump_converter'] = ''\n    opt_info['dump_fields'] = strategy.get('dump_fields', [])\n    opt_info['dump_file_num'] = strategy.get('dump_file_num', 16)\n    opt_info['user_define_dump_filename'] = strategy.get('user_define_dump_filename', '')\n    opt_info['dump_fields_path'] = strategy.get('dump_fields_path', '')\n    opt_info['dump_param'] = strategy.get('dump_param', [])\n    gpus_env = os.getenv('FLAGS_selected_gpus', '0')\n    opt_info['worker_places'] = [int(s) for s in gpus_env.split(',')]\n    opt_info['use_ps_gpu'] = strategy.get('use_ps_gpu', False)\n    if server._server.downpour_server_param.downpour_table_param[0].accessor.accessor_class in ['DownpourCtrAccessor', 'DownpourCtrDoubleAccessor', 'DownpourUnitAccessor', 'DownpourDoubleUnitAccessor', 'DownpourCtrDymfAccessor']:\n        opt_info['dump_slot'] = True\n    elif server._server.downpour_server_param.downpour_table_param[0].accessor.accessor_class == 'DownpourSparseValueAccessor':\n        opt_info['no_cvm'] = True\n    opt_info['adjust_ins_weight'] = strategy.get('adjust_ins_weight', {})\n    opt_info['copy_table'] = strategy.get('copy_table', {})\n    opt_info['loss_names'] = strategy.get('loss_names', [])\n    for loss in losses:\n        loss.block.program._fleet_opt = opt_info\n    param_grads_list = []\n    for loss in losses:\n        prog_id = str(id(loss.block.program))\n        param_grads_list.append(prog_id_to_param_grads[prog_id])\n    return (None, param_grads_list, opt_info)",
            "def _minimize(self, losses, startup_program=None, parameter_list=None, no_grad_set=None, strategy={}):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        DownpounSGD is a distributed optimizer so\\n        that user can call minimize to generate backward\\n        operators and optimization operators within minimize function\\n        Args:\\n            loss(Variable): loss variable defined by user\\n            startup_program(Program): startup program that defined by user\\n            parameter_list(str list): parameter names defined by users\\n            no_grad_set(set): a set of variables that is defined by users\\n            so that these variables do not need gradient computation\\n            strategy(dict): user-defined properties\\n        Returns:\\n            [optimize_ops, grads_and_weights]\\n        '\n    prog_id_to_sparse_table = OrderedDict()\n    prog_id_to_inputs_dict = OrderedDict()\n    prog_id_to_outputs_dict = OrderedDict()\n    ps_param = pslib.PSParameter()\n    server = DownpourServer()\n    prog_id_to_worker = OrderedDict()\n    prog_id_to_param_grads = OrderedDict()\n    prog_id_to_sparse_grads = OrderedDict()\n    program_id_set = set()\n    sparse_table_to_index = OrderedDict()\n    sparse_table_index = 0\n    for num in range(len(losses)):\n        loss = losses[num]\n        parameters = None\n        if parameter_list is not None:\n            parameters = parameter_list[num]\n        prog_id = str(id(loss.block.program))\n        params_grads = sorted(paddle.static.append_backward(loss, parameters, no_grad_set), key=lambda x: x[0].name)\n        flag_use_ps_gpu = strategy.get('use_ps_gpu', False)\n        if flag_use_ps_gpu:\n            if not isinstance(startup_program, list):\n                startup_program = [startup_program]\n            optimizer = copy.deepcopy(self._optimizer)\n            optimize_ops = optimizer.apply_optimize(loss, startup_program=startup_program[num], params_grads=params_grads)\n            embedding_table = self._find_multi_distributed_lookup_table([loss])\n            self._remove_optimize_op_for_embedding(loss, embedding_table)\n        flag_multi_task = self._has_conditional_block(loss)\n        if flag_multi_task:\n            self._cond_params = {}\n            self._other_params = []\n            now_program = loss.block.program\n            root_block = now_program.block(0)\n            all_params = []\n            for par in root_block.all_parameters():\n                all_params.append(par.name)\n            ops_ = root_block.ops\n            fill_value_dict = {}\n            equal_fill_dict = {}\n            for op in ops_:\n                if op.type == 'fill_constant':\n                    fill_value_dict[op.output('Out')[0]] = op.attr('value')\n                if op.type == 'equal':\n                    equal_fill_dict[op.output('Out')[0]] = op.input('Y')[0]\n                if op.type == 'conditional_block':\n                    self._generte_cond_para_map(op, fill_value_dict, equal_fill_dict, now_program, all_params)\n        if prog_id not in program_id_set:\n            program_id_set.add(prog_id)\n            sparse_table = self._find_multi_distributed_lookup_table([loss])\n            prog_id_to_sparse_table[prog_id] = sparse_table\n            for tn in sparse_table:\n                if sparse_table_to_index.get(tn) is None:\n                    sparse_table_to_index[tn] = sparse_table_index\n                    sparse_table_index += 1\n            emb_to_size = self._gen_distributed_emb_to_size_dict(loss.block.program)\n            inputs_dict = self._find_distributed_lookup_table_inputs(loss.block.program, sparse_table)\n            prog_id_to_inputs_dict[prog_id] = inputs_dict\n            outputs_dict = self._find_distributed_lookup_table_outputs(loss.block.program, sparse_table)\n            prog_id_to_outputs_dict[prog_id] = outputs_dict\n            prog_id_to_worker[prog_id] = DownpourWorker(self._window)\n            grads_dict = self._find_distributed_lookup_table_grads(loss.block.program, sparse_table)\n            prog_id_to_sparse_grads[prog_id] = grads_dict\n        if prog_id not in prog_id_to_param_grads:\n            prog_id_to_param_grads[prog_id] = []\n        prog_id_to_param_grads[prog_id].append(params_grads)\n    if strategy.get('fleet_desc_file') is not None:\n        fleet_desc_file = strategy['fleet_desc_file']\n        with open(fleet_desc_file) as f:\n            text_format.Merge(f.read(), ps_param)\n        server.get_desc().CopyFrom(ps_param.server_param)\n        if len(ps_param.trainer_param) == 1:\n            for k in prog_id_to_worker:\n                prog_id_to_worker[k].get_desc().CopyFrom(ps_param.trainer_param[0])\n        else:\n            if len(ps_param.trainer_param) != len(prog_id_to_worker):\n                raise ValueError(f'trainer param size != program size, {len(ps_param.trainer_param)} vs {len(prog_id_to_worker)}')\n            idx = 0\n            for k in prog_id_to_worker:\n                prog_id_to_worker[k].get_desc().CopyFrom(ps_param.trainer_param[idx])\n                idx += 1\n    if FLEET_GLOBAL_DICT['enable']:\n        one_slot = None\n        strategy['device_worker'] = 'Hogwild'\n        emb_to_table = FLEET_GLOBAL_DICT['emb_to_table']\n        emb_to_accessor = FLEET_GLOBAL_DICT['emb_to_accessor']\n        emb_to_size = FLEET_GLOBAL_DICT['emb_to_size']\n        if len(sparse_table_to_index) != len(emb_to_table):\n            raise ValueError('sparse tables from  program != sparse tables from op: {} vs {}'.format(len(sparse_table_to_index), len(emb_to_table)))\n        for key in sparse_table_to_index:\n            if key not in emb_to_table or sparse_table_to_index[key] != emb_to_table[key]:\n                print('sparse_table_to_index ', sparse_table_to_index)\n                print('emb_to_table ', emb_to_table)\n                raise ValueError('key error: %s' % key)\n            if strategy.get(key) is None:\n                strategy[key] = {}\n            st = strategy[key]\n            accessor = None\n            if st.get('sparse_accessor_class') is not None:\n                accessor = st['sparse_accessor_class']\n            tables = server.get_desc().downpour_server_param.downpour_table_param\n            for table in tables:\n                if table.table_id == sparse_table_to_index[key]:\n                    accessor = table.accessor.accessor_class\n                    break\n            for loss in losses:\n                for op in loss.block.program.global_block().ops:\n                    if op.type in self.supported_embedding_types:\n                        if accessor is not None and op.has_attr('AccessorClass'):\n                            op._set_attr('AccessorClass', accessor)\n                        if one_slot is None:\n                            one_slot = loss.block.program.global_block().var(op.input('Ids')[0])\n            if accessor is None:\n                accessor = emb_to_accessor[key]\n            if accessor == 'DownpourFeatureValueAccessor' or accessor == 'DownpourCtrDymfAccessor' or accessor == 'DownpourCtrAccessor' or (accessor == 'DownpourDoubleUnitAccessor') or (accessor == 'DownpourUnitAccessor'):\n                if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[key] - 3:\n                    raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding size - 3 = {}'.format(st['sparse_embedx_dim'], emb_to_size[key] - 3))\n                st['sparse_embedx_dim'] = emb_to_size[key] - 3\n            elif accessor == 'DownpourSparseValueAccessor':\n                if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[key]:\n                    raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding size = {}'.format(st['sparse_embedx_dim'], emb_to_size[key]))\n                st['sparse_embedx_dim'] = emb_to_size[key]\n    for tn in sparse_table_to_index:\n        sparse_table_index = sparse_table_to_index[tn]\n        st = self._check_config_fleet_with_program_op(strategy, tn, emb_to_size)\n        if st.get(tn) is not None:\n            server.add_sparse_table(sparse_table_index, st[tn])\n        else:\n            server.add_sparse_table(sparse_table_index, None)\n    program_id_set.clear()\n    for loss in losses:\n        prog_id = str(id(loss.block.program))\n        if prog_id not in program_id_set:\n            program_id_set.add(prog_id)\n            worker = prog_id_to_worker[prog_id]\n            inputs_dict = prog_id_to_inputs_dict[prog_id]\n            outputs_dict = prog_id_to_outputs_dict[prog_id]\n            for tn in prog_id_to_sparse_table[prog_id]:\n                sparse_table_index = sparse_table_to_index[tn]\n                grads_dict = prog_id_to_sparse_grads[prog_id]\n                worker.add_sparse_table(sparse_table_index, inputs_dict[tn], outputs_dict[tn], grads_dict[tn])\n    dense_start_table_id = len(sparse_table_to_index)\n    dense_table_index = len(sparse_table_to_index)\n    program_configs = {}\n    program_id_set.clear()\n    for loss_index in range(len(losses)):\n        program_id = str(id(losses[loss_index].block.program))\n        if program_id not in program_id_set:\n            program_id_set.add(program_id)\n            worker = prog_id_to_worker[program_id]\n            sparse_table_names = prog_id_to_sparse_table[program_id]\n            sparse_table_index = [sparse_table_to_index[i] for i in sparse_table_names]\n            program_configs[program_id] = {'pull_sparse': list(sparse_table_index), 'push_sparse': list(sparse_table_index)}\n            params_grads = prog_id_to_param_grads[program_id]\n            for pg in params_grads:\n                params = []\n                grads = []\n                data_norm_params = []\n                data_norm_grads = []\n                for i in pg:\n                    is_data_norm_data = False\n                    for data_norm_name in self.data_norm_name:\n                        if i[0].name.endswith(data_norm_name):\n                            is_data_norm_data = True\n                            data_norm_params.append(i[0])\n                    if not is_data_norm_data:\n                        params.append(i[0])\n                for i in pg:\n                    is_data_norm_data = False\n                    for data_norm_grad in self.data_norm_name:\n                        if i[0].name.endswith(data_norm_grad):\n                            is_data_norm_data = True\n                            data_norm_grads.append(i[1])\n                    if not is_data_norm_data:\n                        grads.append(i[1])\n                multi_task_dense_tables_push = []\n                multi_task_dense_tables_pull = []\n                if flag_multi_task:\n                    (dense_tables, cond2denseid, lists_params, lists_grads, root_params_list, root_grads_list) = self._generate_multi_dense_table(params, grads, self._cond_params, self._other_params, sparse_table_names, dense_table_index)\n                    program_configs[program_id]['cond2denseid'] = cond2denseid\n                    multi_task_dense_tables_push = dense_tables\n                    multi_task_dense_tables_pull = dense_tables[:]\n                if strategy.get('dense_table') is not None:\n                    if flag_multi_task:\n                        server_dense_table_index = dense_table_index\n                        if len(root_params_list) > 0:\n                            server.add_dense_table(server_dense_table_index, root_params_list, root_grads_list, strategy['dense_table'], sparse_table_names)\n                            server_dense_table_index += 1\n                        for i in range(len(lists_params)):\n                            server.add_dense_table(server_dense_table_index, lists_params[i], lists_grads[i], strategy['dense_table'], sparse_table_names)\n                            server_dense_table_index += 1\n                    else:\n                        server.add_dense_table(dense_table_index, params, grads, strategy['dense_table'], sparse_table_names)\n                else:\n                    server.add_dense_table(dense_table_index, params, grads, None, sparse_table_names)\n                if flag_multi_task:\n                    if len(root_params_list) > 0:\n                        worker.add_dense_table(dense_table_index, self._learning_rate, root_params_list, root_grads_list, dense_start_table_id, sparse_table_names)\n                        dense_table_index += 1\n                    for i in range(len(lists_params)):\n                        worker.add_dense_table(dense_table_index, self._learning_rate, lists_params[i], lists_grads[i], dense_start_table_id, sparse_table_names)\n                        dense_table_index += 1\n                    dense_table_index -= 1\n                else:\n                    worker.add_dense_table(dense_table_index, self._learning_rate, params, grads, dense_start_table_id, sparse_table_names)\n                if FLEET_GLOBAL_DICT['enable']:\n                    cur_prog = losses[loss_index].block.program\n                    cur_prog.global_block().append_op(type='push_dense', inputs={'Ids': one_slot}, attrs={'InputNames': [i.name for i in grads], 'TableId': dense_table_index, 'ScaleDataNorm': strategy.get('scale_datanorm', -1)})\n                if 'pull_dense' in program_configs[program_id] and 'push_dense' in program_configs[program_id] and (len(program_configs[program_id]['pull_dense']) > 0):\n                    if flag_multi_task:\n                        program_configs[program_id]['pull_dense'].extend(multi_task_dense_tables_pull)\n                        program_configs[program_id]['push_dense'].extend(multi_task_dense_tables_push)\n                    else:\n                        program_configs[program_id]['pull_dense'].extend([dense_table_index])\n                        program_configs[program_id]['push_dense'].extend([dense_table_index])\n                elif flag_multi_task:\n                    program_configs[program_id]['pull_dense'] = multi_task_dense_tables_pull\n                    program_configs[program_id]['push_dense'] = multi_task_dense_tables_push\n                else:\n                    program_configs[program_id]['pull_dense'] = [dense_table_index]\n                    program_configs[program_id]['push_dense'] = [dense_table_index]\n                if len(data_norm_params) != 0 and len(data_norm_grads) != 0:\n                    dense_table_index += 1\n                    if strategy.get('datanorm_table') is not None:\n                        server.add_data_norm_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, strategy['datanorm_table'], sparse_table_names)\n                    else:\n                        server.add_data_norm_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, None, sparse_table_names)\n                    worker.add_dense_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, dense_start_table_id, sparse_table_names)\n                    if FLEET_GLOBAL_DICT['enable']:\n                        cur_prog = losses[loss_index].block.program\n                        cur_prog.global_block().append_op(type='push_dense', inputs={'Ids': one_slot}, attrs={'InputNames': [i.name for i in data_norm_grads], 'TableId': dense_table_index, 'ScaleDataNorm': strategy.get('scale_datanorm', -1)})\n                    program_configs[program_id]['pull_dense'].extend([dense_table_index])\n                    program_configs[program_id]['push_dense'].extend([dense_table_index])\n                dense_table_index += 1\n        worker_skipped_ops = ['lookup_table', 'lookup_table_grad']\n        if len(worker.get_desc().skip_op) == 0:\n            worker.get_desc().skip_op.extend(worker_skipped_ops)\n    ps_param.server_param.CopyFrom(server.get_desc())\n    if len(ps_param.trainer_param) == 0:\n        for k in prog_id_to_worker:\n            tp = ps_param.trainer_param.add()\n            tp.CopyFrom(prog_id_to_worker[k].get_desc())\n    if strategy.get('fs_uri') is not None:\n        ps_param.fs_client_param.uri = strategy['fs_uri']\n    elif ps_param.fs_client_param.uri == '':\n        ps_param.fs_client_param.uri = 'hdfs://your_hdfs_uri'\n    if strategy.get('fs_user') is not None:\n        ps_param.fs_client_param.user = strategy['fs_user']\n    elif ps_param.fs_client_param.user == '':\n        ps_param.fs_client_param.user = 'your_hdfs_user'\n    if strategy.get('fs_passwd') is not None:\n        ps_param.fs_client_param.passwd = strategy['fs_passwd']\n    elif ps_param.fs_client_param.passwd == '':\n        ps_param.fs_client_param.passwd = 'your_hdfs_passwd'\n    if strategy.get('fs_hadoop_bin') is not None:\n        ps_param.fs_client_param.hadoop_bin = strategy['fs_hadoop_bin']\n    elif ps_param.fs_client_param.hadoop_bin == '':\n        ps_param.fs_client_param.hadoop_bin = '$HADOOP_HOME/bin/hadoop'\n    opt_info = {}\n    opt_info['program_id_to_worker'] = prog_id_to_worker\n    opt_info['program_configs'] = program_configs\n    opt_info['trainer'] = strategy.get('trainer', 'DistMultiTrainer')\n    opt_info['device_worker'] = strategy.get('device_worker', 'DownpourSGD')\n    opt_info['optimizer'] = 'DownpourSGD'\n    opt_info['fleet_desc'] = ps_param\n    opt_info['worker_skipped_ops'] = worker_skipped_ops\n    opt_info['use_cvm'] = strategy.get('use_cvm', False)\n    opt_info['no_cvm'] = strategy.get('no_cvm', False)\n    opt_info['scale_sparse_gradient_with_batch_size'] = strategy.get('scale_sparse_gradient_with_batch_size', True)\n    opt_info['worker_class'] = strategy.get('worker_class', 'DownpourWorker')\n    opt_info['stat_var_names'] = strategy.get('stat_var_names', [])\n    opt_info['local_tables'] = strategy.get('local_tables', [])\n    opt_info['async_tables'] = strategy.get('async_tables', [])\n    opt_info['async_tables'] = strategy.get('async_tables', [])\n    opt_info['scale_datanorm'] = strategy.get('scale_datanorm', -1)\n    opt_info['check_nan_var_names'] = strategy.get('check_nan_var_names', [])\n    opt_info['dump_slot'] = False\n    opt_info['dump_converter'] = ''\n    opt_info['dump_fields'] = strategy.get('dump_fields', [])\n    opt_info['dump_file_num'] = strategy.get('dump_file_num', 16)\n    opt_info['user_define_dump_filename'] = strategy.get('user_define_dump_filename', '')\n    opt_info['dump_fields_path'] = strategy.get('dump_fields_path', '')\n    opt_info['dump_param'] = strategy.get('dump_param', [])\n    gpus_env = os.getenv('FLAGS_selected_gpus', '0')\n    opt_info['worker_places'] = [int(s) for s in gpus_env.split(',')]\n    opt_info['use_ps_gpu'] = strategy.get('use_ps_gpu', False)\n    if server._server.downpour_server_param.downpour_table_param[0].accessor.accessor_class in ['DownpourCtrAccessor', 'DownpourCtrDoubleAccessor', 'DownpourUnitAccessor', 'DownpourDoubleUnitAccessor', 'DownpourCtrDymfAccessor']:\n        opt_info['dump_slot'] = True\n    elif server._server.downpour_server_param.downpour_table_param[0].accessor.accessor_class == 'DownpourSparseValueAccessor':\n        opt_info['no_cvm'] = True\n    opt_info['adjust_ins_weight'] = strategy.get('adjust_ins_weight', {})\n    opt_info['copy_table'] = strategy.get('copy_table', {})\n    opt_info['loss_names'] = strategy.get('loss_names', [])\n    for loss in losses:\n        loss.block.program._fleet_opt = opt_info\n    param_grads_list = []\n    for loss in losses:\n        prog_id = str(id(loss.block.program))\n        param_grads_list.append(prog_id_to_param_grads[prog_id])\n    return (None, param_grads_list, opt_info)",
            "def _minimize(self, losses, startup_program=None, parameter_list=None, no_grad_set=None, strategy={}):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        DownpounSGD is a distributed optimizer so\\n        that user can call minimize to generate backward\\n        operators and optimization operators within minimize function\\n        Args:\\n            loss(Variable): loss variable defined by user\\n            startup_program(Program): startup program that defined by user\\n            parameter_list(str list): parameter names defined by users\\n            no_grad_set(set): a set of variables that is defined by users\\n            so that these variables do not need gradient computation\\n            strategy(dict): user-defined properties\\n        Returns:\\n            [optimize_ops, grads_and_weights]\\n        '\n    prog_id_to_sparse_table = OrderedDict()\n    prog_id_to_inputs_dict = OrderedDict()\n    prog_id_to_outputs_dict = OrderedDict()\n    ps_param = pslib.PSParameter()\n    server = DownpourServer()\n    prog_id_to_worker = OrderedDict()\n    prog_id_to_param_grads = OrderedDict()\n    prog_id_to_sparse_grads = OrderedDict()\n    program_id_set = set()\n    sparse_table_to_index = OrderedDict()\n    sparse_table_index = 0\n    for num in range(len(losses)):\n        loss = losses[num]\n        parameters = None\n        if parameter_list is not None:\n            parameters = parameter_list[num]\n        prog_id = str(id(loss.block.program))\n        params_grads = sorted(paddle.static.append_backward(loss, parameters, no_grad_set), key=lambda x: x[0].name)\n        flag_use_ps_gpu = strategy.get('use_ps_gpu', False)\n        if flag_use_ps_gpu:\n            if not isinstance(startup_program, list):\n                startup_program = [startup_program]\n            optimizer = copy.deepcopy(self._optimizer)\n            optimize_ops = optimizer.apply_optimize(loss, startup_program=startup_program[num], params_grads=params_grads)\n            embedding_table = self._find_multi_distributed_lookup_table([loss])\n            self._remove_optimize_op_for_embedding(loss, embedding_table)\n        flag_multi_task = self._has_conditional_block(loss)\n        if flag_multi_task:\n            self._cond_params = {}\n            self._other_params = []\n            now_program = loss.block.program\n            root_block = now_program.block(0)\n            all_params = []\n            for par in root_block.all_parameters():\n                all_params.append(par.name)\n            ops_ = root_block.ops\n            fill_value_dict = {}\n            equal_fill_dict = {}\n            for op in ops_:\n                if op.type == 'fill_constant':\n                    fill_value_dict[op.output('Out')[0]] = op.attr('value')\n                if op.type == 'equal':\n                    equal_fill_dict[op.output('Out')[0]] = op.input('Y')[0]\n                if op.type == 'conditional_block':\n                    self._generte_cond_para_map(op, fill_value_dict, equal_fill_dict, now_program, all_params)\n        if prog_id not in program_id_set:\n            program_id_set.add(prog_id)\n            sparse_table = self._find_multi_distributed_lookup_table([loss])\n            prog_id_to_sparse_table[prog_id] = sparse_table\n            for tn in sparse_table:\n                if sparse_table_to_index.get(tn) is None:\n                    sparse_table_to_index[tn] = sparse_table_index\n                    sparse_table_index += 1\n            emb_to_size = self._gen_distributed_emb_to_size_dict(loss.block.program)\n            inputs_dict = self._find_distributed_lookup_table_inputs(loss.block.program, sparse_table)\n            prog_id_to_inputs_dict[prog_id] = inputs_dict\n            outputs_dict = self._find_distributed_lookup_table_outputs(loss.block.program, sparse_table)\n            prog_id_to_outputs_dict[prog_id] = outputs_dict\n            prog_id_to_worker[prog_id] = DownpourWorker(self._window)\n            grads_dict = self._find_distributed_lookup_table_grads(loss.block.program, sparse_table)\n            prog_id_to_sparse_grads[prog_id] = grads_dict\n        if prog_id not in prog_id_to_param_grads:\n            prog_id_to_param_grads[prog_id] = []\n        prog_id_to_param_grads[prog_id].append(params_grads)\n    if strategy.get('fleet_desc_file') is not None:\n        fleet_desc_file = strategy['fleet_desc_file']\n        with open(fleet_desc_file) as f:\n            text_format.Merge(f.read(), ps_param)\n        server.get_desc().CopyFrom(ps_param.server_param)\n        if len(ps_param.trainer_param) == 1:\n            for k in prog_id_to_worker:\n                prog_id_to_worker[k].get_desc().CopyFrom(ps_param.trainer_param[0])\n        else:\n            if len(ps_param.trainer_param) != len(prog_id_to_worker):\n                raise ValueError(f'trainer param size != program size, {len(ps_param.trainer_param)} vs {len(prog_id_to_worker)}')\n            idx = 0\n            for k in prog_id_to_worker:\n                prog_id_to_worker[k].get_desc().CopyFrom(ps_param.trainer_param[idx])\n                idx += 1\n    if FLEET_GLOBAL_DICT['enable']:\n        one_slot = None\n        strategy['device_worker'] = 'Hogwild'\n        emb_to_table = FLEET_GLOBAL_DICT['emb_to_table']\n        emb_to_accessor = FLEET_GLOBAL_DICT['emb_to_accessor']\n        emb_to_size = FLEET_GLOBAL_DICT['emb_to_size']\n        if len(sparse_table_to_index) != len(emb_to_table):\n            raise ValueError('sparse tables from  program != sparse tables from op: {} vs {}'.format(len(sparse_table_to_index), len(emb_to_table)))\n        for key in sparse_table_to_index:\n            if key not in emb_to_table or sparse_table_to_index[key] != emb_to_table[key]:\n                print('sparse_table_to_index ', sparse_table_to_index)\n                print('emb_to_table ', emb_to_table)\n                raise ValueError('key error: %s' % key)\n            if strategy.get(key) is None:\n                strategy[key] = {}\n            st = strategy[key]\n            accessor = None\n            if st.get('sparse_accessor_class') is not None:\n                accessor = st['sparse_accessor_class']\n            tables = server.get_desc().downpour_server_param.downpour_table_param\n            for table in tables:\n                if table.table_id == sparse_table_to_index[key]:\n                    accessor = table.accessor.accessor_class\n                    break\n            for loss in losses:\n                for op in loss.block.program.global_block().ops:\n                    if op.type in self.supported_embedding_types:\n                        if accessor is not None and op.has_attr('AccessorClass'):\n                            op._set_attr('AccessorClass', accessor)\n                        if one_slot is None:\n                            one_slot = loss.block.program.global_block().var(op.input('Ids')[0])\n            if accessor is None:\n                accessor = emb_to_accessor[key]\n            if accessor == 'DownpourFeatureValueAccessor' or accessor == 'DownpourCtrDymfAccessor' or accessor == 'DownpourCtrAccessor' or (accessor == 'DownpourDoubleUnitAccessor') or (accessor == 'DownpourUnitAccessor'):\n                if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[key] - 3:\n                    raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding size - 3 = {}'.format(st['sparse_embedx_dim'], emb_to_size[key] - 3))\n                st['sparse_embedx_dim'] = emb_to_size[key] - 3\n            elif accessor == 'DownpourSparseValueAccessor':\n                if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[key]:\n                    raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding size = {}'.format(st['sparse_embedx_dim'], emb_to_size[key]))\n                st['sparse_embedx_dim'] = emb_to_size[key]\n    for tn in sparse_table_to_index:\n        sparse_table_index = sparse_table_to_index[tn]\n        st = self._check_config_fleet_with_program_op(strategy, tn, emb_to_size)\n        if st.get(tn) is not None:\n            server.add_sparse_table(sparse_table_index, st[tn])\n        else:\n            server.add_sparse_table(sparse_table_index, None)\n    program_id_set.clear()\n    for loss in losses:\n        prog_id = str(id(loss.block.program))\n        if prog_id not in program_id_set:\n            program_id_set.add(prog_id)\n            worker = prog_id_to_worker[prog_id]\n            inputs_dict = prog_id_to_inputs_dict[prog_id]\n            outputs_dict = prog_id_to_outputs_dict[prog_id]\n            for tn in prog_id_to_sparse_table[prog_id]:\n                sparse_table_index = sparse_table_to_index[tn]\n                grads_dict = prog_id_to_sparse_grads[prog_id]\n                worker.add_sparse_table(sparse_table_index, inputs_dict[tn], outputs_dict[tn], grads_dict[tn])\n    dense_start_table_id = len(sparse_table_to_index)\n    dense_table_index = len(sparse_table_to_index)\n    program_configs = {}\n    program_id_set.clear()\n    for loss_index in range(len(losses)):\n        program_id = str(id(losses[loss_index].block.program))\n        if program_id not in program_id_set:\n            program_id_set.add(program_id)\n            worker = prog_id_to_worker[program_id]\n            sparse_table_names = prog_id_to_sparse_table[program_id]\n            sparse_table_index = [sparse_table_to_index[i] for i in sparse_table_names]\n            program_configs[program_id] = {'pull_sparse': list(sparse_table_index), 'push_sparse': list(sparse_table_index)}\n            params_grads = prog_id_to_param_grads[program_id]\n            for pg in params_grads:\n                params = []\n                grads = []\n                data_norm_params = []\n                data_norm_grads = []\n                for i in pg:\n                    is_data_norm_data = False\n                    for data_norm_name in self.data_norm_name:\n                        if i[0].name.endswith(data_norm_name):\n                            is_data_norm_data = True\n                            data_norm_params.append(i[0])\n                    if not is_data_norm_data:\n                        params.append(i[0])\n                for i in pg:\n                    is_data_norm_data = False\n                    for data_norm_grad in self.data_norm_name:\n                        if i[0].name.endswith(data_norm_grad):\n                            is_data_norm_data = True\n                            data_norm_grads.append(i[1])\n                    if not is_data_norm_data:\n                        grads.append(i[1])\n                multi_task_dense_tables_push = []\n                multi_task_dense_tables_pull = []\n                if flag_multi_task:\n                    (dense_tables, cond2denseid, lists_params, lists_grads, root_params_list, root_grads_list) = self._generate_multi_dense_table(params, grads, self._cond_params, self._other_params, sparse_table_names, dense_table_index)\n                    program_configs[program_id]['cond2denseid'] = cond2denseid\n                    multi_task_dense_tables_push = dense_tables\n                    multi_task_dense_tables_pull = dense_tables[:]\n                if strategy.get('dense_table') is not None:\n                    if flag_multi_task:\n                        server_dense_table_index = dense_table_index\n                        if len(root_params_list) > 0:\n                            server.add_dense_table(server_dense_table_index, root_params_list, root_grads_list, strategy['dense_table'], sparse_table_names)\n                            server_dense_table_index += 1\n                        for i in range(len(lists_params)):\n                            server.add_dense_table(server_dense_table_index, lists_params[i], lists_grads[i], strategy['dense_table'], sparse_table_names)\n                            server_dense_table_index += 1\n                    else:\n                        server.add_dense_table(dense_table_index, params, grads, strategy['dense_table'], sparse_table_names)\n                else:\n                    server.add_dense_table(dense_table_index, params, grads, None, sparse_table_names)\n                if flag_multi_task:\n                    if len(root_params_list) > 0:\n                        worker.add_dense_table(dense_table_index, self._learning_rate, root_params_list, root_grads_list, dense_start_table_id, sparse_table_names)\n                        dense_table_index += 1\n                    for i in range(len(lists_params)):\n                        worker.add_dense_table(dense_table_index, self._learning_rate, lists_params[i], lists_grads[i], dense_start_table_id, sparse_table_names)\n                        dense_table_index += 1\n                    dense_table_index -= 1\n                else:\n                    worker.add_dense_table(dense_table_index, self._learning_rate, params, grads, dense_start_table_id, sparse_table_names)\n                if FLEET_GLOBAL_DICT['enable']:\n                    cur_prog = losses[loss_index].block.program\n                    cur_prog.global_block().append_op(type='push_dense', inputs={'Ids': one_slot}, attrs={'InputNames': [i.name for i in grads], 'TableId': dense_table_index, 'ScaleDataNorm': strategy.get('scale_datanorm', -1)})\n                if 'pull_dense' in program_configs[program_id] and 'push_dense' in program_configs[program_id] and (len(program_configs[program_id]['pull_dense']) > 0):\n                    if flag_multi_task:\n                        program_configs[program_id]['pull_dense'].extend(multi_task_dense_tables_pull)\n                        program_configs[program_id]['push_dense'].extend(multi_task_dense_tables_push)\n                    else:\n                        program_configs[program_id]['pull_dense'].extend([dense_table_index])\n                        program_configs[program_id]['push_dense'].extend([dense_table_index])\n                elif flag_multi_task:\n                    program_configs[program_id]['pull_dense'] = multi_task_dense_tables_pull\n                    program_configs[program_id]['push_dense'] = multi_task_dense_tables_push\n                else:\n                    program_configs[program_id]['pull_dense'] = [dense_table_index]\n                    program_configs[program_id]['push_dense'] = [dense_table_index]\n                if len(data_norm_params) != 0 and len(data_norm_grads) != 0:\n                    dense_table_index += 1\n                    if strategy.get('datanorm_table') is not None:\n                        server.add_data_norm_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, strategy['datanorm_table'], sparse_table_names)\n                    else:\n                        server.add_data_norm_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, None, sparse_table_names)\n                    worker.add_dense_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, dense_start_table_id, sparse_table_names)\n                    if FLEET_GLOBAL_DICT['enable']:\n                        cur_prog = losses[loss_index].block.program\n                        cur_prog.global_block().append_op(type='push_dense', inputs={'Ids': one_slot}, attrs={'InputNames': [i.name for i in data_norm_grads], 'TableId': dense_table_index, 'ScaleDataNorm': strategy.get('scale_datanorm', -1)})\n                    program_configs[program_id]['pull_dense'].extend([dense_table_index])\n                    program_configs[program_id]['push_dense'].extend([dense_table_index])\n                dense_table_index += 1\n        worker_skipped_ops = ['lookup_table', 'lookup_table_grad']\n        if len(worker.get_desc().skip_op) == 0:\n            worker.get_desc().skip_op.extend(worker_skipped_ops)\n    ps_param.server_param.CopyFrom(server.get_desc())\n    if len(ps_param.trainer_param) == 0:\n        for k in prog_id_to_worker:\n            tp = ps_param.trainer_param.add()\n            tp.CopyFrom(prog_id_to_worker[k].get_desc())\n    if strategy.get('fs_uri') is not None:\n        ps_param.fs_client_param.uri = strategy['fs_uri']\n    elif ps_param.fs_client_param.uri == '':\n        ps_param.fs_client_param.uri = 'hdfs://your_hdfs_uri'\n    if strategy.get('fs_user') is not None:\n        ps_param.fs_client_param.user = strategy['fs_user']\n    elif ps_param.fs_client_param.user == '':\n        ps_param.fs_client_param.user = 'your_hdfs_user'\n    if strategy.get('fs_passwd') is not None:\n        ps_param.fs_client_param.passwd = strategy['fs_passwd']\n    elif ps_param.fs_client_param.passwd == '':\n        ps_param.fs_client_param.passwd = 'your_hdfs_passwd'\n    if strategy.get('fs_hadoop_bin') is not None:\n        ps_param.fs_client_param.hadoop_bin = strategy['fs_hadoop_bin']\n    elif ps_param.fs_client_param.hadoop_bin == '':\n        ps_param.fs_client_param.hadoop_bin = '$HADOOP_HOME/bin/hadoop'\n    opt_info = {}\n    opt_info['program_id_to_worker'] = prog_id_to_worker\n    opt_info['program_configs'] = program_configs\n    opt_info['trainer'] = strategy.get('trainer', 'DistMultiTrainer')\n    opt_info['device_worker'] = strategy.get('device_worker', 'DownpourSGD')\n    opt_info['optimizer'] = 'DownpourSGD'\n    opt_info['fleet_desc'] = ps_param\n    opt_info['worker_skipped_ops'] = worker_skipped_ops\n    opt_info['use_cvm'] = strategy.get('use_cvm', False)\n    opt_info['no_cvm'] = strategy.get('no_cvm', False)\n    opt_info['scale_sparse_gradient_with_batch_size'] = strategy.get('scale_sparse_gradient_with_batch_size', True)\n    opt_info['worker_class'] = strategy.get('worker_class', 'DownpourWorker')\n    opt_info['stat_var_names'] = strategy.get('stat_var_names', [])\n    opt_info['local_tables'] = strategy.get('local_tables', [])\n    opt_info['async_tables'] = strategy.get('async_tables', [])\n    opt_info['async_tables'] = strategy.get('async_tables', [])\n    opt_info['scale_datanorm'] = strategy.get('scale_datanorm', -1)\n    opt_info['check_nan_var_names'] = strategy.get('check_nan_var_names', [])\n    opt_info['dump_slot'] = False\n    opt_info['dump_converter'] = ''\n    opt_info['dump_fields'] = strategy.get('dump_fields', [])\n    opt_info['dump_file_num'] = strategy.get('dump_file_num', 16)\n    opt_info['user_define_dump_filename'] = strategy.get('user_define_dump_filename', '')\n    opt_info['dump_fields_path'] = strategy.get('dump_fields_path', '')\n    opt_info['dump_param'] = strategy.get('dump_param', [])\n    gpus_env = os.getenv('FLAGS_selected_gpus', '0')\n    opt_info['worker_places'] = [int(s) for s in gpus_env.split(',')]\n    opt_info['use_ps_gpu'] = strategy.get('use_ps_gpu', False)\n    if server._server.downpour_server_param.downpour_table_param[0].accessor.accessor_class in ['DownpourCtrAccessor', 'DownpourCtrDoubleAccessor', 'DownpourUnitAccessor', 'DownpourDoubleUnitAccessor', 'DownpourCtrDymfAccessor']:\n        opt_info['dump_slot'] = True\n    elif server._server.downpour_server_param.downpour_table_param[0].accessor.accessor_class == 'DownpourSparseValueAccessor':\n        opt_info['no_cvm'] = True\n    opt_info['adjust_ins_weight'] = strategy.get('adjust_ins_weight', {})\n    opt_info['copy_table'] = strategy.get('copy_table', {})\n    opt_info['loss_names'] = strategy.get('loss_names', [])\n    for loss in losses:\n        loss.block.program._fleet_opt = opt_info\n    param_grads_list = []\n    for loss in losses:\n        prog_id = str(id(loss.block.program))\n        param_grads_list.append(prog_id_to_param_grads[prog_id])\n    return (None, param_grads_list, opt_info)",
            "def _minimize(self, losses, startup_program=None, parameter_list=None, no_grad_set=None, strategy={}):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        DownpounSGD is a distributed optimizer so\\n        that user can call minimize to generate backward\\n        operators and optimization operators within minimize function\\n        Args:\\n            loss(Variable): loss variable defined by user\\n            startup_program(Program): startup program that defined by user\\n            parameter_list(str list): parameter names defined by users\\n            no_grad_set(set): a set of variables that is defined by users\\n            so that these variables do not need gradient computation\\n            strategy(dict): user-defined properties\\n        Returns:\\n            [optimize_ops, grads_and_weights]\\n        '\n    prog_id_to_sparse_table = OrderedDict()\n    prog_id_to_inputs_dict = OrderedDict()\n    prog_id_to_outputs_dict = OrderedDict()\n    ps_param = pslib.PSParameter()\n    server = DownpourServer()\n    prog_id_to_worker = OrderedDict()\n    prog_id_to_param_grads = OrderedDict()\n    prog_id_to_sparse_grads = OrderedDict()\n    program_id_set = set()\n    sparse_table_to_index = OrderedDict()\n    sparse_table_index = 0\n    for num in range(len(losses)):\n        loss = losses[num]\n        parameters = None\n        if parameter_list is not None:\n            parameters = parameter_list[num]\n        prog_id = str(id(loss.block.program))\n        params_grads = sorted(paddle.static.append_backward(loss, parameters, no_grad_set), key=lambda x: x[0].name)\n        flag_use_ps_gpu = strategy.get('use_ps_gpu', False)\n        if flag_use_ps_gpu:\n            if not isinstance(startup_program, list):\n                startup_program = [startup_program]\n            optimizer = copy.deepcopy(self._optimizer)\n            optimize_ops = optimizer.apply_optimize(loss, startup_program=startup_program[num], params_grads=params_grads)\n            embedding_table = self._find_multi_distributed_lookup_table([loss])\n            self._remove_optimize_op_for_embedding(loss, embedding_table)\n        flag_multi_task = self._has_conditional_block(loss)\n        if flag_multi_task:\n            self._cond_params = {}\n            self._other_params = []\n            now_program = loss.block.program\n            root_block = now_program.block(0)\n            all_params = []\n            for par in root_block.all_parameters():\n                all_params.append(par.name)\n            ops_ = root_block.ops\n            fill_value_dict = {}\n            equal_fill_dict = {}\n            for op in ops_:\n                if op.type == 'fill_constant':\n                    fill_value_dict[op.output('Out')[0]] = op.attr('value')\n                if op.type == 'equal':\n                    equal_fill_dict[op.output('Out')[0]] = op.input('Y')[0]\n                if op.type == 'conditional_block':\n                    self._generte_cond_para_map(op, fill_value_dict, equal_fill_dict, now_program, all_params)\n        if prog_id not in program_id_set:\n            program_id_set.add(prog_id)\n            sparse_table = self._find_multi_distributed_lookup_table([loss])\n            prog_id_to_sparse_table[prog_id] = sparse_table\n            for tn in sparse_table:\n                if sparse_table_to_index.get(tn) is None:\n                    sparse_table_to_index[tn] = sparse_table_index\n                    sparse_table_index += 1\n            emb_to_size = self._gen_distributed_emb_to_size_dict(loss.block.program)\n            inputs_dict = self._find_distributed_lookup_table_inputs(loss.block.program, sparse_table)\n            prog_id_to_inputs_dict[prog_id] = inputs_dict\n            outputs_dict = self._find_distributed_lookup_table_outputs(loss.block.program, sparse_table)\n            prog_id_to_outputs_dict[prog_id] = outputs_dict\n            prog_id_to_worker[prog_id] = DownpourWorker(self._window)\n            grads_dict = self._find_distributed_lookup_table_grads(loss.block.program, sparse_table)\n            prog_id_to_sparse_grads[prog_id] = grads_dict\n        if prog_id not in prog_id_to_param_grads:\n            prog_id_to_param_grads[prog_id] = []\n        prog_id_to_param_grads[prog_id].append(params_grads)\n    if strategy.get('fleet_desc_file') is not None:\n        fleet_desc_file = strategy['fleet_desc_file']\n        with open(fleet_desc_file) as f:\n            text_format.Merge(f.read(), ps_param)\n        server.get_desc().CopyFrom(ps_param.server_param)\n        if len(ps_param.trainer_param) == 1:\n            for k in prog_id_to_worker:\n                prog_id_to_worker[k].get_desc().CopyFrom(ps_param.trainer_param[0])\n        else:\n            if len(ps_param.trainer_param) != len(prog_id_to_worker):\n                raise ValueError(f'trainer param size != program size, {len(ps_param.trainer_param)} vs {len(prog_id_to_worker)}')\n            idx = 0\n            for k in prog_id_to_worker:\n                prog_id_to_worker[k].get_desc().CopyFrom(ps_param.trainer_param[idx])\n                idx += 1\n    if FLEET_GLOBAL_DICT['enable']:\n        one_slot = None\n        strategy['device_worker'] = 'Hogwild'\n        emb_to_table = FLEET_GLOBAL_DICT['emb_to_table']\n        emb_to_accessor = FLEET_GLOBAL_DICT['emb_to_accessor']\n        emb_to_size = FLEET_GLOBAL_DICT['emb_to_size']\n        if len(sparse_table_to_index) != len(emb_to_table):\n            raise ValueError('sparse tables from  program != sparse tables from op: {} vs {}'.format(len(sparse_table_to_index), len(emb_to_table)))\n        for key in sparse_table_to_index:\n            if key not in emb_to_table or sparse_table_to_index[key] != emb_to_table[key]:\n                print('sparse_table_to_index ', sparse_table_to_index)\n                print('emb_to_table ', emb_to_table)\n                raise ValueError('key error: %s' % key)\n            if strategy.get(key) is None:\n                strategy[key] = {}\n            st = strategy[key]\n            accessor = None\n            if st.get('sparse_accessor_class') is not None:\n                accessor = st['sparse_accessor_class']\n            tables = server.get_desc().downpour_server_param.downpour_table_param\n            for table in tables:\n                if table.table_id == sparse_table_to_index[key]:\n                    accessor = table.accessor.accessor_class\n                    break\n            for loss in losses:\n                for op in loss.block.program.global_block().ops:\n                    if op.type in self.supported_embedding_types:\n                        if accessor is not None and op.has_attr('AccessorClass'):\n                            op._set_attr('AccessorClass', accessor)\n                        if one_slot is None:\n                            one_slot = loss.block.program.global_block().var(op.input('Ids')[0])\n            if accessor is None:\n                accessor = emb_to_accessor[key]\n            if accessor == 'DownpourFeatureValueAccessor' or accessor == 'DownpourCtrDymfAccessor' or accessor == 'DownpourCtrAccessor' or (accessor == 'DownpourDoubleUnitAccessor') or (accessor == 'DownpourUnitAccessor'):\n                if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[key] - 3:\n                    raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding size - 3 = {}'.format(st['sparse_embedx_dim'], emb_to_size[key] - 3))\n                st['sparse_embedx_dim'] = emb_to_size[key] - 3\n            elif accessor == 'DownpourSparseValueAccessor':\n                if st.get('sparse_embedx_dim') is not None and st['sparse_embedx_dim'] != emb_to_size[key]:\n                    raise ValueError('fleet config sparse_embedx_dim={} not equal to embedding size = {}'.format(st['sparse_embedx_dim'], emb_to_size[key]))\n                st['sparse_embedx_dim'] = emb_to_size[key]\n    for tn in sparse_table_to_index:\n        sparse_table_index = sparse_table_to_index[tn]\n        st = self._check_config_fleet_with_program_op(strategy, tn, emb_to_size)\n        if st.get(tn) is not None:\n            server.add_sparse_table(sparse_table_index, st[tn])\n        else:\n            server.add_sparse_table(sparse_table_index, None)\n    program_id_set.clear()\n    for loss in losses:\n        prog_id = str(id(loss.block.program))\n        if prog_id not in program_id_set:\n            program_id_set.add(prog_id)\n            worker = prog_id_to_worker[prog_id]\n            inputs_dict = prog_id_to_inputs_dict[prog_id]\n            outputs_dict = prog_id_to_outputs_dict[prog_id]\n            for tn in prog_id_to_sparse_table[prog_id]:\n                sparse_table_index = sparse_table_to_index[tn]\n                grads_dict = prog_id_to_sparse_grads[prog_id]\n                worker.add_sparse_table(sparse_table_index, inputs_dict[tn], outputs_dict[tn], grads_dict[tn])\n    dense_start_table_id = len(sparse_table_to_index)\n    dense_table_index = len(sparse_table_to_index)\n    program_configs = {}\n    program_id_set.clear()\n    for loss_index in range(len(losses)):\n        program_id = str(id(losses[loss_index].block.program))\n        if program_id not in program_id_set:\n            program_id_set.add(program_id)\n            worker = prog_id_to_worker[program_id]\n            sparse_table_names = prog_id_to_sparse_table[program_id]\n            sparse_table_index = [sparse_table_to_index[i] for i in sparse_table_names]\n            program_configs[program_id] = {'pull_sparse': list(sparse_table_index), 'push_sparse': list(sparse_table_index)}\n            params_grads = prog_id_to_param_grads[program_id]\n            for pg in params_grads:\n                params = []\n                grads = []\n                data_norm_params = []\n                data_norm_grads = []\n                for i in pg:\n                    is_data_norm_data = False\n                    for data_norm_name in self.data_norm_name:\n                        if i[0].name.endswith(data_norm_name):\n                            is_data_norm_data = True\n                            data_norm_params.append(i[0])\n                    if not is_data_norm_data:\n                        params.append(i[0])\n                for i in pg:\n                    is_data_norm_data = False\n                    for data_norm_grad in self.data_norm_name:\n                        if i[0].name.endswith(data_norm_grad):\n                            is_data_norm_data = True\n                            data_norm_grads.append(i[1])\n                    if not is_data_norm_data:\n                        grads.append(i[1])\n                multi_task_dense_tables_push = []\n                multi_task_dense_tables_pull = []\n                if flag_multi_task:\n                    (dense_tables, cond2denseid, lists_params, lists_grads, root_params_list, root_grads_list) = self._generate_multi_dense_table(params, grads, self._cond_params, self._other_params, sparse_table_names, dense_table_index)\n                    program_configs[program_id]['cond2denseid'] = cond2denseid\n                    multi_task_dense_tables_push = dense_tables\n                    multi_task_dense_tables_pull = dense_tables[:]\n                if strategy.get('dense_table') is not None:\n                    if flag_multi_task:\n                        server_dense_table_index = dense_table_index\n                        if len(root_params_list) > 0:\n                            server.add_dense_table(server_dense_table_index, root_params_list, root_grads_list, strategy['dense_table'], sparse_table_names)\n                            server_dense_table_index += 1\n                        for i in range(len(lists_params)):\n                            server.add_dense_table(server_dense_table_index, lists_params[i], lists_grads[i], strategy['dense_table'], sparse_table_names)\n                            server_dense_table_index += 1\n                    else:\n                        server.add_dense_table(dense_table_index, params, grads, strategy['dense_table'], sparse_table_names)\n                else:\n                    server.add_dense_table(dense_table_index, params, grads, None, sparse_table_names)\n                if flag_multi_task:\n                    if len(root_params_list) > 0:\n                        worker.add_dense_table(dense_table_index, self._learning_rate, root_params_list, root_grads_list, dense_start_table_id, sparse_table_names)\n                        dense_table_index += 1\n                    for i in range(len(lists_params)):\n                        worker.add_dense_table(dense_table_index, self._learning_rate, lists_params[i], lists_grads[i], dense_start_table_id, sparse_table_names)\n                        dense_table_index += 1\n                    dense_table_index -= 1\n                else:\n                    worker.add_dense_table(dense_table_index, self._learning_rate, params, grads, dense_start_table_id, sparse_table_names)\n                if FLEET_GLOBAL_DICT['enable']:\n                    cur_prog = losses[loss_index].block.program\n                    cur_prog.global_block().append_op(type='push_dense', inputs={'Ids': one_slot}, attrs={'InputNames': [i.name for i in grads], 'TableId': dense_table_index, 'ScaleDataNorm': strategy.get('scale_datanorm', -1)})\n                if 'pull_dense' in program_configs[program_id] and 'push_dense' in program_configs[program_id] and (len(program_configs[program_id]['pull_dense']) > 0):\n                    if flag_multi_task:\n                        program_configs[program_id]['pull_dense'].extend(multi_task_dense_tables_pull)\n                        program_configs[program_id]['push_dense'].extend(multi_task_dense_tables_push)\n                    else:\n                        program_configs[program_id]['pull_dense'].extend([dense_table_index])\n                        program_configs[program_id]['push_dense'].extend([dense_table_index])\n                elif flag_multi_task:\n                    program_configs[program_id]['pull_dense'] = multi_task_dense_tables_pull\n                    program_configs[program_id]['push_dense'] = multi_task_dense_tables_push\n                else:\n                    program_configs[program_id]['pull_dense'] = [dense_table_index]\n                    program_configs[program_id]['push_dense'] = [dense_table_index]\n                if len(data_norm_params) != 0 and len(data_norm_grads) != 0:\n                    dense_table_index += 1\n                    if strategy.get('datanorm_table') is not None:\n                        server.add_data_norm_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, strategy['datanorm_table'], sparse_table_names)\n                    else:\n                        server.add_data_norm_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, None, sparse_table_names)\n                    worker.add_dense_table(dense_table_index, self._learning_rate, data_norm_params, data_norm_grads, dense_start_table_id, sparse_table_names)\n                    if FLEET_GLOBAL_DICT['enable']:\n                        cur_prog = losses[loss_index].block.program\n                        cur_prog.global_block().append_op(type='push_dense', inputs={'Ids': one_slot}, attrs={'InputNames': [i.name for i in data_norm_grads], 'TableId': dense_table_index, 'ScaleDataNorm': strategy.get('scale_datanorm', -1)})\n                    program_configs[program_id]['pull_dense'].extend([dense_table_index])\n                    program_configs[program_id]['push_dense'].extend([dense_table_index])\n                dense_table_index += 1\n        worker_skipped_ops = ['lookup_table', 'lookup_table_grad']\n        if len(worker.get_desc().skip_op) == 0:\n            worker.get_desc().skip_op.extend(worker_skipped_ops)\n    ps_param.server_param.CopyFrom(server.get_desc())\n    if len(ps_param.trainer_param) == 0:\n        for k in prog_id_to_worker:\n            tp = ps_param.trainer_param.add()\n            tp.CopyFrom(prog_id_to_worker[k].get_desc())\n    if strategy.get('fs_uri') is not None:\n        ps_param.fs_client_param.uri = strategy['fs_uri']\n    elif ps_param.fs_client_param.uri == '':\n        ps_param.fs_client_param.uri = 'hdfs://your_hdfs_uri'\n    if strategy.get('fs_user') is not None:\n        ps_param.fs_client_param.user = strategy['fs_user']\n    elif ps_param.fs_client_param.user == '':\n        ps_param.fs_client_param.user = 'your_hdfs_user'\n    if strategy.get('fs_passwd') is not None:\n        ps_param.fs_client_param.passwd = strategy['fs_passwd']\n    elif ps_param.fs_client_param.passwd == '':\n        ps_param.fs_client_param.passwd = 'your_hdfs_passwd'\n    if strategy.get('fs_hadoop_bin') is not None:\n        ps_param.fs_client_param.hadoop_bin = strategy['fs_hadoop_bin']\n    elif ps_param.fs_client_param.hadoop_bin == '':\n        ps_param.fs_client_param.hadoop_bin = '$HADOOP_HOME/bin/hadoop'\n    opt_info = {}\n    opt_info['program_id_to_worker'] = prog_id_to_worker\n    opt_info['program_configs'] = program_configs\n    opt_info['trainer'] = strategy.get('trainer', 'DistMultiTrainer')\n    opt_info['device_worker'] = strategy.get('device_worker', 'DownpourSGD')\n    opt_info['optimizer'] = 'DownpourSGD'\n    opt_info['fleet_desc'] = ps_param\n    opt_info['worker_skipped_ops'] = worker_skipped_ops\n    opt_info['use_cvm'] = strategy.get('use_cvm', False)\n    opt_info['no_cvm'] = strategy.get('no_cvm', False)\n    opt_info['scale_sparse_gradient_with_batch_size'] = strategy.get('scale_sparse_gradient_with_batch_size', True)\n    opt_info['worker_class'] = strategy.get('worker_class', 'DownpourWorker')\n    opt_info['stat_var_names'] = strategy.get('stat_var_names', [])\n    opt_info['local_tables'] = strategy.get('local_tables', [])\n    opt_info['async_tables'] = strategy.get('async_tables', [])\n    opt_info['async_tables'] = strategy.get('async_tables', [])\n    opt_info['scale_datanorm'] = strategy.get('scale_datanorm', -1)\n    opt_info['check_nan_var_names'] = strategy.get('check_nan_var_names', [])\n    opt_info['dump_slot'] = False\n    opt_info['dump_converter'] = ''\n    opt_info['dump_fields'] = strategy.get('dump_fields', [])\n    opt_info['dump_file_num'] = strategy.get('dump_file_num', 16)\n    opt_info['user_define_dump_filename'] = strategy.get('user_define_dump_filename', '')\n    opt_info['dump_fields_path'] = strategy.get('dump_fields_path', '')\n    opt_info['dump_param'] = strategy.get('dump_param', [])\n    gpus_env = os.getenv('FLAGS_selected_gpus', '0')\n    opt_info['worker_places'] = [int(s) for s in gpus_env.split(',')]\n    opt_info['use_ps_gpu'] = strategy.get('use_ps_gpu', False)\n    if server._server.downpour_server_param.downpour_table_param[0].accessor.accessor_class in ['DownpourCtrAccessor', 'DownpourCtrDoubleAccessor', 'DownpourUnitAccessor', 'DownpourDoubleUnitAccessor', 'DownpourCtrDymfAccessor']:\n        opt_info['dump_slot'] = True\n    elif server._server.downpour_server_param.downpour_table_param[0].accessor.accessor_class == 'DownpourSparseValueAccessor':\n        opt_info['no_cvm'] = True\n    opt_info['adjust_ins_weight'] = strategy.get('adjust_ins_weight', {})\n    opt_info['copy_table'] = strategy.get('copy_table', {})\n    opt_info['loss_names'] = strategy.get('loss_names', [])\n    for loss in losses:\n        loss.block.program._fleet_opt = opt_info\n    param_grads_list = []\n    for loss in losses:\n        prog_id = str(id(loss.block.program))\n        param_grads_list.append(prog_id_to_param_grads[prog_id])\n    return (None, param_grads_list, opt_info)"
        ]
    }
]