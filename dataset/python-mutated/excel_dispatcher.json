[
    {
        "func_name": "_read",
        "original": "@classmethod\ndef _read(cls, io, **kwargs):\n    \"\"\"\n        Read data from `io` according to the passed `read_excel` `kwargs` parameters.\n\n        Parameters\n        ----------\n        io : str, bytes, ExcelFile, xlrd.Book, path object, or file-like object\n            `io` parameter of `read_excel` function.\n        **kwargs : dict\n            Parameters of `read_excel` function.\n\n        Returns\n        -------\n        new_query_compiler : BaseQueryCompiler\n            Query compiler with imported data for further processing.\n        \"\"\"\n    if kwargs.get('engine', None) is not None and kwargs.get('engine') != 'openpyxl':\n        return cls.single_worker_read(io, reason='Modin only implements parallel `read_excel` with `openpyxl` engine, ' + 'please specify `engine=None` or `engine=\"openpyxl\"` to ' + \"use Modin's parallel implementation.\", **kwargs)\n    if kwargs.get('skiprows') is not None:\n        return cls.single_worker_read(io, reason=\"Modin doesn't support 'skiprows' parameter of `read_excel`\", **kwargs)\n    if isinstance(io, bytes):\n        io = BytesIO(io)\n    if not isinstance(io, (str, os.PathLike, BytesIO)) or isinstance(io, (ExcelFile, pandas.ExcelFile)):\n        if isinstance(io, ExcelFile):\n            io._set_pandas_mode()\n        return cls.single_worker_read(io, reason='Modin only implements parallel `read_excel` the following types of `io`: ' + 'str, os.PathLike, io.BytesIO.', **kwargs)\n    from zipfile import ZipFile\n    from openpyxl.reader.excel import ExcelReader\n    from openpyxl.worksheet._reader import WorksheetReader\n    from openpyxl.worksheet.worksheet import Worksheet\n    from modin.core.storage_formats.pandas.parsers import PandasExcelParser\n    sheet_name = kwargs.get('sheet_name', 0)\n    if sheet_name is None or isinstance(sheet_name, list):\n        return cls.single_worker_read(io, reason='`read_excel` functionality is only implemented for a single sheet at a ' + 'time. Multiple sheet reading coming soon!', **kwargs)\n    warnings.warn('Parallel `read_excel` is a new feature! If you run into any ' + 'problems, please visit https://github.com/modin-project/modin/issues. ' + \"If you find a new issue and can't file it on GitHub, please \" + 'email bug_reports@modin.org.')\n    io_file = open(io, 'rb') if isinstance(io, (str, os.PathLike)) else io\n    try:\n        ex = ExcelReader(io_file, read_only=True)\n        ex.read()\n        wb = ex.wb\n        ex.read_manifest()\n        ex.read_strings()\n        ws = Worksheet(wb)\n    finally:\n        if isinstance(io, (str, os.PathLike)):\n            io_file.close()\n    pandas_kw = dict(kwargs)\n    with ZipFile(io) as z:\n        if isinstance(sheet_name, int):\n            sheet_name = 'sheet{}'.format(sheet_name + 1)\n        else:\n            sheet_name = 'sheet{}'.format(wb.sheetnames.index(sheet_name) + 1)\n        if any((sheet_name.lower() in name for name in z.namelist())):\n            sheet_name = sheet_name.lower()\n        elif any((sheet_name.title() in name for name in z.namelist())):\n            sheet_name = sheet_name.title()\n        else:\n            raise ValueError('Sheet {} not found'.format(sheet_name.lower()))\n        kwargs['sheet_name'] = sheet_name\n        f = z.open('xl/worksheets/{}.xml'.format(sheet_name))\n        f = BytesIO(f.read())\n        total_bytes = cls.file_size(f)\n        sheet_block = f.read(EXCEL_READ_BLOCK_SIZE)\n        end_of_row_tag = b'</row>'\n        while end_of_row_tag not in sheet_block:\n            sheet_block += f.read(EXCEL_READ_BLOCK_SIZE)\n        idx_of_header_end = sheet_block.index(end_of_row_tag) + len(end_of_row_tag)\n        sheet_header_with_first_row = sheet_block[:idx_of_header_end]\n        if kwargs['header'] is not None:\n            f.seek(idx_of_header_end)\n            sheet_header = sheet_header_with_first_row\n        else:\n            start_of_row_tag = b'<row'\n            idx_of_header_start = sheet_block.index(start_of_row_tag)\n            sheet_header = sheet_block[:idx_of_header_start]\n            f.seek(idx_of_header_start)\n        kwargs['_header'] = sheet_header\n        footer = b'</sheetData></worksheet>'\n        common_args = (ws, BytesIO(sheet_header_with_first_row + footer), ex.shared_strings, False)\n        if cls.need_rich_text_param():\n            reader = WorksheetReader(*common_args, rich_text=False)\n        else:\n            reader = WorksheetReader(*common_args)\n        reader.bind_cells()\n        data = PandasExcelParser.get_sheet_data(ws, kwargs.get('convert_float', True))\n        if kwargs['header'] is None:\n            column_names = pandas.RangeIndex(len(data[0]))\n        else:\n            column_names = pandas.Index(data[0])\n        index_col = kwargs.get('index_col', None)\n        if index_col is not None:\n            column_names = column_names.drop(column_names[index_col])\n        if not all(column_names) or kwargs.get('usecols'):\n            pandas_kw['nrows'] = 1\n            df = pandas.read_excel(io, **pandas_kw)\n            column_names = df.columns\n        chunk_size = max(1, (total_bytes - f.tell()) // NPartitions.get())\n        (column_widths, num_splits) = cls._define_metadata(pandas.DataFrame(columns=column_names), column_names)\n        kwargs['fname'] = io\n        kwargs['skiprows'] = 0\n        row_count = 0\n        data_ids = []\n        index_ids = []\n        dtypes_ids = []\n        kwargs['num_splits'] = num_splits\n        while f.tell() < total_bytes:\n            args = kwargs\n            args['skiprows'] = row_count + args['skiprows']\n            args['start'] = f.tell()\n            chunk = f.read(chunk_size)\n            if b'<row' not in chunk:\n                break\n            row_close_tag = b'</row>'\n            row_count = re.subn(row_close_tag, b'', chunk)[1]\n            while row_count == 0:\n                chunk += f.read(chunk_size)\n                row_count += re.subn(row_close_tag, b'', chunk)[1]\n            last_index = chunk.rindex(row_close_tag)\n            f.seek(-(len(chunk) - last_index) + len(row_close_tag), 1)\n            args['end'] = f.tell()\n            if b'</row>' not in chunk and b'</sheetData>' in chunk:\n                break\n            remote_results_list = cls.deploy(func=cls.parse, f_kwargs=args, num_returns=num_splits + 2)\n            data_ids.append(remote_results_list[:-2])\n            index_ids.append(remote_results_list[-2])\n            dtypes_ids.append(remote_results_list[-1])\n            if b'</sheetData>' in chunk:\n                break\n    if index_col is None:\n        row_lengths = cls.materialize(index_ids)\n        new_index = pandas.RangeIndex(sum(row_lengths))\n    else:\n        index_objs = cls.materialize(index_ids)\n        row_lengths = [len(o) for o in index_objs]\n        new_index = index_objs[0].append(index_objs[1:])\n    data_ids = cls.build_partition(data_ids, row_lengths, column_widths)\n    dtypes = cls.get_dtypes(dtypes_ids, column_names)\n    new_frame = cls.frame_cls(data_ids, new_index, column_names, row_lengths, column_widths, dtypes=dtypes)\n    new_query_compiler = cls.query_compiler_cls(new_frame)\n    if index_col is None:\n        new_query_compiler._modin_frame.synchronize_labels(axis=0)\n    return new_query_compiler",
        "mutated": [
            "@classmethod\ndef _read(cls, io, **kwargs):\n    if False:\n        i = 10\n    '\\n        Read data from `io` according to the passed `read_excel` `kwargs` parameters.\\n\\n        Parameters\\n        ----------\\n        io : str, bytes, ExcelFile, xlrd.Book, path object, or file-like object\\n            `io` parameter of `read_excel` function.\\n        **kwargs : dict\\n            Parameters of `read_excel` function.\\n\\n        Returns\\n        -------\\n        new_query_compiler : BaseQueryCompiler\\n            Query compiler with imported data for further processing.\\n        '\n    if kwargs.get('engine', None) is not None and kwargs.get('engine') != 'openpyxl':\n        return cls.single_worker_read(io, reason='Modin only implements parallel `read_excel` with `openpyxl` engine, ' + 'please specify `engine=None` or `engine=\"openpyxl\"` to ' + \"use Modin's parallel implementation.\", **kwargs)\n    if kwargs.get('skiprows') is not None:\n        return cls.single_worker_read(io, reason=\"Modin doesn't support 'skiprows' parameter of `read_excel`\", **kwargs)\n    if isinstance(io, bytes):\n        io = BytesIO(io)\n    if not isinstance(io, (str, os.PathLike, BytesIO)) or isinstance(io, (ExcelFile, pandas.ExcelFile)):\n        if isinstance(io, ExcelFile):\n            io._set_pandas_mode()\n        return cls.single_worker_read(io, reason='Modin only implements parallel `read_excel` the following types of `io`: ' + 'str, os.PathLike, io.BytesIO.', **kwargs)\n    from zipfile import ZipFile\n    from openpyxl.reader.excel import ExcelReader\n    from openpyxl.worksheet._reader import WorksheetReader\n    from openpyxl.worksheet.worksheet import Worksheet\n    from modin.core.storage_formats.pandas.parsers import PandasExcelParser\n    sheet_name = kwargs.get('sheet_name', 0)\n    if sheet_name is None or isinstance(sheet_name, list):\n        return cls.single_worker_read(io, reason='`read_excel` functionality is only implemented for a single sheet at a ' + 'time. Multiple sheet reading coming soon!', **kwargs)\n    warnings.warn('Parallel `read_excel` is a new feature! If you run into any ' + 'problems, please visit https://github.com/modin-project/modin/issues. ' + \"If you find a new issue and can't file it on GitHub, please \" + 'email bug_reports@modin.org.')\n    io_file = open(io, 'rb') if isinstance(io, (str, os.PathLike)) else io\n    try:\n        ex = ExcelReader(io_file, read_only=True)\n        ex.read()\n        wb = ex.wb\n        ex.read_manifest()\n        ex.read_strings()\n        ws = Worksheet(wb)\n    finally:\n        if isinstance(io, (str, os.PathLike)):\n            io_file.close()\n    pandas_kw = dict(kwargs)\n    with ZipFile(io) as z:\n        if isinstance(sheet_name, int):\n            sheet_name = 'sheet{}'.format(sheet_name + 1)\n        else:\n            sheet_name = 'sheet{}'.format(wb.sheetnames.index(sheet_name) + 1)\n        if any((sheet_name.lower() in name for name in z.namelist())):\n            sheet_name = sheet_name.lower()\n        elif any((sheet_name.title() in name for name in z.namelist())):\n            sheet_name = sheet_name.title()\n        else:\n            raise ValueError('Sheet {} not found'.format(sheet_name.lower()))\n        kwargs['sheet_name'] = sheet_name\n        f = z.open('xl/worksheets/{}.xml'.format(sheet_name))\n        f = BytesIO(f.read())\n        total_bytes = cls.file_size(f)\n        sheet_block = f.read(EXCEL_READ_BLOCK_SIZE)\n        end_of_row_tag = b'</row>'\n        while end_of_row_tag not in sheet_block:\n            sheet_block += f.read(EXCEL_READ_BLOCK_SIZE)\n        idx_of_header_end = sheet_block.index(end_of_row_tag) + len(end_of_row_tag)\n        sheet_header_with_first_row = sheet_block[:idx_of_header_end]\n        if kwargs['header'] is not None:\n            f.seek(idx_of_header_end)\n            sheet_header = sheet_header_with_first_row\n        else:\n            start_of_row_tag = b'<row'\n            idx_of_header_start = sheet_block.index(start_of_row_tag)\n            sheet_header = sheet_block[:idx_of_header_start]\n            f.seek(idx_of_header_start)\n        kwargs['_header'] = sheet_header\n        footer = b'</sheetData></worksheet>'\n        common_args = (ws, BytesIO(sheet_header_with_first_row + footer), ex.shared_strings, False)\n        if cls.need_rich_text_param():\n            reader = WorksheetReader(*common_args, rich_text=False)\n        else:\n            reader = WorksheetReader(*common_args)\n        reader.bind_cells()\n        data = PandasExcelParser.get_sheet_data(ws, kwargs.get('convert_float', True))\n        if kwargs['header'] is None:\n            column_names = pandas.RangeIndex(len(data[0]))\n        else:\n            column_names = pandas.Index(data[0])\n        index_col = kwargs.get('index_col', None)\n        if index_col is not None:\n            column_names = column_names.drop(column_names[index_col])\n        if not all(column_names) or kwargs.get('usecols'):\n            pandas_kw['nrows'] = 1\n            df = pandas.read_excel(io, **pandas_kw)\n            column_names = df.columns\n        chunk_size = max(1, (total_bytes - f.tell()) // NPartitions.get())\n        (column_widths, num_splits) = cls._define_metadata(pandas.DataFrame(columns=column_names), column_names)\n        kwargs['fname'] = io\n        kwargs['skiprows'] = 0\n        row_count = 0\n        data_ids = []\n        index_ids = []\n        dtypes_ids = []\n        kwargs['num_splits'] = num_splits\n        while f.tell() < total_bytes:\n            args = kwargs\n            args['skiprows'] = row_count + args['skiprows']\n            args['start'] = f.tell()\n            chunk = f.read(chunk_size)\n            if b'<row' not in chunk:\n                break\n            row_close_tag = b'</row>'\n            row_count = re.subn(row_close_tag, b'', chunk)[1]\n            while row_count == 0:\n                chunk += f.read(chunk_size)\n                row_count += re.subn(row_close_tag, b'', chunk)[1]\n            last_index = chunk.rindex(row_close_tag)\n            f.seek(-(len(chunk) - last_index) + len(row_close_tag), 1)\n            args['end'] = f.tell()\n            if b'</row>' not in chunk and b'</sheetData>' in chunk:\n                break\n            remote_results_list = cls.deploy(func=cls.parse, f_kwargs=args, num_returns=num_splits + 2)\n            data_ids.append(remote_results_list[:-2])\n            index_ids.append(remote_results_list[-2])\n            dtypes_ids.append(remote_results_list[-1])\n            if b'</sheetData>' in chunk:\n                break\n    if index_col is None:\n        row_lengths = cls.materialize(index_ids)\n        new_index = pandas.RangeIndex(sum(row_lengths))\n    else:\n        index_objs = cls.materialize(index_ids)\n        row_lengths = [len(o) for o in index_objs]\n        new_index = index_objs[0].append(index_objs[1:])\n    data_ids = cls.build_partition(data_ids, row_lengths, column_widths)\n    dtypes = cls.get_dtypes(dtypes_ids, column_names)\n    new_frame = cls.frame_cls(data_ids, new_index, column_names, row_lengths, column_widths, dtypes=dtypes)\n    new_query_compiler = cls.query_compiler_cls(new_frame)\n    if index_col is None:\n        new_query_compiler._modin_frame.synchronize_labels(axis=0)\n    return new_query_compiler",
            "@classmethod\ndef _read(cls, io, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Read data from `io` according to the passed `read_excel` `kwargs` parameters.\\n\\n        Parameters\\n        ----------\\n        io : str, bytes, ExcelFile, xlrd.Book, path object, or file-like object\\n            `io` parameter of `read_excel` function.\\n        **kwargs : dict\\n            Parameters of `read_excel` function.\\n\\n        Returns\\n        -------\\n        new_query_compiler : BaseQueryCompiler\\n            Query compiler with imported data for further processing.\\n        '\n    if kwargs.get('engine', None) is not None and kwargs.get('engine') != 'openpyxl':\n        return cls.single_worker_read(io, reason='Modin only implements parallel `read_excel` with `openpyxl` engine, ' + 'please specify `engine=None` or `engine=\"openpyxl\"` to ' + \"use Modin's parallel implementation.\", **kwargs)\n    if kwargs.get('skiprows') is not None:\n        return cls.single_worker_read(io, reason=\"Modin doesn't support 'skiprows' parameter of `read_excel`\", **kwargs)\n    if isinstance(io, bytes):\n        io = BytesIO(io)\n    if not isinstance(io, (str, os.PathLike, BytesIO)) or isinstance(io, (ExcelFile, pandas.ExcelFile)):\n        if isinstance(io, ExcelFile):\n            io._set_pandas_mode()\n        return cls.single_worker_read(io, reason='Modin only implements parallel `read_excel` the following types of `io`: ' + 'str, os.PathLike, io.BytesIO.', **kwargs)\n    from zipfile import ZipFile\n    from openpyxl.reader.excel import ExcelReader\n    from openpyxl.worksheet._reader import WorksheetReader\n    from openpyxl.worksheet.worksheet import Worksheet\n    from modin.core.storage_formats.pandas.parsers import PandasExcelParser\n    sheet_name = kwargs.get('sheet_name', 0)\n    if sheet_name is None or isinstance(sheet_name, list):\n        return cls.single_worker_read(io, reason='`read_excel` functionality is only implemented for a single sheet at a ' + 'time. Multiple sheet reading coming soon!', **kwargs)\n    warnings.warn('Parallel `read_excel` is a new feature! If you run into any ' + 'problems, please visit https://github.com/modin-project/modin/issues. ' + \"If you find a new issue and can't file it on GitHub, please \" + 'email bug_reports@modin.org.')\n    io_file = open(io, 'rb') if isinstance(io, (str, os.PathLike)) else io\n    try:\n        ex = ExcelReader(io_file, read_only=True)\n        ex.read()\n        wb = ex.wb\n        ex.read_manifest()\n        ex.read_strings()\n        ws = Worksheet(wb)\n    finally:\n        if isinstance(io, (str, os.PathLike)):\n            io_file.close()\n    pandas_kw = dict(kwargs)\n    with ZipFile(io) as z:\n        if isinstance(sheet_name, int):\n            sheet_name = 'sheet{}'.format(sheet_name + 1)\n        else:\n            sheet_name = 'sheet{}'.format(wb.sheetnames.index(sheet_name) + 1)\n        if any((sheet_name.lower() in name for name in z.namelist())):\n            sheet_name = sheet_name.lower()\n        elif any((sheet_name.title() in name for name in z.namelist())):\n            sheet_name = sheet_name.title()\n        else:\n            raise ValueError('Sheet {} not found'.format(sheet_name.lower()))\n        kwargs['sheet_name'] = sheet_name\n        f = z.open('xl/worksheets/{}.xml'.format(sheet_name))\n        f = BytesIO(f.read())\n        total_bytes = cls.file_size(f)\n        sheet_block = f.read(EXCEL_READ_BLOCK_SIZE)\n        end_of_row_tag = b'</row>'\n        while end_of_row_tag not in sheet_block:\n            sheet_block += f.read(EXCEL_READ_BLOCK_SIZE)\n        idx_of_header_end = sheet_block.index(end_of_row_tag) + len(end_of_row_tag)\n        sheet_header_with_first_row = sheet_block[:idx_of_header_end]\n        if kwargs['header'] is not None:\n            f.seek(idx_of_header_end)\n            sheet_header = sheet_header_with_first_row\n        else:\n            start_of_row_tag = b'<row'\n            idx_of_header_start = sheet_block.index(start_of_row_tag)\n            sheet_header = sheet_block[:idx_of_header_start]\n            f.seek(idx_of_header_start)\n        kwargs['_header'] = sheet_header\n        footer = b'</sheetData></worksheet>'\n        common_args = (ws, BytesIO(sheet_header_with_first_row + footer), ex.shared_strings, False)\n        if cls.need_rich_text_param():\n            reader = WorksheetReader(*common_args, rich_text=False)\n        else:\n            reader = WorksheetReader(*common_args)\n        reader.bind_cells()\n        data = PandasExcelParser.get_sheet_data(ws, kwargs.get('convert_float', True))\n        if kwargs['header'] is None:\n            column_names = pandas.RangeIndex(len(data[0]))\n        else:\n            column_names = pandas.Index(data[0])\n        index_col = kwargs.get('index_col', None)\n        if index_col is not None:\n            column_names = column_names.drop(column_names[index_col])\n        if not all(column_names) or kwargs.get('usecols'):\n            pandas_kw['nrows'] = 1\n            df = pandas.read_excel(io, **pandas_kw)\n            column_names = df.columns\n        chunk_size = max(1, (total_bytes - f.tell()) // NPartitions.get())\n        (column_widths, num_splits) = cls._define_metadata(pandas.DataFrame(columns=column_names), column_names)\n        kwargs['fname'] = io\n        kwargs['skiprows'] = 0\n        row_count = 0\n        data_ids = []\n        index_ids = []\n        dtypes_ids = []\n        kwargs['num_splits'] = num_splits\n        while f.tell() < total_bytes:\n            args = kwargs\n            args['skiprows'] = row_count + args['skiprows']\n            args['start'] = f.tell()\n            chunk = f.read(chunk_size)\n            if b'<row' not in chunk:\n                break\n            row_close_tag = b'</row>'\n            row_count = re.subn(row_close_tag, b'', chunk)[1]\n            while row_count == 0:\n                chunk += f.read(chunk_size)\n                row_count += re.subn(row_close_tag, b'', chunk)[1]\n            last_index = chunk.rindex(row_close_tag)\n            f.seek(-(len(chunk) - last_index) + len(row_close_tag), 1)\n            args['end'] = f.tell()\n            if b'</row>' not in chunk and b'</sheetData>' in chunk:\n                break\n            remote_results_list = cls.deploy(func=cls.parse, f_kwargs=args, num_returns=num_splits + 2)\n            data_ids.append(remote_results_list[:-2])\n            index_ids.append(remote_results_list[-2])\n            dtypes_ids.append(remote_results_list[-1])\n            if b'</sheetData>' in chunk:\n                break\n    if index_col is None:\n        row_lengths = cls.materialize(index_ids)\n        new_index = pandas.RangeIndex(sum(row_lengths))\n    else:\n        index_objs = cls.materialize(index_ids)\n        row_lengths = [len(o) for o in index_objs]\n        new_index = index_objs[0].append(index_objs[1:])\n    data_ids = cls.build_partition(data_ids, row_lengths, column_widths)\n    dtypes = cls.get_dtypes(dtypes_ids, column_names)\n    new_frame = cls.frame_cls(data_ids, new_index, column_names, row_lengths, column_widths, dtypes=dtypes)\n    new_query_compiler = cls.query_compiler_cls(new_frame)\n    if index_col is None:\n        new_query_compiler._modin_frame.synchronize_labels(axis=0)\n    return new_query_compiler",
            "@classmethod\ndef _read(cls, io, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Read data from `io` according to the passed `read_excel` `kwargs` parameters.\\n\\n        Parameters\\n        ----------\\n        io : str, bytes, ExcelFile, xlrd.Book, path object, or file-like object\\n            `io` parameter of `read_excel` function.\\n        **kwargs : dict\\n            Parameters of `read_excel` function.\\n\\n        Returns\\n        -------\\n        new_query_compiler : BaseQueryCompiler\\n            Query compiler with imported data for further processing.\\n        '\n    if kwargs.get('engine', None) is not None and kwargs.get('engine') != 'openpyxl':\n        return cls.single_worker_read(io, reason='Modin only implements parallel `read_excel` with `openpyxl` engine, ' + 'please specify `engine=None` or `engine=\"openpyxl\"` to ' + \"use Modin's parallel implementation.\", **kwargs)\n    if kwargs.get('skiprows') is not None:\n        return cls.single_worker_read(io, reason=\"Modin doesn't support 'skiprows' parameter of `read_excel`\", **kwargs)\n    if isinstance(io, bytes):\n        io = BytesIO(io)\n    if not isinstance(io, (str, os.PathLike, BytesIO)) or isinstance(io, (ExcelFile, pandas.ExcelFile)):\n        if isinstance(io, ExcelFile):\n            io._set_pandas_mode()\n        return cls.single_worker_read(io, reason='Modin only implements parallel `read_excel` the following types of `io`: ' + 'str, os.PathLike, io.BytesIO.', **kwargs)\n    from zipfile import ZipFile\n    from openpyxl.reader.excel import ExcelReader\n    from openpyxl.worksheet._reader import WorksheetReader\n    from openpyxl.worksheet.worksheet import Worksheet\n    from modin.core.storage_formats.pandas.parsers import PandasExcelParser\n    sheet_name = kwargs.get('sheet_name', 0)\n    if sheet_name is None or isinstance(sheet_name, list):\n        return cls.single_worker_read(io, reason='`read_excel` functionality is only implemented for a single sheet at a ' + 'time. Multiple sheet reading coming soon!', **kwargs)\n    warnings.warn('Parallel `read_excel` is a new feature! If you run into any ' + 'problems, please visit https://github.com/modin-project/modin/issues. ' + \"If you find a new issue and can't file it on GitHub, please \" + 'email bug_reports@modin.org.')\n    io_file = open(io, 'rb') if isinstance(io, (str, os.PathLike)) else io\n    try:\n        ex = ExcelReader(io_file, read_only=True)\n        ex.read()\n        wb = ex.wb\n        ex.read_manifest()\n        ex.read_strings()\n        ws = Worksheet(wb)\n    finally:\n        if isinstance(io, (str, os.PathLike)):\n            io_file.close()\n    pandas_kw = dict(kwargs)\n    with ZipFile(io) as z:\n        if isinstance(sheet_name, int):\n            sheet_name = 'sheet{}'.format(sheet_name + 1)\n        else:\n            sheet_name = 'sheet{}'.format(wb.sheetnames.index(sheet_name) + 1)\n        if any((sheet_name.lower() in name for name in z.namelist())):\n            sheet_name = sheet_name.lower()\n        elif any((sheet_name.title() in name for name in z.namelist())):\n            sheet_name = sheet_name.title()\n        else:\n            raise ValueError('Sheet {} not found'.format(sheet_name.lower()))\n        kwargs['sheet_name'] = sheet_name\n        f = z.open('xl/worksheets/{}.xml'.format(sheet_name))\n        f = BytesIO(f.read())\n        total_bytes = cls.file_size(f)\n        sheet_block = f.read(EXCEL_READ_BLOCK_SIZE)\n        end_of_row_tag = b'</row>'\n        while end_of_row_tag not in sheet_block:\n            sheet_block += f.read(EXCEL_READ_BLOCK_SIZE)\n        idx_of_header_end = sheet_block.index(end_of_row_tag) + len(end_of_row_tag)\n        sheet_header_with_first_row = sheet_block[:idx_of_header_end]\n        if kwargs['header'] is not None:\n            f.seek(idx_of_header_end)\n            sheet_header = sheet_header_with_first_row\n        else:\n            start_of_row_tag = b'<row'\n            idx_of_header_start = sheet_block.index(start_of_row_tag)\n            sheet_header = sheet_block[:idx_of_header_start]\n            f.seek(idx_of_header_start)\n        kwargs['_header'] = sheet_header\n        footer = b'</sheetData></worksheet>'\n        common_args = (ws, BytesIO(sheet_header_with_first_row + footer), ex.shared_strings, False)\n        if cls.need_rich_text_param():\n            reader = WorksheetReader(*common_args, rich_text=False)\n        else:\n            reader = WorksheetReader(*common_args)\n        reader.bind_cells()\n        data = PandasExcelParser.get_sheet_data(ws, kwargs.get('convert_float', True))\n        if kwargs['header'] is None:\n            column_names = pandas.RangeIndex(len(data[0]))\n        else:\n            column_names = pandas.Index(data[0])\n        index_col = kwargs.get('index_col', None)\n        if index_col is not None:\n            column_names = column_names.drop(column_names[index_col])\n        if not all(column_names) or kwargs.get('usecols'):\n            pandas_kw['nrows'] = 1\n            df = pandas.read_excel(io, **pandas_kw)\n            column_names = df.columns\n        chunk_size = max(1, (total_bytes - f.tell()) // NPartitions.get())\n        (column_widths, num_splits) = cls._define_metadata(pandas.DataFrame(columns=column_names), column_names)\n        kwargs['fname'] = io\n        kwargs['skiprows'] = 0\n        row_count = 0\n        data_ids = []\n        index_ids = []\n        dtypes_ids = []\n        kwargs['num_splits'] = num_splits\n        while f.tell() < total_bytes:\n            args = kwargs\n            args['skiprows'] = row_count + args['skiprows']\n            args['start'] = f.tell()\n            chunk = f.read(chunk_size)\n            if b'<row' not in chunk:\n                break\n            row_close_tag = b'</row>'\n            row_count = re.subn(row_close_tag, b'', chunk)[1]\n            while row_count == 0:\n                chunk += f.read(chunk_size)\n                row_count += re.subn(row_close_tag, b'', chunk)[1]\n            last_index = chunk.rindex(row_close_tag)\n            f.seek(-(len(chunk) - last_index) + len(row_close_tag), 1)\n            args['end'] = f.tell()\n            if b'</row>' not in chunk and b'</sheetData>' in chunk:\n                break\n            remote_results_list = cls.deploy(func=cls.parse, f_kwargs=args, num_returns=num_splits + 2)\n            data_ids.append(remote_results_list[:-2])\n            index_ids.append(remote_results_list[-2])\n            dtypes_ids.append(remote_results_list[-1])\n            if b'</sheetData>' in chunk:\n                break\n    if index_col is None:\n        row_lengths = cls.materialize(index_ids)\n        new_index = pandas.RangeIndex(sum(row_lengths))\n    else:\n        index_objs = cls.materialize(index_ids)\n        row_lengths = [len(o) for o in index_objs]\n        new_index = index_objs[0].append(index_objs[1:])\n    data_ids = cls.build_partition(data_ids, row_lengths, column_widths)\n    dtypes = cls.get_dtypes(dtypes_ids, column_names)\n    new_frame = cls.frame_cls(data_ids, new_index, column_names, row_lengths, column_widths, dtypes=dtypes)\n    new_query_compiler = cls.query_compiler_cls(new_frame)\n    if index_col is None:\n        new_query_compiler._modin_frame.synchronize_labels(axis=0)\n    return new_query_compiler",
            "@classmethod\ndef _read(cls, io, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Read data from `io` according to the passed `read_excel` `kwargs` parameters.\\n\\n        Parameters\\n        ----------\\n        io : str, bytes, ExcelFile, xlrd.Book, path object, or file-like object\\n            `io` parameter of `read_excel` function.\\n        **kwargs : dict\\n            Parameters of `read_excel` function.\\n\\n        Returns\\n        -------\\n        new_query_compiler : BaseQueryCompiler\\n            Query compiler with imported data for further processing.\\n        '\n    if kwargs.get('engine', None) is not None and kwargs.get('engine') != 'openpyxl':\n        return cls.single_worker_read(io, reason='Modin only implements parallel `read_excel` with `openpyxl` engine, ' + 'please specify `engine=None` or `engine=\"openpyxl\"` to ' + \"use Modin's parallel implementation.\", **kwargs)\n    if kwargs.get('skiprows') is not None:\n        return cls.single_worker_read(io, reason=\"Modin doesn't support 'skiprows' parameter of `read_excel`\", **kwargs)\n    if isinstance(io, bytes):\n        io = BytesIO(io)\n    if not isinstance(io, (str, os.PathLike, BytesIO)) or isinstance(io, (ExcelFile, pandas.ExcelFile)):\n        if isinstance(io, ExcelFile):\n            io._set_pandas_mode()\n        return cls.single_worker_read(io, reason='Modin only implements parallel `read_excel` the following types of `io`: ' + 'str, os.PathLike, io.BytesIO.', **kwargs)\n    from zipfile import ZipFile\n    from openpyxl.reader.excel import ExcelReader\n    from openpyxl.worksheet._reader import WorksheetReader\n    from openpyxl.worksheet.worksheet import Worksheet\n    from modin.core.storage_formats.pandas.parsers import PandasExcelParser\n    sheet_name = kwargs.get('sheet_name', 0)\n    if sheet_name is None or isinstance(sheet_name, list):\n        return cls.single_worker_read(io, reason='`read_excel` functionality is only implemented for a single sheet at a ' + 'time. Multiple sheet reading coming soon!', **kwargs)\n    warnings.warn('Parallel `read_excel` is a new feature! If you run into any ' + 'problems, please visit https://github.com/modin-project/modin/issues. ' + \"If you find a new issue and can't file it on GitHub, please \" + 'email bug_reports@modin.org.')\n    io_file = open(io, 'rb') if isinstance(io, (str, os.PathLike)) else io\n    try:\n        ex = ExcelReader(io_file, read_only=True)\n        ex.read()\n        wb = ex.wb\n        ex.read_manifest()\n        ex.read_strings()\n        ws = Worksheet(wb)\n    finally:\n        if isinstance(io, (str, os.PathLike)):\n            io_file.close()\n    pandas_kw = dict(kwargs)\n    with ZipFile(io) as z:\n        if isinstance(sheet_name, int):\n            sheet_name = 'sheet{}'.format(sheet_name + 1)\n        else:\n            sheet_name = 'sheet{}'.format(wb.sheetnames.index(sheet_name) + 1)\n        if any((sheet_name.lower() in name for name in z.namelist())):\n            sheet_name = sheet_name.lower()\n        elif any((sheet_name.title() in name for name in z.namelist())):\n            sheet_name = sheet_name.title()\n        else:\n            raise ValueError('Sheet {} not found'.format(sheet_name.lower()))\n        kwargs['sheet_name'] = sheet_name\n        f = z.open('xl/worksheets/{}.xml'.format(sheet_name))\n        f = BytesIO(f.read())\n        total_bytes = cls.file_size(f)\n        sheet_block = f.read(EXCEL_READ_BLOCK_SIZE)\n        end_of_row_tag = b'</row>'\n        while end_of_row_tag not in sheet_block:\n            sheet_block += f.read(EXCEL_READ_BLOCK_SIZE)\n        idx_of_header_end = sheet_block.index(end_of_row_tag) + len(end_of_row_tag)\n        sheet_header_with_first_row = sheet_block[:idx_of_header_end]\n        if kwargs['header'] is not None:\n            f.seek(idx_of_header_end)\n            sheet_header = sheet_header_with_first_row\n        else:\n            start_of_row_tag = b'<row'\n            idx_of_header_start = sheet_block.index(start_of_row_tag)\n            sheet_header = sheet_block[:idx_of_header_start]\n            f.seek(idx_of_header_start)\n        kwargs['_header'] = sheet_header\n        footer = b'</sheetData></worksheet>'\n        common_args = (ws, BytesIO(sheet_header_with_first_row + footer), ex.shared_strings, False)\n        if cls.need_rich_text_param():\n            reader = WorksheetReader(*common_args, rich_text=False)\n        else:\n            reader = WorksheetReader(*common_args)\n        reader.bind_cells()\n        data = PandasExcelParser.get_sheet_data(ws, kwargs.get('convert_float', True))\n        if kwargs['header'] is None:\n            column_names = pandas.RangeIndex(len(data[0]))\n        else:\n            column_names = pandas.Index(data[0])\n        index_col = kwargs.get('index_col', None)\n        if index_col is not None:\n            column_names = column_names.drop(column_names[index_col])\n        if not all(column_names) or kwargs.get('usecols'):\n            pandas_kw['nrows'] = 1\n            df = pandas.read_excel(io, **pandas_kw)\n            column_names = df.columns\n        chunk_size = max(1, (total_bytes - f.tell()) // NPartitions.get())\n        (column_widths, num_splits) = cls._define_metadata(pandas.DataFrame(columns=column_names), column_names)\n        kwargs['fname'] = io\n        kwargs['skiprows'] = 0\n        row_count = 0\n        data_ids = []\n        index_ids = []\n        dtypes_ids = []\n        kwargs['num_splits'] = num_splits\n        while f.tell() < total_bytes:\n            args = kwargs\n            args['skiprows'] = row_count + args['skiprows']\n            args['start'] = f.tell()\n            chunk = f.read(chunk_size)\n            if b'<row' not in chunk:\n                break\n            row_close_tag = b'</row>'\n            row_count = re.subn(row_close_tag, b'', chunk)[1]\n            while row_count == 0:\n                chunk += f.read(chunk_size)\n                row_count += re.subn(row_close_tag, b'', chunk)[1]\n            last_index = chunk.rindex(row_close_tag)\n            f.seek(-(len(chunk) - last_index) + len(row_close_tag), 1)\n            args['end'] = f.tell()\n            if b'</row>' not in chunk and b'</sheetData>' in chunk:\n                break\n            remote_results_list = cls.deploy(func=cls.parse, f_kwargs=args, num_returns=num_splits + 2)\n            data_ids.append(remote_results_list[:-2])\n            index_ids.append(remote_results_list[-2])\n            dtypes_ids.append(remote_results_list[-1])\n            if b'</sheetData>' in chunk:\n                break\n    if index_col is None:\n        row_lengths = cls.materialize(index_ids)\n        new_index = pandas.RangeIndex(sum(row_lengths))\n    else:\n        index_objs = cls.materialize(index_ids)\n        row_lengths = [len(o) for o in index_objs]\n        new_index = index_objs[0].append(index_objs[1:])\n    data_ids = cls.build_partition(data_ids, row_lengths, column_widths)\n    dtypes = cls.get_dtypes(dtypes_ids, column_names)\n    new_frame = cls.frame_cls(data_ids, new_index, column_names, row_lengths, column_widths, dtypes=dtypes)\n    new_query_compiler = cls.query_compiler_cls(new_frame)\n    if index_col is None:\n        new_query_compiler._modin_frame.synchronize_labels(axis=0)\n    return new_query_compiler",
            "@classmethod\ndef _read(cls, io, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Read data from `io` according to the passed `read_excel` `kwargs` parameters.\\n\\n        Parameters\\n        ----------\\n        io : str, bytes, ExcelFile, xlrd.Book, path object, or file-like object\\n            `io` parameter of `read_excel` function.\\n        **kwargs : dict\\n            Parameters of `read_excel` function.\\n\\n        Returns\\n        -------\\n        new_query_compiler : BaseQueryCompiler\\n            Query compiler with imported data for further processing.\\n        '\n    if kwargs.get('engine', None) is not None and kwargs.get('engine') != 'openpyxl':\n        return cls.single_worker_read(io, reason='Modin only implements parallel `read_excel` with `openpyxl` engine, ' + 'please specify `engine=None` or `engine=\"openpyxl\"` to ' + \"use Modin's parallel implementation.\", **kwargs)\n    if kwargs.get('skiprows') is not None:\n        return cls.single_worker_read(io, reason=\"Modin doesn't support 'skiprows' parameter of `read_excel`\", **kwargs)\n    if isinstance(io, bytes):\n        io = BytesIO(io)\n    if not isinstance(io, (str, os.PathLike, BytesIO)) or isinstance(io, (ExcelFile, pandas.ExcelFile)):\n        if isinstance(io, ExcelFile):\n            io._set_pandas_mode()\n        return cls.single_worker_read(io, reason='Modin only implements parallel `read_excel` the following types of `io`: ' + 'str, os.PathLike, io.BytesIO.', **kwargs)\n    from zipfile import ZipFile\n    from openpyxl.reader.excel import ExcelReader\n    from openpyxl.worksheet._reader import WorksheetReader\n    from openpyxl.worksheet.worksheet import Worksheet\n    from modin.core.storage_formats.pandas.parsers import PandasExcelParser\n    sheet_name = kwargs.get('sheet_name', 0)\n    if sheet_name is None or isinstance(sheet_name, list):\n        return cls.single_worker_read(io, reason='`read_excel` functionality is only implemented for a single sheet at a ' + 'time. Multiple sheet reading coming soon!', **kwargs)\n    warnings.warn('Parallel `read_excel` is a new feature! If you run into any ' + 'problems, please visit https://github.com/modin-project/modin/issues. ' + \"If you find a new issue and can't file it on GitHub, please \" + 'email bug_reports@modin.org.')\n    io_file = open(io, 'rb') if isinstance(io, (str, os.PathLike)) else io\n    try:\n        ex = ExcelReader(io_file, read_only=True)\n        ex.read()\n        wb = ex.wb\n        ex.read_manifest()\n        ex.read_strings()\n        ws = Worksheet(wb)\n    finally:\n        if isinstance(io, (str, os.PathLike)):\n            io_file.close()\n    pandas_kw = dict(kwargs)\n    with ZipFile(io) as z:\n        if isinstance(sheet_name, int):\n            sheet_name = 'sheet{}'.format(sheet_name + 1)\n        else:\n            sheet_name = 'sheet{}'.format(wb.sheetnames.index(sheet_name) + 1)\n        if any((sheet_name.lower() in name for name in z.namelist())):\n            sheet_name = sheet_name.lower()\n        elif any((sheet_name.title() in name for name in z.namelist())):\n            sheet_name = sheet_name.title()\n        else:\n            raise ValueError('Sheet {} not found'.format(sheet_name.lower()))\n        kwargs['sheet_name'] = sheet_name\n        f = z.open('xl/worksheets/{}.xml'.format(sheet_name))\n        f = BytesIO(f.read())\n        total_bytes = cls.file_size(f)\n        sheet_block = f.read(EXCEL_READ_BLOCK_SIZE)\n        end_of_row_tag = b'</row>'\n        while end_of_row_tag not in sheet_block:\n            sheet_block += f.read(EXCEL_READ_BLOCK_SIZE)\n        idx_of_header_end = sheet_block.index(end_of_row_tag) + len(end_of_row_tag)\n        sheet_header_with_first_row = sheet_block[:idx_of_header_end]\n        if kwargs['header'] is not None:\n            f.seek(idx_of_header_end)\n            sheet_header = sheet_header_with_first_row\n        else:\n            start_of_row_tag = b'<row'\n            idx_of_header_start = sheet_block.index(start_of_row_tag)\n            sheet_header = sheet_block[:idx_of_header_start]\n            f.seek(idx_of_header_start)\n        kwargs['_header'] = sheet_header\n        footer = b'</sheetData></worksheet>'\n        common_args = (ws, BytesIO(sheet_header_with_first_row + footer), ex.shared_strings, False)\n        if cls.need_rich_text_param():\n            reader = WorksheetReader(*common_args, rich_text=False)\n        else:\n            reader = WorksheetReader(*common_args)\n        reader.bind_cells()\n        data = PandasExcelParser.get_sheet_data(ws, kwargs.get('convert_float', True))\n        if kwargs['header'] is None:\n            column_names = pandas.RangeIndex(len(data[0]))\n        else:\n            column_names = pandas.Index(data[0])\n        index_col = kwargs.get('index_col', None)\n        if index_col is not None:\n            column_names = column_names.drop(column_names[index_col])\n        if not all(column_names) or kwargs.get('usecols'):\n            pandas_kw['nrows'] = 1\n            df = pandas.read_excel(io, **pandas_kw)\n            column_names = df.columns\n        chunk_size = max(1, (total_bytes - f.tell()) // NPartitions.get())\n        (column_widths, num_splits) = cls._define_metadata(pandas.DataFrame(columns=column_names), column_names)\n        kwargs['fname'] = io\n        kwargs['skiprows'] = 0\n        row_count = 0\n        data_ids = []\n        index_ids = []\n        dtypes_ids = []\n        kwargs['num_splits'] = num_splits\n        while f.tell() < total_bytes:\n            args = kwargs\n            args['skiprows'] = row_count + args['skiprows']\n            args['start'] = f.tell()\n            chunk = f.read(chunk_size)\n            if b'<row' not in chunk:\n                break\n            row_close_tag = b'</row>'\n            row_count = re.subn(row_close_tag, b'', chunk)[1]\n            while row_count == 0:\n                chunk += f.read(chunk_size)\n                row_count += re.subn(row_close_tag, b'', chunk)[1]\n            last_index = chunk.rindex(row_close_tag)\n            f.seek(-(len(chunk) - last_index) + len(row_close_tag), 1)\n            args['end'] = f.tell()\n            if b'</row>' not in chunk and b'</sheetData>' in chunk:\n                break\n            remote_results_list = cls.deploy(func=cls.parse, f_kwargs=args, num_returns=num_splits + 2)\n            data_ids.append(remote_results_list[:-2])\n            index_ids.append(remote_results_list[-2])\n            dtypes_ids.append(remote_results_list[-1])\n            if b'</sheetData>' in chunk:\n                break\n    if index_col is None:\n        row_lengths = cls.materialize(index_ids)\n        new_index = pandas.RangeIndex(sum(row_lengths))\n    else:\n        index_objs = cls.materialize(index_ids)\n        row_lengths = [len(o) for o in index_objs]\n        new_index = index_objs[0].append(index_objs[1:])\n    data_ids = cls.build_partition(data_ids, row_lengths, column_widths)\n    dtypes = cls.get_dtypes(dtypes_ids, column_names)\n    new_frame = cls.frame_cls(data_ids, new_index, column_names, row_lengths, column_widths, dtypes=dtypes)\n    new_query_compiler = cls.query_compiler_cls(new_frame)\n    if index_col is None:\n        new_query_compiler._modin_frame.synchronize_labels(axis=0)\n    return new_query_compiler"
        ]
    }
]