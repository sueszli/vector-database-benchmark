[
    {
        "func_name": "_read_raw_data",
        "original": "def _read_raw_data(path):\n    \"\"\"\n    Return the raw lines of the train and test files.\n    \"\"\"\n    with zipfile.ZipFile(path) as datafile:\n        return (datafile.read('ml-100k/ua.base').decode().split('\\n'), datafile.read('ml-100k/ua.test').decode().split('\\n'), datafile.read('ml-100k/u.item').decode(errors='ignore').split('\\n'), datafile.read('ml-100k/u.genre').decode(errors='ignore').split('\\n'))",
        "mutated": [
            "def _read_raw_data(path):\n    if False:\n        i = 10\n    '\\n    Return the raw lines of the train and test files.\\n    '\n    with zipfile.ZipFile(path) as datafile:\n        return (datafile.read('ml-100k/ua.base').decode().split('\\n'), datafile.read('ml-100k/ua.test').decode().split('\\n'), datafile.read('ml-100k/u.item').decode(errors='ignore').split('\\n'), datafile.read('ml-100k/u.genre').decode(errors='ignore').split('\\n'))",
            "def _read_raw_data(path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Return the raw lines of the train and test files.\\n    '\n    with zipfile.ZipFile(path) as datafile:\n        return (datafile.read('ml-100k/ua.base').decode().split('\\n'), datafile.read('ml-100k/ua.test').decode().split('\\n'), datafile.read('ml-100k/u.item').decode(errors='ignore').split('\\n'), datafile.read('ml-100k/u.genre').decode(errors='ignore').split('\\n'))",
            "def _read_raw_data(path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Return the raw lines of the train and test files.\\n    '\n    with zipfile.ZipFile(path) as datafile:\n        return (datafile.read('ml-100k/ua.base').decode().split('\\n'), datafile.read('ml-100k/ua.test').decode().split('\\n'), datafile.read('ml-100k/u.item').decode(errors='ignore').split('\\n'), datafile.read('ml-100k/u.genre').decode(errors='ignore').split('\\n'))",
            "def _read_raw_data(path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Return the raw lines of the train and test files.\\n    '\n    with zipfile.ZipFile(path) as datafile:\n        return (datafile.read('ml-100k/ua.base').decode().split('\\n'), datafile.read('ml-100k/ua.test').decode().split('\\n'), datafile.read('ml-100k/u.item').decode(errors='ignore').split('\\n'), datafile.read('ml-100k/u.genre').decode(errors='ignore').split('\\n'))",
            "def _read_raw_data(path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Return the raw lines of the train and test files.\\n    '\n    with zipfile.ZipFile(path) as datafile:\n        return (datafile.read('ml-100k/ua.base').decode().split('\\n'), datafile.read('ml-100k/ua.test').decode().split('\\n'), datafile.read('ml-100k/u.item').decode(errors='ignore').split('\\n'), datafile.read('ml-100k/u.genre').decode(errors='ignore').split('\\n'))"
        ]
    },
    {
        "func_name": "_parse",
        "original": "def _parse(data):\n    for line in data:\n        if not line:\n            continue\n        (uid, iid, rating, timestamp) = [int(x) for x in line.split('\\t')]\n        yield (uid - 1, iid - 1, rating, timestamp)",
        "mutated": [
            "def _parse(data):\n    if False:\n        i = 10\n    for line in data:\n        if not line:\n            continue\n        (uid, iid, rating, timestamp) = [int(x) for x in line.split('\\t')]\n        yield (uid - 1, iid - 1, rating, timestamp)",
            "def _parse(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    for line in data:\n        if not line:\n            continue\n        (uid, iid, rating, timestamp) = [int(x) for x in line.split('\\t')]\n        yield (uid - 1, iid - 1, rating, timestamp)",
            "def _parse(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    for line in data:\n        if not line:\n            continue\n        (uid, iid, rating, timestamp) = [int(x) for x in line.split('\\t')]\n        yield (uid - 1, iid - 1, rating, timestamp)",
            "def _parse(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    for line in data:\n        if not line:\n            continue\n        (uid, iid, rating, timestamp) = [int(x) for x in line.split('\\t')]\n        yield (uid - 1, iid - 1, rating, timestamp)",
            "def _parse(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    for line in data:\n        if not line:\n            continue\n        (uid, iid, rating, timestamp) = [int(x) for x in line.split('\\t')]\n        yield (uid - 1, iid - 1, rating, timestamp)"
        ]
    },
    {
        "func_name": "_get_dimensions",
        "original": "def _get_dimensions(train_data, test_data):\n    uids = set()\n    iids = set()\n    for (uid, iid, _, _) in itertools.chain(train_data, test_data):\n        uids.add(uid)\n        iids.add(iid)\n    rows = max(uids) + 1\n    cols = max(iids) + 1\n    return (rows, cols)",
        "mutated": [
            "def _get_dimensions(train_data, test_data):\n    if False:\n        i = 10\n    uids = set()\n    iids = set()\n    for (uid, iid, _, _) in itertools.chain(train_data, test_data):\n        uids.add(uid)\n        iids.add(iid)\n    rows = max(uids) + 1\n    cols = max(iids) + 1\n    return (rows, cols)",
            "def _get_dimensions(train_data, test_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    uids = set()\n    iids = set()\n    for (uid, iid, _, _) in itertools.chain(train_data, test_data):\n        uids.add(uid)\n        iids.add(iid)\n    rows = max(uids) + 1\n    cols = max(iids) + 1\n    return (rows, cols)",
            "def _get_dimensions(train_data, test_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    uids = set()\n    iids = set()\n    for (uid, iid, _, _) in itertools.chain(train_data, test_data):\n        uids.add(uid)\n        iids.add(iid)\n    rows = max(uids) + 1\n    cols = max(iids) + 1\n    return (rows, cols)",
            "def _get_dimensions(train_data, test_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    uids = set()\n    iids = set()\n    for (uid, iid, _, _) in itertools.chain(train_data, test_data):\n        uids.add(uid)\n        iids.add(iid)\n    rows = max(uids) + 1\n    cols = max(iids) + 1\n    return (rows, cols)",
            "def _get_dimensions(train_data, test_data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    uids = set()\n    iids = set()\n    for (uid, iid, _, _) in itertools.chain(train_data, test_data):\n        uids.add(uid)\n        iids.add(iid)\n    rows = max(uids) + 1\n    cols = max(iids) + 1\n    return (rows, cols)"
        ]
    },
    {
        "func_name": "_build_interaction_matrix",
        "original": "def _build_interaction_matrix(rows, cols, data, min_rating):\n    mat = sp.lil_matrix((rows, cols), dtype=np.int32)\n    for (uid, iid, rating, _) in data:\n        if rating >= min_rating:\n            mat[uid, iid] = rating\n    return mat.tocoo()",
        "mutated": [
            "def _build_interaction_matrix(rows, cols, data, min_rating):\n    if False:\n        i = 10\n    mat = sp.lil_matrix((rows, cols), dtype=np.int32)\n    for (uid, iid, rating, _) in data:\n        if rating >= min_rating:\n            mat[uid, iid] = rating\n    return mat.tocoo()",
            "def _build_interaction_matrix(rows, cols, data, min_rating):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    mat = sp.lil_matrix((rows, cols), dtype=np.int32)\n    for (uid, iid, rating, _) in data:\n        if rating >= min_rating:\n            mat[uid, iid] = rating\n    return mat.tocoo()",
            "def _build_interaction_matrix(rows, cols, data, min_rating):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    mat = sp.lil_matrix((rows, cols), dtype=np.int32)\n    for (uid, iid, rating, _) in data:\n        if rating >= min_rating:\n            mat[uid, iid] = rating\n    return mat.tocoo()",
            "def _build_interaction_matrix(rows, cols, data, min_rating):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    mat = sp.lil_matrix((rows, cols), dtype=np.int32)\n    for (uid, iid, rating, _) in data:\n        if rating >= min_rating:\n            mat[uid, iid] = rating\n    return mat.tocoo()",
            "def _build_interaction_matrix(rows, cols, data, min_rating):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    mat = sp.lil_matrix((rows, cols), dtype=np.int32)\n    for (uid, iid, rating, _) in data:\n        if rating >= min_rating:\n            mat[uid, iid] = rating\n    return mat.tocoo()"
        ]
    },
    {
        "func_name": "_parse_item_metadata",
        "original": "def _parse_item_metadata(num_items, item_metadata_raw, genres_raw):\n    genres = []\n    for line in genres_raw:\n        if line:\n            (genre, gid) = line.split('|')\n            genres.append('genre:{}'.format(genre))\n    id_feature_labels = np.empty(num_items, dtype=str)\n    genre_feature_labels = np.array(genres)\n    id_features = sp.identity(num_items, format='csr', dtype=np.float32)\n    genre_features = sp.lil_matrix((num_items, len(genres)), dtype=np.float32)\n    for line in item_metadata_raw:\n        if not line:\n            continue\n        splt = line.split('|')\n        iid = int(splt[0]) - 1\n        title = splt[1]\n        id_feature_labels[iid] = title\n        item_genres = [idx for (idx, val) in enumerate(splt[5:]) if int(val) > 0]\n        for gid in item_genres:\n            genre_features[iid, gid] = 1.0\n    return (id_features, id_feature_labels, genre_features.tocsr(), genre_feature_labels)",
        "mutated": [
            "def _parse_item_metadata(num_items, item_metadata_raw, genres_raw):\n    if False:\n        i = 10\n    genres = []\n    for line in genres_raw:\n        if line:\n            (genre, gid) = line.split('|')\n            genres.append('genre:{}'.format(genre))\n    id_feature_labels = np.empty(num_items, dtype=str)\n    genre_feature_labels = np.array(genres)\n    id_features = sp.identity(num_items, format='csr', dtype=np.float32)\n    genre_features = sp.lil_matrix((num_items, len(genres)), dtype=np.float32)\n    for line in item_metadata_raw:\n        if not line:\n            continue\n        splt = line.split('|')\n        iid = int(splt[0]) - 1\n        title = splt[1]\n        id_feature_labels[iid] = title\n        item_genres = [idx for (idx, val) in enumerate(splt[5:]) if int(val) > 0]\n        for gid in item_genres:\n            genre_features[iid, gid] = 1.0\n    return (id_features, id_feature_labels, genre_features.tocsr(), genre_feature_labels)",
            "def _parse_item_metadata(num_items, item_metadata_raw, genres_raw):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    genres = []\n    for line in genres_raw:\n        if line:\n            (genre, gid) = line.split('|')\n            genres.append('genre:{}'.format(genre))\n    id_feature_labels = np.empty(num_items, dtype=str)\n    genre_feature_labels = np.array(genres)\n    id_features = sp.identity(num_items, format='csr', dtype=np.float32)\n    genre_features = sp.lil_matrix((num_items, len(genres)), dtype=np.float32)\n    for line in item_metadata_raw:\n        if not line:\n            continue\n        splt = line.split('|')\n        iid = int(splt[0]) - 1\n        title = splt[1]\n        id_feature_labels[iid] = title\n        item_genres = [idx for (idx, val) in enumerate(splt[5:]) if int(val) > 0]\n        for gid in item_genres:\n            genre_features[iid, gid] = 1.0\n    return (id_features, id_feature_labels, genre_features.tocsr(), genre_feature_labels)",
            "def _parse_item_metadata(num_items, item_metadata_raw, genres_raw):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    genres = []\n    for line in genres_raw:\n        if line:\n            (genre, gid) = line.split('|')\n            genres.append('genre:{}'.format(genre))\n    id_feature_labels = np.empty(num_items, dtype=str)\n    genre_feature_labels = np.array(genres)\n    id_features = sp.identity(num_items, format='csr', dtype=np.float32)\n    genre_features = sp.lil_matrix((num_items, len(genres)), dtype=np.float32)\n    for line in item_metadata_raw:\n        if not line:\n            continue\n        splt = line.split('|')\n        iid = int(splt[0]) - 1\n        title = splt[1]\n        id_feature_labels[iid] = title\n        item_genres = [idx for (idx, val) in enumerate(splt[5:]) if int(val) > 0]\n        for gid in item_genres:\n            genre_features[iid, gid] = 1.0\n    return (id_features, id_feature_labels, genre_features.tocsr(), genre_feature_labels)",
            "def _parse_item_metadata(num_items, item_metadata_raw, genres_raw):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    genres = []\n    for line in genres_raw:\n        if line:\n            (genre, gid) = line.split('|')\n            genres.append('genre:{}'.format(genre))\n    id_feature_labels = np.empty(num_items, dtype=str)\n    genre_feature_labels = np.array(genres)\n    id_features = sp.identity(num_items, format='csr', dtype=np.float32)\n    genre_features = sp.lil_matrix((num_items, len(genres)), dtype=np.float32)\n    for line in item_metadata_raw:\n        if not line:\n            continue\n        splt = line.split('|')\n        iid = int(splt[0]) - 1\n        title = splt[1]\n        id_feature_labels[iid] = title\n        item_genres = [idx for (idx, val) in enumerate(splt[5:]) if int(val) > 0]\n        for gid in item_genres:\n            genre_features[iid, gid] = 1.0\n    return (id_features, id_feature_labels, genre_features.tocsr(), genre_feature_labels)",
            "def _parse_item_metadata(num_items, item_metadata_raw, genres_raw):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    genres = []\n    for line in genres_raw:\n        if line:\n            (genre, gid) = line.split('|')\n            genres.append('genre:{}'.format(genre))\n    id_feature_labels = np.empty(num_items, dtype=str)\n    genre_feature_labels = np.array(genres)\n    id_features = sp.identity(num_items, format='csr', dtype=np.float32)\n    genre_features = sp.lil_matrix((num_items, len(genres)), dtype=np.float32)\n    for line in item_metadata_raw:\n        if not line:\n            continue\n        splt = line.split('|')\n        iid = int(splt[0]) - 1\n        title = splt[1]\n        id_feature_labels[iid] = title\n        item_genres = [idx for (idx, val) in enumerate(splt[5:]) if int(val) > 0]\n        for gid in item_genres:\n            genre_features[iid, gid] = 1.0\n    return (id_features, id_feature_labels, genre_features.tocsr(), genre_feature_labels)"
        ]
    },
    {
        "func_name": "fetch_movielens",
        "original": "def fetch_movielens(data_home=None, indicator_features=True, genre_features=False, min_rating=0.0, download_if_missing=True):\n    \"\"\"\n    Fetch the `Movielens 100k dataset <http://grouplens.org/datasets/movielens/100k/>`_.\n\n    The dataset contains 100,000 interactions from 1000 users on 1700 movies,\n    and is exhaustively described in its\n    `README <http://files.grouplens.org/datasets/movielens/ml-100k-README.txt>`_.\n\n    Parameters\n    ----------\n\n    data_home: path, optional\n        Path to the directory in which the downloaded data should be placed.\n        Defaults to ``~/lightfm_data/``.\n    indicator_features: bool, optional\n        Use an [n_items, n_items] identity matrix for item features. When True with genre_features,\n        indicator and genre features are concatenated into a single feature matrix of shape\n        [n_items, n_items + n_genres].\n    genre_features: bool, optional\n        Use a [n_items, n_genres] matrix for item features. When True with item_indicator_features,\n        indicator and genre features are concatenated into a single feature matrix of shape\n        [n_items, n_items + n_genres].\n    min_rating: float, optional\n        Minimum rating to include in the interaction matrix.\n    download_if_missing: bool, optional\n        Download the data if not present. Raises an IOError if False and data is missing.\n\n    Notes\n    -----\n\n    The return value is a dictionary containing the following keys:\n\n    Returns\n    -------\n\n    train: sp.coo_matrix of shape [n_users, n_items]\n         Contains training set interactions.\n    test: sp.coo_matrix of shape [n_users, n_items]\n         Contains testing set interactions.\n    item_features: sp.csr_matrix of shape [n_items, n_item_features]\n         Contains item features.\n    item_feature_labels: np.array of strings of shape [n_item_features,]\n         Labels of item features.\n    item_labels: np.array of strings of shape [n_items,]\n         Items' titles.\n    \"\"\"\n    if not (indicator_features or genre_features):\n        raise ValueError('At least one of item_indicator_features or genre_features must be True')\n    zip_path = _common.get_data(data_home, 'https://github.com/maciejkula/lightfm_datasets/releases/download/v0.1.0/movielens.zip', 'movielens100k', 'movielens.zip', download_if_missing)\n    try:\n        (train_raw, test_raw, item_metadata_raw, genres_raw) = _read_raw_data(zip_path)\n    except zipfile.BadZipFile:\n        os.unlink(zip_path)\n        raise ValueError('Corrupted Movielens download. Check your internet connection and try again.')\n    (num_users, num_items) = _get_dimensions(_parse(train_raw), _parse(test_raw))\n    train = _build_interaction_matrix(num_users, num_items, _parse(train_raw), min_rating)\n    test = _build_interaction_matrix(num_users, num_items, _parse(test_raw), min_rating)\n    assert train.shape == test.shape\n    (id_features, id_feature_labels, genre_features_matrix, genre_feature_labels) = _parse_item_metadata(num_items, item_metadata_raw, genres_raw)\n    assert id_features.shape == (num_items, len(id_feature_labels))\n    assert genre_features_matrix.shape == (num_items, len(genre_feature_labels))\n    if indicator_features and (not genre_features):\n        features = id_features\n        feature_labels = id_feature_labels\n    elif genre_features and (not indicator_features):\n        features = genre_features_matrix\n        feature_labels = genre_feature_labels\n    else:\n        features = sp.hstack([id_features, genre_features_matrix]).tocsr()\n        feature_labels = np.concatenate((id_feature_labels, genre_feature_labels))\n    data = {'train': train, 'test': test, 'item_features': features, 'item_feature_labels': feature_labels, 'item_labels': id_feature_labels}\n    return data",
        "mutated": [
            "def fetch_movielens(data_home=None, indicator_features=True, genre_features=False, min_rating=0.0, download_if_missing=True):\n    if False:\n        i = 10\n    \"\\n    Fetch the `Movielens 100k dataset <http://grouplens.org/datasets/movielens/100k/>`_.\\n\\n    The dataset contains 100,000 interactions from 1000 users on 1700 movies,\\n    and is exhaustively described in its\\n    `README <http://files.grouplens.org/datasets/movielens/ml-100k-README.txt>`_.\\n\\n    Parameters\\n    ----------\\n\\n    data_home: path, optional\\n        Path to the directory in which the downloaded data should be placed.\\n        Defaults to ``~/lightfm_data/``.\\n    indicator_features: bool, optional\\n        Use an [n_items, n_items] identity matrix for item features. When True with genre_features,\\n        indicator and genre features are concatenated into a single feature matrix of shape\\n        [n_items, n_items + n_genres].\\n    genre_features: bool, optional\\n        Use a [n_items, n_genres] matrix for item features. When True with item_indicator_features,\\n        indicator and genre features are concatenated into a single feature matrix of shape\\n        [n_items, n_items + n_genres].\\n    min_rating: float, optional\\n        Minimum rating to include in the interaction matrix.\\n    download_if_missing: bool, optional\\n        Download the data if not present. Raises an IOError if False and data is missing.\\n\\n    Notes\\n    -----\\n\\n    The return value is a dictionary containing the following keys:\\n\\n    Returns\\n    -------\\n\\n    train: sp.coo_matrix of shape [n_users, n_items]\\n         Contains training set interactions.\\n    test: sp.coo_matrix of shape [n_users, n_items]\\n         Contains testing set interactions.\\n    item_features: sp.csr_matrix of shape [n_items, n_item_features]\\n         Contains item features.\\n    item_feature_labels: np.array of strings of shape [n_item_features,]\\n         Labels of item features.\\n    item_labels: np.array of strings of shape [n_items,]\\n         Items' titles.\\n    \"\n    if not (indicator_features or genre_features):\n        raise ValueError('At least one of item_indicator_features or genre_features must be True')\n    zip_path = _common.get_data(data_home, 'https://github.com/maciejkula/lightfm_datasets/releases/download/v0.1.0/movielens.zip', 'movielens100k', 'movielens.zip', download_if_missing)\n    try:\n        (train_raw, test_raw, item_metadata_raw, genres_raw) = _read_raw_data(zip_path)\n    except zipfile.BadZipFile:\n        os.unlink(zip_path)\n        raise ValueError('Corrupted Movielens download. Check your internet connection and try again.')\n    (num_users, num_items) = _get_dimensions(_parse(train_raw), _parse(test_raw))\n    train = _build_interaction_matrix(num_users, num_items, _parse(train_raw), min_rating)\n    test = _build_interaction_matrix(num_users, num_items, _parse(test_raw), min_rating)\n    assert train.shape == test.shape\n    (id_features, id_feature_labels, genre_features_matrix, genre_feature_labels) = _parse_item_metadata(num_items, item_metadata_raw, genres_raw)\n    assert id_features.shape == (num_items, len(id_feature_labels))\n    assert genre_features_matrix.shape == (num_items, len(genre_feature_labels))\n    if indicator_features and (not genre_features):\n        features = id_features\n        feature_labels = id_feature_labels\n    elif genre_features and (not indicator_features):\n        features = genre_features_matrix\n        feature_labels = genre_feature_labels\n    else:\n        features = sp.hstack([id_features, genre_features_matrix]).tocsr()\n        feature_labels = np.concatenate((id_feature_labels, genre_feature_labels))\n    data = {'train': train, 'test': test, 'item_features': features, 'item_feature_labels': feature_labels, 'item_labels': id_feature_labels}\n    return data",
            "def fetch_movielens(data_home=None, indicator_features=True, genre_features=False, min_rating=0.0, download_if_missing=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"\\n    Fetch the `Movielens 100k dataset <http://grouplens.org/datasets/movielens/100k/>`_.\\n\\n    The dataset contains 100,000 interactions from 1000 users on 1700 movies,\\n    and is exhaustively described in its\\n    `README <http://files.grouplens.org/datasets/movielens/ml-100k-README.txt>`_.\\n\\n    Parameters\\n    ----------\\n\\n    data_home: path, optional\\n        Path to the directory in which the downloaded data should be placed.\\n        Defaults to ``~/lightfm_data/``.\\n    indicator_features: bool, optional\\n        Use an [n_items, n_items] identity matrix for item features. When True with genre_features,\\n        indicator and genre features are concatenated into a single feature matrix of shape\\n        [n_items, n_items + n_genres].\\n    genre_features: bool, optional\\n        Use a [n_items, n_genres] matrix for item features. When True with item_indicator_features,\\n        indicator and genre features are concatenated into a single feature matrix of shape\\n        [n_items, n_items + n_genres].\\n    min_rating: float, optional\\n        Minimum rating to include in the interaction matrix.\\n    download_if_missing: bool, optional\\n        Download the data if not present. Raises an IOError if False and data is missing.\\n\\n    Notes\\n    -----\\n\\n    The return value is a dictionary containing the following keys:\\n\\n    Returns\\n    -------\\n\\n    train: sp.coo_matrix of shape [n_users, n_items]\\n         Contains training set interactions.\\n    test: sp.coo_matrix of shape [n_users, n_items]\\n         Contains testing set interactions.\\n    item_features: sp.csr_matrix of shape [n_items, n_item_features]\\n         Contains item features.\\n    item_feature_labels: np.array of strings of shape [n_item_features,]\\n         Labels of item features.\\n    item_labels: np.array of strings of shape [n_items,]\\n         Items' titles.\\n    \"\n    if not (indicator_features or genre_features):\n        raise ValueError('At least one of item_indicator_features or genre_features must be True')\n    zip_path = _common.get_data(data_home, 'https://github.com/maciejkula/lightfm_datasets/releases/download/v0.1.0/movielens.zip', 'movielens100k', 'movielens.zip', download_if_missing)\n    try:\n        (train_raw, test_raw, item_metadata_raw, genres_raw) = _read_raw_data(zip_path)\n    except zipfile.BadZipFile:\n        os.unlink(zip_path)\n        raise ValueError('Corrupted Movielens download. Check your internet connection and try again.')\n    (num_users, num_items) = _get_dimensions(_parse(train_raw), _parse(test_raw))\n    train = _build_interaction_matrix(num_users, num_items, _parse(train_raw), min_rating)\n    test = _build_interaction_matrix(num_users, num_items, _parse(test_raw), min_rating)\n    assert train.shape == test.shape\n    (id_features, id_feature_labels, genre_features_matrix, genre_feature_labels) = _parse_item_metadata(num_items, item_metadata_raw, genres_raw)\n    assert id_features.shape == (num_items, len(id_feature_labels))\n    assert genre_features_matrix.shape == (num_items, len(genre_feature_labels))\n    if indicator_features and (not genre_features):\n        features = id_features\n        feature_labels = id_feature_labels\n    elif genre_features and (not indicator_features):\n        features = genre_features_matrix\n        feature_labels = genre_feature_labels\n    else:\n        features = sp.hstack([id_features, genre_features_matrix]).tocsr()\n        feature_labels = np.concatenate((id_feature_labels, genre_feature_labels))\n    data = {'train': train, 'test': test, 'item_features': features, 'item_feature_labels': feature_labels, 'item_labels': id_feature_labels}\n    return data",
            "def fetch_movielens(data_home=None, indicator_features=True, genre_features=False, min_rating=0.0, download_if_missing=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"\\n    Fetch the `Movielens 100k dataset <http://grouplens.org/datasets/movielens/100k/>`_.\\n\\n    The dataset contains 100,000 interactions from 1000 users on 1700 movies,\\n    and is exhaustively described in its\\n    `README <http://files.grouplens.org/datasets/movielens/ml-100k-README.txt>`_.\\n\\n    Parameters\\n    ----------\\n\\n    data_home: path, optional\\n        Path to the directory in which the downloaded data should be placed.\\n        Defaults to ``~/lightfm_data/``.\\n    indicator_features: bool, optional\\n        Use an [n_items, n_items] identity matrix for item features. When True with genre_features,\\n        indicator and genre features are concatenated into a single feature matrix of shape\\n        [n_items, n_items + n_genres].\\n    genre_features: bool, optional\\n        Use a [n_items, n_genres] matrix for item features. When True with item_indicator_features,\\n        indicator and genre features are concatenated into a single feature matrix of shape\\n        [n_items, n_items + n_genres].\\n    min_rating: float, optional\\n        Minimum rating to include in the interaction matrix.\\n    download_if_missing: bool, optional\\n        Download the data if not present. Raises an IOError if False and data is missing.\\n\\n    Notes\\n    -----\\n\\n    The return value is a dictionary containing the following keys:\\n\\n    Returns\\n    -------\\n\\n    train: sp.coo_matrix of shape [n_users, n_items]\\n         Contains training set interactions.\\n    test: sp.coo_matrix of shape [n_users, n_items]\\n         Contains testing set interactions.\\n    item_features: sp.csr_matrix of shape [n_items, n_item_features]\\n         Contains item features.\\n    item_feature_labels: np.array of strings of shape [n_item_features,]\\n         Labels of item features.\\n    item_labels: np.array of strings of shape [n_items,]\\n         Items' titles.\\n    \"\n    if not (indicator_features or genre_features):\n        raise ValueError('At least one of item_indicator_features or genre_features must be True')\n    zip_path = _common.get_data(data_home, 'https://github.com/maciejkula/lightfm_datasets/releases/download/v0.1.0/movielens.zip', 'movielens100k', 'movielens.zip', download_if_missing)\n    try:\n        (train_raw, test_raw, item_metadata_raw, genres_raw) = _read_raw_data(zip_path)\n    except zipfile.BadZipFile:\n        os.unlink(zip_path)\n        raise ValueError('Corrupted Movielens download. Check your internet connection and try again.')\n    (num_users, num_items) = _get_dimensions(_parse(train_raw), _parse(test_raw))\n    train = _build_interaction_matrix(num_users, num_items, _parse(train_raw), min_rating)\n    test = _build_interaction_matrix(num_users, num_items, _parse(test_raw), min_rating)\n    assert train.shape == test.shape\n    (id_features, id_feature_labels, genre_features_matrix, genre_feature_labels) = _parse_item_metadata(num_items, item_metadata_raw, genres_raw)\n    assert id_features.shape == (num_items, len(id_feature_labels))\n    assert genre_features_matrix.shape == (num_items, len(genre_feature_labels))\n    if indicator_features and (not genre_features):\n        features = id_features\n        feature_labels = id_feature_labels\n    elif genre_features and (not indicator_features):\n        features = genre_features_matrix\n        feature_labels = genre_feature_labels\n    else:\n        features = sp.hstack([id_features, genre_features_matrix]).tocsr()\n        feature_labels = np.concatenate((id_feature_labels, genre_feature_labels))\n    data = {'train': train, 'test': test, 'item_features': features, 'item_feature_labels': feature_labels, 'item_labels': id_feature_labels}\n    return data",
            "def fetch_movielens(data_home=None, indicator_features=True, genre_features=False, min_rating=0.0, download_if_missing=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"\\n    Fetch the `Movielens 100k dataset <http://grouplens.org/datasets/movielens/100k/>`_.\\n\\n    The dataset contains 100,000 interactions from 1000 users on 1700 movies,\\n    and is exhaustively described in its\\n    `README <http://files.grouplens.org/datasets/movielens/ml-100k-README.txt>`_.\\n\\n    Parameters\\n    ----------\\n\\n    data_home: path, optional\\n        Path to the directory in which the downloaded data should be placed.\\n        Defaults to ``~/lightfm_data/``.\\n    indicator_features: bool, optional\\n        Use an [n_items, n_items] identity matrix for item features. When True with genre_features,\\n        indicator and genre features are concatenated into a single feature matrix of shape\\n        [n_items, n_items + n_genres].\\n    genre_features: bool, optional\\n        Use a [n_items, n_genres] matrix for item features. When True with item_indicator_features,\\n        indicator and genre features are concatenated into a single feature matrix of shape\\n        [n_items, n_items + n_genres].\\n    min_rating: float, optional\\n        Minimum rating to include in the interaction matrix.\\n    download_if_missing: bool, optional\\n        Download the data if not present. Raises an IOError if False and data is missing.\\n\\n    Notes\\n    -----\\n\\n    The return value is a dictionary containing the following keys:\\n\\n    Returns\\n    -------\\n\\n    train: sp.coo_matrix of shape [n_users, n_items]\\n         Contains training set interactions.\\n    test: sp.coo_matrix of shape [n_users, n_items]\\n         Contains testing set interactions.\\n    item_features: sp.csr_matrix of shape [n_items, n_item_features]\\n         Contains item features.\\n    item_feature_labels: np.array of strings of shape [n_item_features,]\\n         Labels of item features.\\n    item_labels: np.array of strings of shape [n_items,]\\n         Items' titles.\\n    \"\n    if not (indicator_features or genre_features):\n        raise ValueError('At least one of item_indicator_features or genre_features must be True')\n    zip_path = _common.get_data(data_home, 'https://github.com/maciejkula/lightfm_datasets/releases/download/v0.1.0/movielens.zip', 'movielens100k', 'movielens.zip', download_if_missing)\n    try:\n        (train_raw, test_raw, item_metadata_raw, genres_raw) = _read_raw_data(zip_path)\n    except zipfile.BadZipFile:\n        os.unlink(zip_path)\n        raise ValueError('Corrupted Movielens download. Check your internet connection and try again.')\n    (num_users, num_items) = _get_dimensions(_parse(train_raw), _parse(test_raw))\n    train = _build_interaction_matrix(num_users, num_items, _parse(train_raw), min_rating)\n    test = _build_interaction_matrix(num_users, num_items, _parse(test_raw), min_rating)\n    assert train.shape == test.shape\n    (id_features, id_feature_labels, genre_features_matrix, genre_feature_labels) = _parse_item_metadata(num_items, item_metadata_raw, genres_raw)\n    assert id_features.shape == (num_items, len(id_feature_labels))\n    assert genre_features_matrix.shape == (num_items, len(genre_feature_labels))\n    if indicator_features and (not genre_features):\n        features = id_features\n        feature_labels = id_feature_labels\n    elif genre_features and (not indicator_features):\n        features = genre_features_matrix\n        feature_labels = genre_feature_labels\n    else:\n        features = sp.hstack([id_features, genre_features_matrix]).tocsr()\n        feature_labels = np.concatenate((id_feature_labels, genre_feature_labels))\n    data = {'train': train, 'test': test, 'item_features': features, 'item_feature_labels': feature_labels, 'item_labels': id_feature_labels}\n    return data",
            "def fetch_movielens(data_home=None, indicator_features=True, genre_features=False, min_rating=0.0, download_if_missing=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"\\n    Fetch the `Movielens 100k dataset <http://grouplens.org/datasets/movielens/100k/>`_.\\n\\n    The dataset contains 100,000 interactions from 1000 users on 1700 movies,\\n    and is exhaustively described in its\\n    `README <http://files.grouplens.org/datasets/movielens/ml-100k-README.txt>`_.\\n\\n    Parameters\\n    ----------\\n\\n    data_home: path, optional\\n        Path to the directory in which the downloaded data should be placed.\\n        Defaults to ``~/lightfm_data/``.\\n    indicator_features: bool, optional\\n        Use an [n_items, n_items] identity matrix for item features. When True with genre_features,\\n        indicator and genre features are concatenated into a single feature matrix of shape\\n        [n_items, n_items + n_genres].\\n    genre_features: bool, optional\\n        Use a [n_items, n_genres] matrix for item features. When True with item_indicator_features,\\n        indicator and genre features are concatenated into a single feature matrix of shape\\n        [n_items, n_items + n_genres].\\n    min_rating: float, optional\\n        Minimum rating to include in the interaction matrix.\\n    download_if_missing: bool, optional\\n        Download the data if not present. Raises an IOError if False and data is missing.\\n\\n    Notes\\n    -----\\n\\n    The return value is a dictionary containing the following keys:\\n\\n    Returns\\n    -------\\n\\n    train: sp.coo_matrix of shape [n_users, n_items]\\n         Contains training set interactions.\\n    test: sp.coo_matrix of shape [n_users, n_items]\\n         Contains testing set interactions.\\n    item_features: sp.csr_matrix of shape [n_items, n_item_features]\\n         Contains item features.\\n    item_feature_labels: np.array of strings of shape [n_item_features,]\\n         Labels of item features.\\n    item_labels: np.array of strings of shape [n_items,]\\n         Items' titles.\\n    \"\n    if not (indicator_features or genre_features):\n        raise ValueError('At least one of item_indicator_features or genre_features must be True')\n    zip_path = _common.get_data(data_home, 'https://github.com/maciejkula/lightfm_datasets/releases/download/v0.1.0/movielens.zip', 'movielens100k', 'movielens.zip', download_if_missing)\n    try:\n        (train_raw, test_raw, item_metadata_raw, genres_raw) = _read_raw_data(zip_path)\n    except zipfile.BadZipFile:\n        os.unlink(zip_path)\n        raise ValueError('Corrupted Movielens download. Check your internet connection and try again.')\n    (num_users, num_items) = _get_dimensions(_parse(train_raw), _parse(test_raw))\n    train = _build_interaction_matrix(num_users, num_items, _parse(train_raw), min_rating)\n    test = _build_interaction_matrix(num_users, num_items, _parse(test_raw), min_rating)\n    assert train.shape == test.shape\n    (id_features, id_feature_labels, genre_features_matrix, genre_feature_labels) = _parse_item_metadata(num_items, item_metadata_raw, genres_raw)\n    assert id_features.shape == (num_items, len(id_feature_labels))\n    assert genre_features_matrix.shape == (num_items, len(genre_feature_labels))\n    if indicator_features and (not genre_features):\n        features = id_features\n        feature_labels = id_feature_labels\n    elif genre_features and (not indicator_features):\n        features = genre_features_matrix\n        feature_labels = genre_feature_labels\n    else:\n        features = sp.hstack([id_features, genre_features_matrix]).tocsr()\n        feature_labels = np.concatenate((id_feature_labels, genre_feature_labels))\n    data = {'train': train, 'test': test, 'item_features': features, 'item_feature_labels': feature_labels, 'item_labels': id_feature_labels}\n    return data"
        ]
    }
]