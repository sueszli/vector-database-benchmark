[
    {
        "func_name": "numeric_stats_spark",
        "original": "def numeric_stats_spark(df: DataFrame, summary: dict) -> dict:\n    column = df.columns[0]\n    expr = [F.mean(F.col(column)).alias('mean'), F.stddev(F.col(column)).alias('std'), F.variance(F.col(column)).alias('variance'), F.min(F.col(column)).alias('min'), F.max(F.col(column)).alias('max'), F.kurtosis(F.col(column)).alias('kurtosis'), F.skewness(F.col(column)).alias('skewness'), F.sum(F.col(column)).alias('sum')]\n    return df.agg(*expr).first().asDict()",
        "mutated": [
            "def numeric_stats_spark(df: DataFrame, summary: dict) -> dict:\n    if False:\n        i = 10\n    column = df.columns[0]\n    expr = [F.mean(F.col(column)).alias('mean'), F.stddev(F.col(column)).alias('std'), F.variance(F.col(column)).alias('variance'), F.min(F.col(column)).alias('min'), F.max(F.col(column)).alias('max'), F.kurtosis(F.col(column)).alias('kurtosis'), F.skewness(F.col(column)).alias('skewness'), F.sum(F.col(column)).alias('sum')]\n    return df.agg(*expr).first().asDict()",
            "def numeric_stats_spark(df: DataFrame, summary: dict) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    column = df.columns[0]\n    expr = [F.mean(F.col(column)).alias('mean'), F.stddev(F.col(column)).alias('std'), F.variance(F.col(column)).alias('variance'), F.min(F.col(column)).alias('min'), F.max(F.col(column)).alias('max'), F.kurtosis(F.col(column)).alias('kurtosis'), F.skewness(F.col(column)).alias('skewness'), F.sum(F.col(column)).alias('sum')]\n    return df.agg(*expr).first().asDict()",
            "def numeric_stats_spark(df: DataFrame, summary: dict) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    column = df.columns[0]\n    expr = [F.mean(F.col(column)).alias('mean'), F.stddev(F.col(column)).alias('std'), F.variance(F.col(column)).alias('variance'), F.min(F.col(column)).alias('min'), F.max(F.col(column)).alias('max'), F.kurtosis(F.col(column)).alias('kurtosis'), F.skewness(F.col(column)).alias('skewness'), F.sum(F.col(column)).alias('sum')]\n    return df.agg(*expr).first().asDict()",
            "def numeric_stats_spark(df: DataFrame, summary: dict) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    column = df.columns[0]\n    expr = [F.mean(F.col(column)).alias('mean'), F.stddev(F.col(column)).alias('std'), F.variance(F.col(column)).alias('variance'), F.min(F.col(column)).alias('min'), F.max(F.col(column)).alias('max'), F.kurtosis(F.col(column)).alias('kurtosis'), F.skewness(F.col(column)).alias('skewness'), F.sum(F.col(column)).alias('sum')]\n    return df.agg(*expr).first().asDict()",
            "def numeric_stats_spark(df: DataFrame, summary: dict) -> dict:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    column = df.columns[0]\n    expr = [F.mean(F.col(column)).alias('mean'), F.stddev(F.col(column)).alias('std'), F.variance(F.col(column)).alias('variance'), F.min(F.col(column)).alias('min'), F.max(F.col(column)).alias('max'), F.kurtosis(F.col(column)).alias('kurtosis'), F.skewness(F.col(column)).alias('skewness'), F.sum(F.col(column)).alias('sum')]\n    return df.agg(*expr).first().asDict()"
        ]
    },
    {
        "func_name": "describe_numeric_1d_spark",
        "original": "@describe_numeric_1d.register\ndef describe_numeric_1d_spark(config: Settings, df: DataFrame, summary: dict) -> Tuple[Settings, DataFrame, dict]:\n    \"\"\"Describe a boolean series.\n\n    Args:\n        series: The Series to describe.\n        summary: The dict containing the series description so far.\n\n    Returns:\n        A dict containing calculated series description values.\n    \"\"\"\n    stats = numeric_stats_spark(df, summary)\n    summary['min'] = stats['min']\n    summary['max'] = stats['max']\n    summary['mean'] = stats['mean']\n    summary['std'] = stats['std']\n    summary['variance'] = stats['variance']\n    summary['skewness'] = stats['skewness']\n    summary['kurtosis'] = stats['kurtosis']\n    summary['sum'] = stats['sum']\n    value_counts = summary['value_counts']\n    n_infinite = value_counts.where(F.col(df.columns[0]).isin([np.inf, -np.inf])).agg(F.sum(F.col('count')).alias('count')).first()\n    if n_infinite is None or n_infinite['count'] is None:\n        n_infinite = 0\n    else:\n        n_infinite = n_infinite['count']\n    summary['n_infinite'] = n_infinite\n    n_zeros = value_counts.where(f'{df.columns[0]} = 0').first()\n    if n_zeros is None:\n        n_zeros = 0\n    else:\n        n_zeros = n_zeros['count']\n    summary['n_zeros'] = n_zeros\n    n_negative = value_counts.where(f'{df.columns[0]} < 0').agg(F.sum(F.col('count')).alias('count')).first()\n    if n_negative is None or n_negative['count'] is None:\n        n_negative = 0\n    else:\n        n_negative = n_negative['count']\n    summary['n_negative'] = n_negative\n    quantiles = config.vars.num.quantiles\n    quantile_threshold = 0.05\n    summary.update({f'{percentile:.0%}': value for (percentile, value) in zip(quantiles, df.stat.approxQuantile(f'{df.columns[0]}', quantiles, quantile_threshold))})\n    median = summary['50%']\n    summary['mad'] = df.select(F.abs(F.col(f'{df.columns[0]}').cast('int') - median).alias('abs_dev')).stat.approxQuantile('abs_dev', [0.5], quantile_threshold)[0]\n    summary['p_negative'] = summary['n_negative'] / summary['n']\n    summary['range'] = summary['max'] - summary['min']\n    summary['iqr'] = summary['75%'] - summary['25%']\n    summary['cv'] = summary['std'] / summary['mean'] if summary['mean'] else np.NaN\n    summary['p_zeros'] = summary['n_zeros'] / summary['n']\n    summary['p_infinite'] = summary['n_infinite'] / summary['n']\n    summary['monotonic'] = 0\n    infinity_values = [np.inf, -np.inf]\n    infinity_index = summary['value_counts_without_nan'].index.isin(infinity_values)\n    summary.update(histogram_compute(config, summary['value_counts_without_nan'][~infinity_index].index.values, summary['n_distinct'], weights=summary['value_counts_without_nan'][~infinity_index].values))\n    return (config, df, summary)",
        "mutated": [
            "@describe_numeric_1d.register\ndef describe_numeric_1d_spark(config: Settings, df: DataFrame, summary: dict) -> Tuple[Settings, DataFrame, dict]:\n    if False:\n        i = 10\n    'Describe a boolean series.\\n\\n    Args:\\n        series: The Series to describe.\\n        summary: The dict containing the series description so far.\\n\\n    Returns:\\n        A dict containing calculated series description values.\\n    '\n    stats = numeric_stats_spark(df, summary)\n    summary['min'] = stats['min']\n    summary['max'] = stats['max']\n    summary['mean'] = stats['mean']\n    summary['std'] = stats['std']\n    summary['variance'] = stats['variance']\n    summary['skewness'] = stats['skewness']\n    summary['kurtosis'] = stats['kurtosis']\n    summary['sum'] = stats['sum']\n    value_counts = summary['value_counts']\n    n_infinite = value_counts.where(F.col(df.columns[0]).isin([np.inf, -np.inf])).agg(F.sum(F.col('count')).alias('count')).first()\n    if n_infinite is None or n_infinite['count'] is None:\n        n_infinite = 0\n    else:\n        n_infinite = n_infinite['count']\n    summary['n_infinite'] = n_infinite\n    n_zeros = value_counts.where(f'{df.columns[0]} = 0').first()\n    if n_zeros is None:\n        n_zeros = 0\n    else:\n        n_zeros = n_zeros['count']\n    summary['n_zeros'] = n_zeros\n    n_negative = value_counts.where(f'{df.columns[0]} < 0').agg(F.sum(F.col('count')).alias('count')).first()\n    if n_negative is None or n_negative['count'] is None:\n        n_negative = 0\n    else:\n        n_negative = n_negative['count']\n    summary['n_negative'] = n_negative\n    quantiles = config.vars.num.quantiles\n    quantile_threshold = 0.05\n    summary.update({f'{percentile:.0%}': value for (percentile, value) in zip(quantiles, df.stat.approxQuantile(f'{df.columns[0]}', quantiles, quantile_threshold))})\n    median = summary['50%']\n    summary['mad'] = df.select(F.abs(F.col(f'{df.columns[0]}').cast('int') - median).alias('abs_dev')).stat.approxQuantile('abs_dev', [0.5], quantile_threshold)[0]\n    summary['p_negative'] = summary['n_negative'] / summary['n']\n    summary['range'] = summary['max'] - summary['min']\n    summary['iqr'] = summary['75%'] - summary['25%']\n    summary['cv'] = summary['std'] / summary['mean'] if summary['mean'] else np.NaN\n    summary['p_zeros'] = summary['n_zeros'] / summary['n']\n    summary['p_infinite'] = summary['n_infinite'] / summary['n']\n    summary['monotonic'] = 0\n    infinity_values = [np.inf, -np.inf]\n    infinity_index = summary['value_counts_without_nan'].index.isin(infinity_values)\n    summary.update(histogram_compute(config, summary['value_counts_without_nan'][~infinity_index].index.values, summary['n_distinct'], weights=summary['value_counts_without_nan'][~infinity_index].values))\n    return (config, df, summary)",
            "@describe_numeric_1d.register\ndef describe_numeric_1d_spark(config: Settings, df: DataFrame, summary: dict) -> Tuple[Settings, DataFrame, dict]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Describe a boolean series.\\n\\n    Args:\\n        series: The Series to describe.\\n        summary: The dict containing the series description so far.\\n\\n    Returns:\\n        A dict containing calculated series description values.\\n    '\n    stats = numeric_stats_spark(df, summary)\n    summary['min'] = stats['min']\n    summary['max'] = stats['max']\n    summary['mean'] = stats['mean']\n    summary['std'] = stats['std']\n    summary['variance'] = stats['variance']\n    summary['skewness'] = stats['skewness']\n    summary['kurtosis'] = stats['kurtosis']\n    summary['sum'] = stats['sum']\n    value_counts = summary['value_counts']\n    n_infinite = value_counts.where(F.col(df.columns[0]).isin([np.inf, -np.inf])).agg(F.sum(F.col('count')).alias('count')).first()\n    if n_infinite is None or n_infinite['count'] is None:\n        n_infinite = 0\n    else:\n        n_infinite = n_infinite['count']\n    summary['n_infinite'] = n_infinite\n    n_zeros = value_counts.where(f'{df.columns[0]} = 0').first()\n    if n_zeros is None:\n        n_zeros = 0\n    else:\n        n_zeros = n_zeros['count']\n    summary['n_zeros'] = n_zeros\n    n_negative = value_counts.where(f'{df.columns[0]} < 0').agg(F.sum(F.col('count')).alias('count')).first()\n    if n_negative is None or n_negative['count'] is None:\n        n_negative = 0\n    else:\n        n_negative = n_negative['count']\n    summary['n_negative'] = n_negative\n    quantiles = config.vars.num.quantiles\n    quantile_threshold = 0.05\n    summary.update({f'{percentile:.0%}': value for (percentile, value) in zip(quantiles, df.stat.approxQuantile(f'{df.columns[0]}', quantiles, quantile_threshold))})\n    median = summary['50%']\n    summary['mad'] = df.select(F.abs(F.col(f'{df.columns[0]}').cast('int') - median).alias('abs_dev')).stat.approxQuantile('abs_dev', [0.5], quantile_threshold)[0]\n    summary['p_negative'] = summary['n_negative'] / summary['n']\n    summary['range'] = summary['max'] - summary['min']\n    summary['iqr'] = summary['75%'] - summary['25%']\n    summary['cv'] = summary['std'] / summary['mean'] if summary['mean'] else np.NaN\n    summary['p_zeros'] = summary['n_zeros'] / summary['n']\n    summary['p_infinite'] = summary['n_infinite'] / summary['n']\n    summary['monotonic'] = 0\n    infinity_values = [np.inf, -np.inf]\n    infinity_index = summary['value_counts_without_nan'].index.isin(infinity_values)\n    summary.update(histogram_compute(config, summary['value_counts_without_nan'][~infinity_index].index.values, summary['n_distinct'], weights=summary['value_counts_without_nan'][~infinity_index].values))\n    return (config, df, summary)",
            "@describe_numeric_1d.register\ndef describe_numeric_1d_spark(config: Settings, df: DataFrame, summary: dict) -> Tuple[Settings, DataFrame, dict]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Describe a boolean series.\\n\\n    Args:\\n        series: The Series to describe.\\n        summary: The dict containing the series description so far.\\n\\n    Returns:\\n        A dict containing calculated series description values.\\n    '\n    stats = numeric_stats_spark(df, summary)\n    summary['min'] = stats['min']\n    summary['max'] = stats['max']\n    summary['mean'] = stats['mean']\n    summary['std'] = stats['std']\n    summary['variance'] = stats['variance']\n    summary['skewness'] = stats['skewness']\n    summary['kurtosis'] = stats['kurtosis']\n    summary['sum'] = stats['sum']\n    value_counts = summary['value_counts']\n    n_infinite = value_counts.where(F.col(df.columns[0]).isin([np.inf, -np.inf])).agg(F.sum(F.col('count')).alias('count')).first()\n    if n_infinite is None or n_infinite['count'] is None:\n        n_infinite = 0\n    else:\n        n_infinite = n_infinite['count']\n    summary['n_infinite'] = n_infinite\n    n_zeros = value_counts.where(f'{df.columns[0]} = 0').first()\n    if n_zeros is None:\n        n_zeros = 0\n    else:\n        n_zeros = n_zeros['count']\n    summary['n_zeros'] = n_zeros\n    n_negative = value_counts.where(f'{df.columns[0]} < 0').agg(F.sum(F.col('count')).alias('count')).first()\n    if n_negative is None or n_negative['count'] is None:\n        n_negative = 0\n    else:\n        n_negative = n_negative['count']\n    summary['n_negative'] = n_negative\n    quantiles = config.vars.num.quantiles\n    quantile_threshold = 0.05\n    summary.update({f'{percentile:.0%}': value for (percentile, value) in zip(quantiles, df.stat.approxQuantile(f'{df.columns[0]}', quantiles, quantile_threshold))})\n    median = summary['50%']\n    summary['mad'] = df.select(F.abs(F.col(f'{df.columns[0]}').cast('int') - median).alias('abs_dev')).stat.approxQuantile('abs_dev', [0.5], quantile_threshold)[0]\n    summary['p_negative'] = summary['n_negative'] / summary['n']\n    summary['range'] = summary['max'] - summary['min']\n    summary['iqr'] = summary['75%'] - summary['25%']\n    summary['cv'] = summary['std'] / summary['mean'] if summary['mean'] else np.NaN\n    summary['p_zeros'] = summary['n_zeros'] / summary['n']\n    summary['p_infinite'] = summary['n_infinite'] / summary['n']\n    summary['monotonic'] = 0\n    infinity_values = [np.inf, -np.inf]\n    infinity_index = summary['value_counts_without_nan'].index.isin(infinity_values)\n    summary.update(histogram_compute(config, summary['value_counts_without_nan'][~infinity_index].index.values, summary['n_distinct'], weights=summary['value_counts_without_nan'][~infinity_index].values))\n    return (config, df, summary)",
            "@describe_numeric_1d.register\ndef describe_numeric_1d_spark(config: Settings, df: DataFrame, summary: dict) -> Tuple[Settings, DataFrame, dict]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Describe a boolean series.\\n\\n    Args:\\n        series: The Series to describe.\\n        summary: The dict containing the series description so far.\\n\\n    Returns:\\n        A dict containing calculated series description values.\\n    '\n    stats = numeric_stats_spark(df, summary)\n    summary['min'] = stats['min']\n    summary['max'] = stats['max']\n    summary['mean'] = stats['mean']\n    summary['std'] = stats['std']\n    summary['variance'] = stats['variance']\n    summary['skewness'] = stats['skewness']\n    summary['kurtosis'] = stats['kurtosis']\n    summary['sum'] = stats['sum']\n    value_counts = summary['value_counts']\n    n_infinite = value_counts.where(F.col(df.columns[0]).isin([np.inf, -np.inf])).agg(F.sum(F.col('count')).alias('count')).first()\n    if n_infinite is None or n_infinite['count'] is None:\n        n_infinite = 0\n    else:\n        n_infinite = n_infinite['count']\n    summary['n_infinite'] = n_infinite\n    n_zeros = value_counts.where(f'{df.columns[0]} = 0').first()\n    if n_zeros is None:\n        n_zeros = 0\n    else:\n        n_zeros = n_zeros['count']\n    summary['n_zeros'] = n_zeros\n    n_negative = value_counts.where(f'{df.columns[0]} < 0').agg(F.sum(F.col('count')).alias('count')).first()\n    if n_negative is None or n_negative['count'] is None:\n        n_negative = 0\n    else:\n        n_negative = n_negative['count']\n    summary['n_negative'] = n_negative\n    quantiles = config.vars.num.quantiles\n    quantile_threshold = 0.05\n    summary.update({f'{percentile:.0%}': value for (percentile, value) in zip(quantiles, df.stat.approxQuantile(f'{df.columns[0]}', quantiles, quantile_threshold))})\n    median = summary['50%']\n    summary['mad'] = df.select(F.abs(F.col(f'{df.columns[0]}').cast('int') - median).alias('abs_dev')).stat.approxQuantile('abs_dev', [0.5], quantile_threshold)[0]\n    summary['p_negative'] = summary['n_negative'] / summary['n']\n    summary['range'] = summary['max'] - summary['min']\n    summary['iqr'] = summary['75%'] - summary['25%']\n    summary['cv'] = summary['std'] / summary['mean'] if summary['mean'] else np.NaN\n    summary['p_zeros'] = summary['n_zeros'] / summary['n']\n    summary['p_infinite'] = summary['n_infinite'] / summary['n']\n    summary['monotonic'] = 0\n    infinity_values = [np.inf, -np.inf]\n    infinity_index = summary['value_counts_without_nan'].index.isin(infinity_values)\n    summary.update(histogram_compute(config, summary['value_counts_without_nan'][~infinity_index].index.values, summary['n_distinct'], weights=summary['value_counts_without_nan'][~infinity_index].values))\n    return (config, df, summary)",
            "@describe_numeric_1d.register\ndef describe_numeric_1d_spark(config: Settings, df: DataFrame, summary: dict) -> Tuple[Settings, DataFrame, dict]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Describe a boolean series.\\n\\n    Args:\\n        series: The Series to describe.\\n        summary: The dict containing the series description so far.\\n\\n    Returns:\\n        A dict containing calculated series description values.\\n    '\n    stats = numeric_stats_spark(df, summary)\n    summary['min'] = stats['min']\n    summary['max'] = stats['max']\n    summary['mean'] = stats['mean']\n    summary['std'] = stats['std']\n    summary['variance'] = stats['variance']\n    summary['skewness'] = stats['skewness']\n    summary['kurtosis'] = stats['kurtosis']\n    summary['sum'] = stats['sum']\n    value_counts = summary['value_counts']\n    n_infinite = value_counts.where(F.col(df.columns[0]).isin([np.inf, -np.inf])).agg(F.sum(F.col('count')).alias('count')).first()\n    if n_infinite is None or n_infinite['count'] is None:\n        n_infinite = 0\n    else:\n        n_infinite = n_infinite['count']\n    summary['n_infinite'] = n_infinite\n    n_zeros = value_counts.where(f'{df.columns[0]} = 0').first()\n    if n_zeros is None:\n        n_zeros = 0\n    else:\n        n_zeros = n_zeros['count']\n    summary['n_zeros'] = n_zeros\n    n_negative = value_counts.where(f'{df.columns[0]} < 0').agg(F.sum(F.col('count')).alias('count')).first()\n    if n_negative is None or n_negative['count'] is None:\n        n_negative = 0\n    else:\n        n_negative = n_negative['count']\n    summary['n_negative'] = n_negative\n    quantiles = config.vars.num.quantiles\n    quantile_threshold = 0.05\n    summary.update({f'{percentile:.0%}': value for (percentile, value) in zip(quantiles, df.stat.approxQuantile(f'{df.columns[0]}', quantiles, quantile_threshold))})\n    median = summary['50%']\n    summary['mad'] = df.select(F.abs(F.col(f'{df.columns[0]}').cast('int') - median).alias('abs_dev')).stat.approxQuantile('abs_dev', [0.5], quantile_threshold)[0]\n    summary['p_negative'] = summary['n_negative'] / summary['n']\n    summary['range'] = summary['max'] - summary['min']\n    summary['iqr'] = summary['75%'] - summary['25%']\n    summary['cv'] = summary['std'] / summary['mean'] if summary['mean'] else np.NaN\n    summary['p_zeros'] = summary['n_zeros'] / summary['n']\n    summary['p_infinite'] = summary['n_infinite'] / summary['n']\n    summary['monotonic'] = 0\n    infinity_values = [np.inf, -np.inf]\n    infinity_index = summary['value_counts_without_nan'].index.isin(infinity_values)\n    summary.update(histogram_compute(config, summary['value_counts_without_nan'][~infinity_index].index.values, summary['n_distinct'], weights=summary['value_counts_without_nan'][~infinity_index].values))\n    return (config, df, summary)"
        ]
    }
]