[
    {
        "func_name": "read_data_split_and_search",
        "original": "def read_data_split_and_search():\n    \"\"\"\n    This function provides a simple example on how to tune parameters of a given algorithm\n\n    The BayesianSearch object will save:\n        - A .txt file with all the cases explored and the recommendation quality\n        - A _best_model file which contains the trained model and can be loaded with recommender.load_model()\n        - A _best_parameter file which contains a dictionary with all the fit parameters, it can be passed to recommender.fit(**_best_parameter)\n        - A _best_result_validation file which contains a dictionary with the results of the best solution on the validation\n        - A _best_result_test file which contains a dictionary with the results, on the test set, of the best solution chosen using the validation set\n    \"\"\"\n    dataReader = Movielens1MReader()\n    dataset = dataReader.load_data()\n    (URM_train, URM_test) = split_train_in_two_percentage_global_sample(dataset.get_URM_all(), train_percentage=0.8)\n    (URM_train, URM_validation) = split_train_in_two_percentage_global_sample(URM_train, train_percentage=0.8)\n    output_folder_path = 'result_experiments/'\n    if not os.path.exists(output_folder_path):\n        os.makedirs(output_folder_path)\n    collaborative_algorithm_list = [Random, TopPop, P3alphaRecommender, RP3betaRecommender, ItemKNNCFRecommender, UserKNNCFRecommender, MatrixFactorization_BPR_Cython, MatrixFactorization_FunkSVD_Cython, PureSVDRecommender, SLIM_BPR_Cython, SLIMElasticNetRecommender]\n    from Evaluation.Evaluator import EvaluatorHoldout\n    cutoff_list = [5, 10, 20]\n    metric_to_optimize = 'MAP'\n    cutoff_to_optimize = 10\n    n_cases = 10\n    n_random_starts = int(n_cases / 3)\n    evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=cutoff_list)\n    evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=cutoff_list)\n    runParameterSearch_Collaborative_partial = partial(runHyperparameterSearch_Collaborative, URM_train=URM_train, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, n_cases=n_cases, n_random_starts=n_random_starts, evaluator_validation_earlystopping=evaluator_validation, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, resume_from_saved=True, similarity_type_list=['cosine'], parallelizeKNN=False)\n    pool = multiprocessing.Pool(processes=int(multiprocessing.cpu_count()), maxtasksperchild=1)\n    pool.map(runParameterSearch_Collaborative_partial, collaborative_algorithm_list)\n    for (ICM_name, ICM_object) in dataset.get_loaded_ICM_dict().items():\n        try:\n            runHyperparameterSearch_Content(ItemKNNCBFRecommender, URM_train=URM_train, URM_train_last_test=URM_train + URM_validation, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, parallelizeKNN=True, allow_weighting=True, resume_from_saved=True, similarity_type_list=['cosine'], ICM_name=ICM_name, ICM_object=ICM_object.copy(), n_cases=n_cases, n_random_starts=n_random_starts)\n        except Exception as e:\n            print('On CBF recommender for ICM {} Exception {}'.format(ICM_name, str(e)))\n            traceback.print_exc()\n        try:\n            runHyperparameterSearch_Hybrid(ItemKNN_CFCBF_Hybrid_Recommender, URM_train=URM_train, URM_train_last_test=URM_train + URM_validation, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, parallelizeKNN=True, allow_weighting=True, resume_from_saved=True, similarity_type_list=['cosine'], ICM_name=ICM_name, ICM_object=ICM_object.copy(), n_cases=n_cases, n_random_starts=n_random_starts)\n        except Exception as e:\n            print('On recommender {} Exception {}'.format(ItemKNN_CFCBF_Hybrid_Recommender, str(e)))\n            traceback.print_exc()",
        "mutated": [
            "def read_data_split_and_search():\n    if False:\n        i = 10\n    '\\n    This function provides a simple example on how to tune parameters of a given algorithm\\n\\n    The BayesianSearch object will save:\\n        - A .txt file with all the cases explored and the recommendation quality\\n        - A _best_model file which contains the trained model and can be loaded with recommender.load_model()\\n        - A _best_parameter file which contains a dictionary with all the fit parameters, it can be passed to recommender.fit(**_best_parameter)\\n        - A _best_result_validation file which contains a dictionary with the results of the best solution on the validation\\n        - A _best_result_test file which contains a dictionary with the results, on the test set, of the best solution chosen using the validation set\\n    '\n    dataReader = Movielens1MReader()\n    dataset = dataReader.load_data()\n    (URM_train, URM_test) = split_train_in_two_percentage_global_sample(dataset.get_URM_all(), train_percentage=0.8)\n    (URM_train, URM_validation) = split_train_in_two_percentage_global_sample(URM_train, train_percentage=0.8)\n    output_folder_path = 'result_experiments/'\n    if not os.path.exists(output_folder_path):\n        os.makedirs(output_folder_path)\n    collaborative_algorithm_list = [Random, TopPop, P3alphaRecommender, RP3betaRecommender, ItemKNNCFRecommender, UserKNNCFRecommender, MatrixFactorization_BPR_Cython, MatrixFactorization_FunkSVD_Cython, PureSVDRecommender, SLIM_BPR_Cython, SLIMElasticNetRecommender]\n    from Evaluation.Evaluator import EvaluatorHoldout\n    cutoff_list = [5, 10, 20]\n    metric_to_optimize = 'MAP'\n    cutoff_to_optimize = 10\n    n_cases = 10\n    n_random_starts = int(n_cases / 3)\n    evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=cutoff_list)\n    evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=cutoff_list)\n    runParameterSearch_Collaborative_partial = partial(runHyperparameterSearch_Collaborative, URM_train=URM_train, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, n_cases=n_cases, n_random_starts=n_random_starts, evaluator_validation_earlystopping=evaluator_validation, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, resume_from_saved=True, similarity_type_list=['cosine'], parallelizeKNN=False)\n    pool = multiprocessing.Pool(processes=int(multiprocessing.cpu_count()), maxtasksperchild=1)\n    pool.map(runParameterSearch_Collaborative_partial, collaborative_algorithm_list)\n    for (ICM_name, ICM_object) in dataset.get_loaded_ICM_dict().items():\n        try:\n            runHyperparameterSearch_Content(ItemKNNCBFRecommender, URM_train=URM_train, URM_train_last_test=URM_train + URM_validation, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, parallelizeKNN=True, allow_weighting=True, resume_from_saved=True, similarity_type_list=['cosine'], ICM_name=ICM_name, ICM_object=ICM_object.copy(), n_cases=n_cases, n_random_starts=n_random_starts)\n        except Exception as e:\n            print('On CBF recommender for ICM {} Exception {}'.format(ICM_name, str(e)))\n            traceback.print_exc()\n        try:\n            runHyperparameterSearch_Hybrid(ItemKNN_CFCBF_Hybrid_Recommender, URM_train=URM_train, URM_train_last_test=URM_train + URM_validation, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, parallelizeKNN=True, allow_weighting=True, resume_from_saved=True, similarity_type_list=['cosine'], ICM_name=ICM_name, ICM_object=ICM_object.copy(), n_cases=n_cases, n_random_starts=n_random_starts)\n        except Exception as e:\n            print('On recommender {} Exception {}'.format(ItemKNN_CFCBF_Hybrid_Recommender, str(e)))\n            traceback.print_exc()",
            "def read_data_split_and_search():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    This function provides a simple example on how to tune parameters of a given algorithm\\n\\n    The BayesianSearch object will save:\\n        - A .txt file with all the cases explored and the recommendation quality\\n        - A _best_model file which contains the trained model and can be loaded with recommender.load_model()\\n        - A _best_parameter file which contains a dictionary with all the fit parameters, it can be passed to recommender.fit(**_best_parameter)\\n        - A _best_result_validation file which contains a dictionary with the results of the best solution on the validation\\n        - A _best_result_test file which contains a dictionary with the results, on the test set, of the best solution chosen using the validation set\\n    '\n    dataReader = Movielens1MReader()\n    dataset = dataReader.load_data()\n    (URM_train, URM_test) = split_train_in_two_percentage_global_sample(dataset.get_URM_all(), train_percentage=0.8)\n    (URM_train, URM_validation) = split_train_in_two_percentage_global_sample(URM_train, train_percentage=0.8)\n    output_folder_path = 'result_experiments/'\n    if not os.path.exists(output_folder_path):\n        os.makedirs(output_folder_path)\n    collaborative_algorithm_list = [Random, TopPop, P3alphaRecommender, RP3betaRecommender, ItemKNNCFRecommender, UserKNNCFRecommender, MatrixFactorization_BPR_Cython, MatrixFactorization_FunkSVD_Cython, PureSVDRecommender, SLIM_BPR_Cython, SLIMElasticNetRecommender]\n    from Evaluation.Evaluator import EvaluatorHoldout\n    cutoff_list = [5, 10, 20]\n    metric_to_optimize = 'MAP'\n    cutoff_to_optimize = 10\n    n_cases = 10\n    n_random_starts = int(n_cases / 3)\n    evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=cutoff_list)\n    evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=cutoff_list)\n    runParameterSearch_Collaborative_partial = partial(runHyperparameterSearch_Collaborative, URM_train=URM_train, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, n_cases=n_cases, n_random_starts=n_random_starts, evaluator_validation_earlystopping=evaluator_validation, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, resume_from_saved=True, similarity_type_list=['cosine'], parallelizeKNN=False)\n    pool = multiprocessing.Pool(processes=int(multiprocessing.cpu_count()), maxtasksperchild=1)\n    pool.map(runParameterSearch_Collaborative_partial, collaborative_algorithm_list)\n    for (ICM_name, ICM_object) in dataset.get_loaded_ICM_dict().items():\n        try:\n            runHyperparameterSearch_Content(ItemKNNCBFRecommender, URM_train=URM_train, URM_train_last_test=URM_train + URM_validation, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, parallelizeKNN=True, allow_weighting=True, resume_from_saved=True, similarity_type_list=['cosine'], ICM_name=ICM_name, ICM_object=ICM_object.copy(), n_cases=n_cases, n_random_starts=n_random_starts)\n        except Exception as e:\n            print('On CBF recommender for ICM {} Exception {}'.format(ICM_name, str(e)))\n            traceback.print_exc()\n        try:\n            runHyperparameterSearch_Hybrid(ItemKNN_CFCBF_Hybrid_Recommender, URM_train=URM_train, URM_train_last_test=URM_train + URM_validation, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, parallelizeKNN=True, allow_weighting=True, resume_from_saved=True, similarity_type_list=['cosine'], ICM_name=ICM_name, ICM_object=ICM_object.copy(), n_cases=n_cases, n_random_starts=n_random_starts)\n        except Exception as e:\n            print('On recommender {} Exception {}'.format(ItemKNN_CFCBF_Hybrid_Recommender, str(e)))\n            traceback.print_exc()",
            "def read_data_split_and_search():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    This function provides a simple example on how to tune parameters of a given algorithm\\n\\n    The BayesianSearch object will save:\\n        - A .txt file with all the cases explored and the recommendation quality\\n        - A _best_model file which contains the trained model and can be loaded with recommender.load_model()\\n        - A _best_parameter file which contains a dictionary with all the fit parameters, it can be passed to recommender.fit(**_best_parameter)\\n        - A _best_result_validation file which contains a dictionary with the results of the best solution on the validation\\n        - A _best_result_test file which contains a dictionary with the results, on the test set, of the best solution chosen using the validation set\\n    '\n    dataReader = Movielens1MReader()\n    dataset = dataReader.load_data()\n    (URM_train, URM_test) = split_train_in_two_percentage_global_sample(dataset.get_URM_all(), train_percentage=0.8)\n    (URM_train, URM_validation) = split_train_in_two_percentage_global_sample(URM_train, train_percentage=0.8)\n    output_folder_path = 'result_experiments/'\n    if not os.path.exists(output_folder_path):\n        os.makedirs(output_folder_path)\n    collaborative_algorithm_list = [Random, TopPop, P3alphaRecommender, RP3betaRecommender, ItemKNNCFRecommender, UserKNNCFRecommender, MatrixFactorization_BPR_Cython, MatrixFactorization_FunkSVD_Cython, PureSVDRecommender, SLIM_BPR_Cython, SLIMElasticNetRecommender]\n    from Evaluation.Evaluator import EvaluatorHoldout\n    cutoff_list = [5, 10, 20]\n    metric_to_optimize = 'MAP'\n    cutoff_to_optimize = 10\n    n_cases = 10\n    n_random_starts = int(n_cases / 3)\n    evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=cutoff_list)\n    evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=cutoff_list)\n    runParameterSearch_Collaborative_partial = partial(runHyperparameterSearch_Collaborative, URM_train=URM_train, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, n_cases=n_cases, n_random_starts=n_random_starts, evaluator_validation_earlystopping=evaluator_validation, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, resume_from_saved=True, similarity_type_list=['cosine'], parallelizeKNN=False)\n    pool = multiprocessing.Pool(processes=int(multiprocessing.cpu_count()), maxtasksperchild=1)\n    pool.map(runParameterSearch_Collaborative_partial, collaborative_algorithm_list)\n    for (ICM_name, ICM_object) in dataset.get_loaded_ICM_dict().items():\n        try:\n            runHyperparameterSearch_Content(ItemKNNCBFRecommender, URM_train=URM_train, URM_train_last_test=URM_train + URM_validation, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, parallelizeKNN=True, allow_weighting=True, resume_from_saved=True, similarity_type_list=['cosine'], ICM_name=ICM_name, ICM_object=ICM_object.copy(), n_cases=n_cases, n_random_starts=n_random_starts)\n        except Exception as e:\n            print('On CBF recommender for ICM {} Exception {}'.format(ICM_name, str(e)))\n            traceback.print_exc()\n        try:\n            runHyperparameterSearch_Hybrid(ItemKNN_CFCBF_Hybrid_Recommender, URM_train=URM_train, URM_train_last_test=URM_train + URM_validation, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, parallelizeKNN=True, allow_weighting=True, resume_from_saved=True, similarity_type_list=['cosine'], ICM_name=ICM_name, ICM_object=ICM_object.copy(), n_cases=n_cases, n_random_starts=n_random_starts)\n        except Exception as e:\n            print('On recommender {} Exception {}'.format(ItemKNN_CFCBF_Hybrid_Recommender, str(e)))\n            traceback.print_exc()",
            "def read_data_split_and_search():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    This function provides a simple example on how to tune parameters of a given algorithm\\n\\n    The BayesianSearch object will save:\\n        - A .txt file with all the cases explored and the recommendation quality\\n        - A _best_model file which contains the trained model and can be loaded with recommender.load_model()\\n        - A _best_parameter file which contains a dictionary with all the fit parameters, it can be passed to recommender.fit(**_best_parameter)\\n        - A _best_result_validation file which contains a dictionary with the results of the best solution on the validation\\n        - A _best_result_test file which contains a dictionary with the results, on the test set, of the best solution chosen using the validation set\\n    '\n    dataReader = Movielens1MReader()\n    dataset = dataReader.load_data()\n    (URM_train, URM_test) = split_train_in_two_percentage_global_sample(dataset.get_URM_all(), train_percentage=0.8)\n    (URM_train, URM_validation) = split_train_in_two_percentage_global_sample(URM_train, train_percentage=0.8)\n    output_folder_path = 'result_experiments/'\n    if not os.path.exists(output_folder_path):\n        os.makedirs(output_folder_path)\n    collaborative_algorithm_list = [Random, TopPop, P3alphaRecommender, RP3betaRecommender, ItemKNNCFRecommender, UserKNNCFRecommender, MatrixFactorization_BPR_Cython, MatrixFactorization_FunkSVD_Cython, PureSVDRecommender, SLIM_BPR_Cython, SLIMElasticNetRecommender]\n    from Evaluation.Evaluator import EvaluatorHoldout\n    cutoff_list = [5, 10, 20]\n    metric_to_optimize = 'MAP'\n    cutoff_to_optimize = 10\n    n_cases = 10\n    n_random_starts = int(n_cases / 3)\n    evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=cutoff_list)\n    evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=cutoff_list)\n    runParameterSearch_Collaborative_partial = partial(runHyperparameterSearch_Collaborative, URM_train=URM_train, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, n_cases=n_cases, n_random_starts=n_random_starts, evaluator_validation_earlystopping=evaluator_validation, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, resume_from_saved=True, similarity_type_list=['cosine'], parallelizeKNN=False)\n    pool = multiprocessing.Pool(processes=int(multiprocessing.cpu_count()), maxtasksperchild=1)\n    pool.map(runParameterSearch_Collaborative_partial, collaborative_algorithm_list)\n    for (ICM_name, ICM_object) in dataset.get_loaded_ICM_dict().items():\n        try:\n            runHyperparameterSearch_Content(ItemKNNCBFRecommender, URM_train=URM_train, URM_train_last_test=URM_train + URM_validation, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, parallelizeKNN=True, allow_weighting=True, resume_from_saved=True, similarity_type_list=['cosine'], ICM_name=ICM_name, ICM_object=ICM_object.copy(), n_cases=n_cases, n_random_starts=n_random_starts)\n        except Exception as e:\n            print('On CBF recommender for ICM {} Exception {}'.format(ICM_name, str(e)))\n            traceback.print_exc()\n        try:\n            runHyperparameterSearch_Hybrid(ItemKNN_CFCBF_Hybrid_Recommender, URM_train=URM_train, URM_train_last_test=URM_train + URM_validation, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, parallelizeKNN=True, allow_weighting=True, resume_from_saved=True, similarity_type_list=['cosine'], ICM_name=ICM_name, ICM_object=ICM_object.copy(), n_cases=n_cases, n_random_starts=n_random_starts)\n        except Exception as e:\n            print('On recommender {} Exception {}'.format(ItemKNN_CFCBF_Hybrid_Recommender, str(e)))\n            traceback.print_exc()",
            "def read_data_split_and_search():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    This function provides a simple example on how to tune parameters of a given algorithm\\n\\n    The BayesianSearch object will save:\\n        - A .txt file with all the cases explored and the recommendation quality\\n        - A _best_model file which contains the trained model and can be loaded with recommender.load_model()\\n        - A _best_parameter file which contains a dictionary with all the fit parameters, it can be passed to recommender.fit(**_best_parameter)\\n        - A _best_result_validation file which contains a dictionary with the results of the best solution on the validation\\n        - A _best_result_test file which contains a dictionary with the results, on the test set, of the best solution chosen using the validation set\\n    '\n    dataReader = Movielens1MReader()\n    dataset = dataReader.load_data()\n    (URM_train, URM_test) = split_train_in_two_percentage_global_sample(dataset.get_URM_all(), train_percentage=0.8)\n    (URM_train, URM_validation) = split_train_in_two_percentage_global_sample(URM_train, train_percentage=0.8)\n    output_folder_path = 'result_experiments/'\n    if not os.path.exists(output_folder_path):\n        os.makedirs(output_folder_path)\n    collaborative_algorithm_list = [Random, TopPop, P3alphaRecommender, RP3betaRecommender, ItemKNNCFRecommender, UserKNNCFRecommender, MatrixFactorization_BPR_Cython, MatrixFactorization_FunkSVD_Cython, PureSVDRecommender, SLIM_BPR_Cython, SLIMElasticNetRecommender]\n    from Evaluation.Evaluator import EvaluatorHoldout\n    cutoff_list = [5, 10, 20]\n    metric_to_optimize = 'MAP'\n    cutoff_to_optimize = 10\n    n_cases = 10\n    n_random_starts = int(n_cases / 3)\n    evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=cutoff_list)\n    evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=cutoff_list)\n    runParameterSearch_Collaborative_partial = partial(runHyperparameterSearch_Collaborative, URM_train=URM_train, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, n_cases=n_cases, n_random_starts=n_random_starts, evaluator_validation_earlystopping=evaluator_validation, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, resume_from_saved=True, similarity_type_list=['cosine'], parallelizeKNN=False)\n    pool = multiprocessing.Pool(processes=int(multiprocessing.cpu_count()), maxtasksperchild=1)\n    pool.map(runParameterSearch_Collaborative_partial, collaborative_algorithm_list)\n    for (ICM_name, ICM_object) in dataset.get_loaded_ICM_dict().items():\n        try:\n            runHyperparameterSearch_Content(ItemKNNCBFRecommender, URM_train=URM_train, URM_train_last_test=URM_train + URM_validation, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, parallelizeKNN=True, allow_weighting=True, resume_from_saved=True, similarity_type_list=['cosine'], ICM_name=ICM_name, ICM_object=ICM_object.copy(), n_cases=n_cases, n_random_starts=n_random_starts)\n        except Exception as e:\n            print('On CBF recommender for ICM {} Exception {}'.format(ICM_name, str(e)))\n            traceback.print_exc()\n        try:\n            runHyperparameterSearch_Hybrid(ItemKNN_CFCBF_Hybrid_Recommender, URM_train=URM_train, URM_train_last_test=URM_train + URM_validation, metric_to_optimize=metric_to_optimize, cutoff_to_optimize=cutoff_to_optimize, evaluator_validation=evaluator_validation, evaluator_test=evaluator_test, output_folder_path=output_folder_path, parallelizeKNN=True, allow_weighting=True, resume_from_saved=True, similarity_type_list=['cosine'], ICM_name=ICM_name, ICM_object=ICM_object.copy(), n_cases=n_cases, n_random_starts=n_random_starts)\n        except Exception as e:\n            print('On recommender {} Exception {}'.format(ItemKNN_CFCBF_Hybrid_Recommender, str(e)))\n            traceback.print_exc()"
        ]
    }
]