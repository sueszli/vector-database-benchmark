[
    {
        "func_name": "test_generic_lgssm_forecast",
        "original": "@pytest.mark.parametrize('model_class', ['lgssm', 'lgssmgp'])\n@pytest.mark.parametrize('state_dim', [2, 3])\n@pytest.mark.parametrize('obs_dim', [2, 4])\n@pytest.mark.parametrize('T', [11, 17])\ndef test_generic_lgssm_forecast(model_class, state_dim, obs_dim, T):\n    torch.set_default_dtype(torch.float64)\n    if model_class == 'lgssm':\n        model = GenericLGSSM(state_dim=state_dim, obs_dim=obs_dim, obs_noise_scale_init=0.1 + torch.rand(obs_dim))\n    elif model_class == 'lgssmgp':\n        model = GenericLGSSMWithGPNoiseModel(state_dim=state_dim, obs_dim=obs_dim, nu=1.5, obs_noise_scale_init=0.1 + torch.rand(obs_dim))\n        model.kernel.length_scale = 1e-06 * torch.ones(obs_dim)\n        model.kernel.kernel_scale = 1e-06 * torch.ones(obs_dim)\n    targets = torch.randn(T, obs_dim)\n    filtering_state = model._filter(targets)\n    (actual_loc, actual_cov) = model._forecast(3, filtering_state, include_observation_noise=False)\n    obs_matrix = model.obs_matrix if model_class == 'lgssm' else model.z_obs_matrix\n    trans_matrix = model.trans_matrix if model_class == 'lgssm' else model.z_trans_matrix\n    trans_matrix_sq = torch.mm(trans_matrix, trans_matrix)\n    trans_matrix_cubed = torch.mm(trans_matrix_sq, trans_matrix)\n    trans_obs = torch.mm(trans_matrix, obs_matrix)\n    trans_trans_obs = torch.mm(trans_matrix_sq, obs_matrix)\n    trans_trans_trans_obs = torch.mm(trans_matrix_cubed, obs_matrix)\n    fs_loc = filtering_state.loc if model_class == 'lgssm' else filtering_state.loc[-state_dim:]\n    predicted_mean1 = torch.mm(fs_loc.unsqueeze(-2), trans_obs).squeeze(-2)\n    predicted_mean2 = torch.mm(fs_loc.unsqueeze(-2), trans_trans_obs).squeeze(-2)\n    predicted_mean3 = torch.mm(fs_loc.unsqueeze(-2), trans_trans_trans_obs).squeeze(-2)\n    assert_equal(actual_loc[0], predicted_mean1)\n    assert_equal(actual_loc[1], predicted_mean2)\n    assert_equal(actual_loc[2], predicted_mean3)\n    (fs_covar, process_covar) = (None, None)\n    if model_class == 'lgssm':\n        process_covar = model._get_trans_dist().covariance_matrix\n        fs_covar = filtering_state.covariance_matrix\n    elif model_class == 'lgssmgp':\n        process_covar = model.trans_noise_scale_sq.diag_embed()\n        fs_covar = filtering_state.covariance_matrix[-state_dim:, -state_dim:]\n    predicted_covar1 = torch.mm(trans_obs.t(), torch.mm(fs_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    predicted_covar2 = torch.mm(trans_trans_obs.t(), torch.mm(fs_covar, trans_trans_obs)) + torch.mm(trans_obs.t(), torch.mm(process_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    predicted_covar3 = torch.mm(trans_trans_trans_obs.t(), torch.mm(fs_covar, trans_trans_trans_obs)) + torch.mm(trans_trans_obs.t(), torch.mm(process_covar, trans_trans_obs)) + torch.mm(trans_obs.t(), torch.mm(process_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    assert_equal(actual_cov[0], predicted_covar1)\n    assert_equal(actual_cov[1], predicted_covar2)\n    assert_equal(actual_cov[2], predicted_covar3)",
        "mutated": [
            "@pytest.mark.parametrize('model_class', ['lgssm', 'lgssmgp'])\n@pytest.mark.parametrize('state_dim', [2, 3])\n@pytest.mark.parametrize('obs_dim', [2, 4])\n@pytest.mark.parametrize('T', [11, 17])\ndef test_generic_lgssm_forecast(model_class, state_dim, obs_dim, T):\n    if False:\n        i = 10\n    torch.set_default_dtype(torch.float64)\n    if model_class == 'lgssm':\n        model = GenericLGSSM(state_dim=state_dim, obs_dim=obs_dim, obs_noise_scale_init=0.1 + torch.rand(obs_dim))\n    elif model_class == 'lgssmgp':\n        model = GenericLGSSMWithGPNoiseModel(state_dim=state_dim, obs_dim=obs_dim, nu=1.5, obs_noise_scale_init=0.1 + torch.rand(obs_dim))\n        model.kernel.length_scale = 1e-06 * torch.ones(obs_dim)\n        model.kernel.kernel_scale = 1e-06 * torch.ones(obs_dim)\n    targets = torch.randn(T, obs_dim)\n    filtering_state = model._filter(targets)\n    (actual_loc, actual_cov) = model._forecast(3, filtering_state, include_observation_noise=False)\n    obs_matrix = model.obs_matrix if model_class == 'lgssm' else model.z_obs_matrix\n    trans_matrix = model.trans_matrix if model_class == 'lgssm' else model.z_trans_matrix\n    trans_matrix_sq = torch.mm(trans_matrix, trans_matrix)\n    trans_matrix_cubed = torch.mm(trans_matrix_sq, trans_matrix)\n    trans_obs = torch.mm(trans_matrix, obs_matrix)\n    trans_trans_obs = torch.mm(trans_matrix_sq, obs_matrix)\n    trans_trans_trans_obs = torch.mm(trans_matrix_cubed, obs_matrix)\n    fs_loc = filtering_state.loc if model_class == 'lgssm' else filtering_state.loc[-state_dim:]\n    predicted_mean1 = torch.mm(fs_loc.unsqueeze(-2), trans_obs).squeeze(-2)\n    predicted_mean2 = torch.mm(fs_loc.unsqueeze(-2), trans_trans_obs).squeeze(-2)\n    predicted_mean3 = torch.mm(fs_loc.unsqueeze(-2), trans_trans_trans_obs).squeeze(-2)\n    assert_equal(actual_loc[0], predicted_mean1)\n    assert_equal(actual_loc[1], predicted_mean2)\n    assert_equal(actual_loc[2], predicted_mean3)\n    (fs_covar, process_covar) = (None, None)\n    if model_class == 'lgssm':\n        process_covar = model._get_trans_dist().covariance_matrix\n        fs_covar = filtering_state.covariance_matrix\n    elif model_class == 'lgssmgp':\n        process_covar = model.trans_noise_scale_sq.diag_embed()\n        fs_covar = filtering_state.covariance_matrix[-state_dim:, -state_dim:]\n    predicted_covar1 = torch.mm(trans_obs.t(), torch.mm(fs_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    predicted_covar2 = torch.mm(trans_trans_obs.t(), torch.mm(fs_covar, trans_trans_obs)) + torch.mm(trans_obs.t(), torch.mm(process_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    predicted_covar3 = torch.mm(trans_trans_trans_obs.t(), torch.mm(fs_covar, trans_trans_trans_obs)) + torch.mm(trans_trans_obs.t(), torch.mm(process_covar, trans_trans_obs)) + torch.mm(trans_obs.t(), torch.mm(process_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    assert_equal(actual_cov[0], predicted_covar1)\n    assert_equal(actual_cov[1], predicted_covar2)\n    assert_equal(actual_cov[2], predicted_covar3)",
            "@pytest.mark.parametrize('model_class', ['lgssm', 'lgssmgp'])\n@pytest.mark.parametrize('state_dim', [2, 3])\n@pytest.mark.parametrize('obs_dim', [2, 4])\n@pytest.mark.parametrize('T', [11, 17])\ndef test_generic_lgssm_forecast(model_class, state_dim, obs_dim, T):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    torch.set_default_dtype(torch.float64)\n    if model_class == 'lgssm':\n        model = GenericLGSSM(state_dim=state_dim, obs_dim=obs_dim, obs_noise_scale_init=0.1 + torch.rand(obs_dim))\n    elif model_class == 'lgssmgp':\n        model = GenericLGSSMWithGPNoiseModel(state_dim=state_dim, obs_dim=obs_dim, nu=1.5, obs_noise_scale_init=0.1 + torch.rand(obs_dim))\n        model.kernel.length_scale = 1e-06 * torch.ones(obs_dim)\n        model.kernel.kernel_scale = 1e-06 * torch.ones(obs_dim)\n    targets = torch.randn(T, obs_dim)\n    filtering_state = model._filter(targets)\n    (actual_loc, actual_cov) = model._forecast(3, filtering_state, include_observation_noise=False)\n    obs_matrix = model.obs_matrix if model_class == 'lgssm' else model.z_obs_matrix\n    trans_matrix = model.trans_matrix if model_class == 'lgssm' else model.z_trans_matrix\n    trans_matrix_sq = torch.mm(trans_matrix, trans_matrix)\n    trans_matrix_cubed = torch.mm(trans_matrix_sq, trans_matrix)\n    trans_obs = torch.mm(trans_matrix, obs_matrix)\n    trans_trans_obs = torch.mm(trans_matrix_sq, obs_matrix)\n    trans_trans_trans_obs = torch.mm(trans_matrix_cubed, obs_matrix)\n    fs_loc = filtering_state.loc if model_class == 'lgssm' else filtering_state.loc[-state_dim:]\n    predicted_mean1 = torch.mm(fs_loc.unsqueeze(-2), trans_obs).squeeze(-2)\n    predicted_mean2 = torch.mm(fs_loc.unsqueeze(-2), trans_trans_obs).squeeze(-2)\n    predicted_mean3 = torch.mm(fs_loc.unsqueeze(-2), trans_trans_trans_obs).squeeze(-2)\n    assert_equal(actual_loc[0], predicted_mean1)\n    assert_equal(actual_loc[1], predicted_mean2)\n    assert_equal(actual_loc[2], predicted_mean3)\n    (fs_covar, process_covar) = (None, None)\n    if model_class == 'lgssm':\n        process_covar = model._get_trans_dist().covariance_matrix\n        fs_covar = filtering_state.covariance_matrix\n    elif model_class == 'lgssmgp':\n        process_covar = model.trans_noise_scale_sq.diag_embed()\n        fs_covar = filtering_state.covariance_matrix[-state_dim:, -state_dim:]\n    predicted_covar1 = torch.mm(trans_obs.t(), torch.mm(fs_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    predicted_covar2 = torch.mm(trans_trans_obs.t(), torch.mm(fs_covar, trans_trans_obs)) + torch.mm(trans_obs.t(), torch.mm(process_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    predicted_covar3 = torch.mm(trans_trans_trans_obs.t(), torch.mm(fs_covar, trans_trans_trans_obs)) + torch.mm(trans_trans_obs.t(), torch.mm(process_covar, trans_trans_obs)) + torch.mm(trans_obs.t(), torch.mm(process_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    assert_equal(actual_cov[0], predicted_covar1)\n    assert_equal(actual_cov[1], predicted_covar2)\n    assert_equal(actual_cov[2], predicted_covar3)",
            "@pytest.mark.parametrize('model_class', ['lgssm', 'lgssmgp'])\n@pytest.mark.parametrize('state_dim', [2, 3])\n@pytest.mark.parametrize('obs_dim', [2, 4])\n@pytest.mark.parametrize('T', [11, 17])\ndef test_generic_lgssm_forecast(model_class, state_dim, obs_dim, T):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    torch.set_default_dtype(torch.float64)\n    if model_class == 'lgssm':\n        model = GenericLGSSM(state_dim=state_dim, obs_dim=obs_dim, obs_noise_scale_init=0.1 + torch.rand(obs_dim))\n    elif model_class == 'lgssmgp':\n        model = GenericLGSSMWithGPNoiseModel(state_dim=state_dim, obs_dim=obs_dim, nu=1.5, obs_noise_scale_init=0.1 + torch.rand(obs_dim))\n        model.kernel.length_scale = 1e-06 * torch.ones(obs_dim)\n        model.kernel.kernel_scale = 1e-06 * torch.ones(obs_dim)\n    targets = torch.randn(T, obs_dim)\n    filtering_state = model._filter(targets)\n    (actual_loc, actual_cov) = model._forecast(3, filtering_state, include_observation_noise=False)\n    obs_matrix = model.obs_matrix if model_class == 'lgssm' else model.z_obs_matrix\n    trans_matrix = model.trans_matrix if model_class == 'lgssm' else model.z_trans_matrix\n    trans_matrix_sq = torch.mm(trans_matrix, trans_matrix)\n    trans_matrix_cubed = torch.mm(trans_matrix_sq, trans_matrix)\n    trans_obs = torch.mm(trans_matrix, obs_matrix)\n    trans_trans_obs = torch.mm(trans_matrix_sq, obs_matrix)\n    trans_trans_trans_obs = torch.mm(trans_matrix_cubed, obs_matrix)\n    fs_loc = filtering_state.loc if model_class == 'lgssm' else filtering_state.loc[-state_dim:]\n    predicted_mean1 = torch.mm(fs_loc.unsqueeze(-2), trans_obs).squeeze(-2)\n    predicted_mean2 = torch.mm(fs_loc.unsqueeze(-2), trans_trans_obs).squeeze(-2)\n    predicted_mean3 = torch.mm(fs_loc.unsqueeze(-2), trans_trans_trans_obs).squeeze(-2)\n    assert_equal(actual_loc[0], predicted_mean1)\n    assert_equal(actual_loc[1], predicted_mean2)\n    assert_equal(actual_loc[2], predicted_mean3)\n    (fs_covar, process_covar) = (None, None)\n    if model_class == 'lgssm':\n        process_covar = model._get_trans_dist().covariance_matrix\n        fs_covar = filtering_state.covariance_matrix\n    elif model_class == 'lgssmgp':\n        process_covar = model.trans_noise_scale_sq.diag_embed()\n        fs_covar = filtering_state.covariance_matrix[-state_dim:, -state_dim:]\n    predicted_covar1 = torch.mm(trans_obs.t(), torch.mm(fs_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    predicted_covar2 = torch.mm(trans_trans_obs.t(), torch.mm(fs_covar, trans_trans_obs)) + torch.mm(trans_obs.t(), torch.mm(process_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    predicted_covar3 = torch.mm(trans_trans_trans_obs.t(), torch.mm(fs_covar, trans_trans_trans_obs)) + torch.mm(trans_trans_obs.t(), torch.mm(process_covar, trans_trans_obs)) + torch.mm(trans_obs.t(), torch.mm(process_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    assert_equal(actual_cov[0], predicted_covar1)\n    assert_equal(actual_cov[1], predicted_covar2)\n    assert_equal(actual_cov[2], predicted_covar3)",
            "@pytest.mark.parametrize('model_class', ['lgssm', 'lgssmgp'])\n@pytest.mark.parametrize('state_dim', [2, 3])\n@pytest.mark.parametrize('obs_dim', [2, 4])\n@pytest.mark.parametrize('T', [11, 17])\ndef test_generic_lgssm_forecast(model_class, state_dim, obs_dim, T):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    torch.set_default_dtype(torch.float64)\n    if model_class == 'lgssm':\n        model = GenericLGSSM(state_dim=state_dim, obs_dim=obs_dim, obs_noise_scale_init=0.1 + torch.rand(obs_dim))\n    elif model_class == 'lgssmgp':\n        model = GenericLGSSMWithGPNoiseModel(state_dim=state_dim, obs_dim=obs_dim, nu=1.5, obs_noise_scale_init=0.1 + torch.rand(obs_dim))\n        model.kernel.length_scale = 1e-06 * torch.ones(obs_dim)\n        model.kernel.kernel_scale = 1e-06 * torch.ones(obs_dim)\n    targets = torch.randn(T, obs_dim)\n    filtering_state = model._filter(targets)\n    (actual_loc, actual_cov) = model._forecast(3, filtering_state, include_observation_noise=False)\n    obs_matrix = model.obs_matrix if model_class == 'lgssm' else model.z_obs_matrix\n    trans_matrix = model.trans_matrix if model_class == 'lgssm' else model.z_trans_matrix\n    trans_matrix_sq = torch.mm(trans_matrix, trans_matrix)\n    trans_matrix_cubed = torch.mm(trans_matrix_sq, trans_matrix)\n    trans_obs = torch.mm(trans_matrix, obs_matrix)\n    trans_trans_obs = torch.mm(trans_matrix_sq, obs_matrix)\n    trans_trans_trans_obs = torch.mm(trans_matrix_cubed, obs_matrix)\n    fs_loc = filtering_state.loc if model_class == 'lgssm' else filtering_state.loc[-state_dim:]\n    predicted_mean1 = torch.mm(fs_loc.unsqueeze(-2), trans_obs).squeeze(-2)\n    predicted_mean2 = torch.mm(fs_loc.unsqueeze(-2), trans_trans_obs).squeeze(-2)\n    predicted_mean3 = torch.mm(fs_loc.unsqueeze(-2), trans_trans_trans_obs).squeeze(-2)\n    assert_equal(actual_loc[0], predicted_mean1)\n    assert_equal(actual_loc[1], predicted_mean2)\n    assert_equal(actual_loc[2], predicted_mean3)\n    (fs_covar, process_covar) = (None, None)\n    if model_class == 'lgssm':\n        process_covar = model._get_trans_dist().covariance_matrix\n        fs_covar = filtering_state.covariance_matrix\n    elif model_class == 'lgssmgp':\n        process_covar = model.trans_noise_scale_sq.diag_embed()\n        fs_covar = filtering_state.covariance_matrix[-state_dim:, -state_dim:]\n    predicted_covar1 = torch.mm(trans_obs.t(), torch.mm(fs_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    predicted_covar2 = torch.mm(trans_trans_obs.t(), torch.mm(fs_covar, trans_trans_obs)) + torch.mm(trans_obs.t(), torch.mm(process_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    predicted_covar3 = torch.mm(trans_trans_trans_obs.t(), torch.mm(fs_covar, trans_trans_trans_obs)) + torch.mm(trans_trans_obs.t(), torch.mm(process_covar, trans_trans_obs)) + torch.mm(trans_obs.t(), torch.mm(process_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    assert_equal(actual_cov[0], predicted_covar1)\n    assert_equal(actual_cov[1], predicted_covar2)\n    assert_equal(actual_cov[2], predicted_covar3)",
            "@pytest.mark.parametrize('model_class', ['lgssm', 'lgssmgp'])\n@pytest.mark.parametrize('state_dim', [2, 3])\n@pytest.mark.parametrize('obs_dim', [2, 4])\n@pytest.mark.parametrize('T', [11, 17])\ndef test_generic_lgssm_forecast(model_class, state_dim, obs_dim, T):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    torch.set_default_dtype(torch.float64)\n    if model_class == 'lgssm':\n        model = GenericLGSSM(state_dim=state_dim, obs_dim=obs_dim, obs_noise_scale_init=0.1 + torch.rand(obs_dim))\n    elif model_class == 'lgssmgp':\n        model = GenericLGSSMWithGPNoiseModel(state_dim=state_dim, obs_dim=obs_dim, nu=1.5, obs_noise_scale_init=0.1 + torch.rand(obs_dim))\n        model.kernel.length_scale = 1e-06 * torch.ones(obs_dim)\n        model.kernel.kernel_scale = 1e-06 * torch.ones(obs_dim)\n    targets = torch.randn(T, obs_dim)\n    filtering_state = model._filter(targets)\n    (actual_loc, actual_cov) = model._forecast(3, filtering_state, include_observation_noise=False)\n    obs_matrix = model.obs_matrix if model_class == 'lgssm' else model.z_obs_matrix\n    trans_matrix = model.trans_matrix if model_class == 'lgssm' else model.z_trans_matrix\n    trans_matrix_sq = torch.mm(trans_matrix, trans_matrix)\n    trans_matrix_cubed = torch.mm(trans_matrix_sq, trans_matrix)\n    trans_obs = torch.mm(trans_matrix, obs_matrix)\n    trans_trans_obs = torch.mm(trans_matrix_sq, obs_matrix)\n    trans_trans_trans_obs = torch.mm(trans_matrix_cubed, obs_matrix)\n    fs_loc = filtering_state.loc if model_class == 'lgssm' else filtering_state.loc[-state_dim:]\n    predicted_mean1 = torch.mm(fs_loc.unsqueeze(-2), trans_obs).squeeze(-2)\n    predicted_mean2 = torch.mm(fs_loc.unsqueeze(-2), trans_trans_obs).squeeze(-2)\n    predicted_mean3 = torch.mm(fs_loc.unsqueeze(-2), trans_trans_trans_obs).squeeze(-2)\n    assert_equal(actual_loc[0], predicted_mean1)\n    assert_equal(actual_loc[1], predicted_mean2)\n    assert_equal(actual_loc[2], predicted_mean3)\n    (fs_covar, process_covar) = (None, None)\n    if model_class == 'lgssm':\n        process_covar = model._get_trans_dist().covariance_matrix\n        fs_covar = filtering_state.covariance_matrix\n    elif model_class == 'lgssmgp':\n        process_covar = model.trans_noise_scale_sq.diag_embed()\n        fs_covar = filtering_state.covariance_matrix[-state_dim:, -state_dim:]\n    predicted_covar1 = torch.mm(trans_obs.t(), torch.mm(fs_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    predicted_covar2 = torch.mm(trans_trans_obs.t(), torch.mm(fs_covar, trans_trans_obs)) + torch.mm(trans_obs.t(), torch.mm(process_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    predicted_covar3 = torch.mm(trans_trans_trans_obs.t(), torch.mm(fs_covar, trans_trans_trans_obs)) + torch.mm(trans_trans_obs.t(), torch.mm(process_covar, trans_trans_obs)) + torch.mm(trans_obs.t(), torch.mm(process_covar, trans_obs)) + torch.mm(obs_matrix.t(), torch.mm(process_covar, obs_matrix))\n    assert_equal(actual_cov[0], predicted_covar1)\n    assert_equal(actual_cov[1], predicted_covar2)\n    assert_equal(actual_cov[2], predicted_covar3)"
        ]
    }
]