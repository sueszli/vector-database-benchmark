[
    {
        "func_name": "test_getitem",
        "original": "def test_getitem():\n    np.random.seed(0)\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    img_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='RandomFlip3D', flip_ratio_bev_horizontal=1.0), dict(type='Normalize', **img_norm_cfg), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file='tests/data/kitti/kitti_infos_mono3d.coco.json', info_file='tests/data/kitti/kitti_infos_mono3d.pkl', pipeline=pipeline, data_root='tests/data/kitti/', img_prefix='tests/data/kitti/', test_mode=False)\n    data = kitti_dataset[0]\n    img_metas = data['img_metas']._data\n    filename = img_metas['filename']\n    img_shape = img_metas['img_shape']\n    pad_shape = img_metas['pad_shape']\n    flip = img_metas['flip']\n    bboxes = data['gt_bboxes']._data\n    labels3d = data['gt_labels_3d']._data\n    labels = data['gt_labels']._data\n    centers2d = data['centers2d']._data\n    depths = data['depths']._data\n    expected_filename = 'tests/data/kitti/training/image_2/000007.png'\n    expected_img_shape = (375, 1242, 3)\n    expected_pad_shape = (384, 1248, 3)\n    expected_flip = True\n    expected_bboxes = torch.tensor([[625.3445, 175.012, 676.5177, 224.9605], [729.5906, 179.8571, 760.1503, 202.539], [676.7557, 175.7334, 699.7753, 193.9447], [886.5021, 176.138, 911.1581, 213.8148]])\n    expected_labels = torch.tensor([2, 2, 2, 1])\n    expected_centers2d = torch.tensor([[650.6185, 198.3731], [744.2711, 190.7532], [687.8787, 184.5331], [898.475, 194.4337]])\n    expected_depths = torch.tensor([25.0127, 47.5527, 60.5227, 34.0927])\n    assert filename == expected_filename\n    assert img_shape == expected_img_shape\n    assert pad_shape == expected_pad_shape\n    assert flip == expected_flip\n    assert torch.allclose(bboxes, expected_bboxes, 1e-05)\n    assert torch.all(labels == expected_labels)\n    assert torch.all(labels3d == expected_labels)\n    assert torch.allclose(centers2d, expected_centers2d, 1e-05)\n    assert torch.allclose(depths, expected_depths, 1e-05)",
        "mutated": [
            "def test_getitem():\n    if False:\n        i = 10\n    np.random.seed(0)\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    img_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='RandomFlip3D', flip_ratio_bev_horizontal=1.0), dict(type='Normalize', **img_norm_cfg), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file='tests/data/kitti/kitti_infos_mono3d.coco.json', info_file='tests/data/kitti/kitti_infos_mono3d.pkl', pipeline=pipeline, data_root='tests/data/kitti/', img_prefix='tests/data/kitti/', test_mode=False)\n    data = kitti_dataset[0]\n    img_metas = data['img_metas']._data\n    filename = img_metas['filename']\n    img_shape = img_metas['img_shape']\n    pad_shape = img_metas['pad_shape']\n    flip = img_metas['flip']\n    bboxes = data['gt_bboxes']._data\n    labels3d = data['gt_labels_3d']._data\n    labels = data['gt_labels']._data\n    centers2d = data['centers2d']._data\n    depths = data['depths']._data\n    expected_filename = 'tests/data/kitti/training/image_2/000007.png'\n    expected_img_shape = (375, 1242, 3)\n    expected_pad_shape = (384, 1248, 3)\n    expected_flip = True\n    expected_bboxes = torch.tensor([[625.3445, 175.012, 676.5177, 224.9605], [729.5906, 179.8571, 760.1503, 202.539], [676.7557, 175.7334, 699.7753, 193.9447], [886.5021, 176.138, 911.1581, 213.8148]])\n    expected_labels = torch.tensor([2, 2, 2, 1])\n    expected_centers2d = torch.tensor([[650.6185, 198.3731], [744.2711, 190.7532], [687.8787, 184.5331], [898.475, 194.4337]])\n    expected_depths = torch.tensor([25.0127, 47.5527, 60.5227, 34.0927])\n    assert filename == expected_filename\n    assert img_shape == expected_img_shape\n    assert pad_shape == expected_pad_shape\n    assert flip == expected_flip\n    assert torch.allclose(bboxes, expected_bboxes, 1e-05)\n    assert torch.all(labels == expected_labels)\n    assert torch.all(labels3d == expected_labels)\n    assert torch.allclose(centers2d, expected_centers2d, 1e-05)\n    assert torch.allclose(depths, expected_depths, 1e-05)",
            "def test_getitem():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    np.random.seed(0)\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    img_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='RandomFlip3D', flip_ratio_bev_horizontal=1.0), dict(type='Normalize', **img_norm_cfg), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file='tests/data/kitti/kitti_infos_mono3d.coco.json', info_file='tests/data/kitti/kitti_infos_mono3d.pkl', pipeline=pipeline, data_root='tests/data/kitti/', img_prefix='tests/data/kitti/', test_mode=False)\n    data = kitti_dataset[0]\n    img_metas = data['img_metas']._data\n    filename = img_metas['filename']\n    img_shape = img_metas['img_shape']\n    pad_shape = img_metas['pad_shape']\n    flip = img_metas['flip']\n    bboxes = data['gt_bboxes']._data\n    labels3d = data['gt_labels_3d']._data\n    labels = data['gt_labels']._data\n    centers2d = data['centers2d']._data\n    depths = data['depths']._data\n    expected_filename = 'tests/data/kitti/training/image_2/000007.png'\n    expected_img_shape = (375, 1242, 3)\n    expected_pad_shape = (384, 1248, 3)\n    expected_flip = True\n    expected_bboxes = torch.tensor([[625.3445, 175.012, 676.5177, 224.9605], [729.5906, 179.8571, 760.1503, 202.539], [676.7557, 175.7334, 699.7753, 193.9447], [886.5021, 176.138, 911.1581, 213.8148]])\n    expected_labels = torch.tensor([2, 2, 2, 1])\n    expected_centers2d = torch.tensor([[650.6185, 198.3731], [744.2711, 190.7532], [687.8787, 184.5331], [898.475, 194.4337]])\n    expected_depths = torch.tensor([25.0127, 47.5527, 60.5227, 34.0927])\n    assert filename == expected_filename\n    assert img_shape == expected_img_shape\n    assert pad_shape == expected_pad_shape\n    assert flip == expected_flip\n    assert torch.allclose(bboxes, expected_bboxes, 1e-05)\n    assert torch.all(labels == expected_labels)\n    assert torch.all(labels3d == expected_labels)\n    assert torch.allclose(centers2d, expected_centers2d, 1e-05)\n    assert torch.allclose(depths, expected_depths, 1e-05)",
            "def test_getitem():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    np.random.seed(0)\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    img_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='RandomFlip3D', flip_ratio_bev_horizontal=1.0), dict(type='Normalize', **img_norm_cfg), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file='tests/data/kitti/kitti_infos_mono3d.coco.json', info_file='tests/data/kitti/kitti_infos_mono3d.pkl', pipeline=pipeline, data_root='tests/data/kitti/', img_prefix='tests/data/kitti/', test_mode=False)\n    data = kitti_dataset[0]\n    img_metas = data['img_metas']._data\n    filename = img_metas['filename']\n    img_shape = img_metas['img_shape']\n    pad_shape = img_metas['pad_shape']\n    flip = img_metas['flip']\n    bboxes = data['gt_bboxes']._data\n    labels3d = data['gt_labels_3d']._data\n    labels = data['gt_labels']._data\n    centers2d = data['centers2d']._data\n    depths = data['depths']._data\n    expected_filename = 'tests/data/kitti/training/image_2/000007.png'\n    expected_img_shape = (375, 1242, 3)\n    expected_pad_shape = (384, 1248, 3)\n    expected_flip = True\n    expected_bboxes = torch.tensor([[625.3445, 175.012, 676.5177, 224.9605], [729.5906, 179.8571, 760.1503, 202.539], [676.7557, 175.7334, 699.7753, 193.9447], [886.5021, 176.138, 911.1581, 213.8148]])\n    expected_labels = torch.tensor([2, 2, 2, 1])\n    expected_centers2d = torch.tensor([[650.6185, 198.3731], [744.2711, 190.7532], [687.8787, 184.5331], [898.475, 194.4337]])\n    expected_depths = torch.tensor([25.0127, 47.5527, 60.5227, 34.0927])\n    assert filename == expected_filename\n    assert img_shape == expected_img_shape\n    assert pad_shape == expected_pad_shape\n    assert flip == expected_flip\n    assert torch.allclose(bboxes, expected_bboxes, 1e-05)\n    assert torch.all(labels == expected_labels)\n    assert torch.all(labels3d == expected_labels)\n    assert torch.allclose(centers2d, expected_centers2d, 1e-05)\n    assert torch.allclose(depths, expected_depths, 1e-05)",
            "def test_getitem():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    np.random.seed(0)\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    img_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='RandomFlip3D', flip_ratio_bev_horizontal=1.0), dict(type='Normalize', **img_norm_cfg), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file='tests/data/kitti/kitti_infos_mono3d.coco.json', info_file='tests/data/kitti/kitti_infos_mono3d.pkl', pipeline=pipeline, data_root='tests/data/kitti/', img_prefix='tests/data/kitti/', test_mode=False)\n    data = kitti_dataset[0]\n    img_metas = data['img_metas']._data\n    filename = img_metas['filename']\n    img_shape = img_metas['img_shape']\n    pad_shape = img_metas['pad_shape']\n    flip = img_metas['flip']\n    bboxes = data['gt_bboxes']._data\n    labels3d = data['gt_labels_3d']._data\n    labels = data['gt_labels']._data\n    centers2d = data['centers2d']._data\n    depths = data['depths']._data\n    expected_filename = 'tests/data/kitti/training/image_2/000007.png'\n    expected_img_shape = (375, 1242, 3)\n    expected_pad_shape = (384, 1248, 3)\n    expected_flip = True\n    expected_bboxes = torch.tensor([[625.3445, 175.012, 676.5177, 224.9605], [729.5906, 179.8571, 760.1503, 202.539], [676.7557, 175.7334, 699.7753, 193.9447], [886.5021, 176.138, 911.1581, 213.8148]])\n    expected_labels = torch.tensor([2, 2, 2, 1])\n    expected_centers2d = torch.tensor([[650.6185, 198.3731], [744.2711, 190.7532], [687.8787, 184.5331], [898.475, 194.4337]])\n    expected_depths = torch.tensor([25.0127, 47.5527, 60.5227, 34.0927])\n    assert filename == expected_filename\n    assert img_shape == expected_img_shape\n    assert pad_shape == expected_pad_shape\n    assert flip == expected_flip\n    assert torch.allclose(bboxes, expected_bboxes, 1e-05)\n    assert torch.all(labels == expected_labels)\n    assert torch.all(labels3d == expected_labels)\n    assert torch.allclose(centers2d, expected_centers2d, 1e-05)\n    assert torch.allclose(depths, expected_depths, 1e-05)",
            "def test_getitem():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    np.random.seed(0)\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    img_norm_cfg = dict(mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='RandomFlip3D', flip_ratio_bev_horizontal=1.0), dict(type='Normalize', **img_norm_cfg), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file='tests/data/kitti/kitti_infos_mono3d.coco.json', info_file='tests/data/kitti/kitti_infos_mono3d.pkl', pipeline=pipeline, data_root='tests/data/kitti/', img_prefix='tests/data/kitti/', test_mode=False)\n    data = kitti_dataset[0]\n    img_metas = data['img_metas']._data\n    filename = img_metas['filename']\n    img_shape = img_metas['img_shape']\n    pad_shape = img_metas['pad_shape']\n    flip = img_metas['flip']\n    bboxes = data['gt_bboxes']._data\n    labels3d = data['gt_labels_3d']._data\n    labels = data['gt_labels']._data\n    centers2d = data['centers2d']._data\n    depths = data['depths']._data\n    expected_filename = 'tests/data/kitti/training/image_2/000007.png'\n    expected_img_shape = (375, 1242, 3)\n    expected_pad_shape = (384, 1248, 3)\n    expected_flip = True\n    expected_bboxes = torch.tensor([[625.3445, 175.012, 676.5177, 224.9605], [729.5906, 179.8571, 760.1503, 202.539], [676.7557, 175.7334, 699.7753, 193.9447], [886.5021, 176.138, 911.1581, 213.8148]])\n    expected_labels = torch.tensor([2, 2, 2, 1])\n    expected_centers2d = torch.tensor([[650.6185, 198.3731], [744.2711, 190.7532], [687.8787, 184.5331], [898.475, 194.4337]])\n    expected_depths = torch.tensor([25.0127, 47.5527, 60.5227, 34.0927])\n    assert filename == expected_filename\n    assert img_shape == expected_img_shape\n    assert pad_shape == expected_pad_shape\n    assert flip == expected_flip\n    assert torch.allclose(bboxes, expected_bboxes, 1e-05)\n    assert torch.all(labels == expected_labels)\n    assert torch.all(labels3d == expected_labels)\n    assert torch.allclose(centers2d, expected_centers2d, 1e-05)\n    assert torch.allclose(depths, expected_depths, 1e-05)"
        ]
    },
    {
        "func_name": "test_format_results",
        "original": "def test_format_results():\n    root_path = 'tests/data/kitti/'\n    info_file = 'tests/data/kitti/kitti_infos_mono3d.pkl'\n    ann_file = 'tests/data/kitti/kitti_infos_mono3d.coco.json'\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file=ann_file, info_file=info_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results.pkl')\n    (result_files, tmp_dir) = kitti_dataset.format_results(results)\n    result_data = result_files['img_bbox']\n    assert len(result_data) == 1\n    assert len(result_data[0]['name']) == 4\n    det = result_data[0]\n    expected_bbox = torch.tensor([[565.4989, 175.02547, 616.70184, 225.00565], [481.85907, 179.8642, 512.43414, 202.5624], [542.23157, 175.73912, 565.26263, 193.96303], [330.8572, 176.1482, 355.53937, 213.8469]])\n    expected_dims = torch.tensor([[3.201, 1.6110001, 1.661], [3.701, 1.401, 1.511], [4.051, 1.4610001, 1.661], [1.9510001, 1.7210001, 0.501]])\n    expected_rotation = torch.tensor([-1.59, 1.55, 1.56, 1.54])\n    expected_detname = ['Car', 'Car', 'Car', 'Cyclist']\n    assert torch.allclose(torch.from_numpy(det['bbox']), expected_bbox, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['dimensions']), expected_dims, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['rotation_y']), expected_rotation, 1e-05)\n    assert det['name'].tolist() == expected_detname\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results2d.pkl')\n    (result_files, tmp_dir) = kitti_dataset.format_results(results)\n    result_data = result_files['img_bbox2d']\n    assert len(result_data) == 1\n    assert len(result_data[0]['name']) == 4\n    det = result_data[0]\n    expected_bbox = torch.tensor([[330.84191493, 176.13804312, 355.49885373, 213.81578769], [565.48227204, 175.01202566, 616.65650883, 224.96147091], [481.84967085, 179.85710612, 512.41043776, 202.54001526], [542.22471517, 175.73341152, 565.24534908, 193.94568878]])\n    expected_dims = torch.tensor([[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]])\n    expected_rotation = torch.tensor([0.0, 0.0, 0.0, 0.0])\n    expected_detname = ['Cyclist', 'Car', 'Car', 'Car']\n    assert torch.allclose(torch.from_numpy(det['bbox']).float(), expected_bbox, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['dimensions']).float(), expected_dims, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['rotation_y']).float(), expected_rotation, 1e-05)\n    assert det['name'].tolist() == expected_detname",
        "mutated": [
            "def test_format_results():\n    if False:\n        i = 10\n    root_path = 'tests/data/kitti/'\n    info_file = 'tests/data/kitti/kitti_infos_mono3d.pkl'\n    ann_file = 'tests/data/kitti/kitti_infos_mono3d.coco.json'\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file=ann_file, info_file=info_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results.pkl')\n    (result_files, tmp_dir) = kitti_dataset.format_results(results)\n    result_data = result_files['img_bbox']\n    assert len(result_data) == 1\n    assert len(result_data[0]['name']) == 4\n    det = result_data[0]\n    expected_bbox = torch.tensor([[565.4989, 175.02547, 616.70184, 225.00565], [481.85907, 179.8642, 512.43414, 202.5624], [542.23157, 175.73912, 565.26263, 193.96303], [330.8572, 176.1482, 355.53937, 213.8469]])\n    expected_dims = torch.tensor([[3.201, 1.6110001, 1.661], [3.701, 1.401, 1.511], [4.051, 1.4610001, 1.661], [1.9510001, 1.7210001, 0.501]])\n    expected_rotation = torch.tensor([-1.59, 1.55, 1.56, 1.54])\n    expected_detname = ['Car', 'Car', 'Car', 'Cyclist']\n    assert torch.allclose(torch.from_numpy(det['bbox']), expected_bbox, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['dimensions']), expected_dims, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['rotation_y']), expected_rotation, 1e-05)\n    assert det['name'].tolist() == expected_detname\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results2d.pkl')\n    (result_files, tmp_dir) = kitti_dataset.format_results(results)\n    result_data = result_files['img_bbox2d']\n    assert len(result_data) == 1\n    assert len(result_data[0]['name']) == 4\n    det = result_data[0]\n    expected_bbox = torch.tensor([[330.84191493, 176.13804312, 355.49885373, 213.81578769], [565.48227204, 175.01202566, 616.65650883, 224.96147091], [481.84967085, 179.85710612, 512.41043776, 202.54001526], [542.22471517, 175.73341152, 565.24534908, 193.94568878]])\n    expected_dims = torch.tensor([[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]])\n    expected_rotation = torch.tensor([0.0, 0.0, 0.0, 0.0])\n    expected_detname = ['Cyclist', 'Car', 'Car', 'Car']\n    assert torch.allclose(torch.from_numpy(det['bbox']).float(), expected_bbox, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['dimensions']).float(), expected_dims, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['rotation_y']).float(), expected_rotation, 1e-05)\n    assert det['name'].tolist() == expected_detname",
            "def test_format_results():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    root_path = 'tests/data/kitti/'\n    info_file = 'tests/data/kitti/kitti_infos_mono3d.pkl'\n    ann_file = 'tests/data/kitti/kitti_infos_mono3d.coco.json'\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file=ann_file, info_file=info_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results.pkl')\n    (result_files, tmp_dir) = kitti_dataset.format_results(results)\n    result_data = result_files['img_bbox']\n    assert len(result_data) == 1\n    assert len(result_data[0]['name']) == 4\n    det = result_data[0]\n    expected_bbox = torch.tensor([[565.4989, 175.02547, 616.70184, 225.00565], [481.85907, 179.8642, 512.43414, 202.5624], [542.23157, 175.73912, 565.26263, 193.96303], [330.8572, 176.1482, 355.53937, 213.8469]])\n    expected_dims = torch.tensor([[3.201, 1.6110001, 1.661], [3.701, 1.401, 1.511], [4.051, 1.4610001, 1.661], [1.9510001, 1.7210001, 0.501]])\n    expected_rotation = torch.tensor([-1.59, 1.55, 1.56, 1.54])\n    expected_detname = ['Car', 'Car', 'Car', 'Cyclist']\n    assert torch.allclose(torch.from_numpy(det['bbox']), expected_bbox, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['dimensions']), expected_dims, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['rotation_y']), expected_rotation, 1e-05)\n    assert det['name'].tolist() == expected_detname\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results2d.pkl')\n    (result_files, tmp_dir) = kitti_dataset.format_results(results)\n    result_data = result_files['img_bbox2d']\n    assert len(result_data) == 1\n    assert len(result_data[0]['name']) == 4\n    det = result_data[0]\n    expected_bbox = torch.tensor([[330.84191493, 176.13804312, 355.49885373, 213.81578769], [565.48227204, 175.01202566, 616.65650883, 224.96147091], [481.84967085, 179.85710612, 512.41043776, 202.54001526], [542.22471517, 175.73341152, 565.24534908, 193.94568878]])\n    expected_dims = torch.tensor([[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]])\n    expected_rotation = torch.tensor([0.0, 0.0, 0.0, 0.0])\n    expected_detname = ['Cyclist', 'Car', 'Car', 'Car']\n    assert torch.allclose(torch.from_numpy(det['bbox']).float(), expected_bbox, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['dimensions']).float(), expected_dims, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['rotation_y']).float(), expected_rotation, 1e-05)\n    assert det['name'].tolist() == expected_detname",
            "def test_format_results():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    root_path = 'tests/data/kitti/'\n    info_file = 'tests/data/kitti/kitti_infos_mono3d.pkl'\n    ann_file = 'tests/data/kitti/kitti_infos_mono3d.coco.json'\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file=ann_file, info_file=info_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results.pkl')\n    (result_files, tmp_dir) = kitti_dataset.format_results(results)\n    result_data = result_files['img_bbox']\n    assert len(result_data) == 1\n    assert len(result_data[0]['name']) == 4\n    det = result_data[0]\n    expected_bbox = torch.tensor([[565.4989, 175.02547, 616.70184, 225.00565], [481.85907, 179.8642, 512.43414, 202.5624], [542.23157, 175.73912, 565.26263, 193.96303], [330.8572, 176.1482, 355.53937, 213.8469]])\n    expected_dims = torch.tensor([[3.201, 1.6110001, 1.661], [3.701, 1.401, 1.511], [4.051, 1.4610001, 1.661], [1.9510001, 1.7210001, 0.501]])\n    expected_rotation = torch.tensor([-1.59, 1.55, 1.56, 1.54])\n    expected_detname = ['Car', 'Car', 'Car', 'Cyclist']\n    assert torch.allclose(torch.from_numpy(det['bbox']), expected_bbox, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['dimensions']), expected_dims, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['rotation_y']), expected_rotation, 1e-05)\n    assert det['name'].tolist() == expected_detname\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results2d.pkl')\n    (result_files, tmp_dir) = kitti_dataset.format_results(results)\n    result_data = result_files['img_bbox2d']\n    assert len(result_data) == 1\n    assert len(result_data[0]['name']) == 4\n    det = result_data[0]\n    expected_bbox = torch.tensor([[330.84191493, 176.13804312, 355.49885373, 213.81578769], [565.48227204, 175.01202566, 616.65650883, 224.96147091], [481.84967085, 179.85710612, 512.41043776, 202.54001526], [542.22471517, 175.73341152, 565.24534908, 193.94568878]])\n    expected_dims = torch.tensor([[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]])\n    expected_rotation = torch.tensor([0.0, 0.0, 0.0, 0.0])\n    expected_detname = ['Cyclist', 'Car', 'Car', 'Car']\n    assert torch.allclose(torch.from_numpy(det['bbox']).float(), expected_bbox, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['dimensions']).float(), expected_dims, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['rotation_y']).float(), expected_rotation, 1e-05)\n    assert det['name'].tolist() == expected_detname",
            "def test_format_results():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    root_path = 'tests/data/kitti/'\n    info_file = 'tests/data/kitti/kitti_infos_mono3d.pkl'\n    ann_file = 'tests/data/kitti/kitti_infos_mono3d.coco.json'\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file=ann_file, info_file=info_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results.pkl')\n    (result_files, tmp_dir) = kitti_dataset.format_results(results)\n    result_data = result_files['img_bbox']\n    assert len(result_data) == 1\n    assert len(result_data[0]['name']) == 4\n    det = result_data[0]\n    expected_bbox = torch.tensor([[565.4989, 175.02547, 616.70184, 225.00565], [481.85907, 179.8642, 512.43414, 202.5624], [542.23157, 175.73912, 565.26263, 193.96303], [330.8572, 176.1482, 355.53937, 213.8469]])\n    expected_dims = torch.tensor([[3.201, 1.6110001, 1.661], [3.701, 1.401, 1.511], [4.051, 1.4610001, 1.661], [1.9510001, 1.7210001, 0.501]])\n    expected_rotation = torch.tensor([-1.59, 1.55, 1.56, 1.54])\n    expected_detname = ['Car', 'Car', 'Car', 'Cyclist']\n    assert torch.allclose(torch.from_numpy(det['bbox']), expected_bbox, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['dimensions']), expected_dims, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['rotation_y']), expected_rotation, 1e-05)\n    assert det['name'].tolist() == expected_detname\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results2d.pkl')\n    (result_files, tmp_dir) = kitti_dataset.format_results(results)\n    result_data = result_files['img_bbox2d']\n    assert len(result_data) == 1\n    assert len(result_data[0]['name']) == 4\n    det = result_data[0]\n    expected_bbox = torch.tensor([[330.84191493, 176.13804312, 355.49885373, 213.81578769], [565.48227204, 175.01202566, 616.65650883, 224.96147091], [481.84967085, 179.85710612, 512.41043776, 202.54001526], [542.22471517, 175.73341152, 565.24534908, 193.94568878]])\n    expected_dims = torch.tensor([[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]])\n    expected_rotation = torch.tensor([0.0, 0.0, 0.0, 0.0])\n    expected_detname = ['Cyclist', 'Car', 'Car', 'Car']\n    assert torch.allclose(torch.from_numpy(det['bbox']).float(), expected_bbox, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['dimensions']).float(), expected_dims, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['rotation_y']).float(), expected_rotation, 1e-05)\n    assert det['name'].tolist() == expected_detname",
            "def test_format_results():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    root_path = 'tests/data/kitti/'\n    info_file = 'tests/data/kitti/kitti_infos_mono3d.pkl'\n    ann_file = 'tests/data/kitti/kitti_infos_mono3d.coco.json'\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file=ann_file, info_file=info_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results.pkl')\n    (result_files, tmp_dir) = kitti_dataset.format_results(results)\n    result_data = result_files['img_bbox']\n    assert len(result_data) == 1\n    assert len(result_data[0]['name']) == 4\n    det = result_data[0]\n    expected_bbox = torch.tensor([[565.4989, 175.02547, 616.70184, 225.00565], [481.85907, 179.8642, 512.43414, 202.5624], [542.23157, 175.73912, 565.26263, 193.96303], [330.8572, 176.1482, 355.53937, 213.8469]])\n    expected_dims = torch.tensor([[3.201, 1.6110001, 1.661], [3.701, 1.401, 1.511], [4.051, 1.4610001, 1.661], [1.9510001, 1.7210001, 0.501]])\n    expected_rotation = torch.tensor([-1.59, 1.55, 1.56, 1.54])\n    expected_detname = ['Car', 'Car', 'Car', 'Cyclist']\n    assert torch.allclose(torch.from_numpy(det['bbox']), expected_bbox, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['dimensions']), expected_dims, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['rotation_y']), expected_rotation, 1e-05)\n    assert det['name'].tolist() == expected_detname\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results2d.pkl')\n    (result_files, tmp_dir) = kitti_dataset.format_results(results)\n    result_data = result_files['img_bbox2d']\n    assert len(result_data) == 1\n    assert len(result_data[0]['name']) == 4\n    det = result_data[0]\n    expected_bbox = torch.tensor([[330.84191493, 176.13804312, 355.49885373, 213.81578769], [565.48227204, 175.01202566, 616.65650883, 224.96147091], [481.84967085, 179.85710612, 512.41043776, 202.54001526], [542.22471517, 175.73341152, 565.24534908, 193.94568878]])\n    expected_dims = torch.tensor([[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]])\n    expected_rotation = torch.tensor([0.0, 0.0, 0.0, 0.0])\n    expected_detname = ['Cyclist', 'Car', 'Car', 'Car']\n    assert torch.allclose(torch.from_numpy(det['bbox']).float(), expected_bbox, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['dimensions']).float(), expected_dims, 1e-05)\n    assert torch.allclose(torch.from_numpy(det['rotation_y']).float(), expected_rotation, 1e-05)\n    assert det['name'].tolist() == expected_detname"
        ]
    },
    {
        "func_name": "test_evaluate",
        "original": "def test_evaluate():\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    root_path = 'tests/data/kitti/'\n    info_file = 'tests/data/kitti/kitti_infos_mono3d.pkl'\n    ann_file = 'tests/data/kitti/kitti_infos_mono3d.coco.json'\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file=ann_file, info_file=info_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results.pkl')\n    results2d = mmcv.load('tests/data/kitti/mono3d_sample_results2d.pkl')\n    results[0]['img_bbox2d'] = results2d[0]['img_bbox2d']\n    metric = ['mAP']\n    ap_dict = kitti_dataset.evaluate(results, metric)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_easy'], 3.0303)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_moderate'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_hard'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_easy'], 3.0303)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_moderate'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_hard'], 6.0606)",
        "mutated": [
            "def test_evaluate():\n    if False:\n        i = 10\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    root_path = 'tests/data/kitti/'\n    info_file = 'tests/data/kitti/kitti_infos_mono3d.pkl'\n    ann_file = 'tests/data/kitti/kitti_infos_mono3d.coco.json'\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file=ann_file, info_file=info_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results.pkl')\n    results2d = mmcv.load('tests/data/kitti/mono3d_sample_results2d.pkl')\n    results[0]['img_bbox2d'] = results2d[0]['img_bbox2d']\n    metric = ['mAP']\n    ap_dict = kitti_dataset.evaluate(results, metric)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_easy'], 3.0303)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_moderate'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_hard'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_easy'], 3.0303)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_moderate'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_hard'], 6.0606)",
            "def test_evaluate():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    root_path = 'tests/data/kitti/'\n    info_file = 'tests/data/kitti/kitti_infos_mono3d.pkl'\n    ann_file = 'tests/data/kitti/kitti_infos_mono3d.coco.json'\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file=ann_file, info_file=info_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results.pkl')\n    results2d = mmcv.load('tests/data/kitti/mono3d_sample_results2d.pkl')\n    results[0]['img_bbox2d'] = results2d[0]['img_bbox2d']\n    metric = ['mAP']\n    ap_dict = kitti_dataset.evaluate(results, metric)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_easy'], 3.0303)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_moderate'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_hard'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_easy'], 3.0303)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_moderate'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_hard'], 6.0606)",
            "def test_evaluate():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    root_path = 'tests/data/kitti/'\n    info_file = 'tests/data/kitti/kitti_infos_mono3d.pkl'\n    ann_file = 'tests/data/kitti/kitti_infos_mono3d.coco.json'\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file=ann_file, info_file=info_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results.pkl')\n    results2d = mmcv.load('tests/data/kitti/mono3d_sample_results2d.pkl')\n    results[0]['img_bbox2d'] = results2d[0]['img_bbox2d']\n    metric = ['mAP']\n    ap_dict = kitti_dataset.evaluate(results, metric)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_easy'], 3.0303)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_moderate'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_hard'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_easy'], 3.0303)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_moderate'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_hard'], 6.0606)",
            "def test_evaluate():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    root_path = 'tests/data/kitti/'\n    info_file = 'tests/data/kitti/kitti_infos_mono3d.pkl'\n    ann_file = 'tests/data/kitti/kitti_infos_mono3d.coco.json'\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file=ann_file, info_file=info_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results.pkl')\n    results2d = mmcv.load('tests/data/kitti/mono3d_sample_results2d.pkl')\n    results[0]['img_bbox2d'] = results2d[0]['img_bbox2d']\n    metric = ['mAP']\n    ap_dict = kitti_dataset.evaluate(results, metric)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_easy'], 3.0303)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_moderate'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_hard'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_easy'], 3.0303)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_moderate'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_hard'], 6.0606)",
            "def test_evaluate():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not torch.cuda.is_available():\n        pytest.skip('test requires GPU and torch+cuda')\n    root_path = 'tests/data/kitti/'\n    info_file = 'tests/data/kitti/kitti_infos_mono3d.pkl'\n    ann_file = 'tests/data/kitti/kitti_infos_mono3d.coco.json'\n    class_names = ['Pedestrian', 'Cyclist', 'Car']\n    pipeline = [dict(type='LoadImageFromFileMono3D'), dict(type='LoadAnnotations3D', with_bbox=True, with_label=True, with_attr_label=False, with_bbox_3d=True, with_label_3d=True, with_bbox_depth=True), dict(type='Resize', img_scale=(1242, 375), keep_ratio=True), dict(type='Pad', size_divisor=32), dict(type='DefaultFormatBundle3D', class_names=class_names), dict(type='Collect3D', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_3d', 'gt_labels_3d', 'centers2d', 'depths'])]\n    kitti_dataset = KittiMonoDataset(ann_file=ann_file, info_file=info_file, pipeline=pipeline, data_root=root_path, test_mode=True)\n    results = mmcv.load('tests/data/kitti/mono3d_sample_results.pkl')\n    results2d = mmcv.load('tests/data/kitti/mono3d_sample_results2d.pkl')\n    results[0]['img_bbox2d'] = results2d[0]['img_bbox2d']\n    metric = ['mAP']\n    ap_dict = kitti_dataset.evaluate(results, metric)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_easy'], 3.0303)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_moderate'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox/KITTI/Overall_3D_AP11_hard'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_easy'], 3.0303)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_moderate'], 6.0606)\n    assert np.isclose(ap_dict['img_bbox2d/KITTI/Overall_2D_AP11_hard'], 6.0606)"
        ]
    }
]