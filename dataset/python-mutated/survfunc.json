[
    {
        "func_name": "_calc_survfunc_right",
        "original": "def _calc_survfunc_right(time, status, weights=None, entry=None, compress=True, retall=True):\n    \"\"\"\n    Calculate the survival function and its standard error for a single\n    group.\n    \"\"\"\n    if entry is None:\n        (utime, rtime) = np.unique(time, return_inverse=True)\n    else:\n        tx = np.concatenate((time, entry))\n        (utime, rtime) = np.unique(tx, return_inverse=True)\n        rtime = rtime[0:len(time)]\n    ml = len(utime)\n    if weights is None:\n        d = np.bincount(rtime, weights=status, minlength=ml)\n    else:\n        d = np.bincount(rtime, weights=status * weights, minlength=ml)\n    if weights is None:\n        n = np.bincount(rtime, minlength=ml)\n    else:\n        n = np.bincount(rtime, weights=weights, minlength=ml)\n    if entry is not None:\n        n = np.cumsum(n) - n\n        rentry = np.searchsorted(utime, entry, side='left')\n        if weights is None:\n            n0 = np.bincount(rentry, minlength=ml)\n        else:\n            n0 = np.bincount(rentry, weights=weights, minlength=ml)\n        n0 = np.cumsum(n0) - n0\n        n = n0 - n\n    else:\n        n = np.cumsum(n[::-1])[::-1]\n    if compress:\n        ii = np.flatnonzero(d > 0)\n        d = d[ii]\n        n = n[ii]\n        utime = utime[ii]\n    sp = 1 - d / n.astype(np.float64)\n    ii = sp < 1e-16\n    sp[ii] = 1e-16\n    sp = np.log(sp)\n    sp = np.cumsum(sp)\n    sp = np.exp(sp)\n    sp[ii] = 0\n    if not retall:\n        return (sp, utime, rtime, n, d)\n    if weights is None:\n        denom = n * (n - d)\n        denom = np.clip(denom, 1e-12, np.inf)\n        se = d / denom.astype(np.float64)\n        se[(n == d) | (n == 0)] = np.nan\n        se = np.cumsum(se)\n        se = np.sqrt(se)\n        locs = np.isfinite(se) | (sp != 0)\n        se[locs] *= sp[locs]\n        se[~locs] = np.nan\n    else:\n        se = d / (n * n).astype(np.float64)\n        se = np.cumsum(se)\n        se = np.sqrt(se)\n    return (sp, se, utime, rtime, n, d)",
        "mutated": [
            "def _calc_survfunc_right(time, status, weights=None, entry=None, compress=True, retall=True):\n    if False:\n        i = 10\n    '\\n    Calculate the survival function and its standard error for a single\\n    group.\\n    '\n    if entry is None:\n        (utime, rtime) = np.unique(time, return_inverse=True)\n    else:\n        tx = np.concatenate((time, entry))\n        (utime, rtime) = np.unique(tx, return_inverse=True)\n        rtime = rtime[0:len(time)]\n    ml = len(utime)\n    if weights is None:\n        d = np.bincount(rtime, weights=status, minlength=ml)\n    else:\n        d = np.bincount(rtime, weights=status * weights, minlength=ml)\n    if weights is None:\n        n = np.bincount(rtime, minlength=ml)\n    else:\n        n = np.bincount(rtime, weights=weights, minlength=ml)\n    if entry is not None:\n        n = np.cumsum(n) - n\n        rentry = np.searchsorted(utime, entry, side='left')\n        if weights is None:\n            n0 = np.bincount(rentry, minlength=ml)\n        else:\n            n0 = np.bincount(rentry, weights=weights, minlength=ml)\n        n0 = np.cumsum(n0) - n0\n        n = n0 - n\n    else:\n        n = np.cumsum(n[::-1])[::-1]\n    if compress:\n        ii = np.flatnonzero(d > 0)\n        d = d[ii]\n        n = n[ii]\n        utime = utime[ii]\n    sp = 1 - d / n.astype(np.float64)\n    ii = sp < 1e-16\n    sp[ii] = 1e-16\n    sp = np.log(sp)\n    sp = np.cumsum(sp)\n    sp = np.exp(sp)\n    sp[ii] = 0\n    if not retall:\n        return (sp, utime, rtime, n, d)\n    if weights is None:\n        denom = n * (n - d)\n        denom = np.clip(denom, 1e-12, np.inf)\n        se = d / denom.astype(np.float64)\n        se[(n == d) | (n == 0)] = np.nan\n        se = np.cumsum(se)\n        se = np.sqrt(se)\n        locs = np.isfinite(se) | (sp != 0)\n        se[locs] *= sp[locs]\n        se[~locs] = np.nan\n    else:\n        se = d / (n * n).astype(np.float64)\n        se = np.cumsum(se)\n        se = np.sqrt(se)\n    return (sp, se, utime, rtime, n, d)",
            "def _calc_survfunc_right(time, status, weights=None, entry=None, compress=True, retall=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Calculate the survival function and its standard error for a single\\n    group.\\n    '\n    if entry is None:\n        (utime, rtime) = np.unique(time, return_inverse=True)\n    else:\n        tx = np.concatenate((time, entry))\n        (utime, rtime) = np.unique(tx, return_inverse=True)\n        rtime = rtime[0:len(time)]\n    ml = len(utime)\n    if weights is None:\n        d = np.bincount(rtime, weights=status, minlength=ml)\n    else:\n        d = np.bincount(rtime, weights=status * weights, minlength=ml)\n    if weights is None:\n        n = np.bincount(rtime, minlength=ml)\n    else:\n        n = np.bincount(rtime, weights=weights, minlength=ml)\n    if entry is not None:\n        n = np.cumsum(n) - n\n        rentry = np.searchsorted(utime, entry, side='left')\n        if weights is None:\n            n0 = np.bincount(rentry, minlength=ml)\n        else:\n            n0 = np.bincount(rentry, weights=weights, minlength=ml)\n        n0 = np.cumsum(n0) - n0\n        n = n0 - n\n    else:\n        n = np.cumsum(n[::-1])[::-1]\n    if compress:\n        ii = np.flatnonzero(d > 0)\n        d = d[ii]\n        n = n[ii]\n        utime = utime[ii]\n    sp = 1 - d / n.astype(np.float64)\n    ii = sp < 1e-16\n    sp[ii] = 1e-16\n    sp = np.log(sp)\n    sp = np.cumsum(sp)\n    sp = np.exp(sp)\n    sp[ii] = 0\n    if not retall:\n        return (sp, utime, rtime, n, d)\n    if weights is None:\n        denom = n * (n - d)\n        denom = np.clip(denom, 1e-12, np.inf)\n        se = d / denom.astype(np.float64)\n        se[(n == d) | (n == 0)] = np.nan\n        se = np.cumsum(se)\n        se = np.sqrt(se)\n        locs = np.isfinite(se) | (sp != 0)\n        se[locs] *= sp[locs]\n        se[~locs] = np.nan\n    else:\n        se = d / (n * n).astype(np.float64)\n        se = np.cumsum(se)\n        se = np.sqrt(se)\n    return (sp, se, utime, rtime, n, d)",
            "def _calc_survfunc_right(time, status, weights=None, entry=None, compress=True, retall=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Calculate the survival function and its standard error for a single\\n    group.\\n    '\n    if entry is None:\n        (utime, rtime) = np.unique(time, return_inverse=True)\n    else:\n        tx = np.concatenate((time, entry))\n        (utime, rtime) = np.unique(tx, return_inverse=True)\n        rtime = rtime[0:len(time)]\n    ml = len(utime)\n    if weights is None:\n        d = np.bincount(rtime, weights=status, minlength=ml)\n    else:\n        d = np.bincount(rtime, weights=status * weights, minlength=ml)\n    if weights is None:\n        n = np.bincount(rtime, minlength=ml)\n    else:\n        n = np.bincount(rtime, weights=weights, minlength=ml)\n    if entry is not None:\n        n = np.cumsum(n) - n\n        rentry = np.searchsorted(utime, entry, side='left')\n        if weights is None:\n            n0 = np.bincount(rentry, minlength=ml)\n        else:\n            n0 = np.bincount(rentry, weights=weights, minlength=ml)\n        n0 = np.cumsum(n0) - n0\n        n = n0 - n\n    else:\n        n = np.cumsum(n[::-1])[::-1]\n    if compress:\n        ii = np.flatnonzero(d > 0)\n        d = d[ii]\n        n = n[ii]\n        utime = utime[ii]\n    sp = 1 - d / n.astype(np.float64)\n    ii = sp < 1e-16\n    sp[ii] = 1e-16\n    sp = np.log(sp)\n    sp = np.cumsum(sp)\n    sp = np.exp(sp)\n    sp[ii] = 0\n    if not retall:\n        return (sp, utime, rtime, n, d)\n    if weights is None:\n        denom = n * (n - d)\n        denom = np.clip(denom, 1e-12, np.inf)\n        se = d / denom.astype(np.float64)\n        se[(n == d) | (n == 0)] = np.nan\n        se = np.cumsum(se)\n        se = np.sqrt(se)\n        locs = np.isfinite(se) | (sp != 0)\n        se[locs] *= sp[locs]\n        se[~locs] = np.nan\n    else:\n        se = d / (n * n).astype(np.float64)\n        se = np.cumsum(se)\n        se = np.sqrt(se)\n    return (sp, se, utime, rtime, n, d)",
            "def _calc_survfunc_right(time, status, weights=None, entry=None, compress=True, retall=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Calculate the survival function and its standard error for a single\\n    group.\\n    '\n    if entry is None:\n        (utime, rtime) = np.unique(time, return_inverse=True)\n    else:\n        tx = np.concatenate((time, entry))\n        (utime, rtime) = np.unique(tx, return_inverse=True)\n        rtime = rtime[0:len(time)]\n    ml = len(utime)\n    if weights is None:\n        d = np.bincount(rtime, weights=status, minlength=ml)\n    else:\n        d = np.bincount(rtime, weights=status * weights, minlength=ml)\n    if weights is None:\n        n = np.bincount(rtime, minlength=ml)\n    else:\n        n = np.bincount(rtime, weights=weights, minlength=ml)\n    if entry is not None:\n        n = np.cumsum(n) - n\n        rentry = np.searchsorted(utime, entry, side='left')\n        if weights is None:\n            n0 = np.bincount(rentry, minlength=ml)\n        else:\n            n0 = np.bincount(rentry, weights=weights, minlength=ml)\n        n0 = np.cumsum(n0) - n0\n        n = n0 - n\n    else:\n        n = np.cumsum(n[::-1])[::-1]\n    if compress:\n        ii = np.flatnonzero(d > 0)\n        d = d[ii]\n        n = n[ii]\n        utime = utime[ii]\n    sp = 1 - d / n.astype(np.float64)\n    ii = sp < 1e-16\n    sp[ii] = 1e-16\n    sp = np.log(sp)\n    sp = np.cumsum(sp)\n    sp = np.exp(sp)\n    sp[ii] = 0\n    if not retall:\n        return (sp, utime, rtime, n, d)\n    if weights is None:\n        denom = n * (n - d)\n        denom = np.clip(denom, 1e-12, np.inf)\n        se = d / denom.astype(np.float64)\n        se[(n == d) | (n == 0)] = np.nan\n        se = np.cumsum(se)\n        se = np.sqrt(se)\n        locs = np.isfinite(se) | (sp != 0)\n        se[locs] *= sp[locs]\n        se[~locs] = np.nan\n    else:\n        se = d / (n * n).astype(np.float64)\n        se = np.cumsum(se)\n        se = np.sqrt(se)\n    return (sp, se, utime, rtime, n, d)",
            "def _calc_survfunc_right(time, status, weights=None, entry=None, compress=True, retall=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Calculate the survival function and its standard error for a single\\n    group.\\n    '\n    if entry is None:\n        (utime, rtime) = np.unique(time, return_inverse=True)\n    else:\n        tx = np.concatenate((time, entry))\n        (utime, rtime) = np.unique(tx, return_inverse=True)\n        rtime = rtime[0:len(time)]\n    ml = len(utime)\n    if weights is None:\n        d = np.bincount(rtime, weights=status, minlength=ml)\n    else:\n        d = np.bincount(rtime, weights=status * weights, minlength=ml)\n    if weights is None:\n        n = np.bincount(rtime, minlength=ml)\n    else:\n        n = np.bincount(rtime, weights=weights, minlength=ml)\n    if entry is not None:\n        n = np.cumsum(n) - n\n        rentry = np.searchsorted(utime, entry, side='left')\n        if weights is None:\n            n0 = np.bincount(rentry, minlength=ml)\n        else:\n            n0 = np.bincount(rentry, weights=weights, minlength=ml)\n        n0 = np.cumsum(n0) - n0\n        n = n0 - n\n    else:\n        n = np.cumsum(n[::-1])[::-1]\n    if compress:\n        ii = np.flatnonzero(d > 0)\n        d = d[ii]\n        n = n[ii]\n        utime = utime[ii]\n    sp = 1 - d / n.astype(np.float64)\n    ii = sp < 1e-16\n    sp[ii] = 1e-16\n    sp = np.log(sp)\n    sp = np.cumsum(sp)\n    sp = np.exp(sp)\n    sp[ii] = 0\n    if not retall:\n        return (sp, utime, rtime, n, d)\n    if weights is None:\n        denom = n * (n - d)\n        denom = np.clip(denom, 1e-12, np.inf)\n        se = d / denom.astype(np.float64)\n        se[(n == d) | (n == 0)] = np.nan\n        se = np.cumsum(se)\n        se = np.sqrt(se)\n        locs = np.isfinite(se) | (sp != 0)\n        se[locs] *= sp[locs]\n        se[~locs] = np.nan\n    else:\n        se = d / (n * n).astype(np.float64)\n        se = np.cumsum(se)\n        se = np.sqrt(se)\n    return (sp, se, utime, rtime, n, d)"
        ]
    },
    {
        "func_name": "_calc_incidence_right",
        "original": "def _calc_incidence_right(time, status, weights=None):\n    \"\"\"\n    Calculate the cumulative incidence function and its standard error.\n    \"\"\"\n    status0 = (status >= 1).astype(np.float64)\n    (sp, utime, rtime, n, d) = _calc_survfunc_right(time, status0, weights, compress=False, retall=False)\n    ngrp = int(status.max())\n    d = []\n    for k in range(ngrp):\n        status0 = (status == k + 1).astype(np.float64)\n        if weights is None:\n            d0 = np.bincount(rtime, weights=status0, minlength=len(utime))\n        else:\n            d0 = np.bincount(rtime, weights=status0 * weights, minlength=len(utime))\n        d.append(d0)\n    ip = []\n    sp0 = np.r_[1, sp[:-1]] / n\n    for k in range(ngrp):\n        ip0 = np.cumsum(sp0 * d[k])\n        ip.append(ip0)\n    if weights is not None:\n        return (ip, None, utime)\n    se = []\n    da = sum(d)\n    for k in range(ngrp):\n        ra = da / (n * (n - da))\n        v = ip[k] ** 2 * np.cumsum(ra)\n        v -= 2 * ip[k] * np.cumsum(ip[k] * ra)\n        v += np.cumsum(ip[k] ** 2 * ra)\n        ra = (n - d[k]) * d[k] / n\n        v += np.cumsum(sp0 ** 2 * ra)\n        ra = sp0 * d[k] / n\n        v -= 2 * ip[k] * np.cumsum(ra)\n        v += 2 * np.cumsum(ip[k] * ra)\n        se.append(np.sqrt(v))\n    return (ip, se, utime)",
        "mutated": [
            "def _calc_incidence_right(time, status, weights=None):\n    if False:\n        i = 10\n    '\\n    Calculate the cumulative incidence function and its standard error.\\n    '\n    status0 = (status >= 1).astype(np.float64)\n    (sp, utime, rtime, n, d) = _calc_survfunc_right(time, status0, weights, compress=False, retall=False)\n    ngrp = int(status.max())\n    d = []\n    for k in range(ngrp):\n        status0 = (status == k + 1).astype(np.float64)\n        if weights is None:\n            d0 = np.bincount(rtime, weights=status0, minlength=len(utime))\n        else:\n            d0 = np.bincount(rtime, weights=status0 * weights, minlength=len(utime))\n        d.append(d0)\n    ip = []\n    sp0 = np.r_[1, sp[:-1]] / n\n    for k in range(ngrp):\n        ip0 = np.cumsum(sp0 * d[k])\n        ip.append(ip0)\n    if weights is not None:\n        return (ip, None, utime)\n    se = []\n    da = sum(d)\n    for k in range(ngrp):\n        ra = da / (n * (n - da))\n        v = ip[k] ** 2 * np.cumsum(ra)\n        v -= 2 * ip[k] * np.cumsum(ip[k] * ra)\n        v += np.cumsum(ip[k] ** 2 * ra)\n        ra = (n - d[k]) * d[k] / n\n        v += np.cumsum(sp0 ** 2 * ra)\n        ra = sp0 * d[k] / n\n        v -= 2 * ip[k] * np.cumsum(ra)\n        v += 2 * np.cumsum(ip[k] * ra)\n        se.append(np.sqrt(v))\n    return (ip, se, utime)",
            "def _calc_incidence_right(time, status, weights=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Calculate the cumulative incidence function and its standard error.\\n    '\n    status0 = (status >= 1).astype(np.float64)\n    (sp, utime, rtime, n, d) = _calc_survfunc_right(time, status0, weights, compress=False, retall=False)\n    ngrp = int(status.max())\n    d = []\n    for k in range(ngrp):\n        status0 = (status == k + 1).astype(np.float64)\n        if weights is None:\n            d0 = np.bincount(rtime, weights=status0, minlength=len(utime))\n        else:\n            d0 = np.bincount(rtime, weights=status0 * weights, minlength=len(utime))\n        d.append(d0)\n    ip = []\n    sp0 = np.r_[1, sp[:-1]] / n\n    for k in range(ngrp):\n        ip0 = np.cumsum(sp0 * d[k])\n        ip.append(ip0)\n    if weights is not None:\n        return (ip, None, utime)\n    se = []\n    da = sum(d)\n    for k in range(ngrp):\n        ra = da / (n * (n - da))\n        v = ip[k] ** 2 * np.cumsum(ra)\n        v -= 2 * ip[k] * np.cumsum(ip[k] * ra)\n        v += np.cumsum(ip[k] ** 2 * ra)\n        ra = (n - d[k]) * d[k] / n\n        v += np.cumsum(sp0 ** 2 * ra)\n        ra = sp0 * d[k] / n\n        v -= 2 * ip[k] * np.cumsum(ra)\n        v += 2 * np.cumsum(ip[k] * ra)\n        se.append(np.sqrt(v))\n    return (ip, se, utime)",
            "def _calc_incidence_right(time, status, weights=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Calculate the cumulative incidence function and its standard error.\\n    '\n    status0 = (status >= 1).astype(np.float64)\n    (sp, utime, rtime, n, d) = _calc_survfunc_right(time, status0, weights, compress=False, retall=False)\n    ngrp = int(status.max())\n    d = []\n    for k in range(ngrp):\n        status0 = (status == k + 1).astype(np.float64)\n        if weights is None:\n            d0 = np.bincount(rtime, weights=status0, minlength=len(utime))\n        else:\n            d0 = np.bincount(rtime, weights=status0 * weights, minlength=len(utime))\n        d.append(d0)\n    ip = []\n    sp0 = np.r_[1, sp[:-1]] / n\n    for k in range(ngrp):\n        ip0 = np.cumsum(sp0 * d[k])\n        ip.append(ip0)\n    if weights is not None:\n        return (ip, None, utime)\n    se = []\n    da = sum(d)\n    for k in range(ngrp):\n        ra = da / (n * (n - da))\n        v = ip[k] ** 2 * np.cumsum(ra)\n        v -= 2 * ip[k] * np.cumsum(ip[k] * ra)\n        v += np.cumsum(ip[k] ** 2 * ra)\n        ra = (n - d[k]) * d[k] / n\n        v += np.cumsum(sp0 ** 2 * ra)\n        ra = sp0 * d[k] / n\n        v -= 2 * ip[k] * np.cumsum(ra)\n        v += 2 * np.cumsum(ip[k] * ra)\n        se.append(np.sqrt(v))\n    return (ip, se, utime)",
            "def _calc_incidence_right(time, status, weights=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Calculate the cumulative incidence function and its standard error.\\n    '\n    status0 = (status >= 1).astype(np.float64)\n    (sp, utime, rtime, n, d) = _calc_survfunc_right(time, status0, weights, compress=False, retall=False)\n    ngrp = int(status.max())\n    d = []\n    for k in range(ngrp):\n        status0 = (status == k + 1).astype(np.float64)\n        if weights is None:\n            d0 = np.bincount(rtime, weights=status0, minlength=len(utime))\n        else:\n            d0 = np.bincount(rtime, weights=status0 * weights, minlength=len(utime))\n        d.append(d0)\n    ip = []\n    sp0 = np.r_[1, sp[:-1]] / n\n    for k in range(ngrp):\n        ip0 = np.cumsum(sp0 * d[k])\n        ip.append(ip0)\n    if weights is not None:\n        return (ip, None, utime)\n    se = []\n    da = sum(d)\n    for k in range(ngrp):\n        ra = da / (n * (n - da))\n        v = ip[k] ** 2 * np.cumsum(ra)\n        v -= 2 * ip[k] * np.cumsum(ip[k] * ra)\n        v += np.cumsum(ip[k] ** 2 * ra)\n        ra = (n - d[k]) * d[k] / n\n        v += np.cumsum(sp0 ** 2 * ra)\n        ra = sp0 * d[k] / n\n        v -= 2 * ip[k] * np.cumsum(ra)\n        v += 2 * np.cumsum(ip[k] * ra)\n        se.append(np.sqrt(v))\n    return (ip, se, utime)",
            "def _calc_incidence_right(time, status, weights=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Calculate the cumulative incidence function and its standard error.\\n    '\n    status0 = (status >= 1).astype(np.float64)\n    (sp, utime, rtime, n, d) = _calc_survfunc_right(time, status0, weights, compress=False, retall=False)\n    ngrp = int(status.max())\n    d = []\n    for k in range(ngrp):\n        status0 = (status == k + 1).astype(np.float64)\n        if weights is None:\n            d0 = np.bincount(rtime, weights=status0, minlength=len(utime))\n        else:\n            d0 = np.bincount(rtime, weights=status0 * weights, minlength=len(utime))\n        d.append(d0)\n    ip = []\n    sp0 = np.r_[1, sp[:-1]] / n\n    for k in range(ngrp):\n        ip0 = np.cumsum(sp0 * d[k])\n        ip.append(ip0)\n    if weights is not None:\n        return (ip, None, utime)\n    se = []\n    da = sum(d)\n    for k in range(ngrp):\n        ra = da / (n * (n - da))\n        v = ip[k] ** 2 * np.cumsum(ra)\n        v -= 2 * ip[k] * np.cumsum(ip[k] * ra)\n        v += np.cumsum(ip[k] ** 2 * ra)\n        ra = (n - d[k]) * d[k] / n\n        v += np.cumsum(sp0 ** 2 * ra)\n        ra = sp0 * d[k] / n\n        v -= 2 * ip[k] * np.cumsum(ra)\n        v += 2 * np.cumsum(ip[k] * ra)\n        se.append(np.sqrt(v))\n    return (ip, se, utime)"
        ]
    },
    {
        "func_name": "_checkargs",
        "original": "def _checkargs(time, status, entry, freq_weights, exog):\n    if len(time) != len(status):\n        raise ValueError('time and status must have the same length')\n    if entry is not None and len(entry) != len(time):\n        msg = 'entry times and event times must have the same length'\n        raise ValueError(msg)\n    if entry is not None and np.any(entry >= time):\n        msg = 'Entry times must not occur on or after event times'\n        raise ValueError(msg)\n    if freq_weights is not None and len(freq_weights) != len(time):\n        raise ValueError('weights, time and status must have the same length')\n    if exog is not None and exog.shape[0] != len(time):\n        raise ValueError('the rows of exog should align with time')",
        "mutated": [
            "def _checkargs(time, status, entry, freq_weights, exog):\n    if False:\n        i = 10\n    if len(time) != len(status):\n        raise ValueError('time and status must have the same length')\n    if entry is not None and len(entry) != len(time):\n        msg = 'entry times and event times must have the same length'\n        raise ValueError(msg)\n    if entry is not None and np.any(entry >= time):\n        msg = 'Entry times must not occur on or after event times'\n        raise ValueError(msg)\n    if freq_weights is not None and len(freq_weights) != len(time):\n        raise ValueError('weights, time and status must have the same length')\n    if exog is not None and exog.shape[0] != len(time):\n        raise ValueError('the rows of exog should align with time')",
            "def _checkargs(time, status, entry, freq_weights, exog):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if len(time) != len(status):\n        raise ValueError('time and status must have the same length')\n    if entry is not None and len(entry) != len(time):\n        msg = 'entry times and event times must have the same length'\n        raise ValueError(msg)\n    if entry is not None and np.any(entry >= time):\n        msg = 'Entry times must not occur on or after event times'\n        raise ValueError(msg)\n    if freq_weights is not None and len(freq_weights) != len(time):\n        raise ValueError('weights, time and status must have the same length')\n    if exog is not None and exog.shape[0] != len(time):\n        raise ValueError('the rows of exog should align with time')",
            "def _checkargs(time, status, entry, freq_weights, exog):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if len(time) != len(status):\n        raise ValueError('time and status must have the same length')\n    if entry is not None and len(entry) != len(time):\n        msg = 'entry times and event times must have the same length'\n        raise ValueError(msg)\n    if entry is not None and np.any(entry >= time):\n        msg = 'Entry times must not occur on or after event times'\n        raise ValueError(msg)\n    if freq_weights is not None and len(freq_weights) != len(time):\n        raise ValueError('weights, time and status must have the same length')\n    if exog is not None and exog.shape[0] != len(time):\n        raise ValueError('the rows of exog should align with time')",
            "def _checkargs(time, status, entry, freq_weights, exog):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if len(time) != len(status):\n        raise ValueError('time and status must have the same length')\n    if entry is not None and len(entry) != len(time):\n        msg = 'entry times and event times must have the same length'\n        raise ValueError(msg)\n    if entry is not None and np.any(entry >= time):\n        msg = 'Entry times must not occur on or after event times'\n        raise ValueError(msg)\n    if freq_weights is not None and len(freq_weights) != len(time):\n        raise ValueError('weights, time and status must have the same length')\n    if exog is not None and exog.shape[0] != len(time):\n        raise ValueError('the rows of exog should align with time')",
            "def _checkargs(time, status, entry, freq_weights, exog):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if len(time) != len(status):\n        raise ValueError('time and status must have the same length')\n    if entry is not None and len(entry) != len(time):\n        msg = 'entry times and event times must have the same length'\n        raise ValueError(msg)\n    if entry is not None and np.any(entry >= time):\n        msg = 'Entry times must not occur on or after event times'\n        raise ValueError(msg)\n    if freq_weights is not None and len(freq_weights) != len(time):\n        raise ValueError('weights, time and status must have the same length')\n    if exog is not None and exog.shape[0] != len(time):\n        raise ValueError('the rows of exog should align with time')"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, time, status, title=None, freq_weights=None, exog=None, bw_factor=1.0, dimred=True):\n    _checkargs(time, status, None, freq_weights, None)\n    time = self.time = np.asarray(time)\n    status = self.status = np.asarray(status)\n    if freq_weights is not None:\n        freq_weights = self.freq_weights = np.asarray(freq_weights)\n    if exog is not None:\n        from ._kernel_estimates import _kernel_cumincidence\n        exog = self.exog = np.asarray(exog)\n        nobs = exog.shape[0]\n        kw = nobs ** (-1 / 3.0) * bw_factor\n        kfunc = lambda x: np.exp(-x ** 2 / kw ** 2).sum(1)\n        x = _kernel_cumincidence(time, status, exog, kfunc, freq_weights, dimred)\n        self.times = x[0]\n        self.cinc = x[1]\n        return\n    x = _calc_incidence_right(time, status, freq_weights)\n    self.cinc = x[0]\n    self.cinc_se = x[1]\n    self.times = x[2]\n    self.title = '' if not title else title",
        "mutated": [
            "def __init__(self, time, status, title=None, freq_weights=None, exog=None, bw_factor=1.0, dimred=True):\n    if False:\n        i = 10\n    _checkargs(time, status, None, freq_weights, None)\n    time = self.time = np.asarray(time)\n    status = self.status = np.asarray(status)\n    if freq_weights is not None:\n        freq_weights = self.freq_weights = np.asarray(freq_weights)\n    if exog is not None:\n        from ._kernel_estimates import _kernel_cumincidence\n        exog = self.exog = np.asarray(exog)\n        nobs = exog.shape[0]\n        kw = nobs ** (-1 / 3.0) * bw_factor\n        kfunc = lambda x: np.exp(-x ** 2 / kw ** 2).sum(1)\n        x = _kernel_cumincidence(time, status, exog, kfunc, freq_weights, dimred)\n        self.times = x[0]\n        self.cinc = x[1]\n        return\n    x = _calc_incidence_right(time, status, freq_weights)\n    self.cinc = x[0]\n    self.cinc_se = x[1]\n    self.times = x[2]\n    self.title = '' if not title else title",
            "def __init__(self, time, status, title=None, freq_weights=None, exog=None, bw_factor=1.0, dimred=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    _checkargs(time, status, None, freq_weights, None)\n    time = self.time = np.asarray(time)\n    status = self.status = np.asarray(status)\n    if freq_weights is not None:\n        freq_weights = self.freq_weights = np.asarray(freq_weights)\n    if exog is not None:\n        from ._kernel_estimates import _kernel_cumincidence\n        exog = self.exog = np.asarray(exog)\n        nobs = exog.shape[0]\n        kw = nobs ** (-1 / 3.0) * bw_factor\n        kfunc = lambda x: np.exp(-x ** 2 / kw ** 2).sum(1)\n        x = _kernel_cumincidence(time, status, exog, kfunc, freq_weights, dimred)\n        self.times = x[0]\n        self.cinc = x[1]\n        return\n    x = _calc_incidence_right(time, status, freq_weights)\n    self.cinc = x[0]\n    self.cinc_se = x[1]\n    self.times = x[2]\n    self.title = '' if not title else title",
            "def __init__(self, time, status, title=None, freq_weights=None, exog=None, bw_factor=1.0, dimred=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    _checkargs(time, status, None, freq_weights, None)\n    time = self.time = np.asarray(time)\n    status = self.status = np.asarray(status)\n    if freq_weights is not None:\n        freq_weights = self.freq_weights = np.asarray(freq_weights)\n    if exog is not None:\n        from ._kernel_estimates import _kernel_cumincidence\n        exog = self.exog = np.asarray(exog)\n        nobs = exog.shape[0]\n        kw = nobs ** (-1 / 3.0) * bw_factor\n        kfunc = lambda x: np.exp(-x ** 2 / kw ** 2).sum(1)\n        x = _kernel_cumincidence(time, status, exog, kfunc, freq_weights, dimred)\n        self.times = x[0]\n        self.cinc = x[1]\n        return\n    x = _calc_incidence_right(time, status, freq_weights)\n    self.cinc = x[0]\n    self.cinc_se = x[1]\n    self.times = x[2]\n    self.title = '' if not title else title",
            "def __init__(self, time, status, title=None, freq_weights=None, exog=None, bw_factor=1.0, dimred=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    _checkargs(time, status, None, freq_weights, None)\n    time = self.time = np.asarray(time)\n    status = self.status = np.asarray(status)\n    if freq_weights is not None:\n        freq_weights = self.freq_weights = np.asarray(freq_weights)\n    if exog is not None:\n        from ._kernel_estimates import _kernel_cumincidence\n        exog = self.exog = np.asarray(exog)\n        nobs = exog.shape[0]\n        kw = nobs ** (-1 / 3.0) * bw_factor\n        kfunc = lambda x: np.exp(-x ** 2 / kw ** 2).sum(1)\n        x = _kernel_cumincidence(time, status, exog, kfunc, freq_weights, dimred)\n        self.times = x[0]\n        self.cinc = x[1]\n        return\n    x = _calc_incidence_right(time, status, freq_weights)\n    self.cinc = x[0]\n    self.cinc_se = x[1]\n    self.times = x[2]\n    self.title = '' if not title else title",
            "def __init__(self, time, status, title=None, freq_weights=None, exog=None, bw_factor=1.0, dimred=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    _checkargs(time, status, None, freq_weights, None)\n    time = self.time = np.asarray(time)\n    status = self.status = np.asarray(status)\n    if freq_weights is not None:\n        freq_weights = self.freq_weights = np.asarray(freq_weights)\n    if exog is not None:\n        from ._kernel_estimates import _kernel_cumincidence\n        exog = self.exog = np.asarray(exog)\n        nobs = exog.shape[0]\n        kw = nobs ** (-1 / 3.0) * bw_factor\n        kfunc = lambda x: np.exp(-x ** 2 / kw ** 2).sum(1)\n        x = _kernel_cumincidence(time, status, exog, kfunc, freq_weights, dimred)\n        self.times = x[0]\n        self.cinc = x[1]\n        return\n    x = _calc_incidence_right(time, status, freq_weights)\n    self.cinc = x[0]\n    self.cinc_se = x[1]\n    self.times = x[2]\n    self.title = '' if not title else title"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, time, status, entry=None, title=None, freq_weights=None, exog=None, bw_factor=1.0):\n    _checkargs(time, status, entry, freq_weights, exog)\n    time = self.time = np.asarray(time)\n    status = self.status = np.asarray(status)\n    if freq_weights is not None:\n        freq_weights = self.freq_weights = np.asarray(freq_weights)\n    if entry is not None:\n        entry = self.entry = np.asarray(entry)\n    if exog is not None:\n        if entry is not None:\n            raise ValueError('exog and entry cannot both be present')\n        from ._kernel_estimates import _kernel_survfunc\n        exog = self.exog = np.asarray(exog)\n        nobs = exog.shape[0]\n        kw = nobs ** (-1 / 3.0) * bw_factor\n        kfunc = lambda x: np.exp(-x ** 2 / kw ** 2).sum(1)\n        x = _kernel_survfunc(time, status, exog, kfunc, freq_weights)\n        self.surv_prob = x[0]\n        self.surv_times = x[1]\n        return\n    x = _calc_survfunc_right(time, status, weights=freq_weights, entry=entry)\n    self.surv_prob = x[0]\n    self.surv_prob_se = x[1]\n    self.surv_times = x[2]\n    self.n_risk = x[4]\n    self.n_events = x[5]\n    self.title = '' if not title else title",
        "mutated": [
            "def __init__(self, time, status, entry=None, title=None, freq_weights=None, exog=None, bw_factor=1.0):\n    if False:\n        i = 10\n    _checkargs(time, status, entry, freq_weights, exog)\n    time = self.time = np.asarray(time)\n    status = self.status = np.asarray(status)\n    if freq_weights is not None:\n        freq_weights = self.freq_weights = np.asarray(freq_weights)\n    if entry is not None:\n        entry = self.entry = np.asarray(entry)\n    if exog is not None:\n        if entry is not None:\n            raise ValueError('exog and entry cannot both be present')\n        from ._kernel_estimates import _kernel_survfunc\n        exog = self.exog = np.asarray(exog)\n        nobs = exog.shape[0]\n        kw = nobs ** (-1 / 3.0) * bw_factor\n        kfunc = lambda x: np.exp(-x ** 2 / kw ** 2).sum(1)\n        x = _kernel_survfunc(time, status, exog, kfunc, freq_weights)\n        self.surv_prob = x[0]\n        self.surv_times = x[1]\n        return\n    x = _calc_survfunc_right(time, status, weights=freq_weights, entry=entry)\n    self.surv_prob = x[0]\n    self.surv_prob_se = x[1]\n    self.surv_times = x[2]\n    self.n_risk = x[4]\n    self.n_events = x[5]\n    self.title = '' if not title else title",
            "def __init__(self, time, status, entry=None, title=None, freq_weights=None, exog=None, bw_factor=1.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    _checkargs(time, status, entry, freq_weights, exog)\n    time = self.time = np.asarray(time)\n    status = self.status = np.asarray(status)\n    if freq_weights is not None:\n        freq_weights = self.freq_weights = np.asarray(freq_weights)\n    if entry is not None:\n        entry = self.entry = np.asarray(entry)\n    if exog is not None:\n        if entry is not None:\n            raise ValueError('exog and entry cannot both be present')\n        from ._kernel_estimates import _kernel_survfunc\n        exog = self.exog = np.asarray(exog)\n        nobs = exog.shape[0]\n        kw = nobs ** (-1 / 3.0) * bw_factor\n        kfunc = lambda x: np.exp(-x ** 2 / kw ** 2).sum(1)\n        x = _kernel_survfunc(time, status, exog, kfunc, freq_weights)\n        self.surv_prob = x[0]\n        self.surv_times = x[1]\n        return\n    x = _calc_survfunc_right(time, status, weights=freq_weights, entry=entry)\n    self.surv_prob = x[0]\n    self.surv_prob_se = x[1]\n    self.surv_times = x[2]\n    self.n_risk = x[4]\n    self.n_events = x[5]\n    self.title = '' if not title else title",
            "def __init__(self, time, status, entry=None, title=None, freq_weights=None, exog=None, bw_factor=1.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    _checkargs(time, status, entry, freq_weights, exog)\n    time = self.time = np.asarray(time)\n    status = self.status = np.asarray(status)\n    if freq_weights is not None:\n        freq_weights = self.freq_weights = np.asarray(freq_weights)\n    if entry is not None:\n        entry = self.entry = np.asarray(entry)\n    if exog is not None:\n        if entry is not None:\n            raise ValueError('exog and entry cannot both be present')\n        from ._kernel_estimates import _kernel_survfunc\n        exog = self.exog = np.asarray(exog)\n        nobs = exog.shape[0]\n        kw = nobs ** (-1 / 3.0) * bw_factor\n        kfunc = lambda x: np.exp(-x ** 2 / kw ** 2).sum(1)\n        x = _kernel_survfunc(time, status, exog, kfunc, freq_weights)\n        self.surv_prob = x[0]\n        self.surv_times = x[1]\n        return\n    x = _calc_survfunc_right(time, status, weights=freq_weights, entry=entry)\n    self.surv_prob = x[0]\n    self.surv_prob_se = x[1]\n    self.surv_times = x[2]\n    self.n_risk = x[4]\n    self.n_events = x[5]\n    self.title = '' if not title else title",
            "def __init__(self, time, status, entry=None, title=None, freq_weights=None, exog=None, bw_factor=1.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    _checkargs(time, status, entry, freq_weights, exog)\n    time = self.time = np.asarray(time)\n    status = self.status = np.asarray(status)\n    if freq_weights is not None:\n        freq_weights = self.freq_weights = np.asarray(freq_weights)\n    if entry is not None:\n        entry = self.entry = np.asarray(entry)\n    if exog is not None:\n        if entry is not None:\n            raise ValueError('exog and entry cannot both be present')\n        from ._kernel_estimates import _kernel_survfunc\n        exog = self.exog = np.asarray(exog)\n        nobs = exog.shape[0]\n        kw = nobs ** (-1 / 3.0) * bw_factor\n        kfunc = lambda x: np.exp(-x ** 2 / kw ** 2).sum(1)\n        x = _kernel_survfunc(time, status, exog, kfunc, freq_weights)\n        self.surv_prob = x[0]\n        self.surv_times = x[1]\n        return\n    x = _calc_survfunc_right(time, status, weights=freq_weights, entry=entry)\n    self.surv_prob = x[0]\n    self.surv_prob_se = x[1]\n    self.surv_times = x[2]\n    self.n_risk = x[4]\n    self.n_events = x[5]\n    self.title = '' if not title else title",
            "def __init__(self, time, status, entry=None, title=None, freq_weights=None, exog=None, bw_factor=1.0):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    _checkargs(time, status, entry, freq_weights, exog)\n    time = self.time = np.asarray(time)\n    status = self.status = np.asarray(status)\n    if freq_weights is not None:\n        freq_weights = self.freq_weights = np.asarray(freq_weights)\n    if entry is not None:\n        entry = self.entry = np.asarray(entry)\n    if exog is not None:\n        if entry is not None:\n            raise ValueError('exog and entry cannot both be present')\n        from ._kernel_estimates import _kernel_survfunc\n        exog = self.exog = np.asarray(exog)\n        nobs = exog.shape[0]\n        kw = nobs ** (-1 / 3.0) * bw_factor\n        kfunc = lambda x: np.exp(-x ** 2 / kw ** 2).sum(1)\n        x = _kernel_survfunc(time, status, exog, kfunc, freq_weights)\n        self.surv_prob = x[0]\n        self.surv_times = x[1]\n        return\n    x = _calc_survfunc_right(time, status, weights=freq_weights, entry=entry)\n    self.surv_prob = x[0]\n    self.surv_prob_se = x[1]\n    self.surv_times = x[2]\n    self.n_risk = x[4]\n    self.n_events = x[5]\n    self.title = '' if not title else title"
        ]
    },
    {
        "func_name": "plot",
        "original": "def plot(self, ax=None):\n    \"\"\"\n        Plot the survival function.\n\n        Examples\n        --------\n        Change the line color:\n\n        >>> import statsmodels.api as sm\n        >>> data = sm.datasets.get_rdataset(\"flchain\", \"survival\").data\n        >>> df = data.loc[data.sex == \"F\", :]\n        >>> sf = sm.SurvfuncRight(df[\"futime\"], df[\"death\"])\n        >>> fig = sf.plot()\n        >>> ax = fig.get_axes()[0]\n        >>> li = ax.get_lines()\n        >>> li[0].set_color('purple')\n        >>> li[1].set_color('purple')\n\n        Do not show the censoring points:\n\n        >>> fig = sf.plot()\n        >>> ax = fig.get_axes()[0]\n        >>> li = ax.get_lines()\n        >>> li[1].set_visible(False)\n        \"\"\"\n    return plot_survfunc(self, ax)",
        "mutated": [
            "def plot(self, ax=None):\n    if False:\n        i = 10\n    '\\n        Plot the survival function.\\n\\n        Examples\\n        --------\\n        Change the line color:\\n\\n        >>> import statsmodels.api as sm\\n        >>> data = sm.datasets.get_rdataset(\"flchain\", \"survival\").data\\n        >>> df = data.loc[data.sex == \"F\", :]\\n        >>> sf = sm.SurvfuncRight(df[\"futime\"], df[\"death\"])\\n        >>> fig = sf.plot()\\n        >>> ax = fig.get_axes()[0]\\n        >>> li = ax.get_lines()\\n        >>> li[0].set_color(\\'purple\\')\\n        >>> li[1].set_color(\\'purple\\')\\n\\n        Do not show the censoring points:\\n\\n        >>> fig = sf.plot()\\n        >>> ax = fig.get_axes()[0]\\n        >>> li = ax.get_lines()\\n        >>> li[1].set_visible(False)\\n        '\n    return plot_survfunc(self, ax)",
            "def plot(self, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Plot the survival function.\\n\\n        Examples\\n        --------\\n        Change the line color:\\n\\n        >>> import statsmodels.api as sm\\n        >>> data = sm.datasets.get_rdataset(\"flchain\", \"survival\").data\\n        >>> df = data.loc[data.sex == \"F\", :]\\n        >>> sf = sm.SurvfuncRight(df[\"futime\"], df[\"death\"])\\n        >>> fig = sf.plot()\\n        >>> ax = fig.get_axes()[0]\\n        >>> li = ax.get_lines()\\n        >>> li[0].set_color(\\'purple\\')\\n        >>> li[1].set_color(\\'purple\\')\\n\\n        Do not show the censoring points:\\n\\n        >>> fig = sf.plot()\\n        >>> ax = fig.get_axes()[0]\\n        >>> li = ax.get_lines()\\n        >>> li[1].set_visible(False)\\n        '\n    return plot_survfunc(self, ax)",
            "def plot(self, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Plot the survival function.\\n\\n        Examples\\n        --------\\n        Change the line color:\\n\\n        >>> import statsmodels.api as sm\\n        >>> data = sm.datasets.get_rdataset(\"flchain\", \"survival\").data\\n        >>> df = data.loc[data.sex == \"F\", :]\\n        >>> sf = sm.SurvfuncRight(df[\"futime\"], df[\"death\"])\\n        >>> fig = sf.plot()\\n        >>> ax = fig.get_axes()[0]\\n        >>> li = ax.get_lines()\\n        >>> li[0].set_color(\\'purple\\')\\n        >>> li[1].set_color(\\'purple\\')\\n\\n        Do not show the censoring points:\\n\\n        >>> fig = sf.plot()\\n        >>> ax = fig.get_axes()[0]\\n        >>> li = ax.get_lines()\\n        >>> li[1].set_visible(False)\\n        '\n    return plot_survfunc(self, ax)",
            "def plot(self, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Plot the survival function.\\n\\n        Examples\\n        --------\\n        Change the line color:\\n\\n        >>> import statsmodels.api as sm\\n        >>> data = sm.datasets.get_rdataset(\"flchain\", \"survival\").data\\n        >>> df = data.loc[data.sex == \"F\", :]\\n        >>> sf = sm.SurvfuncRight(df[\"futime\"], df[\"death\"])\\n        >>> fig = sf.plot()\\n        >>> ax = fig.get_axes()[0]\\n        >>> li = ax.get_lines()\\n        >>> li[0].set_color(\\'purple\\')\\n        >>> li[1].set_color(\\'purple\\')\\n\\n        Do not show the censoring points:\\n\\n        >>> fig = sf.plot()\\n        >>> ax = fig.get_axes()[0]\\n        >>> li = ax.get_lines()\\n        >>> li[1].set_visible(False)\\n        '\n    return plot_survfunc(self, ax)",
            "def plot(self, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Plot the survival function.\\n\\n        Examples\\n        --------\\n        Change the line color:\\n\\n        >>> import statsmodels.api as sm\\n        >>> data = sm.datasets.get_rdataset(\"flchain\", \"survival\").data\\n        >>> df = data.loc[data.sex == \"F\", :]\\n        >>> sf = sm.SurvfuncRight(df[\"futime\"], df[\"death\"])\\n        >>> fig = sf.plot()\\n        >>> ax = fig.get_axes()[0]\\n        >>> li = ax.get_lines()\\n        >>> li[0].set_color(\\'purple\\')\\n        >>> li[1].set_color(\\'purple\\')\\n\\n        Do not show the censoring points:\\n\\n        >>> fig = sf.plot()\\n        >>> ax = fig.get_axes()[0]\\n        >>> li = ax.get_lines()\\n        >>> li[1].set_visible(False)\\n        '\n    return plot_survfunc(self, ax)"
        ]
    },
    {
        "func_name": "quantile",
        "original": "def quantile(self, p):\n    \"\"\"\n        Estimated quantile of a survival distribution.\n\n        Parameters\n        ----------\n        p : float\n            The probability point at which the quantile\n            is determined.\n\n        Returns the estimated quantile.\n        \"\"\"\n    ii = np.flatnonzero(self.surv_prob < 1 - p)\n    if len(ii) == 0:\n        return np.nan\n    return self.surv_times[ii[0]]",
        "mutated": [
            "def quantile(self, p):\n    if False:\n        i = 10\n    '\\n        Estimated quantile of a survival distribution.\\n\\n        Parameters\\n        ----------\\n        p : float\\n            The probability point at which the quantile\\n            is determined.\\n\\n        Returns the estimated quantile.\\n        '\n    ii = np.flatnonzero(self.surv_prob < 1 - p)\n    if len(ii) == 0:\n        return np.nan\n    return self.surv_times[ii[0]]",
            "def quantile(self, p):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Estimated quantile of a survival distribution.\\n\\n        Parameters\\n        ----------\\n        p : float\\n            The probability point at which the quantile\\n            is determined.\\n\\n        Returns the estimated quantile.\\n        '\n    ii = np.flatnonzero(self.surv_prob < 1 - p)\n    if len(ii) == 0:\n        return np.nan\n    return self.surv_times[ii[0]]",
            "def quantile(self, p):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Estimated quantile of a survival distribution.\\n\\n        Parameters\\n        ----------\\n        p : float\\n            The probability point at which the quantile\\n            is determined.\\n\\n        Returns the estimated quantile.\\n        '\n    ii = np.flatnonzero(self.surv_prob < 1 - p)\n    if len(ii) == 0:\n        return np.nan\n    return self.surv_times[ii[0]]",
            "def quantile(self, p):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Estimated quantile of a survival distribution.\\n\\n        Parameters\\n        ----------\\n        p : float\\n            The probability point at which the quantile\\n            is determined.\\n\\n        Returns the estimated quantile.\\n        '\n    ii = np.flatnonzero(self.surv_prob < 1 - p)\n    if len(ii) == 0:\n        return np.nan\n    return self.surv_times[ii[0]]",
            "def quantile(self, p):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Estimated quantile of a survival distribution.\\n\\n        Parameters\\n        ----------\\n        p : float\\n            The probability point at which the quantile\\n            is determined.\\n\\n        Returns the estimated quantile.\\n        '\n    ii = np.flatnonzero(self.surv_prob < 1 - p)\n    if len(ii) == 0:\n        return np.nan\n    return self.surv_times[ii[0]]"
        ]
    },
    {
        "func_name": "quantile_ci",
        "original": "def quantile_ci(self, p, alpha=0.05, method='cloglog'):\n    \"\"\"\n        Returns a confidence interval for a survival quantile.\n\n        Parameters\n        ----------\n        p : float\n            The probability point for which a confidence interval is\n            determined.\n        alpha : float\n            The confidence interval has nominal coverage probability\n            1 - `alpha`.\n        method : str\n            Function to use for g-transformation, must be ...\n\n        Returns\n        -------\n        lb : float\n            The lower confidence limit.\n        ub : float\n            The upper confidence limit.\n\n        Notes\n        -----\n        The confidence interval is obtained by inverting Z-tests.  The\n        limits of the confidence interval will always be observed\n        event times.\n\n        References\n        ----------\n        The method is based on the approach used in SAS, documented here:\n\n          http://support.sas.com/documentation/cdl/en/statug/68162/HTML/default/viewer.htm#statug_lifetest_details03.htm\n        \"\"\"\n    tr = norm.ppf(1 - alpha / 2)\n    method = method.lower()\n    if method == 'cloglog':\n        g = lambda x: np.log(-np.log(x))\n        gprime = lambda x: -1 / (x * np.log(x))\n    elif method == 'linear':\n        g = lambda x: x\n        gprime = lambda x: 1\n    elif method == 'log':\n        g = np.log\n        gprime = lambda x: 1 / x\n    elif method == 'logit':\n        g = lambda x: np.log(x / (1 - x))\n        gprime = lambda x: 1 / (x * (1 - x))\n    elif method == 'asinsqrt':\n        g = lambda x: np.arcsin(np.sqrt(x))\n        gprime = lambda x: 1 / (2 * np.sqrt(x) * np.sqrt(1 - x))\n    else:\n        raise ValueError('unknown method')\n    r = g(self.surv_prob) - g(1 - p)\n    r /= gprime(self.surv_prob) * self.surv_prob_se\n    ii = np.flatnonzero(np.abs(r) <= tr)\n    if len(ii) == 0:\n        return (np.nan, np.nan)\n    lb = self.surv_times[ii[0]]\n    if ii[-1] == len(self.surv_times) - 1:\n        ub = np.inf\n    else:\n        ub = self.surv_times[ii[-1] + 1]\n    return (lb, ub)",
        "mutated": [
            "def quantile_ci(self, p, alpha=0.05, method='cloglog'):\n    if False:\n        i = 10\n    '\\n        Returns a confidence interval for a survival quantile.\\n\\n        Parameters\\n        ----------\\n        p : float\\n            The probability point for which a confidence interval is\\n            determined.\\n        alpha : float\\n            The confidence interval has nominal coverage probability\\n            1 - `alpha`.\\n        method : str\\n            Function to use for g-transformation, must be ...\\n\\n        Returns\\n        -------\\n        lb : float\\n            The lower confidence limit.\\n        ub : float\\n            The upper confidence limit.\\n\\n        Notes\\n        -----\\n        The confidence interval is obtained by inverting Z-tests.  The\\n        limits of the confidence interval will always be observed\\n        event times.\\n\\n        References\\n        ----------\\n        The method is based on the approach used in SAS, documented here:\\n\\n          http://support.sas.com/documentation/cdl/en/statug/68162/HTML/default/viewer.htm#statug_lifetest_details03.htm\\n        '\n    tr = norm.ppf(1 - alpha / 2)\n    method = method.lower()\n    if method == 'cloglog':\n        g = lambda x: np.log(-np.log(x))\n        gprime = lambda x: -1 / (x * np.log(x))\n    elif method == 'linear':\n        g = lambda x: x\n        gprime = lambda x: 1\n    elif method == 'log':\n        g = np.log\n        gprime = lambda x: 1 / x\n    elif method == 'logit':\n        g = lambda x: np.log(x / (1 - x))\n        gprime = lambda x: 1 / (x * (1 - x))\n    elif method == 'asinsqrt':\n        g = lambda x: np.arcsin(np.sqrt(x))\n        gprime = lambda x: 1 / (2 * np.sqrt(x) * np.sqrt(1 - x))\n    else:\n        raise ValueError('unknown method')\n    r = g(self.surv_prob) - g(1 - p)\n    r /= gprime(self.surv_prob) * self.surv_prob_se\n    ii = np.flatnonzero(np.abs(r) <= tr)\n    if len(ii) == 0:\n        return (np.nan, np.nan)\n    lb = self.surv_times[ii[0]]\n    if ii[-1] == len(self.surv_times) - 1:\n        ub = np.inf\n    else:\n        ub = self.surv_times[ii[-1] + 1]\n    return (lb, ub)",
            "def quantile_ci(self, p, alpha=0.05, method='cloglog'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns a confidence interval for a survival quantile.\\n\\n        Parameters\\n        ----------\\n        p : float\\n            The probability point for which a confidence interval is\\n            determined.\\n        alpha : float\\n            The confidence interval has nominal coverage probability\\n            1 - `alpha`.\\n        method : str\\n            Function to use for g-transformation, must be ...\\n\\n        Returns\\n        -------\\n        lb : float\\n            The lower confidence limit.\\n        ub : float\\n            The upper confidence limit.\\n\\n        Notes\\n        -----\\n        The confidence interval is obtained by inverting Z-tests.  The\\n        limits of the confidence interval will always be observed\\n        event times.\\n\\n        References\\n        ----------\\n        The method is based on the approach used in SAS, documented here:\\n\\n          http://support.sas.com/documentation/cdl/en/statug/68162/HTML/default/viewer.htm#statug_lifetest_details03.htm\\n        '\n    tr = norm.ppf(1 - alpha / 2)\n    method = method.lower()\n    if method == 'cloglog':\n        g = lambda x: np.log(-np.log(x))\n        gprime = lambda x: -1 / (x * np.log(x))\n    elif method == 'linear':\n        g = lambda x: x\n        gprime = lambda x: 1\n    elif method == 'log':\n        g = np.log\n        gprime = lambda x: 1 / x\n    elif method == 'logit':\n        g = lambda x: np.log(x / (1 - x))\n        gprime = lambda x: 1 / (x * (1 - x))\n    elif method == 'asinsqrt':\n        g = lambda x: np.arcsin(np.sqrt(x))\n        gprime = lambda x: 1 / (2 * np.sqrt(x) * np.sqrt(1 - x))\n    else:\n        raise ValueError('unknown method')\n    r = g(self.surv_prob) - g(1 - p)\n    r /= gprime(self.surv_prob) * self.surv_prob_se\n    ii = np.flatnonzero(np.abs(r) <= tr)\n    if len(ii) == 0:\n        return (np.nan, np.nan)\n    lb = self.surv_times[ii[0]]\n    if ii[-1] == len(self.surv_times) - 1:\n        ub = np.inf\n    else:\n        ub = self.surv_times[ii[-1] + 1]\n    return (lb, ub)",
            "def quantile_ci(self, p, alpha=0.05, method='cloglog'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns a confidence interval for a survival quantile.\\n\\n        Parameters\\n        ----------\\n        p : float\\n            The probability point for which a confidence interval is\\n            determined.\\n        alpha : float\\n            The confidence interval has nominal coverage probability\\n            1 - `alpha`.\\n        method : str\\n            Function to use for g-transformation, must be ...\\n\\n        Returns\\n        -------\\n        lb : float\\n            The lower confidence limit.\\n        ub : float\\n            The upper confidence limit.\\n\\n        Notes\\n        -----\\n        The confidence interval is obtained by inverting Z-tests.  The\\n        limits of the confidence interval will always be observed\\n        event times.\\n\\n        References\\n        ----------\\n        The method is based on the approach used in SAS, documented here:\\n\\n          http://support.sas.com/documentation/cdl/en/statug/68162/HTML/default/viewer.htm#statug_lifetest_details03.htm\\n        '\n    tr = norm.ppf(1 - alpha / 2)\n    method = method.lower()\n    if method == 'cloglog':\n        g = lambda x: np.log(-np.log(x))\n        gprime = lambda x: -1 / (x * np.log(x))\n    elif method == 'linear':\n        g = lambda x: x\n        gprime = lambda x: 1\n    elif method == 'log':\n        g = np.log\n        gprime = lambda x: 1 / x\n    elif method == 'logit':\n        g = lambda x: np.log(x / (1 - x))\n        gprime = lambda x: 1 / (x * (1 - x))\n    elif method == 'asinsqrt':\n        g = lambda x: np.arcsin(np.sqrt(x))\n        gprime = lambda x: 1 / (2 * np.sqrt(x) * np.sqrt(1 - x))\n    else:\n        raise ValueError('unknown method')\n    r = g(self.surv_prob) - g(1 - p)\n    r /= gprime(self.surv_prob) * self.surv_prob_se\n    ii = np.flatnonzero(np.abs(r) <= tr)\n    if len(ii) == 0:\n        return (np.nan, np.nan)\n    lb = self.surv_times[ii[0]]\n    if ii[-1] == len(self.surv_times) - 1:\n        ub = np.inf\n    else:\n        ub = self.surv_times[ii[-1] + 1]\n    return (lb, ub)",
            "def quantile_ci(self, p, alpha=0.05, method='cloglog'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns a confidence interval for a survival quantile.\\n\\n        Parameters\\n        ----------\\n        p : float\\n            The probability point for which a confidence interval is\\n            determined.\\n        alpha : float\\n            The confidence interval has nominal coverage probability\\n            1 - `alpha`.\\n        method : str\\n            Function to use for g-transformation, must be ...\\n\\n        Returns\\n        -------\\n        lb : float\\n            The lower confidence limit.\\n        ub : float\\n            The upper confidence limit.\\n\\n        Notes\\n        -----\\n        The confidence interval is obtained by inverting Z-tests.  The\\n        limits of the confidence interval will always be observed\\n        event times.\\n\\n        References\\n        ----------\\n        The method is based on the approach used in SAS, documented here:\\n\\n          http://support.sas.com/documentation/cdl/en/statug/68162/HTML/default/viewer.htm#statug_lifetest_details03.htm\\n        '\n    tr = norm.ppf(1 - alpha / 2)\n    method = method.lower()\n    if method == 'cloglog':\n        g = lambda x: np.log(-np.log(x))\n        gprime = lambda x: -1 / (x * np.log(x))\n    elif method == 'linear':\n        g = lambda x: x\n        gprime = lambda x: 1\n    elif method == 'log':\n        g = np.log\n        gprime = lambda x: 1 / x\n    elif method == 'logit':\n        g = lambda x: np.log(x / (1 - x))\n        gprime = lambda x: 1 / (x * (1 - x))\n    elif method == 'asinsqrt':\n        g = lambda x: np.arcsin(np.sqrt(x))\n        gprime = lambda x: 1 / (2 * np.sqrt(x) * np.sqrt(1 - x))\n    else:\n        raise ValueError('unknown method')\n    r = g(self.surv_prob) - g(1 - p)\n    r /= gprime(self.surv_prob) * self.surv_prob_se\n    ii = np.flatnonzero(np.abs(r) <= tr)\n    if len(ii) == 0:\n        return (np.nan, np.nan)\n    lb = self.surv_times[ii[0]]\n    if ii[-1] == len(self.surv_times) - 1:\n        ub = np.inf\n    else:\n        ub = self.surv_times[ii[-1] + 1]\n    return (lb, ub)",
            "def quantile_ci(self, p, alpha=0.05, method='cloglog'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns a confidence interval for a survival quantile.\\n\\n        Parameters\\n        ----------\\n        p : float\\n            The probability point for which a confidence interval is\\n            determined.\\n        alpha : float\\n            The confidence interval has nominal coverage probability\\n            1 - `alpha`.\\n        method : str\\n            Function to use for g-transformation, must be ...\\n\\n        Returns\\n        -------\\n        lb : float\\n            The lower confidence limit.\\n        ub : float\\n            The upper confidence limit.\\n\\n        Notes\\n        -----\\n        The confidence interval is obtained by inverting Z-tests.  The\\n        limits of the confidence interval will always be observed\\n        event times.\\n\\n        References\\n        ----------\\n        The method is based on the approach used in SAS, documented here:\\n\\n          http://support.sas.com/documentation/cdl/en/statug/68162/HTML/default/viewer.htm#statug_lifetest_details03.htm\\n        '\n    tr = norm.ppf(1 - alpha / 2)\n    method = method.lower()\n    if method == 'cloglog':\n        g = lambda x: np.log(-np.log(x))\n        gprime = lambda x: -1 / (x * np.log(x))\n    elif method == 'linear':\n        g = lambda x: x\n        gprime = lambda x: 1\n    elif method == 'log':\n        g = np.log\n        gprime = lambda x: 1 / x\n    elif method == 'logit':\n        g = lambda x: np.log(x / (1 - x))\n        gprime = lambda x: 1 / (x * (1 - x))\n    elif method == 'asinsqrt':\n        g = lambda x: np.arcsin(np.sqrt(x))\n        gprime = lambda x: 1 / (2 * np.sqrt(x) * np.sqrt(1 - x))\n    else:\n        raise ValueError('unknown method')\n    r = g(self.surv_prob) - g(1 - p)\n    r /= gprime(self.surv_prob) * self.surv_prob_se\n    ii = np.flatnonzero(np.abs(r) <= tr)\n    if len(ii) == 0:\n        return (np.nan, np.nan)\n    lb = self.surv_times[ii[0]]\n    if ii[-1] == len(self.surv_times) - 1:\n        ub = np.inf\n    else:\n        ub = self.surv_times[ii[-1] + 1]\n    return (lb, ub)"
        ]
    },
    {
        "func_name": "summary",
        "original": "def summary(self):\n    \"\"\"\n        Return a summary of the estimated survival function.\n\n        The summary is a dataframe containing the unique event times,\n        estimated survival function values, and related quantities.\n        \"\"\"\n    df = pd.DataFrame(index=self.surv_times)\n    df.index.name = 'Time'\n    df['Surv prob'] = self.surv_prob\n    df['Surv prob SE'] = self.surv_prob_se\n    df['num at risk'] = self.n_risk\n    df['num events'] = self.n_events\n    return df",
        "mutated": [
            "def summary(self):\n    if False:\n        i = 10\n    '\\n        Return a summary of the estimated survival function.\\n\\n        The summary is a dataframe containing the unique event times,\\n        estimated survival function values, and related quantities.\\n        '\n    df = pd.DataFrame(index=self.surv_times)\n    df.index.name = 'Time'\n    df['Surv prob'] = self.surv_prob\n    df['Surv prob SE'] = self.surv_prob_se\n    df['num at risk'] = self.n_risk\n    df['num events'] = self.n_events\n    return df",
            "def summary(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Return a summary of the estimated survival function.\\n\\n        The summary is a dataframe containing the unique event times,\\n        estimated survival function values, and related quantities.\\n        '\n    df = pd.DataFrame(index=self.surv_times)\n    df.index.name = 'Time'\n    df['Surv prob'] = self.surv_prob\n    df['Surv prob SE'] = self.surv_prob_se\n    df['num at risk'] = self.n_risk\n    df['num events'] = self.n_events\n    return df",
            "def summary(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Return a summary of the estimated survival function.\\n\\n        The summary is a dataframe containing the unique event times,\\n        estimated survival function values, and related quantities.\\n        '\n    df = pd.DataFrame(index=self.surv_times)\n    df.index.name = 'Time'\n    df['Surv prob'] = self.surv_prob\n    df['Surv prob SE'] = self.surv_prob_se\n    df['num at risk'] = self.n_risk\n    df['num events'] = self.n_events\n    return df",
            "def summary(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Return a summary of the estimated survival function.\\n\\n        The summary is a dataframe containing the unique event times,\\n        estimated survival function values, and related quantities.\\n        '\n    df = pd.DataFrame(index=self.surv_times)\n    df.index.name = 'Time'\n    df['Surv prob'] = self.surv_prob\n    df['Surv prob SE'] = self.surv_prob_se\n    df['num at risk'] = self.n_risk\n    df['num events'] = self.n_events\n    return df",
            "def summary(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Return a summary of the estimated survival function.\\n\\n        The summary is a dataframe containing the unique event times,\\n        estimated survival function values, and related quantities.\\n        '\n    df = pd.DataFrame(index=self.surv_times)\n    df.index.name = 'Time'\n    df['Surv prob'] = self.surv_prob\n    df['Surv prob SE'] = self.surv_prob_se\n    df['num at risk'] = self.n_risk\n    df['num events'] = self.n_events\n    return df"
        ]
    },
    {
        "func_name": "simultaneous_cb",
        "original": "def simultaneous_cb(self, alpha=0.05, method='hw', transform='log'):\n    \"\"\"\n        Returns a simultaneous confidence band for the survival function.\n\n        Parameters\n        ----------\n        alpha : float\n            `1 - alpha` is the desired simultaneous coverage\n            probability for the confidence region.  Currently alpha\n            must be set to 0.05, giving 95% simultaneous intervals.\n        method : str\n            The method used to produce the simultaneous confidence\n            band.  Only the Hall-Wellner (hw) method is currently\n            implemented.\n        transform : str\n            The used to produce the interval (note that the returned\n            interval is on the survival probability scale regardless\n            of which transform is used).  Only `log` and `arcsin` are\n            implemented.\n\n        Returns\n        -------\n        lcb : array_like\n            The lower confidence limits corresponding to the points\n            in `surv_times`.\n        ucb : array_like\n            The upper confidence limits corresponding to the points\n            in `surv_times`.\n        \"\"\"\n    method = method.lower()\n    if method != 'hw':\n        msg = 'only the Hall-Wellner (hw) method is implemented'\n        raise ValueError(msg)\n    if alpha != 0.05:\n        raise ValueError('alpha must be set to 0.05')\n    transform = transform.lower()\n    s2 = self.surv_prob_se ** 2 / self.surv_prob ** 2\n    nn = self.n_risk\n    if transform == 'log':\n        denom = np.sqrt(nn) * np.log(self.surv_prob)\n        theta = 1.3581 * (1 + nn * s2) / denom\n        theta = np.exp(theta)\n        lcb = self.surv_prob ** (1 / theta)\n        ucb = self.surv_prob ** theta\n    elif transform == 'arcsin':\n        k = 1.3581\n        k *= (1 + nn * s2) / (2 * np.sqrt(nn))\n        k *= np.sqrt(self.surv_prob / (1 - self.surv_prob))\n        f = np.arcsin(np.sqrt(self.surv_prob))\n        v = np.clip(f - k, 0, np.inf)\n        lcb = np.sin(v) ** 2\n        v = np.clip(f + k, -np.inf, np.pi / 2)\n        ucb = np.sin(v) ** 2\n    else:\n        raise ValueError('Unknown transform')\n    return (lcb, ucb)",
        "mutated": [
            "def simultaneous_cb(self, alpha=0.05, method='hw', transform='log'):\n    if False:\n        i = 10\n    '\\n        Returns a simultaneous confidence band for the survival function.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the desired simultaneous coverage\\n            probability for the confidence region.  Currently alpha\\n            must be set to 0.05, giving 95% simultaneous intervals.\\n        method : str\\n            The method used to produce the simultaneous confidence\\n            band.  Only the Hall-Wellner (hw) method is currently\\n            implemented.\\n        transform : str\\n            The used to produce the interval (note that the returned\\n            interval is on the survival probability scale regardless\\n            of which transform is used).  Only `log` and `arcsin` are\\n            implemented.\\n\\n        Returns\\n        -------\\n        lcb : array_like\\n            The lower confidence limits corresponding to the points\\n            in `surv_times`.\\n        ucb : array_like\\n            The upper confidence limits corresponding to the points\\n            in `surv_times`.\\n        '\n    method = method.lower()\n    if method != 'hw':\n        msg = 'only the Hall-Wellner (hw) method is implemented'\n        raise ValueError(msg)\n    if alpha != 0.05:\n        raise ValueError('alpha must be set to 0.05')\n    transform = transform.lower()\n    s2 = self.surv_prob_se ** 2 / self.surv_prob ** 2\n    nn = self.n_risk\n    if transform == 'log':\n        denom = np.sqrt(nn) * np.log(self.surv_prob)\n        theta = 1.3581 * (1 + nn * s2) / denom\n        theta = np.exp(theta)\n        lcb = self.surv_prob ** (1 / theta)\n        ucb = self.surv_prob ** theta\n    elif transform == 'arcsin':\n        k = 1.3581\n        k *= (1 + nn * s2) / (2 * np.sqrt(nn))\n        k *= np.sqrt(self.surv_prob / (1 - self.surv_prob))\n        f = np.arcsin(np.sqrt(self.surv_prob))\n        v = np.clip(f - k, 0, np.inf)\n        lcb = np.sin(v) ** 2\n        v = np.clip(f + k, -np.inf, np.pi / 2)\n        ucb = np.sin(v) ** 2\n    else:\n        raise ValueError('Unknown transform')\n    return (lcb, ucb)",
            "def simultaneous_cb(self, alpha=0.05, method='hw', transform='log'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Returns a simultaneous confidence band for the survival function.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the desired simultaneous coverage\\n            probability for the confidence region.  Currently alpha\\n            must be set to 0.05, giving 95% simultaneous intervals.\\n        method : str\\n            The method used to produce the simultaneous confidence\\n            band.  Only the Hall-Wellner (hw) method is currently\\n            implemented.\\n        transform : str\\n            The used to produce the interval (note that the returned\\n            interval is on the survival probability scale regardless\\n            of which transform is used).  Only `log` and `arcsin` are\\n            implemented.\\n\\n        Returns\\n        -------\\n        lcb : array_like\\n            The lower confidence limits corresponding to the points\\n            in `surv_times`.\\n        ucb : array_like\\n            The upper confidence limits corresponding to the points\\n            in `surv_times`.\\n        '\n    method = method.lower()\n    if method != 'hw':\n        msg = 'only the Hall-Wellner (hw) method is implemented'\n        raise ValueError(msg)\n    if alpha != 0.05:\n        raise ValueError('alpha must be set to 0.05')\n    transform = transform.lower()\n    s2 = self.surv_prob_se ** 2 / self.surv_prob ** 2\n    nn = self.n_risk\n    if transform == 'log':\n        denom = np.sqrt(nn) * np.log(self.surv_prob)\n        theta = 1.3581 * (1 + nn * s2) / denom\n        theta = np.exp(theta)\n        lcb = self.surv_prob ** (1 / theta)\n        ucb = self.surv_prob ** theta\n    elif transform == 'arcsin':\n        k = 1.3581\n        k *= (1 + nn * s2) / (2 * np.sqrt(nn))\n        k *= np.sqrt(self.surv_prob / (1 - self.surv_prob))\n        f = np.arcsin(np.sqrt(self.surv_prob))\n        v = np.clip(f - k, 0, np.inf)\n        lcb = np.sin(v) ** 2\n        v = np.clip(f + k, -np.inf, np.pi / 2)\n        ucb = np.sin(v) ** 2\n    else:\n        raise ValueError('Unknown transform')\n    return (lcb, ucb)",
            "def simultaneous_cb(self, alpha=0.05, method='hw', transform='log'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Returns a simultaneous confidence band for the survival function.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the desired simultaneous coverage\\n            probability for the confidence region.  Currently alpha\\n            must be set to 0.05, giving 95% simultaneous intervals.\\n        method : str\\n            The method used to produce the simultaneous confidence\\n            band.  Only the Hall-Wellner (hw) method is currently\\n            implemented.\\n        transform : str\\n            The used to produce the interval (note that the returned\\n            interval is on the survival probability scale regardless\\n            of which transform is used).  Only `log` and `arcsin` are\\n            implemented.\\n\\n        Returns\\n        -------\\n        lcb : array_like\\n            The lower confidence limits corresponding to the points\\n            in `surv_times`.\\n        ucb : array_like\\n            The upper confidence limits corresponding to the points\\n            in `surv_times`.\\n        '\n    method = method.lower()\n    if method != 'hw':\n        msg = 'only the Hall-Wellner (hw) method is implemented'\n        raise ValueError(msg)\n    if alpha != 0.05:\n        raise ValueError('alpha must be set to 0.05')\n    transform = transform.lower()\n    s2 = self.surv_prob_se ** 2 / self.surv_prob ** 2\n    nn = self.n_risk\n    if transform == 'log':\n        denom = np.sqrt(nn) * np.log(self.surv_prob)\n        theta = 1.3581 * (1 + nn * s2) / denom\n        theta = np.exp(theta)\n        lcb = self.surv_prob ** (1 / theta)\n        ucb = self.surv_prob ** theta\n    elif transform == 'arcsin':\n        k = 1.3581\n        k *= (1 + nn * s2) / (2 * np.sqrt(nn))\n        k *= np.sqrt(self.surv_prob / (1 - self.surv_prob))\n        f = np.arcsin(np.sqrt(self.surv_prob))\n        v = np.clip(f - k, 0, np.inf)\n        lcb = np.sin(v) ** 2\n        v = np.clip(f + k, -np.inf, np.pi / 2)\n        ucb = np.sin(v) ** 2\n    else:\n        raise ValueError('Unknown transform')\n    return (lcb, ucb)",
            "def simultaneous_cb(self, alpha=0.05, method='hw', transform='log'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Returns a simultaneous confidence band for the survival function.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the desired simultaneous coverage\\n            probability for the confidence region.  Currently alpha\\n            must be set to 0.05, giving 95% simultaneous intervals.\\n        method : str\\n            The method used to produce the simultaneous confidence\\n            band.  Only the Hall-Wellner (hw) method is currently\\n            implemented.\\n        transform : str\\n            The used to produce the interval (note that the returned\\n            interval is on the survival probability scale regardless\\n            of which transform is used).  Only `log` and `arcsin` are\\n            implemented.\\n\\n        Returns\\n        -------\\n        lcb : array_like\\n            The lower confidence limits corresponding to the points\\n            in `surv_times`.\\n        ucb : array_like\\n            The upper confidence limits corresponding to the points\\n            in `surv_times`.\\n        '\n    method = method.lower()\n    if method != 'hw':\n        msg = 'only the Hall-Wellner (hw) method is implemented'\n        raise ValueError(msg)\n    if alpha != 0.05:\n        raise ValueError('alpha must be set to 0.05')\n    transform = transform.lower()\n    s2 = self.surv_prob_se ** 2 / self.surv_prob ** 2\n    nn = self.n_risk\n    if transform == 'log':\n        denom = np.sqrt(nn) * np.log(self.surv_prob)\n        theta = 1.3581 * (1 + nn * s2) / denom\n        theta = np.exp(theta)\n        lcb = self.surv_prob ** (1 / theta)\n        ucb = self.surv_prob ** theta\n    elif transform == 'arcsin':\n        k = 1.3581\n        k *= (1 + nn * s2) / (2 * np.sqrt(nn))\n        k *= np.sqrt(self.surv_prob / (1 - self.surv_prob))\n        f = np.arcsin(np.sqrt(self.surv_prob))\n        v = np.clip(f - k, 0, np.inf)\n        lcb = np.sin(v) ** 2\n        v = np.clip(f + k, -np.inf, np.pi / 2)\n        ucb = np.sin(v) ** 2\n    else:\n        raise ValueError('Unknown transform')\n    return (lcb, ucb)",
            "def simultaneous_cb(self, alpha=0.05, method='hw', transform='log'):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Returns a simultaneous confidence band for the survival function.\\n\\n        Parameters\\n        ----------\\n        alpha : float\\n            `1 - alpha` is the desired simultaneous coverage\\n            probability for the confidence region.  Currently alpha\\n            must be set to 0.05, giving 95% simultaneous intervals.\\n        method : str\\n            The method used to produce the simultaneous confidence\\n            band.  Only the Hall-Wellner (hw) method is currently\\n            implemented.\\n        transform : str\\n            The used to produce the interval (note that the returned\\n            interval is on the survival probability scale regardless\\n            of which transform is used).  Only `log` and `arcsin` are\\n            implemented.\\n\\n        Returns\\n        -------\\n        lcb : array_like\\n            The lower confidence limits corresponding to the points\\n            in `surv_times`.\\n        ucb : array_like\\n            The upper confidence limits corresponding to the points\\n            in `surv_times`.\\n        '\n    method = method.lower()\n    if method != 'hw':\n        msg = 'only the Hall-Wellner (hw) method is implemented'\n        raise ValueError(msg)\n    if alpha != 0.05:\n        raise ValueError('alpha must be set to 0.05')\n    transform = transform.lower()\n    s2 = self.surv_prob_se ** 2 / self.surv_prob ** 2\n    nn = self.n_risk\n    if transform == 'log':\n        denom = np.sqrt(nn) * np.log(self.surv_prob)\n        theta = 1.3581 * (1 + nn * s2) / denom\n        theta = np.exp(theta)\n        lcb = self.surv_prob ** (1 / theta)\n        ucb = self.surv_prob ** theta\n    elif transform == 'arcsin':\n        k = 1.3581\n        k *= (1 + nn * s2) / (2 * np.sqrt(nn))\n        k *= np.sqrt(self.surv_prob / (1 - self.surv_prob))\n        f = np.arcsin(np.sqrt(self.surv_prob))\n        v = np.clip(f - k, 0, np.inf)\n        lcb = np.sin(v) ** 2\n        v = np.clip(f + k, -np.inf, np.pi / 2)\n        ucb = np.sin(v) ** 2\n    else:\n        raise ValueError('Unknown transform')\n    return (lcb, ucb)"
        ]
    },
    {
        "func_name": "survdiff",
        "original": "def survdiff(time, status, group, weight_type=None, strata=None, entry=None, **kwargs):\n    \"\"\"\n    Test for the equality of two survival distributions.\n\n    Parameters\n    ----------\n    time : array_like\n        The event or censoring times.\n    status : array_like\n        The censoring status variable, status=1 indicates that the\n        event occurred, status=0 indicates that the observation was\n        censored.\n    group : array_like\n        Indicators of the two groups\n    weight_type : str\n        The following weight types are implemented:\n            None (default) : logrank test\n            fh : Fleming-Harrington, weights by S^(fh_p),\n                 requires exponent fh_p to be provided as keyword\n                 argument; the weights are derived from S defined at\n                 the previous event time, and the first weight is\n                 always 1.\n            gb : Gehan-Breslow, weights by the number at risk\n            tw : Tarone-Ware, weights by the square root of the number\n                 at risk\n    strata : array_like\n        Optional stratum indicators for a stratified test\n    entry : array_like\n        Entry times to handle left truncation. The subject is not in\n        the risk set on or before the entry time.\n\n    Returns\n    -------\n    chisq : The chi-square (1 degree of freedom) distributed test\n            statistic value\n    pvalue : The p-value for the chi^2 test\n    \"\"\"\n    time = np.asarray(time)\n    status = np.asarray(status)\n    group = np.asarray(group)\n    gr = np.unique(group)\n    if strata is None:\n        (obs, var) = _survdiff(time, status, group, weight_type, gr, entry, **kwargs)\n    else:\n        strata = np.asarray(strata)\n        stu = np.unique(strata)\n        (obs, var) = (0.0, 0.0)\n        for st in stu:\n            ii = strata == st\n            (obs1, var1) = _survdiff(time[ii], status[ii], group[ii], weight_type, gr, entry, **kwargs)\n            obs += obs1\n            var += var1\n    chisq = obs.dot(np.linalg.solve(var, obs))\n    pvalue = 1 - chi2.cdf(chisq, len(gr) - 1)\n    return (chisq, pvalue)",
        "mutated": [
            "def survdiff(time, status, group, weight_type=None, strata=None, entry=None, **kwargs):\n    if False:\n        i = 10\n    '\\n    Test for the equality of two survival distributions.\\n\\n    Parameters\\n    ----------\\n    time : array_like\\n        The event or censoring times.\\n    status : array_like\\n        The censoring status variable, status=1 indicates that the\\n        event occurred, status=0 indicates that the observation was\\n        censored.\\n    group : array_like\\n        Indicators of the two groups\\n    weight_type : str\\n        The following weight types are implemented:\\n            None (default) : logrank test\\n            fh : Fleming-Harrington, weights by S^(fh_p),\\n                 requires exponent fh_p to be provided as keyword\\n                 argument; the weights are derived from S defined at\\n                 the previous event time, and the first weight is\\n                 always 1.\\n            gb : Gehan-Breslow, weights by the number at risk\\n            tw : Tarone-Ware, weights by the square root of the number\\n                 at risk\\n    strata : array_like\\n        Optional stratum indicators for a stratified test\\n    entry : array_like\\n        Entry times to handle left truncation. The subject is not in\\n        the risk set on or before the entry time.\\n\\n    Returns\\n    -------\\n    chisq : The chi-square (1 degree of freedom) distributed test\\n            statistic value\\n    pvalue : The p-value for the chi^2 test\\n    '\n    time = np.asarray(time)\n    status = np.asarray(status)\n    group = np.asarray(group)\n    gr = np.unique(group)\n    if strata is None:\n        (obs, var) = _survdiff(time, status, group, weight_type, gr, entry, **kwargs)\n    else:\n        strata = np.asarray(strata)\n        stu = np.unique(strata)\n        (obs, var) = (0.0, 0.0)\n        for st in stu:\n            ii = strata == st\n            (obs1, var1) = _survdiff(time[ii], status[ii], group[ii], weight_type, gr, entry, **kwargs)\n            obs += obs1\n            var += var1\n    chisq = obs.dot(np.linalg.solve(var, obs))\n    pvalue = 1 - chi2.cdf(chisq, len(gr) - 1)\n    return (chisq, pvalue)",
            "def survdiff(time, status, group, weight_type=None, strata=None, entry=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Test for the equality of two survival distributions.\\n\\n    Parameters\\n    ----------\\n    time : array_like\\n        The event or censoring times.\\n    status : array_like\\n        The censoring status variable, status=1 indicates that the\\n        event occurred, status=0 indicates that the observation was\\n        censored.\\n    group : array_like\\n        Indicators of the two groups\\n    weight_type : str\\n        The following weight types are implemented:\\n            None (default) : logrank test\\n            fh : Fleming-Harrington, weights by S^(fh_p),\\n                 requires exponent fh_p to be provided as keyword\\n                 argument; the weights are derived from S defined at\\n                 the previous event time, and the first weight is\\n                 always 1.\\n            gb : Gehan-Breslow, weights by the number at risk\\n            tw : Tarone-Ware, weights by the square root of the number\\n                 at risk\\n    strata : array_like\\n        Optional stratum indicators for a stratified test\\n    entry : array_like\\n        Entry times to handle left truncation. The subject is not in\\n        the risk set on or before the entry time.\\n\\n    Returns\\n    -------\\n    chisq : The chi-square (1 degree of freedom) distributed test\\n            statistic value\\n    pvalue : The p-value for the chi^2 test\\n    '\n    time = np.asarray(time)\n    status = np.asarray(status)\n    group = np.asarray(group)\n    gr = np.unique(group)\n    if strata is None:\n        (obs, var) = _survdiff(time, status, group, weight_type, gr, entry, **kwargs)\n    else:\n        strata = np.asarray(strata)\n        stu = np.unique(strata)\n        (obs, var) = (0.0, 0.0)\n        for st in stu:\n            ii = strata == st\n            (obs1, var1) = _survdiff(time[ii], status[ii], group[ii], weight_type, gr, entry, **kwargs)\n            obs += obs1\n            var += var1\n    chisq = obs.dot(np.linalg.solve(var, obs))\n    pvalue = 1 - chi2.cdf(chisq, len(gr) - 1)\n    return (chisq, pvalue)",
            "def survdiff(time, status, group, weight_type=None, strata=None, entry=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Test for the equality of two survival distributions.\\n\\n    Parameters\\n    ----------\\n    time : array_like\\n        The event or censoring times.\\n    status : array_like\\n        The censoring status variable, status=1 indicates that the\\n        event occurred, status=0 indicates that the observation was\\n        censored.\\n    group : array_like\\n        Indicators of the two groups\\n    weight_type : str\\n        The following weight types are implemented:\\n            None (default) : logrank test\\n            fh : Fleming-Harrington, weights by S^(fh_p),\\n                 requires exponent fh_p to be provided as keyword\\n                 argument; the weights are derived from S defined at\\n                 the previous event time, and the first weight is\\n                 always 1.\\n            gb : Gehan-Breslow, weights by the number at risk\\n            tw : Tarone-Ware, weights by the square root of the number\\n                 at risk\\n    strata : array_like\\n        Optional stratum indicators for a stratified test\\n    entry : array_like\\n        Entry times to handle left truncation. The subject is not in\\n        the risk set on or before the entry time.\\n\\n    Returns\\n    -------\\n    chisq : The chi-square (1 degree of freedom) distributed test\\n            statistic value\\n    pvalue : The p-value for the chi^2 test\\n    '\n    time = np.asarray(time)\n    status = np.asarray(status)\n    group = np.asarray(group)\n    gr = np.unique(group)\n    if strata is None:\n        (obs, var) = _survdiff(time, status, group, weight_type, gr, entry, **kwargs)\n    else:\n        strata = np.asarray(strata)\n        stu = np.unique(strata)\n        (obs, var) = (0.0, 0.0)\n        for st in stu:\n            ii = strata == st\n            (obs1, var1) = _survdiff(time[ii], status[ii], group[ii], weight_type, gr, entry, **kwargs)\n            obs += obs1\n            var += var1\n    chisq = obs.dot(np.linalg.solve(var, obs))\n    pvalue = 1 - chi2.cdf(chisq, len(gr) - 1)\n    return (chisq, pvalue)",
            "def survdiff(time, status, group, weight_type=None, strata=None, entry=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Test for the equality of two survival distributions.\\n\\n    Parameters\\n    ----------\\n    time : array_like\\n        The event or censoring times.\\n    status : array_like\\n        The censoring status variable, status=1 indicates that the\\n        event occurred, status=0 indicates that the observation was\\n        censored.\\n    group : array_like\\n        Indicators of the two groups\\n    weight_type : str\\n        The following weight types are implemented:\\n            None (default) : logrank test\\n            fh : Fleming-Harrington, weights by S^(fh_p),\\n                 requires exponent fh_p to be provided as keyword\\n                 argument; the weights are derived from S defined at\\n                 the previous event time, and the first weight is\\n                 always 1.\\n            gb : Gehan-Breslow, weights by the number at risk\\n            tw : Tarone-Ware, weights by the square root of the number\\n                 at risk\\n    strata : array_like\\n        Optional stratum indicators for a stratified test\\n    entry : array_like\\n        Entry times to handle left truncation. The subject is not in\\n        the risk set on or before the entry time.\\n\\n    Returns\\n    -------\\n    chisq : The chi-square (1 degree of freedom) distributed test\\n            statistic value\\n    pvalue : The p-value for the chi^2 test\\n    '\n    time = np.asarray(time)\n    status = np.asarray(status)\n    group = np.asarray(group)\n    gr = np.unique(group)\n    if strata is None:\n        (obs, var) = _survdiff(time, status, group, weight_type, gr, entry, **kwargs)\n    else:\n        strata = np.asarray(strata)\n        stu = np.unique(strata)\n        (obs, var) = (0.0, 0.0)\n        for st in stu:\n            ii = strata == st\n            (obs1, var1) = _survdiff(time[ii], status[ii], group[ii], weight_type, gr, entry, **kwargs)\n            obs += obs1\n            var += var1\n    chisq = obs.dot(np.linalg.solve(var, obs))\n    pvalue = 1 - chi2.cdf(chisq, len(gr) - 1)\n    return (chisq, pvalue)",
            "def survdiff(time, status, group, weight_type=None, strata=None, entry=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Test for the equality of two survival distributions.\\n\\n    Parameters\\n    ----------\\n    time : array_like\\n        The event or censoring times.\\n    status : array_like\\n        The censoring status variable, status=1 indicates that the\\n        event occurred, status=0 indicates that the observation was\\n        censored.\\n    group : array_like\\n        Indicators of the two groups\\n    weight_type : str\\n        The following weight types are implemented:\\n            None (default) : logrank test\\n            fh : Fleming-Harrington, weights by S^(fh_p),\\n                 requires exponent fh_p to be provided as keyword\\n                 argument; the weights are derived from S defined at\\n                 the previous event time, and the first weight is\\n                 always 1.\\n            gb : Gehan-Breslow, weights by the number at risk\\n            tw : Tarone-Ware, weights by the square root of the number\\n                 at risk\\n    strata : array_like\\n        Optional stratum indicators for a stratified test\\n    entry : array_like\\n        Entry times to handle left truncation. The subject is not in\\n        the risk set on or before the entry time.\\n\\n    Returns\\n    -------\\n    chisq : The chi-square (1 degree of freedom) distributed test\\n            statistic value\\n    pvalue : The p-value for the chi^2 test\\n    '\n    time = np.asarray(time)\n    status = np.asarray(status)\n    group = np.asarray(group)\n    gr = np.unique(group)\n    if strata is None:\n        (obs, var) = _survdiff(time, status, group, weight_type, gr, entry, **kwargs)\n    else:\n        strata = np.asarray(strata)\n        stu = np.unique(strata)\n        (obs, var) = (0.0, 0.0)\n        for st in stu:\n            ii = strata == st\n            (obs1, var1) = _survdiff(time[ii], status[ii], group[ii], weight_type, gr, entry, **kwargs)\n            obs += obs1\n            var += var1\n    chisq = obs.dot(np.linalg.solve(var, obs))\n    pvalue = 1 - chi2.cdf(chisq, len(gr) - 1)\n    return (chisq, pvalue)"
        ]
    },
    {
        "func_name": "_survdiff",
        "original": "def _survdiff(time, status, group, weight_type, gr, entry=None, **kwargs):\n    if entry is None:\n        (utimes, rtimes) = np.unique(time, return_inverse=True)\n    else:\n        (utimes, rtimes) = np.unique(np.concatenate((time, entry)), return_inverse=True)\n        rtimes = rtimes[0:len(time)]\n    tse = [(gr_i, None) for gr_i in gr]\n    if entry is not None:\n        for (k, _) in enumerate(gr):\n            ii = group == gr[k]\n            entry1 = entry[ii]\n            tse[k] = (gr[k], entry1)\n    (nrisk, obsv) = ([], [])\n    ml = len(utimes)\n    for (g, entry0) in tse:\n        mk = group == g\n        n = np.bincount(rtimes, weights=mk, minlength=ml)\n        ob = np.bincount(rtimes, weights=status * mk, minlength=ml)\n        obsv.append(ob)\n        if entry is not None:\n            n = np.cumsum(n) - n\n            rentry = np.searchsorted(utimes, entry0, side='left')\n            n0 = np.bincount(rentry, minlength=ml)\n            n0 = np.cumsum(n0) - n0\n            nr = n0 - n\n        else:\n            nr = np.cumsum(n[::-1])[::-1]\n        nrisk.append(nr)\n    obs = sum(obsv)\n    nrisk_tot = sum(nrisk)\n    ix = np.flatnonzero(nrisk_tot > 1)\n    weights = None\n    if weight_type is not None:\n        weight_type = weight_type.lower()\n        if weight_type == 'gb':\n            weights = nrisk_tot\n        elif weight_type == 'tw':\n            weights = np.sqrt(nrisk_tot)\n        elif weight_type == 'fh':\n            if 'fh_p' not in kwargs:\n                msg = \"weight_type type 'fh' requires specification of fh_p\"\n                raise ValueError(msg)\n            fh_p = kwargs['fh_p']\n            sp = 1 - obs / nrisk_tot.astype(np.float64)\n            sp = np.log(sp)\n            sp = np.cumsum(sp)\n            sp = np.exp(sp)\n            weights = sp ** fh_p\n            weights = np.roll(weights, 1)\n            weights[0] = 1\n        else:\n            raise ValueError('weight_type not implemented')\n    dfs = len(gr) - 1\n    r = np.vstack(nrisk) / np.clip(nrisk_tot, 1e-10, np.inf)[None, :]\n    groups_oe = []\n    groups_var = []\n    var_denom = nrisk_tot - 1\n    var_denom = np.clip(var_denom, 1e-10, np.inf)\n    for g in range(1, dfs + 1):\n        oe = obsv[g] - r[g] * obs\n        var_tensor_part = r[1:, :].T * (np.eye(1, dfs, g - 1).ravel() - r[g, :, None])\n        var_scalar_part = obs * (nrisk_tot - obs) / var_denom\n        var = var_tensor_part * var_scalar_part[:, None]\n        if weights is not None:\n            oe = weights * oe\n            var = (weights ** 2)[:, None] * var\n        groups_oe.append(oe[ix].sum())\n        groups_var.append(var[ix].sum(axis=0))\n    obs_vec = np.hstack(groups_oe)\n    var_mat = np.vstack(groups_var)\n    return (obs_vec, var_mat)",
        "mutated": [
            "def _survdiff(time, status, group, weight_type, gr, entry=None, **kwargs):\n    if False:\n        i = 10\n    if entry is None:\n        (utimes, rtimes) = np.unique(time, return_inverse=True)\n    else:\n        (utimes, rtimes) = np.unique(np.concatenate((time, entry)), return_inverse=True)\n        rtimes = rtimes[0:len(time)]\n    tse = [(gr_i, None) for gr_i in gr]\n    if entry is not None:\n        for (k, _) in enumerate(gr):\n            ii = group == gr[k]\n            entry1 = entry[ii]\n            tse[k] = (gr[k], entry1)\n    (nrisk, obsv) = ([], [])\n    ml = len(utimes)\n    for (g, entry0) in tse:\n        mk = group == g\n        n = np.bincount(rtimes, weights=mk, minlength=ml)\n        ob = np.bincount(rtimes, weights=status * mk, minlength=ml)\n        obsv.append(ob)\n        if entry is not None:\n            n = np.cumsum(n) - n\n            rentry = np.searchsorted(utimes, entry0, side='left')\n            n0 = np.bincount(rentry, minlength=ml)\n            n0 = np.cumsum(n0) - n0\n            nr = n0 - n\n        else:\n            nr = np.cumsum(n[::-1])[::-1]\n        nrisk.append(nr)\n    obs = sum(obsv)\n    nrisk_tot = sum(nrisk)\n    ix = np.flatnonzero(nrisk_tot > 1)\n    weights = None\n    if weight_type is not None:\n        weight_type = weight_type.lower()\n        if weight_type == 'gb':\n            weights = nrisk_tot\n        elif weight_type == 'tw':\n            weights = np.sqrt(nrisk_tot)\n        elif weight_type == 'fh':\n            if 'fh_p' not in kwargs:\n                msg = \"weight_type type 'fh' requires specification of fh_p\"\n                raise ValueError(msg)\n            fh_p = kwargs['fh_p']\n            sp = 1 - obs / nrisk_tot.astype(np.float64)\n            sp = np.log(sp)\n            sp = np.cumsum(sp)\n            sp = np.exp(sp)\n            weights = sp ** fh_p\n            weights = np.roll(weights, 1)\n            weights[0] = 1\n        else:\n            raise ValueError('weight_type not implemented')\n    dfs = len(gr) - 1\n    r = np.vstack(nrisk) / np.clip(nrisk_tot, 1e-10, np.inf)[None, :]\n    groups_oe = []\n    groups_var = []\n    var_denom = nrisk_tot - 1\n    var_denom = np.clip(var_denom, 1e-10, np.inf)\n    for g in range(1, dfs + 1):\n        oe = obsv[g] - r[g] * obs\n        var_tensor_part = r[1:, :].T * (np.eye(1, dfs, g - 1).ravel() - r[g, :, None])\n        var_scalar_part = obs * (nrisk_tot - obs) / var_denom\n        var = var_tensor_part * var_scalar_part[:, None]\n        if weights is not None:\n            oe = weights * oe\n            var = (weights ** 2)[:, None] * var\n        groups_oe.append(oe[ix].sum())\n        groups_var.append(var[ix].sum(axis=0))\n    obs_vec = np.hstack(groups_oe)\n    var_mat = np.vstack(groups_var)\n    return (obs_vec, var_mat)",
            "def _survdiff(time, status, group, weight_type, gr, entry=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if entry is None:\n        (utimes, rtimes) = np.unique(time, return_inverse=True)\n    else:\n        (utimes, rtimes) = np.unique(np.concatenate((time, entry)), return_inverse=True)\n        rtimes = rtimes[0:len(time)]\n    tse = [(gr_i, None) for gr_i in gr]\n    if entry is not None:\n        for (k, _) in enumerate(gr):\n            ii = group == gr[k]\n            entry1 = entry[ii]\n            tse[k] = (gr[k], entry1)\n    (nrisk, obsv) = ([], [])\n    ml = len(utimes)\n    for (g, entry0) in tse:\n        mk = group == g\n        n = np.bincount(rtimes, weights=mk, minlength=ml)\n        ob = np.bincount(rtimes, weights=status * mk, minlength=ml)\n        obsv.append(ob)\n        if entry is not None:\n            n = np.cumsum(n) - n\n            rentry = np.searchsorted(utimes, entry0, side='left')\n            n0 = np.bincount(rentry, minlength=ml)\n            n0 = np.cumsum(n0) - n0\n            nr = n0 - n\n        else:\n            nr = np.cumsum(n[::-1])[::-1]\n        nrisk.append(nr)\n    obs = sum(obsv)\n    nrisk_tot = sum(nrisk)\n    ix = np.flatnonzero(nrisk_tot > 1)\n    weights = None\n    if weight_type is not None:\n        weight_type = weight_type.lower()\n        if weight_type == 'gb':\n            weights = nrisk_tot\n        elif weight_type == 'tw':\n            weights = np.sqrt(nrisk_tot)\n        elif weight_type == 'fh':\n            if 'fh_p' not in kwargs:\n                msg = \"weight_type type 'fh' requires specification of fh_p\"\n                raise ValueError(msg)\n            fh_p = kwargs['fh_p']\n            sp = 1 - obs / nrisk_tot.astype(np.float64)\n            sp = np.log(sp)\n            sp = np.cumsum(sp)\n            sp = np.exp(sp)\n            weights = sp ** fh_p\n            weights = np.roll(weights, 1)\n            weights[0] = 1\n        else:\n            raise ValueError('weight_type not implemented')\n    dfs = len(gr) - 1\n    r = np.vstack(nrisk) / np.clip(nrisk_tot, 1e-10, np.inf)[None, :]\n    groups_oe = []\n    groups_var = []\n    var_denom = nrisk_tot - 1\n    var_denom = np.clip(var_denom, 1e-10, np.inf)\n    for g in range(1, dfs + 1):\n        oe = obsv[g] - r[g] * obs\n        var_tensor_part = r[1:, :].T * (np.eye(1, dfs, g - 1).ravel() - r[g, :, None])\n        var_scalar_part = obs * (nrisk_tot - obs) / var_denom\n        var = var_tensor_part * var_scalar_part[:, None]\n        if weights is not None:\n            oe = weights * oe\n            var = (weights ** 2)[:, None] * var\n        groups_oe.append(oe[ix].sum())\n        groups_var.append(var[ix].sum(axis=0))\n    obs_vec = np.hstack(groups_oe)\n    var_mat = np.vstack(groups_var)\n    return (obs_vec, var_mat)",
            "def _survdiff(time, status, group, weight_type, gr, entry=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if entry is None:\n        (utimes, rtimes) = np.unique(time, return_inverse=True)\n    else:\n        (utimes, rtimes) = np.unique(np.concatenate((time, entry)), return_inverse=True)\n        rtimes = rtimes[0:len(time)]\n    tse = [(gr_i, None) for gr_i in gr]\n    if entry is not None:\n        for (k, _) in enumerate(gr):\n            ii = group == gr[k]\n            entry1 = entry[ii]\n            tse[k] = (gr[k], entry1)\n    (nrisk, obsv) = ([], [])\n    ml = len(utimes)\n    for (g, entry0) in tse:\n        mk = group == g\n        n = np.bincount(rtimes, weights=mk, minlength=ml)\n        ob = np.bincount(rtimes, weights=status * mk, minlength=ml)\n        obsv.append(ob)\n        if entry is not None:\n            n = np.cumsum(n) - n\n            rentry = np.searchsorted(utimes, entry0, side='left')\n            n0 = np.bincount(rentry, minlength=ml)\n            n0 = np.cumsum(n0) - n0\n            nr = n0 - n\n        else:\n            nr = np.cumsum(n[::-1])[::-1]\n        nrisk.append(nr)\n    obs = sum(obsv)\n    nrisk_tot = sum(nrisk)\n    ix = np.flatnonzero(nrisk_tot > 1)\n    weights = None\n    if weight_type is not None:\n        weight_type = weight_type.lower()\n        if weight_type == 'gb':\n            weights = nrisk_tot\n        elif weight_type == 'tw':\n            weights = np.sqrt(nrisk_tot)\n        elif weight_type == 'fh':\n            if 'fh_p' not in kwargs:\n                msg = \"weight_type type 'fh' requires specification of fh_p\"\n                raise ValueError(msg)\n            fh_p = kwargs['fh_p']\n            sp = 1 - obs / nrisk_tot.astype(np.float64)\n            sp = np.log(sp)\n            sp = np.cumsum(sp)\n            sp = np.exp(sp)\n            weights = sp ** fh_p\n            weights = np.roll(weights, 1)\n            weights[0] = 1\n        else:\n            raise ValueError('weight_type not implemented')\n    dfs = len(gr) - 1\n    r = np.vstack(nrisk) / np.clip(nrisk_tot, 1e-10, np.inf)[None, :]\n    groups_oe = []\n    groups_var = []\n    var_denom = nrisk_tot - 1\n    var_denom = np.clip(var_denom, 1e-10, np.inf)\n    for g in range(1, dfs + 1):\n        oe = obsv[g] - r[g] * obs\n        var_tensor_part = r[1:, :].T * (np.eye(1, dfs, g - 1).ravel() - r[g, :, None])\n        var_scalar_part = obs * (nrisk_tot - obs) / var_denom\n        var = var_tensor_part * var_scalar_part[:, None]\n        if weights is not None:\n            oe = weights * oe\n            var = (weights ** 2)[:, None] * var\n        groups_oe.append(oe[ix].sum())\n        groups_var.append(var[ix].sum(axis=0))\n    obs_vec = np.hstack(groups_oe)\n    var_mat = np.vstack(groups_var)\n    return (obs_vec, var_mat)",
            "def _survdiff(time, status, group, weight_type, gr, entry=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if entry is None:\n        (utimes, rtimes) = np.unique(time, return_inverse=True)\n    else:\n        (utimes, rtimes) = np.unique(np.concatenate((time, entry)), return_inverse=True)\n        rtimes = rtimes[0:len(time)]\n    tse = [(gr_i, None) for gr_i in gr]\n    if entry is not None:\n        for (k, _) in enumerate(gr):\n            ii = group == gr[k]\n            entry1 = entry[ii]\n            tse[k] = (gr[k], entry1)\n    (nrisk, obsv) = ([], [])\n    ml = len(utimes)\n    for (g, entry0) in tse:\n        mk = group == g\n        n = np.bincount(rtimes, weights=mk, minlength=ml)\n        ob = np.bincount(rtimes, weights=status * mk, minlength=ml)\n        obsv.append(ob)\n        if entry is not None:\n            n = np.cumsum(n) - n\n            rentry = np.searchsorted(utimes, entry0, side='left')\n            n0 = np.bincount(rentry, minlength=ml)\n            n0 = np.cumsum(n0) - n0\n            nr = n0 - n\n        else:\n            nr = np.cumsum(n[::-1])[::-1]\n        nrisk.append(nr)\n    obs = sum(obsv)\n    nrisk_tot = sum(nrisk)\n    ix = np.flatnonzero(nrisk_tot > 1)\n    weights = None\n    if weight_type is not None:\n        weight_type = weight_type.lower()\n        if weight_type == 'gb':\n            weights = nrisk_tot\n        elif weight_type == 'tw':\n            weights = np.sqrt(nrisk_tot)\n        elif weight_type == 'fh':\n            if 'fh_p' not in kwargs:\n                msg = \"weight_type type 'fh' requires specification of fh_p\"\n                raise ValueError(msg)\n            fh_p = kwargs['fh_p']\n            sp = 1 - obs / nrisk_tot.astype(np.float64)\n            sp = np.log(sp)\n            sp = np.cumsum(sp)\n            sp = np.exp(sp)\n            weights = sp ** fh_p\n            weights = np.roll(weights, 1)\n            weights[0] = 1\n        else:\n            raise ValueError('weight_type not implemented')\n    dfs = len(gr) - 1\n    r = np.vstack(nrisk) / np.clip(nrisk_tot, 1e-10, np.inf)[None, :]\n    groups_oe = []\n    groups_var = []\n    var_denom = nrisk_tot - 1\n    var_denom = np.clip(var_denom, 1e-10, np.inf)\n    for g in range(1, dfs + 1):\n        oe = obsv[g] - r[g] * obs\n        var_tensor_part = r[1:, :].T * (np.eye(1, dfs, g - 1).ravel() - r[g, :, None])\n        var_scalar_part = obs * (nrisk_tot - obs) / var_denom\n        var = var_tensor_part * var_scalar_part[:, None]\n        if weights is not None:\n            oe = weights * oe\n            var = (weights ** 2)[:, None] * var\n        groups_oe.append(oe[ix].sum())\n        groups_var.append(var[ix].sum(axis=0))\n    obs_vec = np.hstack(groups_oe)\n    var_mat = np.vstack(groups_var)\n    return (obs_vec, var_mat)",
            "def _survdiff(time, status, group, weight_type, gr, entry=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if entry is None:\n        (utimes, rtimes) = np.unique(time, return_inverse=True)\n    else:\n        (utimes, rtimes) = np.unique(np.concatenate((time, entry)), return_inverse=True)\n        rtimes = rtimes[0:len(time)]\n    tse = [(gr_i, None) for gr_i in gr]\n    if entry is not None:\n        for (k, _) in enumerate(gr):\n            ii = group == gr[k]\n            entry1 = entry[ii]\n            tse[k] = (gr[k], entry1)\n    (nrisk, obsv) = ([], [])\n    ml = len(utimes)\n    for (g, entry0) in tse:\n        mk = group == g\n        n = np.bincount(rtimes, weights=mk, minlength=ml)\n        ob = np.bincount(rtimes, weights=status * mk, minlength=ml)\n        obsv.append(ob)\n        if entry is not None:\n            n = np.cumsum(n) - n\n            rentry = np.searchsorted(utimes, entry0, side='left')\n            n0 = np.bincount(rentry, minlength=ml)\n            n0 = np.cumsum(n0) - n0\n            nr = n0 - n\n        else:\n            nr = np.cumsum(n[::-1])[::-1]\n        nrisk.append(nr)\n    obs = sum(obsv)\n    nrisk_tot = sum(nrisk)\n    ix = np.flatnonzero(nrisk_tot > 1)\n    weights = None\n    if weight_type is not None:\n        weight_type = weight_type.lower()\n        if weight_type == 'gb':\n            weights = nrisk_tot\n        elif weight_type == 'tw':\n            weights = np.sqrt(nrisk_tot)\n        elif weight_type == 'fh':\n            if 'fh_p' not in kwargs:\n                msg = \"weight_type type 'fh' requires specification of fh_p\"\n                raise ValueError(msg)\n            fh_p = kwargs['fh_p']\n            sp = 1 - obs / nrisk_tot.astype(np.float64)\n            sp = np.log(sp)\n            sp = np.cumsum(sp)\n            sp = np.exp(sp)\n            weights = sp ** fh_p\n            weights = np.roll(weights, 1)\n            weights[0] = 1\n        else:\n            raise ValueError('weight_type not implemented')\n    dfs = len(gr) - 1\n    r = np.vstack(nrisk) / np.clip(nrisk_tot, 1e-10, np.inf)[None, :]\n    groups_oe = []\n    groups_var = []\n    var_denom = nrisk_tot - 1\n    var_denom = np.clip(var_denom, 1e-10, np.inf)\n    for g in range(1, dfs + 1):\n        oe = obsv[g] - r[g] * obs\n        var_tensor_part = r[1:, :].T * (np.eye(1, dfs, g - 1).ravel() - r[g, :, None])\n        var_scalar_part = obs * (nrisk_tot - obs) / var_denom\n        var = var_tensor_part * var_scalar_part[:, None]\n        if weights is not None:\n            oe = weights * oe\n            var = (weights ** 2)[:, None] * var\n        groups_oe.append(oe[ix].sum())\n        groups_var.append(var[ix].sum(axis=0))\n    obs_vec = np.hstack(groups_oe)\n    var_mat = np.vstack(groups_var)\n    return (obs_vec, var_mat)"
        ]
    },
    {
        "func_name": "plot_survfunc",
        "original": "def plot_survfunc(survfuncs, ax=None):\n    \"\"\"\n    Plot one or more survivor functions.\n\n    Parameters\n    ----------\n    survfuncs : object or array_like\n        A single SurvfuncRight object, or a list or SurvfuncRight\n        objects that are plotted together.\n\n    Returns\n    -------\n    A figure instance on which the plot was drawn.\n\n    Examples\n    --------\n    Add a legend:\n\n    >>> import statsmodels.api as sm\n    >>> from statsmodels.duration.survfunc import plot_survfunc\n    >>> data = sm.datasets.get_rdataset(\"flchain\", \"survival\").data\n    >>> df = data.loc[data.sex == \"F\", :]\n    >>> sf0 = sm.SurvfuncRight(df[\"futime\"], df[\"death\"])\n    >>> sf1 = sm.SurvfuncRight(3.0 * df[\"futime\"], df[\"death\"])\n    >>> fig = plot_survfunc([sf0, sf1])\n    >>> ax = fig.get_axes()[0]\n    >>> ax.set_position([0.1, 0.1, 0.64, 0.8])\n    >>> ha, lb = ax.get_legend_handles_labels()\n    >>> leg = fig.legend((ha[0], ha[1]), (lb[0], lb[1]), loc='center right')\n\n    Change the line colors:\n\n    >>> fig = plot_survfunc([sf0, sf1])\n    >>> ax = fig.get_axes()[0]\n    >>> ax.set_position([0.1, 0.1, 0.64, 0.8])\n    >>> ha, lb = ax.get_legend_handles_labels()\n    >>> ha[0].set_color('purple')\n    >>> ha[1].set_color('orange')\n    \"\"\"\n    (fig, ax) = utils.create_mpl_ax(ax)\n    try:\n        assert type(survfuncs[0]) is SurvfuncRight\n    except:\n        survfuncs = [survfuncs]\n    for (gx, sf) in enumerate(survfuncs):\n        surv_times = np.concatenate(([0], sf.surv_times))\n        surv_prob = np.concatenate(([1], sf.surv_prob))\n        mxt = max(sf.time)\n        if mxt > surv_times[-1]:\n            surv_times = np.concatenate((surv_times, [mxt]))\n            surv_prob = np.concatenate((surv_prob, [surv_prob[-1]]))\n        label = getattr(sf, 'title', 'Group %d' % (gx + 1))\n        (li,) = ax.step(surv_times, surv_prob, '-', label=label, lw=2, where='post')\n        ii = np.flatnonzero(np.logical_not(sf.status))\n        ti = np.unique(sf.time[ii])\n        jj = np.searchsorted(surv_times, ti) - 1\n        sp = surv_prob[jj]\n        ax.plot(ti, sp, '+', ms=12, color=li.get_color(), label=label + ' points')\n    ax.set_ylim(0, 1.01)\n    return fig",
        "mutated": [
            "def plot_survfunc(survfuncs, ax=None):\n    if False:\n        i = 10\n    '\\n    Plot one or more survivor functions.\\n\\n    Parameters\\n    ----------\\n    survfuncs : object or array_like\\n        A single SurvfuncRight object, or a list or SurvfuncRight\\n        objects that are plotted together.\\n\\n    Returns\\n    -------\\n    A figure instance on which the plot was drawn.\\n\\n    Examples\\n    --------\\n    Add a legend:\\n\\n    >>> import statsmodels.api as sm\\n    >>> from statsmodels.duration.survfunc import plot_survfunc\\n    >>> data = sm.datasets.get_rdataset(\"flchain\", \"survival\").data\\n    >>> df = data.loc[data.sex == \"F\", :]\\n    >>> sf0 = sm.SurvfuncRight(df[\"futime\"], df[\"death\"])\\n    >>> sf1 = sm.SurvfuncRight(3.0 * df[\"futime\"], df[\"death\"])\\n    >>> fig = plot_survfunc([sf0, sf1])\\n    >>> ax = fig.get_axes()[0]\\n    >>> ax.set_position([0.1, 0.1, 0.64, 0.8])\\n    >>> ha, lb = ax.get_legend_handles_labels()\\n    >>> leg = fig.legend((ha[0], ha[1]), (lb[0], lb[1]), loc=\\'center right\\')\\n\\n    Change the line colors:\\n\\n    >>> fig = plot_survfunc([sf0, sf1])\\n    >>> ax = fig.get_axes()[0]\\n    >>> ax.set_position([0.1, 0.1, 0.64, 0.8])\\n    >>> ha, lb = ax.get_legend_handles_labels()\\n    >>> ha[0].set_color(\\'purple\\')\\n    >>> ha[1].set_color(\\'orange\\')\\n    '\n    (fig, ax) = utils.create_mpl_ax(ax)\n    try:\n        assert type(survfuncs[0]) is SurvfuncRight\n    except:\n        survfuncs = [survfuncs]\n    for (gx, sf) in enumerate(survfuncs):\n        surv_times = np.concatenate(([0], sf.surv_times))\n        surv_prob = np.concatenate(([1], sf.surv_prob))\n        mxt = max(sf.time)\n        if mxt > surv_times[-1]:\n            surv_times = np.concatenate((surv_times, [mxt]))\n            surv_prob = np.concatenate((surv_prob, [surv_prob[-1]]))\n        label = getattr(sf, 'title', 'Group %d' % (gx + 1))\n        (li,) = ax.step(surv_times, surv_prob, '-', label=label, lw=2, where='post')\n        ii = np.flatnonzero(np.logical_not(sf.status))\n        ti = np.unique(sf.time[ii])\n        jj = np.searchsorted(surv_times, ti) - 1\n        sp = surv_prob[jj]\n        ax.plot(ti, sp, '+', ms=12, color=li.get_color(), label=label + ' points')\n    ax.set_ylim(0, 1.01)\n    return fig",
            "def plot_survfunc(survfuncs, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n    Plot one or more survivor functions.\\n\\n    Parameters\\n    ----------\\n    survfuncs : object or array_like\\n        A single SurvfuncRight object, or a list or SurvfuncRight\\n        objects that are plotted together.\\n\\n    Returns\\n    -------\\n    A figure instance on which the plot was drawn.\\n\\n    Examples\\n    --------\\n    Add a legend:\\n\\n    >>> import statsmodels.api as sm\\n    >>> from statsmodels.duration.survfunc import plot_survfunc\\n    >>> data = sm.datasets.get_rdataset(\"flchain\", \"survival\").data\\n    >>> df = data.loc[data.sex == \"F\", :]\\n    >>> sf0 = sm.SurvfuncRight(df[\"futime\"], df[\"death\"])\\n    >>> sf1 = sm.SurvfuncRight(3.0 * df[\"futime\"], df[\"death\"])\\n    >>> fig = plot_survfunc([sf0, sf1])\\n    >>> ax = fig.get_axes()[0]\\n    >>> ax.set_position([0.1, 0.1, 0.64, 0.8])\\n    >>> ha, lb = ax.get_legend_handles_labels()\\n    >>> leg = fig.legend((ha[0], ha[1]), (lb[0], lb[1]), loc=\\'center right\\')\\n\\n    Change the line colors:\\n\\n    >>> fig = plot_survfunc([sf0, sf1])\\n    >>> ax = fig.get_axes()[0]\\n    >>> ax.set_position([0.1, 0.1, 0.64, 0.8])\\n    >>> ha, lb = ax.get_legend_handles_labels()\\n    >>> ha[0].set_color(\\'purple\\')\\n    >>> ha[1].set_color(\\'orange\\')\\n    '\n    (fig, ax) = utils.create_mpl_ax(ax)\n    try:\n        assert type(survfuncs[0]) is SurvfuncRight\n    except:\n        survfuncs = [survfuncs]\n    for (gx, sf) in enumerate(survfuncs):\n        surv_times = np.concatenate(([0], sf.surv_times))\n        surv_prob = np.concatenate(([1], sf.surv_prob))\n        mxt = max(sf.time)\n        if mxt > surv_times[-1]:\n            surv_times = np.concatenate((surv_times, [mxt]))\n            surv_prob = np.concatenate((surv_prob, [surv_prob[-1]]))\n        label = getattr(sf, 'title', 'Group %d' % (gx + 1))\n        (li,) = ax.step(surv_times, surv_prob, '-', label=label, lw=2, where='post')\n        ii = np.flatnonzero(np.logical_not(sf.status))\n        ti = np.unique(sf.time[ii])\n        jj = np.searchsorted(surv_times, ti) - 1\n        sp = surv_prob[jj]\n        ax.plot(ti, sp, '+', ms=12, color=li.get_color(), label=label + ' points')\n    ax.set_ylim(0, 1.01)\n    return fig",
            "def plot_survfunc(survfuncs, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n    Plot one or more survivor functions.\\n\\n    Parameters\\n    ----------\\n    survfuncs : object or array_like\\n        A single SurvfuncRight object, or a list or SurvfuncRight\\n        objects that are plotted together.\\n\\n    Returns\\n    -------\\n    A figure instance on which the plot was drawn.\\n\\n    Examples\\n    --------\\n    Add a legend:\\n\\n    >>> import statsmodels.api as sm\\n    >>> from statsmodels.duration.survfunc import plot_survfunc\\n    >>> data = sm.datasets.get_rdataset(\"flchain\", \"survival\").data\\n    >>> df = data.loc[data.sex == \"F\", :]\\n    >>> sf0 = sm.SurvfuncRight(df[\"futime\"], df[\"death\"])\\n    >>> sf1 = sm.SurvfuncRight(3.0 * df[\"futime\"], df[\"death\"])\\n    >>> fig = plot_survfunc([sf0, sf1])\\n    >>> ax = fig.get_axes()[0]\\n    >>> ax.set_position([0.1, 0.1, 0.64, 0.8])\\n    >>> ha, lb = ax.get_legend_handles_labels()\\n    >>> leg = fig.legend((ha[0], ha[1]), (lb[0], lb[1]), loc=\\'center right\\')\\n\\n    Change the line colors:\\n\\n    >>> fig = plot_survfunc([sf0, sf1])\\n    >>> ax = fig.get_axes()[0]\\n    >>> ax.set_position([0.1, 0.1, 0.64, 0.8])\\n    >>> ha, lb = ax.get_legend_handles_labels()\\n    >>> ha[0].set_color(\\'purple\\')\\n    >>> ha[1].set_color(\\'orange\\')\\n    '\n    (fig, ax) = utils.create_mpl_ax(ax)\n    try:\n        assert type(survfuncs[0]) is SurvfuncRight\n    except:\n        survfuncs = [survfuncs]\n    for (gx, sf) in enumerate(survfuncs):\n        surv_times = np.concatenate(([0], sf.surv_times))\n        surv_prob = np.concatenate(([1], sf.surv_prob))\n        mxt = max(sf.time)\n        if mxt > surv_times[-1]:\n            surv_times = np.concatenate((surv_times, [mxt]))\n            surv_prob = np.concatenate((surv_prob, [surv_prob[-1]]))\n        label = getattr(sf, 'title', 'Group %d' % (gx + 1))\n        (li,) = ax.step(surv_times, surv_prob, '-', label=label, lw=2, where='post')\n        ii = np.flatnonzero(np.logical_not(sf.status))\n        ti = np.unique(sf.time[ii])\n        jj = np.searchsorted(surv_times, ti) - 1\n        sp = surv_prob[jj]\n        ax.plot(ti, sp, '+', ms=12, color=li.get_color(), label=label + ' points')\n    ax.set_ylim(0, 1.01)\n    return fig",
            "def plot_survfunc(survfuncs, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n    Plot one or more survivor functions.\\n\\n    Parameters\\n    ----------\\n    survfuncs : object or array_like\\n        A single SurvfuncRight object, or a list or SurvfuncRight\\n        objects that are plotted together.\\n\\n    Returns\\n    -------\\n    A figure instance on which the plot was drawn.\\n\\n    Examples\\n    --------\\n    Add a legend:\\n\\n    >>> import statsmodels.api as sm\\n    >>> from statsmodels.duration.survfunc import plot_survfunc\\n    >>> data = sm.datasets.get_rdataset(\"flchain\", \"survival\").data\\n    >>> df = data.loc[data.sex == \"F\", :]\\n    >>> sf0 = sm.SurvfuncRight(df[\"futime\"], df[\"death\"])\\n    >>> sf1 = sm.SurvfuncRight(3.0 * df[\"futime\"], df[\"death\"])\\n    >>> fig = plot_survfunc([sf0, sf1])\\n    >>> ax = fig.get_axes()[0]\\n    >>> ax.set_position([0.1, 0.1, 0.64, 0.8])\\n    >>> ha, lb = ax.get_legend_handles_labels()\\n    >>> leg = fig.legend((ha[0], ha[1]), (lb[0], lb[1]), loc=\\'center right\\')\\n\\n    Change the line colors:\\n\\n    >>> fig = plot_survfunc([sf0, sf1])\\n    >>> ax = fig.get_axes()[0]\\n    >>> ax.set_position([0.1, 0.1, 0.64, 0.8])\\n    >>> ha, lb = ax.get_legend_handles_labels()\\n    >>> ha[0].set_color(\\'purple\\')\\n    >>> ha[1].set_color(\\'orange\\')\\n    '\n    (fig, ax) = utils.create_mpl_ax(ax)\n    try:\n        assert type(survfuncs[0]) is SurvfuncRight\n    except:\n        survfuncs = [survfuncs]\n    for (gx, sf) in enumerate(survfuncs):\n        surv_times = np.concatenate(([0], sf.surv_times))\n        surv_prob = np.concatenate(([1], sf.surv_prob))\n        mxt = max(sf.time)\n        if mxt > surv_times[-1]:\n            surv_times = np.concatenate((surv_times, [mxt]))\n            surv_prob = np.concatenate((surv_prob, [surv_prob[-1]]))\n        label = getattr(sf, 'title', 'Group %d' % (gx + 1))\n        (li,) = ax.step(surv_times, surv_prob, '-', label=label, lw=2, where='post')\n        ii = np.flatnonzero(np.logical_not(sf.status))\n        ti = np.unique(sf.time[ii])\n        jj = np.searchsorted(surv_times, ti) - 1\n        sp = surv_prob[jj]\n        ax.plot(ti, sp, '+', ms=12, color=li.get_color(), label=label + ' points')\n    ax.set_ylim(0, 1.01)\n    return fig",
            "def plot_survfunc(survfuncs, ax=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n    Plot one or more survivor functions.\\n\\n    Parameters\\n    ----------\\n    survfuncs : object or array_like\\n        A single SurvfuncRight object, or a list or SurvfuncRight\\n        objects that are plotted together.\\n\\n    Returns\\n    -------\\n    A figure instance on which the plot was drawn.\\n\\n    Examples\\n    --------\\n    Add a legend:\\n\\n    >>> import statsmodels.api as sm\\n    >>> from statsmodels.duration.survfunc import plot_survfunc\\n    >>> data = sm.datasets.get_rdataset(\"flchain\", \"survival\").data\\n    >>> df = data.loc[data.sex == \"F\", :]\\n    >>> sf0 = sm.SurvfuncRight(df[\"futime\"], df[\"death\"])\\n    >>> sf1 = sm.SurvfuncRight(3.0 * df[\"futime\"], df[\"death\"])\\n    >>> fig = plot_survfunc([sf0, sf1])\\n    >>> ax = fig.get_axes()[0]\\n    >>> ax.set_position([0.1, 0.1, 0.64, 0.8])\\n    >>> ha, lb = ax.get_legend_handles_labels()\\n    >>> leg = fig.legend((ha[0], ha[1]), (lb[0], lb[1]), loc=\\'center right\\')\\n\\n    Change the line colors:\\n\\n    >>> fig = plot_survfunc([sf0, sf1])\\n    >>> ax = fig.get_axes()[0]\\n    >>> ax.set_position([0.1, 0.1, 0.64, 0.8])\\n    >>> ha, lb = ax.get_legend_handles_labels()\\n    >>> ha[0].set_color(\\'purple\\')\\n    >>> ha[1].set_color(\\'orange\\')\\n    '\n    (fig, ax) = utils.create_mpl_ax(ax)\n    try:\n        assert type(survfuncs[0]) is SurvfuncRight\n    except:\n        survfuncs = [survfuncs]\n    for (gx, sf) in enumerate(survfuncs):\n        surv_times = np.concatenate(([0], sf.surv_times))\n        surv_prob = np.concatenate(([1], sf.surv_prob))\n        mxt = max(sf.time)\n        if mxt > surv_times[-1]:\n            surv_times = np.concatenate((surv_times, [mxt]))\n            surv_prob = np.concatenate((surv_prob, [surv_prob[-1]]))\n        label = getattr(sf, 'title', 'Group %d' % (gx + 1))\n        (li,) = ax.step(surv_times, surv_prob, '-', label=label, lw=2, where='post')\n        ii = np.flatnonzero(np.logical_not(sf.status))\n        ti = np.unique(sf.time[ii])\n        jj = np.searchsorted(surv_times, ti) - 1\n        sp = surv_prob[jj]\n        ax.plot(ti, sp, '+', ms=12, color=li.get_color(), label=label + ' points')\n    ax.set_ylim(0, 1.01)\n    return fig"
        ]
    }
]