[
    {
        "func_name": "stackedensemble_nfolds_test",
        "original": "def stackedensemble_nfolds_test():\n    \"\"\"This test checks the following:\n    1) That H2OStackedEnsembleEstimator `metalearner_nfolds` works correctly\n    2) That H2OStackedEnsembleEstimator `metalearner_fold_assignment` works correctly\n    3) That Stacked Ensemble cross-validation metrics are correctly copied from metalearner\n    \"\"\"\n    train = h2o.import_file(path=pyunit_utils.locate('smalldata/testng/higgs_train_5k.csv'), destination_frame='higgs_train_5k')\n    test = h2o.import_file(path=pyunit_utils.locate('smalldata/testng/higgs_test_5k.csv'), destination_frame='higgs_test_5k')\n    fold_column = 'fold_id'\n    train[fold_column] = train.kfold_column(n_folds=3, seed=1)\n    x = train.columns\n    y = 'response'\n    x.remove(y)\n    x.remove(fold_column)\n    train[y] = train[y].asfactor()\n    test[y] = test[y].asfactor()\n    nfolds = 3\n    my_gbm = H2OGradientBoostingEstimator(distribution='bernoulli', ntrees=10, nfolds=nfolds, fold_assignment='Modulo', keep_cross_validation_predictions=True, seed=1)\n    my_gbm.train(x=x, y=y, training_frame=train)\n    my_rf = H2ORandomForestEstimator(ntrees=50, nfolds=nfolds, fold_assignment='Modulo', keep_cross_validation_predictions=True, seed=1)\n    my_rf.train(x=x, y=y, training_frame=train)\n    stack0 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf])\n    stack0.train(x=x, y=y, training_frame=train)\n    assert stack0.params['metalearner_nfolds']['actual'] == 0\n    meta0 = h2o.get_model(stack0.metalearner()['name'])\n    assert meta0.params['nfolds']['actual'] == 0\n    stack1 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3)\n    stack1.train(x=x, y=y, training_frame=train)\n    assert stack1.params['metalearner_nfolds']['actual'] == 3\n    meta1 = h2o.get_model(stack1.metalearner()['name'])\n    assert meta1.params['nfolds']['actual'] == 3\n    assert meta1.params['fold_assignment']['input'] == 'AUTO'\n    assert meta1.params['fold_assignment']['actual'] == 'Random'\n    assert stack1.mse(valid=True) is None\n    assert stack1.mse(xval=True) == meta1.mse(xval=True)\n    ss = test.split_frame(ratios=[0.5], seed=1)\n    stack2 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3)\n    stack2.train(x=x, y=y, training_frame=train, validation_frame=ss[0])\n    meta2 = h2o.get_model(stack2.metalearner()['name'])\n    assert stack2.mse(valid=True) == meta2.mse(valid=True)\n    assert stack2.mse(xval=True) == meta2.mse(xval=True)\n    stack3 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3, metalearner_fold_assignment='Modulo')\n    stack3.train(x=x, y=y, training_frame=train)\n    assert stack3.params['metalearner_fold_assignment']['actual'] == 'Modulo'\n    meta3 = h2o.get_model(stack3.metalearner()['name'])\n    assert meta3.params['fold_assignment']['actual'] == 'Modulo'\n    stack4 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_fold_column=fold_column, metalearner_params=dict(keep_cross_validation_models=True))\n    stack4.train(x=x, y=y, training_frame=train)\n    assert stack4.params['metalearner_fold_column']['actual']['column_name'] == fold_column\n    meta4 = h2o.get_model(stack4.metalearner()['name'])\n    assert meta4.params['fold_column']['actual']['column_name'] == fold_column\n    assert meta4.params['nfolds']['actual'] == 0\n    assert len(meta4.cross_validation_models()) == 3",
        "mutated": [
            "def stackedensemble_nfolds_test():\n    if False:\n        i = 10\n    'This test checks the following:\\n    1) That H2OStackedEnsembleEstimator `metalearner_nfolds` works correctly\\n    2) That H2OStackedEnsembleEstimator `metalearner_fold_assignment` works correctly\\n    3) That Stacked Ensemble cross-validation metrics are correctly copied from metalearner\\n    '\n    train = h2o.import_file(path=pyunit_utils.locate('smalldata/testng/higgs_train_5k.csv'), destination_frame='higgs_train_5k')\n    test = h2o.import_file(path=pyunit_utils.locate('smalldata/testng/higgs_test_5k.csv'), destination_frame='higgs_test_5k')\n    fold_column = 'fold_id'\n    train[fold_column] = train.kfold_column(n_folds=3, seed=1)\n    x = train.columns\n    y = 'response'\n    x.remove(y)\n    x.remove(fold_column)\n    train[y] = train[y].asfactor()\n    test[y] = test[y].asfactor()\n    nfolds = 3\n    my_gbm = H2OGradientBoostingEstimator(distribution='bernoulli', ntrees=10, nfolds=nfolds, fold_assignment='Modulo', keep_cross_validation_predictions=True, seed=1)\n    my_gbm.train(x=x, y=y, training_frame=train)\n    my_rf = H2ORandomForestEstimator(ntrees=50, nfolds=nfolds, fold_assignment='Modulo', keep_cross_validation_predictions=True, seed=1)\n    my_rf.train(x=x, y=y, training_frame=train)\n    stack0 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf])\n    stack0.train(x=x, y=y, training_frame=train)\n    assert stack0.params['metalearner_nfolds']['actual'] == 0\n    meta0 = h2o.get_model(stack0.metalearner()['name'])\n    assert meta0.params['nfolds']['actual'] == 0\n    stack1 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3)\n    stack1.train(x=x, y=y, training_frame=train)\n    assert stack1.params['metalearner_nfolds']['actual'] == 3\n    meta1 = h2o.get_model(stack1.metalearner()['name'])\n    assert meta1.params['nfolds']['actual'] == 3\n    assert meta1.params['fold_assignment']['input'] == 'AUTO'\n    assert meta1.params['fold_assignment']['actual'] == 'Random'\n    assert stack1.mse(valid=True) is None\n    assert stack1.mse(xval=True) == meta1.mse(xval=True)\n    ss = test.split_frame(ratios=[0.5], seed=1)\n    stack2 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3)\n    stack2.train(x=x, y=y, training_frame=train, validation_frame=ss[0])\n    meta2 = h2o.get_model(stack2.metalearner()['name'])\n    assert stack2.mse(valid=True) == meta2.mse(valid=True)\n    assert stack2.mse(xval=True) == meta2.mse(xval=True)\n    stack3 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3, metalearner_fold_assignment='Modulo')\n    stack3.train(x=x, y=y, training_frame=train)\n    assert stack3.params['metalearner_fold_assignment']['actual'] == 'Modulo'\n    meta3 = h2o.get_model(stack3.metalearner()['name'])\n    assert meta3.params['fold_assignment']['actual'] == 'Modulo'\n    stack4 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_fold_column=fold_column, metalearner_params=dict(keep_cross_validation_models=True))\n    stack4.train(x=x, y=y, training_frame=train)\n    assert stack4.params['metalearner_fold_column']['actual']['column_name'] == fold_column\n    meta4 = h2o.get_model(stack4.metalearner()['name'])\n    assert meta4.params['fold_column']['actual']['column_name'] == fold_column\n    assert meta4.params['nfolds']['actual'] == 0\n    assert len(meta4.cross_validation_models()) == 3",
            "def stackedensemble_nfolds_test():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'This test checks the following:\\n    1) That H2OStackedEnsembleEstimator `metalearner_nfolds` works correctly\\n    2) That H2OStackedEnsembleEstimator `metalearner_fold_assignment` works correctly\\n    3) That Stacked Ensemble cross-validation metrics are correctly copied from metalearner\\n    '\n    train = h2o.import_file(path=pyunit_utils.locate('smalldata/testng/higgs_train_5k.csv'), destination_frame='higgs_train_5k')\n    test = h2o.import_file(path=pyunit_utils.locate('smalldata/testng/higgs_test_5k.csv'), destination_frame='higgs_test_5k')\n    fold_column = 'fold_id'\n    train[fold_column] = train.kfold_column(n_folds=3, seed=1)\n    x = train.columns\n    y = 'response'\n    x.remove(y)\n    x.remove(fold_column)\n    train[y] = train[y].asfactor()\n    test[y] = test[y].asfactor()\n    nfolds = 3\n    my_gbm = H2OGradientBoostingEstimator(distribution='bernoulli', ntrees=10, nfolds=nfolds, fold_assignment='Modulo', keep_cross_validation_predictions=True, seed=1)\n    my_gbm.train(x=x, y=y, training_frame=train)\n    my_rf = H2ORandomForestEstimator(ntrees=50, nfolds=nfolds, fold_assignment='Modulo', keep_cross_validation_predictions=True, seed=1)\n    my_rf.train(x=x, y=y, training_frame=train)\n    stack0 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf])\n    stack0.train(x=x, y=y, training_frame=train)\n    assert stack0.params['metalearner_nfolds']['actual'] == 0\n    meta0 = h2o.get_model(stack0.metalearner()['name'])\n    assert meta0.params['nfolds']['actual'] == 0\n    stack1 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3)\n    stack1.train(x=x, y=y, training_frame=train)\n    assert stack1.params['metalearner_nfolds']['actual'] == 3\n    meta1 = h2o.get_model(stack1.metalearner()['name'])\n    assert meta1.params['nfolds']['actual'] == 3\n    assert meta1.params['fold_assignment']['input'] == 'AUTO'\n    assert meta1.params['fold_assignment']['actual'] == 'Random'\n    assert stack1.mse(valid=True) is None\n    assert stack1.mse(xval=True) == meta1.mse(xval=True)\n    ss = test.split_frame(ratios=[0.5], seed=1)\n    stack2 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3)\n    stack2.train(x=x, y=y, training_frame=train, validation_frame=ss[0])\n    meta2 = h2o.get_model(stack2.metalearner()['name'])\n    assert stack2.mse(valid=True) == meta2.mse(valid=True)\n    assert stack2.mse(xval=True) == meta2.mse(xval=True)\n    stack3 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3, metalearner_fold_assignment='Modulo')\n    stack3.train(x=x, y=y, training_frame=train)\n    assert stack3.params['metalearner_fold_assignment']['actual'] == 'Modulo'\n    meta3 = h2o.get_model(stack3.metalearner()['name'])\n    assert meta3.params['fold_assignment']['actual'] == 'Modulo'\n    stack4 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_fold_column=fold_column, metalearner_params=dict(keep_cross_validation_models=True))\n    stack4.train(x=x, y=y, training_frame=train)\n    assert stack4.params['metalearner_fold_column']['actual']['column_name'] == fold_column\n    meta4 = h2o.get_model(stack4.metalearner()['name'])\n    assert meta4.params['fold_column']['actual']['column_name'] == fold_column\n    assert meta4.params['nfolds']['actual'] == 0\n    assert len(meta4.cross_validation_models()) == 3",
            "def stackedensemble_nfolds_test():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'This test checks the following:\\n    1) That H2OStackedEnsembleEstimator `metalearner_nfolds` works correctly\\n    2) That H2OStackedEnsembleEstimator `metalearner_fold_assignment` works correctly\\n    3) That Stacked Ensemble cross-validation metrics are correctly copied from metalearner\\n    '\n    train = h2o.import_file(path=pyunit_utils.locate('smalldata/testng/higgs_train_5k.csv'), destination_frame='higgs_train_5k')\n    test = h2o.import_file(path=pyunit_utils.locate('smalldata/testng/higgs_test_5k.csv'), destination_frame='higgs_test_5k')\n    fold_column = 'fold_id'\n    train[fold_column] = train.kfold_column(n_folds=3, seed=1)\n    x = train.columns\n    y = 'response'\n    x.remove(y)\n    x.remove(fold_column)\n    train[y] = train[y].asfactor()\n    test[y] = test[y].asfactor()\n    nfolds = 3\n    my_gbm = H2OGradientBoostingEstimator(distribution='bernoulli', ntrees=10, nfolds=nfolds, fold_assignment='Modulo', keep_cross_validation_predictions=True, seed=1)\n    my_gbm.train(x=x, y=y, training_frame=train)\n    my_rf = H2ORandomForestEstimator(ntrees=50, nfolds=nfolds, fold_assignment='Modulo', keep_cross_validation_predictions=True, seed=1)\n    my_rf.train(x=x, y=y, training_frame=train)\n    stack0 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf])\n    stack0.train(x=x, y=y, training_frame=train)\n    assert stack0.params['metalearner_nfolds']['actual'] == 0\n    meta0 = h2o.get_model(stack0.metalearner()['name'])\n    assert meta0.params['nfolds']['actual'] == 0\n    stack1 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3)\n    stack1.train(x=x, y=y, training_frame=train)\n    assert stack1.params['metalearner_nfolds']['actual'] == 3\n    meta1 = h2o.get_model(stack1.metalearner()['name'])\n    assert meta1.params['nfolds']['actual'] == 3\n    assert meta1.params['fold_assignment']['input'] == 'AUTO'\n    assert meta1.params['fold_assignment']['actual'] == 'Random'\n    assert stack1.mse(valid=True) is None\n    assert stack1.mse(xval=True) == meta1.mse(xval=True)\n    ss = test.split_frame(ratios=[0.5], seed=1)\n    stack2 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3)\n    stack2.train(x=x, y=y, training_frame=train, validation_frame=ss[0])\n    meta2 = h2o.get_model(stack2.metalearner()['name'])\n    assert stack2.mse(valid=True) == meta2.mse(valid=True)\n    assert stack2.mse(xval=True) == meta2.mse(xval=True)\n    stack3 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3, metalearner_fold_assignment='Modulo')\n    stack3.train(x=x, y=y, training_frame=train)\n    assert stack3.params['metalearner_fold_assignment']['actual'] == 'Modulo'\n    meta3 = h2o.get_model(stack3.metalearner()['name'])\n    assert meta3.params['fold_assignment']['actual'] == 'Modulo'\n    stack4 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_fold_column=fold_column, metalearner_params=dict(keep_cross_validation_models=True))\n    stack4.train(x=x, y=y, training_frame=train)\n    assert stack4.params['metalearner_fold_column']['actual']['column_name'] == fold_column\n    meta4 = h2o.get_model(stack4.metalearner()['name'])\n    assert meta4.params['fold_column']['actual']['column_name'] == fold_column\n    assert meta4.params['nfolds']['actual'] == 0\n    assert len(meta4.cross_validation_models()) == 3",
            "def stackedensemble_nfolds_test():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'This test checks the following:\\n    1) That H2OStackedEnsembleEstimator `metalearner_nfolds` works correctly\\n    2) That H2OStackedEnsembleEstimator `metalearner_fold_assignment` works correctly\\n    3) That Stacked Ensemble cross-validation metrics are correctly copied from metalearner\\n    '\n    train = h2o.import_file(path=pyunit_utils.locate('smalldata/testng/higgs_train_5k.csv'), destination_frame='higgs_train_5k')\n    test = h2o.import_file(path=pyunit_utils.locate('smalldata/testng/higgs_test_5k.csv'), destination_frame='higgs_test_5k')\n    fold_column = 'fold_id'\n    train[fold_column] = train.kfold_column(n_folds=3, seed=1)\n    x = train.columns\n    y = 'response'\n    x.remove(y)\n    x.remove(fold_column)\n    train[y] = train[y].asfactor()\n    test[y] = test[y].asfactor()\n    nfolds = 3\n    my_gbm = H2OGradientBoostingEstimator(distribution='bernoulli', ntrees=10, nfolds=nfolds, fold_assignment='Modulo', keep_cross_validation_predictions=True, seed=1)\n    my_gbm.train(x=x, y=y, training_frame=train)\n    my_rf = H2ORandomForestEstimator(ntrees=50, nfolds=nfolds, fold_assignment='Modulo', keep_cross_validation_predictions=True, seed=1)\n    my_rf.train(x=x, y=y, training_frame=train)\n    stack0 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf])\n    stack0.train(x=x, y=y, training_frame=train)\n    assert stack0.params['metalearner_nfolds']['actual'] == 0\n    meta0 = h2o.get_model(stack0.metalearner()['name'])\n    assert meta0.params['nfolds']['actual'] == 0\n    stack1 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3)\n    stack1.train(x=x, y=y, training_frame=train)\n    assert stack1.params['metalearner_nfolds']['actual'] == 3\n    meta1 = h2o.get_model(stack1.metalearner()['name'])\n    assert meta1.params['nfolds']['actual'] == 3\n    assert meta1.params['fold_assignment']['input'] == 'AUTO'\n    assert meta1.params['fold_assignment']['actual'] == 'Random'\n    assert stack1.mse(valid=True) is None\n    assert stack1.mse(xval=True) == meta1.mse(xval=True)\n    ss = test.split_frame(ratios=[0.5], seed=1)\n    stack2 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3)\n    stack2.train(x=x, y=y, training_frame=train, validation_frame=ss[0])\n    meta2 = h2o.get_model(stack2.metalearner()['name'])\n    assert stack2.mse(valid=True) == meta2.mse(valid=True)\n    assert stack2.mse(xval=True) == meta2.mse(xval=True)\n    stack3 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3, metalearner_fold_assignment='Modulo')\n    stack3.train(x=x, y=y, training_frame=train)\n    assert stack3.params['metalearner_fold_assignment']['actual'] == 'Modulo'\n    meta3 = h2o.get_model(stack3.metalearner()['name'])\n    assert meta3.params['fold_assignment']['actual'] == 'Modulo'\n    stack4 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_fold_column=fold_column, metalearner_params=dict(keep_cross_validation_models=True))\n    stack4.train(x=x, y=y, training_frame=train)\n    assert stack4.params['metalearner_fold_column']['actual']['column_name'] == fold_column\n    meta4 = h2o.get_model(stack4.metalearner()['name'])\n    assert meta4.params['fold_column']['actual']['column_name'] == fold_column\n    assert meta4.params['nfolds']['actual'] == 0\n    assert len(meta4.cross_validation_models()) == 3",
            "def stackedensemble_nfolds_test():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'This test checks the following:\\n    1) That H2OStackedEnsembleEstimator `metalearner_nfolds` works correctly\\n    2) That H2OStackedEnsembleEstimator `metalearner_fold_assignment` works correctly\\n    3) That Stacked Ensemble cross-validation metrics are correctly copied from metalearner\\n    '\n    train = h2o.import_file(path=pyunit_utils.locate('smalldata/testng/higgs_train_5k.csv'), destination_frame='higgs_train_5k')\n    test = h2o.import_file(path=pyunit_utils.locate('smalldata/testng/higgs_test_5k.csv'), destination_frame='higgs_test_5k')\n    fold_column = 'fold_id'\n    train[fold_column] = train.kfold_column(n_folds=3, seed=1)\n    x = train.columns\n    y = 'response'\n    x.remove(y)\n    x.remove(fold_column)\n    train[y] = train[y].asfactor()\n    test[y] = test[y].asfactor()\n    nfolds = 3\n    my_gbm = H2OGradientBoostingEstimator(distribution='bernoulli', ntrees=10, nfolds=nfolds, fold_assignment='Modulo', keep_cross_validation_predictions=True, seed=1)\n    my_gbm.train(x=x, y=y, training_frame=train)\n    my_rf = H2ORandomForestEstimator(ntrees=50, nfolds=nfolds, fold_assignment='Modulo', keep_cross_validation_predictions=True, seed=1)\n    my_rf.train(x=x, y=y, training_frame=train)\n    stack0 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf])\n    stack0.train(x=x, y=y, training_frame=train)\n    assert stack0.params['metalearner_nfolds']['actual'] == 0\n    meta0 = h2o.get_model(stack0.metalearner()['name'])\n    assert meta0.params['nfolds']['actual'] == 0\n    stack1 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3)\n    stack1.train(x=x, y=y, training_frame=train)\n    assert stack1.params['metalearner_nfolds']['actual'] == 3\n    meta1 = h2o.get_model(stack1.metalearner()['name'])\n    assert meta1.params['nfolds']['actual'] == 3\n    assert meta1.params['fold_assignment']['input'] == 'AUTO'\n    assert meta1.params['fold_assignment']['actual'] == 'Random'\n    assert stack1.mse(valid=True) is None\n    assert stack1.mse(xval=True) == meta1.mse(xval=True)\n    ss = test.split_frame(ratios=[0.5], seed=1)\n    stack2 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3)\n    stack2.train(x=x, y=y, training_frame=train, validation_frame=ss[0])\n    meta2 = h2o.get_model(stack2.metalearner()['name'])\n    assert stack2.mse(valid=True) == meta2.mse(valid=True)\n    assert stack2.mse(xval=True) == meta2.mse(xval=True)\n    stack3 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_nfolds=3, metalearner_fold_assignment='Modulo')\n    stack3.train(x=x, y=y, training_frame=train)\n    assert stack3.params['metalearner_fold_assignment']['actual'] == 'Modulo'\n    meta3 = h2o.get_model(stack3.metalearner()['name'])\n    assert meta3.params['fold_assignment']['actual'] == 'Modulo'\n    stack4 = H2OStackedEnsembleEstimator(base_models=[my_gbm, my_rf], metalearner_fold_column=fold_column, metalearner_params=dict(keep_cross_validation_models=True))\n    stack4.train(x=x, y=y, training_frame=train)\n    assert stack4.params['metalearner_fold_column']['actual']['column_name'] == fold_column\n    meta4 = h2o.get_model(stack4.metalearner()['name'])\n    assert meta4.params['fold_column']['actual']['column_name'] == fold_column\n    assert meta4.params['nfolds']['actual'] == 0\n    assert len(meta4.cross_validation_models()) == 3"
        ]
    }
]