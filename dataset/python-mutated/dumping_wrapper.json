[
    {
        "func_name": "__init__",
        "original": "def __init__(self, sess, session_root, watch_fn=None, thread_name_filter=None, pass_through_operrors=None):\n    \"\"\"Constructor of DumpingDebugWrapperSession.\n\n    Args:\n      sess: The TensorFlow `Session` object being wrapped.\n      session_root: (`str`) Path to the session root directory. Must be a\n        directory that does not exist or an empty directory. If the directory\n        does not exist, it will be created by the debugger core during debug\n        `tf.Session.run`\n        calls.\n        As the `run()` calls occur, subdirectories will be added to\n        `session_root`. The subdirectories' names has the following pattern:\n          run_<epoch_time_stamp>_<zero_based_run_counter>\n        E.g., run_1480734393835964_ad4c953a85444900ae79fc1b652fb324\n      watch_fn: (`Callable`) A Callable that can be used to define per-run\n        debug ops and watched tensors. See the doc of\n        `NonInteractiveDebugWrapperSession.__init__()` for details.\n      thread_name_filter: Regular-expression white list for threads on which the\n        wrapper session will be active. See doc of `BaseDebugWrapperSession` for\n        more details.\n      pass_through_operrors: If true, all captured OpErrors will be\n        propagated. By default this captures all OpErrors.\n\n    Raises:\n       ValueError: If `session_root` is an existing and non-empty directory or\n       if `session_root` is a file.\n    \"\"\"\n    framework.NonInteractiveDebugWrapperSession.__init__(self, sess, watch_fn=watch_fn, thread_name_filter=thread_name_filter, pass_through_operrors=pass_through_operrors)\n    session_root = os.path.expanduser(session_root)\n    if gfile.Exists(session_root):\n        if not gfile.IsDirectory(session_root):\n            raise ValueError('session_root path points to a file: %s' % session_root)\n        elif gfile.ListDirectory(session_root):\n            raise ValueError('session_root path points to a non-empty directory: %s' % session_root)\n    else:\n        gfile.MakeDirs(session_root)\n    self._session_root = session_root\n    self._run_counter = 0\n    self._run_counter_lock = threading.Lock()",
        "mutated": [
            "def __init__(self, sess, session_root, watch_fn=None, thread_name_filter=None, pass_through_operrors=None):\n    if False:\n        i = 10\n    \"Constructor of DumpingDebugWrapperSession.\\n\\n    Args:\\n      sess: The TensorFlow `Session` object being wrapped.\\n      session_root: (`str`) Path to the session root directory. Must be a\\n        directory that does not exist or an empty directory. If the directory\\n        does not exist, it will be created by the debugger core during debug\\n        `tf.Session.run`\\n        calls.\\n        As the `run()` calls occur, subdirectories will be added to\\n        `session_root`. The subdirectories' names has the following pattern:\\n          run_<epoch_time_stamp>_<zero_based_run_counter>\\n        E.g., run_1480734393835964_ad4c953a85444900ae79fc1b652fb324\\n      watch_fn: (`Callable`) A Callable that can be used to define per-run\\n        debug ops and watched tensors. See the doc of\\n        `NonInteractiveDebugWrapperSession.__init__()` for details.\\n      thread_name_filter: Regular-expression white list for threads on which the\\n        wrapper session will be active. See doc of `BaseDebugWrapperSession` for\\n        more details.\\n      pass_through_operrors: If true, all captured OpErrors will be\\n        propagated. By default this captures all OpErrors.\\n\\n    Raises:\\n       ValueError: If `session_root` is an existing and non-empty directory or\\n       if `session_root` is a file.\\n    \"\n    framework.NonInteractiveDebugWrapperSession.__init__(self, sess, watch_fn=watch_fn, thread_name_filter=thread_name_filter, pass_through_operrors=pass_through_operrors)\n    session_root = os.path.expanduser(session_root)\n    if gfile.Exists(session_root):\n        if not gfile.IsDirectory(session_root):\n            raise ValueError('session_root path points to a file: %s' % session_root)\n        elif gfile.ListDirectory(session_root):\n            raise ValueError('session_root path points to a non-empty directory: %s' % session_root)\n    else:\n        gfile.MakeDirs(session_root)\n    self._session_root = session_root\n    self._run_counter = 0\n    self._run_counter_lock = threading.Lock()",
            "def __init__(self, sess, session_root, watch_fn=None, thread_name_filter=None, pass_through_operrors=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Constructor of DumpingDebugWrapperSession.\\n\\n    Args:\\n      sess: The TensorFlow `Session` object being wrapped.\\n      session_root: (`str`) Path to the session root directory. Must be a\\n        directory that does not exist or an empty directory. If the directory\\n        does not exist, it will be created by the debugger core during debug\\n        `tf.Session.run`\\n        calls.\\n        As the `run()` calls occur, subdirectories will be added to\\n        `session_root`. The subdirectories' names has the following pattern:\\n          run_<epoch_time_stamp>_<zero_based_run_counter>\\n        E.g., run_1480734393835964_ad4c953a85444900ae79fc1b652fb324\\n      watch_fn: (`Callable`) A Callable that can be used to define per-run\\n        debug ops and watched tensors. See the doc of\\n        `NonInteractiveDebugWrapperSession.__init__()` for details.\\n      thread_name_filter: Regular-expression white list for threads on which the\\n        wrapper session will be active. See doc of `BaseDebugWrapperSession` for\\n        more details.\\n      pass_through_operrors: If true, all captured OpErrors will be\\n        propagated. By default this captures all OpErrors.\\n\\n    Raises:\\n       ValueError: If `session_root` is an existing and non-empty directory or\\n       if `session_root` is a file.\\n    \"\n    framework.NonInteractiveDebugWrapperSession.__init__(self, sess, watch_fn=watch_fn, thread_name_filter=thread_name_filter, pass_through_operrors=pass_through_operrors)\n    session_root = os.path.expanduser(session_root)\n    if gfile.Exists(session_root):\n        if not gfile.IsDirectory(session_root):\n            raise ValueError('session_root path points to a file: %s' % session_root)\n        elif gfile.ListDirectory(session_root):\n            raise ValueError('session_root path points to a non-empty directory: %s' % session_root)\n    else:\n        gfile.MakeDirs(session_root)\n    self._session_root = session_root\n    self._run_counter = 0\n    self._run_counter_lock = threading.Lock()",
            "def __init__(self, sess, session_root, watch_fn=None, thread_name_filter=None, pass_through_operrors=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Constructor of DumpingDebugWrapperSession.\\n\\n    Args:\\n      sess: The TensorFlow `Session` object being wrapped.\\n      session_root: (`str`) Path to the session root directory. Must be a\\n        directory that does not exist or an empty directory. If the directory\\n        does not exist, it will be created by the debugger core during debug\\n        `tf.Session.run`\\n        calls.\\n        As the `run()` calls occur, subdirectories will be added to\\n        `session_root`. The subdirectories' names has the following pattern:\\n          run_<epoch_time_stamp>_<zero_based_run_counter>\\n        E.g., run_1480734393835964_ad4c953a85444900ae79fc1b652fb324\\n      watch_fn: (`Callable`) A Callable that can be used to define per-run\\n        debug ops and watched tensors. See the doc of\\n        `NonInteractiveDebugWrapperSession.__init__()` for details.\\n      thread_name_filter: Regular-expression white list for threads on which the\\n        wrapper session will be active. See doc of `BaseDebugWrapperSession` for\\n        more details.\\n      pass_through_operrors: If true, all captured OpErrors will be\\n        propagated. By default this captures all OpErrors.\\n\\n    Raises:\\n       ValueError: If `session_root` is an existing and non-empty directory or\\n       if `session_root` is a file.\\n    \"\n    framework.NonInteractiveDebugWrapperSession.__init__(self, sess, watch_fn=watch_fn, thread_name_filter=thread_name_filter, pass_through_operrors=pass_through_operrors)\n    session_root = os.path.expanduser(session_root)\n    if gfile.Exists(session_root):\n        if not gfile.IsDirectory(session_root):\n            raise ValueError('session_root path points to a file: %s' % session_root)\n        elif gfile.ListDirectory(session_root):\n            raise ValueError('session_root path points to a non-empty directory: %s' % session_root)\n    else:\n        gfile.MakeDirs(session_root)\n    self._session_root = session_root\n    self._run_counter = 0\n    self._run_counter_lock = threading.Lock()",
            "def __init__(self, sess, session_root, watch_fn=None, thread_name_filter=None, pass_through_operrors=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Constructor of DumpingDebugWrapperSession.\\n\\n    Args:\\n      sess: The TensorFlow `Session` object being wrapped.\\n      session_root: (`str`) Path to the session root directory. Must be a\\n        directory that does not exist or an empty directory. If the directory\\n        does not exist, it will be created by the debugger core during debug\\n        `tf.Session.run`\\n        calls.\\n        As the `run()` calls occur, subdirectories will be added to\\n        `session_root`. The subdirectories' names has the following pattern:\\n          run_<epoch_time_stamp>_<zero_based_run_counter>\\n        E.g., run_1480734393835964_ad4c953a85444900ae79fc1b652fb324\\n      watch_fn: (`Callable`) A Callable that can be used to define per-run\\n        debug ops and watched tensors. See the doc of\\n        `NonInteractiveDebugWrapperSession.__init__()` for details.\\n      thread_name_filter: Regular-expression white list for threads on which the\\n        wrapper session will be active. See doc of `BaseDebugWrapperSession` for\\n        more details.\\n      pass_through_operrors: If true, all captured OpErrors will be\\n        propagated. By default this captures all OpErrors.\\n\\n    Raises:\\n       ValueError: If `session_root` is an existing and non-empty directory or\\n       if `session_root` is a file.\\n    \"\n    framework.NonInteractiveDebugWrapperSession.__init__(self, sess, watch_fn=watch_fn, thread_name_filter=thread_name_filter, pass_through_operrors=pass_through_operrors)\n    session_root = os.path.expanduser(session_root)\n    if gfile.Exists(session_root):\n        if not gfile.IsDirectory(session_root):\n            raise ValueError('session_root path points to a file: %s' % session_root)\n        elif gfile.ListDirectory(session_root):\n            raise ValueError('session_root path points to a non-empty directory: %s' % session_root)\n    else:\n        gfile.MakeDirs(session_root)\n    self._session_root = session_root\n    self._run_counter = 0\n    self._run_counter_lock = threading.Lock()",
            "def __init__(self, sess, session_root, watch_fn=None, thread_name_filter=None, pass_through_operrors=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Constructor of DumpingDebugWrapperSession.\\n\\n    Args:\\n      sess: The TensorFlow `Session` object being wrapped.\\n      session_root: (`str`) Path to the session root directory. Must be a\\n        directory that does not exist or an empty directory. If the directory\\n        does not exist, it will be created by the debugger core during debug\\n        `tf.Session.run`\\n        calls.\\n        As the `run()` calls occur, subdirectories will be added to\\n        `session_root`. The subdirectories' names has the following pattern:\\n          run_<epoch_time_stamp>_<zero_based_run_counter>\\n        E.g., run_1480734393835964_ad4c953a85444900ae79fc1b652fb324\\n      watch_fn: (`Callable`) A Callable that can be used to define per-run\\n        debug ops and watched tensors. See the doc of\\n        `NonInteractiveDebugWrapperSession.__init__()` for details.\\n      thread_name_filter: Regular-expression white list for threads on which the\\n        wrapper session will be active. See doc of `BaseDebugWrapperSession` for\\n        more details.\\n      pass_through_operrors: If true, all captured OpErrors will be\\n        propagated. By default this captures all OpErrors.\\n\\n    Raises:\\n       ValueError: If `session_root` is an existing and non-empty directory or\\n       if `session_root` is a file.\\n    \"\n    framework.NonInteractiveDebugWrapperSession.__init__(self, sess, watch_fn=watch_fn, thread_name_filter=thread_name_filter, pass_through_operrors=pass_through_operrors)\n    session_root = os.path.expanduser(session_root)\n    if gfile.Exists(session_root):\n        if not gfile.IsDirectory(session_root):\n            raise ValueError('session_root path points to a file: %s' % session_root)\n        elif gfile.ListDirectory(session_root):\n            raise ValueError('session_root path points to a non-empty directory: %s' % session_root)\n    else:\n        gfile.MakeDirs(session_root)\n    self._session_root = session_root\n    self._run_counter = 0\n    self._run_counter_lock = threading.Lock()"
        ]
    },
    {
        "func_name": "prepare_run_debug_urls",
        "original": "def prepare_run_debug_urls(self, fetches, feed_dict):\n    \"\"\"Implementation of abstract method in superclass.\n\n    See doc of `NonInteractiveDebugWrapperSession.prepare_run_debug_urls()`\n    for details. This implementation creates a run-specific subdirectory under\n    self._session_root and stores information regarding run `fetches` and\n    `feed_dict.keys()` in the subdirectory.\n\n    Args:\n      fetches: Same as the `fetches` argument to `Session.run()`\n      feed_dict: Same as the `feed_dict` argument to `Session.run()`\n\n    Returns:\n      debug_urls: (`str` or `list` of `str`) file:// debug URLs to be used in\n        this `Session.run()` call.\n    \"\"\"\n    self._run_counter_lock.acquire()\n    run_dir = os.path.join(self._session_root, 'run_%d_%d' % (int(time.time() * 1000000.0), self._run_counter))\n    self._run_counter += 1\n    self._run_counter_lock.release()\n    gfile.MkDir(run_dir)\n    fetches_event = event_pb2.Event()\n    fetches_event.log_message.message = repr(fetches)\n    fetches_path = os.path.join(run_dir, debug_data.METADATA_FILE_PREFIX + debug_data.FETCHES_INFO_FILE_TAG)\n    with gfile.Open(os.path.join(fetches_path), 'wb') as f:\n        f.write(fetches_event.SerializeToString())\n    feed_keys_event = event_pb2.Event()\n    feed_keys_event.log_message.message = repr(feed_dict.keys()) if feed_dict else repr(feed_dict)\n    feed_keys_path = os.path.join(run_dir, debug_data.METADATA_FILE_PREFIX + debug_data.FEED_KEYS_INFO_FILE_TAG)\n    with gfile.Open(os.path.join(feed_keys_path), 'wb') as f:\n        f.write(feed_keys_event.SerializeToString())\n    return ['file://' + run_dir]",
        "mutated": [
            "def prepare_run_debug_urls(self, fetches, feed_dict):\n    if False:\n        i = 10\n    'Implementation of abstract method in superclass.\\n\\n    See doc of `NonInteractiveDebugWrapperSession.prepare_run_debug_urls()`\\n    for details. This implementation creates a run-specific subdirectory under\\n    self._session_root and stores information regarding run `fetches` and\\n    `feed_dict.keys()` in the subdirectory.\\n\\n    Args:\\n      fetches: Same as the `fetches` argument to `Session.run()`\\n      feed_dict: Same as the `feed_dict` argument to `Session.run()`\\n\\n    Returns:\\n      debug_urls: (`str` or `list` of `str`) file:// debug URLs to be used in\\n        this `Session.run()` call.\\n    '\n    self._run_counter_lock.acquire()\n    run_dir = os.path.join(self._session_root, 'run_%d_%d' % (int(time.time() * 1000000.0), self._run_counter))\n    self._run_counter += 1\n    self._run_counter_lock.release()\n    gfile.MkDir(run_dir)\n    fetches_event = event_pb2.Event()\n    fetches_event.log_message.message = repr(fetches)\n    fetches_path = os.path.join(run_dir, debug_data.METADATA_FILE_PREFIX + debug_data.FETCHES_INFO_FILE_TAG)\n    with gfile.Open(os.path.join(fetches_path), 'wb') as f:\n        f.write(fetches_event.SerializeToString())\n    feed_keys_event = event_pb2.Event()\n    feed_keys_event.log_message.message = repr(feed_dict.keys()) if feed_dict else repr(feed_dict)\n    feed_keys_path = os.path.join(run_dir, debug_data.METADATA_FILE_PREFIX + debug_data.FEED_KEYS_INFO_FILE_TAG)\n    with gfile.Open(os.path.join(feed_keys_path), 'wb') as f:\n        f.write(feed_keys_event.SerializeToString())\n    return ['file://' + run_dir]",
            "def prepare_run_debug_urls(self, fetches, feed_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Implementation of abstract method in superclass.\\n\\n    See doc of `NonInteractiveDebugWrapperSession.prepare_run_debug_urls()`\\n    for details. This implementation creates a run-specific subdirectory under\\n    self._session_root and stores information regarding run `fetches` and\\n    `feed_dict.keys()` in the subdirectory.\\n\\n    Args:\\n      fetches: Same as the `fetches` argument to `Session.run()`\\n      feed_dict: Same as the `feed_dict` argument to `Session.run()`\\n\\n    Returns:\\n      debug_urls: (`str` or `list` of `str`) file:// debug URLs to be used in\\n        this `Session.run()` call.\\n    '\n    self._run_counter_lock.acquire()\n    run_dir = os.path.join(self._session_root, 'run_%d_%d' % (int(time.time() * 1000000.0), self._run_counter))\n    self._run_counter += 1\n    self._run_counter_lock.release()\n    gfile.MkDir(run_dir)\n    fetches_event = event_pb2.Event()\n    fetches_event.log_message.message = repr(fetches)\n    fetches_path = os.path.join(run_dir, debug_data.METADATA_FILE_PREFIX + debug_data.FETCHES_INFO_FILE_TAG)\n    with gfile.Open(os.path.join(fetches_path), 'wb') as f:\n        f.write(fetches_event.SerializeToString())\n    feed_keys_event = event_pb2.Event()\n    feed_keys_event.log_message.message = repr(feed_dict.keys()) if feed_dict else repr(feed_dict)\n    feed_keys_path = os.path.join(run_dir, debug_data.METADATA_FILE_PREFIX + debug_data.FEED_KEYS_INFO_FILE_TAG)\n    with gfile.Open(os.path.join(feed_keys_path), 'wb') as f:\n        f.write(feed_keys_event.SerializeToString())\n    return ['file://' + run_dir]",
            "def prepare_run_debug_urls(self, fetches, feed_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Implementation of abstract method in superclass.\\n\\n    See doc of `NonInteractiveDebugWrapperSession.prepare_run_debug_urls()`\\n    for details. This implementation creates a run-specific subdirectory under\\n    self._session_root and stores information regarding run `fetches` and\\n    `feed_dict.keys()` in the subdirectory.\\n\\n    Args:\\n      fetches: Same as the `fetches` argument to `Session.run()`\\n      feed_dict: Same as the `feed_dict` argument to `Session.run()`\\n\\n    Returns:\\n      debug_urls: (`str` or `list` of `str`) file:// debug URLs to be used in\\n        this `Session.run()` call.\\n    '\n    self._run_counter_lock.acquire()\n    run_dir = os.path.join(self._session_root, 'run_%d_%d' % (int(time.time() * 1000000.0), self._run_counter))\n    self._run_counter += 1\n    self._run_counter_lock.release()\n    gfile.MkDir(run_dir)\n    fetches_event = event_pb2.Event()\n    fetches_event.log_message.message = repr(fetches)\n    fetches_path = os.path.join(run_dir, debug_data.METADATA_FILE_PREFIX + debug_data.FETCHES_INFO_FILE_TAG)\n    with gfile.Open(os.path.join(fetches_path), 'wb') as f:\n        f.write(fetches_event.SerializeToString())\n    feed_keys_event = event_pb2.Event()\n    feed_keys_event.log_message.message = repr(feed_dict.keys()) if feed_dict else repr(feed_dict)\n    feed_keys_path = os.path.join(run_dir, debug_data.METADATA_FILE_PREFIX + debug_data.FEED_KEYS_INFO_FILE_TAG)\n    with gfile.Open(os.path.join(feed_keys_path), 'wb') as f:\n        f.write(feed_keys_event.SerializeToString())\n    return ['file://' + run_dir]",
            "def prepare_run_debug_urls(self, fetches, feed_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Implementation of abstract method in superclass.\\n\\n    See doc of `NonInteractiveDebugWrapperSession.prepare_run_debug_urls()`\\n    for details. This implementation creates a run-specific subdirectory under\\n    self._session_root and stores information regarding run `fetches` and\\n    `feed_dict.keys()` in the subdirectory.\\n\\n    Args:\\n      fetches: Same as the `fetches` argument to `Session.run()`\\n      feed_dict: Same as the `feed_dict` argument to `Session.run()`\\n\\n    Returns:\\n      debug_urls: (`str` or `list` of `str`) file:// debug URLs to be used in\\n        this `Session.run()` call.\\n    '\n    self._run_counter_lock.acquire()\n    run_dir = os.path.join(self._session_root, 'run_%d_%d' % (int(time.time() * 1000000.0), self._run_counter))\n    self._run_counter += 1\n    self._run_counter_lock.release()\n    gfile.MkDir(run_dir)\n    fetches_event = event_pb2.Event()\n    fetches_event.log_message.message = repr(fetches)\n    fetches_path = os.path.join(run_dir, debug_data.METADATA_FILE_PREFIX + debug_data.FETCHES_INFO_FILE_TAG)\n    with gfile.Open(os.path.join(fetches_path), 'wb') as f:\n        f.write(fetches_event.SerializeToString())\n    feed_keys_event = event_pb2.Event()\n    feed_keys_event.log_message.message = repr(feed_dict.keys()) if feed_dict else repr(feed_dict)\n    feed_keys_path = os.path.join(run_dir, debug_data.METADATA_FILE_PREFIX + debug_data.FEED_KEYS_INFO_FILE_TAG)\n    with gfile.Open(os.path.join(feed_keys_path), 'wb') as f:\n        f.write(feed_keys_event.SerializeToString())\n    return ['file://' + run_dir]",
            "def prepare_run_debug_urls(self, fetches, feed_dict):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Implementation of abstract method in superclass.\\n\\n    See doc of `NonInteractiveDebugWrapperSession.prepare_run_debug_urls()`\\n    for details. This implementation creates a run-specific subdirectory under\\n    self._session_root and stores information regarding run `fetches` and\\n    `feed_dict.keys()` in the subdirectory.\\n\\n    Args:\\n      fetches: Same as the `fetches` argument to `Session.run()`\\n      feed_dict: Same as the `feed_dict` argument to `Session.run()`\\n\\n    Returns:\\n      debug_urls: (`str` or `list` of `str`) file:// debug URLs to be used in\\n        this `Session.run()` call.\\n    '\n    self._run_counter_lock.acquire()\n    run_dir = os.path.join(self._session_root, 'run_%d_%d' % (int(time.time() * 1000000.0), self._run_counter))\n    self._run_counter += 1\n    self._run_counter_lock.release()\n    gfile.MkDir(run_dir)\n    fetches_event = event_pb2.Event()\n    fetches_event.log_message.message = repr(fetches)\n    fetches_path = os.path.join(run_dir, debug_data.METADATA_FILE_PREFIX + debug_data.FETCHES_INFO_FILE_TAG)\n    with gfile.Open(os.path.join(fetches_path), 'wb') as f:\n        f.write(fetches_event.SerializeToString())\n    feed_keys_event = event_pb2.Event()\n    feed_keys_event.log_message.message = repr(feed_dict.keys()) if feed_dict else repr(feed_dict)\n    feed_keys_path = os.path.join(run_dir, debug_data.METADATA_FILE_PREFIX + debug_data.FEED_KEYS_INFO_FILE_TAG)\n    with gfile.Open(os.path.join(feed_keys_path), 'wb') as f:\n        f.write(feed_keys_event.SerializeToString())\n    return ['file://' + run_dir]"
        ]
    }
]