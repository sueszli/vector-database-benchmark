[
    {
        "func_name": "create_attach_sparsifier",
        "original": "def create_attach_sparsifier(model, **sparse_config):\n    \"\"\"Create a DataNormSparsifier and the attach it to the model embedding layers\n\n    Args:\n        model (nn.Module)\n            layer of the model that needs to be attached to the sparsifier\n        sparse_config (Dict)\n            Config to the DataNormSparsifier. Should contain the following keys:\n                - sparse_block_shape\n                - norm\n                - sparsity_level\n    \"\"\"\n    data_norm_sparsifier = DataNormSparsifier(**sparse_config)\n    for (name, parameter) in model.named_parameters():\n        if 'emb_l' in name:\n            valid_name = get_valid_name(name)\n            data_norm_sparsifier.add_data(name=valid_name, data=parameter)\n    return data_norm_sparsifier",
        "mutated": [
            "def create_attach_sparsifier(model, **sparse_config):\n    if False:\n        i = 10\n    'Create a DataNormSparsifier and the attach it to the model embedding layers\\n\\n    Args:\\n        model (nn.Module)\\n            layer of the model that needs to be attached to the sparsifier\\n        sparse_config (Dict)\\n            Config to the DataNormSparsifier. Should contain the following keys:\\n                - sparse_block_shape\\n                - norm\\n                - sparsity_level\\n    '\n    data_norm_sparsifier = DataNormSparsifier(**sparse_config)\n    for (name, parameter) in model.named_parameters():\n        if 'emb_l' in name:\n            valid_name = get_valid_name(name)\n            data_norm_sparsifier.add_data(name=valid_name, data=parameter)\n    return data_norm_sparsifier",
            "def create_attach_sparsifier(model, **sparse_config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Create a DataNormSparsifier and the attach it to the model embedding layers\\n\\n    Args:\\n        model (nn.Module)\\n            layer of the model that needs to be attached to the sparsifier\\n        sparse_config (Dict)\\n            Config to the DataNormSparsifier. Should contain the following keys:\\n                - sparse_block_shape\\n                - norm\\n                - sparsity_level\\n    '\n    data_norm_sparsifier = DataNormSparsifier(**sparse_config)\n    for (name, parameter) in model.named_parameters():\n        if 'emb_l' in name:\n            valid_name = get_valid_name(name)\n            data_norm_sparsifier.add_data(name=valid_name, data=parameter)\n    return data_norm_sparsifier",
            "def create_attach_sparsifier(model, **sparse_config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Create a DataNormSparsifier and the attach it to the model embedding layers\\n\\n    Args:\\n        model (nn.Module)\\n            layer of the model that needs to be attached to the sparsifier\\n        sparse_config (Dict)\\n            Config to the DataNormSparsifier. Should contain the following keys:\\n                - sparse_block_shape\\n                - norm\\n                - sparsity_level\\n    '\n    data_norm_sparsifier = DataNormSparsifier(**sparse_config)\n    for (name, parameter) in model.named_parameters():\n        if 'emb_l' in name:\n            valid_name = get_valid_name(name)\n            data_norm_sparsifier.add_data(name=valid_name, data=parameter)\n    return data_norm_sparsifier",
            "def create_attach_sparsifier(model, **sparse_config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Create a DataNormSparsifier and the attach it to the model embedding layers\\n\\n    Args:\\n        model (nn.Module)\\n            layer of the model that needs to be attached to the sparsifier\\n        sparse_config (Dict)\\n            Config to the DataNormSparsifier. Should contain the following keys:\\n                - sparse_block_shape\\n                - norm\\n                - sparsity_level\\n    '\n    data_norm_sparsifier = DataNormSparsifier(**sparse_config)\n    for (name, parameter) in model.named_parameters():\n        if 'emb_l' in name:\n            valid_name = get_valid_name(name)\n            data_norm_sparsifier.add_data(name=valid_name, data=parameter)\n    return data_norm_sparsifier",
            "def create_attach_sparsifier(model, **sparse_config):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Create a DataNormSparsifier and the attach it to the model embedding layers\\n\\n    Args:\\n        model (nn.Module)\\n            layer of the model that needs to be attached to the sparsifier\\n        sparse_config (Dict)\\n            Config to the DataNormSparsifier. Should contain the following keys:\\n                - sparse_block_shape\\n                - norm\\n                - sparsity_level\\n    '\n    data_norm_sparsifier = DataNormSparsifier(**sparse_config)\n    for (name, parameter) in model.named_parameters():\n        if 'emb_l' in name:\n            valid_name = get_valid_name(name)\n            data_norm_sparsifier.add_data(name=valid_name, data=parameter)\n    return data_norm_sparsifier"
        ]
    },
    {
        "func_name": "save_model_states",
        "original": "def save_model_states(state_dict, sparsified_model_dump_path, save_file_name, sparse_block_shape, norm, zip=True):\n    \"\"\"Dumps the state_dict() of the model.\n\n    Args:\n        state_dict (Dict)\n            The state_dict() as dumped by dlrm_s_pytorch.py. Only the model state will be extracted\n            from this dictionary. This corresponds to the 'state_dict' key in the state_dict dictionary.\n            >>> model_state = state_dict['state_dict']\n        save_file_name (str)\n            The filename (not path) when saving the model state dictionary\n        sparse_block_shape (Tuple)\n            The block shape corresponding to the data norm sparsifier. **Used for creating save directory**\n        norm (str)\n            type of norm (L1, L2) for the datanorm sparsifier. **Used for creating save directory**\n        zip (bool)\n            if True, the file is zip-compressed.\n    \"\"\"\n    folder_name = os.path.join(sparsified_model_dump_path, str(norm))\n    folder_str = f'config_{sparse_block_shape}'\n    model_state = state_dict['state_dict']\n    model_state_path = os.path.join(folder_name, folder_str, save_file_name)\n    if not os.path.exists(os.path.dirname(model_state_path)):\n        os.makedirs(os.path.dirname(model_state_path))\n    torch.save(model_state, model_state_path)\n    if zip:\n        zip_path = model_state_path.replace('.ckpt', '.zip')\n        with ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zip:\n            zip.write(model_state_path, save_file_name)\n        os.remove(model_state_path)\n        model_state_path = zip_path\n    model_state_path = os.path.abspath(model_state_path)\n    file_size = os.path.getsize(model_state_path)\n    file_size = file_size >> 20\n    return (model_state_path, file_size)",
        "mutated": [
            "def save_model_states(state_dict, sparsified_model_dump_path, save_file_name, sparse_block_shape, norm, zip=True):\n    if False:\n        i = 10\n    \"Dumps the state_dict() of the model.\\n\\n    Args:\\n        state_dict (Dict)\\n            The state_dict() as dumped by dlrm_s_pytorch.py. Only the model state will be extracted\\n            from this dictionary. This corresponds to the 'state_dict' key in the state_dict dictionary.\\n            >>> model_state = state_dict['state_dict']\\n        save_file_name (str)\\n            The filename (not path) when saving the model state dictionary\\n        sparse_block_shape (Tuple)\\n            The block shape corresponding to the data norm sparsifier. **Used for creating save directory**\\n        norm (str)\\n            type of norm (L1, L2) for the datanorm sparsifier. **Used for creating save directory**\\n        zip (bool)\\n            if True, the file is zip-compressed.\\n    \"\n    folder_name = os.path.join(sparsified_model_dump_path, str(norm))\n    folder_str = f'config_{sparse_block_shape}'\n    model_state = state_dict['state_dict']\n    model_state_path = os.path.join(folder_name, folder_str, save_file_name)\n    if not os.path.exists(os.path.dirname(model_state_path)):\n        os.makedirs(os.path.dirname(model_state_path))\n    torch.save(model_state, model_state_path)\n    if zip:\n        zip_path = model_state_path.replace('.ckpt', '.zip')\n        with ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zip:\n            zip.write(model_state_path, save_file_name)\n        os.remove(model_state_path)\n        model_state_path = zip_path\n    model_state_path = os.path.abspath(model_state_path)\n    file_size = os.path.getsize(model_state_path)\n    file_size = file_size >> 20\n    return (model_state_path, file_size)",
            "def save_model_states(state_dict, sparsified_model_dump_path, save_file_name, sparse_block_shape, norm, zip=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Dumps the state_dict() of the model.\\n\\n    Args:\\n        state_dict (Dict)\\n            The state_dict() as dumped by dlrm_s_pytorch.py. Only the model state will be extracted\\n            from this dictionary. This corresponds to the 'state_dict' key in the state_dict dictionary.\\n            >>> model_state = state_dict['state_dict']\\n        save_file_name (str)\\n            The filename (not path) when saving the model state dictionary\\n        sparse_block_shape (Tuple)\\n            The block shape corresponding to the data norm sparsifier. **Used for creating save directory**\\n        norm (str)\\n            type of norm (L1, L2) for the datanorm sparsifier. **Used for creating save directory**\\n        zip (bool)\\n            if True, the file is zip-compressed.\\n    \"\n    folder_name = os.path.join(sparsified_model_dump_path, str(norm))\n    folder_str = f'config_{sparse_block_shape}'\n    model_state = state_dict['state_dict']\n    model_state_path = os.path.join(folder_name, folder_str, save_file_name)\n    if not os.path.exists(os.path.dirname(model_state_path)):\n        os.makedirs(os.path.dirname(model_state_path))\n    torch.save(model_state, model_state_path)\n    if zip:\n        zip_path = model_state_path.replace('.ckpt', '.zip')\n        with ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zip:\n            zip.write(model_state_path, save_file_name)\n        os.remove(model_state_path)\n        model_state_path = zip_path\n    model_state_path = os.path.abspath(model_state_path)\n    file_size = os.path.getsize(model_state_path)\n    file_size = file_size >> 20\n    return (model_state_path, file_size)",
            "def save_model_states(state_dict, sparsified_model_dump_path, save_file_name, sparse_block_shape, norm, zip=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Dumps the state_dict() of the model.\\n\\n    Args:\\n        state_dict (Dict)\\n            The state_dict() as dumped by dlrm_s_pytorch.py. Only the model state will be extracted\\n            from this dictionary. This corresponds to the 'state_dict' key in the state_dict dictionary.\\n            >>> model_state = state_dict['state_dict']\\n        save_file_name (str)\\n            The filename (not path) when saving the model state dictionary\\n        sparse_block_shape (Tuple)\\n            The block shape corresponding to the data norm sparsifier. **Used for creating save directory**\\n        norm (str)\\n            type of norm (L1, L2) for the datanorm sparsifier. **Used for creating save directory**\\n        zip (bool)\\n            if True, the file is zip-compressed.\\n    \"\n    folder_name = os.path.join(sparsified_model_dump_path, str(norm))\n    folder_str = f'config_{sparse_block_shape}'\n    model_state = state_dict['state_dict']\n    model_state_path = os.path.join(folder_name, folder_str, save_file_name)\n    if not os.path.exists(os.path.dirname(model_state_path)):\n        os.makedirs(os.path.dirname(model_state_path))\n    torch.save(model_state, model_state_path)\n    if zip:\n        zip_path = model_state_path.replace('.ckpt', '.zip')\n        with ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zip:\n            zip.write(model_state_path, save_file_name)\n        os.remove(model_state_path)\n        model_state_path = zip_path\n    model_state_path = os.path.abspath(model_state_path)\n    file_size = os.path.getsize(model_state_path)\n    file_size = file_size >> 20\n    return (model_state_path, file_size)",
            "def save_model_states(state_dict, sparsified_model_dump_path, save_file_name, sparse_block_shape, norm, zip=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Dumps the state_dict() of the model.\\n\\n    Args:\\n        state_dict (Dict)\\n            The state_dict() as dumped by dlrm_s_pytorch.py. Only the model state will be extracted\\n            from this dictionary. This corresponds to the 'state_dict' key in the state_dict dictionary.\\n            >>> model_state = state_dict['state_dict']\\n        save_file_name (str)\\n            The filename (not path) when saving the model state dictionary\\n        sparse_block_shape (Tuple)\\n            The block shape corresponding to the data norm sparsifier. **Used for creating save directory**\\n        norm (str)\\n            type of norm (L1, L2) for the datanorm sparsifier. **Used for creating save directory**\\n        zip (bool)\\n            if True, the file is zip-compressed.\\n    \"\n    folder_name = os.path.join(sparsified_model_dump_path, str(norm))\n    folder_str = f'config_{sparse_block_shape}'\n    model_state = state_dict['state_dict']\n    model_state_path = os.path.join(folder_name, folder_str, save_file_name)\n    if not os.path.exists(os.path.dirname(model_state_path)):\n        os.makedirs(os.path.dirname(model_state_path))\n    torch.save(model_state, model_state_path)\n    if zip:\n        zip_path = model_state_path.replace('.ckpt', '.zip')\n        with ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zip:\n            zip.write(model_state_path, save_file_name)\n        os.remove(model_state_path)\n        model_state_path = zip_path\n    model_state_path = os.path.abspath(model_state_path)\n    file_size = os.path.getsize(model_state_path)\n    file_size = file_size >> 20\n    return (model_state_path, file_size)",
            "def save_model_states(state_dict, sparsified_model_dump_path, save_file_name, sparse_block_shape, norm, zip=True):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Dumps the state_dict() of the model.\\n\\n    Args:\\n        state_dict (Dict)\\n            The state_dict() as dumped by dlrm_s_pytorch.py. Only the model state will be extracted\\n            from this dictionary. This corresponds to the 'state_dict' key in the state_dict dictionary.\\n            >>> model_state = state_dict['state_dict']\\n        save_file_name (str)\\n            The filename (not path) when saving the model state dictionary\\n        sparse_block_shape (Tuple)\\n            The block shape corresponding to the data norm sparsifier. **Used for creating save directory**\\n        norm (str)\\n            type of norm (L1, L2) for the datanorm sparsifier. **Used for creating save directory**\\n        zip (bool)\\n            if True, the file is zip-compressed.\\n    \"\n    folder_name = os.path.join(sparsified_model_dump_path, str(norm))\n    folder_str = f'config_{sparse_block_shape}'\n    model_state = state_dict['state_dict']\n    model_state_path = os.path.join(folder_name, folder_str, save_file_name)\n    if not os.path.exists(os.path.dirname(model_state_path)):\n        os.makedirs(os.path.dirname(model_state_path))\n    torch.save(model_state, model_state_path)\n    if zip:\n        zip_path = model_state_path.replace('.ckpt', '.zip')\n        with ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zip:\n            zip.write(model_state_path, save_file_name)\n        os.remove(model_state_path)\n        model_state_path = zip_path\n    model_state_path = os.path.abspath(model_state_path)\n    file_size = os.path.getsize(model_state_path)\n    file_size = file_size >> 20\n    return (model_state_path, file_size)"
        ]
    },
    {
        "func_name": "sparsify_model",
        "original": "def sparsify_model(path_to_model, sparsified_model_dump_path):\n    \"\"\"Sparsifies the embedding layers of the dlrm model for different sparsity levels, norms and block shapes\n    using the DataNormSparsifier.\n    The function tracks the step time of the sparsifier and the size of the compressed checkpoint and collates\n    it into a csv.\n\n    Note::\n        This function dumps a csv sparse_model_metadata.csv in the current directory.\n\n    Args:\n        path_to_model (str)\n            path to the trained criteo model ckpt file\n        sparsity_levels (List of float)\n            list of sparsity levels to be sparsified on\n        norms (List of str)\n            list of norms to be sparsified on\n        sparse_block_shapes (List of tuples)\n            List of sparse block shapes to be sparsified on\n    \"\"\"\n    sparsity_levels = [sl / 10 for sl in range(0, 10)]\n    sparsity_levels += [0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0]\n    norms = ['L1', 'L2']\n    sparse_block_shapes = [(1, 1), (1, 4)]\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    print('Running for sparsity levels - ', sparsity_levels)\n    print('Running for sparse block shapes - ', sparse_block_shapes)\n    print('Running for norms - ', norms)\n    orig_model = get_dlrm_model()\n    saved_state = torch.load(path_to_model, map_location=device)\n    orig_model.load_state_dict(saved_state['state_dict'])\n    orig_model = orig_model.to(device)\n    step_time_dict = {}\n    stat_dict: Dict[str, List] = {'norm': [], 'sparse_block_shape': [], 'sparsity_level': [], 'step_time_sec': [], 'zip_file_size': [], 'path': []}\n    for norm in norms:\n        for sbs in sparse_block_shapes:\n            if norm == 'L2' and sbs == (1, 1):\n                continue\n            for sl in sparsity_levels:\n                model = copy.deepcopy(orig_model)\n                sparsifier = create_attach_sparsifier(model, sparse_block_shape=sbs, norm=norm, sparsity_level=sl)\n                t1 = time.time()\n                sparsifier.step()\n                t2 = time.time()\n                step_time = t2 - t1\n                norm_sl = f'{norm}_{sbs}_{sl}'\n                print(f'Step Time for {norm_sl}=: {step_time} s')\n                step_time_dict[norm_sl] = step_time\n                sparsifier.squash_mask()\n                saved_state['state_dict'] = model.state_dict()\n                file_name = f'criteo_model_norm={norm}_sl={sl}.ckpt'\n                (state_path, file_size) = save_model_states(saved_state, sparsified_model_dump_path, file_name, sbs, norm=norm)\n                stat_dict['norm'].append(norm)\n                stat_dict['sparse_block_shape'].append(sbs)\n                stat_dict['sparsity_level'].append(sl)\n                stat_dict['step_time_sec'].append(step_time)\n                stat_dict['zip_file_size'].append(file_size)\n                stat_dict['path'].append(state_path)\n    df = pd.DataFrame(stat_dict)\n    filename = 'sparse_model_metadata.csv'\n    df.to_csv(filename, index=False)\n    print(f'Saved sparsified metadata file in {filename}')",
        "mutated": [
            "def sparsify_model(path_to_model, sparsified_model_dump_path):\n    if False:\n        i = 10\n    'Sparsifies the embedding layers of the dlrm model for different sparsity levels, norms and block shapes\\n    using the DataNormSparsifier.\\n    The function tracks the step time of the sparsifier and the size of the compressed checkpoint and collates\\n    it into a csv.\\n\\n    Note::\\n        This function dumps a csv sparse_model_metadata.csv in the current directory.\\n\\n    Args:\\n        path_to_model (str)\\n            path to the trained criteo model ckpt file\\n        sparsity_levels (List of float)\\n            list of sparsity levels to be sparsified on\\n        norms (List of str)\\n            list of norms to be sparsified on\\n        sparse_block_shapes (List of tuples)\\n            List of sparse block shapes to be sparsified on\\n    '\n    sparsity_levels = [sl / 10 for sl in range(0, 10)]\n    sparsity_levels += [0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0]\n    norms = ['L1', 'L2']\n    sparse_block_shapes = [(1, 1), (1, 4)]\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    print('Running for sparsity levels - ', sparsity_levels)\n    print('Running for sparse block shapes - ', sparse_block_shapes)\n    print('Running for norms - ', norms)\n    orig_model = get_dlrm_model()\n    saved_state = torch.load(path_to_model, map_location=device)\n    orig_model.load_state_dict(saved_state['state_dict'])\n    orig_model = orig_model.to(device)\n    step_time_dict = {}\n    stat_dict: Dict[str, List] = {'norm': [], 'sparse_block_shape': [], 'sparsity_level': [], 'step_time_sec': [], 'zip_file_size': [], 'path': []}\n    for norm in norms:\n        for sbs in sparse_block_shapes:\n            if norm == 'L2' and sbs == (1, 1):\n                continue\n            for sl in sparsity_levels:\n                model = copy.deepcopy(orig_model)\n                sparsifier = create_attach_sparsifier(model, sparse_block_shape=sbs, norm=norm, sparsity_level=sl)\n                t1 = time.time()\n                sparsifier.step()\n                t2 = time.time()\n                step_time = t2 - t1\n                norm_sl = f'{norm}_{sbs}_{sl}'\n                print(f'Step Time for {norm_sl}=: {step_time} s')\n                step_time_dict[norm_sl] = step_time\n                sparsifier.squash_mask()\n                saved_state['state_dict'] = model.state_dict()\n                file_name = f'criteo_model_norm={norm}_sl={sl}.ckpt'\n                (state_path, file_size) = save_model_states(saved_state, sparsified_model_dump_path, file_name, sbs, norm=norm)\n                stat_dict['norm'].append(norm)\n                stat_dict['sparse_block_shape'].append(sbs)\n                stat_dict['sparsity_level'].append(sl)\n                stat_dict['step_time_sec'].append(step_time)\n                stat_dict['zip_file_size'].append(file_size)\n                stat_dict['path'].append(state_path)\n    df = pd.DataFrame(stat_dict)\n    filename = 'sparse_model_metadata.csv'\n    df.to_csv(filename, index=False)\n    print(f'Saved sparsified metadata file in {filename}')",
            "def sparsify_model(path_to_model, sparsified_model_dump_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    'Sparsifies the embedding layers of the dlrm model for different sparsity levels, norms and block shapes\\n    using the DataNormSparsifier.\\n    The function tracks the step time of the sparsifier and the size of the compressed checkpoint and collates\\n    it into a csv.\\n\\n    Note::\\n        This function dumps a csv sparse_model_metadata.csv in the current directory.\\n\\n    Args:\\n        path_to_model (str)\\n            path to the trained criteo model ckpt file\\n        sparsity_levels (List of float)\\n            list of sparsity levels to be sparsified on\\n        norms (List of str)\\n            list of norms to be sparsified on\\n        sparse_block_shapes (List of tuples)\\n            List of sparse block shapes to be sparsified on\\n    '\n    sparsity_levels = [sl / 10 for sl in range(0, 10)]\n    sparsity_levels += [0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0]\n    norms = ['L1', 'L2']\n    sparse_block_shapes = [(1, 1), (1, 4)]\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    print('Running for sparsity levels - ', sparsity_levels)\n    print('Running for sparse block shapes - ', sparse_block_shapes)\n    print('Running for norms - ', norms)\n    orig_model = get_dlrm_model()\n    saved_state = torch.load(path_to_model, map_location=device)\n    orig_model.load_state_dict(saved_state['state_dict'])\n    orig_model = orig_model.to(device)\n    step_time_dict = {}\n    stat_dict: Dict[str, List] = {'norm': [], 'sparse_block_shape': [], 'sparsity_level': [], 'step_time_sec': [], 'zip_file_size': [], 'path': []}\n    for norm in norms:\n        for sbs in sparse_block_shapes:\n            if norm == 'L2' and sbs == (1, 1):\n                continue\n            for sl in sparsity_levels:\n                model = copy.deepcopy(orig_model)\n                sparsifier = create_attach_sparsifier(model, sparse_block_shape=sbs, norm=norm, sparsity_level=sl)\n                t1 = time.time()\n                sparsifier.step()\n                t2 = time.time()\n                step_time = t2 - t1\n                norm_sl = f'{norm}_{sbs}_{sl}'\n                print(f'Step Time for {norm_sl}=: {step_time} s')\n                step_time_dict[norm_sl] = step_time\n                sparsifier.squash_mask()\n                saved_state['state_dict'] = model.state_dict()\n                file_name = f'criteo_model_norm={norm}_sl={sl}.ckpt'\n                (state_path, file_size) = save_model_states(saved_state, sparsified_model_dump_path, file_name, sbs, norm=norm)\n                stat_dict['norm'].append(norm)\n                stat_dict['sparse_block_shape'].append(sbs)\n                stat_dict['sparsity_level'].append(sl)\n                stat_dict['step_time_sec'].append(step_time)\n                stat_dict['zip_file_size'].append(file_size)\n                stat_dict['path'].append(state_path)\n    df = pd.DataFrame(stat_dict)\n    filename = 'sparse_model_metadata.csv'\n    df.to_csv(filename, index=False)\n    print(f'Saved sparsified metadata file in {filename}')",
            "def sparsify_model(path_to_model, sparsified_model_dump_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    'Sparsifies the embedding layers of the dlrm model for different sparsity levels, norms and block shapes\\n    using the DataNormSparsifier.\\n    The function tracks the step time of the sparsifier and the size of the compressed checkpoint and collates\\n    it into a csv.\\n\\n    Note::\\n        This function dumps a csv sparse_model_metadata.csv in the current directory.\\n\\n    Args:\\n        path_to_model (str)\\n            path to the trained criteo model ckpt file\\n        sparsity_levels (List of float)\\n            list of sparsity levels to be sparsified on\\n        norms (List of str)\\n            list of norms to be sparsified on\\n        sparse_block_shapes (List of tuples)\\n            List of sparse block shapes to be sparsified on\\n    '\n    sparsity_levels = [sl / 10 for sl in range(0, 10)]\n    sparsity_levels += [0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0]\n    norms = ['L1', 'L2']\n    sparse_block_shapes = [(1, 1), (1, 4)]\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    print('Running for sparsity levels - ', sparsity_levels)\n    print('Running for sparse block shapes - ', sparse_block_shapes)\n    print('Running for norms - ', norms)\n    orig_model = get_dlrm_model()\n    saved_state = torch.load(path_to_model, map_location=device)\n    orig_model.load_state_dict(saved_state['state_dict'])\n    orig_model = orig_model.to(device)\n    step_time_dict = {}\n    stat_dict: Dict[str, List] = {'norm': [], 'sparse_block_shape': [], 'sparsity_level': [], 'step_time_sec': [], 'zip_file_size': [], 'path': []}\n    for norm in norms:\n        for sbs in sparse_block_shapes:\n            if norm == 'L2' and sbs == (1, 1):\n                continue\n            for sl in sparsity_levels:\n                model = copy.deepcopy(orig_model)\n                sparsifier = create_attach_sparsifier(model, sparse_block_shape=sbs, norm=norm, sparsity_level=sl)\n                t1 = time.time()\n                sparsifier.step()\n                t2 = time.time()\n                step_time = t2 - t1\n                norm_sl = f'{norm}_{sbs}_{sl}'\n                print(f'Step Time for {norm_sl}=: {step_time} s')\n                step_time_dict[norm_sl] = step_time\n                sparsifier.squash_mask()\n                saved_state['state_dict'] = model.state_dict()\n                file_name = f'criteo_model_norm={norm}_sl={sl}.ckpt'\n                (state_path, file_size) = save_model_states(saved_state, sparsified_model_dump_path, file_name, sbs, norm=norm)\n                stat_dict['norm'].append(norm)\n                stat_dict['sparse_block_shape'].append(sbs)\n                stat_dict['sparsity_level'].append(sl)\n                stat_dict['step_time_sec'].append(step_time)\n                stat_dict['zip_file_size'].append(file_size)\n                stat_dict['path'].append(state_path)\n    df = pd.DataFrame(stat_dict)\n    filename = 'sparse_model_metadata.csv'\n    df.to_csv(filename, index=False)\n    print(f'Saved sparsified metadata file in {filename}')",
            "def sparsify_model(path_to_model, sparsified_model_dump_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    'Sparsifies the embedding layers of the dlrm model for different sparsity levels, norms and block shapes\\n    using the DataNormSparsifier.\\n    The function tracks the step time of the sparsifier and the size of the compressed checkpoint and collates\\n    it into a csv.\\n\\n    Note::\\n        This function dumps a csv sparse_model_metadata.csv in the current directory.\\n\\n    Args:\\n        path_to_model (str)\\n            path to the trained criteo model ckpt file\\n        sparsity_levels (List of float)\\n            list of sparsity levels to be sparsified on\\n        norms (List of str)\\n            list of norms to be sparsified on\\n        sparse_block_shapes (List of tuples)\\n            List of sparse block shapes to be sparsified on\\n    '\n    sparsity_levels = [sl / 10 for sl in range(0, 10)]\n    sparsity_levels += [0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0]\n    norms = ['L1', 'L2']\n    sparse_block_shapes = [(1, 1), (1, 4)]\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    print('Running for sparsity levels - ', sparsity_levels)\n    print('Running for sparse block shapes - ', sparse_block_shapes)\n    print('Running for norms - ', norms)\n    orig_model = get_dlrm_model()\n    saved_state = torch.load(path_to_model, map_location=device)\n    orig_model.load_state_dict(saved_state['state_dict'])\n    orig_model = orig_model.to(device)\n    step_time_dict = {}\n    stat_dict: Dict[str, List] = {'norm': [], 'sparse_block_shape': [], 'sparsity_level': [], 'step_time_sec': [], 'zip_file_size': [], 'path': []}\n    for norm in norms:\n        for sbs in sparse_block_shapes:\n            if norm == 'L2' and sbs == (1, 1):\n                continue\n            for sl in sparsity_levels:\n                model = copy.deepcopy(orig_model)\n                sparsifier = create_attach_sparsifier(model, sparse_block_shape=sbs, norm=norm, sparsity_level=sl)\n                t1 = time.time()\n                sparsifier.step()\n                t2 = time.time()\n                step_time = t2 - t1\n                norm_sl = f'{norm}_{sbs}_{sl}'\n                print(f'Step Time for {norm_sl}=: {step_time} s')\n                step_time_dict[norm_sl] = step_time\n                sparsifier.squash_mask()\n                saved_state['state_dict'] = model.state_dict()\n                file_name = f'criteo_model_norm={norm}_sl={sl}.ckpt'\n                (state_path, file_size) = save_model_states(saved_state, sparsified_model_dump_path, file_name, sbs, norm=norm)\n                stat_dict['norm'].append(norm)\n                stat_dict['sparse_block_shape'].append(sbs)\n                stat_dict['sparsity_level'].append(sl)\n                stat_dict['step_time_sec'].append(step_time)\n                stat_dict['zip_file_size'].append(file_size)\n                stat_dict['path'].append(state_path)\n    df = pd.DataFrame(stat_dict)\n    filename = 'sparse_model_metadata.csv'\n    df.to_csv(filename, index=False)\n    print(f'Saved sparsified metadata file in {filename}')",
            "def sparsify_model(path_to_model, sparsified_model_dump_path):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    'Sparsifies the embedding layers of the dlrm model for different sparsity levels, norms and block shapes\\n    using the DataNormSparsifier.\\n    The function tracks the step time of the sparsifier and the size of the compressed checkpoint and collates\\n    it into a csv.\\n\\n    Note::\\n        This function dumps a csv sparse_model_metadata.csv in the current directory.\\n\\n    Args:\\n        path_to_model (str)\\n            path to the trained criteo model ckpt file\\n        sparsity_levels (List of float)\\n            list of sparsity levels to be sparsified on\\n        norms (List of str)\\n            list of norms to be sparsified on\\n        sparse_block_shapes (List of tuples)\\n            List of sparse block shapes to be sparsified on\\n    '\n    sparsity_levels = [sl / 10 for sl in range(0, 10)]\n    sparsity_levels += [0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0]\n    norms = ['L1', 'L2']\n    sparse_block_shapes = [(1, 1), (1, 4)]\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    print('Running for sparsity levels - ', sparsity_levels)\n    print('Running for sparse block shapes - ', sparse_block_shapes)\n    print('Running for norms - ', norms)\n    orig_model = get_dlrm_model()\n    saved_state = torch.load(path_to_model, map_location=device)\n    orig_model.load_state_dict(saved_state['state_dict'])\n    orig_model = orig_model.to(device)\n    step_time_dict = {}\n    stat_dict: Dict[str, List] = {'norm': [], 'sparse_block_shape': [], 'sparsity_level': [], 'step_time_sec': [], 'zip_file_size': [], 'path': []}\n    for norm in norms:\n        for sbs in sparse_block_shapes:\n            if norm == 'L2' and sbs == (1, 1):\n                continue\n            for sl in sparsity_levels:\n                model = copy.deepcopy(orig_model)\n                sparsifier = create_attach_sparsifier(model, sparse_block_shape=sbs, norm=norm, sparsity_level=sl)\n                t1 = time.time()\n                sparsifier.step()\n                t2 = time.time()\n                step_time = t2 - t1\n                norm_sl = f'{norm}_{sbs}_{sl}'\n                print(f'Step Time for {norm_sl}=: {step_time} s')\n                step_time_dict[norm_sl] = step_time\n                sparsifier.squash_mask()\n                saved_state['state_dict'] = model.state_dict()\n                file_name = f'criteo_model_norm={norm}_sl={sl}.ckpt'\n                (state_path, file_size) = save_model_states(saved_state, sparsified_model_dump_path, file_name, sbs, norm=norm)\n                stat_dict['norm'].append(norm)\n                stat_dict['sparse_block_shape'].append(sbs)\n                stat_dict['sparsity_level'].append(sl)\n                stat_dict['step_time_sec'].append(step_time)\n                stat_dict['zip_file_size'].append(file_size)\n                stat_dict['path'].append(state_path)\n    df = pd.DataFrame(stat_dict)\n    filename = 'sparse_model_metadata.csv'\n    df.to_csv(filename, index=False)\n    print(f'Saved sparsified metadata file in {filename}')"
        ]
    }
]