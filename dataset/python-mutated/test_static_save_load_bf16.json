[
    {
        "func_name": "setUp",
        "original": "def setUp(self):\n    self.temp_dir = tempfile.TemporaryDirectory()",
        "mutated": [
            "def setUp(self):\n    if False:\n        i = 10\n    self.temp_dir = tempfile.TemporaryDirectory()",
            "def setUp(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.temp_dir = tempfile.TemporaryDirectory()",
            "def setUp(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.temp_dir = tempfile.TemporaryDirectory()",
            "def setUp(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.temp_dir = tempfile.TemporaryDirectory()",
            "def setUp(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.temp_dir = tempfile.TemporaryDirectory()"
        ]
    },
    {
        "func_name": "tearDown",
        "original": "def tearDown(self):\n    self.temp_dir.cleanup()",
        "mutated": [
            "def tearDown(self):\n    if False:\n        i = 10\n    self.temp_dir.cleanup()",
            "def tearDown(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    self.temp_dir.cleanup()",
            "def tearDown(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    self.temp_dir.cleanup()",
            "def tearDown(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    self.temp_dir.cleanup()",
            "def tearDown(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    self.temp_dir.cleanup()"
        ]
    },
    {
        "func_name": "set_place",
        "original": "def set_place(self):\n    return base.CPUPlace()",
        "mutated": [
            "def set_place(self):\n    if False:\n        i = 10\n    return base.CPUPlace()",
            "def set_place(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    return base.CPUPlace()",
            "def set_place(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    return base.CPUPlace()",
            "def set_place(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    return base.CPUPlace()",
            "def set_place(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    return base.CPUPlace()"
        ]
    },
    {
        "func_name": "test_ptb_rnn_cpu_bfloat16",
        "original": "def test_ptb_rnn_cpu_bfloat16(self):\n    seed = 90\n    hidden_size = 10\n    vocab_size = 500\n    num_layers = 1\n    num_steps = 3\n    init_scale = 0.1\n    batch_size = 4\n    batch_num = 100\n    with new_program_scope():\n        base.default_startup_program().random_seed = seed\n        base.default_main_program().random_seed = seed\n        ptb_model = PtbModel('ptb_model', hidden_size=hidden_size, vocab_size=vocab_size, num_layers=num_layers, num_steps=num_steps, init_scale=init_scale)\n        place = self.set_place()\n        exe = base.Executor(place)\n        sgd = paddle.optimizer.SGD(learning_rate=0.001)\n        x = paddle.static.data(name='x', shape=[-1, num_steps], dtype='int64')\n        x.desc.set_need_check_feed(False)\n        y = paddle.static.data(name='y', shape=[-1, 1], dtype='float32')\n        y.desc.set_need_check_feed(False)\n        init_hidden = paddle.static.data(name='init_hidden', shape=[-1, 1], dtype='float32')\n        init_hidden.desc.set_need_check_feed(False)\n        init_cell = paddle.static.data(name='init_cell', shape=[-1, 1], dtype='float32')\n        init_cell.desc.set_need_check_feed(False)\n        (static_loss, static_last_hidden, static_last_cell) = ptb_model(x, y, init_hidden, init_cell)\n        sgd = paddle.static.amp.bf16.decorate_bf16(sgd, amp_lists=paddle.static.amp.bf16.AutoMixedPrecisionListsBF16(custom_fp32_list={'transpose2', 'concat'}), use_bf16_guard=False, use_pure_bf16=True)\n        sgd.minimize(static_loss, framework.default_startup_program())\n        out = exe.run(framework.default_startup_program())\n        for i in range(batch_num):\n            x_data = np.arange(12).reshape(4, 3).astype('int64')\n            y_data = np.arange(1, 13).reshape(4, 3).astype('int64')\n            x_data = x_data.reshape((-1, num_steps, 1))\n            y_data = y_data.reshape((-1, 1))\n            init_hidden_data = np.zeros((num_layers, batch_size, hidden_size), dtype='uint16')\n            init_cell_data = np.zeros((num_layers, batch_size, hidden_size), dtype='uint16')\n            fetch_list = [static_loss, static_last_hidden, static_last_cell]\n            out = exe.run(base.default_main_program(), feed={'x': x_data, 'y': y_data, 'init_hidden': init_hidden_data, 'init_cell': init_cell_data}, fetch_list=fetch_list)\n        main_program = framework.default_main_program()\n        base_map = {}\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                self.assertTrue(np.sum(np.abs(t)) != 0)\n                base_map[var.name] = t\n        save_dir = os.path.join(self.temp_dir.name, 'test_1')\n        paddle.static.save(main_program, save_dir)\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                ten = base.global_scope().find_var(var.name).get_tensor()\n                ten.set(np.zeros_like(np.array(ten)), place)\n                new_t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                self.assertTrue(np.sum(np.abs(new_t)) == 0)\n        paddle.static.load(main_program, os.path.join(self.temp_dir.name, 'test_1.pdparams'), exe)\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                new_t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                base_t = base_map[var.name]\n                np.testing.assert_array_equal(new_t, base_t)",
        "mutated": [
            "def test_ptb_rnn_cpu_bfloat16(self):\n    if False:\n        i = 10\n    seed = 90\n    hidden_size = 10\n    vocab_size = 500\n    num_layers = 1\n    num_steps = 3\n    init_scale = 0.1\n    batch_size = 4\n    batch_num = 100\n    with new_program_scope():\n        base.default_startup_program().random_seed = seed\n        base.default_main_program().random_seed = seed\n        ptb_model = PtbModel('ptb_model', hidden_size=hidden_size, vocab_size=vocab_size, num_layers=num_layers, num_steps=num_steps, init_scale=init_scale)\n        place = self.set_place()\n        exe = base.Executor(place)\n        sgd = paddle.optimizer.SGD(learning_rate=0.001)\n        x = paddle.static.data(name='x', shape=[-1, num_steps], dtype='int64')\n        x.desc.set_need_check_feed(False)\n        y = paddle.static.data(name='y', shape=[-1, 1], dtype='float32')\n        y.desc.set_need_check_feed(False)\n        init_hidden = paddle.static.data(name='init_hidden', shape=[-1, 1], dtype='float32')\n        init_hidden.desc.set_need_check_feed(False)\n        init_cell = paddle.static.data(name='init_cell', shape=[-1, 1], dtype='float32')\n        init_cell.desc.set_need_check_feed(False)\n        (static_loss, static_last_hidden, static_last_cell) = ptb_model(x, y, init_hidden, init_cell)\n        sgd = paddle.static.amp.bf16.decorate_bf16(sgd, amp_lists=paddle.static.amp.bf16.AutoMixedPrecisionListsBF16(custom_fp32_list={'transpose2', 'concat'}), use_bf16_guard=False, use_pure_bf16=True)\n        sgd.minimize(static_loss, framework.default_startup_program())\n        out = exe.run(framework.default_startup_program())\n        for i in range(batch_num):\n            x_data = np.arange(12).reshape(4, 3).astype('int64')\n            y_data = np.arange(1, 13).reshape(4, 3).astype('int64')\n            x_data = x_data.reshape((-1, num_steps, 1))\n            y_data = y_data.reshape((-1, 1))\n            init_hidden_data = np.zeros((num_layers, batch_size, hidden_size), dtype='uint16')\n            init_cell_data = np.zeros((num_layers, batch_size, hidden_size), dtype='uint16')\n            fetch_list = [static_loss, static_last_hidden, static_last_cell]\n            out = exe.run(base.default_main_program(), feed={'x': x_data, 'y': y_data, 'init_hidden': init_hidden_data, 'init_cell': init_cell_data}, fetch_list=fetch_list)\n        main_program = framework.default_main_program()\n        base_map = {}\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                self.assertTrue(np.sum(np.abs(t)) != 0)\n                base_map[var.name] = t\n        save_dir = os.path.join(self.temp_dir.name, 'test_1')\n        paddle.static.save(main_program, save_dir)\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                ten = base.global_scope().find_var(var.name).get_tensor()\n                ten.set(np.zeros_like(np.array(ten)), place)\n                new_t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                self.assertTrue(np.sum(np.abs(new_t)) == 0)\n        paddle.static.load(main_program, os.path.join(self.temp_dir.name, 'test_1.pdparams'), exe)\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                new_t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                base_t = base_map[var.name]\n                np.testing.assert_array_equal(new_t, base_t)",
            "def test_ptb_rnn_cpu_bfloat16(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    seed = 90\n    hidden_size = 10\n    vocab_size = 500\n    num_layers = 1\n    num_steps = 3\n    init_scale = 0.1\n    batch_size = 4\n    batch_num = 100\n    with new_program_scope():\n        base.default_startup_program().random_seed = seed\n        base.default_main_program().random_seed = seed\n        ptb_model = PtbModel('ptb_model', hidden_size=hidden_size, vocab_size=vocab_size, num_layers=num_layers, num_steps=num_steps, init_scale=init_scale)\n        place = self.set_place()\n        exe = base.Executor(place)\n        sgd = paddle.optimizer.SGD(learning_rate=0.001)\n        x = paddle.static.data(name='x', shape=[-1, num_steps], dtype='int64')\n        x.desc.set_need_check_feed(False)\n        y = paddle.static.data(name='y', shape=[-1, 1], dtype='float32')\n        y.desc.set_need_check_feed(False)\n        init_hidden = paddle.static.data(name='init_hidden', shape=[-1, 1], dtype='float32')\n        init_hidden.desc.set_need_check_feed(False)\n        init_cell = paddle.static.data(name='init_cell', shape=[-1, 1], dtype='float32')\n        init_cell.desc.set_need_check_feed(False)\n        (static_loss, static_last_hidden, static_last_cell) = ptb_model(x, y, init_hidden, init_cell)\n        sgd = paddle.static.amp.bf16.decorate_bf16(sgd, amp_lists=paddle.static.amp.bf16.AutoMixedPrecisionListsBF16(custom_fp32_list={'transpose2', 'concat'}), use_bf16_guard=False, use_pure_bf16=True)\n        sgd.minimize(static_loss, framework.default_startup_program())\n        out = exe.run(framework.default_startup_program())\n        for i in range(batch_num):\n            x_data = np.arange(12).reshape(4, 3).astype('int64')\n            y_data = np.arange(1, 13).reshape(4, 3).astype('int64')\n            x_data = x_data.reshape((-1, num_steps, 1))\n            y_data = y_data.reshape((-1, 1))\n            init_hidden_data = np.zeros((num_layers, batch_size, hidden_size), dtype='uint16')\n            init_cell_data = np.zeros((num_layers, batch_size, hidden_size), dtype='uint16')\n            fetch_list = [static_loss, static_last_hidden, static_last_cell]\n            out = exe.run(base.default_main_program(), feed={'x': x_data, 'y': y_data, 'init_hidden': init_hidden_data, 'init_cell': init_cell_data}, fetch_list=fetch_list)\n        main_program = framework.default_main_program()\n        base_map = {}\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                self.assertTrue(np.sum(np.abs(t)) != 0)\n                base_map[var.name] = t\n        save_dir = os.path.join(self.temp_dir.name, 'test_1')\n        paddle.static.save(main_program, save_dir)\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                ten = base.global_scope().find_var(var.name).get_tensor()\n                ten.set(np.zeros_like(np.array(ten)), place)\n                new_t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                self.assertTrue(np.sum(np.abs(new_t)) == 0)\n        paddle.static.load(main_program, os.path.join(self.temp_dir.name, 'test_1.pdparams'), exe)\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                new_t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                base_t = base_map[var.name]\n                np.testing.assert_array_equal(new_t, base_t)",
            "def test_ptb_rnn_cpu_bfloat16(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    seed = 90\n    hidden_size = 10\n    vocab_size = 500\n    num_layers = 1\n    num_steps = 3\n    init_scale = 0.1\n    batch_size = 4\n    batch_num = 100\n    with new_program_scope():\n        base.default_startup_program().random_seed = seed\n        base.default_main_program().random_seed = seed\n        ptb_model = PtbModel('ptb_model', hidden_size=hidden_size, vocab_size=vocab_size, num_layers=num_layers, num_steps=num_steps, init_scale=init_scale)\n        place = self.set_place()\n        exe = base.Executor(place)\n        sgd = paddle.optimizer.SGD(learning_rate=0.001)\n        x = paddle.static.data(name='x', shape=[-1, num_steps], dtype='int64')\n        x.desc.set_need_check_feed(False)\n        y = paddle.static.data(name='y', shape=[-1, 1], dtype='float32')\n        y.desc.set_need_check_feed(False)\n        init_hidden = paddle.static.data(name='init_hidden', shape=[-1, 1], dtype='float32')\n        init_hidden.desc.set_need_check_feed(False)\n        init_cell = paddle.static.data(name='init_cell', shape=[-1, 1], dtype='float32')\n        init_cell.desc.set_need_check_feed(False)\n        (static_loss, static_last_hidden, static_last_cell) = ptb_model(x, y, init_hidden, init_cell)\n        sgd = paddle.static.amp.bf16.decorate_bf16(sgd, amp_lists=paddle.static.amp.bf16.AutoMixedPrecisionListsBF16(custom_fp32_list={'transpose2', 'concat'}), use_bf16_guard=False, use_pure_bf16=True)\n        sgd.minimize(static_loss, framework.default_startup_program())\n        out = exe.run(framework.default_startup_program())\n        for i in range(batch_num):\n            x_data = np.arange(12).reshape(4, 3).astype('int64')\n            y_data = np.arange(1, 13).reshape(4, 3).astype('int64')\n            x_data = x_data.reshape((-1, num_steps, 1))\n            y_data = y_data.reshape((-1, 1))\n            init_hidden_data = np.zeros((num_layers, batch_size, hidden_size), dtype='uint16')\n            init_cell_data = np.zeros((num_layers, batch_size, hidden_size), dtype='uint16')\n            fetch_list = [static_loss, static_last_hidden, static_last_cell]\n            out = exe.run(base.default_main_program(), feed={'x': x_data, 'y': y_data, 'init_hidden': init_hidden_data, 'init_cell': init_cell_data}, fetch_list=fetch_list)\n        main_program = framework.default_main_program()\n        base_map = {}\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                self.assertTrue(np.sum(np.abs(t)) != 0)\n                base_map[var.name] = t\n        save_dir = os.path.join(self.temp_dir.name, 'test_1')\n        paddle.static.save(main_program, save_dir)\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                ten = base.global_scope().find_var(var.name).get_tensor()\n                ten.set(np.zeros_like(np.array(ten)), place)\n                new_t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                self.assertTrue(np.sum(np.abs(new_t)) == 0)\n        paddle.static.load(main_program, os.path.join(self.temp_dir.name, 'test_1.pdparams'), exe)\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                new_t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                base_t = base_map[var.name]\n                np.testing.assert_array_equal(new_t, base_t)",
            "def test_ptb_rnn_cpu_bfloat16(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    seed = 90\n    hidden_size = 10\n    vocab_size = 500\n    num_layers = 1\n    num_steps = 3\n    init_scale = 0.1\n    batch_size = 4\n    batch_num = 100\n    with new_program_scope():\n        base.default_startup_program().random_seed = seed\n        base.default_main_program().random_seed = seed\n        ptb_model = PtbModel('ptb_model', hidden_size=hidden_size, vocab_size=vocab_size, num_layers=num_layers, num_steps=num_steps, init_scale=init_scale)\n        place = self.set_place()\n        exe = base.Executor(place)\n        sgd = paddle.optimizer.SGD(learning_rate=0.001)\n        x = paddle.static.data(name='x', shape=[-1, num_steps], dtype='int64')\n        x.desc.set_need_check_feed(False)\n        y = paddle.static.data(name='y', shape=[-1, 1], dtype='float32')\n        y.desc.set_need_check_feed(False)\n        init_hidden = paddle.static.data(name='init_hidden', shape=[-1, 1], dtype='float32')\n        init_hidden.desc.set_need_check_feed(False)\n        init_cell = paddle.static.data(name='init_cell', shape=[-1, 1], dtype='float32')\n        init_cell.desc.set_need_check_feed(False)\n        (static_loss, static_last_hidden, static_last_cell) = ptb_model(x, y, init_hidden, init_cell)\n        sgd = paddle.static.amp.bf16.decorate_bf16(sgd, amp_lists=paddle.static.amp.bf16.AutoMixedPrecisionListsBF16(custom_fp32_list={'transpose2', 'concat'}), use_bf16_guard=False, use_pure_bf16=True)\n        sgd.minimize(static_loss, framework.default_startup_program())\n        out = exe.run(framework.default_startup_program())\n        for i in range(batch_num):\n            x_data = np.arange(12).reshape(4, 3).astype('int64')\n            y_data = np.arange(1, 13).reshape(4, 3).astype('int64')\n            x_data = x_data.reshape((-1, num_steps, 1))\n            y_data = y_data.reshape((-1, 1))\n            init_hidden_data = np.zeros((num_layers, batch_size, hidden_size), dtype='uint16')\n            init_cell_data = np.zeros((num_layers, batch_size, hidden_size), dtype='uint16')\n            fetch_list = [static_loss, static_last_hidden, static_last_cell]\n            out = exe.run(base.default_main_program(), feed={'x': x_data, 'y': y_data, 'init_hidden': init_hidden_data, 'init_cell': init_cell_data}, fetch_list=fetch_list)\n        main_program = framework.default_main_program()\n        base_map = {}\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                self.assertTrue(np.sum(np.abs(t)) != 0)\n                base_map[var.name] = t\n        save_dir = os.path.join(self.temp_dir.name, 'test_1')\n        paddle.static.save(main_program, save_dir)\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                ten = base.global_scope().find_var(var.name).get_tensor()\n                ten.set(np.zeros_like(np.array(ten)), place)\n                new_t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                self.assertTrue(np.sum(np.abs(new_t)) == 0)\n        paddle.static.load(main_program, os.path.join(self.temp_dir.name, 'test_1.pdparams'), exe)\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                new_t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                base_t = base_map[var.name]\n                np.testing.assert_array_equal(new_t, base_t)",
            "def test_ptb_rnn_cpu_bfloat16(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    seed = 90\n    hidden_size = 10\n    vocab_size = 500\n    num_layers = 1\n    num_steps = 3\n    init_scale = 0.1\n    batch_size = 4\n    batch_num = 100\n    with new_program_scope():\n        base.default_startup_program().random_seed = seed\n        base.default_main_program().random_seed = seed\n        ptb_model = PtbModel('ptb_model', hidden_size=hidden_size, vocab_size=vocab_size, num_layers=num_layers, num_steps=num_steps, init_scale=init_scale)\n        place = self.set_place()\n        exe = base.Executor(place)\n        sgd = paddle.optimizer.SGD(learning_rate=0.001)\n        x = paddle.static.data(name='x', shape=[-1, num_steps], dtype='int64')\n        x.desc.set_need_check_feed(False)\n        y = paddle.static.data(name='y', shape=[-1, 1], dtype='float32')\n        y.desc.set_need_check_feed(False)\n        init_hidden = paddle.static.data(name='init_hidden', shape=[-1, 1], dtype='float32')\n        init_hidden.desc.set_need_check_feed(False)\n        init_cell = paddle.static.data(name='init_cell', shape=[-1, 1], dtype='float32')\n        init_cell.desc.set_need_check_feed(False)\n        (static_loss, static_last_hidden, static_last_cell) = ptb_model(x, y, init_hidden, init_cell)\n        sgd = paddle.static.amp.bf16.decorate_bf16(sgd, amp_lists=paddle.static.amp.bf16.AutoMixedPrecisionListsBF16(custom_fp32_list={'transpose2', 'concat'}), use_bf16_guard=False, use_pure_bf16=True)\n        sgd.minimize(static_loss, framework.default_startup_program())\n        out = exe.run(framework.default_startup_program())\n        for i in range(batch_num):\n            x_data = np.arange(12).reshape(4, 3).astype('int64')\n            y_data = np.arange(1, 13).reshape(4, 3).astype('int64')\n            x_data = x_data.reshape((-1, num_steps, 1))\n            y_data = y_data.reshape((-1, 1))\n            init_hidden_data = np.zeros((num_layers, batch_size, hidden_size), dtype='uint16')\n            init_cell_data = np.zeros((num_layers, batch_size, hidden_size), dtype='uint16')\n            fetch_list = [static_loss, static_last_hidden, static_last_cell]\n            out = exe.run(base.default_main_program(), feed={'x': x_data, 'y': y_data, 'init_hidden': init_hidden_data, 'init_cell': init_cell_data}, fetch_list=fetch_list)\n        main_program = framework.default_main_program()\n        base_map = {}\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                self.assertTrue(np.sum(np.abs(t)) != 0)\n                base_map[var.name] = t\n        save_dir = os.path.join(self.temp_dir.name, 'test_1')\n        paddle.static.save(main_program, save_dir)\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                ten = base.global_scope().find_var(var.name).get_tensor()\n                ten.set(np.zeros_like(np.array(ten)), place)\n                new_t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                self.assertTrue(np.sum(np.abs(new_t)) == 0)\n        paddle.static.load(main_program, os.path.join(self.temp_dir.name, 'test_1.pdparams'), exe)\n        for var in main_program.list_vars():\n            if isinstance(var, framework.Parameter) or var.persistable:\n                new_t = np.array(base.global_scope().find_var(var.name).get_tensor())\n                base_t = base_map[var.name]\n                np.testing.assert_array_equal(new_t, base_t)"
        ]
    }
]