[
    {
        "func_name": "process_name",
        "original": "def process_name(name):\n    if not re.match('^[+-]?\\\\d*\\\\.\\\\d*', name):\n        name = name.replace('.', '/')\n    return name.encode(encoding='utf-8')",
        "mutated": [
            "def process_name(name):\n    if False:\n        i = 10\n    if not re.match('^[+-]?\\\\d*\\\\.\\\\d*', name):\n        name = name.replace('.', '/')\n    return name.encode(encoding='utf-8')",
            "def process_name(name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    if not re.match('^[+-]?\\\\d*\\\\.\\\\d*', name):\n        name = name.replace('.', '/')\n    return name.encode(encoding='utf-8')",
            "def process_name(name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    if not re.match('^[+-]?\\\\d*\\\\.\\\\d*', name):\n        name = name.replace('.', '/')\n    return name.encode(encoding='utf-8')",
            "def process_name(name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    if not re.match('^[+-]?\\\\d*\\\\.\\\\d*', name):\n        name = name.replace('.', '/')\n    return name.encode(encoding='utf-8')",
            "def process_name(name):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    if not re.match('^[+-]?\\\\d*\\\\.\\\\d*', name):\n        name = name.replace('.', '/')\n    return name.encode(encoding='utf-8')"
        ]
    },
    {
        "func_name": "visualize",
        "original": "def visualize(model_path: str, log_path: str, input: np.ndarray=None, inp_dict: dict=None, cal_params: bool=True, cal_flops: bool=True, cal_activations: bool=True, logging_to_stdout: bool=True, bar_length_max: int=20):\n    \"\"\"Load megengine dumped model and visualize graph structure with tensorboard log files.\n    Can also record and print model's statistics like :func:`~.module_stats`\n\n    Args:\n      model_path: dir path for megengine dumped model.\n      log_path: dir path for tensorboard graph log.\n      input: user defined input data for running model and calculating stats,\n        alternative with inp_dict, used when the model has only one input.\n      inp_dict: input dict for running model and calculating stats, alternative with\n        input, used when the model has more than one input.\n        When both input and inp_dict are None, a random input will be used.\n      cal_params: whether calculate and record params size.\n      cal_flops: whether calculate and record op flops.\n      cal_activations: whether calculate and record op activations.\n      logging_to_stdout: whether print all calculated statistic details.\n      bar_length_max: size of bar indicating max flops or parameter size in net stats.\n      model_path: str:\n      log_path: str:\n      input: np.ndarray:\n      inp_dict: dict:\n      cal_params: bool:\n      cal_flops: bool:\n      cal_activations: bool:\n      logging_to_stdout: bool:\n      bar_length_max: int:\n    \"\"\"\n    if log_path:\n        try:\n            from tensorboard.compat.proto.attr_value_pb2 import AttrValue\n            from tensorboard.compat.proto.config_pb2 import RunMetadata\n            from tensorboard.compat.proto.graph_pb2 import GraphDef\n            from tensorboard.compat.proto.node_def_pb2 import NodeDef\n            from tensorboard.compat.proto.step_stats_pb2 import AllocatorMemoryUsed, DeviceStepStats, NodeExecStats, StepStats\n            from tensorboard.compat.proto.tensor_shape_pb2 import TensorShapeProto\n            from tensorboard.compat.proto.versions_pb2 import VersionDef\n            from tensorboardX import SummaryWriter\n        except ImportError:\n            logger.error('TensorBoard and TensorboardX are required for visualize.', exc_info=True)\n            return\n    enable_receptive_field()\n    graph = Network.load(model_path)\n    graph.reset_batch_size(1)\n    has_input = False\n    if input is not None or inp_dict is not None:\n        has_input = True\n        repl_dict = {}\n        inp_vars = graph.input_vars\n        if inp_dict is not None:\n            assert len(inp_dict) == len(inp_vars), 'Inputs are not sufficient for calculation.'\n            for v in inp_vars:\n                new_input = graph.make_const(inp_dict[v.name], name=v.name)\n                repl_dict[v] = new_input\n        else:\n            assert len(inp_vars) == 1, 'The graph needs more than one input.'\n            inp_var = inp_vars[0]\n            repl_dict[inp_var] = graph.make_const(input, name=inp_var.name)\n        graph.replace_vars(repl_dict=repl_dict)\n    graph._compile()\n\n    def process_name(name):\n        if not re.match('^[+-]?\\\\d*\\\\.\\\\d*', name):\n            name = name.replace('.', '/')\n        return name.encode(encoding='utf-8')\n    summary = [['item', 'value']]\n    node_list = []\n    flops_list = []\n    params_list = []\n    activations_list = []\n    total_stats = namedtuple('total_stats', ['param_size', 'param_dims', 'flops', 'act_size', 'act_dims'])\n    stats_details = namedtuple('module_stats', ['params', 'flops', 'activations'])\n    disable_stats = False\n    for node in tqdm(graph.all_oprs):\n        if hasattr(node, 'output_idx'):\n            node_oup = node.outputs[node.output_idx]\n        else:\n            if len(node.outputs) != 1:\n                logger.warning(\"OpNode {} has more than one output and not has 'output_idx' attr.\".format(node))\n            node_oup = node.outputs[0]\n        inp_list = [process_name(var.owner.name) for var in node.inputs]\n        if log_path:\n            attr = {'params': AttrValue(s=str(node.params).encode(encoding='utf-8')), 'dtype': AttrValue(s=str(node_oup.dtype).encode(encoding='utf-8'))}\n            if node_oup.shape:\n                attr['_output_shapes'] = AttrValue(list=AttrValue.ListValue(shape=[TensorShapeProto(dim=[TensorShapeProto.Dim(size=d) for d in node_oup.shape])]))\n            else:\n                disable_stats = True\n                logger.warning(f'OpNode {node.name} do not has shape attr, would not calculate flops/params/activations for this net.')\n        if not disable_stats:\n            if cal_flops:\n                flops_stats = get_op_stats(node, node.inputs, node.outputs)\n                if flops_stats is not None:\n                    if log_path and hasattr(flops_stats, 'flops_num'):\n                        attr['flops'] = AttrValue(s=sizeof_fmt(flops_stats['flops']).encode(encoding='utf-8'))\n                    flops_stats['name'] = node.name\n                    flops_stats['class_name'] = node.type\n                    flops_list.append(flops_stats)\n            if cal_activations:\n                acts = get_activation_stats(node_oup, has_input=has_input)\n                acts['name'] = node.name\n                acts['class_name'] = node.type\n                activations_list.append(acts)\n            if cal_params:\n                if node.type == 'ImmutableTensor':\n                    param_stats = get_param_stats(node_oup)\n                    if log_path:\n                        attr['size'] = AttrValue(s=sizeof_fmt(param_stats['size']).encode(encoding='utf-8'))\n                    param_stats['name'] = node.name\n                    params_list.append(param_stats)\n        if log_path:\n            node_list.append(NodeDef(name=process_name(node.name), op=node.type, input=inp_list, attr=attr))\n    extra_info = {'#ops': len(graph.all_oprs), '#params': len(params_list)}\n    (total_flops, total_param_dims, total_param_size, total_act_dims, total_act_size) = (0, 0, 0, 0, 0)\n    if not disable_stats:\n        if cal_params:\n            (total_param_dims, total_param_size, params_list) = sum_param_stats(params_list, bar_length_max)\n            extra_info['total_param_dims'] = sizeof_fmt(total_param_dims, suffix='')\n            extra_info['total_param_size'] = sizeof_fmt(total_param_size)\n            if logging_to_stdout:\n                print_param_stats(params_list)\n        if cal_flops:\n            (total_flops, flops_list) = sum_op_stats(flops_list, bar_length_max)\n            extra_info['total_flops'] = sizeof_fmt(total_flops, suffix='OPs')\n            if logging_to_stdout:\n                print_op_stats(flops_list)\n        if cal_activations:\n            (total_act_dims, total_act_size, activations_list) = sum_activations_stats(activations_list, bar_length_max)\n            extra_info['total_act_dims'] = sizeof_fmt(total_act_dims, suffix='')\n            extra_info['total_act_size'] = sizeof_fmt(total_act_size)\n            if logging_to_stdout:\n                print_activations_stats(activations_list, has_input=has_input)\n        if cal_flops and cal_params:\n            extra_info['flops/param_size'] = '{:3.3f}'.format(total_flops / total_param_size)\n        print_summary(**extra_info)\n    if log_path:\n        graph_def = GraphDef(node=node_list, versions=VersionDef(producer=22))\n        device = '/device:CPU:0'\n        stepstats = RunMetadata(step_stats=StepStats(dev_stats=[DeviceStepStats(device=device)]))\n        writer = SummaryWriter(log_path)\n        writer._get_file_writer().add_graph((graph_def, stepstats))\n    return (total_stats(param_size=total_param_size, param_dims=total_param_dims, flops=total_flops, act_size=total_act_size, act_dims=total_act_dims), stats_details(params=params_list, flops=flops_list, activations=activations_list))",
        "mutated": [
            "def visualize(model_path: str, log_path: str, input: np.ndarray=None, inp_dict: dict=None, cal_params: bool=True, cal_flops: bool=True, cal_activations: bool=True, logging_to_stdout: bool=True, bar_length_max: int=20):\n    if False:\n        i = 10\n    \"Load megengine dumped model and visualize graph structure with tensorboard log files.\\n    Can also record and print model's statistics like :func:`~.module_stats`\\n\\n    Args:\\n      model_path: dir path for megengine dumped model.\\n      log_path: dir path for tensorboard graph log.\\n      input: user defined input data for running model and calculating stats,\\n        alternative with inp_dict, used when the model has only one input.\\n      inp_dict: input dict for running model and calculating stats, alternative with\\n        input, used when the model has more than one input.\\n        When both input and inp_dict are None, a random input will be used.\\n      cal_params: whether calculate and record params size.\\n      cal_flops: whether calculate and record op flops.\\n      cal_activations: whether calculate and record op activations.\\n      logging_to_stdout: whether print all calculated statistic details.\\n      bar_length_max: size of bar indicating max flops or parameter size in net stats.\\n      model_path: str:\\n      log_path: str:\\n      input: np.ndarray:\\n      inp_dict: dict:\\n      cal_params: bool:\\n      cal_flops: bool:\\n      cal_activations: bool:\\n      logging_to_stdout: bool:\\n      bar_length_max: int:\\n    \"\n    if log_path:\n        try:\n            from tensorboard.compat.proto.attr_value_pb2 import AttrValue\n            from tensorboard.compat.proto.config_pb2 import RunMetadata\n            from tensorboard.compat.proto.graph_pb2 import GraphDef\n            from tensorboard.compat.proto.node_def_pb2 import NodeDef\n            from tensorboard.compat.proto.step_stats_pb2 import AllocatorMemoryUsed, DeviceStepStats, NodeExecStats, StepStats\n            from tensorboard.compat.proto.tensor_shape_pb2 import TensorShapeProto\n            from tensorboard.compat.proto.versions_pb2 import VersionDef\n            from tensorboardX import SummaryWriter\n        except ImportError:\n            logger.error('TensorBoard and TensorboardX are required for visualize.', exc_info=True)\n            return\n    enable_receptive_field()\n    graph = Network.load(model_path)\n    graph.reset_batch_size(1)\n    has_input = False\n    if input is not None or inp_dict is not None:\n        has_input = True\n        repl_dict = {}\n        inp_vars = graph.input_vars\n        if inp_dict is not None:\n            assert len(inp_dict) == len(inp_vars), 'Inputs are not sufficient for calculation.'\n            for v in inp_vars:\n                new_input = graph.make_const(inp_dict[v.name], name=v.name)\n                repl_dict[v] = new_input\n        else:\n            assert len(inp_vars) == 1, 'The graph needs more than one input.'\n            inp_var = inp_vars[0]\n            repl_dict[inp_var] = graph.make_const(input, name=inp_var.name)\n        graph.replace_vars(repl_dict=repl_dict)\n    graph._compile()\n\n    def process_name(name):\n        if not re.match('^[+-]?\\\\d*\\\\.\\\\d*', name):\n            name = name.replace('.', '/')\n        return name.encode(encoding='utf-8')\n    summary = [['item', 'value']]\n    node_list = []\n    flops_list = []\n    params_list = []\n    activations_list = []\n    total_stats = namedtuple('total_stats', ['param_size', 'param_dims', 'flops', 'act_size', 'act_dims'])\n    stats_details = namedtuple('module_stats', ['params', 'flops', 'activations'])\n    disable_stats = False\n    for node in tqdm(graph.all_oprs):\n        if hasattr(node, 'output_idx'):\n            node_oup = node.outputs[node.output_idx]\n        else:\n            if len(node.outputs) != 1:\n                logger.warning(\"OpNode {} has more than one output and not has 'output_idx' attr.\".format(node))\n            node_oup = node.outputs[0]\n        inp_list = [process_name(var.owner.name) for var in node.inputs]\n        if log_path:\n            attr = {'params': AttrValue(s=str(node.params).encode(encoding='utf-8')), 'dtype': AttrValue(s=str(node_oup.dtype).encode(encoding='utf-8'))}\n            if node_oup.shape:\n                attr['_output_shapes'] = AttrValue(list=AttrValue.ListValue(shape=[TensorShapeProto(dim=[TensorShapeProto.Dim(size=d) for d in node_oup.shape])]))\n            else:\n                disable_stats = True\n                logger.warning(f'OpNode {node.name} do not has shape attr, would not calculate flops/params/activations for this net.')\n        if not disable_stats:\n            if cal_flops:\n                flops_stats = get_op_stats(node, node.inputs, node.outputs)\n                if flops_stats is not None:\n                    if log_path and hasattr(flops_stats, 'flops_num'):\n                        attr['flops'] = AttrValue(s=sizeof_fmt(flops_stats['flops']).encode(encoding='utf-8'))\n                    flops_stats['name'] = node.name\n                    flops_stats['class_name'] = node.type\n                    flops_list.append(flops_stats)\n            if cal_activations:\n                acts = get_activation_stats(node_oup, has_input=has_input)\n                acts['name'] = node.name\n                acts['class_name'] = node.type\n                activations_list.append(acts)\n            if cal_params:\n                if node.type == 'ImmutableTensor':\n                    param_stats = get_param_stats(node_oup)\n                    if log_path:\n                        attr['size'] = AttrValue(s=sizeof_fmt(param_stats['size']).encode(encoding='utf-8'))\n                    param_stats['name'] = node.name\n                    params_list.append(param_stats)\n        if log_path:\n            node_list.append(NodeDef(name=process_name(node.name), op=node.type, input=inp_list, attr=attr))\n    extra_info = {'#ops': len(graph.all_oprs), '#params': len(params_list)}\n    (total_flops, total_param_dims, total_param_size, total_act_dims, total_act_size) = (0, 0, 0, 0, 0)\n    if not disable_stats:\n        if cal_params:\n            (total_param_dims, total_param_size, params_list) = sum_param_stats(params_list, bar_length_max)\n            extra_info['total_param_dims'] = sizeof_fmt(total_param_dims, suffix='')\n            extra_info['total_param_size'] = sizeof_fmt(total_param_size)\n            if logging_to_stdout:\n                print_param_stats(params_list)\n        if cal_flops:\n            (total_flops, flops_list) = sum_op_stats(flops_list, bar_length_max)\n            extra_info['total_flops'] = sizeof_fmt(total_flops, suffix='OPs')\n            if logging_to_stdout:\n                print_op_stats(flops_list)\n        if cal_activations:\n            (total_act_dims, total_act_size, activations_list) = sum_activations_stats(activations_list, bar_length_max)\n            extra_info['total_act_dims'] = sizeof_fmt(total_act_dims, suffix='')\n            extra_info['total_act_size'] = sizeof_fmt(total_act_size)\n            if logging_to_stdout:\n                print_activations_stats(activations_list, has_input=has_input)\n        if cal_flops and cal_params:\n            extra_info['flops/param_size'] = '{:3.3f}'.format(total_flops / total_param_size)\n        print_summary(**extra_info)\n    if log_path:\n        graph_def = GraphDef(node=node_list, versions=VersionDef(producer=22))\n        device = '/device:CPU:0'\n        stepstats = RunMetadata(step_stats=StepStats(dev_stats=[DeviceStepStats(device=device)]))\n        writer = SummaryWriter(log_path)\n        writer._get_file_writer().add_graph((graph_def, stepstats))\n    return (total_stats(param_size=total_param_size, param_dims=total_param_dims, flops=total_flops, act_size=total_act_size, act_dims=total_act_dims), stats_details(params=params_list, flops=flops_list, activations=activations_list))",
            "def visualize(model_path: str, log_path: str, input: np.ndarray=None, inp_dict: dict=None, cal_params: bool=True, cal_flops: bool=True, cal_activations: bool=True, logging_to_stdout: bool=True, bar_length_max: int=20):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    \"Load megengine dumped model and visualize graph structure with tensorboard log files.\\n    Can also record and print model's statistics like :func:`~.module_stats`\\n\\n    Args:\\n      model_path: dir path for megengine dumped model.\\n      log_path: dir path for tensorboard graph log.\\n      input: user defined input data for running model and calculating stats,\\n        alternative with inp_dict, used when the model has only one input.\\n      inp_dict: input dict for running model and calculating stats, alternative with\\n        input, used when the model has more than one input.\\n        When both input and inp_dict are None, a random input will be used.\\n      cal_params: whether calculate and record params size.\\n      cal_flops: whether calculate and record op flops.\\n      cal_activations: whether calculate and record op activations.\\n      logging_to_stdout: whether print all calculated statistic details.\\n      bar_length_max: size of bar indicating max flops or parameter size in net stats.\\n      model_path: str:\\n      log_path: str:\\n      input: np.ndarray:\\n      inp_dict: dict:\\n      cal_params: bool:\\n      cal_flops: bool:\\n      cal_activations: bool:\\n      logging_to_stdout: bool:\\n      bar_length_max: int:\\n    \"\n    if log_path:\n        try:\n            from tensorboard.compat.proto.attr_value_pb2 import AttrValue\n            from tensorboard.compat.proto.config_pb2 import RunMetadata\n            from tensorboard.compat.proto.graph_pb2 import GraphDef\n            from tensorboard.compat.proto.node_def_pb2 import NodeDef\n            from tensorboard.compat.proto.step_stats_pb2 import AllocatorMemoryUsed, DeviceStepStats, NodeExecStats, StepStats\n            from tensorboard.compat.proto.tensor_shape_pb2 import TensorShapeProto\n            from tensorboard.compat.proto.versions_pb2 import VersionDef\n            from tensorboardX import SummaryWriter\n        except ImportError:\n            logger.error('TensorBoard and TensorboardX are required for visualize.', exc_info=True)\n            return\n    enable_receptive_field()\n    graph = Network.load(model_path)\n    graph.reset_batch_size(1)\n    has_input = False\n    if input is not None or inp_dict is not None:\n        has_input = True\n        repl_dict = {}\n        inp_vars = graph.input_vars\n        if inp_dict is not None:\n            assert len(inp_dict) == len(inp_vars), 'Inputs are not sufficient for calculation.'\n            for v in inp_vars:\n                new_input = graph.make_const(inp_dict[v.name], name=v.name)\n                repl_dict[v] = new_input\n        else:\n            assert len(inp_vars) == 1, 'The graph needs more than one input.'\n            inp_var = inp_vars[0]\n            repl_dict[inp_var] = graph.make_const(input, name=inp_var.name)\n        graph.replace_vars(repl_dict=repl_dict)\n    graph._compile()\n\n    def process_name(name):\n        if not re.match('^[+-]?\\\\d*\\\\.\\\\d*', name):\n            name = name.replace('.', '/')\n        return name.encode(encoding='utf-8')\n    summary = [['item', 'value']]\n    node_list = []\n    flops_list = []\n    params_list = []\n    activations_list = []\n    total_stats = namedtuple('total_stats', ['param_size', 'param_dims', 'flops', 'act_size', 'act_dims'])\n    stats_details = namedtuple('module_stats', ['params', 'flops', 'activations'])\n    disable_stats = False\n    for node in tqdm(graph.all_oprs):\n        if hasattr(node, 'output_idx'):\n            node_oup = node.outputs[node.output_idx]\n        else:\n            if len(node.outputs) != 1:\n                logger.warning(\"OpNode {} has more than one output and not has 'output_idx' attr.\".format(node))\n            node_oup = node.outputs[0]\n        inp_list = [process_name(var.owner.name) for var in node.inputs]\n        if log_path:\n            attr = {'params': AttrValue(s=str(node.params).encode(encoding='utf-8')), 'dtype': AttrValue(s=str(node_oup.dtype).encode(encoding='utf-8'))}\n            if node_oup.shape:\n                attr['_output_shapes'] = AttrValue(list=AttrValue.ListValue(shape=[TensorShapeProto(dim=[TensorShapeProto.Dim(size=d) for d in node_oup.shape])]))\n            else:\n                disable_stats = True\n                logger.warning(f'OpNode {node.name} do not has shape attr, would not calculate flops/params/activations for this net.')\n        if not disable_stats:\n            if cal_flops:\n                flops_stats = get_op_stats(node, node.inputs, node.outputs)\n                if flops_stats is not None:\n                    if log_path and hasattr(flops_stats, 'flops_num'):\n                        attr['flops'] = AttrValue(s=sizeof_fmt(flops_stats['flops']).encode(encoding='utf-8'))\n                    flops_stats['name'] = node.name\n                    flops_stats['class_name'] = node.type\n                    flops_list.append(flops_stats)\n            if cal_activations:\n                acts = get_activation_stats(node_oup, has_input=has_input)\n                acts['name'] = node.name\n                acts['class_name'] = node.type\n                activations_list.append(acts)\n            if cal_params:\n                if node.type == 'ImmutableTensor':\n                    param_stats = get_param_stats(node_oup)\n                    if log_path:\n                        attr['size'] = AttrValue(s=sizeof_fmt(param_stats['size']).encode(encoding='utf-8'))\n                    param_stats['name'] = node.name\n                    params_list.append(param_stats)\n        if log_path:\n            node_list.append(NodeDef(name=process_name(node.name), op=node.type, input=inp_list, attr=attr))\n    extra_info = {'#ops': len(graph.all_oprs), '#params': len(params_list)}\n    (total_flops, total_param_dims, total_param_size, total_act_dims, total_act_size) = (0, 0, 0, 0, 0)\n    if not disable_stats:\n        if cal_params:\n            (total_param_dims, total_param_size, params_list) = sum_param_stats(params_list, bar_length_max)\n            extra_info['total_param_dims'] = sizeof_fmt(total_param_dims, suffix='')\n            extra_info['total_param_size'] = sizeof_fmt(total_param_size)\n            if logging_to_stdout:\n                print_param_stats(params_list)\n        if cal_flops:\n            (total_flops, flops_list) = sum_op_stats(flops_list, bar_length_max)\n            extra_info['total_flops'] = sizeof_fmt(total_flops, suffix='OPs')\n            if logging_to_stdout:\n                print_op_stats(flops_list)\n        if cal_activations:\n            (total_act_dims, total_act_size, activations_list) = sum_activations_stats(activations_list, bar_length_max)\n            extra_info['total_act_dims'] = sizeof_fmt(total_act_dims, suffix='')\n            extra_info['total_act_size'] = sizeof_fmt(total_act_size)\n            if logging_to_stdout:\n                print_activations_stats(activations_list, has_input=has_input)\n        if cal_flops and cal_params:\n            extra_info['flops/param_size'] = '{:3.3f}'.format(total_flops / total_param_size)\n        print_summary(**extra_info)\n    if log_path:\n        graph_def = GraphDef(node=node_list, versions=VersionDef(producer=22))\n        device = '/device:CPU:0'\n        stepstats = RunMetadata(step_stats=StepStats(dev_stats=[DeviceStepStats(device=device)]))\n        writer = SummaryWriter(log_path)\n        writer._get_file_writer().add_graph((graph_def, stepstats))\n    return (total_stats(param_size=total_param_size, param_dims=total_param_dims, flops=total_flops, act_size=total_act_size, act_dims=total_act_dims), stats_details(params=params_list, flops=flops_list, activations=activations_list))",
            "def visualize(model_path: str, log_path: str, input: np.ndarray=None, inp_dict: dict=None, cal_params: bool=True, cal_flops: bool=True, cal_activations: bool=True, logging_to_stdout: bool=True, bar_length_max: int=20):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    \"Load megengine dumped model and visualize graph structure with tensorboard log files.\\n    Can also record and print model's statistics like :func:`~.module_stats`\\n\\n    Args:\\n      model_path: dir path for megengine dumped model.\\n      log_path: dir path for tensorboard graph log.\\n      input: user defined input data for running model and calculating stats,\\n        alternative with inp_dict, used when the model has only one input.\\n      inp_dict: input dict for running model and calculating stats, alternative with\\n        input, used when the model has more than one input.\\n        When both input and inp_dict are None, a random input will be used.\\n      cal_params: whether calculate and record params size.\\n      cal_flops: whether calculate and record op flops.\\n      cal_activations: whether calculate and record op activations.\\n      logging_to_stdout: whether print all calculated statistic details.\\n      bar_length_max: size of bar indicating max flops or parameter size in net stats.\\n      model_path: str:\\n      log_path: str:\\n      input: np.ndarray:\\n      inp_dict: dict:\\n      cal_params: bool:\\n      cal_flops: bool:\\n      cal_activations: bool:\\n      logging_to_stdout: bool:\\n      bar_length_max: int:\\n    \"\n    if log_path:\n        try:\n            from tensorboard.compat.proto.attr_value_pb2 import AttrValue\n            from tensorboard.compat.proto.config_pb2 import RunMetadata\n            from tensorboard.compat.proto.graph_pb2 import GraphDef\n            from tensorboard.compat.proto.node_def_pb2 import NodeDef\n            from tensorboard.compat.proto.step_stats_pb2 import AllocatorMemoryUsed, DeviceStepStats, NodeExecStats, StepStats\n            from tensorboard.compat.proto.tensor_shape_pb2 import TensorShapeProto\n            from tensorboard.compat.proto.versions_pb2 import VersionDef\n            from tensorboardX import SummaryWriter\n        except ImportError:\n            logger.error('TensorBoard and TensorboardX are required for visualize.', exc_info=True)\n            return\n    enable_receptive_field()\n    graph = Network.load(model_path)\n    graph.reset_batch_size(1)\n    has_input = False\n    if input is not None or inp_dict is not None:\n        has_input = True\n        repl_dict = {}\n        inp_vars = graph.input_vars\n        if inp_dict is not None:\n            assert len(inp_dict) == len(inp_vars), 'Inputs are not sufficient for calculation.'\n            for v in inp_vars:\n                new_input = graph.make_const(inp_dict[v.name], name=v.name)\n                repl_dict[v] = new_input\n        else:\n            assert len(inp_vars) == 1, 'The graph needs more than one input.'\n            inp_var = inp_vars[0]\n            repl_dict[inp_var] = graph.make_const(input, name=inp_var.name)\n        graph.replace_vars(repl_dict=repl_dict)\n    graph._compile()\n\n    def process_name(name):\n        if not re.match('^[+-]?\\\\d*\\\\.\\\\d*', name):\n            name = name.replace('.', '/')\n        return name.encode(encoding='utf-8')\n    summary = [['item', 'value']]\n    node_list = []\n    flops_list = []\n    params_list = []\n    activations_list = []\n    total_stats = namedtuple('total_stats', ['param_size', 'param_dims', 'flops', 'act_size', 'act_dims'])\n    stats_details = namedtuple('module_stats', ['params', 'flops', 'activations'])\n    disable_stats = False\n    for node in tqdm(graph.all_oprs):\n        if hasattr(node, 'output_idx'):\n            node_oup = node.outputs[node.output_idx]\n        else:\n            if len(node.outputs) != 1:\n                logger.warning(\"OpNode {} has more than one output and not has 'output_idx' attr.\".format(node))\n            node_oup = node.outputs[0]\n        inp_list = [process_name(var.owner.name) for var in node.inputs]\n        if log_path:\n            attr = {'params': AttrValue(s=str(node.params).encode(encoding='utf-8')), 'dtype': AttrValue(s=str(node_oup.dtype).encode(encoding='utf-8'))}\n            if node_oup.shape:\n                attr['_output_shapes'] = AttrValue(list=AttrValue.ListValue(shape=[TensorShapeProto(dim=[TensorShapeProto.Dim(size=d) for d in node_oup.shape])]))\n            else:\n                disable_stats = True\n                logger.warning(f'OpNode {node.name} do not has shape attr, would not calculate flops/params/activations for this net.')\n        if not disable_stats:\n            if cal_flops:\n                flops_stats = get_op_stats(node, node.inputs, node.outputs)\n                if flops_stats is not None:\n                    if log_path and hasattr(flops_stats, 'flops_num'):\n                        attr['flops'] = AttrValue(s=sizeof_fmt(flops_stats['flops']).encode(encoding='utf-8'))\n                    flops_stats['name'] = node.name\n                    flops_stats['class_name'] = node.type\n                    flops_list.append(flops_stats)\n            if cal_activations:\n                acts = get_activation_stats(node_oup, has_input=has_input)\n                acts['name'] = node.name\n                acts['class_name'] = node.type\n                activations_list.append(acts)\n            if cal_params:\n                if node.type == 'ImmutableTensor':\n                    param_stats = get_param_stats(node_oup)\n                    if log_path:\n                        attr['size'] = AttrValue(s=sizeof_fmt(param_stats['size']).encode(encoding='utf-8'))\n                    param_stats['name'] = node.name\n                    params_list.append(param_stats)\n        if log_path:\n            node_list.append(NodeDef(name=process_name(node.name), op=node.type, input=inp_list, attr=attr))\n    extra_info = {'#ops': len(graph.all_oprs), '#params': len(params_list)}\n    (total_flops, total_param_dims, total_param_size, total_act_dims, total_act_size) = (0, 0, 0, 0, 0)\n    if not disable_stats:\n        if cal_params:\n            (total_param_dims, total_param_size, params_list) = sum_param_stats(params_list, bar_length_max)\n            extra_info['total_param_dims'] = sizeof_fmt(total_param_dims, suffix='')\n            extra_info['total_param_size'] = sizeof_fmt(total_param_size)\n            if logging_to_stdout:\n                print_param_stats(params_list)\n        if cal_flops:\n            (total_flops, flops_list) = sum_op_stats(flops_list, bar_length_max)\n            extra_info['total_flops'] = sizeof_fmt(total_flops, suffix='OPs')\n            if logging_to_stdout:\n                print_op_stats(flops_list)\n        if cal_activations:\n            (total_act_dims, total_act_size, activations_list) = sum_activations_stats(activations_list, bar_length_max)\n            extra_info['total_act_dims'] = sizeof_fmt(total_act_dims, suffix='')\n            extra_info['total_act_size'] = sizeof_fmt(total_act_size)\n            if logging_to_stdout:\n                print_activations_stats(activations_list, has_input=has_input)\n        if cal_flops and cal_params:\n            extra_info['flops/param_size'] = '{:3.3f}'.format(total_flops / total_param_size)\n        print_summary(**extra_info)\n    if log_path:\n        graph_def = GraphDef(node=node_list, versions=VersionDef(producer=22))\n        device = '/device:CPU:0'\n        stepstats = RunMetadata(step_stats=StepStats(dev_stats=[DeviceStepStats(device=device)]))\n        writer = SummaryWriter(log_path)\n        writer._get_file_writer().add_graph((graph_def, stepstats))\n    return (total_stats(param_size=total_param_size, param_dims=total_param_dims, flops=total_flops, act_size=total_act_size, act_dims=total_act_dims), stats_details(params=params_list, flops=flops_list, activations=activations_list))",
            "def visualize(model_path: str, log_path: str, input: np.ndarray=None, inp_dict: dict=None, cal_params: bool=True, cal_flops: bool=True, cal_activations: bool=True, logging_to_stdout: bool=True, bar_length_max: int=20):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    \"Load megengine dumped model and visualize graph structure with tensorboard log files.\\n    Can also record and print model's statistics like :func:`~.module_stats`\\n\\n    Args:\\n      model_path: dir path for megengine dumped model.\\n      log_path: dir path for tensorboard graph log.\\n      input: user defined input data for running model and calculating stats,\\n        alternative with inp_dict, used when the model has only one input.\\n      inp_dict: input dict for running model and calculating stats, alternative with\\n        input, used when the model has more than one input.\\n        When both input and inp_dict are None, a random input will be used.\\n      cal_params: whether calculate and record params size.\\n      cal_flops: whether calculate and record op flops.\\n      cal_activations: whether calculate and record op activations.\\n      logging_to_stdout: whether print all calculated statistic details.\\n      bar_length_max: size of bar indicating max flops or parameter size in net stats.\\n      model_path: str:\\n      log_path: str:\\n      input: np.ndarray:\\n      inp_dict: dict:\\n      cal_params: bool:\\n      cal_flops: bool:\\n      cal_activations: bool:\\n      logging_to_stdout: bool:\\n      bar_length_max: int:\\n    \"\n    if log_path:\n        try:\n            from tensorboard.compat.proto.attr_value_pb2 import AttrValue\n            from tensorboard.compat.proto.config_pb2 import RunMetadata\n            from tensorboard.compat.proto.graph_pb2 import GraphDef\n            from tensorboard.compat.proto.node_def_pb2 import NodeDef\n            from tensorboard.compat.proto.step_stats_pb2 import AllocatorMemoryUsed, DeviceStepStats, NodeExecStats, StepStats\n            from tensorboard.compat.proto.tensor_shape_pb2 import TensorShapeProto\n            from tensorboard.compat.proto.versions_pb2 import VersionDef\n            from tensorboardX import SummaryWriter\n        except ImportError:\n            logger.error('TensorBoard and TensorboardX are required for visualize.', exc_info=True)\n            return\n    enable_receptive_field()\n    graph = Network.load(model_path)\n    graph.reset_batch_size(1)\n    has_input = False\n    if input is not None or inp_dict is not None:\n        has_input = True\n        repl_dict = {}\n        inp_vars = graph.input_vars\n        if inp_dict is not None:\n            assert len(inp_dict) == len(inp_vars), 'Inputs are not sufficient for calculation.'\n            for v in inp_vars:\n                new_input = graph.make_const(inp_dict[v.name], name=v.name)\n                repl_dict[v] = new_input\n        else:\n            assert len(inp_vars) == 1, 'The graph needs more than one input.'\n            inp_var = inp_vars[0]\n            repl_dict[inp_var] = graph.make_const(input, name=inp_var.name)\n        graph.replace_vars(repl_dict=repl_dict)\n    graph._compile()\n\n    def process_name(name):\n        if not re.match('^[+-]?\\\\d*\\\\.\\\\d*', name):\n            name = name.replace('.', '/')\n        return name.encode(encoding='utf-8')\n    summary = [['item', 'value']]\n    node_list = []\n    flops_list = []\n    params_list = []\n    activations_list = []\n    total_stats = namedtuple('total_stats', ['param_size', 'param_dims', 'flops', 'act_size', 'act_dims'])\n    stats_details = namedtuple('module_stats', ['params', 'flops', 'activations'])\n    disable_stats = False\n    for node in tqdm(graph.all_oprs):\n        if hasattr(node, 'output_idx'):\n            node_oup = node.outputs[node.output_idx]\n        else:\n            if len(node.outputs) != 1:\n                logger.warning(\"OpNode {} has more than one output and not has 'output_idx' attr.\".format(node))\n            node_oup = node.outputs[0]\n        inp_list = [process_name(var.owner.name) for var in node.inputs]\n        if log_path:\n            attr = {'params': AttrValue(s=str(node.params).encode(encoding='utf-8')), 'dtype': AttrValue(s=str(node_oup.dtype).encode(encoding='utf-8'))}\n            if node_oup.shape:\n                attr['_output_shapes'] = AttrValue(list=AttrValue.ListValue(shape=[TensorShapeProto(dim=[TensorShapeProto.Dim(size=d) for d in node_oup.shape])]))\n            else:\n                disable_stats = True\n                logger.warning(f'OpNode {node.name} do not has shape attr, would not calculate flops/params/activations for this net.')\n        if not disable_stats:\n            if cal_flops:\n                flops_stats = get_op_stats(node, node.inputs, node.outputs)\n                if flops_stats is not None:\n                    if log_path and hasattr(flops_stats, 'flops_num'):\n                        attr['flops'] = AttrValue(s=sizeof_fmt(flops_stats['flops']).encode(encoding='utf-8'))\n                    flops_stats['name'] = node.name\n                    flops_stats['class_name'] = node.type\n                    flops_list.append(flops_stats)\n            if cal_activations:\n                acts = get_activation_stats(node_oup, has_input=has_input)\n                acts['name'] = node.name\n                acts['class_name'] = node.type\n                activations_list.append(acts)\n            if cal_params:\n                if node.type == 'ImmutableTensor':\n                    param_stats = get_param_stats(node_oup)\n                    if log_path:\n                        attr['size'] = AttrValue(s=sizeof_fmt(param_stats['size']).encode(encoding='utf-8'))\n                    param_stats['name'] = node.name\n                    params_list.append(param_stats)\n        if log_path:\n            node_list.append(NodeDef(name=process_name(node.name), op=node.type, input=inp_list, attr=attr))\n    extra_info = {'#ops': len(graph.all_oprs), '#params': len(params_list)}\n    (total_flops, total_param_dims, total_param_size, total_act_dims, total_act_size) = (0, 0, 0, 0, 0)\n    if not disable_stats:\n        if cal_params:\n            (total_param_dims, total_param_size, params_list) = sum_param_stats(params_list, bar_length_max)\n            extra_info['total_param_dims'] = sizeof_fmt(total_param_dims, suffix='')\n            extra_info['total_param_size'] = sizeof_fmt(total_param_size)\n            if logging_to_stdout:\n                print_param_stats(params_list)\n        if cal_flops:\n            (total_flops, flops_list) = sum_op_stats(flops_list, bar_length_max)\n            extra_info['total_flops'] = sizeof_fmt(total_flops, suffix='OPs')\n            if logging_to_stdout:\n                print_op_stats(flops_list)\n        if cal_activations:\n            (total_act_dims, total_act_size, activations_list) = sum_activations_stats(activations_list, bar_length_max)\n            extra_info['total_act_dims'] = sizeof_fmt(total_act_dims, suffix='')\n            extra_info['total_act_size'] = sizeof_fmt(total_act_size)\n            if logging_to_stdout:\n                print_activations_stats(activations_list, has_input=has_input)\n        if cal_flops and cal_params:\n            extra_info['flops/param_size'] = '{:3.3f}'.format(total_flops / total_param_size)\n        print_summary(**extra_info)\n    if log_path:\n        graph_def = GraphDef(node=node_list, versions=VersionDef(producer=22))\n        device = '/device:CPU:0'\n        stepstats = RunMetadata(step_stats=StepStats(dev_stats=[DeviceStepStats(device=device)]))\n        writer = SummaryWriter(log_path)\n        writer._get_file_writer().add_graph((graph_def, stepstats))\n    return (total_stats(param_size=total_param_size, param_dims=total_param_dims, flops=total_flops, act_size=total_act_size, act_dims=total_act_dims), stats_details(params=params_list, flops=flops_list, activations=activations_list))",
            "def visualize(model_path: str, log_path: str, input: np.ndarray=None, inp_dict: dict=None, cal_params: bool=True, cal_flops: bool=True, cal_activations: bool=True, logging_to_stdout: bool=True, bar_length_max: int=20):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    \"Load megengine dumped model and visualize graph structure with tensorboard log files.\\n    Can also record and print model's statistics like :func:`~.module_stats`\\n\\n    Args:\\n      model_path: dir path for megengine dumped model.\\n      log_path: dir path for tensorboard graph log.\\n      input: user defined input data for running model and calculating stats,\\n        alternative with inp_dict, used when the model has only one input.\\n      inp_dict: input dict for running model and calculating stats, alternative with\\n        input, used when the model has more than one input.\\n        When both input and inp_dict are None, a random input will be used.\\n      cal_params: whether calculate and record params size.\\n      cal_flops: whether calculate and record op flops.\\n      cal_activations: whether calculate and record op activations.\\n      logging_to_stdout: whether print all calculated statistic details.\\n      bar_length_max: size of bar indicating max flops or parameter size in net stats.\\n      model_path: str:\\n      log_path: str:\\n      input: np.ndarray:\\n      inp_dict: dict:\\n      cal_params: bool:\\n      cal_flops: bool:\\n      cal_activations: bool:\\n      logging_to_stdout: bool:\\n      bar_length_max: int:\\n    \"\n    if log_path:\n        try:\n            from tensorboard.compat.proto.attr_value_pb2 import AttrValue\n            from tensorboard.compat.proto.config_pb2 import RunMetadata\n            from tensorboard.compat.proto.graph_pb2 import GraphDef\n            from tensorboard.compat.proto.node_def_pb2 import NodeDef\n            from tensorboard.compat.proto.step_stats_pb2 import AllocatorMemoryUsed, DeviceStepStats, NodeExecStats, StepStats\n            from tensorboard.compat.proto.tensor_shape_pb2 import TensorShapeProto\n            from tensorboard.compat.proto.versions_pb2 import VersionDef\n            from tensorboardX import SummaryWriter\n        except ImportError:\n            logger.error('TensorBoard and TensorboardX are required for visualize.', exc_info=True)\n            return\n    enable_receptive_field()\n    graph = Network.load(model_path)\n    graph.reset_batch_size(1)\n    has_input = False\n    if input is not None or inp_dict is not None:\n        has_input = True\n        repl_dict = {}\n        inp_vars = graph.input_vars\n        if inp_dict is not None:\n            assert len(inp_dict) == len(inp_vars), 'Inputs are not sufficient for calculation.'\n            for v in inp_vars:\n                new_input = graph.make_const(inp_dict[v.name], name=v.name)\n                repl_dict[v] = new_input\n        else:\n            assert len(inp_vars) == 1, 'The graph needs more than one input.'\n            inp_var = inp_vars[0]\n            repl_dict[inp_var] = graph.make_const(input, name=inp_var.name)\n        graph.replace_vars(repl_dict=repl_dict)\n    graph._compile()\n\n    def process_name(name):\n        if not re.match('^[+-]?\\\\d*\\\\.\\\\d*', name):\n            name = name.replace('.', '/')\n        return name.encode(encoding='utf-8')\n    summary = [['item', 'value']]\n    node_list = []\n    flops_list = []\n    params_list = []\n    activations_list = []\n    total_stats = namedtuple('total_stats', ['param_size', 'param_dims', 'flops', 'act_size', 'act_dims'])\n    stats_details = namedtuple('module_stats', ['params', 'flops', 'activations'])\n    disable_stats = False\n    for node in tqdm(graph.all_oprs):\n        if hasattr(node, 'output_idx'):\n            node_oup = node.outputs[node.output_idx]\n        else:\n            if len(node.outputs) != 1:\n                logger.warning(\"OpNode {} has more than one output and not has 'output_idx' attr.\".format(node))\n            node_oup = node.outputs[0]\n        inp_list = [process_name(var.owner.name) for var in node.inputs]\n        if log_path:\n            attr = {'params': AttrValue(s=str(node.params).encode(encoding='utf-8')), 'dtype': AttrValue(s=str(node_oup.dtype).encode(encoding='utf-8'))}\n            if node_oup.shape:\n                attr['_output_shapes'] = AttrValue(list=AttrValue.ListValue(shape=[TensorShapeProto(dim=[TensorShapeProto.Dim(size=d) for d in node_oup.shape])]))\n            else:\n                disable_stats = True\n                logger.warning(f'OpNode {node.name} do not has shape attr, would not calculate flops/params/activations for this net.')\n        if not disable_stats:\n            if cal_flops:\n                flops_stats = get_op_stats(node, node.inputs, node.outputs)\n                if flops_stats is not None:\n                    if log_path and hasattr(flops_stats, 'flops_num'):\n                        attr['flops'] = AttrValue(s=sizeof_fmt(flops_stats['flops']).encode(encoding='utf-8'))\n                    flops_stats['name'] = node.name\n                    flops_stats['class_name'] = node.type\n                    flops_list.append(flops_stats)\n            if cal_activations:\n                acts = get_activation_stats(node_oup, has_input=has_input)\n                acts['name'] = node.name\n                acts['class_name'] = node.type\n                activations_list.append(acts)\n            if cal_params:\n                if node.type == 'ImmutableTensor':\n                    param_stats = get_param_stats(node_oup)\n                    if log_path:\n                        attr['size'] = AttrValue(s=sizeof_fmt(param_stats['size']).encode(encoding='utf-8'))\n                    param_stats['name'] = node.name\n                    params_list.append(param_stats)\n        if log_path:\n            node_list.append(NodeDef(name=process_name(node.name), op=node.type, input=inp_list, attr=attr))\n    extra_info = {'#ops': len(graph.all_oprs), '#params': len(params_list)}\n    (total_flops, total_param_dims, total_param_size, total_act_dims, total_act_size) = (0, 0, 0, 0, 0)\n    if not disable_stats:\n        if cal_params:\n            (total_param_dims, total_param_size, params_list) = sum_param_stats(params_list, bar_length_max)\n            extra_info['total_param_dims'] = sizeof_fmt(total_param_dims, suffix='')\n            extra_info['total_param_size'] = sizeof_fmt(total_param_size)\n            if logging_to_stdout:\n                print_param_stats(params_list)\n        if cal_flops:\n            (total_flops, flops_list) = sum_op_stats(flops_list, bar_length_max)\n            extra_info['total_flops'] = sizeof_fmt(total_flops, suffix='OPs')\n            if logging_to_stdout:\n                print_op_stats(flops_list)\n        if cal_activations:\n            (total_act_dims, total_act_size, activations_list) = sum_activations_stats(activations_list, bar_length_max)\n            extra_info['total_act_dims'] = sizeof_fmt(total_act_dims, suffix='')\n            extra_info['total_act_size'] = sizeof_fmt(total_act_size)\n            if logging_to_stdout:\n                print_activations_stats(activations_list, has_input=has_input)\n        if cal_flops and cal_params:\n            extra_info['flops/param_size'] = '{:3.3f}'.format(total_flops / total_param_size)\n        print_summary(**extra_info)\n    if log_path:\n        graph_def = GraphDef(node=node_list, versions=VersionDef(producer=22))\n        device = '/device:CPU:0'\n        stepstats = RunMetadata(step_stats=StepStats(dev_stats=[DeviceStepStats(device=device)]))\n        writer = SummaryWriter(log_path)\n        writer._get_file_writer().add_graph((graph_def, stepstats))\n    return (total_stats(param_size=total_param_size, param_dims=total_param_dims, flops=total_flops, act_size=total_act_size, act_dims=total_act_dims), stats_details(params=params_list, flops=flops_list, activations=activations_list))"
        ]
    },
    {
        "func_name": "main",
        "original": "def main():\n    parser = argparse.ArgumentParser(description='load a megengine dumped model and export log file for tensorboard visualization.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument('model_path', help='dumped model path.')\n    parser.add_argument('--log_path', help='tensorboard log path.')\n    parser.add_argument('--load_input_data', help='load input data from pickle file; it should be a numpy array or a dict of numpy array')\n    parser.add_argument('--bar_length_max', type=int, default=20, help='size of bar indicating max flops or parameter size in net stats.')\n    parser.add_argument('--cal_params', action='store_true', help='whether calculate and record params size.')\n    parser.add_argument('--cal_flops', action='store_true', help='whether calculate and record op flops.')\n    parser.add_argument('--cal_activations', action='store_true', help='whether calculate and record op activations.')\n    parser.add_argument('--logging_to_stdout', action='store_true', help='whether print all calculated statistic details.')\n    parser.add_argument('--all', action='store_true', help=\"whether print all stats. Tensorboard logs will be placed in './log' if not specified.\")\n    args = parser.parse_args()\n    if args.load_input_data:\n        logger.info('load data from {}'.format(args.load_input_data))\n        data = mge.load(args.load_input_data)\n        if isinstance(data, dict):\n            for v in data.values():\n                assert isinstance(v, np.ndarray), 'data should provide ndarray; got {} instead'.format(v)\n            args.inp_dict = data\n        elif isinstance(data, np.ndarray):\n            args.input = data\n        else:\n            logger.error('input data should be a numpy array or a dict of numpy array')\n    if args.all:\n        args.cal_params = True\n        args.cal_flops = True\n        args.cal_activations = True\n        args.logging_to_stdout = True\n        if not args.log_path:\n            args.log_path = './log'\n    kwargs = vars(args)\n    kwargs.pop('all')\n    kwargs.pop('load_input_data')\n    visualize(**kwargs)",
        "mutated": [
            "def main():\n    if False:\n        i = 10\n    parser = argparse.ArgumentParser(description='load a megengine dumped model and export log file for tensorboard visualization.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument('model_path', help='dumped model path.')\n    parser.add_argument('--log_path', help='tensorboard log path.')\n    parser.add_argument('--load_input_data', help='load input data from pickle file; it should be a numpy array or a dict of numpy array')\n    parser.add_argument('--bar_length_max', type=int, default=20, help='size of bar indicating max flops or parameter size in net stats.')\n    parser.add_argument('--cal_params', action='store_true', help='whether calculate and record params size.')\n    parser.add_argument('--cal_flops', action='store_true', help='whether calculate and record op flops.')\n    parser.add_argument('--cal_activations', action='store_true', help='whether calculate and record op activations.')\n    parser.add_argument('--logging_to_stdout', action='store_true', help='whether print all calculated statistic details.')\n    parser.add_argument('--all', action='store_true', help=\"whether print all stats. Tensorboard logs will be placed in './log' if not specified.\")\n    args = parser.parse_args()\n    if args.load_input_data:\n        logger.info('load data from {}'.format(args.load_input_data))\n        data = mge.load(args.load_input_data)\n        if isinstance(data, dict):\n            for v in data.values():\n                assert isinstance(v, np.ndarray), 'data should provide ndarray; got {} instead'.format(v)\n            args.inp_dict = data\n        elif isinstance(data, np.ndarray):\n            args.input = data\n        else:\n            logger.error('input data should be a numpy array or a dict of numpy array')\n    if args.all:\n        args.cal_params = True\n        args.cal_flops = True\n        args.cal_activations = True\n        args.logging_to_stdout = True\n        if not args.log_path:\n            args.log_path = './log'\n    kwargs = vars(args)\n    kwargs.pop('all')\n    kwargs.pop('load_input_data')\n    visualize(**kwargs)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    parser = argparse.ArgumentParser(description='load a megengine dumped model and export log file for tensorboard visualization.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument('model_path', help='dumped model path.')\n    parser.add_argument('--log_path', help='tensorboard log path.')\n    parser.add_argument('--load_input_data', help='load input data from pickle file; it should be a numpy array or a dict of numpy array')\n    parser.add_argument('--bar_length_max', type=int, default=20, help='size of bar indicating max flops or parameter size in net stats.')\n    parser.add_argument('--cal_params', action='store_true', help='whether calculate and record params size.')\n    parser.add_argument('--cal_flops', action='store_true', help='whether calculate and record op flops.')\n    parser.add_argument('--cal_activations', action='store_true', help='whether calculate and record op activations.')\n    parser.add_argument('--logging_to_stdout', action='store_true', help='whether print all calculated statistic details.')\n    parser.add_argument('--all', action='store_true', help=\"whether print all stats. Tensorboard logs will be placed in './log' if not specified.\")\n    args = parser.parse_args()\n    if args.load_input_data:\n        logger.info('load data from {}'.format(args.load_input_data))\n        data = mge.load(args.load_input_data)\n        if isinstance(data, dict):\n            for v in data.values():\n                assert isinstance(v, np.ndarray), 'data should provide ndarray; got {} instead'.format(v)\n            args.inp_dict = data\n        elif isinstance(data, np.ndarray):\n            args.input = data\n        else:\n            logger.error('input data should be a numpy array or a dict of numpy array')\n    if args.all:\n        args.cal_params = True\n        args.cal_flops = True\n        args.cal_activations = True\n        args.logging_to_stdout = True\n        if not args.log_path:\n            args.log_path = './log'\n    kwargs = vars(args)\n    kwargs.pop('all')\n    kwargs.pop('load_input_data')\n    visualize(**kwargs)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    parser = argparse.ArgumentParser(description='load a megengine dumped model and export log file for tensorboard visualization.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument('model_path', help='dumped model path.')\n    parser.add_argument('--log_path', help='tensorboard log path.')\n    parser.add_argument('--load_input_data', help='load input data from pickle file; it should be a numpy array or a dict of numpy array')\n    parser.add_argument('--bar_length_max', type=int, default=20, help='size of bar indicating max flops or parameter size in net stats.')\n    parser.add_argument('--cal_params', action='store_true', help='whether calculate and record params size.')\n    parser.add_argument('--cal_flops', action='store_true', help='whether calculate and record op flops.')\n    parser.add_argument('--cal_activations', action='store_true', help='whether calculate and record op activations.')\n    parser.add_argument('--logging_to_stdout', action='store_true', help='whether print all calculated statistic details.')\n    parser.add_argument('--all', action='store_true', help=\"whether print all stats. Tensorboard logs will be placed in './log' if not specified.\")\n    args = parser.parse_args()\n    if args.load_input_data:\n        logger.info('load data from {}'.format(args.load_input_data))\n        data = mge.load(args.load_input_data)\n        if isinstance(data, dict):\n            for v in data.values():\n                assert isinstance(v, np.ndarray), 'data should provide ndarray; got {} instead'.format(v)\n            args.inp_dict = data\n        elif isinstance(data, np.ndarray):\n            args.input = data\n        else:\n            logger.error('input data should be a numpy array or a dict of numpy array')\n    if args.all:\n        args.cal_params = True\n        args.cal_flops = True\n        args.cal_activations = True\n        args.logging_to_stdout = True\n        if not args.log_path:\n            args.log_path = './log'\n    kwargs = vars(args)\n    kwargs.pop('all')\n    kwargs.pop('load_input_data')\n    visualize(**kwargs)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    parser = argparse.ArgumentParser(description='load a megengine dumped model and export log file for tensorboard visualization.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument('model_path', help='dumped model path.')\n    parser.add_argument('--log_path', help='tensorboard log path.')\n    parser.add_argument('--load_input_data', help='load input data from pickle file; it should be a numpy array or a dict of numpy array')\n    parser.add_argument('--bar_length_max', type=int, default=20, help='size of bar indicating max flops or parameter size in net stats.')\n    parser.add_argument('--cal_params', action='store_true', help='whether calculate and record params size.')\n    parser.add_argument('--cal_flops', action='store_true', help='whether calculate and record op flops.')\n    parser.add_argument('--cal_activations', action='store_true', help='whether calculate and record op activations.')\n    parser.add_argument('--logging_to_stdout', action='store_true', help='whether print all calculated statistic details.')\n    parser.add_argument('--all', action='store_true', help=\"whether print all stats. Tensorboard logs will be placed in './log' if not specified.\")\n    args = parser.parse_args()\n    if args.load_input_data:\n        logger.info('load data from {}'.format(args.load_input_data))\n        data = mge.load(args.load_input_data)\n        if isinstance(data, dict):\n            for v in data.values():\n                assert isinstance(v, np.ndarray), 'data should provide ndarray; got {} instead'.format(v)\n            args.inp_dict = data\n        elif isinstance(data, np.ndarray):\n            args.input = data\n        else:\n            logger.error('input data should be a numpy array or a dict of numpy array')\n    if args.all:\n        args.cal_params = True\n        args.cal_flops = True\n        args.cal_activations = True\n        args.logging_to_stdout = True\n        if not args.log_path:\n            args.log_path = './log'\n    kwargs = vars(args)\n    kwargs.pop('all')\n    kwargs.pop('load_input_data')\n    visualize(**kwargs)",
            "def main():\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    parser = argparse.ArgumentParser(description='load a megengine dumped model and export log file for tensorboard visualization.', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument('model_path', help='dumped model path.')\n    parser.add_argument('--log_path', help='tensorboard log path.')\n    parser.add_argument('--load_input_data', help='load input data from pickle file; it should be a numpy array or a dict of numpy array')\n    parser.add_argument('--bar_length_max', type=int, default=20, help='size of bar indicating max flops or parameter size in net stats.')\n    parser.add_argument('--cal_params', action='store_true', help='whether calculate and record params size.')\n    parser.add_argument('--cal_flops', action='store_true', help='whether calculate and record op flops.')\n    parser.add_argument('--cal_activations', action='store_true', help='whether calculate and record op activations.')\n    parser.add_argument('--logging_to_stdout', action='store_true', help='whether print all calculated statistic details.')\n    parser.add_argument('--all', action='store_true', help=\"whether print all stats. Tensorboard logs will be placed in './log' if not specified.\")\n    args = parser.parse_args()\n    if args.load_input_data:\n        logger.info('load data from {}'.format(args.load_input_data))\n        data = mge.load(args.load_input_data)\n        if isinstance(data, dict):\n            for v in data.values():\n                assert isinstance(v, np.ndarray), 'data should provide ndarray; got {} instead'.format(v)\n            args.inp_dict = data\n        elif isinstance(data, np.ndarray):\n            args.input = data\n        else:\n            logger.error('input data should be a numpy array or a dict of numpy array')\n    if args.all:\n        args.cal_params = True\n        args.cal_flops = True\n        args.cal_activations = True\n        args.logging_to_stdout = True\n        if not args.log_path:\n            args.log_path = './log'\n    kwargs = vars(args)\n    kwargs.pop('all')\n    kwargs.pop('load_input_data')\n    visualize(**kwargs)"
        ]
    }
]