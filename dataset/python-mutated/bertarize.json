[
    {
        "func_name": "main",
        "original": "def main(args):\n    pruning_method = args.pruning_method\n    threshold = args.threshold\n    model_name_or_path = args.model_name_or_path.rstrip('/')\n    target_model_path = args.target_model_path\n    print(f'Load fine-pruned model from {model_name_or_path}')\n    model = torch.load(os.path.join(model_name_or_path, 'pytorch_model.bin'))\n    pruned_model = {}\n    for (name, tensor) in model.items():\n        if 'embeddings' in name or 'LayerNorm' in name or 'pooler' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif 'classifier' in name or 'qa_output' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif 'bias' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif pruning_method == 'magnitude':\n            mask = MagnitudeBinarizer.apply(inputs=tensor, threshold=threshold)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'topK':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            mask = TopKBinarizer.apply(scores, threshold)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'sigmoied_threshold':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            mask = ThresholdBinarizer.apply(scores, threshold, True)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'l0':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            (l, r) = (-0.1, 1.1)\n            s = torch.sigmoid(scores)\n            s_bar = s * (r - l) + l\n            mask = s_bar.clamp(min=0.0, max=1.0)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        else:\n            raise ValueError('Unknown pruning method')\n    if target_model_path is None:\n        target_model_path = os.path.join(os.path.dirname(model_name_or_path), f'bertarized_{os.path.basename(model_name_or_path)}')\n    if not os.path.isdir(target_model_path):\n        shutil.copytree(model_name_or_path, target_model_path)\n        print(f'\\nCreated folder {target_model_path}')\n    torch.save(pruned_model, os.path.join(target_model_path, 'pytorch_model.bin'))\n    print('\\nPruned model saved! See you later!')",
        "mutated": [
            "def main(args):\n    if False:\n        i = 10\n    pruning_method = args.pruning_method\n    threshold = args.threshold\n    model_name_or_path = args.model_name_or_path.rstrip('/')\n    target_model_path = args.target_model_path\n    print(f'Load fine-pruned model from {model_name_or_path}')\n    model = torch.load(os.path.join(model_name_or_path, 'pytorch_model.bin'))\n    pruned_model = {}\n    for (name, tensor) in model.items():\n        if 'embeddings' in name or 'LayerNorm' in name or 'pooler' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif 'classifier' in name or 'qa_output' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif 'bias' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif pruning_method == 'magnitude':\n            mask = MagnitudeBinarizer.apply(inputs=tensor, threshold=threshold)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'topK':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            mask = TopKBinarizer.apply(scores, threshold)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'sigmoied_threshold':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            mask = ThresholdBinarizer.apply(scores, threshold, True)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'l0':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            (l, r) = (-0.1, 1.1)\n            s = torch.sigmoid(scores)\n            s_bar = s * (r - l) + l\n            mask = s_bar.clamp(min=0.0, max=1.0)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        else:\n            raise ValueError('Unknown pruning method')\n    if target_model_path is None:\n        target_model_path = os.path.join(os.path.dirname(model_name_or_path), f'bertarized_{os.path.basename(model_name_or_path)}')\n    if not os.path.isdir(target_model_path):\n        shutil.copytree(model_name_or_path, target_model_path)\n        print(f'\\nCreated folder {target_model_path}')\n    torch.save(pruned_model, os.path.join(target_model_path, 'pytorch_model.bin'))\n    print('\\nPruned model saved! See you later!')",
            "def main(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    pruning_method = args.pruning_method\n    threshold = args.threshold\n    model_name_or_path = args.model_name_or_path.rstrip('/')\n    target_model_path = args.target_model_path\n    print(f'Load fine-pruned model from {model_name_or_path}')\n    model = torch.load(os.path.join(model_name_or_path, 'pytorch_model.bin'))\n    pruned_model = {}\n    for (name, tensor) in model.items():\n        if 'embeddings' in name or 'LayerNorm' in name or 'pooler' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif 'classifier' in name or 'qa_output' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif 'bias' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif pruning_method == 'magnitude':\n            mask = MagnitudeBinarizer.apply(inputs=tensor, threshold=threshold)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'topK':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            mask = TopKBinarizer.apply(scores, threshold)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'sigmoied_threshold':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            mask = ThresholdBinarizer.apply(scores, threshold, True)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'l0':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            (l, r) = (-0.1, 1.1)\n            s = torch.sigmoid(scores)\n            s_bar = s * (r - l) + l\n            mask = s_bar.clamp(min=0.0, max=1.0)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        else:\n            raise ValueError('Unknown pruning method')\n    if target_model_path is None:\n        target_model_path = os.path.join(os.path.dirname(model_name_or_path), f'bertarized_{os.path.basename(model_name_or_path)}')\n    if not os.path.isdir(target_model_path):\n        shutil.copytree(model_name_or_path, target_model_path)\n        print(f'\\nCreated folder {target_model_path}')\n    torch.save(pruned_model, os.path.join(target_model_path, 'pytorch_model.bin'))\n    print('\\nPruned model saved! See you later!')",
            "def main(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    pruning_method = args.pruning_method\n    threshold = args.threshold\n    model_name_or_path = args.model_name_or_path.rstrip('/')\n    target_model_path = args.target_model_path\n    print(f'Load fine-pruned model from {model_name_or_path}')\n    model = torch.load(os.path.join(model_name_or_path, 'pytorch_model.bin'))\n    pruned_model = {}\n    for (name, tensor) in model.items():\n        if 'embeddings' in name or 'LayerNorm' in name or 'pooler' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif 'classifier' in name or 'qa_output' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif 'bias' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif pruning_method == 'magnitude':\n            mask = MagnitudeBinarizer.apply(inputs=tensor, threshold=threshold)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'topK':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            mask = TopKBinarizer.apply(scores, threshold)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'sigmoied_threshold':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            mask = ThresholdBinarizer.apply(scores, threshold, True)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'l0':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            (l, r) = (-0.1, 1.1)\n            s = torch.sigmoid(scores)\n            s_bar = s * (r - l) + l\n            mask = s_bar.clamp(min=0.0, max=1.0)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        else:\n            raise ValueError('Unknown pruning method')\n    if target_model_path is None:\n        target_model_path = os.path.join(os.path.dirname(model_name_or_path), f'bertarized_{os.path.basename(model_name_or_path)}')\n    if not os.path.isdir(target_model_path):\n        shutil.copytree(model_name_or_path, target_model_path)\n        print(f'\\nCreated folder {target_model_path}')\n    torch.save(pruned_model, os.path.join(target_model_path, 'pytorch_model.bin'))\n    print('\\nPruned model saved! See you later!')",
            "def main(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    pruning_method = args.pruning_method\n    threshold = args.threshold\n    model_name_or_path = args.model_name_or_path.rstrip('/')\n    target_model_path = args.target_model_path\n    print(f'Load fine-pruned model from {model_name_or_path}')\n    model = torch.load(os.path.join(model_name_or_path, 'pytorch_model.bin'))\n    pruned_model = {}\n    for (name, tensor) in model.items():\n        if 'embeddings' in name or 'LayerNorm' in name or 'pooler' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif 'classifier' in name or 'qa_output' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif 'bias' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif pruning_method == 'magnitude':\n            mask = MagnitudeBinarizer.apply(inputs=tensor, threshold=threshold)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'topK':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            mask = TopKBinarizer.apply(scores, threshold)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'sigmoied_threshold':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            mask = ThresholdBinarizer.apply(scores, threshold, True)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'l0':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            (l, r) = (-0.1, 1.1)\n            s = torch.sigmoid(scores)\n            s_bar = s * (r - l) + l\n            mask = s_bar.clamp(min=0.0, max=1.0)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        else:\n            raise ValueError('Unknown pruning method')\n    if target_model_path is None:\n        target_model_path = os.path.join(os.path.dirname(model_name_or_path), f'bertarized_{os.path.basename(model_name_or_path)}')\n    if not os.path.isdir(target_model_path):\n        shutil.copytree(model_name_or_path, target_model_path)\n        print(f'\\nCreated folder {target_model_path}')\n    torch.save(pruned_model, os.path.join(target_model_path, 'pytorch_model.bin'))\n    print('\\nPruned model saved! See you later!')",
            "def main(args):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    pruning_method = args.pruning_method\n    threshold = args.threshold\n    model_name_or_path = args.model_name_or_path.rstrip('/')\n    target_model_path = args.target_model_path\n    print(f'Load fine-pruned model from {model_name_or_path}')\n    model = torch.load(os.path.join(model_name_or_path, 'pytorch_model.bin'))\n    pruned_model = {}\n    for (name, tensor) in model.items():\n        if 'embeddings' in name or 'LayerNorm' in name or 'pooler' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif 'classifier' in name or 'qa_output' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif 'bias' in name:\n            pruned_model[name] = tensor\n            print(f'Copied layer {name}')\n        elif pruning_method == 'magnitude':\n            mask = MagnitudeBinarizer.apply(inputs=tensor, threshold=threshold)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'topK':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            mask = TopKBinarizer.apply(scores, threshold)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'sigmoied_threshold':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            mask = ThresholdBinarizer.apply(scores, threshold, True)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        elif pruning_method == 'l0':\n            if 'mask_scores' in name:\n                continue\n            prefix_ = name[:-6]\n            scores = model[f'{prefix_}mask_scores']\n            (l, r) = (-0.1, 1.1)\n            s = torch.sigmoid(scores)\n            s_bar = s * (r - l) + l\n            mask = s_bar.clamp(min=0.0, max=1.0)\n            pruned_model[name] = tensor * mask\n            print(f'Pruned layer {name}')\n        else:\n            raise ValueError('Unknown pruning method')\n    if target_model_path is None:\n        target_model_path = os.path.join(os.path.dirname(model_name_or_path), f'bertarized_{os.path.basename(model_name_or_path)}')\n    if not os.path.isdir(target_model_path):\n        shutil.copytree(model_name_or_path, target_model_path)\n        print(f'\\nCreated folder {target_model_path}')\n    torch.save(pruned_model, os.path.join(target_model_path, 'pytorch_model.bin'))\n    print('\\nPruned model saved! See you later!')"
        ]
    }
]