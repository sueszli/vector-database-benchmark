[
    {
        "func_name": "__init__",
        "original": "def __init__(self, batch_size, batch, state_size, nlayers, out_features):\n    \"\"\"\n        Coordinator object to run on worker.  Only one coordinator exists.  Responsible\n        for facilitating communication between agent and observers and recording benchmark\n        throughput and latency data.\n        Args:\n            batch_size (int): Number of observer requests to process in a batch\n            batch (bool): Whether to process and respond to observer requests as a batch or 1 at a time\n            state_size (list): List of ints dictating the dimensions of the state\n            nlayers (int): Number of layers in the model\n            out_features (int): Number of out features in the model\n        \"\"\"\n    self.batch_size = batch_size\n    self.batch = batch\n    self.agent_rref = None\n    self.ob_rrefs = []\n    agent_info = rpc.get_worker_info(AGENT_NAME)\n    self.agent_rref = rpc.remote(agent_info, AgentBase)\n    for rank in range(batch_size):\n        ob_info = rpc.get_worker_info(OBSERVER_NAME.format(rank + 2))\n        ob_ref = rpc.remote(ob_info, ObserverBase)\n        self.ob_rrefs.append(ob_ref)\n        ob_ref.rpc_sync().set_state(state_size, batch)\n    self.agent_rref.rpc_sync().set_world(batch_size, state_size, nlayers, out_features, self.batch)",
        "mutated": [
            "def __init__(self, batch_size, batch, state_size, nlayers, out_features):\n    if False:\n        i = 10\n    '\\n        Coordinator object to run on worker.  Only one coordinator exists.  Responsible\\n        for facilitating communication between agent and observers and recording benchmark\\n        throughput and latency data.\\n        Args:\\n            batch_size (int): Number of observer requests to process in a batch\\n            batch (bool): Whether to process and respond to observer requests as a batch or 1 at a time\\n            state_size (list): List of ints dictating the dimensions of the state\\n            nlayers (int): Number of layers in the model\\n            out_features (int): Number of out features in the model\\n        '\n    self.batch_size = batch_size\n    self.batch = batch\n    self.agent_rref = None\n    self.ob_rrefs = []\n    agent_info = rpc.get_worker_info(AGENT_NAME)\n    self.agent_rref = rpc.remote(agent_info, AgentBase)\n    for rank in range(batch_size):\n        ob_info = rpc.get_worker_info(OBSERVER_NAME.format(rank + 2))\n        ob_ref = rpc.remote(ob_info, ObserverBase)\n        self.ob_rrefs.append(ob_ref)\n        ob_ref.rpc_sync().set_state(state_size, batch)\n    self.agent_rref.rpc_sync().set_world(batch_size, state_size, nlayers, out_features, self.batch)",
            "def __init__(self, batch_size, batch, state_size, nlayers, out_features):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Coordinator object to run on worker.  Only one coordinator exists.  Responsible\\n        for facilitating communication between agent and observers and recording benchmark\\n        throughput and latency data.\\n        Args:\\n            batch_size (int): Number of observer requests to process in a batch\\n            batch (bool): Whether to process and respond to observer requests as a batch or 1 at a time\\n            state_size (list): List of ints dictating the dimensions of the state\\n            nlayers (int): Number of layers in the model\\n            out_features (int): Number of out features in the model\\n        '\n    self.batch_size = batch_size\n    self.batch = batch\n    self.agent_rref = None\n    self.ob_rrefs = []\n    agent_info = rpc.get_worker_info(AGENT_NAME)\n    self.agent_rref = rpc.remote(agent_info, AgentBase)\n    for rank in range(batch_size):\n        ob_info = rpc.get_worker_info(OBSERVER_NAME.format(rank + 2))\n        ob_ref = rpc.remote(ob_info, ObserverBase)\n        self.ob_rrefs.append(ob_ref)\n        ob_ref.rpc_sync().set_state(state_size, batch)\n    self.agent_rref.rpc_sync().set_world(batch_size, state_size, nlayers, out_features, self.batch)",
            "def __init__(self, batch_size, batch, state_size, nlayers, out_features):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Coordinator object to run on worker.  Only one coordinator exists.  Responsible\\n        for facilitating communication between agent and observers and recording benchmark\\n        throughput and latency data.\\n        Args:\\n            batch_size (int): Number of observer requests to process in a batch\\n            batch (bool): Whether to process and respond to observer requests as a batch or 1 at a time\\n            state_size (list): List of ints dictating the dimensions of the state\\n            nlayers (int): Number of layers in the model\\n            out_features (int): Number of out features in the model\\n        '\n    self.batch_size = batch_size\n    self.batch = batch\n    self.agent_rref = None\n    self.ob_rrefs = []\n    agent_info = rpc.get_worker_info(AGENT_NAME)\n    self.agent_rref = rpc.remote(agent_info, AgentBase)\n    for rank in range(batch_size):\n        ob_info = rpc.get_worker_info(OBSERVER_NAME.format(rank + 2))\n        ob_ref = rpc.remote(ob_info, ObserverBase)\n        self.ob_rrefs.append(ob_ref)\n        ob_ref.rpc_sync().set_state(state_size, batch)\n    self.agent_rref.rpc_sync().set_world(batch_size, state_size, nlayers, out_features, self.batch)",
            "def __init__(self, batch_size, batch, state_size, nlayers, out_features):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Coordinator object to run on worker.  Only one coordinator exists.  Responsible\\n        for facilitating communication between agent and observers and recording benchmark\\n        throughput and latency data.\\n        Args:\\n            batch_size (int): Number of observer requests to process in a batch\\n            batch (bool): Whether to process and respond to observer requests as a batch or 1 at a time\\n            state_size (list): List of ints dictating the dimensions of the state\\n            nlayers (int): Number of layers in the model\\n            out_features (int): Number of out features in the model\\n        '\n    self.batch_size = batch_size\n    self.batch = batch\n    self.agent_rref = None\n    self.ob_rrefs = []\n    agent_info = rpc.get_worker_info(AGENT_NAME)\n    self.agent_rref = rpc.remote(agent_info, AgentBase)\n    for rank in range(batch_size):\n        ob_info = rpc.get_worker_info(OBSERVER_NAME.format(rank + 2))\n        ob_ref = rpc.remote(ob_info, ObserverBase)\n        self.ob_rrefs.append(ob_ref)\n        ob_ref.rpc_sync().set_state(state_size, batch)\n    self.agent_rref.rpc_sync().set_world(batch_size, state_size, nlayers, out_features, self.batch)",
            "def __init__(self, batch_size, batch, state_size, nlayers, out_features):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Coordinator object to run on worker.  Only one coordinator exists.  Responsible\\n        for facilitating communication between agent and observers and recording benchmark\\n        throughput and latency data.\\n        Args:\\n            batch_size (int): Number of observer requests to process in a batch\\n            batch (bool): Whether to process and respond to observer requests as a batch or 1 at a time\\n            state_size (list): List of ints dictating the dimensions of the state\\n            nlayers (int): Number of layers in the model\\n            out_features (int): Number of out features in the model\\n        '\n    self.batch_size = batch_size\n    self.batch = batch\n    self.agent_rref = None\n    self.ob_rrefs = []\n    agent_info = rpc.get_worker_info(AGENT_NAME)\n    self.agent_rref = rpc.remote(agent_info, AgentBase)\n    for rank in range(batch_size):\n        ob_info = rpc.get_worker_info(OBSERVER_NAME.format(rank + 2))\n        ob_ref = rpc.remote(ob_info, ObserverBase)\n        self.ob_rrefs.append(ob_ref)\n        ob_ref.rpc_sync().set_state(state_size, batch)\n    self.agent_rref.rpc_sync().set_world(batch_size, state_size, nlayers, out_features, self.batch)"
        ]
    },
    {
        "func_name": "run_coordinator",
        "original": "def run_coordinator(self, episodes, episode_steps, queue):\n    \"\"\"\n        Runs n benchmark episodes.  Each episode is started by coordinator telling each\n        observer to contact the agent.  Each episode is concluded by coordinator telling agent\n        to finish the episode, and then the coordinator records benchmark data\n        Args:\n            episodes (int): Number of episodes to run\n            episode_steps (int): Number steps to be run in each episdoe by each observer\n            queue (SimpleQueue): SimpleQueue from torch.multiprocessing.get_context() for\n                                 saving benchmark run results to\n        \"\"\"\n    agent_latency_final = []\n    agent_throughput_final = []\n    observer_latency_final = []\n    observer_throughput_final = []\n    for ep in range(episodes):\n        ep_start_time = time.time()\n        print(f'Episode {ep} - ', end='')\n        n_steps = episode_steps\n        agent_start_time = time.time()\n        futs = []\n        for ob_rref in self.ob_rrefs:\n            futs.append(ob_rref.rpc_async().run_ob_episode(self.agent_rref, n_steps))\n        rets = torch.futures.wait_all(futs)\n        (agent_latency, agent_throughput) = self.agent_rref.rpc_sync().finish_episode(rets)\n        self.agent_rref.rpc_sync().reset_metrics()\n        agent_latency_final += agent_latency\n        agent_throughput_final += agent_throughput\n        observer_latency_final += [ret[2] for ret in rets]\n        observer_throughput_final += [ret[3] for ret in rets]\n        ep_end_time = time.time()\n        episode_time = ep_end_time - ep_start_time\n        print(round(episode_time, 3))\n    observer_latency_final = [t for s in observer_latency_final for t in s]\n    observer_throughput_final = [t for s in observer_throughput_final for t in s]\n    benchmark_metrics = {'agent latency (seconds)': {}, 'agent throughput': {}, 'observer latency (seconds)': {}, 'observer throughput': {}}\n    print(f'For batch size {self.batch_size}')\n    print('\\nAgent Latency - ', len(agent_latency_final))\n    agent_latency_final = sorted(agent_latency_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(agent_latency_final, p)\n        print('p' + str(p) + ':', round(v, 3))\n        p = f'p{p}'\n        benchmark_metrics['agent latency (seconds)'][p] = round(v, 3)\n    print('\\nAgent Throughput - ', len(agent_throughput_final))\n    agent_throughput_final = sorted(agent_throughput_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(agent_throughput_final, p)\n        print('p' + str(p) + ':', int(v))\n        p = f'p{p}'\n        benchmark_metrics['agent throughput'][p] = int(v)\n    print('\\nObserver Latency - ', len(observer_latency_final))\n    observer_latency_final = sorted(observer_latency_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(observer_latency_final, p)\n        print('p' + str(p) + ':', round(v, 3))\n        p = f'p{p}'\n        benchmark_metrics['observer latency (seconds)'][p] = round(v, 3)\n    print('\\nObserver Throughput - ', len(observer_throughput_final))\n    observer_throughput_final = sorted(observer_throughput_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(observer_throughput_final, p)\n        print('p' + str(p) + ':', int(v))\n        p = f'p{p}'\n        benchmark_metrics['observer throughput'][p] = int(v)\n    if queue:\n        queue.put(benchmark_metrics)",
        "mutated": [
            "def run_coordinator(self, episodes, episode_steps, queue):\n    if False:\n        i = 10\n    '\\n        Runs n benchmark episodes.  Each episode is started by coordinator telling each\\n        observer to contact the agent.  Each episode is concluded by coordinator telling agent\\n        to finish the episode, and then the coordinator records benchmark data\\n        Args:\\n            episodes (int): Number of episodes to run\\n            episode_steps (int): Number steps to be run in each episdoe by each observer\\n            queue (SimpleQueue): SimpleQueue from torch.multiprocessing.get_context() for\\n                                 saving benchmark run results to\\n        '\n    agent_latency_final = []\n    agent_throughput_final = []\n    observer_latency_final = []\n    observer_throughput_final = []\n    for ep in range(episodes):\n        ep_start_time = time.time()\n        print(f'Episode {ep} - ', end='')\n        n_steps = episode_steps\n        agent_start_time = time.time()\n        futs = []\n        for ob_rref in self.ob_rrefs:\n            futs.append(ob_rref.rpc_async().run_ob_episode(self.agent_rref, n_steps))\n        rets = torch.futures.wait_all(futs)\n        (agent_latency, agent_throughput) = self.agent_rref.rpc_sync().finish_episode(rets)\n        self.agent_rref.rpc_sync().reset_metrics()\n        agent_latency_final += agent_latency\n        agent_throughput_final += agent_throughput\n        observer_latency_final += [ret[2] for ret in rets]\n        observer_throughput_final += [ret[3] for ret in rets]\n        ep_end_time = time.time()\n        episode_time = ep_end_time - ep_start_time\n        print(round(episode_time, 3))\n    observer_latency_final = [t for s in observer_latency_final for t in s]\n    observer_throughput_final = [t for s in observer_throughput_final for t in s]\n    benchmark_metrics = {'agent latency (seconds)': {}, 'agent throughput': {}, 'observer latency (seconds)': {}, 'observer throughput': {}}\n    print(f'For batch size {self.batch_size}')\n    print('\\nAgent Latency - ', len(agent_latency_final))\n    agent_latency_final = sorted(agent_latency_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(agent_latency_final, p)\n        print('p' + str(p) + ':', round(v, 3))\n        p = f'p{p}'\n        benchmark_metrics['agent latency (seconds)'][p] = round(v, 3)\n    print('\\nAgent Throughput - ', len(agent_throughput_final))\n    agent_throughput_final = sorted(agent_throughput_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(agent_throughput_final, p)\n        print('p' + str(p) + ':', int(v))\n        p = f'p{p}'\n        benchmark_metrics['agent throughput'][p] = int(v)\n    print('\\nObserver Latency - ', len(observer_latency_final))\n    observer_latency_final = sorted(observer_latency_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(observer_latency_final, p)\n        print('p' + str(p) + ':', round(v, 3))\n        p = f'p{p}'\n        benchmark_metrics['observer latency (seconds)'][p] = round(v, 3)\n    print('\\nObserver Throughput - ', len(observer_throughput_final))\n    observer_throughput_final = sorted(observer_throughput_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(observer_throughput_final, p)\n        print('p' + str(p) + ':', int(v))\n        p = f'p{p}'\n        benchmark_metrics['observer throughput'][p] = int(v)\n    if queue:\n        queue.put(benchmark_metrics)",
            "def run_coordinator(self, episodes, episode_steps, queue):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        Runs n benchmark episodes.  Each episode is started by coordinator telling each\\n        observer to contact the agent.  Each episode is concluded by coordinator telling agent\\n        to finish the episode, and then the coordinator records benchmark data\\n        Args:\\n            episodes (int): Number of episodes to run\\n            episode_steps (int): Number steps to be run in each episdoe by each observer\\n            queue (SimpleQueue): SimpleQueue from torch.multiprocessing.get_context() for\\n                                 saving benchmark run results to\\n        '\n    agent_latency_final = []\n    agent_throughput_final = []\n    observer_latency_final = []\n    observer_throughput_final = []\n    for ep in range(episodes):\n        ep_start_time = time.time()\n        print(f'Episode {ep} - ', end='')\n        n_steps = episode_steps\n        agent_start_time = time.time()\n        futs = []\n        for ob_rref in self.ob_rrefs:\n            futs.append(ob_rref.rpc_async().run_ob_episode(self.agent_rref, n_steps))\n        rets = torch.futures.wait_all(futs)\n        (agent_latency, agent_throughput) = self.agent_rref.rpc_sync().finish_episode(rets)\n        self.agent_rref.rpc_sync().reset_metrics()\n        agent_latency_final += agent_latency\n        agent_throughput_final += agent_throughput\n        observer_latency_final += [ret[2] for ret in rets]\n        observer_throughput_final += [ret[3] for ret in rets]\n        ep_end_time = time.time()\n        episode_time = ep_end_time - ep_start_time\n        print(round(episode_time, 3))\n    observer_latency_final = [t for s in observer_latency_final for t in s]\n    observer_throughput_final = [t for s in observer_throughput_final for t in s]\n    benchmark_metrics = {'agent latency (seconds)': {}, 'agent throughput': {}, 'observer latency (seconds)': {}, 'observer throughput': {}}\n    print(f'For batch size {self.batch_size}')\n    print('\\nAgent Latency - ', len(agent_latency_final))\n    agent_latency_final = sorted(agent_latency_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(agent_latency_final, p)\n        print('p' + str(p) + ':', round(v, 3))\n        p = f'p{p}'\n        benchmark_metrics['agent latency (seconds)'][p] = round(v, 3)\n    print('\\nAgent Throughput - ', len(agent_throughput_final))\n    agent_throughput_final = sorted(agent_throughput_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(agent_throughput_final, p)\n        print('p' + str(p) + ':', int(v))\n        p = f'p{p}'\n        benchmark_metrics['agent throughput'][p] = int(v)\n    print('\\nObserver Latency - ', len(observer_latency_final))\n    observer_latency_final = sorted(observer_latency_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(observer_latency_final, p)\n        print('p' + str(p) + ':', round(v, 3))\n        p = f'p{p}'\n        benchmark_metrics['observer latency (seconds)'][p] = round(v, 3)\n    print('\\nObserver Throughput - ', len(observer_throughput_final))\n    observer_throughput_final = sorted(observer_throughput_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(observer_throughput_final, p)\n        print('p' + str(p) + ':', int(v))\n        p = f'p{p}'\n        benchmark_metrics['observer throughput'][p] = int(v)\n    if queue:\n        queue.put(benchmark_metrics)",
            "def run_coordinator(self, episodes, episode_steps, queue):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        Runs n benchmark episodes.  Each episode is started by coordinator telling each\\n        observer to contact the agent.  Each episode is concluded by coordinator telling agent\\n        to finish the episode, and then the coordinator records benchmark data\\n        Args:\\n            episodes (int): Number of episodes to run\\n            episode_steps (int): Number steps to be run in each episdoe by each observer\\n            queue (SimpleQueue): SimpleQueue from torch.multiprocessing.get_context() for\\n                                 saving benchmark run results to\\n        '\n    agent_latency_final = []\n    agent_throughput_final = []\n    observer_latency_final = []\n    observer_throughput_final = []\n    for ep in range(episodes):\n        ep_start_time = time.time()\n        print(f'Episode {ep} - ', end='')\n        n_steps = episode_steps\n        agent_start_time = time.time()\n        futs = []\n        for ob_rref in self.ob_rrefs:\n            futs.append(ob_rref.rpc_async().run_ob_episode(self.agent_rref, n_steps))\n        rets = torch.futures.wait_all(futs)\n        (agent_latency, agent_throughput) = self.agent_rref.rpc_sync().finish_episode(rets)\n        self.agent_rref.rpc_sync().reset_metrics()\n        agent_latency_final += agent_latency\n        agent_throughput_final += agent_throughput\n        observer_latency_final += [ret[2] for ret in rets]\n        observer_throughput_final += [ret[3] for ret in rets]\n        ep_end_time = time.time()\n        episode_time = ep_end_time - ep_start_time\n        print(round(episode_time, 3))\n    observer_latency_final = [t for s in observer_latency_final for t in s]\n    observer_throughput_final = [t for s in observer_throughput_final for t in s]\n    benchmark_metrics = {'agent latency (seconds)': {}, 'agent throughput': {}, 'observer latency (seconds)': {}, 'observer throughput': {}}\n    print(f'For batch size {self.batch_size}')\n    print('\\nAgent Latency - ', len(agent_latency_final))\n    agent_latency_final = sorted(agent_latency_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(agent_latency_final, p)\n        print('p' + str(p) + ':', round(v, 3))\n        p = f'p{p}'\n        benchmark_metrics['agent latency (seconds)'][p] = round(v, 3)\n    print('\\nAgent Throughput - ', len(agent_throughput_final))\n    agent_throughput_final = sorted(agent_throughput_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(agent_throughput_final, p)\n        print('p' + str(p) + ':', int(v))\n        p = f'p{p}'\n        benchmark_metrics['agent throughput'][p] = int(v)\n    print('\\nObserver Latency - ', len(observer_latency_final))\n    observer_latency_final = sorted(observer_latency_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(observer_latency_final, p)\n        print('p' + str(p) + ':', round(v, 3))\n        p = f'p{p}'\n        benchmark_metrics['observer latency (seconds)'][p] = round(v, 3)\n    print('\\nObserver Throughput - ', len(observer_throughput_final))\n    observer_throughput_final = sorted(observer_throughput_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(observer_throughput_final, p)\n        print('p' + str(p) + ':', int(v))\n        p = f'p{p}'\n        benchmark_metrics['observer throughput'][p] = int(v)\n    if queue:\n        queue.put(benchmark_metrics)",
            "def run_coordinator(self, episodes, episode_steps, queue):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        Runs n benchmark episodes.  Each episode is started by coordinator telling each\\n        observer to contact the agent.  Each episode is concluded by coordinator telling agent\\n        to finish the episode, and then the coordinator records benchmark data\\n        Args:\\n            episodes (int): Number of episodes to run\\n            episode_steps (int): Number steps to be run in each episdoe by each observer\\n            queue (SimpleQueue): SimpleQueue from torch.multiprocessing.get_context() for\\n                                 saving benchmark run results to\\n        '\n    agent_latency_final = []\n    agent_throughput_final = []\n    observer_latency_final = []\n    observer_throughput_final = []\n    for ep in range(episodes):\n        ep_start_time = time.time()\n        print(f'Episode {ep} - ', end='')\n        n_steps = episode_steps\n        agent_start_time = time.time()\n        futs = []\n        for ob_rref in self.ob_rrefs:\n            futs.append(ob_rref.rpc_async().run_ob_episode(self.agent_rref, n_steps))\n        rets = torch.futures.wait_all(futs)\n        (agent_latency, agent_throughput) = self.agent_rref.rpc_sync().finish_episode(rets)\n        self.agent_rref.rpc_sync().reset_metrics()\n        agent_latency_final += agent_latency\n        agent_throughput_final += agent_throughput\n        observer_latency_final += [ret[2] for ret in rets]\n        observer_throughput_final += [ret[3] for ret in rets]\n        ep_end_time = time.time()\n        episode_time = ep_end_time - ep_start_time\n        print(round(episode_time, 3))\n    observer_latency_final = [t for s in observer_latency_final for t in s]\n    observer_throughput_final = [t for s in observer_throughput_final for t in s]\n    benchmark_metrics = {'agent latency (seconds)': {}, 'agent throughput': {}, 'observer latency (seconds)': {}, 'observer throughput': {}}\n    print(f'For batch size {self.batch_size}')\n    print('\\nAgent Latency - ', len(agent_latency_final))\n    agent_latency_final = sorted(agent_latency_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(agent_latency_final, p)\n        print('p' + str(p) + ':', round(v, 3))\n        p = f'p{p}'\n        benchmark_metrics['agent latency (seconds)'][p] = round(v, 3)\n    print('\\nAgent Throughput - ', len(agent_throughput_final))\n    agent_throughput_final = sorted(agent_throughput_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(agent_throughput_final, p)\n        print('p' + str(p) + ':', int(v))\n        p = f'p{p}'\n        benchmark_metrics['agent throughput'][p] = int(v)\n    print('\\nObserver Latency - ', len(observer_latency_final))\n    observer_latency_final = sorted(observer_latency_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(observer_latency_final, p)\n        print('p' + str(p) + ':', round(v, 3))\n        p = f'p{p}'\n        benchmark_metrics['observer latency (seconds)'][p] = round(v, 3)\n    print('\\nObserver Throughput - ', len(observer_throughput_final))\n    observer_throughput_final = sorted(observer_throughput_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(observer_throughput_final, p)\n        print('p' + str(p) + ':', int(v))\n        p = f'p{p}'\n        benchmark_metrics['observer throughput'][p] = int(v)\n    if queue:\n        queue.put(benchmark_metrics)",
            "def run_coordinator(self, episodes, episode_steps, queue):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        Runs n benchmark episodes.  Each episode is started by coordinator telling each\\n        observer to contact the agent.  Each episode is concluded by coordinator telling agent\\n        to finish the episode, and then the coordinator records benchmark data\\n        Args:\\n            episodes (int): Number of episodes to run\\n            episode_steps (int): Number steps to be run in each episdoe by each observer\\n            queue (SimpleQueue): SimpleQueue from torch.multiprocessing.get_context() for\\n                                 saving benchmark run results to\\n        '\n    agent_latency_final = []\n    agent_throughput_final = []\n    observer_latency_final = []\n    observer_throughput_final = []\n    for ep in range(episodes):\n        ep_start_time = time.time()\n        print(f'Episode {ep} - ', end='')\n        n_steps = episode_steps\n        agent_start_time = time.time()\n        futs = []\n        for ob_rref in self.ob_rrefs:\n            futs.append(ob_rref.rpc_async().run_ob_episode(self.agent_rref, n_steps))\n        rets = torch.futures.wait_all(futs)\n        (agent_latency, agent_throughput) = self.agent_rref.rpc_sync().finish_episode(rets)\n        self.agent_rref.rpc_sync().reset_metrics()\n        agent_latency_final += agent_latency\n        agent_throughput_final += agent_throughput\n        observer_latency_final += [ret[2] for ret in rets]\n        observer_throughput_final += [ret[3] for ret in rets]\n        ep_end_time = time.time()\n        episode_time = ep_end_time - ep_start_time\n        print(round(episode_time, 3))\n    observer_latency_final = [t for s in observer_latency_final for t in s]\n    observer_throughput_final = [t for s in observer_throughput_final for t in s]\n    benchmark_metrics = {'agent latency (seconds)': {}, 'agent throughput': {}, 'observer latency (seconds)': {}, 'observer throughput': {}}\n    print(f'For batch size {self.batch_size}')\n    print('\\nAgent Latency - ', len(agent_latency_final))\n    agent_latency_final = sorted(agent_latency_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(agent_latency_final, p)\n        print('p' + str(p) + ':', round(v, 3))\n        p = f'p{p}'\n        benchmark_metrics['agent latency (seconds)'][p] = round(v, 3)\n    print('\\nAgent Throughput - ', len(agent_throughput_final))\n    agent_throughput_final = sorted(agent_throughput_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(agent_throughput_final, p)\n        print('p' + str(p) + ':', int(v))\n        p = f'p{p}'\n        benchmark_metrics['agent throughput'][p] = int(v)\n    print('\\nObserver Latency - ', len(observer_latency_final))\n    observer_latency_final = sorted(observer_latency_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(observer_latency_final, p)\n        print('p' + str(p) + ':', round(v, 3))\n        p = f'p{p}'\n        benchmark_metrics['observer latency (seconds)'][p] = round(v, 3)\n    print('\\nObserver Throughput - ', len(observer_throughput_final))\n    observer_throughput_final = sorted(observer_throughput_final)\n    for p in [50, 75, 90, 95]:\n        v = np.percentile(observer_throughput_final, p)\n        print('p' + str(p) + ':', int(v))\n        p = f'p{p}'\n        benchmark_metrics['observer throughput'][p] = int(v)\n    if queue:\n        queue.put(benchmark_metrics)"
        ]
    }
]