[
    {
        "func_name": "FakeQuantization8BitsRowwise",
        "original": "def FakeQuantization8BitsRowwise(data):\n    min_el = np.min(data, axis=1)\n    max_el = np.max(data, axis=1)\n    scale = (max_el - min_el) / 255.0\n    bias = min_el\n    inv_scale = 1.0 / scale\n    data = data.T\n    data = np.round((data - bias) * inv_scale) * scale + bias\n    return data.T",
        "mutated": [
            "def FakeQuantization8BitsRowwise(data):\n    if False:\n        i = 10\n    min_el = np.min(data, axis=1)\n    max_el = np.max(data, axis=1)\n    scale = (max_el - min_el) / 255.0\n    bias = min_el\n    inv_scale = 1.0 / scale\n    data = data.T\n    data = np.round((data - bias) * inv_scale) * scale + bias\n    return data.T",
            "def FakeQuantization8BitsRowwise(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    min_el = np.min(data, axis=1)\n    max_el = np.max(data, axis=1)\n    scale = (max_el - min_el) / 255.0\n    bias = min_el\n    inv_scale = 1.0 / scale\n    data = data.T\n    data = np.round((data - bias) * inv_scale) * scale + bias\n    return data.T",
            "def FakeQuantization8BitsRowwise(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    min_el = np.min(data, axis=1)\n    max_el = np.max(data, axis=1)\n    scale = (max_el - min_el) / 255.0\n    bias = min_el\n    inv_scale = 1.0 / scale\n    data = data.T\n    data = np.round((data - bias) * inv_scale) * scale + bias\n    return data.T",
            "def FakeQuantization8BitsRowwise(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    min_el = np.min(data, axis=1)\n    max_el = np.max(data, axis=1)\n    scale = (max_el - min_el) / 255.0\n    bias = min_el\n    inv_scale = 1.0 / scale\n    data = data.T\n    data = np.round((data - bias) * inv_scale) * scale + bias\n    return data.T",
            "def FakeQuantization8BitsRowwise(data):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    min_el = np.min(data, axis=1)\n    max_el = np.max(data, axis=1)\n    scale = (max_el - min_el) / 255.0\n    bias = min_el\n    inv_scale = 1.0 / scale\n    data = data.T\n    data = np.round((data - bias) * inv_scale) * scale + bias\n    return data.T"
        ]
    },
    {
        "func_name": "test_quantize_op",
        "original": "def test_quantize_op(self):\n    op = core.CreateOperator('FloatToRowwiseQuantized8Bits', ['input_data'], ['quantized_input', 'scale_bias'])\n    input_data = np.float32(np.asarray([[801.0, 786, 235.2, 2353.3434], [5.0, 11.0, 9.0, -2.0]]))\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    op1 = core.CreateOperator('Rowwise8BitQuantizedToFloat', ['quantized_input', 'scale_bias'], ['dequantized_input'])\n    workspace.RunOperatorOnce(op1)\n    result = workspace.FetchBlob('dequantized_input')\n    ground_truth = FakeQuantization8BitsRowwise(input_data)\n    np.testing.assert_array_almost_equal(result, ground_truth)",
        "mutated": [
            "def test_quantize_op(self):\n    if False:\n        i = 10\n    op = core.CreateOperator('FloatToRowwiseQuantized8Bits', ['input_data'], ['quantized_input', 'scale_bias'])\n    input_data = np.float32(np.asarray([[801.0, 786, 235.2, 2353.3434], [5.0, 11.0, 9.0, -2.0]]))\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    op1 = core.CreateOperator('Rowwise8BitQuantizedToFloat', ['quantized_input', 'scale_bias'], ['dequantized_input'])\n    workspace.RunOperatorOnce(op1)\n    result = workspace.FetchBlob('dequantized_input')\n    ground_truth = FakeQuantization8BitsRowwise(input_data)\n    np.testing.assert_array_almost_equal(result, ground_truth)",
            "def test_quantize_op(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    op = core.CreateOperator('FloatToRowwiseQuantized8Bits', ['input_data'], ['quantized_input', 'scale_bias'])\n    input_data = np.float32(np.asarray([[801.0, 786, 235.2, 2353.3434], [5.0, 11.0, 9.0, -2.0]]))\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    op1 = core.CreateOperator('Rowwise8BitQuantizedToFloat', ['quantized_input', 'scale_bias'], ['dequantized_input'])\n    workspace.RunOperatorOnce(op1)\n    result = workspace.FetchBlob('dequantized_input')\n    ground_truth = FakeQuantization8BitsRowwise(input_data)\n    np.testing.assert_array_almost_equal(result, ground_truth)",
            "def test_quantize_op(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    op = core.CreateOperator('FloatToRowwiseQuantized8Bits', ['input_data'], ['quantized_input', 'scale_bias'])\n    input_data = np.float32(np.asarray([[801.0, 786, 235.2, 2353.3434], [5.0, 11.0, 9.0, -2.0]]))\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    op1 = core.CreateOperator('Rowwise8BitQuantizedToFloat', ['quantized_input', 'scale_bias'], ['dequantized_input'])\n    workspace.RunOperatorOnce(op1)\n    result = workspace.FetchBlob('dequantized_input')\n    ground_truth = FakeQuantization8BitsRowwise(input_data)\n    np.testing.assert_array_almost_equal(result, ground_truth)",
            "def test_quantize_op(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    op = core.CreateOperator('FloatToRowwiseQuantized8Bits', ['input_data'], ['quantized_input', 'scale_bias'])\n    input_data = np.float32(np.asarray([[801.0, 786, 235.2, 2353.3434], [5.0, 11.0, 9.0, -2.0]]))\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    op1 = core.CreateOperator('Rowwise8BitQuantizedToFloat', ['quantized_input', 'scale_bias'], ['dequantized_input'])\n    workspace.RunOperatorOnce(op1)\n    result = workspace.FetchBlob('dequantized_input')\n    ground_truth = FakeQuantization8BitsRowwise(input_data)\n    np.testing.assert_array_almost_equal(result, ground_truth)",
            "def test_quantize_op(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    op = core.CreateOperator('FloatToRowwiseQuantized8Bits', ['input_data'], ['quantized_input', 'scale_bias'])\n    input_data = np.float32(np.asarray([[801.0, 786, 235.2, 2353.3434], [5.0, 11.0, 9.0, -2.0]]))\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    op1 = core.CreateOperator('Rowwise8BitQuantizedToFloat', ['quantized_input', 'scale_bias'], ['dequantized_input'])\n    workspace.RunOperatorOnce(op1)\n    result = workspace.FetchBlob('dequantized_input')\n    ground_truth = FakeQuantization8BitsRowwise(input_data)\n    np.testing.assert_array_almost_equal(result, ground_truth)"
        ]
    },
    {
        "func_name": "test_quantize_tensor_with_const_row_op",
        "original": "def test_quantize_tensor_with_const_row_op(self):\n    op = core.CreateOperator('FloatToRowwiseQuantized8Bits', ['input_data'], ['quantized_input', 'scale_bias'])\n    input_data = np.float32(np.asarray([[801.0, 786, 235.2, 2353.3434], [9.0, 9.0, 9.0, 9.0]]))\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    op1 = core.CreateOperator('Rowwise8BitQuantizedToFloat', ['quantized_input', 'scale_bias'], ['dequantized_input'])\n    workspace.RunOperatorOnce(op1)\n    result = workspace.FetchBlob('dequantized_input')\n    ground_truth = FakeQuantization8BitsRowwise(input_data)\n    ground_truth[1, :] = 9.0\n    np.testing.assert_array_almost_equal(result, ground_truth)",
        "mutated": [
            "def test_quantize_tensor_with_const_row_op(self):\n    if False:\n        i = 10\n    op = core.CreateOperator('FloatToRowwiseQuantized8Bits', ['input_data'], ['quantized_input', 'scale_bias'])\n    input_data = np.float32(np.asarray([[801.0, 786, 235.2, 2353.3434], [9.0, 9.0, 9.0, 9.0]]))\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    op1 = core.CreateOperator('Rowwise8BitQuantizedToFloat', ['quantized_input', 'scale_bias'], ['dequantized_input'])\n    workspace.RunOperatorOnce(op1)\n    result = workspace.FetchBlob('dequantized_input')\n    ground_truth = FakeQuantization8BitsRowwise(input_data)\n    ground_truth[1, :] = 9.0\n    np.testing.assert_array_almost_equal(result, ground_truth)",
            "def test_quantize_tensor_with_const_row_op(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    op = core.CreateOperator('FloatToRowwiseQuantized8Bits', ['input_data'], ['quantized_input', 'scale_bias'])\n    input_data = np.float32(np.asarray([[801.0, 786, 235.2, 2353.3434], [9.0, 9.0, 9.0, 9.0]]))\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    op1 = core.CreateOperator('Rowwise8BitQuantizedToFloat', ['quantized_input', 'scale_bias'], ['dequantized_input'])\n    workspace.RunOperatorOnce(op1)\n    result = workspace.FetchBlob('dequantized_input')\n    ground_truth = FakeQuantization8BitsRowwise(input_data)\n    ground_truth[1, :] = 9.0\n    np.testing.assert_array_almost_equal(result, ground_truth)",
            "def test_quantize_tensor_with_const_row_op(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    op = core.CreateOperator('FloatToRowwiseQuantized8Bits', ['input_data'], ['quantized_input', 'scale_bias'])\n    input_data = np.float32(np.asarray([[801.0, 786, 235.2, 2353.3434], [9.0, 9.0, 9.0, 9.0]]))\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    op1 = core.CreateOperator('Rowwise8BitQuantizedToFloat', ['quantized_input', 'scale_bias'], ['dequantized_input'])\n    workspace.RunOperatorOnce(op1)\n    result = workspace.FetchBlob('dequantized_input')\n    ground_truth = FakeQuantization8BitsRowwise(input_data)\n    ground_truth[1, :] = 9.0\n    np.testing.assert_array_almost_equal(result, ground_truth)",
            "def test_quantize_tensor_with_const_row_op(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    op = core.CreateOperator('FloatToRowwiseQuantized8Bits', ['input_data'], ['quantized_input', 'scale_bias'])\n    input_data = np.float32(np.asarray([[801.0, 786, 235.2, 2353.3434], [9.0, 9.0, 9.0, 9.0]]))\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    op1 = core.CreateOperator('Rowwise8BitQuantizedToFloat', ['quantized_input', 'scale_bias'], ['dequantized_input'])\n    workspace.RunOperatorOnce(op1)\n    result = workspace.FetchBlob('dequantized_input')\n    ground_truth = FakeQuantization8BitsRowwise(input_data)\n    ground_truth[1, :] = 9.0\n    np.testing.assert_array_almost_equal(result, ground_truth)",
            "def test_quantize_tensor_with_const_row_op(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    op = core.CreateOperator('FloatToRowwiseQuantized8Bits', ['input_data'], ['quantized_input', 'scale_bias'])\n    input_data = np.float32(np.asarray([[801.0, 786, 235.2, 2353.3434], [9.0, 9.0, 9.0, 9.0]]))\n    workspace.FeedBlob('input_data', input_data)\n    workspace.RunOperatorOnce(op)\n    op1 = core.CreateOperator('Rowwise8BitQuantizedToFloat', ['quantized_input', 'scale_bias'], ['dequantized_input'])\n    workspace.RunOperatorOnce(op1)\n    result = workspace.FetchBlob('dequantized_input')\n    ground_truth = FakeQuantization8BitsRowwise(input_data)\n    ground_truth[1, :] = 9.0\n    np.testing.assert_array_almost_equal(result, ground_truth)"
        ]
    },
    {
        "func_name": "test_SparseSegmentUint8",
        "original": "def test_SparseSegmentUint8(self):\n    init_net = core.Net('init')\n    net = core.Net('bench')\n    size = 10 ** 3\n    isize = 10 ** 2\n    d = init_net.UniformFill([], shape=[size, 32])\n    w = init_net.UniformFill([], shape=[isize])\n    i = init_net.UniformIntFill([], shape=[isize], max=size - 1)\n    i = init_net.Cast([i], to=core.DataType.INT64)\n    l = init_net.ConstantFill([], ['l'], shape=[isize // 10], value=10, dtype=core.DataType.INT32)\n    net.FloatToRowwiseQuantized8Bits([d], ['quantized_data', 'scale_bias'])\n    net.Rowwise8BitQuantizedToFloat(['quantized_data', 'scale_bias'], ['dequantized_data'])\n    net.SparseLengthsWeightedSum(['dequantized_data', w, i, l], ['PositionWeighted_0'], engine='fp16')\n    net.SparseLengthsWeightedSum8BitsRowwise(['quantized_data', w, i, l, 'scale_bias'], ['PositionWeighted_1'])\n    net.SparseLengthsSum(['dequantized_data', i, l], ['Sum_0'], engine='fp16')\n    net.SparseLengthsSum8BitsRowwise(['quantized_data', i, l, 'scale_bias'], ['Sum_1'])\n    net.SparseLengthsMean(['dequantized_data', i, l], ['Mean_0'], engine='fp16')\n    net.SparseLengthsMean8BitsRowwise(['quantized_data', i, l, 'scale_bias'], ['Mean_1'])\n    gathered_w = net.Gather(['quantized_data', i], engine='fp16')\n    gathered_scale_bias = net.Gather(['scale_bias', i], engine='fp16')\n    net.Rowwise8BitQuantizedToFloat([gathered_w, gathered_scale_bias], 'Gathered_1')\n    net.Gather(['dequantized_data', i], 'Gathered_0')\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(init_net)\n    workspace.CreateNet(net)\n    workspace.RunNetOnce(net)\n    PositionWeighted_1 = workspace.FetchBlob('PositionWeighted_1')\n    ground_truth_posw = workspace.FetchBlob('PositionWeighted_0')\n    np.testing.assert_array_almost_equal(PositionWeighted_1, ground_truth_posw, decimal=5)\n    Sum_1 = workspace.FetchBlob('Sum_1')\n    ground_truth_sum = workspace.FetchBlob('Sum_0')\n    np.testing.assert_array_almost_equal(Sum_1, ground_truth_sum, decimal=5)\n    Mean_1 = workspace.FetchBlob('Mean_1')\n    ground_truth_mean = workspace.FetchBlob('Mean_0')\n    np.testing.assert_array_almost_equal(Mean_1, ground_truth_mean, decimal=5)\n    Gathered_1 = workspace.FetchBlob('Gathered_1')\n    ground_truth_gathered = workspace.FetchBlob('Gathered_0')\n    np.testing.assert_array_almost_equal(Gathered_1, ground_truth_gathered, decimal=5)",
        "mutated": [
            "def test_SparseSegmentUint8(self):\n    if False:\n        i = 10\n    init_net = core.Net('init')\n    net = core.Net('bench')\n    size = 10 ** 3\n    isize = 10 ** 2\n    d = init_net.UniformFill([], shape=[size, 32])\n    w = init_net.UniformFill([], shape=[isize])\n    i = init_net.UniformIntFill([], shape=[isize], max=size - 1)\n    i = init_net.Cast([i], to=core.DataType.INT64)\n    l = init_net.ConstantFill([], ['l'], shape=[isize // 10], value=10, dtype=core.DataType.INT32)\n    net.FloatToRowwiseQuantized8Bits([d], ['quantized_data', 'scale_bias'])\n    net.Rowwise8BitQuantizedToFloat(['quantized_data', 'scale_bias'], ['dequantized_data'])\n    net.SparseLengthsWeightedSum(['dequantized_data', w, i, l], ['PositionWeighted_0'], engine='fp16')\n    net.SparseLengthsWeightedSum8BitsRowwise(['quantized_data', w, i, l, 'scale_bias'], ['PositionWeighted_1'])\n    net.SparseLengthsSum(['dequantized_data', i, l], ['Sum_0'], engine='fp16')\n    net.SparseLengthsSum8BitsRowwise(['quantized_data', i, l, 'scale_bias'], ['Sum_1'])\n    net.SparseLengthsMean(['dequantized_data', i, l], ['Mean_0'], engine='fp16')\n    net.SparseLengthsMean8BitsRowwise(['quantized_data', i, l, 'scale_bias'], ['Mean_1'])\n    gathered_w = net.Gather(['quantized_data', i], engine='fp16')\n    gathered_scale_bias = net.Gather(['scale_bias', i], engine='fp16')\n    net.Rowwise8BitQuantizedToFloat([gathered_w, gathered_scale_bias], 'Gathered_1')\n    net.Gather(['dequantized_data', i], 'Gathered_0')\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(init_net)\n    workspace.CreateNet(net)\n    workspace.RunNetOnce(net)\n    PositionWeighted_1 = workspace.FetchBlob('PositionWeighted_1')\n    ground_truth_posw = workspace.FetchBlob('PositionWeighted_0')\n    np.testing.assert_array_almost_equal(PositionWeighted_1, ground_truth_posw, decimal=5)\n    Sum_1 = workspace.FetchBlob('Sum_1')\n    ground_truth_sum = workspace.FetchBlob('Sum_0')\n    np.testing.assert_array_almost_equal(Sum_1, ground_truth_sum, decimal=5)\n    Mean_1 = workspace.FetchBlob('Mean_1')\n    ground_truth_mean = workspace.FetchBlob('Mean_0')\n    np.testing.assert_array_almost_equal(Mean_1, ground_truth_mean, decimal=5)\n    Gathered_1 = workspace.FetchBlob('Gathered_1')\n    ground_truth_gathered = workspace.FetchBlob('Gathered_0')\n    np.testing.assert_array_almost_equal(Gathered_1, ground_truth_gathered, decimal=5)",
            "def test_SparseSegmentUint8(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    init_net = core.Net('init')\n    net = core.Net('bench')\n    size = 10 ** 3\n    isize = 10 ** 2\n    d = init_net.UniformFill([], shape=[size, 32])\n    w = init_net.UniformFill([], shape=[isize])\n    i = init_net.UniformIntFill([], shape=[isize], max=size - 1)\n    i = init_net.Cast([i], to=core.DataType.INT64)\n    l = init_net.ConstantFill([], ['l'], shape=[isize // 10], value=10, dtype=core.DataType.INT32)\n    net.FloatToRowwiseQuantized8Bits([d], ['quantized_data', 'scale_bias'])\n    net.Rowwise8BitQuantizedToFloat(['quantized_data', 'scale_bias'], ['dequantized_data'])\n    net.SparseLengthsWeightedSum(['dequantized_data', w, i, l], ['PositionWeighted_0'], engine='fp16')\n    net.SparseLengthsWeightedSum8BitsRowwise(['quantized_data', w, i, l, 'scale_bias'], ['PositionWeighted_1'])\n    net.SparseLengthsSum(['dequantized_data', i, l], ['Sum_0'], engine='fp16')\n    net.SparseLengthsSum8BitsRowwise(['quantized_data', i, l, 'scale_bias'], ['Sum_1'])\n    net.SparseLengthsMean(['dequantized_data', i, l], ['Mean_0'], engine='fp16')\n    net.SparseLengthsMean8BitsRowwise(['quantized_data', i, l, 'scale_bias'], ['Mean_1'])\n    gathered_w = net.Gather(['quantized_data', i], engine='fp16')\n    gathered_scale_bias = net.Gather(['scale_bias', i], engine='fp16')\n    net.Rowwise8BitQuantizedToFloat([gathered_w, gathered_scale_bias], 'Gathered_1')\n    net.Gather(['dequantized_data', i], 'Gathered_0')\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(init_net)\n    workspace.CreateNet(net)\n    workspace.RunNetOnce(net)\n    PositionWeighted_1 = workspace.FetchBlob('PositionWeighted_1')\n    ground_truth_posw = workspace.FetchBlob('PositionWeighted_0')\n    np.testing.assert_array_almost_equal(PositionWeighted_1, ground_truth_posw, decimal=5)\n    Sum_1 = workspace.FetchBlob('Sum_1')\n    ground_truth_sum = workspace.FetchBlob('Sum_0')\n    np.testing.assert_array_almost_equal(Sum_1, ground_truth_sum, decimal=5)\n    Mean_1 = workspace.FetchBlob('Mean_1')\n    ground_truth_mean = workspace.FetchBlob('Mean_0')\n    np.testing.assert_array_almost_equal(Mean_1, ground_truth_mean, decimal=5)\n    Gathered_1 = workspace.FetchBlob('Gathered_1')\n    ground_truth_gathered = workspace.FetchBlob('Gathered_0')\n    np.testing.assert_array_almost_equal(Gathered_1, ground_truth_gathered, decimal=5)",
            "def test_SparseSegmentUint8(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    init_net = core.Net('init')\n    net = core.Net('bench')\n    size = 10 ** 3\n    isize = 10 ** 2\n    d = init_net.UniformFill([], shape=[size, 32])\n    w = init_net.UniformFill([], shape=[isize])\n    i = init_net.UniformIntFill([], shape=[isize], max=size - 1)\n    i = init_net.Cast([i], to=core.DataType.INT64)\n    l = init_net.ConstantFill([], ['l'], shape=[isize // 10], value=10, dtype=core.DataType.INT32)\n    net.FloatToRowwiseQuantized8Bits([d], ['quantized_data', 'scale_bias'])\n    net.Rowwise8BitQuantizedToFloat(['quantized_data', 'scale_bias'], ['dequantized_data'])\n    net.SparseLengthsWeightedSum(['dequantized_data', w, i, l], ['PositionWeighted_0'], engine='fp16')\n    net.SparseLengthsWeightedSum8BitsRowwise(['quantized_data', w, i, l, 'scale_bias'], ['PositionWeighted_1'])\n    net.SparseLengthsSum(['dequantized_data', i, l], ['Sum_0'], engine='fp16')\n    net.SparseLengthsSum8BitsRowwise(['quantized_data', i, l, 'scale_bias'], ['Sum_1'])\n    net.SparseLengthsMean(['dequantized_data', i, l], ['Mean_0'], engine='fp16')\n    net.SparseLengthsMean8BitsRowwise(['quantized_data', i, l, 'scale_bias'], ['Mean_1'])\n    gathered_w = net.Gather(['quantized_data', i], engine='fp16')\n    gathered_scale_bias = net.Gather(['scale_bias', i], engine='fp16')\n    net.Rowwise8BitQuantizedToFloat([gathered_w, gathered_scale_bias], 'Gathered_1')\n    net.Gather(['dequantized_data', i], 'Gathered_0')\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(init_net)\n    workspace.CreateNet(net)\n    workspace.RunNetOnce(net)\n    PositionWeighted_1 = workspace.FetchBlob('PositionWeighted_1')\n    ground_truth_posw = workspace.FetchBlob('PositionWeighted_0')\n    np.testing.assert_array_almost_equal(PositionWeighted_1, ground_truth_posw, decimal=5)\n    Sum_1 = workspace.FetchBlob('Sum_1')\n    ground_truth_sum = workspace.FetchBlob('Sum_0')\n    np.testing.assert_array_almost_equal(Sum_1, ground_truth_sum, decimal=5)\n    Mean_1 = workspace.FetchBlob('Mean_1')\n    ground_truth_mean = workspace.FetchBlob('Mean_0')\n    np.testing.assert_array_almost_equal(Mean_1, ground_truth_mean, decimal=5)\n    Gathered_1 = workspace.FetchBlob('Gathered_1')\n    ground_truth_gathered = workspace.FetchBlob('Gathered_0')\n    np.testing.assert_array_almost_equal(Gathered_1, ground_truth_gathered, decimal=5)",
            "def test_SparseSegmentUint8(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    init_net = core.Net('init')\n    net = core.Net('bench')\n    size = 10 ** 3\n    isize = 10 ** 2\n    d = init_net.UniformFill([], shape=[size, 32])\n    w = init_net.UniformFill([], shape=[isize])\n    i = init_net.UniformIntFill([], shape=[isize], max=size - 1)\n    i = init_net.Cast([i], to=core.DataType.INT64)\n    l = init_net.ConstantFill([], ['l'], shape=[isize // 10], value=10, dtype=core.DataType.INT32)\n    net.FloatToRowwiseQuantized8Bits([d], ['quantized_data', 'scale_bias'])\n    net.Rowwise8BitQuantizedToFloat(['quantized_data', 'scale_bias'], ['dequantized_data'])\n    net.SparseLengthsWeightedSum(['dequantized_data', w, i, l], ['PositionWeighted_0'], engine='fp16')\n    net.SparseLengthsWeightedSum8BitsRowwise(['quantized_data', w, i, l, 'scale_bias'], ['PositionWeighted_1'])\n    net.SparseLengthsSum(['dequantized_data', i, l], ['Sum_0'], engine='fp16')\n    net.SparseLengthsSum8BitsRowwise(['quantized_data', i, l, 'scale_bias'], ['Sum_1'])\n    net.SparseLengthsMean(['dequantized_data', i, l], ['Mean_0'], engine='fp16')\n    net.SparseLengthsMean8BitsRowwise(['quantized_data', i, l, 'scale_bias'], ['Mean_1'])\n    gathered_w = net.Gather(['quantized_data', i], engine='fp16')\n    gathered_scale_bias = net.Gather(['scale_bias', i], engine='fp16')\n    net.Rowwise8BitQuantizedToFloat([gathered_w, gathered_scale_bias], 'Gathered_1')\n    net.Gather(['dequantized_data', i], 'Gathered_0')\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(init_net)\n    workspace.CreateNet(net)\n    workspace.RunNetOnce(net)\n    PositionWeighted_1 = workspace.FetchBlob('PositionWeighted_1')\n    ground_truth_posw = workspace.FetchBlob('PositionWeighted_0')\n    np.testing.assert_array_almost_equal(PositionWeighted_1, ground_truth_posw, decimal=5)\n    Sum_1 = workspace.FetchBlob('Sum_1')\n    ground_truth_sum = workspace.FetchBlob('Sum_0')\n    np.testing.assert_array_almost_equal(Sum_1, ground_truth_sum, decimal=5)\n    Mean_1 = workspace.FetchBlob('Mean_1')\n    ground_truth_mean = workspace.FetchBlob('Mean_0')\n    np.testing.assert_array_almost_equal(Mean_1, ground_truth_mean, decimal=5)\n    Gathered_1 = workspace.FetchBlob('Gathered_1')\n    ground_truth_gathered = workspace.FetchBlob('Gathered_0')\n    np.testing.assert_array_almost_equal(Gathered_1, ground_truth_gathered, decimal=5)",
            "def test_SparseSegmentUint8(self):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    init_net = core.Net('init')\n    net = core.Net('bench')\n    size = 10 ** 3\n    isize = 10 ** 2\n    d = init_net.UniformFill([], shape=[size, 32])\n    w = init_net.UniformFill([], shape=[isize])\n    i = init_net.UniformIntFill([], shape=[isize], max=size - 1)\n    i = init_net.Cast([i], to=core.DataType.INT64)\n    l = init_net.ConstantFill([], ['l'], shape=[isize // 10], value=10, dtype=core.DataType.INT32)\n    net.FloatToRowwiseQuantized8Bits([d], ['quantized_data', 'scale_bias'])\n    net.Rowwise8BitQuantizedToFloat(['quantized_data', 'scale_bias'], ['dequantized_data'])\n    net.SparseLengthsWeightedSum(['dequantized_data', w, i, l], ['PositionWeighted_0'], engine='fp16')\n    net.SparseLengthsWeightedSum8BitsRowwise(['quantized_data', w, i, l, 'scale_bias'], ['PositionWeighted_1'])\n    net.SparseLengthsSum(['dequantized_data', i, l], ['Sum_0'], engine='fp16')\n    net.SparseLengthsSum8BitsRowwise(['quantized_data', i, l, 'scale_bias'], ['Sum_1'])\n    net.SparseLengthsMean(['dequantized_data', i, l], ['Mean_0'], engine='fp16')\n    net.SparseLengthsMean8BitsRowwise(['quantized_data', i, l, 'scale_bias'], ['Mean_1'])\n    gathered_w = net.Gather(['quantized_data', i], engine='fp16')\n    gathered_scale_bias = net.Gather(['scale_bias', i], engine='fp16')\n    net.Rowwise8BitQuantizedToFloat([gathered_w, gathered_scale_bias], 'Gathered_1')\n    net.Gather(['dequantized_data', i], 'Gathered_0')\n    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n    workspace.RunNetOnce(init_net)\n    workspace.CreateNet(net)\n    workspace.RunNetOnce(net)\n    PositionWeighted_1 = workspace.FetchBlob('PositionWeighted_1')\n    ground_truth_posw = workspace.FetchBlob('PositionWeighted_0')\n    np.testing.assert_array_almost_equal(PositionWeighted_1, ground_truth_posw, decimal=5)\n    Sum_1 = workspace.FetchBlob('Sum_1')\n    ground_truth_sum = workspace.FetchBlob('Sum_0')\n    np.testing.assert_array_almost_equal(Sum_1, ground_truth_sum, decimal=5)\n    Mean_1 = workspace.FetchBlob('Mean_1')\n    ground_truth_mean = workspace.FetchBlob('Mean_0')\n    np.testing.assert_array_almost_equal(Mean_1, ground_truth_mean, decimal=5)\n    Gathered_1 = workspace.FetchBlob('Gathered_1')\n    ground_truth_gathered = workspace.FetchBlob('Gathered_0')\n    np.testing.assert_array_almost_equal(Gathered_1, ground_truth_gathered, decimal=5)"
        ]
    }
]