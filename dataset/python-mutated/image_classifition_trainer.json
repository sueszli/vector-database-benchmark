[
    {
        "func_name": "train_model",
        "original": "def train_model(model, dataset, cfg, distributed=False, val_dataset=None, timestamp=None, device=None, meta=None):\n    import torch\n    import warnings\n    from mmcv.runner import DistSamplerSeedHook, Fp16OptimizerHook, build_optimizer, build_runner, get_dist_info\n    from mmcls.core import DistEvalHook, DistOptimizerHook, EvalHook\n    from mmcls.datasets import build_dataloader\n    from mmcls.utils import wrap_distributed_model, wrap_non_distributed_model\n    from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n    logger = get_logger()\n    dataset = dataset if isinstance(dataset, (list, tuple)) else [dataset]\n    sampler_cfg = cfg.train.get('sampler', None)\n    data_loaders = [build_dataloader(ds, cfg.train.dataloader.batch_size_per_gpu, cfg.train.dataloader.workers_per_gpu, num_gpus=len(cfg.gpu_ids), dist=distributed, round_up=True, seed=cfg.seed, sampler_cfg=sampler_cfg) for ds in dataset]\n    if distributed:\n        find_unused_parameters = cfg.get('find_unused_parameters', False)\n        model = MMDistributedDataParallel(model.cuda(), device_ids=[torch.cuda.current_device()], broadcast_buffers=False, find_unused_parameters=find_unused_parameters)\n    elif device == 'cpu':\n        logger.warning('The argument `device` is deprecated. To use cpu to train, please refers to https://mmclassification.readthedocs.io/en/latest/getting_started.html#train-a-model')\n        model = model.cpu()\n    else:\n        model = MMDataParallel(model, device_ids=cfg.gpu_ids)\n        if not model.device_ids:\n            from mmcv import __version__, digit_version\n            assert digit_version(__version__) >= (1, 4, 4), 'To train with CPU, please confirm your mmcv version is not lower than v1.4.4'\n    optimizer = build_optimizer(model, cfg.train.optimizer)\n    if cfg.train.get('runner') is None:\n        cfg.train.runner = {'type': 'EpochBasedRunner', 'max_epochs': cfg.train.max_epochs}\n        logger.warning('config is now expected to have a `runner` section, please set `runner` in your config.', UserWarning)\n    runner = build_runner(cfg.train.runner, default_args=dict(model=model, batch_processor=None, optimizer=optimizer, work_dir=cfg.work_dir, logger=logger, meta=meta))\n    runner.timestamp = timestamp\n    fp16_cfg = cfg.get('fp16', None)\n    if fp16_cfg is not None:\n        optimizer_config = Fp16OptimizerHook(**cfg.train.optimizer_config, **fp16_cfg, distributed=distributed)\n    elif distributed and 'type' not in cfg.train.optimizer_config:\n        optimizer_config = DistOptimizerHook(**cfg.train.optimizer_config)\n    else:\n        optimizer_config = cfg.train.optimizer_config\n    runner.register_training_hooks(cfg.train.lr_config, optimizer_config, cfg.train.checkpoint_config, cfg.train.log_config, cfg.train.get('momentum_config', None), custom_hooks_config=cfg.train.get('custom_hooks', None))\n    if distributed and cfg.train.runner['type'] == 'EpochBasedRunner':\n        runner.register_hook(DistSamplerSeedHook())\n    if val_dataset is not None:\n        val_dataloader = build_dataloader(val_dataset, samples_per_gpu=cfg.evaluation.dataloader.batch_size_per_gpu, workers_per_gpu=cfg.evaluation.dataloader.workers_per_gpu, dist=distributed, shuffle=False, round_up=True)\n        eval_cfg = cfg.train.get('evaluation', {})\n        eval_cfg['by_epoch'] = cfg.train.runner['type'] != 'IterBasedRunner'\n        eval_hook = DistEvalHook if distributed else EvalHook\n        runner.register_hook(eval_hook(val_dataloader, **eval_cfg), priority='LOW')\n    if cfg.train.resume_from:\n        runner.resume(cfg.train.resume_from, map_location='cpu')\n    elif cfg.train.load_from:\n        runner.load_checkpoint(cfg.train.load_from)\n    cfg.train.workflow = [tuple(flow) for flow in cfg.train.workflow]\n    runner.run(data_loaders, cfg.train.workflow)",
        "mutated": [
            "def train_model(model, dataset, cfg, distributed=False, val_dataset=None, timestamp=None, device=None, meta=None):\n    if False:\n        i = 10\n    import torch\n    import warnings\n    from mmcv.runner import DistSamplerSeedHook, Fp16OptimizerHook, build_optimizer, build_runner, get_dist_info\n    from mmcls.core import DistEvalHook, DistOptimizerHook, EvalHook\n    from mmcls.datasets import build_dataloader\n    from mmcls.utils import wrap_distributed_model, wrap_non_distributed_model\n    from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n    logger = get_logger()\n    dataset = dataset if isinstance(dataset, (list, tuple)) else [dataset]\n    sampler_cfg = cfg.train.get('sampler', None)\n    data_loaders = [build_dataloader(ds, cfg.train.dataloader.batch_size_per_gpu, cfg.train.dataloader.workers_per_gpu, num_gpus=len(cfg.gpu_ids), dist=distributed, round_up=True, seed=cfg.seed, sampler_cfg=sampler_cfg) for ds in dataset]\n    if distributed:\n        find_unused_parameters = cfg.get('find_unused_parameters', False)\n        model = MMDistributedDataParallel(model.cuda(), device_ids=[torch.cuda.current_device()], broadcast_buffers=False, find_unused_parameters=find_unused_parameters)\n    elif device == 'cpu':\n        logger.warning('The argument `device` is deprecated. To use cpu to train, please refers to https://mmclassification.readthedocs.io/en/latest/getting_started.html#train-a-model')\n        model = model.cpu()\n    else:\n        model = MMDataParallel(model, device_ids=cfg.gpu_ids)\n        if not model.device_ids:\n            from mmcv import __version__, digit_version\n            assert digit_version(__version__) >= (1, 4, 4), 'To train with CPU, please confirm your mmcv version is not lower than v1.4.4'\n    optimizer = build_optimizer(model, cfg.train.optimizer)\n    if cfg.train.get('runner') is None:\n        cfg.train.runner = {'type': 'EpochBasedRunner', 'max_epochs': cfg.train.max_epochs}\n        logger.warning('config is now expected to have a `runner` section, please set `runner` in your config.', UserWarning)\n    runner = build_runner(cfg.train.runner, default_args=dict(model=model, batch_processor=None, optimizer=optimizer, work_dir=cfg.work_dir, logger=logger, meta=meta))\n    runner.timestamp = timestamp\n    fp16_cfg = cfg.get('fp16', None)\n    if fp16_cfg is not None:\n        optimizer_config = Fp16OptimizerHook(**cfg.train.optimizer_config, **fp16_cfg, distributed=distributed)\n    elif distributed and 'type' not in cfg.train.optimizer_config:\n        optimizer_config = DistOptimizerHook(**cfg.train.optimizer_config)\n    else:\n        optimizer_config = cfg.train.optimizer_config\n    runner.register_training_hooks(cfg.train.lr_config, optimizer_config, cfg.train.checkpoint_config, cfg.train.log_config, cfg.train.get('momentum_config', None), custom_hooks_config=cfg.train.get('custom_hooks', None))\n    if distributed and cfg.train.runner['type'] == 'EpochBasedRunner':\n        runner.register_hook(DistSamplerSeedHook())\n    if val_dataset is not None:\n        val_dataloader = build_dataloader(val_dataset, samples_per_gpu=cfg.evaluation.dataloader.batch_size_per_gpu, workers_per_gpu=cfg.evaluation.dataloader.workers_per_gpu, dist=distributed, shuffle=False, round_up=True)\n        eval_cfg = cfg.train.get('evaluation', {})\n        eval_cfg['by_epoch'] = cfg.train.runner['type'] != 'IterBasedRunner'\n        eval_hook = DistEvalHook if distributed else EvalHook\n        runner.register_hook(eval_hook(val_dataloader, **eval_cfg), priority='LOW')\n    if cfg.train.resume_from:\n        runner.resume(cfg.train.resume_from, map_location='cpu')\n    elif cfg.train.load_from:\n        runner.load_checkpoint(cfg.train.load_from)\n    cfg.train.workflow = [tuple(flow) for flow in cfg.train.workflow]\n    runner.run(data_loaders, cfg.train.workflow)",
            "def train_model(model, dataset, cfg, distributed=False, val_dataset=None, timestamp=None, device=None, meta=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    import torch\n    import warnings\n    from mmcv.runner import DistSamplerSeedHook, Fp16OptimizerHook, build_optimizer, build_runner, get_dist_info\n    from mmcls.core import DistEvalHook, DistOptimizerHook, EvalHook\n    from mmcls.datasets import build_dataloader\n    from mmcls.utils import wrap_distributed_model, wrap_non_distributed_model\n    from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n    logger = get_logger()\n    dataset = dataset if isinstance(dataset, (list, tuple)) else [dataset]\n    sampler_cfg = cfg.train.get('sampler', None)\n    data_loaders = [build_dataloader(ds, cfg.train.dataloader.batch_size_per_gpu, cfg.train.dataloader.workers_per_gpu, num_gpus=len(cfg.gpu_ids), dist=distributed, round_up=True, seed=cfg.seed, sampler_cfg=sampler_cfg) for ds in dataset]\n    if distributed:\n        find_unused_parameters = cfg.get('find_unused_parameters', False)\n        model = MMDistributedDataParallel(model.cuda(), device_ids=[torch.cuda.current_device()], broadcast_buffers=False, find_unused_parameters=find_unused_parameters)\n    elif device == 'cpu':\n        logger.warning('The argument `device` is deprecated. To use cpu to train, please refers to https://mmclassification.readthedocs.io/en/latest/getting_started.html#train-a-model')\n        model = model.cpu()\n    else:\n        model = MMDataParallel(model, device_ids=cfg.gpu_ids)\n        if not model.device_ids:\n            from mmcv import __version__, digit_version\n            assert digit_version(__version__) >= (1, 4, 4), 'To train with CPU, please confirm your mmcv version is not lower than v1.4.4'\n    optimizer = build_optimizer(model, cfg.train.optimizer)\n    if cfg.train.get('runner') is None:\n        cfg.train.runner = {'type': 'EpochBasedRunner', 'max_epochs': cfg.train.max_epochs}\n        logger.warning('config is now expected to have a `runner` section, please set `runner` in your config.', UserWarning)\n    runner = build_runner(cfg.train.runner, default_args=dict(model=model, batch_processor=None, optimizer=optimizer, work_dir=cfg.work_dir, logger=logger, meta=meta))\n    runner.timestamp = timestamp\n    fp16_cfg = cfg.get('fp16', None)\n    if fp16_cfg is not None:\n        optimizer_config = Fp16OptimizerHook(**cfg.train.optimizer_config, **fp16_cfg, distributed=distributed)\n    elif distributed and 'type' not in cfg.train.optimizer_config:\n        optimizer_config = DistOptimizerHook(**cfg.train.optimizer_config)\n    else:\n        optimizer_config = cfg.train.optimizer_config\n    runner.register_training_hooks(cfg.train.lr_config, optimizer_config, cfg.train.checkpoint_config, cfg.train.log_config, cfg.train.get('momentum_config', None), custom_hooks_config=cfg.train.get('custom_hooks', None))\n    if distributed and cfg.train.runner['type'] == 'EpochBasedRunner':\n        runner.register_hook(DistSamplerSeedHook())\n    if val_dataset is not None:\n        val_dataloader = build_dataloader(val_dataset, samples_per_gpu=cfg.evaluation.dataloader.batch_size_per_gpu, workers_per_gpu=cfg.evaluation.dataloader.workers_per_gpu, dist=distributed, shuffle=False, round_up=True)\n        eval_cfg = cfg.train.get('evaluation', {})\n        eval_cfg['by_epoch'] = cfg.train.runner['type'] != 'IterBasedRunner'\n        eval_hook = DistEvalHook if distributed else EvalHook\n        runner.register_hook(eval_hook(val_dataloader, **eval_cfg), priority='LOW')\n    if cfg.train.resume_from:\n        runner.resume(cfg.train.resume_from, map_location='cpu')\n    elif cfg.train.load_from:\n        runner.load_checkpoint(cfg.train.load_from)\n    cfg.train.workflow = [tuple(flow) for flow in cfg.train.workflow]\n    runner.run(data_loaders, cfg.train.workflow)",
            "def train_model(model, dataset, cfg, distributed=False, val_dataset=None, timestamp=None, device=None, meta=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    import torch\n    import warnings\n    from mmcv.runner import DistSamplerSeedHook, Fp16OptimizerHook, build_optimizer, build_runner, get_dist_info\n    from mmcls.core import DistEvalHook, DistOptimizerHook, EvalHook\n    from mmcls.datasets import build_dataloader\n    from mmcls.utils import wrap_distributed_model, wrap_non_distributed_model\n    from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n    logger = get_logger()\n    dataset = dataset if isinstance(dataset, (list, tuple)) else [dataset]\n    sampler_cfg = cfg.train.get('sampler', None)\n    data_loaders = [build_dataloader(ds, cfg.train.dataloader.batch_size_per_gpu, cfg.train.dataloader.workers_per_gpu, num_gpus=len(cfg.gpu_ids), dist=distributed, round_up=True, seed=cfg.seed, sampler_cfg=sampler_cfg) for ds in dataset]\n    if distributed:\n        find_unused_parameters = cfg.get('find_unused_parameters', False)\n        model = MMDistributedDataParallel(model.cuda(), device_ids=[torch.cuda.current_device()], broadcast_buffers=False, find_unused_parameters=find_unused_parameters)\n    elif device == 'cpu':\n        logger.warning('The argument `device` is deprecated. To use cpu to train, please refers to https://mmclassification.readthedocs.io/en/latest/getting_started.html#train-a-model')\n        model = model.cpu()\n    else:\n        model = MMDataParallel(model, device_ids=cfg.gpu_ids)\n        if not model.device_ids:\n            from mmcv import __version__, digit_version\n            assert digit_version(__version__) >= (1, 4, 4), 'To train with CPU, please confirm your mmcv version is not lower than v1.4.4'\n    optimizer = build_optimizer(model, cfg.train.optimizer)\n    if cfg.train.get('runner') is None:\n        cfg.train.runner = {'type': 'EpochBasedRunner', 'max_epochs': cfg.train.max_epochs}\n        logger.warning('config is now expected to have a `runner` section, please set `runner` in your config.', UserWarning)\n    runner = build_runner(cfg.train.runner, default_args=dict(model=model, batch_processor=None, optimizer=optimizer, work_dir=cfg.work_dir, logger=logger, meta=meta))\n    runner.timestamp = timestamp\n    fp16_cfg = cfg.get('fp16', None)\n    if fp16_cfg is not None:\n        optimizer_config = Fp16OptimizerHook(**cfg.train.optimizer_config, **fp16_cfg, distributed=distributed)\n    elif distributed and 'type' not in cfg.train.optimizer_config:\n        optimizer_config = DistOptimizerHook(**cfg.train.optimizer_config)\n    else:\n        optimizer_config = cfg.train.optimizer_config\n    runner.register_training_hooks(cfg.train.lr_config, optimizer_config, cfg.train.checkpoint_config, cfg.train.log_config, cfg.train.get('momentum_config', None), custom_hooks_config=cfg.train.get('custom_hooks', None))\n    if distributed and cfg.train.runner['type'] == 'EpochBasedRunner':\n        runner.register_hook(DistSamplerSeedHook())\n    if val_dataset is not None:\n        val_dataloader = build_dataloader(val_dataset, samples_per_gpu=cfg.evaluation.dataloader.batch_size_per_gpu, workers_per_gpu=cfg.evaluation.dataloader.workers_per_gpu, dist=distributed, shuffle=False, round_up=True)\n        eval_cfg = cfg.train.get('evaluation', {})\n        eval_cfg['by_epoch'] = cfg.train.runner['type'] != 'IterBasedRunner'\n        eval_hook = DistEvalHook if distributed else EvalHook\n        runner.register_hook(eval_hook(val_dataloader, **eval_cfg), priority='LOW')\n    if cfg.train.resume_from:\n        runner.resume(cfg.train.resume_from, map_location='cpu')\n    elif cfg.train.load_from:\n        runner.load_checkpoint(cfg.train.load_from)\n    cfg.train.workflow = [tuple(flow) for flow in cfg.train.workflow]\n    runner.run(data_loaders, cfg.train.workflow)",
            "def train_model(model, dataset, cfg, distributed=False, val_dataset=None, timestamp=None, device=None, meta=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    import torch\n    import warnings\n    from mmcv.runner import DistSamplerSeedHook, Fp16OptimizerHook, build_optimizer, build_runner, get_dist_info\n    from mmcls.core import DistEvalHook, DistOptimizerHook, EvalHook\n    from mmcls.datasets import build_dataloader\n    from mmcls.utils import wrap_distributed_model, wrap_non_distributed_model\n    from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n    logger = get_logger()\n    dataset = dataset if isinstance(dataset, (list, tuple)) else [dataset]\n    sampler_cfg = cfg.train.get('sampler', None)\n    data_loaders = [build_dataloader(ds, cfg.train.dataloader.batch_size_per_gpu, cfg.train.dataloader.workers_per_gpu, num_gpus=len(cfg.gpu_ids), dist=distributed, round_up=True, seed=cfg.seed, sampler_cfg=sampler_cfg) for ds in dataset]\n    if distributed:\n        find_unused_parameters = cfg.get('find_unused_parameters', False)\n        model = MMDistributedDataParallel(model.cuda(), device_ids=[torch.cuda.current_device()], broadcast_buffers=False, find_unused_parameters=find_unused_parameters)\n    elif device == 'cpu':\n        logger.warning('The argument `device` is deprecated. To use cpu to train, please refers to https://mmclassification.readthedocs.io/en/latest/getting_started.html#train-a-model')\n        model = model.cpu()\n    else:\n        model = MMDataParallel(model, device_ids=cfg.gpu_ids)\n        if not model.device_ids:\n            from mmcv import __version__, digit_version\n            assert digit_version(__version__) >= (1, 4, 4), 'To train with CPU, please confirm your mmcv version is not lower than v1.4.4'\n    optimizer = build_optimizer(model, cfg.train.optimizer)\n    if cfg.train.get('runner') is None:\n        cfg.train.runner = {'type': 'EpochBasedRunner', 'max_epochs': cfg.train.max_epochs}\n        logger.warning('config is now expected to have a `runner` section, please set `runner` in your config.', UserWarning)\n    runner = build_runner(cfg.train.runner, default_args=dict(model=model, batch_processor=None, optimizer=optimizer, work_dir=cfg.work_dir, logger=logger, meta=meta))\n    runner.timestamp = timestamp\n    fp16_cfg = cfg.get('fp16', None)\n    if fp16_cfg is not None:\n        optimizer_config = Fp16OptimizerHook(**cfg.train.optimizer_config, **fp16_cfg, distributed=distributed)\n    elif distributed and 'type' not in cfg.train.optimizer_config:\n        optimizer_config = DistOptimizerHook(**cfg.train.optimizer_config)\n    else:\n        optimizer_config = cfg.train.optimizer_config\n    runner.register_training_hooks(cfg.train.lr_config, optimizer_config, cfg.train.checkpoint_config, cfg.train.log_config, cfg.train.get('momentum_config', None), custom_hooks_config=cfg.train.get('custom_hooks', None))\n    if distributed and cfg.train.runner['type'] == 'EpochBasedRunner':\n        runner.register_hook(DistSamplerSeedHook())\n    if val_dataset is not None:\n        val_dataloader = build_dataloader(val_dataset, samples_per_gpu=cfg.evaluation.dataloader.batch_size_per_gpu, workers_per_gpu=cfg.evaluation.dataloader.workers_per_gpu, dist=distributed, shuffle=False, round_up=True)\n        eval_cfg = cfg.train.get('evaluation', {})\n        eval_cfg['by_epoch'] = cfg.train.runner['type'] != 'IterBasedRunner'\n        eval_hook = DistEvalHook if distributed else EvalHook\n        runner.register_hook(eval_hook(val_dataloader, **eval_cfg), priority='LOW')\n    if cfg.train.resume_from:\n        runner.resume(cfg.train.resume_from, map_location='cpu')\n    elif cfg.train.load_from:\n        runner.load_checkpoint(cfg.train.load_from)\n    cfg.train.workflow = [tuple(flow) for flow in cfg.train.workflow]\n    runner.run(data_loaders, cfg.train.workflow)",
            "def train_model(model, dataset, cfg, distributed=False, val_dataset=None, timestamp=None, device=None, meta=None):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    import torch\n    import warnings\n    from mmcv.runner import DistSamplerSeedHook, Fp16OptimizerHook, build_optimizer, build_runner, get_dist_info\n    from mmcls.core import DistEvalHook, DistOptimizerHook, EvalHook\n    from mmcls.datasets import build_dataloader\n    from mmcls.utils import wrap_distributed_model, wrap_non_distributed_model\n    from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n    logger = get_logger()\n    dataset = dataset if isinstance(dataset, (list, tuple)) else [dataset]\n    sampler_cfg = cfg.train.get('sampler', None)\n    data_loaders = [build_dataloader(ds, cfg.train.dataloader.batch_size_per_gpu, cfg.train.dataloader.workers_per_gpu, num_gpus=len(cfg.gpu_ids), dist=distributed, round_up=True, seed=cfg.seed, sampler_cfg=sampler_cfg) for ds in dataset]\n    if distributed:\n        find_unused_parameters = cfg.get('find_unused_parameters', False)\n        model = MMDistributedDataParallel(model.cuda(), device_ids=[torch.cuda.current_device()], broadcast_buffers=False, find_unused_parameters=find_unused_parameters)\n    elif device == 'cpu':\n        logger.warning('The argument `device` is deprecated. To use cpu to train, please refers to https://mmclassification.readthedocs.io/en/latest/getting_started.html#train-a-model')\n        model = model.cpu()\n    else:\n        model = MMDataParallel(model, device_ids=cfg.gpu_ids)\n        if not model.device_ids:\n            from mmcv import __version__, digit_version\n            assert digit_version(__version__) >= (1, 4, 4), 'To train with CPU, please confirm your mmcv version is not lower than v1.4.4'\n    optimizer = build_optimizer(model, cfg.train.optimizer)\n    if cfg.train.get('runner') is None:\n        cfg.train.runner = {'type': 'EpochBasedRunner', 'max_epochs': cfg.train.max_epochs}\n        logger.warning('config is now expected to have a `runner` section, please set `runner` in your config.', UserWarning)\n    runner = build_runner(cfg.train.runner, default_args=dict(model=model, batch_processor=None, optimizer=optimizer, work_dir=cfg.work_dir, logger=logger, meta=meta))\n    runner.timestamp = timestamp\n    fp16_cfg = cfg.get('fp16', None)\n    if fp16_cfg is not None:\n        optimizer_config = Fp16OptimizerHook(**cfg.train.optimizer_config, **fp16_cfg, distributed=distributed)\n    elif distributed and 'type' not in cfg.train.optimizer_config:\n        optimizer_config = DistOptimizerHook(**cfg.train.optimizer_config)\n    else:\n        optimizer_config = cfg.train.optimizer_config\n    runner.register_training_hooks(cfg.train.lr_config, optimizer_config, cfg.train.checkpoint_config, cfg.train.log_config, cfg.train.get('momentum_config', None), custom_hooks_config=cfg.train.get('custom_hooks', None))\n    if distributed and cfg.train.runner['type'] == 'EpochBasedRunner':\n        runner.register_hook(DistSamplerSeedHook())\n    if val_dataset is not None:\n        val_dataloader = build_dataloader(val_dataset, samples_per_gpu=cfg.evaluation.dataloader.batch_size_per_gpu, workers_per_gpu=cfg.evaluation.dataloader.workers_per_gpu, dist=distributed, shuffle=False, round_up=True)\n        eval_cfg = cfg.train.get('evaluation', {})\n        eval_cfg['by_epoch'] = cfg.train.runner['type'] != 'IterBasedRunner'\n        eval_hook = DistEvalHook if distributed else EvalHook\n        runner.register_hook(eval_hook(val_dataloader, **eval_cfg), priority='LOW')\n    if cfg.train.resume_from:\n        runner.resume(cfg.train.resume_from, map_location='cpu')\n    elif cfg.train.load_from:\n        runner.load_checkpoint(cfg.train.load_from)\n    cfg.train.workflow = [tuple(flow) for flow in cfg.train.workflow]\n    runner.run(data_loaders, cfg.train.workflow)"
        ]
    },
    {
        "func_name": "__init__",
        "original": "def __init__(self, model: Optional[Union[TorchModel, nn.Module, str]]=None, cfg_file: Optional[str]=None, arg_parse_fn: Optional[Callable]=None, data_collator: Optional[Union[Callable, Dict[str, Callable]]]=None, train_dataset: Optional[Union[MsDataset, Dataset]]=None, eval_dataset: Optional[Union[MsDataset, Dataset]]=None, preprocessor: Optional[Union[Preprocessor, Dict[str, Preprocessor]]]=None, optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler._LRScheduler]=(None, None), model_revision: Optional[str]=DEFAULT_MODEL_REVISION, seed: int=0, cfg_modify_fn: Optional[Callable]=None, **kwargs):\n    \"\"\" High-level finetune api for Image Classifition.\n\n        Args:\n            model: model id\n            model_version: model version, default is None.\n            cfg_modify_fn: An input fn which is used to modify the cfg read out of the file.\n        \"\"\"\n    import torch\n    import mmcv\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, get_classes\n    from mmcls.models import build_classifier\n    from mmcv.runner import get_dist_info, init_dist\n    from mmcls.apis import set_random_seed\n    from mmcls.utils import collect_env\n    from mmcv.utils import get_logger as mmcv_get_logger\n    import modelscope.models.cv.image_classification.backbones\n    self._seed = seed\n    set_random_seed(self._seed)\n    if isinstance(model, str):\n        self.model_dir = self.get_or_download_model_dir(model, model_revision=model_revision)\n        if cfg_file is None:\n            cfg_file = os.path.join(self.model_dir, ModelFile.CONFIGURATION)\n    else:\n        assert cfg_file is not None, 'Config file should not be None if model is not from pretrained!'\n        self.model_dir = os.path.dirname(cfg_file)\n    super().__init__(cfg_file, arg_parse_fn)\n    cfg = self.cfg\n    if 'work_dir' in kwargs:\n        self.work_dir = kwargs['work_dir']\n    else:\n        self.work_dir = self.cfg.train.get('work_dir', './work_dir')\n    mmcv.mkdir_or_exist(osp.abspath(self.work_dir))\n    cfg.work_dir = self.work_dir\n    self.eval_checkpoint_path = os.path.join(self.model_dir, ModelFile.TORCH_MODEL_FILE)\n    if 'resume_from' in kwargs:\n        cfg.train.resume_from = kwargs['resume_from']\n    else:\n        cfg.train.resume_from = cfg.train.get('resume_from', None)\n    if 'load_from' in kwargs:\n        cfg.train.load_from = kwargs['load_from']\n    elif cfg.train.get('resume_from', None) is None:\n        cfg.train.load_from = os.path.join(self.model_dir, ModelFile.TORCH_MODEL_FILE)\n    if 'device' in kwargs:\n        cfg.device = kwargs['device']\n    else:\n        cfg.device = cfg.get('device', 'cuda')\n    if 'gpu_ids' in kwargs:\n        cfg.gpu_ids = kwargs['gpu_ids'][0:1]\n    else:\n        cfg.gpu_ids = [0]\n    if 'fp16' in kwargs:\n        cfg.fp16 = None if kwargs['fp16'] is None else kwargs['fp16']\n    else:\n        cfg.fp16 = None\n    cfg.no_validate = kwargs.get('no_validate', False)\n    if cfg_modify_fn is not None:\n        cfg = cfg_modify_fn(cfg)\n    if 'max_epochs' not in kwargs:\n        assert hasattr(self.cfg.train, 'max_epochs'), 'max_epochs is missing in configuration file'\n        self.max_epochs = self.cfg.train.max_epochs\n    else:\n        self.max_epochs = kwargs['max_epochs']\n    cfg.train.max_epochs = self.max_epochs\n    if cfg.train.get('runner', None) is not None:\n        cfg.train.runner.max_epochs = self.max_epochs\n    if 'launcher' in kwargs:\n        distributed = True\n        dist_params = kwargs['dist_params'] if 'dist_params' in kwargs else {'backend': 'nccl'}\n        init_dist(kwargs['launcher'], **dist_params)\n        (_, world_size) = get_dist_info()\n        cfg.gpu_ids = list(range(world_size))\n    else:\n        distributed = False\n    mmcv_get_logger('modelscope')\n    timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n    log_file = osp.join(self.work_dir, f'{timestamp}.log')\n    logger = get_logger(log_file=log_file)\n    meta = dict()\n    env_info_dict = collect_env()\n    env_info = '\\n'.join([f'{k}: {v}' for (k, v) in env_info_dict.items()])\n    dash_line = '-' * 60 + '\\n'\n    logger.info('Environment info:\\n' + dash_line + env_info + '\\n' + dash_line)\n    meta['env_info'] = env_info\n    meta['config'] = cfg.pretty_text\n    logger.info(f'Distributed training: {distributed}')\n    logger.info(f'Config:\\n{cfg.pretty_text}')\n    cfg.seed = self._seed\n    _deterministic = kwargs.get('deterministic', False)\n    logger.info(f'Set random seed to {cfg.seed}, deterministic: {_deterministic}')\n    set_random_seed(cfg.seed, deterministic=_deterministic)\n    meta['seed'] = cfg.seed\n    meta['exp_name'] = osp.basename(cfg_file)\n    self.train_dataset = train_dataset\n    self.eval_dataset = eval_dataset\n    if cfg.dataset.get('data_prefix', None) is None:\n        self.data_prefix = ''\n    else:\n        self.data_prefix = cfg.dataset.data_prefix\n    model = build_classifier(self.cfg.model.mm_model)\n    model.init_weights()\n    self.cfg = cfg\n    self.device = cfg.device\n    self.cfg_file = cfg_file\n    self.model = model\n    self.distributed = distributed\n    self.timestamp = timestamp\n    self.meta = meta\n    self.logger = logger",
        "mutated": [
            "def __init__(self, model: Optional[Union[TorchModel, nn.Module, str]]=None, cfg_file: Optional[str]=None, arg_parse_fn: Optional[Callable]=None, data_collator: Optional[Union[Callable, Dict[str, Callable]]]=None, train_dataset: Optional[Union[MsDataset, Dataset]]=None, eval_dataset: Optional[Union[MsDataset, Dataset]]=None, preprocessor: Optional[Union[Preprocessor, Dict[str, Preprocessor]]]=None, optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler._LRScheduler]=(None, None), model_revision: Optional[str]=DEFAULT_MODEL_REVISION, seed: int=0, cfg_modify_fn: Optional[Callable]=None, **kwargs):\n    if False:\n        i = 10\n    ' High-level finetune api for Image Classifition.\\n\\n        Args:\\n            model: model id\\n            model_version: model version, default is None.\\n            cfg_modify_fn: An input fn which is used to modify the cfg read out of the file.\\n        '\n    import torch\n    import mmcv\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, get_classes\n    from mmcls.models import build_classifier\n    from mmcv.runner import get_dist_info, init_dist\n    from mmcls.apis import set_random_seed\n    from mmcls.utils import collect_env\n    from mmcv.utils import get_logger as mmcv_get_logger\n    import modelscope.models.cv.image_classification.backbones\n    self._seed = seed\n    set_random_seed(self._seed)\n    if isinstance(model, str):\n        self.model_dir = self.get_or_download_model_dir(model, model_revision=model_revision)\n        if cfg_file is None:\n            cfg_file = os.path.join(self.model_dir, ModelFile.CONFIGURATION)\n    else:\n        assert cfg_file is not None, 'Config file should not be None if model is not from pretrained!'\n        self.model_dir = os.path.dirname(cfg_file)\n    super().__init__(cfg_file, arg_parse_fn)\n    cfg = self.cfg\n    if 'work_dir' in kwargs:\n        self.work_dir = kwargs['work_dir']\n    else:\n        self.work_dir = self.cfg.train.get('work_dir', './work_dir')\n    mmcv.mkdir_or_exist(osp.abspath(self.work_dir))\n    cfg.work_dir = self.work_dir\n    self.eval_checkpoint_path = os.path.join(self.model_dir, ModelFile.TORCH_MODEL_FILE)\n    if 'resume_from' in kwargs:\n        cfg.train.resume_from = kwargs['resume_from']\n    else:\n        cfg.train.resume_from = cfg.train.get('resume_from', None)\n    if 'load_from' in kwargs:\n        cfg.train.load_from = kwargs['load_from']\n    elif cfg.train.get('resume_from', None) is None:\n        cfg.train.load_from = os.path.join(self.model_dir, ModelFile.TORCH_MODEL_FILE)\n    if 'device' in kwargs:\n        cfg.device = kwargs['device']\n    else:\n        cfg.device = cfg.get('device', 'cuda')\n    if 'gpu_ids' in kwargs:\n        cfg.gpu_ids = kwargs['gpu_ids'][0:1]\n    else:\n        cfg.gpu_ids = [0]\n    if 'fp16' in kwargs:\n        cfg.fp16 = None if kwargs['fp16'] is None else kwargs['fp16']\n    else:\n        cfg.fp16 = None\n    cfg.no_validate = kwargs.get('no_validate', False)\n    if cfg_modify_fn is not None:\n        cfg = cfg_modify_fn(cfg)\n    if 'max_epochs' not in kwargs:\n        assert hasattr(self.cfg.train, 'max_epochs'), 'max_epochs is missing in configuration file'\n        self.max_epochs = self.cfg.train.max_epochs\n    else:\n        self.max_epochs = kwargs['max_epochs']\n    cfg.train.max_epochs = self.max_epochs\n    if cfg.train.get('runner', None) is not None:\n        cfg.train.runner.max_epochs = self.max_epochs\n    if 'launcher' in kwargs:\n        distributed = True\n        dist_params = kwargs['dist_params'] if 'dist_params' in kwargs else {'backend': 'nccl'}\n        init_dist(kwargs['launcher'], **dist_params)\n        (_, world_size) = get_dist_info()\n        cfg.gpu_ids = list(range(world_size))\n    else:\n        distributed = False\n    mmcv_get_logger('modelscope')\n    timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n    log_file = osp.join(self.work_dir, f'{timestamp}.log')\n    logger = get_logger(log_file=log_file)\n    meta = dict()\n    env_info_dict = collect_env()\n    env_info = '\\n'.join([f'{k}: {v}' for (k, v) in env_info_dict.items()])\n    dash_line = '-' * 60 + '\\n'\n    logger.info('Environment info:\\n' + dash_line + env_info + '\\n' + dash_line)\n    meta['env_info'] = env_info\n    meta['config'] = cfg.pretty_text\n    logger.info(f'Distributed training: {distributed}')\n    logger.info(f'Config:\\n{cfg.pretty_text}')\n    cfg.seed = self._seed\n    _deterministic = kwargs.get('deterministic', False)\n    logger.info(f'Set random seed to {cfg.seed}, deterministic: {_deterministic}')\n    set_random_seed(cfg.seed, deterministic=_deterministic)\n    meta['seed'] = cfg.seed\n    meta['exp_name'] = osp.basename(cfg_file)\n    self.train_dataset = train_dataset\n    self.eval_dataset = eval_dataset\n    if cfg.dataset.get('data_prefix', None) is None:\n        self.data_prefix = ''\n    else:\n        self.data_prefix = cfg.dataset.data_prefix\n    model = build_classifier(self.cfg.model.mm_model)\n    model.init_weights()\n    self.cfg = cfg\n    self.device = cfg.device\n    self.cfg_file = cfg_file\n    self.model = model\n    self.distributed = distributed\n    self.timestamp = timestamp\n    self.meta = meta\n    self.logger = logger",
            "def __init__(self, model: Optional[Union[TorchModel, nn.Module, str]]=None, cfg_file: Optional[str]=None, arg_parse_fn: Optional[Callable]=None, data_collator: Optional[Union[Callable, Dict[str, Callable]]]=None, train_dataset: Optional[Union[MsDataset, Dataset]]=None, eval_dataset: Optional[Union[MsDataset, Dataset]]=None, preprocessor: Optional[Union[Preprocessor, Dict[str, Preprocessor]]]=None, optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler._LRScheduler]=(None, None), model_revision: Optional[str]=DEFAULT_MODEL_REVISION, seed: int=0, cfg_modify_fn: Optional[Callable]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    ' High-level finetune api for Image Classifition.\\n\\n        Args:\\n            model: model id\\n            model_version: model version, default is None.\\n            cfg_modify_fn: An input fn which is used to modify the cfg read out of the file.\\n        '\n    import torch\n    import mmcv\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, get_classes\n    from mmcls.models import build_classifier\n    from mmcv.runner import get_dist_info, init_dist\n    from mmcls.apis import set_random_seed\n    from mmcls.utils import collect_env\n    from mmcv.utils import get_logger as mmcv_get_logger\n    import modelscope.models.cv.image_classification.backbones\n    self._seed = seed\n    set_random_seed(self._seed)\n    if isinstance(model, str):\n        self.model_dir = self.get_or_download_model_dir(model, model_revision=model_revision)\n        if cfg_file is None:\n            cfg_file = os.path.join(self.model_dir, ModelFile.CONFIGURATION)\n    else:\n        assert cfg_file is not None, 'Config file should not be None if model is not from pretrained!'\n        self.model_dir = os.path.dirname(cfg_file)\n    super().__init__(cfg_file, arg_parse_fn)\n    cfg = self.cfg\n    if 'work_dir' in kwargs:\n        self.work_dir = kwargs['work_dir']\n    else:\n        self.work_dir = self.cfg.train.get('work_dir', './work_dir')\n    mmcv.mkdir_or_exist(osp.abspath(self.work_dir))\n    cfg.work_dir = self.work_dir\n    self.eval_checkpoint_path = os.path.join(self.model_dir, ModelFile.TORCH_MODEL_FILE)\n    if 'resume_from' in kwargs:\n        cfg.train.resume_from = kwargs['resume_from']\n    else:\n        cfg.train.resume_from = cfg.train.get('resume_from', None)\n    if 'load_from' in kwargs:\n        cfg.train.load_from = kwargs['load_from']\n    elif cfg.train.get('resume_from', None) is None:\n        cfg.train.load_from = os.path.join(self.model_dir, ModelFile.TORCH_MODEL_FILE)\n    if 'device' in kwargs:\n        cfg.device = kwargs['device']\n    else:\n        cfg.device = cfg.get('device', 'cuda')\n    if 'gpu_ids' in kwargs:\n        cfg.gpu_ids = kwargs['gpu_ids'][0:1]\n    else:\n        cfg.gpu_ids = [0]\n    if 'fp16' in kwargs:\n        cfg.fp16 = None if kwargs['fp16'] is None else kwargs['fp16']\n    else:\n        cfg.fp16 = None\n    cfg.no_validate = kwargs.get('no_validate', False)\n    if cfg_modify_fn is not None:\n        cfg = cfg_modify_fn(cfg)\n    if 'max_epochs' not in kwargs:\n        assert hasattr(self.cfg.train, 'max_epochs'), 'max_epochs is missing in configuration file'\n        self.max_epochs = self.cfg.train.max_epochs\n    else:\n        self.max_epochs = kwargs['max_epochs']\n    cfg.train.max_epochs = self.max_epochs\n    if cfg.train.get('runner', None) is not None:\n        cfg.train.runner.max_epochs = self.max_epochs\n    if 'launcher' in kwargs:\n        distributed = True\n        dist_params = kwargs['dist_params'] if 'dist_params' in kwargs else {'backend': 'nccl'}\n        init_dist(kwargs['launcher'], **dist_params)\n        (_, world_size) = get_dist_info()\n        cfg.gpu_ids = list(range(world_size))\n    else:\n        distributed = False\n    mmcv_get_logger('modelscope')\n    timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n    log_file = osp.join(self.work_dir, f'{timestamp}.log')\n    logger = get_logger(log_file=log_file)\n    meta = dict()\n    env_info_dict = collect_env()\n    env_info = '\\n'.join([f'{k}: {v}' for (k, v) in env_info_dict.items()])\n    dash_line = '-' * 60 + '\\n'\n    logger.info('Environment info:\\n' + dash_line + env_info + '\\n' + dash_line)\n    meta['env_info'] = env_info\n    meta['config'] = cfg.pretty_text\n    logger.info(f'Distributed training: {distributed}')\n    logger.info(f'Config:\\n{cfg.pretty_text}')\n    cfg.seed = self._seed\n    _deterministic = kwargs.get('deterministic', False)\n    logger.info(f'Set random seed to {cfg.seed}, deterministic: {_deterministic}')\n    set_random_seed(cfg.seed, deterministic=_deterministic)\n    meta['seed'] = cfg.seed\n    meta['exp_name'] = osp.basename(cfg_file)\n    self.train_dataset = train_dataset\n    self.eval_dataset = eval_dataset\n    if cfg.dataset.get('data_prefix', None) is None:\n        self.data_prefix = ''\n    else:\n        self.data_prefix = cfg.dataset.data_prefix\n    model = build_classifier(self.cfg.model.mm_model)\n    model.init_weights()\n    self.cfg = cfg\n    self.device = cfg.device\n    self.cfg_file = cfg_file\n    self.model = model\n    self.distributed = distributed\n    self.timestamp = timestamp\n    self.meta = meta\n    self.logger = logger",
            "def __init__(self, model: Optional[Union[TorchModel, nn.Module, str]]=None, cfg_file: Optional[str]=None, arg_parse_fn: Optional[Callable]=None, data_collator: Optional[Union[Callable, Dict[str, Callable]]]=None, train_dataset: Optional[Union[MsDataset, Dataset]]=None, eval_dataset: Optional[Union[MsDataset, Dataset]]=None, preprocessor: Optional[Union[Preprocessor, Dict[str, Preprocessor]]]=None, optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler._LRScheduler]=(None, None), model_revision: Optional[str]=DEFAULT_MODEL_REVISION, seed: int=0, cfg_modify_fn: Optional[Callable]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    ' High-level finetune api for Image Classifition.\\n\\n        Args:\\n            model: model id\\n            model_version: model version, default is None.\\n            cfg_modify_fn: An input fn which is used to modify the cfg read out of the file.\\n        '\n    import torch\n    import mmcv\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, get_classes\n    from mmcls.models import build_classifier\n    from mmcv.runner import get_dist_info, init_dist\n    from mmcls.apis import set_random_seed\n    from mmcls.utils import collect_env\n    from mmcv.utils import get_logger as mmcv_get_logger\n    import modelscope.models.cv.image_classification.backbones\n    self._seed = seed\n    set_random_seed(self._seed)\n    if isinstance(model, str):\n        self.model_dir = self.get_or_download_model_dir(model, model_revision=model_revision)\n        if cfg_file is None:\n            cfg_file = os.path.join(self.model_dir, ModelFile.CONFIGURATION)\n    else:\n        assert cfg_file is not None, 'Config file should not be None if model is not from pretrained!'\n        self.model_dir = os.path.dirname(cfg_file)\n    super().__init__(cfg_file, arg_parse_fn)\n    cfg = self.cfg\n    if 'work_dir' in kwargs:\n        self.work_dir = kwargs['work_dir']\n    else:\n        self.work_dir = self.cfg.train.get('work_dir', './work_dir')\n    mmcv.mkdir_or_exist(osp.abspath(self.work_dir))\n    cfg.work_dir = self.work_dir\n    self.eval_checkpoint_path = os.path.join(self.model_dir, ModelFile.TORCH_MODEL_FILE)\n    if 'resume_from' in kwargs:\n        cfg.train.resume_from = kwargs['resume_from']\n    else:\n        cfg.train.resume_from = cfg.train.get('resume_from', None)\n    if 'load_from' in kwargs:\n        cfg.train.load_from = kwargs['load_from']\n    elif cfg.train.get('resume_from', None) is None:\n        cfg.train.load_from = os.path.join(self.model_dir, ModelFile.TORCH_MODEL_FILE)\n    if 'device' in kwargs:\n        cfg.device = kwargs['device']\n    else:\n        cfg.device = cfg.get('device', 'cuda')\n    if 'gpu_ids' in kwargs:\n        cfg.gpu_ids = kwargs['gpu_ids'][0:1]\n    else:\n        cfg.gpu_ids = [0]\n    if 'fp16' in kwargs:\n        cfg.fp16 = None if kwargs['fp16'] is None else kwargs['fp16']\n    else:\n        cfg.fp16 = None\n    cfg.no_validate = kwargs.get('no_validate', False)\n    if cfg_modify_fn is not None:\n        cfg = cfg_modify_fn(cfg)\n    if 'max_epochs' not in kwargs:\n        assert hasattr(self.cfg.train, 'max_epochs'), 'max_epochs is missing in configuration file'\n        self.max_epochs = self.cfg.train.max_epochs\n    else:\n        self.max_epochs = kwargs['max_epochs']\n    cfg.train.max_epochs = self.max_epochs\n    if cfg.train.get('runner', None) is not None:\n        cfg.train.runner.max_epochs = self.max_epochs\n    if 'launcher' in kwargs:\n        distributed = True\n        dist_params = kwargs['dist_params'] if 'dist_params' in kwargs else {'backend': 'nccl'}\n        init_dist(kwargs['launcher'], **dist_params)\n        (_, world_size) = get_dist_info()\n        cfg.gpu_ids = list(range(world_size))\n    else:\n        distributed = False\n    mmcv_get_logger('modelscope')\n    timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n    log_file = osp.join(self.work_dir, f'{timestamp}.log')\n    logger = get_logger(log_file=log_file)\n    meta = dict()\n    env_info_dict = collect_env()\n    env_info = '\\n'.join([f'{k}: {v}' for (k, v) in env_info_dict.items()])\n    dash_line = '-' * 60 + '\\n'\n    logger.info('Environment info:\\n' + dash_line + env_info + '\\n' + dash_line)\n    meta['env_info'] = env_info\n    meta['config'] = cfg.pretty_text\n    logger.info(f'Distributed training: {distributed}')\n    logger.info(f'Config:\\n{cfg.pretty_text}')\n    cfg.seed = self._seed\n    _deterministic = kwargs.get('deterministic', False)\n    logger.info(f'Set random seed to {cfg.seed}, deterministic: {_deterministic}')\n    set_random_seed(cfg.seed, deterministic=_deterministic)\n    meta['seed'] = cfg.seed\n    meta['exp_name'] = osp.basename(cfg_file)\n    self.train_dataset = train_dataset\n    self.eval_dataset = eval_dataset\n    if cfg.dataset.get('data_prefix', None) is None:\n        self.data_prefix = ''\n    else:\n        self.data_prefix = cfg.dataset.data_prefix\n    model = build_classifier(self.cfg.model.mm_model)\n    model.init_weights()\n    self.cfg = cfg\n    self.device = cfg.device\n    self.cfg_file = cfg_file\n    self.model = model\n    self.distributed = distributed\n    self.timestamp = timestamp\n    self.meta = meta\n    self.logger = logger",
            "def __init__(self, model: Optional[Union[TorchModel, nn.Module, str]]=None, cfg_file: Optional[str]=None, arg_parse_fn: Optional[Callable]=None, data_collator: Optional[Union[Callable, Dict[str, Callable]]]=None, train_dataset: Optional[Union[MsDataset, Dataset]]=None, eval_dataset: Optional[Union[MsDataset, Dataset]]=None, preprocessor: Optional[Union[Preprocessor, Dict[str, Preprocessor]]]=None, optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler._LRScheduler]=(None, None), model_revision: Optional[str]=DEFAULT_MODEL_REVISION, seed: int=0, cfg_modify_fn: Optional[Callable]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    ' High-level finetune api for Image Classifition.\\n\\n        Args:\\n            model: model id\\n            model_version: model version, default is None.\\n            cfg_modify_fn: An input fn which is used to modify the cfg read out of the file.\\n        '\n    import torch\n    import mmcv\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, get_classes\n    from mmcls.models import build_classifier\n    from mmcv.runner import get_dist_info, init_dist\n    from mmcls.apis import set_random_seed\n    from mmcls.utils import collect_env\n    from mmcv.utils import get_logger as mmcv_get_logger\n    import modelscope.models.cv.image_classification.backbones\n    self._seed = seed\n    set_random_seed(self._seed)\n    if isinstance(model, str):\n        self.model_dir = self.get_or_download_model_dir(model, model_revision=model_revision)\n        if cfg_file is None:\n            cfg_file = os.path.join(self.model_dir, ModelFile.CONFIGURATION)\n    else:\n        assert cfg_file is not None, 'Config file should not be None if model is not from pretrained!'\n        self.model_dir = os.path.dirname(cfg_file)\n    super().__init__(cfg_file, arg_parse_fn)\n    cfg = self.cfg\n    if 'work_dir' in kwargs:\n        self.work_dir = kwargs['work_dir']\n    else:\n        self.work_dir = self.cfg.train.get('work_dir', './work_dir')\n    mmcv.mkdir_or_exist(osp.abspath(self.work_dir))\n    cfg.work_dir = self.work_dir\n    self.eval_checkpoint_path = os.path.join(self.model_dir, ModelFile.TORCH_MODEL_FILE)\n    if 'resume_from' in kwargs:\n        cfg.train.resume_from = kwargs['resume_from']\n    else:\n        cfg.train.resume_from = cfg.train.get('resume_from', None)\n    if 'load_from' in kwargs:\n        cfg.train.load_from = kwargs['load_from']\n    elif cfg.train.get('resume_from', None) is None:\n        cfg.train.load_from = os.path.join(self.model_dir, ModelFile.TORCH_MODEL_FILE)\n    if 'device' in kwargs:\n        cfg.device = kwargs['device']\n    else:\n        cfg.device = cfg.get('device', 'cuda')\n    if 'gpu_ids' in kwargs:\n        cfg.gpu_ids = kwargs['gpu_ids'][0:1]\n    else:\n        cfg.gpu_ids = [0]\n    if 'fp16' in kwargs:\n        cfg.fp16 = None if kwargs['fp16'] is None else kwargs['fp16']\n    else:\n        cfg.fp16 = None\n    cfg.no_validate = kwargs.get('no_validate', False)\n    if cfg_modify_fn is not None:\n        cfg = cfg_modify_fn(cfg)\n    if 'max_epochs' not in kwargs:\n        assert hasattr(self.cfg.train, 'max_epochs'), 'max_epochs is missing in configuration file'\n        self.max_epochs = self.cfg.train.max_epochs\n    else:\n        self.max_epochs = kwargs['max_epochs']\n    cfg.train.max_epochs = self.max_epochs\n    if cfg.train.get('runner', None) is not None:\n        cfg.train.runner.max_epochs = self.max_epochs\n    if 'launcher' in kwargs:\n        distributed = True\n        dist_params = kwargs['dist_params'] if 'dist_params' in kwargs else {'backend': 'nccl'}\n        init_dist(kwargs['launcher'], **dist_params)\n        (_, world_size) = get_dist_info()\n        cfg.gpu_ids = list(range(world_size))\n    else:\n        distributed = False\n    mmcv_get_logger('modelscope')\n    timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n    log_file = osp.join(self.work_dir, f'{timestamp}.log')\n    logger = get_logger(log_file=log_file)\n    meta = dict()\n    env_info_dict = collect_env()\n    env_info = '\\n'.join([f'{k}: {v}' for (k, v) in env_info_dict.items()])\n    dash_line = '-' * 60 + '\\n'\n    logger.info('Environment info:\\n' + dash_line + env_info + '\\n' + dash_line)\n    meta['env_info'] = env_info\n    meta['config'] = cfg.pretty_text\n    logger.info(f'Distributed training: {distributed}')\n    logger.info(f'Config:\\n{cfg.pretty_text}')\n    cfg.seed = self._seed\n    _deterministic = kwargs.get('deterministic', False)\n    logger.info(f'Set random seed to {cfg.seed}, deterministic: {_deterministic}')\n    set_random_seed(cfg.seed, deterministic=_deterministic)\n    meta['seed'] = cfg.seed\n    meta['exp_name'] = osp.basename(cfg_file)\n    self.train_dataset = train_dataset\n    self.eval_dataset = eval_dataset\n    if cfg.dataset.get('data_prefix', None) is None:\n        self.data_prefix = ''\n    else:\n        self.data_prefix = cfg.dataset.data_prefix\n    model = build_classifier(self.cfg.model.mm_model)\n    model.init_weights()\n    self.cfg = cfg\n    self.device = cfg.device\n    self.cfg_file = cfg_file\n    self.model = model\n    self.distributed = distributed\n    self.timestamp = timestamp\n    self.meta = meta\n    self.logger = logger",
            "def __init__(self, model: Optional[Union[TorchModel, nn.Module, str]]=None, cfg_file: Optional[str]=None, arg_parse_fn: Optional[Callable]=None, data_collator: Optional[Union[Callable, Dict[str, Callable]]]=None, train_dataset: Optional[Union[MsDataset, Dataset]]=None, eval_dataset: Optional[Union[MsDataset, Dataset]]=None, preprocessor: Optional[Union[Preprocessor, Dict[str, Preprocessor]]]=None, optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler._LRScheduler]=(None, None), model_revision: Optional[str]=DEFAULT_MODEL_REVISION, seed: int=0, cfg_modify_fn: Optional[Callable]=None, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    ' High-level finetune api for Image Classifition.\\n\\n        Args:\\n            model: model id\\n            model_version: model version, default is None.\\n            cfg_modify_fn: An input fn which is used to modify the cfg read out of the file.\\n        '\n    import torch\n    import mmcv\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, get_classes\n    from mmcls.models import build_classifier\n    from mmcv.runner import get_dist_info, init_dist\n    from mmcls.apis import set_random_seed\n    from mmcls.utils import collect_env\n    from mmcv.utils import get_logger as mmcv_get_logger\n    import modelscope.models.cv.image_classification.backbones\n    self._seed = seed\n    set_random_seed(self._seed)\n    if isinstance(model, str):\n        self.model_dir = self.get_or_download_model_dir(model, model_revision=model_revision)\n        if cfg_file is None:\n            cfg_file = os.path.join(self.model_dir, ModelFile.CONFIGURATION)\n    else:\n        assert cfg_file is not None, 'Config file should not be None if model is not from pretrained!'\n        self.model_dir = os.path.dirname(cfg_file)\n    super().__init__(cfg_file, arg_parse_fn)\n    cfg = self.cfg\n    if 'work_dir' in kwargs:\n        self.work_dir = kwargs['work_dir']\n    else:\n        self.work_dir = self.cfg.train.get('work_dir', './work_dir')\n    mmcv.mkdir_or_exist(osp.abspath(self.work_dir))\n    cfg.work_dir = self.work_dir\n    self.eval_checkpoint_path = os.path.join(self.model_dir, ModelFile.TORCH_MODEL_FILE)\n    if 'resume_from' in kwargs:\n        cfg.train.resume_from = kwargs['resume_from']\n    else:\n        cfg.train.resume_from = cfg.train.get('resume_from', None)\n    if 'load_from' in kwargs:\n        cfg.train.load_from = kwargs['load_from']\n    elif cfg.train.get('resume_from', None) is None:\n        cfg.train.load_from = os.path.join(self.model_dir, ModelFile.TORCH_MODEL_FILE)\n    if 'device' in kwargs:\n        cfg.device = kwargs['device']\n    else:\n        cfg.device = cfg.get('device', 'cuda')\n    if 'gpu_ids' in kwargs:\n        cfg.gpu_ids = kwargs['gpu_ids'][0:1]\n    else:\n        cfg.gpu_ids = [0]\n    if 'fp16' in kwargs:\n        cfg.fp16 = None if kwargs['fp16'] is None else kwargs['fp16']\n    else:\n        cfg.fp16 = None\n    cfg.no_validate = kwargs.get('no_validate', False)\n    if cfg_modify_fn is not None:\n        cfg = cfg_modify_fn(cfg)\n    if 'max_epochs' not in kwargs:\n        assert hasattr(self.cfg.train, 'max_epochs'), 'max_epochs is missing in configuration file'\n        self.max_epochs = self.cfg.train.max_epochs\n    else:\n        self.max_epochs = kwargs['max_epochs']\n    cfg.train.max_epochs = self.max_epochs\n    if cfg.train.get('runner', None) is not None:\n        cfg.train.runner.max_epochs = self.max_epochs\n    if 'launcher' in kwargs:\n        distributed = True\n        dist_params = kwargs['dist_params'] if 'dist_params' in kwargs else {'backend': 'nccl'}\n        init_dist(kwargs['launcher'], **dist_params)\n        (_, world_size) = get_dist_info()\n        cfg.gpu_ids = list(range(world_size))\n    else:\n        distributed = False\n    mmcv_get_logger('modelscope')\n    timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n    log_file = osp.join(self.work_dir, f'{timestamp}.log')\n    logger = get_logger(log_file=log_file)\n    meta = dict()\n    env_info_dict = collect_env()\n    env_info = '\\n'.join([f'{k}: {v}' for (k, v) in env_info_dict.items()])\n    dash_line = '-' * 60 + '\\n'\n    logger.info('Environment info:\\n' + dash_line + env_info + '\\n' + dash_line)\n    meta['env_info'] = env_info\n    meta['config'] = cfg.pretty_text\n    logger.info(f'Distributed training: {distributed}')\n    logger.info(f'Config:\\n{cfg.pretty_text}')\n    cfg.seed = self._seed\n    _deterministic = kwargs.get('deterministic', False)\n    logger.info(f'Set random seed to {cfg.seed}, deterministic: {_deterministic}')\n    set_random_seed(cfg.seed, deterministic=_deterministic)\n    meta['seed'] = cfg.seed\n    meta['exp_name'] = osp.basename(cfg_file)\n    self.train_dataset = train_dataset\n    self.eval_dataset = eval_dataset\n    if cfg.dataset.get('data_prefix', None) is None:\n        self.data_prefix = ''\n    else:\n        self.data_prefix = cfg.dataset.data_prefix\n    model = build_classifier(self.cfg.model.mm_model)\n    model.init_weights()\n    self.cfg = cfg\n    self.device = cfg.device\n    self.cfg_file = cfg_file\n    self.model = model\n    self.distributed = distributed\n    self.timestamp = timestamp\n    self.meta = meta\n    self.logger = logger"
        ]
    },
    {
        "func_name": "train",
        "original": "def train(self, *args, **kwargs):\n    from mmcls import __version__\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, MmDataset, preprocess_transform\n    from mmcls.utils import setup_multi_processes\n    if self.train_dataset is None:\n        raise ValueError(\"Not found train dataset, please set the 'train_dataset' parameter!\")\n    self.cfg.model.mm_model.pretrained = None\n    self.cfg.dump(osp.join(self.work_dir, osp.basename(self.cfg_file)))\n    if self.cfg.dataset.classes is None:\n        data_root = get_ms_dataset_root(self.train_dataset)\n        classname_path = osp.join(data_root, 'classname.txt')\n        classes = classname_path if osp.exists(classname_path) else None\n    else:\n        classes = self.cfg.dataset.classes\n    datasets = [MmDataset(self.train_dataset, pipeline=self.cfg.preprocessor.train, classes=classes, data_prefix=self.data_prefix)]\n    if len(self.cfg.train.workflow) == 2:\n        if self.eval_dataset is None:\n            raise ValueError(\"Not found evaluate dataset, please set the 'eval_dataset' parameter!\")\n        val_data_pipeline = self.cfg.preprocessor.train\n        val_dataset = MmDataset(self.eval_dataset, pipeline=val_data_pipeline, classes=classes, data_prefix=self.data_prefix)\n        datasets.append(val_dataset)\n    self.meta.update(dict(mmcls_version=__version__, config=self.cfg.pretty_text, CLASSES=datasets[0].CLASSES))\n    val_dataset = None\n    if not self.cfg.no_validate:\n        val_dataset = MmDataset(self.eval_dataset, pipeline=preprocess_transform(self.cfg.preprocessor.val), classes=classes, data_prefix=self.data_prefix)\n    train_model(self.model, datasets, self.cfg, distributed=self.distributed, val_dataset=val_dataset, timestamp=self.timestamp, device='cpu' if self.device == 'cpu' else 'cuda', meta=self.meta)",
        "mutated": [
            "def train(self, *args, **kwargs):\n    if False:\n        i = 10\n    from mmcls import __version__\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, MmDataset, preprocess_transform\n    from mmcls.utils import setup_multi_processes\n    if self.train_dataset is None:\n        raise ValueError(\"Not found train dataset, please set the 'train_dataset' parameter!\")\n    self.cfg.model.mm_model.pretrained = None\n    self.cfg.dump(osp.join(self.work_dir, osp.basename(self.cfg_file)))\n    if self.cfg.dataset.classes is None:\n        data_root = get_ms_dataset_root(self.train_dataset)\n        classname_path = osp.join(data_root, 'classname.txt')\n        classes = classname_path if osp.exists(classname_path) else None\n    else:\n        classes = self.cfg.dataset.classes\n    datasets = [MmDataset(self.train_dataset, pipeline=self.cfg.preprocessor.train, classes=classes, data_prefix=self.data_prefix)]\n    if len(self.cfg.train.workflow) == 2:\n        if self.eval_dataset is None:\n            raise ValueError(\"Not found evaluate dataset, please set the 'eval_dataset' parameter!\")\n        val_data_pipeline = self.cfg.preprocessor.train\n        val_dataset = MmDataset(self.eval_dataset, pipeline=val_data_pipeline, classes=classes, data_prefix=self.data_prefix)\n        datasets.append(val_dataset)\n    self.meta.update(dict(mmcls_version=__version__, config=self.cfg.pretty_text, CLASSES=datasets[0].CLASSES))\n    val_dataset = None\n    if not self.cfg.no_validate:\n        val_dataset = MmDataset(self.eval_dataset, pipeline=preprocess_transform(self.cfg.preprocessor.val), classes=classes, data_prefix=self.data_prefix)\n    train_model(self.model, datasets, self.cfg, distributed=self.distributed, val_dataset=val_dataset, timestamp=self.timestamp, device='cpu' if self.device == 'cpu' else 'cuda', meta=self.meta)",
            "def train(self, *args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    from mmcls import __version__\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, MmDataset, preprocess_transform\n    from mmcls.utils import setup_multi_processes\n    if self.train_dataset is None:\n        raise ValueError(\"Not found train dataset, please set the 'train_dataset' parameter!\")\n    self.cfg.model.mm_model.pretrained = None\n    self.cfg.dump(osp.join(self.work_dir, osp.basename(self.cfg_file)))\n    if self.cfg.dataset.classes is None:\n        data_root = get_ms_dataset_root(self.train_dataset)\n        classname_path = osp.join(data_root, 'classname.txt')\n        classes = classname_path if osp.exists(classname_path) else None\n    else:\n        classes = self.cfg.dataset.classes\n    datasets = [MmDataset(self.train_dataset, pipeline=self.cfg.preprocessor.train, classes=classes, data_prefix=self.data_prefix)]\n    if len(self.cfg.train.workflow) == 2:\n        if self.eval_dataset is None:\n            raise ValueError(\"Not found evaluate dataset, please set the 'eval_dataset' parameter!\")\n        val_data_pipeline = self.cfg.preprocessor.train\n        val_dataset = MmDataset(self.eval_dataset, pipeline=val_data_pipeline, classes=classes, data_prefix=self.data_prefix)\n        datasets.append(val_dataset)\n    self.meta.update(dict(mmcls_version=__version__, config=self.cfg.pretty_text, CLASSES=datasets[0].CLASSES))\n    val_dataset = None\n    if not self.cfg.no_validate:\n        val_dataset = MmDataset(self.eval_dataset, pipeline=preprocess_transform(self.cfg.preprocessor.val), classes=classes, data_prefix=self.data_prefix)\n    train_model(self.model, datasets, self.cfg, distributed=self.distributed, val_dataset=val_dataset, timestamp=self.timestamp, device='cpu' if self.device == 'cpu' else 'cuda', meta=self.meta)",
            "def train(self, *args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    from mmcls import __version__\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, MmDataset, preprocess_transform\n    from mmcls.utils import setup_multi_processes\n    if self.train_dataset is None:\n        raise ValueError(\"Not found train dataset, please set the 'train_dataset' parameter!\")\n    self.cfg.model.mm_model.pretrained = None\n    self.cfg.dump(osp.join(self.work_dir, osp.basename(self.cfg_file)))\n    if self.cfg.dataset.classes is None:\n        data_root = get_ms_dataset_root(self.train_dataset)\n        classname_path = osp.join(data_root, 'classname.txt')\n        classes = classname_path if osp.exists(classname_path) else None\n    else:\n        classes = self.cfg.dataset.classes\n    datasets = [MmDataset(self.train_dataset, pipeline=self.cfg.preprocessor.train, classes=classes, data_prefix=self.data_prefix)]\n    if len(self.cfg.train.workflow) == 2:\n        if self.eval_dataset is None:\n            raise ValueError(\"Not found evaluate dataset, please set the 'eval_dataset' parameter!\")\n        val_data_pipeline = self.cfg.preprocessor.train\n        val_dataset = MmDataset(self.eval_dataset, pipeline=val_data_pipeline, classes=classes, data_prefix=self.data_prefix)\n        datasets.append(val_dataset)\n    self.meta.update(dict(mmcls_version=__version__, config=self.cfg.pretty_text, CLASSES=datasets[0].CLASSES))\n    val_dataset = None\n    if not self.cfg.no_validate:\n        val_dataset = MmDataset(self.eval_dataset, pipeline=preprocess_transform(self.cfg.preprocessor.val), classes=classes, data_prefix=self.data_prefix)\n    train_model(self.model, datasets, self.cfg, distributed=self.distributed, val_dataset=val_dataset, timestamp=self.timestamp, device='cpu' if self.device == 'cpu' else 'cuda', meta=self.meta)",
            "def train(self, *args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    from mmcls import __version__\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, MmDataset, preprocess_transform\n    from mmcls.utils import setup_multi_processes\n    if self.train_dataset is None:\n        raise ValueError(\"Not found train dataset, please set the 'train_dataset' parameter!\")\n    self.cfg.model.mm_model.pretrained = None\n    self.cfg.dump(osp.join(self.work_dir, osp.basename(self.cfg_file)))\n    if self.cfg.dataset.classes is None:\n        data_root = get_ms_dataset_root(self.train_dataset)\n        classname_path = osp.join(data_root, 'classname.txt')\n        classes = classname_path if osp.exists(classname_path) else None\n    else:\n        classes = self.cfg.dataset.classes\n    datasets = [MmDataset(self.train_dataset, pipeline=self.cfg.preprocessor.train, classes=classes, data_prefix=self.data_prefix)]\n    if len(self.cfg.train.workflow) == 2:\n        if self.eval_dataset is None:\n            raise ValueError(\"Not found evaluate dataset, please set the 'eval_dataset' parameter!\")\n        val_data_pipeline = self.cfg.preprocessor.train\n        val_dataset = MmDataset(self.eval_dataset, pipeline=val_data_pipeline, classes=classes, data_prefix=self.data_prefix)\n        datasets.append(val_dataset)\n    self.meta.update(dict(mmcls_version=__version__, config=self.cfg.pretty_text, CLASSES=datasets[0].CLASSES))\n    val_dataset = None\n    if not self.cfg.no_validate:\n        val_dataset = MmDataset(self.eval_dataset, pipeline=preprocess_transform(self.cfg.preprocessor.val), classes=classes, data_prefix=self.data_prefix)\n    train_model(self.model, datasets, self.cfg, distributed=self.distributed, val_dataset=val_dataset, timestamp=self.timestamp, device='cpu' if self.device == 'cpu' else 'cuda', meta=self.meta)",
            "def train(self, *args, **kwargs):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    from mmcls import __version__\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, MmDataset, preprocess_transform\n    from mmcls.utils import setup_multi_processes\n    if self.train_dataset is None:\n        raise ValueError(\"Not found train dataset, please set the 'train_dataset' parameter!\")\n    self.cfg.model.mm_model.pretrained = None\n    self.cfg.dump(osp.join(self.work_dir, osp.basename(self.cfg_file)))\n    if self.cfg.dataset.classes is None:\n        data_root = get_ms_dataset_root(self.train_dataset)\n        classname_path = osp.join(data_root, 'classname.txt')\n        classes = classname_path if osp.exists(classname_path) else None\n    else:\n        classes = self.cfg.dataset.classes\n    datasets = [MmDataset(self.train_dataset, pipeline=self.cfg.preprocessor.train, classes=classes, data_prefix=self.data_prefix)]\n    if len(self.cfg.train.workflow) == 2:\n        if self.eval_dataset is None:\n            raise ValueError(\"Not found evaluate dataset, please set the 'eval_dataset' parameter!\")\n        val_data_pipeline = self.cfg.preprocessor.train\n        val_dataset = MmDataset(self.eval_dataset, pipeline=val_data_pipeline, classes=classes, data_prefix=self.data_prefix)\n        datasets.append(val_dataset)\n    self.meta.update(dict(mmcls_version=__version__, config=self.cfg.pretty_text, CLASSES=datasets[0].CLASSES))\n    val_dataset = None\n    if not self.cfg.no_validate:\n        val_dataset = MmDataset(self.eval_dataset, pipeline=preprocess_transform(self.cfg.preprocessor.val), classes=classes, data_prefix=self.data_prefix)\n    train_model(self.model, datasets, self.cfg, distributed=self.distributed, val_dataset=val_dataset, timestamp=self.timestamp, device='cpu' if self.device == 'cpu' else 'cuda', meta=self.meta)"
        ]
    },
    {
        "func_name": "evaluate",
        "original": "def evaluate(self, checkpoint_path: str=None, *args, **kwargs) -> Dict[str, float]:\n    import warnings\n    import torch\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, MmDataset, preprocess_transform, get_trained_checkpoints_name\n    from mmcls.datasets import build_dataloader\n    from mmcv.runner import get_dist_info, load_checkpoint, wrap_fp16_model\n    from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n    from mmcls.apis import multi_gpu_test, single_gpu_test\n    from mmcls.utils import setup_multi_processes\n    if self.eval_dataset is None:\n        raise ValueError(\"Not found evaluate dataset, please set the 'eval_dataset' parameter!\")\n    self.cfg.model.mm_model.pretrained = None\n    if self.cfg.dataset.classes is None:\n        data_root = get_ms_dataset_root(self.eval_dataset)\n        classname_path = osp.join(data_root, 'classname.txt')\n        classes = classname_path if osp.exists(classname_path) else None\n    else:\n        classes = self.cfg.dataset.classes\n    dataset = MmDataset(self.eval_dataset, pipeline=preprocess_transform(self.cfg.preprocessor.val), classes=classes, data_prefix=self.data_prefix)\n    data_loader = build_dataloader(dataset, samples_per_gpu=self.cfg.evaluation.dataloader.batch_size_per_gpu, workers_per_gpu=self.cfg.evaluation.dataloader.workers_per_gpu, dist=self.distributed, shuffle=False, round_up=True)\n    model = copy.deepcopy(self.model)\n    fp16_cfg = self.cfg.get('fp16', None)\n    if fp16_cfg is not None:\n        wrap_fp16_model(model)\n    if checkpoint_path is None:\n        trained_checkpoints = get_trained_checkpoints_name(self.work_dir)\n        if trained_checkpoints is not None:\n            checkpoint = load_checkpoint(model, os.path.join(self.work_dir, trained_checkpoints), map_location='cpu')\n        else:\n            checkpoint = load_checkpoint(model, self.eval_checkpoint_path, map_location='cpu')\n    else:\n        checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n    if 'CLASSES' in checkpoint.get('meta', {}):\n        CLASSES = checkpoint['meta']['CLASSES']\n    else:\n        from mmcls.datasets import ImageNet\n        self.logger.warning(\"Class names are not saved in the checkpoint's meta data, use imagenet by default.\")\n        CLASSES = ImageNet.CLASSES\n    if not self.distributed:\n        if self.device == 'cpu':\n            model = model.cpu()\n        else:\n            model = MMDataParallel(model, device_ids=self.cfg.gpu_ids)\n            if not model.device_ids:\n                assert mmcv.digit_version(mmcv.__version__) >= (1, 4, 4), 'To test with CPU, please confirm your mmcv version is not lower than v1.4.4'\n        model.CLASSES = CLASSES\n        show_kwargs = {}\n        outputs = single_gpu_test(model, data_loader, False, None, **show_kwargs)\n    else:\n        model = MMDistributedDataParallel(model.cuda(), device_ids=[torch.cuda.current_device()], broadcast_buffers=False)\n        outputs = multi_gpu_test(model, data_loader, None, True)\n    (rank, _) = get_dist_info()\n    if rank == 0:\n        results = {}\n        logger = get_logger()\n        metric_options = self.cfg.evaluation.get('metric_options', {})\n        if 'topk' in metric_options.keys():\n            metric_options['topk'] = tuple(metric_options['topk'])\n        elif len(CLASSES) < 5:\n            metric_options['topk'] = (1,)\n        if self.cfg.evaluation.metrics:\n            eval_results = dataset.evaluate(results=outputs, metric=self.cfg.evaluation.metrics, metric_options=metric_options, logger=logger)\n            results.update(eval_results)\n        return results\n    return None",
        "mutated": [
            "def evaluate(self, checkpoint_path: str=None, *args, **kwargs) -> Dict[str, float]:\n    if False:\n        i = 10\n    import warnings\n    import torch\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, MmDataset, preprocess_transform, get_trained_checkpoints_name\n    from mmcls.datasets import build_dataloader\n    from mmcv.runner import get_dist_info, load_checkpoint, wrap_fp16_model\n    from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n    from mmcls.apis import multi_gpu_test, single_gpu_test\n    from mmcls.utils import setup_multi_processes\n    if self.eval_dataset is None:\n        raise ValueError(\"Not found evaluate dataset, please set the 'eval_dataset' parameter!\")\n    self.cfg.model.mm_model.pretrained = None\n    if self.cfg.dataset.classes is None:\n        data_root = get_ms_dataset_root(self.eval_dataset)\n        classname_path = osp.join(data_root, 'classname.txt')\n        classes = classname_path if osp.exists(classname_path) else None\n    else:\n        classes = self.cfg.dataset.classes\n    dataset = MmDataset(self.eval_dataset, pipeline=preprocess_transform(self.cfg.preprocessor.val), classes=classes, data_prefix=self.data_prefix)\n    data_loader = build_dataloader(dataset, samples_per_gpu=self.cfg.evaluation.dataloader.batch_size_per_gpu, workers_per_gpu=self.cfg.evaluation.dataloader.workers_per_gpu, dist=self.distributed, shuffle=False, round_up=True)\n    model = copy.deepcopy(self.model)\n    fp16_cfg = self.cfg.get('fp16', None)\n    if fp16_cfg is not None:\n        wrap_fp16_model(model)\n    if checkpoint_path is None:\n        trained_checkpoints = get_trained_checkpoints_name(self.work_dir)\n        if trained_checkpoints is not None:\n            checkpoint = load_checkpoint(model, os.path.join(self.work_dir, trained_checkpoints), map_location='cpu')\n        else:\n            checkpoint = load_checkpoint(model, self.eval_checkpoint_path, map_location='cpu')\n    else:\n        checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n    if 'CLASSES' in checkpoint.get('meta', {}):\n        CLASSES = checkpoint['meta']['CLASSES']\n    else:\n        from mmcls.datasets import ImageNet\n        self.logger.warning(\"Class names are not saved in the checkpoint's meta data, use imagenet by default.\")\n        CLASSES = ImageNet.CLASSES\n    if not self.distributed:\n        if self.device == 'cpu':\n            model = model.cpu()\n        else:\n            model = MMDataParallel(model, device_ids=self.cfg.gpu_ids)\n            if not model.device_ids:\n                assert mmcv.digit_version(mmcv.__version__) >= (1, 4, 4), 'To test with CPU, please confirm your mmcv version is not lower than v1.4.4'\n        model.CLASSES = CLASSES\n        show_kwargs = {}\n        outputs = single_gpu_test(model, data_loader, False, None, **show_kwargs)\n    else:\n        model = MMDistributedDataParallel(model.cuda(), device_ids=[torch.cuda.current_device()], broadcast_buffers=False)\n        outputs = multi_gpu_test(model, data_loader, None, True)\n    (rank, _) = get_dist_info()\n    if rank == 0:\n        results = {}\n        logger = get_logger()\n        metric_options = self.cfg.evaluation.get('metric_options', {})\n        if 'topk' in metric_options.keys():\n            metric_options['topk'] = tuple(metric_options['topk'])\n        elif len(CLASSES) < 5:\n            metric_options['topk'] = (1,)\n        if self.cfg.evaluation.metrics:\n            eval_results = dataset.evaluate(results=outputs, metric=self.cfg.evaluation.metrics, metric_options=metric_options, logger=logger)\n            results.update(eval_results)\n        return results\n    return None",
            "def evaluate(self, checkpoint_path: str=None, *args, **kwargs) -> Dict[str, float]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    import warnings\n    import torch\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, MmDataset, preprocess_transform, get_trained_checkpoints_name\n    from mmcls.datasets import build_dataloader\n    from mmcv.runner import get_dist_info, load_checkpoint, wrap_fp16_model\n    from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n    from mmcls.apis import multi_gpu_test, single_gpu_test\n    from mmcls.utils import setup_multi_processes\n    if self.eval_dataset is None:\n        raise ValueError(\"Not found evaluate dataset, please set the 'eval_dataset' parameter!\")\n    self.cfg.model.mm_model.pretrained = None\n    if self.cfg.dataset.classes is None:\n        data_root = get_ms_dataset_root(self.eval_dataset)\n        classname_path = osp.join(data_root, 'classname.txt')\n        classes = classname_path if osp.exists(classname_path) else None\n    else:\n        classes = self.cfg.dataset.classes\n    dataset = MmDataset(self.eval_dataset, pipeline=preprocess_transform(self.cfg.preprocessor.val), classes=classes, data_prefix=self.data_prefix)\n    data_loader = build_dataloader(dataset, samples_per_gpu=self.cfg.evaluation.dataloader.batch_size_per_gpu, workers_per_gpu=self.cfg.evaluation.dataloader.workers_per_gpu, dist=self.distributed, shuffle=False, round_up=True)\n    model = copy.deepcopy(self.model)\n    fp16_cfg = self.cfg.get('fp16', None)\n    if fp16_cfg is not None:\n        wrap_fp16_model(model)\n    if checkpoint_path is None:\n        trained_checkpoints = get_trained_checkpoints_name(self.work_dir)\n        if trained_checkpoints is not None:\n            checkpoint = load_checkpoint(model, os.path.join(self.work_dir, trained_checkpoints), map_location='cpu')\n        else:\n            checkpoint = load_checkpoint(model, self.eval_checkpoint_path, map_location='cpu')\n    else:\n        checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n    if 'CLASSES' in checkpoint.get('meta', {}):\n        CLASSES = checkpoint['meta']['CLASSES']\n    else:\n        from mmcls.datasets import ImageNet\n        self.logger.warning(\"Class names are not saved in the checkpoint's meta data, use imagenet by default.\")\n        CLASSES = ImageNet.CLASSES\n    if not self.distributed:\n        if self.device == 'cpu':\n            model = model.cpu()\n        else:\n            model = MMDataParallel(model, device_ids=self.cfg.gpu_ids)\n            if not model.device_ids:\n                assert mmcv.digit_version(mmcv.__version__) >= (1, 4, 4), 'To test with CPU, please confirm your mmcv version is not lower than v1.4.4'\n        model.CLASSES = CLASSES\n        show_kwargs = {}\n        outputs = single_gpu_test(model, data_loader, False, None, **show_kwargs)\n    else:\n        model = MMDistributedDataParallel(model.cuda(), device_ids=[torch.cuda.current_device()], broadcast_buffers=False)\n        outputs = multi_gpu_test(model, data_loader, None, True)\n    (rank, _) = get_dist_info()\n    if rank == 0:\n        results = {}\n        logger = get_logger()\n        metric_options = self.cfg.evaluation.get('metric_options', {})\n        if 'topk' in metric_options.keys():\n            metric_options['topk'] = tuple(metric_options['topk'])\n        elif len(CLASSES) < 5:\n            metric_options['topk'] = (1,)\n        if self.cfg.evaluation.metrics:\n            eval_results = dataset.evaluate(results=outputs, metric=self.cfg.evaluation.metrics, metric_options=metric_options, logger=logger)\n            results.update(eval_results)\n        return results\n    return None",
            "def evaluate(self, checkpoint_path: str=None, *args, **kwargs) -> Dict[str, float]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    import warnings\n    import torch\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, MmDataset, preprocess_transform, get_trained_checkpoints_name\n    from mmcls.datasets import build_dataloader\n    from mmcv.runner import get_dist_info, load_checkpoint, wrap_fp16_model\n    from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n    from mmcls.apis import multi_gpu_test, single_gpu_test\n    from mmcls.utils import setup_multi_processes\n    if self.eval_dataset is None:\n        raise ValueError(\"Not found evaluate dataset, please set the 'eval_dataset' parameter!\")\n    self.cfg.model.mm_model.pretrained = None\n    if self.cfg.dataset.classes is None:\n        data_root = get_ms_dataset_root(self.eval_dataset)\n        classname_path = osp.join(data_root, 'classname.txt')\n        classes = classname_path if osp.exists(classname_path) else None\n    else:\n        classes = self.cfg.dataset.classes\n    dataset = MmDataset(self.eval_dataset, pipeline=preprocess_transform(self.cfg.preprocessor.val), classes=classes, data_prefix=self.data_prefix)\n    data_loader = build_dataloader(dataset, samples_per_gpu=self.cfg.evaluation.dataloader.batch_size_per_gpu, workers_per_gpu=self.cfg.evaluation.dataloader.workers_per_gpu, dist=self.distributed, shuffle=False, round_up=True)\n    model = copy.deepcopy(self.model)\n    fp16_cfg = self.cfg.get('fp16', None)\n    if fp16_cfg is not None:\n        wrap_fp16_model(model)\n    if checkpoint_path is None:\n        trained_checkpoints = get_trained_checkpoints_name(self.work_dir)\n        if trained_checkpoints is not None:\n            checkpoint = load_checkpoint(model, os.path.join(self.work_dir, trained_checkpoints), map_location='cpu')\n        else:\n            checkpoint = load_checkpoint(model, self.eval_checkpoint_path, map_location='cpu')\n    else:\n        checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n    if 'CLASSES' in checkpoint.get('meta', {}):\n        CLASSES = checkpoint['meta']['CLASSES']\n    else:\n        from mmcls.datasets import ImageNet\n        self.logger.warning(\"Class names are not saved in the checkpoint's meta data, use imagenet by default.\")\n        CLASSES = ImageNet.CLASSES\n    if not self.distributed:\n        if self.device == 'cpu':\n            model = model.cpu()\n        else:\n            model = MMDataParallel(model, device_ids=self.cfg.gpu_ids)\n            if not model.device_ids:\n                assert mmcv.digit_version(mmcv.__version__) >= (1, 4, 4), 'To test with CPU, please confirm your mmcv version is not lower than v1.4.4'\n        model.CLASSES = CLASSES\n        show_kwargs = {}\n        outputs = single_gpu_test(model, data_loader, False, None, **show_kwargs)\n    else:\n        model = MMDistributedDataParallel(model.cuda(), device_ids=[torch.cuda.current_device()], broadcast_buffers=False)\n        outputs = multi_gpu_test(model, data_loader, None, True)\n    (rank, _) = get_dist_info()\n    if rank == 0:\n        results = {}\n        logger = get_logger()\n        metric_options = self.cfg.evaluation.get('metric_options', {})\n        if 'topk' in metric_options.keys():\n            metric_options['topk'] = tuple(metric_options['topk'])\n        elif len(CLASSES) < 5:\n            metric_options['topk'] = (1,)\n        if self.cfg.evaluation.metrics:\n            eval_results = dataset.evaluate(results=outputs, metric=self.cfg.evaluation.metrics, metric_options=metric_options, logger=logger)\n            results.update(eval_results)\n        return results\n    return None",
            "def evaluate(self, checkpoint_path: str=None, *args, **kwargs) -> Dict[str, float]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    import warnings\n    import torch\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, MmDataset, preprocess_transform, get_trained_checkpoints_name\n    from mmcls.datasets import build_dataloader\n    from mmcv.runner import get_dist_info, load_checkpoint, wrap_fp16_model\n    from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n    from mmcls.apis import multi_gpu_test, single_gpu_test\n    from mmcls.utils import setup_multi_processes\n    if self.eval_dataset is None:\n        raise ValueError(\"Not found evaluate dataset, please set the 'eval_dataset' parameter!\")\n    self.cfg.model.mm_model.pretrained = None\n    if self.cfg.dataset.classes is None:\n        data_root = get_ms_dataset_root(self.eval_dataset)\n        classname_path = osp.join(data_root, 'classname.txt')\n        classes = classname_path if osp.exists(classname_path) else None\n    else:\n        classes = self.cfg.dataset.classes\n    dataset = MmDataset(self.eval_dataset, pipeline=preprocess_transform(self.cfg.preprocessor.val), classes=classes, data_prefix=self.data_prefix)\n    data_loader = build_dataloader(dataset, samples_per_gpu=self.cfg.evaluation.dataloader.batch_size_per_gpu, workers_per_gpu=self.cfg.evaluation.dataloader.workers_per_gpu, dist=self.distributed, shuffle=False, round_up=True)\n    model = copy.deepcopy(self.model)\n    fp16_cfg = self.cfg.get('fp16', None)\n    if fp16_cfg is not None:\n        wrap_fp16_model(model)\n    if checkpoint_path is None:\n        trained_checkpoints = get_trained_checkpoints_name(self.work_dir)\n        if trained_checkpoints is not None:\n            checkpoint = load_checkpoint(model, os.path.join(self.work_dir, trained_checkpoints), map_location='cpu')\n        else:\n            checkpoint = load_checkpoint(model, self.eval_checkpoint_path, map_location='cpu')\n    else:\n        checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n    if 'CLASSES' in checkpoint.get('meta', {}):\n        CLASSES = checkpoint['meta']['CLASSES']\n    else:\n        from mmcls.datasets import ImageNet\n        self.logger.warning(\"Class names are not saved in the checkpoint's meta data, use imagenet by default.\")\n        CLASSES = ImageNet.CLASSES\n    if not self.distributed:\n        if self.device == 'cpu':\n            model = model.cpu()\n        else:\n            model = MMDataParallel(model, device_ids=self.cfg.gpu_ids)\n            if not model.device_ids:\n                assert mmcv.digit_version(mmcv.__version__) >= (1, 4, 4), 'To test with CPU, please confirm your mmcv version is not lower than v1.4.4'\n        model.CLASSES = CLASSES\n        show_kwargs = {}\n        outputs = single_gpu_test(model, data_loader, False, None, **show_kwargs)\n    else:\n        model = MMDistributedDataParallel(model.cuda(), device_ids=[torch.cuda.current_device()], broadcast_buffers=False)\n        outputs = multi_gpu_test(model, data_loader, None, True)\n    (rank, _) = get_dist_info()\n    if rank == 0:\n        results = {}\n        logger = get_logger()\n        metric_options = self.cfg.evaluation.get('metric_options', {})\n        if 'topk' in metric_options.keys():\n            metric_options['topk'] = tuple(metric_options['topk'])\n        elif len(CLASSES) < 5:\n            metric_options['topk'] = (1,)\n        if self.cfg.evaluation.metrics:\n            eval_results = dataset.evaluate(results=outputs, metric=self.cfg.evaluation.metrics, metric_options=metric_options, logger=logger)\n            results.update(eval_results)\n        return results\n    return None",
            "def evaluate(self, checkpoint_path: str=None, *args, **kwargs) -> Dict[str, float]:\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    import warnings\n    import torch\n    from modelscope.models.cv.image_classification.utils import get_ms_dataset_root, MmDataset, preprocess_transform, get_trained_checkpoints_name\n    from mmcls.datasets import build_dataloader\n    from mmcv.runner import get_dist_info, load_checkpoint, wrap_fp16_model\n    from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n    from mmcls.apis import multi_gpu_test, single_gpu_test\n    from mmcls.utils import setup_multi_processes\n    if self.eval_dataset is None:\n        raise ValueError(\"Not found evaluate dataset, please set the 'eval_dataset' parameter!\")\n    self.cfg.model.mm_model.pretrained = None\n    if self.cfg.dataset.classes is None:\n        data_root = get_ms_dataset_root(self.eval_dataset)\n        classname_path = osp.join(data_root, 'classname.txt')\n        classes = classname_path if osp.exists(classname_path) else None\n    else:\n        classes = self.cfg.dataset.classes\n    dataset = MmDataset(self.eval_dataset, pipeline=preprocess_transform(self.cfg.preprocessor.val), classes=classes, data_prefix=self.data_prefix)\n    data_loader = build_dataloader(dataset, samples_per_gpu=self.cfg.evaluation.dataloader.batch_size_per_gpu, workers_per_gpu=self.cfg.evaluation.dataloader.workers_per_gpu, dist=self.distributed, shuffle=False, round_up=True)\n    model = copy.deepcopy(self.model)\n    fp16_cfg = self.cfg.get('fp16', None)\n    if fp16_cfg is not None:\n        wrap_fp16_model(model)\n    if checkpoint_path is None:\n        trained_checkpoints = get_trained_checkpoints_name(self.work_dir)\n        if trained_checkpoints is not None:\n            checkpoint = load_checkpoint(model, os.path.join(self.work_dir, trained_checkpoints), map_location='cpu')\n        else:\n            checkpoint = load_checkpoint(model, self.eval_checkpoint_path, map_location='cpu')\n    else:\n        checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n    if 'CLASSES' in checkpoint.get('meta', {}):\n        CLASSES = checkpoint['meta']['CLASSES']\n    else:\n        from mmcls.datasets import ImageNet\n        self.logger.warning(\"Class names are not saved in the checkpoint's meta data, use imagenet by default.\")\n        CLASSES = ImageNet.CLASSES\n    if not self.distributed:\n        if self.device == 'cpu':\n            model = model.cpu()\n        else:\n            model = MMDataParallel(model, device_ids=self.cfg.gpu_ids)\n            if not model.device_ids:\n                assert mmcv.digit_version(mmcv.__version__) >= (1, 4, 4), 'To test with CPU, please confirm your mmcv version is not lower than v1.4.4'\n        model.CLASSES = CLASSES\n        show_kwargs = {}\n        outputs = single_gpu_test(model, data_loader, False, None, **show_kwargs)\n    else:\n        model = MMDistributedDataParallel(model.cuda(), device_ids=[torch.cuda.current_device()], broadcast_buffers=False)\n        outputs = multi_gpu_test(model, data_loader, None, True)\n    (rank, _) = get_dist_info()\n    if rank == 0:\n        results = {}\n        logger = get_logger()\n        metric_options = self.cfg.evaluation.get('metric_options', {})\n        if 'topk' in metric_options.keys():\n            metric_options['topk'] = tuple(metric_options['topk'])\n        elif len(CLASSES) < 5:\n            metric_options['topk'] = (1,)\n        if self.cfg.evaluation.metrics:\n            eval_results = dataset.evaluate(results=outputs, metric=self.cfg.evaluation.metrics, metric_options=metric_options, logger=logger)\n            results.update(eval_results)\n        return results\n    return None"
        ]
    }
]