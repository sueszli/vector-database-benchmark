"""The user interface to define skip connections."""
from typing import TYPE_CHECKING, Any, Callable, ClassVar, Dict, FrozenSet, Generator, Iterable, List, Optional, Set, Sequence, Tuple, Type, TypeVar, Union, cast
from torch import Tensor, nn
from ..microbatch import Batch
from .namespace import Namespace
from .tracker import current_skip_tracker
__all__ = ['skippable', 'stash', 'pop', 'verify_skippables']
Tensors = Sequence[Tensor]
TensorOrTensors = Union[Tensor, Tensors]
StashPop = Union['stash', 'pop']
StashPopGenerator = Generator[StashPop, Optional[Tensor], TensorOrTensors]
if TYPE_CHECKING:
    SkippableModule = nn.Module[Union[StashPopGenerator, TensorOrTensors]]
else:
    SkippableModule = nn.Module
T = TypeVar('T', bound='Skippable')

class Skippable(nn.Module):
    """The base class for skippable modules.

    Do not use this class directly. Define a subclass by :func:`skippable`
    instead.

    """
    module_cls: ClassVar[Type[SkippableModule]]
    stashable_names: ClassVar[FrozenSet[str]]
    poppable_names: ClassVar[FrozenSet[str]]

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        if False:
            return 10
        super().__init__()
        self.module = self.module_cls(*args, **kwargs)
        self.namespaces: Dict[str, Namespace] = {}

    def __repr__(self) -> str:
        if False:
            while True:
                i = 10
        return f'@skippable({self.module})'

    def namespaced(self, name: str) -> Tuple[Namespace, str]:
        if False:
            while True:
                i = 10
        'Prepend namespace for the given skip name.'
        ns = self.namespaces.get(name)
        ns = cast(Namespace, ns)
        return (ns, name)

    def stashable(self) -> Iterable[Tuple[Namespace, str]]:
        if False:
            print('Hello World!')
        'Iterate over namespaced skip names to be stashed.'
        for name in self.stashable_names:
            yield self.namespaced(name)

    def poppable(self) -> Iterable[Tuple[Namespace, str]]:
        if False:
            while True:
                i = 10
        'Iterate over namespaced skip names to be popped.'
        for name in self.poppable_names:
            yield self.namespaced(name)

    def isolate(self: T, ns: Namespace, *, only: Optional[Iterable[str]]=None) -> T:
        if False:
            return 10
        "Isolate a specified subset or the whole set of skip tensors.\n\n        In a single sequential module, skip tensors with the same\n        name are not allowed unless they are isolated by different namespaces.\n\n        Here's an example using the same name for skip tensors twice. Each pair\n        of ``Layer1`` and ``Layer2`` is isolated with its own namespace ``ns1``\n        and ``ns2``. There is no conflict anymore::\n\n            ns1 = Namespace()\n            ns2 = Namespace()\n\n            model = nn.Sequential(\n                Layer1().isolate(ns1),\n                Layer1().isolate(ns2),\n                Layer2(),\n                Layer3().isolate(ns2),\n                Layer3().isolate(ns1),\n            )\n\n        When `only` parameter is omitted, all skip tensors are isolated. You\n        can isolate a subset of skip tensors by passing `only` parameter::\n\n            ns_alice = Namespace()\n            ns_bob = Namespace()\n\n            model = nn.Sequential(\n                ...\n                StashStashPop().isolate(ns_alice, only=['alice']) \\\n                               .isolate(ns_bob, only=['bob']),\n                ...\n            )\n\n        Args:\n            ns (Namespace):\n                namespace for isolation\n\n        Keyword Args:\n            only (iterable of strs):\n                names of specific skip tensors to be isolated (omit this option\n                to isolate all skip tensors declared in this module)\n\n        Returns:\n            this module itself\n\n        "
        names: Iterable[str]
        if only is None:
            names = self.stashable_names | self.poppable_names
        else:
            names = set(only)
        for name in names:
            self.namespaces[name] = ns
        return self

    def dispatch(self, input, handle_stash: Callable[[str, Optional[Tensor]], None], handle_pop: Callable[[str], Optional[Tensor]]):
        if False:
            while True:
                i = 10
        "Dispatch :class:`stash` or :class:`pop` commands.\n\n        The commands are generated by the module's ``forward()``.\n        "
        generator = self.module(input)
        if not isinstance(generator, Generator):
            output = generator
            return output
        try:
            op = next(generator)
            while True:
                if isinstance(op, stash):
                    handle_stash(op.name, op.tensor)
                    op = next(generator)
                    continue
                if isinstance(op, pop):
                    tensor = handle_pop(op.name)
                    op = generator.send(tensor)
                    continue
                raise TypeError(f'{op!r} is not a command from @skippable')
        except StopIteration as stop:
            output = stop.args[0]
            return output

    def forward(self, input: Union[List[Any], Tensor]) -> TensorOrTensors:
        if False:
            while True:
                i = 10
        "Perform the forward propagation.\n\n        :class:`stash` or :class:`pop` commands will be handled by portals\n        silently. The portals won't be exposed to users.\n\n        Raises:\n            RuntimeError:\n                illegal 'stash' or 'pop' is found.\n\n        "
        skip_tracker = current_skip_tracker()
        stashed_tensors: Dict[str, Optional[Tensor]] = {}
        poppable_tensors = {}
        batch = Batch(input)
        for (ns, name) in self.poppable():
            try:
                poppable_tensors[name] = skip_tracker.load(batch, ns, name)
            except KeyError as e:
                raise RuntimeError(f"'{name}' has not been stashed") from e
        input = batch.values

        def handle_stash(name: str, tensor: Optional[Tensor]) -> None:
            if False:
                return 10
            if name not in self.stashable_names:
                raise RuntimeError(f"'{name}' has not been declared as stashable")
            stashed_tensors[name] = tensor

        def handle_pop(name: str) -> Optional[Tensor]:
            if False:
                return 10
            if name not in self.poppable_names:
                raise RuntimeError(f"'{name}' has not been declared as poppable")
            return poppable_tensors.pop(name)
        output = self.dispatch(input, handle_stash, handle_pop)
        not_stashed = self.stashable_names - stashed_tensors.keys()
        if not_stashed:
            comma_names = ', '.join((f"'{n}'" for n in not_stashed))
            raise RuntimeError(f'{comma_names} must be stashed but have not')
        not_popped = poppable_tensors.keys()
        if not_popped:
            comma_names = ', '.join((f"'{n}'" for n in not_popped))
            raise RuntimeError(f'{comma_names} must be popped but have not')
        batch = Batch(output)
        for (ns, name) in self.stashable():
            tensor = stashed_tensors[name]
            skip_tracker.save(batch, ns, name, tensor)
        output = batch.values
        return output

def skippable(stash: Iterable[str]=(), pop: Iterable[str]=()) -> Callable[[Type[SkippableModule]], Type[Skippable]]:
    if False:
        print('Hello World!')
    'Define a decorator to create :class:`nn.Module <torch.nn.Module>` with skip connections.\n\n    These decorated modules are called "skippable". This functionality works perfectly\n    fine even when the module is not wrapped by :class:`~torch.distributed.pipeline.sync.Pipe`.\n\n    Each skip tensor is managed by its name. Before manipulating skip tensors,\n    a skippable module must statically declare the names for skip tensors by\n    `stash` and/or `pop` parameters. Skip tensors with pre-declared name can be\n    stashed by ``yield stash(name, tensor)`` or popped by ``tensor = yield\n    pop(name)``.\n\n    Here is an example with three layers. A skip tensor named "1to3" is stashed\n    and popped at the first and last layer, respectively::\n\n        @skippable(stash=[\'1to3\'])\n        class Layer1(nn.Module):\n            def forward(self, input):\n                yield stash(\'1to3\', input)\n                return f1(input)\n\n        class Layer2(nn.Module):\n            def forward(self, input):\n                return f2(input)\n\n        @skippable(pop=[\'1to3\'])\n        class Layer3(nn.Module):\n            def forward(self, input):\n                skip_1to3 = yield pop(\'1to3\')\n                return f3(input) + skip_1to3\n\n        model = nn.Sequential(Layer1(), Layer2(), Layer3())\n\n    One skippable module can stash or pop multiple skip tensors::\n\n        @skippable(stash=[\'alice\', \'bob\'], pop=[\'carol\'])\n        class StashStashPop(nn.Module):\n            def forward(self, input):\n                yield stash(\'alice\', f_alice(input))\n                yield stash(\'bob\', f_bob(input))\n                carol = yield pop(\'carol\')\n                return input + carol\n\n    Every skip tensor must be associated with exactly one pair of `stash` and\n    `pop`. :class:`~torch.distributed.pipeline.sync.Pipe` checks this\n    restriction automatically when wrapping a module. You can also check the\n    restriction by :func:`verify_skippables`\n    without :class:`~torch.distributed.pipeline.sync.Pipe`.\n\n    '
    stashable_names = frozenset(stash)
    poppable_names = frozenset(pop)

    def extend_skippable(module_cls: Type[SkippableModule]) -> Type[Skippable]:
        if False:
            while True:
                i = 10
        name = module_cls.__name__
        bases = (Skippable,)
        attrs = {'module_cls': module_cls, 'stashable_names': stashable_names, 'poppable_names': poppable_names}
        return type(name, bases, attrs)
    return extend_skippable

class stash:
    """The command to stash a skip tensor.

    ::

        def forward(self, input):
            yield stash('name', input)
            return f(input)

    Args:
        name (str): name of skip tensor
        input (torch.Tensor or None): tensor to pass to the skip connection

    """
    __slots__ = ('name', 'tensor')

    def __init__(self, name: str, tensor: Optional[Tensor]) -> None:
        if False:
            return 10
        self.name = name
        self.tensor = tensor

class pop:
    """The command to pop a skip tensor.

    ::

        def forward(self, input):
            skip = yield pop('name')
            return f(input) + skip

    Args:
        name (str): name of skip tensor

    Returns:
        the skip tensor previously stashed by another layer under the same name

    """
    __slots__ = ('name',)

    def __init__(self, name: str) -> None:
        if False:
            for i in range(10):
                print('nop')
        self.name = name

def verify_skippables(module: nn.Sequential) -> None:
    if False:
        i = 10
        return i + 15
    'Verify if the underlying skippable modules satisfy integrity.\n\n    Every skip tensor must have only one pair of `stash` and `pop`. If there\n    are one or more unmatched pairs, it will raise :exc:`TypeError` with the\n    detailed messages.\n\n    Here are a few failure cases. :func:`verify_skippables` will report failure\n    for these cases::\n\n        # Layer1 stashes "1to3".\n        # Layer3 pops "1to3".\n\n        nn.Sequential(Layer1(), Layer2())\n        #               └──── ?\n\n        nn.Sequential(Layer2(), Layer3())\n        #                   ? ────┘\n\n        nn.Sequential(Layer1(), Layer2(), Layer3(), Layer3())\n        #               └───────────────────┘       ^^^^^^\n\n        nn.Sequential(Layer1(), Layer1(), Layer2(), Layer3())\n        #             ^^^^^^      └───────────────────┘\n\n    To use the same name for multiple skip tensors, they must be isolated by\n    different namespaces. See :meth:`isolate()\n    <torchpipe.skip.skippable.Skippable.isolate>`.\n\n    Raises:\n        TypeError:\n            one or more pairs of `stash` and `pop` are not matched.\n\n    '
    stashed: Set[Tuple[Namespace, str]] = set()
    popped: Set[Tuple[Namespace, str]] = set()
    msgs: List[str] = []
    for (layer_name, layer) in module.named_children():
        if not isinstance(layer, Skippable):
            continue
        for name in layer.stashable_names & layer.poppable_names:
            msg = f"'{layer_name}' declared '{name}' both as stashable and as poppable"
            msgs.append(msg)
        for (ns, name) in layer.stashable():
            if name in layer.poppable_names:
                continue
            if (ns, name) in stashed:
                msg = f"'{layer_name}' redeclared '{name}' as stashable but not isolated by namespace"
                msgs.append(msg)
                continue
            stashed.add((ns, name))
        for (ns, name) in layer.poppable():
            if name in layer.stashable_names:
                continue
            if (ns, name) in popped:
                msg = f"'{layer_name}' redeclared '{name}' as poppable but not isolated by namespace"
                msgs.append(msg)
                continue
            if (ns, name) not in stashed:
                msg = f"'{layer_name}' declared '{name}' as poppable but it was not stashed"
                msgs.append(msg)
                continue
            popped.add((ns, name))
    for (_, name) in stashed - popped:
        msg = f"no module declared '{name}' as poppable but stashed"
        msgs.append(msg)
    if msgs:
        raise TypeError('one or more pairs of stash and pop do not match:\n\n%s' % '\n'.join(('* %s' % x for x in msgs)))