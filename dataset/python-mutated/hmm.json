[
    {
        "func_name": "__init__",
        "original": "def __init__(self, initial_proba, transition_proba):\n    \"\"\"\n        construct hidden markov model\n\n        Parameters\n        ----------\n        initial_proba : (n_hidden,) np.ndarray\n            initial probability of each hidden state\n        transition_proba : (n_hidden, n_hidden) np.ndarray\n            transition probability matrix\n            (i, j) component denotes the transition probability from i-th to j-th hidden state\n\n        Attribute\n        ---------\n        n_hidden : int\n            number of hidden state\n        \"\"\"\n    self.n_hidden = initial_proba.size\n    self.initial_proba = initial_proba\n    self.transition_proba = transition_proba",
        "mutated": [
            "def __init__(self, initial_proba, transition_proba):\n    if False:\n        i = 10\n    '\\n        construct hidden markov model\\n\\n        Parameters\\n        ----------\\n        initial_proba : (n_hidden,) np.ndarray\\n            initial probability of each hidden state\\n        transition_proba : (n_hidden, n_hidden) np.ndarray\\n            transition probability matrix\\n            (i, j) component denotes the transition probability from i-th to j-th hidden state\\n\\n        Attribute\\n        ---------\\n        n_hidden : int\\n            number of hidden state\\n        '\n    self.n_hidden = initial_proba.size\n    self.initial_proba = initial_proba\n    self.transition_proba = transition_proba",
            "def __init__(self, initial_proba, transition_proba):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        construct hidden markov model\\n\\n        Parameters\\n        ----------\\n        initial_proba : (n_hidden,) np.ndarray\\n            initial probability of each hidden state\\n        transition_proba : (n_hidden, n_hidden) np.ndarray\\n            transition probability matrix\\n            (i, j) component denotes the transition probability from i-th to j-th hidden state\\n\\n        Attribute\\n        ---------\\n        n_hidden : int\\n            number of hidden state\\n        '\n    self.n_hidden = initial_proba.size\n    self.initial_proba = initial_proba\n    self.transition_proba = transition_proba",
            "def __init__(self, initial_proba, transition_proba):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        construct hidden markov model\\n\\n        Parameters\\n        ----------\\n        initial_proba : (n_hidden,) np.ndarray\\n            initial probability of each hidden state\\n        transition_proba : (n_hidden, n_hidden) np.ndarray\\n            transition probability matrix\\n            (i, j) component denotes the transition probability from i-th to j-th hidden state\\n\\n        Attribute\\n        ---------\\n        n_hidden : int\\n            number of hidden state\\n        '\n    self.n_hidden = initial_proba.size\n    self.initial_proba = initial_proba\n    self.transition_proba = transition_proba",
            "def __init__(self, initial_proba, transition_proba):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        construct hidden markov model\\n\\n        Parameters\\n        ----------\\n        initial_proba : (n_hidden,) np.ndarray\\n            initial probability of each hidden state\\n        transition_proba : (n_hidden, n_hidden) np.ndarray\\n            transition probability matrix\\n            (i, j) component denotes the transition probability from i-th to j-th hidden state\\n\\n        Attribute\\n        ---------\\n        n_hidden : int\\n            number of hidden state\\n        '\n    self.n_hidden = initial_proba.size\n    self.initial_proba = initial_proba\n    self.transition_proba = transition_proba",
            "def __init__(self, initial_proba, transition_proba):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        construct hidden markov model\\n\\n        Parameters\\n        ----------\\n        initial_proba : (n_hidden,) np.ndarray\\n            initial probability of each hidden state\\n        transition_proba : (n_hidden, n_hidden) np.ndarray\\n            transition probability matrix\\n            (i, j) component denotes the transition probability from i-th to j-th hidden state\\n\\n        Attribute\\n        ---------\\n        n_hidden : int\\n            number of hidden state\\n        '\n    self.n_hidden = initial_proba.size\n    self.initial_proba = initial_proba\n    self.transition_proba = transition_proba"
        ]
    },
    {
        "func_name": "fit",
        "original": "def fit(self, seq, iter_max=100):\n    \"\"\"\n        perform EM algorithm to estimate parameter of emission model and hidden variables\n\n        Parameters\n        ----------\n        seq : (N, ndim) np.ndarray\n            observed sequence\n        iter_max : int\n            maximum number of EM steps\n\n        Returns\n        -------\n        posterior : (N, n_hidden) np.ndarray\n            posterior distribution of each latent variable\n        \"\"\"\n    params = np.hstack((self.initial_proba.ravel(), self.transition_proba.ravel()))\n    for i in range(iter_max):\n        (p_hidden, p_transition) = self.expect(seq)\n        self.maximize(seq, p_hidden, p_transition)\n        params_new = np.hstack((self.initial_proba.ravel(), self.transition_proba.ravel()))\n        if np.allclose(params, params_new):\n            break\n        else:\n            params = params_new\n    return self.forward_backward(seq)",
        "mutated": [
            "def fit(self, seq, iter_max=100):\n    if False:\n        i = 10\n    '\\n        perform EM algorithm to estimate parameter of emission model and hidden variables\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n        iter_max : int\\n            maximum number of EM steps\\n\\n        Returns\\n        -------\\n        posterior : (N, n_hidden) np.ndarray\\n            posterior distribution of each latent variable\\n        '\n    params = np.hstack((self.initial_proba.ravel(), self.transition_proba.ravel()))\n    for i in range(iter_max):\n        (p_hidden, p_transition) = self.expect(seq)\n        self.maximize(seq, p_hidden, p_transition)\n        params_new = np.hstack((self.initial_proba.ravel(), self.transition_proba.ravel()))\n        if np.allclose(params, params_new):\n            break\n        else:\n            params = params_new\n    return self.forward_backward(seq)",
            "def fit(self, seq, iter_max=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        perform EM algorithm to estimate parameter of emission model and hidden variables\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n        iter_max : int\\n            maximum number of EM steps\\n\\n        Returns\\n        -------\\n        posterior : (N, n_hidden) np.ndarray\\n            posterior distribution of each latent variable\\n        '\n    params = np.hstack((self.initial_proba.ravel(), self.transition_proba.ravel()))\n    for i in range(iter_max):\n        (p_hidden, p_transition) = self.expect(seq)\n        self.maximize(seq, p_hidden, p_transition)\n        params_new = np.hstack((self.initial_proba.ravel(), self.transition_proba.ravel()))\n        if np.allclose(params, params_new):\n            break\n        else:\n            params = params_new\n    return self.forward_backward(seq)",
            "def fit(self, seq, iter_max=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        perform EM algorithm to estimate parameter of emission model and hidden variables\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n        iter_max : int\\n            maximum number of EM steps\\n\\n        Returns\\n        -------\\n        posterior : (N, n_hidden) np.ndarray\\n            posterior distribution of each latent variable\\n        '\n    params = np.hstack((self.initial_proba.ravel(), self.transition_proba.ravel()))\n    for i in range(iter_max):\n        (p_hidden, p_transition) = self.expect(seq)\n        self.maximize(seq, p_hidden, p_transition)\n        params_new = np.hstack((self.initial_proba.ravel(), self.transition_proba.ravel()))\n        if np.allclose(params, params_new):\n            break\n        else:\n            params = params_new\n    return self.forward_backward(seq)",
            "def fit(self, seq, iter_max=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        perform EM algorithm to estimate parameter of emission model and hidden variables\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n        iter_max : int\\n            maximum number of EM steps\\n\\n        Returns\\n        -------\\n        posterior : (N, n_hidden) np.ndarray\\n            posterior distribution of each latent variable\\n        '\n    params = np.hstack((self.initial_proba.ravel(), self.transition_proba.ravel()))\n    for i in range(iter_max):\n        (p_hidden, p_transition) = self.expect(seq)\n        self.maximize(seq, p_hidden, p_transition)\n        params_new = np.hstack((self.initial_proba.ravel(), self.transition_proba.ravel()))\n        if np.allclose(params, params_new):\n            break\n        else:\n            params = params_new\n    return self.forward_backward(seq)",
            "def fit(self, seq, iter_max=100):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        perform EM algorithm to estimate parameter of emission model and hidden variables\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n        iter_max : int\\n            maximum number of EM steps\\n\\n        Returns\\n        -------\\n        posterior : (N, n_hidden) np.ndarray\\n            posterior distribution of each latent variable\\n        '\n    params = np.hstack((self.initial_proba.ravel(), self.transition_proba.ravel()))\n    for i in range(iter_max):\n        (p_hidden, p_transition) = self.expect(seq)\n        self.maximize(seq, p_hidden, p_transition)\n        params_new = np.hstack((self.initial_proba.ravel(), self.transition_proba.ravel()))\n        if np.allclose(params, params_new):\n            break\n        else:\n            params = params_new\n    return self.forward_backward(seq)"
        ]
    },
    {
        "func_name": "expect",
        "original": "def expect(self, seq):\n    \"\"\"\n        estimate posterior distributions of hidden states and\n        transition probability between adjacent latent variables\n\n        Parameters\n        ----------\n        seq : (N, ndim) np.ndarray\n            observed sequence\n\n        Returns\n        -------\n        p_hidden : (N, n_hidden) np.ndarray\n            posterior distribution of each hidden variable\n        p_transition : (N - 1, n_hidden, n_hidden) np.ndarray\n            posterior transition probability between adjacent latent variables\n        \"\"\"\n    likelihood = self.likelihood(seq)\n    f = self.initial_proba * likelihood[0]\n    constant = [f.sum()]\n    forward = [f / f.sum()]\n    for like in likelihood[1:]:\n        f = forward[-1] @ self.transition_proba * like\n        constant.append(f.sum())\n        forward.append(f / f.sum())\n    forward = np.asarray(forward)\n    constant = np.asarray(constant)\n    backward = [np.ones(self.n_hidden)]\n    for (like, c) in zip(likelihood[-1:0:-1], constant[-1:0:-1]):\n        backward.insert(0, self.transition_proba @ (like * backward[0]) / c)\n    backward = np.asarray(backward)\n    p_hidden = forward * backward\n    p_transition = self.transition_proba * likelihood[1:, None, :] * backward[1:, None, :] * forward[:-1, :, None]\n    return (p_hidden, p_transition)",
        "mutated": [
            "def expect(self, seq):\n    if False:\n        i = 10\n    '\\n        estimate posterior distributions of hidden states and\\n        transition probability between adjacent latent variables\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        p_hidden : (N, n_hidden) np.ndarray\\n            posterior distribution of each hidden variable\\n        p_transition : (N - 1, n_hidden, n_hidden) np.ndarray\\n            posterior transition probability between adjacent latent variables\\n        '\n    likelihood = self.likelihood(seq)\n    f = self.initial_proba * likelihood[0]\n    constant = [f.sum()]\n    forward = [f / f.sum()]\n    for like in likelihood[1:]:\n        f = forward[-1] @ self.transition_proba * like\n        constant.append(f.sum())\n        forward.append(f / f.sum())\n    forward = np.asarray(forward)\n    constant = np.asarray(constant)\n    backward = [np.ones(self.n_hidden)]\n    for (like, c) in zip(likelihood[-1:0:-1], constant[-1:0:-1]):\n        backward.insert(0, self.transition_proba @ (like * backward[0]) / c)\n    backward = np.asarray(backward)\n    p_hidden = forward * backward\n    p_transition = self.transition_proba * likelihood[1:, None, :] * backward[1:, None, :] * forward[:-1, :, None]\n    return (p_hidden, p_transition)",
            "def expect(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        estimate posterior distributions of hidden states and\\n        transition probability between adjacent latent variables\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        p_hidden : (N, n_hidden) np.ndarray\\n            posterior distribution of each hidden variable\\n        p_transition : (N - 1, n_hidden, n_hidden) np.ndarray\\n            posterior transition probability between adjacent latent variables\\n        '\n    likelihood = self.likelihood(seq)\n    f = self.initial_proba * likelihood[0]\n    constant = [f.sum()]\n    forward = [f / f.sum()]\n    for like in likelihood[1:]:\n        f = forward[-1] @ self.transition_proba * like\n        constant.append(f.sum())\n        forward.append(f / f.sum())\n    forward = np.asarray(forward)\n    constant = np.asarray(constant)\n    backward = [np.ones(self.n_hidden)]\n    for (like, c) in zip(likelihood[-1:0:-1], constant[-1:0:-1]):\n        backward.insert(0, self.transition_proba @ (like * backward[0]) / c)\n    backward = np.asarray(backward)\n    p_hidden = forward * backward\n    p_transition = self.transition_proba * likelihood[1:, None, :] * backward[1:, None, :] * forward[:-1, :, None]\n    return (p_hidden, p_transition)",
            "def expect(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        estimate posterior distributions of hidden states and\\n        transition probability between adjacent latent variables\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        p_hidden : (N, n_hidden) np.ndarray\\n            posterior distribution of each hidden variable\\n        p_transition : (N - 1, n_hidden, n_hidden) np.ndarray\\n            posterior transition probability between adjacent latent variables\\n        '\n    likelihood = self.likelihood(seq)\n    f = self.initial_proba * likelihood[0]\n    constant = [f.sum()]\n    forward = [f / f.sum()]\n    for like in likelihood[1:]:\n        f = forward[-1] @ self.transition_proba * like\n        constant.append(f.sum())\n        forward.append(f / f.sum())\n    forward = np.asarray(forward)\n    constant = np.asarray(constant)\n    backward = [np.ones(self.n_hidden)]\n    for (like, c) in zip(likelihood[-1:0:-1], constant[-1:0:-1]):\n        backward.insert(0, self.transition_proba @ (like * backward[0]) / c)\n    backward = np.asarray(backward)\n    p_hidden = forward * backward\n    p_transition = self.transition_proba * likelihood[1:, None, :] * backward[1:, None, :] * forward[:-1, :, None]\n    return (p_hidden, p_transition)",
            "def expect(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        estimate posterior distributions of hidden states and\\n        transition probability between adjacent latent variables\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        p_hidden : (N, n_hidden) np.ndarray\\n            posterior distribution of each hidden variable\\n        p_transition : (N - 1, n_hidden, n_hidden) np.ndarray\\n            posterior transition probability between adjacent latent variables\\n        '\n    likelihood = self.likelihood(seq)\n    f = self.initial_proba * likelihood[0]\n    constant = [f.sum()]\n    forward = [f / f.sum()]\n    for like in likelihood[1:]:\n        f = forward[-1] @ self.transition_proba * like\n        constant.append(f.sum())\n        forward.append(f / f.sum())\n    forward = np.asarray(forward)\n    constant = np.asarray(constant)\n    backward = [np.ones(self.n_hidden)]\n    for (like, c) in zip(likelihood[-1:0:-1], constant[-1:0:-1]):\n        backward.insert(0, self.transition_proba @ (like * backward[0]) / c)\n    backward = np.asarray(backward)\n    p_hidden = forward * backward\n    p_transition = self.transition_proba * likelihood[1:, None, :] * backward[1:, None, :] * forward[:-1, :, None]\n    return (p_hidden, p_transition)",
            "def expect(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        estimate posterior distributions of hidden states and\\n        transition probability between adjacent latent variables\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        p_hidden : (N, n_hidden) np.ndarray\\n            posterior distribution of each hidden variable\\n        p_transition : (N - 1, n_hidden, n_hidden) np.ndarray\\n            posterior transition probability between adjacent latent variables\\n        '\n    likelihood = self.likelihood(seq)\n    f = self.initial_proba * likelihood[0]\n    constant = [f.sum()]\n    forward = [f / f.sum()]\n    for like in likelihood[1:]:\n        f = forward[-1] @ self.transition_proba * like\n        constant.append(f.sum())\n        forward.append(f / f.sum())\n    forward = np.asarray(forward)\n    constant = np.asarray(constant)\n    backward = [np.ones(self.n_hidden)]\n    for (like, c) in zip(likelihood[-1:0:-1], constant[-1:0:-1]):\n        backward.insert(0, self.transition_proba @ (like * backward[0]) / c)\n    backward = np.asarray(backward)\n    p_hidden = forward * backward\n    p_transition = self.transition_proba * likelihood[1:, None, :] * backward[1:, None, :] * forward[:-1, :, None]\n    return (p_hidden, p_transition)"
        ]
    },
    {
        "func_name": "forward_backward",
        "original": "def forward_backward(self, seq):\n    \"\"\"\n        estimate posterior distributions of hidden states\n\n        Parameters\n        ----------\n        seq : (N, ndim) np.ndarray\n            observed sequence\n\n        Returns\n        -------\n        posterior : (N, n_hidden) np.ndarray\n            posterior distribution of hidden states\n        \"\"\"\n    likelihood = self.likelihood(seq)\n    f = self.initial_proba * likelihood[0]\n    constant = [f.sum()]\n    forward = [f / f.sum()]\n    for like in likelihood[1:]:\n        f = forward[-1] @ self.transition_proba * like\n        constant.append(f.sum())\n        forward.append(f / f.sum())\n    backward = [np.ones(self.n_hidden)]\n    for (like, c) in zip(likelihood[-1:0:-1], constant[-1:0:-1]):\n        backward.insert(0, self.transition_proba @ (like * backward[0]) / c)\n    forward = np.asarray(forward)\n    backward = np.asarray(backward)\n    posterior = forward * backward\n    return posterior",
        "mutated": [
            "def forward_backward(self, seq):\n    if False:\n        i = 10\n    '\\n        estimate posterior distributions of hidden states\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        posterior : (N, n_hidden) np.ndarray\\n            posterior distribution of hidden states\\n        '\n    likelihood = self.likelihood(seq)\n    f = self.initial_proba * likelihood[0]\n    constant = [f.sum()]\n    forward = [f / f.sum()]\n    for like in likelihood[1:]:\n        f = forward[-1] @ self.transition_proba * like\n        constant.append(f.sum())\n        forward.append(f / f.sum())\n    backward = [np.ones(self.n_hidden)]\n    for (like, c) in zip(likelihood[-1:0:-1], constant[-1:0:-1]):\n        backward.insert(0, self.transition_proba @ (like * backward[0]) / c)\n    forward = np.asarray(forward)\n    backward = np.asarray(backward)\n    posterior = forward * backward\n    return posterior",
            "def forward_backward(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        estimate posterior distributions of hidden states\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        posterior : (N, n_hidden) np.ndarray\\n            posterior distribution of hidden states\\n        '\n    likelihood = self.likelihood(seq)\n    f = self.initial_proba * likelihood[0]\n    constant = [f.sum()]\n    forward = [f / f.sum()]\n    for like in likelihood[1:]:\n        f = forward[-1] @ self.transition_proba * like\n        constant.append(f.sum())\n        forward.append(f / f.sum())\n    backward = [np.ones(self.n_hidden)]\n    for (like, c) in zip(likelihood[-1:0:-1], constant[-1:0:-1]):\n        backward.insert(0, self.transition_proba @ (like * backward[0]) / c)\n    forward = np.asarray(forward)\n    backward = np.asarray(backward)\n    posterior = forward * backward\n    return posterior",
            "def forward_backward(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        estimate posterior distributions of hidden states\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        posterior : (N, n_hidden) np.ndarray\\n            posterior distribution of hidden states\\n        '\n    likelihood = self.likelihood(seq)\n    f = self.initial_proba * likelihood[0]\n    constant = [f.sum()]\n    forward = [f / f.sum()]\n    for like in likelihood[1:]:\n        f = forward[-1] @ self.transition_proba * like\n        constant.append(f.sum())\n        forward.append(f / f.sum())\n    backward = [np.ones(self.n_hidden)]\n    for (like, c) in zip(likelihood[-1:0:-1], constant[-1:0:-1]):\n        backward.insert(0, self.transition_proba @ (like * backward[0]) / c)\n    forward = np.asarray(forward)\n    backward = np.asarray(backward)\n    posterior = forward * backward\n    return posterior",
            "def forward_backward(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        estimate posterior distributions of hidden states\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        posterior : (N, n_hidden) np.ndarray\\n            posterior distribution of hidden states\\n        '\n    likelihood = self.likelihood(seq)\n    f = self.initial_proba * likelihood[0]\n    constant = [f.sum()]\n    forward = [f / f.sum()]\n    for like in likelihood[1:]:\n        f = forward[-1] @ self.transition_proba * like\n        constant.append(f.sum())\n        forward.append(f / f.sum())\n    backward = [np.ones(self.n_hidden)]\n    for (like, c) in zip(likelihood[-1:0:-1], constant[-1:0:-1]):\n        backward.insert(0, self.transition_proba @ (like * backward[0]) / c)\n    forward = np.asarray(forward)\n    backward = np.asarray(backward)\n    posterior = forward * backward\n    return posterior",
            "def forward_backward(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        estimate posterior distributions of hidden states\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        posterior : (N, n_hidden) np.ndarray\\n            posterior distribution of hidden states\\n        '\n    likelihood = self.likelihood(seq)\n    f = self.initial_proba * likelihood[0]\n    constant = [f.sum()]\n    forward = [f / f.sum()]\n    for like in likelihood[1:]:\n        f = forward[-1] @ self.transition_proba * like\n        constant.append(f.sum())\n        forward.append(f / f.sum())\n    backward = [np.ones(self.n_hidden)]\n    for (like, c) in zip(likelihood[-1:0:-1], constant[-1:0:-1]):\n        backward.insert(0, self.transition_proba @ (like * backward[0]) / c)\n    forward = np.asarray(forward)\n    backward = np.asarray(backward)\n    posterior = forward * backward\n    return posterior"
        ]
    },
    {
        "func_name": "filtering",
        "original": "def filtering(self, seq):\n    \"\"\"\n        bayesian filtering\n\n        Parameters\n        ----------\n        seq : (N, ndim) np.ndarray\n            observed sequence\n\n        Returns\n        -------\n        posterior : (N, n_hidden) np.ndarray\n            posterior distributions of each latent variables\n        \"\"\"\n    likelihood = self.likelihood(seq)\n    p = self.initial_proba * likelihood[0]\n    posterior = [p / np.sum(p)]\n    for like in likelihood[1:]:\n        p = posterior[-1] @ self.transition_proba * like\n        posterior.append(p / np.sum(p))\n    posterior = np.asarray(posterior)\n    return posterior",
        "mutated": [
            "def filtering(self, seq):\n    if False:\n        i = 10\n    '\\n        bayesian filtering\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        posterior : (N, n_hidden) np.ndarray\\n            posterior distributions of each latent variables\\n        '\n    likelihood = self.likelihood(seq)\n    p = self.initial_proba * likelihood[0]\n    posterior = [p / np.sum(p)]\n    for like in likelihood[1:]:\n        p = posterior[-1] @ self.transition_proba * like\n        posterior.append(p / np.sum(p))\n    posterior = np.asarray(posterior)\n    return posterior",
            "def filtering(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        bayesian filtering\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        posterior : (N, n_hidden) np.ndarray\\n            posterior distributions of each latent variables\\n        '\n    likelihood = self.likelihood(seq)\n    p = self.initial_proba * likelihood[0]\n    posterior = [p / np.sum(p)]\n    for like in likelihood[1:]:\n        p = posterior[-1] @ self.transition_proba * like\n        posterior.append(p / np.sum(p))\n    posterior = np.asarray(posterior)\n    return posterior",
            "def filtering(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        bayesian filtering\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        posterior : (N, n_hidden) np.ndarray\\n            posterior distributions of each latent variables\\n        '\n    likelihood = self.likelihood(seq)\n    p = self.initial_proba * likelihood[0]\n    posterior = [p / np.sum(p)]\n    for like in likelihood[1:]:\n        p = posterior[-1] @ self.transition_proba * like\n        posterior.append(p / np.sum(p))\n    posterior = np.asarray(posterior)\n    return posterior",
            "def filtering(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        bayesian filtering\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        posterior : (N, n_hidden) np.ndarray\\n            posterior distributions of each latent variables\\n        '\n    likelihood = self.likelihood(seq)\n    p = self.initial_proba * likelihood[0]\n    posterior = [p / np.sum(p)]\n    for like in likelihood[1:]:\n        p = posterior[-1] @ self.transition_proba * like\n        posterior.append(p / np.sum(p))\n    posterior = np.asarray(posterior)\n    return posterior",
            "def filtering(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        bayesian filtering\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        posterior : (N, n_hidden) np.ndarray\\n            posterior distributions of each latent variables\\n        '\n    likelihood = self.likelihood(seq)\n    p = self.initial_proba * likelihood[0]\n    posterior = [p / np.sum(p)]\n    for like in likelihood[1:]:\n        p = posterior[-1] @ self.transition_proba * like\n        posterior.append(p / np.sum(p))\n    posterior = np.asarray(posterior)\n    return posterior"
        ]
    },
    {
        "func_name": "viterbi",
        "original": "def viterbi(self, seq):\n    \"\"\"\n        viterbi algorithm (a.k.a. max-sum algorithm)\n\n        Parameters\n        ----------\n        seq : (N, ndim) np.ndarray\n            observed sequence\n\n        Returns\n        -------\n        seq_hid : (N,) np.ndarray\n            the most probable sequence of hidden variables\n        \"\"\"\n    nll = -np.log(self.likelihood(seq))\n    cost_total = nll[0]\n    from_list = []\n    for i in range(1, len(seq)):\n        cost_temp = cost_total[:, None] - np.log(self.transition_proba) + nll[i]\n        cost_total = np.min(cost_temp, axis=0)\n        index = np.argmin(cost_temp, axis=0)\n        from_list.append(index)\n    seq_hid = [np.argmin(cost_total)]\n    for source in from_list[::-1]:\n        seq_hid.insert(0, source[seq_hid[0]])\n    return seq_hid",
        "mutated": [
            "def viterbi(self, seq):\n    if False:\n        i = 10\n    '\\n        viterbi algorithm (a.k.a. max-sum algorithm)\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        seq_hid : (N,) np.ndarray\\n            the most probable sequence of hidden variables\\n        '\n    nll = -np.log(self.likelihood(seq))\n    cost_total = nll[0]\n    from_list = []\n    for i in range(1, len(seq)):\n        cost_temp = cost_total[:, None] - np.log(self.transition_proba) + nll[i]\n        cost_total = np.min(cost_temp, axis=0)\n        index = np.argmin(cost_temp, axis=0)\n        from_list.append(index)\n    seq_hid = [np.argmin(cost_total)]\n    for source in from_list[::-1]:\n        seq_hid.insert(0, source[seq_hid[0]])\n    return seq_hid",
            "def viterbi(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n    '\\n        viterbi algorithm (a.k.a. max-sum algorithm)\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        seq_hid : (N,) np.ndarray\\n            the most probable sequence of hidden variables\\n        '\n    nll = -np.log(self.likelihood(seq))\n    cost_total = nll[0]\n    from_list = []\n    for i in range(1, len(seq)):\n        cost_temp = cost_total[:, None] - np.log(self.transition_proba) + nll[i]\n        cost_total = np.min(cost_temp, axis=0)\n        index = np.argmin(cost_temp, axis=0)\n        from_list.append(index)\n    seq_hid = [np.argmin(cost_total)]\n    for source in from_list[::-1]:\n        seq_hid.insert(0, source[seq_hid[0]])\n    return seq_hid",
            "def viterbi(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n    '\\n        viterbi algorithm (a.k.a. max-sum algorithm)\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        seq_hid : (N,) np.ndarray\\n            the most probable sequence of hidden variables\\n        '\n    nll = -np.log(self.likelihood(seq))\n    cost_total = nll[0]\n    from_list = []\n    for i in range(1, len(seq)):\n        cost_temp = cost_total[:, None] - np.log(self.transition_proba) + nll[i]\n        cost_total = np.min(cost_temp, axis=0)\n        index = np.argmin(cost_temp, axis=0)\n        from_list.append(index)\n    seq_hid = [np.argmin(cost_total)]\n    for source in from_list[::-1]:\n        seq_hid.insert(0, source[seq_hid[0]])\n    return seq_hid",
            "def viterbi(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        n = 10\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n    '\\n        viterbi algorithm (a.k.a. max-sum algorithm)\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        seq_hid : (N,) np.ndarray\\n            the most probable sequence of hidden variables\\n        '\n    nll = -np.log(self.likelihood(seq))\n    cost_total = nll[0]\n    from_list = []\n    for i in range(1, len(seq)):\n        cost_temp = cost_total[:, None] - np.log(self.transition_proba) + nll[i]\n        cost_total = np.min(cost_temp, axis=0)\n        index = np.argmin(cost_temp, axis=0)\n        from_list.append(index)\n    seq_hid = [np.argmin(cost_total)]\n    for source in from_list[::-1]:\n        seq_hid.insert(0, source[seq_hid[0]])\n    return seq_hid",
            "def viterbi(self, seq):\n    if False:\n        i = 10\n        while True:\n            print('Mutation')\n        dp = [0, 1]\n        for i in range(2, n + 1):\n            dp.append(dp[i - 1] + dp[i - 2])\n        print(dp[n])\n\n        def dfs(node):\n            if node == None:\n                return []\n            left = dfs(node.left)\n            right = dfs(node.right)\n        length = 15\n        if length <= 0:\n            return []\n        elif length == 1:\n            return [0]\n        sequence = [0, 1]\n        while len(sequence) < length:\n            next_value = sequence[-1] + sequence[-2]\n            sequence.append(next_value)\n        return sequence\n    '\\n        viterbi algorithm (a.k.a. max-sum algorithm)\\n\\n        Parameters\\n        ----------\\n        seq : (N, ndim) np.ndarray\\n            observed sequence\\n\\n        Returns\\n        -------\\n        seq_hid : (N,) np.ndarray\\n            the most probable sequence of hidden variables\\n        '\n    nll = -np.log(self.likelihood(seq))\n    cost_total = nll[0]\n    from_list = []\n    for i in range(1, len(seq)):\n        cost_temp = cost_total[:, None] - np.log(self.transition_proba) + nll[i]\n        cost_total = np.min(cost_temp, axis=0)\n        index = np.argmin(cost_temp, axis=0)\n        from_list.append(index)\n    seq_hid = [np.argmin(cost_total)]\n    for source in from_list[::-1]:\n        seq_hid.insert(0, source[seq_hid[0]])\n    return seq_hid"
        ]
    }
]